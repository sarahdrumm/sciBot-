On the Streaming Complexity of Computing Local
Clustering Coefficients∗
Konstantin Kutzkov
IT University of Copenhagen
Copenhagen , Denmark konk@itu.dk
Rasmus Pagh
IT University of Copenhagen
Copenhagen , Denmark pagh@itu.dk
ABSTRACT Due to a large number of applications , the problem of estimating the number of triangles in graphs revealed as a stream of edges , and the closely related problem of estimating the graph ’s clustering coefficient , have received considerable attention in the last decade . Both efficient algorithms and impossibility results have shed light on the computational complexity of the problem . Motivated by applications in Web mining , Becchetti et al . presented new algorithms for the estimation of the local number of triangles , ie , the number of triangles incident to individual vertices . The algorithms are shown , both theoretically and experimentally , to efficiently handle the problem . However , at least two passes over the data are needed and thus the algorithms are not suitable for real streaming scenarios .
In the present work , we consider the problem of estimating the clustering coefficient of individual vertices in a graph over n vertices revealed as a stream of m edges . As a first result we show that any one pass randomized streaming algorithm that can distinguish a graph with no triangles from a graph having a vertex of degree d with clustering coefficient > 1/2 must use Ω(m/d ) bits of space in expectation . Our second result is a new randomized one pass algorithm estimating the local clustering coefficient of each vertex with degree at least d . The space requirement of our algorithm is within a logarithmic factor of the lower bound , thus our approach is close to optimal . We also extend the algorithm to local triangle counting and report experimental results on its performance on real life graphs .
Categories and Subject Descriptors F22 [ Analysis of Algorithms and Problem Complexity ] : Nonnumerical Algorithms and Problems
Keywords Graph algorithms , Streaming , Local clustering coefficient , Triangle counting
1 .
INTRODUCTION
The last decades have witnessed a rapid growth of available data . Many of the best known algorithms assume random access to the input , and this turns out to be an infeasible requirement for many real life problems . This motivates the ( semi ) streaming model of computation where only one or a small number of sequential scans of the input are allowed . The model has become a ubiquitous computational paradigm and considerable progress has been made towards a better understanding of the complexity of many basic algorithmic problems .
Graphs are a ubiquitous representation of relationships between objects in real life problems . Many applications require knowledge of certain structural properties of a given graph which will allow a better analysis of the original problem . The clustering coefficient of a graph , introduced in [ 32 ] , gives the probability that two of the neighbors of a vertex chosen at random are connected by an edge . It provides important information about the structure of the graph and the existence of local communities . The computation of the clustering coefficient of a graph , and the closely related problem of computing the total number of triangles in a graph revealed as a stream of edges , have received considerable attention . Becchetti et al . [ 6 ] showed that for certain applications in Web mining the computation of the clustering coefficient of individual vertices is required , and presented a semi streaming algorithm for the problem . In this paper we study whether the problem admits an efficient solution in a real streaming scenario when only one pass over the input graph is allowed .
∗
Work supported by the Danish National Research Council
2 . PRELIMINARIES under the Sapere Aude program .
Notation .
Let G = ( V , E ) be a simple undirected graph without loops . We denote the number of vertices V by n and the number of edges E by m . An edge between the vertices u and v is written as ( u , v ) . We assume a total order on vertices in V and since our graph is undirected and loopless we will consider only edges ( u , v ) with u < v . NG(v ) = {u ∈ V : ( u , v ) ∈ E} is the neighborhood of v . The degree of a vertex v is dv = |NG(v)| , ie , the number of edges adjacent to v . An r clique Kr in G is a subgraph of G on r vertices
677 2 such that for any vertex pair u , v in Kr there exists an edge |{(u , w ) ∈ E : ( u , v ) ∈ E . A triangle is a 3 clique . Tv = 1 ( u , v ) ∈ E , ( v , w ) ∈ E}| is the number of triangles containing v . A 2 path centered at v is a triple of vertices ( u , v , w ) such that there exist edges ( u , v ) , ( v , w ) and u and w are called the endpoints of the 2 path ( u , v , w ) . A triangle on the vertices u , v , w is denoted by fiu , v , w' . The clustering coefficient of a vertex v of degree at least two , denoted as Cv , is defined as the ratio of triangles containing v to the number of 2 paths centered at v . More formally , we define
Cv =
2Tv dv(dv − 1 )
The global clustering coefficient of G is
.
GG =
1 n
Cv . v∈V :d(v)≥2
Note that we define the local clustering coefficient only for vertices of degree at least two . In the literature the clustering coefficient of vertices of degree less than two traditionally has been set to either 0 or 1 , or declared to be meaningless . As discussed in several works , see eg [ 18 , 26 ] , the different definitions have resulted in different results . Therefore , in order to avoid confusions , we consider only graphs with vertices of degree at least two . This is also justified by the real life graphs we consider in our experiments , since they do not contain vertices of degree less than two .
Probability theory .
We assume that the reader is familiar with basic definitions from probability theory . In the analysis of our algorithms we will use these inequalities :
• Markov ’s inequality Let X be a random variable . Then for every λ > 1 :
Pr[X ≥ λE[X ] ] ≤ 1 λ
( 1 ) • Chebyshev ’s inequality . Let X be a random variable and s >0 . Then
Pr[|X − E[X]| ≥ s ] ≤ V [ X ] s2
( 2 ) • Chernoff ’s inequality . We will use the following form of the inequality : Let X1 , . . . , X . be fi independent identically distributed Bernoulli random variables and E[Xi ] = μ . Then for any ε > 0 we have
Xi − μ| > εμ ] ≤ 2e−ε2μ./2
( 3 )
Pr[| 1 fi i=1
A family F of functions from V to a finite set S is k wise independent if for a function f : V → S chosen uniformly at random from F it holds
Pr[f ( v1 ) = c1 ∧ f ( v2 ) = c2 ∧ ··· ∧ f ( vk ) = ck ] = 1 sk for s = |S| , distinct vi ∈ V and any ci ∈ S and k ∈ N . A family H of functions from V to a finite totally ordered set S is called ( ε , k) min wise independent if for any X ⊆ V and Y ⊆ X , |Y | = k , for a function h chosen uniformly at random from H it holds
Pr[max y∈Y h(y ) < min z∈X\Y h(z ) ] = ( 1 ± ε )
1fi|X|
' k
We will refer to a function chosen uniformly at random from a k wise independent family as a k wise independent function . of some quantity q , if it returns a value ˜q , such that ( 1 − ε)q ≤ ˜q ≤ ( 1 + ε)q , with probability at least 1 − δ for any 0 < ε , δ <1 .
We will say that an algorithm returns an ( ε , δ) approximation
The streaming model .
We assume that the input graph is read as a stream of edges . In the literature , two models have been considered . In the incidence list stream model for each vertex u ∈ V the edges ( u , v1 ) , . . . ,( u , vdu ) , ie , all edges adjacent to u , In an adjacency stream model are revealed in succession . edges arrive in arbitrary order . Clearly , the incidence list model provides more information and algorithms analyzed in this model are usually better than algorithms assuming the adjacency stream model . Our results apply to the adjacency stream model .
3 . PREVIOUS WORK
Counting the number of triangles in a graph and computing its clustering coefficient are widely studied problems , with applications ranging from computational biology to mining social networks . It is known that unlike random Erd¨os R´enyi graphs [ 14 ] , real life graphs are characterized by high clustering coefficients , see for instance [ 2 ] , and the clustering coefficient is an important metric for mining knowledge about the original data . For example , Coleman [ 11 ] and Portes [ 25 ] use the clustering coefficient when analyzing human behaviour in social networks , and Becchetti et al . [ 6 ] used it for the detection of spamming activity in large scale Web graphs . The best known exact algorithm [ 3 ] uses as a subroutine matrix multiplication and runs in time O(nω ) , where ω = 2.3727 is the best known exponent for rectangular matrix multiplication [ 30 ] . The algorithm also counts exactly the number of triangles per vertex . Note however that this algorithm is mainly of theoretical importance since it requires random access to the graph , and thus the graph has to fit in memory . Also , currently known asymptotically fast matrix multiplication algorithms do not admit an efficient implementation for realistic input sizes .
Several authors presented sampling based algorithms for the estimation of the global number of triangles in a ( semi)streaming setting [ 5 , 9 , 12 , 16 , 21 , 24 , 28 , 29 ] . Building upon results from linear algebra , researchers proposed techniques for approximate triangle counting not relying on sampling [ 4 , 27 ] . The closely related problem of estimating the global clustering coefficient was considered in [ 10 , 26 ] . The algorithm by Schank and Wagner [ 26 ] is based on sampling and requires two passes over the input graph . The algorithm was improved to work in a single pass by Buriol et al . [ 10 ] at the price of a slightly increased time and space complexity . Motivated by the problem of detection of emerging web communities by analyzing the Web graph [ 22 ] , Buriol et al . [ 10 ] studied the problem of counting bipartite cliques of small size . The more general problem of estimating the number of graph minors of fixed size was studied by Bordino et al [ 7 ] .
678 Despite of the fact that researchers have considered applications involving counting the number of triangles per vertex [ 13 , 23 ] , only recently the problem of estimating the local number of triangles was rigorously studied by Becchetti et al . [ 6 ] . The authors propose two algorithms working in a semi streaming fashion such that the input graph is stored on an external device and a few sequential scans over it are allowed . The algorithms are based on min wise permutation hashing [ 8 ] . Both algorithms use O(n ) main memory . However , the first algorithm also requires sequential writing to a persistent storage device and uses O(m ) external memory . The second algorithm works only in main memory but one cannot theoretically prove that the algorithm achieves an arbitrarily good approximation of the number of triangles at individual vertices . It is easy to adjust the algorithms to work in two passes but there is no straightforward extension of the approach running in a single pass over the input , thus it is not suitable for real streaming applications .
Our contribution .
Algorithms working in only one pass over the input are important since they can be used in real streaming scenarios and thus have a wider range of applications . We study the complexity of estimating the local clustering coefficient by randomized algorithms in one pass over the input from two perspectives :
1 . Lower bound . We show that any one pass randomized algorithm detecting with error probability at most 1/3 if there exists a vertex of degree at least 2d with clustering coefficient at least 1/2 needs Ω(m/d ) bits . This holds even if we guarantee that if there exists any triangle , there exists a vertex with clustering coefficient at least 1/2 .
2 . Upper bound . We design a randomized one pass algorithm deciding with constant error probability whether a given vertex of degree d or more has a clustering coefficient above a given constant threshold α using O( m d ) words . More precisely , we achieve an ( ε , δ)approximation of the clustering coefficient α of all vertices of degree at least d in time O( m δ ) and space O(( m δ ) for any δ , ε , α > 0 . We extend our algorithm to also estimate the number of triangles per high degree vertex . At the end we provide an experimental evaluation of the algorithm .
αε2 log n d + log 1
αε2 log 1
ε log n
ε ) 1
In case d is no larger than the average degree , the space usage is Ω(n ) bits so we are in the semi streaming domain in terms of space usage . Our algorithm has space usage o(n ) whenever the fraction of vertices with degree d or more is sufficiently small . This is the case for many real life graphs . Note that the lower bound is given in bits while the upper bound is terms of the number of sampled edges , ie machine words of O(log n ) bits each . Thus , for a fixed vertex the lower and upper bound match up to a logarithmic factor .
4 . LOWER BOUND
We begin with a negative result that will show the limitations of any randomized one pass algorithm detecting vertices with high clustering coefficient . Lower bounds on the complexity of global triangle counting have been shown in several works [ 5 , 16 , 33 ] .
Theorem 1 . Let G = ( V , E ) be a simple undirected graph without loops over m edges . Any randomized streaming algorithm , performing only one pass over the edges of G and being able to distinguish between a graph where all vertices of degree 2d = o( m ) have a clustering coefficient 0 , and a graph where there is a vertex of degree 2d with clustering coefficient at least 1/2 , with error probability 1/3 , must use Ω(m/d ) bits in expectation .
√
, . . . , wy
1
1 , . . . , ux
1 , . . . , wx , . . . , uy d} , U x = {ux
Proof . Let DetectClusteredVertices be a randomized streaming algorithm detecting vertices with high clustering coefficient in G . Assume without loss of generality that m/(2d ) is integer . We show that if DetectClusteredVertices uses s bits of memory , this would imply a protocol for the Set Disjointness problem on strings x , y ∈ {0 , 1}m/(2d ) using s bits of communication . This problems has answer 1 if there exists an index i such that xi = yi = 1 , and answer 0 otherwise . By existing lower bounds on the randomized communication complexity of Set Disjointness [ 19 ] this implies that s = Ω(m/d ) bits are needed for any constant error probability smaller than 1 . Denote by xi the ith bit in the string x . We will reduce the Set Disjointness problem to detecting vertices with clustering coefficient more than 1/2 in a graph revealed as a stream of edges in the adjacency stream model . Let W x = d} , U y = d} , W y = {wy {wx {uy d} be four sets of d vertices each . The reader is referred to Figure 1 for a graphical description of our construction . We read x ∈ {0 , 1}m/(2d ) bit by bit and create a vertex vi for the ith index in x . If xi = 0 , then we feed Detectj ) , 1 ≤ j ≤ d . ClusteredVertices with the d edges ( vi , ux If xi = 1 , then we feed DetectClusteredVertices with j ) , 1 ≤ j ≤ d . We proceed with the bits in the d edges ( vi , wx y in the same way but we create edges ( vi , uy j ) and ( vi , wy j ) . j ) , 1 ≤ i , j ≤ d , for wx j ∈ W y . Now it is easy to see fi that the graph contains a triangle if and only if there exists an i such that xi = yi = 1 , and in this case the clustering coefficient of vi is d2/ > 1/2 , otherwise all vertices have clustering coefficient 0 . Also , each vertex vi has degree exactly 2d , the total number of vertices is m/(2d ) + 4d and for d = o( m ) the number of edges is m + d2 = O(m ) . Thus , we have reduced the Set Disjointness problem for input strings x , y ∈ {0 , 1}m/(2d ) to the problem of distinguishing between vertices of degree d with clustering coefficient 0 or more than 1/2 in streamed graphs over O(m ) edges . We conclude that DetectClusteredVertices needs Ω(m/d ) bits for graphs over m edges .
After processing x and y we add d2 edges ( wx i ∈ W x , wy ' i , wy
1
2d 2
√
One can extend the above proof such that the vertices vi can also have odd degree in a trivial way . For a better readability we choose not to present this extension here .
The above lower bound supports the intuition that the space requirements of any randomized one pass algorithm for estimating the clustering coefficient of individual vertices , should not depend only on the value of the coefficient but also on the vertex degree . In order to estimate the clustering coefficient of a given vertex v we need some kind of sampling of 2 paths centered at v for which we can check whether they are a part of a triangle . But to obtain a good estimate of low degree vertices , without any prior knowledge about the degree distributions in the graph , we need a low sampling probability , which in turn results in many sampled edges .
679 W x
W y v1 v2 v3 v4 v5 v6 v7 v8 v9 v10
Vbits
U x
U y
Figure 1 : An example of a hard instance for our lower bound construction . The edges going out from v1 denote that x1 = 1 and y1 = 0 . Similarly , we see that x4 = 0 and y4 = 1 , while x6 = y6 = 0 and x10 = y10 = 1 . Only v10 among the considered vertices is part of a triangle and has a clustering coefficient larger than 1/2 .
5 . ONE PASS ALGORITHM
In this section we present a randomized one pass algorithm estimating the clustering coefficient of vertices of degree above some threshold d . In Section 5.1 we first give some intuition what are the difficulties for the estimation of the clustering coefficient in only one pass and then describe the main idea behind the new algorithm . A thorough description and theoretical analysis of our algorithm is given is Section 52 In Section 5.3 we show how to extend the algorithm to local triangle counting for high degree vertices . In Section 5.4 we conclude with an experimental evaluation of the performance of the algorithm on real life graphs .
5.1 Intuition
A straightforward idea for the estimation of the clustering coefficient in only one pass of high degree vertices is to sample independently each incoming edge with a certain probability p . Then in the sparsified graph we compute the clustering coefficient for all vertices . This sparsification approach is essentially the Doulion algorithm [ 28 , 29 ] , which was shown to accurately estimate the number of triangles in a graph given as a stream of edges . Let us consider a vertex v contained in a triangle fiu , v , w' . The probability that we will sample the 2 path ( u , v , w ) is p2 while the probability to sample the triangle fiu , v , w' is p3 . Thus , we have to multiply by 1/p the clustering coefficient we have computed for each vertex in the sparsified graph in order to obtain in expectation the true clustering coefficient . But this means that the estimates obtained from the sparsified graph need to be very accurate in order to obtain a concentration around the expected value with high probability , which in turn implies a large value for the sampling probability p resulting in large space consumption .
A simple algorithm can work as follows : for each vertex v we sample independently a number of 2 paths ( u , v , w ) and for each of them check whether the edge ( u , w ) exists in the graph . The approach can be implemented in three passes over the edges . In the first pass we find a set of candidate vertices of degree at least d . This can be done by a frequent items mining algorithms , eg [ 20 ] , in space O(m/d ) such that each vertex of degree d or more is guaranteed to be among the candidates . In a second pass we determine the set of vertices of degree d or more and the exact degree of each of them . Then for each vertex v of degree d or more we sample a number of 2 paths ( u , v , w ) and check whether the edge ( u , w ) appears in the stream , this can be done for example using reservoir sampling [ 31 ] as shown in [ 9 ] . It is easy to show that the sketched algorithm will compute an ( ε , δ) approximation of a vertex of degree at least d and clustering coefficient α in space O( m dε2α log 1 δ )
In the next section we show how to combine the above two approaches to work for high degree vertices in only one pass over the input graph achieving essentially the same space complexity . We will use the idea of monochromatic sampling [ 24 ] . Basically , we randomly color the vertices and then take an edge in the sample iff its endpoints have the same color . Clearly , if two of the edges of a triangle are sampled , the third edge must also be sampled . Thus , for a sampled 2 path ( u , v , w ) , after processing the stream of edges we can check whether there exists a triangle fiu , v , w' . The sampling probability for a triangle fiu , v , w' is the same as for the 2 path ( u , v , w ) , namely p2 . 5.2 The algorithm
A high level pseudocode description of our algorithm is given in Figure 2 . The main method is EstimateClusteringCoefficients . It reads the input graph as a stream of edges in arbitrary order . First we run K independent copies of SparsifyGraph in parallel . Assume we have defined a k wise independent function f : V → [ 0 , 1]1 , for a k that will be specified later . Let C be a natural number denoting the number of colors . Then we sample each incoming edge ( u , v ) iff ffCf ( u)fi = ffCf ( v)fi , where ffrfi denotes that the real number r is mapped to the biggest integer smaller than ( or equal to ) r , ie , we map to one of C colors . At the end we obtain a sparsified graph where all edge endpoints have the same color . Obviously , if C = d , we expect sparsified graphs with m/d edges . In order to control the space usage of the algorithm , we check after each edge has been sampled whether not more than t edges are sampled , for a user defined t . If this is the case , then the algorithm breaks its execution and returns an empty graph .
Clearly , if we have sampled a 2 path ( u , v , w ) , then , if existent , we must have also sampled the edge ( u , w ) . In CheckTwoPaths for each vertex with at least two sampled neighbors we choose the two of these neighbors for which f gives the smallest value and check whether the considered 2 path is part of a triangle . We will show that the expected value is an almost unbiased estimator of the clustering coefficient of vertex v such that the bias depends on how independent is the coloring function . Assume we return R ≤ K nonempty graphs . At the end , for each vertex v with at least R/2 sampled 2 paths ( u , v , w ) we output as an estimate of the clustering coefficient αv the ratio of triangles to 2 paths centered at v obtained from the samples .
1In fact , f maps V to a discrete set uniformly distributed on the unit interval .
680 4
Theorem 2 . Let G = ( V , E ) be a graph over n variables revealed as a stream of m edges . Let further K = δ , C = d/4 colors , fi : V → [ 0 , 1 ] , 1 ≤ i ≤ K , αε2 log n ε ) , and t = be k wise independent , such that k = O(log 1 9m/d . Then EstimateClusteringCoefficients returns an ( ε , δ) approximation of the clustering coefficient for all vertices of degree at least d and clustering coefficient at least α for any ε , α , δ > 0 . The expected running time of the algorithm is O( m δ ) and the worst case space complexity is O(( m
αε2 log 1 d + log 1
ε log n ε ) 1
αε2 log n
δ ) .
Proof . Let us assume that we run K parallel instances of SparsifyGraph . In the following we will obtain a bound on K that will guarantee the claimed bounds . We will estimate the probability for each of three “ bad ” events that lead to an incorrect estimate . Assume first that for a given vertex v we have sampled fi ≤ K 2 paths ( ui , v , wi ) , each in one of the copies of the algorithm run in parallel . For a given non empty sparsified S , 1 ≤ i ≤ fi , introduce an indicator random varigraph Gi able Xi , 1 ≤ i ≤ fi , such that Xi = 1 iff ( ui , wi ) ∈ Gi S , ie , if u , v , w form a triangle . We first show that for a random enough coloring function fi , E[Xi ] is an almost unbiased estimator of α . Let v ’s clustering coefficient be αv and let us define a function h : N ( v ) → [ 0 , 1 ] as h(u ) = ( f ( u ) − f ( v ) ) mod 1 for u ∈ N ( v ) . It is easy to see that the two vertices u , w yielding the smallest values h(u ) and h(w ) are those yielding the smallest values f ( u ) and f ( w ) larger than f ( v ) . Thus , under the assumption that |Nv(GS)| ≥ 2 , choosing the two neighbors of v in GS with the smallest values given by f corresponds to choosing the two vertices in Nv(G ) with the smallest values given by h . If f is k wise independent under the assumptions that f ( v ) evaluates to a certain value , we have that h is ( k−1) wise independent . For k = O(log 1 ε ) , h is then ( ε , 2) min wise independent , see [ 15 ] for the state of the art result . Thus , the chosen pair of vertices is sampled almost uniformly at random among all pairs of v ’s neighbors and we have ( 1− ε)αv ≤ E[Xi ] ≤ ( 1 + ε)αv . Xi as an estimation of αv . The functions fi are independent and thus the colorings are also independent . Consequently the indicator random variables Xi are independent , thus by applying Chernoff ’s inequality and using ε < 1 we bound the probability that ˜αv is not an ( 1 ± 3ε) approximation is upper bounded by 2 −ε2αv /2 Since α ≤ αv , we need
We return ˜αv = 1 . ff . i=1 fi = log 3 ε2α log n δ such that the error probability for a single vertex is bounded by δ 3n . Thus , the error probability of the estimate for any vertex is δ/3 .
Second , let us assume that the K parallel instances return R non empty graphs , ie , in R cases we have not sampled more than the allowed t edges . We estimate how many independent colorings , each for C = d/4 colors , are needed such that we obtain at least fi = log 3 δ samples for a vertex of degree at least d . Consider a given vertex v with dv ≥ d . We have d 4 colors and thus a sampling probability of d . We introduce an indicator random variable X1 , . . . , Xdv 4 for each neighbor ui of v , denoting whether f ( v ) = f ( ui ) . Xi . We want to bound Pr[X ≤ 1 ] . Clearly , Let X = ≥ 4 . The Xi are {0 , 1} valued , and we have E[X ] = 4dv d wlog we can assume that f is 3 wise independent , there
ε2α log n ffdv i=1 fore it is easy to see that V [ X ] ≤ E[X ] . Thus , we can set s = E[X ] − 1 in Chebyshev ’s inequality and obtain
Pr[|X − E[X]| ≥ E[X ] − 1 ] ≤
V [ X ]
( E[X ] − 1)2
≤
E[X ]
( E[X ] − 1)2
≤ 4 9 for dv ≥ d . Now , we introduce an indicator random variable Y v for vertex v of degree at least d , denoting whether i enough edges have been sampled in the ith sparsified graph , 1 ≤ i ≤ S . Clearly , E[Y v i ] ≥ 5/9 . Since the colorings are independent , we can apply again Chernoff ’s inequality and bound the probability for not enough sampled edges . Therefore , if we have
R = 2 n log 3 ε2α log δ ε2α log n the probability that in fi = log 3 δ graphs for any vertex of degree at least d we have less than two sampled neighbors , is upper bounded by δ/3 .
Finally , we have to consider the possibility that too many edges have been sampled and the algorithm returns an empty graph . By simply applying Markov ’s inequality for a sampling probability 4 d we get that with probability 4/9 more than 9m d edges are sampled . We apply again Chernoff ’s inequality . Running
K = 4 log 3 ε2α log n δ copies in parallel , we bound the probability that too many edges are sampled in more than R = 2 log 3 δ of the copies , to δ/3 .
ε2α log n
Summing up , the probability that either too many edges are sampled , or not enough neighbors for a vertex of degree d are sampled , or the algorithm does not return an ( 1 ± ε) approximation of the clustering coefficient for vertices of degree at least d , is 3(δ/3 ) = δ for 0 < δ <1 .
A O(log 1
ε ) wise independent function can be defined in ε ) machine words and evaluated in time O(log 1
O(log 1 ε ) . Note that for a approximation parameter ε that can be described in constant number of machine words , log 1 ε is constant . Storing the adjacency lists of the vertices in the sparsified graphs in hashtables , we can achieve expected constant update time per incoming edge . The sampling of 2 paths and checking whether they are contained in a triangle can thus be done in expected linear time in the size of the sparsified graph . The size of the hash table H is clearly bounded by the number of sampled edges in the R non empty graphs and the expected time for update and look up is constant . The time and space complexity of the algorithm follow then immediately from the above discussion .
The size of the input graph .
In the above analysis we assume that the number of edges and vertices are known in advance . If this is not the case , one can start with a conservative choice for the number of colors and , if too many edges have been sampled , scale the sampling probability , ie , increase the number of colors . When presenting the implementation of our algorithm we discuss more details about this , but we omit the rigorous description of this extension .
681 SameColor Input : a k wise independent function f : V → [ 0 , 1 ] , num ber of colors C , vertices u and v
1 : if ffCf ( u)fi = ffCf ( v)fi then 2 : 3 : else 4 : return false return true
SparsifyGraph Input : stream of edges E , number of colors C , k wise inde pendent function f : V → [ 0 , 1 ] , threshold t if SameColor(f , C , u , v ) then
1 : GS = ∅ 2 : for each edge ( u , v ) ∈ E do 3 : GS = GS ∪ ( u , v ) . 4 : if |GS| > t then 5 : 6 : 7 : Return GS . return the empty graph .
CheckTwoPaths Input : a sparsified graph GS 1 : for each vertex v ∈ GS such that |NGS ( v)| ≥ 2 do 2 : choose the two neighbors u , w , u < w , from NGS ( v ) with the smallest f ( u ) and f ( w ) sampled(v ) = true if ( u , w ) ∈ GS then
3 : 4 : 5 : 6 : 7 : 8 : Return a set of pairs ( v , Xff(v ) ) such that v ∈ V and
Xff(v ) = 1 //there is a triangle
Xff(v ) = 0 //no triangle else sampled(v )
EstimateClusteringCoefficients
Input : a stream of edges E , a family of K k wise functions fi : V → [ 0 , 1 ] , number of colors C , Hashtable HfiV , fiInt , Int'' , int K , threshold t
1 : Run in parallel K copies of SparsifyGraph(E , C , fi , t ) 2 : for each of R returned non empty sparsified graph Gi S do else if v /∈ H then pv = tv = 0
VP = CheckTwoPaths(Gi S ) for each ( v , Xff(v ) ) ∈ VP do
3 : 4 : 5 : 6 : 7 : 8 : 9 : 10 : 11 : 12 : 13 : for each ( v , ( pv , tv ) ) ∈ H with pv ≥ R/2 do 14 : pv++ if Xff(v ) == 1 then get ( v , ( pv , tv ) ) from H put ( v , ( pv , tv ) ) in H
Return ( v , tv/pv ) . tv++
Figure 2 : A high level pseudocode description of the algorithm .
5.3 Local triangle counting
It is easy to extend the algorithm to count the local number of triangles for vertices of sufficiently high degree . All we need is to also estimate the number of 2 paths per highdegree vertex . Indeed , we already have the necessary components for the analysis . In the following theorem we show how to estimate the degree of a vertex for which we have sampled at least R/2 times at least two neighbors and that for high degree vertices we can obtain a high quality estimate of the degree . We will use the same notation as in the proof of Theorem 2 .
ε log n
αε2 log n
αε2 log 1 ε ) 1
δ ) for any ε , α , δ > 0 .
Theorem 3 . Let G = ( V , E ) be a graph over n variables revealed as a stream of m edges . There exists a randomized one pass algorithm achieving an ( ε , δ) approximation of the number of triangles centered at each vertex of degree at least d and a clustering coefficient at least α in expected time O( m δ ) and worst case space complexity O(( m d + log 1 Proof . Consider a vertex v of degree dv ≥ d . We first show how to obtain an approximation of dv . Assume we extend EstimateClusteringCoefficients in the following way . For each vertex with at least one sampled neighbor we record the number of sampled neighbors in each sparsified graph . δ non empty sparsified graphs for some ε > 0 that will be specified later . Let us logically divide them into log n 3 ε . 2 graphs . In each group for each sparsified graph we introduce an indicator random variable Xi , 1 ≤ i ≤ dv , for each of the dv Xi , ie , X is the sum of the neighbors of v . Let X = Xi in all groups . Clearly , E[X ] = 3dv dε . 2 . Also , we can assume that the coloring function is 3 wise independent and the 3 ε.2 colorings are independent , thus we have V [ X ] ≤ E[X ] . We apply Chebyshev ’s inequality with s = εE[X ] :
Assume we return S = 3 ff 3dv
δ groups of
ε.2 log n
ε.2 i=1
Pr[|X−E[X]| ≥ εE[X ] ] ≤ V [ X ] ε2E[X]2
≤
1
ε2E[X ]
= d 3dv
≤ 1 3
3
In each of the log n
δ groups we then estimate dv as dε.2X , which is with probability at least 2/3 ( 1± ε ) approximation of dv . Now we return the median of the estimates , ˜dv , in the log n δ groups . The colorings in the groups are independent and a standard application of Chernoff ’s inequality yields that the median will not be an ( 1 ± ε ) approximation of dv with error probability δ/n . Summing up , the error proba' bility for any vertex is bounded by δ . ˜αv , where ˜αv is an ( 1 ± ε ) approximation of the clustering coefficient αv . With some algebra one can obtain that this yields an ( 1± 7ε ) approximation of the number of triangles at v .
An estimate of the number of triangles at v is now fi ˜dv
2
The bounds on the running time and the space complexity of the algorithm easily follow from Theorem 2 and the above discussion .
For the case of directed graphs the algorithm can be extended to distinguish between the four possible kinds of triangles [ 6 ] a high degree vertex can be involved in . The only difference is that we will count only the kind of triangles we are interested in . We defer the description of the extension to the full version of the paper .
682 5.4 Experiments
We implemented our algorithm in Java and ran experiments on a Windows machine with an Intel Core i5 with 2.66 GHz clocked processor with 3 MB Cache . The available RAM memory was 4 GB . Due to the relatively small amount of memory , we ran the copies of SparsifyGraph sequentially , thus we will not report results on the running time . It is clear that this modification does not affect in any way the estimates obtained by our algorithm . For our coloring function we created random numbers r(v ) , v ∈ V , in the interval [ 0 , 1 ) by reading for each vertex 64 random bits from the Marsaglia Random Number CDROM2 . Then for a given number of colors C two vertices u , v have the same color iff ffC · r(u)fi = ffC · r(v)fi . When the graph size is not known in advance , one can dynamically adjust the sampling probability as follows . Once we have that too many edges have been sampled , we double the number of colors , C = 2C , and throw away edges that are not any more monochromatic .
We performed experiments on several graphs and chose to present results for two representative graphs , which we think illustrate best the advantages and limitations of the algorithm . Also , we present only experiments on the estimation of the local clustering coefficient , since the estimates on the local number of triangles yield identical observations . The first graph , Web BerkStan , is taken from the SNAP library 3 . It is a directed Web graph in which an edge ( u , v ) shows that there is a link from a page u in the domain berkeley.edu to a page v in the domain stanfordedu We made the graph undirected such that there is an edge ( u , v ) for pages u and v connected by a link in either direction and removed loops . The resulting graph consists of 680,485 vertices and 15,190,579 edges .
Following [ 10 ] we created a graph MovieActors1000 from the Internet Movie Database4 . From a set of 1,000 movies , with at least 10 actors starring , we created an undirected graph such that an edge ( u , v ) records that the actors u in v star together in at least one movie . The resulting graph has 19,037 vertices and 6,501,181 edges .
Clearly , the first graph Web BerkStan is very sparse , average degree of 22.323 , while MovieAvtors1000 is a relatively dense graph with an average degree of 341502 Also , the degree distribution in Web BerkStan is quite skewed , the largest degree being 84,290 while the largest degree in MovieActors1000 is only 2,542 .
The number of edges in the two graphs is of the same order , thus we compared the results for a fixed sparsification rate of 0.001 and a varying number of parallel copies of SparsifyGraph . For the two graphs we computed exactly the clustering coefficient for vertices of degree at least 1,000 . Note that we chose a smaller sampling probability than the one given by Theorem 2 such that estimates for vertices of degree at least 1,000 will be reported with high probability . The reason is that allows a clearer overview of ( dis)advantages of the algorithm for the two considered graphs . In Web BerkStan there are 568 vertices of degree at least 1,000 , while in MovieActors1000 there are 1,161 such vertices . The average clustering coefficient for the considered high degree vertices for Web BerkStan is 0.030141 , while for MovieActors1000 it is 0466
2http://wwwstatfsuedu/pub/diehard/cdrom/ 3http://snapstanfordedu/data/ 4http://wwwimdbcom/
Let H be the set of vertices of degree at least 1,000 for which estimates were reported and let h = |H| . Let further Cv be the exact clustering coefficients for vertices v ∈ H and ˜Cv be the corresponding approximation we obtain . Following [ 6 ] we evaluated our algorithm with respect to the following measures :
1 . Average relative error
|Cv − ˜Cv| v∈H
Cv
2 . Pearson correlation coefficient . ff r = ff v∈H
( h h v∈H C 2v − (
Cv ˜Cv − ff ff v∈H
Cv)2)(h v∈H ff
Cv ff
˜Cv v∈H ˜C 2v − ( v∈H ff v∈H
˜Cv)2 )
3 . Spearman ’s rank correlation .
Let Exact and Approx be two sets containing the exact and approximated clustering coefficients . Sorting Exact and Approx in decreasing order , for each vertex v ∈ H we define dist(v ) = rExact(Cv ) − rApprox( ˜Cv ) , where rS(x ) is the rank of the element x ∈ S in the sorted sequence S . Then the Spearman ’s rank correlation is defined as ρ = 1 − 6
2 v∈H dist(v ) h(h2−1 )
.
For a number of parallel copies of the algorithm , varying between 50 and 400 , we evaluated the quality of the achieved estimates . Note that this means that the sparsification factor is between 5 % and 40 % . We report estimates on the clustering coefficient of vertices v ∈ V for which in at least half of the copies a 2 path centered at v was recorded .
Our first observation is that the larger skew in degree distributions in Web BerkStan results in a higher recall in reported results for vertices of degree 1,000 or more . For Web BerkStan for all number of parallel copies estimates for more than 80 % of the high degree vertices were reported while for MovieActors1000 the recall never exceeded 50 % .
Not surprisingly , the larger the number of samples the better approximation is achieved . Figures 3 and 4 show the achieved approximation of clustering coefficient of reported high degree vertices for the two graphs for a sparsification ratio of 20 % . The approximation is tighter for the MovieActors1000 graph while for Web BerkStan it is more dispersed but this is due to the larger clustering coefficients in the former graph . This is also confirmed by the plot in Figure 5 where we see that the average relative error is much smaller for MovieActors1000 . However , the correlation of the estimates of the clustering coefficient for high degree vertices and its true value is comparable for the two graphs as can be seen in Figures 6 and 7 .
The above evaluation , as well as other experiments we performed but not report here , lead to the following observations :
• For graphs with a very skewed degree distribution we can report good estimates only for a fraction of the vertices if we want to achieve notable space savings . This is in accordance with the result in Theorem 1 and we believe that this is the best one can hope for . On the other hand the high degree vertices are correctly identified .
683 • For graphs with a lighter skew in the degree distribution however , our algorithm is able to yield good results for a reasonably big proportion of the vertices . A drawback is that it becomes more difficult to detect all high degree vertices .
• Even in cases when the estimates do not approximate very good the exact values , as in Web BerkStan , there is a clear correlation between estimates and exact values .
It is worth noting that we did not perform experiments on the large Web scale graphs considered in [ 6 ] . For the full version of the paper we are planning to present a more thorough experimental evaluation on datasets from different domains .
0.14
0.12
0.1 t
Exact Approximation i n e c i f f e o c g n i r e t s u C l
0.08
0.06
0.04
0.02
0
0
50
100
150
200
250
Vertices
300
350
400
450
500
Figure 3 : Exact and approximated clustering coefficients of high degree vertices for Web BerkStan . t i n e c i f f e o c g n i r e t s u C l
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Exact Approximation
50
100
150
200
250
300
350
400
450
Vertices
Figure 4 : Exact and approximated clustering coefficients of high degree vertices for MovieActors1000 .
6 . FUTURE DIRECTIONS
We have presented results on the streaming complexity of randomized algorithms estimating the local clustering coefficient . The upper and lower bound on the space usage almost match . We believe that our algorithm is almost optimal in terms of space requirements and an open question is to obtain a tight bound on the space complexity of the problem . Also , it would be interesting whether a similar lower bound is possible for the incidence list stream model .
Web−BerkStan MovieActor1000
1.4
1.2
1
0.8
0.6
0.4
0.2 r o r r e e v i t l a e r e g a r e v A
0 50
100
150
200
250
Parallel copies
300
350
400
Figure 5 : Average relative error for a varying number of parallel copies for the two graphs .
Web−BerkStan MovieActor1000
1
0.95
0.9
0.85
0.8
0.75
0.7
0.65 t i n e c i f f e o c t i n e c i f f e o c n o s r a e P
50
100
150
200
250
Parallel copies
300
350
400
Figure 6 : Pearson correlation coefficient for a varying number of parallel copies for the two graphs .
We expect that certain heuristics can improve the running time performance of our algorithm . For example , for many vertices we sample more than two neighbors and we can check for more 2 paths whether they are involved in a triangle . However , one should not consider 2 paths sharing an edge since this will increase the variance of the estimates and the bounds in Theorem 2 will not hold any more .
Also , the advantages of monochromatic sampling compared to na¨ıve sampling of edges become more pronounced if one wants to count the number of k cliques or more generally dense subgraphs of fixed size , both locally and globally , for k > 3 . For example , inspired by concrete applications in Web mining , Bordino et al . [ 7 ] present an extension of the approach by Buriol et al . [ 9 ] to counting graph minors of fixed size . Many of the graph minors are dense , thus it is interesting to study whether using monochromatic sampling one can design better algorithms .
An interesting direction is to study whether one can combine our approach with ideas from Lp sampling in order to obtain an algorithm for the more general problem of processing dynamic graph streams , where edge deletions are also allowed , see eg [ 1 , 17 ] .
Acknowledgements .
We thank Paolo Boldi for useful discussions in the early stage of this work .
684 improvement for min wise based algorithms . Inf . Comput . 209(4 ) : 737–747 ( 2011 )
[ 16 ] H . Jowhari , M . Ghodsi . New Streaming Algorithms for Counting Triangles in Graphs . COCOON 2005 : 710–716
[ 17 ] H . Jowhari , M . Saglam , G . Tardos . Tight bounds for Lp samplers , finding duplicates in streams , and related problems . PODS 2011 : 49–58
[ 18 ] M . Kaiser . Mean clustering coefficients : the role of isolated nodes and leafs on clustering measures for small world networks . New J . Phys . 10 , 2008 .
[ 19 ] B . Kalyanasundaram , G . Schnitger . The Probabilistic Communication Complexity of Set Intersection . SIAM J . Discrete Math . 5(4 ) : 545–557 ( 1992 )
[ 20 ] R . M . Karp , S . Shenker , C . H . Papadimitriou . A simple algorithm for finding frequent elements in streams and bags . ACM Trans . Database Syst . 28 : 51–55 ( 2003 )
[ 21 ] M . N . Kolountzakis , G . L . Miller , R . Peng , C . E . Tsourakakis . Efficient Triangle Counting in Large Graphs via Degree based Vertex Partitioning . Internet Mathematics , to appear
[ 22 ] R . Kumar , P . Raghavan , S . Rajagopalan , A . Tomkins .
Trawling the Web for Emerging Cyber Communities . Computer Networks 31(11 16 ) : 1481–1493 ( 1999 ) [ 23 ] M . E . J . Newman . The structure and function of complex networks . SIAM Review , 45(2):167–256 , 2003
[ 24 ] R . Pagh , C . E . Tsourakakis . Colorful triangle counting and a MapReduce implementation . Inf . Process . Lett . 112(7 ) : 277–281 ( 2012 )
[ 25 ] A . Portes . Social capital : Its origins and applications in modern sociology . Annual Review of Sociology , 24(1):1–24 , 1998 .
[ 26 ] T . Schank , D . Wagner . Approximating Clustering
Coefficient and Transitivity . J . Graph Algorithms Appl . 9(2 ) : 265–275 ( 2005 )
[ 27 ] C . E . Tsourakakis . Fast Counting of Triangles in
Large Real Networks without Counting : Algorithms and Laws . ICDM 2008 : 608–617
[ 28 ] C . E . Tsourakakis , U . Kang , G . L . Miller , C .
Faloutsos . DOULION : counting triangles in massive graphs with a coin . KDD 2009 : 837–846
[ 29 ] C . E . Tsourakakis , M . N . Kolountzakis , G . L . Miller . Triangle Sparsifiers . J . of Graph Algorithms and Appl . 15(6 ) : 703–726 ( 2011 )
[ 30 ] V . Vassilevska Williams . Multiplying matrices faster than Coppersmith Winograd . STOC 2012 , 887–898
[ 31 ] J . S . Vitter . Random Sampling with a Reservoir . ACM
Trans . Math . Softw . 11(1 ) : 37–57 ( 1985 )
[ 32 ] D . J . Watts , S . H . Strogatz . Collective dynamics of “ small world ” networks . Nature , 393 : 440–442 , 1998 .
[ 33 ] S . Zhang . Streaming Algorithms Measured in Terms of the Computed Quantity . COCOON 2007 : 338–348
Web−BerkStan MovieActor1000
1
0.95
0.9
0.85
0.8
0.75
0.7 n o i t l a e r r o c k n a r n a m r a e p S
0.65
50
100
150
200
250
Parallel copies
300
350
400
Figure 7 : Spearman rank correlation for a varying number of parallel copies for the two graphs .
7 . REFERENCES [ 1 ] K . J . Ahn , S . Guha , A . McGregor . Graph sketches : sparsification , spanners , and subgraphs . PODS 2012 : 5–14
[ 2 ] R . Albert , A L Barab´asi . Statistical mechanics of complex networks . Rev . Mod . Phys . 74 , 47–97 ( 2002 ) [ 3 ] N . Alon , R . Yuster , U . Zwick . Finding and Counting
Given Length Cycles . Algorithmica 17(3 ) : 209–223 ( 1997 )
[ 4 ] H . Avron . Counting triangles in large graphs using randomized matrix trace estimation . Large Scale Data Mining : Theory and Applications ( KDD Workshop ) , 2010 .
[ 5 ] Z . Bar Yossef , R . Kumar , D . Sivakumar . Reductions in streaming algorithms , with an application to counting triangles in graphs . SODA 2002 : 623–632
[ 6 ] L . Becchetti , P . Boldi , C . Castillo , A . Gionis . Efficient algorithms for large scale local triangle counting . TKDD 4(3 ) : ( 2010 )
[ 7 ] I . Bordino , D . Donato , A . Gionis , S . Leonardi . Mining Large Networks with Subgraph Counting . ICDM 2008 : 737–742
[ 8 ] A . Z . Broder , M . Charikar , A . M . Frieze , M . Mitzenmacher . Min Wise Independent Permutations . STOC 1998 : 327–336
[ 9 ] L . S . Buriol , G . Frahling , S . Leonardi , A .
Marchetti Spaccamela , C . Sohler . Counting triangles in data streams . PODS 2006 : 253–262
[ 10 ] L . S . Buriol , G . Frahling , S . Leonardi , C . Sohler .
Estimating Clustering Indexes in Data Streams . ESA 2007 : 618–632
[ 11 ] J . S . Coleman . Social capital in the creation of human capital . American Journal of Sociology , 94 : 95–120 , 1988
[ 12 ] D . Coppersmith , R . Kumar . An improved data stream algorithm for frequency moments . SODA 2004 : 151–156
[ 13 ] J P Eckmann and E . Moses . Curvature of co links uncovers hidden thematic layers in the world wide web . PNAS , 99(9):5825–5829 , 2002 .
[ 14 ] P . Erd¨os , and A . R´enyi . On the evolution of random graphs . Publ . Math . Inst . Hungar . Acad . Sci . 5 17–61 , 1960
[ 15 ] G . Feigenblat , E . Porat , A . Shiftan . Exponential time
685
