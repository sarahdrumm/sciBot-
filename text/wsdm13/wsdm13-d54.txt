News Recommendation via Hypergraph Learning : Encapsulation of User Behavior and News Content
School of Computing and Information Sciences
School of Computing and Information Sciences
Lei Li
Florida International University
Miami , FL 33199 lli003@csfiuedu
Tao Li
Florida International University
Miami , FL 33199 taoli@csfiuedu
ABSTRACT Personalized news recommender systems have gained increasing attention in recent years . Within a news reading community , the implicit correlations among news readers , news articles , topics and named entities , eg , what types of named entities in articles are preferred by users , and why users like the articles , could be valuable for building an effective news recommender . In this paper , we propose a novel news personalization framework by mining such correlations . We use hypergraph to model various high order relations among different objects in news data , and formulate news recommendation as a ranking problem on fine grained hypergraphs . In addition , by transductive inference , our proposed algorithm is capable of effectively handling the socalled cold start problem . Extensive experiments on a data set collected from various news websites have demonstrated the effectiveness of our proposed algorithm .
Categories and Subject Descriptors : H33[Information Search and Retrieval ] : Information filtering
General Terms : Algorithms , Design , Experimentation
Keywords : Personalization , News Recommendation , Hypergraph Learning , Named Entity , Transductive Inference
1 .
INTRODUCTION
Common research efforts in personalized news recommendation can be divided into two categories : ( 1)modeling user profiles by analyzing news content in users’ consumption history and then retrieving relevant news articles for recommendation ( content filtering ) ; and ( 2)analyzing reading behaviors of users similar to the target user and then recommending items based on the collaborative activities ( collaborative filtering ) . Many hybrid methods , which integrate the above two categories of algorithms , have also been developed . Despite extensive recent advances , several critical issues in news recommendation have not been well explored in previous studies , including user profiling ( ie , how to obtain high quality user profiles from historical consumptions of users? ) , news evolving ( ie , how to recommend news items that are newly published and without enough accessing activities ? ) and user cold start ( ie , how to provide reasonable recommendation for new users ? ) [ 21 ] .
A key step in news recommender systems is to build the readers’ preference profiles based on their historical consumption , ie , the reading history . Traditionally , user profiling is conducted by extracting representative elements ( eg , words or phrases ) from the reading history or selecting similar access patterns . However , users’ historical consumption may contain a gigantic amount of element correlations , eg , a group of users like the same topic , which cannot be well captured by the aforementioned profiling paradigms .
Further , online readers tend to prefer some named entities in news articles , eg , when the event happened , where it happened , who were involved , etc . These types of entities can attract online readers’ interest since they contain concise information about the news article itself . Therefore , named entities would be valuable to model users’ preferences . However , few research efforts have been reported on utilizing named entities for user profiling . In [ 12 ] and [ 20 ] , named entities extracted from news articles are represented as an entity vector , and then the similarity based on such a vector is calculated for retrieving relevant news items . Such a representation might cause the information loss of news access data , eg , what type of entities is preferred by a group of users , and therefore render user profiling less effective .
In our work , to address the aforementioned issues , we propose a novel news personalization algorithm by mining the implicit relations among users , news articles , topics and named entities . Motivated by [ 5 ] , we use a unified hypergraph to model multi type objects and implicit relations in news reading community . A hypergraph is a generalization of the ordinary graph , in which the edges , called hyperedges , are arbitrary non empty subsets of the vertex set [ 4 ] . However , due to the special properties of news articles ( eg , textual content , implicit relation and short shelf life ) , a straightforward extension of hypergraph modeling on music community cannot be directly applied to news recommendation . Instead , we first partition the hypergraph into multiple fine grained ones , and further model personalized news recommendation as a ranking problem on fine grained hypergraphs to recommend news articles .
To the best of our knowledge , our work is the first journey towards modeling implicit high order correlations in news reading community via hypergraph , by considering the special properties of news articles and online readers’ behaviors . The contribution of this paper is three fold :
305 • A hypergraph representation of news reading community . We explore implicit correlations among readers , articles , topics and named entities , and represent these relations as a unified hypergraph , by which a user ’s reading behavior can be well captured ( cf . §32 )
• A principled framework for news selection . We partition the hypergraph into fine grained ones , and then model the recommendation problem as a local selection problem on sub hypergraphs , instead of global selection on the entire hypergraph ( cf . §4.1 and §42 ) • A novel strategy for solving “ cold start ” . We embrace new users into a specific sub hypergraph , and then resolve cold start using transductive inference on the hypergraph ( cf . §43 )
Roadmap : §2 presents a brief summary of prior work relevant to personalized news recommendation and hyperIn §3 , we introduce the data model used graph learning . in our work and formalize the problem . In §4 , we discuss how to perform ranking and transductive inference on the hypergraph . Extensive experimental results are reported in §5 , and finally §6 concludes the paper .
2 . RELATED WORK
2.1 Content based Methods
Content based news recommenders construct user profiles based on news content , and recommend for users news articles similar to user profiles in content wise [ 10 , 12 , 22 ] . The computational representation of news content is the cornerstone of content based recommenders . In practice , news content is often represented by vector space model or topic models that are widely used in text mining . To calculate the relevance between news items and user profiles , different affinity measurements might be applied , depending on specific strategies of news recommenders . For example , Newsjunkie [ 12 ] filters news stories by formal measures of information novelty to custom tailor newsfeeds based on a user ’s reading history . [ 10 ] tries to obtain users’ reading interests from multiple news channels . However , it might be insufficient to simply represent users’ profiles by a bag of words for capturing the reading preference of users [ 20 ] . 2.2 Collaborative filtering
Collaborative filtering based news recommenders model users profiles by analyzing feedbacks of news readers , eg , click on news articles , and then recommend news based on similar users’ behaviors . Therefore , these news recommenders are content free [ 9 ] . Collaborative filtering can be roughly categorized into two groups : memory based methods [ 25 , 26 ] ( ie , neighborhood based recommendation ) and model based approaches [ 14 , 24 ] ( ie , latent factor based recommendation ) . Collaborative filtering assumes that the overlap historical consumptions between users exist ; however , with the rapid change of both news repository and user repository , it suffers from the well known cold start problem [ 27 ] , which renders collaborative filtering less effective . 2.3 Hybrid Approaches
To remedy the inability of both content filtering and collaborative filtering , many researchers investigate the feasibility of combining these two types of methods , and propose hybrid solutions to news recommendation . Representative examples include [ 6 , 7 ] . Another extensively studied direction in recommendation community is hybrid filtering , which is similar to the problem in our work . Several recently published methods include [ 2 , 3 , 17 ] . However , most hybrid filtering methods either focus on analyzing explicit ratings in the data , or assume that demographic and other auxiliary information of users are available . Although it is possible to incorporate user behaviors into these methods , they still suffer from the difficulty of comprehensively capsuling highorder relations within news reading community . 2.4 Hypergraph Learning
In machine learning problem settings , a typical representation of data is hypergraph , by which the information loss issue resulted from pairwise relationship among objects can be effectively remedied . Hypergraph can help resolve general learning problems , eg , clustering [ 13 ] , classification [ 28 , 30 ] and embedding [ 34 ] . Hypergraph learning has been explored in various machine learning areas , such as gene expression classification [ 16 , 29 ] , image retrieval [ 11 , 15 , 31 ] , document analysis [ 18 ] , etc .
Our work is essentially a graph based hybrid recommendation approach . In [ 1 ] , social interactions , eg , comments by news readers , are modeled as a graph and news articles are filtered based on the content and interactions . However , their model failed to consider the implicit relations among news readers , news articles and named entities , which are essential for news recommendation .
What differentiates our work from prior methods is that we model personalized news recommendation as a hypergraph learning paradigm by integrating all implicit correlations among users , news items , topics and named entities into a unified hypergraph , and then recommending news articles via a hypergraph ranking algorithm . The way that we encapsule the data into a hypergraph is similar to [ 5 ] , in which a music recommendation algorithm is proposed by considering the integration of multiple kinds of social media information and music acoustic based content . However , the intrinsic characteristics of news recommendation render it different from music recommendation . The differences between these two tasks are summarized as follows :
• Content wise : News content is composed of words , prone to be associated with topics , whereas music content consists of acoustic features , which are difficult to interpret and understand ;
• Evolutionary : News community evolves much faster than music community due to the instantaneity of news articles , ie , news articles have short shelf life ;
• Relation wise : The relations within news community are mostly implicit , while music community has multiple explicit relations .
Given these differences , the derived hypergraph from a news reading community would be much more complex than the one from a music sharing community . Simply applying the work in [ 5 ] to news recommendation might suffer the scalability issue . Therefore , we propose to first partition the hypergraph into more fine grained ones . Further , our proposed method has the capability of effectively handling the cold start problem in recommendation scenario .
306 3 . DATA MODEL AND PROBLEM STATE
MENT
In this section we start by introducing our data model of news reading community and some basic notations , and then we formally state our exploration problem . 3.1 Preliminaries
.
We follow the definitions in [ 5 , 34 ] to describe hypergraph preliminaries . We denote G(V , E , w ) as a hypergraph , where V is a finite set of vertices , E is a family of hyperedges on V , and w is a weight function , w : E → R . Each hyperedge e ∈ E contains a list of vertices that belong to V . The degree of a hyperedge e is defined by δ(e ) =|e | , ie , the number of vertices in e . The degree d(v ) of a vertex v is defined by d(v ) = v∈e w(e ) , where w(e ) is the weight of the hyperedge e . We say that there is a hyperpath between vertices v1 and vk if there is an alternative sequence of distinct vertices and hyperedges v1 , e1 , v2 , e2,··· , ek−1 , vk , such that {vi , vi+1} ⊆ ei for 1 ≤ i ≤ k − 1 . We formulate a vertex hyperedge incidence matrix H ∈ R in which each entry h(v , e ) is 1 ifv ∈ e and 0 otherwise . Then we have d(v ) = v∈V h(v , e ) . Let Dv and De denote the diagonal matrices containing the vertex and hyperedge degrees respectively , and W the diagonal matrix |E| × |E| containing the weights of hyperedges . 3.2 Data Model e∈E w(e)h(v , e ) , and δ(e ) =
|V |×|E|
.
.
In news reading community , multiple types of resources are often available for analysis , including users , news articles , representative terms , named entities , etc . Let U denote the user pool , and N denote the set of news articles , both of which are the major elements being considered in recomt denote the representative mender systems . Further , let T e be the set of named entities interms , or say , topics , and T volved in the entire news corpus . Notice that in reality , the pools of these four types of resources would be enlarged as there are always news events happening everyday with different topic categories and distinct named entities . In our data model , we name these resources as Media Objects . To facilitate the reading , we list some notations in Table 1 .
Table 1 : Notations in our data model .
U e t
N Tt Te nk i α E UNT E UNT E UUN t E UUT E UUT E NNT E NNT E N k e t e ui ni tt k te k the user set . a particular user . the article set . a particular article . the k th topic . the topic set . the k th entity . the entity set . the k nearest neighbors of an article i . the importance factor of content similarities . the set of user article topic hyperedges . the set of user article entity hyperedges . the set of user user article hyperedges . the set of user user topic hyperedges . the set of user user entity hyperedges . the set of article article topic hyperedges . the set of article article entity hyperedges . the set of k nearest articles hyperedges .
Besides , several relations among objects are implicitly embedded among media objects . For example , two users u1 , u2 ∈ U are the fans of NBA star LeBron James ( te e ) , which is a named entity appearing in news articles of sports event j ∈ T ( tt t ) . Then there is an implicit relation among these media objects . In our data model , we formalize a hypergraph i ∈ T
G that contains 7 different implicit relations with different objects1 and 1 implicit relation that considers the similarity graph of news articles :
• E UNT t
: A user reads a news article that describes an event , or a topic . Typically we assign the weight of this hyperedge to be 1 . Here we assume that a user would only navigate a news item once .
• E UNT e
: A user reads a news article that embraces a , we assign the hyper t named entity . Similar to E UNT edge weight as 1 .
• E UUN : Two users might read the same news article .
We assign the hyperedge weight to be 1 .
• E UUT t
: Two users might read news articles with the same topic . The weight w(euiuj tt k ) for this relation is set to be the frequency that both users , ui and uj , read articles with the same topic tt w(euiuj tt k)|ui ∈ U , uj ∈ U , tt k ) = |{(ui , uj , tt k ∈ T k , ie , t}| . ( 1 )
We normalize the weight as w(euiuj tt k ) =
.fi|U| w(euiuj tt .fi|U| k ) m=1 w(euiumtt k )
. l=1 w(euluj tt k )
( 2 ) The above heuristic normalization aims to penalize the abnormal news readers with dense reading activities . Moreover , in order to treat different types of relations equally , we further normalize the weight as follows : w(euiuj tt k ) = w(euiuj tt k ) ave(w(euiuj Tt
,
) )
( 3 ) where ave(w(euiuj T weights for users ui and uj on different topics .
) ) is the average of normalized t
• E UUT e
: Two users might read news articles containing the same named entity . The weight w(euiuj te k ) for this relation is set to be the frequency that both users , ui and uj , read articles containing the same entity te k . The weight normalization is similar to Eq ( 2 ) and Eq ( 3 ) .
• E NNT t
: Two news articles might describe the same or similar topic . We assign the hyperedge weight as 1 .
• E NNT e
: Two news articles might contain the same en tity . We assign the hyperedge weight to be 1 .
• E N k
: In our data model , we also consider the similarity of news articles . We construct a k nearest neighbor ( k NN ) news graph based on content based item similarities . In the hypergraph , a hyperedge of this type is composed of the top k articles similar to the target news item and the target item itself . The weight 1It is natural that the edges can be generalized from a pairwise co occurrence , eg , an edge incident on a news item and all of its readers . However , the generated incidence matrix would become much denser . For simplicity , we only consider the hyperedges with three vertices . Our algorithm can be extend to hyperedges with arbitrary number of vertices .
307 w(enk news item and the ones similar to the target , ie , i ) is the averaged similarity between the target w(enk i ) = kfi j=1
1 k sim(ni , nj ) ,
( 4 ) where sim(ni , nj ) is the similarity between two news articles . In our work , this similarity is calculated using the cosine similarity by considering the content features of news items . We introduce a parameter α to control the relative importance of content based similarities in the unified hypergraph model . Then , the hyperedge weight is given by w(enk i ) = α ∗ w(enk i ) .
( 5 )
Finally , the unified hypergraph of news reading community is composed of 4 types of media objects as vertices and 8 types of object relations as hyperedges . Figure 1 summarizes the aforementioned media objects and relations . By employing the unified hypergraph model , we can effectively capture the high order relations among various types of media objects without loss of any important information .
( cid:75)(cid:853)fi(cid:94)(cid:449)(cid:349)(cid:410)(cid:460)(cid:286)(cid:396)(cid:367)(cid:258)(cid:374)(cid:282)fi(cid:894)'(cid:87)(cid:895)(cid:886)(cid:258)(cid:455)(cid:374)(cid:286)fi ( cid:381)(cid:381)(cid:374)(cid:286)(cid:455 ) ( cid:449)(cid:349)(cid:367)(cid:367)fi(cid:373)(cid:349)(cid:400)(cid:400)fi(cid:410)(cid:346)(cid:286)fi(cid:286)(cid:374)(cid:410)(cid:349)(cid:396)(cid:286)fi(cid:336)(cid:396)(cid:381)(cid:437)(cid:393)(cid:857 )
( cid:258)(cid:396)(cid:396)(cid:455)fi(cid:87)(cid:381)(cid:410)(cid:410)(cid:286)(cid:396)fi(cid:286)(cid:271)(cid:381)(cid:381)(cid:364)(cid:400 ) ( cid:367)(cid:258)(cid:437)(cid:374)(cid:272)(cid:346)fi(cid:282)(cid:286)(cid:367)(cid:258)(cid:455)(cid:286)(cid:282 ) e
E UNT e
E UUT kE N t
E UNT
UUNE
'(cid:100)(cid:75)(cid:853 ) ( cid:374)(cid:336)(cid:367)(cid:258)(cid:374)(cid:282 ) ( cid:894)'(cid:87)(cid:895 ) ( cid:886 ) ( cid:100)(cid:346)(cid:286 ) '(cid:100)(cid:75)(cid:853)fi(cid:374)(cid:336)(cid:367)(cid:258)(cid:374)(cid:282)fi(cid:894)'(cid:87)(cid:895)fi ( cid:100)(cid:346)(cid:286)fi ( cid:373)(cid:258)(cid:336)(cid:349)(cid:272)(cid:258)(cid:367)fi(cid:449)(cid:381)(cid:396)(cid:367)(cid:282)fi(cid:381)(cid:296 ) ( cid:258)(cid:396)(cid:396)(cid:455)fi(cid:87)(cid:381)(cid:410)(cid:410)(cid:286)(cid:396 ) ( cid:857 )
( cid:258)(cid:455)(cid:374)(cid:286)fi(cid:381)(cid:381)(cid:374)(cid:286)(cid:455 )
( cid:258)(cid:396)(cid:396)(cid:455)fi(cid:87)(cid:381)(cid:410)(cid:410)(cid:286)(cid:396 ) e
E NNT t
E UUT t
E NNT
( cid:94)(cid:393)(cid:381)(cid:396)(cid:410)(cid:400 )
( cid:374)(cid:410)(cid:286)(cid:396)(cid:410)(cid:258)(cid:349)(cid:374)(cid:373)(cid:286)(cid:374)(cid:410 )
Figure 1 : An illustrative example of data model in news reading community .
Based on the data model introduced above , we can derive the vertex hyperedge incidence matrix H ( as described in Table 2 ) and also the weight matrix W . The size of both matrices depends on the cardinality of different element sets involved in the matrices , and they are all sparse matrices . 3.3 Problem Statement
In this subsection , we first define the problem of personalized news recommendation , and then analyze the major technical issues for resolving the problem . PROBLEM ( Personalized News Recommendation ) : Given a collection of newly published news articles N and a target online reader u , recommend a list of news items S that maximally match u ’s reading preference .
It is straightforward to observe that the success of personalized news recommendation depends on two critical subproblems : user profiling and news personalization . The former aims at capturing online users’ reading preference , whereas the latter tries to select news items to be optimally consistent to user ’s preference . capsule as follows :
To facilitate user profiling , we define a concept of news Definition 1 . ( News Capsule ) . A news capsule , C = ) , is a subset of a given hypergraph G = ( V , E , w ) ,
( V C , EC , wC
= {U , N , T t , T e} ⊂V = {U , N , T t , T e} , ie , U ⊂ where V C U , N ⊂ N , T t ⊂ T t , T e ⊂ T e , and EC ⊂ E , wC ⊂ w .
A capsule C is said to be compact iff ∀u ∈ U , u ’s reading preference is maximally captured in C . To evaluate how well u ’s preference is captured , we formalize another definition .
Definition 2 . ( Maximality ) . Given a user u and a news capsule C that u belongs to , u ’s reading preference is said to be maximally captured in C iff most hyperedges that embrace u are within C .
Then the first technical problem of user profiling in our setting can be defined as follows :
SUBPROBLEM 1 ( User Profiling ) : Given a hypert and graph G consisting of multiple media objects ( U,N,T e ) associated with a series of object relations ( see § 3.2 ) , T model users’ profiles P to capture users’ reading preferences by news capsules , such that in each news capsule , the maximality is satisfied .
The well captured user profiles serve as the basis of personalized news recommendation . We discuss our solution to this subproblem in § 41
Given a collection of newly published news articles and a target online user ’s profile , our goal is to recommend to this user a list of news articles that satisfy the user ’s reading appetite . We expect that by a recommendation list , the user ’s preference is optimally matched , and also the news list is diverse enough so that the user would not get bored when he/she is navigating news articles .
Definition 3 . ( Optimally Matchable ) . Given a news list l recommended to a user u and u ’s profile p , l is said to be optimally matchable to u ’s reading preference only if there is no other list lfi and p is larger than the one between l and p . by which the similarity between lfi
Definition 4 . ( Diversity ) . Given a news list l recommended to a user u , l is said to be diverse if it matches all of u ’s different reading interests . A user ’s reading interest can be categorized by the topics and named entities in the consumption history .
We now formally define our second problem of selecting a list of news articles from newly published news collection to maximally match an online user ’s reading preference . SUBPROBLEM 2 ( News Personalization ) : Given a collection of newly published news articles S and a user ’s profile p , select a subset S∗ is optimally matchable to p and the diversity of S∗ is maximized , where the diversity denotes distinct topics and named entities in p . The essence of personalized news recommendation is well captured in the above problem formation . We discuss our personalization solution in § 42 from S where S∗
In reality , with various subjective factors involved in news recommendation , the optimality of both SUBPROBLEM1 and SUBPROBLEM2 is difficult to achieve . Many existing news recommenders try to approximately resolve both problems based on certain evaluation criteria . In our work , we employ hypergraph learning to tackle these problems .
4 . RECOMMENDATION METHODOLOGY In this section , we discuss how to approximately address the aforementioned problems via hypergraph learning . The
308 Table 2 : The incidence matrix H of the unified hypergraph . t
E UNT t UE UNT NE UNT tE UNT t
T t
0
U
N t
T e
T e
E UNT e UE UNT NE UNT e t
E UUN
E UUT t UE UUN UE UUT NE UUN
0 tE UUT
T t
0 eE UNT e
T
0 0 e
E UUT e UE UUT
0 0 eE UUT t
E NNT e
E NNT
0
NE NNT tE NNT
T t t
0
NE NNT e
0 eE NNT e
T k
E N
0 NE N k
0 0
0
T e
0 unified hypergraph defined in § 3.2 is used to model the high order relations among different types of media objects in news reading community . In order to effectively capture online users’ reading preference , we propose to initially partition the entire hypergraph into multiple news capsules , by which users’ reading behaviors can be stored . Given newlypublished news articles , we integrate relevant articles into the capsule that embraces the user , and then perform ranking on this specific news capsule . In this way , we are capable of providing instant news recommendation . 4.1 News Hypergraph Partition
Recall from § 3.3 that a news capsule is a subset of a given hypergraph . We follow the definitions in [ 34 ] to describe the hypergraph partition . For a vertex subset S ⊂ V , let Sc denote the complement of S . A hyperedge e is said to be a cut if it is incident with both S and Sc simultaneously . We further denote the hyperedge boundary ∂S of S be a hyperedge set consisting of multiple cuts , ie , ∂S := {e ∈ E|e ∩ S = ∅ , e ∩ Sc = ∅} , and define the volume volS of S . to be the sum of degrees of the vertices in S , ie , volS := v∈S d(v ) . Moreover , we denote the volume of ∂S by vol ∂S := w(e ) fi e∈∂S
|e ∩ S||e ∩ Sc|
.
δ(e )
( 6 )
( 7 )
We then formalize the hypergraph partition as arg min ∅=S⊂V
Ncut(S ) := vol∂S(
1 volS +
1 volSc ) , which is similar to the normalized cut on ordinary graphs . In this paper , we will not focus on how to resolve the hypergraph partitioning problem . To automatically generate hypergraph partitions ( news capsules ) with compact representations , we employ the method introduced in [ 34 ] . It generalizes a methodology of spectral clustering originally operating on undirected graphs to hypergraphs , which is essentially suitable to the problem setting in our work . We partition the news hypergraph into m disjoint news capsules where m is predefined .
Discussion : The hypergraph built upon a news reading community could be very large . Directly performing graph inference on such a hypergraph would be inefficient . By partitioning the graph into multiple subgraphs , the inference will be performed on a smaller scale , which can improve the efficiency to a great extent . In our work , we employ “ cut ” to partition the graph , which can be viewed as a hard clustering scheme . Other clustering methods can be applied to our problem setting , eg , soft clustering that can generate overlapping news capsules . However , this is not our main focus , and therefore we leave it to our future work .
A practical issue suffered by the hypergraph partitioning in our problem setting would be the imbalanced user distribution over different capsules . This issue could be caused by the imbalanced distribution of different types of edges . For example , the edges between news and topics can be much denser than the edges between news and users , and as a result , some capsules might contain very few users , or even no users at all . It is trivial to resolve this issue by considering some constrains ( eg , do not “ cut ” on user inside edges ) when partitioning the hypergraph .
The partition paradigm is based on not only topical categories , but also the reading behaviors of users , involving the preferences on topics and named entities . In each capsule C , ∀u ∈ U , the maximality defined in § 3.3 is suboptimally satisfied based on the partition paradigm . One may argue that a per user capsule would be more suitable to satisfy the maximality ; however , such a capsule cannot be used for graph inference . 4.2 News Recommendation via Ranking
Hypergraph partitioning provides us a list of disjoint news capsules , in which the users’ reading preferences are encapsulated , including topics , named entities and similar users . In the following , we present our approach in which we model the recommendation as a sub hypergraph ranking problem . Formally , given a capsule ( or a sub hypergraph ) C , a set of newly published news articles S and a target user u within C , we first link articles in S onto C . To do so , we extract topics and named entities from S and then compare these objects with the objects in C . In this way , we can not only connect new articles to C , but also add new objects into C . Next , we reconstruct the unified hypergraph based on the enriched C C and get the vertex hyperedge incidence matrix H and the . Since the scale of C is supposed to be weight matrix W much smaller than the entire hypergraph , the reconstruction C would be more efficient . Then the vertex degree matrix D v C and the hyperedge degree matrix D e are computed based on H . In the following , we discuss how to perform ranking on a sub hypergraph by using similar idea of [ 5 ] . and W
C
C
C
We define the cost function of f as follows :
Q(f ) =
1 2
|V |' i,j=1
' e∈E
1
δ(e )
'
{vi,vj}⊆e w(e ) fi d(vi )
− fj d(vj ) ffffffffff
2 ffffffffff
|V |' i=1
+ μ
||fi − yi||2 ,
( 8 ) where μ > 0 is the regularization factor . To achieve the optimal ranking result , we need to minimize Q(f ) :
∗ f
= arg min f
Q(f ) .
( 9 )
For inference , we need to smooth the process as much as possible under the constraint that vertices that are contained by many common hyperedges should have similar ranking scores . As an illustrative example , if two news articles have been accessed by many common users , then both articles will
309 ∗
C
C e ) as
∗
−1
C v )
)T ( D
C v )
W
( D f −1/2H y , −1(H C have similar ranking scores . The smoothness can be achieved by minimizing the first term in Eq ( 8 ) . We also need to minimize the difference between the obtained ranking scores and the pre given scores to guarantee that the result will not deviate much from the truth , ie , to minimize the second term in Eq ( 8 ) . After a series of mathematical derivation by [ 5 ] , we can obtain the optimal f = ( I − γA ) C
( 10 ) −1/2 . Notice where A = ( D that under the constraint of C , the matrix I − γA is highly sparse , and therefore the inverse of I− γA can be efficiently calculated . y corresponds a query vector given a user , each entry of which can be either 1 or 0 , indicating what topics and entities are preferred by the user . After performing ranking on the sub hypergraph , we can choose top ranked news articles as the recommendation list . Discussion : An interesting setup to approximately satisfy the diversity requirement defined in § 3.3 is to predefine e t and named entities T query scores over different topics T within the profile of the target user . Specifically , we can analyze the user ’s profile and choose the topics and named entities that are ranked high in terms of the accumulated score of the edge weights . For these topics and named entities , the corresponding values in y can be set to 1 for the query purpose , whereas for other topics and named entities , the values can be set to 0 . For example , given a user q with preference over the topic “ Basketball ” and the named entity “ LeBron James ” , we can specify 1 value for the corresponding two entries in yq . In addition , we can set 1 value for entries that are related to the user ’s preference , eg , “ NBA ” and “ Competitive Sports ” , which can be obtained using some simple text mining techiniques . In this way , the ranking result can have more diverse content in terms of topics and named entities that are distributed over the target user ’s profile and related preferences . Therefore the setup of the query vector y fosters the diversity in the results . 4.3 Transductive Inference on Hypergraph
Our proposed framework is capable of handling the socalled cold start problem , especially for new users . In this subsection , we introduce the strategy of how we can tackle the user cold start problem . Given a new user q without enough reading history , traditional recommender systems fail to construct a comprehensive user profile due to the data sparsity . Comparatively in our framework , we initially embrace this new user q into a specific capsule ( by extracting topics and named entities of the limited consumption history of q and linking them to the capsule ) . Taking q into the construction of the query vector y , we perform transductive inference on the new capsule to derive the vertices related to q ’s preference , and finally provide the recommendation list for q . ) , in which the vertices in a subset S ⊂ V C have labels in L = {1,−1} predefined by the new user q according to q ’s reading history , our goal is to predict the labels of the remaining unlabeled vertices . Note that for news recommendation , the labels {1,−1} indicate whether the user is interested in the corresponding element or not . On the one hand , the inference function should be as smooth as possible , ie , we should assign the same label to all vertices contained in the same hyperedge ; moreover , vertices lying on a densely linked sub
Specifically , given a news capsule C = ( V C , EC , wC hypergraph are likely to have the same label . Thus we define a function
Ω(f ) =
1 2 fi fi e∈E
{u,v}⊆e w(e ) δ(e ) f ( u)ff d(u )
− f ( v)ff d(v )
'''''
'''''
2
,
( 11 ) which sums the weighted variation of a function on each edge of the capsule . On the other hand , the initial label assignment should be changed as little as possible . Let y denote the initial label vector , in which the assignments are defined by y(v ) = 1 or −1 if vertex v has been labeled as positive or negative respectively , and 0 if it is unlabeled . Then we consider the following optimization problem [ 33 ]
{Ω(f ) +μ||f − y||2} , arg min f∈R|V |
( 12 ) where μ > 0 is the parameter specifying the tradeoff between the two components . The optimization problem defined in Eq ( 12 ) is similar to the one in Eq ( 8 ) . The difference here is that for transudctive inference , our goal is to derive the labels of the unlabeled vertices , whereas for ranking , we try to derive the complete importance order of the vertices . Due to the space limit , we omit the detailed procedure for sovling Eq ( 12 ) . In this way , even if a user does not have enough reading history , we can still get enough labeled news items that the user might prefer . Hereby , for new users , we can recommend a list of unordered news articles .
5 . EMPIRICAL EVALUATION
In this section , we provide a comprehensive experimental evaluation to show the effectiveness of our proposed hypergraphbased news recommendation algorithm ( Hyper for short ) .
5.1 Real World Data Collection
The data used in our experiment is obtained from multiple news reading portals , ranging from Aug 15th , 2010 to Nov 16th , 2010 [ 20 ] , which includes news articles and users’ access histories . It contains 10 news topic categories , such as sports , movies , politics , etc . We preprocess the data by removing news articles that are rarely accessed ( ie , the accessed frequency is less than 1 per day ) and by storing users with frequent online reading behaviors ( ie , users who read news articles everyday and read more than 1 piece of news each day ) . By preprocessing , some unexpected noise can be removed to ensure the quality of the generated hypergraph . We perform LDA on news articles to extract representative words from each news category , as the topics of the data model2 . For named entities , we use NLP tools , eg , GATE [ 8 ] , to perform information extraction . The media objects and relations contained in this data collection are summarized in Table 3(a ) and 3(b ) , respectively . Note that the number of nearest neighbors , k , in the news similarity graph is not fixed , and therefore the number of hyperedges varies for E N 5.2 Experiments
. k
In this subsection , we first consider the effect of different factors in our unified news hypergraph on the recommendation performance , ie , by constructing the hypergraph using different combinations of hyperedges ; We then investigate 2Here each “ topic ” is represented as a bag of words when constructing the unified hypergraph .
310 Table 3 : Statistics of our news collection .
( a ) Objects
Elements
Users
Articles Topics Entities
Count 3,280 58,873
10
121,617
Relations t
E UNT e E UNT E UUN t E UUT
( b ) Relations e
Count Relations 501,239 672,348 307,652 43,785
E UUT E NNT e E NNT k E N t pare the metrics introduced in § 521 , and the results are shown in Figure 2 , in which Figure 2(a ) demonstrates the performance difference of multiple hypergraph constructions in terms of F1 score , whereas Figure 2(b ) shows the ranking performance in terms of NDCG .
Count 402,918 52,136 176,431 the performance of local selection ( selecting articles in specific news capsules ) and global selection ( selecting articles on the entire hypergraph ) ; Further , we demonstrate the superiority of the transductive inference on news capsules in handling the user cold start problem ; We also provide comprehensive comparisons with existing and recently published approaches related to news recommendation .
521 Evaluation Setup
For evaluation purpose , we divide the entire news data into two disjoint sets , where the first one ranges from Aug 15th , 2010 to Nov 6th , 2010 , regarded as the training set , and the remaining falls into the testing set . The training set is used to construct the unified hypergraph , whereas the testing set is regarded as the ground truth for recommendation evaluation . For each user in the testing set , we recommend news items ( top@10 , top@20 and top@303 ) to the user at each day of the testing range . For comparison , we compute the averaged F1 score over multiple users and multiple days . We also use Normalized Discount Cumulative Gain ( NDCG ) to measure the ranking quality of the recommended list based on a user ’s actual accessing sequence . NDCG at position n is defined as
N DCG@n = N ( n ) × nfi i=1
2ri − 1 log2(i + 1 )
, where N ( n ) is the NDCG at n of the ideal ranking list , and ri is the relevance rating of item at rank i . In our scenario , ri = 1 if the user has read the recommended news article and 0 otherwise .
522 Construction of Hypergraph k
In our proposed data model , we integrate 8 different hyperedges or object relations into the construction of news hypergraph . Such a hypergraph provides an elegant representation of the news data , encapsulating multiple correlations among different media objects . To evaluate the effect of such a representation in personalized news recommendation , we consider different combinations of hyperedges for hypergraph construction : ( 1 ) E N ( NK ) : consider news similarities based on users’ profiles , which is essentially a content based method ; ( 2 ) E UUN ( UN ) : construct the hypergraph using only users’ co visit information , which can be t regarded as an example of collaborative filtering ; ( 3 ) E UNT , E UUT ( UNT ) : build hypergraph by considering the topics in news collection and users’ access patterns in a hybrid way ; and ( 4 ) E UNT ( UNE ) : construct the hypergraph using the entity information , ie , considering users’ preference on specific named entities . We com3The “ top@x ” means the top ranked x news items being recommended to the user . and E NNT
, E UUT
, E NNT t t e e e
( 13 )
523 Local Selection VS Global Selection
( a ) F1 score comparison .
( b ) NDCG comparison
Figure 2 : Performance comparison of different hypergraph constructions .
It is evident that the unified hypergraph model significantly outperforms other constructions of hypergraph from both accuracy and ranking perspective . The reason behind this is straightforward : in our unified model , high order correlations among different media objects are well captured , which extensively enrich a user ’s reading preference and hence make the recommended result more accurate . Besides this , we observe that : ( i ) The performance of hybrid constructions ( ie , UNT and UNE ) is better than uni edge construction ( ie , NK and UN ) ; and ( ii ) the result of UNE is comparable with UNT , which means that in real world news recommender systems , users pay equal or more attention on named entities they prefer , not just the topics that news articles are reporting .
To recommend news articles to a target user , our approach first partitions the entire hypergraph into multiple news capsules , and then locates the capsule that the user belongs to for further recommendation . Such a paradigm can not only expedite the recommendation ( since we only consider partial hypergraph ) , but also improve the accuracy of the recommendation because the information in a news capsule is more specialized than the one in a global perspective . To validate this claim , we choose different values for m ( the number of capsules defined in § 4.1 ) and compare the recommendation results with the one using the entire hypergraph ( Global , for short ) . Figure 3 depicts the comparison .
( a ) F1 score comparison .
( b ) NDCG comparison
Figure 3 : Performance comparison of local selection with different number of capsules and global selection .
With different m , the performance of our approach varies . Hyper achieves the optimal performance when m = 50 ,
311 which is not compatible with the number of topics . By partitioning the entire hypergraph into more capsules , the information within each capsule is more specialized , and therefore a user ’s reading interest can be modeled in a more finegrained level . Compared with the global selection , Hyperm=50 performs better in terms of both F1 score and NDCG .
We are also interested in the performance details of local selection and global selection . Therefore , for Hyperm=50 and global selection , we randomly select 100 users to provide recommendations for them , and then plot the precision and recall pair for each user on top@10 , top@20 and top@30 news items recommended to these user . Figure 4 shows the resulted plot . As observed in Figure 4 , besides the higher recommendation precision and recall , the performance distribution of Hyper is more dense than the one of the global selection , which demonstrates the stability of our proposed local selection strategy .
Top @30
0.22
0.21
0.2
0.19
0.18
0.17
0.16 l l a c e r
Top @10
0.28
0.27
0.26
0.25
0.24
0.23
0.22
Top @20
0.33
0.32
0.31
0.3
0.29
0.28
0.27
0.15
0.25
0.3
Precision
0.21
0.35
0.3
0.35
Precision
0.26
0.4
0.36
0.38
0.4 Precision
0.42
Figure 4 : Precision recall plot for local selection with m = 50 and global selection . Remark : “ 2 ” denotes users using the global selection strategy ; and “ + ” represents users using the local selection strategy .
524 Parameter Tuning k
In our algorithm , there are several parameters for tuning , ie , the number of the nearest neighbor k in Eq ( 4 ) , the control parameter α in Eq ( 5 ) , the regularization factor γ in Eq ( 10 ) and μ in Eq ( 12 ) .
Both k and α are related to E N in the data model . To explore the effect of the parameters k and α ( the influence of hyperedges relevant to news content similarity ) , we use F1score as the evaluation metric . Figure 5 shows the results . We first empirically fix α = 0.2 and evaluate the changing of k . Figure 5(a ) shows the F1 score measured as a function of k . The optimal value for k is obtained when k = 70 . We then fix k and evaluate the changing of α . Figure 5(b ) shows the F1 score measured as a function of α . The best result is obtained when α = 02
0.35
1 F d e g a r e v A
0.3
0.25
0.4
0.35
0.3
0.25
1 F d e g a r e v A top@10 top@20 top@30 top@10 top@20 top@30
0.2
0
20
40
60
80
100
0.2
0 k
( a ) α = 0.2
0.2
0.4
α
0.6
0.8
1
( b ) k = 70
Figure 5 : Parameter Tuning .
The parameters γ and μ are common factors in many hypergraph learning methods . In our experiment , we empirically set γ as 0.9 and μ as 01
525 Comparison with Other Methods
We also implement several recently published methods : Goo [ 9 ] , ClickB [ 23 ] , Bilinear [ 7 ] , Bandit [ 19 ] , fLDA [ 3 ] , and SCENE [ 20 ] for comparison . The details of these algorithms are described as follows :
• Goo : The method is essentially a collaborative filtering approach , in which MinHash clustering , PLSI and covisitation counts are taken into account for a unified recommendation paradigm .
• ClickB : In this approach , the profiles of user ’s news interests are built based on their past click behavior , and then a Bayesian framework for predicting users’ current news interests .
• Bilinear : This method maintains profiles of content of interest based on temporal characteristics of the content , eg , popularity and freshness , and also maintains profiles of users including historical activities . The recommendation is achieved via a feature based machine learning approach .
• Bandit : The method models recommendation as a contextual bandit problem , in which a learning algorithm sequentially selects articles to serve users based on contextual information about users and articles , while simultaneously adapting its selection strategy based on user click feedback .
• fLDA : The method regularizes both user and item factors simultaneously through user features and the bag of words associated with each item . It is essentially a hybrid filtering method .
• SCENE : The method assumes the interestingness of news articles with respect to a user could be regressive , and uses the “ submodularity ” property to model the news selection problem .
Note that the parameters of these baseline methods are optimally tuned in our experiment to ensure the fair comparison . We use F1 score and NDCG to compare these baselines with Hyper . The results are shown in Figure 6(a ) and 6(b ) . It is evident that our proposed method significantly outperforms other candidates on both metrics . The results of fLDA and SCENE are comparable to ours . In fLDA , each word in an item is associated with a discrete latent factor often referred to as the topic of the word ; item topics are obtained by averaging topics across all words in an item . Therefore , fLDA considers more fine grained granularity of topics , and consequently obtains reasonable recommendation results . SCENE explicitly takes into account the “ submodularity ” within users’ reading behaviors for recommendation . As we observe , the performance of Goo and ClickB is relatively poor . This is because the recommended lists of both methods are heavily determined by users’ co visiting histories ; however , the news data used in the experiments contains a great portion of relatively new users4 , ie , users 4In our dataset , the number of new users is around 400 , compared with the total number of users , 3,280 .
312 ( a ) F1 score comparison .
( b ) NDCG comparison
( c ) F1 score comparison .
( d ) NDCG comparison
Figure 6 : Performance comparison for regular recommendation and cold start user recommendation . Remark : ( a ) and ( b ) are comparisons of different algorithms on averaged metrics ; ( c ) and ( d ) are comparisons of different algorithms for the cold start problem of new users . who read less than 5 news articles per day . Hence , the coldstart problem of new users in the dataset causes the poor performance of both methods .
526 Handling Cold start
In traditional recommendation methods , the cold start prob lem cannot be well handled due to the data sparsity . To resolve it , we perform transductive inference on the unified news capsule for new users . The intuition is straightforward : we borrow the concept of inference by utilizing a small set of labeled data to infer the labels of unlabeled data on the hypergraph . Notice that in such a case , we do not focus on the ranking of news articles , but pay more attention on the interestedness of items , ie , whether the items are preferred by the user or not .
Specifically , we randomly choose 100 users who read news articles less than 5 per day , and then recommend news articles ( top@10 , top@20 and top@30 ) for these users . For evaluation purpose , we compare our method with Goo , ClickB , Bilinear , Bandit , fLDA and SCENE . Figure 6(c ) and 6(d ) shows the comparison results . As shown in Figure 6(c ) , the cold start problem can be elegantly alleviated by using our proposed method , Hyper . The explanation is straightin Hyper , we explicitly model the recommendaforward : tion for new users as transductive inference on a specified news capsule , and meanwhile we consider high order correlations among different media objects , which significantly complement the data sparsity of new users when performing recommendation . In Figure 6(d ) we also observe that although we do not intentionally take the ranking into account , our method surprisingly outperforms the others in terms of NDCG . The reason is that we can provide more news articles in the recommendation list that match a user ’s reading interest , and thus the quality of ranking is improved consequently . The result of fLDA on cold start handling is comparable to our performance . For cold start users , fLDA gives more weight to the prior mean ( predicted by user and/or item features ) in estimating the factor , and therefore selects news items that are quite relevant to the prior .
527 Diversity Evaluation
The recommended news list provided by our algorithm shows a great diversity on topic aspects . Such diversity is originated from the sparkle of the query vector y designed in § 4.2 , by which we can not only specify the target user , but also provide topics and named entities that the user prefers . To evaluate how diverse our recommendation result is , we compare the set diversity [ 32 ] among the results of our method and other recommender systems . The set diversity is defined as the average dissimilarity of all pairs of news items in the resulted list . Specifically , given a news set S , the average dissimilarity of S , fd(S ) , is defined as ( 1 − sim(si , sj) ) , fd(S ) = fi fi
( 14 )
2 p(p − 1 ) si∈S sj∈S,sj=si where |S| = p , and the dissimilarity of a news pair is 1 − sim(si , sj ) , in which sim(si , sj ) denotes the content similarity between the news item si and sj , and it is calculated using the cosine similarity .
For diversity evaluation , we choose the aforementioned methods ( Goo , ClickB , Bilinear , Bandit , fLDA and SCENE ) as our comparison baselines . We employ the experiment setup similar to the previous section , and then compare the diversities of recommended lists with different cardinalities ( top@10 , top@20 and top@30 ) . Table 4 shows the averaged diversity for 100 randomly selected users .
Table 4 : Diversity evaluation on the result list . ( Bold indicates the best performance . * indicates the statistical significance at p <0 .01 wrt the randomness of selected users . )
Methods
Goo top@10 0.4101 0.4329 0.4234 0.5056 0.4726
ClickB Bilinear Bandit fLDA SCENE 0.6537* top@20 0.3074 0.3128 0.2517 0.4126 0.3981 0.5771 top@30 0.1105 0.1562 0.0933 0.2925 0.2705 0.4859
Ours
0.6323
0.5987*
0.5072*
From the result , we observe that ( i ) The diversity decreases as the recommended news list enlarges . It is straightforward that when more news articles are selected , the topic distribution of the news list becomes closer to the user ’s reading interest , and therefore the selected news items are more similar . ( ii ) The diversity of the recommendation list provided by the baseline methods drops dramatically as the list size increases , since they did not take the diversity into account . ( iii ) Our proposed method outperforms the others very significantly , except SCENE . SCENE explicitly selects different news items solely from topic wise for recommendation , and hence the diversity of the result from SCENE is higher more or less . In our work , we consider the interest of news readers by specifying different topics and named en
313 tities in the query vector y . The diversity decreases very smoothly when we recommend more news items to individual users , compared with other rivals .
6 . CONCLUDING REMARKS
In this paper , we propose to use hypergraph learning methods to deal with the issues existed in news recommenders . We first represent news data as a unified hypergraph , in which various correlations among different media objects are integrated into an information capsule . We then decompose the recommendation problem as two subproblems : partitioning and ranking , where the former aims to separate the entire hypergraph into multiple groups , or subcapsules , and the latter is designed to select a list of news articles from a specific capsule and recommend them to a target user ( the user is regarded as a query ) .
In our proposed data model , we simplify the profiling problem by only analyzing a user ’s reading history ( as the profile ) without accessing any other auxiliary information . In reality , a news reader might have other information , eg , demographics , locations , and other social and behavioral patterns . We believe such information can be easily incorporated into our proposed framework , eg , by encapsuling the user relations within close locations or the same social community into the data model . In our future work , we plan to delve into extending our framework along this direction . In addition , although we intentionally partition the hypergraph into multiple small ones to expedite the procedure , the scalability of our proposed framework is not quite satisfactory . We plan to use distributed environment , eg Hadoop , to accelerate the partitioning and recommendation procedure in our future work .
ACKNOWLEDGEMENTS We thank the reviewers for their valuable comments . The work is supported in part by NSF grants IIS 0546280 , DBI0850203 , CCF 0939179 , HRD 0833093 and CNS 1126619 .
7 . REFERENCES [ 1 ] B . Adams , D . Phung , and S . Venkatesh . Social reader : following social networks in the wilds of the blogosphere . In Proc . of 1st SIGMM workshop on Social media , pages 73–80 . ACM , 2009 .
[ 2 ] D . Agarwal and BC Chen . Regression based latent factor models . In Proc . of SIGKDD , pages 19–28 . ACM , 2009 .
[ 3 ] D . Agarwal and BC Chen . flda : matrix factorization through latent dirichlet allocation . In Proc . of WSDM , pages 91–100 . ACM , 2010 .
[ 4 ] S . Agarwal , K . Branson , and S . Belongie . Higher order learning with graphs . In Proc . of ICML , pages 17–24 . ACM , 2006 .
[ 5 ] J . Bu , S . Tan , C . Chen , C . Wang , H . Wu , L . Zhang , and X . He .
Music recommendation by unified hypergraph : Combining social media information and music content . In Proc . of ACM MM , pages 391–400 . ACM , 2010 .
[ 6 ] R . Burke . Hybrid systems for personalized recommendations .
Intelligent Techniques for Web Personalization , pages 133–152 , 2005 .
[ 7 ] W . Chu and ST Park . Personalized recommendation on dynamic content using predictive bilinear models . In Proc . of WWW , pages 691–700 . ACM , 2009 .
[ 8 ] DH Cunningham , DD Maynard , DK Bontcheva , and MV
Tablan . GATE : A framework and graphical development environment for robust NLP tools and applications . In Proc . of ACL , 2002 .
[ 9 ] AS Das , M . Datar , A . Garg , and S . Rajaram . Google news personalization : scalable online collaborative filtering . In Proc . of WWW , pages 271–280 . ACM , 2007 .
[ 10 ] R . Di Massa , M . Montagnuolo , and A . Messina . Implicit news recommendation based on user interest models and multimodal content analysis . In Proc . of AIEMPro , pages 33–38 . ACM , 2010 .
[ 11 ] L . Ding and A . Yilmaz . Image segmentation as learning on hypergraphs . In Proc . of ICMLA , pages 247–252 , 2008 . [ 12 ] E . Gabrilovich , S . Dumais , and E . Horvitz . Newsjunkie : providing personalized newsfeeds via analysis of information novelty . In Proc . of WWW , pages 482–490 . ACM , 2004 .
[ 13 ] K . George and K . Vipin . Multilevel k way hypergraph partitioning . VLSI Design , 11(3):285–300 , 2000 .
[ 14 ] T . Hofmann . Latent semantic models for collaborative filtering .
ACM Transactions on Information Systems , 22(1):89–115 , 2004 .
[ 15 ] Y . Huang , Q . Liu , S . Zhang , and DN Metaxas . Image retrieval via probabilistic hypergraph ranking . In Proc . of CVPR , pages 3376–3383 . IEEE .
[ 16 ] TH Hwang , Z . Tian , R . Kuangy , and JP Kocher . Learning on weighted hypergraphs to integrate protein interactions and gene expressions for cancer outcome prediction . In Proc . of ICDM , pages 293–302 . IEEE , 2008 .
[ 17 ] A . Karatzoglou , X . Amatriain , L . Baltrunas , and N . Oliver .
Multiverse recommendation : n dimensional tensor factorization for context aware collaborative filtering . In Proc . of RecSys , pages 79–86 . ACM , 2010 .
[ 18 ] D . Li and S . Li . Hypergraph based inductive learning for generating implicit key phrases . In Proc . of WWW , pages 77–78 . ACM , 2011 .
[ 19 ] L . Li , W . Chu , J . Langford , and RE Schapire . A contextual bandit approach to personalized news article recommendation . In Proc . of WWW , pages 661–670 . ACM , 2010 .
[ 20 ] L . Li , D . Wang , T . Li , D . Knox , and B . Padmanabhan . Scene : a scalable two stage personalized news recommendation system . In Proc . of SIGIR , pages 125–134 . ACM , 2011 .
[ 21 ] L . Li , DD Wang , SZ Zhu , and T . Li . Personalized news recommendation : a review and an experimental investigation . Journal of Computer Science and Technology , 26(5):754–766 , 2011 .
[ 22 ] L . Li , L . Zheng , and T . Li . Logo : a long short user interest integration in personalized news recommendation . In Proc . of RecSys , pages 317–320 . ACM , 2011 .
[ 23 ] J . Liu , P . Dolan , and ER Pedersen . Personalized news recommendation based on click behavior . In Proc . of IUI , pages 31–40 . ACM , 2010 .
[ 24 ] DM Pennock , E . Horvitz , S . Lawrence , and CL Giles .
Collaborative filtering by personality diagnosis : A hybrid memory and model based approach . In Proc . of UAI , pages 473–480 , 2000 .
[ 25 ] P . Resnick , N . Iacovou , M . Suchak , P . Bergstrom , and J . Riedl .
GroupLens : an open architecture for collaborative filtering of netnews . In Proc . of CSCW , pages 175–186 . ACM , 1994 .
[ 26 ] B . Sarwar , G . Karypis , J . Konstan , and J . Reidl . Item based collaborative filtering recommendation algorithms . In Proc . of WWW , pages 285–295 . ACM , 2001 .
[ 27 ] AI Schein , A . Popescul , LH Ungar , and DM Pennock .
Methods and metrics for cold start recommendations . In Proc . of SIGIR , pages 253–260 . ACM , 2002 .
[ 28 ] L . Sun , S . Ji , and J . Ye . Hypergraph spectral learning for multi label classification . In Proc . of SIGKDD , pages 668–676 . ACM , 2008 .
[ 29 ] Z . Tian , TH Hwang , and R . Kuang . A hypergraph based learning algorithm for classifying gene expression and arraycgh data with prior knowledge . Bioinformatics , 25(21):2831 , 2009 .
[ 30 ] G . Wachman and R . Khardon . Learning from interpretations : a rooted kernel for ordered hypergraphs . In Proc . of ICML , pages 943–950 . ACM , 2007 .
[ 31 ] F . Wu , YH Han , and YT Zhuang . Multiple hypergraph clustering of web images by miningword2image correlations . Journal of Computer Science and Technology , 25(4):750–760 , 2010 .
[ 32 ] M . Zhang and N . Hurley . Avoiding monotony : improving the diversity of recommendation lists . In Proc . of RecSys , pages 123–130 . ACM , 2008 .
[ 33 ] D . Zhou , J . Huang , and B . Scholkopf . Beyond pairwise classification and clustering using hypergraphs . Technical report , 2005 .
[ 34 ] D . Zhou , J . Huang , and B . Scholkopf . Learning with hypergraphs : Clustering , classification , and embedding . Advances in Neural Information Processing Systems , 19:1601 , 2007 .
314
