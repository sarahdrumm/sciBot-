queryCategorizr : A Large Scale Semi Supervised System for Categorization of Web Search Queries
Mihajlo Grbovic† , Nemanja Djuric† , Vladan Radosavljevic† , Narayan Bhamidipati† , Jordan Hawker‡ , Caleb Johnson‡
†Yahoo Labs ‡Yahoo , Inc .
{mihajlo , nemanja , vladan , narayanb , hawkerj , calebj}@yahoo inc.com
701 First Avenue , Sunnyvale , CA , USA
ABSTRACT Understanding interests expressed through user ’s search query is a task of critical importance for many internet applications . To help identify user interests , web engines commonly utilize classification of queries into one or more predefined interest categories . However , majority of the queries are noisy short texts , making accurate classification a challenging task . In this demonstration , we present queryCategorizr , a novel semi supervised learning system that embeds queries into low dimensional vector space using a neural language model applied on search log sessions , and classifies them into general interest categories while relying on a small set of labeled queries . Empirical results on large scale data show that queryCategorizr outperforms the current stateof the art approaches . In addition , we describe a Graphical User Interface ( GUI ) that allows users to query the system and explore classification results in an interactive manner .
Keywords Query categorization ; word2vec ; query embeddings .
Categories and Subject Descriptors I27 [ Artificial Intelligence ] : Natural Language Processing—Text analysis ; Language parsing and understanding
1 .
INTRODUCTION
Search engines are used by billions of online users every day as a tool to promptly find desired information . In order to capture and more easily act upon very clear intent that the users channel through queries , query classification is a task of critical importance to search engines . Here , one aims to classify textual queries into one or more predefined interest categories , such as “ finance ” , “ sports ” , or “ technology ” . This allows search companies to better understand user intentions , improve user experience through better personalization , provide more relevant search results and targeted recommendations , and optimize organization of content . However , query categorization poses difficult , quite different challenges than standard text classification ,
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author ’s site if the Material is used in electronic media . WWW 2015 Companion , May 18–22 , 2015 , Florence , Italy . ACM 978 1 4503 3473 0/15/05 . http://dxdoiorg/101145/27409082742850 as queries are usually very noisy and short , with majority containing less than three words [ 1 ] . In addition , large number of possible queries induces very sparse feature space for bag of words ( BOW ) encoding schemes , which limits applicability of standard BOW based approaches . To reduce sparsity , some authors proposed to expand the feature space using features computed from documents retrieved when issuing a query [ 1 ] . However , this introduces additional latency , which often represents an unacceptable overhead .
To address these issues we take a radically new approach to query categorization by using distributed language models , motivated by their recent success in a number of natural language processing ( NLP ) tasks [ 3 , 4 ] . In the context of NLP , distributed models are able to learn word representations in a low dimensional continuous vector space using a surrounding word context in a sentence , such that semantically similar words are close to each other in the embedding space [ 3 ] . However , directly applying these models to the problem of query categorization is a challenging task . Finding distributed representations of queries , as opposed to words , brings unique challenges unlike those found in everyday NLP problems . Contrary to everyday language , where words , sentences , and language rules are clearly defined , in search queries there is no notion of “ a sentence of queries ” or the surrounding context , that would be equivalent to a natural language domain for which the distributed language models were developed . We address these issues and propose a novel method that exploits the fact that user queries are recorded with the timestamp in search logs , from which we create “ query sentences ” using logged user sessions . This allowed us to apply language models and learn query representations in a low dimensional space where semantically similar queries are nearby . As a result , and in contrast to BOW approaches , related queries have a high similarity score even if they do not have any common terms .
Abovementioned state of the art language models are unsupervised , and to use their strengths in the query classification task we propose their semi supervised extension . Semisupervised methods [ 6 ] are typically used when majority of the training data , in our setting queries , are unlabeled . Such methods aim at achieving high accuracy on the labeled data and ensuring some statistical dependence on unlabeled examples . The proposed algorithm can be placed under such framework . Using a limited number of labeled queries and large amount of unlabeled data , the method learns “ category vectors ” in the same space as queries , which simplifies the classification to a nearest neighbor search in the joint space .
In this demonstration we also describe implementation steps of the deployed query categorization system , called queryCategorizr . These include details about data acquisition , representation learning , and classification . We also present a graphical user interface ( GUI ) which enables service that takes a query as input and outputs related query categories . In addition , the service can retrieve search queries semantically similar to the input query . Our key contributions are summarized below :
• We provide the first application of distributed language models to semi supervised query categorization , where we propose to learn distributed query and category representations in a joint space that compactly captures their semantic information ;
• We trained the model using more than 12 billion search sessions collected on Yahoo servers , resulting in highly effective classification method . The queryCategorizr system achieves 86 % precision with high recall ;
• We provide user interface coupled with sophisticated , cutting edge back end technology to demonstrate effectiveness of our approach .
2 . PROBLEM SETUP
Let us assume we are given search logs of N users during a period of T months , comprising Q unique queries . In search logs , every query q is recorded along with its timestamp t . For each user ui we collect data in the form Di = {(qi , ti ) , i = 1 , . . . , Ni , t1 < t2 < . . . < tNi} , where Ni represents number of queries that user ui generated . Given data set D = ∪N i=1Di , the objective is to find representation of queries that appeared in the data , such that semantically similar queries are nearby in the embedding space .
We consider the task of query classification , where we aim to classify queries into a pre defined category taxonomy . In our work , we leverage top 2 levels of an in house interest taxonomy , amounting to 150 categories . These categories cover a variety of topics , such as “ sports/baseball’ , “ finance/mortgage ” , or “ entertainment/movies ” . To map the queries into one or more interest categories , we propose to learn query and category representations in a joint , lowdimensional space using semi supervised neural language models applied to historical search logs .
3 . BACK END SYSTEM
In this section we discuss the queryCategorizr system , and describe server side components that learn query representations from data set D and classify queries into the taxonomy . 3.1 Data sessionization The user log data set D was sessionized and processed into session data set S containing S search sessions . A search session is defined as an uninterrupted sequences of web search activity , where a session ends when a user was inactive for more than 30 minutes [ 2 ] . More specifically , and without loss of generality , session s = ( q1 , . . . , qM ) ∈ S is an uninterrupted sequence of M queries ( analogous to a sentence in NLP ) , and each query q consists of L words , q = ( w1 , . . . , wL ) . In the case of repetitive queries , eg , s = ( q1 , q2 , q3 = q2 , q4 = q2 , q5 ) , repetitions were de duplicated , resulting in s = ( q1 , q2 , q5 ) . Lastly , sessions containing only one query were discarded .
( a ) Unsupervised
( b ) Semi supervised
Figure 1 : Skip gram model variants
We assume D is processed into session data S = ∪S
3.2 Model training s=1Ss . Given Ss = {(qi , ti ) , i = 1Ni , t1 < . . . < tNs} , where Ns represents number of queries in session s , the objective is to find query representation such that semantically similar queries are nearby in the feature space . For this purpose we extend ideas originating from recently proposed language models , as described in the remainder of the section .
The skip gram model [ 3 ] learns representations of queries in a low dimensional space in an unsupervised fashion , using a query session as a “ sentence ” and the queries within as “ words ” , to borrow the terminology from NLP domain . The representations are learned by maximizing the objective function L over the entire set of sessions S , as
L = log P(qm+i|qm ) .
( 3.1 ) s∈S qm∈s
−b≤i≤b,i=0
Probability P(qm+i|qm ) of observing a neighboring query qm+i given current query qm is defined using the soft max ,
P(qm+i|qm ) =
Q exp(v qm v q=1 exp(v qm+i ) qm v q )
,
( 3.2 ) where vq and v q are the input and output vector representations of query q of dimensionality d , and b defines the length of the context for query sequences .
As illustrated in Figure 1a and equation ( 3.2 ) , skip gram uses central query qm to predict b queries that come before and b queries that come after it in the search session . Thus , queries that often co occur and queries with similar contexts ( ie , with similar neighboring queries ) will have similar representations as learned by the model . Semi supervised skip gram ( SS SG ) assumes that some queries from the training data D are labeled with categories from the taxonomy . Then , we assign a vector to each category , and leverage query contexts in sessions to jointly learn query vectors and category vectors in the same feature space . To this end , given the labeled queries , we extend Ds to obtain data set Dl where categories were imputed into sessions . In particular , labeled queries were accompanied by assigned categories , and every time a vector of labeled central query qm is updated to predict the surrounding queries , vectors of categories assigned to qm are updated as well . More formally , assuming central query qm is labeled with Cm of C categories in total , ζm = {c1 , . . . , cCm} , the semisupervised skip gram learns query and category representa
…  …  qm ­‐b  qm  qm ­‐1  qm+1  qm+b  Projec(on  m ­‐th  query  queries  within  a  session  c1  ck  …  m ­‐th  query  categories  …  …  qm ­‐b  qm  qm ­‐1  qm+1  qm+b  Projec3on  m ­‐th  query  queries  within  a  session   Figure 2 : Nearest neighbors for query “ looney tunes ” tions by maximizing the following objective function L , log P(qm+i|c ) log P(qm+i|qm ) +
. qm∈s
−b≤i≤b,i=0 s∈S ( 3.3 ) Probability P(qm+i|c ) of observing query qm+i given label c of the current query qm is defined using the soft max , c∈ζm
P(qm+i|c ) =
Q c v exp(v q=1 exp(v qm+i ) c v q )
.
( 3.4 )
The SS SG model is illustrated in Figure 1b . 3.3 Classification
In order to classify an unlabeled query qu we perform the following operations : 1 ) lookup vector representation of qu ; 2 ) lookup vectors for all C categories ; 3 ) calculate cosine similarity between category vectors and query qu , and label the query with the category that has the highest similarity . Handling out of vocabulary queries . To classify a query not seen during training , we segment it using Conditional Random Field [ 5 ] . Then , its representation was obtained as a sum of vectors which correspond to the segments .
4 . FRONT END SYSTEM
To build GUI for the queryCategorizr system , we considered modern web application standards and employed a browser heavy approach with HTML/CSS/JavaScript code , as well as a light API layer in Python . 4.1 Architecture
Cutting edge front end technologies were employed in development of the interface , enabling the creation of a fast , robust web application . The project uses Node1 as an I/O serving layer with Ember CLI2 ( powered by Broccoli3 ) , providing a lightning fast asset pipeline to support constanttime rebuilds and compact build definitions . Ember CLI also allowed us to write next generation JavaScript code compliant with upcoming ECMAScript 6 language specifications4 by enabling a built in transpiler5 to convert ES6 syntax to ES5.1 compliant AMD ( RequireJS6 ) modules . NPM7 1http://nodejs.org/ , all URLs last accessed in January 2015 2http://wwwember clicom/ 3https://github.com/broccolijs/broccoli 4https://peoplemozillaorg/ jorendorff/es6 draft.html 5https://github.com/esnext/es6 module transpiler 6http://requirejs.org/ 7https://wwwnpmjscom/
Figure 3 : Categorization of input query “ bank of america ” and Bower8 package managers were utilized in concert to bring in external library dependencies . Lastly , JQuery9 was used to perform AJAX requests to retrieve data from the SS SG model via the API layer written in Python . 4.2
Implementation
Our choice of front end technologies was derived from the goal of creating a Single Page Application ( SPA ) to handle business logic effectively on the client side of the system , without the need to pass page assets back and forth to the server side of the application after the initial page load . EmberJS10 serves as the primary backbone of the project , providing an opinionated MVC framework with hierarchical routing and two way data binding to the DOM . We utilized Ember idiomatic UI components , such as tables and selects , that bring feature rich client interaction to these classic web elements . Bootstrap11 provided responsive layouts , as well as stylized inputs and buttons to give the application a clean , aesthetically pleasing interface . 4.3 Design
Primary design choices for user interface revolved around data exploration . The UI of queryCategorizr is shown in Figures 2 and 3 . It is composed of three major components : a query input box , results box , and a drop down menus to select different functionalities . The demo works by typing in queries in the query input box . Depending on the selected functionality , searching for a query in the application reveals 1 ) the list of highly relevant queries identified by the SS SG model ; or 2 ) interest categories for a given query . Results are updated immediately , together with relevance scores , as a user types in a query or clicks on one from the results list . This allows the user to view results as quickly as possible with near instant feedback on their queries . We also created a user experience that allows data relations to be investigated on an iterative basis . By clicking on retrieved queries/interests from the results table , the user can easily evolve their initial query into a series of relevant inquiries .
5 . EVALUATION
We learned query representations using more than 12 billion search sessions extracted from search logs collected on Yahoo servers . For the purposes of SS SG training a limited portion of queries were manually labeled by human editors , resulting in approximately 2,000 labeled queries per category from the interest taxonomy .
The semi supervised skip gram model was optimized using stochastic gradient ascent , suitable for large scale prob8http://bower.io/ 9http://jquery.com/ 10http://emberjs.com/ 11http://getbootstrap.com/
Table 1 : Precision and recall of different methods
Method Precision Recall LR BOW 0.71 SVM BOW 0.74 0.80 LR SG SVM SG 0.82 0.86 SS SG
0.66 0.65 0.64 0.62 0.63 ing the demonstration , we will showcase two functionalities mentioned previously : 1 ) finding semantically similar queries ; and 2 ) classifying queries into interest categories . We will first go over the set of queries prepared in advance to demonstrate strengths and weaknesses of the queryCategorizr system . Then , we will ask users to test capabilities of queryCategorizr using their own queries12 .
7 . CONCLUSION
In this paper we described queryCategorizr , a state of theart system for understanding of user search queries . The system includes functionalities such as finding semantically similar queries and categorizing queries into interest categories , useful in a number of online applications . We demonstrated the benefits of the system via graphical user interface in which users freely explors system capabilities in an intuitive manner . In the future , we plan to expand the system by incorporating embedded representations of other user events , such as clicked ads or read articles .
8 . REFERENCES [ 1 ] E . Gabrilovich , A . Broder , M . Fontoura , A . Joshi , V . Josifovski , L . Riedel , and T . Zhang . Classifying search queries using the web as a source of knowledge . ACM Transactions on the Web , 3(2):1–28 , April 2009 . [ 2 ] D . Gayo Avello . A survey on session detection methods in query logs and a proposal for future evaluation . Inf . Sci . , 179(12):1822–1843 , May 2009 .
[ 3 ] T . Mikolov , I . Sutskever , K . Chen , G . S . Corrado , and
J . Dean . Distributed representations of words and phrases and their compositionality . In Advances in Neural Information Processing Systems , pages 3111–3119 , 2013 .
[ 4 ] J . Turian , L . Ratinov , and Y . Bengio . Word representations : a simple and general method for semi supervised learning . In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics , pages 384–394 . Association for Computational Linguistics , 2010 .
[ 5 ] X . Yu and H . Shi . Query segmentation using conditional random fields . In Proceedings of the First International Workshop on Keyword Search on Structured Data , KEYS ’09 , pages 21–26 , 2009 .
[ 6 ] K . Zhang , J . T . Kwok , and B . Parvin . Prototype vector machine for large scale semi supervised learning . In Proceedings of the 26th Annual International Conference on Machine Learning , pages 1233–1240 . ACM , 2009 .
12Demonstration video is available online at the following URL : http://youtu.be/RSQ7mK xpH8
Figure 4 : Queries categorized into “ automotive ” category lems . However , computation of gradients ∇L in ( 3.1 ) and ( 3.3 ) is proportional to the vocabulary size Q , which is computationally expensive for our application as Q could easily reach tens of millions queries . As an alternative , we used negative sampling approach proposed in [ 3 ] , which significantly reduces the computational complexity of the training . Vector representations were trained for 60 million most frequent queries found in the search logs . Training was done using a machine with 256GB of RAM memory and 24 cores . Dimensionality of the embedding space was set to D = 300 , while context neighborhood size was set to 5 . Finally , we used 10 negative samples in each vector update . In the first experiment we verified that the semisupervised algorithm maps semantically similar queries close to each other in the embedding space , and also close to the best matching categories . This is illustrated in Figure 4 , where we show nearest queries to the vector of “ automotive ” category ( size of a query in the word cloud is proportional to the cosine similarity ) . We can see that SS SG grouped semantically related queries into the same part of the space , while keeping them close to the appropriate category vector . To better quantify the value of our approach , we evaluated the proposed semi supervised algorithm on the labeled query set using 5 fold cross validation . We compared semisupervised based classification to the logistic regression ( LR ) and linear support vector machine ( SVM ) classifiers that use BOW features . We also compared to LR and SVM where we used features learned by unsupervised SG to represent the labeled queries . We report the results in Table 1 , where we can see that classification using the SS SG method achieved higher precision than the competing methods , while at the same time maintaining competitive recall measure .
6 . DEMONSTRATION
Our demonstration system consists of three critical components : 1 ) front end user interface ; 2 ) back end service that processes all user requests ; and 3 ) back end server that performs classification and query similarity calculations . Dur toyotahondanissanmercedes_benzhyundaibmwkiasubaruaudilexusedmundsmazdavolkswagenbmw_usaacurainfinitihonda_carsmitsubishivwmercedesvolvorange_rovernissan_altimatruecarscionkia_optimaland_roverhonda_accordkia_sorentohonda_crvhonda_civictoyota_tacomatoyota_comsubaru_forester_2014hyundai_sonatatoyota_carslexus_is_2014toyota_camrynissan_roguefiattoyota_corollahyundai_santa_fehonda_pilothonda_comnissan_carstoyota_rav4hyundai_genesisnissan_versakia_soulhyundai_elantranissan_muranotoyota_priusnissan_juketoyota_highlandermazda_6nissan_pathfinderacura_mdxmercedes_clamazda_3subaru_outbackscion_frsmbusakia_dealer_locatortrue_carmitsubishi_carsmazda_cx_5volvo_carsjaguar_carsnissan_maximahyundai_carstoyota_recallkia_cadenza_2014toyota_corolla_2014fiat_500audi_q52014_toyota_highlandernissan_leafbmw_x5toyota_dealerslexus_rx_350nissan_commercedes_usatoyota_highlander_2014volkswagonhonda_fitsubaru_brzaudi_usamazda_cx5nissan_rogue_2014kia_sportage2014_toyota_corollahonda_dealersbmw_carskia_cars2014_nissan_roguemazda_carslexus_carshonda_accord_2014audi_q7kia_combmwusainfiniti_q50honda_odysseyrange_rover_evoquetoyota_siennasubaru_wrxvolkswagen_passathonda_crv_2013priushonda_crv_2014toyota_fj_cruiserhyundai_tucsonmercedes_benz_cla_2013mercedes_benz_usa2014_honda_accordconsumer_reports_carskia_optima_2014honda_odyssey_2014toyota_venzahonda_civic_20132013_honda_accordfj_cruiser2014_mazda_3toyota_dealer_locatormazda_cx_9kia_riotoyota_avalonlexus_comacura_rdx_2014nissan_sentrakia_fortenissan_frontierhyundai_accentsubaru_impreza2014_infiniti_q50suzuki_carshonda_dealer_locatornissan_dealerstoyota_rav4_2014infiniti_g37costco_auto_programtoyota_sequoiaaudi_a6honda_pilot_2014toyota_4runnernissan_usainfiniti_carshonda_ridgelinebmw_x1toyota_rav4_2013subaru_forester2014_kia_optimaacura_mdx_2014subaru_legacyhonda_accord_2013hyundai_dealersrange_rover_sporthundaibmw_comsubaru_dealer_locatorscion_tcbenzacura_tlhyundai_velostertoyota_dealerrav4infinity_caracura_dealer_locator2014_honda_civicbmw_x3volkswagen_jettasuburuinfiniti_g35compare_carsvolvo_xc90honda_pilot_2013honda_dealershiphonda_elementtoyota_yarishonda_dealerhyndaitrue_car_pricingtoyota_camry_2013mitsubishi_outlanderhonda_odyssey_2013nissan_xterrakia_optima_2013infiniti_qx56hyndai2013honda_crosstourtoyota_tacoma_2014audi_a3subaru_recall_2013hyundai_equusacura_rdx_2013nissan_armadavolkswagon_comnissan_dealer_locatormazda_comsubaru_crosstrek_2013nissiansubaru_crosstrek_2014subaru_comtoyota_land_cruiserlexus_suvjettatoyota_camry_2014mbusa_comcar_reviewsvw_comnissan_sentra_2013volvo_s60nissan_pathfinder_2014toyota_suvhyundai_genesis_coupeacura_com2014_honda_crvtoyota_tacoma_2013infinity_automazda_usa2014_carslandrovermazda_3_20142014_honda_fitvolkswagen_tiguanhonda_civic_2014isuzuaudi_comtoyota_corolla_2013lexus_dealersnissan_dealerkia_dealersmercedes_suvacura_rdxscion_xbtoyota_matrixtoyota_avalon_2014kia_soul_2014camrynissan_rogue_2013best_cars_2013infiniti_fx35acura_tsxkia_motors2013_kia_optimabest_suvnissan_juke_2013mitsubishi_lanceraudi_suvbest_cars_2014crossover_vehicleshyundiamazda_5nissan_pathfinder_2013bmw_3_serieskia_soul_2013nissan_altima_2013bmw_suvvw_beetlehyundai_com2013_toyota_avalonacura_ilx2014_kia_sorentotoyota_scion2014_acura_mdxcar_brandsvolvo_xc60mazda_cx_7toyota_rav_4honda_usaexterior_colorshonda_suvinfiniti_suvhonda_crztoyota_sienna_2014nissan_questinfinity_carsvw_passattoyota_celicavw_jettalexus_es_350jukebmw_5_seriesaudi_carskia_sorento_2014toyota_usarav_4vw_usacorollabmw_dealersnissan_cubekia_cadenzanissan_suvfiat_carsaltimahyundai_2012corolla_2014iihsaudi_q3longo_lexusaccurapassatq50mazda3nissanusarav4_2013nisankia_suvvolvo_c30lexus_is_3502014_lexusxterramazda_cx9toyataland_cruiserelantravelostervolvo_suvmaximaused_bmwacura_suvinfiniti_comvw_golfhonda_crxhonda_cr_vlexus_is_2015mazda_tributekia_sorrentoyaristoyota_used_carsmazda_suvprius_cmini_usascion_carsmazadahonda_fit_2013toyota_fj4runnervw_dealerslexus_rxsuzuki_sx4nissonvw_carsvw_ccnew_car_dealsinfiniti_usanissalexus_2014toyatoscion_xd2014_hondalexus_usavw_gtidch_hondahonda_cars_usahyandaismall_carsinfinithundai2013awd_carsmadzaused_bmw_carslexus_gxbmw_2014honda_truckbmw_528ibest_suvsautonation_hondamazda6venzahyundihuyndaiinfintikia_usavolvo_dealerstiguanjetta_tdiveloster_2013bmw_leasecivic_silexus_rx3002014_kiatoytahundayused_subarufiat_usatoyotmazda5cx5masdaused_lexussuburahondhyunda2014_crvq72013_lexusused_auditoyoyalexaskia_carhundicx_5vw_tdilexus_com_usa2014_infinitiis250qx60bmw_328dtototavwusacube_carvolvo_v70rx350kia_solhundahonafiat_comvovlosubrunisssiconml_350buikmazda2kia_k9hindahundiakiassubaroazeragl_450hondaimercedsacruaaudiecameryhyuandikia_truckluxuslexucr_vxc90aduiinfinitiusatouotalexuxtayotabmwx3hondikia_irvineluxeses350bmw_525auid
