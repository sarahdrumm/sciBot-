Improving Productivity in Citizen Science through
Controlled Intervention
Avi Segal
Ben Gurion University , Israel
Robert J . Simpson University of Oxford , UK avise@postbguacil robertsimpson@astrooxacuk
Ya’akov ( Kobi ) Gal
Ben Gurion University , Israel kobig@bguacil
Victoria Homsy , Mark Hartswood , Kevin R . Page and Marina Jirotka
University of Oxford , UK
{victoriahomsy@yahoo.com , markhartswood@csoxacuk , kevinpage@oercoxacuk , marinajirotka@csoxacuk }
ABSTRACT The majority of volunteers participating in citizen science projects perform only a few tasks each before leaving the system . We designed an intervention strategy to reduce disengagement in 16 different citizen science projects . Targeted users who had left the system received emails that directly addressed motivational factors that affect their engagement . Results show that participants receiving the emails were significantly more likely to return to productive activity when compared to a control group . Categories and Subject Descriptors H53 [ Group and Organization Interfaces ] : Collaborative Computing . General Terms Experimentation , Human Factors . Keywords Peer production , crowdsourcing , citizen science , intervention strategies . 1 . INTRODUCTION Volunteers have been involved in scientific research for over 100 years . More technological developments have transformed the role of these non professional scientists to active participants in large scale endeavors , termed citizen science , in which volunteers collectively create or analyze data at a scale that professional researchers cannot accomplish on their own [ 1 ] .
Participants in contribution rates and motivation [ 3 ] . A small minority of participants are highly committed and contribute tens of thousands of tasks , also becoming involved in higher order participation , such as forum moderation . Whilst the platform could not function without the participation patterns of users in citizen science projects exhibits a
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author's site if the Material is used in electronic media . WWW’15 Companion , May 18–22 , 2015 , Florence , Italy . ACM 978 1 4503 3473 0/15/05 . http://dxdoiorg/101145/27409082743051 these committed , high volume contributors , in citizen science projects differ widely recently , long tail distribution , and most volunteers carry out only a few tasks [ 4 ] .
Prior work has showed that citizen science volunteers are driven by diverse range of motivations with varying degrees of commitment and engagement [ 3,4,5 ] . These studies were limited to analyzing isolated citizen projects , and did not attempt to implement and test intervention policies to bring back users to the system . Our work bridges this gap by moving towards a general methodology for reducing disengagement in citizen science through a controlled intervention .
Our methodology is based on the analysis of two years’ worth of participation data from 16 different citizen science projects and included the following : ( 1 ) Surveys to reveal the motivations that drive users’ participation in citizen science ; ( 2 ) Identifying cohorts based on the survey results and the participation data ; ( 3 ) Designing an intervention strategy that targets specific cohorts and is designed to increase their engagement with the system ; ( 4 ) Analyzing the efficacy of this strategy over time , according to performance and persistence measures .
The study was conducted using the Zooniverse platform , the largest citizen science platform that exists today . Zooniverse includes over a million volunteers and 25 live projects spanning astrophysics , zoology , biology , medicine , climate science , and the humanities [ 15 ] . In all of these projects the volunteers identify , classify , mark , and label data , which is subsequently aggregated and analyzed in order to reach scientific conclusions . The number of active projects is steadfastly growing , from 8 live projects in the beginning of 2012 , to 25 live projects in 2014 , and its user base includes volunteers from varying occupations , age groups , level of education and geographical location [ 2 ] .
The vast majority of participants in Zooniverse work on a few tasks and participate for just a few days before leaving the system [ 18 ] . Despite their casual participation , these users contribute a substantial fraction of the overall effort going into the projects . This is demonstrated in Figure 1 , which shows the fraction of total contributions as a function of the number of contributions per user in the Galaxy Zoo project .
331 Figure 1 : Fraction of total contributions ( y axis ) as a function of the average number of contributions per user ( x axis ) in the
Galaxy Zoo project . Note the sharp spike for users with very small contribution rates on the left hand side of the Figure . becomes
If rate identified important . increasingly
“ classification individual mistakes science projects could survey the effects of
The tall spike in the left hand side of the figure shows that the total contribution for users with small number of contributions forms the vast majority of volunteers . The figure also shows the long tail of decreasing contributions as the number of average contributions per user grows .
As the number of citizen science projects continues to grow , the need to be more efficient and retain volunteer engagement for longer volunteer disengagement ( the point at which users stop participating in the system ) can be delayed by just a few tasks , then overall productivity of citizen improve significantly .
We designed and administered a survey to 3,000 randomly selected users in Zooniverse who participate in a wide variety of projects . The anxiety ” ( overestimating [ 5] ) , competition from other life demands and leisure activities , and boredom from specific projects as prominent causes of disengagement among volunteers . For many users the cause of classification anxiety was revealed to be a misunderstanding of the collective nature of citizen science projects , in which aggregation of data diminishes the effects of individual mistakes .
To identify target communities for the intervention we combined our analysis of the survey with findings revealed by clustering two years’ worth of user participation data from 16 different projects . We focused our intervention on two cohorts who quickly left the system after an initial burst of activity . Volunteers in the first cohort spent less than a day making contributions , and those in the second spent between one and ten days as active volunteers . These cohorts are significant as they capture the vast majority of user participation in the system for all projects .
We designed interventions in the form of emails that directly addressed the causes of disengagement that were revealed in the survey and sent to each user in the two cohorts described above . We compared the effectiveness of this intervention method with a control group that included participants with similar participation patterns who did not receive any email notification .
The results showed that participants from the intervention group were significantly more likely to return to activity in their in that identifies meaningful cohorts respective projects than participants from the control group , without experiencing a drop in contribution rates and activity in the system , as compared to the control group . In addition , returning participants from the intervention group resumed activity at least as fast , and remained active in the system for at least as long as returning participants from the control group .
Our work has insights for the designers of citizen science platforms in general , by 1 ) Providing an example of a general methodology for reducing disengagement in different citizen science projects the population , 2 ) Uncovering the motivational factors that reduce participation of different groups in the system , and 3 ) Providing a guideline for interventions to stimulate re engagement and bring back users to be productive contributors . 2 . RELATED WORK This paper relates to prior work on identifying participation patterns and the study of disengagement in citizen science . We relate to each of these in turn .
The majority of the labor in general peer production sites is often apportioned to 1 % of users of the website [ 7 ] . Preece and Shneiderman [ 6 ] defined categories of users that are distinguished by their depth of social engagement within the community : ‘readers’ who lurk in the background ; ‘contributors’ who create content and contribute to the community ; ‘collaborators’ who work together and regularly contribute and ‘leaders’ who participate in the governance of the site . The ratio of contributors in citizen science projects is significantly higher than that of peer production sites , averaging at 10 % [ 18 ] . Contributors in citizen science exhibit a variety of contribution styles . In particular , Eveleigh identified 'dabblers' as important classes of volunteers [ 5 ] . Dabblers exhibit a low commitment attitude , a weak tie to projects , and an intermittent approach to participation , with occasional short bursts of activity . Nonetheless , these casual contribution styles form the majority of user contributions to Zooniverse [ 19 ] and were the focus of attention in this study .
Some identifying disengagement in citizen science . Rotman described a ‘circuit of engagement’ whereby volunteers , motivated initially out of curiosity , may subsequently leave the system if they are not made to feel part of the wider scientific community [ 9 ] . Jackson et al . studies have focused on specifically
332 [ 20 ] identified ways in which the technical features of the projects may serve as motivational factors leading participants towards sustained participation . Eveleigh [ 5 ] cited competition with other life activities , anxiety over making mistakes and boredom as main reasons driving disengagement . Kittur added low work quality and inappropriate task assignment as major reasons for early disengagement [ 10 ] . Mao et al . [ 8 ] used machine learning to predict disengagement in the Galaxy Zoo project , focusing on disengagement after 5 minutes and 30 minutes sessions , respectively .
There is no prior work on alleviating disengagement in citizen science through controlled intervention studies . Wiggins and Crowston [ 19 ] emphasized the importance of fitting the project environment to its specific goals and characteristics in order to enhance participation . Some projects , like foldit [ 16 , 21 ] , are framed in the context of a game in order to enhance user engagement . A few citizen science projects exhibit badges and leader boards functionalities , although there is evidence that competitive game elements may be counterproductive and work to de motivate casual contributors and reduce the quality of the work [ 11 , 12 , 13 ] . the four to understand reasons following sections we describe a
In stage multidisciplinary process consisting of : ( 1 ) Surveying volunteer populations for participation and disengagement ; ( 2 ) Profiling volunteer populations to reveal distinct cohorts that may be targeted by interventions ; ( 3 ) Intervention design to target the cohorts and address the motivational factors uncovered in the survey ; ( 4 ) Evaluation and follow up to determine effectiveness of intervention strategy . questions ( Q1 to Q9 ) focused on demographics , including age , education level , employment status , occupation , and country of residence to ascertain how our sample compares to the general population . Q10 to Q13 were included to gain insight into how participation in citizen science fits into participants’ lives particularly in relation to daily routines , and where contributions are made . Q14 to Q17 asked about participants’ experience of forums and chat , their motivations and what might encourage greater participation . Q18 probed if anxiety around the accuracy of contributions was common experience , and if so , how participants dealt with their anxiety . Q19 ascertained if this anxiety leads to disengagement . Q20 to Q22 focused on trying to understand what makes projects engaging , whereas Q23 and Q24 elicited what makes some projects less engaging and probed reasons for disengagement . Finally , Q25 prompted respondents for additional comments on their participation and for suggestions of improvements that might increase engagement . In this paper we report mainly on responses to questions about anxiety and disengagement .
We based our analysis on 257 completed responses to the survey that were obtained over the course of a month ( July August 2014 ) ; an 8.6 % response rate . Out of the submitted responses , 35 % of users reported to be living in the US , and 30 % in the UK . The remainder of the responses came from 31 different countries spanning Europe , Asia , Africa , North America , and Australia . 59 % of the responses were from males while 39 % were from females , with 2 % preferring not to answer . The mean age of participants was 44 , with a flat distribution of ages ranging from 18 to 79 . The open ended questions were analyzed using thematic analysis [ 22 ] .
Our findings are consistent with the study by Eveleigh et al . [ 12 ] for the ‘Old Weather’ project regarding classification anxiety . However , we extended this study in revealing the causes and effects of this anxiety on users’ participation . We focus on this topic first as it illustrates the collective nature of participation in citizen science platforms , a topic we address in detail in our discussion . A significant majority 82 % of respondents indicated that they had experienced classification anxiety during their participation . Around 25 % of anxious participants report disengaging from projects or the site as a whole . In free text responses statements like “ Rather than accidentally marking everything wrong , I chose to stop instead ” were common . intervention approach we
3 . UNDERSTANDING PARTICIPATION AND DISENGAGEMENT ( STAGE 1 ) implemented a To guide our questionnaire to uncover reasons for patterns of engagement and disengagement within Zooniverse . Our survey included 25 questions and was sent on July 7th 2014 to 3,000 participants randomly selected out of those who had logged in to the system at least once in the previous 3 months . The purpose for this timespan was to target citizen scientists who had disengaged but had contributed sufficiently recently to still be inclined to respond to the survey . The survey took approximately ten minutes to complete by participants , and there was no monetary ( or other ) reward offered . The survey was composed as follows : Initial
Table 1 : Citizen Science projects used in study
333 Figure 2 : Activity Patterns in 16 Citizen Science Projects is rooted this classification anxiety
We argue in a misunderstanding of the collective nature of citizen science . In scientific data analysis that is carried out by paid professionals , accuracy is crucial for valid results ; scientists undergo years of training to become expert at gathering and analyzing data . Citizen Science is a place where these principles of conventional scientific practice are almost entirely inverted . Volunteers are invited to classify objects almost immediate they land on a project homepage , typically after only the briefest of tutorials . But in contrast to conventional scientific practice , in citizen science , mistakes typically do not destroy the validity of the results . Due to the collective nature of citizen science many participants complete each task , and techniques such as majority voting and statistical aggregation serve to alleviate the effects of individual mistakes on the analysis . In fact , ‘mistakes’ often give scientists important information , for example , telling them that an object is ambiguous or otherwise hard to interpret . It seems that volunteers fail to perceive that they are actually contributing as part of a collective but instead retain a conventional model of scientific practice with the attendant anxiety about individual mistakes which may lead them towards disengaging from the platform .
The most common reason given for intermittent contributions was due to distracting life events . In response to the question “ When do you participate in Zooniverse ? ” , thirty eight percent of respondents agreed with the statement : “ Sometimes I don't contribute for a while , but then I pick it up again ” , corresponding to the category of ‘dabblers’ described by Eveleigh [ 5 ] . For the follow up question : “ What made you stop ” , of those who responded the vast majority ( 66 % ) cited distraction , time pressure , work , family obligations and competing leisure interests as reasons for disengagement . Some respondents express their experience of disengagement as akin to ‘forgetting’ ( “ I just get other things to do and forget about it ” ) . They also describe how re engagement is associated with remembering or being reminded , ( “ When I have a lull and I remember , I have a look at the Zooniverse . ” ; “ I need to be nudged ” ) . Some of these respondents also report that they become bored or find a project less appealing than they initially thought ( “ I get a little bored , and forget about it . ” ) , sometimes , because of the way that the Zooniverse site is structured , not realizing there are other projects they might find more appealing ( “ I've been participating at GalaxyZoo for a few weeks and it is only now in this survey I realize all the other projects that I can join . ” ) .
Taken together , these responses suggest there is a significant ‘reengagement potential’ for participants who disengage , which might be activated by a suitable reminder . Such a reminder might usefully provide reassurance about classification accuracy , as well as directing ‘bored’ participants towards other projects they could try . We describe our intervention strategy in greater detail in section 5 . 4 . PROFILING VOLUNTEER POPULATIONS ( STAGE 2 ) To understand which citizen science sub population we might usefully target with an intervention ( ie which may be prone to distraction , anxiety or boredom ) we analyzed the engagement patterns of volunteers in 16 different projects . This sample is representative of the gamut of different topics in Zooniverse ( eg , biology , nature , astronomy ) and popularity with volunteers , as measured by the number of registered users as of July 2014 .
Table 1 provides a general description of these projects . Data was collected beginning September 2012 for all projects , with the exception of the Planet Hunters project , for which data was already available from December 2010 .
We measured users’ activity in the system by the number of days elapsed since their first and last seen login . Let ( cid:3038 ) be the current timestamp . Let be the timestamp of the user ’s first login to the system . Let be the timestamp representing the user ’s most difference between and . Figure 2 describes users' activity in recent login to the system . We measured a user ’s activity as the the system for all of the supplied projects . The X axis shows range groups of participation time spans , and the Y axis shows the ratio of users that fall into each group .
The figure clearly identifies two distinct groups that make up the vast majority of activity in the system . The largest cohort of users consists of those who spent less than a day as active users , which we will denote the "1 day" cohort . This cohort included 56 to 87 percent of volunteers . Another large cohort consists of volunteers who spend between one to nine days as active users in the system , which we will denote the “ 10 day ” cohort . This cohort included 4 to 14 percent of volunteers . Together these cohorts make up at least 60 % of the user population in Zooniverse . We thus decided to focus our intervention strategy on these two cohorts . Even a
334 tly addressed th r survey , empha erance to individ of other projects h email . The e a week after th 1 day cohort wa n the contribution fits to the total co VENTION D intervention was cohorts to being signed the users intervention ( tes nder email that w ir respective pro his approach b users return to b nd the differen r returning to the s small increase in s significant benef 5 . INTERV 5 T The goal of the i d day and 10 day W We randomly ass a a control and an eceived a remin r eturn to the the r W We evaluated th q quickly ) these u in ntervention , an p persistence ) after
T The email direct u uncovered in our p projects , the tole th he availability o r eceived no such g group was sent T The mail for the ng PROJECTNA “ Thanks for tryi “ e on PROJECTN Y You're not alone nth . You can d p part every mon E with the comm P PROJECTNAME Talk at PROJE te eam , by visiting L . at PROJECTURL a ome people wor W We know that so E but this is P PROJECTNAME v volunteers' clicks s to learn about We use statistica s see each image . e everyone's answe ers , and the occ r results . If If PROJECTNAM Z Zooniverse citize y you would rather w wwwzooniverse c contributions h http://zooniverse R Rob and the Zoon
T The email to the v volunteers as re p providing users c contributions to u user ’s last login t
T The intervention 2 2014 and Septem r elevant email t to otal , the interve v volunteers from s selected from th 2 292 randomly se v volunteers from assigned to both a fr from the analy Z Zooniverse supp th he aforementio ti imestamp of task was conducted b mber 24th , 2014 to the volunteer ention group con the 1 day coho e 10 day cohort elected volunteer the 10 day coho h cohorts and re ysis . To meas plied us contribu oned dates , inc k contribution .
ME didn't suit yo en science proje r not receive the org/account/new to all Zoon eorg/me We loo niverse Team . ” e 10 day cohort egular contribut with a link t Zooniverse . It to the system . to ns of these popu ontributions of th DESIGN ( S s to bring back g productive use in the 1 day and st ) group . The i was designed to e ojects and to ma y measuring w being active us nce in contribu e system . lations can lead he projects . STAGE 3 ) the disengaged 1ers in the system m . to d 10 day cohort intervention grou up to encourage them ns . ake contribution ow whether ( and ho he ers following th ution rates ( i.e e . , he motivational asizing the collec dual mistakes b on the system . T email sent out to e user ’s last log as as follows : ere issues that we he ctive nature of th nd by volunteers , an up The control grou on o the interventio gin to the system m .
AME , we appre NAME thousan discuss the ima munity , and the p CTTALKURL . G eciate your click nds of people ta ages you see o project's researc Get involved aga ks! ke on ch ain rry that they ar sn't the case . the data , and m al techniques to casional error d ren't very good We can use a ultiple people w get the most fro does not affect th at all will om he ou , then check o ects at www.zoo ese emails you c wsletters . You niverse projec ok forward to see out all of the oth oniverse.org , or can unsubscribe can see yo cts visitin eing you again , her if at ur ng by varied slightly tors rather than to a service w t was sent two in addressing th n newcomers an which tracks the o weeks after th he nd eir he between the date 4 . On each day rs in the interve nsisted of 306 r ort and 541 vol t . The control g rs from the 1 da ort . Note that vo eceived both ma sure inter ution data for th cluding user ID es of August 15t y , we sent out th ention groups . randomly selecte lunteers random group consisted ay cohort and 54 olunteers that we ails were remove rventions impac he two groups f D , task ID an th , he In ed mly of 40 ere ed ct , for nd the hypotheses : ention group w n the return of v ol group . e intervention s returning volu the following h shed to examine We wis 1 . Se to the interve ending emails ositive effect on sig gnificant and po red to the contro ctivity as compar ac 2 . Re teers from the eturning volunt sume activity at t least as fast as re the e control group . 3 . Re ntervention grou eers from the in eturning volunte t ( remain active in the system ) lea ast as persistent he control group olunteers from th vo . 4 . Re e intervention teers from the eturning volunt s many contribut rovide at least as pr tions as returning fro om the control g group . 6 . A NT OF EFF SSESSMEN ON ( STAGE ERVENTIO INTE We firs st compared the number of volu t returned to acti ntrol groups that and con urning volunteer the ratio of retu shows f volunteers wh n , the ratio of be seen ention was sig ing the interve followi interven ntion group than n for the control represent 95 % co rs in the figure r The bar ifference in the o significant di was no subject ts between the 1 day and 10 day
FECTIVEN E 4 ) unteers from the ivity in the syste rs from both gro ho returned to gnificantly high group ( Chi squ onfidence interv e returning ratio ys cohorts . will have a volunteers to group will unteers from up will be at as returning group will g volunteers
NESS OF intervention em . Figure 3 oups . As can the system her for the are p<003 ) vals . There o results of
Figu ure 3 : Return ra atio for interven ntion and contr ol groups
Tab Group ble 2 : Persistenc Contr Befor of tas l groups ays fter active tion and contro ce for intervent Da ntributions Con ributions er Afte re ( num . ( num . Af asks ) sks ) of ta 20 18 23.5 21
1.5 1.2 xt compared the in both groups g out the email that the aver ntion group ( 4 . ( 5.7 days ) , al cant ( one tailed n e speed in which s as measured by to their first log rage return tim 1 days ) was le lthough this re non paired t test h volunteers retu y the number o gin back to the me for volunte ess than that of esult was not t , p=0052 ) urned to the f days from system . We eers in the f the control statistically ention Interve Control l
We nex system sending found interven group signific
335 One may suspect that although email interventions are able to bring back more volunteers , their activity in the system is lower than that of volunteers in the control group , who return to the system on their own accord . To check this , we looked at the median number of classifications before and after the reminder for both groups , as shown in the Table 2 . The results show that there was no statistically significant difference between the two groups in the number of classifications before and after the intervention . We chose to present the median rather than the average contribution rate to offset the effect of “ outlier ” volunteers whose contribution rates are exceptionally high . When looking at average contribution rates , we see a decrease for both groups in the number of classifications before and after the intervention ( not shown in the table ) . However , this decrease was significantly more pronounced for the control group than for the intervention group ( non paired t test , p<003 )
Lastly , there was no statistically significant difference between the number of days active in the system after the intervention between the intervention group ( 1.5 days ) and the control groups ( 1.2 days , one tailed non paired t test , p=032 ) Thus , we conclude that our reminder intervention ensures persistence , which does not fall from the persistence of those returning without a reminder . 7 . DISCUSSION AND CONCLUSIONS In this paper we presented a general methodology for reducing disengagement in citizen science that is based on the analysis of two years of participation data in 16 citizen science projects . This methodology included : ( 1 ) Surveys to reveal the motivations that drive users’ participation in the different projects ; ( 2 ) Identifying cohorts based on the survey results and the participation data ; ( 3 ) Designing an intervention strategy that targets specific cohorts and addresses the motivational issues revealed in the survey ; ( 4 ) Analyzing the efficacy of this strategy over time , according to performance and persistence measures .
Applying is triggered by life distractions , classification anxiety , and boredom . We identified target communities for the intervention that capture the vast majority of user participation in the system for all projects . We designed interventions in the form of emails that directly addressed underlying issues uncovered by the survey . The methodology was shown to successfully promote re engagement of users across 16 different citizen science projects . Returning participants from the intervention group resumed activity at least as fast , and remained active in the system for at least as long as returning participants from the control group . Our methodology is an example of the new engineering approach combining social and computational elements [ 14,15 ] and the work by Burke et al . [ 17 ] suggesting to target intervention to specific users to increase their social contribution .
We now mention three issues with our approach and explain how each corresponds to a type of trade off inherent when designing interventions for “ non uniform ” populations in which volunteers vary widely in the extent of contribution .
First , we identified two cohorts , those who disengage after a day , and those who remain in the system for up to 10 days before disengaging . But as far as our intervention is concerned , we treat these as a single population . On the one hand this is sensible because combined they represent the larger population of contributors who rapidly disengage ( corresponding to Eveleigh et the methodology revealed that disengagement issues , enabling the other hand , better als’ ‘drop outs’ [ 5] ) . On tailored interventions may be more effective for each cohort as presumably those disengaging after a day have a different shared experience to those disengaging after a few days . Moreover , it may be possible to disaggregate these populations even further based on finer differentiations of engagement patterns and underlying motivational increasingly more focused and efficient interventions . That said , we have been successful with a relatively simple ( yet crude ) instrument , and ever more refined approaches would incur correspondingly greater overheads in terms of cost and complexity .
A second issue relates to the presumption that our survey findings map onto the experience of those 1 day and 10 day cohorts identified in the participation profile . We are assuming that distracting life events , anxiety and boredom count as significant reasons for disengagement within these cohorts , without being able to precisely identify what the actual reasons are for any individual who disengages , nor denying that there may well be a mix of other reasons that we have yet to encounter . This imprecision is related to methodological limits of qualitative research , particularly surveys , where generalizations need to be made in order to map from the survey sample to the overall population . Again , there is a trade off here , since greater precision attracts overheads – not least ultimately the risk of annoying or alienating volunteers .
Finally , the e mail intervention works much less like a hunting spear and much more like a net in the way that it ensnares several ( presumed ) sub populations simultaneously ( those who have been distracted from their project , are anxious or who are bored ) . These messages may also act in concert on those occasions where both reassurance and a reminder are needed , but they may also miss the mark where disengagement occurs for some other reason . On the plus side , the e mail message has a degree of generality , it can speak to multiple audiences simultaneously , but this increases the challenges of assessing its effectiveness .
While the work described here has produced a significant improvement in productivity from a specific intervention , we believe further cyclic iterations of the 4 step methodology will uncover additional insights into the motivations of other citizen science projects . Future work will target interventions to users during their online interaction with the system using machine learning models and consider other intervention channels such as task recommendations and modal messages as well as other reward schemes . 8 . ACKNOWLEDGEMENTS This work was supported in part by EU FP7 FET SmartSociety project ( http://wwwsmart society projecteu/ ) under the Grant agreement n600854 It was also supported in part by SOCIAM : The Theory and Practice of Social Machines , funded by the UK . Engineering and Physical Sciences Research Council ( EPSRC ) under grant number EP/J017728/1 and comprises the Universities of Southampton , Oxford and Edinburgh .
336 9 . REFERENCES [ 1 ] Silvertown , J . 2009 . A new dawn for citizen science . Trends in Ecology & Evolution . 24 , 9 , 467 – 471 .
[ 2 ] Raddick , M . J . , Bracey , G . , Gay , P . L . , Lintott , C . J . , Murray ,
P . , Schawinski , K . , Szalay , A . S . , and Vandenberg , J . 2009 . Galaxy Zoo : exploring the motivations of citizen science volunteers . arXiv:09092925
[ 3 ] Reed , J . , Raddick , M . J . , Lardner , A . , and Carney , K . 2013 .
An Exploratory Factor Analysis of Motivations for Participating in Zooniverse , a Collection of Virtual Citizen Science Projects . 46th Hawaii International Conference on System Sciences ( HICSS ) , 610 619 , ( Hawaii , 7 10 Jan , 2013 ) .
[ 4 ] Nov , O . , Arazy , O . , and Anderson , D . 2011 . Dusting for science : motivation and participation of digital citizen science volunteers . In Proceedings of the 2011 iConference ( iConference '11 ) . ACM , 68 74 . ( New York , NY , USA ) DOI=http://doiacmorg/101145/19407611940771
[ 5 ] Eveleigh , A . , Jennett , C . , Blandford , A . , Brohan , P . , and Cox ,
A . , L . 2014 . Designing for dabblers and deterring drop outs in citizen science . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems ( CHI '14 ) . ACM , 2985 2994 . ( New York , NY , USA ) DOI=http://doiacmorg/101145/25562882557262
[ 6 ] Preece , J . , and Shneiderman , B . 2009 . The reader to leader framework : Motivating technology mediated social participation . AIS Transactions on Human Computer Interaction 1,1 , 13 32 .
[ 7 ] Ortega , F . , Gonzalez Barahona , J . M . , Robles , G . 2008 . On the Inequality of Contributions to Wikipedia . Proceedings of the 41st Annual Hawaii International Conference on System Sciences . 304 . ( 7 10 Jan . 2008 ) DOI=101109/HICSS2008333
[ 8 ] Mao , A . , Kamar , E . , and Horvitz , E . 2013 . Why Stop Now ? Predicting Worker Engagement in Online Crowdsourcing . In First AAAI Conference on Human Computation and Crowdsourcing . ( November 7–9 , 2013 , Palm Springs , California ) . http://wwwaaaiorg/ocs/indexphp/HCOMP/HCOMP13/pap er/view/7498
[ 9 ] Rotman , D . , Preece , J . , Hammock , J . , Procita , K . , Hansen ,
D . , Parr , C . , Lewis , D . , and Jacobs , D . 2012 . Dynamic changes in motivation in collaborative citizen science projects . In Proceedings of the ACM 2012 conference on Computer Supported Cooperative Work ( CSCW '12 ) .
[ 10 ] Kittur , A . , Nickerson , J . V . , Bernstein , M . S . , Gerber , E . M . , Shaw , A . , Zimmerman , J . , Lease , M . , and Horton , J . J . , The Future of Crowd Work . 16th ACM Conference on Computer Supported Coooperative Work ( CSCW 2013 ) . ( December 18 , 2012 ) Available at SSRN : http://ssrn.com/abstract=2190946
[ 11 ] Darch , P . 2014 . Managing the Public to Manage Data :
Citizen Science and Astronomy . International Journal of Digital Curation , 9 , 1 , 25–40 .
[ 12 ] Eveleigh , A . , Jennett , C . , Lynn , S . and Cox , A . L . 2013 . “ I want to be a Captain! I want to be a Captain! ” : Gamification in the Old Weather citizen science project . Short paper presented at Gamification 2013 ( 2 4 October 2013 , Stratford , Ontario ) . https://uwaterlooca/gamification/sites/cagamification/files/u ploads/files/gamification2013 proceedings.pdf
[ 13 ] Preist , C . , Massung , E . , and Coyle . D . 2014 . Competing or aiming to be average ? : normification as a means of engaging digital volunteers . In Proceedings of the 17th ACM conference on Computer supported cooperative work & social computing ( CSCW '14 ) . ACM . 1222 1233 . ( New York , NY , USA ) DOI=http://doiacmorg/101145/25316022531615
[ 14 ] Miorandi , D . and Maggi , L . 2014 . “ Programming ” Social
Collective Intelligence . To appear in IEEE Technology and Society , special issue on Technology for Collective Action ( 2014 ) .
[ 15 ] Simpson , R . and Page , KR and De Roure , D . Zooniverse : observing the world's largest citizen science platform . In Proceedings of 23rd international conference on World Wide Web .
[ 16 ] Khatib , F . and Cooper , S . and Tyka , M D and Xu , K and Makedon , I and Popović Zoran and Baker , D . Algorithm discovery by protein folding game players . In PNAS , vol . 108 no . 47 , pages 18949–18953 , 2011 .
[ 17 ] Burke , M . , Marlow , C . , & Lento , T . ( 2010 , April ) . Social network activity and social well being . In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems .
[ 18 ] Sauermanna H . and Franzoni . Crowd science user contribution patterns and their implications . In PNAS , vol . 112 no . 3 , pages 679 684 , 2015 .
[ 19 ] Wiggins , A . , and Crowston K . From Conservation to
Crowdsourcing : A Typology of Citizen Science . Proceedings of the Forty fourth Hawai'i International Conference on System Science ( HICSS 44 )
[ 20 ] Jackson , C . B . , Østerlund , C . , Mugar , G . , Hassman , K . D . , &
Crowston , K . Motivations for Sustained Participation in Crowdsourcing : Case Studies of Citizen Science on the Role of Talk .
[ 21 ] Cooper , S . , Khatib , F . , Treuille , A . , Barbero , J . , Lee , J . , Beenen , M . , & Popović , Z . ( 2010 ) . Predicting protein structures with a multiplayer online game . Nature , 466(7307 ) , 756 760 .
[ 22 ] Guest , G . 2012 . Applied Thematic Analysis . California :
SAGE Publications , Inc
337
