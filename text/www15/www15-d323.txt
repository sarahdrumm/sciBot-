Real Time News Certification System on Sina Weibo
Xing Zhou1,2 , Juan Cao1 , Zhiwei Jin1,2,Fei Xie3,Yu Su3,Junqiang Zhang1,2,Dafeng Chu3 ,
,Xuehui Cao3
1Key Laboratory of Intelligent Information Processing of Chinese Academy of Sciences ( CAS )
Institute of Computing Technology , Beijing , China
2University of Chinese Academy of Sciences , Beijing , China
3Xinhua News Agency , Beijing , China
{zhouxing,caojuan,jinzhiwei,zhangjunqiang}@ictaccn
{xiefei,suyu,chudafeng,caoxuehui}@xinhua.org
ABSTRACT In this paper , we propose a novel framework for real time news certification . Traditional methods detect rumors on message level and analyze the credibility of one tweet . However , in most occasions , we only remember the keywords of an event and it ’s hard for us to completely describe an event in a tweet . Based on the keywords of an event , we gather related microblogs through a distributed data acquisition system which solves the real time processing needs . Then , we build an ensemble model that combine userbased , propagation based and content based model . The experiments show that our system can give a response at 35 seconds on average per query which is critical for realtime system . Most importantly , our ensemble model boost the performance . We also offer some important information such as key users , key microblogs and timeline of events for further investigation of an event . Our system is already deployed in the Xihua News Agency for half a year . To the best of our knowledge , this is the first real time news certification system for verifying social media contents .
Categories and Subject Descriptors H.4 [ Information Systems Applications ] : Types of Systems
Keywords Rumor Detection ; Real Time System ; Ensemble model
1 .
INTRODUCTION
With the rapid growth of Microblogging platforms such as Twitter[3],and the Chinese Sina Weibo[1 ] , social networks has become an essential part of our daily life . People spend lots of time on these platforms to share their feelings and opinions with others and get the latest news from these platforms . The user generated content in the platform is huge and get spread around quickly which makes the automatic identify information credibility an critical problem .
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author ’s site if the Material is used in electronic media . WWW15 Companion , May 18–22 , 2015 , Florence , Italy . ACM 978 1 4503 3473 0/15/05 . http://dxdoiorg/101145/27409082742571
There are many works has been done on rumor detection . Storyful [ 2 ] is the world ’s first social media news agency , which aims to discover breaking news and verify them at the first time . Sina Weibo has an official service platform1 that encourage users to report fake news and these news will be judged by official committee members . Undoubtedly , without proper domain knowledge , people can hardly distinguish between fake news and other messages . The huge amount of microblogs also make it impossible to identify rumors by humans .
Recently , many researches has been devoted to automatic rumor detection on social media . These methods can be classified into two categories:classification based approach and propagation based approach . The classification based approach uses supervised learning algorithms to identify news credibility . By leveraging the information of microblogs , a large number of lexical and semantic features can be extracted and a supervised learning algorithm can be learned from labeled data . Some researches also propose new models to capture implicit patterns . Ke et al[11 ] propose a graph kernel based hybrid SVM classifier to captures the high order propagation patterns behind the messages . Xia et al[6 ] propose a social spammer detection framework by harnessing sentiment analysis . The propagation approach , like the one proposed by Gupta et al.[5 ] , has been proved to be quite effective and outperforms the classification based approach .
Most of the traditional methods focus on evaluating message level credibility which is not practical for real systems . In the real scene , we want a system that can provide the credibility of an event only by input some keywords representing an event . Just like the search engineer as google , user can get what he want by input some keywords . Based on this kind of certification needs , we build a real time system that can collect related microblogs of the provided keywords and detect the credibility of the event .
In this paper , we model the rumor detection problem from three aspects : content , propagation and information source . Instead of building a single model , we perform a two stage framework to handle these three aspects . We first build a single model for each aspect , and then we blend three individual model by weighted combination . Concretely , We exploit a content based model by leveraging event,sub events and messages information . A propagation based model is build to capture propagation network influence . The user influ
1http://serviceaccountweibocom/
983 ence is considered by user based model . Rumors cannot be judged from each single aspect , and the influence degree of each aspect is hard to measure . So we build an ensemble model to combine these three aspects and the weight for each aspect can be learned from the learning algorithms .
The main contributions of this paper are as follows : • We build a real time news certification system that can detect the credibility of an event by providing some keywords about it . The average response time for each query is 35 seconds which is practical for real time system .
• We build a distributed data acquisition system to gather event related information through Sina Weibo , which solves the real time processing needs for rumor detection system .
• We model the rumor detection problem from three aspects and build a model for each part , ie contentbased model , propagation based model and user based model . Then we blend these three individual models . Our experiments show the ensemble model achieves significant better accuracy than individual ones .
• Apart from giving the final credibility of an event , we also provide some important information such as key users , key microblogs and timeline of an event . These information can be used for further investigation .
The remainder of the paper is organized as follows .
In section 2 , we describe the framework of our system . Section 3 discusses all three individual models , which tackle the rumor detection task from different perspectives . Section 4 presents the experimental results . We demonstrate our application in a system point of view in section 5 . We give an overview of related works in section 6 . Section 7 concludes this paper .
2 . FRAMEWORK
We first give an overview of our proposed system , which has been used in Xinhua News Agency for half a year . Then , we introduce our distributed data acquisition system , which not only provide data support for following analysis , but also meets the demand of real time response .
2.1 System Overview
The proposed system can be divided into four stages : crawling data , generating individual models , building an ensemble model and visualizing the results . Figure 1 shows the system framework .
Given the keywords and time range of a news events , the related microblogs can be collected through the search engine of Sina Weibo2 . Based on these messages , we can extract key users and microblogs which can be used for following analysis . The key users are used for information source certification while the key microblogs are used for propagation and content certification . All the data above are crawled through distributed data acquisition system which will be illustrated below . After three individual models have been developed , we combine the scores of the above mentioned models via weighted combination . Finally , we get an eventlevel credibility score and each single model will also have a 2http://sweibocom/
Figure 1 : The framework of real time rumor detection application credibility score that measure the credibility of corresponding aspect . To improve the user experience of our application , we visualize the results and provide useful information of events for further investigation .
2.2 Distributed Data Acquisition System
Figure 2 : The framework of distributed data acquisition system
In our rumor detection application , we need to gather three kinds of information , ie Microblogs , propagation and Microbloggers . Like most distributed system , we also have master node and child nodes . The master node is responsible for task distribution and results integration while child node process the specific task and store the collected data in the appointed temporary storage space . The child node will inform the master node after all tasks finished . Then , master node will merge all slices of data from temporary storage space and stored the combined data in permanent storage space . After above operations , the temporary storage will be deleted .
Our distributed system is based on ZooKeeper3,a centralized service for maintaining configuration information ,
3http://zookeeperapacheorg/
984 naming , providing distributed synchronization , and providing group services . As the attributes of frequent data interaction,stored,read , we adopt efficient key val database Redis 4 to handle the real time data acquisition task . Redis , works with an in memory dataset , can achieve outstanding performance .
3 . DESCRIPTION OF THE MODELS
In this section , we introduce the individual modeling methods we have used in our system . The novelty of this paper consists in combining different modeling methods together for rumor detection .
3.1 Content Based Method
The content based model is a powerful method for modeling rumor detection task . In this part , we build a hierarchical propagation model[7 ] . The credibility network has three layers : message layer , sub event layer and event layer . Following that , the semantic and structure features are exploited to adjust the weights of links in the network .
Figure 4 : The number of microblogs change within a day . observation , the event is changing along the time and the propagation pattern is different between rumor and normal news . Through the Weibo index 5 platform , an open platform for event trend analysis , we observe that the number of microblogs is changing along the time . Take a rumor ” Mother in law gave bentley ” and normal news ” Deng yaping , Instant search ” as an example . In Figure 5(a)(c ) , we can hardly find different propagation pattern between this two events for the nature of event is changing over time . After the natural fluctuations of event removed , we can find distinct differences between rumor and normal news in Figure5 ( b)(d ) . In Figure5(b)rumor is more fluctuate with time after processing while normal news become smoothing and the peak node is reduced which shows in Figure5(d ) .
Figure 3 : A three layer hierarchical credibility network
Given a news event and its related microblogs , sub events are generated by clustering algorithm . Sub event layer is constructed to capture implicit sematic information within an event . Four types of network links are made to reflect the relation between network nodes . The intra level links(Message to Message , Sub event to Sub event ) reflect the relations among entities of a same type while the interlevel links(Message to Sub event,Sub event to Event ) reflect the impact from level to level . After the network constructed , all entities are initialize with credibility values using classification results . We formulate this propagation as a graph optimization problem and provides a global optimal solution to it .
Above are the basic idea of our content based model for rumor detection which has been published in ICDM 2014 . In this content based algorithm , we can get a content credibility denoted as Scontent .
3.2 Propagation based method
The propagation pattern behind social network is an important part for rumor detection . Most of the existing works ignore the propagation trend along the time . Based on our
4http://redis.io/
( a ) rumor : original
( b ) rumor : normalization
( c ) normal : original
( d ) normal : normalization
Figure 5 : Propagation pattern between rumor and normal news
In order to simulate the natural fluctuation of events , we manually select 100 common words such as ” Microblog , china , Sina ” , and record the number of microblogs at each hour for each word , then we can get an average time trend curve donated as base event curve . The value at each hour point in this curve constitute the base value set denoted as Vb = {vb1 , vb2 vbn} Given an event data collection , we can get the corresponding microblogs count at each hour point . After remove the natural fluctuation by Vb and normalization , we scale the original value into [ 0,1 ] range . Finally by setting 4 hours a time range , we get the normalization value set of this event denoted as Ve = {ve1 , ve2 ven} From value 5http://dataweibocom/index/
985 set Ve , we can get the median vm and standard deviation vstd . Then the normal line is set by vn = vm + vstd to avoid the fluctuations of event itself and three propagation based value can get : users . We randomly selected equal number of normal users from one million users and get the final dateset D3 . The SVM parameter are selected by 5 fold cross validation . In this user based model , we can get a user credibility score denoted as Suser .
Table 1 : Three kinds of points
# peak point Cp # abnormal point Cab # normal point Cn if vei > vni if vei > vni and i in range [ 03],[47 ] if vei < vni
The abnormal point is the peak point at time range [ 0:003.59 ] and [ 4:00 7.59 ] based on the hypothesis that events spread quickly in these period of time is more likely to be a rumor . We compute the propagation influence score for each event using :
Spropa(e ) = α
Cp Cn
+ ( 1 − α )
Cab Cp
( 1 ) where α is smoothing factor with range α ∈ [ 0.0 , 10 ] In this equation , if an event has more peak point and most of peak point is also an abnormal one , it ’s more likely to be a rumor . In our application , we set α = 04
3.3 Information source based method
In this section , we build a user based model to measure the credibility of information source . We consider two kinds of features as described in [ 13][12 ] . The personal dependent features are mostly determined by user themselves such as whether the user ’s identity is verified , the gender of user , the location of user and so on . Personal independent features are include the number of followers , the number of friends ,the number of posted microblogs etc .
In addition to those implicit features that we can get directly from Sina weibo platform , we also extract some advanced features from user ’s microblogs .
User Sentiment feature refers to the overall sentiment orientation of a user . We collect the microblogs of a user and compute sentiment score for each microblog . The overall sentiment orientation of a user is i=n i=1
US =
1 n
Si
( 2 )
3.4 Model Ensemble
From above individual models , we can get three credibility scores ie Scontent , Sprop , Suser , which measure the influence of each part . In this work , we apply Logistic Regression to blend these individual models . Logistic regression is widely used for binary classification . Given input data x and weights w , it models the classification problem by the following probability distribution P ( y = ±1|x , w ) =
( 4 )
1
1 + exp(−y(w T x ) )
After the blending process , we get our final predictor which give an event level score Sevent for us to determine the credibility of an event .
4 . EXPERIMENTS 4.1 Real Data Set
To evaluate the proposed ensemble model , we collect a real news dataset from Sina Weibo . The fake news collected from several top fake news rank list7 selected by authoritative news agencies from 2013 to 2014 . The true news came from a hot news discovery system of Xinhua News Agency , which recommends 10 hot events every day.To keep the balance of the dataset , we random sampled the same number of fake news from around 7000 hot news from 2013 to 2014 . By filtering the duplicated news as well as the ones with fewer than 20 messages , we get the final dataset shows in Table 2
Table 2 : Details of dataset
Type
Number
# Fake News # True News # News # Messages
73 73 146
49,713 where n is number of posted microblogs , and Si is the sentiment score computed by lexicon based algorithm which has been proposed in [ 10 ] .
User Active feature is measure the activeness of a user . The activeness value is calculated by the average amount of posted microblogs per day .
Compared with existing studies [ 4 ] using the human labeled likely fake and exactly fake as ground truth , we only select the fake news certified by authoritative sources .
4.2 Performance of our model
UA =
N M
Tend − Tf irst
( 3 )
Based on our dataset , we compare the performance of different model combinations . where NM is the total number of microblogs of a user posted and Tend , Tf irst respectively represent the last and first time that microblog posted .
Combine these features , we train a SVM classifier for user classification . Our dataset D16 consists of 15667 users who have posted fake news in the Sina Weibo platform . We reserve those users who have posted fake news more than once and get the rumor user dataset D2 which has 1151
6The data is collected from Sina Weibo service platform http://serviceaccountweibocom/
The content based method is the model[7 ] that we have proposed in ICDM 2014 previously . We set it as our baselearner and compare the performance of different model combination . Our experiments show that the final ensemble model can achieve better performance than individual ones and blending all three models by Logistic regression achieves
7http://newsxinhuanetcom/zgjx/2014 01/08/c 133024019.htm ; http://opinionhaiwainetcn/n/2013/1220/c23260120062341html
986 5.2 Visualization of individual parts
The novelty of our proposed framework is that we analysis the credibility of events from three individual parts and blending these three parts for final rumor detection . We also offer visualization of these parts .
• Event visualization
After microblogs crawled , we perform events clustering and generate the event ’s timeline to show the event evolution along the time .
Figure 7 : Event timeline visualization
• Propagation visualization
In this part , we select the key microblog and visualize the propagation structure .
Table 3 : Performance of Different Models
Models
Accuracy
Content Content + Propagation Content+Propagation+User
78.76 % 79.27 % 79.93 % the best performance .
From a system perspective , we can not only give an overall event credibility score for user but also provide the credibility score of three different aspects . These three credibility scores can be used by news editors for further investigation and decision making because we can’t judge news credibility by machine only for the accuracy is not achieve to 100 %
5 . SYSTEM DESCRIPTION
In this section , we introduce our real time rumor detection application from a system point of view . Two kinds of interaction manner are provided by our system . Given the keywords of an event and specify a time range , our system will judge the credibility of the event in this period of time . In addition , user can also click the hot news list that come from a hot news discovery system of Xinhua News Agency . The hot news list is updated everyday while the historical cases list on the right side slightly changed and record the classical cases .
5.1 Event certification
Let ’s take the fake news ” Wutai mountain monk beaten female tourists ” as an example to demonstrate our application in detail . After system processing , we come into a visualization page of this event . We first give an overview of this event by extract event ’s keywords , key users and location from the crawled microblogs . This part lies in the left side of Figure 6 . On the right side , we show the event level credibility score which derived from our proposed ensemble model . The ” Red Alert ” indicates the event is likely to be a rumor . More interestingly , we can also provide three credibility scores from content,propagation and user aspects . This feature of our system is meaningful for real world application . In this event , the content level credibility score Scontent is higher which means the content is more suspicious than other aspects . More emphasize should be paid on content if further investigation needs to be launched . Actually , the event is judged to be rumor by authoritative new agencies for the reason that content is inconsistent with the provided pictures .
Figure 6 : Event certification
Figure 8 : Visualization of microblog propagation
• User visualization
The user we selected in this part is derived from the top 5 key users . The user profile is list in the user information table .
987 8 . ACKNOWLEDGMENTS
This work is supported by the National High Technology
Research and Development Program of China ( 2014AA015202 ) , National Nature Science Foundation of China ( 61172153 ) .
9 . REFERENCES [ 1 ] Sina weibo . http://wwwweibocom [ 2 ] Storyful . http://wwwstoryfulcom [ 3 ] Twitter . http://wwwtwittercom [ 4 ] C . Castillo , M . Mendoza , and B . Poblete . Information credibility on twitter . In Proc . of the Intl . Conf . on World Wide Web ( WWW ) , pages 675–684 , 2011 . [ 5 ] M . Gupta , P . Zhao , and J . Han . Evaluating event credibility on twitter . In Proc . of the 2012 SIAM International Conference on Data Mining,SDM , pages 153–164 , 2012 .
[ 6 ] X . Hua , J . Tang , H . Gao , and H . Liu . Social spammer detection with sentiment information . IEEE 13th International Conference on Data Mining,ICDM , 2014 .
[ 7 ] Z . Jin , J . Cao , Y G Jiang , and Y . Zhang . News credibility evaluation on microblog with a hierarchical propagation model . IEEE 13th International Conference on Data Mining,ICDM , November 2014 . [ 8 ] S . Kwon , M . Cha , K . Jung , W . Chen , and Y . Wang .
Prominent features of rumor propagation in online social media . IEEE 13th International Conference on Data Mining,ICDM , pages 1103–1108 , 2013 .
[ 9 ] S . Sun , H . Liu , J . He , and X . Du . Detecting event rumors on sina weibo automatically . In Proc . of the 15th Asia Pacific Web Conference,APWeb , Springer , pages 120–131 , 2013 .
[ 10 ] X . Wan . Using bilingual knowledge and ensemble techniques for unsupervised chinese sentiment analysis . Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing , EMNLP , pages 553–561 , 2008 .
[ 11 ] K . Wu , S . Yang , and K . Q . Zhu . False rumors detection on sina weibo by propagation structures . IEEE International Conference on Data Engineering,ICDE , 2015 .
[ 12 ] F . Yang , X . Yu , Y . Liu , and M . Yang . Rumor has it :
Identifying misinformation in microblogs . in Proceedings of the Conference on Empirical Methods in Natural Language Processing . Association for Computational Linguistics , page 1589´lC1599 , 2011 .
[ 13 ] F . Yang , X . Yu , Y . Liu , and M . Yang . Automatic detection of rumor on sina weibo . In Proceedings of the ACM SIGKDD Workshop on Mining Data Semantics,ACM , pages 1–7 , 2012 .
Figure 9 : Visualization of user information
6 . RELATED WORKS
Previous works on rumor detection mainly modeled the problem as binary classification problem . Catillo et al[4 ] compared different supervised learning algorithm and reported that decision tree achieves the best performance with accuracy of 89 % . [ 8][9 ] exploit this idea to detect rumors on Sina Weibo with several new features . K . Wu et al[11 ] proposed a hybrid SVM classifier which combines a random walk graph kernel with normal RBF kernel . They reported a significant improvement over the state of the art methods . Different from the above classification methods , M . Gupta et al[5 ] analyzed event a´rs credibility by constructing a threelayer network to propagate credibility between users , tweets and events . By exploiting the inter entity relationships , the propagation network can get better results than basic classification methods . Considering that users and similar events in this network are indirect factors for the credibility of an event , we further build a three layer credibility network with three direct factors of message , sub event and event to evaluate the credibility of news on Sina Weibo [ 7 ] . The hierarchical structure of message to sub event , and sub event to event reasonably modeled the relations among them and the process of credibility propagation on Microblog . With a subevent layer , deeper semantic relations within the event are revealed . This approach has achieved stable improvements over classification methods on two real data sets .
7 . CONCLUSION
In this paper , we have proposed the real time framework to address the problem of rumor detection on Sina Weibo . We develop a distributed data acquisition system to address the real time data collection problem . Based on this data acquisition system , we first model the rumor detection problem from three individual parts and build a single model for each one . Then we combine these three rather complementary and conceptually different individual models : one based on content , one based on propagation and one based on information source . Our results show the proposed ensemble model outperforms individual ones with accuracy of 07993 More importantly , we also provide the credibility score of three individual parts which can be used for further investigation and decision making by news editors in Xinhua News Agency . The visualization of different parts improve the user experience of our system . Our real time rumor detection application has been deployed in Xinhua News Agency for half a year . This indicates the efficient and effectiveness of our system .
988
