An Optimization Framework for Weighting Implicit
Relevance Labels for Personalized Web Search
Yury Ustinovskiy
Yandex
Leo Tolstoy st . 16 , Moscow , yuraust@yandex team.ru
Russia
Gleb Gusev
Yandex
Leo Tolstoy st . 16 , Moscow , gleb57@yandex team.ru
Russia
Pavel Serdyukov
Yandex
Leo Tolstoy st . 16 , Moscow , pavser@yandex team.ru
Russia
ABSTRACT Implicit feedback from users of a web search engine is an essential source providing consistent personal relevance labels from the actual population of users . However , previous studies on personalized search employ this source in a rather straightforward manner . Basically , documents that were clicked on get maximal gain , and the rest of the documents are assigned the zero gain . As we demonstrate in our paper , a ranking algorithm trained using these gains directly as the ground truth relevance labels leads to a suboptimal personalized ranking .
In this paper we develop a framework for automatic reweighting of these labels . Our approach is based on more subtle aspects of user interaction with the result page . We propose an efficient methodology for deriving confidence levels for relevance labels that relies directly on the objective ranking measure . All our algorithms are evaluated on a large scale query log provided by a major commercial search engine . The results of the experiments prove that the current state of the art personalization approaches could be significantly improved by enriching relevance grades with weights extracted from post impression user behavior .
Categories and Subject Descriptors H33 [ Information Systems Applications ]
General Terms Algorithms , Measurement , Experimentation
Keywords Personalization ; Click Prediction ; Gradient Descent
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author ’s site if the Material is used in electronic media . WWW 2015 , May 18–22 , 2015 , Florence , Italy . ACM 978 1 4503 3469 3/15/05 . http://dxdoiorg/101145/27362772741105
1 .
INTRODUCTION
Most of major search engines record detailed information about users’ requests , including timestamps of actions , sets of retrieved documents , and detailed interactions of users with SERPs ( search engine result pages ) , and store petabytes of such data . For these reasons , scalable methods of user logs processing and utilization are gaining an increasing interest in the IR community . The rapid development of these technologies made possible various practical applications of implicit feedback analysis , including evaluation of ranking quality [ 12 ] , improvement of web search performance [ 1 , 9 ] , and web search personalization [ 4 , 5 , 6 , 8 , 11 , 14 , 16 , 19 , 21 , 23 ] .
Implicit feedback data are often employed as the source of implicit personalized relevance labels and thus become absolutely indispensable for personalization of web search . Such data allow the collection of a large scale sample of judgements for a representative set of queries directly from users [ 14 ] . These judgements could be further used as the ground truth relevance labels for training and evaluating personalized rankers .
The most straightforward yet still prevalent approach treats clicked documents as relevant and non clicked ones as totally irrelevant . However , clearly , not every click is an indicator of high personal document relevance and not every impression without a click indicates complete irrelevance . Noisy clicks may mislead learning to rank algorithm decreasing the quality of the trained ranking model . This raises the problem of identifying “ reliable ” clicks . A step toward solving this problem was made in [ 3 , 4 ] , where the authors considered only satisfied clicks ( ie , the last clicks on SERP and clicks followed by a dwell time exceeding some fixed threshold ) as the evidence of relevance . Since satisfied clicks are less noisy than all clicks , it is expected that a personalized ranker trained on these gain values results in a better ranking .
In this paper we suggest a far reaching generalization of this idea . Namely , ‘satisfied clicks’ approach to the collection of the personalized relevance labels still misses valuable information available in the click through log . In particular , this approach ( 1 ) does not distinguish between skipped documents and not examined documents ; ( 2 ) does not account for various types of satisfied clicks differently ( eg , multiple clicks , singleton clicks , first clicks , super long clicks ) ; ( 3 ) does not take into account positional bias . We aim at improving personalized ranking by interpreting implicit feedback in a more sophisticated way than it has been done in the the current approaches to search personalization , see ,
1144 eg , [ 4 , 11 , 16 ] . The key component of our framework is an additional step which automatically extracts confidence levels of relevance labels from characteristics of user ’s actions on the SERP prior to training a personalized ranker . The relevance labels equipped with these weights , utilized by machine learning algorithm , are expected to improve the ranking quality .
To compare our method with the state of the art approaches we need some fixed evaluation methodology . For this reason we use several popular implicit relevance labels to evaluate quality of personalized rankers and refer to these labels as gains .
To sum up , we make the following contributions : • formulate the problem of weighting the implicit rele vance labels for personalized search ;
• propose a novel optimization framework for automatic training of confidence levels of implicit relevance labels as functions of characteristics of user behavior ;
• provide new findings on user behavior modelling for web search personalization . In particular , we analyze the impact of dwell time and original ranking position on the confidence of the implicit personal relevance of the corresponding document .
We evaluate classical personalized relevance labels enriched with our confidence levels on the large scale search log provided by Yandex1 for the data mining challenge on web search personalization organized at Kaggle.com2 in the scope of WSCD workshop held at WSDM 2014 , [ 13 ] . The team that has won the challenge shared with us the dataset they used for training and testing their models . Our experiments prove that even given a very competitive personalization algorithm using a variety of strong state of the art features and a powerful machine learning algorithm one can significantly improve the quality of its ranking by introducing weights of labels .
The remainder of the paper is organized as follows . In Section 2 we review related work on personalization , learning of user behavior models and semi supervised learning . In Section 3 we fix some notations and give the formal statement of our problem . The core section of the paper is Section 4 , where we define our algorithm for general and linear models . In Section 5 we give details of our experimental setup and list the features we use for learning . Results of the experiments are reported in Section 6 . Finally , we discuss possible directions of future work and conclude the paper in Sections 7 and 8 .
2 . RELATED WORK
In numerous studies [ 4 , 5 , 6 , 11 , 14 , 16 , 23 ] appeared in the last decade , it has been demonstrated that personal and contextual information extracted from click through logs has the potential to significantly improve personalized ranking quality . First papers on search personalization employ explicit relevance labels to learn ranking models . In [ 14 ] Shen et al . employed previous queries and clicks on the returned results to specify the actual information need of a searcher . The authors evaluated several context sensitive
1yandex.com 2kaggle.com/c/yandex personalized web search challenge language models on the TREC collection augmented with click through data and used editorial relevance labels to tune and evaluate their algorithms . Tan et al . [ 17 ] collected search history from users to get information about users’ search preferences . The approach turned out to be especially effective for recurring queries . All the experiments were evaluated on a set of manually labelled queries collected from volunteers . Matthijs and Radlinski [ 11 ] studied the effect of a set of personalized features extracted from a browsing history by tuning a few parameters . The authors reported results of both offline experiments on the labelled set of queries and online evaluations . As opposed to these studies , we train and evaluate all our algorithms on user clicks stored in search logs .
A large body of work has been devoted to search personalization algorithms using clicks for learning and evaluation . Bennett et al . [ 3 ] personalized web search by leveraging location information from both users and web sites . The authors re ranked documents by training a location sensitive model and evaluated it on a proprietary dataset collected via a browser plugin . They used satisfied clicks as an indicator of relevance and considered MRR ( Mean Reciprocal Rank ) of these clicks as the principal performance measure . The same labelling method and performance measures were chosen in [ 22 ] . In this paper White et al . improved ranking of results for the current user query by using behavioral data of the other users in the same cohort . In this study we consider the same evaluation methodology based on users’ clicks . However , unlike the above papers , we propose to use these binary gain values to train a personalization ranker not directly . We develop a framework for systematic learning of numerically valued weights of these gains by analyzing different aspects of user interaction with the result page . We also emphasize that our goal is complementary to the one pursued in the above mentioned studies on personalization mainly devoted to investigations of different sources of personalization features . Studies on personalization form a small portion of works employing implicit feedback to train machine learning algorithms . One of the pioneer works in this area is [ 9 ] , where Joachims collects implicit feedback from a set users’ clicks to improve the overall retrieval quality of a search engine . Agichtein et al . [ 1 ] collect features representing user implicit feedback and used them to learn a new ranking model . Authors employed manually assigned relevance labels to train and evaluate their model . Unlike these papers we do not aggregate clickthrough data to estimate document relevance , instead we estimate confidence in a personal relevance label of a document in a particular search session to a particular user .
In that paper Yue et . al .
The idea of our study is related to the one suggested in [ 26 ] . improved conventional interleaving algorithms by interpreting users’ actions in a more subtle way than it is defined in the state of the art interleaving techniques . The authors suggested a machine learning approach that solves the reverse problem of hypothesis testing — it weights various types of clicks differently in order to improve the statistical power of the interleaving metrics . Our approach can also be considered a solution to the reverse problem of personalization , however , in contrast to that study , we ( 1 ) weight not only clicked documents and ( 2 ) focus on a completely different task : personalized web search ranking .
1145 An interesting theoretical machine learning approach to the general reverse learning problem was proposed in [ 25 ] by Xu et al . Similarly to our study , they combined two classes of features , one of which is known only for a subset of samples . To improve a standard linear machine learning model , authors estimated unknown feature values relying on the values of learning gains . Unlike that paper , in our problem statement , features describing user ’s interaction with the result page are available in training data only .
3 . PROBLEM FORMULATION 3.1 Notations
In this section we fix notations and provide some insights into personalization framework . First , let us describe the data that are available in personalization learning . Let S = {t1 , . . . , tS} be the training dataset , consisting of S samples ti . Each sample ti is a tuple {u , q , d} corresponding to a user u , a query q issued by this user , and a document retrieved for the query . Let Q be the set of userquery pairs occurring in the training dataset S . We assume that in dataset S for each pair {u , q} ∈ Q , we have exactly 10 tuples ti in S , corresponding to the top k = 10 retrieved documents . These 10 tuples are further denoted as Su,q ⊂ S . Each sample ti is characterized by an N dimensional peri ) ∈ RN that sonalization feature vector xi = ( x1 can be calculated based on the data available before the result page is shown to the user . Those may be any possible features that can be potentially used as components of a personalized ranking model . Among them , there could be both non personal features , eg , text relevance of document d to query q , and personal features , eg , user specific popularity of d or the match between the document ’s text and the user ’s interest profile . In what follows we denote by X the map that sends samples to their feature vectors : i ) ∈ RN .
X : S → RN , X : ti → ( x1 i , . . . , xN i , . . . , xN
The goal of the personalized web search is to re rank for every query {u , q} ∈ Q the corresponding documents Su,q , on the basis of the personalization feature vectors . Typically , it is done by providing a scoring function F , which maps the personalization features X ( {u , q , d} ) to the ranking scores of the documents . Since the values of function F depend only on the feature vectors X ( {u , q , d} ) , we will further consider F as a function on the N dimensional feature space RN :
F : RN → R .
Hereby samples ti ∈ Su,q are ranked according to the values fi = F(X ( ti) ) .
To evaluate the quality of a personalized ranker we need gain values , that is ground truth relevance labels assigned to all documents , retrieved for the queries {u , q} ∈ Q . So , we define gain as a function
G : S → R .
In the classical information retrieval approach , editorial relevance labels are assigned to the query document pairs by assessors and could be directly used to define the gain function G . For example , the standard mapping used in DCG ( Discount Cumulative Gain ) or NDCG ( Normalized Discount Cumulative Gain ) takes values in {2g − 1|g = 0 , 1 , 2 , 3 , 4} .
The situation in the personalization of Web search is quite different : collecting a large scale sample of personalized relevance labels from real users in the same manner is usually significantly more complicated and practically infeasible . The approach widely adopted in the existing studies on personalized search [ 4 , 11 , 16 ] is to use certain user actions as implicit indicators of a document ’s personal relevance , eg , to consider clicked documents with dwell time >30 seconds as relevant and the rest of the documents as irrelevant : G({u , q , d} ) = longclick(d ) := {1 iff d is clicked , and dwell time >30s} . This methodology allows to collect large training datasets comprising data from click through logs of commercial search engines . Given a gain function G , one defines the performance measure O : Perm(Su,q ) → R on the set of rankings , ie , permutations , of Su,q , in the following way :
O(σ ) =
G(t)·discount(σ(t) ) ,
( 1 ) t∈Su,q where σ : Su,q → {1 , . . . , k} is an ordering of documents in Su,q , σ({u , q , d} ) is the position of document d in the ranking , and discount(k ) is a positional discount ( eg , 1/ log2(k + 1 ) for DCG or 1/k for MRR ) . Objective performance measure of a ranker F is the av{u , q} ∈ Q , where rankF ( d ) ∈ {1 , . . . , k} is the rank of document d according to the value of the scoring function F(X ( {u , q , d}) ) : erage of O,{rankF ( d)}d∈Su,q
over all user query pairs
O,{rankF ( d)}d∈Su,q
→ max ,
( 2 )
M(F ) :=
1 |Q|
{u,q}∈Q where O(· ) is introduced in Equation ( 1 ) . The family of performance measures of the form ( 2 ) includes , as its special cases , both DCG like measures in the case of multi graded editorial relevance labels G and classical click measures ( eg , MRR or MAP ) in the case of click through based gains G . 3.2 Our approach So far , we have the training set S , the gain function G , and the feature map X . Our goal is to produce a scoring function F as optimal as possible in terms of the objective metric ( 2 ) . With this formulation of personalization learning framework one can apply the majority of the state of the art machine learning algorithms , including linear regression , polynomial regression , decision trees models , neural networks , etc .
Standard machine learning algorithms previously applied to search personalization assume that all learning samples ti ∈ S carry equally important evidences for a machine learning algorithm . We argue that this straightforward approach leads to a suboptimal ranking . For example , assume , when evaluating ranker F , only the documents , followed by a satisfied click , are treated as relevant answers , ie , G({u , q , d} ) = ( last click ) OR ( dwell time>30s ) . Let d be a document from the training set such that 20s < dwell time(d ) ≤ 30s . A standard machine learning algorithm utilizes the right inequality only . However , intuitively , the information that the click on document d has dwell time larger than 20s may carry an additional signal for the machine learning algorithm and could be also useful for training ranker F . We may think of these documents as of something intermediate between non clicked documents ( or
1146 clicked with an insignificant dwell time ) and documents with a sufficiently long dwell time , so they could be treated as potentially relevant by our algorithm A . Hence our confidence in the label that marks them as irrelevant can be lower than for documents with the dwell time around 5s .
Another important distinctive property of the implicit relevance labelling that can adopted in search personalization is the existence of two types of non relevant samples . The results of the first type are skipped , ie , their snippets or titles were examined by a user and the results were deliberately not clicked . The results of the second type are not examined , ie , neither their snippets , nor the documents themselves , were examined by a user . Clearly , skipped documents have , a priori , larger confidence in their negative label than not examined documents . Since we do not know for sure whether a given result was examined or not by a user , further we follow the widespread assumption : a user examines all snippets up to the last clicked document . In what follows , all not clicked results ranked above the last clicked result are referred to as ‘skips’ and the remaining not clicked results are said to be ‘not examined’ .
At this point we would like to stress that we do not deal with the problem of improving the evaluation methodology of personalized search defined by equation ( 2 ) . On the contrary , we assume that there is some fixed metric M defined by some state of the art gain function G , eg , based on the fact of a click or the fact of a satisfied click , as in most of the studies on personalization . Such a labelling is typically established by simple rules , and the gain values it produces turn out to be noisy , as we have discussed in the beginning of this section . That is , not every document with zero/positive label is useless/useful for a user . We argue that direct utilization of these gain values for training a personalization algorithm leads to a suboptimal ( according to the metric M ) ranking .
To address this weakness of the state of the art personalization approaches , we suggest introduction of weights , ie , we equip every sample ti ∈ S with a certain positive number wi ∈ R , which reflects the confidence in the corresponding gain value and the need for a machine learning algorithm to take into account the gain for this particular example . Classically this approach is applied when the observed measurements ( gain values G(ti ) ) have different uncertainties [ 2 ] : the closer the weight wi to zero is , the less confident about the gain value G(ti ) we are .
For the empirical use , the appropriate weight values wi are not known and must be estimated . The core idea of the present paper is adding of an extra step in the machine learning , see Section 4 , which trains the weight values wi ∈ [ 0 ; 1 ] in advance . As we have discussed above , in the traditional personalization learning each sample ti ∈ S is equipped with feature vector X ( ti ) ∈ RN . The fundamental advancement of our weight based personalization learning is the utilization of additional information gathered along with standard gain values G(t ) : post impression features reflecting a more complete picture of the interaction between the user and the search system that resulted into particular gain values . Among them , there are , for instance , the total number of clicks on SERP , the indicator of the fact the document d was clicked by a user , the dwell time of a click , etc . Assume that each sample ti ∈ S in the training dataset is characterized i , . . . , yM by M dimensional weight feature vector yi = ( y1 i ) .
Let Y be the corresponding map : Y : S → RM , Y : ti → ( y1 i , . . . , yM i ) ∈ RM .
We emphasize that these features cannot be calculated before the result page is formed , thus do not participate in the ranking model . However , they are possibly useful during the training of the ranker F , since they implicitly carry the information about degree of relevance of documents in S . Unfortunately , state of the art search personalization algorithms do not allow employment of features Y(ti ) . For this reason we suggest to learn a weight function W on the space of Y features . Namely , let W be the function mapping the space of Y features to the weights :
W : RM → [ 0 ; 1 ] , W : Y(ti ) → wi .
Assume that we are given a machine learning algorithm A , which takes into account weights of samples . An example of such algorithm is a linear model minimizing weighted sum of residual squares , discussed in Section 4 . Given the weight function W , gain function G and such a machine learning algorithm , we assume that one uniquely determines the ranker FW . Our aim is to provide such weight function W that the ranker FW maximizes the overall ranking quality M(FW ) :
W = argmax
W
M(FW ) .
( 3 )
In the next section we show that , under additional assumptions on the machine learning algorithm A and on the set of possible weight functions , this problem can be solved via steepest gradient descent .
4 . ALGORITHM 4.1 Assumptions In this section we explain how to learn the weight function W introduced in Section 32 To solve the optimization problem ( 3 ) , one has to reduce the set of all possible functions W : RM → R to some finite dimensional parametric family . In order to learn the parameters of W , we need to know the impact of each parameter on the objective function M = M(FW ) . If there are few parameters , one can perform an exhaustive search in the parameter space . However , the computational complexity of this exhaustive search grows exponentially with the growth of the number of parameters . Since each step of the exhaustive search requires separate training of an algorithm , which is usually resource consuming , exhaustive search quickly becomes infeasible with the growth of parameter space dimension . Ideally , we would like to start a gradient descent optimization of M with respect to parameters of the weight function W . Weight function First we fix the class of weight functions we are considering . Although our framework is applicable to various parametric families of weight functions , further in this paper we deal only with logistic weight functions :
Wβ(y ) = sigmoid(y·β ) ,
1 sigmoid(z ) =
( 4 ) where y = ( y1 , . . . , yM ) ∈ RM is a row vector of Y features , β = ( β1 , . . . , βM )T is a column vector of parameters , and y· β = yiβi . Here and below superscript T stands for
1 + e−z ,
1147 X S × N matrix with personalization features , its i th row is feature vector xi = X ( ti ) of sample ti S × M matrix with weight features , its i th row is feature vector yi = Y(ti ) of sample ti
Y
Wβ b
β M dimensional column vector of weight parameters diagonal S × S matrix with Wβ(yi ) at the i th position N dimensional column vector of ranker F parameters S dimensional column vector of the ranker values , its i th coordinate is fi = F(X ( ti ) ) S dimensional column vector of the gain values , its i th coordinate is gi = G(ti ) L2 regularization parameter
µ g f
Table 1 : Matrix notations . matrix transposition . The choice of the sigmoid transform is convenient , since it automatically guarantees that the weight function takes its values in the unit interval ( 0 ; 1 ) .
Learning to rank algorithm
In the most general setting , derivatives
∂M ∂βi steepest descend optimization could not be efficiently computed and even do not necessarily exist . To guarantee the existence of these derivatives and to be able to calculate them , we limit ourselves to the particular class of machine learning algorithms — linear regression ranking models — and use a smoothed variant of the performance measure M : SoftRank smoothing [ 18 ] .
Before we describe this algorithm , we fix matrix notations for some objects defined in Section 3 and introduce some additional notions specific for the algorithm , which are summarized in Table 1 . Linear ranker F is any ranker given by a linear function F : RN → R , ie , a function of the form
N i=1 ti∈S ti∈S where b = ( b1 , . . . , bN )T is a column vector of coefficients — parameters of the ranking function . Thus , in the matrix notation , the vector of ranker values is f = X · b .
Regression learning is one of the possible pointwise approaches to the learning to rank problem . This type of algorithms predicts the gain value gi = G(ti ) for each sample ( point ) ti ∈ S separately . Typically , this is done by minimizing the residual sum of squares :
RSS =
( gi − fi)2 → min .
To incorporate weights into RSS optimization problem we use its weighted analogue : WRSS , by multiplying each residual square by the corresponding weight :
WRSS = wi(gi − fi)2 → min .
For the reduction of the overfitting to the training dataset we add L2 regularization term to the WRSS minimization
F(x ) = x·b = xibi , x = ( x1 , . . . , xN ) ,
( 5 )
Here the vector of ranker values is : required for f = Xb = X(X T WβX + µId )
−1X T Wβg .
( 7 )
( 8 ) problem . The impact of the regularization on the final solution is controlled by the parameter µ ∈ R ( L2RSS is defined analogously ) :
,gi − fi
2 + µ||b||2 → min
( 6 )
L2WRSS = wi ti∈S
Further in the paper we assume that the machine learning algorithm A solves this minimization problem . We would like to point out that although the framework described below solves the weight optimization problem ( 3 ) only for linear regression algorithm , the learned weight function W itself could be used in a more complicated algorithms . For example , our experimental results in Section 6 prove that the weight function learned for a simple linear regression problem ( solution to ( 3 ) for ranker ( 5 ) ) significantly improves a decision tree model . 4.2 Gradient computation fi = xi·b and linear learning has the explicit solution :
In the case of L2WRSS regression problem ( 6 ) , we have b = ( X T WβX + µId )
−1X T Wβg ;
For our choice of the weight function , see ( 4 ) , the elements of the matrix Wβ smoothly depend on the parameter vector β , so together with equation ( 8 ) this gives smooth dependence of the vector f on parameters β , and we can compute all the derivatives for i = 1 , . . . , M . Set ting Zβ = X T WβX + µId and differentiating the equality Zβb = X T Wβg with respect to βi , one obtains :
∂f ∂βk
∂b ∂βi
= Z
−1 β X T ∂Wβ ∂βi g − Z
−1 β
∂Zβ ∂βi b =
= Z
−1 β X T ∂Wβ ∂βi
( g − f ) .
( 9 )
∂Wβ ∂βi
∂M ∂fj is the elementwise derivative of matrix Wβ , ie , k sigmoid(yk · β ) at k th the diagonal S × S matrix with yi position .
To finish the computation of the derivatives
∂M ∂βi we need to find . Although in the straightforward interpretation of the metric M described above , this derivative never exists , there are effective methods to cope with this problem . Indeed , ordering of documents Su,q defined by the values of the ranking function F is locally constant and changes discontinuously as scores fi = F(X ( t ) ) vary , so does the objective function M . A standard method of turning M into a smooth function is a probabilistic smoothing of the ranking measure , see [ 18 , 20 , 24 ] . Further we employ SoftRank approach from [ 18 ] . In a nutshell , this method replaces each score fi with a random variable with a normal distribution with the mean fi and computes the expectation value EM instead of the true value M . We refer to [ 18 , Section 3 ] for technical details and explicit formulas . By abuse of notation we continue writing simply M instead of EM .
1148 Now we have all ingredients to start steepest descend in the space of parameters β . Let βj ∈ RM be the vector of weight function parameters at j th iteration . The pseudocode in Algorithm 1 summarizes iterative steepest descend learning of the weight function Wβ in the case of linear ranker F , see equations ( 5 ) and ( 6 ) .
Input : feature matrices X , Y , vector of gain values g Parameters : number of iterations J , step size regularization , parameter of L2 regularization µ Initialization : β0 = ( 0 , . . . , 0)T for j = 0 to J do f = X(X T Wβj X + µId)−1X T Wβj g ( see ( 8) ) ; fifififiβ=βj
S i=1
= fifififiβ=βj
∂M ∂fi
· ∂fi ∂β step =
∂M ∂f
· ∂f ∂β
( see ( 9) ) ;
βj+1 = βj + step ; end Output : optimized vector βJ
Algorithm 1 : Steepest descend optimization of β .
4.3 Computational complexity
In this section we give an upper bound on the complexity of one iteration of Algorithm 1 . In what follows , we assume that M , N S , since in the personalization framework it is usually very easy to collect a training set of arbitrarily large size , and , typically , in studies on personalization [ 3 , 4 , 15 ] , the number of samples in the training set is several orders of magnitude larger than the number of features . Under these assumptions we estimate the complexity of our algorithm with a sigmoid weight function W and a linear ranker F ( see equations ( 4 ) and ( 5) ) . To calculate the derivatives ( 9 ) we first compute the S×S matrix with the numbers sigmoid(yk · β ) , k = 1 . . . , S , on multiplythe diagonal . Then compute M matrices
∂Wβ ∂βi ing diagonal by numbers yi k and matrix Wβ , which requires O(M S ) operations . After this , using the fact that matrix Wβ is diagonal , we compute matrix Zβ , in O(SN 2 ) operations . Recall that computation of a product of two matrices of sizes A × B and B × C requires O(ABC ) operations , and finding a solution of a linear system of a size A × A requires O(A3 ) operations . Hence , to multiply right hand sides of equations ( 8 ) and ( 9 ) from the right to left one requires
O(S ) + O(N S ) + O(N 3 ) + O(N S)+
+ M,O(S ) + O(N S ) + O(N 3 ) + O(N S) = operations . Taking into account the fact that M , N S , we obtain the estimate O(SM N ) + O(SN 2 ) operations to
= O(SN M ) + O(N 3M ) compute the vectors
, see ( 9 ) .
∂f ∂βi
The complexity of the procedure of smoothing the objective function is described in [ 18 , Section 36 ] The computa tion of the derivatives
∂M ∂fj for one user query pair requires
O(k3 ) operations , where k is the number of documents retrieved for a given query q ( assumed to be constant across different queries in our case ) . So , the computation of all the derivatives of the objective function M over all scores fi , i = 1 , . . . , S requires
S k
O(k3 ) = O(Sk2 ) operations .
All in all the computation of the gradients
O(SN M ) + O(SN 2 ) + O(Sk2 )
∂M ∂β requires : operations . Note that the complexity of our framework is linear with respect to the number of samples in the training dataset and the number of iterations . 5 . EXPERIMENTAL SETUP
In this section we describe the dataset and the features that are used to train both the personalized ranker and the weight function used in our learning framework . 5.1 Data
In the experiments we verify our theoretically grounded framework on the large scale log of a popular commercial search engine . Namely , we use a sample from the publicly available dataset shared by Yandex with the participants of ‘Personalized Web Search Challenge’ on KagglecomThis dataset contains user sessions collected during 30 days including user ids , their queries , query terms , SERPs , and clicks . All queries with no clicks on the result page were eliminated . The sessions from the first 27 days were intended for training and are supplied with all available data , while the sessions from the last three days are not accompanied by information about clicks and were used to find the winners of the challenge . While the clicks for the latter sessions had not become publicly available even after the challenge , we use the former sessions for our experiments , also used by all participants of the challenge to train and test their solutions . The stream of user actions stored in the dataset is pre segmented into search sessions . As described below , we use this segmentation to compute some of the weight features . All data including texts of queries are fully anonymized and encoded by numerical values . An original production ranking recorded in this dataset , which was presented to real users , will be further referred to as non personalized baseline . 5.2 Personalization features The core component of any personalization algorithm is the set of features X used for training a personalized ranker . Note that the specific choice of features X is out of the scope of our study , and the framework we suggest could be applied regardless of a feature set . However , to prove effectiveness of our methodology on the real data , we conduct our experiments by using a competitive collection of personalization features . Namely , we use the evaluation dataset provided by team pampampampam , the winner of the Personalized Web Search Challenge . This evaluation dataset S consists of 280K queries uniformly sampled from the 27th day in the original raw Kaggle log for training and testing purposes . For each querydocument pair , personalization features are computed based on the information available prior to the moment this query was issued ( including the information from the first 26 days of the Kaggle dataset ) .
1149 We briefly enlist the types of features extracted from the Yandex dataset . For every sample {u , q , d} ∈ S we used 165 features covering most of the existing sources of signal for personalization investigated in previous studies on personalization [ 4 , 16 , 21 ] . Since some data used in these studies is unavailable in our case , as we use the above mentioned publicly available dataset , we use simplified versions of some features , eg , we do not have any information on topics of documents , stopwords in queries and IDF ’s ( inverse document frequencies ) of words .
• Features based on the user behavior aggregated over all users , eg , various click through rates of document d , the number of times document d was shown , the number of times document d was skipped .
• Features reflecting the short term search context of a given query , eg , the number of times the document was shown/clicked/skipped by the user in the current search session . These features are analogous to the Query Doc User Features from [ 4 ] based on URLmatch with decay .
• Features intended for long term personalization ( see [ 4 , 16 ] ) computed during the first 26 days , eg , the number of times the document/host was shown/clicked/skipped by the user in the past . These features are analogous to the Query Doc User Features from [ 4 ] based on URL match without decay .
• Characteristics of query q , eg , word count , query popularity , click entropy , sum of inverse frequencies of its terms . These features include all Query features from [ 4 ] .
• The original position of document d assigned by the default non personalized ranker ( The Query Doc feature from [ 4] ) .
During evaluation of our personalization system we perform the following version of cross validation by proceeding the following splitting of the dataset five times . We divide the whole dataset S containing 2.8M samples into two parts on the basis of unique user id : ( 1 ) part S1 containing 1/3 of query document pairs is used for learning of personalization models and weights as it is described in Algorithm 1 ; ( 2 ) the remaining part S2 is used for evaluation . We did this type of splitting following the state of the art studies on personalization [ 3 , 15 , 19 ] to prevent user specific overfitting and to ensure that the model we learned is applicable to users not seen in the training dataset . All performance values reported below are averaged over these five splittings . 5.3 Weight features The core part of our experiments is the choice of the set of weight features Y . These features characterise user behavior on the result page and are used only as components of the function Wβ trained with the procedure described in Section 4 . They do not participate in training a personalization ranker , since these features cannot be calculated before the search results are shown to the user . The basic features of user interaction with SERP are reported in Table 2 . There are two types of features : the first ones depend on the particular query document pair and the second ones depend on the whole SERP . All the non binary features are
Feature
Description click∗ dwell long∗ last∗ first∗ sat∗ position skip∗ skipprev∗ skipabove topclick bottomclick numclick numclick3 numskips lastquery∗ examtime
Document level features
1 iff d was clicked dwell time of a click , 0 if click(d)=0 1 iff dwell(d ) > 30 1 iff click(d ) = 1 and d is the last clicked document 1 iff click(d ) = 1 and d is the first clicked document last(d ) = 1 or long = 1 original position of the document d was skipped the previous document in the ranking list was skipped the number of above d SERP level features the highest position among all clicks the lowest position among all clicks total number of clicks on the result page number of clicks at top 3 results total number of skipped documents on the result page query q is the last query in the session time to the first click on SERP skipped documents
Table 2 : Basic weight features ( ∗ indicates binary )
Feature # Discretization levels dwell position skipabove numclick numclick3 numskips examtime
10
10 3 2 4 3 10
0–5–15–30–50–90–150–300–750– 3000–∞ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 0 , 1 , 2–∞ 1 , 2–∞ 0 , 1 , 2 , 3 0 , 1 , 2–∞ 0–5–15–30–50–90–150–300–750– 3000–∞
Table 3 : Discretization of non binary features .
Feature click=x AND numclick=y AND position=1 click=x AND numclick=y AND position>1 last=1 AND numclick=x first=1 AND numclick=x skip=0 AND click=0 skipprev=1 AND click=1
# 4 4 2 2 1 1
Table 4 : Composite weight features and their counts .
1150 turned into the binary ones as it is reported in Table 3 . The set of binary features we choose was motivated by the basic binary features used in [ 26 ] for improving the statistical power of interleaving algorithms . From the binary features we combine more complex ones as described in Table 4 . To sum up , we take binary features from Tables 2 and 3 and the ones presented in Table 4 ( 64 features in total ) .
Besides improving the quality of the personalized ranker , we expect that the values of weight function will help answering the following questions :
Q1 How does the time the user has spent on the clicked document d affect the confidence in its positive gain value ?
Q2 How does positional bias of users’ clicks affect the weights of the gain values ?
Q3 Do all the non clicked documents indicate non relevance to the same extent ?
6 . RESULTS In this section we report the results of various experiments we conduct on training weight functions W on the Yandex dataset . Below we compute re ranking performances on all the queries in the test set , which , in particular , includes many of the queries not affected by the personalization . Although averaging improvements over all queries , instead of affected ones , decreases change in MRR* , it also provides more insight into the overall effect of our method .
We conclude this section by analyzing the learned weight function in the scope of the stated research questions and provide some insight into interpreting the user behavior . 6.1 Evaluation methodology To evaluate the quality of our framework we used five simplest and widely used [ 1 , 9 , 22 ] , ‘basic’ binary gains G : click , first click , last click , long click , satisfied click .
1 S 2
1 S 3
We fix the positional discount function : discount(k ) = 1/k and compute the corresponding objective measures as in equations ( 1 ) and ( 2 ) for each of the gains . Further these five performance metrics are referred to as MRR* ( where * stands for one of the gains : click , first , last , long or sat ) . Relying on the unique user identifier , we randomly divide part S1 into three equal parts : S1 = S 1 1 . First , we adjust the regularization parameter and use it in the subsequent experiments : µ = argmaxµM(F ) , where the performance metric M is computed over S 2 1 and the ranker F is trained via L2 regularized RSS linear model on S1 1 . Step regularization parameter was set to the trivial default value = 1 and was not tuned . Smaller values of could possibly improve the quality of our framework , however , at the same time , they would increase the optimal number of iterations and thus , the runtime of the steepest descent algorithm . After that we run Algorithm 1 and find the best iteration count according to the performance M(FW ) measured on the set S 2 1 . The resulting ranker trained on the set S 1 1 is evaluated on the set S2 . The remaining set S 3
1 is further used to tune the parame ters of the decision tree model , see Section 63
NoWeight Weight
2.8 %
2.4 %
2 %
1.6 %
1.2 % t n e m e v o r p m i
M
0.8 %
0.4 %
0 % click first last long sat
Figure 1 : Relative improvements of MRR* of various gains for linear models trained without and with weights over the non personalized baseline .
WRSS \ gain G W for ‘first’ W for gain G first last
MRR* improvement in % sat click +1.17 +0.98 +1.54 +1.24 +1.32 +1.68 +0.98 +2.66 +2.00 +2.16 long
Table 5 : MRR* improvements over the nonpersonalized baseline of the linear rankers learned with weights trained for ‘first’ gain and for the corresponding gain .
6.2 Linear model
In this section we compare two personalization algorithms : linear regression model learned with the identical weights ( L2RSS ) and linear regression model learned with the weight function optimized with our framework ( L2WRSS ) . The improvements of both learning algorithms over non personalized baseline according to five binary gains are demonstrated in Figure 1 . For every gain , weighted L2WRSS model significantly outperforms the corresponding L2RSS model . To demonstrate that the weight function W trained with our framework essentially depends on the choice of the evaluation metric M , and , therefore , on the gain function G , we also conduct the following experiment . We trained weight function W relying on the ‘first’ gain , and the corresponding ranker FW was evaluated according to the other basic gains . In Table 5 we report the performance of this ranker in comparison with the rankers trained by utilizing weight functions optimized by Algorithm 1 for the corresponding gains . One can see that for ‘click’ ‘last’ , ‘long’ and ‘sat’ gains the weight function trained for the ‘first’ gain is significantly outperformed . This proves that the choice of the performance measure strongly affects the weight function provided by our algorithm . Another argument supporting this claim will be discussed in Section 64 6.3 Decision tree model
To understand whether the weights provided by our framework are specific for linear machine learning algorithms only or could be used for more complicated models , we used them at the top of a proprietary implementation of Friedman ’s gradient boosted decision tree based machine learning algorithm [ 7 ] with the WRSS loss function .
1151 Alg.\ gain G
RSS
WRSS
MRR* improvement in % first click +1.95 +1.50 +2.75 +2.11 +2.22 +2.02 +1.60 +2.81 +2.23 +2.34 long last sat
Table 6 : MRR* improvements over the nonpersonalized baseline of the decision tree rankers learned without ( RSS ) and with ( WRSS ) trained weights . All WRSS rankers significantly ( p<0.05 ) outperform RSS rankers according to the Student t test . t h g i e
W
Alg . meas diff RSS
Fraction of queries in % minus 11.30 11.83 plus 15.65 16.67
26.94 28.50
WRSS plus/minus
1.38 1.41
Table 7 : Fractions of affected ( ‘meas diff ’ ) , improved ( ‘plus’ ) , deteriorated ( ‘minus’ ) queries and robustness rate ( ‘plus/minus’ ) for the decision tree rankers learned for ‘sat’ gain without ( RSS ) and with ( WRSS ) trained weights .
Namely , given the gain function G , we train a weight function , as in Section 62 For the trained weights , we learn the 1 S 2 gradient boosted decision tree model on the set S 1 1 . Note that in Section 6.1 we have trained weights wi using the same dataset S 1 1 , this ensures that the model trained with the use of our weights has accessed the same set of labelled samples as the model trained using baseline identical weights .
1S 2
We would like to point out that the decision tree training model based on RSS loss function we use in this section coincides with the training model used by the winners of the Personalized Web Search Challenge . Thus it represents very strong personalization benchmark and any statistically significant improvement is valuable and important .
The resulting improvements are summarized in Table 6 . Although the corresponding weight functions were trained under the assumption that machine learning algorithm A is linear ( see Section 4.1 ) , the utilization of these weights inside the decision tree model significantly improves its performance for all five basic gains . This indicates , that trained weights are universal and , being applicable to any algorithm based on minimizing WRSS loss function , they improve various machine learning algorithms .
For a better understanding of the magnitude of our improvements , we compare them with other studies on personalization . Most papers [ 3 , 4 , 5 , 15 , 22 ] report improvement of the order of a tenth of a percent up to a few percent over the non personalized baseline . However , all these papers employ some new sources of data for personalization , eg , short term and long term history , task aggregation , geographical data , browsing data , etc . On the contrary , in our experiments we ( 1 ) achieve the improvements by changing the machine learning framework only , rather then by incorporating new signals for personalization and ( 2 ) evaluate our methodology against a very strong personalization baseline . This observation proves that weight learning framework indeed a notable improvement of the existing approaches .
Another important property of any re ranking algorithm is its robustness . The fractions of affected queries , ie , measurably different from the baseline performance , improved ,
1
0.8
0.6
0.4
0.2
0
3
9
27
81
243
729
Dwelltime
Figure 2 : Average trained weight ( for satisfied clicks gain ) of clicked documents as a function of dwell time . deteriorated queries are common characteristic of re ranking models , see , e.g , [ 3 , 11 , 16 ] . A robust algorithm not only improves the average quality , but also does not “ hurt much ” , ie , has low fraction of deteriorated and improved queries . From Table 7 one can see that the personalization model learned with weights affects more queries and has a better improvement/deterioration ratio .
To conclude this section , we would like to mention that web search personalization is known as one of the most challenging learning tasks . For instance , the additional improvement of 0.12 % over the baseline ( eg , the same as the WRSS achieved over RSS according to MRR with ‘sat’ gain ) would allow the team that took the 3rd place in Kaggle competition become a winner3 . Given that , by applying our framework , we managed to improve even the ranking system that won the challenge , we consider this improvement as an important and convincing motivation for opening a new research direction of optimizing weight functions of personalized labels introduced in our paper . 6.4 Analyzing weight function
Now we address the research question Q1 by analyzing the effect the dwell time has on the trained weight values wi . Dwell time is a common measure of conversion , so it has been widely studied from different perspectives [ 10 ] . Figure 2 depicts the average weight of documents with a given interval of dwelltime on the logscale . One could conclude that the average weight values increase in the neighbourhood of point 30 , justifying this threshold for satisfied clicks . In fact , it works in the opposite direction . Namely , these weights dramatically increase at 30 , since they were optimized for a metric MRR SAT , where only satisfied clicks are relevant . This observation again proves ( as Table 5 ) that the weight function essentially depends on the choice of the evaluation metric M . We stress that choice of the ‘right’ metric M lies out of the scope of our study and could not be done solely using data available in our experiments .
To answer both questions Q2 and Q3 , we demonstrate the average of the trained weight values over clicked/skipped/not examined documents ranked at the various fixed positions in Figure 3 . The weights of a skipped
3http://wwwkagglecom/c/yandex personalized websearch challenge/leaderboard
1152 t h g i e
W
1
0.8
0.6
0.4
0.2
0
Click Skip NotExamined
1
2
3
4
5 6 Rank
7
8
9
10
Figure 3 : Average trained weight ( for satisfied clicks gain ) of clicked , skipped and not examined documents as a function of ranking position . document at position 10 and a not examined document at position 1 are not presented , since ( by definition ) there are no such documents .
As we have expected , the average confidence in the negative label of ‘skipped’ documents is noticeably larger than of ‘not examined’ ones . Interestingly , confidence in the positive label of clicked documents increases up to position 3 and decreases after it . There are two possible explanations of this behavior . The first one is related to positional bias : users tend to click on the top ranked documents despite their relevance , so clicks at first positions are often noisy . The second effect is that the queries with clicks at low ranked documents are typically complex and ambiguous so do not have a single relevant result , unlike , eg , navigational queries . Confidence in the relevance of a particular result retrieved in a response to such complex query is lower .
7 . FUTURE WORK
Improving personalized ranking is the focus of our study . However , our framework and the tuned weight function itself could be applied in a wide variety of settings , and , hence , there are various directions for future work .
Given a set of query document pairs equipped with editorial labels , we can use the method proposed in our study to learn confidence levels of these labels , taking into account query , document and assessor features . Besides it , the weights we learn potentially provide a valuable signal for automatic evaluation of search engine performance . Namely , similarly to classical click based metrics like MRR and MAP , it is possible to use measures of the form ( 1 ) that would incorporate the tuned weights wi into the gain function G . At last , as we have briefly discussed in Section 6.4 , the weight values and coefficients βi of the trained weight functions Wβ encode important information about user ’s behavior patterns and provide useful insights for its modelling and analysis .
Besides diverse possible applications of our framework , there is a large room for its development and improvement . Probably the most essential direction for future research is to extend our algorithm , which is primarily intended for linear regression models , to more complicated machine learning models , eg , neural networks and decision trees . The gap between improvements demonstrated in the linear and decision tree model cases , see Figure 1 and Table 6 , suggests that the solution to this extension problem will likely substantially improve the overall effectiveness of our framework .
8 . CONCLUSION
In this paper , following the most studies on personalization of web search , we deal with a training of a personalized ranker on the basis of user clicks . The state of theart approaches to personalization employ very simple and noisy implicit personal relevance labels , missing vast amount of useful information . We have presented an optimization framework for training the confidence levels of these labels . Given a click through dataset and a fixed evaluation methodology , our algorithm extracts weights of relevance labels from various features characterising user interaction with the result page . These weights could be utilized in the majority of machine learning algorithms .
Our experiments with the large scale publicly available dataset demonstrate that rankers trained via both simple linear models and the state of the art decision trees machine learning algorithms significantly benefit from the employment of the trained weight function .
Acknowledgements We are grateful to the team pampampampam and its members , who have shared their learning dataset with us . Also we would like to thank Igor Kuralenok for valuable discussions and advice on this research .
9 . REFERENCES [ 1 ] E . Agichtein , E . Brill , and S . Dumais . Improving web search ranking by incorporating user behavior information . In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR ’06 , pages 19–26 , New York , NY , USA , 2006 . ACM .
[ 2 ] A . Aitken . On least squares and linear combination of observations . volume 55 of Proc . R . Soc . Edinb , pages 42–48 , 1934 .
[ 3 ] P . N . Bennett , F . Radlinski , R . W . White , and
E . Yilmaz . Inferring and using location metadata to personalize web search . In Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR ’11 , pages 135–144 , New York , NY , USA , 2011 . ACM .
[ 4 ] P . N . Bennett , R . W . White , W . Chu , S . T . Dumais ,
P . Bailey , F . Borisyuk , and X . Cui . Modeling the impact of short and long term behavior on search personalization . In Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR ’12 , pages 185–194 , New York , NY , USA , 2012 . ACM .
[ 5 ] K . Collins Thompson , P . N . Bennett , R . W . White ,
S . de la Chica , and D . Sontag . Personalizing web search results by reading level . In Proceedings of the 20th ACM International Conference on Information and Knowledge Management , CIKM ’11 , pages 403–412 , New York , NY , USA , 2011 . ACM .
[ 6 ] Z . Dou , R . Song , and J R Wen . A large scale evaluation and analysis of personalized search
1153 strategies . In Proceedings of the 16th International Conference on World Wide Web , WWW ’07 , pages 581–590 , New York , NY , USA , 2007 . ACM .
[ 7 ] J . H . Friedman . Stochastic gradient boosting . Comput .
Stat . Data Anal . , 38(4):367–378 , Feb . 2002 .
[ 8 ] D . Jiang , K . W T Leung , and W . Ng . Context aware search personalization with concept preference . In Proceedings of the 20th ACM International Conference on Information and Knowledge Management , CIKM ’11 , pages 563–572 , New York , NY , USA , 2011 . ACM .
[ 9 ] T . Joachims . Optimizing search engines using clickthrough data . In Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ’02 , pages 133–142 , New York , NY , USA , 2002 . ACM .
[ 10 ] C . Liu , R . W . White , and S . Dumais . Understanding web browsing behaviors through weibull analysis of dwell time . In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR ’10 , pages 379–386 , New York , NY , USA , 2010 . ACM .
[ 11 ] N . Matthijs and F . Radlinski . Personalizing web search using long term browsing history . In Proceedings of the Fourth ACM International Conference on Web Search and Data Mining , WSDM ’11 , pages 25–34 , New York , NY , USA , 2011 . ACM . [ 12 ] F . Radlinski , M . Kurup , and T . Joachims . How does clickthrough data reflect retrieval quality ? In Proceedings of the 17th ACM Conference on Information and Knowledge Management , CIKM ’08 , pages 43–52 , New York , NY , USA , 2008 . ACM .
[ 13 ] P . Serdyukov , G . Dupret , and N . Craswell . Log based personalization : The 4th web search click data ( wscd ) workshop . WSDM ’14 , pages 685–686 , New York , NY , USA , 2014 . ACM .
[ 14 ] X . Shen , B . Tan , and C . Zhai . Context sensitive information retrieval using implicit feedback . In Proceedings of the 28th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR ’05 , pages 43–50 , New York , NY , USA , 2005 . ACM .
[ 15 ] M . Shokouhi , R . W . White , P . Bennett , and
F . Radlinski . Fighting search engine amnesia : Reranking repeated results . In Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR ’13 , pages 273–282 , New York , NY , USA , 2013 . ACM .
[ 16 ] D . Sontag , K . Collins Thompson , P . N . Bennett ,
R . W . White , S . Dumais , and B . Billerbeck . Probabilistic models for personalizing web search . WSDM ’12 , pages 433–442 , New York , NY , USA , 2012 . ACM .
[ 17 ] B . Tan , X . Shen , and C . Zhai . Mining long term search history to improve search accuracy . In Proceedings of the 12th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ’06 , pages 718–723 , New York , NY , USA , 2006 . ACM .
[ 18 ] M . Taylor , J . Guiver , S . Robertson , and T . Minka . Softrank : Optimizing non smooth rank metrics . In Proceedings of the 2008 International Conference on Web Search and Data Mining , WSDM ’08 , pages 77–86 , New York , NY , USA , 2008 . ACM .
[ 19 ] Y . Ustinovskiy and P . Serdyukov . Personalization of web search using short term browsing context . In Proceedings of the 22Nd ACM International Conference on Conference on Information and Knowledge Management , CIKM ’13 , pages 1979–1988 , New York , NY , USA , 2013 . ACM .
[ 20 ] M . N . Volkovs and R . S . Zemel . Boltzrank : Learning to maximize expected ranking gain . In Proceedings of the 26th Annual International Conference on Machine Learning , ICML ’09 , pages 1089–1096 , New York , NY , USA , 2009 . ACM .
[ 21 ] R . W . White , P . N . Bennett , and S . T . Dumais .
Predicting short term interests using activity based search context . In Proceedings of the 19th ACM International Conference on Information and Knowledge Management , CIKM ’10 , pages 1009–1018 , New York , NY , USA , 2010 . ACM .
[ 22 ] R . W . White , W . Chu , A . Hassan , X . He , Y . Song , and H . Wang . Enhancing personalized search by mining and modeling task behavior . In Proceedings of the 22Nd International Conference on World Wide Web , WWW ’13 , pages 1411–1420 , Republic and Canton of Geneva , Switzerland , 2013 . International World Wide Web Conferences Steering Committee .
[ 23 ] B . Xiang , D . Jiang , J . Pei , X . Sun , E . Chen , and
H . Li . Context aware ranking in web search . In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR ’10 , pages 451–458 , New York , NY , USA , 2010 . ACM .
[ 24 ] J . Xu , T Y Liu , M . Lu , H . Li , and W Y Ma .
Directly optimizing evaluation measures in learning to rank . In Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR ’08 , pages 107–114 , New York , NY , USA , 2008 . ACM .
[ 25 ] L . Xu , M . White , and D . Schuurmans . Optimal reverse prediction : A unified perspective on supervised , unsupervised and semi supervised learning . In Proceedings of the 26th Annual International Conference on Machine Learning , ICML ’09 , pages 1137–1144 , New York , NY , USA , 2009 . ACM .
[ 26 ] Y . Yue , Y . Gao , O . Chapelle , Y . Zhang , and
T . Joachims . Learning more powerful test statistics for click based retrieval evaluation . In Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval , SIGIR ’10 , pages 507–514 , New York , NY , USA , 2010 . ACM .
1154
