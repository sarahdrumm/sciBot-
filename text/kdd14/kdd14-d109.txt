Product Selection Problem : Improve Market Share by
Learning Consumer Behavior
Silei Xu slxu@csecuhkeduhk
John CS Lui cslui@csecuhkeduhk
Department of Computer Science and Engineering
The Chinese University of Hong Kong
New Territories , Hong Kong
ABSTRACT It is often crucial for manufacturers to decide what products to produce so that they can increase their market share in an increasingly fierce market . To decide which products to produce , manufacturers need to analyze the consumers’ requirements and how consumers make their purchase decisions so that the new products will be competitive in the market . In this paper , we first present a general distancebased product adoption model to capture consumers’ purchase behavior . Using this model , various distance metrics can be used to describe different real life purchase behavior . We then provide a learning algorithm to decide which set of distance metrics one should use when we are given some historical purchase data . Based on the product adoption model , we formalize the k most marketable products ( or k MMP ) selection problem and formally prove that the problem is NP hard . To tackle this problem , we propose an efficient greedy based approximation algorithm with a provable solution guarantee . Using submodularity analysis , we prove that our approximation algorithm can achieve at least 63 % of the optimal solution . We apply our algorithm on both synthetic datasets and real world datasets ( TripAdvisor.com ) , and show that our algorithm can easily achieve five or more orders of speedup over the exhaustive search and achieve about 96 % of the optimal solution on average . Our experiments also show the significant impact of different distance metrics on the results , and how proper distance metrics can improve the accuracy of product selection .
Categories and Subject Descriptors F2.2 [ Analysis of Algorithms and Problem Complexity ] : Nonnumerical Algorithms and Problems
Keywords Product selection ; consumer behavior ; model learning ; submodular set function ; approximation algorithm
1 .
INTRODUCTION
Product competition in the current digital age is becoming increasingly fierce . Consumers can easily access the information about a given product via the Internet . Moreover , consumers can share their opinions on products in the form of ratings or reviews via various web services , eg , Amazon . Therefore , instead of relying on the sales pitch by salesmen or traditional TV advertisements , consumers can now review many competing products before they make their final purchase decision . Manufacturers , on the other hand , can use the web information , such as ratings and reviews , to gain a better understanding of consumers’ requirements on various products . This leads to a new challenge on how to discover consumers’ preferences , and how these preferences may help manufacturer to select appropriate new products so to compete with other manufacturers in the market .
To introduce new products into a market , a manufacturer usually has a set of candidate products to consider . However , due to budget constraints , the manufacturer can only produce a small subset of these candidate products . The objective of a manufacturer is to select a subset of products which can maximize its profit or market share . In this study , we consider the following scenario : In a market consisting of a set of existing products from various manufacturers and a set of consumers , a manufacturer wants to select “ k most marketable products ” from a set of candidate products so as to maximize the market share of all products from this manufacturer ( this includes the possibility that some existing products in the market are from the same manufacturer ) .
One of the major challenges of the “ k most marketable products ” problem is how to model various consumers’ adoption behavior , ie , how consumers make their purchase decisions . Different adoption behavior may lead to different product selection results . However , there is a lack of formal work of how to model these behaviors using available data . Furthermore , finding the optimal solution to the “ k most marketable products ” problem can be shown to be NP hard in general .
In this paper , we first model the consumers’ adoption behavior with a generalized distance based model where different distance metrics can be used to describe many different consumers behaviors . We then propose a method to learn which set of distance metrics one should use when we are given some historical purchase data . We also present a computationally efficient approximation algorithm to solve the k most marketable products problem . To the best of our knowledge , this is the first paper that provides the formal consumers’ adoption model and the analysis of product selection . The contributions of this paper are : ketable products ( k MMP ) for a manufacturer .
• We formulate the problem of finding the k most mar• We model the adoption behavior of consumers using a general distance based product adoption model which can take on various different distance metrics . • We provide a learning method to determine the appropriate set of distance metrics using the historical purchase data on market share of a subset of the existing products . • We prove that the k MMP problem is NP hard and propose a computationally efficient approximation algorithm . By proving the monotonicity and submodularity properties of the objective function , we show that our approximation algorithm provides a ( 1−1/e)approximation as compared with the optimal solution . • We carry out experiments on synthetic and real world datasets to demonstrate the computational efficiency of our algorithm and quality of its solutions . We also illustrate how one can select the appropriate distance metrics by learning from the historical purchase data so as to improve the market share .
The outline of the paper is as follows . In Section 2 , we propose a general product adoption model which can accommodate different distance metrics to describe the consumers’ adoption behavior , and we formulate the k MMP problem . In Section 3 , we present a learning method to select the appropriate set of distance metrics according to the historical market share of existing products . In Section 4 , we propose an exact algorithm for the case of k = 1 and prove that finding the exact solution for k > 1 is NP hard . To tackle the computational challenge , we present an approximation algorithm in Section 5 . We show that this algorithm is computationally efficient and also provides a high quality solution guarantee . In Section 6 , we perform experiments on both the synthetic data and the real world data . Related work is shown in Section 7 , and Section 8 concludes .
2 . MATHEMATICAL MODELS AND PROB
LEM FORMULATION
In this section , we first present a model of a market by considering both products and consumers . Then we present a distance based product adoption model to describe various consumers’ product adoption behaviors . Based on these models , we formulate the k MMP problem . 2.1 Market Model Let us consider a market which consists of a set of l consumers C ={c1 , c2 , . . . , cl} and a set of m existing products PE = {p1 , p2 , . . . , pm} . Let M represent a manufacturer in the market , and PM denote the set of existing products produced by M , where PM ⊆PE and |PM| = mM . The remaining products in PE are from other manufacturers who are the competitors of M . These competing products are denoted by PC , where PC ⊆PE and |PC| = mC . According to these definitions , we have m = mM +mC , PE =PM ∪ PC , and PM ∩ PC = ∅ .
Suppose the manufacturer M wants to produce some new products to maximize its utility , ie , the market share . M has a set of n candidate new products to choose from , which we denote by PN = {pm+1 , pm+2 , . . . , pm+n} . Note that all the products in PN are new to the market , in other words , PN ∩ PE = ∅ . Due to the budget , technological and manufacturing constraints , the manufacturer M can only produce k ≤ n of these candidate products in PN . Each product in PE ∪PN is associated with d attributes denoted by A = {a1 , a2 , . . . , ad} . Each attribute ai is represented by a non negative real number , and higher value implies higher quality . One can use ai to represent various attributes of a given product , eg , durability , ratings , inverse of price . Hence , the quality of a product can be described by a d dimensional vector . Specially , the quality of product pj is described by the vector qj = ( qj[1 ] , qj[2 ] , . . . , qj[d] ) , where qj[t]∈ [ 0,∞ ) , ∀t ∈ {1 , 2 , , d} indicates pj ’s quality on attribute at . Similarly , each consumer in C is also associated with A to describe his requirements on different attributes . Let ri = ( ri[1 ] , ri[2 ] , . . . , ri[d ] ) be the requirement vector of consumer ci , where ri[t]∈ [ 0,∞ ) , ∀t∈{1 , 2 , . . . , d} indicates ci ’s minimum requirement on attribute at , ie , ci requires that the product ’s quality on attribute at is at least ri[t ] , or he will not adopt ( or purchase ) that product .
Example 1 . To illustrate the notations , we present an example in Figure 1 . Consider a market of smart phones where we have two existing products PE ={p1 , p2} and three consumers C = {c1 , c2 , c3} . Manufacturer M is considering two candidate products PN = {p3 , p4} . Let say each product is described by two attributes : a1 is the inverse of price ( units per thousand dollars , UPM for short ) and a2 is durability ( years ) , and they are represented in the horizontal and the vertical axis respectively . The quality vectors of products and the requirement vectors of consumers are shown in the figure ( with PE:♦ , PN :2 , C:◦ ) . For instance , the quality vector of p1 is ( 2 , 6 ) , so we can purchase two units of p1 with one thousand dollars ( or the price of p1 is $500 ) , and the durability of p1 is six years . Similarly , the requirement vector of c1 is ( 1 , 5 ) , so consumer c1 wants a product which is at most $1000 and can last for at least five years .
7
6
5
4
3
2
1
0 durability ( years ) p1(2 , 6 ) c1(1 , 5 ) p2(6 , 4 ) c2(2 , 3 ) p3(7 , 3 ) p4(9 , 2 ) c3(7 , 1 ) inverse of price
( UPM )
1
2
3
4
5
6
7
8
9 10
Figure 1 : An illustration of the market model
2.2 Product Adoption Model
We assume that a consumer may adopt a product if the product satisfies his requirement . We say that a product satisfies a consumer ’s requirements if and only if the product meets the requirements of that consumer on all attributes . Formally , we define the product satisfiability condition .
Definition 1 . ( Product satisfiability ) Consider a consumer ci and a product pj . We say the product pj satisfies the consumer ci if and only if qj[t ] ≥ ri[t ] , ∀t = 1 , . . . , d . We denote this relationship as pj ci , and pj is said to be a satisfactory product of ci , while ci is a potential consumer of pj in other words .
For example , consider the products and consumers depicted in Figure 1 . One can observe that the quality vector of p1 is ( 2 , 6 ) and the requirement vector of c1 is ( 1 , 5 ) . Since 2 > 1 and 6 > 5 , so p1 satisfies c1 , or p1 c1 . Similarly , we have p3 c2 and p3 c3 .
We assume that if a consumer has some satisfactory products , then he will adopt one unit of product from any of these feasible products . When a consumer ci has only one satisfactory product , say pj , then ci will adopt pj for sure . However , it becomes complicated when there are multiple satisfactory products . All previous works [ 7 , 12 , 13 , 16 ] assume that the consumer will randomly adopt one of the satisfactory products , but this is not realistic in many situations . In the following , we present the distance based adoption model to describe some realistic and representative product adoption behavior when consumers make their purchase decisions . Our model is very general to model various product adoption behaviors in the real world scenarios .
In a real world market , products with higher quality usually attract more consumers . Therefore , we use a distance measure between a product ’s quality and a consumer ’s requirement to decide which product the consumer may adopt . Note that consumers will only consider their satisfactory products . Furthermore , larger distance implies better quality . Let di,j be the distance between the consumer ci ’s requirement vector ( ri ) and the product pj ’s quality vector ( qj ) . We assume that ci will adopt the product pj which has the largest distance among all his satisfactory products . If there are multiple satisfactory products which have the same largest distance measure with ci , then ci will randomly select one of these products . Mathematically , we define the distance based adoption model as follows .
Definition 2 . ( Distance based adoption model ) Given a consumer ci and a set P of products available in the market , let FP(ci|P ) be the set of products which have the largest distance between their quality vectors and ci ’s requirement vector among all ci ’s satisfactory products . The probability that ci adopts a product pj ∈P is
Pr(i , j|P ) =
1
|FP(ci|P)|
0 if pj ∈ FP(ci|P ) , otherwise .
( 1 ) fl
Note that we can use many distance metrics , eg , l1 , l2 , l∞ norms . For instance , if l1 norm ( or the Manhattan distance ) is used , then consumers will choose the satisfactory products which have the largest sum of all components’ values in the quality vectors . To describe different adoption behaviors of different consumers in a real world market , we also take into account the weighted distance metrics . Let wt be the weight of attribute at , wt ≥ 0,∀at ∈A , then under the l1 norm , the distance di,j can be expressed as : di,j = wt · ( qj[t ] − ri[t] ) .
( 2 ) at∈A
It is important to point out that the algorithms we present in this paper are general to all distance metrics . Readers can use other distance metrics when appropriate . In here , we present four representative distance metrics which we use as examples for illustrations and experiments . • Discrete metric ( DM ) . We define di,j = 1 for consumers ci and ci ’s satisfactory product pj in the discrete metric . This distance metric simplifies the adoption model that consumers will randomly select one from all his satisfactory products . Using this distance metric , our work subsumes the adoption models of previous works [ 7 , 12 , 13 , 16 ] . • Norm metric ( NM ) . In this distance metric , we set the weight wt = 1.0 , ∀at ∈ A based on the l1 norm metric as defined in Equation ( 2 ) . Note that in general , one can use other norm as distance metric and our algorithms still apply . • Price metric ( PM ) . In a real world market , one common situation is that if a consumer ’s requirements are satisfied , then he will select the cheapest product , ie , the one with the highest quality on the attribute of “ price ” . In this case , we can set the weight of all attributes to zero except the “ price ” based on the l1 norm metric as defined in Equation ( 2 ) . • Richman metric ( RM ) . Unlike the price metric , some consumers may be rich and they are insensitive to the price but only want the best product . In this case , we can set the weight of “ price ” attribute to zero while setting the weight of other attributes to one .
Example 2 . To illustrate , let us consider the products and consumers depicted in Figure 1 . Suppose that manufacturer M decides to produce p3 , then the set of available products in the market is P = PE ∪{p3} = {p1 , p2 , p3} . Let us consider the probability c2 will adopt p3 , ie , Pr(2 , 3|P ) , when c2 uses the above four distance metrics . From Figure 1 , one can observe that c2 is satisfied by p1 , p2 , and p3 . If c2 uses the discrete metric , then d2,1 = d2,2 = d2,3 = 1 , so Pr(2 , 3|P ) = 1/3 . If c2 uses the norm metric , then we have d2,1 = 3 , d2,2 = d2,3 = 5 . Hence , c2 will select p2 and p3 with probability Pr(2 , 2|P ) = P r(2 , 3|P ) = 1/2 . If c2 uses the price metric , then we only need to consider the attribute inverse of price . We have d2,1 = 0 , d2,2 = 4 , d2,3 = 5 , so Pr(2 , 3|P ) = 1 , c2 will adopt p3 . If c2 uses the richman metric , we have d2,1 = 3 , d2,2 = 1 , d2,3 = 0 . Thus c2 will adopt p1 only , or Pr(2 , 1|P ) = 1 and Pr(2 , 3|P ) = 0 . 2.3 Problem Formulation
To find the k most marketable products , we first need to define the expected market share of a set of products under the distance based adoption model . Given the market condition , ie , the consumers C and the existing products PE , let P be the set of products we consider , then the expected market share of P is defined as
· pj∈P ci∈PC(pj )
MS ( P ) =
1 l
Pr(i , j|PE ∪ P ) ,
( 3 ) where l =|C| , PC(pj ) denotes the set of potential consumers of product pj , and Pr(i , j|PE∪P ) is defined in Equation ( 1 ) . Example 3 . Let us illustrate the expected market share of p3 , or MS ( {p3} ) , by considering the scenario depicted in Figure 1 . There are two existing products ( PE = {p1 , p2} ) and three consumers ( C = {c1 , c2 , c3} ) in the market . By adding product p3 into the market , p3 satisfies consumers c2 and c3 . Assume that c2 uses the norm metric , then according to Example 2 , we have Pr(2 , 3|P ) = 1/2 . Now consider consumer c3 . Since we have not added p4 into the market , p3 is c3 ’s only satisfactory product , so c3 will adopt p3 for sure . Therefore , in this scenario , c2 and c3 will adopt p3 with probability 1/2 and 1 , respectively . So the expected sales of p3 is 1.5 units , It follows that the expected market share of p3 is 1.5/3 = 50 % since there are three consumers in total .
Based on the definition of market share in Equation ( 3 ) , we formulate the k Most Marketable Products ( k MMP ) problem as follows .
Definition 3 . ( k MMP ) Given a set of consumers C , a set of existing products PE = PC ∪ PM in the market , and PN , a set of candidate products by the manufacturer M , select a set P ⊆ PN where |P| = k so to maximize MS ( P ∪ PM ) for manufacturer M .
To solve the k MMP problem , we need to tackle the following two issues : ( 1 ) Find the proper distance metrics for the market . ( 2 ) Design an efficient algorithm to find the solution to the k MMP problem . Since there are various potential distance metrics and manufacturers usually do not know which distance metrics the consumers may adopt , we present a learning approach to discover the proper set of distance metrics for a given market from historical purchase data . This is presented in Section 3 . After deciding on the proper distance metrics , we present the algorithmic design in solving the k MMP problem . In Section 4 , we present an efficient and exact algorithm for the 1 MMP problem and prove that the k MMP problem is NP hard when k ≥ 2 . In Section 5 , we present an efficient approximation algorithm . By exploiting the monotonicity and submodularity properties of the market share function MS ( · ) , we prove that our approximation algorithm can provide high performance guarantee on the quality of the solutions .
3 . DISTANCE METRIC LEARNING
As discussed in Section 2 , there are various distance metrics one can use and the product selection results can vary significantly depending on the distance metrics according to the results shown in Section 6 . Hence , it is important to “ learn ” about the proper distance metrics ( in other words , consumers’ product adoption behavior ) from the available data . In this work , we propose a learning method based on the market share of a set of products in the market so to discover the appropriate distance metrics .
Note that in real life , some manufacturers may not release full information about their market share . Therefore , we assume that we only know the market share of a subset of existing products . Formally , let P E be the n products that E ⊆ PE . Let ms j we know the market share data , where P be the market share of pj ∈P E . Assume that we have a model set consisting of distancebased product adoption models using m different potential distance metrics , which are numbered from 1 to m . Let eji be the expected market share of product pj under the product adoption model using the i th potential distance metric . Let θi be the probability that consumers use the i th distance metric , and Θ = ( θ1 , θ2 , . . . , θm )T . Then we can forecast the market share for each product pj ∈P E as : fj(Θ ) = Θ · ( ej1 , ej2 , . . . , ejm )
= θ1ej1 + θ2ej2 + . . . + θm ejm , where fj(Θ ) is the forecast market share of product pj .
( 4 )
We can find the best fit for Θ by minimizing the squared difference between the forecast market share fj and the realworld market share ms j . Let ∆j be the difference between fj and ms j , or mathematically , ∆j(Θ ) = |fj(Θ)− ms j| . We can formalize the model selection problem as follows .
Minimize
∆2 j ( Θ ) , pj∈P
E subject to
Θ ≥ 0 ,
θ1 + θ2 + . . . + θm = 1 ,
( 5 ) where Θ ≥ 0 means that θi ≥ 0,∀i ∈ {1 , . . . , m} . Thus , the problem is reduced to a linear regression problem with constrained least squares approach , which can be solved using the technique in [ 3 ] . Once we solve this linear regression problem , we can forecast the market share fj(Θ ) based on the probability vector Θ .
Example 4 . Consider a model set consisting of adoption models using the norm metric ( NM ) , the price metric ( PM ) and the richman metric ( RM ) . Assume we obtain the realworld market share of three products p1 , p2 , and p3 and we want to forecast the market share of p4 . The real world market share and the expected market share under three different models of these products are shown in Table 4 .
NM PM RM real world 20 % 1 % 50 % 30 % 10 % 10 % 5 % 30 % 0 % 10 % 40 % 5 % unknown
5 % 15 % 20 % p1 p2 p3 p4
Table 1 : An example of model selection
Let θ1 , θ2 , and θ3 be the probability of consumers using the norm metric , the price metric , and the richman metric , respectively . Then we can formalize the problem as follows . flflflflflfl20 % · θ1
30 % · θ1 5 % · θ1 Θ ≥ 0 ,
Minimize subject to
50 % · θ3 −5 % 10 % · θ3 −15 % 0 % · θ3 −20 %
1 % · θ2 10 % · θ2 30 % · θ2 θ1 + θ2 + θ3 = 1 . flflflflflfl2
2
( 6 )
We obtain Θ = ( 0.3074 , 0.6926 , 0)T by solving the above optimization problem . Thus , we can forecast that the real world market share of p4 as ( 10 % , 40 % , 5%)· Θ = 3078 %
In Section 6 , we will show that we can estimate the probability vector Θ with high accuracy if we know the model set and the market share of a small number of products , based on which , we can find products with higher market share .
4 . EXACT ALGORITHM AND HARDNESS Let us first present the exact algorithm for solving a special case of the k MMP problem when k = 1 . This will serve as the foundation of our approximation algorithm in Section 5 . Then we prove the NP hardness of the k MMP problem when k≥ 2 . 4.1 Exact Top 1 Algorithm
One way to find the exact solution of the 1 MMP problem is via exhaustive search : Calculate the expected market share for all candidate products in PN and select the product with the largest market share . To calculate the expected market share of a product , we need to check the requirement vectors of all l consumers and the quality vectors of their satisfactory products with time complexity O(mld ) , where m is the number of existing products and d is the dimension of the attribute vector A . Assume that we consider a model set S consisting of m potential product adoption models . Since there are n candidate products , the computational complexity of the exhaustive search is O(mmnld ) .
In the following , we present an enhanced algorithm for the 1 MMP problem based on precomputation . This enhanced algorithm has a lower computational complexity , or O(m(m+n)ld ) . The pseudo code of this algorithm is shown in Algorithm 1 .
Algorithm 1 : Exact top 1 algorithm Input : PE,PM ,PN ,C , S , Θ Output : 1 MMP for all model t in S do dmaxt [ i ] ← di,j where pj ∈ FP(ci|PE ) ; et[i ] ← |FP(ci|PE)| ; mt[i ] ← |FP(ci|PE ) ∩ PM| ; end max increase ← 0 ; for all pj ∈ PN do for all ci ∈ PC(pj ) under each model t in S do
∆sales t(pj ) ← 0 ; if d(i , j ) > dmaxt [ i ] then
∆sales t(pj ) ← ∆sales t(pj ) + ( 1 − mt[i ] et[i ] ) ; else if d(i , j ) = dmaxt [ i ] then
∆sales t(pj ) ← ∆sales t(pj)+( mt[i]+1 et[i]+1 − mt[i ] et[i ] ) ; end ∆Sales(pj ) ← θ1∆sales 1(pj ) + . . . + θm ∆sales m ( pj ) if ∆Sales(pj ) > max increase then res ← pj ; max increase ← ∆Sales(pj ) ; end end return res
Lemma 1 . The computational complexity of Algorithm 1 is O(m(m + n)ld ) , where m = |S| , m = |PE| , n = |PN| , l =|C| , d =|A| .
Proof . Firstly , it takes O(d ) time to calculate the distance for each pair of consumer and product under each adoption model , while there are l consumers , m existing products , and m product adoption models , so it takes O(mmld ) in total . Then , for each product pj ∈ PN , we calculate the increase of sales caused by adding pj , which takes O(mld ) time . Since there are n candidate new products , the complexity of these steps is O(mnld ) . Therefore , the total computational complexity of Algorithm 1 is O(m(m+n)ld ) . 4.2 Top k Exact Algorithm
Similarly , exhaustive search is a direct approach to find the exact solution of the k MMP problem . By enumerating all possible subsets of size k from PN , and calculating the expected market share of each subset , one can find the set of product with size k which achieves the largest market share . However , the exhaustive approach is not scalable since there exist exponentially many possible subsets . In the following theorem , we formally show that finding the exact solution of the k MMP problem is NP hard .
Theorem 1 . Finding the exact solution for the k MMP selection problem is NP hard when k ≥ 2 and the number of attributes is d ≥ 3 .
Proof . Please refer to the appendix .
5 . APPROXIMATION ALGORITHM
In this section , we extend the top 1 algorithm for the k MMP problem using a greedy based approximation algorithm . The algorithm is not only computationally efficient , but also provide at least ( 1−1/e) approximation by exploiting that the market share function is monotone and submodular . In the following , let us first present our approximation algorithm . Then we formally prove its performance guarantee , and finally prove that the market share function we consider is indeed monotone and submodular . 5.1 Greedy based Approximation Algorithm Our approximation algorithm is based on the exact top 1 algorithm to solve the top k problem . The main idea is as follows . We select k products in k steps . In each step , we select the product which is the solution of the exact top 1 algorithm . Furthermore , instead of building the farthest product tables at each step , we only build them in the first step , and then update the tables in the remaining steps . The pseudo code of this algorithm is depicted in Algorithm 2 .
Algorithm 2 : Approximation top k algorithm Input : PE,PM ,PN ,C , S , Θ , k Output : k MMP Pres ← ∅ ; while |Pres| < k do pnew ← solution of the exact top 1 algorithm ; for ci ∈ PC(pnew ) under each model t in S do fd t[i ] ← d(i , new ) , et[i ] ← 1 , mt[i ] ← 1 ; et[i ] ← et[i ] + 1 , mt[i ] ← mt[i ] + 1 ; else if d(i , new ) = fd t[i ] then if d(i , new ) > fd t[i ] then end Pres ← Pres ∩ {pnew} ; PM ← PM ∪ {pnew} ; PN ← PN \ {pnew} ; end return Pres
Theorem 2 . ( Computational complexity ) The computational complexity of Algorithm 2 is O(m(m + kn)ld ) , where m = |S| , m =|PE| , n =|PN| , l =|C| , d =|A| .
Proof . Based on Lemma 1 , it takes O(mmld ) time to build these farthest product tables and O(mnld ) time to find the exact solution of 1 MMP . The complexity of updating tables is only O(ld ) . Since we only build the tables once and find the 1 MMP k times in Algorithm 2 , the computational complexity of Algorithm 2 is ( m(m + kn)ld ) .
5.2 Guarantee on Solution Quality
To prove the performance guarantee of our approximation algorithm , let us first introduce the notion of “ submodular set function ” [ 11 ] .
Definition 4 . ( Submodular set function ) Given a finite ground set U , a function f that maps subsets of U to real numbers is called submodular if f ( S ∪{u})−f ( S)≥ f ( T ∪{u})−f ( T ) , ∀S⊆ T⊆ U , u∈ U . ( 7 )
Next , we show one interesting property of submodular set functions [ 5 ] , based on which we design our approximation algorithm with theoretical performance guarantee .
Theorem 3 . For a non negative monotone submodular function f : 2U → R , let S⊆ U be the set of size k obtained by selecting elements from U one at a time , each time choosing the element that provides the largest marginal increase in the function value . Let S∗⊆ U be the set that maximizes the value of f over all k element sets . Then we have f ( S ) ≥ ( 1− 1/e ) · f ( S∗ ) . In other words , S provides a ( 1− 1/e)approximation , or guarantees a lower bound on the quality of solution as compared to the optimal solution .
Applying to the k MMP problem , the ground set is PM∪ PN , the market share function MS ( · ) defined in Section 2 maps subsets of PM∪PN to real numbers , ie , the expected market share of products . According to Theorem 3 , if we can prove that MS ( · ) is a non negative monotone submodular set function , then our approximation Algorithm 2 can provide a ( 1− 1/e) approximation . We leaves the proof of these properties in the next subsection , and once we prove them , we have the following theorem .
Theorem 4 . ( Performance guarantee ) The approximation algorithm stated in Algorithm 2 provides at least ( 1− 1/e) approximate solutions compared with the optimal ones , where e is the base of the natural logarithm .
Proof . According to Theorem 5 , which will be proved in the following sub section , the market share function MS ( · ) in Equation ( 3 ) is non negative , monotone submodular . So , according to Theorem 3 , Algorithm 2 provides ( 1− 1/e)approximate solutions . 5.3 Submodular Market Share Function Let us consider the market share function MS ( · ) defined in Section 2 . According to the definition of MS ( · ) , it is obviously non negative , so we seek to prove the monotonicity and submodularity properties . For the ease of presentation , we define the following notations . For any set S ⊆ PM ∪PN of products , let PS =PE∪ S and Sj = S∪{pj} , let pr i(S ) = pj∈S Pr(i , j|PS ) denote the probability of the consumer ci adopting products in S when a set PS of products is available in the market . Furthermore , when a set P of products is available in the market , we define FC(pj|P ) as the set of consumers that pj is their farthest product , and recall that FP(ci|P ) is the set of farthest products from ci . One key fact we use in our proof is that by adding a new product , say pu , only those consumers in FC(pu|Pu ) will change their product adoption decisions . Therefore , to calculate the change of market share caused by adding pu , we only need to consider the consumers in FC(pu|Pu ) . Mathematically , we have the following proposition .
Proposition 1 . Let PS be the set of products in the market , by adding a new product pu into the market , pu∈PN\PS , the increase of the market share of products in Su is [ pr i(Su ) − pr i(S ) ] .
MS ( Su ) − MS ( S ) =
( 8 )
1 l ci∈FC(pu|Su )
Based on Proposition 1 , we now proceed to prove the monotonicity and submodularity of the market share function MS ( · ) . First , we prove two lemmas ( Lemma 2 and 3 ) . Based on these two lemmas , we prove the monotonicity and submodularity properties in Theorem 5 .
Lemma 2 . Let S ⊆ PM ∪ PN be a set of products , and pu be another product in PN , pu ∈ PN\S . For a consumer ci∈C , if ci ∈ FC(pu|PSu ) , then we have pr i(Su ) − pr i(S ) ≥ 0 . Proof . Please refer to the appendix . Lemma 3 . Let S and T be two sets of products , S ⊆ T ⊆ PM∪PN , and pu be another product in PN , pu∈PN\T . For a consumer ci∈C , if ci∈ FC(pu|PTu ) , then we have
( 9 ) pr i(Su ) − pr i(S ) ≥ pr i(Tu ) − pr i(T ) .
( 10 )
Proof . Please refer to the appendix .
Theorem 5 . Suppose consumers adopt products following the distance based adoption model , then the market share function MS ( · ) defined in Equation ( 3 ) is monotone submodular for the k MMP problem .
Proof . We prove the monotonicity property first . To prove the monotonicity property , we need to show MS ( Su ) − MS ( S ) ≥ 0 ∀S ⊆ PN ∪ PM , pu ∈ PN
( 11 ) holds , which can be proved by combining the results of Proposition 1 and Lemma 2 .
To prove the submodularity property , according to Defi nition 4 , we need to show
MS ( Su ) − MS ( S ) ≥ MS ( Tu ) − MS ( T )
( 12 ) holds ∀S⊆ T ⊆PN ∪PM and pu∈PN . In the case of pu∈ S , Inequality ( 12 ) holds since both sides are equal to 0 . In the case of pu ∈ T \ S , the right side of the inequality equals 0 , while according to the monotonicity , which has been proved , the left side is non negative . Hence Inequality ( 12 ) also holds . In the case of pu ∈ PN \ T , Inequality ( 12 ) can be easily proved by combining the results of Proposition 1 and Lemma 3 . Thus , Inequality ( 12 ) holds ∀S⊆ T ⊆PN ∪PM and pu∈PN .
6 . EXPERIMENTS
We perform experiments on both synthetic datasets and real world web datasets . We implement our approximation algorithm and the exhaustive search algorithm in C++ and perform experiments on a PC with a 16 core 2.4GHz CPU , 30 GB of main memory under the 64 bit Debian 60 First , we use synthetic datasets to evaluate the computational efficiency and accuracy of our approximation algorithm . Then we apply our algorithm on the real world web datasets to show the impact of different distance metrics , and how to learn distance metrics from some historical sales data and to perform product selection .
6.1 Speedup and Accuracy
We generate the synthetic datasets using the generator provide by [ 1 ] . In a real world market , products usually do not have high quality on all attributes . Instead , they have high quality on some subset of attributes only . For example , a smart phone with a large screen will have high quality on display but low quality on portability . Furthermore , if a product has high quality on most attributes , then the price of this product will be high in general , which indicates low quality on the price attribute . We generate the datasets of products with negative correlation on attributes : Products which have high quality in one attribute tends to have low quality on at least one other attribute . On the other hand , we generate the consumers’ requirement of each attribute independently using a uniform distribution .
We compare the running time and the market share between our approximation algorithm ( or greedy ) and the exhaustive search algorithm ( or exh ) . We examine the impact of various factors , including the size of datasets ( n , m , l , d ) , the number of new products we need to select ( k ) , and models using different distance metrics ( four distance metrics as introduced in Section 2 ) . The default settings of these parameters are : m = 100 , n = 20 , l = 10 , 000 , d = 10 , k = 2 . The computational efficiency and accuracy our experiments are similar under all distance models , so we only show the results for the norm distance metric .
Note that both the running time of our approximation algorithm and the exhaustive algorithm increases linearly with m , l , and d , due to the page limit , we only show the results of varying k and n while keeping other parameters as default values . Table 2 shows the speedup of our approximation algorithm over the exhaustive algorithm . Figure 2 shows the running time of these two algorithms , where the horizontal axis depicts the variation on parameters n ( number of candidate products we need to consider ) and k ( number of products we need to select ) , while the vertical axis depicts the log scale of the running time , in seconds .
From the table and the figure , one can observe that our approximation algorithm is significantly faster than the exhaustive algorithm : O(nk ) times faster when selecting k products from n candidate products . The speedup is around 285,000 even for a small dataset ( ie , select k = 5 products from n = 20 candidates ) . In this case , the running time of exhaustive algorithm is around 40 hours . In the case of selecting five products from n = 80 candidates , our conservative estimate on the running time of the exhaustive algorithm is about 10 years . In contrast , the running time of our approximation algorithm for all cases remain in less than one second . We also test our approximation algorithm on a larger dataset where m = 1 , 000 , n = 100 , l = 1 , 000 , 000 . We select k = 8 new products from the 100 candidates . Our approximation algorithm still only takes about 7 minutes .
Figure 3 depicts the expected market share of the two algorithms . One can observe that our approximation algorithm provides high accuracy : about 0.96 approximation on average as compared with the optimal solution obtained using the exhaustive algorithm . This shows that our algorithm generates results which is much better than the theoretical lower bound guarantee . In fact , the results of the two algorithms are exactly the same for over 80 % of all experiments we performed and our approximation algorithm still provides a 0.82 approximation even under the worst case scenario among all experiments . k = 2 65.89 256.62 535.29 915.38 n = 20 n = 40 n = 60 n = 80 k = 5 k = 4 k = 3 1160.37 18799.17 285804.08 287626.53 ≈ 1×107 8111.76 ≈ 5×107 26511.67 ≈ 1×106 57812.33 ≈ 4×106 ≈ 2×108
Table 2 : Speedup : varying k and n greedy exh
20
40
60
80 n
( a ) varying n greedy exh time(s )
102
101
100 time(s )
104
102
100
2
3
4
5 k
( b ) varying k
Figure 2 : Running time : greedy vs . exh greedy exh
20
40
60
80
( a ) varying n greedy exh
MS
4
3
2
MS 5
4
3
2
2
3
4
5
( b ) varying k
Figure 3 : Market share ( % ) : greedy vs . exh
6.2
Impact of Distance Metrics
In this subsection , we perform experiments on a real world web dataset , and we aim to show the influence of using different distance metrics .
We extract the TripAdvisor dataset from [ 15 ] . Hotels and reviewers of these hotels are considered as products and consumers respectively in this dataset . The reviewers rated hotels on seven attributes : value , room , location , cleanliness , front desk , service , and business service . We use the average rating of an attribute as the quality of that attribute for each hotel . We also add the inverse of the average price of the hotel as the eighth attribute , which is normalized in the range of ( 1 , 5 ) . For each consumer , we extract requirement vector as follows . Let ¯r be the average rating of a hotel ’s attribute and ri be the rating from the consumer ci . If ri is lower than ¯r , it means that ci has a higher requirement than average , and if ri is higher than ¯r , ci may have a lower requirement than the average . Thus , we set the requirement of ci as ¯r +(¯r−ri ) . For example , if ¯r = 3.5 and ri = 4 , then the requirement of ci will be 35+(35−4 ) = 3 . Table 3 shows the overall statistics of the dataset .
# of products # of consumers # of attributes
1,605
186,249
8
Table 3 : Parameters of our web datasets
We select the first 605 hotels as the candidate products and set the remaining 1000 hotels as the existing products . We apply our approximation algorithm to solve the 2 MMP problem using the four distance metrics introduced in Section 2 : discrete metric ( DM ) , norm metric ( NM ) , price metric ( PM ) , and richman metric ( RM ) . The results are shown in the first four rows of the second column in Table 4 . One can observe that the results vary greatly when we use different distance metrics . This implies the importance of inferring and understanding consumers’ adoption behavior . distance metrics
DM NM PM RM ˆΘ
ID of selected products 214 , 566 284 , 214 566 , 350 284 , 214
566 , 284 market share of selected products
32.33 % 11.20 % 35.43 % 11.20 %
38.09 %
Table 4 : Results of the 2 MMP problem
6.3 Learning Distance Metrics
In the following , we evaluate the accuracy of our learning method using the same dataset in the last subsection . Since we do not have the information about products’ real world market share and consumers’ adoption models , we manually set the probability ˆΘ that consumers use the above four distance metrics . Then we randomly set the distance metric for each consumer according to ˆΘ and estimate the “ realworld market share ” by enumerating each consumer ’s choice . We estimate the probability as Θ using the learning method in Section 3 and compare the normalized root mean square error ( NRMSE ) between Θ and ˆΘ to evaluate the accuracy of our learning method . Note that NRMSE ranges in ( 0 , 1 ) and lower value implies higher accuracy .
We present the experimental results in the case that ˆΘ = ( 0.1 , 0.2 , 0.6 , 0.1)T and the “ real world market share ” of a set P E of five products are known . Firstly , we calculate the expected market share of these products under all the four potential models . The results are shown in Table 5 along with the “ real world market share ” .
ID 91 500 517 746 350
DM NM PM RM real world 0.21 0.40 1.30 1.07 0.68
2.93 0.27 13.75 1.87 2.64
0.13 0.14 49.83 0.79 1.09
0.13 0.07 25.38 11.40 1.09
4.81 0.33 2.10 0.81 3.80
Table 5 : Market share ( % )
Then , by solving the following optimization problem , we can estimate Θ = ( 0.1084 , 0.1979 , 0.5953 , 0.0984)T . One can observe that Θ is very close to ˆΘ ( NRMSE ≈ 0.0099 ) , which indicates a high accuracy of the estimation . flflflflflflflflfl
2
2
Minimize flflflflflflflflfl
0.21%θ1 0.40%θ1 1.30%θ1 1.07%θ1 0.70%θ1
0.13%θ2 0.14%θ2 49.83%θ2 0.79%θ2 0.15%θ2
4.81%θ3 0.33%θ3 2.10%θ3 0.81%θ3 1.68%θ3
0.13%θ4 −2.93 % 0.07%θ4 −0.27 % 25.38%θ4 −13.75 % 11.40%θ4 −1.87 % 0.15%θ4 −2.64 % subject to Θ ≥ 0 ,
θ1 + θ2 + θ3 + θ4 = 1 .
Based on the derived probability Θ , one can forecast the market share of products and make a better product selection decision . The result of the 2 MMP problem in this scenario is shown in the last row of Table 4 . For the selected products under each adoption model in Table 4 , we estimate the “ real world market share ” and list the result in the last column . One can observe that , the product selection result based on learning the proper weighting of distance metrics achieves a better market share than other distance metrics . E of products that we know the market share and examine the NRMSE . The results are shown in Figure 4 , where the vertical axis is the NRMSE of the estimation , the horizontal axis of ( a ) is n which is the size of P E , and the horizontal axis of ( b ) is the average variance σ2 of the expected market share of products in P E under different models when n = 5 and n = 20 .
We also select different sets P
One can observe that our estimation maintains a high accuracy in general . The average accuracy is about 0.035 even in the case that we only know the market share of five products . Furthermore , the accuracy increases exponentially fast when the size of P E increases . On the other hand , product sets with larger σ2 have higher accuracy , which is realistic since if the market share varies slightly under different models , it may be difficult to estimate .
Due to the page limit , we only present the above example . We like to note that our results and conclusions are consistent when we vary ˆΘ , model set , or any other parameters .
7 . RELATED WORK Product selection : Let us provide some related work on product selection . In [ 6 ] , authors formulated a number of microeconomic applications as optimization problems via data mining perspective . Inspired by [ 6 ] , Li et al . [ 7 ] extended
¯σ2=0.0012
10−1 guarantee , this results has found applications in a number of areas , eg , discrete optimization [ 10 ] , materialized view [ 4 ] , and influence maximization [ 5 ] .
E S M R N
E S M R N
10−2
10−3
5
35
20 ( a ) varying n
50 n n = 5 n = 20
10−1
10−2
10−3
8 . CONCLUSIONS
In this work , we present the problem of finding the k most marketable products ( k MMP ) under a distance based adoption model . Our adoption model is general in that we can use different distance metrics to describe various consumers’ adoption behaviors . Given some historical data sets on market share , we propose a learning method to select the appropriate distance metrics to describe consumers’ production adoption behavior . We prove that the k MMP problem is NP hard when k≥ 2 and the number of products’ attributes , d , is three or more . We propose a polynomial time approximation algorithm to solve the k MMP problem . Using the submodularity analysis , we formally prove that our approximation algorithm can guarantee a ( 1−1/e)approximation as compared to the optimal solution . We compared our approximation algorithm with the exhaustive search algorithm on the synthetic datasets . The results showed that our approximation algorithm can achieve O(nk ) times speedup when selecting k products from n candidates . Furthermore , the solution quality of our algorithm is about 96 % on average , which is much higher than the theoretical lower bound . We also perform experiments on the real world web datasets to show the crucial impact of different distance metrics and how we can improve the accuracy of product selection using our distance metric selection method .
9 . ACKNOWLEDGMENTS
The work of John CS Lui is supported in part by the
GRF Grant 415112 .
10 . REFERENCES [ 1 ] S . Borzsony , D . Kossmann , and K . Stocker . The skyline operator . In ICDE , pages 421–430 , 2001 .
[ 2 ] G . Cornuejols , M . L . Fisher , and G . L . Nemhauser .
Location of bank accounts to optimize float . Management science , 23(8):789–810 , 1977 .
[ 3 ] P . E . Gill , W . Murray , and M . H . Wright . Practical optimization . 1981 .
[ 4 ] V . Harinarayan , A . Rajaraman , and J . D . Ullman .
Implementing data cubes efficiently . In ACM SIGMOD Record , volume 25 , pages 205–216 . ACM , 1996 .
[ 5 ] D . Kempe , J . Kleinberg , and ´E . Tardos . Maximizing the spread of influence through a social network . In KDD , pages 137–146 , 2003 .
[ 6 ] J . Kleinberg , C . Papadimitriou , and P . Raghavan . A microeconomic view of data mining . Data mining and knowledge discovery , pages 311–324 , 1998 .
[ 7 ] C . Li , B . C . Ooi , A . K . Tung , and S . Wang . Dada : a data cube for dominant relationship analysis . In SIGMOD , pages 659–670 , 2006 .
[ 8 ] C Y Lin , J L Koh , and A . L . Chen . Determining k most demanding products with maximum expected number of total customers . In TKDE , pages 1732–1747 , 2012 .
[ 9 ] X . Lin , Y . Yuan , Q . Zhang , and Y . Zhang . Selecting stars : the k most representative skyline operator . In ICDE , pages 86–95 , 2007 .
10−6 10−5 10−4 10−3 10−2
σ2
( b ) varying σ2
Figure 4 : Accuracy of distance metric learning the concept of dominance , which is used as skyline operators [ 1 ] to analyze various forms of relationships between products and consumers . A manufacturer can position popular products effectively while remaining profitable by analyzing the dominance relationships . The works in [ 16 , 14 , 13 , 12 ] considered the situation that there exist multiple manufacturers . The authors of [ 16 ] derived the Nash Equilibrium when each manufacturer modifies its product in a round robin manner to maximize the market share . Wan et al . [ 14 ] aimed to find the most competitive products which are not dominated by any competitors without taking into account the consumers . They extended their work in [ 13 , 12 ] by considering the consumers’ preferences . However , the above papers all aimed to maximize the number of potential consumers , which is not equivalent to the market share derived in this paper . In fact , potential consumers may not lead to higher market share because different consumers have different probability to adopt new products . Authors in [ 8 ] aimed to find the products with the maximum expected number of total adopters , which is similar with the market share in our paper . But their algorithm could not provide any theoretical performance guarantee . Furthermore , none of the previous works consider the complicated product adoption behavior of consumers . Instead , they assumed that consumers will make randomly product adoption decisions , which corresponds to a special case of our product adoption model using the discrete norm . Maximization of submodular functions : Submodular functions have properties which are very similar to the convex and concave functions . The authors of [ 2 , 11 ] showed that a natural greedy hill climbing strategy can achieve a provable performance guarantee for a problem of maximizing a non negative monotone submodular function : at least 63 % of optimal . Due to the generality of this performance
[ 10 ] G . L . Nemhauser and L . A . Wolsey . Integer and combinatorial optimization , volume 18 . Wiley New York , 1988 .
[ 11 ] G . L . Nemhauser , L . A . Wolsey , and M . L . Fisher . An analysis of approximations for maximizing submodular set functions I . Mathematical Programming , pages 265–294 , 1978 .
[ 12 ] Y . Peng , R . C W Wong , and Q . Wan . Finding top k preferable products . In TKDE , pages 1774–1788 , 2012 .
[ 13 ] Q . Wan , R . Wong , and Y . Peng . Finding top k profitable products . In ICDE , pages 1055–1066 , 2011 . [ 14 ] Q . Wan , R . C W Wong , I . F . Ilyas , M . T . ¨Ozsu , and
Y . Peng . Creating competitive products . In VLDB , pages 898–909 , 2009 .
[ 15 ] H . Wang . http://timescsuiucedu/~wang296/Data
[ 16 ] Z . Zhang , L . V . S . Lakshmanan , and A . K . H . Tung .
On domination game analysis for microeconomic data mining . In TKDD , pages 18:1–18:27 , 2009 .
APPENDIX • Proof of Theorem 1 :
Proof . The NP hardness proof can be achieved by transforming an NP hard problem , called the top k Representative Skyline Product ( top k RSP ) [ 9 ] , to a special case of the k MMP problem .
Let us state the top k RSP [ 9 ] . Given a set U of points and a positive integer k , compute a set S of k skyline points such that the number of points dominated by these k points is maximized . A point p = ( p[1 ] , p[2 ] , . . . , p[d ] ) dominates another point q = ( q[1 ] , q[2 ] , . . . , q[d ] ) iff p[i ] ≥ q[i ] ∀1 ≤ i ≤ d and there exists at least one dimension k such that p[k ] > q[k ] , and we denote this as p q . Consequently , the skyline point is defined as follows . Given a set U of points , the skyline points of U are the set of S ⊆ U points which are not dominated by any points in U .
Given an instance of top k RSP problem , we construct an instance of k MMP problem , which can be carried out as follows . Set PE = ∅ , ie , m = 0 . Let PN be the set of skyline points in U , and C be the rest , ie , C = U\PN . Note that in general , the concept of dominance is different from product satisfiability as stated in Definition 1 . Formally , we have pj ci ⇒ pj ci , but pj ci ( cid:59 ) pj ci . However , if pj ci but pj ci , then the quality vector of pj is exactly the same with the requirement vector of ci , ie , pj and ci have the same location in the d dimensional space . But in our construction , the product points are skyline points while the consumer points are not , so there does not exist such kind of ci and pj pairing in our construct . Therefore , we can treat dominance and product satisfiability to be the same in this instance . Let P be the set of k products we select from PN . In this case , since there is no existing product , so if a consumer has any satisfactory product in P , the consumer will adopt one unit of products in P , otherwise , 0 . As a result , the expected number of adopters is equal to the number of consumers who have satisfactory products in P . In another word , MS ( P ) is equal to the total number of points dominated by the skyline points in P divide by the total number of non skyline points . Since the total number of non skyline points is fixed , the result of the corresponding top k RSP problem is also the result of this instance of the k MMP problem .
Therefore , any instance of the top k RSP problem can be transformed to an instance of the k MMP problem . Since the top k RSP problem has been proved to be an NP hard problem , the k MMP problem is also NP hard . • Proof of Lemma 2 :
Proof . To simplify the proof , we define the following notations . Let σ = |FP(ci|PSu )| and s = |FP(ci|PSu )|∩Su| , where σ≥ s≥ 1 . Let d = di,j where pj ∈ FC(ci|PS ) . Since ci∈ FC(pu|PSu ) , we have di,u ≥ d . If di,u > d , then ci will adopt pu with probability 1 , ie , pr i(Su ) = 1 . While pr i(S ) ≤ 1 , so Inequality ( 9 ) holds . If di,u = d , then FP(ci|PSu ) = FP(ci|PS)∪{pu} , so |FP(ci|PS)| = σ−1 . Similarly , we have |FP(ci|PS ) ∩ S| = s−1 . When σ = 1 , FP(ci|PS ) is an empty set , which means pu is ci ’s only choice , the situation is the same with the case of di,u = d . So we only need to consider the case when σ > 1 . Bring the notations into Inequality ( 9 ) , we have pr i(Su ) − pr i(S ) =
− s − 1 σ − 1 s σ
=
σ − s σ(σ − 1 )
≥ 0 ,
( 13 ) which can be proved by observing that σ≥ s and σ > 1 . • Proof of Lemma 3 :
Proof . Because Su⊆ Tu , pu has more competitors when a set Tu of products is available in the market . As a result , FC(pu|Tu ) ⊆ FC(pu|Su ) . Since ci ∈ FC(pu|Tu ) , we have ci ∈ FC(pu|Su ) . Follow the same notations in the proof of Lemma 2 , let us consider the case of σ = 1 first . In this case , pr i(Su ) = 1 , pr i(S ) = 0 , so the left side of Inequality ( 10 ) equals to 1 . While the right side of the inequality is obviously no larger than 1 , so the Inequality ( 10 ) holds . Now let us consider the case when σ > 1 . According to the proof of Lemma 2 , we have pr i(Su ) − pr i(S ) = s σ
− s − 1 σ − 1
.
( 14 )
Let dT and dS denote the distance between ci and the products in FP(ci|PT ) and FP(ci|PS ) , respectively , where di,u≥ dT ≥ dS . In the case of di,u > dS , then the left side of Inequality 10 equals to 1 , so the inequality holds . Thus , the remaining thing is to prove the inequality holds when di,u = dT = dS . In this case , FP(ci|PSu ) = FP(ci|PS)∪{pu} , FP(ci|PTu ) = FP(ci|PT )∪{pu} , and FP(ci|PS)⊆ FP(ci|PT ) . Let δ =|FP(ci|PTu )|−|FP(ci|PSu )| , then it follows that δ≥ 0 , σ+δ = |FP(ci|PTu )| , s+δ =|FP(ci|PTu )∪Tu| . Thus we have pr i(Tu ) − pr i(T ) = s + δ σ + δ
− s + δ + 1 σ + δ + 1
.
( 15 )
According to Equation ( 14 ) and ( 15 ) , we can derive Inequality ( 10 ) as follows .
Inequality ( 10 ) holds
− s − 1 − s + δ − 1 ⇔ s ≥ s + δ σ − 1 σ + δ − 1 σ + δ σ ⇔ σ − s σ − s ≥ σ(σ − 1 ) ( σ + δ)(σ + δ − 1 )
( 16 )
Hence , we only need to show that Inequality ( 16 ) holds , which can be proved by observing that σ > 1 , δ ≥ 0 and σ≥ s .
