Efficient Multi Task Feature Learning with Calibration
1Center for Evolutionary Medicine and Informatics , The Biodesign Institute , ASU , Tempe , AZ 85287
Pinghua Gong1,2 , Jiayu Zhou1,2 , Wei Fan3 , Jieping Ye1,2
2Department of Computer Science and Engineering , ASU , Tempe , AZ 85287
3Huawei Noahʼs Ark Lab , Hong Kong , China
1,2{pinghua.gong , jiayu.zhou , jiepingye}@asuedu , 3davidfanwei@huaweicom
ABSTRACT Multi task feature learning has been proposed to improve the generalization performance by learning the shared features among multiple related tasks and it has been successfully applied to many real world problems in machine learning , data mining , computer vision and bioinformatics . Most existing multi task feature learning models simply assume a common noise level for all tasks , which may not be the case in real applications . Recently , a Calibrated Multivariate Regression ( CMR ) model has been proposed , which calibrates different tasks with respect to their noise levels and achieves superior prediction performance over the noncalibrated one . A major challenge is how to solve the CMR model efficiently as it is formulated as a composite optimization problem consisting of two non smooth terms . In this paper , we propose a variant of the calibrated multi task feature learning formulation by including a squared norm regularizer . We show that the dual problem of the proposed formulation is a smooth optimization problem with a piecewise sphere constraint . The simplicity of the dual problem enables us to develop fast dual optimization algorithms with low per iteration cost . We also provide a detailed convergence analysis for the proposed dual optimization algorithm . Empirical studies demonstrate that , the dual optimization algorithm quickly converges and it is much more efficient than the primal optimization algorithm . Moreover , the calibrated multi task feature learning algorithms with and without the squared norm regularizer achieve similar prediction performance and both outperform the non calibrated ones . Thus , the proposed variant not only enables us to develop fast optimization algorithms , but also keeps the superior prediction performance of the calibrated multi task feature learning over the non calibrated one .
Categories and Subject Descriptors H28 [ Database Management ] : Database Applications— Data Mining
Keywords Multi task learning ; feature selection ; calibration ; dual problem ; accelerated gradient descent
1 .
INTRODUCTION
Multi task feature learning aims to improve the generalization performance by learning multiple related tasks together and exploring the shared features among tasks . It has received a lot of interests and has been successfully applied to a wide range of applications including gene data analysis [ 18 ] , breast cancer classification [ 34 ] , neural semantic basis discovery [ 21 ] and disease progression prediction [ 36 , 37 ] . Most existing multi task feature learning models can be formulated as a regularized optimization problem and they usually focus on how to design a good regularizer to capture the underlying shared features among tasks ; examples include group lasso multi task feature learning [ 1 , 19 , 23 , 25 , 29 , 33 , 34 ] , tree guided group lasso multi task feature learning [ 18 ] , composite regularized multi task feature learning [ 14 , 16 ] and non convex regularized multi task feature learning [ 13 , 15 ] .
However , most existing multi task feature learning models simply assume a common noise level for all tasks , which may not hold in real applications . Moreover , theoretical analysis in Lounici et al . [ 26 ] shows that , to achieve the optimal parameter estimation error bounds , the regularized parameter should be chosen in proportion to the maximum standard deviations of the noise for all tasks . In practice , the standard deviations of the noise are unknown or very difficult to estimate , which makes the parameter tuning quite challenging . To this end , Liu et al . [ 22 ] propose a Calibrated Multivariate Regression ( CMR ) model which calibrates each task by employing different noise levels for all tasks and achieve superior prediction performance over the non calibrated one . Moreover , their theoretical analysis shows that the CMR model can achieve the optimal parameter estimation error bounds by properly tuning the regularized parameter which does not depend on the standard deviations of the noise for all tasks . This makes the parameter tuning of the CMR model much more insensitive to the noise levels . However , one major challenge in the practical use of the CMR model is that it is formulated as a composite optimization problem consisting of two non smooth terms , which makes the optimization problem challenging to solve .
In this paper , inspired by the great success of the elastic net [ 38 ] , we propose a variant of the calibrated multi task feature learning formulation by including a squared norm regularizer . The major contributions of this paper include :
( 1 ) We show that the dual problem of the proposed formulation is a smooth optimization problem with a piecewise sphere constraint . ( 2 ) The simplicity of the dual problem enables us to develop fast dual optimization algorithms with low per iteration cost . ( 3 ) We provide a detailed convergence analysis for the proposed algorithm . ( 4 ) Experimental results demonstrate that , the dual optimization algorithm quickly converges and it is much more efficient than the primal optimization algorithm . Moreover , the calibrated multi task feature learning algorithms with and without the squared norm regularizer achieve similar prediction performance and both outperform the non calibrated ones . These results demonstrate that the proposed variant not only enables us to develop fast optimization algorithms , but also keeps the superior prediction performance of the calibrated multi task feature learning over the non calibrated one .
The rest of the paper is organized as follows : We introduce preliminaries in Section 2 . We propose a variant of the multi task feature formulation and develop fast optimization algorithms in Section 3 . We report experimental results in Section 4 and we conclude in Section 5 .
2 . PRELIMINARIES
Assume that we are given m learning tasks associated with the data {(X1 , y1),··· , ( Xm , ym)} and a linear model : yi = Xiw⋆ i + ǫi , i ∈ {1 , · ·· , m} , where Xi ∈ Rni×d is the data matrix and yi ∈ Rni is the response vector for the i th task , respectively ; w⋆ i ∈ Rd is the underlying true weight and ǫi ∈ Rni is the noise vector for the i th task , respectively ; each entry of ǫi is sampled from the normal distribution with mean zero and standard deviation σi . The ordinary ( non calibrated ) multi task feature learning model is formulated as the following problem :
W∈Rd×m( mXi=1 min kXiwi − yik2 + λr(W ) ) ,
( 1 ) where k · k is the Euclidean norm ; W = [ w1,·· · , wm ] ∈ Rd×m is the weight matrix with the i th column wi ∈ Rd being the weight vector for the i th task ; λ > 0 is a regularized parameter ; r(W ) is a model specific regularizer ( such as group lasso , tree guided group lasso , a composite regularizer and a non convex regularizer ) . To calibrate each task by considering the different noise levels of all tasks , Liu et al . [ 22 ] propose to use the square root function [ 6 , 11 ] instead of the least squares function , resulting in the following Calibrated Multivariate Regression ( CMR ) model :
W∈Rd×m( mXi=1 min kXiwi − yik + λr(W ) ) .
( 2 )
Liu et al . following weighted regularized least squares problem :
[ 22 ] interpret the CMR model in Eq ( 2 ) as the
W∈Rd×m( mXi=1 min
1
σi√ni kXiwi − yik2 + λr(W ) ) ,
( 3 )
1 is the weight for calibrating the i th task . When where we do not have any prior knowledge on σi ’s , σi is chosen as
σi√ni
σi =
1 √ni kXiwi − yik , i ∈ {1 , ··· , m} .
( 4 )
Thus , using the weight defined in Eq ( 4 ) , the CMR model in Eq ( 2 ) calibrates different tasks via solving the weighted regularized least squares model in Eq ( 3 ) . Although the Robust Feature Selection ( RFS ) algorithm in [ 28 ] also uses a similar square root loss , it is quite different from the CMR model in Eq ( 2 ) that RFS “ calibrates ” different samples but not different tasks via the square root loss . Notice that the regularizer and the loss function in Eq ( 2 ) are usually both non smooth , which makes the optimization problem challenging to solve .
3 . FORMULATION AND EFFICIENT OP
TIMIZATION ALGORITHMS
Inspired by the great success of the elastic net [ 38 ] , we propose a variant of the calibrated multi task feature learning model by adding a squared norm regularizer as follows : min
λ2 2 kWk2 kXiwi − yik + λ1kWk1,2 +
W∈Rd×m( mXi=1 F ) , ( 5 ) where kWk1,2 = Pd j=1 kwjk with wj being the j th row F =Pm i=1Pd of W ; kWk2 ij with wij being the ( i , j) th entry of W ; λ1 , λ2 > 0 are regularized parameters . The major benefit of the proposed formulation is that we can derive a smooth dual optimization problem with a piecewise sphere constraint . The simplicity of the dual problem enables us to develop fast optimization algorithms with low per iteration cost . Moreover , the proposed variant keeps the superior prediction performance of the calibrated multi task feature learning over the non calibrated one . j=1 w2
3.1 The Dual Ascent Optimization Algorithm We first derive the dual problem of the optimization problem in Eq ( 5 ) and then present key properties of the dual problem . Finally , we propose fast algorithms to solve the dual problem and provide detailed convergence analysis accordingly . Let zi = Xiwi − yi . Then Eq ( 5 ) is equivalent to the following constrained optimization problem : min
W,z( mXi=1
F ) , λ2 2 kWk2 st zi = Xiwi − yi , i ∈ {1 , ··· , m} , kzik + λ1kWk1,2 +
( 6 )
1 , ··· , zT i=1 ni . It is easy to verify that where z = [ zT the strong duality [ 9 ] holds for the optimization problem in Eq ( 6 ) . We can write down the Lagrange function of the above problem as follows : m]T ∈ RPm
L(W , z , θ ) = kzik + λ1kWk1,2 +
λ2 2 kWk2
F mXi=1 mXi=1 m]T ∈ RPm 1 ,··· , θT
+
θT i ( Xiwi − yi − zi ) ,
( 7 ) where θ = [ θT i=1 ni with θi ∈ Rni being the Lagrange multiplier corresponding to the constraint zi = Xiwi − yi . Minimizing L(W , z , θ ) with respect to W and z , we obtain the objective function of the dual problem of
F + i ( Xiwi − yi ) )
θT mXi=1
Eq ( 6 ) as follows :
+
W ( λ1kWk1,2 + ˜D(θ ) = min zi nkzik − θT mXi=1 zi nkzik − θT
λ2 2 kWk2 i zio , i zio =fl 0 , min min where
( 8 )
( 9 ) if kθik ≤ 1 , −∞ , otherwise .
Thus , we obtain the dual problem of Eq ( 6 ) as follows : max θ D(θ ) , st kθik ≤ 1 , i ∈ {1 , ··· , m} ,
( 10 ) where the objective function is
W ( λ1kWk1,2 +
D(θ ) = min
λ2 2 kWk2
F + mXi=1 i ( Xiwi − yi ) ) .
θT
( 11 )
We show that the optimization problem in Eq ( 11 ) has nice properties which enable us to develop fast algorithms for solving the dual problem in Eq ( 10 ) .
Theorem 1 . The optimization problem in Eq ( 11 ) has a unique solution W ( θ ) . Moreover , D(θ ) is continuously differentiable and L Lipschitz continuous gradient . Specifically , the gradient of D(θ ) is ∇D(θ ) = [ (X1w1(θ ) − y1)T , ··· , ( Xmwm(θ ) − ym)T ]T , ( 12 ) where wi(θ ) is the i th column of W ( θ ) . The Lipschitz constant of ∇D(θ ) is
L = maxi∈{1,··· ,m} σ2 max(Xi )
λ2
,
( 13 ) where σmax(Xi ) is the largest singular value of Xi .
Proof . Denote the objective function of the optimization problem in Eq ( 11 ) as f ( W , θ ) = λ1kWk1,2 +
λ2 2 kWk2
F + mXi=1
θT i ( Xiwi − yi ) .
( 14 )
Obviously , f ( W , θ ) is strongly convex and coercive with respect to W . Hence , the optimization problem in Eq ( 11 ) has a unique solution W ( θ ) .
To prove the remaining part of Theorem 1 , we rewrite f ( W , θ ) in the following compact form : f ( W , θ ) = λ1kWk1,2 + where Tr(· ) denotes the trace norm and
λ2 2 kWk2
F + Tr(W T U ( θ ) ) − θT y ,
1 θ1,··· , X T mθm ] ∈ Rd×m ,
U ( θ ) = [ X T θ = [ θT y = [ yT
1 , ··· , θT 1 ,··· , yT m]T ∈ RPm m]T ∈ RPm i=1 ni , i=1 ni .
Denote g(W ) = λ1kWk1,2 +
λ2 2 kWk2 F .
( 15 )
Then we have
D(θ ) = min
W nf ( W , θ ) = g(W ) + Tr(W T U ( θ ) ) − θT yo W nTr(−W T U ( θ ) ) − g(W )o − θT y = − max = −g⋆(−U ( θ ) ) − θT y ,
( 16 ) where g⋆(· ) is the conjugate function of g(· ) . Recalling the definition of g(· ) in Eq ( 15 ) , we know that g(· ) is a proper , lower semi continuous and convex function . Thus , we have g⋆⋆(· ) = g(· ) and g⋆(· ) is also a proper , lower semicontinuous and convex function . Moreover , g(· ) is strongly convex with the parameter λ2 . Thus , by Proposition 12.60 in [ 31 ] , we obtain that g⋆(· ) is continuously differentiable and ∇g⋆(· ) is Lipschitz continuous with constant 1/λ2 . Hence , D(θ ) is continuously differentiable . Noting that W ( θ ) is the minimizer of the optimization problem in Eq ( 11 ) , we have
W ( θ ) = arg max
W and hence nTr(−W T U ( θ ) ) − g(W )o ,
−U ( θ ) ∈ ∂g(W ( θ) ) .
According to Corollary 2351 in [ 30 ] , we have −U ( θ ) ∈ ∂g(W ( θ ) ) if and only if W ( θ ) = ∇g⋆(−U ( θ) ) , which together with Eq ( 16 ) and the definition of U ( θ ) implies that
∇D(θ ) = Xs(θ ) − y
= [ (X1w1(θ))T ,·· · , ( Xmwm(θ))T ]T − y ,
( 17 ) where
X =
X1
. . .
Xm
 , s(θ ) =
∇1g⋆(−U ( θ ) )
∇mg⋆(−U ( θ ) )
 with ∇ig⋆(−U ( θ ) ) being the partial derivative of g⋆(−U ( θ ) ) with respect to the i th column of −U ( θ ) . Thus , Eq ( 12 ) immediately follows from Eq ( 17 ) . Moreover , for any θ , γ ∈ RPm i=1 ni , we have k∇D(θ ) − ∇D(γ)k = kX(s(θ ) − s(γ))k ,
Recalling that ∇g⋆(· ) is Lipschitz continuous with constant 1/λ2 , we have k∇D(θ ) − ∇D(γ)k ≤ σmax(X)ks(θ ) − s(γ)k ≤ kU ( θ ) − U ( γ)kF =
σmax(X )
σmax(X )
λ2
λ2 kX T ( θ − γ)k
σ2 max(X )
λ2
≤ kθ − γk , where σmax(X ) is the largest singular value of X . By noticing that X is a block diagonal matrix , we have k∇D(θ ) − ∇D(γ)k ≤ maxi∈{1,··· ,m} σ2 max(Xi )
λ2 kθ − γk .
That is , ∇D(θ ) is Lipschitz continuous with constant L defined in Eq ( 13 ) . fi
Remark 1 . The squared norm regularizer λ2
F in Eq ( 5 ) is critical for the establishment of Theorem 1 and hence is crucial to develop fast optimization algorithms on solving the dual problem in Eq ( 10 ) .
2 kWk2
Based on Theorem 1 , we know that the objective function of the dual problem in Eq ( 10 ) is smooth ( Lipschitz continuous gradient ) and the constraint is a piecewise sphere . Thus , we can use the framework of FISTA [ 4 , 24 , 12 , 2 ] to solve the dual problem in Eq ( 10 ) . We present the pseudo codes in Algorithm 1 . Notice that the dual problem in Eq ( 10 ) is a maximization problem . Therefore , the gradient projection step in Eq ( 20 ) and the line search criterion in Eq ( 21 ) are modified accordingly .
In Algorithm 1 , there are two critical steps . In the following , we show that both steps have closed form solutions with low cost . The first critical step is how to efficiently compute the dual objective function value D(θ ) and the gradient ∇D(θ ) , which depends on how to efficiently obtain the optimal solution W ( θ ) for the problem in Eq ( 11 ) . Next , we show how to efficiently solve the optimization problem in Eq ( 11 ) . By exploring the special structure of Eq ( 11 ) , we have for all j ∈ {1 , ··· , d} : wj ( θ ) = arg min wj fl λ2
2 kwjk2 + uj(θ)(wj )T + λ1kwjk ,
( 18 ) where wj ( θ ) , wj and uj(θ ) are the j th row of W ( θ ) , W and U ( θ ) = [ X T mθm ] , respectively . Eq ( 18 ) has the following closed form solution [ 14 , 23 ] : wj ( θ ) = arg min
1 θ1,··· , X T wj ( λ2 2 flflflflwj + wj ( 1 2flflflflwj + max0 , 1 −
= arg min
= −
1 λ2
2
2 uj ( θ ) uj ( θ )
+ λ1kwjk ) λ2 kwjk )
λ2 flflflfl λ2 flflflfl kuj ( θ)k uj ( θ ) .
λ1
λ1
+
Algorithm 1 : Accelerated Dual Ascent Algorithm i=1 ni , η0 > 0 , β > 1
Input : θ0 ∈ RPm 1 Initialize θ1 ← θ0 ; t0 ← 1 ; t1 ← 1 ; 2 for k = 1 , 2 , ··· do 3 4 5 6 7
αk ← tk−1−1 νk ← θk + αk(θk − θk−1 ) ; for j = 0 , 1 , 2,··· do tk
;
( ˜νk
ηk ← βjηk−1 ; Compute θk via gradient projection : θk = 1 )T max(1 , k ˜νk h( ˜νk 1 )T ,··· , ( ˜νk mk)T m)T ,··· , max(1,k ˜νk 1 ηk ∇D(νk ) . = ˜νk = νk + ( 20 ) m)TiT
1k ) with
( ˜νk if the following line search criterion
D(θk ) ≥D(ν k ) + ∇D(ν k)T ( θk − ν k )
ηk 2 kθk − ν kk2
− is satisfied then break ; end
( 21 ) end Compute W k ← W ( θk ) via Eq ( 19 ) ; if some convergence criterion is satisfied then
Let θ⋆ ← θk and W ⋆ ← W k ; break ;
8 9 10 11 12 13 14 15
( 19 )
16 17 end end tk+1 ←
1+√1+4t2 k
2
;
Output : θ⋆ , W ⋆
The second critical step is how to efficiently solve the gradient projection subproblem . Due to the simplicity of the piecewise sphere constraint , the gradient projection subproblem has a closed form solution in Eq ( 20 ) .
By Theorem 4.4 in [ 4 ] , we have the following result .
Theorem 2 . ( Theorem 4.4 [ 4 ] ) Let {θk} be the sequence generated by Algorithm 1 and θ⋆ be an optimal solution for the problem in Eq ( 10 ) . Then for all k ≥ 1 , we have
D(θ⋆ ) − D(θk ) ≤
2βLkθ0 − θ⋆k2
( k + 1)2
, where θ0 is the initial point ; β > 1 is the factor used in the line search ( β is defined in Algorithm 1 ) ; L is the Lipschitz constant defined in Eq ( 13 ) .
Based on Theorem 2 , we establish a convergence rate for the sequence {W k} generated by Algorithm 1 in the following theorem :
Theorem 3 . Let {W k} and {θk} be the sequences generated by Algorithm 1 , and let W ⋆ and θ⋆ be any optimal solutions for the problems in Eq ( 5 ) and Eq ( 10 ) , respectively . Then for all k ≥ 1 , we have kW k − W ⋆kF ≤ 2r βL
λ2 kθ0 − θ⋆k k + 1
.
Proof . We follow the proof of Theorem 4.1 in [ 5 ] . Denote h(z , θ ) = mXi=1nkzik − θT i zio , zk ∈ arg min z h(z , θk ) ,
( 22 )
( 23 ) where {θk} is the sequence generated by Algorithm 1 . Considering Eqs . ( 7 ) , ( 14 ) , ( 22 ) together , we have L(W , z , θk ) = f ( W , θk ) + h(z , θk ) .
( 24 )
From Algorithm 1 , we have
W k = W ( θk ) = arg min f ( W , θk ) .
( 25 )
W
By the optimality condition of Eq ( 25 ) , we have
O ∈ ∂W k f ( W k , θk ) ,
( 26 ) where O denotes the zero matrix and ∂W k f ( W k , θk ) denotes the sub differential of f ( W , θk ) with respect to W at the point W = W k . Recalling that f ( W , θk ) is strongly convex with respect to W with the parameter λ2 , which together with Eq ( 26 ) implies that for all W ∈ Rd×m f ( W , θk ) − f ( W k , θk ) ≥
λ2 2 kW − W kk2 F .
( 27 )
By Eq ( 23 ) , we have for all z ∈ RPm i=1 ni h(z , θk ) − h(zk , θk ) ≥ 0 .
( 28 )
Adding Eqs . ( 27 ) , ( 28 ) together and considering Eq ( 24 ) , we have for all W ∈ Rd×m and z ∈ RPm i=1 ni :
L(W , z , θk ) − L(W k , zk , θk ) ≥ From Eqs . ( 11 ) , ( 25 ) , we know that
λ2 2 kW − W kk2 F .
( 29 )
D(θk ) = f ( W k , θk ) .
( 30 ) Recalling that the sequence {θk} = {[(θk m)T ]T} satisfies the constraint in Eq ( 10 ) and considering Eqs . ( 9 ) , ( 23 ) , we have for all k ≥ 1 :
1 )T ,··· , ( θk h(zk , θk ) = 0 , which together with Eqs . ( 24 ) , ( 30 ) implies that
D(θk ) = L(W k , zk , θk ) .
( 31 )
Denote by ( W ⋆ , z⋆ ) as an optimal solution for the optimization problem in Eq ( 6 ) . Then by the equality constraint in Eq ( 6 ) , we have for all i ∈ {1 , ··· , m} i − yi , z⋆ = Xiw⋆ which together with Eq ( 7 ) implies that
L(W ⋆ , z⋆ , θk ) = mXi=1 kz⋆ i k + λ1kW ⋆k1,2 +
λ2 2 kW ⋆k2
F . ( 32 )
Noticing that Eq ( 32 ) attains the minimum objective function value in Eq ( 6 ) and strong duality holds for the optimization problem in Eq ( 6 ) , we have
D(θ⋆ ) = L(W ⋆ , z⋆ , θk ) ,
( 33 ) where θ⋆ is an optimal solution of the dual problem in Eq ( 10 ) . Substituting W = W ⋆ , z = z⋆ into Eq ( 29 ) and considering Eqs . ( 31 ) , ( 33 ) , we obtain
D(θ⋆ ) − D(θk ) ≥
λ2 2 kW ⋆ − W kk2 F , which together with Theorem 2 immediately implies that the inequality in Theorem 3 holds . fi
Remark 2 . In additional to FISTA [ 4 ] , we can use many other optimization algorithms to solve the dual problem in Eq ( 10 ) . For example , the SpaRSA framework [ 32 ] can be adopted to efficiently solve the dual problem . The theoretical convergence rate of SpaRSA is no better than that of FISTA . However , due to the utilization of the BarzilaiBorwein ( BB ) rule [ 3 , 32 ] , the empirical convergence performance of SpaRSA is much better than that of FISTA for solving the dual problem in Eq ( 10 ) [ see Section 42 ]
3.2 Discussion
2 kWk2
Pm a differentiable term λ2
Notice that the objective function in Eq ( 5 ) consists of F and a non differentiable term i=1 kXiwi − yik + λ1kWk1,2 . Theoretically , we can use the framework of FISTA [ 4 ] to directly solve the optimization problem in Eq ( 5 ) , achieving a convergence rate of O(1/k2 ) . If we additionally consider the strong convexity of the objective function in Eq ( 5 ) , the proximal gradient method ( PGM ) can achieve a geometrically linear convergence rate . However , both FISTA and PGM are not practical for directly solving the optimization problem in Eq ( 5 ) . Specifically , at each iteration of both FISTA and PGM , we need to solve the following proximal operator problem : min
2kW − Bk2
F + ρ mXi=1 kXiwi − yik + λ1kWk1,2! ) , W ( 1 where B ∈ Rd×m and ρ > 0 are both constant with respect to W . Obviously , solving the above proximal operator problem is as difficult as solving the original optimization problem in Eq ( 5 ) .
We can also use a similar primal smoothed optimization algorithm ( more details are provided in the Appendix A ) proposed in [ 22 ] to solve the primal problem in Eq ( 5 ) directly . One problem is that the smoothing parameter is quite challenging to tune while this parameter is crucial to the convergence performance of the SPG algorithm .
Another approach which can solve the optimization problem in Eq ( 5 ) is the Alternating Direction Method of Multipliers ( ADMM ) method [ 8 ] ( more details are provided in the Appendix B ) . One problem is that , at each step , we need to solve a Lasso problem which does not admit a closed form solution . Moreover , the penalty parameter is very hard to tune while this parameter is critical for the efficiency of the ADMM method .
A very straightforward approach to solve the optimization problem in Eq ( 5 ) is the sub gradient method [ 10 ] . In the non smooth case , the objective function value sequence {l(W k)} generated by the sub gradient method converges to the optimal value l⋆ at a rate of O(1/√k ) under certain conditions [ 10 ] , where l(W ) denotes the objective function in Eq ( 5 ) . However , this convergence rate is established without exploiting the strong convexity of the objective function l(W ) . By considering the strong convexity of l(W ) , Beck and Teboulle [ 5 ] show that the convergence rate of the objective function value has been improved from O(1/√k ) to O(ln(k)/k ) using the sub gradient method . However , the sub gradient method still converges slowly because the subgradient method is a very general method for solving nonsmooth optimization problems without exploring the special structure of Eq ( 5 ) and the step size at each step is shrinking to zero ( or the step size is a very small constant ) .
The cutting plane method [ 7 ] and the level set method [ 20 ] are another two approaches which can solve the optimization problem in Eq ( 5 ) . They can be viewed as improved methods of the sub gradient method . Similar to the sub gradient method , the cutting plane and the level set methods are general methods for solving non smooth optimization problems and do not exploit the the special structure of Eq ( 5 ) .
4 . EXPERIMENTS
In this section , we first evaluate the prediction performance of the calibrated multi task feature algorithms with and without the squared norm regularizer . Then , we present computational efficiency studies for our proposed algorithms . Matlab codes are included at MALSAR package [ 35 ] .
4.1 Prediction Performance
We include the following algorithms for comparison : ( 1 ) Calibration : the calibrated multi task feature learning formulation in Eq ( 5 ) by setting λ2 = 0 ; ( 2 ) Calibration
Table 1 : The averaged MSE ( standard deviation ) over 10 random splittings of training and test samples . Training ratio refers to the ratio of training samples to the total samples . data sets training ratio Calibration Calibration L2 LeastSquares LeastSquares L2
Synthetic
ADNI ADAS Cog
ADNI MMSE
60 % 70 % 80 % 60 % 70 % 80 % 60 % 70 % 80 %
1173(037 ) 919(043 ) 724(042 ) 3727(231 ) 3295(188 ) 2711(212 ) 2193(087 ) 1875(024 ) 1520(100 )
1180(042 ) 918(040 ) 725(042 ) 3745(224 ) 3357(221 ) 2673(172 ) 2180(097 ) 1852(039 ) 1508(112 )
1203(029 ) 1009(049 ) 828(065 ) 3892(275 ) 3419(199 ) 2738(182 ) 2363(071 ) 2026(086 ) 1653(076 )
1203(029 ) 1009(049 ) 828(065 ) 3902(281 ) 3415(198 ) 2735(175 ) 2369(071 ) 2030(087 ) 1654(078 )
Synthetic ( λ =1e−5 ) 0
Synthetic ( λ =1e−5 ) 0
P−SPG P−SFISTA P−ADMM D−PG D−FISTA OptimalObj
2000
1500
1000
500
0
−500 l e u a V n o i t c n u F e v i t c e b O j
) l a u D
( l a m i r
300
200
100
0
−100
P−SPG P−SFISTA D−PG D−FISTA OptimalObj l e u a V n o i t c n u F e v i t c e b O j
) l a u D
( l a m i r
P
−1000
0
1
2
3
CPU time ( seconds )
Synthetic ( λ =1e−6 ) 0
P
−200
0
4
0.5 1 CPU time ( seconds )
Synthetic ( λ =1e−6 ) 0
1.5
1000
500
0 l e u a V n o i t c n u F e v i t c e b O j
) l a u D
−500
( l a m i r
P
−1000
0
2
4
6
CPU time ( seconds )
P−SPG P−SFISTA P−ADMM D−PG D−FISTA OptimalObj
600
400
200
0
−200
−400
P−SPG P−SFISTA D−PG D−FISTA OptimalObj l e u a V n o i t c n u F e v i t c e b O j
) l a u D
( l a m i r
P
−600
0
8
0.2
0.4 0.8 CPU time ( seconds )
0.6
1
1.2
Figure 1 : The primal objective function value ( P SPG , P SFISTA and P ADMM ) and the dual objective function value ( D PG and D FISTA ) vs . CPU time ( seconds ) plots on the Synthetic data set . The right figures are magnified views of the left figures . The legend “ PrimalObj ” denotes the optimal primal objective i=1 ni , where ni is the number function value in Eq ( 5 ) and regularized parameters are set as λ1 = λ2 = λ0Pm of samples from the i th task .
L2 : the calibrated multi task feature learning formulation in Eq ( 5 ) by setting λ2 6= 0 ; ( 3 ) LeastSquares : the noncalibrated multi task feature learning formulation in Eq ( 1 ) by setting r(W ) = kWk1,2 ; ( 4 ) LeastSquares L2 : the noncalibrated multi task feature learning formulation in Eq ( 1 ) by setting r(W ) = kWk1,2 and adding a squared norm regularizer λ2 F . We conduct experiments on both synthetic and real world data sets which are described as follows :
2 kWk2
Synthetic Data : We adopt the similar procedure in [ 22 ] to generate the synthetic data as follows : we set the number of tasks as m = 10 and each task has ni = 100 samples which have d = 200 features ( ie , the dimensionality is d = 200 ) ; each row of the data matrix Xi ∈ Rni×d of the i th task is independently sampled from the multivariate normal distribution N ( 0 , Σ ) with σjj = 1 and σjk = 0.5 for all j 6= k , and it is normalized such that the length of each column of Xi is 1 ; each entry of the underlying ground truth matrix W ∈ Rd×m is independently sampled from the uniform distribution U ( −10 , 10 ) and then we randomly set 95 % rows of W as zero vectors ; each entry of the noise vector δi ∈ Rni is independently sampled from the normal distribution N ( 0 , σ2 i ) , where σi = 2−(i−1)/4 for i = 1,··· , m ; the response vector yi ∈ Rni of the i th task is computed by yi = Xiwi + σmaxδi , where σmax = 2√2 . Real World Data : We conduct experiments on two realworld data sets which are summarized as follows : ( I ) The Alzheimer ’s Disease Neuroimaging Initiative ( ADNI)1 is a longitudinal study aiming at identifying important neuroimaging biomarkers that are predictive of the progression of the Alzheimer ’s disease and building predictive models for prognosis of the disease . In our experiments , we use 310 MRI features from 648 patients to predict the MMSE value , which is a cognitive score that indicates the cognitive functionality of the patients . According to the medical diagnosis , there
1wwwloniuclaedu/ADNI/
ADNI ADAS−Cog ( λ =1e−5 ) 0
ADNI ADAS−Cog ( λ =1e−5 ) 0
400
350
300
250
200
150
100
50
0
P−SPG P−SFISTA D−PG D−FISTA OptimalObj l e u a V n o i t c n u F e v i t c e b O j
) l a u D
( l a m i r
P
−50
P−SPG P−SFISTA P−ADMM D−PG D−FISTA OptimalObj
5
10
15
20
0
CPU time ( seconds )
ADNI ADAS−Cog ( λ =1e−6 ) 0
0.05
0.1 CPU time ( seconds )
ADNI ADAS−Cog ( λ =1e−6 ) 0
0.15
500
400
300
200
100
0
P−SPG P−SFISTA D−PG D−FISTA OptimalObj l e u a V n o i t c n u F e v i t c e b O j
) l a u D
( l a m i r
P
−100
0
8
0.2
0.4
0.6
0.8
1
CPU time ( seconds )
P−SPG P−SFISTA P−ADMM D−PG D−FISTA OptimalObj
1000
500
0 l e u a V n o i t c n u F e v i t c e b O j
) l a u D
( l a m i r
P
−500
0
1000
500
0
−500 l e u a V n o i t c n u F e v i t c e b O j
) l a u D
( l a m i r
P
−1000
0
2
4
6
CPU time ( seconds )
Figure 2 : The primal objective function value ( P SPG , P SFISTA and P ADMM ) and the dual objective function value ( D PG and D FISTA ) vs . CPU time ( seconds ) plots on the ADNI ADAS Cog data set . The right figures are magnified views of the left figures . The legend “ PrimalObj ” denotes the optimal primal i=1 ni , where ni is the objective function value in Eq ( 5 ) and regularized parameters are set as λ1 = λ2 = λ0Pm number of samples from the i th task . are 191 normal control ( NC ) , 319 mild cognitive impairment ( MCI ) , and 138 patients with probably Alzheimer ’s disease ( AD ) [ please refer to [ 36 , 37 ] for more details about the data ] . We thus construct three tasks , and in each medical group we build one regression model to predict the corresponding MMSE scores . ( II ) We also use the ADNI data set and build multi task regression models for predicting the ADAS Cog score , which is another important cognitive score . We construct the task in the same way as in ( I ) .
In the prediction performance experiments , we terminate the comparative algorithms when the relative change of the two consecutive objective function values is less than 10−6 or the number of iterations exceeds 10000 . We randomly split the samples from each task into training and test samples with different training ratios ( 60 % , 70 % and 80% ) . All parameters of the comparative algorithms are tuned via 5 fold cross validation . For each training ratio , we report the averaged mean squared error ( MSE ) and the standard deviation over 10 random splittings of training and test samples as shown in Table 1 . From these results , we have the following observations : ( a ) The calibrated multi task feature learning algorithms ( Calibration and Calibration L2 ) outperform the non calibrated ones ( LeastSquares and LeastSquaresL2 ) , which shows the superior prediction performance of the calibrated algorithms over the non calibrated ones . ( b ) Calibration and Calibration L2 achieve very similar prediction performance , which demonstrates that the proposed variant keeps the superior prediction performance of the calibrated multi task feature learning over the non calibrated one . In the next subsection , we will show that solving the smooth dual problem using a proper optimization algorithm is much more efficient than solving the primal problem directly .
4.2 Computational Efficiency Studies
We study the computational efficiency of solving the optimization problem in Eq ( 5 ) by comparing the following algorithms : ( 1 ) D PG : solve the primal optimization problem in Eq ( 5 ) via using SpaRSA [ 32 ] to solve the dual optimization problem in Eq ( 10 ) ; ( 2 ) D FISTA : solve the primal optimization problem in Eq ( 5 ) via using FISTA [ 4 ] to solve the dual optimization problem in Eq ( 10 ) ; ( 3 ) P SPG : solve the primal optimization problem in Eq ( 5 ) via using SpaRSA [ 32 ] to solve the smoothed optimization problem in Eq ( 37 ) ; ( 4 ) P SFISTA : solve the primal optimization problem in Eq ( 5 ) via using FISTA [ 4 ] to solve the smoothed optimization problem in Eq ( 37 ) ; ( 5 ) P ADMM : solve the primal optimization problem in Eq ( 5 ) by using ADMM [ 8 ] . We conduct the experiments on the same data sets ( both synthetic and real world ) described in the last subsection . We initialize D PG and D FISTA with θ0 whose entries are independently sampled from the standard normal distribution , and initialize P SPG , P FISTA and P ADMM with W 0 which is computed by Eq ( 19 ) using θ0 . We terminate the comparative algorithms when the relative change of the two consecutive objective function values2 is less than 10−6 or the number of iterations exceeds 10000 . All algorithms are implemented in Matlab and executed on an Intel Core i7 3770 CPU ( @3.4GHz ) with 32GB memory .
2The objective function value indicates the dual objective function value in Eq ( 10 ) and the primal objective function value in Eq ( 5 ) for dual optimization algorithms ( D PG and D FISTA ) and for primal optimization algorithms ( P SPG , P FISTA and P ADMM ) , respectively .
ADNI MMSE ( λ =1e−5 ) 0
ADNI MMSE ( λ =1e−5 ) 0
1000
500
0
−500 l e u a V n o i t c n u F e v i t c e b O j
) l a u D
( l a m i r
P
−1000
0
1000
500
0
−500 l e u a V n o i t c n u F e v i t c e b O j
) l a u D
( l a m i r
P
−1000
0
P−SPG P−SFISTA P−ADMM D−PG D−FISTA OptimalObj
1
2
3
4
5
CPU time ( seconds )
ADNI MMSE ( λ =1e−6 ) 0
P−SPG P−SFISTA P−ADMM D−PG D−FISTA OptimalObj
2
4
6
8
10
CPU time ( seconds )
250
200
150
100
50
0
P−SPG P−SFISTA D−PG D−FISTA OptimalObj l e u a V n o i t c n u F e v i t c e b O j
) l a u D
( l a m i r
P
−50
0
0.1
0.2
0.3
0.4
0.5
CPU time ( seconds )
ADNI MMSE ( λ =1e−6 ) 0 l e u a V n o i t c n u F e v i t c e b O j
) l a u D
( l a m i r
400
300
200
100
0
−100
−200
P
−300
0
P−SPG P−SFISTA D−PG D−FISTA OptimalObj
0.2
0.4
0.6
0.8
CPU time ( seconds )
Figure 3 : The primal objective function value ( P SPG , P SFISTA and P ADMM ) and the dual objective function value ( D PG and D FISTA ) vs . CPU time ( seconds ) plots on the ADNI MMSE data set . The right figures are magnified views of the left figures . The legend “ PrimalObj ” denotes the optimal primal objective i=1 ni , where ni is the number function value in Eq ( 5 ) and regularized parameters are set as λ1 = λ2 = λ0Pm of samples from the i th task .
To show detailed convergence behaviors of the comparative algorithms and compare their computational efficiency , we report the primal objective function value ( for P SPG , PFISTA and P ADMM ) and the dual objective function value ( for D PG and D FISTA ) vs . CPU time plots as shown in Figure 1 , Figure 2 and Figure 3 . To better compare the efficiency of dual and primal optimization algorithms , in each figure , we also draw a horizontal line indicating the optimal primal objective function value in Eq ( 5 ) . From these results , we have the following observations : ( a ) DPG and D FISTA increase the dual objective function value which finally converges to the optimal primal objective function value . This validates the fact that the strong duality holds for the optimization problem in Eq ( 5 ) . ( b ) D PG is the most efficient among all algorithms on all data sets . Specifically , D PG always quickly increases the dual objective function and rapidly terminates by approaching the optimal primal objective function value . ( c ) D PG converges faster than D FISTA and D SPG converges faster than PSFISTA , which demonstrates that SpaRSA indeed has very good empirical convergence performance . Although there is no rigorous proof that D PG is the most efficient , empirical studies demonstrate that using SpaRSA to solve the dual problem is much more efficient than that by solving the primal problem directly . This may be due to the nice properties of the dual problem and the empirically fast convergence of SpaRSA .
5 . CONCLUSIONS
In this paper , we study a variant of the calibrated multitask feature learning by adding a squared norm regularizer .
We derive a smooth dual optimization problem with a piecewise sphere constraint , which enables us to develop fast dual optimization algorithms . We also provide a detailed convergence analysis for the proposed dual optimization algorithm . Empirical studies demonstrate that , the dual optimization algorithm quickly converges and it is much more efficient than the primal optimization algorithm . Moreover , the calibrated multi task feature learning algorithms with and without the squared norm regularizer achieve similar prediction performance and both outperform the non calibrated ones . In our future work , we will analyze statistical properties of the proposed formulation and apply it to other applications such as Drosophila image annotation [ 17 ] .
Acknowledgements This work is supported in part by China 973 Fundamental R&D Program ( No.2014CB340304 ) , NIH ( R01 LM010730 ) , and NSF ( IIS 0953662 , CCF 1025177 ) .
6 . REFERENCES [ 1 ] A . Argyriou , T . Evgeniou , and M . Pontil . Convex multi task feature learning . Machine Learning , 73(3):243–272 , 2008 .
[ 2 ] F . Bach , R . Jenatton , J . Mairal , and G . Obozinski .
Optimization with sparsity inducing penalties . Foundations and Trends Rfl in Machine Learning , 4(1):1–106 , 2011 .
[ 3 ] J . Barzilai and J . Borwein . Two point step size gradient methods . IMA Journal of Numerical Analysis , 8(1):141–148 , 1988 .
[ 4 ] A . Beck and M . Teboulle . A fast iterative shrinkage thresholding algorithm for linear inverse problems . SIAM Journal on Imaging Sciences , 2(1):183–202 , 2009 .
[ 5 ] A . Beck and M . Teboulle . A fast dual proximal gradient
[ 31 ] R . T . Rockafellar and R . Wets . Variational Analysis .
Springer , 1998 .
[ 32 ] S . Wright , R . Nowak , and M . Figueiredo . Sparse reconstruction by separable approximation . IEEE Transactions on Signal Processing , 57(7):2479–2493 , 2009 .
[ 33 ] X . Yang , S . Kim , and E . Xing . Heterogeneous multitask learning with joint sparsity constraints . In NIPS , 2009 .
[ 34 ] Y . Zhang , D . Yeung , and Q . Xu . Probabilistic multi task feature selection . In NIPS , 2010 .
[ 35 ] J . Zhou , J . Chen , and J . Ye . MALSAR : Multi tAsk
Learning via StructurAl Regularization . Arizona State University , 2011 .
[ 36 ] J . Zhou , J . Liu , V . Narayan , and J . Ye . Modeling disease progression via fused sparse group lasso . In SIGKDD , pages 1095–1103 , 2012 .
[ 37 ] J . Zhou , L . Yuan , J . Liu , and J . Ye . A multi task learning formulation for predicting disease progression . In SIGKDD , pages 814–822 , 2011 .
[ 38 ] H . Zou and T . Hastie . Regularization and variable selection via the elastic net . Journal of the Royal Statistical Society : Series B ( Statistical Methodology ) , 67(2):301–320 , 2005 .
APPENDIX
A . Primal Smoothed Optimization Algorithm We use the smoothing technique [ 27 ] to derive a primal smoothed optimization algorithm to solve Eq ( 5 ) . Based on the definition of the dual norm , we have max kvik≤1 mXi=1 kvik≤1nvT max mXi=1 kXiwi − yik =
Define a function as mXi=1 kXiwi − yikµ = mXi=1 following proposition thatPm where µ > 0 is a smoothing parameter . We show in the i=1 kXiwi − yikµ is smooth .
Theorem 4 . The optimization problem in Eq ( 35 ) has a vT i ( Xiwi − yi ) . i ( Xiwi − yi ) −
( 34 )
µ
2 kvik2o ,
( 35 ) algorithm for convex minimization and applications . Operations Research Letters , 42(1):1–6 , 2014 .
[ 6 ] A . Belloni , V . Chernozhukov , and L . Wang . Square root lasso : pivotal recovery of sparse signals via conic programming . Biometrika , 98(4):791–806 , 2011 .
[ 7 ] D . Bertsekas . Nonlinear Programming . Athena Scientific ,
1999 .
[ 8 ] S . Boyd , N . Parikh , E . Chu , B . Peleato , and J . Eckstein . Distributed optimization and statistical learning via the alternating direction method of multipliers . Foundations and Trends Rfl in Machine Learning , 3(1):1–122 , 2011 .
[ 9 ] S . Boyd and L . Vandenberghe . Convex optimization .
Cambridge university press , 2004 .
[ 10 ] S . Boyd , L . Xiao , and A . Mutapcic . Subgradient methods .
Lecture notes of EE392o , Stanford University , 2003 .
[ 11 ] F . Bunea , J . Lederer , and Y . She . The group square root lasso : Theoretical properties and fast algorithms . arXiv preprint arXiv:1302.0261 , 2013 .
[ 12 ] P . Gong , K . Gai , and C . Zhang . Efficient euclidean projections via piecewise root finding and its application in gradient projection . Neurocomputing , 74(17):2754–2766 , 2011 .
[ 13 ] P . Gong , J . Ye , and C . Zhang . Multi stage multi task feature learning . In NIPS , pages 1997–2005 , 2012 .
[ 14 ] P . Gong , J . Ye , and C . Zhang . Robust multi task feature learning . In SIGKDD , pages 895–903 , 2012 .
[ 15 ] P . Gong , J . Ye , and C . Zhang . Multi stage multi task feature learning . Journal of Machine Learning Research , 14(1):2979–3010 , 2013 .
[ 16 ] A . Jalali , P . Ravikumar , S . Sanghavi , and C . Ruan . A dirty model for multi task learning . NIPS , 2010 .
[ 17 ] S . Ji , L . Sun , R . Jin , S . Kumar , and J . Ye . Automated annotation of drosophila gene expression patterns using a controlled vocabulary . Bioinformatics , 24(17):1881–1888 , 2008 .
[ 18 ] S . Kim and E . Xing . Tree guided group lasso for multi task regression with structured sparsity . In ICML , 2009 .
[ 19 ] M . Kolar , J . Lafferty , and L . Wasserman . Union support recovery in multi task learning . Journal of Machine Learning Research , 12:2415–2435 , 2011 .
[ 20 ] C . Lemar´echal , A . Nemirovskii , and Y . Nesterov . New variants of bundle methods . Mathematical Programming , 69(1):111–147 , 1995 . descent procedures for the multi task lasso with applications to neural semantic basis discovery . In ICML , pages 649–656 , 2009 .
[ 22 ] H . Liu , L . Wang , and T . Zhao . Multivariate regression with calibration . arXiv preprint arXiv:1305.2238 , 2013 .
[ 23 ] J . Liu , S . Ji , and J . Ye . Multi task feature learning via efficient ℓ2,1 norm minimization . In UAI , 2009 .
[ 24 ] J . Liu , S . Ji , and J . Ye . Slep : Sparse learning with efficient projections . Arizona State University , 2009 .
[ 25 ] K . Lounici , M . Pontil , A . Tsybakov , and S . Van De Geer .
Taking advantage of sparsity in multi task learning . In COLT , 2009 .
[ 26 ] K . Lounici , M . Pontil , S . Van De Geer , and A . Tsybakov .
Oracle inequalities and optimal inference under group sparsity . The Annals of Statistics , 39(4):2164–2204 , 2011 .
[ 27 ] Y . Nesterov . Smooth minimization of non smooth functions . Mathematical Programming , 103(1):127–152 , 2005 .
[ 28 ] F . Nie , H . Huang , X . Cai , and C . Ding . Efficient and robust feature selection via joint ℓ2,1 norms minimization . In NIPS , pages 1813–1821 , 2010 .
[ 29 ] G . Obozinski , B . Taskar , and M . Jordan . Multi task feature selection . Statistics Department , UC Berkeley , Tech . Rep , 2006 .
[ 30 ] R . T . Rockafellar . Convex Analysis . Princeton University
Press , 1997 .
[ 21 ] H . Liu , M . Palatucci , and J . Zhang . Blockwise coordinate unique solution in the following closed form : vi(wi ) =
Xiwi − yi
. max(µ,kXiwi − yik ) i=1 kXiwi − yikµ is continuously differentiable and Lipschitz continuous gradient with respect to W . Specif
Moreover , Pm ically , the gradient Gµ(W ) of Pm
Gµ(W ) = [ X T
1 v1(w1),· ·· , X T and the Lipschitz constant of Gµ(W ) is i=1 kXiwi − yikµ is mvm(wm) ] ,
˜L = maxi∈{1,··· ,m} σ2 max(Xi )
µ
.
( 36 )
Based on Theorem 4 ( the proof of Theorem 4 is very similar to that of Theorem 1 and is thus omitted here ) , we know i=1 kXiwi− yikµ is a smoothed surrogate of the noni=1 kXiwi − yik . Thus , we consider solving the following smoothed version of the optimization problem in Eq ( 5 ) : thatPm smooth termPm W∈Rd×m( mXi=1 cW = arg min kXiwi − yikµ +
λ2 2 kWk2
F + λ1kWk1,2 ) .
( 37 )
The primal smoothed algorithm in fact solves the optimization problem in Eq ( 5 ) via solving the smoothed optimization problem in Eq ( 37 ) . To be more specific , we present a primal smoothed optimization algorithm called accelerated primal smoothed algorithm given in Algorithm 2 , in which FISTA [ 4 ] is used to solve the smoothed optimization problem in Eq ( 37 ) and some notations are defined as follows : l(W )µ = s(W )µ = mXi=1 mXi=1 kXiwi − yikµ +
λ2 2 kWk2
F + λ1kWk1,2 , kXiwi − yikµ +
λ2 2 kWk2 F .
The convergence analysis of Algorithm 2 is similar to The orem 2.2 in [ 22 ] and is thus omitted here .
; tk
Algorithm 2 : Accelerated Primal Smoothed Algorithm Input : W 0 ∈ Rd×m , η0 > 0 , β > 1 ; 1 Initialize W 1 ← W 0 ; t0 ← 1 ; t1 ← 1 ; 2 for k = 1 , 2 , ··· do 3 4 5 6 7
αk ← tk−1−1 V k = W k + αk(W k − W k−1 ) ; for j = 0 , 1 , 2,·· · do ηk ← βj ηk−1 ; eV k ← V k − 1 2 kW −eV kk2 l(W k)µ ≤l(W k)µ + tr(∇l(V k)T
ηk ∇s(V k)µ ; F + λ1kWk1,2o ; µ ( W k − V k ) )
Compute W k via proximal gradient : if the following line search criterion
W n ηk
W k = arg min
+
ηk 2 kW k − V kk2
F is satisfied then break ; end end if some convergence criterion is satisfied then
Let W ⋆ ← W k ; break ;
8 9 10 11 12 13 14 end tk+1 ←
1+√1+4t2 k
2
;
15 16 end
Output : W ⋆
Remark 3 . Similar to the dual optimization algorithm , we can also use SpaRSA [ 32 ] to solve the smoothed optimization problem in Eq ( 37 ) . Due to the use of the BarzilaiBorwein ( BB ) rule [ 3 , 32 ] , SpaRSA achieves very good empirical convergence performance .
B . Alternating Direction Method of Multipliers ( ADMM ) We know that the optimization problem in Eq ( 5 ) is equivalent to the constrained optimization problem in Eq ( 6 ) and we can write down the augmented Lagrange function of
Eq ( 6 ) as follows :
LA(W , z , θ , ρ ) = mXi=1 kzik + λ1kWk1,2 +
λ2 2 kWk2 F ,
ρ
+ mXi=1nθT i ( yi − zi − Xiwi ) + m]T ∈ RPm
2kyi − zi − Xiwik2o , m]T ∈ 1 ,··· , θT where z = [ zT RPm i=1 ni with θi ∈ Rni being the Lagrange multiplier corresponding to the constraint zi = yi − Xiwi ; ρ > 0 is a penalty parameter . The ADMM solves the optimization problem in Eq ( 5 )
1 ,··· , zT i=1 ni ; θ = [ θT by alternatively updating the variables as follows : ( 1 ) Update W :
W k = arg min i − Xiwi ) i
F
+
+
λ2 2 kWk2
W flλ1kWk1,2 + mXi=1h(θk−1 )T ( yi − zk−1 i − Xiwik2io ρ 2kyi − zk−1 W flλ1kWk1,2 + λ2 2 kWk2 mXi=1flflflflfl
θk−1 ρ − zk−1
ρ 2
+
F i i + yi − Xiwiflflflflfl 2 )
= arg min
We can use FISTA [ 4 ] or SpaSRA [ 32 ] to efficiently solve the above problem , where the gradient of the smooth part of the objective function is given by :
∇W fs(W ) = λ2W + [ t1 . . . tm ] with ti = −ρX T i + yi − Xiwi! . i θk−1
ρ − zk−1 i
( 2 ) Update z : zk = arg min
= arg min
For the above problem , the optimal solution is given by the following closed form : kzik + z ( mXi=1 mXi=1(kzik +
+ z i i
ρ
ρ mXi=1h(θk−1 )T ( yi − zi − Xiwk i ) i k2io ρ 2kyi − zi − Xiwk 2flflflflfl θk−1 + yi − zi − Xiwk 2flflflflzi − θk−1 ρkvik vi , + yi − Xiwk i . i + ρyi − zk iflflflflfl iflflflfl i . i − Xiwk
+ yi − Xiwk
ρkzik + 1 i ρ i ρ
1
θk−1
θk i = θk−1
2 ) .
2 ) zk i = arg min zi ( 1 = max0 , 1 − where vi =
( 3 ) Update θ :
