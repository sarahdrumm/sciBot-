A Case Study : Privacy Preserving Release of
Spatio temporal Density in Paris
Gergely Acs
INRIA gergelyacs@inriafr
Claude Castelluccia
INRIA claudecastelluccia@inriafr
ABSTRACT With billions of handsets in use worldwide , the quantity of mobility data is gigantic . When aggregated they can help understand complex processes , such as the spread viruses , and built better transportation systems , prevent traffic congestion . While the benefits provided by these datasets are indisputable , they unfortunately pose a considerable threat to location privacy .
In this paper , we present a new anonymization scheme to release the spatio temporal density of Paris , in France , ie , the number of individuals in 989 different areas of the city released every hour over a whole week . The density is computed from a call data record ( CDR ) dataset , provided by the French Telecom operator Orange , containing the CDR of roughly 2 million users over one week . Our scheme is differential private , and hence , provides provable privacy guarantee to each individual in the dataset . Our main goal with this case study is to show that , even with large dimensional sensitive data , differential privacy can provide practical utility with meaningful privacy guarantee , if the anonymization scheme is carefully designed . This work is part of the national project XData ( http://xdata.fr ) that aims at combining large ( anonymized ) datasets provided by different service providers ( telecom , electricity , water management , postal service , etc )
1 .
INTRODUCTION
Mobile phone datasets have become widely available in recent years and have opened the possibility to improve our understanding of large scale social networks by investigating how people exchange information , interact , and develop social interactions . While the benefits provided by these datasets are indisputable , they unfortunately pose a considerable threat to location privacy . Not only this can impact people lives negatively , this also affects research . Because privacy is so important to people , companies and researchers are reluctant to publish mobile phone datasets by fear of being held responsible for potential privacy breaches . It is
( c ) 2014 Association for Computing Machinery . ACM acknowledges that this contribution was authored or co authored by an employee , contractor or affiliate of the national government . As such , the Government retains a nonexclusive , royalty free right to publish or reproduce this article , or to allow others to do so , for Government purposes only . KDD’14 , August 24–27 , 2014 , New York , NY , USA . Copyright 2014 ACM 978 1 4503 2956 9/14/08 $1500 http://dxdoiorg/101145/26233302623361 therefore urgent to develop practical tools for private releases and analysis of mobility datasets .
This paper focuses on applications that only need location counts , ie , the repartition of visitors on a map at a given period of time . This information can typically be published by dividing a map into cells , and then releasing the count ( ie , number of users ) associated to each of the cells . However , it is important to ensure that this publication does not leak any information about the mobility patterns of individual users , which might be trivial when , for example , the count values are small .
Why Differential Privacy ? Privacy has different definitions and different models have been proposed . In this paper , we use differential privacy [ 10 ] which has emerged as a compelling privacy model . The advantage of this model , compared to the many others proposed in the literature , is two fold . First , it provides a formal and measurable privacy guarantee regardless what other background information or sophisticated inference technique the adversary uses even in the future . Second , it is closed with respect to sequential and parallel composition , ie , the result of the sequential or parallel combination of two differential private algorithms is also differential private .
This has particular importance in practice , since it does not only simplify the design of anonymization solutions , but also allows to measure differential privacy when a given dataset , or a set of correlated datasets , is anonymized ( and released ) several times , possibly by different entities .
Differential private schemes often requires adding noise to the published data ( eg , to the published location counts ) so that it leaks almost no information about any participating individual , but still reveals aggregated information about the population as a whole . The variance of the noise is calibrated to both the sensitivity of the counts ( ie , the maximal change of the counts due to the inclusion/exclusion of a single record in a dataset ) and a desired privacy level ε . For large dimensional data , such as temporal density , the sensitivity is usually so large that the added noise is much larger than the actual density count values for stringent privacy requirement ( ie ε < 1 ) . Consequently , the resultant anonymized data is often meaningless .
Contributions . In this paper , we show that , for a given privacy level ( ie , a given ε ) , the magnitude of noise can be substantially reduced by using several optimizations and by customizing the anonymization mechanisms to the public characteristics of datasets and applications . We observe that the temporal density , of each cell , can be characterized by a periodic time series . This is explained by the fact that aggregated mobility patterns are quite periodic . Moreover these time series follow very similar trends , as most people in nearby cells have similar calling patterns . As a consequence , time series can be compressed by sampling , clustering and low pass filtering . Sampling and clustering reduce data sensitivity , which results in lower added noise and better performance . We further attenuate the distortion resulting from the compression and perturbation phases via novel optimization and post processing algorithms . We show experimentally that the achieved performance is quite high and that differential privacy can be practical in real world applications . However , we believe that there are probably no differential private anonymization techniques that fit all applications , and that anonymization algorithms have to be customized to each application and dataset .
The XData project . This work was done in the context of the French XData project . XData is a national funded project under the “ Big Data program ” , whose goal is to study the benefit of combining and cross processing different types of datasets provided by various service providers ( such as Orange , Electricit´e de France , La Poste , etc ) However , according to the European Data Protection laws ( Directive 95/46/EC ) , all datasets have to be anonymized , prior crossprocessing , such that data subjects are no longer identifiable . The law does not dictate any specific privacy model , but stipulates that “ to determine whether a person is identifiable , account should be taken of all the means likely reasonably to be used either by the controller or by any other person to identify the said person ” . We believe that the best existing model to achieve this goal is probably differential privacy . This paper shows how to anonymize the mobility data , provided by Orange , under the differential privacy model . In particular , we show how to release density information . Geographical density is useful in many of applications envisioned by the XData projet , such as identifying areas where to install new businesses or build new infrastructures .
2 . RELATED WORK
Several recent studies have demonstrated the privacy risks of releasing location data by re identifying individuals from geospatial data sets [ 8 , 28 , 13 ] . As a result , a plethora of privacy preserving techniques have been introduced , however , most of them do not provide any formal privacy guarantee ( see [ 6 ] and the references therein ) .
Differential privacy ( DP ) was first rigorously presented in [ 10 ] with the Laplace mechanism ( LPA ) as a first generic tool to guarantee DP . There exist two relaxations of ε DP ; ( ε,δ) probabilistic DP [ 20 ] and ( ε , δ) indistinguishability [ 9 ] . The former guarantees ε DP with high probability ( ≥ 1−δ ) , while the latter relaxes the bound of ε DP .
Location privacy has also been addressed in the context of DP . [ 5 ] applies DP to location , and more generally , sequential data release . However , this scheme does not release time information apart from the sequentiality of locations . Another recent work [ 2 ] formalizes location privacy as protecting the users’ location within a radius r with a level of privacy that depends on r . This corresponds to a generalized version of DP . They target LBS applications and add noise directly to users’ GPS coordinates . Commuting patterns in US were anonymized in the probabilistic DP model in [ 20 ] . This scheme has also been deployed in practice within the project called OnTheMap by the US Census Bureau . Other authors [ 7 , 19 ] apply different spatial decomposition techniques to partition the two dimensional domain into cells , and then obtain noisy counts for each cell . However , these techniques are not concerned with releasing multiple counts over time .
Several DP techniques have been proposed to release time series . In [ 12 ] , the authors propose a framework to release real time aggregate statistics under DP based on filtering and adaptive sampling . Some other proposals [ 11 , 4 ] provide a weaker guarantee on continuous data streams ; they provide event level privacy to protect an event ( ie , one user ’s presence at a particular time point ) , rather than the presence of that user . As all these works address the real time ( interactive ) release of aggregates , they are usually less accurate than off line ( non interactive ) approaches , which can access the whole time series and build more accurate models for perturbation .
The most related work to ours is [ 24 , 17 , 23 ] . All of them address the off line release of time series under DP . Rastogi and Nath [ 24 ] proposed a Discrete Fourier Transform ( DFT ) based algorithm which guarantees DP by perturbing the discrete Fourier coefficients . This technique was further improved for DP histogram release in [ 1 ] . We reuse the improved private DFT algorithm from [ 1 ] , and further improve its accuracy at the cost of some privacy . In [ 17 ] , the time series are pre processed by pre sampling and smoothing them via averaging . These techniques diminish the global sensitivity of the data , and thereby allows to lower the injected Laplace noise . We also use a similar sampling technique to [ 17 ] in order to compress time series . However , [ 17 ] is a more general solution and targets even non periodic time series where averaging may be a better perturbation model than DFT . As aggregated location counts are typically periodic , DFT is a more accurate perturbation model for our application . Finally , DP WHERE [ 23 ] adds noise to the set of empirical probability distributions which is derived from the original CDR datasets , and samples from these distributions to generate synthetic CDRs . Instead of releasing the whole CDR dataset , we only aim at releasing the temporal density of IRIS cells which is a more specific problem . This mapping between CDRs and IRIS cells influences utility and is not considered in [ 23 ] .
3 . PRELIMINARIES 3.1 Differential Privacy
Intuitively , differential privacy [ 10 ] ( DP ) requires that the outcome of any computation be insensitive to the change of a single record in the dataset . Consequently , for a record owner , it means that any privacy breach will not be due to participating in the database .
Definition 1 ( Differential Privacy ) A privacy mechanism A gives ε differential privacy if for any database D1 and D2 differing on at most one record , and for any possible output O ∈ Range(A ) , −ε × P r[A(D2 ) = O ] ≤ P r[A(D1 ) = O ] ≤ eε × P r[A(D2 ) = O ] e where the probability is taken over the randomness of A .
A relaxation of DP is probabilistic DP [ 20 ] , where privacy breaches may occur with very small probability .
Definition 2 ( Probabilistic Differential Privacy [ 20 ] ) A privacy mechanism A gives ( ε , δ) probabilistic differential privacy if for any database D1 and D2 differing on at most one record , and for any possible output O ∈ Range(A ) , we can partition the output space Ω into Ω1 and Ω2 such that ( 1 ) for all O ∈ Ω1 , −ε × P r[A(D2 ) = O ] ≤ P r[A(D1 ) = O ] ≤ eε × P r[A(D2 ) = O ] e and ( 2 ) for any database D , P r[A(D ) ∈ Ω2 ] ≤ δ where the probability is taken over the randomness of A .
The latter definition guarantees that algorithm A achieves DP with high probability ( ≥ 1− δ ) , and the set Ω2 contains all outputs that are privacy breaches according to Definition 1 . The probability of these outputs are bounded by δ . Notice that with δ = 0 probabilistic DP boils down to Definition 1 . Although probabilistic DP has weaker privacy guarantee than Definition 1 , it provides higher utility in practice .
The definition of differential privacy enjoys the property of sequential composition , which specifies the privacy guarantee in a sequence of computation . Theorem 1 ( [21 ] ) Let Ai each provide εi differential privacy . A sequence of Ai(D ) over the dataset D provides i εi differential privacy .
3.2 Differential Private Mechanisms
Three principal techniques for achieving ( probabilistic ) DP are Laplace mechanism [ 10 ] ( LPA ) , Gaussian mechanism [ 15 ] ( GPA ) , and Exponential mechanism [ 22 ] . A fundamental concept of all these techniques is the global sensitivity of a function [ 10 ] :
Definition 3 ( Global Sensitivity ) For any function f : D → Rd , the sensitivity of f is ∆f = maxD1,D2 ||f ( D1 ) − f ( D2)||1 for all D1,D2 differing in at most one record .
The global sensitivity is also called as L1 sensitivity due to the L1 norm used in its definition and is denoted by ∆1f . Similarly , the L2 sensitivity ∆2f of a function f , which is used later in this paper , is defined by the L2 norm || · ||2 . Laplace mechanism ( LPA ) . A standard mechanism to achieve differential privacy is to add Laplace noise to the true output of a function . The noise is generated according to a Laplace distribution with the probability density function ( PDF ) p(x|λ ) = 1 2λ e−|x|/λ , where λ is calibrated as follows . Theorem 2 ( [10 ] ) For any function f : D → Rd , the mechanism A
A(D ) = f ( D ) + L1(λ ) , . . . ,Ld(λ ) gives ε differential privacy , if Li(λ ) are iid Laplace variables with scale parameter λ = ∆f /ε .
Gaussian mechanism ( GPA ) . An alternative technique to achieve probabilistic DP is to add Gaussian noise to the true output of a function . The noise is generated according to the Gaussian distribution with the PDF p(x|σ ) = 1√ Theorem 3 ( [15 ] ) For any function f : D → Rd , the mechanism A e−x2/2σ2
2πσ
.
A(D ) = f ( D ) + G1(σ ) , . . . ,Gd(σ ) gives ( ε , δ) probabilistic differential privacy for any ε ≤ 1 and σ2 ≥ 2(∆2f )2 ln(4/δ)/ε2 , where Gi(σ ) are iid Gaussian variables with variance σ2 .
Assuming identical values of ε , a Gaussian random variable is more concentrated around 0 than a Laplace random variable thereby ensuring better utility for GPA . However , this larger accuracy also entails weaker privacy , since there is a small probability δ that ε DP will not hold .
Exponential mechanism . The exponential mechanism [ 22 ] captures all DP mechanisms with a measurable output space . In particular , it assigns exponentially greater probabilities of being selected to outputs of higher utility so that the final output would be close to the optimum yet still differential private . Theorem 4 ( [22 ] ) Given a utility function u : ( D × R ) → R for a database D , the mechanism A , A(D , u ) = return r with probability ∝ exp
εu(D , r ) fl
2∆u gives ε differential privacy , where ∆u = max∀r,D1,D2 |u(D1 , r ) − u(D2 , r)| . 3.3 Utility Metrics
Mean Relative Error
The error between the private and original time series is measured by the following metrics . Consider counts X = {X0 , . . . , Xn−1} . We denote the original time series by X , the sanitized one by ˆX .
( MRE ) : MRE(X , ˆX ) = | ˆXi−Xi| max(γ,Xi ) , where the sanity bound γ mitFollowing the igates the effect of very small counts .
( 1/n)n−1 convention [ 27 ] , we adjust γ to 0.1 % ofn−1 i=0 ( Xi− n−1 n−1 i=0 ( Xi− i Xi/n)( ˆXi− n−1 i=0 Xi . PC(X , ˆX ) i=0 ( ˆXi−
. PC measures the
( PC ) : ˆXi/n )
Correlation
Pearson i Xi/n)2 i
ˆXi/n)2 i i=0
= linear correlation between the noisy and the original time series ( ie , whether they have similar trends ) , and it always falls between 1 and 1 .
4 . PROBLEM DEFINITION
Our goal is to release the spatio temporal density of 989 non overlapping areas in Paris , called IRIS cells . Each cell is defined by INSEE1 and covers about 2000 inhabitants . The set of all IRIS cells is denoted by L henceforth , and are depicted in Figure 1 based on their contours2 .
We aim to release the number of all individuals who visited a specific IRIS cell in each hour over a whole week . Since human mobility trajectories exhibit a high degree of temporal and spatial regularity [ 14 ] , one week long period should be sufficient for most practical applications . Therefore , we are interested in the time series XL = X L 167 of any IRIS cell L ∈ L , where X L t denotes the number of individuals at L in the ( t + 1)th hour of the week , such that any single individual can visit a tower only once in an hour .
1 , . . . , X L
0 , X L of
Institute
1National http://wwwinseefr/fr/methodes/defaultasp?page= zonages/iris.htm 2Available on IGN ’s website ( National Geographic Institute ) : http://professionnelsignfr/contoursiris and Economics :
Statistics
We will omit t and L in the sequel , if they are unambiguous L in the given context . X denotes the set of time series of all IRIS cells in the sequel . 4.1 Dataset
To compute these time series , we use a CDR ( Call Data Record ) dataset provided by the French telecom company Orange3 , where T represents the set of cell towers of the operator , and a cell tower T ∈ T is visited by an individual at time t , if the operator has a recorded event at time t at tower T related to the individual . An event can be an incoming/outgoing call or message to/from the individual . This dataset contains the events of N = 1 , 992 , 846 users at |T| = 1303 towers within the administrative region of Paris ( ie , the union of all IRIS cells ) over a single week ( 10/09/2007 17/09/2007 ) . Within this interval , the average number of events per user is 13.55 with a standard deviation of 18.33 ( assuming that an individual can visit any tower cell only once in an hour ) and with a maximum at 732 . The set of all events related to an individual constitute his/her record ( trajectory ) in the dataset . Similarly to IRIS T , where X T cells , we can create another set of time series X t denotes the number of visits of tower T in the ( t + 1)th hour of the week . 4.2 Computing the time series of IRIS cells
T We map the counts in X as follows . First , we compute the Voronoi tesselation of the towers cells T which is shown in Figure 1 . Then , we calculate the count of each IRIS cell in each hour from the counts of its overlapping tower cells ; each tower cell contributes with a count which is proportional to the size of the overlapping area . More specifically , if an IRIS cell L overlaps with tower cells {T1 , T2 , . . . , Tc} , then
L to X c
X L t = t × size(Ti ∩ L )
X Ti size(Ti )
( 1 ) at time t . i=1
The rationale behind this mapping is that users are usually registered at the geographically closest tower at any time . We acknowledge that this mapping algorithm might sometimes be incorrect , since the real association of users and towers depends on several other factors such as signal strength or load balancing . Nevertheless , without more details of the cellular network beyond the towers’ GPS position , we are not aware of any better mapping technique .
5 . PRIVACY PRESERVING RELEASE OF
SPATIO TEMPORAL DENSITY
L Our aim is to transform the time series of all IRIS cells X
L to a sanitized version ˆX satisfies Definition L 1 . That is , the distribution of ˆX will be insensitive ( up to ε ) to all the visits of any single user during the whole week , L meanwhile the error between ˆX
L such that ˆX
L and X is small .
Our sanitization algorithm is sketched in Algorithm 1 . First , the input dataset is pre sampled such that only visits are retained per user ( Line 1 ) . This ensures that the global L sensitivity of all the time series ( ie , X ) is no more than . Then , the pre sampled time series of each IRIS cell is computed from that of the tower cells using Voronoi tesselation
3http://wwworangecom
Figure 1 : IRIS cells of Paris ( left ) and Voronoi tesselation of tower cells ( right )
Algorithm 1 Our sanitization scheme
T
input time series ( from CDR ) , ( ε , δ) privacy param
Input : X eters , L IRIS cells , maximum visits per user L Output : Noisy time series ˆX 1 : Create X
T by sampling at most visits per user from X
T
( Section 5.1 )
L 2 : Compute the IRIS time series X 3 : Compute the minimum cover C ⊆ T∪L and the corresponding
( Section 4.2 ) from X
T
( Section 5.2 )
C time series X
C into ˆX
C 4 : Perturb X 5 : Apply smoothing on ˆX C L 6 : Compute ˆX from ˆX
C
( Section 5.4 ) using Formula ( 1 )
( Section 5.3 ) //see Algorithm 2 and Formula ( 1 ) ( Line 2 ) . After the largest cells , which cover the whole city and also have large counts , from T∪L are identified ( Line 3 ) , their time series are perturbed to guarantee privacy ( Line 4 ) . In order to mitigate the distortion of the previous steps , we apply smoothing on the perturbed time series as a post processing step ( Line 5 ) . Finally , the time series of all IRIS cells are computed from the post processed time series in C ( Line 6 ) . 5.1 Pre sampling
) . T ∆1(X
To perturb the time series of all IRIS cells , we first have to L compute their sensitivity , ie , ∆1(X ) . To this end , we first need to calculate the sensitivity of the time series of all tower T Indeed , Formula ( 1 ) does not change cells , ie , ∆1(X T the L1 sensitivity of tower counts , and hence , ∆1(X ) = L ∆1(X
) .
) is given by the maximum total number of ( tower ) visits of a single user in any input dataset . This upper bound must universally hold for all possible input datasets , and is usually on the order of few hundreds ; recall that the maximum number of visits per user is 732 in our dataset . This would require excessive noise to be added in the perturbation phase . We instead follow a different approach and divide the whole sanitization process into two main steps . We first perturb a pre sample of our dataset which better withstands perturbation , and then mitigate the distortion effect of sampling in a post processing step described later in Section 54
In particular , we truncate each record of any input dataset by considering at most one visit per hour for each user , and then select at most of such visits per user uniformly at random over the whole week . This implies that a user can contribute with at most to all the counts in total regardless of the input dataset , and hence , the L1 sensitivity of the dataset always becomes . The pre sampled dataset is T denoted by X , and ∆1(X 5.2 Computing the largest covering cells
L ) = ∆1(X
) = .
L To sanitize X
, there are two basic ( naive ) approaches . L First , we can directly perturb the IRIS counts X by apt + L(/ε ) for all plying the Laplace mechanism : ˆX L L ∈ L . Alternatively , we can first perturb the tower counts T L , then compute the noisy IRIS counts ˆX X T from ˆX by applying Formula ( 1 ) . Although both techniques guarantee ε DP according to Theorem 2 , in terms of utility , they are suboptimal .
T to obtain ˆX t = X
L
Cells with small counts have larger relative error , whereas larger counts better resist noise . This is due to the fact that the injected noise is independent of the magnitude of the original counts but only depends on their sensitivity . Therefore , the best approach is to first select cells having the largest counts ( which can be either tower or IRIS cells ) such that they cover whole Paris , perturb the counts of these cells , and then recompute the noisy counts of the smaller IRIS cells , which were not selected in the cover , from the larger ( noisy ) tower counts .
However , selecting the optimal cover of Paris ( ie , the set of cells having the largest counts ) must also be differential private . Fortunately , a simple heuristic helps us to accurately approximate the optimal cover without using the true counts of the cells ( that would require to introduce more noise ) : cells with large size tend to have large counts4 . This is also confirmed by Figure 2a and 2b . Hence , we re state the problem as follows . How can we select the minimum cardinality subset of cells C ⊆ T∪L such that C is a complete cover ( ie , covers whole Paris ) ? More formally , let G(V , E ) denote a graph , where each vertex corresponds to a cell in T∪ L , and ( v , v ) ∈ E iff cells v and v overlap . In this setting , our problem translates to the classical minimum vertex cover problem [ 3 ] . Indeed , as T and L are also complete covers of Paris , each vertex in V has at least one edge ( a tower cell is always overlapped by at least one IRIS cell , and vice verse ) , and we want to compute the minimum cardinality subset of cells which cover all the overlapping areas between cells . Although the minimum vertex cover problem is NP hard in general , our covering problem belongs to the special cases which can be efficiently solved .
Theorem 5 ( Minimum cardinality cover ) Selecting the minimum cardinality subset of cells C ⊆ T ∪ L such that
C is a complete cover can be solved in O(|T||L||T| + |L| ) .
Proof . G(V , E ) is bipartite , since the IRIS cells as well as the tower cells are partitionings of Paris , ie , there are no overlapping cells in any of the two sets . Hence , for all ( v , v ) ∈ E , either v ∈ T and v ∈ L , or v ∈ T and v ∈ L . For bipartite graphs , the minimum vertex cover problem is equivalent to the maximum matching problem based on K¨onig ’s theorem [ 3 ] , which can be solved in polynomial time , where |V | = |T| + |L| and |E| ≤ |T||L| . 4Tower cells are represented by their Voronoi polygons as it is depicted in Figure 1 eg , with the Hopcroft Karp algorithm [ 16 ] in O(|E||V | ) ,
Figure 2c shows the largest IRIS and tower cells covering Paris . We computed the mean count of each cell over the whole week which are illustrated by the cell colors . Apparently , the minimum cover contains cells with larger counts ; the mean counts are 91 on average for the IRIS cells ( Figure 2b ) and 120 on average for the minimum cover ( Figure 2c ) . However , care must be taken before computing the cell counts in the minimum cover C . Since C can contain both IRIS and tower cells which may overlap , the L1 sensitivity of all the counts in C can be larger than . Indeed , if C contains a tower cell T and one of its overlapping IRIS cell L , then adding/removing a user who visited T at time t will change L X t with a non zero value . A trivial ( but not optimal ) solution is to modify the counts of all towers in C which have overlapping IRIS cells . For example , if T overlaps with IRIS cells {L1 , L2 , . . . , Lc} , then X T t should
T t with 1 , and also X
Li t × size(Li∩T ) size(T )
. be reduced byc i=1 X 5.3 Perturbation
After identifying the largest covering cells , their time seC ) can be perturbed by adding L(/ε ) to each ries ( ie , X count in all time series ( see Theorem 2 ) . Unfortunately , this naive method provides very poor results which is also illustrated in Figure 3a . Indeed , individual cells have much smaller counts than the magnitude of the injected noise ; the standard deviation of the Laplacian noise is 141 with ε = 0.3 , which is even larger than the mean count in the minimum cover .
A better approach exploits ( 1 ) the similarity of geographically close time series , as well as ( 2 ) their periodic nature . In particular , we first cluster nearby less populated cells until their aggregated counts become sufficiently large to resist noise . The key observation is that the time series of close cells follow very similar trends , but their counts usually have different magnitudes . Hence , if we simply aggregate ( ie , sum up ) all time series within such a cluster , the aggregated series will have a trend close to its individual components yet large enough counts to tolerate perturbation . To this end , we first accurately approximate the time series of individual cells by normalizing their aggregated time series ( ie , divide the aggregated count of each hour with the total number of visits inside the cluster ) , and scale back with the ( noisy ) total number of visits of individual cells .
In order to guarantee DP , we also need to perturb the aggregated time series before normalization . To do so , we exploit their periodic nature and apply a Fourier based perturbation scheme [ 24 , 1 ] : we add noise to the Fourier coefficients of the aggregated time series , and remove all high frequency components that would be suppressed by the noise . As only low frequency components are retained and perturbed , this method preserves the trends of the original data more faithfully than LPA . t=0 X to167
The whole perturbation process is summarized in Algorithm 2 . First , the noisy total number of visits of each cell in the minimum cover C is computed by adding noise L(2/ε ) i t for cell i ( Line 1 ) . These noisy total counts are used to cluster similar cells in Line 2 by invoking Algorithm 3 . When the clusters are created , their aggregated time series ( ie , the sum of all cells’ time series within the cluster ) is perturbed with a Fourier based perturbation scheme in Line 5 ( Algorithm 4 ) . Finally , the perturbed time series of each cell i in cover C is computed in Line 7 by scaling back
( a ) Tower cells , |T| = 1303
( b ) IRIS cells , |L| = 989
( c ) Minimum cardinality cover ,
|C| = 826
Figure 2 : Covering Paris with the largest tower and IRIS cells . Each cell is colored based on their mean count . Large cells tend to have large counts ( closer to red ) , while small cells are less populated ( closer to blue ) . The minimum cover ( Figure 2c ) includes large , more populated cells : IRIS cells from the city center , and tower cells around the perimeter .
Algorithm 2 Perturbation C Input : Minimum cover C , Pre sampled time series X C total count τ , Privacy budget ε , δ , Sensitivity ∆1(X C Output : Noisy time series ˆX
, Minimum ) =
1 : ˆSi :=167 :=
E t=0 X i t + L(2/ε ) for each i ∈ C i i∈E X
0 ,
1 , . . . ,
2 : E := Cluster(C , τ , ˆS ) //see Algorithm 3 3 : for each cluster E ∈ E do 4 : X 5 : 6 : 7 : 8 : 9 : end for
ˆXE := EFPAG(X for each cell i ∈ E do ˆXi := ˆSi · ( ˆXE t /|| ˆXE||1 ) end for i∈E X
E i i∈E X i
167
, ε/2 , δ ) //see Algorithm 4
Algorithm 3 Cluster cells Input : Minimum cover C = {c0 , c1 , . . . , c|C|} , Minimum total count τ , Noisy total counts ˆS of cells in C Output : Cluster configuration E ⊂ 2|C| 1 : E := {{c0} , {c1} , {c2} , . . . , {c|C|}}
2 : ˆSE :=
ˆSi for each cluster E ∈ E ci∈E
3 : while ∃E ∈ E such that ˆSE < τ do 4 : 5 : 6 : 7 : 8 : 9 : end while
E := arg minE∈E ˆSE Let E be the geographically closest neighbor of E E := E ∪ E ˆSE := ˆSE + ˆSE Remove E from E the normalized aggregated time series with the noisy total count cell i ( ie , with ˆSi ) . Since Line 1 guarantees ε/2 DP C to the total counts ( ∆1(X ) = ) , it follows from Theorem 1 that Algorithm 2 is ( ε , δ) DP if EFPAG is ( ε/2 , δ) DP .
531 Clustering cells Algorithm 3 is a simple iterative process that , in each iteration , merges the least visited cluster with its geographically closest neighboring cluster until all clusters in the resultant configuration have a total count larger than a predefined threshold τ . Initially , each cluster is a singleton composed of an individual cell in the cover . Then , in Line 4 , we select the cluster which has the smallest ( noisy ) total count , and merge with its closest neighboring cluster in Line 5 8 . The distance between two clusters are measured with the physical distance between their cluster centers5 . In each step , the noisy total count of each cluster is computed as the sum of all ( noisy ) total counts of each cell within the cluster ( Line 7 ) . Since the total counts of cells are noisy , Algorithm 3 preserves DP .
532 Perturbing aggregated time series To perturb aggregated time series , we build on the Fourier
Perturbation Algorithm ( FPA ) [ 24 ] :
5The cluster center is the centroid of its consitituent cell polygons .
F the coefficients
1 . Compute
Fourier the
= F0 , F1 , . . . , Fn−1 of input aggregated time series X with length n by discrete Fourier transform . 2 . Remove the last n − k coefficients from F , which correspond to the high frequency components in X , and retain only the first k elements of F , denoted by Fk . Note that k is an input to the algorithm .
√ k 3 . Generate the noisy version of Fk , denoted by ˆF , by Laplace mechanism : add iid Laplace noise L( k/ε ) to each coefficient in Fk . k 4 . Pad ˆF to be a n dimensional vector by appending ) . Finally , n − k zeros , which is denoted by PADn( ˆF k the inverse DFT is applied to PADn( ˆF noisy version of X .
) to obtain a k squared error E||X − ˆX||2 ≤ n
FPA provably guarantees ε DP [ 24 ] . Enhanced FPA [ 1 ] improves basic FPA by selecting the coefficients to be removed more effectively . Specifically , in Step 2 , EFPA chooses k probabilistically using the exponential mechanism such that the values of k which minimize the root sumi=k+1 |Fi−1|2 + 2k∆2(X ) ( RSSE ) have exponentially larger probability to be selected . In this paper , we improve the accuracy of EFPA in two ways . First , instead of the Discrete Fourier Transform ( DFT ) , we
ε
040801201602002402803203604000408012016020024028032036040004080120160200240280320360400 Algorithm 4 EFPAG
Input : Truncated time series X with length n , Privacy budget ε , δ , L2 sensitivity of X : ∆2(X ) Output : Noisy time series ˆX with length n 1 : F := DCT(X ) // Discrete Cosine Transform 2 : Compute √ uG(X , k )
=
√ i=k+1 |Fi−1|2 + n − ε·uG(X,k )
4∆2(X )
2∆2(X ) k ln1/2(4/δ ) ε for all 1 ≤ k ≤ n
3 : Select k with probability ∝ exp k 4 : ˆF k 5 : return ˆX = IDCT(PADn( ˆF
:= Fk + G(
√
2∆2(X ) ln1/2(4/δ)/ε)k
) ) //Inverse DCT
( a ) Large counts
( b ) Small counts around local minimas
Figure 4 : Our scheme before improvements ( ε = 0.3 , δ = 2 · 10−6 , = 30 ) .
( a ) LPA
( b ) Our approach
( a ) Scaling
( b ) Smoothing n
Figure 3 : Noisy time series of an IRIS cell ( ε = 0.3 , = 30 ) apply the orthonormal version of the Discrete Cosine Transform ( DCT ) , which tends to provide smaller high frequency components due to its different boundary conditions [ 26 ] . This can result in smaller RSSE when these components are removed in Step 2 . Moreover , since we use orthonormal DCT , the resultant scheme also preserves ε DP [ 1 ] .
Second , instead of adding Laplace noise , we add properly calibrated Gaussian noise to the first k Fourier coefficients of X thereby providing larger accuracy at the cost k of weaker privacy . More specifically , when ˆF is generated in Step 3 , we employ the Gaussian mechanism instead of LPA and add iid Gaussian noise G(σ ) to each coefficient √ in Fk , where σ = 2∆2(X ) ln1/2(4/δ)/ε to provide ( ε , δ)probabilistic DP based on Theorem 3 . In addition , we select k with probability ∝ exp in Step 2 , where
− ε·uG(X,k ) i=k+1 |Fi−1|2 + uG(X , k ) = follows from Theorem 5 in [ 1 ] and Theorem 3 . When we use GPA in Step 3 , the new scheme ( with DCT ) is denoted by EFPAG in the rest . which k ln1/2(4/δ ) ε
Since Gaussian noise has smaller variance than Laplacian , EFPAG provides better accuracy than EFPA . Specifically , the variance of the Gaussian noise added to the Fourier coefficients is 8∆2(X)2 ln(4/δ)/ε2 , which is independent of the number of retained coefficients ( ie , k ) . By contrast , the variance of the Laplace noise added to the coefficients in EFPA is 8∆2(X)2k/ε2 which linearly increases with the number of retained coefficients . However , this improvement also leads to some privacy degradation which is measured by δ . In the sequel , we fix δ to 2 · 10−6(≤ 1/N ) .
EFPAG is summarized in Algorithm 4 , where the total budget ε is uniformly divided between GPA ( Line 4 ) and exponential mechanism ( Line 2 ) , therefore , EFPAG is ( ε , δ)probabilistically DP due to Theorem 1 .
4
√
√
2∆2(X )
Figure 5 : Our scheme after improvements ( ε = 0.3 , δ = 2 · 10−6 , = 30 )
Finally , in order to employ EFPA(G ) , we need to compute C the L2 sensitivity of the counts in the cover C , ie , ∆2(X ) . E C Indeed , since E is a partitioning of C , ∆2(X ) . ) = ∆2(X Recall that , as a result of pre sampling , at most a single visit of a user is retained in any slot , and at most visits per user over the whole week . This means that , for any t , there is only a single tower whose count can change ( by at most 1 ) by modifying a single user ’s data . From Formula ( 1 ) , it follows that the total change of all IRIS cell counts is L at most 1 at any t , and hence ∆2(X based C on the definition of L2 norm . Since C ⊆ T ∪ L , ∆2(X ) ≤ √ . Figure 3 illustrates the improvement of our approach
T ) ≤ ∆2(X
√
) =
( Clustering + EFPAG ) over simple LPA . 5.4 Further improvements
Although our approach is clearly superior to LPA , Figure 4 still suggests a large error on average . This difference between ˆX and X is the result of two errors : the sampling error ( between X and X ) is attributed to pre sampling , whereas the perturbation error ( between ˆX and X ) is due to our perturbation scheme .
As illustrated by Figure 4a , sampling error mainly distorts large counts : although the noisy counts are close to the counts of the truncated ( pre sampled ) time series between 9:00 AM and 11:00 PM , it is still far from the original count values . This significantly increases MRE .
In addition , as Figure 4b also shows , noisy counts also deviate from pre sampled as well as from original counts around the local minimas ( close to 4:00 AM every day ) , which further deteriorates MRE . This perturbation error is caused by the higher frequency components that are retained and perturbed by EFPA(G ) .
MoTuWedThuFriSatSun41220412204122041220412204122041220050100150200250300350VisitcountOriginalPrivate(MRE:073,PC:059)MoTuWedThuFriSatSun41220412204122041220412204122041220050100150200250VisitcountOriginalPrivate(MRE:038,PC:098)MoTuWedThuFriSatSun41220412204122041220412204122041220050100150200250VisitcountOriginalTruncatedPrivate(MRE:038,PC:098)MoTuWedThuFriSatSun41220412204122041220412204122041220010203040506070VisitcountOriginalTruncatedPrivate(MRE:038,PC:098)MoTuWedThuFriSatSun41220412204122041220412204122041220050100150200250VisitcountOriginalPrivate(MRE:016,PC:099)MoTuWedThuFriSatSun41220412204122041220412204122041220010203040506070VisitcountOriginalPrivate(MRE:016,PC:099 ) To alleviate these errors , we propose two further improvements : first , we improve the perturbation of total cell counts ( Line 1 in Algorithm 2 ) , which is used in cell clustering ( Algorithm 3 ) and scaling ( Line 6 in Algorithm 2 ) . Then , as a post processing step , we smooth out small counts ( ie , between 0:00 and 6:00 AM ) through non linear least square fitting to diminish perturbation error . i t=0 X i t=0 X i t=0 X i i t=0 X
167
Improved scaling t is ∆1(X ) which is too large . t +L(2/ε ) . Since X
541 Recall that we scale back the normalized aggregated time series with ˆSi in Line 6 ( Algorithm 2 ) , where ˆSi = is the pre sampled time series of cell i , ˆXi ( Line 6 ) will be a scaled down version of the original time series Xi due to the fact that the visits per individual are sampled uniformly at random . Also , as we have discussed in Section 5.1 , adding Laplace noise directly t is very inaccurate , as to the original total count 167 the sensitivity of167 We rather perturb the original total count167 t using a different approach : we first approximate the relative frequencies of each tower by another constraint sampling , and scale back these frequencies to count values with the ( noisy ) total number of visits in the dataset . The main idea is that sampling requires only a small amount of noise to guarantee privacy , while the total number of all visits is so large that it tolerates a large noise magnitude .
167 visits in the dataset ( K = 167 tal number of visits 167 having the noisy167 compute the noisy167
In particular , we estimate the histogram H where a bin Hj represents the frequency of visits at tower j , ie , Hj = t /K , where K denotes the total number of tower t ) . To do so , we sample a single visit per user uniformly at random , and create a new histogram ˜H from the sampled visits ( with size N ) . Using this approximative histogram ˜H , the tot of a tower j is computed as ( ˜Hj + L(2/ε ) ) × ˆK , where ˆK = K + L(2∆1(X)/ε ) and ∆1(X ) is universally fixed for all input dataset6 . Finally , t for each tower cell j , we can also for any IRIS cell L ( using Formula ( 1 ) ) and calculate ˆSi for all cell i in C . This technique is 2 · ( ε/2 ) = ε differential private based on Theorem 1 .
T∈T X T t=0 X j t=0 X L t t=0 X j t=0 X j t=0
Figure 6a compares the accuracy of our sampling approach to perturb the relative frequencies of each tower ( ie , sampling is followed by adding L(2/ε ) to each Hj ) with the naive Laplace approach ( ie , L(2∆1(X)/ε ) is added to each Hj without sampling ) . Sampling clearly boosts the accuracy of histogram perturbation ( Figure 6a ) especially for smaller values of ε , and eventually yields significantly more accurate estimation of167 for all towers T ( Figure 6b ) . t=0 X T t
The effect of scaling is illustrated in Figure 5a . Recall that the full privacy budget ε is divided equally between EFPA(G ) and scaling ( see Algorithm 1 ) . Hence , our sanitization scheme is ε DP ( or ( ε , δ) prob . DP with EFPAG ) based on Theorem 1 .
Smoothing
542 In order to smooth out low ( noisy ) counts around the local minimas ( around 4:00 AM each day ) , we fit an exponential curve to the noisy counts between 0:00 AM and 4:00 AM
6∆1(X ) is fixed to 732 in this paper . Notice that although ∆1(X ) is large so is K : K = 137 , 255 , 052 in our dataset , and |K − ˆK|/K is less than 10−5 on average
( a ) Perturbing H with sampling
167 Figure 6 : Perturbing the total visits167 and without sampling .
( b ) MRE of the noisy t=0 X T t over all towers T . t=0 X T t of each tower cell T . pute parameters a , b such that the error where the counts are exponentially decreasing , and another exponential curve between 4:00 AM and 6:00 AM , where the counts are exponentially increasing . In particular , we fit function g(x , a , b ) = a·exp(b·x ) to the noisy counts , ie , comi( ˆXi−g(xi , a , b))2 is minimized where xi runs over the hours of the given time intervals for each day , and then replace the noisy counts with the values of the fitted function . This is a standard non linear least square fitting problem which can be approximated with any numerical minimization method ( eg , Levenberg Marquardt algorithm [ 18] ) . Since this operation is performed on the noisy time series , it is already private . The effect of smoothing in illustrated in Figure 5b .
6 . PERFORMANCE EVALUATION
We evaluate the utility of our scheme depending on the guaranteed privacy ( ie , ε ) with EFPA and EFPAG , where δ = 2 · 10−6 < 1/N . The minimum total count τ used in Algorithm 3 is adjusted such that the expected RSSE is less than 1 % of the total count when all coefficients are retained 168 · σ/0.01 , where σ2 is the in EFPA(G ) . That is , τ = variance of noise added to each coefficient . We compare our approaches to the naive Laplace mechanism ( LPA ) that adds L(/ε ) noise to each count of each time series in cover C . We use the CDR dataset described in Section 4 .
√
First , we analyze the utility depending on the presampling size . Then , we show how pre sampling combined with the improved scaling and smoothing boost accuracy , and also report the error distribution among individual IRIS cells . Finally , we measure the Earth Mover ’s Distance ( EMD ) which captures the error between spatial distributions in terms of geographical distances . 6.1 Utility depending on the pre sample size Recall that the number of visits retained per user ( ie , ) determines the injected noise in the perturbation phase . In general , larger values of imply larger noise , which degrades utility . On the other hand , smaller values of preserve more information about individuals which results in a more accurate representation of the original dataset . The goal is to select a value of which yields the best trade off . Nevertheless , we experimentally show next that our scheme exhibits stable performance with quite different values of .
In Figure 7 , we report the utility of our scheme with EFPAG for three values of : 10 , 30 and 168 . In each case , perturbation is followed by the improvements described in
0204060810ε′/210−310−210−1100Jensen Shannondivergencewithsamplingw/osampling0204060810ε′000005010015020025030035040045MREwithsamplingw/osampling Figure 7 : Utility depending on the pre sampling size .
( a ) Relative error
( b ) EMD
Figure 9 : Error depending on time with EFPAG ( ε = 0.3 , = 30 )
Figure 8 : Utility of our scheme with different perturbation techniques .
Section 54 Specifically , we computed the average of MRE and Pearson correlation over all cells . We repeated the whole process 20 times and plotted the mean and standard deviation of the average MRE and PC over all executions .
LPA has significantly larger error for all values of , and provides especially poor results for smaller values of ε . By contrast , our scheme does not only provide practical utility even for stringent privacy guarantee , but also has stable performance for different . For instance , for ε = 0.3 , MRE is less than 20 % , while PC is larger than 095 Therefore , the output of our scheme has almost perfect linear correlation with the original data thanks to the combination of clustering and the Fourier perturbation approach . Moreover , the variations of these values are very moderate : 0.2 ± 0.03 and 0.95± 0.03 , respectively , for different values of . In the rest of the paper , we fix to 30 .
EFPAG and EFPA7 are compared in Figure 8 . EFPAG outperforms EFPA especially for smaller ε : MRE is reduced by 0.03 and PC is increased by 0.02 on average . 6.2 Pre sampling with scaling
The distortion effect of pre sampling is mitigated by the improved scaling step detailed in Section 541 Our aim now is to show that scaling and smoothing indeed results in better utility . Figure 8 depicts a variation of our scheme , denoted by ” EFPA− ” when the improvements described in Section 5.4 are not employed after perturbation . The results show that MRE is reduced by 0.07 on average when the presample size is diminished to = 30 and improvements are employed . By contrast , PC is increased only by about 0.01 for smaller values of ε ; the change is not so significant due to the fact that scaling does not influence linear correlation ,
7Recall that EFPAG adds Gaussian noise whereas EFPA adds Laplacian noise to the retained Fourier coefficients .
Figure 10 : Error and Pearson correlation on IRIS cells with EFPAG , = 30 . The box extends from the lower to upper quartile values of the cell errors , with a red line at the median . and smoothing modifies relatively small number of counts in general .
In Figure 9 , we also plotted the average relative error depending on the time for our scheme with and without improvements . In particular , we computed the relative error and took the average over all cells in each hour . Figure 9a confirms that scaling significantly diminishes the relative error in daylight when counts are larger . The improvement can be almost a factor of 4 . This has particular importance in practice , as location counts in daylight are usually more important than at night . 6.3 Error variation among IRIS cells
Figure 10 shows through box plots how MRE and Pearson correlation change among IRIS cells ; we compute these metrics for each IRIS cell , and compute the corresponding box plot over the metric values of all cells . Although medians do not change significantly for different values of ε , MRE has larger variation for smaller ε , ie , there are more cells which have larger error .
The MRE and PC of individual IRIS cells are also illustrated by color maps in Figure 11 . This figure shows that our scheme can provide practical utility for most cells with strong privacy guarantee . Specifically , the average MRE over all cells is only 0.17 with ε = 03 6.4 Earth Mover ’s Distance
In order to compare the sanitized spatial probability distribution with the original one at a given time , we use Earth Mover ’s Distance ( EMD ) [ 25 ] . EMD measures the “ amount of energy ” ( or cost ) needed to transform one distribution to another , and is a metric for probability distributions ( ie , location counts have to be normalized ) . Formally , for any
01020304050607080910ε000204060810MRE01020304050607080910ε000204060810PearsonCorrelationEFPAG,ℓ=10LPA,ℓ=10EFPAG,ℓ=30LPA,ℓ=30EFPAG,ℓ=168LPA,ℓ=16801020304050607080910ε000005010015020025030035040MRE01020304050607080910ε090092094096098100PearsonCorrelationEFPAG−(ℓ=168)EFPAG−(ℓ=30)EFPAG(ℓ=168)EFPAG(ℓ=30)EFPA(ℓ=30)MoTuWedThuFriSatSun41220412204122041220412204122041220000102030405EFPAGEFPAGno impMoTuWedThuFriSatSun41220412204122041220412204122041220020040060080010001200140016001800EMD(meters)EFPAEFPAGLPA01020304050607080910ε000102030405MRE01020304050607080910ε088090092094096098100PearsonCorrelation [ 4 ] T H H . Chan , E . Shi , and D . Song . Private and continual release of statistics . ACM Trans . Inf . Syst . Secur . , 14(3):26:1–26:24 , Nov . 2011 .
[ 5 ] R . Chen , G . ´Acs , and C . Castelluccia . Differentially private sequential data publication via variable length n grams . In ACM CCS , pages 638–649 , 2012 .
[ 6 ] C Y Chow and M . F . Mokbel . Trajectory privacy in location based services and data publication . SIGKDD Explor . Newsletter , 13(1):19–29 , Aug . 2011 .
[ 7 ] G . Cormode , C . Procopiuc , D . Srivastava , E . Shen , and T . Yu . Differentially private spatial decompositions . In ICDE , pages 20–31 , 2012 .
[ 8 ] Y A de Montjoye , C . A . Hidalgo , M . Verleysen , and V . D .
Blondel . Unique in the crowd : The privacy bounds of human mobility . Scientific Reports , Nature , March 2013 . [ 9 ] C . Dwork , K . Kenthapadi , F . McSherry , I . Mironov , and
M . Naor . Our data , ourselves : privacy via distributed noise generation . In EUROCRYPT , pages 486–503 , 2006 .
[ 10 ] C . Dwork , F . McSherry , K . Nissim , and A . Smith .
Calibrating noise to sensitivity in private data analysis . In TCC , pages 265–284 , 2006 .
[ 11 ] C . Dwork , M . Naor , T . Pitassi , and G . N . Rothblum .
Differential privacy under continual observation . In ACM STOC , pages 715–724 , 2010 .
[ 12 ] L . Fan and L . Xiong . Real time aggregate monitoring with differential privacy . In ACM CIKM , pages 2169–2173 , 2012 . [ 13 ] P . Golle and K . Partridge . On the anonymity of home/work location pairs . In Percom , pages 390–397 , 2009 .
[ 14 ] M . C . Gonzalez , C . A . Hidalgo , and A L Barabasi .
Understanding individual human mobility patterns . Nature , 453 , 2008 .
[ 15 ] M . G¨otz . On User Privacy in Personalized Mobile Services .
PhD thesis , Cornell University , May 2012 .
[ 16 ] J . E . Hopcroft and R . M . Karp . An n5/2 algorithm for maximum matchings in bipartite graphs . SIAM Journal on Computing , 2(4 ) , 1973 .
[ 17 ] G . Kellaris and S . Papadopoulos . Practical differential privacy via grouping and smoothing . In VLDB , pages 301–312 , 2013 .
[ 18 ] K . Levenberg . A method for the solution of certain non linear problems in least squares . Quarterly of Applied Mathematics , 2:164–168 , 1944 .
[ 19 ] N . Li , W . Yang , and W . Qardaji . Differentially private grids for geospatial data . In ICDE , pages 757–768 , 2013 . [ 20 ] A . Machanavajjhala , D . Kifer , J . M . Abowd , J . Gehrke , and L . Vilhuber . Privacy : Theory meets practice on the map . In ICDE , 2008 .
[ 21 ] F . McSherry . Privacy integrated queries : an extensible platform for privacy preserving data analysis . In SIGMOD , pages 19–30 , 2009 .
[ 22 ] F . McSherry and K . Talwar . Mechanism design via differential privacy . In FOCS , 2007 .
[ 23 ] D . J . Mir , S . Isaacman , R . C´aceres , M . Martonosi , and
R . N . Wright . Dp where : Differentially private modeling of human mobility . In BigData Conference , pages 580–588 , 2013 .
[ 24 ] V . Rastogi and S . Nath . Differentially private aggregation of distributed time series with transformation and encryption . In SIGMOD , 2010 .
[ 25 ] Y . Rubner , C . Tomasi , and L . J . Guibas . The earth mover ’s distance as a metric for image retrieval . Int . J . Comput . Vision , 40(2):99–121 , Nov . 2000 .
[ 26 ] G . Strang . The discrete cosine transform . SIAM Rev . ,
41(1):135–147 , Mar . 1999 .
[ 27 ] X . Xiao , G . Bender , M . Hay , and J . Gehrke . iReduct :
Differential privacy with reduced relative errors . In SIGMOD , pages 229–240 , 2011 .
[ 28 ] H . Zang and J . Bolot . Anonymization of location data does not work : A large scale measurement study . In Mobicom , pages 145–156 , 2011 .
( a ) LPA ( Avg . MRE : 1.01 , PC : 0.47 )
( b ) Our scheme with EFPAG ( Avg . MRE : 0.17 , PC : 0.96 ) t , k X k i fij ≤ ˆX j t / k
L L t , ˆX t , EMD(X j fij ≤ X i t ) = min{fij} t /
Figure 11 : MRE and PC of each IRIS cell ( = 30 , ε = 0.3 ) i,j fijdij such that fij ≥ 0 , t , where {fij} ˆX k denotes the set of all possible flows ( each fij represents the amount of probability mass transported from IRIS cell i to j ) , and dij is the geographical distance between the centers of cells i and j , resp . Intuitively , EMD measures the meters of error between two spatial density maps . Figure 9b reports the EMD depending on the time . The mean EMD over the whole week is 258 meters for EFPA , 188 meters for EFPAG , and 341 meters for LPA .
7 . CONCLUSIONS
The goal of this work is to demonstrate through a realworld application that differential privacy can be a practical model for data anonymization , even if the input dataset has large dimension and/or is highly sensitive . We showed that , in order to achieve meaningful accuracy , the sanitization process has to be carefully customized to the application and public characteristics of the dataset . We strongly believe that there are no “ universal ” sanitization solutions that fit all applications , ie , provide good accuracy in all scenarios . In particular , achieving the best performance requires to find the most faithful and concise representation of the data , such that it withstands perturbation . In our application ( ie , spatio temporal density ) , clustering and sampling with Fourier based perturbation are seemingly the best choices due to the periodic nature and large sensitivity of location counts . We experimentally showed that our scheme can provide practical utility and strong privacy guarantee .
8 . REFERENCES [ 1 ] G . ´Acs , R . Chen , and C . Castelluccia . Differentially private histogram publishing through lossy compression . In ICDM , 2012 .
[ 2 ] M . E . Andr´es , N . E . Bordenabe , K . Chatzikokolakis , and
C . Palamidessi . Geo indistinguishability : Differential privacy for location based systems . In ACM CCS , pages 901–914 . ACM , 2013 .
[ 3 ] J . A . Bondy and U . S . R . Murty . Graph Theory with
Applications . Elsevier , New York , 1976 .
MRE000008016024032040048056064PC0001020304050607080910MRE000008016024032040048056064PC0001020304050607080910
