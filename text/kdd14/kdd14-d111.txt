Quantifying Herding Effects in Crowd Wisdom
Ting Wang
Dashun Wang
Fei Wang
IBM TJ Watson Research Center
Yorktown Heights , NY
{tingwang , dashun , fwang}@usibmcom
ABSTRACT In many diverse settings , aggregated opinions of others play an increasingly dominant role in shaping individual decision making . One key prerequisite of harnessing the “ crowd wisdom ” is the independency of individuals’ opinions , yet in real settings collective opinions are rarely simple aggregations of independent minds . Recent experimental studies document that disclosing prior collective opinions distorts individuals’ decision making as well as their perceptions of quality and value , highlighting a fundamental disconnect from current modeling efforts : How to model social influence and its impact on systems that are constantly evolving ? In this paper , we develop a mechanistic framework to model social influence of prior collective opinions ( eg , online product ratings ) on subsequent individual decision making . We find our method successfully captures the dynamics of rating growth , helping us separate social influence bias from inherent values . Using large scale longitudinal customer rating datasets , we demonstrate that our model not only effectively assesses social influence bias , but also accurately predicts long term cumulative growth of ratings solely based on early rating trajectories . We believe our framework will play an increasingly important role as our understanding of social processes deepens . It promotes strategies to untangle manipulations and social biases and provides insights towards a more reliable and effective design of social platforms .
Categories and Subject Descriptors H28 [ Database Management ] : Database Applications— Data mining ; J.4 [ Social and Behavior Sciences ] : Sociology
General Terms Algorithms , Experimentation
Keywords Crowd wisdom ; social influence ; herding effect Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than ACM must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee . Request permissions from permissions@acmorg KDD’14 , August 24–27 , 2014 , New York , NY , USA . Copyright 2014 ACM 978 1 4503 2956 9/14/08 $1500 http://dxdoiorg/101145/26233302623720
1 .
INTRODUCTION
With the explosive growth of information , our decisions are increasingly relying on aggregated opinions contributed by others , with the belief that the aggregations over a large population can successfully harness the “ wisdom of crowds ” [ 22 ] . Indeed , rooting back to Galton [ 8 ] , many studies have shown that collective opinions of a group are often closer to the truth than the answer of an individual to a question . While the crowd wisdom applies usefully to a spectrum of domains , ranging from product or service recommendation [ 10 ] and crowdsourcing [ 5 , 20 , 26 ] to stock markets and political elections [ 22 ] , one key prerequisite of harnessing the crowd wisdom is the independency of individuals’ opinions [ 22 ] . Indeed , most if not all of the times , individuals are exposed to others’ opinions before forming and expressing their own . As concrete examples , we go to the theater after checking reviews of the movies online ; we download songs from the hit list ; we purchase products or go to restaurants after researching what others think about them . As a result , the market does not simply aggregate pre existing individual preferences , but rather creates an environment rich in social influence .
Thanks to the availability of Web based experiments , recent studies offered convincing evidence that social influence exerts important but counterintuitive effects on collective judgement [ 16 , 19 ] . Indeed , through carefully designed control experiments in different settings , these studies demonstrate that disclosing prior collective opinions distorts individuals’ decision making as well as their perceptions of quality and value , creating herding effects that are irrational and pervasive , yet consequential to market outcome . Despite the significance of these results in experimental settings , there has been no quantitative framework to model social influence and its impact on systems that are constantly evolving . Indeed , models on collective intelligence , from majority voting to collaborating filtering to crowdsourcing [ 5 ] , all assume independent crowds , representing a critical gap between modeling frameworks and empirical insights .
Here we develop a mechanistic framework to model social influence of prior collective opinions ( eg , product ratings ) on subsequent individual decisions , namely , Herding Effect Aware Rating Dynamics Model ( Heard ) . Using 28 million ratings spanning over 18 years on over 1.7 million products from Amazon [ 15 ] as an exemplary case , we demonstrate that our method successfully captures the dynamics of rating growth across different product categories , allowing us to separate social biases introduced by prior ratings from the true values inherent to products . We further show that ,
1087 comparing with competing methods , our framework not only effectively detects the presence of social biases and gauges less biased values for any given product , but also accurately predicts the long term cumulative growth of ratings through a scalable estimation model solely based on early rating trajectories . As a result , Heard can also make testable predictions of collective response to artificial manipulations in rating systems , assisting in further testings through more systematic experiments .
To the best of our knowledge , this work represents one of the first few quantitative framework to model social influence biases introduced from prior opinions . We believe our method is of fundamental importance to studies of social processes , promotes new strategies in untangling manipulations and biases within social environments , and provides significant insights towards design of platforms that aggregate individual opinions , from electoral polling to market analysis to product recommendation .
The remainder of the paper will proceed as follows . Section 2 surveys relevant literature . Section 3 details the model design of Heard and develops efficient inference algorithms to fit the model . Section 4 presents a scalable algorithm to predict the future rating growth based on Heard . Section 5 empirically evaluates the proposed models and algorithms . The paper is concluded in Section 6 .
2 . RELATED WORK
In this section , we review three categories of related work , namely , social network induced influence , measuring social influence in experimental settings , and effect of semantics of prior opinions .
Social networks have attracted significant interest , partly due to the availability of large datasets in many domains . One active line of enquiry in social network studies is how behavior [ 1 , 2 ] , opinion [ 7 ] , and information [ 13 , 24 , 3 ] spreads through social networks . It is conceivable that microscopic social interactions could induce influence that is visible on an aggregated level [ 25 ] . In a way , the process of generating collective opinions is similar to consensus formation [ 11 ] . For example , individuals may change their opinions after learning about what their friends think . This is supported by experimental results by Lorenz et al . [ 14 ] , in which they demonstrated that even mild social interactions can significantly bias simple estimation tasks . Therefore , Das et al . [ 4 ] proposed a social sampling method that takes into account individuals’ influence from their social neighbors and arrives at a de biased estimation of collective opinions . While this line of research shows that social interactions can exert influence on overall outcome , their focus on networks inevitably distinguishes themselves from our work . Indeed , often times , the population responsible for collective opinions are not interactive . You choose a restaurant , go watch a movie , or purchase a book , because of the opinions or reviews authored by people you do not know . Therefore , our work focuses on how to model social influence on a macroscopic level and hence predict the outcome of crowd wisdom .
On the other hand , there have been a number of experimental studies on measuring social influence within a population , thanks to the emergence of Web based experiments . For example , Salganik et al . [ 19 ] implemented a music lab , where individuals download and rate songs with or without information about how good the songs are , and they demonstrated that increasing social influence could result in differential outcomes for songs of similar quality . Muchnik et al . [ 16 ] ran a large scale randomized experiment on a reddit like website , finding that prior ratings created significant bias in individual rating behavior , from turnout to binary choices . These studies confirmed experimentally that disclosing prior ratings can create strong herding effects that are irrational and pervasive , leading to significant bias that is consequential to collective outcome . At the same time , they also highlight a fundamental gap between experimental insights and modeling efforts . Our work directly addresses this gap : To the best of our knowledge , this work is among the first few attempt to quantitatively model the herding effects in crowd wisdom and develop effective mechanisms to factor out such bias in estimation .
Finally , there have been a number of interesting studies into the semantics of collective opinions , such as that analyze the text and social aspects of product reviews [ 10 , 15 , 21 , 9 ] . While they are useful for review spam detection , customer sentiment analysis , product recommendation , and more , insights extracted from semantic features are , however , not mechanistic , hence not capable of projecting the full rating trajectories . Nevertheless , these studies are complementary to our work , in a sense that the useful semantic features learned can be integrated into our model in forms of prior belief of model parameters . Indeed , one shall see in next sections that incorporating such text and social information into the rating growth model would be a promising future direction .
Our work also draws connections to other modeling efforts . The design of our herding effects model is inspired by the multi neuron coupled spiking phenomena [ 17 ] . The exponential additive generative mechanism has been applied in modeling latent topics for text [ 6 ] . Our work differs in proposing a more general form of generative model and developing scalable inference algorithms to fit the model . 3 . MODEL AND ALGORITHM
In this section , we detail the design of the Heard model and present efficient inference algorithms to fit the model . Concretely , we draw an analogy to the coupled spiking phenomena in a multi neuron system to model the dynamics of rating growth and fit the model parameters using maximum likelihood estimation . 3.1 HEARD Model
Without loss of generality , we consider a discrete K level rating system , which is extensively used by today ’s online retailers ; for example , Amazon adopts a one to five star rating system . Consider the sequence of ratings regarding a specific product , with ri ∈ {1 , 2 , . . . , K} being the i th rating . We assume the first ( i − 1 ) ratings form the history for ri : xi = [ xi,1 , xi,2 , . . . , xi,K ] , where xi,k represents the proportion of level k ratings among the first ( i − 1 ) ratings . k=1 xi,k = 1 for i > 1 and x1 is an all zero vector . We intend to model how disclosing such rating history would influence individual rating behavior on ri .
Clearly , K
Intuitively , the generation of a new level k rating is driven by multiple factors , including : the intrinsic product quality , the occurrence of preceding level k ratings , and the history of other ratings . We can draw a close analogy to the spiking activities of a multi neuron system [ 17 ] : the response ( ie , spike ) generated by a neuron is jointly determined by the stimulus strength and the preceding spikes of this neuron
1088 0 otherwise . Then the log likelihood of parameters Θ given this rating sequence is expressed as :
L(Θ ) =
=
1 N
1 N
N K i=1 log
N i=1 k=1
P r ( ri|xi , Θ ) yi,k log k xi k xi exp,µk + fiθ k=1 exp,µk + fiθ K F + R(f ),||Θ||2
( 2 )
Lλ(Θ ) = −L(Θ ) +
λ 2
We estimate the model parameters by minimizing the pe nalized log likelihood function , which is defined as :
R(f ) = ∞ where the first term represents the negative log likelihood , the second term is a regularizer with λ being the balance parameter to prevent overfitting , and ||·||F denotes the matrix Frobenius norm . In particular , R(f ) is a penalty term preferring smooth functions . Without prior knowledge , we use 0 ( f(t))2dt , where f(· ) represents the derivative of f ( · ) . While Lλ(Θ ) appears similar to the softmax regression ; it contains the integral of an unknown function and meanwhile all the parameters are coupled , which makes it difficult to directly apply off the shelf optimization methods ( eg , coordinate descent ) . Next we propose an iterative algorithm which optimizes Lλ(Θ ) by ( i ) constructing a surrogate function to decouple the parameters and ( ii ) applying an EulerLagrange equation to fit the unknown function .
1
, θ(n )
, . . . , θ(n )
More specifically , let Θ(n ) = [ θ(n )
K , µ(n ) ] denote the current parameter setting . We construct the following surrogate function Q(Θ ; Θ(n) ) , which is a tight upper bound of Lλ(Θ ) : 1 N i,k − yi,k
φi,k
2
Q(Θ ; Θ(n ) ) = i k
φ2 i,k +
F + R(f ) + ,||Θ||2 k i
φi,k − 2 i,k − 2φ(n ) β(n )
φ(n ) i,k k
1 N
− 1 N K
+
λ 2
C ( n ) i k
φi,k
( 3 ) i,k and C ( n ) i i are defined below :
φi,k = µk + fiθ φ(n ) i,k = µ(n ) where the terms φi,k , φ(n ) i,k , β(n ) k xi i θ(n ) k + f ( n )
φ(n ) i,k
β(n ) i,k = exp k k exp
φ(n ) i,k xi
C ( n ) i
= i,k φ(n ) i,k i,k − β(n )
φ(n)2 exp
φ(n ) i,k k k
+ log
− 1
K k
2
φ(n ) i,k
It is noted that Q(Θ ; Θ(n ) ) possesses the following desir able properties ( details in Appendix ) : fl Q(Θ ; Θ(n ) ) ≥ Lλ(Θ )
∀Θ , Θ(n )
Q(Θ ; Θ(n ) ) = Lλ(Θ(n ) ) ∀Θ(n ) which imply that if Θ(n+1 ) = arg minΘ Q(Θ ; Θ(n) ) , then we must have Lλ(Θ(n ) ) ≥ Lλ(Θ(n+1) ) . Therefore , minimizing
Figure 1 : Illustration of HEARD model . The occurrence of a new level k rating is jointly influenced by ( i ) the intrinsic quality of product , ( ii ) the preceding level k ratings , and ( iii ) the history of other ratings . and correlated neurons . We therefore introduce an additive generative model to describe the distribution of the i th rating ri over different levels : exp,µk + f ( i)θ k=1 exp,µk + f ( i)θ K k xi k xi
( 1 )
P r ( ri = k|xi ) =
This conditional distribution describes the likelihood of In this observing a level k rating given rating history xi . general formulation , we have :
• µ = [ µ1 , µ2 , . . . , µK ] ∈ RK represents the coefficients of an intrinsic distribution , which is assumed related to the true quality of the product .
• f ( ·)1 is the magnitude function , which describes the relationship between the strength of herding effects and the number of historical ratings ; in particular , we have f ( 1 ) = 0 .
• θk ∈ RK weighs the different components of xi . Note that our model captures both positive and negative influence . Concretely , when the k th component θk,k > 0 , the preceding level k ratings excite the occurrence of level k ratings ; while if θk,k < 0 , the level k ratings inhibit the generation of new level k ratings .
These factors are then integrated in an exponential func tion , as illustrated in Figure 1 .
Note that here we ignore the time dimension in our model because various external factors may abruptly influence the temporal dynamics of rating growth , eg , low price promotion , emergence of new products , advertisements , etc . Let Θ = [ θ1 , θ2 , . . . , θK , u ] represent all the parameters . Both Θ and magnitude function f ( · ) are estimated from data ; in particular , f ( · ) is estimated from an infinite dimensional functional space . Next we elaborate their inference . 3.2 Model Inference We assume regarding a specific product , a temporally ordered sequence of N ratings {ri}N i=1 has been observed . Note that while we focus on the case of a single product for ease of presentation , the extension to multiple products is straightforward . For notational simplicity , we introduce a set of indicator variables yi ∈ {0 , 1}K with yi,k = 1 if r(i ) = k and 1In the following , we use fi as a short notation of f ( i ) . intrinsic quality exponentialnon linearityprobabilisticspikinglevel k rating historylevel k‘ rating historypredictiontimeex1089 Q(Θ ; Θ(n ) ) with respect to Θ at each iteration will ensure that Lλ(Θ ) decreases monotonically . Updating Parameters The formulation above has the advantage that we can derive the closed form solution of Θ for arg minΘ Q(Θ ; Θ(n) ) . Specifically , by deriving the derivatives of Q(Θ ; Θ(n ) ) with respect to µk and θk,k and set them to zero , we obtain their update rules as follows :
K i
µ(n+1 ) k
=
K i fixi,k
2(K − 1 ) yi,k − β(n ) i,k
θ(n+1 ) k,k = yi,k − β(n ) 2N ( K − 1 ) + N Kλ i,k
+ 2N ( K − 1)µ(n ) k
( 4 )
+ 2(K − 1 ) i f 2 i x2 i,k + N Kλ i f 2 i x2 i,k θ(n ) k,k
( 5 )
Updating Magnitude Function Next we derive the update rule for magnitude function f ( · ) by optimizing it in an infinite dimensional functional space . We extract the parts of Q(Θ ; Θ(n ) ) relevant to f ( · ) and then reformulate the problem of minimizing Q(Θ ; Θ(n ) ) with respect to f ( · ) as follows : on individual rating behaviors . Under this assumption , we have the following setting :
N i=1 yi,k
N
µk = log fi = 0 k = 1 , 2 , . . . , K i = 1 , 2 , . . . , N
( 8 )
Meanwhile we initialize θ1 , θ2 , . . . , θK randomly .
Putting everything together , Algorithm 1 sketches the procedure of model inference . After initialization , it iterates between updating parameters Θ and solving magnitude function f ( · ) until the objective function converges . Algorithm 1 : Inference of HEARD Model Input : rating history {ri}N Output : setting of parameters Θ and function f // initialization initialize Θ and f according to Eqn.(8 ) ; compute statistics {xi}N // iterative optimization while not converged yet do i=1 ; i=1
// update parameter for k = 1 , 2 , . . . , K do update µk following Eqn.(4 ) ; for k = 1 , 2 , . . . , K do update θk,k following Eqn.(5 ) ;
( f
( t))2dt
( 6 )
// update magnitude function compute {fi}i by solving differential Eqn.(7 ) ;
2 return setting of Θ and f ;
4 . APPLICATION where terms Ai and Bi are defined below : min f∈L1(R )
Aif 2 i +
Ai =
Bi =
1 N
1 N i k k
2
θ(n ) k
+
N K k i
0
λ 2
Bifi +
+∞
2 − 1 i,k + β(n )
N K xi k
θ(n ) k xi
2µ(n ) k − 2φ(n ) i,k − yi,k
θ(n ) k xi k
θ(n ) i,k −
φ(n ) xi
µ(n ) k k k
Abusing the notation a little , we introduce two functions : A(t ) = AtI{t ≤ N ∧ t ∈ N} and B(t ) = BtI{t ≤ N ∧ t ∈ N} , where I{·} is the indicator function which returns 1 if the predicate is true and 0 otherwise .
Then the solution of the objective function as defined in Eqn.(6 ) must satisfy the Euler Lagrange equation [ 27 ] ( proof referred to Appendix ) :
2A(t)f ( t ) + B(t ) − λf
( t ) = 0
( 7 ) where g(· ) is the second order derivate of g(· ) .
Due to the discrete nature of the functions A(t ) and B(t ) , we solve this differential equation numerically using a Seidal type iteration . Specifically , we discretize the differential equations over intervals of length 1 :
λ(fi+1 − 2fi + fi−1 ) − 2Aifi − Bi = 0
Clearly from the equations above we can efficiently solve fi for i = 1 , 2 , . . . , N . We may then perform curve fitting to extrapolate the values of fi for i > N . Complete Algorithm To set a proper starting point for optimization , we consider the degenerated case where the prior ratings have no effect
In this section we show that equipped with the aforementioned Heard model , we are able to answer a set of fundamental questions , including :
Debiasing : What is the intrinsic quality of a product after factoring out the herding effects from its collective ratings ?
Prediction : Based on its rating history , can we predict the distribution of its next 100 ratings ?
What If Analysis : Given its current ratings , how would its future ratings be “ herded ” if we could “ inject ” in 50 five star ratings ?
Next we detail how to answer these questions . 4.1 Debiasing Collective Ratings
To the first question , recall that the Heard model defined in Eqn.(1 ) comprises two additive components , namely , the intrinsic distribution and the herding effect distributions . The background intrinsic distribution as controlled by parameters {µk} is assumed related to the true quality of a product . Therefore , once we have estimated {µk} from the rating history of a product , we can then “ debias ” the collective ratings by factoring out the components attributed to the herding effects . More concretely , abusing the notation a little , let µ = [ µ1 , µ2 , . . . , µK ] . Without the herding effects , each rating is generated by the following unconditional categorical distribution :
η = exp(µ ) k exp(µk )
( 9 )
1090 which represents the intrinsic rating of the product .
The straightforward solution to estimating µ of a given product is to directly fit the model parameters using its rating history as in Algorithm 1 , which however may lead to overfitting . Instead , we introduce an “ out of sample ” extension . As will be detailed in Section 5 , the herding effects often follow similar patterns for products of the same category ( eg , books ) . We therefore use the rating histories of a bulk of products in the same category to train category level parameters {θk} and magnitude function f ( · ) . For the query product , we fix {θk} and f ( · ) and focus on learning productlevel parameter µ . As shown in Algorithm 2 , this procedure is similar to Algorithm 1 , except that at each iteration we only need to update µ .
Algorithm 2 : Out of Sample Extension Input : rating history {ri}i of query product , setting of
{θk}k and f ( · )
Output : setting of µ for given product // initialization initialize µ according to Eqn.(8 ) ; compute statistics {xi}i ; // iterative optimization while not converged yet do
// update parameter for k = 1 , 2 , . . . , K do update µk following Eqn.(4 ) ; return µ ;
4.2 Predicting Rating Growth
Another interesting question one may pose is : given the current rating history of a product , is it possible to predict the distribution of it future ratings ? While it is of theoretical interest to discuss the statistical convergence properties of the rating distribution as the number of ratings approaches infinity ; in real settings , most products during their lifetimes receive only limited number of ratings . We thus focus on a more concrete question as follows :
Given the first N ratings of a product , can we characterize the distribution of its next M ratings ?
Let us first consider the herding effects agnostic case , in which each rating is independently generated by the categorical distribution as defined in Eqn(9 ) Under this assumption , the next M ratings follow a multinomial distribution ; specifically , the expected number of level k rating is given by M ηk with variance M ηk(1 − ηk ) . Next we incorporate the herding effects . Recall that the distribution of the first ( i − 1 ) ratings is given by xi , which also corresponds to the history for the i th rating . The transition probability from xi to xi+1 can be described as below :
P r xi+1 = i − 1 i xi + ek i fififi xi
= exp(φi,k ) k exp(φi,k )
( 10 ) where ek is a 1 of K vector with the k th element being 1 . Note that this transition rule essentially specifies a nonstationary Markov chain in which both the state space and the transition probability change from step to step . This setting is not amenable to exact inference ; we thus resort to Monte Carlo methods [ 18 ] .
Algorithm 3 sketches our prediction model . Starting with current rating distribution xN +1 estimated from the given rating history , it iteratively samples the next rating distribution using the transition rule in Eqn(10 ) Let {x(i ) N +M +1}L i=1 be the set of samples of target distribution xN +M +1 and ˆxN +M +1 = 1 N +M +1 be the expectation of target L distribution . We can prove that for given thresholds and δ , if the sample size L satisfies the following condition :
L i=1 x(i )
L ≥ 1
2 δ
2 2 log
( 11 ) then | ˆxN +M +1−xN +M +1| ≤ 1 with probability at least 1− δ , where 1 denotes a K dimensional all ones vector ( details given in Appendix ) .
δ )M K , thereby scaling up to large M .
It is also noted that Algorithm 3 features the complexity of O , 1
2 log( 1
Algorithm 3 : Prediction of Rating Growth Input : rating history {ri}N i=1 , prediction range M , error threshold
Output : estimation of rating distribution xN +M +1 // initialization estimate Θ and f by Algorithm 1 ; compute required sample size L by Eqn.(11 ) ; compute xN +1 from {ri}N // random sampling for i = 1 , 2 , . . . L do N +1 ← xN +1 ; x(i ) for j = 1 , 2 , . . . , M do i=1 ; sample x(i )
N +1+j according to Eqn.(10 ) ; store x(i )
N +M +1 ; estimate E[xN +M +1 ] by 1
L
4.3 What If Analysis
L i=1 x(i )
N +M +1 ;
The Markovian nature of the Heard model also enables us to perform the “ what if ” analysis . Concretely , given the current rating distribution xi , one may arbitrarily change xi to another distribution x i to reflect any artificial conditions one wishes to “ inject ” in ( eg , a burst of 50 five star ratings due to certain promotion campaigns ) . Staring from this new state x i and applying the prediction method above , one may then gauge the consequences of the injected conditions by predicting the trends of future rating growth .
Such what if analysis is especially valuable for a range of applications including market profitability estimation , budgeted advertising , and fraudulent manipulation detection .
5 . EVALUATION
In this section we present an empirical evaluation on the efficacy of the proposed models and algorithms . 5.1 Experimental Setting
We start with introducing the datasets and the alternative techniques to be evaluated . Real Customer Rating Data We evaluate different models using the real customer rating data collected from Amazon , which spans a period of approximately 18 years , including around 35 million ratings regarding about 2.4 million products [ 15 ] . In particular , we
1091 Books Music Movies category # products # ratings 12,886,488 6,396,350 7,850,072 1,241,778 28,374,688
929,264 556,814 212,836 82,067
Electronics
Total
1,780,981 avg . # ratings avg . rating avg . entropy
13.9 11.5 36.9 15.1 15.9
4.271 4.410 3.944 3.791 4.253
0.666 0.555 0.955 0.824 0.673
Table 1 : Summary of Amazon customer rating dataset .
Figure 2 : Accuracy of short term prediction versus the length of rating history used for training .
Figure 3 : Accuracy of long term prediction by rating growth models under varying range of prediction .
Figure 4 : Estimated magnitude function f ( n ) and fitting curve a ∗ exp(b ∗ n ) − 1 .
030405060701020304050BooksAverage Perplexity 05101520ElectronicsProportion of Rating History for Training0102030Movies & TV0102030MusicIMGHEARDcHEARD030405060703040506070304050607100150200250300005115Difference of Avg . Ratings100150200250300002040608Range of Prediction ( Number of New Ratings)10015020025030000102030405100150200250300005115225 IMGHEARDcHEARDBooksElectronicsMovies & TVMusic04080120160 020206114 020406080 050051152020406080−05005115225304080120160−050515253545magnitude function ffitting curve : a*exp(b*n) 1BooksElectronicsMovies & TVMusica = 0.8436b = 0.007a = 0.8195b = 0.0165a = 0.7982b = 0.0201a = 0.7778b = 0.0129Number of Historical Ratings ( n)f(n)1092 focus on the products in four major categories : Books , Music , Movies & TV , and Electronics , which cover over 72 % of the total number of products in the collection . The statistics of this rating dataset is summarized in Table 1 . It is noticed that these four categories demonstrate fairly diverse characteristics , for example , with average rating entropy ranging from 0.56 to 096 Alternative Models For comparison purposes , besides the Heard model , we implemented two additional rating growth models :
• Independent Multinomial Generative model ( Img ) . It is the null hypothesis model , which assumes each new rating is generated according to a fixed multinomial distribution over different rating levels . This multinomial model is estimated from the rating history following the maximum likelihood principle . • Constant HEARD model ( Heard c ) .
It is a simplified variant of Heard , which follows the definition of Eqn.(1 ) , except that the magnitude function is set as f ( x ) = 1 for x > 1 ; that is , it assumes the strength of herding effects stays constant regardless of the cumulative number of ratings .
We implemented all the models and associated algorithms in Matlab and conducted the experiments on a Linux box running 3.5GHz Intel i7 CPU and 16GB RAM . The default parameter setting is : λ = 1 , δ = 0.05 , and = 001 5.2 Validating Rating Growth Models
In this first set of experiments , we intend to evaluate the validity of different rating growth models . For each product in the dataset , we partition its temporally ordered sequence of ratings into two subsequences as the training ( ie , rating history ) and testing parts respectively . We use the rating history to train the rating growth models and let them predict the “ future ” ratings in the testing set . We compare their accuracy in both short term and long term prediction . Short Term Prediction In short term prediction , we vary the length of rating history ( as the proportion of the entire rating sequence of a product ) and measure the average perplexity of the prediction of the next 50 ratings by different models .
The results are shown in Figure 2 . It is noticed that across all four product categories , Heard and Heard c outperform Img in terms of prediction accuracy . In particular , when only limited data ( eg , 30 % ) is available for training , the accuracy of Img can be arbitrarily bad . This is attributed to the fact that the prediction of Img relies on the overall statistics of the rating history of each product , which however has not emerged yet at this early stage . In contrast , Heard leverages the rating histories of all the products in the same category to fit the model , thereby achieving high accuracy even when facing limited training data . This desirable property makes Heard especially valuable for early stage prediction , as we will discuss shortly .
It is also noticed that Heard achieves higher accuracy than Heard c but with marginally larger variance . This is consistent with the fact that Heard adopts a more complicated model than Heard c , which enables Heard to model a wider range of herding effects but at the cost of slightly higher variance .
Figure 5 : Heat maps of parameters {θk,k} for each product category . Long Term Prediction In long term prediction , we select the products with at least 500 ratings and fix the length of rating history ( for training ) as 200 . We then apply each model to predicting the rating distribution after the next M ratings ( M is referred to as the prediction range ) . The accuracy is measured by the difference between predicted and actual average ratings .
The performance of different models is illustrated in Figure 3 , wherein we vary prediction range M from 100 to 300 . It is observed that compared with Img and Heard c , the prediction accuracy of Heard is much less sensitive to the setting of M . This can be explained as follows . First , the prediction of Img depends on the simple statistics ( ie , fraction of ratings at different levels ) , which however may fluctuate significantly over a large time span . Second , as M increases , the change of the strength of herding effects can no longer be ignored as Heard c does .
We can thus conclude that Heard achieves reliable accuracy in both short term and long term prediction tasks , implying that Heard faithfully captures the growth dynamics of product ratings .
5.3 Characterizing Herding Effect
Next , equipped with the Heard model as the analytical tool , we conduct a quantitative study on the herding effects observable in real customer rating data . More concretely , for each product category , we apply Algorithm 1 to fitting the model and examine the herding effects as characterized by the estimated magnitude function f ( · ) and category level parameters {θk}k .
Strength of Herding Effect Recall that f ( n ) specifies the strength of herding effects as a function of the number of historical ratings n . Figure 4 illustrates the estimated f ( n ) for each product category . We further apply curve fitting to f ( n ) with an exponential model a∗ exp(b∗ n)− 1 ( a and b are parameters ) . Interestingly , the magnitude functions in all four categories tightly follow the
001−001−001000001000−000−000000001−000−001−000000001−001−001−001000003−002−002−002−000006K’KBooks 1234512345−002000002004006000−001−001000001000−000−000000001−000−000−000000001−000−001−001000002−001−002−002000005K’KElectronics 1234512345−002000002004000−000−000000001−000−000−000000000−000−001−000000001−001−001−001000003−002−002−002000006K’KMovies & TV 1234512345−002000002004006−000−000−000−000001−000−000−000000000−000−000−000000001−001−001−001−000003−002−003−002−001007K’KMusic 1234512345−0020000020040061093 Figure 6 : Cumulative proportion of products versus difference between intrinsic and external average ratings . exponential curves , despite their slightly different parameter settings of a and b .
This finding entails multi fold implications : First , it confirms our intuition that the strength of herding effects evolves with the cumulative number of historical ratings . Second , it also echoes the results documented by existing experimental studies ( eg , [ 19 ] ) on the nonlinear relationship between the predicability of individual behaviors and external influence . Third , most importantly , it provides a formula to explicitly quantify the strength of herding effects . For example , comparing the curves for the categories of Books and Movies & TV , it is observed that the herding effects is stronger in the category of Movies & TV , that is , customers are more easily to be influenced by prior ratings when purchasing Movies & TV products . Such information can be valuable for applications such as targeted advertising .
Mutual Influence Now we proceed to examining parameters {θk} . Recall that these parameters dictate the mutual influence between the ratings at different levels , concretely , with θk,k specifying how preceding level k ratings may positively excite or negatively inhibit the generation of level k ratings . Figure 5 illustrates the heat maps of {θk} estimated for each product category . While each category has its unique traits , certain common patterns are observed . First , high ratings ( eg , five star ratings ) tend to stimulate new high ratings while inhibiting the generation of low ratings . Second , high ratings are more impactful than low ratings in influencing other ratings . These observations are consistent with the finding of the asymmetric herding effects of positive and negative prior opinions as reported in [ 16 ] .
5.4 Case Studies
As discussed in Section 4 , equipped with Heard , we are able to perform various analytical tasks . In this set of experiments , we showcase how Heard helps answer two fundamental questions : ( i ) exposing the rating inherent to the quality of a product ( ie , “ intrinsic rating ” ) by factoring out the herding effects from collective ratings , and ( ii ) performing predicative , what if analysis by incorporating artificial conditions into the rating growth dynamics model .
Debiasing Collective Ratings To understand the issue that the simple aggregated ( or external ) rating of a product deviates from its true quality , we apply Heard to estimate the intrinsic ratings as in Sec
Figure 7 : Two sample products with similar intrinsic ratings but with different rating growth histories , leading to significantly distinct external ratings . tion 4.1 and then measure for each product the difference between its intrinsic and external average ratings .
Figure 6 shows the cumulative proportion of products with respect to the difference between intrinsic and external ratings in each category . It is observed that in all the cases , over 50 % products have their external ratings deviate at least 0.5 from their intrinsic ratings , which is significant considering that Amazon uses a five level rating system .
Endowed with the capability of exposing the intrinsic rating of a product , we can then compare the true quality of two products without being misguided by their external ratings . Figure 7 showcases such an example , in which the dynamics of the average external ratings of two sample products is depicted . Despite that they differ significantly in their external ratings ( about 0.9 ) , their intrinsic ratings are indeed fairly similar as shown in the right plot . This is explained by that sample product 2 experiences a sequence of low ratings at the early stage of its history , which considerably changes the dynamics of its rating growth . With the help of Heard , however , we are able to maximally debias this type of influence caused by the herding effects .
What If Analysis As introduced in Section 4.3 , the Markovian nature of the Heard model enables us to perform predicative , “ what if ” analysis by artificially incorporating desired conditions into the prediction model and analyze the consequences using simulation . For example , before deciding whether to invest in a promotion campaign for a product , market analysts may
0040812160020406081Cumulative Prop . of ProductsDifference between Intrinsic and External Average Ratings002040608100204060810020406081BooksElectronicsMovies & TVMusic0040812160040812160040812161234500102030401020304050607080354455123450010203041234535445501020304050607080Intrinsic Rating Dynamics of Average External Ratingsample product 1sample product 2Number of Historical RatingsRating Level1094 Figure 8 : What if analysis by incorporating artificial conditions into prediction model . wish to estimate the long term influence of the burst of high ratings due to the promotion .
Figure 8 shows one concrete example . We pick two sample products respectively from the categories of Movies & TV and Books , which have fairly close average ratings thus far . Now , assuming the promotion takes effect , we inject 50 fivestar ratings into their rating histories . As shown in the right panel of Figure 8 , the prediction by Heard tells us : while both products experience similar short term bursts in their popularity , in the long run the promotion has much longerlasting influence on the sample product from the category of Books . It is clear that this provides valuable information for the decision making of market analysts . 5.5 Scalability
In the last set of experiments , we evaluate the scalability of Heard . Specifically , for model inference , we measure the average execution time per product by Heard under varying length of rating history ( for training ) ; meanwhile , for future rating prediction , we measure its average execution time under varying setting of prediction range .
The results are depicted in Figure 9 . It is observed that the execution time of Heard grows approximately linearly with the length of rating history and the range of prediction . This also confirms our theoretical analysis on the complexity of Algorithm 1 and Algorithm 3 . We can thus conclude that Heard scales up to large rating datasets .
6 . CONCLUSION
This paper presented a quantitative framework to gauge the herding effects in collective opinions of individuals . We proposed Heard , a mechanistic modeling framework for the growth dynamics of online product ratings , which explicitly accounts for the herding effects of prior customer opinions . Using massive customer rating datasets , we demonstrated the efficacy of Heard in capturing the dynamics of rating growth , quantifying social influence and debiasing collective ratings , and further performing what if analysis against artificial manipulations . Heard is not limited to product rating systems . Indeed , the mechanistic nature of Heard makes it applicable for modeling the herding effects in other domains where social influence plays a role , from crowdsourcing and recommender systems to electoral polling .
This work also opens up several directions for future investigations . For example , recent work has shown that the temporal dynamics of collective response to a publication follows rather reproducible patterns , as citations can be captured by a mechanistic model [ 23 ] . Hence , incorporating the temporal dynamics in the rating growth model can be fruit
Figure 9 : Average execution time per product by HEARD in model inference and rating prediction . ful and could potentially shed new light on the nature of crowd wisdom . Furthermore , our framework is orthogonal to studies on the text and social aspects of product reviews and collective opinions , suggesting a rather promising direction by combining the two approaches . Lastly , the model makes falsifiable predictions for collective response against artificial manipulations , making it a viable candidate to assess and guide experimental studies , results of which could feed back to and improve the model with more accurate and realistic predictions . Acknowledgements This research was sponsored by the US Army Research Laboratory and the UK Ministry of Defense and was accomplished under Agreement Number W911NF 06 3 0001 . The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies , either expressed or implied , of the US Army Research Laboratory , the US Government , the UK Ministry of Defense or the UK Government . The US and UK Governments are authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation hereon . The authors would like to thank J . McAuley and J . Leskovec for sharing the Amazon review dataset . 7 . REFERENCES [ 1 ] N . A . Christakis and J . H . Fowler . The spread of obesity in a large social network over 32 years . New England journal of medicine , 357(4):370–379 , 2007 .
[ 2 ] N . A . Christakis and J . H . Fowler . The collective dynamics of smoking in a large social network . New England journal of medicine , 358(21):2249–2258 , 2008 . [ 3 ] P . Cui , S . Jin , L . Yu , F . Wang , W . Zhu , and S . Yang .
Cascading outbreak prediction in networks : A data driven approach . In KDD , 2013 .
[ 4 ] A . Das , S . Gollapudi , R . Panigrahy , and M . Salek .
Debiasing social wisdom . In KDD , 2013 .
[ 5 ] A . P . Dawid and A . M . Skene . Maximum likelihood estimation of observer error rates using the em algorithm . Journal of the Royal Statistical Society . Series C ( Applied Statistics ) , 28(1):20–28 , 1979 . [ 6 ] J . Eisenstein , A . Ahmed , and E . P . Xing . Sparse additive generative models of text . In ICML , 2011 .
[ 7 ] J . H . Fowler , N . A . Christakis , Steptoe , and D . Roux . Dynamic spread of happiness in a large social network : longitudinal analysis of the framingham heart study social network . BMJ : British medical journal , pages 23–27 , 2009 .
0204060801001201401601802003354455Rating HistoryAverage Ratinginjection of 50 five−star ratingssample product from “ Movies & TV ” sample product from “ Books ” 100200300400500025035045055065Length of Rating HistoryExec . Time per Product ( sec)100200300400500123456Range of PredictionExec . Time per Product ( sec)Inference of HEARD ModelPrediction of Rating Growth1095 [ 8 ] F . Galton . Vox populi . Nature , 75(7):450 , 1907 . [ 9 ] G . Ganu , N . Elhadad , and A . Marian . Beyond the stars : Improving rating predictions using review text content . In WebDB , 2009 .
[ 10 ] M . Hu and B . Liu . Mining and summarizing customer reviews . In KDD , 2004 .
[ 11 ] S . Judd , M . Kearns , and Y . Vorobeychik . Behavioral dynamics and influence in networked coloring and consensus . Proceedings of the National Academy of Sciences , 107(34):14978–14982 , 2010 .
[ 12 ] B . Krishnapuram , L . Carin , M . A . T . Figueiredo , and
A . J . Hartemink . Sparse multinomial logistic regression : Fast algorithms and generalization bounds . IEEE Trans . Pattern Anal . Mach . Intell . , 27(6):957–968 , June 2005 .
[ 13 ] D . Liben Nowell and J . Kleinberg . Tracing information flow on a global scale using internet chain letter data . Proceedings of the National Academy of Sciences , 105(12):4633–4638 , 2008 .
[ 14 ] J . Lorenz , H . Rauhut , F . Schweitzer , and D . Helbing .
How social influence can undermine the wisdom of crowd effect . Proceedings of the National Academy of Sciences , 108(22):9020–9025 , 2011 .
[ 15 ] J . McAuley and J . Leskovec . Hidden factors and hidden topics : Understanding rating dimensions with review text . In RecSys , 2013 .
[ 16 ] L . Muchnik , S . Aral , and S . J . Taylor . Social influence bias : A randomized experiment . Science , 341(6146):647–651 , 2013 .
[ 17 ] J . W . Pillow , J . Shlens , L . Paninski , A . Sher , A . M .
Litke , E . J . Chichilnisky , and E . P . Simoncelli . Spatio temporal correlations and visual signaling in a complete neuronal population . Nature , 454(7206):995–999 , 2008 .
[ 18 ] C . P . Robert and G . Casella . Monte Carlo Statistical
Methods ( Springer Texts in Statistics ) . Springer Verlag New York , Inc . , Secaucus , NJ , USA , 2005 .
[ 19 ] M . J . Salganik , P . S . Dodds , and D . J . Watts .
Experimental study of inequality and unpredictability in an artificial cultural market . Science , 311(5762):854–856 , 2006 .
[ 20 ] V . S . Sheng , F . Provost , and P . G . Ipeirotis . Get another label ? improving data quality and data mining using multiple , noisy labelers . In KDD , 2008 .
[ 21 ] H . Sun , A . Morales , and X . Yan . Synthetic review spamming and defense . In KDD , 2013 .
[ 22 ] J . Surowiecki . The Wisdom of Crowds . Anchor , 2005 . [ 23 ] D . Wang , C . Song , and A L Barab´asi . Quantifying long term scientific impact . Science , 342(6154):127–132 , 2013 .
[ 24 ] D . Wang , Z . Wen , H . Tong , C Y Lin , C . Song , and A L Barab´asi . Information spreading in context . In WWW , 2011 .
[ 25 ] T . Wang , M . Srivatsa , D . Agrawal , and L . Liu .
Microscopic social influence . In SDM , 2012 .
[ 26 ] D . Zhou , J . C . Platt , S . Basu , and Y . Mao . Learning from the wisdom of crowds by minimax entropy . In NIPS , 2012 .
[ 27 ] K . Zhou , H . Zha , and L . Song . Learning triggering kernels for multi dimensional hawkes processes . In ICML , 2013 .
First , according to the definition of Eqn.(1 ) , we have :
APPENDIX Surrogate Function . We first prove that the objective function Lλ(Θ ) as defined in Eqn.(2 ) and its surrogate function Q(Θ ; Θ(n ) ) as defined in Eqn.(3 ) satisfy the following relationships : log
1 N
∀Θ , Θ(n )
Lλ(Θ ) =
,||Θ||2 i
Q(Θ(n ) ; Θ(n ) ) = Lλ(Θ(n ) ) ∀Θ(n ) fl Q(Θ ; Θ(n ) ) ≥ Lλ(Θ )
F + R(f ) exp(φi,k ) − We focus on the log sum exponential term log exp(uk ) ≤
( uk − vk)2 − 1 K exp(vk)(uk − vk )
+
λ 2 k k k k
+ k log k k exp(φi,k ) and apply the following quadratic upper bound [ 12 ] : for any vectors u ∈ RK and v ∈ RK ,
( uk − vk ) k k exp(vk )
+ log exp(vk ) yi,kφi,k
2
In our context , we replace the log sum exponential term of Lλ(Θ ) with its upper bound and substitute uk with φi,k and i,k , which then leads to the result of Q(Θ ; Θ(n ) ) ≥ vk with φ(n ) Lλ(Θ ) . To prove Q(Θ(n ) ; Θ(n ) ) = Lλ(Θ(n) ) , it is noted that the upper bound above is exact when u = v . Euler Lagrange Equation . To derive Eqn.(7 ) , it is first noticed that the optimization problem in Eqn.(6 ) can be rewritten as :
∞ min f∈L1(R )
0
F ( f , f
)dt where F ( f , f ) is defined by :
F ( f , f
) = AtI{t ∈ N}f ( t)2 + BtI{t ∈ N}f ( t ) +
( f
( t))2
λ 2
According to Euler Lagrange equation , the solution of this problem satisfies the following differential equation :
∂F ∂f
− d dt
∂F ∂f = 0
By substituting F with the definition above , we get the differential equation in Eqn(7 ) Sample Size . Here we derive the number of samples required for the given thresholds and δ as in Eqn(11 ) Without loss of generality , consider the k th element of xN +M +1 , xN +M +1,k . Following the Hoeffding ’s inequality , we have :
P r(|ˆxN +M +1,k−E[ˆxN +M +1,k]| ≥ ) ≤ exp
−
L 2L2 2 i=1(bi − ai)2 where x(i )
N +M +1,k is bounded by [ ai , bi ] .
Notice that ˆxN +M +1 is an unbiased estimator of xN +M +1 N +M +1,k is bounded by [ 0 , 1 ] . By setting the right side and x(i ) of the inequality above to δ , we obtain Eqn(11 )
1096
