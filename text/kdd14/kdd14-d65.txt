Inside the Atoms : Ranking on a Network of Networks
Jingchao Ni 1 , Hanghang Tong 2 , Wei Fan 3 , and Xiang Zhang 1
1Department of Electrical Engineering and Computer Science , Case Western Reserve University
2School of Computing , Informatics , Decision Systems Engineering , Arizona State University
1{jingchao.ni , xiangzhang}@caseedu , 2htong6@asu.edu , 3davidfanwei@huaweicom
3Huawei Noahs Ark Lab
ABSTRACT Networks are prevalent and have posed many fascinating research questions . How can we spot similar users , eg , virtual identical twins , in Cleveland for a New Yorker ? Given a query disease , how can we prioritize its candidate genes by incorporating the tissuespecific protein interaction networks of those similar diseases ? In most , if not all , of the existing network ranking methods , the nodes are the ranking objects with the finest granularity .
In this paper , we propose a new network data model , a Network of Networks ( NoN ) , where each node of the main network itself can be further represented as another ( domain specific ) network . This new data model enables to compare the nodes in a broader context and rank them at a finer granularity . Moreover , such an NoN model enables much more efficient search when the ranking targets reside in a certain domain specific network . We formulate ranking on NoN as a regularized optimization problem ; propose efficient algorithms and provide theoretical analysis , such as optimality , convergence , complexity and equivalence . Extensive experimental evaluations demonstrate the effectiveness and the efficiency of our methods .
Categories and Subject Descriptors H28 [ Database Management ] : Database Applications—Data mining
Keywords Network of Networks ; Ranking ; Query
1 .
INTRODUCTION
How can we spot similar users , eg , virtual identical twins , in Cleveland for a New Yorker ? Given a disease , how can we prioritize its candidate genes by incorporating the tissue specific protein interaction networks of those similar diseases ? Among all the researchers in the area of bioinformatics , who is most likely to collaborate with a given data miner in the near future ? In these ap
Figure 1 : An example of NoN . The main network is represented by dashed nodes and edges . The domain specific networks are represented by solid nodes and edges . plications , networks ( or graphs1 ) provide a natural data model to capture the relationship among different objects .
In the past decade , many graph ranking algorithms have been proposed . Please see Section 6 for a brief review . Despite their own success , a common limitation of these methods is that ranking stops at the node ( atom ) level . That is , the nodes are the ranking objects with the finest granularity in these existing ranking algorithms .
In this paper , we take one step further and propose a new data model a Network of Networks ( NoN ) . In this NoN model , each node of the main network can be represented as another network . Let us elaborate using the example in Figure 1 . Here , the dashed network represents a geo proximity network ( the main network ) , where the nodes are five different cities and links indicate the geoproximity among different cities . Each node of this main network is further represented as a social network ( the domain specific network ) , where nodes are users and links denote their friendship . Collectively , we call this structure as a ( geo proximity ) network of ( social ) networks .
The main advantage of this new NoN model is that it enables to compare the nodes in a broader context and rank them at a finer granularity . Take Figure 1 as the example , using the existing network models , we could either rank the geo centrality of the cities , or the popularity of the users within each domain specific network . On the other hand , by the NoN model , we will be able to rank all the users by considering both their popularity within each domainspecific network as well as the geo centrality of the locations they belong to . We refer to this setting as CROSSRANK . Moreover , we
1In this paper , we use network and graph interchangeably .
JonJimTomAnnBobBenJimMikeMattJackJoeNYCClevelandDCPittsburghPhiladelphia0805090503001090801070508090800109001MikeMikeJon090801JonMikeAnnJimBobJim Symbol G A Ai θ R ri ei In Ii j dm(i ) Dm g ni mi c , a
Table 1 : Symbols
Definition the adjacency matrix of main network domain specific networks A = {A1 , , Ag} the ith domain specific network the one to one mapping function a network of networks R =< G,A , θ > the ranking vector for Ai the ith query vector for Ai an n × n identity matrix the set of common nodes between Ai and A j the degree of the ith node in G the degree matrix : Dm = diag(dm(1 ) , , dm(g ) ) the number of nodes in the main network the number of nodes in Ai , ( i = 1 , , g ) the number of edges in Ai , ( i = 1 , , g ) the parameters 0 < c < 1 , and a > 0 might be interested in finding who are the most similar from New York City for Jon from Cleveland , ie , who are the virtual identity twins of Jon in New York City . In this case , the ranking targets reside in a certain domain specific network . We refer to this setting as CROSSQUERY . The NoN model will enable much more efficient search for this problem .
The NoN model can be observed in many real world applications . As another example , consider a NoN , where each node in the main network is a research area , and the domain specific networks are the co author networks in different areas . By the NoN model , we can rank authors according to their contributions to multiple areas using CROSSRANK ; and find future collaborators for a researcher in a different area using CROSSQUERY .
The main contributions of this paper can be summarized as : • New Data Model . We propose a novel network data model , a network of networks , which enables network ranking to go beyond the atom/node level ( Section 2 ) . • Algorithms and Analysis . We propose two new ranking algorithms ( CROSSRANK and CROSSQUERY ) in NoN and analyze their optimality , convergence , complexity and relationship with existing ranking algorithms ( Section 3 and 4 ) . • Empirical Evaluations . We perform extensive experiments on real datasets to validate the effectiveness and efficiency of the proposed algorithms ( Section 5 ) .
2 . PROBLEM DEFINITIONS
Table 1 lists the main symbols used throughout this paper . We use the bold capital letters to denote matrices ( eg , G , A , etc. ) , the bold lower cases for vectors ( eg , r ) and calligraphic letters for sets ( eg , A ) . In this paper , we consider weighted undirected networks . We denote the networks by their corresponding weighted adjacency matrices . For example , a network with g nodes can be denoted by a g × g adjacency matrix G . The rows/columns of the matrix G represents the nodes of the network and its non zero element G(i , j ) measures the link strength from node i to node j . With the above notations , a network of networks ( NoN ) can be formally defined as follows .
Definition 1 . Network of Networks ( NoN ) . Given a g× g main network G , a set of g domain specific networks A = {A1 , , Ag} and a one to one mapping function θ , which maps each node in the main network G to a domain specific network , a Network of Networks ( NoN ) is defined as the triplet R =< G,A , θ > . Nodes in the main network are referred to as main nodes , nodes in the domainspecific networks are called domain nodes . Each main node represents a domain specific network through the mapping function θ . In addition , we represent the nodes in each domain specific network as Vi(i = 1 , , g ) . We define Ii , j as the common nodes between Ai and A j , ie , Ii , j = Vi ∩ V j . Take Figure 1 as an example , the dashed network is the main network G , which has five main nodes , including NYC , Pittsburgh , Cleveland , Philadelphia , DC . Each of these main nodes is mapped to a domain specific network ( the solid network ) . For example , the main node Pittsburgh is further represented as a domain specific network with three nodes , including Jim , Ben , Bob . Given an NoN R =< G,A , θ > , a fundamental task is to compare and rank the nodes in this network . For instance , we might be interested in ranking the importance/popularity of the individuals in each domain specific network . Further more , given an individual , eg , Jim from Pittsburgh , we may also want to find the similar users from NYC as well as other cities . We introduce a query vector ei ( i = 1 , , g ) for each domainspecific network , which is an ni×1 nonnegative vector ( ni represents the number of nodes in the domain specific network ) . If we are given a query node of interest from a domain specific network ( eg , Jim from Pittsburgh ) , we set its corresponding entry ei to 1 , and all other entries to 0 . Otherwise , all the entries in ei are set to 1 . ni Formally , we define the CROSSRANK problem as follows .
PROBLEM 1 . CROSSRANK
Given : ( 1 ) an NoN R =< G,A , θ > , and ( 2 ) the query vectors ei
( i = 1 , , g ) ;
Find : ranking vectors ri for the nodes in the domain specific net works Ai ( i = 1 , , g ) .
In the above definition , when all the query vectors are uniform , ie , no query node is given , we essentially want to measure and rank the global importance of all the domain nodes within each domain specific network . On the other hand , if a query node is given , we essentially want to measure the proximity ( ie , relevance ) from the query node to all the domain nodes within each domain specific network . Note that in the latter case , sometimes , we might be interested in ranking domain nodes from a particular domainspecific network . For instance , given Jim from Pittsburgh , we might want to find out the top 3 most similar users from NYC . We call this special case of CROSSRANK as CROSSQUERY , which is formally defined as follows .
PROBLEM 2 . CROSSQUERY
Given : ( 1 ) an NoN R =< G,A , θ > , ( 2 ) a query node of interest from a source domain specific network As , ( 3 ) a target domain specific network Ad , and ( 4 ) an integer k ;
Find : the top k most relevant nodes from the target domain specific network Ad wrt the query node .
In the next two sections , we give our solutions for CROSSRANK and CROSSQUERY , respectively . 3 . CROSSRANK In this section , we present our solution to CROSSRANK . We start with formulating it as a regularized optimization problem , then present an effective algorithm to solve it , followed by some theoretical analysis .
3.1 Optimization Formulation
The basic idea of our method is to formulate CROSSRANK as a regularized optimization problem by encoding the following three types of constrains . ( 1 ) Within network smoothness : for a given domain specific network Ai , the ranking scores among the neighboring nodes should be somehow smooth . That is , for any two adjacent nodes x , y on Ai , we want to minimize the difference of the rank scores between them , ie , ( ri(x ) − ri(y))2 . ( 2 ) Query preference : the ranking vector ri should also reflect the preference of the specific query node of interest from the corresponding domainspecific network . That is , we want to minimize the difference between the ranking vector ri and the corresponding query vector ei . ( 3 ) Cross network consistency : for a pair of domain specific networks Ai and A j that are connected with each other by the main network ( ie , G(i , j ) > 0 ) , they may share some common nodes , ie , Ii j = Vi ∩ V j is non empty . In this case , those common nodes will receive multiple ranking scores ( one from each ranking vector ) . Intuitively , the ranking scores for the same node should be consistent across highly similar domain specific networks . In other words , we want to minimize the difference between ri(Ii j ) and r j(Ii j ) . Here ri(Ii j ) can be viewed as the projection of the entire ranking vector ri on the common node set Ii j . Putting everything together , we have the following regularized objective function J(r1 , , rg ) . The optimal ranking vectors ri ( i = g∑ g∑ 1 , , g ) are those minimize the objective function . | {z } | {z } + ( 1 − c ) ∥ri − ei∥2 − ˜Ai)ri g∑ g∑ √ within−network smoothness − r j(Ii j ) ∥ ri(Ii j ) | {z } √ dm(i )
J(r1 , , rg ) = c
∥2 FG(i , j ) query pre f erence r′ i(Ini
+ a
( 1 ) i=1 i=1 i=1 j=1
F dm( j ) cross−network consistency where ∥ · ∥F denotes the Frobenius norm ; ˜Ai is the symmetrically normalized adjacency matrix of Ai ; and a and c are two regularization parameters . Note that the length of different ranking vectors could be different and all entries of a given ranking vector ri add up to 1 . To make the ranking scores comparable with each other for the common nodes , we normalize ri(Ii j ) and r j(Ii j ) by their corresponding degrees in the main networks , respectively .
Discussions . If we ignore the third term ( cross network consistency ) in Eq ( 1 ) , we can show that the objective function J(r1 , , rg ) can be decoupled into g independent terms . Each of these terms becomes the same objective function of a popular ranking method on homogeneous network random walk with restart ( also called manifold ranking , the personalized pagerank , etc . ) [ 33 , 26 ] . From this perspective , what we essentially aim to do in Eq ( 1 ) is to solve multiple , inter correlated such ranking problems simultaneously . 3.2 Optimization Solutions We first present an equivalent formulation of Eq ( 1 ) . Denote the aggregated ranking vector r = ( r′ g)′ , the aggregated query g)′ . Let the aggregated adjacency matrix ˜A = vector e = ( e′ diag( ˜A1 , , ˜Ag ) be a g × g diagonal block matrix , Oi j be an ni × n j binary indicator matrix with Oi j(x , y ) = 1 if the xth node in Ai is the yth node in A j , ie , common node . Then O is a block matrix whose ( i , j)th block is G(i , j)Oi j .
Since O may be singular due to zero rows/columns , we define , , dm(g)Ing ) − DO with Y = O + DT , where DT = diag(dm(1)In1 Ini(1 ≤ i ≤ g ) being an ni × ni identity matrix and DO being the degree matrix of O . Y is non singular . The ( i , i)th block of DY
, , r′
, , e′
1
1
− 1 = In − ˜Y , where ˜Y = D Y YD 2
( ie , Y ’s degree matrix ) equals dm(i)Ini . Finally , we define X = − 1 − 1 Y ( DY − Y)D D 2 2 Y With these definitions , the objective function in Eq ( 1 ) can be re written as the following matrix form ∑g
( 2 ) i=1 ni is the total number of nodes in all the domain
( In − ˜A)r + ( 1 − c)∥r − e∥2
F + 2ar′Xr
J(r ) = cr′
− 1 Y . 2 where n = specific networks .
LEMMA 1 . Equation ( 1 ) and Equation ( 2 ) are equivalent . PROOF . We only need to prove that the third term in Eq ( 1 ) is equal to that in Eq ( 2 ) .
By the definition of X and r , we have g∑ iIniri − g∑ g∑ i=1 r′ r′ i ˜Yi jr j where ˜Yi j is the ( i , j)th block of ˜Y of size ni × n j . Then r′Xr = r′Xr = r′Inr − r′ ˜Yr = ( g∑ g∑ g∑ ri√ dm(i ) g∑
( DY)ii i=1 i=1 j=1 r j√
Yi j dm( j )
+ j=1 j√ r′ dm( j )
( DY ) j j
) r j√ dm( j ) where ( DY)ii is the ith diagonal block of DY , and Yi j is the ( i , j)th block of Y . Thus r′Xr =
( DO)ii
+
(
) ri√ dm(i )
1 2 − 2 r′ i√ dm(i ) r′ i√ dm(i ) i=1 j=1
( g∑ 1 g∑ g∑ 2 − 2 g∑ j√ i=1 i=1 j=1
+
( j=1
( r′ dm( j ) r′ i√ dm(i ) r′ i√ dm(i )
( DO ) j j r′ i√ dm(i )
+ r j√ j√ dm( j ) r′ dm( j )
+
( DT )ii r′ i√ dm(i )
( DT ) j j ri√ dm(i )
( DT )i j r j√ dm( j ) r j√ )
)
) dm( j )
G(i , j)Oi j r j√ dm( j ) where ( DT )i j , ( DO)i j and Oi j are block matrices representing ( i , j)th block of DT , DO and O , respectively . Since DT is a diagonal block matrix , we have r′ i√ dm(i ) r′ i√ dm(i ) ri√ dm(i ) r j√ g∑
( DT )i j
( DT )ii dm( j )
2 j=1 i=1
= 2 g∑ g∑ g∑ − 2 g∑ j√ j=1 i=1
+ j=1 r′ dm( j ) r j√ dm( j ) r′ i√ dm(i )
( DT )i j r j√
( DT ) j j
= 0 dm( j ) g∑ g∑ i=1 i=1 and r′ i√ dm(i )
( DT )ii ri√ dm(i ) have that r′Xr =
This means DT does not affect the ranking results . Therefore , we
( ) i=1 i(Ii j ) r′ √ dm(i ) g∑ g∑ 1 G(i , j ) 2 √ √ j(Ii j ) r j(Ii j ) r′ g∑ g∑ dm( j ) dm( j ) G(i , j)∥ ri(Ii j ) j=1
√ dm(i )
1 2 i=1 j=1
+
= ri(Ii j ) √ dm(i )
− 2 i(Ii j ) r′ √ dm(i )
√ − r j(Ii j ) dm( j )
∥2
F
√ r j(Ii j ) dm( j )
This completes the proof .
Algorithm 1 : CROSSRANK Input : ( 1 ) a network of networks R =< G,A , θ > ; ( 2 ) the query vectors ei , ( i = 1 , , g ) ; and ( 3 ) the parameters a and c
Output : the ranking vectors ri , ( i = 1 , , g ) Offline computation : Construct ˜A and ˜Y from R ; Online ranking : Construct the aggregated query vector e = ( e′ , , e′ 1 Initialize the aggregated ranking vector r = e ; while not convergence do
Update : r ← (
˜A + 2a 1+2a
˜Y)r + 1−c
1+2a e ; c
1+2a end return the ranking vectors r1 , , rg based on r
1 2 3 4 5 6 7 8 g)′ ;
From Eq ( 2 ) , it can be seen that the objective function J is a quadratic function of the ranking vector r . We have
= 2((1 + 2a)In − c ˜A − 2a ˜Y)r − 2(1 − c)e
∂J ∂r
If we set r = r − η ∂J ∂r , where η = 1 c
2a r = (
˜A +
1 + 2a
1 + 2a
2+4a , we have 1 − c 1 + 2a
˜Y)r + e
( 3 )
Based on Eq ( 3 ) , we have a fixed point approach to compute the optimal ranking vector r that minimizes the objective function J(r ) as illustrated in Algorithm 1 . 3.3 Proofs and Analysis
In this subsection , we analyze Algorithm 1 in terms of its convergence , optimality , complexity and discuss its relationship with existing ranking algorithms .
We start with the the convergence of Algorithm 1 , which is summarized in Theorem 1 . It says that the proposed CROSSRANK algorithm converges to its closed form solution . c
2 A
1+2a
1+2a
1+2a
˜A− 2a
˜Y)−1 1−c
˜A + 2a 1+2a
= 0 . Then let M = verges to the closed form solution : r = ( In− c
THEOREM 1 . Convergence of CROSSRANK . Algorithm 1 con1+2a e . PROOF . First , the closed form solution can be obtained by solv˜Y . Eq ( 3 ) becomes 1+2a e . Next , we show that the eigenvalues of M are ing ∂J ∂r r = Mr + 1−c in ( −1 , 1 ) . Since ˜A and ˜Y are similar to the stochastic matrices AD−1 − 1 A and YD−1 D 1 = D 1 ˜AD 2 eigenvalues within [ −1 , 1 ] . One result of the Weyl ’s inequality theorem [ 1 ] states that for matrices ˆH , H , P ∈ Hn , where Hn is the set of n × n Hermitian matrices , if ˆH = H + P and their eigenvalues are arranged in nonincreasing orders , ie , λ1( ˆH ) ≥ ≥ λn( ˆH ) , λ1(H ) ≥ ≥ λn(H ) , λ1(P ) ≥ ≥ λn(P ) , then the following inequalities hold : λn(P ) ≤ λi( ˆH ) − λi(H ) ≤ λ1(P),∀i = 1 , , n ˜Y , we have
= − 1 Y , respectively , both ˜A and ˜Y have 2
Since ˜A , ˜Y , M ∈ Hn and M = c
˜YD
2 Y
A
Y
λ1(M ) ≤ λn(M ) ≥ c
1 + 2a c
1 + 2a
˜A + 2a 1+2a 2a
1+2a
λ1( ˜A ) +
λn( ˜A ) +
λ1( ˜Y )
λn( ˜Y )
1 + 2a
2a
1 + 2a which means the eigenvalues of M are in the range of [ − c+2a Since 0 < c < 1 , the eigenvalues of M are in ( −1 , 1 ) . Based on this property , we can show the convergence of the fixed point approach . Without loss of generality , let r(0 ) = e , and t
, c+2a 1+2a ] .
1+2a be the iteration index ( t ≥ 1 ) . According to Eq ( 3 ) , we have t−1∑ Mi 1 − c t−1∑ i=0
1 + 2a e r(t ) = Mte +
Since the eigenvalues of M are all in ( −1 , 1 ) , we have Mi = ( In − M ) −1 t→∞ Mt = 0 , and lim lim t→∞ i=0
Therefore t→∞ r(t ) = ( In − M ) r = lim = ( In − c
1 + 2a
˜A − 2a 1 + 2a
−1 1 − c 1 + 2a ˜Y ) e −1 1 − c 1 + 2a e which is the closed form solution .
Next , we show in Lemma 2 that Algorithm 1 finds the global optimal solution of the objective function J(r ) defined in Eq ( 2 ) .
LEMMA 2 . Optimality of CROSSRANK . At convergence , Algorithm 1 finds the global minimal solution of J(r ) defined in Eq ( 2 ) PROOF . This can be proved by showing that the function in Eq ( 2 ) is convex . The Hessian matrix of Eq ( 2 ) is ▽2J = 2((1 + 2a)In − c ˜A − 2a ˜Y ) . Following the similar idea as in the proof of Theorem 1 , we have that the eigenvalues of ▽2J are no less than 2(1 − c ) . Since 0 < c < 1 , ▽2J is positive definite . Therefore , Eq ( 2 ) is convex .
The complexity of Algorithm 1 is summarized in Lemma 3 , which says that it is linear wrt the overall number of nodes and edges in NoN in terms of both space and time cost .
∑g LEMMA 3 . Complexity of CROSSRANK . The time complexity of Algorithm 1 is O(T∗(m + ng ) ) and its space complexity is O(m + i=1 ni , and T∗ is the total iteration n ) , where m = number . i=1 mi , n =
∑g
∑g
PROOF . In the preprocessing stage , we need to construct ˜A and ˜Y . The construction time of ˜A is O(m ) , since there are O(m ) nonzero entries in ˜A . The construction time of ˜Y is O(gn ) , since the nonzero entries of ˜Y are pairwise intersection of node lists of all the domaini=1 gni = gn . Therefore , preprocessing specific networks , ie , cost is O(m + gn ) . The online computation cost depends on the fixpoint updating step in Eq ( 3 ) . Since there are O(m+gn ) nonzero en˜Y , the online computation cost is O(T∗(m+gn) ) . tries in c 1+2a In Algorithm 1 , we need to store ˜A and ˜Y , with space complexity O(m+gn ) . Usually g is much smaller than n , we can regard time and space complexities as O(T∗(m + n ) ) and O(m + n ) respectively .
˜A+ 2a 1+2a
Finally , we show the relationship between the proposed CROSS
RANK algorithm and random walk with restart ( RWR ) .
LEMMA 4 . Relationship between CROSSRANK and RWR . c+2a YD−1
CROSSRANK fixed point approach is equivalent to random walk Y if ˜A with restart with the transition matrix ˜W = c c+2a is stochastic .
˜A + 2a
Eq ( 3 ) to
PROOF . Let ˜c = c+2a
1+2a and W = c c+2a
˜A + 2a c+2a r = ˜cWr + ( 1 − ˜c)e and the closed form solution of Eq ( 2 ) to r = ( In − ˜cW )
−1(1 − ˜c)e
˜Y , we can transform
( 4 )
( 5 )
These formulations have a RWR form except that W is not stochas
1 2 c
2 Y
2 Y
− 1 2 Y
2 Y
2
2 Y
− 1 2 Y
− 1 2 Y
1 2
2 e
( 6 )
= D
= D
˜AD
˜AD
= ˜A .
1 + 2a
˜A + 2a e −1D 1 ii ( ˜A)ii(DY ) c+2a YD−1
− 1 ii ( ˜A)ii(DY ) 2 ii
−1 1 − c 1 + 2a YD−1 Y ) tic , since ˜A and ˜Y are symmetrically normalized . ˜W = c c+2a solution to
If we denote Y , we can further transform the closed form r = ( In − ˜A − 2a ˜Y ) 1 + 2a − 1 Y ( In − ˜A − 2a c 2 1 + 2a 1 + 2a − 1 Y ( 1 − ˜c)e Y ( In − ˜c ˜W ) −1D 1 2 In the above equation , D 1 ˜AD is a diagonal block matrix , of which each diagonal block can be represented − 1 ii where ( DY)ii and ˜Aii are the ith diagonal block as ( DY ) 2 of DY and ˜A , respectively . Since the diagonal values of ( DY)ii equal to dm(i ) , ( DY )
= ( ˜A)ii and D 1
= ˜A since D 1
1 − c 1 + 2a
Note that we can view ˜W as the normalized matrix of a network generated by linking the common nodes between any two domainspecific networks if they are connected in the main network . Eq ( 6 ) shows that if we normalize the initial vector e of CROSSRANK as Y e , the process ˜r = ˜c ˜W˜r + ( 1 − ˜c)˜e spreads information ˜e = D 1 symmetrically within domain specific networks and stochastically across domain specific networks ( note this process converges since ˜W and W are similar ) . It gives the same ranking results as Eq ( 4 ) , − 1 Y on the ranking scores ˜r does not affect the since multiplying D 2 relative ranking order within the domain specific networks . If ˜A is stochastic , ˜W is stochastic and ˜r = ˜c ˜W˜r + ( 1 − ˜c)˜e becomes a stochastic process . This completes the proof . 4 . CROSSQUERY In this section , we address CROSSQUERY . Note that CROSSQUERY is a special case of CROSSRANK , by ( 1 ) requiring the query node being from a source domain specific network As ; ( 2 ) restricting the query results within a target domain specific network Ad ; and ( 3 ) searching for a set of k most relevant nodes from Ad ( as opposed to demanding the exacting ranking vectors ) . Thus , a default solution for CROSSQUERY is to run the CROSSRANK algorithm to get the ranking vector rd for the target domain specific network and return the top k nodes with the highest ranking scores . In this section , we aim to further speed up its computation . 4.1 CROSSQUERY BASIC
According to Lemma 4 , CROSSRANK has a RWR form on the integrated normalized matrix W . This not only reveals an interesting relationship between CROSSRANK and RWR , but also opens the door to take the advantage of the vast machinery of the existing scalable algorithms for RWR [ 25 , 5 , 6 ] . For example , we could modify the algorithm in [ 6 ] to solve CROSSQUERY since limt→∞(˜cW)t = 0 ( a prerequisite of this algorithm ) , which is summarized in Algorithm 2 . This is an exact method that improves the basic power iteration method by estimating the node ranking scores using only a small number of iterations .
Time Complexity . Following the notations in Lemma 3 , the overall time complexity of CROSSQUERY BASIC is O(T(b f + h ) + m + gn ) , where b is the average size of the neighborhood for each node , f and h are the average size of the subtree T ( t ) and the selected nodes set S(t ) over all iterations respectively , T is the total number of iterations . Compared with the CROSSRANK method , whose time complexity is O(T∗(m + gn) ) , where T∗ is the total number of iterations , Algorithm 2 is more efficient since in practice b f << m + gn , h << n and T << T∗ .
1 g)′ ;
, , e′
= 0 , and the upper bound vector ¯r(0 ) d
Algorithm 2 : CROSSQUERY BASIC ( adopted from [ 6 ] ) Input : ( 1 ) matrices W , Wmax ( Wmax(u ) = maxv∈N(u)W(u , v ) where N(u ) is the neighbourhood of u ) ; ( 2 ) node sets V1 , ,Vg ; ( 3 ) nodes q , s , d and ( 4 ) parameters ˜c , k Output : Top k relevant nodes set K Set es(q ) = 1 , ei = 0,∀i ∈ ( 1 , , g)\s , and the query vector e = ( e′ Initialize the random walk vector p = e , the lower bound vector r(0 ) = 0 ; Initialize the iteration number t = 0 , Subtree T ( 0 ) = {q} , the d selected nodes set S(0 ) = Vd , the threshold σ = −1 ; while |S(t)| > k do layer(t ) = {u|u.layer = t by BFS rooted at q,∀u ∈∪g
Increase the iteration number t = t + 1 ; expand T ( t ) = T ( t−1 ) ∪ layer(t ) ; update p(T ( t ) ) ← Wp(T ( t) ) ; ← r(t−1 ) + ( 1 − ˜c)˜ctp(S(t−1) ) ; update lower bound : r(t ) + ˜ct+1Wmax(S(t−1) ) ; ← r(t ) d update upper bound : ¯r(t ) update threshold : σ ← the kth largest value in r(t ) d d ; d ( u ) ≥ σ,∀u ∈ S(t−1)} ; shrink selected nodes : S(t ) = {u|¯r(t ) d ( S(t) ) ; shrink bounds lists : r(t ) d d ( S(t) ) , ¯r(t )
← ¯r(t )
← r(t ) i=1 d d d
Vi} ; end return K = S(t )
1
2
3
4 5 6 7 8 9 10 11 12 13 14 15
4.2 CROSSQUERY FAST
Next , we propose a more efficient algorithm for CROSSQUERY . The basic idea is as follows . Let the corresponding main nodes for As and Ad be node s and node d , respectively . Given s and d , parts of the main network G might have little contributions to measure the relevance for the nodes from Ad wrt the query node , and thus can be pruned with little impact on the final query accuracy . In the context of NoN , even if we can only prune a small portion of the main network , the computational efficiency can be significantly improved since all the corresponding domain specific networks can be filtered out during the ranking process .
Let r(v ) be the ranking score of any node v wrt a query node q by RWR . It is well known that r(v ) can be represented by the so called inverse P distance [ 9 ] .
∑ r(v ) = p∈{q v}
Prob(p)(1 − c)cl(p )
∏l(p)−1 where p ∈ {q v} is a path from q to v , and l(p ) is the unweighed length of p . For any path p : v1 → v2 → → vl(p ) , i=1 Prob(vi+1|vi ) , where Prob(vi+1|vi ) is the tranProb(p ) = sition probability from vi to vi+1 . We call Prob(p ) the transition probability of path p .
Inspired by the relationship between CROSSRANK and RWR ( as indicated by Eq ( 6) ) , here we consider ˜A to be stochastic ( ie , column normalized ) to guide the pruning process . Then we can express the CROSSQUERY score of a node v wrt the query node q as
Prob(p)(1 − ˜c)˜cl(p ) r(v ) = p∈{q v}
( 7 ) The following lemma says that Prob(p),∀p ∈ {q v} , is upper bounded by the transition probability of some path in the main network .
LEMMA 5 . Upper Bound of Prob(p ) . For any path p ∈ {q v} , ∃p′ ∈ {s d} st Prob(p ) ≤ Prob(p′ ) , where p′ is a path con
∑
√ √ dm(s ) dm(d )
∏ necting s and d in the main network . Here Prob(p′ ) = where ei j is the edge connecting main nodes i and j in G . ei j∈p′ G(i , j ) dm(i ) PROOF . For any edge exy ∈ p , let i and j be the main nodes that contain domain nodes x and y respectively . We have ( YD−1
Prob(p ) =
˜Ai(y , x )
2a c c + 2a c + 2a
Y ) ji(y , x )
∏ exy∈p i , j
∏ ∏ ∏ exy∈p i= j exy∈p i , j ei j∈p′ i , j
≤
=
( YD−1
Y ) ji(y , x )
G(i , j ) dm(i )
= Prob(p
′
) where ( YD−1 Y ) ji is the ( j , i)th block of YD−1 matrix from domain specific network i to j .
Y , which is the transition
In the above lemma , p′ consists of edges in p that go across domain specific networks . Let φ be the function that maps each p to its corresponding p′ , ie , φ(p ) = p′ , then we have the following upper bound of the ranking score r(v ) . COROLLARY 1 . Upper Bound of r(v ) . The CROSSQUERY score of a node v ∈ Vd wrt the query node q , ie , r(v ) , is upper bounded by
∑ p∈{q v}
√ √ dm(s ) dm(d ) r(v ) ≤
Prob(φ(p))(1 − ˜c)˜cl(φ(p ) )
PROOF . This can be derived directly from Eq ( 7 ) and Lemma
5 . The detailed proof is omitted .
From Corollary 1 , we have that if Prob(φ(p ) ) is small , the contribution from the path p to r(v ) will be small . Based on this observation , we can extract a subnetwork of the main network consisting of paths with large Prob(φ(p) ) . √ √ √ ˜Prob(φ(p ) ) = dm(s ) dm(d ) Prob(φ(p ) ) =
For any p , let
∏ ei j∈φ(p )
G(i , j )
√ dm(i )
We define the distance between node i and node j as dm( j )
√
G(i , j )
√ dm(i ) dm( j )
)
( 8 )
Li j = −log( ∑
10 p∈{q v}
Then the upper bound of the ranking score r(v ) in Corollary 1 becomes r(v ) ≤
−∑ ei j∈φ(p ) Li j(1 − ˜c)˜cl(φ(p ) )
This transformation allows us to search for short paths connecting s and d in the main network that capture high transition probabilities . We adopt a fast heuristics proposed in [ 12 ] to extract these paths . With the subgraph consisting of the extracted paths in the main network , we then apply CROSSQUERY BASIC on the corresponding NoN to retrieve the top k most relevant nodes from the target domain specific network .
Algorithm 3 summarizes this approach . The algorithm starts the shortest path search rooted from s and d simultaneously in G ( eg , using Dijkstra ’s algorithm ) . Let N(s ) and N(t ) be the neighborhoods of s and d expanded by the algorithm so far . The first overlapping node in N(s ) and N(t ) identifies the shortest path between s and d . Denote this path as p′ max as it has the maximal transition probability from s to d ( Steps 4 to 6 ) . The algorithm continues expanding and adding new nodes in N(s ) and N(t ) . The overlapping nodes in N(s ) and N(t ) will generate new paths . The expansion stops when the transition probability of the newly discovered path
1
2 3 4 5 6 7 8 9 10 11 12 13 max)−log(ϵ ) max ) = ∞ , neighbourhoods N(s ) = ϕ,N(d ) = ϕ , nodes s , d , q and ( 4 ) parameters : ϵ , a , c , k
Algorithm 3 : CROSSQUERY FAST Input : ( 1 ) matrices G , ˜A , Y ; ( 2 ) node sets V1 , ,Vg ; ( 3 ) Output : Top k relevant nodes set K Initialize L(p′ radiuses rs = 0 , rd = 0 , selected nodes set G = ϕ ; Transform similarity in G into distances by Eq ( 8 ) ; while rs ≤ L(p′ if N(s ) and N(d ) first overlap at node u then L(p′ end if rs ≤ L(p′ end if rd ≤ L(p′ end
∨ rd ≤ L(p′ max ) = L(s u d ) ;
Expand N(d ) and update rd ;
Expand N(s ) and update rs ; max)−log(ϵ ) max)−log(ϵ ) max)−log(ϵ ) then then do
2
2
2
2 end Further prune N(s ) and N(d ) : 14 G = {u|L(s , u ) + L(u , d ) ≤ L(p′ Calculate W , Wmax , ˜c based on G , ˜A , Y , a and c ; Apply CROSSQUERY BASIC on the extracted NoN ; return K
15 16 17 max ) − log(ϵ ) , u ∈ N(s ) ∪ N(d)} ;
2 max)−log(ϵ ) new ) > L(p′ new drops below ϵ × ˜Prob(p′ p′ max ) , where 0 < ϵ < 1 is an error max ) − log(ϵ ) , where L(· ) is the factor . Thus we have L(p′ weighed length of a path . Therefore , the neighborhoods with radius L(p′ from s and d ( ie , rs and rd ) will contain all significant paths based on ϵ ( Steps 7 to 12 ) . A node u in the neighborhoods max ) − log(ϵ ) , where L(s , u ) can be pruned if L(s , u ) + L(u , d ) > L(p′ and L(u , d ) are the shortest distances between s and u , u and d , respectively ( Step 14 ) . Finally we apply CROSSQUERY BASIC on the pruned NoN ( Step 15 to 16 ) .
Time Complexity . Let the number of nodes and edges in the main network be g and z respectively , and T be the number of iterations . Subgraph extraction takes O(T(glog(g ) + z ) ) using Dijkstra ’s algorithm . The pruning step takes O(g ) . Thus the overall complexity of subgraph extraction is O(T(glog(g ) + z) ) . Note that since g and z are typically very small compared to the overall size of the domainspecific networks , this step is usually very efficient . Experimental results show that CROSSQUERY FAST brings 4.5× to 7.5× additional speedup while preserving a high accuracy .
.
In this section , we perform comprehensive experiments to evaluate the performance of the proposed methods . We study NoN in two real world applications : ranking authors in the network of co author networks constructed from the DBLP bibliographic data , and prioritizing candidate gene in the network of tissue specific protein interaction networks . Synthetic datasets are also generated to evaluate the efficiency of the developed optimization strategies . All experiments are performed on a 3.00 GHz desktop PC with 8G memory . 5.1 Co Author NoN
We construct the co author NoN from the DBLP data [ 24 ] as follows . The main network consists of 5 research areas , ie , data mining ( DM ) , machine learning ( ML ) , database ( DB ) , information retrieval ( IR ) , and bioinformatics ( BIO ) . Each area corresponds to a node in the main network . The conferences included in each area are summarized in Table 2 . The similarity between two areas is measured by the ratio between the number of citations across these
( 9 )
5 . EXPERIMENTS
Table 2 : Areas in the main network
Area Conference included DM KDD , ICDM , SDM , PKDD , PAKDD ML DB IR BIO ISMB , RECOMB , ECCB , BIBE , BIBM , WABI
ICML , NIPS , AAAI , IJCAI , UAI , ECML VLDB , SIGMOD , ICDE , ICDT , EDBT , PODS SIGIR , WWW , ACL , ECIR , CIKM two areas and the total number of cited papers in them . This is intuitive since two similar areas are more likely to cite each other ’s papers . The co author network in each area is used as the domainspecific network .
511 Effectiveness Evaluation To evaluate the effectiveness of the NoN model , we first apply CROSSRANK and study how the top 10 authors in DB change when varying a . Table 3 shows the ranking results for different a values . Note that when a = 0 , the ranking result is the same as that of applying random walk with restart in each individual area independently .
From the table , we can see that the rank of three authors , Jiawei Han , Christos Faloutsos and Philip S . Yu , increases as a increases . When a = 0 , their rank indicates their contributions to DB only . When a increases , their contributions to areas related to DB are also taken into consideration . In particular , they are the top 3 researchers in DM , which is the most similar area to DB in the main network . This indicates that CROSSRANK can effectively recognize a researcher ’s broader impact by incorporating his/her contribution across multiple areas .
Next , we evaluate the effectiveness of CROSSQUERY by studying an interesting cross area link prediction task , ie , for a given query author , we would like to identify future collaborators for this author in a relevant area . In particular , we partition the DBLP dataset into two parts , one from 2001 to 2005 ( time interval T1 ) and another from 2006 to 2010 ( time interval T2 ) . We are interested in the DB researchers who have no DM publications during T1 but collaborate with DM researchers and publish in DM during T2 . We select such DM DB author pairs and use network in T1 to predict their co authorship in T2 .
For comparison , we select methods developed for ( 1 ) a single merged co author network , and ( 2 ) heterogeneous information network . For a single merged network , we select the following methods . The path counting ( PC ) method uses the number of paths between each pair . Here we consider paths with length no longer than 5 . The Katz method [ 11 ] is also a path counting method that penalizes longer paths . Personalized PageRank [ 9 ] and PropFlow [ 16 ] are random walk based methods . PathSim is designed for heterogeneous information network [ 22 ] . We use the 9 meta paths proposed in [ 21 ] for co authorship link prediction . The parameters of the selected methods are tuned for their optimal performance .
Note that for all the selected methods , we focus on authors with at least certain number of publications , and author pairs who are within a few hops in the merged overall co author networks . This is reasonable since highly productive authors are more likely to cooperate with authors within a small distance [ 21 ] .
We perform leave one out cross validation and use accuracy and AUC value as the evaluation criteria . Specifically , we test one selected DM DB author pair at each time . The DM researcher is used as the query node and DB is the target query area . A prediction is considered accurate if the test DB researcher is among the top 20 ranked authors in DB .
Table 4 : Co authorship prediction results
#Papers Hops
#Pairs Methods
≥ 3
≥ 3
≥ 5
≥ 5
[ 3 , 4 ]
45
[ 3 , 6 ]
70
[ 3 , 4 ]
23
[ 3 , 6 ]
38
PC Katz PropFlow PathSim PageRank CrossQuery PC Katz PropFlow PathSim PageRank CrossQuery PC Katz PropFlow PathSim PageRank CrossQuery PC Katz PropFlow PathSim PageRank CrossQuery
AUC 0.7196 0.7439 0.7558 0.5636 0.7417 0.7685 0.6009 0.6243 0.6268 0.5278 0.6378 0.6632 0.6521 0.6717 0.6850 0.4279 0.6743 0.7099 0.5692 0.5786 0.5950 0.4362 0.5880 0.6308
Accuracy 0.4444 0.5556 0.6222 0.2444 0.5333 0.6444 0.3000 0.3714 0.4429 0.2143 0.3714 0.4571 0.2609 0.3478 0.3478 0.1304 0.3478 0.3478 0.2105 0.2368 0.2895 0.1053 0.2368 0.2895
Table 4 shows the results . From the table , we can see that CROSSQUERY outperforms all alternative methods . The performance gain becomes larger when more test author pairs are available . The alternative methods are not suitable for this cross area query task , since they only consider the similarity between the authors but not areas . Note that the meta paths used in PathSim do not consider the similarity between areas and conferences either .
512 Efficiency Evaluation We evaluate the efficiency of the proposed methods using both the DBLP and synthetic datasets . The main network in the DBLP NoN consists of 121 conferences . The number of nodes in the conference specific coauthor networks ranges from 88 to 14,636 depending on the size of the conferences , with a total of 259,822 nodes . The synthetic NoN are generated using the R MAT model [ 2 ] so that the resulting networks resemble real word networks . The main network consists of 1,023 nodes . The domain specific networks contain 935 to 8,100 nodes with a total of 3,773,519 nodes .
Figure 2 shows the running time of CROSSQUERY BASIC and CROSSQUERY FAST when varying the number of returned nodes k . The running time of CROSSRANK is also reported in the figure as a reference . The running time is averaged over 10 randomly selected query nodes and target domain specific networks . The parameters are a = 0.2 , c = 0.85 , and ϵ = 10−3 . It can be seen that both CROSSQUERY BASIC and CROSSQUERY FAST are much more efficient than CROSSRANK . The running time of CROSSQUERY BASIC and CROSSQUERY FAST increases as k increases . The randomly selected query nodes may affect the trend , eg , in Figure 2(b ) when k = 500 . The corresponding averaged accuracy of CROSSQUERY FAST is shown in 2(c ) . From the results , we can see that CROSSQUERY FAST achieves more than 90 % accuracy for all settings and dramatically improves the efficiency . 5.2 Protein Interaction NoN
In this section , we apply the proposed NoN model to the candidate gene prioritization problem , which has recently attracted in
Table 3 : Top ranked authors in the database area when varying a
Rank 1 2 3 4 5 6 7 8 9 10 a = 0 Divesh Srivastava Jiawei Han Philip S . Yu Hector Garcia Molina Raghu Ramakrishnan Gerhard Weikum Beng Chin Ooi H . V . Jagadish Michael J . Carey Michael Stonebraker a = 0.05 Jiawei Han Divesh Srivastava Philip S . Yu Hector Garcia Molina Raghu Ramakrishnan Gerhard Weikum Christos Faloutsos Michael Stonebraker Michael J . Carey Beng Chin Ooi a = 0.1 Jiawei Han Divesh Srivastava Philip S . Yu Hector Garcia Molina Christos Faloutsos Michael Stonebraker Raghu Ramakrishnan Gerhard Weikum Michael J . Carey Beng Chin Ooi a = 0.3 Jiawei Han Philip S . Yu Divesh Srivastava Christos Faloutsos Michael Stonebraker Hector Garcia Molina Michael J . Carey Raghu Ramakrishnan Gerhard Weikum Elke A . Rundensteiner a = 0.5 Jiawei Han Philip S . Yu Christos Faloutsos Michael Stonebraker Divesh Srivastava Hector Garcia Molina Michael J . Carey Gerhard Weikum Raghu Ramakrishnan Elke A . Rundensteiner
( a ) Query time on DBLP NoN
( b ) Query time on synthetic NoN
( c ) Accuracy of CROSSQUERY FAST
Figure 2 : Efficiency and accuracy of the proposed techniques tensive research interests . Various methods have been proposed including regression based methods [ 29 ] , alignment based methods [ 30 ] , random walk based methods [ 31 , 14 , 28 ] , and maximum flow based methods [ 3 ] .
Most of the state of the art methods use a heterogeneous network as shown in Figure 3(a ) . The heterogeneous network consists of three components : a disease similarity network , a generic protein interaction network , and known disease gene associations connecting the two networks . Based on the “ guilt by association ” principle , these methods utilizes similarities between diseases to infer genes that are associated with diseases [ 4 ] .
Since the majority of genetic disorders tend to manifest only in a few tissues , recent studies have shown that it is more reasonable to utilize tissue specific protein interaction networks in candidate gene prioritization [ 17 ] .
We construct the tissue specific protein interaction NoN as shown in Figure 3(b ) . The similarity network between 5,080 diseases is retrieved from the OMIM database [ 7 ] and used as the main network in NoN . We use the tissue specific protein interaction network contributed in [ 17 ] . The authors generated tissue specific protein interaction networks of 9,998 proteins for 60 human tissues using gene expression profiles in these tissues . For each disease in the main network , we use the protein interaction network in the tissue that is most relevant to the disease as its domain specific network [ 13 ] . We collect 2,187 known associations between 1,524 diseases and 1,326 genes from the OMIM database [ 7 ] and select a subset of known disease gene associations by filtering out diseases with the MAS ( Maximum Association Score ) less than 8 % , which is used for selecting diseases having high associations with relevant tissues [ 17 , 13 ] , and diseases whose maximum similarity to all other diseases is less than 0.5 to preserve significant similarities among diseases [ 27 ] . The resulting disease gene associations involve 147 associations between 106 diseases and 102 genes . These genes are
( a ) Heterogeneous network structure
( b ) NoN structure
Figure 3 : Heterogeneous network and NoN for the candidate gene prioritization problem . The protein interaction network in ( a ) is unweighed while those in ( b ) are weighed , denoting by the edge thickness used as seed nodes in CROSSRANK which are represented by the white rectangles in Figure 3(b )
We select four state of the art methods for comparison , including RWRH [ 14 ] , BIRW [ 31 ] , PRINCE [ 28 ] and Katz [ 20 ] . We use the standard leave one out cross validation to compare the prioritization accuracy of the selected methods . Specifically , at each time , we remove an association between the query disease and one causal gene , as well as all the associations involving the causal gene to avoid the trivial cases where mutations in the same gene cause two very similar diseases [ 28 , 17 ] . This causal gene is used as the test gene . If the test gene is ranked within the top k genes , where k is the total number of known genes for the query disease , this is considered as a successful prediction . This evaluation method is
0 5 10 15 20 25k=5k=20k=50k=200k=500Time ( sec.)CrossRankCrossQuery BasicCrossQuery Fast 0 100 200 300 400 500k=5k=20k=50k=200k=500Time ( sec.)CrossRankCrossQuery BasicCrossQuery Fast 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1DBLPSyntheticAccuracyk=5k=20k=50k=200k=500Protein Interaction NetworkDisease Similarity NetworkbcadAssociationsDisease gene12345Tissue specific Protein Interaction NetworksDisease Similarity Network12345123123412345bcad ( a ) # successful preditions
( b ) ROC using generic protein network ( c ) ROC using tissue specific protein network
Figure 4 : Comparison between CROSSRANK and baseline methods
Method RWRH RWRH* BIRW BIRW* PRINCE PRINCE* Katz Katz* CrossRank
Table 5 : AUC value comparison AUC50 0.2222 0.2143 0.2261 0.2233 0.2373 0.2446 0.1869 0.1948 0.2935
AUC100 AUC300 AUC500 AUC 0.2846 0.2616 0.2786 0.2653 0.2799 0.2899 0.2343 0.2299 0.3477
0.3335 0.3364 0.3198 0.3203 0.3454 0.3656 0.2896 0.2804 0.4280
0.3601 0.3738 0.3381 0.3393 0.3827 0.4133 0.3073 0.3077 0.4800
0.8049 0.8475 0.7586 0.7672 0.8339 0.8832 0.7594 0.7636 0.9048
Table 6 : Ranking results comparison worse 39 47 37 38 35 62 34 35 p value 2.04 × 10−11 2.38 × 10−6 1.82 × 10−11 1.44 × 10−9 1.08 × 10−10 1.17 × 10−2 2.32 × 10−12 1.23 × 10−10
Method CrossRank vs . RWRH CrossRank vs . RWRH* CrossRank vs . BIRW CrossRank vs . BIRW* CrossRank vs . PRINCE CrossRank vs . PRINCE* CrossRank vs . Katz CrossRank vs . Katz* better 106 94 106 100 108 79 108 103 tie 2 6 4 9 4 6 5 9 commonly used in the candidate gene prioritization studies [ 28 ] . The parameters are tuned for their optimal performance for the selected methods .
Note that all these baseline methods use a generic ( non tissuespecific ) protein interaction network . For a fair comparison , we also apply these methods to tissue specific protein interaction networks . Specifically , for each query disease , we replace the generic protein interaction network by its most relevant tissue specific protein interaction network .
Figure 4(a ) shows the number of successful predictions made by the selected methods . As we can see , using tissue specific protein interaction networks can improve the accuracy for the baseline methods . CROSSRANK has more successful predictions than all other methods . Figures 4(b ) and 4(c ) show the ROC curve . The results are consistent with the previous ones . The corresponding AUC values are reported in Table 5 , where AUC values are reported by considering up to 50 , 100 , 300 , 500 and all false positives . Note that a “ * ” indicates the use of tissue specific protein interaction networks .
We further study how often CROSSRANK gives higher ranks to test genes than other methods . The results are shown in Table 6 .
The Wilcoxon signed rank test is used to assess the statistical significance of the difference between the ranking lists given by the two compared methods . It is clear from the table that the results of CROSSRANK are significantly better than that of the alternatives .
6 . RELATED WORK
Networks are ubiquitous in real life applications . The simplest model uses a single graph to represent a network . A variety of ranking algorithms have been developed for a single network [ 9 , 8 , 19 , 6 , 15 ] . Recently , various advanced network models have been proposed , such as multi relational network [ 18 ] , heterogenous information network [ 23 ] , and hypergraph [ 34 ] . The multi relational network and heterogeneous information network can incorporate node or edge type information : in a multi relational network , edges connecting two nodes may be of different types ; while different types of objects can co exist in a heterogenous information network . Some work uses them interchangeably [ 32 ] . A tensor based co ranking framework is proposed in [ 18 ] for multi relational network . In heterogeneous information network , ranking based clustering [ 23 ] and ranking based classification [ 10 ] frameworks are developed , where ranking and clustering/classification can be mutually enhanced . In a hypergraph , an edge can connect any subset of nodes and is similar to a main node in our NoN model . But the set of nodes connected by an edge in a hypergraph do not form any network topology . If we treat each hyperedge as a main node , hypergraph can be viewed as special case of NoN where we do not have any links among domain nodes at all .
7 . CONCLUSION
Ranking is a primitive operation in network analysis . In this paper , we propose a new network data model , Network of Networks ( NoN ) , which enables novel ranking tasks such as CROSSRANK and CROSSQUERY . We formulate ranking on NoN as a regularized optimization problem , develop efficient algorithms , and provide rigorous theoretical analysis . Experimental results on realworld datasets demonstrate the effectiveness and efficiency of the proposed methods .
8 . ACKNOWLEDGEMENT
This work was partially supported by the National Science Foundation grants IIS 1162374 , IIS 1218036 and IIS1017415 , by the Army Research Laboratory under Cooperative Agreement Number W911NF 09 2 0053 , by Defense Advanced Research Projects Agency ( DARPA ) under Contract Number W911NF 11 C 0200 and
0 2 4 6 8 10 12 14 16 18 20GenericTissue specificSuccess countsPPI network typeBIRWRWRHPRINCEKatzCrossRank 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1True positive rateFalse positive rateCrossRankBIRWRWRHPRINCEKatz 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1True positive rateFalse positive rateCrossRankBIRW*RWRH*PRINCE*Katz* W911NF 12 C 0028 , by Region II University Transportation Center under the project number 49997 33 25 , and by China 973 Fundamental R&D Program ( No2014CB340304 )
9 . REFERENCES [ 1 ] R . Bhatia . Linear algebra to quantum cohomology : the story of alfred horn ’s inequalities . American Mathematical Monthly , pages 289–318 , 2001 .
[ 2 ] D . Chakrabarti , Y . Zhan , and C . Faloutsos . R mat : A recursive model for graph mining . In SDM , 2004 .
[ 3 ] Y . Chen , T . Jiang , and R . Jiang . Uncover disease genes by maximizing information flow in the phenome–interactome network . Bioinformatics , 27(13):i167–i176 , 2011 .
[ 4 ] Y . Chen , W . Zhang , M . Gan , and R . Jiang . Constructing human phenome interactome networks for the prioritization of candidate genes . STATISTICS AND ITS INTERFACE , 5(1):137–148 , 2012 .
[ 5 ] Y . Fujiwara , M . Nakatsuji , M . Onizuka , and M . Kitsuregawa .
Fast and exact top k search for random walk with restart . VLDB , 5(5):442–453 , 2012 .
[ 6 ] Y . Fujiwara , M . Nakatsuji , H . Shiokawa , T . Mishima , and
M . Onizuka . Efficient ad hoc search for personalized pagerank . In SIGMOD , pages 445–456 , 2013 .
[ 7 ] A . Hamosh , A . F . Scott , J . S . Amberger , C . A . Bocchini , and
V . A . McKusick . Online mendelian inheritance in man ( omim ) , a knowledgebase of human genes and genetic disorders . Nucleic acids research , 33(suppl 1):D514–D517 , 2005 .
[ 8 ] G . Jeh and J . Widom . Simrank : a measure of structural context similarity . In KDD , pages 538–543 , 2002 .
[ 9 ] G . Jeh and J . Widom . Scaling personalized web search . In
WWW , pages 271–279 , 2003 .
[ 10 ] M . Ji , J . Han , and M . Danilevsky . Ranking based classification of heterogeneous information networks . In KDD , pages 1298–1306 , 2011 .
[ 11 ] L . Katz . A new status index derived from sociometric analysis . Psychometrika , 18(1):39–43 , 1953 .
[ 12 ] Y . Koren , S . C . North , and C . Volinsky . Measuring and extracting proximity in networks . In KDD , pages 245–255 , 2006 .
[ 13 ] K . Lage , N . T . Hansen , E . O . Karlberg , A . C . Eklund , F . S .
Roque , P . K . Donahoe , Z . Szallasi , T . S . Jensen , and S . Brunak . A large scale analysis of tissue specific pathology and gene expression of human disease genes and complexes . Proceedings of the National Academy of Sciences , 105(52):20870–20875 , 2008 .
[ 14 ] Y . Li and J . C . Patra . Genome wide inferring gene–phenotype relationship by walking on the heterogeneous network . Bioinformatics , 26(9):1219–1224 , 2010 .
[ 15 ] D . Liben Nowell and J . Kleinberg . The link prediction problem for social networks . Journal of the American society for information science and technology , 58(7):1019–1031 , 2007 .
[ 16 ] R . N . Lichtenwalter , J . T . Lussier , and N . V . Chawla . New perspectives and methods in link prediction . In KDD , pages 243–252 , 2010 .
[ 17 ] O . Magger , Y . Y . Waldman , E . Ruppin , and R . Sharan . Enhancing the prioritization of disease causing genes through tissue specific protein interaction networks . PLoS Computational Biology , 8(9):e1002690 , 2012 .
[ 18 ] M . K P Ng , X . Li , and Y . Ye . Multirank : co ranking for objects and relations in multi relational data . In KDD , pages 1217–1225 , 2011 .
[ 19 ] P . Sarkar , A . W . Moore , and A . Prakash . Fast incremental proximity search in large graphs . In ICML , pages 896–903 , 2008 .
[ 20 ] U . M . Singh Blom , N . Natarajan , A . Tewari , J . O . Woods ,
I . S . Dhillon , and E . M . Marcotte . Prediction and validation of gene disease associations using methods inspired by social network analyses . PloS one , 8(5):e58977 , 2013 .
[ 21 ] Y . Sun , R . Barber , M . Gupta , C . C . Aggarwal , and J . Han .
Co author relationship prediction in heterogeneous bibliographic networks . In ASONAM , pages 121–128 , 2011 . [ 22 ] Y . Sun , J . Han , X . Yan , P . S . Yu , and T . Wu . Pathsim : Meta path based top k similarity search in heterogeneous information networks . VLDB , 2011 .
[ 23 ] Y . Sun , J . Han , P . Zhao , Z . Yin , H . Cheng , and T . Wu .
Rankclus : integrating clustering with ranking for heterogeneous information network analysis . In EDBT , pages 565–576 , 2009 .
[ 24 ] J . Tang , J . Zhang , L . Yao , J . Li , L . Zhang , and Z . Su .
Arnetminer : extraction and mining of academic social networks . In KDD , pages 990–998 , 2008 .
[ 25 ] H . Tong , C . Faloutsos , and J Y Pan . Random walk with restart : fast solutions and applications . In ICDM , pages 327–346 , 2006 .
[ 26 ] H . Tong , J . He , M . Li , W Y Ma , H J Zhang , and C . Zhang .
Manifold ranking based keyword propagation for image retrieval . EURASIP J . Adv . Sig . Proc . , 2006 .
[ 27 ] M . A . van Driel , J . Bruggeman , G . Vriend , H . G . Brunner , and J . A . Leunissen . A text mining analysis of the human phenome . European journal of human genetics , 14(5):535–542 , 2006 .
[ 28 ] O . Vanunu , O . Magger , E . Ruppin , T . Shlomi , and R . Sharan .
Associating genes and protein complexes with disease via network propagation . PLoS computational biology , 6(1):e1000641 , 2010 .
[ 29 ] X . Wu , R . Jiang , M . Q . Zhang , and S . Li . Network based global inference of human disease genes . Molecular Systems Biology , 4(1 ) , 2008 .
[ 30 ] X . Wu , Q . Liu , and R . Jiang . Align human interactome with phenome to identify causative genes and networks underlying disease families . Bioinformatics , 25(1):98–104 , 2009 .
[ 31 ] M . Xie , T . Hwang , and R . Kuang . Reconstructing disease phenome genome association by bi random walk . Bioinformatics , 2012 .
[ 32 ] Y . Yang , N . Chawla , Y . Sun , and J . Hani . Predicting links in multi relational and heterogeneous networks . In ICDM , pages 755–764 , 2012 .
[ 33 ] D . Zhou , O . Bousquet , T . N . Lal , J . Weston , and
B . Schölkopf . Learning with local and global consistency . Advances in neural information processing systems , 16(16):321–328 , 2004 .
[ 34 ] D . Zhou , J . Huang , and B . Schölkopf . Learning with hypergraphs : Clustering , classification , and embedding . Advances in neural information processing systems , 19:1601 , 2007 .
