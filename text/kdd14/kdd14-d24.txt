COM : a Generative Model for Group Recommendation
†School of Computer Engineering , Nanyang Technological University , Singapore 639798
Quan Yuan†∗ , Gao Cong† , Chin Yew Lin‡ {qyuan1@e . , gaocong@}ntuedusg ‡Microsoft Research , Beijing , China 100080 cyl@microsoft.com
ABSTRACT With the rapid development of online social networks , a growing number of people are willing to share their group activities , eg , having dinners with colleagues , and watching movies with spouses . This motivates the studies on group recommendation , which aims to recommend items for a group of users . Group recommendation is a challenging problem because different group members have different preferences , and how to make a trade off among their preferences for recommendation is still an open problem .
In this paper , we propose a probabilistic model named COM ( COnsensus Model ) to model the generative process of group activities , and make group recommendations . Intuitively , users in a group may have different influences , and those who are expert in topics relevant to the group are usually more influential . In addition , users in a group may behave differently as group members from as individuals . COM is designed based on these intuitions , and is able to incorporate both users’ selection history and personal considerations of content factors . When making recommendations , COM estimates the preference of a group to an item by aggregating the preferences of the group members with different weights . We conduct extensive experiments on four datasets , and the results show that the proposed model is effective in making group recommendations , and outperforms baseline methods significantly . Categories and Subject Descriptors H33 [ Information Search and Retrieval ] : Information Filtering Keywords Group Recommendation ; Collaborative Filtering ; Topic Models
1 .
INTRODUCTION
Recommender systems ( RS ) aim to suggest items for users based on their preferences , and they have been widely deployed to assist users to select items in various fields , such as movies ( Netflix ) , products ( Amazon ) , restaurants ( Yelp ) , etc . A number of rec∗ Research .
Part of this work was done when the first author was on an internship at Microsoft
Figure 1 : An Example of Group Check in ommendation techniques have been proposed , such as user/itembased collaborative filtering ( CF ) [ 17 , 21 ] , clustering CF [ 24 ] , matrix factorization [ 11 ] , etc . , and most of them focus on producing recommendations for individual users . However , people often participate in activities together with others , eg , having dinners with colleagues , watching movies with spouses , and having picnics with friends . This calls for recommendation techniques for a group . Unfortunately , recommender systems designed for individuals are not effective in making recommendations for a group of people . Furthermore , an increasing number of group event records are becoming available on the web , since users often share their group activities on social networks , such as Facebook , Meetup , and Foursquare . For example , the Foursquare check in in Figure 1 shows that user Angele D . , together with her husband , visited the Outback steakhouse . The availability of group event data promotes the research interest on how to make effective recommendations for a group of users [ 3 , 4 , 6 , 8 , 13 , 26 ] , which not only facilitates groups making decisions , but also helps web services improve user engagement .
However , making accurate recommendations for groups is not an easy task , because a group consists of multiple users who have different preferences . How to make a trade off among their preferences to recommend items for a group is challenging . Previous solutions to group recommendation can be divided into two types : memory based and model based approaches . Memory based approaches further fall in two categories based on the aggregation strategy : preference aggregation strategy first aggregates the profiles of group members into a new profile , and then employs recommendation techniques designed for individuals to make group recommendations [ 15 , 28 ] ; score aggregation strategy first calculates a recommendation list for each group member , and then aggregates these lists for group recommendation [ 4 , 7 , 14 , 18 , 20 ] . However , both strategies overlook the interactions between group members , and use trivial methods to aggregate members’ preferences . Different from memory based approaches , model based methods exploit the interactions among members by modeling the generative process of a group [ 13 , 26 ] . However , as to be detailed in Section 2 , the assumptions of these models may not hold in real life .
To achieve better accuracy , we propose a latent Dirichlet allocation ( LDA ) [ 5 ] based generative model , named COnsensus Model ( COM ) , to make group recommendations . COM is novel since it is built based on the following three considerations that have not been exploited by previous work :
1 . Each group is relevant to several topics , eg , a picnic group is relevant to hiking and dining topics , and a movie watching group consisting of families may be relevant to the romance and comedy topics . The item selection of a group is influenced by both these relevant topics and group members’ personal considerations of content factors , such as the geographical distance to venues for venue recommendation , and casts of movies for movie recommendation .
2 . Users in a group may behave differently as group members from as individuals , eg , a user may prefer horror movies when he is alone , but will select romantic movies when watching with his wife .
3 . Different users have different influences in making decisions in a group , and the influence degree of a user in a group is topic dependent : a movie fan is probably influential in making decisions for a movie watching group , but is less influential in a dining group , because the dining group is less relevant to the movie topic .
Based on the three considerations , we model the generative process of a group as follows : each group has a multinomial distribution over latent topics , and these topics attract a set of users to join . The item selection of a user is influenced by both the group topic that attracted her , and her personal considerations of content factors ( Consideration 1 ) . Note that it is the topic of the group , instead of the user ’s , that account for her item selection ( Consideration 2 ) . The final decision of a group is made by aggregating the selections of all users in the group : if a user is an expert in the relevant topics of the group , her selections will have a larger weight ( Consideration 3 ) . Based on the generative model , we propose a recommendation method to suggest items for a target group .
In summary , the contributions of this paper are three fold : • We propose a generative model COM for modeling the process of item selection of a group , which considers members’ topic dependent influences and members’ group behaviors . • We develop a recommendation method to make group recommendations based on COM , which is able to exploit both users’ selection history and users’ personal considerations of content factors . • We evaluate the effectiveness of the proposed method by extensive experiments on four datasets for event venue recommendation and movie recommendation . The experimental results show that our proposed method outperforms five baselines significantly by various evaluation metrics .
The rest of this paper is organized as follows . In Section 2 , we review related work . Section 3 introduces the proposed COM model and the recommendation method . We present experimental results in Section 4 . Finally , Section 5 concludes this paper .
2 . RELATED WORK
We first briefly review recommendation systems in general , and then focus on techniques for group recommendation . 2.1 Recommender Systems
Recommender systems can be classified into three categories : content based , collaborative filtering ( CF ) , and hybrid recommendation approaches [ 1 ] . The content based approaches make recommendations based on the content features of users ( eg , age , gender , etc . ) and items ( eg , price , category , etc. ) , but do not exploit users’ rating/selection history . Thus , when content features are not sufficient , the content based techniques will fail to produce accurate recommendations . In contrast , CF approaches rely on rating/selection history , but do not make use of content features . Consequently , they suffer from the sparsity problem , ie , when the number of users’ ratings is not enough for finding similar users , the performance of CF techniques will be bad . The hybrid approaches combine the content based and CF methods to avoid their limitations . Our proposed model exploits both users’ selection history and content information , and thus it belongs to the hybrid approaches . In addition , when the content information is not available , our model will be reduced as a CF model that makes recommendations based on users’ selection history only .
CF approaches have been extensively studied and can be further divided into two categories , namely , memory based CF and model based CF [ 23 ] . Memory based CF approaches employ rating/selection history to find similar users of the target user , and then compute a recommendation score for a candidate item by a weighted combination of historical ratings on the item from these similar users . In contrast , model based CF builds recommendation models using data mining techniques , such as clustering [ 19 ] , matrix factorization [ 11 ] , probabilistic topic model [ 2 , 25 ] , etc . Our model exploits users’ selection history in the model based manner .
2.2 Group recommendation
Group recommendation techniques have been proposed for various domains , such as web/news pages [ 20 ] , tourism [ 16 ] , restaurants [ 14 ] , music [ 7 ] , TV programs [ 28 ] , and movies [ 18 ] . Group recommendation methods in the earlier studies fall into two categories [ 3 ] : the preference aggregation approaches first aggregate the profiles of the group members into one profile , and makes recommendations based on the aggregated profile [ 15 , 28 ] . The score aggregation approaches , in contrast , first produce recommendations for each group member respectively , and then aggregate their recommendation results for the group [ 4 , 7 , 14 , 18 , 20 ] .
Compared with preference aggregation , score aggregation typically enjoys better flexibility [ 3 , 10 , 18 ] , and thus receives more research attention . The score aggregation approaches usually employ either average ( AVG ) or least misery ( LM ) strategy to aggregate the recommendations of individuals . The AVG strategy averages the recommendation scores of all group members as the final score , aiming to maximize the overall satisfactions of a group [ 15 , 28 ] ; the LM strategy takes the smallest recommendation score of group members as the final score , and tries to make everyone happy [ 4 ] . For LM , the recommendation score of an item is largely influenced by the user who dislikes it most , even if all the others like it very much . For AVG , an item ’s relevance to different users might be diverse , and the recommendation results might be unfair to some users . Baltrunas et al . [ 4 ] compare different aggregation approaches , and find that there is no clear winner , and the effectiveness of an approach depends on the group size and inner group similarity . AmerYahia et al . [ 3 ] go one step further , and argue that an item is a good recommendation for a group if the group members have small disagreements on the item , where the disagreement is defined as the difference among relevance of the item to different group members . Recently , several model based approaches have been proposed . Seko et al . [ 22 ] develop a content based group recommendation method based on the assumption that the choice made by a group is influenced by item genres . However , this approach can be only applied to pre defined groups , eg , couples , while in real life , groups are often ad hoc . Carvalho et al . [ 6 ] introduce game theory into group recommendation by treating a group event as a noncooper ative game among members , and transform the recommendation problem into finding the Nash equilibrium . However , this method cannot suggest a specific item , since the equilibrium contains a set of items .
The model based approaches proposed in [ 8 , 13 , 26 ] adopt the same setting as ours . Ye et al . [ 26 ] assume that when selecting items , a group member will follow her friends’ opinions . They propose a probabilistic generative model to produce group recommendations by aggregating the preferences of pairwise friends in the group , where one influences the other . However , the strong assumption of pairwise influence in a group may not be true , especially when the group is large . In addition , a group does not always consist of friends . Liu et al . [ 13 ] propose a topic model approach based on the assumption that the influential users will become the representatives of all groups to make item selections , irrespective of the group topics and the influential users’ expertise . However , users’ influences should be topic dependent : a user may be influential in a group because of her expertise on the group ’s topics , but may not be in another group . Gorla et al . [ 8 ] assume that the recommendation score for an item depends on its relevance to each group member and its relevance to the group as a whole . They propose an information matching based framework to make group recommendations . However , this framework has a high time complexity , which is O(|U|2|I|2 ) for each target group , where |U| and |I| are the sizes of user and item sets , respectively . We implemented and ran this method , but it could not finish on our datasets after 5 days and we stopped it . It can only finish on very small data we tried .
In our experiments , we will report comparison results with the approaches in the three proposals [ 3,13,26 ] . In the existing studies , these approaches have not been empirically compared with each other .
Finally note that the “ group recommendation ” defined in [ 31 ] concentrate on personalized recommendation of event based groups to a user , which is a totally different task .
3 . CONSENSUS MODEL
We first define the group recommendation problem in Section 3.1 , and then introduce the proposed COnsensus Model ( COM ) in Section 32 After that , the inference algorithm and the recommendation method are presented in Section 3.3 and 3.4 , respectively . Finally , we present how to incorporate content information into the model in Section 35 All the notations used in this paper are listed in Table 1 . 3.1 Problem Statement Let U , I , G be the user , item and group sets , respectively . A group g ∈ G consists of a set of users ( group members ) ug = {ug,1 , ug,2 , , ug,|g|} , where ug,i ∈ U , and |g| is the size of the group , In addition , a group g is associie , the number of users in g . ated with an item ig ∈ I , if ig is selected by group g . We define a group event by <ug , ig> , ie , the item selection event of the group members as a whole . For example , the members of a picnic group selecting a venue for picnic is a group event , and a family selecting a movie to watch is also a group event .
Then , given a target group gt , the problem of group recommendation is defined as recommending a list of items that users in gt may be interested in . 3.2 COnsensus Model for Group Recommen dation
We model the generative process of a group event based on the following intuitions :
Table 1 : Symbols
Description user set , item set , group set the number of latent topics the size of recommendation list the group g , the size of group g the members in group g the item selected by group g user u ∈ U the topic and switch of the user item pair j the set of items that are generated when c = ( · ) distribution of topics specific to group g distribution of users specific to topic z distribution of items specific to topic z distribution of items specific to user u the parameter of Bernoulli distribution specific to user u for sampling the binary switch c Beta prior for λ , where γ = {γ , γt} number of times topic z is assigned to group g , excluding the jth user item pair number of times user u is drawn from topic z , excluding the jth user item pair number of times item i is drawn from topic z , excluding the jth user item pair number of times item i is drawn from user u , excluding the jth user item pair number of times switch c is drawn for user u , excluding the jth user item pair
α , β , ρ , η Dirichlet prior vector for θ , φZU , φUI and φZI γ nGZ g,z,¬ j
Symbol U , I , G K N g , |g| ug ig u z j , c j i(· ) θg φZU z φZI z φUI u λu nZU z,u,¬ j nZI z,i,¬ j nUI u,i,¬ j nUC u,c,¬ j
• Intuition 1 : Each group is relevant to several topics with different degrees of match , eg , a picnic group is more relevant to the hiking and dining topics than to the body building topic . The topics of a group attract users to join the group . • Intuition 2 : When selecting an item , users in a group have two considerations . The first is topics , ie , a user tends to select the items that are related to the group topic , which attracted her to join the group . The second is users’ personal considerations of content factors , such as the geographical distance for venue recommendation , cast lists of movies for movie recommendation , etc . Most of these factors are userspecific , and cannot be captured by topics . In addition , different users make different trade offs between group topics and personal considerations of content factors : some users tend to select the items that match the group topics best , while some may treat the personal considerations more important . • Intuition 3 : Users behave differently when selecting items as members in a specific group and when selecting items as individuals . In a group , a user tends to match her preference to the topics of the group . • Intuition 4 : The preference of a group to a candidate item is determined by the preferences of the group members [ 3 , 8 ] . In addition to this , we exploit the following new intuition : the influence of each member on the item selection of the group is topic dependent .
Specifically , we use a multinomial distribution θg over latent topics to model the topic preferences of group g ( Intuition 1 ) . In addition , each latent topic z has a multinomial distribution φZU over z user set , which represents the relevance of users to the topic z , and a multinomial distribution φZI z over item set , which represents the relevance of items to the topic z . Here φZI z,i reflects given a topic z ,
. how likely the item i is selected ; φZU z,u reveals the appealing degree of topic z to the user u , or the user u ’s expertise on topic z . To model Intuition 1 that users join a group because of different topics , for each member in group g , a latent topic z is sampled from its topic distribution θg , and then a user u is drawn according to φZU z
A user in a group selects items either based on the group topics that attracted her to join the group , or her personal considerations of content factors ( Intuition 2 ) . We use a switch c to decide which one accounts for the item selection of a user , ie , if c = 1 , the item is sampled based on the topic specific multinomial distribution over items φZI ; if c = 0 , the item is drawn from the user specific multinomial distribution of items φUI . Since different users will make different trade offs between group topics and personal considerations of content factors ( Intuition 2 ) , in our model , the switch c is drawn from a user specific Bernoulli distribution with parameter λu . In other words , user u is influenced by group topics with probability λu , and is influenced by her personal considerations with probability 1 − λu . Note that the Bernoulli distribution for λu has a Beta prior γ = {γ , γt} . Next we illustrate the model using an example . Suppose a picnic group is more relevant to both hiking and dining topics than body building topic . The three topics are sampled from the topic distribution of the picnic group , which attract users u1 , u2 and u3 , respectively . Then , these three users determine which venue to visit based on the group topics and their personal considerations of content factors such as traveling distance . Suppose u1 does not mind traveling , and the topic “ hiking ” has a more significant influence to his selection . Then she may select a distant venue that matches the hiking topic best . Thus , the switch c for u1 is more likely to be 1 . u2 and u3 will also make trade offs between group topics and their personal considerations to select the venue for picnic .
Different from COM , previous topic model based approaches [ 13 , 26 ] assume that when selecting items , a group member only considers her own topic preference . The assumption may not hold , because users in a group may behave differently as group members from that when they make choices as individuals ( Intuition 3 ) . For example , suppose u1 is interested in both hiking and movie topics . In previous approaches , u1 may select a theater for the picnic group because of her interest in movie topic . In contrast , in our model , u1 join the picnic group because of the hiking topic , and thus her selection will be related to hiking rather than movie . is as follows :
In summary , the generative process of a collection of group events • For each topic zk , k = 1 , , K
– Draw φZU k – Draw φZI k
∼ Dirichlet(β ) ; ∼ Dirichlet(η ) ; • For each user uv , v = 1 , ,|U| ∼ Dirichlet(ρ ) ;
– Draw φUI v – Draw λv ∼ Beta(γ ) ;
• For each group g
– Draw θg ∼ Dirichlet(α ) ; – For each group member
∗ Draw z ∼ Multinomial(θg ) ; ∗ Draw u ∼ Multinomial(φZU ) ; ∗ Draw switch c ∼ Bernoulli(λu ) ; ∗ If c = 0 · Draw i ∼ Multinomial(φUI u ) ; ∗ If c = 1 · Draw i ∼ Multinomial(φZI z ) ; z
( cid:162 )
( cid:182)(cid:127 ) ( cid:460 )
( cid:172)(cid:437 )
( cid:182 ) ( cid:437 )
( cid:163 )
( cid:164 )
( cid:178)(cid:437 )
( cid:168 )
( cid:182)(cid:127 ) ( cid:460 )
( cid:169 )
( cid:460 )
( cid:437 )
( cid:349 )
( cid:272 )
( cid:878)(cid:336)(cid:878 )
( cid:878)(cid:878 )
Figure 2 : The Graphical Model of COM
The graphical model is shown in Figure 2 . Note that different users in a group will sample different items in the model , which is in accordance with our experience : users may have different preferences over items , and thus are likely to make different choices . In fact , the item selection of a group is often made by two steps : group members express their own opinions on item selections first , and then these selections are weighted and a consensus is reached . As to be detailed in Section 3.4 , we propose a recommendation method that can aggregate the selections of group members based on their topic dependent influences , and produce a single recommendation for the target group .
We remark that the aforementioned generative process is also applicable to the groups with pre defined members , since these groups also have topic distributions . Consider some students plan to form a club group and the topics of the group are dining , hiking , etc . The group is formed because its topics attract the members . If someone is not interested in any of the group topics , she will not join the group . Thus , the generative process of the club can also be explained by the proposed model , where the group members are sampled from the students . 3.3 Parameter Estimation
The total likelihood of the group event corpus is :
=
. . P(z , u , c , i|α , β , ρ , η , γ ) P(c|λ)P(λ|γ , γt)dλ · . P(u|z , φZU)P(φZU|β)dφZU · . .
P(z|θ)P(θ|α)dθ ·
P(i|u , z , c , φUI , φZI)P(φUI|ρ)P(φZI|η)dφUIdφZI(1 )
We employ collapsed Gibbs sampling to obtain samples of the hidden variable assignment , and to estimate the unknown parameters {λ , φZU , φUI , φZI} . For ease of presentation , we define a user u together with the item i selected by u as a user item pair j = ( u , i ) , where the user of j is u ∈ U , and the item of j is i ∈ I .
=
=
∝
Since there are two latent variables in the model , namely z and c , we employ two step Gibbs sampling method . We first sample topics z j for all user item pairs j , and then sample switches c j for all j . For each latent variable ( eg , z j ) , a Gibbs sampling method computes the full conditional probability for the assignment of the variable conditioned on all the other assignments ( eg , z¬ j ) . However , it is challenging to get the full conditional probability because of the complex interdependencies between user u , topic z , switch c and item i : u is sampled based on z , which influences the sampling of c , while i is sampled based on either z or u depending on c .
To solve this problem , we separate the items generated based on topics , and the items generated based on users’ personal considerations of content factors . Then , the last part of Equation 1 becomes :
. . . .
P(i|u , z , c , φUI , φZI)P(φUI|ρ)P(φZI|η)dφUIdφZI
P(i(0)|u , c , φUI)P(φUI|ρ)dφUI · P(i(1)|z , c , φZI)P(φZI|η)dφZI
( 2 ) where i(0 ) is the set of items that are sampled based on users’ personal considerations of content factors ( ie , c = 0 ) , and i(1 ) is the set of items that are sampled based on topics ( ie , c = 1 ) .
Based on the new equation of total likelihood , we can derive the full conditional distribution of topic z j and switch c j assignments for each user item pair j . If the item of j is drawn based on topics , ie , c j = 1 , we sample z j according to the following probability :
P(u|z , φZU)P(φZU|β)dφZU P(u|z¬ j , φZU)P(φZU|β)dφZU
·
· fi fi fi P(z j = k|z¬ j , u , i(1 ) ) fi P(z|θ)P(θ|α)dθ fi P(z¬ j|θ)P(θ|α)dθ fi P(i(1)|z , c , φZI)P(φZI|η)dφZI P(i(1)|z¬ j , c , φZI)P(φZI|η)dφZI ' + βu nGZ g j ,k,¬ j + βu ) ( nGZ g j ,k,¬ j
+ αk + αk ) nZU k,u,¬ j ( nZU k,u,¬ j
'
· u∈U k∈Z
·
' i∈I nZI k,i,¬ j ( nZI k,i,¬ j
+ ηi + ηi )
( 3 ) where g j is the group of j . If the item of j is drawn based on user ’s personal considerations of content factors , ie , c j = 0 , we have :
P(z j = k|z¬ j , u , i(0 ) ) '
+ αk nGZ g j ,k,¬ j k∈Z(nGZ
+ αk ) g j ,k,¬ j
'
·
∝
+ βu nZU k,u,¬ j u∈U(nZU k,u,¬ j
+ βu )
( 4 )
After sampling topics for all user item pairs , we draw a switch c j for each j according to the following posterior probability . When c j = 1 , we have :
= fi fi P(c j = 1|c¬ j , z , u , i ) fi P(c|λ)P(λ|γ , γt)dλ fi P(c¬ j|λ)P(λ|γ , γt)dλ fi P(i(1)|z , c , φZI)P(φZI|η)dφZI P(i(1)|z , c¬ j , φZI)P(φZI|η)dφZI fi
·
P(i(0)|u , c , φUI)P(φUI|ρ)dφUI P(i(0)|u , c¬ j , φUI)P(φUI|ρ)dφUI
·
( 5 )
Note that since c j = 1 , the second term in the right hand side of
Equation 5 is 1 . Thus , we cancel this part , and get :
P(c j = 1|c¬ j , z , u , i )
+ γ nUC u,(1),¬ j + nUC
'
·
+ ηi nZI z j ,i,¬ j i∈I(nZI z j ,i,¬ j nUC u,(0),¬ j
+ ηi ) Similarly , we calculate the sampling probability for c j = 0 :
+ γ+ γt u,(1),¬ j
P(c j = 0|c¬ j , z , u , i ) + γt u,(1),¬ j nUC u,(0),¬ j + nUC nUC u,(0),¬ j
+ γ+ γt
'
·
+ ρi nUI u,i,¬ j i∈I(nUI u,i,¬ j
+ ρi )
∝
∝
After sampling a sufficient number of iterations , we calculate the parameters φZU , φUI , φZI and λ as follows : + βu z,u + βu ) u∈U(nZU
' nZU z,u u,i z,u ffφZU ffφUI ffφZI
= ffP(u|z ) = = ffP(i|u ) = = ffP(i|z ) = ffλu = ffP(c = 1|u ) = z,i
' ' nUI u,i
+ ρi u,i + ρi ) i∈I(nUI nZI z,i i∈I(nZI
+ ηi z,i + ηi ) nUC u,(1 ) + nUC u,(1 )
+ γ + γ+ γt
( 6 )
( 7 )
( 8 )
( 9 )
( 10 )
( 11 ) nUC u,(0 ) 3.4 Recommendation
When making recommendations for a target group gt , we first discover its topic distribution based on the group members ugt . The distribution , denoted by θgt , can be learnt by performing Gibbs sampling on ugt according to the following equation : + αk )
P(z j = k|z¬ j , u j = v , u¬ j ) ∝ ffφZU
( 12 ) k,v ( nGZ gt ,k,¬ j
Since the recommendations should match the topic distribution θgt , based on the generative model , we define the recommendation score for candidate item i as follows : P(i|ugt
+ ( 1 −ffλu ) · ffφUI z,u ( ffλu · ffφZI
θgt ,z · ffφZU
, θgt ) .
( 13 ) u,i ) z,i u∈ugt z∈Z z,i
+ ( 1− λu)· φUI
Equation 13 embeds Intuition 4 ( when selecting items , different users in a group have different influence scores , and the influence scores are topic dependent ) as follows : if the topic z is more relevant to group gt , and a user u is an expert in z , then u will be more influential in item selection . Recall that the expertise of a z,u . In Equation 13 , θgt ,z · φZU user u on topic z is modeled by φZU z,u is the influence score of user u in group gt for a given topic z , and λu · φZI u,i is u ’s preference to a candidate item i given topic z . We margin out the topics , and get the overall preference of u to i . Then the preferences of all members to i are multiplied as the group preference to i . The rationale is three fold : 1 ) the preference of a group to an item depends on the preferences of all individuals ; 2 ) ranking an item based on the product of preferences is equal to the geometric mean of these individuals’ preferences . Compared with the traditional strategies that calculate the arithmetic mean of preferences ( averaging ) or concentrate on the smallest preference ( least misery ) , the aggregated preference score by geometric mean is less sensitive to extreme values ; 3 ) this definition matches the proposed model well .
3.5 Incorporation of Content Information
The Dirichlet prior ρ to φUI u allows us to incorporate different content information into the model . We illustrate the incorporation using two recommendation tasks , namely , venue recommendation and movie recommendation . Venue recommendation for groups : People often visit venues together with others for shopping , dining , etc . Venue recommendation for a group aims to recommend the venues that the group members are interested in . For venue recommendation , geographical distance is an important factor to consider [ 27 , 30 ] . Previous studies reported that users tend to visit nearby venues , and the willingness of visiting a venue decreases with the increase of distance from their current locations . Here , we adopt a power law function of distance to model the willingness of a user moving from one venue to another as [ 29 ] does . More specifically , the willingness of a user to visit a d km far away venue is defined by Equation 14 . wi(d ) = ω· dκ
( 14 ) where ω and κ are parameters of the power law function , which can be learned by maximum likelihood estimation . Then , given a user u , the set of venues that she has visited Iu , we calculate P(i|Iu ) for each candidate venue i according to the geographical distance , and use this value for ρu,i . Based on the Bayes rule , P(i|Iu ) is calculated as follows :
ρu,i = P(i|Iu ) ∝
P(i)P(Iu|i ) P(i ) P(i
|i )
= i∈Iu
( 15 ) |i ) is proportional to the willingness value in Equation 14 , where P(i fi in which d is the distance between venues i Movie recommendation for groups : When selecting a movie to watch , a user may consider several factors , such as genre , cast , etc . We take the cast as an example to illustrate how to exploit content information . Intuitively , users tend to watch the movies stared by their favorite actors or actresses . We incorporate user u ’s cast based considerations to a movie i by modifying the prior ρu,i as follows : and i .
ρu,i ∝
P(s|u ) s∈Si
( 16 ) where s is a movie star , and Si is the cast list of movie i . P(s|u ) is estimated based on the occurrences of s in u ’s watching history . fi Note that the |U| × |I| dimensional matrix φUI requires a large amount of space , in which each value of φUI u,i is determined by both u,i and the prior ρi ( Equation 9 ) . Since for each user u , the count nUI = 0 and ρu,i = 0 ) , we can the values of most items in φUI are 0 ( nUI u,i use sparse matrix to store φUI to reduce the space complexity . 4 . EXPERIMENTS
We first introduce the setup of the experiments in Section 4.1 , and then present the experimental results in Section 4.2 , in which we compare the recommendation accuracy of our model with five baselines on four datasets . After that , we analyze which factor influences group members’ choices more significantly in Section 43 In the end , we show some sample topics discovered by the proposed model to examine their semantics in Section 44 4.1 Experimental Setup 411 Datasets Four real world datasets are used in our experiments . The first dataset is used in previous work [ 12 ] , which is collected from Plan
Table 2 : Statistics of the Datasets
Plancast 41,705 13,885 8,016 20.30 1.00
Jiepang MovieLens MovieLens 28,888 23,621 9,746 4.68 1.01
Simi 891 3,000 441 5
Rand 3,689 3,000 1,518
14.97
3.73
5
6.76
3.83
43.29
13.00
16.83
N/A
1.73
2.42
100.06
4.06
N/A
7.37
Dataset #Users
#Group Events
#Items
Avg . Group Size
Avg . #Items for a Group
Avg . #Records for a User
Avg . #Friends for a User
Avg . #Records for an Item cast1 , an event based social network ( EBSN ) . In Plancast , a user can follow others’ calendars , and join different events . An event involves a group of members , and is held at a venue . A venue is associated with a geographical coordinate . We treat an event as a group , where the users involved in the event are the group members , and the venue of the event is the item selected by them .
Second , we collect 45 million check ins from Jiapang2 , a location based social network ( LBSN ) . As shown in Figure 1 , LBSNs allow users to share their geographical information by check ins , where a check in has a user , time and venue , indicating the user visited the venue at that time . Each a venue in Jiepang is associated with its geographical coordinate . However , Jiepang does not contain explicit group information , and we extract implicit group check ins as follows : we assume if a set of friends visit the same venue at the same time , they are the members of a group . Specifically , the set of individual check ins made by friends within 0.5 hour is regarded as a group check in . For both Jiepang and Plancast datasets , we aim to recommend venues for given groups .
The last two datasets are extracted from 1M MovieLens dataset3 by following the approach in [ 4 ] . MovieLens allows users to rate the movies they have watched by stars ranging from 0 to 5 . Two kinds of groups are considered in the experiments : similar and random , denoted by MovieLens Simi and MovieLens Rand , respectively . Groups in MovieLens Simi have larger inner similarities between members , while groups in MovieLens Rand are randomly formed . The two datasets simulate two kinds of groups in real life : the groups formed by people who have similar preferences , and the groups that happen to be formed by a set of people . For each dataset , we randomly select 3000 groups with 5 members . We also evaluated groups of size 3 and 8 , and obtained similar results . The details for generating the datasets can be found in [ 4 ] . Given a group , if every member gives 4 stars or above to a movie , we assume that the movie is adopted by the group . We also collect the cast list of each movie from IMDB4 as content information .
The information of the four datasets is shown in Table 2 . For each dataset , we randomly mark off 20 % of group events as the test set to evaluate the recommendation accuracy of different methods .
412 Evaluation Metrics Following previous work [ 3,4,8,13 ] , we evaluate the accuracy of different methods with three metrics , namely average precision@N ( Pre@N ) , average recall@N ( Rec@N ) and normalized discounted
1http://plancast.com/ 2http://jiepang.com/ 3http://grouplens.org/datasets/movielens/ 4http://wwwimdbcom/interfaces/ cumulative gain ( nDCG ) , where N is the number of recommendations . We consider three values of N ( ie , 5 , 10 , 20 ) , where 5 is the default value .
Precision@N is the fraction of the top N recommendations that are adopted by a group , while recall@N is the fraction of items adopted by a group ( true items ) that are contained in the top N recommendations . Formally , given a group , the precision@N and recall@N are calculated as : precision@N =
|{top N recommendations} ∩ {true items}|
|{top N recommendations}| recall@N =
|{top N recommendations} ∩ {true items}|
|{true items}|
We average the precision@N and recall@N of all testing groups as the Pre@N and Rec@N , respectively . Note that the average number of true items of a group in Plancast and Jiepang is close to 1 ( Table 2 ) . In this case , Pre@N is proportional to Rec@N , since |{top N recommendations}| is N times greater than |{true items}| . Thus , to save space , we only report Rec@5 for the two datasets . nDCG measures how well a method can rank the true item higher in the recommendation list . It is calculated as follows :
( 17 )
( 18 )
( 19 )
( 20 )
N
DCG = rel1 + i=2 reli log2(i ) nDCG = DCG IDCG where reli = 1 if the ith item in the recommendation list is adopted by the group , and reli = 0 otherwise . IDCG is the maximum possible discounted cumulative gain ( DCG ) with optimal top N recommendations . We average the nDCG values of all groups as the final result . In the experiments , N is fixed at 10 .
For all metrics , larger value indicates better recommendation performance . 413 Recommendation Methods We evaluate 7 methods in our experiments , namely CF AVG , CF LM , CF RD [ 3 ] , SIG [ 26 ] , PIT [ 13 ] , and the proposed methods COMP and COM . To the best of our knowledge , these state ofthe art group recommendation methods have not been compared with each other in previous work , and our evaluation is the first experimental studies on them . User based CF with averaging strategy ( CF AVG ) : Given a candidate item i , CF AVG first estimates the recommendation score of each user in the target group by user based CF , and then uses the average of these scores as the recommendation score for the group . User based CF with least misery strategy ( CF LM ) : Given a candidate item i , CF LM first estimates the recommendation score of each user in the target group by user based CF , and then uses the smallest score as the recommendation score for the group . User based CF with relevance and disagreement ( CF RD ) [ 3 ] : This model calculates the recommendation score for a candidate item i based on the relevance and disagreement of the group , where the relevance is calculated based on either CF AVG or CF LM , and the disagreement can be either the average difference of recommendation scores of pair wise group members , or the variance of members’ recommendation scores . Social influence based group recommendation ( SIG ) [ 26 ] : SIG is a topic model based approach , which has been introduced in Section 2 . Since the MovieLens Simi and MovieLens Rand datasets have no friendship information , we do not report the results of SIG for them .
Personal impact topic model ( PIT ) [ 13 ] : PIT model assumes that different users have different impact scores , and in a group , the user who has a larger impact score is more likely to be selected as the representative . Given a group of users ugt , PIT model first samples a representative user r from ugt based on users’ impact scores , and then r selects a topic based on her topic preference , and finally the topic generates an item for the group . COnsensus Model Plain ( COMP ) : To make a fair comparison with these baselines which do not exploit users’ considerations of content factors , we use a symmetric Dirichlet prior for φUI to disregard the effect of content information . COnsensus Model ( COM ) : The proposed model incorporated with users’ considerations of content factors .
All baselines are evaluated under the optimal settings . For the hyperparameters in COMP and COM , we take fixed values ( α = 50/K , β = η = 0.01 , γ = γt = 0.5 and ρ = 0.01 for COMP ) . The prior ρ in COM encodes the content based knowledge , and needs to be set empirically . Previous work fixes its value as 0.01 [ 9 ] , and thus the sum of the prior is 0.01 × |I| . In this paper , we normalize the value of ρ of each user to a fix value 0.01 × p × |I| , where the parameter p is used to tune the confidence in the prior knowledge . 4.2 Experimental Results Precision and Recall Under Different N
We first fix the number of topics K at 250 , and vary the number of recommendations N . The Pre@N and Rec@N values on the four datasets are plotted in Figure 3 . Please note that the MovieLensSimi/Rand datasets do not contain social relations , and thus the baseline SIG cannot be applied to them .
CF AVG CF LM CF RD
SIG PIT COMP
COM
5
10
N
20
( b ) Rec@N Jiepang
CF AVG CF LM
CF RD PIT
COMP COM
CF AVG CF LM CF RD
SIG PIT COMP
COM
5
10
N
20
( a ) Rec@N Plancast
CF AVG CF LM
CF RD PIT
COMP COM
N @ c e R
N @ e r P
0.6
0.55
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.75
0.7
0.65
0.6
0.55
0.5
0.45
0.4
0.35
0.3
0.25
N @ c e R
N @ c e R
0.35
0.3
0.25
0.2
0.15
0.1
0.05
1
0.9
0.8
0.7
0.6
0.5
0.4
5
10
N
20
5
10
N
20
( c ) Pre@N MovieLens Simi
( d ) Rec@N MovieLens Simi
CF AVG CF LM
CF RD PIT
COMP COM
CF AVG CF LM
CF RD PIT
COMP COM
N @ e r P
0.2
0.18
0.16
0.14
0.12
0.1
0.08
0.06
N @ c e R
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
5
10
N
20
5
10
N
20
( e ) Pre@N MovieLens Rand
( f ) Rec@N MovieLens Rand
Figure 3 : Pre&Rec under #recommendations made ( N )
From Figure 3(a ) and 3(b ) , we can see that the CF based approaches , namely , CF AVG , CF LM and CF RD , do not perform well on the Plancast and Jiepang datasets . This is because the three methods exploit neither the difference of individuals , nor the inter actions among group members . They assume that users in a group make choices independently , and aggregate their choices for recommendations . The performance of SIG is not satisfactory , either . The reason is that SIG makes group recommendations based on the social relations between users in a group , and it requires tags of candidate items . However , in the groups of Plancast , only several or even none of the members are friends to each other , and neither of the two datasets has tag information . The lack of social relations and tags brings down its recommendation accuracy .
In contrast , PIT performs better than the CF based approaches on the Plancast and Jiepang datasets because PIT utilizes the interactions in a group by differentiating influences of users , and assumes that a user with a larger impact score will be influential in every group of the user . However , PIT ignores the fact that the influence of a user will be different across different topics . The performance of PIT on the two MovieLens datasets is not as good as on the Plancast and Jiepang datasets . This is because groups in the two datasets are loosely organized , and users select movie independently . Since no representative member exists to make item selections for a group , the basic assumption of PIT does not hold any more , which results in its bad recommendation accuracy .
Compared with the five baselines , our proposed method COMP always archives superior recommendation accuracy . For example , it outperforms CF AVG , CF LM , CF RD , SIG and PIT by 84 % , 34 % , 76 % , 43 % and 19 % , respectively , for Rec@5 on Plancast . The reasons are two fold : on the one hand , COMP considers the behavior changes of users in a group ; on the other hand , it estimates the topic dependent influences of users in a group . Compared with COMP , COM further improves Rec@5 by more than 15 % on Plancast , Jiepang and MovieLens Rand , showing that COM is effective in incorporating the content information ( geographical distance for Plancast and Jiepang , and cast list for MovieLens Rand ) . The improvement on MovieLens Simi is marginal , since its user item selection matrix has a high density ( about 4% ) . As a result , COMP , which only utilizes users’ selection history , already achieves very good accuracy(eg , Rec@5 is 67.3% ) , and thus the value of relative improvement is small . Precision and Recall Under Different K
We fix the number of recommendations at 5 , and vary the number of topics K from 50 to 400 . The Pre@5 and Rec@5 values on the four datasets are plotted in Figure 4 . Since CF AVG , CF LM and CF RD do not involve topics , their Pre@5 and Rec@5 values do not vary with K .
For the topic model based approaches , namely , SIG , PIT , COMP and COM , their Pre@5 and Rec@5 values do not change much with varying the number of topics . In addition , we notice that SIG performs worse than CF AVG , CF LM and CF RD on Plancast , but better than these CF based approaches on Jiepang when K ≥ 250 . This is because the group events of Jiepang are extracted based on friendships , and thus they fit well with the assumption of the SIG . PIT ’s Rec@5 value is the best among the baselines on the Plancast and Jiepang datasets , but is worse than that of CFAVG , CF LM and CF RD on MovieLens Simi and MovieLensRand . Potential reason is the generative process of groups in the MovieLens datasets is different from that of PIT model . Our proposed method COMP outperforms the best baselines by about 20 % on the four datasets . After incorporating users’ personal considerations of content factors , COM further improve the Rec@5 values by more than 15 % on the Plancast , Jiepang and MovieLens Rand datasets , demonstrating the effectiveness of the proposed model . nDCG Under Different K
Next , we vary the number of topics K , and examine the nDCG results of different approaches to see how well they can rank the
5 @ c e R
5 @ e r P
5 @ e r P
0.4
0.35
0.3
0.25
0.2
0.15
0.75
0.7
0.65
0.6
0.55
0.5
CF AVG CF LM CF RD
SIG PIT COMP
COM
CF AVG CF LM CF RD
SIG PIT COMP
COM
5 @ c e R
0.26
0.24
0.22
0.2
0.18
0.16
0.14
0.12
0.1
50
100
150
200
250
300
350
400
50
100
150
200
250
300
350
400
K
K
( a ) Rec@5 Plancast
( b ) Rec@5 Jiepang
CF AVG CF LM
CF RD PIT
COMP COM
CF AVG CF LM
CF RD PIT
COMP COM
5 @ c e R
0.65
0.6
0.55
0.5
0.45
50
100
150
200
250
300
350
400
50
100
150
200
250
300
350
400
( c ) Pre@5 MovieLens Simi
( d ) Rec@5 MovieLens Simi
K
K
CF AVG CF LM
CF RD PIT
COMP COM
0.2
CF AVG CF LM
CF RD PIT
COMP COM
0.18
0.16
0.14
0.12
0.1
0.08
5 @ c e R
0.28
0.26
0.24
0.22
0.2
0.18
0.16
0.14
0.12
0.1
50
100
150
200
250
300
350
400
50
100
150
200
250
300
350
400
( e ) Pre@5 MovieLens Rand
( f ) Rec@5 MovieLens Rand
K
K
Figure 4 : Pre@5&Rec@5 under #topics ( K ) true items higher . The results are plotted in Figure 5 . We can see that the results display a similar trend with the previous experimental results based on Pre@5 and Rec@5 : PIT performs the best among the baseline methods on Plancast and Jiepang , but the worst on MovieLens Simi and MovieLens Rand . However , our method COMP consistently outperforms the best baseline under different number of topics by more than 15 % on the four datasets . COM achieves the best results , which are at least 16 % greater than that of COMP on Plancast , Jiepang and MovieLens Rand . Effect of p
We next examine the effect of p on the recommendation accuracy of COM . Recall that after incorporating the users’ personal considerations of content factors into the prior , we normalize the prior of each user to p · 0.01 · |I| . Parameter p is set to adjust the effect of the prior , ie , larger p implies that the distribution φUI is u more influenced by the content information . We examine the recommendation accuracy of COM under different value of p ranging from 0.001 to 1000 . The Rec@5 and nDCG on four datasets are plotted in Figure 6 . We can see that the recommendation performance remains relatively stable when varying the value of p . The Pre@5 follows a similar trend with Rec@5 , and we omit it due to the space limitation . Performance for Different Size of Groups
This set of experiments is to study the performance of each recommendation method for groups of different sizes . We group the Plancast groups into bins based on group size , and plot the Rec@5 and nDCG curves of each method in Figure 7 . The number of topics is fixed at 250 . Due to the space limitation , the results on the other datasets are not given here . Figure 7 shows that the proposed methods COMP and COM outperform the baselines for groups of different sizes . Among the baselines , CF AVG , CF LM and CFRD perform the worst , followed by SIG and PIT . Compared with that of other methods , the performance of CF based approaches is
CF AVG CF LM CF RD
SIG PIT COMP
COM
CF AVG CF LM CF RD
SIG PIT COMP
COM
G C D n
0.24
0.22
0.2
0.18
0.16
0.14
0.12
0.1
0.08
5 @ c e R
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
CF AVG CF LM CF RD
SIG PIT COMP
COM
CF AVG CF LM CF RD
SIG PIT COMP
COM
G C D n
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
50
100
150
200
250
300
350
400
50
100
150
200
250
300
350
400
1 8
8 15
15 22
22 29
29 36
36 43
43 50
50
1 8
8 15
15 22
22 29
29 36
36 43
43 50
50
K
K
( a ) nDCG Plancast
( b ) nDCG Jiepang
Group Size
( a ) Rec@5
Group Size
( b ) nDCG
CF AVG CF LM
CF RD PIT
COMP COM
0.3
CF AVG CF LM
CF RD PIT
COMP COM
Figure 7 : Rec@5 and nDCG for Different Size of Groups
G C D n
G C D n
0.4
0.35
0.3
0.25
0.2
0.15
0.1
1
0.95
0.9
0.85
0.8
0.75
0.7
0.65
G C D n
0.25
0.2
0.15
50
100
150
200
250
300
350
400
50
100
150
200
250
300
350
400
( c ) nDCG MovieLens Simi
( d ) nDCG MovieLens Rand
K
K
Figure 5 : nDCG under #topics ( K ) better for groups of small size , because their group organizations are simple , and thus these simple aggregating strategies are good for making recommendations . 4.3 Weight of Topics in Item Selection
In this section , we study the weight of topics in users’ item selections by investigating parameter λu , the probability that a user selects an item according to group topics . We first study the effect of the number of topics K on the value of λu . Specifically , for each dataset , we plot the average λu of all users as a function of K . The curves of COMP and COM on the four datasets are shown in Figure 8 . We can see that for COMP which does not exploit the content information , the average λu is almost not affected by the value of K , and its value is between 0.75 to 09 The results reveal that most of items are selected according to topics , but there is still a set of items that are selected based on users’ personal considerations of content factors . Compared with the average λu of COMP , that of COM is much smaller , since additional content information is incorporated . The value of λu on Plancast ( around 0.5 ) is larger than that on Jiepang ( around 0.2 ) for COM , indicating that topics have larger weight in venue selections of Plancast users . In addition , the λu values of both COMP and COM on MovieLens Simi are larger than those on MovieLensRand , because groups in MovieLens Simi consist of people with high similarities , and thus topic is a very important consideration . Then , we fix the number of topics at 250 , and plot the distribution of λu of COM on the four datasets in Figure 9 . We notice that on all datasets , the λu value of the majority of users is smaller than 0.4 , showing that the personal considerations of content information is important for most of people . In addition , we see that the curve
Plancast Jiepang MovieLens Simi MovieLens Rand
5 @ c e R
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
G C D n
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
Plancast Jiepang MovieLens Simi MovieLens Rand
0.001
0.01
0.1
1.0 p
10
100
1000
0.001
0.01
0.1
10.0
100.0
1000.0
1.0 p
( a ) Rec@5
( b ) nDCG
Figure 6 : Rec@5 and nDCG under different p u
λ
. g v A u
λ
. g v A
COMP
COM
1
0.8
0.6
0.4
0.2
0
COMP
COM u
λ
. g v A
1
0.8
0.6
0.4
0.2
0
50
100
150
200
250
300
350
400
50
100
150
200
250
300
350
400
K
( a ) λu vs K Plancast
K
( b ) λu vs K Jiepang
1
0.8
0.6
0.4
0.2
0
COMP
COM
COMP
COM u
λ
. g v A
1
0.8
0.6
0.4
0.2
0
50
100
150
200
250
300
350
400
50
100
150
200
250
300
350
400
( c ) λu vs K MovieLens Simi
K
( d ) λu vs K MovieLens Rand
K
Figure 8 : Avg . λu under #topics ( K ) of Plancast has a long tail , indicating that a considerable portion of users treat topics important . In addition , λu on MovieLens Simi reaches another peak at λu = 1 , showing that in a group with high inner similarity , a considerable portion of people select items based on topics . 4.4 Topic Analysis
We first investigate the venue distribution of each topic generated by COM on Plancast and Jiepang datasets , where the number of topics is set to 250 . For each topic z , we rank the venues i based on φZI z,i . The top 5 venues of 5 randomly selected topics on the two datasets are plotted in Figure 10 . We observe that for each topic , the top ranked venues are close to each other . This is because topics are estimated based on users’ group participation history . Since users tend to join groups held at their nearby venues due to the spatial constraint , the venues visited by each user fall in a small geographical region , and thus the top ranked venues of each topic are close to each other .
Then , we examine the movie distributions of topics of COM on the MovieLens Rand dataset . Specifically , we set the number of topics at 50 for COM , and randomly select 5 topics . For each topic z , we rank the movies i based on the learnt φZI z,i . The top 3 movies of the 5 topics are listed in Table 3 . The name of each topic is generated from the top 10 movies’ genres in IMDB by majority vote . We can find that the discovered topics are semantically meaningful .
5 . CONCLUSION
Recommender systems have been studied for decades , but most of them are designed for individuals . How to make accurate recommendations for groups is still an open problem . In this paper , we propose a probabilistic model COM to simulate the generative
Plancast Jiepang e g a t n e c r e P
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
MovieLens Simi MovieLens Rand e g a t n e c r e P
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
0
0.1
0.2
0.3
0.4
0.5 λ u
0.6
0.7
0.8
0.9
1
0
0.1
0.2
0.3
0.4
0.6
0.7
0.8
0.9
1
0.5 λ u
( a ) Plancast/Jiepang
( b ) MovieLens Simi/Rand
Figure 9 : Distribution of λu
( a ) Plancast
( b ) Jiepang
Figure 10 : Venue Distribution of Topics process of group events and make recommendations for a group of users . Since users’ item selections are not only influenced by topics , but also by users’ personal considerations of content factors , we incorporate the content information into the model . In addition , the proposed model considers the change of users’ behaviors in a group from as individuals , and differentiates the influences of users in a group according to topics . Experimental results on four real world datasets show that the proposed method outperforms five baselines significantly .
For the future work , it would be interesting to exploit social relations to make group recommendations , since the friendships in a group may influence the group ’s choices . In addition , several content factors are difficult to be incorporated into the our model , eg , time . We will investigate how to model such content factors . 6 . ACKNOWLEDGEMENTS
This work is supported in part by a grant awarded by a Singapore MOE AcRF Tier 2 Grant ( ARC30/12 ) , a Singapore MOE AcRF Tier 1 Grant ( RG66/12 ) , and a grant awarded by Microsoft Research Asia . Quan Yuan would like to acknowledge the PhD grant from the Institute for Media Innovation , Nanyang Technological University , Singapore . 7 . REFERENCES [ 1 ] G . Adomavicius and A . Tuzhilin . Toward the next generation of recommender systems : A survey of the state of the art and possible extensions . IEEE Trans . Knowl . Data Eng . , 17(6):734–749 , 2005 .
[ 2 ] D . Agarwal and B C Chen . flda : matrix factorization through latent dirichlet allocation . In WSDM , pages 91–100 , 2010 .
[ 3 ] S . Amer Yahia , S . B . Roy , A . Chawla , G . Das , and C . Yu . Group recommendation : Semantics and efficiency . PVLDB , 2(1):754–765 , 2009 .
[ 4 ] L . Baltrunas , T . Makcinskas , and F . Ricci . Group recommendations with rank aggregation and collaborative filtering . In RecSys , pages 119–126 , 2010 .
[ 5 ] D . M . Blei , A . Y . Ng , and M . I . Jordan . Latent dirichlet allocation . Journal of
Machine Learning Research , 3:993–1022 , 2003 .
[ 6 ] L . A . M . C . Carvalho and H . T . Macedo . Users’ satisfaction in recommendation systems for groups : an approach based on noncooperative games . In WWW ( Companion Volume ) , pages 951–958 , 2013 .
[ 7 ] A . Crossen , J . Budzik , and K . J . Hammond . Flytrap : intelligent group music recommendation . In IUI , pages 184–185 , 2002 .
[ 8 ] J . Gorla , N . Lathia , S . Robertson , and J . Wang . Probabilistic group recommendation via information matching . In WWW , pages 495–504 , 2013 .
Table 3 : Representative Movies for COM Topics Topic Comedy
Big ( 1988 ) , Romancing the Stone ( 1984 ) ,
Four Weddings and a Funeral ( 1994 )
Movies
Action
Drama
Thriller
Animation
Raiders of the Lost Ark ( 1981 )
Star Wars : Episode V The Empire Strikes
Back ( 1980 ) , Full Metal Jacket ( 1987 ) Fight Club ( 1999 ) , Trainspotting ( 1996 ) ,
Magnolia ( 1999 )
Reservoir Dogs ( 1992 ) , Gattaca ( 1997 ) ,
Heavenly Creatures ( 1994 )
Toy Story 2 ( 1999 ) , Mulan ( 1998 ) ,
Peter Pan ( 1953 )
[ 9 ] T . L . Griffiths and M . Steyvers . Finding scientific topics . Proceedings of the
National academy of Sciences of the United States of America , 101(Suppl 1):5228–5235 , 2004 .
[ 10 ] A . Jameson and B . Smyth . Recommendation to groups . In The adaptive web , pages 596–627 . Springer , 2007 .
[ 11 ] Y . Koren , R . M . Bell , and C . Volinsky . Matrix factorization techniques for recommender systems . IEEE Computer , 42(8):30–37 , 2009 .
[ 12 ] X . Liu , Q . He , Y . Tian , W C Lee , J . McPherson , and J . Han . Event based social networks : linking the online and offline social worlds . In KDD , pages 1032–1040 , 2012 .
[ 13 ] X . Liu , Y . Tian , M . Ye , and W C Lee . Exploring personal impact for group recommendation . In CIKM , pages 674–683 , 2012 .
[ 14 ] J . F . McCarthy . Pocket restaurant finder : A situated recommender systems for groups . In Proceeding of Workshop on Mobile Ad Hoc Communication at the 2002 ACM Conference on Human Factors in Computer Systems , 2002 .
[ 15 ] J . F . McCarthy and T . D . Anagnost . Musicfx : An arbiter of group preferences for computer aupported collaborative workouts . In CSCW , pages 363–372 , 1998 .
[ 16 ] K . McCarthy , M . Salamó , L . Coyle , L . McGinty , B . Smyth , and P . Nixon . Cats :
A synchronous approach to collaborative group recommendation . In FLAIRS Conference , volume 2006 , pages 86–91 , 2006 .
[ 17 ] M . R . McLaughlin and J . L . Herlocker . A collaborative filtering algorithm and evaluation metric that accurately model the user experience . In SIGIR , pages 329–336 , 2004 .
[ 18 ] M . O’Connor , D . Cosley , J . A . Konstan , and J . Riedl . Polylens : A recommender system for groups of user . In ECSCW , pages 199–218 , 2001 .
[ 19 ] M . O’Connor and J . Herlocker . Clustering items for collaborative filtering . In Proceedings of the ACM SIGIR workshop on recommender systems , volume 128 . UC Berkeley , 1999 .
[ 20 ] S . Pizzutilo , B . De Carolis , G . Cozzolongo , and F . Ambruoso . Group modeling in a public space : methods , techniques , experiences . In Proceedings of the 5th WSEAS International Conference on Applied Informatics and Communications , pages 175–180 , 2005 .
[ 21 ] B . M . Sarwar , G . Karypis , J . A . Konstan , and J . Riedl . Item based collaborative filtering recommendation algorithms . In WWW , pages 285–295 , 2001 .
[ 22 ] S . Seko , T . Yagi , M . Motegi , and S . yo Muto . Group recommendation using feature space representing behavioral tendency and power balance among members . In RecSys , pages 101–108 , 2011 .
[ 23 ] X . Su and T . M . Khoshgoftaar . A survey of collaborative filtering techniques .
Adv . Artificial Intellegence , 2009 , 2009 .
[ 24 ] L . H . Ungar and D . P . Foster . Clustering methods for collaborative filtering . In
AAAI Workshop on Recommendation Systems , number 1 , 1998 .
[ 25 ] C . Wang and D . M . Blei . Collaborative topic modeling for recommending scientific articles . In KDD , pages 448–456 , 2011 .
[ 26 ] M . Ye , X . Liu , and W C Lee . Exploring social influence for recommendation : a generative model approach . In SIGIR , pages 671–680 , 2012 .
[ 27 ] M . Ye , P . Yin , W C Lee , and D . L . Lee . Exploiting geographical influence for collaborative point of interest recommendation . In SIGIR , pages 325–334 , 2011 .
[ 28 ] Z . Yu , X . Zhou , Y . Hao , and J . Gu . Tv program recommendation for multiple viewers based on user profile merging . User Model . User Adapt . Interact . , 16(1):63–82 , 2006 .
[ 29 ] Q . Yuan , G . Cong , Z . Ma , A . Sun , and N . Magnenat Thalmann . Time aware point of interest recommendation . In SIGIR , pages 363–372 , 2013 .
[ 30 ] Q . Yuan , G . Cong , Z . Ma , A . Sun , and N . Magnenat Thalmann . Who , where , when and what : discover spatio temporal topics for twitter users . In KDD , pages 605–613 , 2013 .
[ 31 ] W . Zhang , J . Wang , and W . Feng . Combining latent factor model with location features for event based group recommendation . In KDD , pages 910–918 , 2013 .
