TCS : Efficient Topic Discovery over Crowd oriented
Service Data
Yongxin Tong
Caleb Chen Cao
Lei Chen
Hong Kong University of Science & Technology , Hong Kong , China
{yxtong , caochen , leichen}@cseusthk
ABSTRACT In recent years , with the widespread usage of Web 2.0 techniques , crowdsourcing plays an important role in offering human intelligence in various service websites , such as Yahoo! Answer and Quora . With the increasing amount of crowd oriented service data , an important task is to analyze latest hot topics and track topic evolution over time . However , the existing techniques in text mining cannot effectively work due to the unique structure of crowd oriented service data , task response pairs , which consists of the task and its corresponding responses . In particular , existing approaches become ineffective with the ever increasing crowdoriented service data that accumulate along the time . In this paper , we first study the problem of discovering topics over crowd oriented service data . Then we propose a new probabilistic topic model , the Topic Crowd Service Model ( TCS model ) , to effectively discover latent topics from massive crowd oriented service data . In particular , in order to train TCS efficiently , we design a novel parameter inference algorithm , the Bucket Parameter Estimation ( BPE ) , which utilizes belief propagation and a new sketching technique , called Pairwise Sketch ( pSketch ) . Finally , we conduct extensive experiments to verify the effectiveness and efficiency of the TCS model and the BPE algorithm .
Categories and Subject Descriptors H28 [ Database Applications ] : Data Mining
General Terms Design , Experimentation , Performance
Keywords Crowd oriented Service , Probabilistic Topic Model , Crowdsourcing
1 .
INTRODUCTION
Crowdsourcing refers to outsourcing works traditionally performed by an employee to an “ undefined , generally large group of people in the form of an open call ” [ 13 ] . In general , crowdsourcing based service has a common framework : each employer ( aka the task publisher ) poses a task , and then this task is responded or finished by many different and unknown crowd employees . Thus , the “ task response pairs ” is the unique structure of crowdsourcing data . In this paper , we call information services provided by crowdsourcing , which include massive task response pairs , as crowd oriented services . Examples of crowd oriented services include Yahoo! Answers , Quora , and Baidu Recommender , etc .
Given a crowd oriented service system , one of the most significant problems is the “ assignment problem ” [ 11 ] , namely how the crowd oriented service system assigns a task to a right employee or helps an employee to find a right task . In order to enhance the accuracy of assignments , an effective method is to match them in terms of the semantic topic distribution of tasks and historical responses of employees . Thus , the problem of discovering topic is a fundamental task for crowd oriented service systems . For example , stackoverflow1 is a crowd oriented website regarding programming techniques . By means of discovering the topic distributions of tasks and responses in stackoverflow , we can know which programming technique is the most popular one in current communities of programmers and guide the crowdsourcing platform to find hidden speciality of crowd employee according to their responses .
Although topic discovery is a basic operator for crowdoriented service data , it is not trivial to capture hidden topics over crowd oriented service data using existing techniques of text mining . Back to the example about stackoverflow , Table 1 includes several real tasks and responses downloaded from the stackoverflow . The crowd oriented service data in Table 1 contains infinite entries that are chronologically ordered and each entry contains a task and its corresponding responses ( if any ) . We can observe that the first and second task response entries discuss the topic related with Android based developing techniques , and the third one is about iPhone techniques . If we use existing text mining techniques , such as Latent Dirichlet allocation ( LDA ) model , to discover the hidden topic distribution , a straightforward solution is to consider each task and response as a document and applies LDA model . For the first two entries in Table 1 , this method can capture the topic about Androidbased technique in the tasks and their responses since “ An
1http://stackoverflow.com/
861 Table 1 : Crowd oriented Service Data from the stackoverflow
Tasks
Responses
Android application database to save images
Android SQLite database with multiple tables can
How to use simpleadapter with activity Android
Find mobilephones on hotspot networks in iPhone ?
An Android ListView with adapter is shown as follows iOS 7 system of Apple devices provide an IP address of
ID 1 2 3 droid ” occur in both of them . However , for the third entry , LDA model might not return similar topic distribution because there is no common words appeared in both of the task and the response .
Thus , for crowd oriented service data , it is the necessary to discover hidden topics by considering both the taskresponse pair correlation and the specific semantic feature of each task and response . Furthermore , a real time crowdoriented service should be viewed as an online updateable data of crowd oriented task response pairs , which is referred as a series of consecutively submitted crowd oriented tasks ( task for short ) and corresponding responses from crowds . Therefore , for these online service data , the efficiency of training the model is another major concern . The latent topics need to be discovered from massive crowd oriented service data in real time . To achieve these goals in discovering topics over crowd oriented service data , we have to address the following two challenges .
• Challenge 1 : How to design an effective model to capture the task response correlation over dynamic evolving crowd oriented service data ?
• Challenge 2 : Facing the high volume of crowd oriented service data , how to guarantee the training efficiency ? There are two critical issues need to be addressed . The first problem is how to efficiently store and process massive task response pairs . The other one is how to design an efficient parameter estimation approach , which can help deriving the proper parameter settings for the proposed topic detection model over crowdoriented service data .
The aforementioned challenges reflect the high demand of an advanced probabilistic model which is tailored to meet the crowd data form and large data size . In answering this demand , we design and present the Topic Crowd Service Model ( TCS ) , which features the capability of discovering latent topics from massive crowd oriented service data with high accuracy . One essential niche of TCS is that it captures the the structure of task response pair by preserving the mutual correlation . The massive size of incoming data , which is continuously increasing everyday , is the nightmare for most conventional parameter estimation methods such as collapsed Gibbs Sampling(GS)[20 ] and Variational Bayes(VB)[1 ] , due to the high computational cost while traversing the dataset . It is observed that such computational cost attributes to the iterative behaviour of scanning the entire corpus and visit the complete topic space . This procedure leads to a linearly increasing computational time cost of the size of the data , the number of topics and the number of training iterations . In answering such challenge , we propose the Block Parameter Estimation(BPE ) , which is a fast parameter estimation method . The BPE features the Pair Sketch(pSketch ) technique , which is a storage space reduction approach that alleviates the pain of updating new data trunks . Moreover , in order to achieve the convergence of parameter inference process , BPE integrates belief propagation[18 ] into the stochastic gradient descent framework [ 3 ] , in which a series of online gradient updates lead to the stationary point of the likelihood function of TCS . Such design of the BPE brings in significantly speedup for the parameter inference process by simplifying the updates of TCS during the iterations : in each iteration , only a small portion of the crowd oriented service data are selected as well as a part of topic space for message updating and passing . In sum , we make following major contributions :
• We design and present a new probabilistic topic model , the Topic Crowd Service Model ( TCS model ) , which features the capability of discovering latent topics from massive crowd oriented service data with high accuracy .
• We propose a fast parameter estimation algorithm , the Bucket Parameter Estimation ( BPE ) , which utilizes a new sketching technique , called pSketch , and belief propagation to enhance the efficiency of the training process significantly .
• We verify the effectiveness and efficiency of the proposed methods through extensive experiments on real datasets . The experimental evaluation shows that TCS model and BPE algorithm outperform several existing probabilistic topic models and parameter estimation methods .
The rest of the paper is organized as follows . Our probIn Section 3 , lem formulation is introduced in Section 2 . we discuss the assumptions and generative process of the Topic Crowd Service Model ( TCS ) . In addition , to train T CS efficiently , we present a new pairwise data based sketch ( pSkech ) to quickly select the significant words in crowdoriented service data in Section 4 . Based on the significant words , we propose an effective parameter estimation algorithm , called Bucket Parameter Estimation ( BPE ) , to train TCS in a specific bucket and multiple consecutive buckets of crowd oriented service data in Section 5 . We present the experimental results , related work and conclude the paper in Sections 6 , 7 , and 8 , respectively .
2 . PROBLEM FORMULATION
In this section , we formally define the related concepts and the problem of discovering hot topics over crowd oriented service data . Let us begin with defining a few basic concepts as follows .
Definition 1
( Task Response Pair ) . Given a crowdoriented task Ti , a set of corresponding responses {Ri,1 , · · · , Ri,m} , the arbitrary pair ( Ti , Ri,j ) for j ∈ [ 1 , m ] is called a task response pair .
862 Notation
Table 2 : Notation
Description
D W WT WR T R K d s z w θ φ α β zk d,s zk d,s,w nd,s,w
λT λR ρD ρK ld ζ the set of all documents the set of all words the set of all words from tasks the set of all words from responses the set of distinct words from tasks the set of distinct words from responses the number of topics document sentence topic word multinomial distribution over topics multinomial distribution over words
Dirichlet prior vector for θ Dirichlet prior vector for φ the sentence s of document d is assigned to topic k the word w in sentence s of document d is assigned to topic k the number of w in sentence s of document d the significant threshold of words in tasks the significant threshold of words in responses the proportion of documents for message passing the proportion of topics for message passing the related documents with the document d the influence of related documents
Definition 2
( Crowd oriented Service Data ) . Let CS={(T1 , R1,1 ) , · · · , ( Tn , Rn,1 ) , · · · , ( Tn , Rn,m)} be a set of task response pairs , where each task and response is a document . Each document d is represented by a subset of the collection of words W={w1 , · · · , w|W |} . Given arbitrary taskresponse pair , a word pair includes two words , one word is from the document of the task , the other word is from the document of the response .
Definition 3
( Topic ) . A semantically coherent topic φ is a multinomial distribution of words {p(w|φ)}w∈W with the constraint Pw∈W p(w|φ ) = 1 . According to the definitions of related concepts , we can now formally define the major task in the problem of discovering topics over crowd oriented service data as follows . Discovering Topics over Crowd oriented Service Data Problem : Given the input of a crowd oriented service data CS , we are required to infer the latent topics φ over in CS .
Moreover , we list notations used in this paper in Table 2 .
3 . TOPIC CROWD SERVICE MODEL
In this section , we present a novel probabilistic model , Topic Crowd Service Model ( TCS ) , for discovering topics over crowd oriented service data . As shown in Table 1 and aforementioned definitions , each document is either a task or a response from crowd employees . Then , we illustrate the underlying logic of TCS . The generative process of TCS is shown in Algorithm 1 .
Each document has a topic distribution . According to the pairs generated by pSketch , which will be introduced in Section 4 , the topically coherency of each document is related . When composing the documents , the user first decides the topic that is aligned with his or her current task requirement and then selects some words according to the chosen topic . Notably , the topic distribution is determined by the document itself and the documents related by the corresponding task response pairs . Furthermore , since each sentence
Algorithm 1 : Generative process of TCS
1 for each topic k ∈{1 , · · · , K} do 2 draw a word distribution φk ∼ Dirichlet(β ) ;
3 for each document d ∈{1 , · · · , D} do 4 5 6 draw topic distribution θd ∼ Dirichlet(α ) ; if d is a task then sample a response d′ with regard to the number of sketch pairs between d and d′ ;
7 8
9
10 11 12 if d is a response then select the corresponding task d′ ; generate new document topic distribution θ′ by combining θd and θd′ ; for each sentence s ∈ d do choose a topic z ∼ Multinomial(θ′ ) ; generate words w ∼ Multinomial(φz ) ; is usually topically coherent , we impose the constraint that the words in each sentence should share the same topic , in order to capture semantic coherency .
Although existing parameter inference techniques , such as Gibbs sampling and variational Bayes , can be used to train the TCS model according to Algorithm 1 , they have to spend higher computational cost . In order to enhance the efficiency of training process significantly , we will consider the problem of training the TCS model as a labelling problem . In other words , the training objective is equal to assign a set of topic labels to explain the observed data . 4 . PAIRWISE SKETCH
As discussed in Section 3 , the latent topic distribution is influenced by corresponding task response pairs in the proposed TCS model . Thus , it is crucial for the training process to calculate frequencies of word pairs from task response pairs . However , due to high volume of online crowd oriented service data , it is infeasible to count and store all word pairs due to the excessively high cost . Fortunately , word pairs with significant frequencies provide most information for discovering latent topics . So we propose to give priority to capture the contents of these pairs . Since finding significant word pairs is the foundation of our parameter estimation algorithm , we present a novel sketching structure , called Pairwise Sketch ( pSketch ) , to efficiently select the significant word pairs from massive online task response pairs . Before discussing the new data structure and algorithm , we first introduce several basic concepts and notations .
Given the set of all words of the given crowd oriented service data W , it can be partitioned into two disjoint subsets , denoted by WT and WR , which consist of all words from tasks and responses , respectively . Moreover , the sets of distinct words in WT and WR are denoted by T and R , respectively . Then , a significant word pair is defined as follows .
Definition 4
( Significant Word Pair ) . Given a crowd oriented service data CS , two significant thresholds λT and λR where λT , λR ∈ ( 0 , 1 ) , a word pair ( t,r ) is a significant word pair if and only if f(t,r)>⌈λT f ( t)⌉ and f(t,r)>⌈λRf ( r)⌉ , where f(t,r ) means the frequency of the word pair ( t,r ) , f(t ) is the sum of frequencies of all word pairs with t as the word in tasks , and f(r ) is similar .
Please note that duplicates of a task in CS is only counted as one task . In general , |WR| >> |WT | , hence we set two dif
863 ( a ) Primary Hashing ( PH )
( b ) Secondary Hashing ( SH )
Figure 1 : Pairwise Sketch ( pSketch ) ferent significant thresholds for them . In order to discover all significant word pairs for online crowd oriented service data efficiently , a straightforward idea is to utilize existing streaming algorithms of finding frequent items , such as the CM Sketch algorithm[7 ] , the lossy counting algorithm[15 ] , the space saving algorithm[17 ] , and etc . However , the existing researches only handle single item rather than correlated pairs . Hence , we have to design a novel solution to find all significant word pairs . Inspired by the space saving algorithm[17 ] , which is one of the fastest streaming algorithms , we propose a novel sketching structure , called the P airwiseSketch ( pSketch ) and algorithm to find all significant word pairs . The pSketch is defined as follows .
Pairwise Sketch : It consists of two hashing structure components : the primary hashing structure ( denoted PH ) and the secondary hashing structure ( denoted SH ) .
Primary Hashing Structure ( PH ) : It includes |T| primary hashing units since the crowd oriented service data has |T| distinct words from tasks . Each primary hashing unit ( denoted PH(ti ) ) uses ti as the hashing key and maps a spacesaving structure , which is also called the Stream Summary in [ 17 ] , to maintain the information about which words from responses are approximate significant for ti . In other words , rj is approximate significant for ti if f ( ti , rj ) > ⌈(λT − ǫ)f ( t)⌉ . ǫ is the error ratio for λT . Moreover , based on [ 17 ] , the number of elements of each space saving structure is equal to ⌈ 1 ǫ ⌉ . Figure 1(a ) shows a primary hashing structure .
ǫ ⌉ , namely m = ⌈ 1
Secondary Hashing Structure ( SH ) : Similar to the Primary Hashing Structure , it consists of the set of secondary hashing units . Similarly , the number of elements of each space saving structure , n = ⌈ 1 δ ⌉ where δ is the error ratio for λR . However , there are two differences between the two hashing structures . On the one hand , the number of secondary hashing units is scalable rather than |R| . As discussed above , we choose the set of words from tasks as the primary hashing set since |WR| >> |WT | . Thus , our basic idea is to construct secondary hashing units only for the words from responses in current significant word pairs . On the other hand , an additional element , called the significant counter ( denoted Sig(rj) ) , appears in each secondary hashing units SH(rj ) and is used to filter out redundant secondary hashing units , where Sig(rj ) records the number of currently significant word pairs from tasks with rj . Once Sig(rj )=0 , rj can be safely deleted from SH . Finally , in practice , in order to discover potential significant words from responses , we relax the monitoring requirement to the concept of ǫ significant words from responses . Namely , a word rj is ǫ significant for a word ti if f ( ti , rj ) > ǫf ( ti ) . Figure 1(b ) shows a secondary hashing structure .
According to the aforementioned pSketch structure , we design the significant word pair sketching algorithm in Algorithm 2 . For each word pair ( t,r ) , the algorithm first checks whether t constructs its primary hashing unit P H(t ) in lines 1 2 . Then , the algorithm calls the space saving algorithm subroutine to maintain frequencies of the word pairs
Algorithm 2 : Significant Word Pairs Sketching
Input : a crowd oriented service data CS , a error ratio
ǫ for λT , a error ratio δ for λR ,
1 for each word pair ( t,r)∈CS do 2 3
Construct PH(t ) ; if t does not construct its PH(t ) in PH then
4 5 6 7
8 9
10 11 12 13
14 15
Call Space Saving(PH(t),r,ǫ ) ; if r becomes ǫ significant for F(t ) then if SH(r ) exists in SH then
Sig(r)← Sig(r)+1 ; else
Construct SH(r ) and Sig(r)← 1 ; if r is not ǫ significant for F(t ) then
Sig(r)← Sig(r) 1 ; if Sig(r)=0 then Delete SH(r ) ; if SH(t)∈SH then
Call Space Saving(SH(t),t,δ ) ; including t in line 4 . If r becomes ǫ significant for t and has SH(r ) in the current secondary hashing structure , the algorithm pluses one for Sig(r ) in lines 5 7 . Otherwise , SH(r ) is constructed in lines 8 9 . When r is not ǫ significant for t , Sig(r ) is decreased by 1 . In particular , the SH(r ) will be deleted from current secondary hashing structure if Sig(r ) is equal to zero . In other words , the current r is never included by any significant word pairs . Finally , the algorithm also call the space saving algorithm subroutine to maintain frequencies of the word pairs including r if SH(r ) is not deleted from SH . Hence , the pSketch structure not only maintains all significant word pairs but also returns them while traversing the sketch structure .
Computational Complexity Analysis : The time complexity and space complexity of Algorithm 2 are shown as follows . Since crowd oriented service data is online in most cases , the number of word pairs may be currently unknown . Hence , we mainly analyze the time of processing each word pair in Algorithm 2 . The processing time for each word pair in Algorithm 2 is an amortized constant time , which can be directly obtained because Algorithm 2 calls the space saving subroutine in constant time , and the space saving subroutine has the amortized constant processing time[17 ] .
ǫδ |T | ) .
The space complexity of Algorithm 2 is O( 1+δ
In the following , the space usages of primary and secondary hash structures are analyzed , respectively . For primary hash structures , Algorithm 2 assigns a space saving structure for each distinct word from task . Each space saving structure spends O( 1 ǫ ) according to its definition[17 ] . Hence , the space usage of primary hash structures is totally O( |T | ǫ ) . Furthermore , according to the definition of ǫ significant word pairs , the maximum number of words that come from responses and satisfy f ( t , r ) > ǫ · f ( t ) for any word t from tasks is 1 ǫ . Thus , the total space usage of secondary hash structures is |T | ǫδ . To sum up , the total space complexity of Algorithm 2 is O( |T | 5 . PARAMETER ESTIMATION
ǫδ ) = O( 1+δ
ǫ + |T |
ǫδ |T | ) .
In this section , we discuss the details of the Bucket Parameter Estimation ( BPE ) . Section 5.1 first shows the procedure
864 of utilizing BPE to train TCS with crowd oriented service data in a specific bucket . Section 5.2 also extends the BPE approach to the scenario of multiple consecutive buckets .
5.1 Parameter Estimation in Single Bucket
Section 4 introduces a novel sketching structure to select the significant task response pairs in crowd oriented service data . According to these task response pairs , we propose a new latent parameter estimation approach in a bucket in this subsection , a . Since each sentence is the basic unit for topic assignment , we first aim to infer the probability that a sentence s of the document d is assigned to the topic k , namely the following formula ,
P ( zk d,s|zk d,−s , nd,−s , zk
·,−s,w , n·,−s,w , ld )
( 1 ) where ld denotes the related documents which include a word occurring with the other word of the current document d in at least a significant word pair in pSketch , −s means all sentences in the current document d without s , and zd,−s and z·,−s,w are all possible topic assignments of neighbouring variables .
Therefore , we denote the belief message by µk d,s , indicating a sentence s of the document d is generated by the topic k . It is represented by the following formula :
( 1 − ζ)µk d,−s + ζµk ld
+ αk
µk d,s ∝
Pk′ ( 1 − ζ)µk′ ΓPr′ ( n·,−s,w′ µk d,−s + ζµk′ ld ·,−s,w′ + βw′ )
+ αk′
ΓPw′ ( n·,−s,w′ µk Γ(n·,−s,wµk
Y w∈s
·,−s,w′ + βw′ + nd,s,w′ ) ·,−s,w + βw + nd,s,w )
Γ(n·,−s,wµk
·,−s,w + βw ) where ζ denotes a ratio to influence the intensity between the current document d and the related documents ld . In addition , belief message µk d,s,w that a word w in the sentence s can be also updated by µk d,s,w = µk d,s
According to Equation 2 , we need to perform a series of iterations to update beliefs and infer parameters . In order to guarantee the efficiency and effectiveness of training the TCS model , there are two crucial challenges : 1 ) What is the best strategy for the training process ? 2 ) when should the iteration process terminates ?
For the first challenge , our main idea is to choose the d,s(t ) − largest belief residual , which is denoted by rk
µk d,s(t − 1)fififi
µk , as the updating goal in the updating process from the ( t − 1)th iteration to the tth iteration . It is reasonable for the updating method in each iteration because the largest belief residuals speed up the convergence of iterations as much as possible . Based on the aforementioned updating strategy , we have to update all non zero belief residuals , whose number is too huge . Hence , to further enhance the efficiency of the training process , we select only significant task response pairs , topics , and documents in the training process according to the pSketch . Before introducing more details of our selection strategy , we first extend the concept of rk d,s to the residuals of higher levels . We denote the residual of the document d on the topic k as rk d,s . In other words , the residual of the document d on the topic k is equal to the sum of all residuals of sentences of the document d in the topic k . Similarly , we also denote the residual d = Ps rk d,s = fififi of the document d as rd = Ps rk d . Then , we define two selected proportions , denoted by ρD and ρK , of documents and topics for message passing in each iteration .
Based on the above concepts , our selection updating strat egy in each iteration is shown as follows .
• Step 1 : We sort all rd in a descending order and choosing ρD × D documents having the ρD × D largest rd , where D is the number of documents .
• Step 2 : For each selected document d , we sort all rk d in a descending order and choose ρK × K topics having the ρK × K largest rk d in d , where K is the number of topics .
• Step 3 : We only update belief messages in the set of
ρD × D documents and ρK × K topics .
According to the above selection updating strategy , we can obtain the normalized estimated messages as follows .
ˆµk d,s(t ) =
ˆµk d,s,w(t ) = d,s(t − 1 )
µk d,s(t ) Pk ˆµk Pk µk d,s(t ) µk d,s,w(t)Pk ˆµk d,s,w(t − 1 )
Pk µk d,s,w(t )
( 3 )
( 4 ) where ( t − 1 ) and t are the previous iteration and the current iteration , respectively . Based on the aforementioned belief messages , we can infer the following parameters : the distribution of topics , θ , and the distribution of words , φ , respectively . Namely ,
( 2 )
θk d =
µk d,· + αk d,· + αk′
.
Pk′ µk′
µk Pw′ µk
·,·,w + βw ·,·,w′ + βw′
φk w =
( 5 )
( 6 )
.
For the second challenge , the iteration process also plays a important role . We give two termination conditions for the iteration process . The first condition is a predefined number of iterations . The second condition is when the convergence of the iteration process occurs .
To sum up , based on the solutions to the above two challenges , Algorithm 3 presents the Bucket Parameter Estimation ( BPE ) algorithm . According to the pseudocode in Algorithm 3 , BPE algorithm first initializes and normalizes d,s(0 ) and µk µk d,s,w(0 ) in line 2 . The pSketch stores the frequencies of significant task response pairs and assists the initialization of µk d,s,w(0 ) . Then , in each iteration , BPE algorithm sorts the documents according to corresponding rd and selects ρD × D documents having the largest residuals in lines 3 10 . For each selected documents , BPE algorithm also sorts topics and selects ρK × K topics having the largest residuals in lines 4 8 . After the selection , this algorithm updates and normalizes µk d,s,w(t ) in line 5 . In particular , please note that BPE algorithm has to sort and calculates all residuals of all documents and topics in the first iteration because there is no previous information . Finally , BPE algorithm terminates when one of two termination conditions , the maximum iteration number and the convergence of iteration , is satisfied . d,s(t ) and µk
5.2 Parameter Estimation in Multiple
Consecutive Buckets .
Section 5.1 have introduced the Bucket Parameter Estimation algorithm within a bucket , we extend the BPE algorithm to the scenario of multiple consecutive buckets . In
865 Algorithm 3 : Bucket Parameter Estimation ( BPE )
1 for each task response pair in each document d and each topic k do
2
Random initialization and normalization µk and µk d,s,w(0 ) based on pSketch ; d,s(0 ) for each document do
3 for each iteration do 4 5 6 7 8 d,s,w(t ) ; d,s(t ) and µk d,s(t ) , rk compute µk compute rk Sort rk Select the ρK × K documents having the largest residuals . d ( t ) and rd(t ) ; d ( t ) in a descending order ;
9 10
Sort rd(t ) in a descending order ; Select the ρD × D documents having the largest residuals . fact , there are many real applications for the scenario of multiple consecutive buckets . For example , incremental crowdoriented service data , updating crowd oriented service data , crowd oriented service data steams , and so on . For such data , we can partition the complete data into multiple buckets , then extend BPE algorithm to infer latent topics and capture the evaluation of topics .
First of all , we define several new input parameters for the scenario of multiple consecutive buckets . We denote m as the index of multiple buckets and Dm as the number of documents in the mth bucket . Please note that m ∈ [ 1 , ∞ ] , d ∈ [ 1 , Dm ] , and w ∈ [ 1 , ∞ ] . The indexes of multiple buckets and words reach infinity because infinity crowd oriented service data are considered in the scenario of multiple consecutive buckets .
Then , we introduce how to extend BPE algorithm to the scenario of multiple consecutive buckets . Different from the updating strategy in the single bucket , the basic idea is that the updating parameters not only consider the information on the current bucket but also integrate the information on the previous buckets . Specifically , in the mth bucket , the extended BPE algorithm first randomly initializes and normalizes the belief messages , denoted by µk d,s[m ] , then initializes the sufficient statistics , denoted by Ωk w[m − 1 ] = n·,·,w[m − 1]µk ·,·,w[m − 1 ] . Hence , the belief message that a sentence s of the document d on the topic k in Equation 2 should be extended as follows ,
µk d,s[m ] ∝
( 1 − ζ)µk d,−s[m ] + ζµk ld
[ m ] + αk
Pk′ ( 1 − ζ)µk′ ·,−s,w′ [ m ] + Ωk d,−s[m ] + ζµk′ ld
[ m ] + αk′ w′ [ m − 1 ] + βw′ )
ΓPw′ ( n·,−s,w′ [ m]µk
ΓPw′ ( n·,−s,w′ [ m]µk Γ(n·,−s,w[m]µk
Y
·,−s,w′ [ m ] + Ωk ·,−s,w[m ] + +Ωk w′ [ m − 1 ] + βw′ + nd,s,w′ ) w[m − 1 ] + βw + nd,s,w ) w∈s
Γ(n·,−s,w[m]µk
·,−s,w[m ] + Ωk
( 7 ) According to the aforementioned belief message updating strategy , the BPE algorithm ( Algorithm 3 ) can be extended to perform until at least one of the two termination conditions is satisfied . w[m − 1 ] + βw )
6 . EXPERIMENTAL STUDY
In this section , we evaluate the performance of TCS and BPE with a large scale crowd oriented service data . Section 6.1 describes the experimental setup . Section 6.2 presents the experimental results of BPE in terms of the efficiency . Section 6.3 measures the memory cost of BPE . Section 6.4 evaluates the effectiveness of TCS model with several standard metrics . Section 6.5 illustrates some results of topics and analyzes topic evolution in multiple consecutive buckets . 6.1 Experimental Setup
A crowd oriented service data ( aka question answer data ) from Yahoo is used as our experimental data . The data contains 142,612 questions and corresponding answers . Similar to [ 20 ] , we set the hyperparameters as α = 2/K and β = 001 Furthermore , for sampling based parameter inference methods , we report the topic modeling results after 300 iterations , which practically ensures convergence in terms of perplexity that is a standard measure for evaluating the generalization of a probabilistic model [ 21 ] . 6.2 Efficiency
We first demonstrate the TCS performance concerning the efficiency aspect . Specifically , we compare BPE with a set of state of the art practices including variational Bayes [ 1 ] ( VB ) and collapsed Gibbs sampling ( GS ) [ 10 , 20 ] . We train all the models on the same dataset from pSketch in order to achieve a fair evaluation . Please refer to Figure 2 for the performance evaluation results . In Figure 2(a ) , the training time with the increase of the data size of a bucket is illustrated , where we set the topic amount K = 300 . We summarize two findings via this experiment : 1 ) As shown in the figure , the training time of TCS(GS ) slightly decreases with the data size of a bucket even it involves the additional cost of residual sorting , while that of TCS(VB ) and TCS(BPE ) increases . This is because the larger data size of a budget leads to a slightly faster convergence of the sampling based parameter inference methods . 2)TCS(BPE ) shows less sensitivity to the change of the size of a bucket , which is a great character concerning online service with dynamic changes . We then increase the topic amount K while fixing the data size of a bucket at 512MB , and we record the time cost of the three parameter inference methods . The results are shown in Figure 2(b ) , in which the running time of all three algorithms increase with K . However , since GS and VB require visiting all documents and the entire topic space , their time cost increase quickly when the data size grows larger . On the contrary , BPE only entails a subset of documents and a fraction of topic space , which qualifies itself as a fast topic modeling of massive crowd oriented service data .
We then answer the question that TCS(BPE ) outperforms the other topic models in terms of training efficiency . We vary the data size of a bucket and the topic amount , and then we evaluate the time consumption of different models and present the result in Figure 2(c ) and 2(d ) . Here all baseline methods are trained on full data while TCS(BPE ) is trained selectively . In Figure2(c ) we set the topic amount to be 300 and the result demonstrates the superiority of TCS(BPE ) over other models : 1 ) TCS is a relatively light weight topic model and does not involve much complicated calculation ; 2 ) TCS(BPE ) utilizes pSketch to reduce the crowd oriented service data that need to be digested by the downstream topic modeling process ; and 3 ) TCS(BPE ) reduces the amount of documents and the scope of the topic space that need to be
866 4
3
2
1
) s r u o H
( e m T i
0 256
TCS(GS ) TCS(VB ) TCS(BPE )
TCS(GS ) TCS(VB ) TCS(BPE )
4
3
2
1
) s r u o H
( e m T i
24
20
16
12
8
4
) s r u o H
( e m T i
LDA TOT Online LDA TCS(BPE )
512 2048 Data Size of A Bucket ( MB )
1024
4096
0 100
150
200
Number of Topics
250
300
0 256
512 2048 Data Size of A Bucket ( MB )
1024
4096
( a ) Time vs Size ( Different Parameter Inference Approaches )
( b ) Time vs # of Topics ( Different Parameter Inference Approaches )
( c ) Time vs Size ( Different Topic Models )
24
20
16
12
8
4
) s r u o H
( e m T i
0 100
LDA TOT Online LDA TCS(BPE )
4x 104
TCS(GS ) TCS(VB ) TCS(BPE )
)
B M
( y r o m e M
3
2
1
TCS(GS ) TCS(VB ) TCS(BPE )
3000
2000
1000
)
B M
( y r o m e M
150
200
Number of Topics
250
300
0 256
512 2048 Data Size of A Bucket ( MB )
1024
4096
0 100
150
200
Number of Topics
250
300
( d ) Time vs # of Topics ( Different Topic Models ) 3x 104 LDA TOT Online LDA TCS(BPE )
B M
2
)
( y r o m e M
1
0 256
512 2048 Data Size of A Bucket ( MB )
1024
4096
( e ) Memory vs Size ( Different Parameter Inference Approaches )
( f ) Memory vs # of Topics ( Different Parameter Inference Approaches )
3000
2500
2000
1500
1000
500
)
B M
( y r o m e M
0 100
LDA TOT Online LDA TCS(BPE )
150
200
Number of Topics
250
300
2500
2000
1500
1000
500
1 y t i x e p r e P l
0 100
LDA TOT Online LDA TCS(BPE )
150
200
Number of Topics
250
300
( g ) Memory vs Size ( Different Topic Models )
( h ) Memory vs # of Topics ( Different Topic Models )
( i ) Perplexity1 vs . # of Topics
1000
750
500
250
2 y t i x e p r e P l
0 10
LDA TOT Online LDA TCS(BPE )
30
50
Trained Percentage
70
90
2400
2000
1600
1200
800
400
1 y t i x e p r e P l
0 256
LDA TOT Online LDA TCS(BPE )
1200
2 y t i x e p r e P l
800
400
LDA TOT Online LDA TCS(BPE )
512 2048 Data Size of A Bucket ( MB )
1024
4096
0 256
512 2048 Data Size of A Bucket ( MB )
1024
4096
( j ) Perplexity2 vs . Observed Percentage
( k ) Perplexity1 vs . Size ( Different Topic Models )
( l ) Perplexity2 vs . Size ( Different Topic Models )
1200
1000
800
600
1 y t i x e p r e P l
TCS(GS ) TCS(VB ) TCS(BPE )
400
256
512 2048 Data Size of A Bucket ( MB )
1024
4096
2 y t i x e p r e P l
700 600 500 400 300 200 100 0 256
TCS(GS ) TCS(VB ) TCS(BPE )
0.05
0.04
0.03
0.02 y t i l i b a b o r P running swimming gym football basketball injury shoe
512 2048 Data Size of A Bucket ( MB )
1024
4096
0.01 1
2
3
4
Buckets
5
6
7
( m ) Perplexity1 vs . Size ( Different Parameter Inference Approaches )
( n ) Perplexity2 vs . Size ( Different Parameter Inference Approaches )
( o ) Topic Evaluation of TCS
Figure 2 : Performance Evaluation
867 scanned in each iteration . We then fix the data size of a bucket to be 512MB while varying the topic amount K increasingly and evaluate the time cost . The results are shown in Figure 2(d ) , where the TCS(BPE ) exhibits significantly better scalability over other methods with a rather moderate linear increase . 6.3 Memory Cost
Memory cost is another significant concern when evaluating topic modeling techniques . In this subsection , Figure 2(e ) and Figure 2(f ) show the results of comparing the memory cost of different parameter inference methods for training TCS . The BPE approach always outperforms both GS and VB in terms of memory cost .
Moreover , we also evaluate the performance of different topic models by varying the data size of a bucket . Please refer to Figure 2(g ) as the results , where TCS(BPE ) consumes much less memory resource than LDA and TOT . The reason is two fold , firstly , classical topic models need to process all data and inevitably occupy large memory resources ; secondly , small data size of each bucket helps other three topic models exploit the memory more effectively . For example , when the bucket size is set to 512MB , the typical memory cost of TCS(BPE ) is only 617MB , which is much less than those consumed by the representative topic models . And this value even outperforms the result of OnlineLDA , which demonstrates the merit of pSketch in Section 4 . Then we demonstrate the memory cost in terms of a varying amount of topics while the data size of a bucket is set to be 512MB . The results are depicted in Figure 2(h ) , where linear increasing behavior is observed for every topic models . However , Online LDA and TCS(BPE ) shows lowest memory usage when the amount grows larger , which indicates its potential as a scalable practice . 6.4 Effectiveness
In this subsection , we discuss the effectiveness of TCS model . Specifically , the evaluation are conducted based on the concept of perplexity measurement[21 ] . Before we elaborate the details of the experiment , we first generalize its definition as below :
P erplexity1(θ , φ ) = (
D d=1 Nd
D
Y
Nd
Y i=1
−1 p(wi|θ , φ )
PD d=1
( N d ) ,
( 8 )
−1 ( N
PD d=1 d−P ) .
P erplexity2(θ , φ ) = (
Y d=1
Y i=P +1 p(wi|θ , φ , wa:P ) )
( 9 ) The difference between P erplexity1 and P erplexity2 is that the former one is used to describe the held − out perplexity on the learned model φ , and the latter one is used to evaluate the effectiveness of prediction of the T CS model . The design of TCS aims to achieve better generalization performance , which can be associated to a lower value of perplexity . In order to facilitate the empirical study , we integrate about ten thousand questions and corresponding responses into a dataset . We then evaluate the TCS capability of predicting unknown task and response words on such dataset , and we notice that the perplexity has a monotonically decreasing relationship with the likelihood of the dataset . Moreover , we adopt LDA [ 20 ] and TOT [ 25](both classical topic models ) and Online LDA [ 12](dynamic topic model ) as the baseline approaches while following their corresponding parameter estimation methods . We summarize the results in Figure 2(i ) , where the lowest line(TCS ) shows lower perplexity and therefore better capability to predicting unseen data comparing with the baselines . Note that for the online models(Online LDA and TCS(BPE) ) , we assume the crowd oriented service data of each hour as a bucket .
Moreover , we aim to measure how effective the proposed models is in terms of predicting the future task and response words based on a portion of available tasks and responses . Specifically , given the task words t1:P from a user ’s log of tasks and response , we try to find out which model provides a better predictive distribution p(t|t1:P ) of the remaining words . In particular , eighty percent of tasks and responses data are set as the training data and the remaining twenty percent as the test data . The calculation of the perplexity is shown in Equation ( 9 ) and we summarize the comparison results in Figure 2(j ) . As shown in the figure , TCS(BPE ) shows good capability to predict the future released tasks and responses given the historical tasks and responses .
We then present Figures 2(k ) and ( l ) to show the perplexity1 and perplexity2 measurements while increasing the data size of a bucket . In Figure 2(k ) the topic amount is fixed to 300 . We can observe that all topic models is not sensitive for changing the data size of a bucket since they show stable value of the perplexity1 in terms of increasing data size of a bucket . Then , Figure 2(l ) shows the perplexity2 measurement with the increase of the data size of a bucket . Not surprisingly , all the topic models remains stable on the perplexity2 measurement , and TCS(BPE ) shows obvious superiority over other methods in terms of perplexity .
We further demonstrate in Figure 2(m ) the perplexity1 measurement with increasingly varying data size of a bucket , while the topic amount K is set to 300 . TCS(VB ) exhibits lower perplexity when the data size of a bucket increases , because larger data size of bucket ushers in more robust online gradient descents for higher accuracy . On the contrary , TCS(GS ) and TCS(BPE ) often perform worse when the data size of a bucket increases , because smaller data size of a bucket helps correct the global biases . In all cases , TCS(BPE ) achieves the lowest predictive perplexity , indicating the highest topic modeling accuracy . Figure 2(n ) shows the performance of the perplexity2 measurement with the same setting above . We report similar result to that in Figure 2(m ) , where TCS(BPE ) achieves highest topic modeling accuracy .
These experimental results above verify that TCS is a robust and effective topic model for crowd oriented service data in terms of the topic modeling accuracy .
6.5 Analysis of Topic Results and Evolution
Based on the topic modeling results of TCS , it is observed that TCS is designed to discover semantically meaningful topics by different parameter inference methods . The top ten words of four topics extracted by VB , GS and BPE on the same dataset are summarized in Table 3 . All three parameter inference methods exhibit effectiveness in grouping semantically coherent task words together as topics , where their results observe high level overlapping of task words except slightly different word ranking . For instance , task words “ running ” , “ swimming ” “ gym ” , “ football ” and “ basketball ” are all contained in the topic Sport . And the rankings of these task words also show great resemblance with each other . Therefore we conclude that the discovered topics are comparable among all the three parameter inference algorithms , which means that using BPE to train TCS can
868 achieve paramount topic modeling accuracy while significantly better efficiency is observed .
The evolution of each topic is another informal but important measure of the success of topic models . We compare the topics that are discovered from consecutive different buckets and show the results in Figure 2(o) , . Again we take the topic Sport as an example of topic evolution . In the first bucket , the task word “ swimming ” ( solid line with circle marker ) does not exist in the top five words . Then after receiving more data from the crowd oriented service data flow , the rank of “ swimming ” climbs from the sixth to the second in the following several buckets . The task words “ gym ” and “ football ” present similar trajectories where they gradually become more and more important in the topic of Sport . Word emergence and word perishment , in the meantime , is another important phenomenon in topic modeling results . For example , in the fourth bucket , the word “ injury ” appears in the topic for the first time and its rank reaches the 7th position in the fifth bucket . On the other hand , the word “ shoe ” ( dotted lines ) loses its importance to the topic as more and more crowd oriented service data are processed , and in the fourth bucket it eventually disappeared . All these results demonstrate the capability of TCS via BPE to detect the topic evolution .
7 . RELATED WORK
In this section , we review the related work in two categories , crowd oriented service computation and topic modeling problems . 7.1 Crowd oriented Service Computation
Crowd oriented service computation is a long existing concept and has been practiced for centuries . With the emergence of Internet web service , especially the one that facilitates online question and answer websites like Yahoo! Answer and Baidu Recommender , crowd oriented service starts to experience a new age where the source of human is broadened to a vast pool of crowds , instead of designated experts . This type of outsourcing to crowds , ie crowdsourcing , is now receiving countless success in many areas such as fund raising , logistics , monitoring and so on .
In crowd oriented service applications , human cognitive abilities are mainly exploited in two types : voting among many options , and providing contents according to certain requirements . Most of basic queries in database [ 8 ] can be decomposed into simple voting as human tasks : such as filtering [ 5 , 6 , 19 ] into two option voting ( Yes or No ) , entity resolution [ 24 ] , join [ 16 ] , data cleaning[23 ] , ranking [ 9 ] , etc .
7.2 Topic Modeling
Since Blei et al . proposed the concept of topic modeling[2 ] , topic modeling has attracted tremendous attention in both academic and industrial areas since its emergence . Especially along with the development of Web2.0 techniques , textual data plays a more and more important role in reallife application . Among these textual data , social network or social media like Facebook or Twitter exhibits great value due to their popularity and diversity in contents . Topic modeling is thus adopted to track emerging events in social communities [ 14 ] and to capture geographical topics [ 29 ] .
Besides aforementioned wide applications , one of important issues is how to efficiently train the probabilistic models . The collapsed variational Bayesian inference for latent Dirichlet Allocation(LDA)[22 ] is proposed to beat its coun terpart in terms of both computation cost and training accuracy . The work in [ 30 , 31 ] then enables the classic loopy belief propagation for parameter estimation by considering the LDA as a factor graph . Topic distribution for new documents can also be inferred without retraining[28 ] . These parameter inference methods tackle the efficiency issue in training probabilistic topic models in different angles , but none of them are able to be easily adapted to meet the requirements from massive crowd oriented service data .
Moreover , another set of related researches with our work is the Community Question Answering ( CQA ) . In this field , most previous work focused on bridging the lexical gap between the queried question and the historical questions [ 26 ] . Recently , a few work has studied how to utilize latent information to fill up the lexical gap [ 32 , 4 ] and how to discover latent topics[27 ] . However , the biggest difference between researches of CQA and our work lies in the research objective . Our work focus on enhancing the efficiency of training process and save the space cost as much as possible through the proposed sketching techniques . However , the main goals of CQA are to bridge the lexical gap between the queried question and the historical questions and to recommend best answers to new questions .
To sum up , to the best of our knowledge , the TCS model together with the BPE algorithm and the pSketch structure is the first technique that systematically investigates the problem of topic discovery over massive crowd oriented service data and provides solutions with solid performance .
8 . CONCLUSIONS
In this paper , we study the problem of discovering latent topics over massive crowd oriented service data efficiently . In order to guarantee the efficiency and effectiveness of the mining process , we design a novel probabilistic topic model , called Topic Crowd Service Model , which seamlessly incorporates a new data structure , called Pairwise Sketch ( pSketch ) and an efficient parameter estimation algorithm , called Bucket Parameter Estimation ( BPE ) . We conduct extensive experiments in real data to verify the effectiveness and efficiency of TCS and BPE . In particular , we verify that BPE algorithm not only significantly enhances the efficiency of topic modeling but also decrease the memory cost than that of existing approaches .
9 . ACKNOWLEDGMENTS
The authors thank the anonymous reviewers for their insightful and constructive comments . This work is supported in part by the Hong Kong RGC Project N HKUST637/13 , National Grand Fundamental Research 973 Program of China under Grant 2012 CB316200 , National Natural Science Foundation of China ( NSFC ) Grant No . 61232018 , Microsoft Research Asia Gift Grant , Microsoft Research Asia Fellowship 2012 and Google Faculty Award 2013 .
10 . REFERENCES [ 1 ] H . Attias . Inferring parameters and structure of latent variable models by variational bayes . In UAI , 1999 .
[ 2 ] D . M . Blei , A . Y . Ng , and M . I . Jordan . Latent dirichlet allocation . Journal of Machine Learning Research , 3:993–1022 , 2003 .
[ 3 ] L . Bottou . Online learning and stochastic approximations .
Online learning in neural networks , 1998 .
[ 4 ] L . Cai , G . Zhou , K . Liu , and J . Zhao . Learning the latent topics for question retrieval in community qa . In IJCNLP , pages 273–281 , 2011 .
869 Topics
Computer Programming
Restaurant
Sport
Tourism
Weather
Java code C++ menu food flavour drink pizza running swimming gym football basketball visitor hotel beach price shop hot cold stormy earth wind
0.049678 0.040128 0.038941 0.036762 0.032754 0.051437 0.045139 0.039116 0.035406 0.032773 0.048745 0.038868 0.028912 0.027712 0.022902 0.068868 0.053937 0.048002 0.038868 0.034149 0.039623 0.036009 0.030854 0.028791 0.026486
Table 3 : Evaluation of the Topic Results
Bucket Parameter Estimation ( BPE ) Gibbs Sampling ( GS ) language software language code C++ Java python menu food drink pizza wine running swimming football basketball gym visitor hotel price museum beach hot stormy cold wind rain
0.045369 0.042315 0.035129 0.031524 0.030671 0.059744 0.050024 0.042367 0.036694 0.030431 0.031074 0.020345 0.019074 0.016109 0.014321 0.060202 0.052887 0.047609 0.041298 0.031011 0.041102 0.037210 0.031852 0.026197 0.023843
Varitional Bayes language code Java software python menu food drink flavour pizza running swimming basketball football gym visitor hotel price beach museum hot cold rain stormy wind
0.041782 0.039274 0.036855 0.033937 0.031726 0.058472 0.049647 0.046438 0.041082 0.037568 0.058742 0.051286 0.047921 0.041235 0.030039 0.061964 0.050129 0.042129 0.036812 0.029432 0.038729 0.032808 0.029458 0.024912 0.019247
[ 5 ] C . C . Cao , J . She , Y . Tong , and L . Chen . Whom to ask ? jury selection for decision making tasks on micro blog services . PVLDB , 5(11):1495–1506 , 2012 .
[ 6 ] C . C . Cao , Y . Tong , L . Chen , and H . V . Jagadish .
Wisemarket : a new paradigm for managing wisdom of online social users . In KDD , pages 455–463 , 2013 .
[ 7 ] G . Cormode and S . Muthukrishnan . An improved data stream summary : the count min sketch and its applications . J . Algorithms , 55(1):58–75 , 2005 .
[ 8 ] M . J . Franklin , D . Kossmann , T . Kraska , S . Ramesh , and
R . Xin . Crowddb : answering queries with crowdsourcing . In SIGMOD , pages 61–72 , 2011 .
[ 9 ] S . Guo , A . G . Parameswaran , and H . Garcia Molina . So who won ? : dynamic max discovery with the crowd . In SIGMOD , pages 385–396 , 2012 .
[ 10 ] G . Heinrich . Parameter estimation for text analysis . Web : http://www . arbylon . net/publications/text est . pdf , 2005 .
[ 11 ] C J Ho , S . Jabbari , and J . W . Vaughan . Adaptive task assignment for crowdsourced classification . In ICML ( 1 ) , pages 534–542 , 2013 .
[ 12 ] M . Hoffman , F . R . Bach , and D . M . Blei . Online learning for latent dirichlet allocation . In NIPS , 2010 .
[ 13 ] J . Howe . Crowdsourcing : Why the Power of the Crowd Is algorithms for filtering data with humans . In SIGMOD , pages 361–372 , 2012 .
[ 20 ] I . Porteous , D . Newman , A . Ihler , A . Asuncion , P . Smyth , and M . Welling . Fast collapsed gibbs sampling for latent dirichlet allocation . In SIGKDD , 2008 .
[ 21 ] M . Rosen Zvi , T . Griffiths , M . Steyvers , and P . Smyth . The author topic model for authors and documents . In UAI , 2004 .
[ 22 ] Y . W . Teh , D . Newman , and M . Welling . A collapsed variational bayesian inference algorithm for latent dirichlet allocation . In NIPS , 2006 .
[ 23 ] Y . Tong , C . C . Cao , C . J . Zhang , Y . Li , and L . Chen .
Crowdcleaner : Data cleaning for multi version data on the web via crowdsourcing . In ICDE , pages 1182–1185 , 2014 .
[ 24 ] J . Wang , T . Kraska , M . J . Franklin , and J . Feng . Crowder : Crowdsourcing entity resolution . PVLDB , 5(11):1483–1494 , 2012 .
[ 25 ] X . Wang and A . McCallum . Topics over time : a non markov continuous time model of topical trends . In SIGKDD , 2006 .
[ 26 ] X . Xue , J . Jeon , and W . B . Croft . Retrieval models for question and answer archives . In SIGIR , pages 475–482 , 2008 .
Driving the Future of Business . Crown Business , 2009 .
[ 27 ] L . Yang , M . Qiu , S . Gottipati , F . Zhu , J . Jiang , H . Sun ,
[ 14 ] C . X . Lin , B . Zhao , Q . Mei , and J . Han . Pet : a statistical model for popular events tracking in social communities . In KDD , pages 929–938 , 2010 .
[ 15 ] G . S . Manku and R . Motwani . Approximate frequency counts over data streams . In VLDB , pages 346–357 , 2002 .
[ 16 ] A . Marcus , E . Wu , D . R . Karger , S . Madden , and R . C .
Miller . Human powered sorts and joins . PVLDB , 5(1):13–24 , 2011 .
[ 17 ] A . Metwally , D . Agrawal , and A . El Abbadi . An integrated efficient solution for computing frequent and top k elements in data streams . ACM Trans . Database Syst . , 31(3):1095–1133 , 2006 .
[ 18 ] K . P . Murphy , Y . Weiss , and M . I . Jordan . Loopy belief propagation for approximate inference : An empirical study . In UAI , 1999 .
[ 19 ] A . G . Parameswaran , H . Garcia Molina , H . Park ,
N . Polyzotis , A . Ramesh , and J . Widom . Crowdscreen : and Z . Chen . Cqarank : jointly model topics and expertise in community question answering . In CIKM , pages 99–108 , 2013 .
[ 28 ] L . Yao , D . Mimno , and A . McCallum . Efficient methods for topic model inference on streaming document collections . In SIGKDD , 2009 .
[ 29 ] Z . Yin , L . Cao , J . Han , C . Zhai , and T . S . Huang .
Geographical topic discovery and comparison . In WWW , pages 247–256 , 2011 .
[ 30 ] J . Zeng , W . Cheung , and J . Liu . Learning topic models by belief propagation . PAMI , 2011 .
[ 31 ] J . Zeng , Z Q Liu , and X Q Cao . Online belief propagation for topic modeling . arXiv , 2012 .
[ 32 ] T . C . Zhou , C Y Lin , I . King , M . R . Lyu , Y I Song , and Y . Cao . Learning to suggest questions in online forums . In AAAI , 2011 .
870
