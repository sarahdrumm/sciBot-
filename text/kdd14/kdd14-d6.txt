Active Collaborative Permutation Learning
Jialei Wang
Dept . of Computer Science
University of Chicago jialei@uchicago.edu
Nathan Srebro
Toyota Technological Institute at Chicago nati@ttic.edu
James A . Evans Dept . of Sociology
University of Chicago jevans@uchicago.edu
ABSTRACT We consider the problem of Collaborative Permutation Recovery , ie recovering multiple permutations over objects ( eg preference rankings over different options ) from limited pairwise comparisons . We tackle both the problem of how to recover multiple related permutations from limited observations , and the active learning problem of which pairwise comparison queries to ask so as to allow better recovery . There has been much work on recovering single permutations from pairwise comparisons , but we show that considering several related permutations jointly we can leverage their relatedness so as to reduce the number of comparisons needed compared to reconstructing each permutation separately . To do so , we take a collaborative filtering / matrix completion approach and use a trace norm or max norm regularized matrix learning model . Our approach can also be seen as a collaborative learning version of Jamieson and Nowak ’s recent work on constrained permutation recovery , where instead of basing the recovery on known features , we learn the best features de novo . Categories and Subject Descriptors H33 [ Information Storage and Retrieval ] : Information Filtering ; I26 [ Artificial Intelligence ] : Learning General Terms Theory , Algorithms , and Experimentation Keywords Collaborative Ranking ; Active Learning ; Matrix Factorization 1 .
INTRODUCTION
Recovering permutations or rankings from pairwise comparisons is an extensively studied problem with wide applications in information retrieval , knowledge discovery and machine learning . The standard setup is that of recovering a single permutation π over m objects based on information of the sort “ A appears before B in the permutation ” . It is well known that if comparisons are indeed consistent with some underlying permutation ( ie there are no discrepancies or errors ) then Θ(m2 ) random queries or Θ(m log m ) adaptively chosen queries are sufficient for recovering the permutation ( this is essentially a sorting problem ) . Also when dealing with noisy comparisons , or when the comparisons are not transitive and consistent with some underlying permutation , methods are available for reconstructing the best consensus permutation from both random and adaptively chosen queries [ 2 , 21 ] .
But in many scenarios , we would like to recover multiple related permutations . Consider for example many people , each with their own tastes or preferences . We could try to recover a single permutation that best tries to explain the consensus among the people , treating comparisons made by different people as not entirelyconsistent noisy comparisons . This approach , seems absurd in the context of survey research , because it would fail to capture individual preferences and miss out entirely on the diversity of preferences in the population .
Alternatively , we could independently learn a separate permutation for each person . While this corresponds to the most common approach to imputing missing survey data , it breaks down in the context of sparse or much missing data . If we can only obtain a limited number of comparisons from each user , perhaps even less than the number of items m , this might not be enough to recover the permutations when each users’ ranking is considered separately . By contrast , in this paper , we investigate the problem of collaborative permutation learning . That is , of jointly recovering multiple related , but not identical , permutations based on pairwise comparisons from different permutations . We will show through theoretical and empirical demonstrations that the solution of these problems could widen the application of learning with permutations to the design of novel , intelligent surveys that only require respondents to rank a few items in order to approximately recover their entire preference ranking . This would allow social and information science researchers to rapidly identify individually preferred products , services , opinions , policies and solutions , without wasting questions on answers that are likely predictable .
This type of collaborative ranking survey has become common for organizations that seek to identify preferred solutions to problems . Consider the survey platform “ All our ideas ” 1 in which individuals and organizations can field surveys or “ idea marketplaces ” of precisely the type we describe here . Individual respondents are posed with a question and an associated pair of possible responses . Respondents can either add a new response , or compare the presented pair . For example , in 2011 , New York City Mayor Michael Bloomberg ’s office fielded such a survey that posed the question “ Which do you think is better for creating a greener , greater New York City ? ” with possible responses including “ open schoolyards across the city as public playgrounds ” , “ increase targeted tree plantings in neighborhoods with high asthma rates ” , and “ keep
1http://allourideas.org
502 NYC ’s drinking water clean by banning fracking in NYC ’s watershed ” [ 25 ] . Collaborative ranking has been used in other academic projects to “ crowdsource ” common knowledge and impressions about the world . Consider the 2013 article , “ the Collaborative Image of the City ” [ 24 ] , which employed a collaborative ranking survey through which thousands of respondents ranked pairs of urban street images from the United States and Europe to determine urban areas of more and less perceived safety and prosperity . In all of this research , however , comparison pairs are chosen randomly and are densely annotated by many respondents . Our research could dramatically improve the efficiency of these efforts .
More formally , we consider the following setup : we have n people and would like to learn for each person i a permutation πi over m items . The information we obtain is through pairwise comparisons of the form “ user i prefers item a over item b ” , ie that a appears before b in πi ( πi(a ) > πi(b) ) . However , these pairwise comparisons might be noisy , or only partially consistent with some underlying permutation . Furthermore , we assume the permutations πi are all related in some way , and modeling this relationship is part of our contribution here . In any case , based on such , possibly noisy and non transitive , pairwise comparisons , our goal is to recover π1 , . . . , πn . We also consider the “ active ” or “ adaptive ” setup where we can actively choose which queries to make , ie at each step we can choose a person i and a pair of items ( a , b ) , and query user i as to whether the person prefers a over b ( ie ask whether πi(a ) < πi(b ) or πi(b ) < πi(a) ) . The two questions we thus ask , and suggests answers for , are : ( 1 ) how can we recover the permutations for every person based on these pairwise preferences , and , ( 2 ) how should we adaptively choose queries so as to make our predictions more accurate and reduce the overall number of queries required .
In order to tackle the problem of collaborative permutation learning , we formulate the problem as a matrix completion problem with pairwise constraints , and use standard matrix factorization regularizers , such as the trace norm or max norm , to reconstruct the matrix based on limited pairwise constraints . In Section 4 we discuss this matrix factorization approach , its underlying assumption about the relatedness of the permutation , and its relationship to the constrained single permutation learning approach of [ 12 ] . We then leverage the existing understanding of methodology on matrix factorization regularizers to suggest efficient optimization methods for fitting our suggested models ( Section 5 ) and to analyze the number of queries required for recovery—in Section 7 we show that under our model , O(n+m ) random queries are sufficient for approximate recovery , significantly less than the O(nm ) required for approximate recovery if learning each permutation independently . In order to further reduce this query complexity we turn to active learning and suggest an adaptive query heuristic based on biasing the queries towards more ambiguous pairs ( Section 6 ) . Notation Let [ n ] = {1 , 2 , , n} . For a matrix X ∈ R n×m , let .fi Xi,j be the ( i , j) th element ; Xi,· be the i th row of X , fiXfiF = i,j be the Frobenius norm , A◦ B = tr(AT B ) be the matrix inner product of A and B , and denote A ff 0 to mean A is positive semi definite . 2 . RELATED WORK j∈[m ] X2 fi i∈[n ]
Rank aggregation from pairwise comparisons .
There has been much work on constructing a permutation based on pairwise comparisons . If the comparisons are transitive , that is consistent with some global permutation , then outputting this global permutation given enough pairwise comparisons is easy . Once the comparisons are noisy , or are not fully consistent , the task be comes trickier and one must both decide on a criteria for measuring the quality of a permutation ( ie its degree of agreement with the comparisons ) and devise an algorithm for finding the optimal permutation under this criteria . Some criteria and algorithms suggested for the problem include Borda Count [ 7 ] , Rank Centrality [ 17 ] , HodgeRank [ 13 ] , Balanced Rank Estimation [ 31 ] , and others . There are , however , two major differences between rank aggregation and the problem we pose here . For rank aggregation , it is typically assumed that : 1 ) there is only one globally optimal ranking , while here we assume each user holds a personal ranking ; and 2 ) there are dense observations , ie , with all , or at least many , pairwise comparisons being observed , while in our setting the observations are usually sparse , with only a very small fraction of pairwise preferences revealed . In particular , there is no hope of obtaining a meaningful global permutations with less than m− 1 comparisons , as even for perfectly consistent data , this does not enable linking relationships among all m items ( more typically , in rank aggregation one has O(m2 ) comparisons ) .
Active learning for ranking . m 2
' ff
Beyond the problem of rank aggregation given dense static data , there has also been interest in adaptive query strategies for learning the optimal distribution . Again , if all comparisons are guaranteed to be transitive and so consistent with some permutation , the problem is easy and boils down to sorting by comparisons , and can the permutation can be recovered using O(m log m ) comparisons , eg using merge sort . When the comparisons are not necessarily consistent , one might wish to obtain the most agreeing ( optimal ) permutation for all possible comparisons , but without actually making all these comparisons . Ie the assumption is a user holds a system of pairwise preferences that is not necessarily consistent with a permutation , and we would like to uncover the most consistent permutation by making the least amount of pairwise queries . Recently , [ 1 ] showed that this problem too can be solved using only O(mpoly log m ) adaptively chosen queries . Furthermore , if we are willing to tolerate discrepancies in fraction of comparisons , relative to the optimal permutation , we need only O(mpoly log 1/ ) queries . This is in contrast to the O(m/ 2 ) random queries required for solving the same task . This demonstrates the power of active learning in ranking , but is still limited to learning a single independent permutation .
( Active ) Collaborative filtering .
The problem of collaborative ranking , as we consider it here , is related to widely studied problem of collaborative filtering as formalized through matrix completion , where we observe some ratings of items by users and would like to use these to predict the ratings of users on items they have not yet rated . Matrix factorization approaches have long been used collaborative filtering problems [ 11 , 23 ] , including using the trace norm and max norm [ 27 ] as well as other related matrix factorization regularizers . Active queries have also been investigated in this context , with heuristics suggested based on the expected value of information(EVIQ ) [ 5 ] or the prediction margin [ 22 ] , as well as using a Bayesian approach [ 14 ] .
The main difference between standard collaborative filtering and the problem studied here , is that in the standard setting single item ratings are observed , providing absolute information about a single entry in the unknown matrix . In contrast , we consider learning from pairwise comparisons , where we can only obtain relative information comparing two items . Our goal is also different , in that instead of seeking accuracy of specific ratings , we seek to capture a permutation for each user . Recent research [ 3 , 32 , 30 ] has also
503 studied the problem of ranking in a collaborative filtering setup , but the objective of this work has been to optimize global ranking measures , such as NDCG or MAP . Moreover , their inputs are still rating scores , rather than pairwise information . 3 . BACKGROUND : CONSTRAINED PERMU
TATION LEARNING
In order to reduce the query complexity of ranking from pairwise comparisons , and allow learning permutations with less than m comparisons , we must use some external information and make assumptions on the permutation to be learned . [ 12 ] suggest associating with each item a a feature vector va ∈ R d which encodes our prior information about a . Thinking of the feature vectors va d , a permutation is then specified as a direction in as points in R d , where the rank order of items is given by their order when proR jected to this direction . Representing the direction in space as a vector u ∈ R d , the permutation πu associated with u is defined by πu(a ) < πu(b ) iff u , va < u , vb ( we assume that u is in general position relative to the vectors v , ie that for no two items a , b , u , va = u , vb ) . Alternatively , one can think of u as specd and order items according to their distances ifying a point in R from u : πu(a ) < πu(b ) iff fiu − vafi < fiu − vbfi . Ordering by the norm or by the projection are equivalent if u and all vectors v are normalized ( ie on the unit sphere ) , and otherwise the difference between them amounts to adding one additional dimension . Although [ 12 ] focused mostly on ordering by distance , here it will be more convenient for us to order by projection .
In either case , for a given feature map , only a subset of permutations can be represented this way , allowing a significant reduction in the query complexity if we focus only on such permutations— [ 12 ] showed how O(d log m ) adaptive queries are enough for learning the optimal permutation ( among permutations of this form ) .
One can think of the feature map as specifying an embedding of items into a possible “ preference space ” , with different axes specifying different attributes one might prefer or not prefer , and a direction u in this space specifying the preferences over these attributes , which in turn defines the preferences over items . The query complexity is then proportional to the dimensionality , or number of “ attributes ” , d , instead of to the number of items m .
But the approach of [ 12 ] is still limited to a learning a single permutation at a time . Furthermore , the reduced query complexity relies on external information in the form of the feature embedding va . [ 12 ] did consider scenarios with individualized permutations , where each of many users has a different permutation over items ( eg beer preferences in their application ) . But their proposed approach was to first obtain good features for each item using some external information source ( in their case , the text of product reviews and descriptions ) and then learn the permutation πi for each user i separately , using only pairwise comparisons by this user i , based on the fixed feature maps . Here , we would like to avoid using a pre determined feature map based on external information , and instead learn this map de novo by considering all users jointly , and leveraging information gleaned from one user ’s comparisons to improve the ranking of other users . 4 . MATRIX COMPLETION BASED CPL As in the model discussed above , we associate with each item a a vector va ∈ R d , such that the permutation for user i is specified by πi(a ) < πi(b ) iff ui , va < ui , vb . However , instead of basing the model on prespecified feature vectors va , we do not assume any prior knowledge on the items . Rather , following a collaborative approach , we jointly learn both the user vectors ui and and item vectors va . Since d and with each user a vector ui ∈ R the item vectors va are learned , the permutation for any single user is not constrained , unlike [ 12 ] . However , having observations on multiple users constrains the possible setting of the item vectors va and thus constraints the relationship between the multiple permutations . In other words , based on the observed comparisons from multiple users , we are learning the population space of possible permutations , which in turn allows us to learn individual permutations with significantly fewer observations .
πi(a ) < πi(b ) iff Xi,a < Xi,b . Requiring that X decomposes as X = U V T of the appropriate dimensions is equivalent to requiring that it has rank at most d . We can thus consider performing collaborative permutation learning as searching for a low rank matrix X such that sgn(Xi,a < Xi,b ) matches our observed pairwise comparisons , or at least matches as many as possible to our observed pairwise comparisons .
However , as was suggested by [ 9 , 27 ] , we instead consider an infinite dimensional model , where the dimensionality d is unbounded ( one can think of Ua,· and Vb,· as vectors in an infinite dimensional Hilbert space , or simply allow them to be vectors in an arbitrarily high dimensional space ) , where we instead constrain the norms fiUa,·fi2 ,fiVb,·fi2 . Constraining the average squared norm of these vectors corresponds to constraining the trace norm ( aka nuclear norm ) of X , which is defined as2 : n m
( fiXfiΣ = min
X=U V T
1 2 fiUa,·fi2
2 + fiVb,·fi2
2
.
( 1 ) a=1 b=1
Similarly , constraining the norm of all vectors ( ie constraining the maximal norm ) corresponds to constraining the max norm of X , defined as : fiXfimax = min
X=U V T max max a fiUa,·fi2
2 , max b fiVb,·fi2
2
.
( 2 )
)
Both the max norm and the trace norm can be thought of either as convex relaxations to the rank [ 10 ] , or as more refined models , allowing an infinite dimensional embedding , regularized through norm regularization rather than a parametric constraint as in , eg , Support Vector Machines [ 27 ] . Either way , in order for the normregularization to be meaningful , we must require not only that Xi,a > Xi,b whenever we observe πi(a ) > πi(b ) , but that the inequality holds with a margin . And in order to allow for noisy or inconsistent observations , instead imposing a hard margin constraint , we seek to minimize an empirical hinge loss , defined below , which penalizes the extent of margin violations . Let S : ( i1 , a1 , b1 ) , ( i2 , a2 , b2 ) , , ( i|S| , a|S| , b|S| ) be the set of observed pairwise preferences , where ( i , a , b ) represents the comparison of user i prefers item a over b . |S| is the total set of observed pairwise comparisons . The empirical hinge loss of X is then defined as : fi ( i,a,b)∈S max(1 − ( Xi,a − Xi,b ) , 0 )
ˆLhinge(X ) =
|S|
And our training objectives , with the trace norm and max norm respectively are : fiXfiΣ + λ ˆLhinge(X ) min
X and min X fiXfimax + λ ˆLhinge(X )
( 3 ) where λ is a regularization tradeoff parameter .
Both the trace norm and max norm are semi definite representable
[ 9 , 27 ] and thus both problems above can be rewritten and solved as semi definite programs ( SDP ) . This allows us to use standard SDP
2The trace norm of X is also equal to the sum of the singular values of X , but we prefer thinking in terms of the matrix factorization characterization of the trace norm
504 solvers . However , in order to handle large scale problem , specialpurpose first order optimization methods are required . Fortunately , in the past few years , there has been much progress in developing such methods for both trace norm and max norm regularized problems , and in the next Section we describe the methods we use here . 5 . LARGE SCALE OPTIMIZATION
In this Section , we describe the accelerated first order methods we use to solve the optimization problems ( 3 ) and fit our models . For both the trace norm and the max norm we adapt recently proposed accelerated proximal methods . 5.1 Accelerated proximal gradient methods for trace norm regularized CPL
For trace norm regularized collaborative permutation learning , we use an accelerated version of Singular Value Thresholding ( SVT ) : SVT optimization [ 6 ] consists of iterative updates corresponding to the optimization of a partial linearization of the objective function , where loss is linearized but the regularizer is not :
Xk = arg min X
ˆLhinge(Xk−1 ) + ( X − Xk−1 ) ◦ ∇ ˆLhinge(Xk−1 )
+
1 2ηk
'X − Xk−1'2
F +
'X'Σ
1 λ
Such an update can be performed by soft thresholding the singularvalues of Xk−1−ηk∇ ˆLhinge(Xk−1 ) , requiring a singular value decomposition at each iteration [ 6 ] . For a smooth loss function , such updates can be accelerated by combining two sequences of iterates Xk and Zk , as in [ 18 , 20 ] . Although our objective function is not smooth , empirically we found that accelerated gradient methods can usually obtain better convergence than simple gradient descent for our problem . In particular , each iteration consists of the following updates :
Xk = SVT 1
2λ
Zk+1 = Xk + (
( Zk − ηk∇ ˆLhinge(Zk ) ) αk − 1 )(Xk − Xk−1 ) αk+1 where the SVT operator is defined as : SVTλ(X ) = U ΣλV T , where X = U ΣV T is the singular value decomposition of X , and ( Σλ)i,i = max{0 , Σi,i − λ} , and αk is the parameter recursively defined as αk+1 = 5.2 Proximal iterative smoothing algorithm for with α1 = 1 .
1+4α2 k 2
√
1+ max norm regularized CPL
For the max norm , we cannot take this approach , because the minimum of a quadratic function plus a max norm regularizer is not given analytically in terms of the SVD . Instead , we take the proximal iterative smoothing ( PRISMA ) technique proposed by [ 19 ] , where the goal is to solve a convex optimization which decomposes into three parts : a smooth part , a simple Lipschitz part , and a non Lipschitz part . Although the pairwise hinge loss functions in max norm regularized CPL problems are not smooth , we can also apply PRISMA to our problem because our objective function is
. This problem can be rewritten as : min X,A,B
1 λ max diag
A X XT B
+ ˆLhinge(X ) + δ
S m+n + where δ n ) positive semi definite matrices ( zeros inside S outside ) . is the indicator function of set of ( m + n ) × ( m + and infinite m+n + m+n +
S fiXfimax + λ ˆLhinge(X ) min
X
. fi
. fi
A X XT B
To apply PRISMA for this problem , we learn A , B , X simultaneously as a ( m + n ) × ( m + n ) matrix ( we denote it as Z ) : at each step , we first perform a gradient descent step on the function ˆLhinge(X ) , then add the proximal operator solution of the function 1 λ max diag(Z ) , and then perform a proximal operator of the function δ Z . Note that the proximal operator of max diag(Z ) is equivalent to the proximal operator of the fi · fi∞ on the diagonal vector of the matrix Z , which has closed form solution [ 8 ] , and the Z can be solved by setting all negative proximal operator of δ eigenvalues of Z to zero . Thus the core updating steps are : m+n + m+n +
S
S
Yk = EVT((1 − 1 λβk αk − 1 αk+1
Zk+1 = Yk + (
)Zk − ηk∇ ˆLhinge(Zk ) + )(Yk − Yk−1 )
1 λβk
DVTβk ( Zk ) ) where DVT is the diagonal value thresholding operator : DVTβk ( X)i,i = sgn(Xi,i ) min(Xi,i , βk ) and DVTβk ( X)i,j = Xi,j for all i = j ; and EVT is the Eigenvalue thresholding operator obtained by setting all negative eigenvalues to zero .
6 . ACTIVE LEARNING STRATEGIES
In this section we discuss some active learning strategies for collaborative permutation learning . Although our goal is to create a system that actively makes queries to all possible pairs , for presentation clarity we consider the setting of pool based batch mode active learning [ 26 ] . Suppose at learning stage t , we already have our learned model Xt , as well as a candidate pool Pt = {(i , a , b)} . We then need to ask users to reveal their comparison labels for a small batch of instances Qt+1 ⊆ Pt , and add these new training data to our current training set St . Then we re train the model using the combined training set St+1 = St ∪ Qt+1 to obtain improvement . The baseline solution is uniform sampling where we randomly sample instances in Pt uniformly . We can also adopt some active ranking methods for single permutation learning in our setting : as inspired by [ 12 ] , which actively query only the “ ambiguous ” pairs for labeling . “ Ambiguous ” is defined as the pair that can not be imputed from known pairwise comparisons based on the consistency assumption . ( Suppose we know “ a ” is preferred to “ b ” , “ b ” is preferred to “ c ” ; pair “ a ” and “ c ” is not an “ ambiguous ” pair because we can transitively impute that “ a ” is preferred than “ c ” ) . We can use this approach in our setting : we uniformly sample “ ambiguous ” pairs for all users independently .
For our proposed approaches , the margin provides important information about the uncertainty of our learned model on the data . [ 29 ] proposed to actively query the instances with smallest margin for Support Vector Machines ( SVMs ) , and [ 22 ] adopted this strategy and showed it ’s effectiveness for maximum margin matrix factorization [ 27 ] . Likewise , we can use similar ideas to select pairs with the smallest difference in their estimated scores : ft(i , a , b ) = |Xt i,a − Xt i,b| .
Since our goal is to interactively estimate the model from data , when the model is inaccurate , the margin information could be misleading . As a result , we propose a stochastic sampling alternative . Given a temperature parameter Tt , we randomly sample query ini,b| stances with probability proportional to p(i,a,b ) = e . Thus we favor instances with smaller margin . At the beginning , we set the temperature high , which means we select instances tending to uniform randomness , and then we decrease the temperature during the learning process . In this way , we are more confident about our model and bias toward more of the instances with small margin . 1 described the detailed process of our proposed “ CPL Margin Sampling ” algorithm . i,a−Xt
− |Xt
Tt
505 Algorithm 1 CPL Margin Sampling — Algorithm of active collaborative permutation learning from pairwise comparisons
|P|×3 : the set of candidate pairwise preferences .
Input : P0 ∈ N Initialization : The initialized model X 0 at time 0 . for t = 1 , 2 , . . . do t−1 i,a
− |X
Computing the margin score achieved by current model . Sampling k triplets from Pt−1 with probability proportional to form the query set Qt , update the train to e ing set St = St−1 ∪ Qt . Learn the new Xt by solving the problem ( 3 ) .
−X Tt−1 t−1 i,b
| end for
7 . THEORETICAL ANALYSIS
In this section we provide some theoretical analysis of the proposed algorithms . Suppose the true permutations are generated by the underlying matrix X∗ , we can define the expected loss for any fim matrix X : fib∈[m ] fin i,a−X∗ i,b
)ff=sgn(Xi,a−Xi,b )
2 i=1 a=1
L(X ) = and the empirical loss for matrix X :
ˆL(X ) = and the expected hinge loss for matrix X : bff=a
Isgn(X∗ nm(m − 1 )
IXi,a<Xi,b
( i,a,b)∈S fib∈[m ] fim nm(m − 1 ) bff=j a=1
1|S| fin i=1
( i,a,b)∈S
Lhinge(X ) =
2 lhinge(i , a , b ) where lhinge(i , a , b ) max(1 − ( Xi,a − Xi,b ) , 0 ) and the empirical hinge loss for matrix X :
ˆLhinge(X ) =
1|S| max(1 − ( Xi,a − Xi,b ) , 0 )
7.1 Generalization bounds of CPL
The following theorems give generalization guarantees for the proposed collaborative permutation learning models .
THEOREM 1 . Let X max[A ] be the set of matrices that with bounded max norm A . Then for any δ > 0 , with probability at least 1− δ over the choice of a sample S , for every X ∈ X max[A ] , the following holds : ff ff L(X ) ≤ ˆLhinge(X ) + 48
A2(n + m )
|S|
+ 3 ln 2 δ 2|S|
Proof Sketch . We treat the matrix X as a function [ n ] × [ m ] → R , and use existing bounds on the Rademacher complexity [ 4 ] of matrices with bounded trace norm or max norm [ 28 , 10 ] . The main difference here is that the instances , and hence the loss , depend on two , rather than only one evaluation of X . Nevertheless , this only results in an increase by a factor of two in the Rademacher complexity of the loss class , and we can use standard arguments for obtaining uniform concentration and generalization guarantees as a function of the Rademacher complexity .
And we get the following generalization bound for trace norm based methods :
THEOREM 2 . Let X Σ[A ] be the set of matrices with bounded trace norm A . Then there exists a constant K , for any δ > 0 , with probability at least 1 − δ over the choice of a sample S , for every ff X ∈ X Σ[A ] , the following holds : ff
L(X ) ≤ ˆLhinge(X ) + 4K
A2 nm ( n + m ) ln n
|S|
+ ln 1 δ 2|S|
7.2 Sample complexity for approximate recov ery
COROLLARY 3 . Suppose X∗ is rank r with bounded entries , let Xmax(S ) be the max norm regularized empirical loss minimizer : Xmax(S ) = arg minX∈X max[ r ] ˆLhinge(X ) , with the sample size , with probability at least 1 − δ , we have |S| ≥ 4608r(n+m)+18 ln 2
√
δ
2
L(Xmax(S ) ) ≤ ˆLhinge(X∗
) +
Proof Sketch . By error decomposition L(Xmax(S ) ) = L(Xmax(S))− ˆLhinge(Xmax(S))+( ˆLhinge(Xmax(S))− ˆLhinge(X∗ ))+ ˆLhinge(X∗ ) , combining the fact of empirical loss minimizer , as well as basic mean inequalities .
Remark . If we further assume that the true scoring matrix suffers 0 hinge loss , ie , that the following realizable condition holds : ) = 0 , we get L(Xmax(S ) ) ≤ , which means we obtain ˆLhinge(X∗ approximate recovery of all the permutations with error .
Similarly , for the trace norm regularized solution , we obtain the following result :
COROLLARY 4 . Suppose X∗ is rank r with bounded entries , let XΣ(S ) be the trace norm regularized empirical loss minimizer : XΣ(S ) = arg minXΣ≤√ rnm ˆLhinge(X ) . Then there exists a constant K , with the sample size |S| ≥ 32K2 r(n+m ) ln n+ln 1 , with probability at least 1 − δ , we have L(XΣ(S ) ) ≤ ˆLhinge(X∗
) +
2
δ
Remark . By comparing the sample complexity of regularized CPL with trace norm versus max norm , we can see that max norm is slightly superior by avoiding a log n factor , which is consistent with the analysis of classical collaborative filtering problems [ 28 ] .
8 . EMPIRICAL STUDIES
In this section , we conduct a set of experiments to demonstrate the effectiveness of our proposed approaches . 8.1 Experimental setting
Size
#Users #Items 5,000
Table 1 : Statistics of data sets used in our experiments Data Sparsity Sushi Vote200 Vote wbc ML100K 500 ML100K 50 HetRec 600 HetRec 70
0.182 0.0004 0.027 0.019 0.010 0.007
10 67 369 500 50 600 70
225,000 6,459 10,658
16 339 500 50 600 70
1,042,049
1,659,704
1,185
1,234
1
We test the performance of various algorithms for the CPL task on both real world and synthetic data sets including actual pairwise comparison surveys , including the following :
506 • Sushi [ 15 ] : which is a data set contains 5,000 users’ order lists over 10 kinds of sushi 3 .
• Vote 200 : a pairwise comparison survey associated with Washington Post ’s idea marketplace [ 25 ] implemented through the online platform 4 . In this survey , people were asked to propose who had the worst year in Washington in 2010 , and then vote their comparisons between various people , agencies , organizations or classes according to the following form : “ Entity A had a worse year than Entity B ” . Entities included “ Representative Charlie Rangel ” , “ The American Homeowner ” , “ Senator Blanche Lincoln ” , “ DC schoolchildren ” , and “ The Political Center ” . Because the voting was anonymous , we have information on voting sessions , but not individual users . While it is very unlikely that multiple users compared items within a single “ session , ” it is possible that the same person came back to the site and voted in multiple sessions , although we expect this behavior , if it occurred , was rare . As such , we treat each session as a singer user following the traditional collaborative filtering approach . There are 67 entities ( items ) in total , and voting results are very sparse . Thus we select a subset that each session contains at least 200 preferences . • Vote wbc : a pairwise comparison survey regarding the relative appeal of different Wikipedia advertisement banners 5 using the same platform as in the Vote 200 data . Here Wikipedia users propose and then compare pairs of possible banners for Wikipedia fundraising . Banner possibilities include “ Knowledge is power . Keep the access to it free ” ; “ A small donation for a world of information ” ; “ A penny a thought ? How many times has Wikipedia helped you ? ” ; and “ Open . Honest . Free . ” • Movielens data 6 : a widely used collaborative filtering data set . We choose two subsets of ’Movielens 100K’ : ’ML100K50’ is a subset that contains 50 users on 50 items ; ’ML100KML500’ is a subset that contains 500 users on 500 movies . We generated all pairwise preferences in the subsets according to user ratings . • HetRec 2011 Movie data 7 : another popular movie rating data set . We choose two subsets : ’HetRec 600’ is the subset that contains 600 users on 600 movies , ’HetRec 70’ is the subset that contains 70 users on 70 movies . We generated all pairwise preferences in the subsets according to user ratings . Table 1 summarizes the statistics associated with these data sets , and shows that our data contains pairwise comparisons ranging up to several million . We measure the performance of algorithms using mean Kendell Tau distance ( MKTD ) , a generalization of Kendell Tau distance to our multiple permutations setting . KendllTau distance is widely used in single permutation learning evaluation [ 12 ] as it measure the fraction of pairwise preferences from the true permutation π recovered by the learned permutation ˆπ : d(π , ˆπ ) = . Suppose our model learns n ranking lists : π1 , πn , given a ground truth set of test pairwise preferences S , the MKTD is defined as :
( a,b):π(a)<π(b ) I{ˆπ(a)>ˆπ(b)}
( m 2 )
.
MKTD =
1|S|
( i,a,b)∈S
I(πi(b)−πi(a))>0 .
3http://wwwkamishimanet/sushi/ 4http://allourideas.org 5http://blogallourideasorg/post/16175975017/ 6http://movielensumnedu 7http://grouplens.org/datasets/hetrec 2011/
We test the performance of our model on the entire data set , and evaluate performance with a learning curve . 8.2 Compare CPL with rank aggregation
This set of experiments is designed to demonstrate how collaborative information is useful for our task . We compared the proposed CPL with a set of single permutation learning methods , including the following two that represent rank aggregation approaches : Borda Count [ 7 ] and Balanced Rank Estimation [ 31 ] . Because there are no natural active learning strategies for these approaches , we compare all algorithms to a uniform sampling of queries for fair comparison . We tune the λ parameter in our algorithms from {2 −9 , 210} for all data sets . Note that we can use rank aggregation methods to learn multiple rankings : each user has one , and we can follow the traditional rank aggregation setting which learns a global ranking list . We add “ Single ” to denote the latter in the figures 8 .
−10 , 2
Figure 1 show the learning curves associated with our algorithms on various data sets . When comparing with Borda Count and Balanced Rank Estimation , we found that they perform reasonably well , and Balanced Rank Estimation usually performs slightly worse than Borda Count ; When comparing the ranking aggregation method which learns multiple and single rankings , we find that the multiple rankings approach usually performs better , although single permutation methods might perform better in circumstances where we do not have enough observed data ; when comparing the previous method with our collaborative approach , we can see that our algorithms performs significantly better . Finally , our method can improve rank aggregation approaches more on the voting data when we have more observations ( Vote200 case ) , which illustrates the intrinsic difficulty of collaborative ranking on highly sparse and noisy data sets .
8.3 Comparison of active learning strategies Knowing that CPL methods are superior , this set of experiments compares various active learning strategies . We compare the following methods : i ) Uniform Sampling ; ii ) Active Ranking : as proposed in [ 12 ] for single permutation learning , note in our setting there are no given features for items , thus we perform a reduced SVD of our learned score matrix X = UrΣrV T r , and use Vr as features for the items ; iii ) SRRA : the Smooth Relative Regret Approximation method proposed in [ 2 ] , which suggests uniform sampling of the pairs for which rank position differences are within a certain range , as suggested by [ 2 ] . At first we narrow the range by 2 ( which means we query the pairs with rank position differences of at most 2 ) , then we double this range at each query stage ; iv ) Simple Margin : deterministic selection of pairs with the smallest margin ; v ) Margin Sampling : For simplicity , we begin with the following temperature attenuation scheme as Tt = 1 t , where t is the learning stage . Since Active Ranking [ 12 ] needs to solve two linear programming problems in order to decide whether a pair is “ Ambiguous ” , when the query pool is large ( as in data sets with millions of pairs ) , the time cost becomes very high . Thus , we omit comparisons with Active Ranking on some large data sets . Figure 2 graphs the learning curves for various learning strategies . We can draw the following conclusions : i ) Both Simple Margin and Margin Sampling perform significantly better than Uniform Sampling , which demonstrate the advantages that come from exploring a range of active learning strategies . While Active Ranking did not perform much better than Random Sampling , this is likely due
8We also tried to compare against Rank Centrality [ 17 ] and HodgeRank [ 13 ] , but they failed in our setting due to the sparseness of the observations
507 D T K M
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
0.55
0.5
0.45
0.4
0.35
D T K M
0.3
0.25
0.2
0.15
0.35
0.3
0.25
D T K M
0.2
0.15
0.1
0.05
0
D T K M
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Various approaches for collaborative permutation learning
CPL Borda Count Borda Count−Single Balanced Rank Estimation Balanced Rank Estimation−Single
%0.5 %1 %1.5 %2 %2.5 %3 %3.5 %4 %4.5 %5
Fraction of Pairwise Comparisons Discovered
( a ) ML100K 500
Various approaches for collaborative permutation learning
CPL Borda Count Borda Count−Single Balanced Rank Estimation Balanced Rank Estimation−Single
%1 %3 %5 %7 %9 %11 %13 %15 %17 %19 %21 %23 %25 %27 %29
Fraction of Pairwise Comparisons Discovered
0.5
0.45
0.4
D T K M
0.35
0.3
0.25
0.2
0.15
0.5
0.48
0.46
0.44
0.42
0.4
0.38
0.36
0.34
0.32
D T K M
Various approaches for collaborative permutation learning
CPL Borda Count Borda Count−Single Balanced Rank Estimation Balanced Rank Estimation−Single
%1 %3 %5 %7 %9 %11 %13 %15 %17 %19 %21 %23 %25 %27 %29
Fraction of Pairwise Comparisons Discovered
( b ) Vote200
Various approaches for collaborative permutation learning
CPL Borda Count Borda Count−Single Balanced Rank Estimation Balanced Rank Estimation−Single
%1 %3 %5 %7 %9 %11 %13 %15 %17 %19 %21 %23 %25 %27 %29
Fraction of Pairwise Comparisons Discovered
( c ) Sushi
( d ) Vote wbc
Figure 1 : Comparison of various learning methods for CPL
Various active learning strategies under the CPL framework
Uniform Sampling Simple Margin SRRA Margin Sampling
%0.5 %1 %1.5 %2 %2.5 %3 %3.5 %4 %4.5 %5
Fraction of Pairwise Comparisons Discovered
( a ) ML100K 500
Various active learning strategies under the CPL framework
Uniform Sampling Simple Margin SRRA Margin Sampling
%1 %3 %5 %7 %9 %11 %13 %15 %17 %19 %21 %23 %25 %27 %29
Fraction of Pairwise Comparisons Discovered
Various active learning approaches for collaborative ranking−Trace Norm
Random Sample Active Ranking Simple Margin SRRA Margin Sampling
%1 %3 %5 %7 %9 %11 %13 %15 %17 %19 %21 %23 %25 %27 %29
Fraction of Pairwise Comparisons Discovered
( b ) Vote200
Various active learning strategies under the CPL framework
Uniform Sampling Active Ranking Simple Margin SRRA Margin Sampling
%1 %3 %5 %7 %9 %11 %13 %15 %17 %19 %21 %23 %25 %27 %29
Fraction of Pairwise Comparisons Discovered
0.4
0.35
0.3
0.25
D T K M
0.2
0.15
0.1
0.55
0.5
D T K M
0.45
0.4
0.35
( c ) Sushi
( d ) Vote wbc
Figure 2 : Comparison of various active learning strategies for CPL
508 D T K M
D T K M
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
0.55
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
Various active learning strategies + various approaches for CPL
CPL−Uniform Borda Count−Uniform Borda Count−SRRA Balanced Rank Estimation−Uniform Balanced Rank Estimation−SRRA CPL−Margin Sampling
%0.5 %1 %1.5 %2 %2.5 %3 %3.5 %4 %4.5 %5
Fraction of Pairwise Comparisons Discovered
( a ) ML100K 500
Various active learning strategies + various approaches for CPL
CPL−Uniform Borda Count−Uniform Borda Count−SRRA Balanced Rank Estimation−Uniform Balanced Rank Estimation−SRRA CPL−Margin Sampling
%1 %3 %5 %7 %9 %11 %13 %15 %17 %19 %21 %23 %25 %27 %29
Fraction of Pairwise Comparisons Discovered
D T K M
D T K M
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.5
0.48
0.46
0.44
0.42
0.4
0.38
0.36
0.34
0.32
Various active learning strategies + various approaches for CPL
CPL−Uniform Borda Count−Uniform Borda Count−SRRA Balanced Rank Estimation−Uniform Balanced Rank Estimation−SRRA CPL−Margin Sampling
%1 %3 %5 %7 %9 %11 %13 %15 %17 %19 %21 %23 %25 %27 %29
Fraction of Pairwise Comparisons Discovered
( b ) Vote200
Various active learning strategies + various approaches for CPL
CPL−Uniform Borda Count−Uniform Borda Count−SRRA Balanced Rank Estimation−Uniform Balanced Rank Estimation−SRRA CPL−Margin Sampling
%1 %3 %5 %7 %9 %11 %13 %15 %17 %19 %21 %23 %25 %27 %29
Fraction of Pairwise Comparisons Discovered
( c ) Sushi
( d ) Vote wbc
Figure 3 : Comparison of our system with single permutation based active learning + rank aggregation approaches to 1 ) The active ranking approach , which is designed for the single ranking problem and so did not utilize collaborative information ; 2 ) The “ embedding ” and “ consistency ” assumptions are not adequate for these real world data sets , especially when the features are not given ; but most critically 3 ) the data are sparse and we can only test our algorithms on questions that were actually posed to and answered by users . Moreover , the SRRA method does not work in our setting , which may source from the reasons why Active Ranking performed poorly . ii ) When comparing Simple Margin and Margin Sampling , we found that Margin Sampling performs significantly better , especially at the beginning of the learning process . This is likely because at the beginning , the model learned is not accurate as the margin information is somewhat misleading and thus we prefer more randomness . As the model becomes more accurate , we can put more trust in the margin information .
8.4 Comparison of the whole system
In this section we compare our proposed active collaborative permutation learning system(CPL+Margin Sampling ) with some traditional rank aggregation methods , equipped with single permutation based active learning approaches . Figure 3 summarizes our results . We can see a significant advantage of our system over traditional approaches . SRRA based active methods cannot do better than uniform sampling in our collaborative setting , which further validates the emerging requirements of our collaborative permutation learning techniques on multiple permutation learning problems .
8.5 Simulations of sample complexity
The following experiment uses simulation on the sample complexity to evaluate our proposed methods . As shown in our theoretical analysis , under realizable condition , we only need O( r(n+m ) ) pairwise observations to recover the multiple rankings list to er
2 ror . We aim to validate the linear growth rates in our proven sample complexity bound . For simplicity , we set #users = #items = n , generalize two n × 5 matrices U , V , where every elements of the two matrices are iid generated by a uniform distribution over [ 0 , 1 ] , then we multiply these two matrices to form an n×n “ rating ” matrix , which is rank 5 , and generate all pairwise comparisons according to the rating . Then , we test the MKTD on pair with margin at least 0.2(since we require realizable conditions for our analysis ) . We test the samples required to approximately recover %97 of the whole pairwise preferences , test the CPL method using both uniform sampling and margin sampling strategies , and also compare with the single permutation learning methods . Figure 4 shows the sample complexity when n grows from 100 to 300 . In the left figures , we see that the sample complexities of our methods look linear as n grows , and CPL requires significantly less samples than traditional methods . When comparing the sample complexities of uniform sampling and margin sampling , we found that margin sampling can usually reduce the samples needed , and it seems that sample complexity of margin sampling also grows linearly with n . We also compare the sample size needed for uniform sampling vs . margin sampling to achieve various approximate recoveries when fixing n = 200 , as left figure of 4 shows , the curves further validate the point that margin sampling does significantly better when we seek a very accurate solution .
8.6 CPL with Trace Norm vs Max Norm
In this section we compare the CPL with trace norm versus max norm . Figure 5 shows the curves learned by both trace norm and max norm regularized CPL algorithms . The basic observation is that trace norm based methods and max norm based algorithms usually perform similarly , and max norm methods often performing slightly better .
509 x 105
3.5
Simulation of sample complexity for approximate recovery d e e N s n o s i r a p m o C e s w i r i a P f o r e b m u N
3
2.5
2
1.5
1
0.5
0 100
Borda Count−Uni−97 % BRE−Uni−97 % CPL−Uni−97 % CPL−MS−97 % d e r i u q e R s n o s i r a p m o C e s w i r i a P f o r e b m u N
150
200
250
300
Number of Users/Iterms x 105
Simulation of sample complexity for approximate recovery
CPL−Uniform CPL−Margin Sampling
4.5
4
3.5
3
2.5
2
1.5
1
0.5
0
2^{−2}
2^{−3}
2^{−4}
2^{−5}
2^{−6}
2^{−7}
2^{−8}
2^{−9} epsilon−Approximate Recovery
Figure 4 : Simulation of Sample Complexity for Approximate Recovery , left : comparison of sample complexity as number of users/items increase ; right : comparison of sample complexity for various approximate recovery .
D T K M
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
Collaborative Permutation Learning : Trace Norm vs Max Norm
Collaborative Permutation Learning : Trace Norm vs Max Norm
Collaborative Permutation Learning : Trace Norm vs Max Norm
CPL−Trace Norm CPL−Max Norm
%0.5 %1 %1.5 %2 %2.5 %3 %3.5 %4 %4.5 %5
Fraction of Pairwise Comparisons Discovered
0.5
0.45
0.4
0.35
D T K M
0.3
0.25
0.2
0.15
CPL−Trace Norm CPL−Max Norm
%1 %3 %5 %7 %9 %11 %13 %15 %17 %19 %21 %23 %25 %27 %29
Fraction of Pairwise Comparisons Discovered
D T K M
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
CPL−Trace Norm CPL−Max Norm
%1 %3 %5 %7 %9 %11 %13 %15 %17 %19 %21 %23 %25 %27 %29
Fraction of Pairwise Comparisons Discovered
Figure 5 : Evaluation on Trace Norm vs Max Norm for CPL : data sets from left to right : ML100K 500 , Vote200 , Hetrec 70 .
Various Tempreture strategies for Margin Sampling
Various Tempreture strategies for Margin Sampling
0.5
0.4
0.3
D T K M
0.2
0.1
0
0.4
0.35
0.3
0.25
D T K M
0.2
0.15
0.1
Linear Quadratic Sublinear Auto
%1 %3 %5 %7 %9 %11%13%15%17%19%21%23%25%27%29
Fraction of Pairwise Comparisons Discovered
Various Tempreture strategies for Margin Sampling
Constant 1 Constant 0.0001 Constant 0.001 Constant 10 Constant 10000 Auto
%1 %3 %5 %7 %9 %11%13%15%17%19%21%23%25%27%29
Fraction of Pairwise Comparisons Discovered
D T K M
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
0.35
0.3
0.25
D T K M
0.2
0.15
0.1
0.05
0
Linear Quadratic Sublinear Auto
%0.5 %1 %1.5 %2 %2.5 %3 %3.5 %4 %4.5 %5
Fraction of Pairwise Comparisons Discovered
Various Tempreture strategies for Margin Sampling
Constant 1 Constant 0.0001 Constant 0.001 Constant 10 Constant 10000 Auto
%0.5 %1 %1.5 %2 %2.5 %3 %3.5 %4 %4.5 %5
Fraction of Pairwise Comparisons Discovered
D T K M
D T K M
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
0.35
0.3
0.25
0.2
0.15
0.1
0.05
Various Tempreture strategies for Margin Sampling
Linear Quadratic Sublinear Auto
%0.5 %1 %1.5 %2 %2.5 %3 %3.5 %4 %4.5 %5
Fraction of Pairwise Comparisons Discovered
Various Tempreture strategies for Margin Sampling
Constant 1 Constant 0.0001 Constant 0.001 Constant 10 Constant 10000 Auto
%0.5 %1 %1.5 %2 %2.5 %3 %3.5 %4 %4.5 %5
Fraction of Pairwise Comparisons Discovered
Figure 6 : Evaluation of temperature decreasing schemes , top : evaluation of decreasing with different rates ; bottom : evaluation of various constant temperatures . Data sets from left to right : Vote200 , ML100K 50 , Hetrec 600 .
510 8.7 Temperature Decreasing Scheme
This experiment aims to study various temperature decreasing schemes for margin sampling . We consider the following general temperature model : Tt = 1 c·tp , compared to the strategy we used in previous experiments where c = 1 , p = 1 , here we also test several schemes by varying c and p : first we fix c = 1 , and vary p = 0.5 , 1 , 2 , which represents sub linear , linear , and quadratic temperature decreasing schemes , respectively . Moreover , we also adopt a “ performance driven ” strategy by setting the temperature according to the MKTD we achieve : Tt = MKTDt(We denote this method “ auto ” in the figures ) . Figure 6 summarizes the results . We can see that our margin sampling strategy is robust : it performs similar and quite well with different decreasing rates , when comparing different constant temperatures , we found that very low temperature tends to behave like simple margin(bad at the beginning ) , very high temperature tends to behave like uniform(bad at the end ) , adequate constant can performs reasonably well , although not so good as decreasing scheme . In addition , the proposed “ performance driven ” temperature scheme appears promising . Thus , our margin sampling algorithms could be easily used in practical applications .
9 . CONCLUSION
This paper studies the problem of collaborative permutation learning from pairwise comparisons , both passively and actively . We demonstrated that collaborative information is important , and propose to utilize collaborative information by matrix completion based algorithms . We then analyzed the generalization ability and sample complexity needed for approximate recovery of our proposed algorithms , and empirically demonstrated that our methods perform much better than traditional approaches . To reduce the number of comparisons required from users , we proposed various active learning strategies , and showed that active querying is very useful in reducing label costs . These approaches provide immediate application to a range of information retrieval and survey tasks . In particular , we highlight their power for creating efficient , just in time comparison surveys that can predict user preferences from small samples of comparisons .
We also identify several promising directions for further research , including : i ) More scalable algorithms : we aim to apply our proposed methods on very large scale problems , where even the SVD is computationally prohibitive . Some existing large scale tracenorm ( and max norm ) optimization methods might be able to be adopted , eg [ 16 ] ; ii ) More theoretical analysis : currently we only explore generalization ability and approximate recovery analysis , but interesting theoretical questions remain , including : 1 ) the sample complexity required for exact recovery of the permutations ( which might require additional assumptions ) ; 2 ) the gap between active learning label complexity and uniform sample complexity .
References [ 1 ] N . Ailon . An active learning algorithm for ranking from pairwise preferences with an almost optimal query complexity . Journal of Machine Learning Research , 13:137–164 , 2012 .
[ 2 ] N . Ailon , R . Begleiter , and E . Ezra . Active learning using smooth relative regret approximations with applications . COLT , 23:191–1920 , 2012 .
[ 3 ] S . Balakrishnan and S . Chopra . Collaborative ranking . In
WSDM , pages 143–152 , 2012 .
[ 4 ] P . L . Bartlett and S . Mendelson . Rademacher and gaussian complexities : Risk bounds and structural results . Journal of Machine Learning Research , 3:463–482 , 2002 .
[ 5 ] C . Boutilier , R . S . Zemel , and B . M . Marlin . Active collaborative filtering . In UAI , pages 98–106 , 2003 .
[ 6 ] J F Cai , E . J . Candès , and Z . Shen . A singular value thresholding algorithm for matrix completion . SIAM Journal on Optimization , 20(4):1956–1982 , 2010 .
[ 7 ] J . C . de Borda . Mémoire sur les élections au scrutin . Histoire de l’Académie Royale des Sciences , 1784 .
[ 8 ] J . C . Duchi and Y . Singer . Efficient online and batch learning using forward backward splitting . Journal of Machine Learning Research , 10:2899–2934 , 2009 .
[ 9 ] M . Fazel , H . Hindi , and S . P . Boyd . A rank minimization heuristic with application to minimum order system approximation . In In Proceedings of the 2001 American Control Conference , pages 4734–4739 , 2001 .
[ 10 ] R . Foygel and N . Srebro . Concentration based guarantees for low rank matrix reconstruction . In COLT , pages 315–340 , 2011 .
[ 11 ] T . Hofmann . Latent semantic models for collaborative filtering . ACM Transactions on Information Systems ( TOIS ) , 22(1):89–115 , 2004 .
[ 12 ] K . G . Jamieson and R . D . Nowak . Active ranking using pairwise comparisons . In NIPS , pages 2240–2248 , 2011 . [ 13 ] X . Jiang , L H Lim , Y . Yao , and Y . Ye . Statistical ranking and combinatorial hodge theory . Math . Program . , 127(1):203–244 , 2011 .
[ 14 ] R . Jin and L . Si . A bayesian approach toward active learning for collaborative filtering . In UAI , pages 278–285 , 2004 .
[ 15 ] T . Kamishima . Nantonac collaborative filtering : recommendation based on order responses . In KDD , pages 583–588 , 2003 .
[ 16 ] J . D . Lee , B . Recht , R . Salakhutdinov , N . Srebro , and J . A .
Tropp . Practical large scale optimization for max norm regularization . In NIPS , pages 1297–1305 , 2010 .
[ 17 ] S . Negahban , S . Oh , and D . Shah . Iterative ranking from pair wise comparisons . In NIPS , pages 2483–2491 , 2012 . [ 18 ] Y . Nesterov . A method for solving a convex programming problem with convergence rate o( 1 k2 ) . 1983 .
[ 19 ] F . Orabona , A . Argyriou , and N . Srebro . Prisma : Proximal iterative smoothing algorithm . CoRR , abs/1206.2372 , 2012 .
[ 20 ] T . K . Pong , P . Tseng , S . Ji , and J . Ye . Trace norm regularization : Reformulations , algorithms , and multi task learning . SIAM Journal on Optimization , 20(6):3465–3489 , 2010 .
[ 21 ] A . Rajkumar and S . Agarwal . A statistical convergence perspective of algorithms for rank aggregation from pairwise data . In ICML , 2014 .
[ 22 ] I . Rish and G . Tesauro . Active collaborative prediction with maximum margin matrix factorization . In ISAIM , 2008 .
[ 23 ] R . Salakhutdinov and A . Mnih . Probabilistic matrix factorization . In NIPS , 2007 .
[ 24 ] P . Salesses , K . Schechtner , and C . A . Hidalgo . The collaborative image of the city : Mapping the inequality of urban perception . 8(7):e68400 , 2013 .
[ 25 ] M . J . Salganik and K . E . C . Levy . Wiki surveys : Open and quantifiable social data collection . arXiv:1202.0500 , 2012 . [ 26 ] B . Settles . Active Learning . Synthesis Lectures on Artificial
Intelligence and Machine Learning . Morgan & Claypool Publishers , 2012 .
[ 27 ] N . Srebro , J . D . M . Rennie , and T . Jaakkola .
Maximum margin matrix factorization . In NIPS , 2004 .
[ 28 ] N . Srebro and A . Shraibman . Rank , trace norm and max norm . In COLT , pages 545–560 , 2005 .
[ 29 ] S . Tong and D . Koller . Support vector machine active learning with applications to text classification . Journal of Machine Learning Research , 2:45–66 , 2001 .
[ 30 ] M . Volkovs and R . S . Zemel . Collaborative ranking with 17 parameters . In NIPS , pages 2303–2311 , 2012 .
[ 31 ] F . L . Wauthier , M . I . Jordan , and N . Jojic . Efficient ranking from pairwise comparisons . In ICML ( 3 ) , pages 109–117 , 2013 .
[ 32 ] M . Weimer , A . Karatzoglou , Q . V . Le , and A . J . Smola . Cofi rank maximum margin matrix factorization for collaborative ranking . In NIPS , 2007 .
511
