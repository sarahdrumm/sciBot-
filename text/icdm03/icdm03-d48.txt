Reliable Detection of Episodes in Event Sequences
January 22 , 2005
Robert Gwadera , Mikhail J . Atallah∗ , Wojciech Szpankowski†
W . Lafayette , IN 47907
{gwadera,mja,spa}@cspurdueedu
Department of Computer Science
Purdue University
Abstract
Suppose one wants to detect “ bad ” or “ suspicious ” subsequences in event sequences . Whether an observed pattern of activity ( in the form of a particular subsequence ) is significant and should be a cause for alarm , depends on how likely it is to occur fortuitously . A long enough sequence of observed events will almost certainly contain any subsequence , and setting thresholds for alarm is an important issue in a monitoring system that seeks to avoid false alarms . Suppose a long sequence T of observed events contains a suspicious subsequence pattern S within it , where the suspicious subsequence S consists of m events and spans a window of size w within T . We address the fundamental problem : is a certain number of occurrences of a particular subsequence unlikely to be generated fortuitously ( ie , indicative of suspicious activity ) ? If the probability of an occurrence generated fortuitously is high and an automated monitoring system flags it as suspicious anyway , then such a system will suffer from generating too many false alarms . This paper quantifies the probability of such an S occurring in T within a window of size w , the number of distinct windows containing S as a subsequence , the expected number of such occurrences , its variance , and establishes its limiting distribution that allows to set up an alarm threshold so that the probability of false alarms is very small . We report on experiments confirming the theory and showing that we can detect bad subsequences with low false alarm rate .
Key Terms : Episode mining , overrepresented and underrepresented patterns , data mining , probabilistic analysis .
∗Portions of this work were supported by Grants EIA 9903545 , IIS 0325345 , IIS 0219560 , IIS 0312357 , and IIS 0242421 from the National Science Foundation , Contract N00014 02 1 0364 from the Office of Naval Research , by sponsors of the Center for Education and Research in Information Assurance and Security , and by Purdue Discovery Park ’s e enterprise Center .
†The work of this author was supported by the NSF Grant CCR 0208709 and NIH R01 GM068959 01 .
1
1 Introduction
Detecting subsequence patterns in event sequences is important in many applications , including intrusion detection , monitoring for suspicious activities , and molecular biology ( eg , see [ 10 , 13 , 18 , 19] ) . Whether an observed pattern of activity is significant or not ( ie , whether it should be a cause for alarm ) depends on how likely it is to occur fortuitously . A long enough sequence of observed events will almost certainly contain any subsequence , and setting thresholds for alarm is an important issue in a monitoring system that seeks to avoid false alarms .
The basic question is then : when is a certain number of occurrences of a particular subsequence unlikely to be generated fortuitously ( ie , indicative of suspicious activity ) ? A quantitative analysis of this question helps one to set a threshold so that real “ intrusions ” are detected and false alarms are avoided . Setting the threshold too low will lead to too many false alarms , whereas setting the threshold too high can result in failure to detect . By knowing the most likely number of occurrences and the probability of deviating from it , we can set a threshold such that the probability of missing real suspicious activities is small . Such a quantitative analysis can also help to choose the size of the sliding window of observation . Finally even in a court case one cannot consider certain observed “ bad ” activity as a convincing evidence against somebody if that activity is quite likely to occur under given circumstances . Therefore it is very important to quantify such probabilities and present a universal and reliable framework for analyzing a variety of event sources .
Let T be an ordered sequence of events ( time ordered events in a computer system , transactions in a database , purchases made , web sites visited , phone calls made , or combinations of these ) . Systems designed to detect “ bad things ” in T usually do not look at the whole of T , they usually involve a sliding “ window of observation ” ( of size , say , w ) within which the analysis is confined . This is done for two reasons : ( i ) T is usually too long , and without a limited window approach it would involve having to save too much state , and ( ii ) T can be so long ( eg , in a continuously monitoring system ) that any subsequence ( bad or good ) would likely occur within it . As an example of the need to confine the analysis to such a limited sliding window , note that three failed login attempts ( with failure due to wrong password ) are significant if they occur in rapid succession , but quite innocuous if they occur within a one month interval . In this study we do not use the notion of real calendar time such as a “ one month interval ” , instead we use the number of events as a proxy for time . This is why our interval length w is not the difference between two time stamps , but rather the size of a ( contiguous ) substring of T .
In [ 11 ] Mannila et al . introduced the problem of discovering frequent episodes in event sequences , where an episode was defined as a partially ordered collection of events occurring together as a subsequence within a window of a given size in an event stream . In that paper three types of episodes were distinguished . A serial episode was defined as a single pattern of events occurring in the given order . A parallel episode was defined as the set of all permutations of a given pattern . A composite episode was defined as a serial and/or parallel composition of events and episodes . The frequency of an episode α f r(α , T , w ) was defined as the fraction of windows of size w in which the episode occurred in the event sequence T . Given a frequency threshold min f r , an episode was considered to be frequent if its frequency exceeded the threshold .
In this paper we are interested in episodes that are “ significant ” ( eg , anomalous ) in order to develop rules of behavior of the event stream ; note that the frequency of occurrence is not enough to determine significance ( eg , an infrequent episode might have more significance than a frequent one , depending on
2 the probabilistic characteristics of the event stream ) . Thus , our problem can be stated as follows . Given an episode α , what window size w and what frequency threshold min f r should we choose to ensure that the discovered episode is significant . Notice that for an appropriately large window size w any episode will almost surely occur in random data . Furthermore for an appropriately low frequency threshold min f r any episode may be considered to be frequent .
More formally , consider an alphabet A of cardinality |A| , an infinite event sequence T = t1t2 , . . . over A and an episode over A in one of the following forms : either as a serial episode S = s1s2 , . . . sm of length m , or a set of serial episodes S = {S1 , S2 , . . . , S|S|} corresponding to a composite episode , or the set of all distinct permutations of S corresponding to a parallel episodes S of length m ; this last case captures situations where the ordering of the events within the window of observation does not matter , eg , for the two events “ bought a large number of bullets ” and “ bought an assault rifle ” it may not matter which one occurred first . We use a positive integer w ≥ m to represent the length of the window of observation . We assume that an episode is given while the event sequence T is generated by a memoryless ( Bernoulli ) or a Markov source . However in this paper we focus on the case of the serial episode S and we assume T is a memoryless sources .
Our interest is in finding Ω∃(n , w , m ) that represents the number of windows containing at least one occurrence of S when sliding the window along n consecutive events of T . Based on the observed value of Ω∃(n , w , m ) our task is to decide whether a suspicious activity took place or not . The main thrust of our approach is based on the observation that when searching for unusual patterns ( eg , overrepresented or underrepresented patterns ) we must assure that such patterns are not generated fortuitously in order to avoid too many false positives . Therefore , as the first step we study the probabilistic behavior of Ω∃(n , w , m ) . We compute the expected value of Ω∃(n , w , m ) , its variance , and then show that Ω∃(n , w , m ) is normally distributed . This allows us to set either an upper thresholds τu(w , m ) ( for overrepresented patterns ) or a lower threshold τ‘(w , m ) ( for underrepresented patterns ) depending on the definition of ≤ β or unusual activity . More precisely , for a given level β , we have either P ≤ β , respectively . That is , if one observes more than τu(w , m ) · n occurrences P ( upper threshold ) or fewer than τ‘(w , m ) · n occurrences ( lower threshold ) of windows with suspicious subsequences , it is highly unlikely that such a number is generated by the probabilistic model ( ie , its probability is smaller than β ) . We also show how to select the window size w so that suspicious subsequences do not occur almost surely in every window . This is necessary to reliably set up the threshold .
> τu(w , m )
Ω∃(n,w,m ) n
< τ‘(w , m )
( cid:179 )
( cid:180 )
( cid:179 )
Ω∃(n,w,m ) n
( cid:180 )
In terms of pattern matching , the problem of finding episodes in an event sequences corresponds to the subsequence matching problem . In particular we consider the subsequences matching within a w window . More formally , given an event sequence T = t1t2 . . . , a pattern S = s1s2 , . . . sm of length m , both over an alphabet A = {a1 , a2 , . . . , a|A|} , the following types of occurrences of S in T were studied in pattern matching literature :
• S is a substring of T if there exists an integer j such that tj+i = si for 1 ≤ i ≤ m • S is a subsequence of T if there exist integers 1 ≤ i1 < i2 < . . . < im such that ti1 = s1 , ti2 = s2 , . . . , tim = sm
• S is a subsequence within a w window of T if S is a subsequence of T and im − i1 < w
3
• S is a minimal subsequence within s w windowed of T if S is a subsequence within a w window in T and there does not exist any sub window of w where S occurs as a subsequence .
In [ 8 ] a precise statistical analysis of the subsequence matching problem was presented . In [ 4 ] the WindowAccumulated Subsequence Matching Problem ( WASP ) was presented as finding the number of w windows of T which contain pattern S as a subsequence within the w window .
Our work builds on the above mentioned research and provides the first probabilistic analysis that quantifies Ω∃(n , w , m ) . We verify our theoretical results by running an extensive series of experiments . One set of experiments is performed on an on line version of War and Peace , as an example of English text source . In another experiment we use web logs obtained from http://wwwcswashingtonedu/ ai/adaptive data/ that contains user accesses to the music machines web site ( currently at http : //machineshyperrealorg ) from 1/01/99 through 4/30/99 . We first show that our formula for the probability approximates very well the experimental one . Then we insert randomly some sequences , defined as “ suspicious ” , and detect them through our threshold mechanism .
The paper is organized as follows .
In section 2 we present our main results containing theoretical foundation . Section 3 contains experimental results demonstrating applicability of the derived formulas . Derivations of theoretical results are presented in Section 4 using analytic tools of analysis of algorithms such as generating functions and complex asymptotic ( cf . [ 16 , 17] ) .
Interested readers can visit our on line application at http://www cgicspurdueedu/cgi bin/ gwadera/demo.cgi for a demonstration of the reliable threshold computation .
2 Main Results Given an alphabet A = {a1 , a2 , . . . , a|A|} and a serial episode as a pattern S = s1s2 , . . . sm of length m , we are interested in occurrences of S as a subsequence within a window of size w in another sequence known as the event sequence T = t1t2 . . . , where a valid occurrence of S in T corresponds to a set of integers i1 , i2 , . . . , im such that the following conditions hold :
1 . 1 ≤ i1 < i2 < . . . < im ;
2 . ti1 = s1 , ti2 = s2 , . . . , tim = sm ; 3 . im − i1 < w .
The first two conditions above state that S is a subsequence of T , while the last condition guarantees that S is a subsequence of T within a window of length w . In various applications , it is of interest to estimate the number of windows of length w containing at least one occurrence of S when sliding the window along n consecutive events in the event sequence T ; we use Ω∃(n , w , m , S,A ) to denote this number , that can range from 0 to n . Notation : Throughout the paper , because S and A are always implied , we simplify our notation by dropping S and A in the notation Ω∃(n , w , m , S,A ) denoting Ω∃(n , w , m ) instead ( S and A are understood ) . We use the same notational simplification for all other variables that depend on S and A . We also occasionally use index m− k to mean “ dropping the last k symbols of S ” , eg , P ∃(w , m− k ) implies a pattern that is the prefix of S of length m − k .
4
Based on the observed value of Ω∃(n , w , m ) our task is to decide whether a suspicious activity took place or not . In terms of Ω∃(n , w , m ) we can define a threshold in two ways depending on what we consider to be the unusual activity . Thus , for a given confidence level β ( eg , β = 10−5 ) we define :
1 . Upper threshold ( τu(w , m) ) : when S is overrepresented in T we quantify it by setting
( cid:181 )
( cid:181 )
P
P
( cid:182 )
( cid:182 )
Ω∃(n , w , m ) n
> τu(w , m )
≤ β .
Ω∃(n , w , m ) n
< τ‘(w , m )
≤ β .
2 . Lower threshold ( τ‘(w , m) ) : when S is underrepresented in T we quantify it by setting
The case number 2 above corresponds to a situation when for a normal behavior of T we must see at least a certain number of windows containing S and if that number drops suddenly then it can suggest an intentional suppression of S .
Another interesting problem is the selection of monitoring system parameters , in particular the size of the window so one can properly design the system . We select w to avoid S being almost surely in every window for the upper threshold τu(w , m ) , or to avoid S being almost surely in none of the windows for the lower threshold τ‘(w , m ) .
In order to find a reliable threshold that minimizes the number of false positives , we compare the observed value of Ω∃(n , w , m ) to a threshold that was computed for the probabilistic model so that the observed value is very rare . Throughout the paper we assume that the event sequence is generated by a memoryless ( Bernoulli ) model , ie , symbols are generated independently of each others with probability P ( ai ) for any ai ∈ A , i = 1 , 2 , . . . ,|A| .
We need to analyze Ω∃(n , w , m ) in order to find the threshold . We will prove here that appropriately normalized Ω∃(n , w , m ) is normally distributed . We also find the mean and the variance of Ω∃(n , w , m ) . In our windowing method we start monitoring T by positioning the right end of the first window on an event in T corresponding to position 1 and while sliding the window n consecutive events to position n we update Ω∃(n , w , m ) . By assuming that T is infinite , we mean that no matter what window size w we select , there is enough past events available for n consecutive windows .
We start with computing the mean value E[Ω∃(n , w , m) ] . Clearly , it is equal to
E[Ω∃(n , w , m ) ] = nP ∃(w , m ) where P ∃(w , m ) is the probability that a window of size w contains at least one occurrence of the episode S of size m as a subsequence . The probability of existence P ∃(w , m ) satisfies the following recurrence
P ∃(w , m ) = ( 1 − pm)P ∃(w − 1 , m ) + pmP ∃(w − 1 , m − 1 ) w > 0 , m > 0 , P ∃(w , 0 ) = 1 P ∃(0 , m ) = 0 P ∃(0 , 0 ) = 1 w > 0 , m > 0 , .

Indeed , consider a window of size w . Observe that either the last symbol of the pattern , sm , does not occur at the w th position of the window or it does occur . In the former situation S must occur within
5 the window of size w − 1 leading to the term ( 1 − pm)P ∃(w − 1 , m ) of the above recurrence . The latter situation provides the second term of the recurrence .
In Section 4 we solve the above recurrence using generating functions . Then we apply Cauchy ’s residue theorem to obtain an asymptotic expansion of P ∃(w , m ) for fixed m and large w . We summarize our results in the next theorem .
Theorem 1 Consider a memoryless source with pi being the probability of generating the i th symbol of S and qi = 1 − pi . Let also pi m w−m i=1 i=0
Pm k=1 nk=i m k=1 qnk k . m m
( 1 − pi)w i=1 pi j6=i
1 pj − pi
+ O(r−w )
( 1 )
( 2 )
• Then for all m and w ≥ m we have
P ( S ) =
P ∃(w , m ) = P ( S )
• Let now m be fixed and assume i 6= j implies pi 6= pj . Then as w → ∞
P ∃(w , m ) = 1 − P ( S ) where r > ( 1 − pmax)−1 .
Notice that the asymptotic approximation reveals the anticipated fact about the behavior of P ∃(w , m ) , ie , that P ∃(w , m ) = 1 as w → ∞ , and the rate of convergence is exponential . Furthermore , Theorem 1 can be used to identify the maximum value wmax of the window size . It seems reasonable to select wmax so that the pattern S does not occur in such a window almost surely or with high probability . Therefore , for a give δ ∈ ( 0 , 1 ) we find wmax so that P ∃(w , m ) < 1 − δ . Since 0 < δ < 1 we can use our asymptotic formula ( 2 ) . We first approximate P ∃(w , m ) by its leading term pmin = min0≤i≤m{pi} , that is ,
P ∃(w , m ) ∼ 1 − P ( S )
This leads to m pmin j6=jmin pj − pmin
( 1 − pmin)w
( cid:179 ) m
1
( cid:180 ) wmax ≈ log(δ ) − log
P ( S ) pmin j6=min log(1 − pmin )
1 pj−pmin which can be estimated from observed data .
When establishing the above formulas for P ∃(w , m ) we also solved two related combinatorial problems on strings that are of independent interest . Namely , given A , w and S :
1 . Construct the set W∃(w , m ) of all windows as strings of length w over A containing all possible occurrences of S as a subsequence . In Theorem 3 we show the enumeration formula .
2 . Find the cardinality of W∃(w , m ) that we denote C∃(w , m ) . In Theorem 4 we prove that
C∃(w , m ) = k + m − 1
( |A| − 1)k|A|w−m−k .
( cid:182 )
( cid:181 ) w−m k=0 k
6
We refer to Section 4 for the solution for those problems .
Now we derive variance and normal limiting distribution of Ω∃(n , w , m ) . Observe that n
Ω∃(n , w , m ) =
I∃ i where
I∃ i = i=1
1 if S occurs at least once as a subsequence in the window ending at position i in T ; 0 otherwise , where i is the relative position with respect to the first position ( i = 1 ) . Thus , we easily have
E[I∃ Var[I∃ i ] = P ∃(w , m ) , i ] = P ∃(w , m ) − ( P ∃(w , m))2 .
In order to compute variance of Ω∃(n , w , m ) we need P ∃ i ( w)∩I∃ ( I∃ j ( w))(w , m , k ) , defined as the probability that two overlapping windows at respective position i and j for |i − j| < w have Ii = 1 and Ij = 1 . The variance can be expressed as follows
Var[Ω∃(n , w , m ) ] = nVar[I∃
1 ] + 2 n
1≤i<j≤n j ( w ) ]
Cov[I∃ i , I∃ w−1
P ∃ i ( w)∩I∃ ( I∃ j ( w))(w , m , k ) − ( P ∃(w , m))2
= nVar[I∃
w−1
1 ] + 2(n − w + 1 ) w−1 k=1
+2 q=2 k=q
P ∃ i ( w)∩I∃ ( I∃ j ( w))(w , m , k ) − ( P ∃(w , m))2
 .
The two terms involving P ∃ j ( w))(w , m , k ) in the above formula represent correlation between wini ( w)∩I∃ ( I∃ dows ( with 2(w − 1 ) neighborhood ) , where k = w − |i − j| represents the length of the overlap between windows at position i and j . P ∃ i ( w)∩I∃ ( I∃ j ( w))(w , m , k ) can be computed from Theorem 3 .
One concludes , however , that Var[Ω∃(n , w , m ) ] ∼ nσ for some σ > 0 . In view of the above , and using the fact that Ω∃(n , w , m ) is the so called w − 1 dependent sequence ( ie , Ω∃(n , w , m ) depends on the last w − 1 windows ) , we may apply Theorem 27.5 of [ 3 ] to establish the central limit theorem for Ω∃(n , w , m ) . Theorem 2 The random variable Ω∃(n , w , m ) obeys the Central Limit Theorem in the sense that its distribution is asymptotically normal . More precisely , for a , b = O(1 ) we have a ≤ Ω∃(n , w , m ) − E[Ω∃(n , w , m ) ]
Var[Ω∃(n , w , m ) ] b a
≤ b
=
1√ 2π
−t2 2 M T e lim n→∞ P for m and w fixed .
7
The above findings are foundations for establishing reliable thresholds τu(w , m ) or τ‘(w , m ) for n large . Let
( cid:180 ) ( cid:180 )
Ω∃(n,w,m ) Ω∃(n,w,m ) n
> τu(w , m ) < τ‘(w , m )
( cid:179 ) ( cid:179 )
P
P n τu(w , m ) τ‘(w , m ) β(a , b )

= β(b,∞ ) = β(−∞ , a ) = P ∃(w , m ) + b = P ∃(w , m ) + a −t2 = 2 dt = Φ(a , b ) b
1√ 2π a e
√ Var[Ω∃(n,w,m ) ] √ Var[Ω∃(n,w,m ) ] n n where Φ(a , b ) is the cumulative normal distribution function . Observe that when a and b are large ( say order of 10 ) the above probability is small enough to be qualified as a moderate large deviations . This captures the nature of unusual episodes , as needed .
3 Experimental Results
The purpose of our experiments was to test the applicability of the analytical results we derived for sources that are apparently not memoryless , ie , they do not satisfy the assumptions under which the formulas for memoryless source were derived . We of course do not need to test the formulas for memoryless sources , because we already know the equations hold in such cases . Therefore we ran the experiments for an English text source and also for web access data .
An English text is of course not memoryless . As an example consider string “ th ” which occurs more frequently than “ tz ” or “ ts ” . So in this example the letter “ h ” will occur more likely if the previous letter was “ t ” . However , English text can be modeled well by a Markov source .
The web accesses are also not memoryless not only because of hierarchical structure but also because of correlations between links . For example a person looking for a product in an on line store will most likely visit all manufacturers of the search product .
We divided our sources into training sets and testing sets . Training sets are data sets which were used for estimating parameters of the model , ie , for estimating probabilities P ( ai ) for any ai ∈ A , i = 1 , 2 , . . . ,|A| . During the monitoring process the testing data are compared to expectations generated by the model .
Thus , the main focus of our experiments was to test how well the formula for P ∃(w , m ) works for apparently non memoryless sources . To accomplish this we estimated the actual probability of existence based on the actual number of windows Ω∃(n , w , m ) as P ∃ and compared its value to the computed P ∃(w , m ) for different values of w . We used the following error metric d e ( w , m ) = Ω∃(n,w,m ) n
1 r r i=1 d =
|P ∃ e ( wi , m ) − P ∃(wi , m)|
P ∃ e ( wi , m )
100 % where w1 < w2 < . . . wr are the tested window sizes .
We used an algorithm , based on dynamic programming , for finding windowed subsequences . We also implement the dynamic programming solution to P ∃(w , m ) given in chapter 2 . We converted the sources appropriately to a special text file format that was used by the algorithm implemented in C++ and run under Linux .
8
3.1 English text source
The text source we used is an on line version of War and Peace by Leo Tolstoy from wwwfriends partners org/newfriends/culture/literature/war_and_peace/war peace_introhtml The work consists of 15 books . Each book has over 20 chapters each of which consists of over 5000 letters . We preprocessed the chapters in order to remove all symbols but 26 letters of the English alphabet without distinguishing between upper and lower case letters . e ( w , m ) = Ω∃(n,w,m )
In the first experiment we compared the analytically computed P ∃(w , m ) ( cf . Theorem 1 ) with its estimator P ∃ . We used chapter 1 5 as a training set for estimation of p1 , p2 , . . . pm based on the symbol frequencies . We set S = gwadera and for selected values of w ∈ [ 13 , 600 ] we ran the algorithm for finding Ω∃(n , w , m ) in chapter 6 of length n = 6881 as the testing source . Figures 1 and 2 illustrate the results showing two main facts : P ∃(w , m ) approaches 1 as w goes to infinity and P ∃(w , m ) very closely approximates the actual P ∃ e ( w , m ) ( d is of order 12% ) . n
Figure 1 : P ∃ e ( w , 7 ) = Ω∃(6881,w,7 ) n and P ∃(w , 7 ) for S = gwadera
√
In the next experiment we demonstrated the application of τu(w , m ) for S = wojciech and w = 100 . In ≤ β(b ) for particular , we set τu(w , m ) = P ∃(w , m)+b β(b ) = 10−8 for which we obtained b = 5.19 using an algorithm for computing the inverse of Φ(b ) . To verify our threshold experimentally we artificially kept injecting S = wojciech as a subsequence into different places of the testing source . After each insertion we ran the algorithm for finding Ω∃(n , w , m ) and checked whether we exceeded τu(w , m ) . To make it more interesting we considered two values of gaps between
Var[Ω∃(n,w,m ) ]
> τu(w , m ) subject to P
Ω∃(n,w,m ) n
( cid:179 ) n
( cid:180 )
9
010020030040050060000102030405060708091window sizeprobability of existencePe$(w , 7 ) , P$(w , 7)Pe$(w , 7 ) ( estimated)P$(w , 7 ) ( computed ) Figure 2 : Ω∃(6881 , w , 7 ) and E[Ω∃(6881 , w , 7 ) ] for S = gwadera inserted symbols of S : gap = 0 and gap = 11 . In other words we injected S as s1ggaps2ggap . . . ggapsm , where g ∈ A+ . The results are shown in Figure 3 . The horizontal dash dot line shows P ∃(100 , 8 ) = 3·10−3 for no insertions . The solid line shows τu(100 , 8 ) = 1.45 · 10−2 . We can see that if gap = 0 , then we need only two episodes to exceed τu(100 , 8 ) versus three if gap = 11 . This makes sense if we notice that if the episode is stretched to the window boundaries ( gap = 11 ) then it is more noise like compared to the case when gap = 0 , which suggests an intentional action ( attack ) and should be detected early .
3.2 Web access data
We used logs of user accesses to the music machines web site ( currently at http://machineshyperreal org ) , which record accesses from 1/01/99 through 4/30/99 . The logs have been anonymized with respect to originating machines . That is , in each hit , the IP address of the machine generating the server request has been converted to a random looking number . All hits from one machine on a particular day are labeled with the same number . In the experiments we focused on http://machineshyperrealorg/ manufacturers/ web page containing links to manufacturers of music instruments . Each link corresponds to an alphabet symbol and the alphabet size was |A| = 81 . The training and testing sequences were created by considering only unique accesses made by the same originating machine . If a given host made many accesses to the same manufacturer per session then we treated it as one access and consider the first access only .
10
010020030040050060001000200030004000500060007000window sizenumber of windowsW$(6881 , w , 7 ) , E[W$(6881 , w , 7)]W$(6881 , w , 7 ) ( actual)E[W$(6881 , w , 7 ) ] ( expected ) Figure 3 : Detection of artificially inserted pattern wojciech
In the first experiment we compared the computed P ∃(w , m ) with its estimator P ∃ e ( w , m ) = Ω∃(n,w,m ) . We created three sources T1 , T2 , T3 each of length n = 22000 . The training set established T1 , T2 and the testing source was T3 . We set S = {Akai , ARP , Korg , M oog , Y amaha , Casio , Sequential} and for selected values of w ∈ [ 25 , 500 ] we ran the algorithm for finding Ω∃(n , w , m ) on T3 . Figures 4 and 5 illustrate the results . P ∃(w , m ) still provides a good approximation of P ∃ e ( w , m ) ( d = 14% ) . The reason the value of d is bigger than for the text source is the fact that the web accesses are a more memory dependent source than English text . Therefore the Markov model seems to be more suitable for the web access source . n
4 Derivations of Analytical Results
In this section we provide derivations and proofs of the findings we claimed in Section 2 . We also present some new results .
4.1 Set of Windows Containing S as a subsequence Let W∃(w , m ) be the set of all distinct windows of length w containing S as a subsequence . P ∃(w , m ) is therefore equal to the sum of the probabilities of all the elements of W∃(w , m ) , as follows :
P ∃(w , m ) =
P ( x ) x∈W∃(w,m )
11
00511522533544550001002003004005006(number of inserted episodes ) x 1/8000Pe= W$(8000 , 100 , 8)/8000W$(8000 , 100 , 8)/8000 ( gap=0 ) , W$(8000 , 100 , 8)/8000 ( gap=11)t(100 , 8 ) ( threshold)P$(100 , 8 ) ( no insertions)W$(8000 , 100 , 8)/8000 ( gap=0)W$(8000 , 100 , 8)/8000 ( gap = 11 ) Figure 4 : P ∃ e ( w , 7 ) = Ω∃(22000,w,7 )
22000 and computed P ∃(w , 7 ) for the web access data
For 1 ≤ i ≤ |W∃(w , m)| , let W∃(w , m)[i ] denote the i th lexicographically smallest element of W∃(w , m ) . Then above equation can be equivalently written as :
P ∃(w , m ) =
P ( W∃(w , m)[i] ) .
|W∃(w,m)| i=1
We will now show that a recursive formula for enumerating the elements of W∃(w , m ) has the form below . Recall that the notation W∃(a , b ) when b < m , means the set of windows of size a that contain the b prefix of S ( = the string consisting the the first b symbols of S ) .
W∃(w , m ) = ( A − {sm} ) × W∃(w − 1 , m ) ∪ {sm} × W∃(w − 1 , m − 1 ) w > 0 ∩ m > 0 , W∃(w , 0 ) = Aw W∃(0 , m ) = 0 W∃(0 , 0 ) = 1 . w > 0 , m > 0 ,

That the elements generated at each level of the recursion are distinct can be seen by noting that we divide W∃(w , m ) into two subsets : Strings that have sm as their last symbol , and strings that have other symbols than sm as their last symbol . We now turn our attention to showing that we do generate all strings of W∃(w , m ) . Consider all positions of a window where S may occur as a subsequence . We claim that the recursion considers all positions where the m respective symbols of S can occur , and that it considers these m tuples of positions in a particular order : Decreasing lexicographic order of those tuples ,
( cid:161)w
( cid:162 ) m
12
05010015020025030035040045050000102030405060708091window sizeprobability of existenceP$e(w , 7 ) , P$(w , 7)P$e(w , 7 ) ( estimated)P$(w , 7 ) ( computed ) Figure 5 : Ω∃(22000 , w , 7 ) and E[Ω∃(22000 , w , 7 ) ] number of occurrences for the web access data
0 0 that is , tuple ( i1 , i2 , . . . , im ) is considered before tuple ( i 2 , . . . , i 1 , i larger than the latter .
0 m ) if the former is lexicographically
Simply observe that W∃(w , m ) can be split into two disjoint subsets : • Windows having sm at their last position . Because the last window symbol is fixed as sm for all of them , their enumeration effectively becomes that of the windows o size w − 1 that contain the ( m−1) prefix of S ( = the string consisting the the first m−1 symbols of S ) . This latter enumeration is what we mean by the notation W∃(w − 1 , m − 1 ) .
• Windows not having sm at their last position . Because the last symbol cannot be considered part of an occurrence of S , their enumeration effectively becomes that of the windows of size w − 1 that contain S . This latter enumeration is what we mean by the notation W∃(w − 1 , m ) .
From the above , it is straightforward to obtain the following ( we omit the details of the derivation ) .
Theorem 3 The set of all distinct windows of length w , that contain a string S of length m as a subsequence , can be enumerated as follows .
W∃(w , m ) =
Pm+1 k=1 nk=w−m
( A − s1)n1 × {s1} × ( A − s2)n2 × {s2} × . . . × ( A − sm)nm × {sm} × Anm+1
13
050100150200250300350400450500005115225x 104window sizenumber of windowsW$(22000 , w , 7 ) , E[W$(22000 , w , 7)]W$(22000 , w , 7 ) ( actual)E[W$(22000 , w , 7 ) ] ( expected ) i W ( 3 , 2)[i ] n1 0 2 3 0 0 4 1 1 baa bab bba aba n2 0 0 1 0 n3 1 1 0 0
Table 1 : Enumeration of W ( 3 , 2 ) for A = {a , b} and S = ba using Theorem 3
The expression for W∃(w , m ) can be represented as a recursion graph G = ( V , E ) shown in Figure 6 . The graph has one start vertex ( 0 ) and one end vertex ( m ) . The vertex set V of the graph , excluding vertex ( 0 ) , consists of numbers 1 , 2 . . . m corresponding to indexes of symbols in S . The edge set E consists of edges from vertex ( i ) to ( i+1 ) and self loops from vertex ( i ) to itself for 0 ≤ i ≤ m . The label for vertex from ( i ) to ( i+1 ) is equal to S[i + 1 ] . The label for self loops of vertex ( i ) is equal to A − S[i + 1 ] if 0 ≤ i < m and A if i = m . The powers ni for i = 1 , 2 , . . . m + 1 symbolize the number of times the i th self loop is used on the path from vertex ( 0 ) to ( m ) . Thus , W∃(w , m ) is equal to all paths from ( 0 ) to ( m ) of length w .
( A − s1)n1
( A − s2)n2
( A − sm)nm
Anm+1
0 s1
1 s2
2 sm m
Figure 6 : Graphical interpretation of the solution to W∃(w , m )
( cid:161)w−m+m+1−1
( cid:162 ) m+1 Based on Theorem 3 we can divide the elements of W∃(w , m ) into equivalence classes V∃ with respect i=1 ni = w − m . The number of such ordered . It is equivalent to the number of positions of S as a subsequence in to the ordered sequences of ( n1 , n2 , . . . , nm+1 ) for which partitions is the window of length w . Thus |V∃| = Example . Let A = {a , b} S = ba and w = 3 . We generate W∃(3 , 2 ) in Table 1 and compute P ∃(w , m ) . From ( 3 ) we obtain P ∃(3 , 2 ) = P ( S)(pa + pb + pb + pa ) = 2P ( S ) .
( cid:161)w w−m
( cid:161)w
( cid:162 ) m
=
( cid:162 )
. m
4.2 Evaluation of C∃(w , m ) Recall that C∃(w , m ) denotes the cardinality of W∃(w , m ) .
The recurrence for C∃(w , m ) follows directly form the one for W∃(w , m ) . Namely ,

C∃(w , m ) = ( |A| − 1)C∃(w − 1 , m ) + C∃(w − 1 , m − 1 ) w > 0 ∩ m > 0 , C∃(w , 0 ) = |A|w C∃(0 , m ) = 0 C∃(0 , 0 ) = 1 . w > 0 , m > 0 ,
We use the method of generating functions to find the solution for C∃(w , m ) . For an in depth discussion of generating functions see , for example , [ 17 ] . We leave m as a free variable and define the following family
14 of generating functions w=0
Wm(x ) =
C∃(w , m)xw where x is a complex number . From the above recurrence we obtain
Wm(x ) = ( |A| − 1 ) W0(x ) =
We now work with Wm(x ) for m > 0 . Wm(x ) = ( |A| − 1 ) = ( |A| − 1)x w=1 C∃(w − 1 , m)xw + w=0 C∃(w , 0)xw
C∃(w − 1 , m)xw +
= ( |A| − 1)x C∃(w , m)xw + x = ( |A| − 1)xWm(x ) + xWm−1(x ) . w=1 w=0 w=1 w=1 C∃(w − 1 , m − 1)xw m > 0 , m = 0 .
C∃(w − 1 , m − 1)xw−1
C∃(w − 1 , m − 1)xw w=1 w=1
C∃(w , m − 1)xw w=0
C∃(w − 1 , m)xw−1 + x
We represent Wm(x ) in the form of a first order recurrence with respect to m .
Wm(x)(1 − ( |A| − 1)x ) = xWm−1(x ) x
Wm(x ) =
( 1 − ( |A| − 1)x ) Wm−1(x )
Using the fact that we obtain
= xm
1
( 1 − ( |A| − 1)x)m W0(x ) .
|A|wxw =
1
( 1 − |A|x ) w=0
W0(x ) =
( 1 − ( |A| − 1)x)m Denoting by [ xw]f(x ) the coefficient at xw of f(x ) , we find
Wm(x ) = xm
1
1
( 1 − |A|x ) .
C∃(w , m ) = [ xw]Wm(x ) .
Since and
[ xw ]
1
( 1 − ( |A| − 1)x)m = we finally obtain
[ xw]Wm(x ) = w−m k=0
( cid:181 ) w + m − 1 w
( |A| − 1)w ,
( cid:182 )
( cid:182 )
( cid:181 ) ( cid:181 ) w ( cid:182 ) k=0 k + m − 1
( |A| − 1)k|A|w−m−k . k
15
[ xw ]
1
( 1 − ( |A| − 1)x)m
1
( 1 − |A|x )
= k + m − 1 k
( |A| − 1)k|A|w−k
Theorem 4 The number of all windows of length w over an alphabet A which contains at least one occurrence of a pattern of length m does not depend on the symbols of the pattern and is equal to :
C∃(w , m ) =
( |A| − 1)k|A|w−m−k .
( cid:182 )
( cid:181 ) w−m k + m − 1 k=0 k
4.3 Evaluation of P ∃(w , m ) Recall that P ∃(w , m ) is the probability that a window of size w contains at least one occurrence of the episode S of size m as a subsequence . The recurrence for P ∃(w , m ) follows directly form the one for W∃(w , m ) . In particular ,

P ∃(w , m ) = ( 1 − pm)P ∃(w − 1 , m ) + pmP ∃(w − 1 , m − 1 ) w > 0 ∩ m > 0 , P ∃(w , 0 ) = 1 P ∃(0 , m ) = 0 P ∃(0 , 0 ) = 1 . w > 0 , m > 0 ,
As before we use the method of generating functions to find the solution for P ∃(w , m ) . Let w=0
Wm(x ) =
P ∃(w , m)xw .
From the above recurrence we find
Wm(x ) = qm W0(x ) = w=1 P ∃(w − 1 , m)xw + pm w=0 P ∃(w , 0)xw w=1 P ∃(w − 1 , m − 1)xw m > 0 , m = 0 .
P ∃(w − 1 , m − 1)xw−1
P ∃(w − 1 , m − 1)xw where qm = 1 − pm . We now work with Wm(x ) for m > 0 P ∃(w − 1 , m)xw + pm P ∃(w − 1 , m)xw−1 + pmx
Wm(x ) = qm
= qmx w=1 w=1 w=1 w=1
= qmx
P ∃(w , m)xw + pmx
P ∃(w , m − 1)xw w=0 w=0
= qmxWm(x ) + pmxWm−1(x ) .
We represent Wm(x ) in the form of the first order recurrence with respect to m
Wm(x)(1 − qmx ) = pmxWm−1(x )
Wm(x ) =
= pmx m ( 1 − qmx ) Wm−1(x ) m
1 pixm i=1 i=1
( 1 − qix ) W0(x )
Using the fact that w=0 xw =
1
( 1 − x ) ,
16 we obtain m i=1 pixm
Wm(x ) =
= P ( S)xm m m i=1 i=1
1
( 1 − qix )
1
( 1 − x )
1
( 1 − qix )
1
( 1 − x ) .
But P ∃(w , m ) = [ xw]Wm(x ) , and since and m
[ xw ]
1
( 1 − qix )
= m i=1 i=1 w=0 i xw = qw
= w=0 i=1 m k=1 nk=w
Pm Pm qw i xw , qn1 1 qn2
2 . . . qnm m m qnk k m k=1 qnk k , k=1 nk=i k=1 nk=w k=1 i=0 w
Pm m
Pm m w=0 i=1 k=1 nk=i k=1 w−m we use the partial sum property to derive the following m
[ xw ] qw i xw
1
( 1 − x )
= we finally obtain i=1 w=0
[ xw]Wm(x ) = P ( S)[xw−m ] i xw qw
1
( 1 − x )
= P ( S ) qnk k .
This proves formula ( 1 ) in Theorem 1 . i=0
431 Asymptotic approximation of P ∃(w , m ) Now we estimate P ∃(w , m ) asymptotically as w → ∞ and m fixed , that is , we prove ( 2 ) of Theorem 1 . In our previous derivations we obtained
Wm(z ) = P ( S)zm
1
( 1 − qiz )
1
( 1 − z ) . m i=1
( cid:73 )
Observe that the exact value of P ∃(w , m ) is equal to the coefficient of Wm(x ) at xw which – we recall – we denote as [ xw]Wm(x ) . By the Cauchy coefficient theorem ( cf . [ 17 ] ) we know that
P ∃(w , m ) = [ zw]Wm(z ) =
1 2πi
Wm(z)z−w−1dz where z is a complex variable and the integration is over a small circle around z = 0 . To evaluate this integral we use another Cauchy result known as the Cauchy residue theorem [ 17 ] . For this we enlarge the
17 circle around z = 0 so that it contains all singularities Wm(z ) . In our case , the radius r of such a circle must satisfy r > ( 1 − pmax)−1 . Then
P ∃(w , m ) = −
Res[Wm(z)z−w−1 , z = p ] + O(r−w ) where Res[f(z ) , z = a ] is the residue of f(z ) at z = a . We recall that if f(z ) = φ(z ) are analytic functions in z = a subject to ϕ(z ) = 0 , ϕ
ϕ(z ) , where φ(z ) and ϕ(z ) 0(z ) 6= 0 and φ(z ) 6= 0 , then a is a pole of f(z ) and p
( cid:183 )
( cid:184 ) φ(z ) ϕ(z ) , z = a
Res[Wm(z)z−w−1 , z = 1 ] = −P ( S)1m−w−1
= −1 .
Therefore ,
Res
Similarly for z = 1 qi we have
( cid:183 )
Res
Wm(z)z−w−1 , z =
1
ϕ
( 1 − qi )
= φ(a ) 0(a ) . m ( cid:182)m−w−1 m m
( cid:181 )
1 qi j6=i i=1
1 pi j6=i pj − pi
.
P ( S )
1 qi ( 1 − pi)w
( cid:184 )
1 qi
= ( −1 )
= P ( S )
1(cid:179 )
1 − qj qi
( cid:180 )
1 1 − 1 qi
Putting everything together we obtain
P ∃(w , m ) = −Res[Wm(z)z−w−1 , z = 1 ] − m
Res
( cid:183 )
Wm(z)z−w−1 , z =
( cid:184 )
1 qi
= 1 − P ( S )
+ O(r−w ) . m m j6=i i=0 1 pj − pi
( 1 − pi)w pi
Finally , we propose a dynamic programming algorithm for computing P ∃(w , m ) . Let Q[i , j ] denote the product k=1 qnk k such that j
 i=1 j i k=1 nk = i then k=0 Q[i − k , j − 1 ] · qk w−m j i=0 Q[i , m ]
Q[i , j ] Q[i , 1 ] Q[0 , j ] P ∃(w , m ) = P ( S )
= = qi 1 = 1
1 < j ≤ m , 1 < i ≤ w − m
1 ≤ j ≤ m
The time complexity of the algorithm is O((w − m)2 · m ) and is equal to the space required to build the table Q[w − m , m ] . Let v[a : b ] denote the substring of a string v between indexes a and b such that a < b and 1 ≤ a , b ≤ w . Let p[1 : m ] be an array with probabilities p1 , p2 , . . . , pm of the symbols in S .
18
Algorithm 1 : Computation of P ∃(w , m ) input : w , m , p[1 : m ] output : P ∃(w , m ) begin for j = 1 to m do
Q[0 , j ] = 1 ; P ∃(w , m ) = 1 ; for i = 1 to w − m do Q[i , 1 ] = ( 1 − p[1])i ; for j = 2 to m do
Q[i , j ] = 0 ; for k = 0 to i do
Q[i , j ] = Q[i , j ] + Q[i − k , j − 1 ] · ( 1 − p[j])k ;
P ∃(w , m ) = P ∃(w , m ) + Q[i , m ] ;
P ∃(w , m ) = P ( S ) · P ∃(w , m ) ; end
4.4 Variance We need to establish a precise formula for variance Var[Ω∃(n , w , m) ] . First observe that
Var[Ω∃(n , w , m ) ] =
Var
I∃ i ( w )
+ 2
Cov[I∃ i ( w ) , I∃ j ( w) ] , n i=1
( cid:163 )
( cid:164 ) n
1≤i<j≤n where trivially and
This leads to
Var[Ω∃(n , w , m ) ] = n
Cov[I∃ i ( w ) , I∃ j ( w ) ] − E[I∃ i ( w ) ] · E[I∃ i ( w ) ]
E[I∃ i ( w ) , I∃ j ( w ) ] = if if
|i − j| ≥ w |i − j| < w . j ( w))(w , m , k ) i ( w ) , I∃ j ( w ) ] = E[I∃
( P ∃(w , m))2 P ∃ i ( w)∩I∃ ( I∃
( cid:163 ) P ∃(w , m ) − ( P ∃(w , m))2(cid:164 ) w−1 w−1 w−1 k=1
+2(n − w + 1 )
+2 q=2 k=q
+
P ∃ i ( w)∩I∃ ( I∃ j ( w))(w , m , k ) − ( P ∃(w , m))2
P ∃ i ( w)∩I∃ ( I∃ j ( w))(w , m , k ) − ( P ∃(w , m))2
.
Because clearly E[I∃ can use P ∃(w ) as an upper bound for P ∃ i ( w)∩I∃ ( I∃ leads to j ( w ) ] ≤ E[I∃ i ( w ) , I∃ i ( w ) ] for 1 ≤ i < j ≤ n implies P ∃ i ( w)∩I∃ ( I∃ j ( w))(w , k ) ≤ P ∃(w ) we j ( w))(w , k ) instead of the enumerative algorithm . This
( cid:163 ) P ∃(w ) − ( P ∃(w))2(cid:164 )
.
Var[Ω∃(n , w , m ) ] ≤ [ n + ( 2n − w)(w − 1 ) ]
19
In other words , W∃(w , m , k)(I∃
To exactly compute P ∃ i ( w)∩I∃ ( I∃ j ( w))(w , m , k ) we define W∃(w , m , k)(I∃ j ( w ) ) as the set of all possible pairwise overlapping windows on k = w − |i − j| symbols such that I∃ j ( w ) = 1 for i < j j ( w ) ) can be enumerated as all 2w − k length and |i − j| < w . strings consisting of two windows W∃(w , m)[r ] and W∃(w , m)[q ] of length w , that overlap on k positions . The overlap is between the last k symbols of W∃(w , m)[r ] and the first k symbols of W∃(w , m)[q ] for 1 ≤ q , r ≤ C∃(w , m ) . Let W∃(w , m , k)(I∃ P ∃ i ( w)∩I∃ ( I∃ j ( w))[l ] be the l th string of W∃(w , m , k)(I∃ i ( w)∩I∃ i ( w ) = 1 , I∃ j ( w) ) . Then we can express j ( w))(w , m , k ) as follows i ( w)∩I∃ i ( w)∩I∃ i ( w)∩I∃
|W∃(w,m,k)|
( cid:179 ) l=1
( cid:180 )
P ∃ i ( w)∩I∃ ( I∃ j ( w))(w , m , k ) =
P
W∃(w , m , k)(I∃ i ( w)∩I∃ j ( w))[l ]
.
Now we present an exact algorithm for computing P ∃ i ( w)∩I∃ ( I∃ j ( w))(w , m , k ) . The idea of the algorithm is to enumerate all pairs of sets of windows , which overlap on k symbols , ie the last k symbols of the first set of windows are equal to the first k symbols of the second set of windows . From Theorem 3 it is known that all elements in W∃(w , m ) can be divided into a set of equivalence classes V∃ . Let V∃[i ] be the i th element of V∃ . Our algorithm generates elements in V∃ and finds all overlaps on k symbols between them .
Let V∃[i ] and V∃[j ] be candidates for the overlap
V∃[i ] = s1 V∃[j ] = s1 m+1 ni nj r=1 ni ni ni nj nj m+1
2 × s2 . . . sm 2 × s2 . . . sm m × sm × Ani 1 × s1 × s2 1 × s1 × s2 m × sm × Anj r = w − m . r = w − m and j ( w))(w , m , k ) for Var[Ω∃(n , w , m ) ] r=1 nj m+1 , m+1 , where si = A − si , i , j ≤ |V∃| ,
Algorithm 2 : Computation of P ∃ i ( w)∩I∃ ( I∃ input : w , m , k , P ( a1 ) , P ( a2 ) , . . . , P ( a|A| ) output : P ∃ i ( w)∩I∃ ( I∃ begin j ( w))(w , m , k )
( cid:161)w
( cid:162 )
( cid:161)w do
( cid:162 ) m do for i = 1 to m for j = 1 to
Overlap[1 : k ] = V∃[i][w − k + 1 : w ] ∩ V∃[j][1 : k ] ; if Overlap[1 : k ] 6= ∅ then
P ∃ i ( w)∩I∃ ( I∃ j ( w))(w , m , k)+ = P ( V∃[i][1 : w−k])·P ( Overlap[1 : k])·P ( V∃[j][k+1 : w]) ) ; end
Note that unlike Algorithm 1 for P ∃(w , m ) , which is fast even for large w Algorithm 2 , is not practical for large w . An alternative approach for large w is to improve Algorithm 2 by cutting the search space ( through elimination of certain pairs of sets of windows ) .
20
5 Conclusions and extensions
We proposed a reliable method for detecting significant episodes , where as a measure of normal behavior of an episode we used Ω∃(n , w , m ) , the number of windows which contain at least one occurrence of the episode . We proved that Ω∃(n , w , m ) is normally distributed and for a given accuracy level β , we showed how to compute the upper threshold τu(w , m ) and the lower threshold τ‘(w , m ) for detecting significant episodes . The reliability of our method stems from the fact that , we provide guarantees on accuracy of our threshold mechanism and an analytic formula for selecting the window size w to ensure that the discovered episode is meaningful . As part of our threshold mechanism we presented an exact formula for P ∃(w , m ) , the probability that a serial episode S of length m occurs in a window of length w in an event sequence T over the alphabet A modeled as a memoryless source . In addition we gave an asymptotic approximation of P ∃(w , m ) , which shows that , for appropriately large w , P ∃(w , m ) asymptotically tends to one as expected . By providing an efficient dynamic programming method for computing P ∃(w , m ) we showed the applicability of our method to real time monitoring systems . In the experiments , we chose two apparently non memoryless sources ( the English alphabet and the web access data ) and showed that , even for these cases , P ∃(w , m ) closely approximated occurrences of windows with episodes . This seems to be yet another one of those intriguing situations where an equation derived under a certain set of assumptions holds in practical examples for which those assumptions are clearly violated . In experiments we tested τu(w , m ) by injecting episodes into the testing source and observed that τu(w , m ) did indeed provide a sharp detection of significant episodes . An obvious extension of this work is to use Theorem 3 to compute P ∃(w , m ) for Markov sources .
21
References
[ 1 ] A . Aho and M . Corasick ( 1975 ) , Efficient String Matching : An Aid to Bibliographic Search Program ming Techniques .
[ 2 ] A . Apostolico and M . Atallah ( 2002 ) , Compact Recognizers of Episode Sequences , Information and
Computation , 174 , 180 192 .
[ 3 ] P . Billingsley ( 1986 ) , Probability and measure , John Wiley , New York .
[ 4 ] L . Boasson , P . Cegielski , I . Guessarian , and Y . Matiyasevich ( 1999 ) , Window Accumulated Subse quence Matching Problem is Linear , Proc . PODS , 327 336 .
[ 5 ] S . Brin , R . Motwani , C . Silverstein , Beyond Market Baskets : Generalizing Association Rules to Correlations , SIGMOD 1997 , Proceedings ACM SIGMOD International Conference on Management of Data , May 13 15 , 1997 , Tucson , Arizona
[ 6 ] M . Crochemore and W . Rytter ( 1994 ) , Text Algorithms , Oxford University Press , New York .
[ 7 ] G . Das , R . Fleischer , L . G asieniec , D . Gunopulos , and J . K¨arkk¨ainen ( 1997 ) , Episode Matching , In Combinatorial Pattern Matching , 8th Annual Symposium , Lecture Notes in Computer Science vol . 1264 , 12–27 .
[ 8 ] P . Flajolet , Y . Guivarc’h , W . Szpankowski , and B . Vall´ee ( 2001 ) , Hidden Pattern Statistics , ICALP
2001 , Crete , Greece , LNCS 2076 , 152 165 .
[ 9 ] G . Kucherov , M . Rusinowitch ( 1997 ) , Matching a Set of Strings with Variable Length Don’t Cares ,
Theoretical Computer Science 178 , 129–154 .
[ 10 ] S . Kumar and EH Spafford ( 1994 ) , A Pattern Matching Model for Intrusion Detection , Proceedings of the National Computer Security Conference , 11–21 .
[ 11 ] H . Mannila , H . Toivonen , and A . Verkamo ( 1997 ) , Discovery of frequent episodes in event sequences
Data Mining and Knowledge Discovery , 1(3 ) , 241 258 .
[ 12 ] P . Nicod`eme , B . Salvy , and P . Flajolet ( 1999 ) , Motif Statistics , European Symposium on Algorithms ,
Lecture Notes in Computer Science , No . 1643 , 194–211 .
[ 13 ] P . Pevzner ( 2000 ) , Computational Molecular Biology : An Algorithmic Approach , MIT Press .
[ 14 ] M . R´egnier and W . Szpankowski ( 1998 ) , On pattern frequency occurrences in a Markovian sequence
Algorithmica , 22 , 631 649 .
[ 15 ] I . Rigoutsos , A . Floratos , L . Parida , Y . Gao and D . Platt ( 2000 ) , The Emergence of Pattern Discovery
Techniques in Computational Biology , Metabolic Engineering , 2 , 159 177 .
[ 16 ] R . Sedgewick and P . Flajolet ( 1995 ) , An Introduction to the Analysis of Algorithms , Addison Wesley ,
Reading , MA .
[ 17 ] W . Szpankowski ( 2001 ) , Average Case Analysis of Algorithms on Sequence , John Wiley , New York .
22
[ 18 ] M . Waterman ( 1995 ) , Introduction to Computational Biology , Chapman and Hall , London .
[ 19 ] A . Wespi , H . Debar , M . Dacier , and M . Nassehi ( 2000 ) , Fixed vs . Variable Length Patterns For
Detecting Suspicious Process Behavior , J . Computer Security , 8 , 159 181 .
[ 20 ] S . Wu and U . Manber ( 1995 ) , Fast Text Searching Allowing Errors , Comm . ACM , 35:10 , 83–991 .
23
Robert Gwadera received the MS degree in Electrical and Computer Engineering from Technical University of Gdansk , Poland in 1995 . In 2003 he received the MS in Computer Sciences from Purdue University . He is currently working towards his PhD in Computer Science at Purdue University . His research interests are data mining , databases and security .
Mikhail ( ” Mike ” ) Atallah obtained his PhD from the Johns Hopkins University in 1982 , and joined the Purdue University Computer Science Department where he was promoted to Associate Professor in 1986 , to Professor in 1989 , and to Distinguished Professor in 2004 . His current research interests are in information security ( in particular , software security , secure protocols , and watermarking ) . He received a Presidential Young Investigator Award from the National Science Foundation in 1985 . A Fellow of the IEEE , he has served on the editorial boards of SIAM Journal on Computing , IEEE Transactions on Computers , and many other journals , and has also served on the Program Committees of many conferences and workshops . He was Keynote and Invited Speaker at many national and international meetings . In June 2001 he co founded Arxan Technologies Inc . , a startup in the software security products space , that has secured funding from top tier venture capital firms .
24
Wojciech Szpankowski received the MS degree and the PhD degree in Electrical and Computer Engineering from Technical University of Gdansk , Poland in 1976 and 1980 , respectively . Currently , he is Professor of Computer Science at Purdue University . During 1992/1993 he was a Professeur Invite INRIA , France , in the Fall of 1999 he was a Visiting Professor at Stanford University . His research interests cover design and analysis of algorithms , bioinformatics and multimedia compression ( information theory ) . He has published over 170 papers on these topics . In 2001 he published his book ” Average Case Analysis of Algorithms on Sequences ” , John Wiley & Sons . He has been a guest editor for several journals . He is managing editor of “ Theoretical Computer Science and Discrete Mathematics ” , and he is on the editorial boards of “ Theoretical Computer Science ” and “ Foundation and Trends in Communications and Information Theory ” . In 2003 he chaired NSF Workshop on Information Theory and Computer Science Interface , Chicago . He is Fellow of the IEEE .
25
