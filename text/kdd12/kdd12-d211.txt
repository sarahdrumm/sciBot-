Towards Heterogeneous Temporal Clinical Event Pattern
Discovery:A Convolutional Approach
Fei Wang1 , Noah Lee,1,2 , Jianying Hu1 , Jimeng Sun1 , Shahram Ebadollahi1
1Healthcare Analytics Research Group , IBM TJ Watson Research Center
2Department of Biomedical Engineering , Columbia University fwang,jyhu,jimeng,ebad@usibmcom,nl2168@columbiaedu
ABSTRACT Large collections of electronic clinical records today provide us with a vast source of information on medical practice . However , the utilization of those data for exploratory analysis to support clinical decisions is still limited . Extracting useful patterns from such data is particularly challenging because it is longitudinal , sparse and heterogeneous . In this paper , we propose a Nonnegative Matrix Factorization ( NMF ) based framework using a convolutional approach for open ended temporal pattern discovery over large collections of clinical records . We call the method One Sided Convolutional NMF ( OSC NMF ) . Our framework can mine common as well as individual shift invariant temporal patterns from heterogeneous events over different patient groups , and handle sparsity as well as scalability problems well . Furthermore , we use an event matrix based representation that can encode quantitatively all key temporal concepts including order , concurrency and synchronicity . We derive efficient multiplicative update rules for OSC NMF , and also prove theoretically its convergence . Finally , the experimental results on both synthetic and real world electronic patient data are presented to demonstrate the effectiveness of the proposed method . Categories and Subject Descriptors J.3 [ Life and Medical Sciences ] : Health ; I.5 [ Pattern Recognition ] : Design Technology—Pattern analysis General Terms Agorithms Keywords Pattern Discovery , NMF , Convolution
1 .
INTRODUCTION
Electronic Health Records ( EHR ) are systematic collections of longitudinal patient health information generated by one or more encounters in any care delivery setting . Included in this information are patient demographics , en
Figure 1 : An example of a diabetic patient ’s electronic record over one year . The x axis corresponds to the day index , the y axis represents different types of recorded events , which can be categorized into 4 groups including procedures ( CPTs ) , lab results ( LABs ) , visits to primary care physician ( PCP ) and visits to specialists ( SPEC ) . The dots in the figure indicate the corresponding events happening at corresponding dates . counter records such as claims , progress notes , problems , medications , vital signs , immunizations , laboratory data and radiology reports , etc . Fig 1 illustrates an example of a temporal event record of a diabetic patient over one year , where 30 key event factors are recorded , including procedures ( CPTs ) , lab results ( LABs ) , visits to primary care physician ( PCP ) and various specialists ( SPEC ) .
In this paper , we study Temporal Pattern Discovery ( TPD ) for EHR data , which aims at finding temporal patterns of one or more groups of patients . TPD is an open ended problem in the sense that the mined patterns can be utilized in various scenarios such as predictive modeling [ 1 ] , information visualization [ 29 ] and comparative effectiveness research [ 25 ] . TPD is also an active research direction that has attracted a lot of interests from data mining related applications including financial marketing [ 6 ] , video content analysis [ 4 ] and social network analysis [ 19 ] . Many challenges in TPD are shared by these applications , however some are particularly pronounced in the medical domain when performing TPD from medical data . These include ( 1 ) Shift Invariance . EHR for all patients are not temporally aligned . Moreover , due to various complexities such as comorbidities , the trajectories for different patients are very different over a long time period . However , it is possible to extract time invariant patterns within a shorter timeframe across patients . Thus an appropriate TPD approach should not be affected by the absolute time stamps .
CPTsLABSSPECPCP453 ( 2 ) Heterogeneity . The EHR data contain multiple types of events ( eg , diagnosis , medication , lab ) . The method needs to be able to mine patterns from the combination of all types of events and capture the relationship among them . ( 2 ) Sparsity and Irregularity . The EHR data are usually very sparse with irregular intervals , as most of the patients do not have frequent events ( eg , the patient shown in Fig 1 only has around 20 events in a year ) or with high regularity . ( 4 ) Quantitative Nature . In clinical settings qualitative relations such are event A is followed by event B is important but typically insufficient . Quantitative measures of the duration of a given event and the interval between multiple events are often of key importance . ( 5 ) Scalability . We may face a large patient population , and each patient may has a long longitudinal record ( eg , chronic disease ) and many different event factors . The algorithm needs to be able to efficiently learn patterns from such a large volume of data .
We propose a novel geometric framework for EHR representation and perform the TPD task based on that . Specifically , we model the EHR record as an image matrix like Fig 1 , where the x axis corresponds to the time stamps and y axis corresponds to the event values . Note that different events can have different value ranges and types ( eg , blood pressure has continuous values , while PCP visits has nonnegative integer values)1 . Furthermore , each event could be either instantaneous ( represented by a single pixel ) , or with a certain duration ( represented by a line segment in the image ) . This provides a succinct representation that can effectively encode a large range of temporal information including event value , time and duration , relationships among different events , and intervals between pairwise events using an image . We call such a representation an event matrix .
Based on the event matrix representation , we propose a novel approach , One Sided Convolutional Nonnegative Matrix Factorization ( OSC NMF ) , to detect temporal patterns from EHR . NMF is a powerful tool for identifying underline structures in a matrix through regularized decomposition and has been successfully applied to many applications including clustering , metric learning , and classification [ 13][14 ] . In order to apply this tool to our problem setting , where each patient is represented by an event matrix with fix number of rows ( determined by the events of interested ) but varying number of columns ( determined by the length of the longitudinal record of the patient ) , we adapt a convolutional approach . Our approach assumes that each patient matrix is generated by the superposition and concatenation of a set of temporal pattern matrices over the time axis . The method is called one sided because the convolution only occurs along the time axis but not on event side . Each pattern matrix essentially encodes a composite temporal pattern with the inherent order , concurrency and synchronicity relations among different events .
To carry out this convolutional decomposition approach we introduce a methodology to minimize the β divergence [ 9 ] between the convoluted matrix and the original patient matrix to obtain the optimal pattern matrices under nonnegativity constraints . β divergence is a general divergence measure that includes many common measures such as KL
1In this paper , we only consider binary event values , ie , the ( i , j) th element of the patient matrix is 1 if the i th event happens at time j , otherwise its value would be 0 . divergence and Euclidean distance as special cases . We provide efficient multiplicative update rules for solving the optimal patterns based on this general measure , and rigorous proofs for the algorithm convergence . Experimental results on applying OSC NMF to both synthetic and real world data are presented to demonstrate its effectiveness .
It is worthwhile to highlight the strength of OSC NMF .
( 1 ) The mined patterns are shift invariant . Because of the convolutional nature of OSC NMF , the mined temporal patterns are independent of the absolute time stamps . ( 2 ) The mined patterns are comprehensive . The mined pattern matrices represent relationships among all different types of events recorded in the patient matrices . ( 3 ) OSC NMF can incorporate sparsity constraints . OSC NMF can easily handle the high sparsity in the data by adding sparsity regularization terms in the objective . ( 4 ) The mined patterns are quantitative . The pattern matrices can naturally encode quantitative relationships among all different events , including duration of events as well as interval and overlap between events . ( 5 ) OSC NMF can handle large scale data set . We provide an efficient stochastic learning framework for OSCNMF , which processes one or a small portion of the data matrices each time , thus results in a constant memory cost . The rest of this paper is organized as follows . Section 2 introduces related work . Algorithm details and extensions are described in section 3 . Section 4 presents the experimental results , is followed by the conclusion in section 5 . 2 . RELATED WORK
In this section we briefly review some previous work that are closely related to our work in this paper .
A lot of work has been done for temporal sequence representation and mining . For example , Keogh et al . proposed symbolic aggregate approximation ( SAX ) [ 15 ] to represent time series using symbolic sequences . However , SAX cannot take into account the relationships among heterogeneous time sequences . [ 17 ] proposed a temporal knowledge representation method with symbolic languages and grammars . [ 5 ] proposed a TPD approach based on first order temporal logic under regular expression constraints . These methods is that they specify some explicit symbolic languages and temporal grammars according to prior knowledge . Frequent item set [ 22][11 ] or sub sequence [ 30 ] mining are also closely related to the work in this paper . However , in these approaches , the time intervals between pairwise events are not considered . In our case , this pairwise event intervals are of key importance ( eg , two events happen in a week and a year are completely different disease condition signals ) .
In medical domain , [ 20 ] proposed a statistical approach for summarizing and visualizing the temporal associations between the prescription of a drug and the occurrence of a medical event . [ 24 ] proposed a temporal abstraction approach for medical TPD . Similar to [ 17 ] , this method also requires predefined temporal grammar and logic with prior knowledge . [ 8 ] proposed a visual interface for finding temporal patterns in multivariate temporal clinical data . The interface was further used in [ 23 ] for searching temporal patterns in patient histories , but the user needs to specify the structure of the pattern on the interface .
On the methodology side , Nonnegative Matrix Factorization ( NMF ) [ 13][14 ] , which aims at factorizing a nonnegative
454 ij
Another important definition is the matrix β divergence . Definition 2 . ( β divergence [ 9 ] ) The β divergence between two matrices A and B with the same size is dβ ( A , B ) =
1
β(β − 1 ) ij + ( β − 1)Bβ Aβ ij − βAij Bβ−1 ij
( 2 )
For completeness , by making use of the limit theory , we where β 0 is a constant . define dβ(A , B ) for β = 0 and β = 1 as follows . ij − Bβ ij d0(A , B ) = lim β→0
Aij ij
Bβ−1 1 − β ij
− Aβ
β
Aβ ij β − 1
+ d1(A , B ) = lim β→1
Aij ij
β − 1
+
β ij
Aij ( log Aij − log Bij ) + ( Bij − Aij ) ij − Aβ Bβ
Aβ−1 ij − Bβ−1 ij ij
( 3 )
Aij ( log Aij − log Bij ) + ( Bij − Aij )
( 4 ) ij
=
=
β divergence is a very general divergence : d0(A , B ) , d1(A , B ) , d2(A , B ) correspond to the Itakura Saito distance , generalized Kullback Leighbler divergence and Euclidean distance . 3.2 The Algorithm
Now coming back to our problem , we first introduce how to make use of OSC NMF to detect temporal patterns from a single patient ’s EHR . Second , we extend OSC NMF to detect patterns from the EHR of multiple groups of patients . Recall we suppose the patient EHR matrix X is constructed by the superposition of the one side convolution of a set of patterns F = {F(r)}R r=1 across the time axis . Then R we propose to detect them by minimizing
J = dβ
X ,
F(r ) ∗ g(r ) r=1
( 5 ) where g(r ) ∈ Rt is the coding matrix for pattern F(r ) . The problem our algorithm aims to solve is min
F(r)0 , g(r)0
J ( ∀r = 1 , 2 , · · · , R )
( 6 )
Since the patient matrix X is nonnegative , we also require {F(r ) , g(r)}R r=1 to be nonnegative . With the definition of β divergence ( Eq ( 2) ) , we have t j=1
∂J ∂F ( r ) ik
=
∂Yij
∂F ( r ) ik ij − Xij Y β−2 Y β−1 R
F(r ) ∗ g(r ) ij r=1 where we define
Y =
Combining Eq ( 1 ) and Eq ( 8 ) , we have ∂Yij/∂F ( r ) Thus we can update F ( r ) ik = g(r ) j−k+1 .
( 7 )
( 8 )
( 9 )
( 10 ) ik ← F ( r ) F ( r ) ik
η(β ) g(r ) j−k+1 ij ij ik by
t t j=1 Xij Y β−2 j=1 Y β−1 g(r ) j−k+1  1
2−β , β < 1 1 , 1 β−1 , β > 2
1 β 2
η(β ) = where η(β ) is the learning rate defined as
Figure 2 : A graphical illustration of one side convolution . The top left figure shows temporal pattern , and the top right figure is the time axis where we use green bars to represent the position where the pattern appears . The bottom figure is the one side convolution result , where each dotted line rectangle corresponds to a pattern . matrix into the product of two low rank nonnegative matrices , has attracted considerable interests from data mining in recent years . There are also a lot of NMF variants that are related to our work . For instance , [ 12][7 ] proposed to enforce sparsity regularizations on the decomposed matrices to obtain sparse solutions . [ 10 ] , [ 21 ] , [ 26 ] and [ 18 ] proposed convolutional sparse NMF to discover the shift invariant temporal patterns from acoustic signals and images . However their approach is designed for time series data and is not applicable to heterogeneous event sequences . Furthermore , all prior methods measure the factorization quality using matrix Frobenius norm , and obtain a common set of patterns by batch learning methods . On the contrary , our method proposed in this paper ( 1 ) is based on a general β divergence loss ; ( 2 ) can detect common and individual patterns from different data groups , and ( 3 ) can be trained with efficient stochastic learning scheme . 3 . ONE SIDED CONVOLUTIONAL NMF
We now describe the One Sided Convolutional NMF ( OSC
NMF ) algorithm in detail . 3.1 Preliminaries
Suppose we have a patient matrix X ∈ Rn×t , where n is the number of event factors , t is the length of the patient clinical history . As mentioned in section 1 , we assume X is the superposition of the one side convolution of a set of hidden patterns F = {F(r)}R r=1 across the time axis . We define the one side convolutional operator ∗ as follows . Definition 1 . ( One Sided Convolution ) . The one sided convolution of F ∈ Rn×m and g ∈ Rt×1 is an n × t matrix with
( F ∗ g)ij = gj−k+1Fik
( 1 ) t k=1
Note that gj = 0 if j 0 or j > t , and Fik = 0 if k > m .
Thus we can see that one side convolution is the operation between a matrix and a vector . This operator is specially designed for our scenario on TPD from electronic clinical records . As in our case , we are interested in patterns composed of all events , thus there is no convolution on the vertical axis . Fig 2 gives us an intuitive graphical illustration of the procedure of one side convolution , where the bottom image is obtained through the one side convolution of the pattern top left and the time vector top right .
455 =n t On the other hand , we have ij − XijY β−2 Y β−1 ∂J n t ∂g n t j=1 Xij Y β−2 j=1 Y β−1 k ← g(r ) g(r )
( r ) k j=1 i=1 i=1 i=1 ij k ij F ( r ) i,j−k+1 ij F ( r ) i,j−k+1
η(β )
F ( r ) i,j−k+1 , therefore
( 11 ) r=1
We have the following theorem ( which is proved in the Appendix ) to guarantee the convergence of the updates . Theorem 1 . Starting from some initial guess on {F(r ) , g(r)}R and iteratively update them with Eq ( 9 ) and Eq ( 11 ) will finally converge to a stationary point . Complexity Analysis For the storage complexity , during the iterations , it is good to hold X and Y in the memory , which costs O(sX + sY ) space , where sX and sY are the number of nonzero elements in X and Y . We also need to hold F(r ) and g(r ) when updating themselves , which brings an additional O(¯sF + ¯sg ) space . Here ¯sF and ¯sg are the averaged number of nonzero r=1 and {g(r)}R elements over {F(r)}R r=1 . So the total storage complexity is O(sX +sY +¯sF +¯sg ) .
For computational complexity , we need O(¯sF ¯sg ) time to compute Y , O(2¯sF ¯sg ) time to update each F(r ) at every iteration , thus update all F = {F(r)}R r=1 over one step costs O((2R + 1)¯sF ¯sg ) time , and the complexity for updating all G = {g(r)}R r=1 over one iteration is the same . Thus the total computational complexity for OSC NMF over T iterations is O((4R + 2)T ¯sF ¯sg ) . Imposing the Sparsity Constraints As shown in Fig 1 , the patient EHR matrices are very sparse . Therefore it is natural to assume that the learned temporal pattern matrices and the convolutional coefficients are also sparse . Similar to [ 12 ] and [ 7 ] , we can enforce the sparsity constraints by adding 1 regularization terms to the objective in Eq ( 5 ) . As a consequence , we can solve for the optimal patterns and codes by minimizing
R
R
R
J1 = dβ
X ,
F(r)∗ g(r )
+λ1
F(r)1 +λ2 g(r)1 r=1 r=1 r=1
( 12 ) where λ1 > 0 and λ2 > 0 are the regularization parameters . Then the problem we want to solve becomes min
F(r)0 , g(r)0
J1 ( ∀r = 1 , 2,··· , R )
( 13 )
Similar to the previous subsection , we can get the update rules for F and g as follows .
η(β )
 t t j=1 Xij Y β−2 g(r ) j−k+1 ij  n j=1 Y β−1 t g(r ) j−k+1 + λ1 n t j=1 Xij Y β−2 j=1 Y β−1 ij F ( r ) i=1 i=1 ij ij F ( r ) i,j−k+1 i,j−k+1 + λ2 ik ←F ( r ) F ( r ) ik k ←g(r ) g(r ) k
η(β )
( 14 )
( 15 )
We can also observe that the storage and computational complexities of OSC NMF after imposing those sparsity constraints remains the same as simple OSC NMF .
However , as pointed out by [ 7 ] , purely solving problem ( 13 ) may cause a scaling problem , as we can always scale F and G to get the same cost function value . To avoid this , we propose an normalization invariant formulation of problem
2 ij F ( r ) ij r=1 r=1 r=1
X ,
( 16 )
+λ1
R
R
R g(r)1
( 13 ) in the following . Normalization Invariant Formulation For the normalization invariant sparse OSC NMF , we need to minimize the following objective with nonnegativity constraints . J n 1 = dβ
F(r)1 +λ2
F(r ) ∗ g(r ) paper , we will consider two types of normalization .
• Individual Normalization . Each pattern matrix is nor
Using the same trick as in [ 7 ] , we can update F and G by
• Total Normalization . Each pattern matrix is normalized by the total Frobenius norm of all the pattern where F(r ) is the r th normalized pattern matrix . In this malized to unit Frobenius norm , ie , F ( r ) matrices , ie , F ( r )   Y β−2 j−k+1 +λ1F ( r)2 Xij +YijF ( r)2 Y β−2 Yij +XijF ( r)2 t   n t XijY β−2 F ( r ) t n Y β−1 F ( r ) R r=1F(r ) ∗ g(r ) whereYij =R t k=1 gj−k+1F ( r ) ik ← F ( r ) F ( r ) k ← g(r ) g(r ) ij = F ( r ) ij / ij = F ( r ) ij / ij We can see that this normalization invariant formulation does not bring any extra storage burden , but brings an extra O(2R¯sF ) computational overhead at each iteration . 3.3 OSC NMF on Data Groups g(r ) j−k+1 +λ1 i,j−k+1 + λ2 ij F ( r ) i,j−k+1 t ik = g(r )
η(β )
η(β ) r=1 i=1 j=1 i=1 j=1 j=1 j=1 ik ik ik ik ij ij
2 ij ij ij k r
.
In the medical domain , patients are often characterized by multiple groups based on characteristics such as diagnosis or treatments . More formally we consider the case where the patient matrices are composed of C groups . We use Xc = [ Xc1 , Xc2 ,··· , Xcnc ] to represent the c th patient group , with Xcl representing the l th data point in this group . nc is the number of patient in the c th group . In many real world applications we are also interested in finding patterns hidden in those groups . In this section we will extend our one side convolutional NMF to these scenarios . ( 1 ) . TPD From One Group We first consider the case of detecting common patterns from one group , ie , C = 1 , which is the same setting as If we still denote the hidden in group sparse coding [ 2 ] . pattern set as F = {F(r)}R r=1 , then the problem we want to solve becomes ( here we directly give the sparsity constrained objective as the non sparse case just correspond to λ1 = λ2 = 0 ) minF ,{Gc}C c=1
J3 st
∀r = 1 , · · · , R ; l = 1 , · · · , n1 ,
( 17 )
F(r ) 0 , g(r )
0 l where G = {g(r ) l }n1 i=1 is the convolution coefficients for the data , n1 is the size of the group . Then the objective we want R to minimize is J3 =
F(r)1+λ2
F(r)∗ g(r ) n1
R n1
R g(r )
+λ1
Xl , dβ l 1 l l=1 r=1 r=1 l=1 r=1
( 18 )
456 , we can obtain the update groups , as well as an individual pattern dictionary {F I for each data group , then we need to solve c }C c=1
If we want to find normalized patterns , we can use the same trick as in [ 7 ] and derive the following update rules
J4=
η(β )
+
γS l
By defining Yl =R r=1 F(r)∗ g(r ) n1 n1 n n rules for F and G as follows . t t j=1 Xlij Y β−2 lij j=1 Y β−1 t g(r ) lj−k+1 t j=1 Xclij Y β−2 i,j−k+1 clij j=1 Y β−1 F ( r ) i,j−k+1 + λ2 ik ←F ( r ) F ( r )
←g(r ) lk g(r ) lj−k+1 g(r ) lk
F ( r ) i=1 i=1 l=1 l=1 cl ij lij ik ik ik l,j lij ik ← F ( r ) F ( r )
Y β−2

Xlij+YlijF ( r)2 Y β−2 Ylij+XlijF ( r)2
  n t XlijY β−2 F ( r ) n t Y β−1 F ( r ) where Yl =R r=1F(r)∗ g(r ) i,j−k+1 + λ2
← g(r ) lk i,j−k+1 g(r ) lk j=1 j=1 i=1 i=1 lij lij lij l,j ik
. l g(r ) lj−k+1 g(r ) lj−k+1
η(β )
( 19 )
( 20 )
+ λ1
η(β ) η(β )  +λ1F ( r)2 ik
+λ1
Complexity Analysis
Similar to the simple OSC NMF case , we can analyze that the storage complexity of group OSC NMF is O(n1(¯sX + ¯sY + ¯¯sg ) + ¯sF ) , where n1 is the size of the group , ¯sX , ¯sY are the averaged number of nonzero elements in {Xl}n1 l=1 and {Yl}n1 l=1 , and ¯¯sg is the averaged number of nonzero elements of all {g(r ) r=1,l=1 . The total computatioinal complexity is O((4R + 2)T n1¯sF ¯¯sg ) . For normalized cases , we just need an extra O(2R¯sF ) time for pattern normalization . l }R,n1
A Stochastic Learning Scheme
We can see that group OSC NMF is storage and time consuming if the group size n1 is very large . In this case , we can adopt the stochastic ( online ) learning scheme in [ 16][3][28 ] , ie , at each time t , the algorithm only ( randomly ) receives one or a small number of matrices Xt from the data pool , then proceeds the following steps : ( 1 ) Estimate the convolution coefficients Gt for Xt based on the current Ft . This can be done by starting from some random of Gt , then iterating with Eq ( 20 ) ( or its normalized version ) several times . ( 2 ) Integrating Xt and Gt with the previously received data and their estimated convolution coeffients to update F with Eq ( 19 ) ( or its normalized version ) only once . With this scheme , when estimating Gt at step t , we need O(nt(¯sX + ¯sY ) + ¯sF ) space , with nt being the size of Xt and usually nt n1 . We also need O(nt(2R + 1)¯sF ¯¯sg ) computational time . For updating F from Eq ( 19 ) ( or Eq ( 21) ) , we need to sum over all received data matrices for both numerator and denominator , thus we can save the summation results on the nominator and denominator in the previous step . Therefor , we just need to compute the corresponding summation terms on Xt . For each round of updating F , we need O(nt(¯sX + ¯sY + ¯¯sg)+2¯sF ) space and O(nt(2R+1)¯sF ¯¯sg ) time . To conclude , the total storage complexity for this online scheme is O(nt(¯sX + ¯sY + ¯¯sg ) + 3¯sF ) , and the total computational complexity is O((4R + 2)T nt¯sF ¯¯sg ) . For normalized cases , we just need to add additional O(2R¯sF ) computational time for pattern normalization . ( 2 ) . TPD From Multiple Data Groups Now assume there are C ( C > 1 ) data groups , and we want to find a common pattern dictionary F S across all data
J4
0
Scl
+ λI
F(r )
S
+ λS cl ij cl ij
( 22 )
( 23 )
+λI c=1 v=1
Ic
F ( r ) Sik
Icl v=1
+λS
S r=1
F ( v ) Ic ik
+γI
Scl c=1 l=1 r=1
F(v ) Ic
+ v=1 g(r ) Scl k c=1 l=1 r=1 dβ
Xcl ,
,g(v ) Ic l flflfl1
0,F(v ) Ic
0,g(r ) Sc l
∗ g(v ) Icl r=1 F(r ) v=1 F(v ) Ic
∗ g(v ) Icl
, then we can g(v ) Iclj−k+1 g(r ) Scl j−k+1
← F ( r ) Sik
← F ( v ) Ic ik
← g(r ) Scl k cl ij g(v ) Iclj−k+1 clij g(r ) Scl j−k+1
C get the update rules for unnormalized case min ( 21 ) st ∀r = 1 , · · · , R ; c = 1 , · · · , C ; l = 1 , · · · , nc ; v = 1 , · · · , V where we use r to index the common patterns ( whose total number is R ) , v to index the individual patterns in the c th group ( whose total number is Vc ) , and l to index the data within each group . The objective we want to minimize is nc C
C R nc LetY = R flflflF(r ) flflfl1 V R R S ∗g(r ) F(r ) flflflg(r ) flflfl1 flflflg(v ) flflflF(v ) flflfl1 V V Scl +V S ∗ g(r ) η(β )  c,l,j XclijY β−2 c,l,j Y β−1  η(β ) l,j Xcl ijY β−2 l,j Y β−1 η(β )  i,j Xcl ijY β−2 i,l,j Y β−1 η(β )  i,j Xcl ijY β−2 i,l,j Y β−1 +V Let Y = R , where FS v=1F(v ) r=1F(r ) and {FIc} are normalized basis , then we have the following S ∗ g(r )
Y  
Xcl ij+Y cl ijF ( r)2 +λSF ( r)2 Y clij+XclijF ( r)2 Y
Y
 
Xcl ij+Y cl ijF ( r)2 Y Y cl ij+Xcl ijF ( r)2

Y clij F ( r )
Y clij F ( r ) 
Y cl ij F ( v )
Y cl ij F
η(β ) η(β ) updating rules for normalized cases
+λIF ( r)2
Si,j−k+1 β−2 i,j Xcl ij β−1 i,j Xcl ij β−1
← g(v ) Icl k
( rI c ) Ic i,j−k+1 g(r ) Scl j−k+1 g(r ) Scl j−k+1 g(v ) Icl j−k+1 g(v ) Icl j−k+1
( rS ) Si,j−k+1
←g(r ) Sclk
←F ( v ) Ic ik
←g(v ) Icl k
∗ g(v ) Icl
( rI c ) Ic i,j−k+1
←F ( r ) Sik cl ij F ( v )
β−2 cl ij
β−2 cl ij
β−2 clij
β−2 cl ij
F ( r )
Si,j−k+1
Ic i,j−k+1 cl ij
Ic i,j−k+1
Si,j−k+1
F
Ic g(v ) Icl k
Sik
+λS
F cl ij
Ic ik
β−2 l,j l,j
Ic ik
+λI
( 24 )
( 25 )
Sik
Sik c,l,j c,l,j i,l,j i,l,j
+ γS
+ γI
+ γS
+ γI
Ic ik
η(β )
η(β ) cl ij
Scl
F ( r ) Sik
F ( v ) Ic ik g(r ) Scl k g(v ) Icl k
The complexity of this multi group OSC NMF can be analyzed similarly as our analysis in previous sections , thus we omit the details here . Note that when facing with large data groups , we can also adopt the stochastic learning scheme .
4 . EXPERIMENTS
In this section we present the experimental evaluation re sults for OSC NMF and its variants .
457 ( a ) Sample 1
( b ) Sample 2
( c ) Sample 3
Figure 3 : Synthetic data set I . There are three samples {Xi}3 black dots to denote value 1 , and the 4 types of temporal patterns are shaded with different colors . i=1 of size 30 × 120 with binary values . We use
( a ) GOSC NMF
( b ) GOSC NMF IN
( c ) GOSC NMF TN
Figure 4 : Detected patterns . GOSC NMF TN algorithm can identify all four types successfully .
4.1 Synthetic Data
We generated two synthetic data sets to validate the effectiveness of the proposed methods . The first one is designed to test whether Group OSC NMF series methods can detect common temporal patterns contained in the data samples . The data set is illustrated in Fig 3 , which is composed of one group of three data samples with size 30 × 120 . There are four types of common patterns present in the data samples indicated by windows of different color in Fig 3 . These samples are binary , with black dots representing 1 .
The following algorithms were applied to this first syn r=1 are randomly initialized . thetic data set to evaluate their effectiveness . ( 1 ) Group OSC NMF ( GOSC NMF ) . The algorithm is introduced in section 3.3 with β = 0.5 , R = 11 , λ1 = λ2 = 0 . All {F(r ) , g(r)}R ( 2 ) Group OSC NMF with Individual Normalization ( GOSC NMF IN ) . The algorithm is the same as in GOSCNMF except that we use normalization invariant updates with individual normalization introduced in section 3.3 , and λS = λI = 05 ( 3 ) Group OSC NMF with Total Normalization ( GOSCNMF TN ) . The algorithm is the same as in GOSC NMFIN except we use normalization invariant updates with total normalization introduced in section 3.3 , and λS = λI = 05 For all three algorithms , we set the window length to m =
7 and the number of iterations to T = 100 .
Fig 4 shows the learned patterns by those algorithms . Fig 4(a ) shows the patterns learned by simple GOSC NMF , from which we can see that all of them are null patterns . This is because the three original data samples are all very sparse . By convolving those null patterns over the time axis we get a zero matrix , and the total β divergence ( β = 0.5 ) between the data samples to this zero matrix is very small . This makes GOSC NMF trapped in this local optimum .
Fig 4(b ) demonstrates that sparse GOSC NMG with individual normalization correctly learns two repeating patterns appearing in the original data samples , while Fig 4(c ) shows that sparse GOSC NMG with total normalization correctly learns all temporal patterns . It can be observed that by adding the sparsity regularizations , the learned patterns are much better . More interestingly , we can see that GOSCNMF TN identify all 4 patterns .
( a ) MGOSC NMF IN
( b ) MGOSC NMF TN
Figure 6 : Group Patterns Discovery : MGOSCNMF TN can successfully identify all patterns including shared pattern ( red , first row ) and all individual patterns from each group ( row 2 4 ) .
The second data set is designed to test whether our multigroup OSC NMF series algorithms introduced in section 3.3 can detect both common and individual temporal patterns contained in different data groups . The data is shown in Fig 5 . We tested three algorithms : ( 1 ) MGOSC NMF . Simple multi group OSC NMF with λS = λI = 0 ; ( 2 ) MGOSCNMF IN . MGOSC NMF with individual normalization , and λS = λI = 0.5 ; ( 3 ) MGOSC NMF TN . MGOSC NMF with total normalization , and λS = λI = 05 For all three methods , we set β = 0.5 , T = 100 , R = V = 4 . All pattern images and convolution coefficients are randomly initialized . The results are shown in Fig 6 , from which we can make similar observations as in Fig 4 . We do not show the learned patterns from simple MGOSC NMF because all of them are zero . MGOSC NMF IN can learn a rich set of pattern images , but not all of them are correct . Finally MGOSC NMFTN correctly learns all individual and common patterns .
X1X2X3FFFFSFIc=1FIc=2FIc=3FSFIc=1FIc=2FIc=3458 Figure 5 : Synthetic data set II . Each row is a data group containing three data samples . All three data groups share a common temporal pattern shaded in red color , while the data within each group has one individual pattern shaded in different colors . 4.2 Real World Data
The real world dataset consists of records from 21K diabetes patients collected over a period of up to one year . The patients are stratified into three groups A , B , and C based on their specific type of diabetes diagnosis using ICD9 code . Group A ( with size 16K ) consists of patients with no complications , group B ( with size 4,925 ) consists of patients with chronic disease complications , and group C has patients ( with size 254 ) with acute complications . To evaluate the clinical relevance of the temporal patterns mined by our algorithm , we treat the diagnoses as labels . We then use the mined temporal patterns as additional features for predicting the diagnoses , and compare the performance against a baseline classifier using the aggregate clinical features without consideration of any temporal relations . The hypothesis is that if the temporal patterns mined by our algorithm indeed contain useful clinical information , then their inclusion should improve the classification performance .
For all three groups , 30 different event conditions were selected as being relevant to the progress of diabetes based on consultations with physicians . The events fall into four different groups : medical procedures ( CPTs ) , lab results ( LABS ) , primary care physician visits ( PCP ) , and visits to various specialists ( SPEC ) . One typical patient EHR example is shown in Fig 1 . We show some examples of repeating patterns ( with one week window length ) for each group in Fig 7 , which have been identified manually by domain experts . Note that in this case , each patient is represented by a 30 × T matrix , where T = 365 , and the total patient population is represented by 21k such matrices , and we adopt the stochastic learning strategy for learning the patterns .
To quantitatively evaluate the performance , we randomly selected 70 % of the data samples from each group to form the training set , and used the rest data for testing . In this experiment , we set β = 0.5 and T = 10000 . The minibatch size when performing stochastic learning was set to 20 . We applied OSC NMF series methods to construct different feature representations for the data and then used Nearest Neighbor ( NN ) classifier ( with Euclidean distance ) to classify the test samples . We repeated the experiments 50 times using random partitioning , and report the average classification accuracy compared against the baseline ( which is the performance using aggregate clinical features alone , with no considerations of any temporal relations ) .
Both single group ( GOSC NFM IN and GOSC NMF TN ) and multi group ( MGOSC NMF IN and MGOSC NMF TN )
Figure 7 : Patient samples from three groups . Shaded windows are manually identified clinical patterns . Red are common patterns across three groups . The other colors are group specific patterns . series were tested . For GOSC NMF IN and GOSC NMFTN , the algorithms were applied to all training data each time and R = 30 patterns were learned ( null patterns were discarded ) . Each sample was then represented by a 30 ( or less if there are zero patterns ) dimensional vector with the value on each dimension equal to the sum of the convolution coefficients g of the corresponding pattern on this sample . This is very similar to the bag of words representation for text data . For MGOSC NMF IN and NGOSCNMF TN , we learned both common and individual patterns for all groups , and discarded the common patterns ( since they are not important for classification across groups ) , using only the individual patterns to construct the dictionary . We set the number of patterns R = V = 30 and discarded the null patterns . Thus each sample was represented by a 90 ( or less ) dimensional vector . For comparison purpose , we also implemented Group and Multi Group PrefixScan [ 22 ] ( G PrefixScan and MG PrefixScan ) , ie , we use a sliding window ( with the same length as we used for OSC NMF methods ) to segment the patient record sequence into a set of overlapping transactions , and then apply PrefixScan to mine frequent item sets from all these transactions . For G PrefixScan , we mine 30 most frequent patterns from all training data , while for MG PrefixScan , we mine 30 most frequent patterns for the training data in each class . Then we also construct the bag of pattern matrix for each patient
Xc=1,1Xc=2,1Xc=3,1Xc=1,2Xc=2,2Xc=3,2Xc=1,3Xc=2,3Xc=3,3Fc=1Fc=2Fc=3459 when 1 β 2 , where αk 0 and holds when
α(r ) ijk = g(r ) j−k+1F ( r ) ik / r k k αk = 1 . The equality g(r ) j−k+1F ( r ) ik
On the other hand , when β < 1 , f ( x ) = xβ is concave , and we have that [ 27 ] for any z , f ( x ) f(z)(x − z ) + f ( z ) . Therefore in this case r k ij
Y β ij
βZβ−1 j−k+1F ( r ) g(r ) ik − Zij
The equality holds whenZij = Yij = k g(r ) β ik −Zij ik . Similarly , f ( x ) = −xβ is convex , if β < 1 ; and it is concave , if β 1 . Hence −Y β
−Zβ
+ Zβ ij
( 26 ) j−k+1F ( r )
−βZβ−1 if β < 1 ij , r j−k+1F ( r ) k g(r ) ( r ) j−k+1F ( r ) ijk
( r ) ik
α g
,
 if β 1
Now let ’s define the following terms for notational convenience . ij r r r k ij ij ijk k α(r )
−
P β ij ( F , α ) = ij ( F , Z ) = βZβ−1 Qβ
 ( β − 1)Qβ

¯F β−1
( β − 1)P β ( β − 1)P β
W β ( F , α , Z ) =
Zβ−1
¯F β−2
= ik ij ij j j ik where Iβ ij ( F , α , Z ) =
∂W(F , α , Z )
∂F ( r ) ik
α(r ) ijk r k ik /α(r ) j−k+1F ( r ) g(r ) g(r ) j−k+1F ( r )
+Zβ ij ijk
β ik −Zij
/β(β − 1 ) ij + Iβ X β ij ( F , α , Z ) ij ( F , Z)−βXijP β−1 ij ( F , α)−βXijP β−1 ij ( F , α)−βXijQβ−1 ij ij ij
( 27 )
( F , α ) , β < 1 ( F , α ) , 1 β 2 ( F , Z ) , β > 2
¯gβ−1 j−k+1 ¯α2−β ,¯Fik ¯gj−k+1− ¯αijkXij , else ijk − Zβ−2 ijk Xij ¯gj−k+1Xij ij
¯gj−k+1− ¯F β−2 j−k+1 ¯α1−β ¯gβ j−k+1 ¯α1−β j ¯gβ−1 ijk ik
, β < 1
, β > 2
We designed the following function
Consequently , if we treat W(F , α , Z ) as a function of F , we have ik , ¯gk = g(r ) where to avoid the notational clutter , we use an overhead bar to replace the superscript ( r ) , ie , ¯Fik = F ( r ) k , ¯αijk = α(r ) ijk . In the following we will use these two symbols interchangablly .
Then the Hessian matrix
−δk,k i,i ( β − 2 ) ¯F β−3 k ¯gβ−1 i,i ( β − 1 ) δk,k i,i ¯F β−3 j−k+1 ¯α1−β j ¯gβ−1 ¯f β ijk , fl 1 , δk,k ¯F β−2 j−k+1 ¯α1−β ¯gβ ijk , δk,k i,i =
∂W(F , α , Z ) ik ∂F ( r ) ∂F ( r ) ik if i = i , k = k otherwise j−k+1 ¯α2−β ijk Xij , β < 1
 where
( 28 ) ijk
=
0 , ik ik ik j ijk = ( β − 1 ) ¯Fik ¯gj−k+1−(β − 2 ) ¯αijkXij f β and ( 29 ) Thus W(F , α , Z ) is convex with respect to F , whose minumum value can be achieved at the point when ∂W(α , Z , F)/∂F = O , from which we can get
1 β 2 β > 2
 j Xij ¯gβ−1 j Zβ−1 j Xij ¯gβ−1
, j ¯gβ j Xij ¯gj−k+1Zβ−2 j−k+1 ¯α1−β j ¯gβ j−k+1 ¯α2−β ijk ¯gj−k+1 j−k+1 ¯α2−β j−k+1 ¯α1−β ijk ijk ijk ij ij
1
2−β
1
β−1
∗
=
F ( r ) ik
,
β < 1
1 β 2
( 30 )
, β > 2
Therefore for any specific α , Z , we have W(F∗ , α , Z ) W(F , α , Z ) . Now let ’s treat W(F∗ , α , Z ) as a function of α , Z , we know that its minimum can be achieved with
∗
=
α(r ) ijk r j−k+1F ( r)∗ g(r ) k g(r ) j−k+1F ( r)∗ ik ik
, Z∗ ij = r k j−k+1F ( r)∗ g(r ) ik
( 31 )
Figure 8 : Common and individual patterns are correctly identified by MGOSC NMF TN with one week window length . Row 1 are two common patterns , and row 2 4 are group specific patterns . Besides the 5 known patterns , MGOSC NMF TN also reveals some unknown patterns , which can potentially lead to new clinical discovery .
( each patient is a 30 dimensional vector with the value on each dimension representing the number of times the corresponding pattern appears within the patient records ) for classification .
Table 1 shows the averaged classification performance measured by Areas Under the Curve ( AUC ) with pattern window length set to one week , two weeks and one month . The results show that ( 1 ) the classification performances with the inclusion of temporal pattern based features are indeed much better compared to the baseline representation ; ( 2 ) longer window patterns are more effective , which is likely due to the fact that the progression of diabetes is slow , making the patterns more salient when we increase the window length ; ( 3 ) multi group methods tend to perform better , as they extract more discriminative patterns for each group ; ( 4 ) our matrix approximation based approaches perform better than traditional PrefixScan type methods .
5 . CONCLUSION
In this paper we propose an One Sided Convolutional Nonnegative Matrix Factorization ( OSC NMF ) approach for temporal pattern discovery in longitudinal clinical records . We present how to adapt OSC NMF to extract patterns from one data sample , a group of data samples and multiple groups of data samples . The experimental results on both synthetic and real world data sets are presented to demonstrate the effectiveness of the proposed approaches . Appendix : Convergence Proof With Y defined in Eq ( 8 ) , we can expand dβ ( X , Y ) using Eq ( 2 ) . For a power function f ( x ) = xβ with β 1 , f ( x ) is convex ; otherwise f ( x ) is concave . Therefore , when β 1 , we have the following conclusion according to Jensen ’s inequality
Y β ij = g(r ) j−k+1F ( r ) ik
α(r ) ijk r k r k
β
 g(r ) j−k+1F ( r ) ik
α(r ) ijk
β
FSFIc=1FIc=2FIc=3460 Table 1 : Averaged AUC Values
1 Week
Baseline
0.5703 ± 0.1236 0.5971 ± 0.0536 G PrefixScan 0.6002 ± 0.0484 MG PrefixScan 0.5996 ± 0.0408 GOSC NMF IN 0.6004 ± 0.0506 GOSC NMF TN 0.6147 ± 0.0374 MGOSC NMF IN MGOSC NMF TN 0.6208 ± 0.0406
2 Weeks
0.5703 ± 0.1236 0.6018 ± 0.0479 0.6021 ± 0.0369 0.6045 ± 0.0458 0.6152 ± 0.0352 0.6436 ± 0.0405 0.6377 ± 0.0370
1 Month
0.5703 ± 0.1236 0.6208 ± 0.0405 0.6230 ± 0.0410 0.6219 ± 0.0347 0.6218 ± 0.0376 0.6386 ± 0.0350 0.6417 ± 0.0290
2 Months
0.5703 ± 0.1236 0.6227 ± 0.0317 0.6231 ± 0.0420 0.6223 ± 0.0258 0.6315 ± 0.0308 0.6432 ± 0.0324 0.6440 ± 0.0312
Therefore J ( F∗ , g ) = W(F∗ , α∗ , Z∗ ) W(F∗ , α , Z ) . Actually if we combine Eq ( 30 ) and Eq ( 31 ) together , we obtain g(r ) j−k+1 ij
( 32 )
t t j=1 Xij Y β−2 j=1 Y β−1 g(r ) j−k+1 ij
η(β ) ik ← F ( r ) F ( r ) ik where η(β ) is defined as in Eq ( 10 ) . current iteration step is from t to t + 1 , then we have
In this way , assume the
J ( F(t + 1 ) , g ) = W(F(t + 1 ) , α(t + 1 ) , Z(t + 1 ) ) W(F(t + 1 ) , α(t ) , Z(t ) ) W(F(t ) , α(t ) , Z(t ) ) = J ( F(t ) , g )
Thus with the updating rules , the objective is monotonically decreasing , and clearly it is lower bounded by 0 , thus the iterations will converge to a stationary point .
6 . REFERENCES [ 1 ] I . Batal , L . Sacchi , R . Bellazzi , and M . Hauskrecht . A temporal abstraction framework for classifying clinical temporal data . In AMIA , pages 29–33 , 2009 .
[ 2 ] S . Bengio , F . Pereira , Y . Singer , and D . Strelow . Group sparse coding . In NIPS , 2009 .
[ 14 ] D . D . Lee and H . S . Seung . Algorithms for Non negative Matrix Factorization . In NIPS 13 , pages 556–562 , 2001 .
[ 15 ] J . Lin , E . Keogh , S . Lonardi , and B . Chiu . A symbolic representation of time series , with implications for streaming algorithms . In Proceedings of the 8th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery , pages 2–11 , 2003 .
[ 16 ] J . Mairal , F . Bach , J . Ponce , and G . Sapiro . Online
Learning for Matrix Factorization and Sparse Coding . Journal of Machine Learning Research , 11:10–60 , 2010 .
[ 17 ] F . M¨orchen and A . Ultsch . Efficient mining of understandable patterns from multivariate interval time series . DMKD , 15(2):181–215 , 2007 .
[ 18 ] M . Mørup , M . N . Schmidt , and L . K . Hansen . Shift invariant sparse coding of image and music data . Technical report , 2008 .
[ 19 ] P . N . E . Nohuddin , F . Coenen , R . Christley , and
C . Setzkorn . Detecting temporal pattern and cluster changes in social networks : A study focusing uk cattle movement database . In IFIP Advances in Information and Communication Technology , pages 163–172 , 2010 .
[ 20 ] G . Nor´en , J . Hopstadius , A . Bate , K . Star , and I . Edwards .
Temporal pattern discovery in longitudinal electronic patient records . DMKD , 20(3):361–387 , 2010 .
[ 3 ] B . Cao , D . Shen , J T Sun , X . Wang , Q . Yang , and
[ 21 ] P . D . O’Grady and B . A . Pearlmutter . Discovering
Z . Chen . Detect and Track Latent Factors with Online Nonnegative Matrix Factorization . In Proceedings of the 20th IJCAI , pages 2689–2694 , 2007 .
[ 4 ] M . Cooper , T . Liu , and E . Rieffel . Video Segmentation via
Temporal Pattern Classification . IEEE TMM , 9(3):610–618 , 2007 . convolutive speech phones using sparseness and non negativity . In ICA , 2007 .
[ 22 ] J . Pei , J . Han , B . Mortazavi Asl , J . Wang , H . Pinto ,
Q . Chen , U . Dayal , and M . Hsu . Mining sequential patterns by pattern growth : The prefixspan approach . IEEE TKDE , 16(11):1424–1440 , 2004 .
[ 5 ] S . de Amo and D . A . Furtado . First order temporal pattern
[ 23 ] C . Plaisant , S . Lam , B . Shneiderman , M . S . Smith , mining with regular expression constraints . Data & Knowledge Engineering , 62(3):401–420 , 2007 .
[ 6 ] X . Du , R . Jin , L . Ding , V . E . Lee , and J . H . T . Jr .
Migration motif : a spatial temporal pattern mining approach for financial markets . In KDD , pages 1135–1144 , 2009 .
[ 7 ] J . Eggert and E . K¨orner . Sparse coding and nmf . In
IJCNN , pages 2529–2533 , 2004 .
[ 8 ] J . Fails , A . Karlson , L . Shahamat , and B . Shneiderman . A Visual Interface for Multivariate Temporal Data : Finding Patterns of Events across Multiple Histories . In Visual Analytics Science And Technology , 2006 IEEE Symposium On , pages 167–174 , 2006 .
[ 9 ] C . F´evotte and J . Idier . Algorithms for nonnegative matrix factorization with the beta divergence . arXiv:1010.1763 , 2010 .
D . Roseman , G . Marchand , M . Gillam , C . Feied , J . Handler , and H . Rappaport . Searching electronic health records for temporal patterns in patient histories : a case study with microsoft amalga . In AMIA , pages 601–605 , 2008 .
[ 24 ] M . Robert Moskovitch and Y . Shahar . Medical temporal knowledge discovery via temporal abstraction . In AMIA , pages 452–456 , 2009 .
[ 25 ] B . R . Shah , J . Drozda , and E . D . Peterson . Leveraging observational registries to inform comparative effectiveness research . American Heart Journal , 160(1):8–15 , 2010 .
[ 26 ] P . Smaragdis . Non negative matrix factor deconvolution ; extraction of multiple sound sources from monophonic inputs . In ICA , pages 494–499 . 2004 .
[ 27 ] H . A . Varian . Microeconomic Analysis Third Edition .
WW Norton and Company , 1992 .
[ 10 ] R . Grosse , R . Raina , H . Kwong , and A . Y . Ng .
Shift invariant Sparse Coding for Audio Classification . In UAI , 2007 .
[ 28 ] F . Wang , C . Tan , P . Li , and C . K¨onig . Efficient document clustering via online nonnegative matrix factorization . In Proceedings of the 11th SDM , 2011 .
[ 11 ] J . Han , J . Pei , Y . Yin , and R . Mao . Mining Frequent
[ 29 ] T . Wang , C . Plaisant , A . Quinn , R . Stanchak ,
Patterns without Candidate Generation : A Frequent Pattern Tree Approach . DMKD , 8(1):53–87 , 2004 .
[ 12 ] P . O . Hoyer . Non negative matrix factorization with sparseness constraints . JMLR , 5:1457–1469 , 2004 .
[ 13 ] D . D . Lee and H . S . Seung . Learning the parts of objects by non negative matrix factorization . Nature , 401(6755):788–791 , 1999 .
B . Shneiderman , and S . Murphy . Aligning temporal data by sentinel events : Discovering patterns in electronic health records . In Proc . of ACM Conference on Human Factors in Computing Systems , pages 457–466 , 2008 .
[ 30 ] M . J . Zaki . Spade : An efficient algorithm for mining frequent sequences . Machine Learning , 42:31–60 , 2001 .
461
