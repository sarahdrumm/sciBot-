Overlapping Decomposition for Causal Graphical Modeling
Lei Han† , Guojie Song† ∗ , Gao Cong‡ , Kunqing Xie†
†Key Laboratory of Machine Perception ( Ministry of Education ) , EECS , Peking University , China
‡School of Computer Engineering , Nanyang Technological University , Singapore
{hanlei , gjsong , xkq}@cispkueducn gaocong@ntuedusg
ABSTRACT
Causal graphical models are developed to detect the dependence relationships between random variables and provide intuitive explanations for the relationships in complex systems . Most of existing work focuses on learning a single graphical model for all the variables . However , a single graphical model cannot accurately characterize the complicated causal relationships for a relatively large graph . In this paper , we propose the problem of estimating an overlapping decomposition for Gaussian graphical models of a large scale to generate overlapping sub graphical models . Specifically , we formulate an objective function for the overlapping decomposition problem and propose an approximate algorithm for it . A key theory of the algorithm is that the problem of solving a k + 1 node graphical model can be reduced to the problem of solving a one step regularization based on a solved k node graphical model . Based on this theory , a greedy expansion algorithm is proposed to generate the overlapping subgraphs . We evaluate the effectiveness of our model on both synthetic datasets and real traffic dataset , and the experimental results show the superiority of our method .
Categories and Subject Descriptors
G.3 [ Mathematics of Computing ] : Probability and Statistics
Keywords
Causality , Graphical Model , Overlapping Decomposition
1 .
INTRODUCTION
Causal graphical models are established to meaningfully characterize causal or statistical relationships that exist among variables of interest and quantify them . The problem of characterizing the causal relationships between variables in complex systems , such as economics , biological systems , traffic systems , climate change , etc . , is important and fundamental . For example , economists want to know whether burning natural gas is a causal factor for the global warming .
∗Corresponding author . Email : gjsong@cispkueducn
The Gaussian graphical model [ 7 ] , which learns the causalities between variables through their covariance , is one of the most promising causal modeling methods . It has been successfully employed in many applications , such as mining the causalities of climate attributes [ 2 ] , gene regulatory network discovery [ 5 ] , etc . In addition , several causal models on temporal evolving graphs have been proposed with applications in cross species gene expression analysis [ 11 ] , oil production equipment stage capture [ 10 ] and climate research [ 12 ] .
These methods construct a single graphical model to capture all the causalities between variables , treating all the variables together . They are typically developed for a small number of variables ( usually in the order of tens ) . We will discuss theoretically in Section 4.2 that learning causalities through a single Gaussian graphical model by the variable covariance will be inaccurate , when large number of variables are considered and small number of observations are available . As a matter of fact , a causality model with only 20 variables can be overwhelming and difficult to interpret at a global level [ 1 , 15 ] . Worse still , it is much more challenging to understand and construct causal relationships using causal graphical models for a relatively large graph ( eg , with hundreds of variables ) , although many applications need to deal with large graphs with heterogenous and complicated relationships . For instance , a highway network in traffic systems often contains hundreds of sample nodes , whose observations are counts of passing vehicles collected by sensors . In such traffic networks , complicated causalities exist between the vehicle counts .
Therefore , it is essential to develop techniques to discover such causalities in a large network . To cope with the challenging problem , we propose to decompose a large graphical model into multiple overlapping sub graphical models . For decomposing a graphical model , it is important to consider both the heterogeneity and homogeneity , where heterogeneity means the local causalities and homogeneity refers to the overlaps between sub graphical models . For example in traffic systems , some crucial traffic nodes may highly correlate with several different local regions , and thus these important nodes should be considered as overlap ( homogeneity ) by these local regions ; meanwhile , we also need to find the causalities within a region ( heterogeneity ) .
Unfortunately , decomposing graphical models is NP hard [ 15 ] even if overlaps are not allowed . When we allow overlaps , the decomposition problem becomes more challenging because the search space becomes larger , which is due to more combinations of subgraph structures than those in the non overlapping case .
In this paper , we address the challenging problem of estimating an overlapping decomposition for Gaussian graphical models of a large scale . We propose a novel approximation algorithm with performance guarantee , which is based on a local subgraph expansion
114 strategy . Specifically , we first formulate the optimization problem with an objective function comprising the negative log likelihood of the observations of Gaussian sub graphical models and some penalized items to constrain the structure of the subgraphs . Unfortunately , the penalized log likelihood methods [ 4 , 19 ] in Gaussian graphical model cannot be used to solve the approximation problem . Instead , we propose an algorithm that starts with the initial small subgraphs and incrementally computes the new Gaussian graphical model when a new node is involved .
One key technique is that we prove that the problem of solving a k + 1 node graphical model can be reduced to the problem of solving a one step regularization based on a solved k node graphical model , referred to as additive expanding property . We study the correctness and accuracy of this technique with detailed analysis . Based on the technique , we propose a greedy expansion algorithm for generating the overlapping sub graphical models .
We evaluate the proposed method with two sets of experiments : First we empirically verify the properties of the proposed overlapping decomposition method on synthetic networks , and compare with the single graphical model [ 4 , 19 ] and the non overlapping decomposition method ( which is a special case of the proposed overlapping decomposition method ) . The experimental results demonstrate the advantages of our techniques . Second , we evaluate the proposed techniques on real life traffic data by learning the causalities between traffic observation points ( eg , a on ramp ) and detecting the traffic regularity in large traffic networks , which is essential for traffic analysis .
In summary , our main contributions are four fold :
1 . We formulate an objective function for the problem of overlapping decomposition of graphical model , and reduce the problem to a local subgraph expansion problem .
2 . We extend the penalized log likelihood in Gaussian graphical model to satisfy an additive expanding property and demonstrate its correctness and accuracy with detailed asymptotic analysis .
3 . We propose a constrained greedy subgraph expansion algo rithm for generating the overlapping subgraphs .
4 . We evaluate our method on both synthetic and real life traffic data . Experimental results show the effectiveness and superiority of our overlapping decomposition theory .
The rest of this paper is organized as follows . In Section 2 , we briefly review closely related work . Section 3 presents the preliminaries and the problem statement . In Section 4 , we present the proposed method including two core techniques and a demonstration . Experimental studies are reported in Section 5 . We conclude this paper and present future directions in Section 6 .
2 . RELATED WORK
Most of existing work on causal graphical models builds a single graphical model . This renders them impractical to relatively large graphs ( with more than hundreds of nodes ) . To cope with larger set of time series variables , Ruan et al . [ 15 ] propose to cluster time series variables into groups such that strong causal relations appear only between time series within a group while the causal relation between inter group variables is weak . The clustering problem is formulated as a regression coefficient sparsification problem for graphical model decomposition . However , the approach [ 15 ] only considers non overlapping decompositions while ignoring the overlap between subgraphs , which exists in many real world applications . Moreover , the approach [ 15 ] is developed for time series variables , and is based on the Vector Autoregressive model , a type of temporal graphical model , rather than Gaussian graphical model as we use .
Our work is closely related to the joint estimation methods for multiple graphical models that share common structures [ 3 , 6 ] . The joint estimation methods [ 3,6 ] are proposed to learn multiple graphical models on the data from different categories but with the same set of features ( variables ) , considering both the underlying homogeneity and heterogeneity of networks . They estimate multiple graphical models for different categories of the features , but not decomposing the features themselves . We proceed to use the example application scenario [ 3 ] to illustrate these methods . Consider a set of webpages collected from computer science departments of universities , and we want to find the causalities between selected keywords ( eg , "book" , "model" , "problem" , etc . ) appearing in the collection . These keywords can be treated as features , and appear in webpages of different categories , such as "student" , "faculty" , "project" , etc . These features may display different dependence structures for different categories while sharing some common causalities across categories . The joint estimation methods cannot be applied to solve our problem , and they cannot be employed to discover the complicated causal relationships in large feature networks . First , these methods do not consider the decomposition on features of a large graph . Second , these methods are developed for graphs with a small number of features ( in the order of tens ) .
Our proposed approach is also related to detecting overlapped community structures [ 9 ] . Community structure detection aims to group similar nodes together based on known distance measurements of nodes or correlations among nodes themselves . In contrast , in our problem we aim to uncover the causalities among correlated nodes , and furthermore find subgraphs based on the discovered causalities but not the known properties of nodes themselves . Thus , our problem is essentially different from community structure detection .
3 . PRELIMINARY AND PROBLEM STATE
MENT
3.1 Preliminary : Gaussian graphical model i , , xn
As a member of the causal graphical model , Gaussian graphical model(GGM ) assumes the joint distribution of the variables to be Gaussian . In GGM , the dependence structure ( or causality ) is determined from the covariance matrix of the variables , and a natural way to evaluate the causalities is to estimate the inverse of the covariance matrix [ 7 , 8 , 18 ] . Consider p random variables X = ( x1 , , xp ) , each variable xi having n observations xi = ( x1 i )T , where we usually have n ≫ p . Without loss of generality , we assume X follows a multivariate Gaussian distribution N ( µ , Σ ) , where the mean vector µ is p dimensional and each element in covariance matrix Σ is the expected value Σij = E[(Xi−µi)(Xj−µj ) ] . The causality matrix Ω is the inverse of the covariance matrix , ie , Ω = Σ−1 . There exists a causal relationship between variables xi and xj iff Ωij 6= 0 [ 7,18 ] . Therefore , the key problem is to calculate Ω . The estimation of Ω can be obtained by minimizing the penalized log likelihood criterion [ 4 , 19 ] , tr(bΣΩ ) − log |Ω| + λXi6=j
|θij|
( 1 ) bΩ = arg min
Ω where θij is the element in Ω ; bΣ is the sample covariance matrix estimated on input X ; | · | and tr(· ) are the determinant and the trace in matrix calculus , respectively ; λ is a tuning parameter .
115 negative log likelihood of the observations of a Gaussian graphi
The part tr(bΣΩ ) − log |Ω| of Equation 1 corresponds to the cal model . The part λPi6=j |θij| is called a ℓ1 penalty , which is to shrink some of the off diagonal elements inbΩ to zero . The tuning parameter λ controls the sparsity ofbΩ . This minimization problem can be solved efficiently by the graphical lasso algorithms proposed in [ 4 , 19 ] .
3.2 Problem Definition Problem Definition : Given p random variables X = ( x1 , , xp ) , where p is large and each variable xi has n observations , xi = ( x1 i )T , we aim to learn the causal relationships between these variables . i , , xn
In other words , we aim to encode the structure of X with an undirected graph G = ( V , E ) , where each node v in V = {v1,··· , vp} corresponds to a variable in X . The edge set E indicates the causalities between any two variables . More precisely , if xi is correlated to xj , then edge eij is included in E . Thus , our objective is to obtain E . As introduced in Section 3.1 , E can be constructed by estimating the causality matrix Ω of X . We add an edge eij to E iff Ωij 6= 0 . Instead of creating a single Gaussian graphical model for G , we propose to construct K Gaussian sub graphical models with overlaps to discover the causalities between variables . Each subgraph , corresponding to a Gaussian sub graphical model , is denoted as gi = ( SVi , SEi ) , 1 ≤ i ≤ K . The causal relationships reflected The challenge is to generate the K sub graphical models and estimate Ωi for each SEi . To achieve this , we proceed to define a new objective function , which helps to formulate the decomposition problem clearly . We first introduce some notations : K vectors {Γ1,·· · , ΓK} , where each 1 × p vector Γi represents the component of a subgraph gi . Element γij in Γi is 1 if node j appears in subgraph gi , and 0 otherwise . In addition , we set j=1 γij ≥ p , because we allow overlaps and we do not restrict that every node has to be included in at least one subgraph . This is reasonable because if a node is independent from all others , it should be left alone . in E , E =Si SEi , are the output . i=1Pp PK
Objective function : We formulate the overlapping decomposition for a graphical model into the problem of estimating a set of Ωi by minimizing
{bΩi}K i=1 = arg min
{Ω1,··· ,ΩK }
λ1
KXi=1Xj6=k
|θi,jk| + λ2
KXi=1 {tr(bΣiΩi ) − log |Ωi|}+ KXi=1 kΓik2
′ kΓi ◦ Γi
1 + λ3Xi<i KXi=1
′k2 1 , kΓik1 ≥ p , ( 2 ) where θi,jk is the element in Ωi ; k · k1 is the ℓ1 norm ; ◦ means the Hadamard product ; λ1 , λ2 and λ3 are tuning parameters . st likelihood of the observations of Gaussian sub graphic model gi . The equation includes three penalized items :
In Equation 2 , tr(bΣiΩi ) − log |Ωi| represents the negative log• penalty λ1PK i=1Pj6=k |θi,jk| controls the sparsity of the • penalty λ2PK i=1 kΓik2
1 is a constraint on the size of each subgraph and balances them , because the sum of the square is small when the subgraphs have the similar size ; causalities in each subgraph ;
• penalty λ3Pi<i
′k2 1 gives a constraint on the sizes of overlaps and balances the sizes of overlaps , because the Hadamard product between any two Γi and Γi ′ denotes the common nodes they share .
′ kΓi ◦ Γi
Given p random variables X = ( x1 , , xp ) , and assume X is encoded with a large graph G , our problem of discovering the causality structures in G is formulated as finding a set of overlapped subgraphs based on Equation 2 .
Challenge and Solution Overview : The overlapping decomposition problem is a combinational optimization problem and it is NPhard even if the penalty factors are not considered [ 15 ] . The problem involves Kp+Kp2 unknown variables in the worst case , where {Γ1,··· , ΓK} needs Kp variables , and {Ω1,· ·· , ΩK} needs at most Kp2 variables . Note that {Ω1,··· , ΩK} needs fewer variables if we do not allow overlaps . Such a large number of unknown variables makes this problem computationally challenging . Moreover , we even do not know how to select a best K for this problem . Hence , instead of finding the optimal solution to the complicated function , we propose a novel approximation algorithm for solving the overlapping decomposition problem , called local subgraph expansion . Our algorithms adopt a bottom up strategy that expand the initial subgraphs by adding selected nodes gradually until the structure of overlapped subgraphs will reach convergence .
During this process , a key operation is to choose whether to include a new node in a subgraph . This operation is invoked many times , and calls for efficient techniques . Specifically , assume that there is a k node subgraph whose inner causal relationships have been detected . We want to know whether a node vk+1 should be added to it . A straightforward method is creating a new Gaussian graphical model on all the k + 1 nodes . However , this ignores the known causal relationships in the k node subgraph and is computationally expensive . Thus , a natural question is whether we can reuse the known causal relationships in a subgraph to detect the causal relationships between a new node and the subgraph . In the next section , we present the proposed approximation method with performance guarantees for the operation .
4 . PROPOSED METHOD
In this section , we propose two techniques . The first technique is generalized by a theorem in Section 41 This technique is used to check whether a new variable ( node ) should be included in a subgraph . The technique extends the penalized log likelihood criterion in Equation 1 so that it can be incrementally expanded to accommodate new nodes . We call it Additive Penalized Log likelihood Expansion ( APLE ) . In Section 4.2 , we also show the correctness and accuracy for APLE , which also motivate the necessity to decompose a large graphical model into sub graphical models from a theoretical view .
The second technique is a local greedy approach presented in Section 43 We define a fitness function based on APLE approach . Moreover , taking into account the constraints ( penalties in Equation 2 ) on the subgraph structures , we develop the Constraint Greedy Subgraph Expansion ( CGSE ) algorithm , which can achieve the local subgraph expansion process .
4.1 Additive Penalized Log likelihood Expan sion
Suppose that ℓ(Ω(k+1 ) ) is a new penalized log likelihood criterion computed by Equation 1 , which is from adding a new variable xk+1 into a solved penalized log likelihood criterion ℓ(Ω(k) ) ,
116 where
Ω(k+1 ) = Ω(k )
θT
θ
θk+1 and θ is a k × 1 causality vector between xk+1 and {x1 , , xk} which we want to get . Since Ω(k ) is already solved ( we assume it is solved by graphical lasso ) , it is positive definite [ 4 , 19 ] . Thus , θk+1 controls whether Ω(k+1 ) is positive definite , and determines the k+1 th eigenvalue of Ω(k+1 ) . Also we select θk+1 to guarantee Ω(k+1 ) positive definite .
Theorem 1 : Suppose bΩ(k ) is a local minimizer of ℓ(Ω(k) ) , then there exists a local minimizer of ℓ(Ω(k+1)),bΩ(k+1 ) , such thatbΩ(k+1 ) = ( bΩ(k),bθ(k) ) , where bθ(k ) is a local minimizer of min 2bεT θ +bεk+1θk+1 −log(θk+1 − θT · bΣ(k ) · θ ) + 2λθkθk1 where ( bε,bεk+1 ) is the sample covariance vector between xk+1 and
{x1 , , xk+1} . Proof : The new penalized log likelihood criterion ℓ(Ω(k+1 ) ) is
( 3 )
ℓ(Ω(k+1 ) ) = tr(bΣ(k+1)Ω(k+1 ) ) − log |Ω(k+1)| + λ
Compactly , we introduce three symbols to denote the items k+1Xi6=j
|θij|
I ( k+1 ) 1
I ( k+1 ) 2
I ( k+1 ) 3
= tr(bΣ(k+1)Ω(k+1 ) ) = log |Ω(k+1)| = λPk+1 i6=j |θij|
We unfold bΣ(k+1 ) and Ω(k+1 ) into block matrices to detect the relationship between ℓ(Ω(k+1 ) ) and ℓ(Ω(k) ) . The unfolded matrices are derived as
I ( k+1 ) 1
I ( k+1 ) 2
I ( k+1 ) 3
= λ
θ
θT
= I ( k )
θk+1 ) bεk+1 · Ω(k ) = tr( bΣ(k ) bε bεT bεT θ +bεk+1θk+1 ) = tr( bΣ(k)Ω(k ) +bεθT bΣ(k)θ + θk+1bε bεT Ω(k ) +bεk+1θT = tr(bΣ(k)Ω(k ) ) + tr(bεθT ) +bεT θ +bεk+1θk+1 1 + 2bεT θ +bεk+1θk+1 = logfifififi θk+1 fifififi = log ( |Ω(k)| · |θk+1 − θT ( Ω(k))−1θ| ) = I ( k ) 2 + log ( θk+1 − θTbΣ(k)θ ) k+1Xi6=j
3 + 2λkθk1
|θij| = I ( k )
Ω(k ) θT
θ by Leibniz formula . Finally , we can get wherebε and θ are k×1 vectors ; the derivation of I ( k+1 )
2 is obtained
ℓ(Ω(k+1 ) ) = ℓ(Ω(k))+
2bεT θ +bεk+1θk+1 − log ( θk+1 − θTbΣ(k)θ ) + 2λkθk1
( 4 )
2
Similarly , we use ℓ(θ(k ) ) to represent Equation 4 , then we have
ℓ(Ω(k+1 ) ) = ℓ(Ω(k ) ) + ℓ(θ(k ) )
( 5 )
Thus , it is understandable that to solve ℓ(Ω(k+1 ) ) based on a solved ℓ(Ω(k) ) , we just need to solve ℓ(θ(k ) ) for an additional problem . Note that Equation 3 is exactly a ℓ1 regularization problem which can be solved efficiently using the algorithms in [ 16,17 ] . has to be adapted corresponding to k as the expansion continues because parameter λθ must be selected appropriately to make sure
One should be noted that the correctness and accuracy ofbΩ(k+1 ) = ( bΩ(k),bθ(k ) ) has not been completely guaranteed by the above proof , ( bΩ(k),bθ(k ) ) equals the local minimizerbΩ(k+1 ) . In other words , λθ ( until subgraphs converge ) . Since λθ controls the sparsity of bθ(k ) , on kbθkk1 will become inappropriate which leads to the uncertainty ofbΩ(k+1 ) = ( bΩ(k),bθ(k) ) .
Thus , a new question raises that how to adapt λθ to make the evaluation accurate when the subgraph expands . In next subsection , we will discuss the asymptotic behavior of APLE and show how to select λθ to ensure the correctness and accuracy of Theorem 1 . if λθ stays unchangeable , when the subgraph expands , constraint
4.2 Asymptotic Analysis of APLE
Asymptotic property is crucial for APLE which makes sure that bΩ(k+1 ) can be obtained by bΩ(k ) and bθ(k ) separately under an ap propriate λθ . A detailed asymptotic analysis of Equation 1 has been discussed in [ 14 ] . Inspired by it , we establish the analysis to our APLE approach as follows .
A1 : There exists a constant η such that 0 < ϕmax(Ω(k )
Let the true causality matrix of ℓ(Ω ) be Ω0 , the true covariance matrix be Σ0 , Ω0 = ( Σ0)−1 , as well as true causality vector θ0 and true covariance vector ε0 . Let k · kF be the Frobenius norm . We make the following assumptions . 0 ) ≤ η , A2 : There exist constants σ1 and σ2 such that σ1 ≤ θk+1 ≤ σ2 ) ≤ η . where ϕmax(· ) denotes the maximum eigenvalue . will guarantee Ω(k+1 ) positive definite and ϕmax(Ω(k+1 ) ( Note that θk+1 determines the k + 1 th eigenvalue of Ω(k+1) ) .
0 n , C0 is a positive constant , then
Theorem 2 : Let bθ(k ) be the local minimizer in Equation 3 . Under A1 and A2 , if λθ = C0q log k kbθ(k ) − θ(k )
0 kF = OP r k log k n ! where OP ( · ) is the order in probability . Proof Let G(∆θ ) = ℓ(θ0 + ∆θ ) − ℓ(θ0 ) . Assume that there exists a bounded convex set
( 6 )
G = {∆θ : k∆θkF ≤ M rn} , where M is a positive constant and rn =r k log k n → 0 ( n ≫ k )
Note that G(∆θ ) is a convex function , if we demonstrate that G is strictly positive everywhere on the boundary ∂G ( k∆θkF = M rn ) , then G has a local minimum inside G . Actually ,
117 G(∆θ ) = ℓ(θ0 + ∆θ ) − ℓ(θ0 )
( 7 ) tion in proof of Theorem 1 that f ( θ ) = I ( k+1 )
For the subtraction of the logarithm terms in Equation 7 , assume
= 2bεT ∆θ − ( log ( θk+1 − ( θT
0 + ∆θ)bΣ(k)(θ0 + ∆θ ) ) 0 bΣ(k)θ0 ) ) + 2λθ(kθ0 + ∆θk1 − kθ0k1 )
− log ( θk+1 − θT that f ( θ ) = log ( θk+1 − θTbΣ(k)θ ) , we can get from the derivaf ( θ0 + ∆θ ) − f ( θ0 ) = ( log |Ω(k+1 ) + ∆(k+1)| − log |Ω(k+1 ) |)− 0 + ∆(k)| − log |Ω(k ) 0 | )
( log |Ω(k ) As has been proved by [ 14 ] , for Ω0 we have
− I ( k )
, therefore
2
2
0
0
0 where
= tr(Σ0∆ ) −e∆T [ Z 1 F = e∆T [ Z 1
0 log |Ω0 + ∆| − log |Ω0|
( 1 − v)(Ω0 + v∆)−1 ⊗ ( Ω0 + v∆)−1dv]e∆
( 1 − v)(Ω0 + v∆)−1 ⊗ ( Ω0 + v∆)−1dv]e∆ 1 4η2 k∆k2
≥
F
Thus we have f ( θ0 + ∆θ ) − f ( θ0 )
0 ∆(k) ) ) − ( F ( k+1 ) − F ( k ) )
0
= ( tr(Σ(k+1 ) ≈ 2εT
∆(k+1 ) ) − tr(Σ(k ) 0 ∆θ − ( F ( k+1 ) − F ( k ) )
Thus , we get
0 )∆θ + ( F ( k+1 ) − F ( k ) ) +2λθ(kθ0 + ∆θk1 − kθ0k1 ) For each item in G(∆θ ) we have the following boundaries
G(∆θ ) = 2(bεT − εT 0 )∆θ| ≤ C1r log k n k∆θk1 ≤ C1r k log k n k∆θkF
B1 : |(bεT −εT
1 4η2 ( k∆(k+1)k2
B2 : F ( k+1)−F ( k ) ≥ B3 : λθ(kθ0+∆θk1−kθ0k1 ) ≤ λθk∆θk1 ≤ λθ√kk∆θkF
F−k∆(k)k2
F ) ≥
1 2η2 k∆θk2
F where B1 is a boundary from [ 14 ] , and B3 can be obtained by mean inequalities . Combine all the above items and finally we can get
F − 2C1r k log k 2η2 − ( 2C1r k log k n k∆θkF − 2λθ√kk∆θkF + 2√kλθ)k∆θk−1
F ) n
1
G(∆θ ) ≥
1 2η2 k∆θk2
= k∆θk2 F ( Take λθ = C0q log k n ,
According to the theorem in [ 3 , 14 ] , under certain assumptions , local minimizerbΩ(k ) of Equation 1 satisfies
0 kF = OP ( r ( k + sk ) log k n kbΩ(k ) − Ω(k ) where sk is the count of non zero off diagonal elements in Ω(k ) ( sk = k(k−1 ) would give a full matrix ) . For a local minimizer
0
)
( 8 )
2 bΩ(k+1 ) , we have kbΩ(k+1 ) − Ω(k+1 )
0
Thus , combined with our Theorem 2 , it can be easily found
F ≈ kbΩ(k ) − Ω(k ) F + 2kbθ(k ) − θ(k ) k2 0 k2 0 k2
F
OP (
( k + sk ) log k
) + OP (
2k log k
) n n ( k + 1 + sk+1 ) log ( k + 1 )
)
≈ OP ( n since 0 ≤ sk+1 − sk ≤ 2k .
Theorem 1 has been guaranteed completely under Theorem 2 .
So , if bθ(k ) is a local minimizer of Equation 3 , we know that there exists a local minimizer bΩ(k+1 ) of ℓ(Ω(k+1 ) ) that ensures bΩ(k+1 ) = ( bΩ(k),bθ(k) ) . So far , the correctness and accuracy of
It is worth mentioning that both Equation 8 and our Theorem 2 are in line with the motivation of the decomposition on large scale graphical model . Note that both of them show that when the number of variables k is relatively large or exceeds the number of observations n of each variable , the error on the estimation will increase dramatically .
This suggests that , when we consider only a single graphical model on a large network , the result will be inaccurate especially when there are not enough observations to establish such a large graphical model . An example is that traffic systems often contain hundreds of ramps ( variables ) , and the number of the observations for each ramp is limited by the sampling quantity . The periodicity of traffic behaviors is often measured by days . Thus , if we want to know the causalities between observations at a specific time period in a day , we can just get one value for each ramp one day . Therefore , the decomposition of a large graphical model is necessary .
4.3 Constraint Greedy Subgraph Expansion
We present the algorithm for the local subgraph expansion process based on our APLE approach . We consider the constraints corresponding to the penalized items in Equation 2 , and apply them to the local subgraph expansion process in this subsection .
Add Constraints : When there is a new node ( variable ) xnew joint in a solved k node subgraph g to do expansion , based on APLE we can obtain a new causality vector bθnew = AP LE(g , xnew , λθ ) . Let E bθ = {i :bθi 6= 0 , 1 ≤ i ≤ k} , we define the fitness as
( 9 )
F itness(bθnew ) = e−γo |E bθ| k where o is the number of subgraphs to which node vnew has been mapped , and thus γ controls the degree of overlaps , which can be regarded as a constraint . With γ , we have that the causality contributions of vnew to other subgraphs reduce as the number of subgraphs to which vnew has already been mapped increases .
G(∆θ ) ≥ k∆θk2 F (
1 2η2 −
2C1 + 2C0
M
) for M sufficiently large we can get G(∆θ ) > 0 .
Because the fitness in Equation 9 is always nonnegative , a threshold ǫf should be given as the minimum accepted fitness , which is actually a constraint on the size of each subgraph .
2
After each iteration of expansion , we check whether there are
118 near duplicated subgraphs based on the following equation . max{|SVi ∩ SVj|
|SVi|
, |SVi ∩ SVj|
|SVj|
} > ǫo ,
( 10 ) where SVi is the set of edges in subgraph gi and SVj is for gj ; ǫo is the combination threshold .
We combine subgraphs gi and gj into a new subgraph if the above equation is satisfied . Here ǫo balances the sizes of overlaps .
Adaption of λθ : It has been mentioned above that as the subgraph expands , λθ has to be adapted to make APLE correct and accurate . According to Theorem 2 , we know that λ(k ) n , and thus when k expands to k + 1 , we have
θ = C0q log k =plogk ( k + 1)λ(k )
θ
λ(k+1 ) θ
= C0r log ( k + 1 ) n
( 11 )
5.1 Synthetic Data
L(R ) is the complexity of ℓ1 regularization method in [ 16 ] , which is logarithmic complexity with R [ 16 ] .
5 . EXPERIMENTAL STUDY
We evaluate the proposed overlapping decomposition of graphical model ( ODGM ) . We compare with the single graphical model(SGM ) , which is solved by the graphical lasso [ 4 ] . To further study the advantage of the overlapping decomposition , we adapt the proposed CGSE algorithm to support the non overlapping decomposition of graphical model ( NODGM ) by setting γ = +∞ in Equation 9 to forbid overlaps . We report results on synthetic datasets in Section 51 In Section 5.2 , we report the performance study on real life traffic dataset , and show the usefulness of the results for traffic analysis .
511 Setting i
Since we focus on graphical models of a relatively large scale , we generate a set of networks whose number of nodes , p , ranges from 100 to 900 . Note that previous work normally uses networks containing tens of nodes . We set the number of observations n = 800 . We follow the approach [ 6 ] to generate the synthetic data . To simulate the heterogeneity in large networks , we generate local centered network by K local Erdös Rényi random graphs {g1 , g2 , , gK} , gi = ( SVi , SEi ) ; for homogeneity we add edges between any gi and gj randomly . Specifically , 1 . We generate K Erdös Rényi graphs , each with a random size in |SVi| = p . Let Ecross be the set of cross i SEi be the set of total inner links . Let ρ = |Ecross|/|Einner| be a factor to control the homogeneity . We randomly add ρ|Einner| cross edges . i SVi
[ 20 , 80 ] , such thatPK links between the K graphs , and let Einner = SK Finally , we can get a network G = ( V , E ) , where V = SK and E = EinnerS Ecross . Aij = Σij = ( A−1)ij /p(A−1)ii(A−1)jj where U ( · ) represents uniform distribution . We scale the diagonal elements to ensure positive definiteness and average the matrix with its transpose to get a symmetric A . Then the covariance matrix Σ is calculated as
2 . Based on the above network , we create a covariance matrix following [ 13 ] . Define a p × p matrix A as
1 , U ( [−1 , −0.5 ] ∪ [ 0.5 , 1] ) , 0 ,
3 . We generate p dimensional samples from N(0,Σ ) . i = j ( i , j ) ∈ E Else
We define Precision , Recall and F1 score to measure the effectiveness of different models in finding the causal relationships . Note that the true causal relationships in E are known in the generated data . Given an estimated bE returned by a method , we define these metrics as follows .
P re = |{(i , j ) : ( i , j ) ∈ E , ( i , j ) ∈ bE}| Rec = |{(i , j ) : ( i , j ) ∈ E , ( i , j ) ∈ bE}|
|{(i , j ) : ( i , j ) ∈ bE}|
|{(i , j ) : ( i , j ) ∈ E}|
F 1 =
2 · P re · Rec P re + Rec
In the following algorithm we will update λθ based on Equation 11 . The proposed Constraint Greedy Subgraph Expansion(CGSE ) algorithm is outlined in Algorithm 1 .
Algorithm 1 CGSE Algorithm
Input : ( 1)p random variables X = {x1 , , xp} where xi contains n observations ; ( 2)K initial seeds S = {S1 , , SK} where |S1| = = |SK| ; Parameters : ( 1)fitness threshold ǫf ; ( 2)combination threshold ǫ0 ; ( 3)initial tuning parameter λ0 ; Output : Correlations among p variables and the overlapping subgraphs ; 1 : g = S ; 2 : K = K ; 3 : for i = 1 to K do 4 : 5 : end for 6 : repeat 7 : 8 : for i = 1 to K do
λi = λ0 ;
Find an unvisited variable xj from the nodes that are not in subgraph gi ; k = |gi| ; λi = ( log(k−1 ) k)1/2λi ; θnew = AP LE(gi , xj , λi ) ; if F itness(θnew ) > ǫf then end if
Add xj into gi ; end for for each gi in g do
9 : 10 : 11 : 12 : 13 : 14 : 15 : 16 : 17 : 18 : 19 : 20 : 21 : 22 : 23 : K = |g| ; 24 : until Each subgraph stays unchangeable 25 : Output g ; for each gj in g ( j 6= i ) do
Combine gj into gi ; end for end for end if if |gi ∩ gj|/|gi| > ǫo or |gi ∩ gj|/|gj| > ǫo then
Algorithm Explanation : Without loss of generality , S can be selected randomly as long as the seeds in S are disjoint with each other . Lines 3–5 initialize the tuning parameter λ0 for each seed . Lines 7–15 give one step expansion for each subgraph . We expand all the subgraphs together , which can achieve a balance for the size of each subgraph . Lines 16–22 check if two subgraphs should be combined .
Complexity Analysis : Assume that the final average subgraph size is R , lines 7–15 can be computed in O(K · L(R ) ) time . Lines 16–22 take at most O(K2p ) time with auxiliary O(p ) space . The number of iteration of line 6 reaches p at most . Thus our CGSE algorithm takes O(K2p2 +Kp· L(R ) ) time in the worst case . Where
119 Moreover , we set the fitness threshold ǫf = 0.1 , combination threshold ǫo = 0.6 , γ = 0.1 and λ0 = 02 We set the number of seeds at |S| = K and each Si is selected randomly from the K Erdös Rényi graphs with size |Si| = 3 . 512 Results Varying p To evaluate these methods on networks of various sizes , we vary p from 100 to 900 . We set ρ = 03 The performances of all the methods are shown in Figure 1 . We can see that when p is small , SGM performs as well as ODGM , because a single graphical model can work well . However , as p increases , the accuracy of SGM falls dramatically . As explained in Section 4.2 , such a large p makes it infeasible to derive a single graphical model from n observations . However , both decomposition methods still work well with the increase of p . ODGM achieves a high accuracy and outperforms NODGM consistently , because non overlapping decomposition cannot capture the overlap information . Varying ρ The parameter ρ plays an important role on controlling the homogeneity of the network . When ρ = 0 , it means the network is essentially heterogeneous and is actually composed of several separate sub networks , while a large ρ indicates that the edges in the network tend to distribute homogeneously . Figure 2 shows the F1 score of ODGM and NODGM while ρ is varied , where we set p = 500 . As expected , when ρ approaches zero , NODGM performs as well as ODGM because the network can be divided completely into sub networks . But as ρ increases , the disparity between ODGM and NODGM becomes larger since ODGM can discover the overlaps while NODGM losses more information .
We do not report the results for varying the parameters ǫf , ǫo and γ due to space limitation . Instead , we will study and visualize the effect of these parameters on a real life traffic network in an intuitive way in the next section .
Figure 1 : F1 score with p varying .
Figure 2 : F1 score with ρ varying .
5.2 Traffic Data
521 Description and setting
We evaluate our methods on real life traffic data . The features in this traffic dataset are observations collected from sensors located
( a ) Figure 3 : ( a)Real traffic network ; ( b)the non overlapping decomposition structure(NODGM ) ; ( c)the overlapping decomposition structure(ODGM ) .
( b )
( c ) on ramps in a highway traffic network . Each observation is the vehicle count during a time interval . Figure 3(a ) gives the structure of the highway traffic network from a province in China , in which each circle represents a traffic station consisting of an on ramp and an off ramp , and the line between any connected traffic stations is the bidirectional highway . There is an important ring in the network which is amplified on the right hand—the city in the center of this ring is a big city and plays a central role in the entire traffic network . There are total 180 traffic stations(circles ) , which correspond to 360 ramps , ie , p = 360 . The observations are collected at time interval 9:00 9:15 AM from 2011/1/1 to 2011/2/28 ( 59 days ) . Therefore , n = 59 for each feature . Due to the stability and periodicity of traffic behaviors , the observations follow a Gaussian distribution .
We set ǫf = 0.1 , ǫo = 0.6 , γ = 0.1 and λ0 = 50 . We set the number of seeds |S| = 12 , and each |Si| = 6 . Because there is no ground truth for causality matrix in real traffic data , F1 score cannot be measured . Nevertheless , the causal information detected is the most important for traffic research , and our domain experts can help with their knowledge on the causal relationship in the traffic network we use . Next , we compare the results returned from the different methods and discuss how the parameters in CGSE influence the causality structures .
522 Results and Analysis
Figure 3(b ) and Figure 3(c ) give the subgraph structures returned by NODGM and ODGM , respectively . For clear representation , we draw the results based on the initial traffic network with 180 traffic stations instead of 360 features , and a subgraph contains a traffic station node iff at least one feature ( ramp ) of this traffic station belongs to it . In the figures , the ellipses with the same label denote a subgraph . Since non overlapping subgraphs have no intersections , the subgraphs cannot be combined together , and thus the number of final subgraphs equals to the number of seeds in Figure 3(b ) . For overlapping structure , when two subgraphs overlap at a certain rate ǫo , they are combined together . Thus , we end up with 8 subgraphs in Figure 3(c ) .
From the two figures , we observe : ( 1)Both NODGM and ODGM show that the causalities between vehicle flows follow the spatial distribution in general— the nearer are two features spatially in traffic network , the more correlated they tend to be ; ( 2)ODGM highlights some crucial traffic nodes with highly overlaps , such as the nodes on the central ring . As mentioned earlier , the central ring is around the central city and plays an important role in the the entire traffic network . Additionally , traffic station C on the ring is the passageway connecting the unique airport of the entire network ; and traffic stations A and B are the top 2 highest vehicle flow traffic stations on both on ramp and off ramp . These domain information
120 Pfl1fl
Ofl1fl
Ofl2fl
Pfl1fl
Ofl1fl
Ofl2fl
Pfl2fl
Nfl2fl
Pfl2fl
Nfl2fl
Pfl2fl
Pfl1fl
Ofl1fl
Ofl2fl
Nfl2fl
Sfl1fl
Jfl1fl
Jfl2fl
Sfl2fl
Kfl2fl
Sfl1fl
Jfl1fl
Jfl2fl
Sfl1fl
Jfl1fl
Jfl2fl
Sfl2fl
Kfl2fl
Sfl2fl
Kfl2fl
Kfl1fl
Afl2fl
Afl1fl
Cfl2fl
Cfl1fl
Dfl2fl
Dfl1fl
Qfl 1fl
Qfl 2fl
Rfl1fl
Rfl2fl
Sfl1fl
Sfl2fl
Tfl1fl
Tfl2fl
Nfl1fl
Qfl 1fl
Nfl1fl
Qfl 1fl
Nfl1fl
Ofl1fl
Kfl1fl
Ofl1fl
Kfl1fl
Ofl1fl
Mfl2fl
Qfl 2fl
Rfl1fl
Mfl1fl
Rfl2fl
Lfl2fl
Lfl1fl
Sfl1fl
Wfl2fl
Sfl2fl
Mfl2fl
Qfl 2fl
Rfl1fl
Mfl1fl
Rfl2fl
Lfl2fl
Sfl1fl
Lfl1fl
Wfl2fl
Sfl2fl
Wfl1fl
Vfl2fl
Tfl1fl
Tfl2fl
Wfl1fl
Vfl2fl
Tfl1fl
Tfl2fl
Ufl1fl
Ufl2fl
Vfl1fl
Ufl1fl
Ufl2fl
Vfl1fl
( a ) SGM
( b ) NODGM
Mfl2fl
Ofl2fl
Mfl1fl
Ifl1fl
Ifl2fl
Lfl2fl
Lfl1fl
Hfl1fl
Wfl2fl
Hfl2fl
Wfl1fl
Vfl2fl
Gfl1fl
Gfl2fl
Ufl1fl
Ufl2fl
Vfl1fl
( c ) ODGM
Afl2fl
Ofl2fl
Ifl1fl
Afl1fl
Ifl2fl
Cfl2fl
Cfl1fl
Hfl1fl
Dfl2fl
Hfl2fl
Afl2fl
Ofl2fl
Ifl1fl
Afl1fl
Ifl2fl
Cfl2fl
Hfl1fl
Cfl1fl
Dfl2fl
Hfl2fl
Dfl1fl
Efl2fl
Gfl1fl
Gfl2fl
Dfl1fl
Efl2fl
Gfl1fl
Gfl2fl
Ffl1fl
Ffl2fl
Efl1fl
Ffl1fl
Ffl2fl
Efl1fl
( d ) SGM
( e ) NODGM
Ffl1fl
Ffl2fl
Efl1fl
Efl2fl
( f ) ODGM
Figure 4 : Detail causalities among the selected features : ( a ) , ( b ) and ( c ) are causalities by SGM , NODGM and ODGM under local concentrated features ; ( d ) , ( e ) and ( f ) are causalities by SGM , NODGM and ODGM under scattered features . matches well with our ODGM result and gives an reasonable explanation . ( 3)ODGM is able to detect long distance causalities in addition to the local causalities within distances . For example , the components(ellipses ) of subgraph 1 , 3 , 4 and 5 are distributed spatially , but they are highly correlated within the vehicle flow . In other words , there also exists long distance origin destination demand in the traffic network . However , NODGM cannot mine such information described in both ( 2 ) and ( 3 ) . ( 4 ) The sparsely located traffic stations are not included in any subgraphs in both the figures . We find that the vehicle flows in most of these traffic station ramps are nearly 0 during the observation periods , and almost 80 % of the ramps and their located highways are newly built . Thus they are seldom used and have no causal relationship with other ramps .
Figure 4 gives the detailed causalities among a set of selected features . For each selected traffic station i , i1 and i2 denote the on ramp and off ramp features , respectively . In Figures 4(a ) , 4(b ) and 4(c ) , the features are selected from traffic station L W in Figure 3(a ) , and these traffic stations are selected locally concentrated . We can see that SGM detects fewer causal information than do NODGM and ODGM because a single graphical model treats the entire network globally , and can only detect the causalities from a global view . In this setting , NODGM detects more causal relationships than do ODGM , which also demonstrates that NODGM focuses more on a local view while ODGM is a nice compromise of SGM and NODGM .
While Figures 4(d ) , 4(e ) and 4(f ) provide the detailed causalities among the features selected from A , C K , O and S , which are scattered in the network . As can be observed from the results , ODGM discovers more meaningful causal information than do SGM and NODGM , eg , the causalities among {E1 , E2 , F 1 , F 2 , G1 , G2} . Both ODGM and SGM are able to discover the important long distance causalities for the key traffic station A and C . However , NODGM is restrained by its non overlapping structure and only detects the inner relationship within subgraphs , even if A and C are highly correlated with others .
These results obtained by ODGM are essentially important for the analysis of traffic systems for the following reasons . First , the traffic stations in the same subgraph are highly correlated and should be considered together by traffic systems . For example , it is possible that vehicle flows rush into each other within the same subgraph . Second , the causalities are very helpful for traffic flow prediction and anomaly detection which are hot concerns of traffic operators and managers . Third , it is important to find the highly overlapped traffic stations . These crucial traffic stations are correlated with a number of regions , based on which the regions with heavy traffic can be detected . On the other hand , the regions with light traffic can also be reflected by independent traffic stations . These information can be used by highway construction planners to design new roads .
523 Varying parameters
We study the effect of parameters γ , ǫf , ǫo and λ0 for CGSE . Figure 5 shows the decomposition results of varying parameters . When varying each parameter , we use the aforementioned default values for the other parameters .
Parameter ǫf controls the minimum fitness , and restricts the size of each subgraph . As shown in Figure 5(a ) , when ǫf decreases , more features are added into subgraphs and the size of each subgraph becomes larger . Figure 5(b ) shows the effect of ǫo . When ǫo is reduced , the subgraphs are more likely to be combined together under ǫo . Figure 5(c ) shows the effect of γ , which controls overlaps , on the number of features with different overlap degrees . We observe that when γ increases , fewer overlaps exist in the decomposition structure , thus the number of overlapped features .
Figure 6 visualizes the generated subgraphs for selected parameter values to show the details . From these figures , we can see that the property of each parameters is in line with the results in Figure 5 , and these figures give a more intuitive and understandable description for our method .
Due to space limitation and as λ0 works similarly as ǫf , we do not give the results of varying λ0 , which controls the sparsity of the causalities in the penalize estimation problem in Equation 3 . When λ0 increases with ǫf fixed , the constraint on the sparsity becomes tighter and fewer causalities are detected , and thus smaller subgraphs generated . Conversely , when λ0 decreases , more causalities will be discovered and the size of each subgraph will increase .
6 . CONCLUSION AND FUTURE WORK
In this paper , we propose an overlapping decomposition technique for large scale graphical models . The techniques enables the penalized log likelihood in Gaussian Graphical Model to satisfy an additive expanding property . We demonstrate its asymptotic stability . Based on this property , we develop a constraint greedy subgraph expansion algorithm to generate overlapped subgraphs . We demonstrate on both synthetic data and real life traffic data that the overlapping decomposition method is more powerful than the single graphical model and its non overlapping decomposition counterpart . In the application of traffic data analysis , the meaningful results show that our model can provide rich information for traffic analysis .
For future work , it is interesting to extend the static overlapping decomposition technique to deal with time varying observations so that we can follow the evolvement of the causalities in a network .
7 . ACKNOWLEDGMENTS
This work is supported by the National Natural Science Foundation of China ( 60703066 , 60874082 ) , and Beijing municipal natural science foundation ( 4102026 ) .
121 ( a )
( b )
( c )
Figure 5 : ( a)relationship among average subgraph size , the number of subgraphs and ǫf ; ( b ) relationship between the number of subgraphs and ǫo ; ( c)relationship between overlap degree and γ .
( a ) ǫf = 0.05
( b ) ǫf = 0.2
( c ) ǫo = 0.8
( d ) ǫo = 0.4
( e ) γ = 0.5
( f ) γ = 2
Figure 6 : Decomposition structures when varying each parameter while keeps others stable . Default setting : ǫf = 0.1 , ǫo = 0.6 and γ = 01
8 . REFERENCES [ 1 ] A . Arnold , Y . Liu , and N . Abe . Temporal causal modeling with graphical granger methods . In Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 66–75 . ACM , 2007 .
[ 2 ] X . Chen , Y . Liu , H . Liu , and J . Carbonell . Learning spatial temporal varying graphs with applications to climate data analysis . In Twenty Fourth AAAI Conference on Artificial Intelligence , 2010 .
[ 3 ] P . Danaher , P . Wang , and D . Witten . The joint graphical lasso for inverse covariance estimation across multiple classes . Arxiv preprint arXiv:1111.0324 , 2011 .
[ 4 ] J . Friedman , T . Hastie , and R . Tibshirani . Sparse inverse covariance estimation with the graphical lasso . Biostatistics , 9(3):432–441 , 2008 .
[ 5 ] N . Friedman . Inferring cellular networks using probabilistic graphical models . Science ’s STKE , 303(5659):799 , 2004 .
[ 6 ] J . Guo , E . Levina , G . Michailidis , and J . Zhu . Joint estimation of multiple graphical models . Biometrika , 98(1):1–15 , 2011 .
[ 7 ] D . Koller and N . Friedman . Probabilistic graphical models : principles and techniques . The MIT Press , 2009 .
[ 8 ] S . Lauritzen . Graphical Models . Oxford University Press ,
1996 .
[ 9 ] C . Lee , F . Reid , A . McDaid , and N . Hurley . Detecting highly overlapping community structure by greedy clique expansion . Arxiv preprint arXiv:1002.1827 , 2010 .
[ 10 ] Y . Liu , J . Kalagnanam , and O . Johnsen . Learning dynamic temporal graphs for oil production equipment monitoring system . In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 1225–1234 . ACM , 2009 .
[ 11 ] Y . Liu , A . Niculescu Mizil , A . Lozano , and Y . Lu . Temporal graphical models for cross species gene regulatory network discovery . In Proceedings of the 9th annual international conference on Computational Systems Bioinformatics , 2010 .
[ 12 ] A . Lozano , H . Li , A . Niculescu Mizil , Y . Liu , C . Perlich ,
J . Hosking , and N . Abe . Spatial temporal causal modeling for climate change attribution . In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 587–596 . ACM , 2009 . [ 13 ] J . Peng , P . Wang , N . Zhou , and J . Zhu . Partial correlation estimation by joint sparse regression models . Journal of the American Statistical Association , 104(486):735–746 , 2009 .
[ 14 ] A . Rothman , P . Bickel , E . Levina , and J . Zhu . Sparse permutation invariant covariance estimation . Electronic Journal of Statistics , 2:494–515 , 2008 .
[ 15 ] N . Ruan , R . Jin , V . Lee , and K . Huang . A sparsification approach for temporal graphical model decomposition . In Data Mining , 2009 . ICDM’09 . Ninth IEEE International Conference on , pages 447–456 . IEEE , 2009 .
[ 16 ] M . Schmidt , G . Fung , and R . Rosales . Fast optimization methods for l1 regularization : A comparative study and two new approaches . Machine Learning : ECML 2007 , pages 286–297 , 2007 .
[ 17 ] M . Schmidt , G . Fung , and R . Rosales . Optimization methods for l1 regularization . University of British Columbia , Technical Report TR 2009 19 , 2009 .
[ 18 ] R . Thompson . Graphical models in applied multivariate statistics . Journal of Classification , 9(1):159–160 , 1992 .
[ 19 ] M . Yuan and Y . Lin . Model selection and estimation in the gaussian graphical model . Biometrika , 94(1):19–35 , 2007 .
122
