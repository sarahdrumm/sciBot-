Capacitated Team Formation Problem on Social Networks
Samik Datta
Bell Labs , Bangalore samik.datta@alcatel lucent.com
Anirban Majumder Bell Labs , Bangalore
KVM Naidu
Walmart Labs , Bangalore
∗ anirban.majumder@alcatel naidukvm@walmartlabs.com lucent.com
ABSTRACT In a team formation problem , one is required to find a group of users that can match the requirements of a collaborative task . Example of such collaborative tasks abound , ranging from software product development to various participatory sensing tasks in knowledge creation . Due to the nature of the task , team members are often required to work on a cooperative basis . Previous studies [ 1 , 2 ] have indicated that co operation becomes effective in presence of social connections . Therefore , effective team selection requires the team members to be socially close as well as a division of the task among team members so that no user is overloaded by the assignment . In this work , we investigate how such teams can be formed on a social network .
Since our team formation problems are proven to be NPhard , we design efficient approximate algorithms for finding near optimum teams with provable guarantees . As traditional data sets from on line social networks ( eg Twitter , Facebook etc ) typically do not contain instances of large scale collaboration , we have crawled millions of software repositories spanning a period of four years and hundreds of thousands of developers from GitHub , a popular open source social coding network . We perform large scale experiments on this data set to evaluate the accuracy and efficiency of our algorithms . Experimental results suggest that our algorithms achieve significant improvement in finding effective teams , as compared to naive strategies and scale well with the size of the data . Finally , we provide a validation of our techniques by comparing with existing software teams .
Categories and Subject Descriptors H28 [ Database Management ] : Database Applications— Data mining ∗ Bangalore .
Work partially done while the author was at Bell Labs ,
Keywords social networks , team formation , capacity
1 .
INTRODUCTION
Social collaboration or team formation is gaining prominence in the web . There is a growing interest in the community to understand the process of social collaboration , namely , how people use social connections to form teams in challenging situations . To understand the sociological aspects of team formation , an on line contest was recently organized by DARPA1 . In this contest , ten balloons were raised into the air and the participants were asked to track their locations . Since no single person could track all of them , the point of the contest was to observe how people would use their social connections to form teams and collectively report the locations .
In today ’s web , large scale software systems are prominent embodiments of the team formation process . In a software project , collaboration among the developers is required at multiple stages of production . Therefore , it is important to ensure that the collaboration is effective , in order to attain the highest level of productivity . Previous studies [ 1 , 2 ] suggest that presence of social connections are often good indicator of effective collaboration . In fact , in our experiments ( see Section 4.2 ) , we observed a strong positive correlation between activities of a project and social nature of the corresponding team . Moreover , due to proliferation of Web 2.0 phenomena , a growing number of Open Source Software sites ( eg GitHub [ 3 ] ) are becoming ‘social’ by imbibing socialnetworking features eg messaging , community formation , friendship links , for their users . It remains to study how one can facilitate the team formation process in this new generation of networks by designing specialized algorithms for team selection that are mindful of the social connections of the team members . Specifically , we ask the following question in this paper : How to build an effective team of users that meets the requirement of a project and the selected teammembers are socially close to each other ?
However , team formation is not limited to the realm of software development only . Teams are fundamental to the concept of participatory sensing users contribute sensory information ( through their mobile phones or other handheld devices ) to constitute a body of knowledge , eg learning about the safety of biking tracks in a terrain 2 collecting
1http://newscnetcom/8301 1023 3 10410403 93.html 2http://wwwopencyclemaporg/
1005 traffic patterns in a city 3 task need to collaborate among themselves in dividing the work . In this context , the social network represents their degree of co operation and therefore , identifying the most effective community of users for a sensing task amounts to finding the ‘best’ team on their social network .
In summary , we believe that the problem of finding team of users on a social network ( for a collaborative task ) , has far reaching applications beyond the ones mentioned here and is an important problem to study . We consider the social team formation problem where the objective is to select a team of users from a social network and a division of the task so that the team members are socially ‘close’ to each other and no user is overloaded by the assignment . Below , we summarize our contributions . 1.1 Our Contributions
• Our key contribution is to account for capacity constraints in the team formation problem ( on a social network ) . For a given task , our goal is to find a team of users from the social network who are ‘socially effective’ in terms of collaboration ( see Section 2.3 ) and a division of the task among team members so that no user is overloaded by the assignment ie no user is assigned task beyond her capacity . To the best of our knowledge , ours is the first work to formulate the team formation problem in presence of a social network and capacity constraints on users ( see Section 2.2 ) , thereby showing that it gives rise to a novel problem previously unstudied in the literature .
This is a major departure from existing works in Operations Research [ 4 , 5 ] that primarily model team formation as a variant of the bi partite matching problem 4 or other heuristics and therefore , completely ignores the social network information . The only known works consider the social network of users are by Lappas et al [ 6 ] and Anagnostopoulos et al [ 7 ] ; however , their formulations do not account for capacity constraints on the users and therefore , are fundamentally different from ours ( see Section 5 for a detailed comparison ) . • As our team formation problems are proven to be NPhard , we present efficient approximation algorithms to find nearly optimal teams with provable guarantees . • We conduct a careful and detailed set of experiments to evaluate the performance of our algorithms . By crawling GitHub [ 3 ] , a popular and the fastest growing open source software site , we have collected large scale social networking graph and collaboration traces ( hundred of thousands of users and nearly a million software repositories ) . Through experiments on this dataset , we have established that our algorithms achieve at much as 40 % reduction in cost compared to other strategies .
We present a validation of our algorithms by showing how our techniques can improve the collaboration cost ( see Section 2.3 ) of existing software teams in GitHub . To the best of our knowledge , ours is the first attempt to collect and analyze large scale ( in the order of hundreds of thousands of users and millions of software projects ) collaboration traces from GitHub that enables us to derive some interesting insights about the nature of collaboration in this network ( refer to Section 42 )
• Further , to demonstrate the generality of our techniques , we present an additional set of experiments on the DBLP dataset . Experimental evidences suggest that our algorithms achieve at least 20 % reduction in cost compared to other heuristics .
1.2 RoadMap
Our paper is organized as follows . In Section 2 , we formulate the team formation problem on social networks , that we address in this paper . Section 3 presents the algorithms for team formation and analyze their properties and performance . We follow it up with detailed evaluation through experiments over real world data sets in Section 4 . We survey the related works in this area in Section 5 . Finally , we conclude in Section 6 .
2 . TEAM FORMATION PROBLEM
In this section , we introduce some notations and formally define our team formation problem on a social network . 2.1 Notation
We represent the social network as an undirected graph G = ( V , E , w ) with vertices in V denoting the users and edges in E , the social connections between them . The edges are weighted by cost function w : E → R + indicating the cost of collaboration among neighboring users in the network . Therefore , for users u and v such that ( u , v ) ∈ E , if w(u , v ) is large , it indicates that they are unlikely to collaborate well with each other . The cost function w can be estimated by analyzing previous collaboration traces of the users 5 . Each user v ∈ V is skilled with a set of items , where items are , for example , programming languages , operating systems etc that are needed for a software project . We denote the set of items for user v by Iv and the universe of all items in the network by I ie I = ∪v∈V Iv . For user v , let cv denote her capacity ie the maximum number of items that can be assigned to v without overloading the user . Finally , a task T is defined as a sub set of items {i1 , i2 , ··· ik} ⊆I . A user u can be assigned an item i from the task only if she is skilled in it ie i ∈ Iu . 2.2 Feasibility Constraints
A team U ⊆ V is said to be feasible for a given task T if it satisfies the following constraints :
• Covering Constraints : There is a valid assignment ψ of the items in T to users in U such that each item i ∈ T is assigned to some user ψ(i ) ∈ U such that i ∈ Iψ(i ) . • Packing Constraints : For each user u ∈ U , the total number of items assigned to u does not exceed her capacity ie
1 ≤ cu .
. i∈T :ψ(i)=u
3http://wwwopenstreetmaporg/ 4http://enwikipediaorg/wiki/Assignment problem
5Refer to Section 4.3 on details of estimating edge costs from a given collaboration trace .
1006 2.3 Social Collaboration Cost
By virtue of the cost function w(· ) , it is possible to calculate the collaboration cost between any pair of users u and v . If u and v are friends ie ( u , v ) ∈ E , then the cost is simply w(u , v ) ; otherwise , it is determined by the cost of the shortest path that connects u and v . However , it is not obvious how to extend this definition of collaboration cost for a team with more than two users . rowed from the work of Lappas et al [ 6 ]
We use the following measures of collaboration cost , bor• Diameter Cost : Given the social network G = ( V , E , w ) , the diameter cost of a team U ⊆ V is defined to be the maximum cost between any pair of users in U . • Steiner Cost : Given the social network G = ( V , E , w ) , the steiner cost of a team U ⊆ V is defined to be the minimum cost of a tree that connects all the users in U . Stated more formally , steiner cost for a team U is the cost of a minimum cost steiner tree that connects all the users in U .
• Bottleneck Edge 6 Cost : Given the social network G(V , E , w ) , and a team U ⊆ V , this cost function is defined as the minimum bottleneck cost of a steiner tree that spans U .
These cost models are intuitive and capture some desirable properties of a team . Observe that , while the diameter and bottleneck costs prohibit pair of users ( for diameter ) or neighboring users ( for bottleneck cost ) for whom there exists a large collaboration cost , steiner cost , on the other hand , is an aggregate measure and attempts to reduce the overall collaboration cost . 2.4 Problem Formulation
In a team formation problem , a user has a task in mind and is willing to collaborate with others from her social network to form a team , so that together , they accomplish the goal . Formally , it can be defined in the following way : Given a social network G(V , E , w ) , a user v who specifies a task T , find a group of other users U ⊆ V , so that the team U ∪{v} is feasible for the task and minimizes the social collaboration cost ( measured in diameter , steiner or the bottleneck cost ) . We refer to the team formation problem with diameter collaboration cost as MinDiamTeam ; Similarly , the variants with steiner and bottleneck collaboration costs are referred to as MinAggrTeam and MinMaxTeam respectively .
In general , we assume that user v also specifies a maximum hop length h so that users who are more than h hops away from her , are not considered by the team selection process . Typical values of h are 1 ( friend network ) , 2 ( friendof friends network ) and ∞ ( unconstrained ie the entire network ) .
Observe that , as per our formulation , user v ( who creates the task ) is guaranteed to be a member of the team . We believe that this scenario is a representative of social collaboration esp . in a software development environment , where the user who creates the project also contributes to it . However , this assumption is not essential to our problem , since our algorithms , presented in Section 3 , can be easily adapted for the case when v is not enforced to be part of the solution . 6The bottleneck cost of a tree is the weight of the maximum weighted edge .
Algorithm 1 The MinDiamSol algorithm for minimizing diameter cost 1 : Input Social Network G(V , E , w ) ; User v ; Task T = 2 : Output Team U ⊆ V ; allocation of T to U . 3 : Pre process the graph to exclude users who are more
{i1 , i2 ··· , ik} ; maximum hop length h . than h hops away from v .
4 : Find the Items(Tv(r fi smallest ) ) = k ; radius
5 : Let T eamv be the team found ; 6 : return T eamv ; fi r such that Max
2.5 Hardness Result
Since the team formation problem considered in [ 6 ] is a specialization of our problem , namely , when all the user capacities are infinite , the hardness results established in their work directly carry over to our problem as well . We briefly summarize this result in the following lemma and refer to [ 6 ] for the proof . 7
Lemma 1 . MinDiamTeam and MinAggrTeam problems are NP hard .
3 . ALGORITHMS
Owing to the hardness result mentioned in Lemma 1 , we can not hope to compute the optimum solutions for our team formation problems MinDiamTeam and MinAggrTeam . We first present approximate algorithms to compute nearly optimum teams ( with provable guarantees ) under these cost models and towards the end of the section present an exact algorithm for MinMaxTeam .
We first present an efficient procedure to identify feasible teams . Specifically , given a team of users U , we present techniques to determine whether U is feasible wrt the task at hand . We describe it in the following lemma .
Lemma 2 . MaxItems : Given a task T = {i1 , i2 , ··· , ik} , and a team of users U ⊆ V , it can be computed in polynomial time , the maximum number of items that can be assigned to U so that no user in U is assigned items more than her capacity . ( refer to Section 22 ) As a corollary , it can be decided whether U forms a feasible team for the task T .
Proof . Given the task T and team U , we form a bipartite graph ( L , R , E ) as follows . For each item i ∈ T , we add a corresponding node li in L . Similarly , for each user u ∈ U , there is a corresponding node ru in R . Add a directed edge ( li , ru ) of capacity 1 between li and ru if the item i can be assigned to u ie i ∈ Iu . Augment this network by adding source and sink nodes s and t . For each node li ∈ L , add a directed edge ( s , li ) of capacity 1 . Similarly , for each ru ∈ R , add a directed edge ( ru , t ) of capacity cu , ie the capacity of user u . We now seek to find the maximum flow between s and t .
Observe that if there is a feasible team , then each of the edges ( s , li ) will be saturated ie having 1 unit of flow through them . Therefore , the maximum flow is at least k . On the other hand , the maximum flow is bounded by the sum of the capacities of the edges ( s , li ) , which is k . 7However , the MinMaxTeam problem is polynomially solvable ( refer to Section 3 ) .
1007 Therefore , if the maximum flow of the network is k , we can conclude that there is a feasible team . Otherwise , it can be verified easily that the s t max flow gives us the maximum number of items that can be assigned to U . The allocation of the items to users in U can be decided by inspecting the set of edges ( li , ru ) if the edge ( li , ru ) carries non zero flow , then the item i is assigned to user u .
Time Complexity For a graph with n vertices and m edges , the best known algorithm for maximum flow has O(mn log m ) time complexity .
In the following discussion , we will use OPT to denote an optimum solution8 and |OPT| , its cost . Algorithm MinDiamSol outlines the pseudo code of our algorithm for the MinDiamTeam problem . Our idea is to guess the value of |OPT| and decide if there is a feasible team whose cost is well approximated by our guessed value . However , we can not hope to find the optimum solution by enumerating all possible values of |OPT| , since our problem is NP Hard . Therefore , instead of minimizing the diameter cost of the team , we rather attempt to minimize the distance between the root user ( ie v ) and the team members .
Assume that r is our guess of the cost . We use the notation Tv(r ) to denote the set of users whose distance from v is at most r ie Tv(r ) = {u|d(v , u ) ≤ r} , where d(v , u ) is the cost of the shortest path that connects v and u . Observe that v ∈ Tv(r ) , for all values of r .
Our objective is to determine the minimum value of r so that the set of users Tv(r ) forms a feasible team for the given task .
Theorem 31 Algorithm MinDiamSol obtains a 2 factor approximation algorithm for the MinDiamTeam problem .
Proof . Let ¯r be the minimum radius computed by Algorithm 3 and rm =|OPT| be the cost of the optimum solution . We claim that rm ≥ ¯r . Otherwise , if rm < ¯r , then OPT ⊆ Tv(rm ) ( since v ∈ OP T ) implying that Tv(rm ) contains a feasible team , which is a clearly a contradiction . Let p , q be any two users present in the solution computed by MinDiamSol . The distance between p and q can be bounded in the following way , d(p , q ) ≤ d(w , p ) +d ( w , q ) ≤ 2 · ¯r ≤ 2 · rm
Here the first inequality follows by applying the triangle inequality for shortest path distances . Since the diameter of the team is being defined as the maximum shortest distance between pairs of users and the inequality holds for any such pair , the proof follows .
Time Complexity The feasible team MinDiamSol can be found by performing a binary search on the diameter of the graph , that requires O(log nh ) invocations of Lemma 2 where nh denotes the number of nodes that are within h hops of root user v . Therefore , the worst case time complexity is O(kn2 h(log nh + log k ) log nh ) . However , in practice , the running time of this algorithm is much less than this worstcase analysis suggests 9 . 8Observe that , as per our problem definition ( Section 2.4 ) user v belongs to the team ie v ∈ OP T . 9refer to Section 443 fi
Our algorithm for MinAggrTeam problem is slightly more complicated than the diameter case . The MinAggrSol algorithm starts by transforming the social network into a simpler graph G is conceptually much easier than doing it in the original graph . Following that , the algorithm greedily picks nodes from G , based on a utility measure , until a feasible team is found . These steps of MinAggrSol are shown in Algorithm 2 . so that finding the team in G fi fi
Algorithm 2 The MinAggrSol algorithm for minimizing steiner cost 1 : Input Social Network G(V , E , w ) ; User v ; Task T = 2 : Output Team U ⊆ V ; allocation of T to U . 3 : Pre process the graph to exclude users who are more
{i1 , i2,··· , ik} ; maximum hop length h . fi fi than h hops away from v .
, λ ) ← AugmentGraph(G ) .
( V , E
4 : G 5 : coverv := {v} ; 6 : while coverv not feasible do ¯x ← argmax 7 : coverv ← coverv ∪ {¯x} x∈{V \coverv }
.
MaxItems(coverv∪{x})−MaxItems(coverv )
λ(v,x ) fi
;
8 : 9 : end while 10 : T eamv ← MinSteinerTree(coverv , G ) ; /* minimum cost steiner tree in G that connects all the users in coverv */
11 : return T eamv ; fi fi fi
The procedure AugmentGraph ( step 4 of MinAggrSol ) creates a graph G , λ ) in the following way for each ( V , E vertex u ∈ V \ {v} , it adds an edge ( v , u ) ∈ E . The cost of the edge ( v , u ) ∈ E fi ie λ(v , u ) is defined as the cost of the shortest path between u and v in G . Conceptually , our construction produces a one level tree with user v being the fi root and all other users are at level 1 . A feasible team in G with user v as the root . We corresponds to a sub tree of G denote the optimum team in G by OPTλ . fi fi fi fi
Although G is structurally much simpler than G , it turns out finding OPTλ is still NP hard , as it can be shown by a direct reduction from the set cover problem . We therefore resort to an approximation for it . To find an approximation to OPTλ , we start with a partial team containing user v only . At each step , we greedily add a user from G to the team only if it maximizes the utility . The utility of a node u ∈ V \ {v} is defined as the ratio of the marginal benefit of adding u to the cover ( in terms of the number of additional items it covers ) to its cost λ(v , u ) . We use the construction highlighted in Lemma 2 to derive the utility values . Once we find a feasible team , we construct a minimum cost steiner tree that connects all the users in the team and return it as a solution . Although computing minimum cost steiner tree is an NP hard problem , there are well known algorithms in the literature ( cf [ 8 ] ) that achieve factor of 2 approximation to it . The following lemma shows that the cost of the solution returned by MinAggrSol is not far from the cost of the optimum solution .
Theorem 32 Algorithm MinAggrSol obtains an O(k log k ) factor approximation to the MinAggrTeam problem , where k is the number of items required by the task .
Our proof consists of two parts as a first step , we find out how well OPT is approximated by OPTλ . Following that , we prove bounds on the error we incur by approximating OPTλ itself . We start with the following observation .
1008 {i1 , i2 ··· , ik} ; maximum hop length h .
Algorithm 3 The MinMaxSol algorithm for minimizing bottleneck edge cost 1 : Input Social Network G(V , E , w ) ; User v ; Task T = 2 : Output Team U ⊆ V ; allocation of T to U . 3 : Pre process the graph to exclude users who are more 4 : for t = 0 → maxweight(E ) do 5 :
Remove all edge e ∈ E such that w(e ) > t ; Let C be the component that contains v ; If MaxItems(C ) = k , let T eamt be the team found /* T eamt ⊆ C */ return T eamt ; than h hops away from v .
6 :
7 : 8 : end for
Lemma 3 . Cost of OPTλ is at most O(k ) times the cost of OPT . fi
Proof . Consider any optimum solution OPT={v , u1 , u2 , ··· , ul−1} and let TOP T be a minimum cost steiner tree in G that connects all users in OPT . Observe that in OPT , there can be at most k users who are assigned one or more items from the task ie l ≤ k . In G , OPT is a 1 level tree with the vertex v at the root and all other vertices {u1 , u2,··· , ul−1} being connected to v via an edge . Observe that OPT is also a feasible solution in G j λ(v , uj ) . Root the tree TOP T at node v . It is easy to observe that the distance of uj ∈ OP T \{v} from v is no more than |OPT| . Moreover , since λ(v , uj ) corresponds to the shortest distance between v and uj in G , we can write λ(v , uj ) ≤ |OP T| . Therefore , can be bounded as ( k − 1 ) · |OP T| . the cost of OPT in G Finally , observe that OPTλ is the minimum cost solution in G and the inequality follows . whose cost is fi fi fi fi
In the next two lemmas , we derive the factor in approxi mating OPTλ .
Lemma 4 . The function MaxItems(S ) over set of users
S ⊆ V is sub modular10 .
Proof . See Appendix A for the proof .
We use a known result on the sub modular cover problem to complete the proof of Theorem 32 The sub modular cover problem is defined as follows : Let E = {1 , 2,··· , m} be a ground set and C be a collection of sets defined over E ie C ⊆ 2E . Let f be a sub modular function defined as f : 2C → Z + ∪ {0} such that f ( C ) = m , f ( ∅ ) = 0 and f fifi ∈ 2C such that is monotone increasing ie fi ⊆ C ) . Each set s ∈ C has a fifi C fi ⊆ C is said to non negative cost w(s ) . A sub collection C form a feasible cover if f ( C ) = f ( C ) and the cost of the cover is defined simply as the sum of the costs of the sets in s∈C' w(s ) . In the minimum cost sub modular cover it ie problem one is asked to find a feasible cover of minimum cost . Wolsey et al [ 9 , 10 ] obtained the following result .
) ≥ f ( C
, it implies f ( C for sets C fi
, C fifi fi fi fi
Lemma 5 .
[ 9 , 10 ] The greedy algorithm that picks sets based on maximum utility , achieves an O(log k ) factor approximation to the sub modular set cover problem . 10For a function f : V → Z + ∪ {0} to be sub modular it means for all S , T ⊆ V , f ( S ) +f ( T ) ≥ f ( S ∪ T ) + f ( S ∩ T )
To put an analogy , the ground set E is the set of items in our requirement T = {i1 , i2,··· , ik} and the collection of subsets C is the set of users who possesses a subset of items from T . Since the function MaxItems is sub modular and satisfies all the requirements , we can conclude that through steps 8 11 of Algorithm 2 ) we compute an O(log k ) approximate solution to OPTλ . Combining this with Lemma 3 , we obtain the result of Theorem 32
Time Complexity Observe that in MinAggrSol , the size of coverv is at most k . Therefore , computing minimum cost team incurs a cost of O(k3 log k + nhk2 + m ) ( steps 4 to 9 ) . The steiner tree computation in step 10 , can be performed in an additional O(m+n log n ) time [ 11 ] . However , in practice , we find that MinAggrSol scales almost linearly with increasing size of the network ( ie m and n ) and number of items ( ie k ) 11 .
Algorithm MinMaxSol outlines the pseudocode of our solution for the MinMaxTeam problem . We first guess that the optimum team contains no edge with cost more than t and remove edges with higher cost . Following that , we identify the component of the graph that contains the root user v and determine whether it contains a feasible team . This is because any team that spans across multiple such components must use an edge of cost > t . Finally we search for the minimum value of t such that this component ( containing the root v ) consists of a feasible team . It can be verified easily that the solution returned by MinMaxSol is optimum . Time Complexity The search for minimum value of t ( in step 4 ) can be performed via binary search on the set of edges in the graph , that requires O(log mh ) invocations of Lemma 2 ; here mh is the number of edges in the graph after the pre processing step ( ie step 3 in MinMaxSol ) . Hence the overall time complexity is O(kn2 h(log nh + log k ) log mh ) . So far we have assumed that the root user has been specified and is required to be part of the solution . However , this restriction can be lifted in the following way we repeat the algorithms over all choices of the root node and return the team that is of minimum cost . This operation preserves the approximation factors of the algorithm but increases the time complexity by a factor of n 12 . In practice , users are often paid for their participation and one would like to minimize the total cost ( eg the sum of the collaboration and participation cost ) . We briefly mention that our team formation algorithms can be easily adapted to optimize over this new cost function and refer to the full version of the paper [ 12 ] for details .
4 . EXPERIMENTS
We now report a detailed set of experiments carefully designed to evaluate the performance of our algorithms . Our first step is to describe the novel data set on which our experiments are based . 4.1 Dataset
Traditional data sets gathered from popular on line social networks ( eg Twitter , Facebook etc . ) do not contain evidence of large scale collaboration and therefore , are not suitable for our experiments . We focus our attention on a popular social coding site , GitHub [ 3 ] . GitHub hosts a large number of software projects and provide social networking
11Please refer to Sections 442 and 443 for details . 12Refer to the full version of the paper [ 12 ] for proofs .
1009 0 . 1
0 . 1
5 . 0 t i n e c i f f e o c n o
0 . 0 i t l a e r r o C
5 . 0 −
5 . 0 t i n e c i f f e o c n o
0 . 0 i t l a e r r o C
5 . 0 −
0 . 1 −
1 6 12 19 26 33 40 47 54 61 68 75 82 89 96
Team size
0 . 1 −
1 6 12 19 26 33 40 47 54 61 68 75 82 89 96
Team size
Figure 1 : Correlation coefficients between number of commits of a project and number of social edges in the team for different team sizes .
Figure 2 : Correlation coefficients between number of commits of a project and number of connected components in the sub graph induced by the team members for different team sizes .
Contributed vs Active projects y=ln(1+x )
5 1
0 1 o t s e t u b i r t n o c r e s u s t c e o r p f o r e b m u N j
5
0
0
20 80 Number of listed projects that are active
40
60
100
Figure 3 : Number of projects actively contributed by a user vs . number of listed projects ( for 2000 users ) . features ( eg messaging , activity streams , friendship links ) for programmers working on these projects . Although there are other social coding sites ( eg SourceForge , Google Codes etc . ) we have selected GitHub for the following reasons i ) Unlike other sites , GitHub provides explicit social links through which users can connect with others , ii ) GitHub APIs allowed us to extract richer quality of data and lastly , iii ) it is the fastest growing among others .
GitHub offers a novel social collaboration model in which a user canfork a copy of the software project owned by her friend . Contribution of the user in this forked copy can be merged with the original one , by communicating it to the owner . For our experiments , we have crawled publicly available information from GitHub consisting of 1,35,346 users and 9,05,000 software projects , during the month of August , 2011 . Our data set corresponds to 15 % of the volume of GitHub and spans over a period of four years . For each project , we collected its composition in terms of programming languages , list of contributors , commit logs , and bug reports filed . Similarly , for each user , we collected the list of her followers and the list of the projects created and contributed by the user .
For our experiments , we crawled the following two datasets data set D1 consists of 1,35,346 users and 9,05,000 software projects and several meta data about the users and projects ( eg commit logs , team composition etc ) This data set is used for estimating parameters to our algorithms ( refer to Section 43 ) Our second data set D2 , is used as test data points . This data set consists of new set of 470 projects collected during the period September December 2011 ( ie following the crawl of D1 ) 13 .
We also perform an additional set of experiments on a DBLP data set to demonstrate the generality of our approach . The description of this dataset and the result of our experiments are presented in Section 45 4.2 Evidence of Social Collaboration in GitHub We analyzed the commit logs of 10k projects over a period of last three months ( relative to the date of our crawl ) and observed an interesting pattern between the activity of the project ( measured in terms of number of commits ) and ‘social’ nature of the corresponding team . For this exper
13GitHub dataset can be obtained by mailing the authors . iment , we group the teams by their size ( ie number of contributors)14 and for each team size , report the correlation coefficient between the social nature of the team and number of commits of the project . We use two simple measures for evaluating ‘social’ nature of a team a)number of social edges present in the team and b ) number of connected components in the sub graph induced by the team members . Figure 1 and Figure 2 show the result of this experiment . We observe that teams with more edges ( hence being more social ) are more active in terms of number of commits in their projects . As a result , we see positive correlation coefficient across almost all different team sizes in Figure 1 . Similarly , teams with larger number of connected components ( hence less social ) are less active and we observe negative correlation coefficient across almost all different teams sizes ( Figure 2 ) . These results suggest that in GitHub , social nature of a team has a strong correlation with the activity of the project .
4.3 Pre processing
Below , we describe in detail how data set D1 is processed to generate the input parameters to our algorithms .
Social Network By virtue of the follower list , we construct a social network of the users included in our crawl . Since collaboration is symmetric in nature , we treat the edges as being undirected . For each pair of users u and v such that ( u , v ) is an edge , we assume their relationship strength to be proportional to the fraction of projects they have worked on together in the past . If Nu and Nv denote the set of projects in which u and v are listed as contributors , |Nu∩Nv| |Nu∪Nv| . then their relationship strength is defined as σu,v = Finally , we use the following function to estimate the collaboration cost between u and v : w(u , v ) = 100 · ( 1 − σu,v ) . 15 . We experimentally verified that this cost function produces intuitive values for the edge weights such that the teams which are highly active ( hence large number of commits ) , have small cost measured in diameter , steiner and bottleneck edge cost models .
14We believe that comparing number of commits of a smaller team with a larger one will be unfair . Therefore , we group teams by their size and compare among teams of same size . 15The constant 100 is arbitrary and is used to avoid rounding errors in our computation .
1010 l n o i t u o S e b s a e F i l f o e g a t n e c r e P
100
75
50
25
MinMaxSol MinDiamSol GreedyDiam MinAggrSol GreedySteiner m a e T a f o t s o C e g a r e v A
2000
1000
500
Actual GreedyDiam GreedySteiner
MinMaxSol MinDiamSol GreedyDiam MinAggrSol GreedySteiner
250
200
150
100
50 i
) s c e s n i ( e m T n o i t a t u p m o C e g a r e v A
0
1
2
3
4
5
6
2 h ( maximum hop length )
4
3 Number of items ( size of network = 135k )
5
6
7
8
9
10
11
2
3
4
5
6
7
8
9
10
11
Number of items ( size of network = 135k )
Figure 4 : Experimental results for the GitHub dataset .
Items Items in data set D1 correspond to programming languages required by the projects and there are 52 of them in our crawl . For each user , we construct her set of items as the collection of programming languages required by her projects .
Tasks In GitHub , tasks correspond to project requirements created by users . We use the projects in D2 and their requirements ( in terms of programming languages ) as tasks for our experiments . Observe that , D2 is not used for estimating other parameters since it might bias the experiment . Further , we synthetically generate few more project requirements for our experiments . Unfortunately , a uniform random sampling of items is not guaranteed to generate realistic project requirements . Instead , we look at the cooccurrences of the items ( bi grams and n grams in general ) to generate synthetic requirements . Capacity To get an understanding of capacities of users , we picked a set of ( ≈ 2k ) users who are believed to be active and looked at the commit logs for their listed projects over a period of one month . Among the listed projects16 , we declare a project to be active for that user , if she made at least one commit during that one month period . The result of this experiment is plotted in Figure 3 . The plot reveals an interesting trend the number of projects contributed by a user is often significantly less compared to the number of projects listed for the user . We strongly believe that this difference is due to the limited capacities of users . Finally , we compute the capacity of user u as ln(1 + Nu ) , where Nu is the number of projects contributed by u , as listed by GitHub . 4.4 Results
441 Comparison with existing GitHub teams
The first set of experiments is to highlight the fact that our techniques can significantly improve the social collaboration cost of existing projects in GitHub . In order to achieve that , we worked with projects in D2 and collected their composition in terms of the list of users who contribute to them and the set of programming languages , number of units of each language needed etc . For every project , we compute the solutions returned by algorithms MinDiamSol and MinAggrSol and compare their cost against the diameter and steiner cost of the actual team . For nearly 40 % of the projects , we observed a reduction of cost in the range of 10 % − 35 % . In Figure 5 , we plot the result for the MinAggrSol . The results for other algorithms are similar and not repeated here .
16All projects listed by GitHub are active ie they are being contributed to by some users in the network .
0 5
)
%
( s t c e o r p j f
0 4
0 3 o n o i t c a r F
0 2
0 1
0
0−10
10−15
15−20
20−25
25−30
30−35
Relative improvement in cost ( % )
Figure 5 : Improvement in collaboration cost as computed by MinAggrSol algorithm over existing teams in GitHub .
For approximately 5 % of the projects , we observed that our algorithms obtained solution which has higher cost than the actual teams . We believe that this is due our imprecise modeling of the input parameters as the test data D2 was kept separate and not used for estimating cost , items and capacities of the users . For rest of the projects , our algorithm reported minor improvement ( < 5 % ) over the existing teams .
442
Scalability
For the purpose of this experiment , we generate subgraphs of the github network of varying sizes ( between 10k and 135k ) . The subgraphs are created by randomly selecting a node and performing breadth first search around it . We create synthetic requirements for a randomly selected root user , through the steps described in Section 4.3 , and measure the time taken by our algorithms 17 . Finally , we report the average over 10 such measurements . In Figure 7 , we plot the result of this experiment . It can be seen that , Algorithms MinMaxSol and MinDiamSol are highly efficient , taking approximately 30 secs on the 135k network . Algorithm MinAggrSol on the other hand scales almost linearly with increasing network size ( nearly 6 min on the 135k subgraph ) .
443 Comparison with Baseline
Baseline Algorithms For baseline comparison , we implement an adapted version of the algorithms RarestFirst and 17For this experiment , we set h to ∞ ; ie the algorithms are run on the entire subgraph .
1011 MinAggrSol MinDiamSol MinMaxSol i
) s c e s n i ( e m T n o i t a t u p m o C e g a r e v A
350
250
150
50
10k 25k
50k
75k
100k
135k size of the network ( number of nodes )
Figure 7 : Computation time of different algorithms with varying network size ( in github ) .
EnhancedSteiner , from the work of Lappas et al [ 6 ] . For a given task , these algorithms find a team of experts from a social network . However , they are not designed to handle capacity constraints on the users . We modify these algorithms as follows first , we run the algorithm and inspect its solution . If the solution is feasible ( cf Section 2.2 ) , we declare it to be valid . Otherwise , for any user u whose capacity constraint is not met , we perform a reallocation of items . Among the items that are assigned to u , we order them based on their rarity the minimum increase in cost to cover the item by other users who are not included in the current solution , and greedily assign the top bu rarest items to u . After we have performed reallocation for all violating users , we contract the set of users into a single node of the graph and repeat the step , until a feasible solution is attained . We name these algorithms GreedyDiam and GreedySteiner respectively .
Results Our current set of experiments is designed to evaluate the performance of MinDiamSol and MinAggrSol with respect to the baseline heuristics . We first determine the minimum value of h , the maximum hop length , for which our input tasks have feasible solution . In Figure 4 , we plot the result of this experiment ( leftmost plot ) . As it can be seen , for a value of h = 3 , our tasks ( both real and synthetic ) have feasible solutions . However , it turns out that both GreedyDiam and GreedySteiner fail to find feasible solutions for all of the tasks unless we increase h to 5 . We therefore set h to 5 for the rest of the experiments .
Figure 4 summarizes the result of our experiment with real tasks . The experiments reveal that MinDiamSol achieves at least 25 % reduction in cost as compared to GreedyDiam . The improvement is much more pronounced in the steiner cost version where our algorithm significantly outperforms the GreedySteiner heuristic by at least 40 % . Our careful inspection of the steps of GreedySteiner reveals that by ignoring capacities of users in its decision making process , it actually ends up including a large number of steiner nodes in the solution and thereby , increasing the cost . The plot on running time ( Figure 4 ) indicates that our algorithms scale linearly with the number of items in a task . 18 4.5 Experiments on DBLP data
Our second data set is obtained from DBLP [ 13 ] and consists of a snapshot of computer science publications taken on December 5th , 2011 . Each publication is written by a set of authors . We follow the same pre processing steps as described in Lappas et al [ 6 ] to generate input parameters 18We also performed experiments with synthetic tasks . The results are similar and not repeated here ( see [ 12] ) . for our algorithms . In addition , we determine capacity of an author u as the average number of publications co authored by u in a year .
Unlike GitHub , DBLP dataset doesn’t have an explicit notion of social graph . We generate the social network based on co authorship : two authors are connected by an edge if they have co authored at least two papers together . The collaboration cost of an edge ( u , v ) is estimated in the following way : If Su ( Sv ) denotes the set of research articles co authored by u ( v resp . ) then the cost of edge ( u , v ) is estimated as 100 · ( 1 − |Su∩Sv| |Su∪Sv| ) . Once again , the constant 100 is arbitrary and is used to avoid any rounding error in computation . Following the pre processing stage , the DBLP dataset contains 7332 authors , 19248 articles and 2763 distinct items .
451 Results
The result of our experiment is summarized in Figure 6 . Since the DBLP network is slightly denser than GitHub , the baseline algorithms can find feasible teams within 4 hops of the root user . Therefore , for the purpose of this experiment , h is set to 4 . We observe that MinDiamSol and MinAggrSol achieve ≈ 20 % improvement over the baseline heuristics . As mentioned earlier , our synthetic construction of the DBLP network is slightly denser than GitHub and contains users with large number of publications ( hence large capacity ) . This fact has led to slight reduction of the gains reported by our algorithms as compared to GitHub experiments .
To conclude , through a fairly extensive set of experiments on real world datasets , we have evaluated the performance of our team formation algorithms . Experimental results suggest that our algorithms outperform other naive strategies by a significant margin ( 20 40 % ) and scale well with hundreds of thousands of users .
5 . RELATED WORK
Team formation is a well studied problem in the Operations Research ( OR ) community [ 4 , 5]In their setting , the goal is to find an allocation of tasks to different individuals so as to satisfy the project requirements . However , this body of work ignores the social relationship among people while deciding the best team and unfortunately , their techniques can not be applied to solve our problem .
Lappas et.al [ 6 ] considered the problem of finding team of experts on a social network . Given a requirement of skills , their goal is to find a team that minimizes the overall communication cost . Although they have a similar objective in mind , our problem is fundamentally very different from them . In [ 6 ] , the authors don’t deal with capacities on users . In effect , their problem can be thought of as uncapacitated version of our problem . As per our understanding , the notion of capacity changes the problem structure completely and their solutions can no longer be adapted to handle our requirement . Moreover , through detailed experiments ( see Section 4 ) , we have established that a natural extension of their algorithms perform very poorly compared to ours .
In [ 14 ] , the authors studied a version of the team formation problem where the goal was to balance the load ( iethe number of projects one is assigned to ) of individuals . However , this version of the problem overlooks the social collaboration cost altogether . In a more recent study [ 7 ] , the authors present algorithms which , in addition to load balance , also find teams with bounded social collaboration cost .
1012 l l n o i t u o S e b s a e F i f o e g a t n e c r e P
100
75
MinMaxSol MinDiamSol GreedyDiam MinAggrSol GreedySteiner m a e T a f o t s o C e g a r e v A
1000
500
100
Actual GreedyDiam GreedySteiner
0
1
2
3
4
5
4
6
8 h ( maximum hop length )
12
14 10 Number of items
16
18
20
) s c e s f o g o l n i ( e m T n o i t a t u p m o C i
. g v A
100
10
0.1
4
6
8
MinMaxSol MinDiamSol GreedyDiam MinAggrSol GreedySteiner
12
10 14 Number of items
16
18
20
Figure 6 : Experimental results for the DBLP dataset .
Their formulation is , however , different from ours in addition to finding teams with bounded collaboration cost , they attempt to minimize the load on team members , whereas , we take the user capacities as constraint and attempt to minimize the social collaboration cost .
The specific techniques required to estimate the strength of relationship among individuals has been pursued in recent research works [ 15 , 16 ] . However , these techniques can not be applied to estimate edge costs in our problem as they rely on peer interactions ( eg e mails exchanged etc . ) which is not available for our data sets . We believe that this direction of research is complimentary to our problem and beyond the scope and goal of this paper .
6 . CONCLUSION
In this work , we presented a novel team formation problem on social networks that attempts to find teams that are socially close as well as division of the task so that no user is overloaded by the assignment . We presented algorithms for this problem under different models of social collaboration and analyzed their performance thoroughly . Our experiments with real life data sets show that these techniques outperform the naive strategies by a significant margin .
7 . REFERENCES [ 1 ] D . McDonald , “ Recommending collaboration with social networks : A comparative evaluation , ” in CHI’03 , 2003 .
[ 2 ] T . Wolf et al . , “ Mining task based social networks to explore collaboration in software teams , ” Software , IEEE , 2009 .
[ 3 ] GitHub , “ http://githubcom ” [ 4 ] A . Baykasoglu et al . , “ Project team selection using fuzzy optimization approach , ” Cybern . Syst . , 2007 .
[ 5 ] H . Wi et al . , “ A team formation model based on knowledge and collaboration , ” Expert Syst . Appl . , 2009 .
[ 6 ] T . Lappas et al . , “ Finding a team of experts in social networks , ” in KDD ’09 , 2009 .
[ 7 ] A . Gionis et al . , “ Online team formation in social networks , ” in WWW ’12 , 2012 .
[ 8 ] V . V . Vazirani , Approximation Algorithms . Springer ,
2004 .
[ 9 ] L . Wolsey , “ An analysis of the greedy algorithm for the submodular set covering problem , ” Combinatorica , vol . 2 , pp . 385–393 , 1982 .
[ 10 ] G . Nemhauser and L . Wolsey , “ Maximizing submodular set functions : Formulations and analysis of algorithms , ” in Annals of Dis . Math , 1981 .
[ 11 ] K . Melhorn , “ A faster approximation algorithm for steiner tree problem in graphs , ” Inf Process . Lett . , vol . 27 , pp . 125–128 , 1988 .
[ 12 ] S . Datta , A . Majumder , and K . Naidu , “ Capacitated
Team Formation Problem on Social Networks , ” arXiv:1205.3643v1 , May 2012 .
[ 13 ] DBLP , “ http://dblpuni trierde ” [ 14 ] A . Anagnostopoulos et al . , “ Power in unity : forming teams in large scale community systems , ” in CIKM ’10 , 2010 .
[ 15 ] R . Xiang et al . , “ Modeling relationship strength in online social networks , ” in WWW ’10 , 2010 .
[ 16 ] J . Leskovec et al . , “ Predicting positive and negative links in online social networks , ” in WWW ’10 , 2010 .
APPENDIX A . PROOF OF LEMMA 4
Proof . Observe that MaxItems is a monotone function for S ⊆ T , MaxItems(S ) ≤ MaxItems(T ) . In order ie to prove sub modularity , we need to establish the following result : for two arbitrary subsets A and B , MaxItems(A ) + MaxItems(B ) ≥ MaxItems(A ∪ B ) +MaxItems ( A ∩ B ) . As a first step , we prove it for sub sets A and B such that A ∩ B = ∅ . For a given task T , consider the allocation of items by MaxItems on the set of users A∪B . Let nA and nB denote the number of items assigned to sets A and B respectively . Since MaxItems(A ) assigns the maximum possible items to A we can claim nA ≤ MaxItems(A ) and similarly , nB ≤ MaxItems(B ) . The proof follows by observing that MaxItems(A ∩ B ) = 0 since A and B are disjoint . For the general case , consider an allocation of the given task T to the set of users A ∪ B by MaxItems(A ∪ B ) . Let nA , nB and nA∩B denote the number of items assigned to sets A , B and A ∩ B respectively . Therefore , nA + nB − nA∩B = MaxItems(A ∪ B ) . Applying a similar reasoning ( as in the last paragraph ) we get , MaxItems(A ) + MaxItems(B ) ≥ MaxItems(A∪ B ) +n A∩B . Now the only thing needs to be proved is whether there exists some solution of MaxItems(A∪B ) such that nA∩B = MaxItems(A∩ B ) . This can be achieved by constructing a minimum cost flow network in the following way : In the construction of Lemma 2 , consider all edges of the form ( li , ru ) where i is an item and u ∈ A∪B . The edge is assigned a cost zero only if u ∈ A ∩ B . For all other users , the cost is set to 1 . For other set of edges , the cost is set to zero . Finally , we compute a minimum cost flow of value MaxItems(A ∪ B ) . It is easy to verify that this construction produces a re allocation of MaxItems(A ∪ B ) so that nA∩B = MaxItems(A ∪ B ) and this completes our proof .
1013
