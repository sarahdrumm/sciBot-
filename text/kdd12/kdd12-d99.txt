Incorporating Heterogeneous Information for Personalized
Tag Recommendation in Social Tagging Systems
Wei Feng
Tsinghua University
Beijing , China
Jianyong Wang Tsinghua University
Beijing , China feng w10@mailstsinghuaeducn jianyong@tsinghuaeducn
ABSTRACT A social tagging system provides users an effective way to collaboratively annotate and organize items with their own tags . A social tagging system contains heterogeneous information like users’ tagging behaviors , social networks , tag semantics and item profiles . All the heterogeneous information helps alleviate the cold start problem due to data sparsity . In this paper , we model a social tagging system as a multi type graph . To learn the weights of different types of nodes and edges , we propose an optimization framework , called OptRank . OptRank can be characterized as follows:(1 ) Edges and nodes are represented by features . Different types of edges and nodes have different set of features . ( 2 ) OptRank learns the best feature weights by maximizing the average AUC ( Area Under the ROC Curve ) of the tag recommender . We conducted experiments on two publicly available datasets , ie , Delicious and Lastfm Experimental results show that : ( 1 ) OptRank outperforms the existing graph based methods when only <user , tag , item> relation is available . ( 2 ) OptRank successfully improves the results by incorporating social network , tag semantics and item profiles .
Categories and Subject Descriptors H33 [ Information Storage and Retrieval ] : Information Search and Retrieval—Information Filtering , Retrieval Models , Selection Process
General Terms Algorithms
Keywords Recommender System , Social Tagging System
1 .
INTRODUCTION
In social tagging systems , users can annotate and organize items with their own tags for future search and sharing . For u1 u2
: : : ujUj U sers t1 t2
: : : tjT j
T ags i1 i2
: : : ijT j
Items
Figure 1 : Social Tagging System example , users can annotate and share Web pages in Delicious1 . Besides Delicious , there are many other social tagging system like Last.fm2 and YouTube3 in entertainment domain and CiteULike4 in the research domain .
Personalized tag recommendation is the key part of a social tagging system . When a user wants to annotate an item , the user may have his/her own vocabulary to organize items . Personalized tag recommendation tries to find the tags that can precisely describe the item with the user ’s vocabulary . A social tagging system , as shown in Figure 1 , contains heterogeneous information and can be modeled as a graph :
• Users(U ) , tags(T ) and items(I ) co exist in the graph .
• Inter relation . Edges between users , tags and items can be derived from annotation behaviors <user , tag , item> . Suppose we have u ∈ U and t ∈ T , the weight of <u , t> is the times of tag t being used by user u . The same rule applies to <u , i> and <i , t> ( i ∈ I ) .
• Intra relation . ( 1 ) Social network among users.(2 ) Tag semantic network based on semantic relatedness . ( 3 ) Item network based on content similarities .
While the inter relation has been well studied in previous work [ 4 , 5 , 12 , 13 , 16 , 17 ] , few work tries to incorporate all the intra relation into a unified model . Incorporating the intra relation may solve the cold start problem due to data sparsity . Users in a social network may influence each other by sharing some annotated items . Semantically related tags may co occur to describe an item . Items that have similar contents may be annotated with the same tag .
When a user u wants to annotate an item i , the recommended tags should meet two requirements : ( 1 ) Highly relevant to user u because users have their own way to organize items . ( 2 ) Highly relevant to item i because tags should precisely describe the item . To rank the tags , we can perform
1http://delicious.com 2http://wwwlastfm 3http://wwwyoutubecom 4http://wwwciteulikeorg
1276 a random walk with restart at user u and item i to assign each tag a visiting probability , which is used as the ranking score . Only tags that are both relevant to u and i can get high scores . However , two problems arise when the random walk is performed on the multi type graph :
• Different types of edges have different meanings and thus are measured in different metrics . For example , the edge weights of a social network may be binary and they have completely different meanings from other types of edges , such as the edges formed by tagging behaviors <user , tag , item> . To perform a random walk , they need to be measured under the same metric .
• The random walker can either restart from the user u or the item i . The probabilities of restart at u and at i should be estimated .
To solve the above two problems , we propose an optimization framework called OptRank . OptRank can be characterized as follows :
• Edges are represented by features . Different types of edges have different set of features . For example , <u1 , u2> ( u1 , u2 ∈ U ) in a social network is represented by the feature set {the number of common tags , the number of common items} . The edge <t , u> ( u ∈ U , t ∈ T ) is represented by the feature {the times of t being used by u} . Each feature has a feature weight . The edge weight is decided by both the features and the feature weights .
• User u and item i for recommendation are represented by a constant feature but their feature weights are learned separately .
• OptRank learns the feature weights by maximizing the average AUC ( Area under the ROC Curve ) of the tag recommender .
Although graph based methods have been studied in the field of personalized tag recommendation by many researchers [ 4 , 5 , 17 ] , most of them belong to the unsupervised approach , in which the edge weights and restart probabilities of u and i are empirically assigned . Inspired by the recent development of semi supervised learning [ 3 ] and graph based learning [ 1 ] , we are able to turn the existing unsupervised graph based methods into supervised methods . More specifically , we extend the supervised random walk proposed in [ 1 ] for link prediction into the setting of personalized tag recommendation . This paper has two major differences from [ 1 ] : ( 1 ) The graph in our setting contains different types of edges , each of them has their own set of features and the corresponding feature weights are learned separately . ( 2 ) Since we have two nodes for restart , we further introduce node features .
To summarize , our contributions are as follows : • To solve the cold start problem due to data sparsity , we are among the first to explore the three new relations : social network , tag semantic relatedness and item content similarities .
• We propose a graph model and extend the random walk with restart to the multi type graph to handle different types of relations uniformly .
• We propose an optimization framework to learn the best edge weights and node weights by maximizing the average AUC of the tag recommender .
The remainder of this paper is organized as follows . The problem we addressed is formulated in Section 2 . Graph model and random walk with restart are introduced in Section 3 . Our optimization framework OptRank is introduced in Section3 . Experimental study is described in Section 5 . Related work is introduced in Section 6 . We conclude the paper and discuss the future work in Section 7 .
2 . PROBLEM STATEMENT AND BASIC FR
AMEWORK
Personalized Tag Recommendation . Given a user u and an item i , personalized tag recommendation tries to find tags to describe or classify the item i precisely according to u ’s vocabulary . Inter relations and intra relations among users , items and tags are considered , which makes the graph as a multi type graph ( as shown in Figure 1 ) .
Highly ranked tags should be relevant to both u and i . To achieve this goal , a random walk with restart is performed on the multi type graph with restart at user u and item i . Only tags that are both near to u and item i can get a high visiting probability . Formally , the random walk with restart is performed according to the following equation :
( t+1 )
  pU pT pI
 
= ( 1 − α)A  pU pT pI
( t )
 
+ α  qU 0 qI
  ( 1 ) where
• α is the restart probability . ( 1 α ) means that the random walker has the probability of ( 1 α ) to perform a random jump based on his current state .
U , pT
T , pT
• pT = ( pT
I ) is a vector of visiting probabilities of all nodes . pT contains the ranking scores for each tag .
• A is the transition matrix that stores graph structure information . A is obtained by normalizing each column of the adjacency matrix A to sum to 1 .
• qT = ( qT
U , 0T , qT
I ) is the preference vector that contains the restart probabilities of each node . q is obtained by normalizing the node weight vector q to sum to 1 .
The transition matrix A and the preference vector q will be introduced in detail in Section 3 .
Optimization Framework To get a good ranking by following Equation 1 , the transition matrix A and the preference vector q need to be carefully assigned . Thus we develop an optimization framework called OptRank .
Given a user u and an item i for personalized tag recommendation , suppose u has finally annotated i with tags ( t1 , t2 , tk ) , these tags are defined to be positive tags , denoted by P T . The rest tags are defined to be negative tags , denoted by N T . In other words , the whole tag set T is divided into two parts , ie T = P T ∪ N T .
A good ranking function defined by Equation 1 should rank all the positive tags higher than the negative tags . For a randomly picked positive tag t1 and a negative tag t2 , a good ranking function has a high probability of ranking t1 higher than t2 . This is the idea of AU C ( Area Under the ROC Curve ) metric . Formally , AU C is defined by the following equation :
( 2 )
AU C = Pi∈P T Pj∈N T
|P T ||N T |
I(pT ( i ) − pT ( j ) )
1277 where I(x ) is 1 when x > 0 . Otherwise I(x ) is 0 .
Our goal is to find the best transition matrix A and the preference vector q to maximize the AU C . To achieve this , edges are represented by features X and nodes u and i are represented by features Y . To better illustrate the idea , we can assume the adjacency matrix A only contains edges of the same type . A with different types of edges will be introduced in Section 31 binary relations , ie , social network , tag semantic relatedness and item content similarities are mapped to edges . ( 3 ) For ternary relation <user , tag , item> where three nodes are involved , binary relations can be derived by projections on each dimension . For example , suppose we have <u , t , i> ( u ∈ U , t ∈ T , i ∈ I ) , <i , t> can be derived by projecting on the user dimention . <i , t> is described by the feature which is the times of i annotated with t .
• Each edge <v , u> ( u,v∈ U ∪ T ∪ I ) is represented by a feature vector X(u , v ) . Let θ represent the vector of feature weights , the edge weight A(u , v ) is computed by A(u , v ) = fedge(θT X(u , v) ) , where fedge:R → R+ . • User u and item i are respectively represented by feature vector5 YU = ( 1 ) and YI = ( 1 ) . Let ξ denote the feature weights . The node weights qU ( u ) and qI ( i ) are computed by qU ( u)=fnode(ξT U YU ) and I YI ) , where fnode:R → R+ . Other enqI ( i)=fnode(ξT tries of qU and qI are all 0 .
According to the above representation , the transition matrix A and the adjacency matrix A can be rewritten to A(θ ) and A(θ ) . q and q can be rewritten to q(ξ ) and q(ξ ) . This means they are respectively decided by parameters θ and ξ . Since the random walk is defined by A(θ ) and q(ξ ) according to Equation 1 , we know that p can be rewritten to p(θ , ξ ) , which means the final ranking scores are parameterized by θ and ξ . However , to make the following formulae more clear , we will not rewrite the above notations with parameters θ and ξ .
With edges and nodes parameterized by θ and ξ , we give a formal description of our optimization framework . Given a user u and an item i for tag recommendation and the positive tag set , the optimization problem is
AU C(θ , ξ ) = Pi∈P T Pj∈N T max θ ,ξ
|P T ||N T |
I(pT ( i ) − pT ( j ) )
However , the above equation only considers a single training instance . When m instances {< uk , ik , P Tk >}m k=1 are considered , the cost function J(θ , ξ ) is defined as the average AU C :
Pi∈P TkPj∈N Tk
|P Tk||N Tk|
I(pT ( i ) − pT ( j ) ) max θ ,ξ
J(θ , ξ ) =
1 m mXk=1 where N Tk = T − P Tk .
The optimization framework OptRank and its solution will be introduced in Section 4 .
3 . GRAPH MODEL
Before introducing the optimization problem , we first introduce more details about Equation 1 . Section 3.1 introduces the transition matrix . Section 3.2 describes the preference vector . Section 3.3 introduces more intuitions and details of the random walk with restart .
3.1 Transition Matrix
Transition matrix stores the graph structure information . Before defining the transition matrix , we first introduce how to construct a graph from a social tagging system . The graph shown in Figure 1 is constructed with three steps : ( 1 ) Users , tags and items are mapped as the nodes . ( 2 ) All the 5Nodes are allowed to have more than one feature , so YU and YI are still in bold to represent vectors .
Now we define the adjacency matrix . Let G denote the whole graph as shown in Figure 1 and A denote its adjacency matrix . Let GM N ( M , N ∈ {U , T , I} ) denote the each sub graph made up by relation <m,n> ( m ∈ M , n ∈ N ) and
AM N denote its adjacency matrix . We have G=SM,N∈{U,T ,I}
GM N and A is composed of sub matrices AM N :
A = 
AU U AU T AU I AT U AT T AT I AIU AIT AII
 
( 4 )
Recall that edges are represented by features .
In Section 2 , the edge feature set is denoted by X and the feature weights is denoted by θ . Since different types of edges have different features and feature weights . We have X={XM N | M , N ∈{U , T , I}} and θ={θM N |M , N ∈ {U , T , I}} . Given an edge <m,n>∈ {M , N } , AM N ( m,n ) is defined by
AM N ( m , n ) = fedge(θT
M N XM N ( m , n ) )
( 5 )
Note that XM N ( m , n ) is a vector and XM N is an array of In this paper , fedge : R → R+ is the three dimensions . sigmoid function : fedge(x ) =
1
1 + e−x
( 6 )
Transition matrix A is obtained by normalizing each col umn of A :
A = 
AU U D−1 AT U D−1 AIU D−1
U AU T D−1 U AT T D−1 U AIT D−1
T AU I D−1 T AT I D−1 AII D−1
T
I
I
I
 
( 7 ) where DU , DT and DI are diagonal matrices . The i th entry in the diagonal of DU is the out degree of the i th user . For u ∈ U , we have
PM ∈{U,T ,I}P|M |
1 k=1 AM U ( k , u )
( 8 )
DT and DI are defined in the same way . Following this definition , each column of A will be normalized to sum to 1 .
3.2 Preference Vector
U , 0T , qT
Given a user u and an item i for tag recommendation , the preference vector qT = ( qT I ) specifies the restart probability at u and i . As introduced in Section 2 , User u and item i are respectively represented by feature vector YU = ( 1 ) and YI = ( 1 ) . Let ξ = {ξU , ξI } denote the feature weights . Node weight qM ( m ) ( M ∈ {U , I} , m ∈ {u , i} ) is computed by qM ( m ) = fnode(ξT
M YM )
( 9 )
The other entries of qU and qI are all set to 0 . fnode : R → R+ is the sigmoid function in this paper : fnode(x ) =
1
1 + e−x
( 10 )
( 3 )
D−1
U ( u , u ) =
1278 u2 u1 u3 t2 t1 t4 t3 i2 i1 i3
Figure 2 : The random walker restart at u1 and i1 in no more than 2 hops
The preference vector qT = ( qT normalizing qT = ( qT
U , 0 , qT
I ) is obtained by
U , 0T , qT I ) to sum to 1 : qU D−1 0 qI D−1 q q
  q = 
( 11 )
( 12 ) where Dq is the summation of each entry in qU and qI . Formally , D−1 is defined as the following equation : q
D−1 q =
1
PM ∈{U,I}P|M | k=1 qM ( k )
Equation 11 ensures that q sums to 1 .
3.3 Random Walk With Restart
In this section , we introduce more intuitions of the random walk with restart for personalized tag recommendation .
As we introduced in Section 2 , the random walker can frequently restart at u and i to rank the tags . We illustrate this idea with an example shown in Figure 2 . In Figure 2 , we want to recommend tags for user u1 to annotate i1 , so the random walker restarts frequently from u1 and i1 . The edges indicate how the random walker jumps from node to node . u1 has the history that she/he has annotated i2 before . i1 has the history that it has been annotated by u3 . Besides annotation relation , u2 is a friend of u1 , i3 has similar contents with i1 , and t4 has high semantic relatedness with t1 . Now we discuss how the random walker behaves in no more than two hops from u1 and i1 :
• When the random walker is only allowed to jump one hop from user u1 and item i1 , the recommended tags either have been used by user u1 or have been annotated on item i1 by other users . As we can see from Figure 2 , t1 is such a tag . When u1 has annotated many items and i1 has been annotated by many users , the random walker will find the best common tags in both sets of u1 ’s tags and i1 ’s tags .
• When the random walker is allowed to jump within two hops , the recommended tags come from different sources : ( 1 ) Items annotated by u1 . For example , i2 has been annotated by u1 and i2 has a tag t2 . t2 may reflect the interests of u1 . ( 2 ) Users that have annotated item i1 . Since u3 has annotated i1 , the tags annotated by u3 may reflect the content of i1 . ( 3 ) Friends of u1 . u2 is a friend of u1 and his/her tags may also be adopted by u1 . ( 4 ) Similar items . Since i3 and i1 have similar content , the tags of i3 may also be the tags of i1 . ( 5)Semantically related tags . t4 and t1 are semantically related , which means that they may co occur in the annotation . When data is sparse , ie , u1 and i1 are both inactive , more information can be taken into account by jumping more than two hops away .
Now we introduce another intuition behind the random walk . With the transition matrix A defined by Equation 7 , we can rewrite Equation 1 as follows : pU = ( 1 − α)(AU U pU + AU T pT + AU I pI ) + αqU
( 13 ) pT = ( 1 − α)(AT U pU + AT T pT + AT I pI ) pI = ( 1 − α)(AIU pU + AIT pT + AII pI ) + αqI
( 14 )
( 15 ) where AM N =AM N D−1 N ( M , N ∈ {U , T , I} ) . AM N pN ( M , N ∈ {U , T , I} ) means that pN is spread to its neighbor nodes through the transition matrix AM N .
First we discuss the extreme case that α equals to 0 . Taking pT as an example , pT receives scores from pU through AT U , pT through AT T and pI through AT I . For t ∈ T , pT ( t ) will have a high score if t has highly ranked user neighbors , tag neighbors and item neighbors . The same rule applies to pU and pI . In other words , users , tags and items reinforce each other iteratively until a stable state is reached . However , there is no personalized information considered . Given a user u and an item i for tag recommendation , when α is greater than 0 , the random walker will restart at u and i . Besides reinforcement rule , pU , pT and pI are also influenced by the distance from u and i . Nodes that are near to u and i will get a higher ranking .
4 . OPTIMIZATION BASED FRAMEWORK In this section , we focus on how to find the best feature weights to achieve an optimal random walk with restart . Section 4.1 describes the objective function for optimization . Section 4.2 introduces how to solve the optimization problem . Section 4.3 introduces the derivatives of the random walk with respect to the feature weights , which belongs to the details in solving the optimization problem .
4.1 Objective Function
As we introduced in Section 2 , we want to maximize the average AUC of the tag recommender according to Equation 3 . To convert this problem into a minimization problem , we can rewrite Equation 2 to an equivalent form :
AU C = 1 − Pi∈P T Pj∈N T
|P T ||N T |
I(pT ( j ) − pT ( i ) )
( 16 )
This equation tells us that to maximize AUC is equivalent to I(pT ( j ) − pT ( i))/|P T ||N T | . We propose an equivalent minimization problem of Equation 3 : minimize Pi∈P T Pj∈N T mXk=1
J(θ , ξ ) = min θ ,ξ
1 m
Pi∈P TkPj∈N Tk
|P Tk||N Tk|
I(pT ( j ) − pT ( i ) )
( 17 ) Since J(θ , ξ ) is not differentiable , we can use the sigmoid function with parameter β as a differentiable approximation :
S(x ; β ) =
1
1 + e−βx
( 18 )
The bigger the β is , the smaller the approximate error is . However , when β is big , the steep gradient will cause a numerical problem . β is empirically assigned . Now we have a
1279 new objective function : min θ ,ξ
J(θ , ξ ) =
1 m mXk=1
Pi∈P TkPj∈N Tk
|P Tk||N Tk|
S(pT ( j ) − pT ( i ) )
( 19 )
4.2 Solving the Optimization Problem
We use gradient descent to solve the optimization problem . The basic idea of gradient descent is to find the direction ( gradient ) that the objective function drops down and make a small step towards the direction to update θ and ξ . However , the cost function defined in Equation 19 requires to sum up all the training instances to perform one update , which is too costly . So we update θ and ξ based on each training instance , which is called stochastic gradient descent . The algorithm is shown in Algorithm 1 .
Algorithm 1 : Stochastic Gradient Descent
Input : m training instances lr : learning rate Output : optimal θ and ξ
1 t=0 ; 2 initialize θ(0 ) and ξ(0 ) ; 3 while J(θ , ξ ) has not converged do 4
Randomly shuffle the m training instances ; foreach training instance k do
5
6 7
θ(t+1 ) = θ(t ) lr ∂Jk ( θ(t ) ,ξ(t ) ) ξ(t+1 ) = ξ(t ) lr ∂Jk(θ(t ) ,ξ(t ) ) t = t + 1 ;
∂θ
∂ξ where Jk(θ , ξ ) is the cost based on the k th instance :
Jk(θ , ξ ) = Pi∈P TkPj∈N Tk
|P Tk||N Tk|
S(pT ( j ) − ( pT ( i ) )
( 20 )
Learning rate lr decides the step size towards the dropping direction . The random shuffle at Line 4 is required by stochastic descent for convergence . The updating rules for θ and ξ are shown in Lines 5 and 6 . We will discuss how to compute ∂Jk(θ , ξ)/∂θ and ∂Jk(θ , ξ)/∂ξ in detail in the following .
∂Jk(θ , ξ )
∂θ
∂Jk(θ , ξ )
∂ξ
= Pi∈P Tk∧j∈N Tk
∂S(δji )
∂δji ∂pT ( j )
|P Tk||N Tk|
∂θ − ∂pT ( i )
∂θ
= Pi∈P Tk∧j∈N Tk
∂S(δji )
∂δji ∂pT ( j )
|P Tk||N Tk|
∂ξ − ∂pT ( i )
∂ξ
( 21 )
( 22 ) where δji = pT ( j ) − pT ( i ) . ∂S(δji)/∂δji is easy to compute . According to Equation 18 , we can derive that ∂S(δji)/∂δji = βS(δji)(1 − S(δji) ) . The remaining question is how to compute ∂pT ( j)/∂θ and ∂pT ( i)/∂ξ , which will be discussed in the next section .
4.3 Derivatives of the Random Walk
In this section , we will discuss how to compute the derivatives of the random walk . Suppose pT = ( pT I )T , we want to compute ∂p/∂θ and ∂p/∂ξ . The basic idea is that we can derive a similar iterative way to compute derivatives from the definition of random walk . Derivatives with respect to θ . Since ∂p/∂θ is composed of ∂p/∂θM N ( M , N ∈ {U , T , I} ) , without loss of generality ,
U , pT
T , pT we introduce how to compute ∂p/∂θU U . Taking the derivatives with respect to θU U on both sides of the Equations 13 , 14 , 15 , we can get
∂pU ∂θU U
= ( 1 − α ) XN∈{U,T ,I}
AU N
∂pN ∂θU U
+
∂AU N ∂θU U pN
∂pT ∂θU U
∂pI ∂θU U
= ( 1−α ) XN∈{U,T ,I} = ( 1 − α ) XN∈{U,T ,I}
AT N AIN
∂pN ∂θU U
+
∂AT N ∂θU U
∂pN ∂θU U
+
∂AIN ∂θU U
( 23 ) pN ( 24 ) pN ( 25 )
Following the same rule , we can compute the derivatives with respect to any θM N ( M , N ∈ {U , T , I} ) , which all lead to the same form with the above three equations . To better illustrate the connections between computing p and computing ∂p/∂θM N , we can rewrite the above three equations with θU U replaced by θM N in the matrix form :
 
∂pU
∂pT
∂pI
∂pU
∂θM N
∂pT
∂θM N
∂pI
∂A
∂θM N
∂θM N
∂θM N
∂θM N
∂θM N
 
 
 +(1−α )
 = ( 1−α)A   pU pT pI ( 26 ) where A is the transition matrix defined in the original random walk . Comparing the above equation with Equation 1 for computing p , we can find two differences : ( 1 ) p is replaced by ∂p/∂θM N . ( 2 ) The last term on the right side is totally changed . However , only the first term ( 1 − α)A∂p/∂θM N decides whether Equation 26 will converge to a stable state . More details about the convergence are discussed in the appendix .
The last detail is how to compute ∂A/∂θM N . Without loss of generality , we discuss how to compute ∂A/∂θU U . Recall that A is composed of sub matrices {AM N |M , N ∈ {U , T , I}} and not all AM N are related with ∂θU U . According to Equation 7 , only AU U , AT U and AIU can be influenced by θU U . So we only need to compute ∂AU U /∂θU U , ∂AT U /∂θU U , ∂AIU /∂θU U . Take ∂AU U /∂θU U for example , we can get
∂AU U ∂θU U
=
∂AU U ∂θU U
D−1
U + AU U
∂D−1 U θU U
( 27 )
Each entry of AU U is defined according to Equation 5 . For u1 , u2 ∈ U , we have
∂AU U ( u1 , u2 )
∂θU U
=
∂fedge(θT
U U XU U ( u1 , u2 ) ) ∂θU U
( 28 )
Each entry in the diagonal of D−1 U is the out degree of a user . According to Equation 8 , for u ∈ U , the derivative is
∂D−1
U ( u , u ) ∂θU U
= −
P|U | k=1
∂AU U ( k,u )
∂θU U k=1 AM U ( k , u))2
( PM ∈{U,T ,I}P|M |
( 29 )
So far we have explained how to compute ∂AU U /∂θU U . The same process can be used for computing ∂AT U /∂θU U and ∂AIU /∂θU U .
Derivatives with respect to ξ . Computing ∂p/∂ξ is analogous to computing ∂p/∂θ . Since ∂p/∂ξ is composed of ∂p/∂ξM ( M ∈ {U , I} ) , without loss of generality , we
1280 first focus on how to compute ∂p/∂ξU . Taking the partial derivatives with respect to ξU on both sides of Equations 13 , 14 and 15 , we can get
∂pU ∂ξU
∂pT ∂ξU
∂pI ∂ξU
= ( 1 − α ) XN∈{U,T ,I} = ( 1 − α ) XN∈{U,T ,I} = ( 1 − α ) XN∈{U,T ,I}
AU N
∂pN ∂ξU
+ α
∂qU ∂ξU
AT N
∂pN ∂ξU
+ α
∂qT ∂ξU
AIN
∂pN ∂ξU
+ α
∂qI ∂ξU
( 30 )
( 31 )
( 32 )
Following the same rule , ∂p/∂ξI can also be obtained . Replacing ξI with ξM ( M ∈ {U , I} ) , we can rewrite the above three equations to a single equation in the matrix form :
 
∂pU ∂ξM ∂pT ∂ξM ∂pI ∂ξM
  = ( 1 − α)A 
∂pU ∂ξM ∂pT ∂ξM ∂pI ∂ξM
 + α  
∂qU ∂ξM ∂qT ∂ξM ∂qI ∂ξM
  ( 33 )
From the above equation , we can see that computing ∂p/∂ξM also has the same form with Equation 1 . More details on the convergence will be discussed in the appendix .
The last detail is how to compute ∂q/∂ξM ( M ∈ {U , I} ) . Without loss of generality , suppose M is U , according to Equation 11 , we have
∂q ∂ξU
=
 
D−1 q + qU
∂D−1 q ∂ξU
∂qU ∂ξU 0 qI
∂D−1 q ∂ξU
 
( 34 )
Each entry of qU is defined according to Equation 9 . For u ∈ U , we have
∂q(u ) ∂ξU
=
∂fnode(ξT ∂ξU
U YU )
( 35 )
When fnode is the sigmoid function , we know that dfnode(x ) / dx = [ fnode(x)][1 − fnode(x) ] . D−1 is defined according to Equation 12 and the derivative is q
∂D−1 q ∂ξU
= −
( 36 )
P|M | k=1
∂qU ( k )
∂ξU k=1 qM ( k))2
( PM ∈{U,I}P|M |
So far we have described how to compute ∂q/∂ξU . The same process can be performed to compute ∂q/∂ξI
To sum up , we have introduced how to compute ∂p/∂θ and ∂p/∂ξ , which can be summarized by Algorithm 2 .
5 . EXPERIMENTAL STUDY
5.1 Datasets
We test OptRank on two publicly available datasets6 : Delicious and Last.fm , which are published by [ 2 ] as benchmarks . Delicious contains 437593 posts involving 1867 users , 40678 tags , 69223 items , 15328 user relations , 197438 tag relations and 151971 item relations . All types of intrarelations we studied are included in Delicious . Posts are represented by <user , tag , item> . Last.fm contains 24164 posts involving 1892 users , 9749 tags , 12523 items and 25434
Algorithm 2 : Derivatives of the random walk
Input : Transition matrix A and preference vector q
Output : ∂p
∂θ and ∂p
∂ξ
1 t=0 ; 2 Initialize p(t ) 3 while p has not converged do 4 5 p(t+1 ) = ( 1 α)Ap(t ) + α q t = t + 1 ;
( 0 )
;
6 t=0 ; 7 Initialize ∂p ∂θ 8 while ∂p 9 10
Computing ∂p ∂θ t = t + 1 ;
∂θ has not converged do
( t+1 ) according to Equation 26
11 t=0 ; 12 Initialize ∂p ∂ξ 13 while ∂p
( 0 )
;
∂ξ has not converged do
14 15
Computing ∂p ∂ξ t = t + 1 ;
( t+1 ) according to Equation 33 user relations . Last.fm is a smaller dataset and only user relations are available . We introduce each type of relation and its features as follows .
Inter relation . For edge <m,n> ( m ∈ M ∧n ∈ N ∧M , N ∈ {U , T , I} ∧ M 6= N ) , the feature vector X M N ( m , n ) = ( the times of m co occurred with n in the posts ) . For example , suppose we have <u , t> ( u ∈ U ∧ t ∈ T ) , X U T ( u , t ) = ( the times of u co occurred with t in the posts ) , which means the times of t used by u . In our experiments , we use the same feature set to denote <m,n> and <n,m> . This means that AM N and ANM are both decided by ξM N and θM N . User Relation . User relations are formed by the social network . Each relation is bi direction and binary weighted . To find the strength of a user relation , we check their items and tags in common . More formally , user u can be represented by an item vector AIU ( · , u ) and a tag vector AT U ( · , u ) . Each entry of AIU and AT U is re weighted by TF IDF . Users and items can be viewed as documents and words in the infor
AM N re weighted by TF IDF . For edge <u1 , u2> ( u1 , u2 ∈ mation retrieval . Let eAM N ( M , N ∈ {U , T , I} ) denote the U ) , the feature vector XU U ( u1 , u2 ) = [ cos(eAT U ( · , u1 ) , eAT U ( · , u2) ) , cos(eAIU ( · , u1 ) , eAIU ( · , u2) ) ]
Tag Relation . Tag semantic relatedness is computed with the help of Wikipedia7 . To be more specific , 47 % tags are article titles in Wikipedia . Articles link to each other by anchor texts . Semantic relatedness of tag pairs can be inferred from the the number of links between article pairs . We use WikipediaMiner [ 10 ] , which is an off the shelf tool , to calculate semantic relatedness . Only tag pairs that have semantic relatedness larger than 0.25 are retained . To refine the edge weights , tags are also represented by user vectors and item vectors . We perform the same TF IDF weighting technique to AU T and AIT . Let eAU T and eAIT denote the
TF IDF weighted matrix . For edge ( t1 , t2 ) ( t1 , t2 ∈ T ) , edge
6http://wwwgrouplensorg/node/462
7http://wwwwikipediaorg
1281 feature XT T ( t1 , t2 ) = [ semantic relatedness , cos(eAU T ( · , t1 ) , eAU T ( · , t2) ) , cos(eAIT ( · , t1 ) , eAIT ( · , t2)) ] .
Item Relation . We calculate item similarities based on Web page titles in Delicious . A title is a vector of words with TF IDF weighting on each entry . Besides content similari ties , we refine edge weight with TF IDF weighted eAU I and eAT I . For <i1 , i2> ( i1 , i2 ∈ I ) , XII ( i1 , i2 ) = [ cos(title1 , title2 ) , cos(eAU I ( · , i1 ) , eAU I ( · , i2) ) , cos(eAT I ( · , i1 ) , eAT I ( · , i2) ) ]
Like logistic regression , we add a constant feature 1 to each feature set XM N and all the features are normalized to have mean 0 and standard deviation 1 . 5.2 Baselines
Since OptRank is an extension of existing graph based methods , we want to prove two points : ( 1 ) OptRank outperforms existing graph based methods when only <user , tag , item> is available . ( 2 ) OptRank further improves the performance by incorporating social networks , tag semantic relatedness , item content similarities . we choose two graph based methods as our baselines .
Random Walk with Restart . Random Walk with Restart , called RWR for short , is the unsupervised version of OptRank . RWR performs on the graph defined by <user , tag , item> . The weight of the edge <m,n> ( m ∈ M ∧ n ∈ N ∧ M , N ∈ {U , T , I} ∧ M 6= N ) is the times of m cooccurred with n in the posts . Given a user u and an item i for tag recommendation , when the random walker decides to restart , it has the probability of 0.5 to restart at u and 0.5 to restart at i . RWR has been adopted in [ 6 ] to incorporate social networks , but the different types of edges are normalized empirically and are hard to reproduce .
FolkRank . FolkRank is a state of the art graph based algorithm . The graph is defined in the same way with RWR . FolkRank can be summarized as three steps : ( 1 ) Calculate a global PageRank score pglobal for each node . ( 2 ) Calculate a personalized PageRank score ppref with special preference to u and i for each node . ( 3 ) Calculate FolkRank score as the wins and loses between the personalized PageRank ppref and the global PageRank pglobal , ie , score = ppref −pglobal . In our experiments , we set the damping factor to 0.7 , which achieves the best performance for FolkRank . In our experiments , FolkRank is denoted by ‘FR’ .
We are aware that there are many methods based on tensor factorization[12 , 13 , 15 ] . However , tensor factorization needs to learn a low rank approximation vector for each user , item and tag . In OptRank , a user can even not exist in the training set but can still get recommendation if she/he has neighbors in the test set . OptRank only needs about 3000 training instances to reach its best performance . However , tensor factorization would fail with such a small training set , which is unfair . For this reason , we did not choose these methods as baselines .
5.3 Evaluation Methodology Performance Measurements . We use average precision , precision recall curve and average AUC ( Area under the ROC Curve ) to measure the performance . We are aware that the optimal of AUC is not necessarily the optimal of average precision/recall . To trade off between best AUC and best precision , we choose the model that has both high AUC and precision in the cross validation set . Then the model is evaluated on the test set .
C U A
0.99
0.988
0.986
0.984
0.982
0.98
0.978
0.976
0.974
AUC Precision
0.4
0.35
0.3
0.25
0.2
0.15 i i n o s c e r P
0.2 0.3 0.4 0.5 0.6 0.7 0.8
α
Figure 3 : The effect of α
Training/Cross Validation/Test Set . Posts are aggregated into records <u , i , PT> ( u ∈ U , i ∈ I ) . For each dataset , we randomly picked 5000 , 3000 , and 3000 records as the training set , cross validation set , and test set .
5.4 Parameters β and learning rate . β in Equation 18 controls the error of approximating I(x ) . The bigger β is , the smaller the approximate error is . However , when β gets too big , the derivative at x = 0 will also get too steep and will cause a numeric problem . When β gets too small , minimizing J(θ , ξ ) would fail to maximize AUC . From Equations 21 and 22 , we can know that the summation of the derivatives is divided by |P Tk||N Tk| . Since large dataset has big |P Tk||N Tk| , we can use a big β . In our experiments , β is 109 in Delicious and 106 in Lastfm Learning rate lr is strongly related to β . When lr gets too big , stochastic gradient descent would fail to converge . lr is set to 10 in both datasets . Restart Probability α . α controls how frequently the random walker chooses to restart . We evaluate how AUC and precision change by differing α from 0.2 to 0.8 in Delicious . The results are shown in Figure 3 . OptRank was run on the inter relation formed by <user , tag , item> . When precision and AUC are both considered , α ∈[0.6 , 0.8 ] seems to be a good choice . Finally , we set α to 07
5.5 Experimental Results Results on Delicious . Results on Delicious are shown in Table 1 and Figure 4 . FR denote FolkRank . OptRank Edge , OptRank Node and OptRank EN denote OptRank with only edge features enabled , only node features enabled , and both features enabled , respectively . Firstly , we compare the algorithms that are only performed on inter relations formed by <user , tag , item> . Since RWR always performs better than FR , we only compare OptRank with RWR in the following . When only edge features are enabled , OptRank Edge has comparable performance with RWR . This indicates that the original transition matrix of RWR and FR is nearly optimal . When only node features are enabled , OptRank Node learns the best weights for u and i , which improves the top1 precision by 3.3 % compared with RWR . This indicates the original node weight is not optimal . When edge features and node features are both enabled , OptRank EN futher improves the top 1 precision by 2.4 % based on OptRank Node . From Figure 4 we can know that the OptRank EN outperforms RWR at top 5 but the advantage disappears at top 10 . However , since a user usually annotates an item with less than 5 tags , top 5 performance is considered more important than top 10 performance . In terms of AUC , FolkRank
1282 i i n o s c e r P
FR RWR OptRank_EN OptRank_I OptRank_UTI
0.35
0.3
0.25
0.2
0.15
0.1
FR RWR OptRank_EN OptRank_U
0.55
0.5
0.45
0.4
0.35
0.3 i i n o s c e r P
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4
0.25 0.3 0.35 0.4 0.45 0.5 0.55 0.6
Figure 4 : Precision Recall Curve on Delicious
Figure 5 : Precision Recall Curve on Last.fm
Recall
Recall
Table 1 : Precision and AUC on Delicious
Algorithm FR RWR OptRank Edge OptRank Node OptRank EN OptRank U OptRank T OptRank I OptRank UTI
P@1 0.219 0.233 0.234 0.266 0.290 0.297 0.302 0.303 0.316
P@2 0.180 0.197 0.194 0.204 0.239 0.247 0.245 0.242 0.262
P@3 0.163 0.179 0.171 0.179 0.201 0.215 0.213 0.210 0.223
AUC 0.6851 0.9812 0.9851 0.9833 0.9862 0.9862 0.9862 0.9863 0.9869 has relatively poor performance , worse than the precision . In contrast , RWR has a much better average AUC . This is probably because FolkRank is an empirically designed algorithm and relies too much on the global information . We can see that a high precision does not indicate a high AUC . Now we discuss how OptRank performs when extra user relations , tag relations and item relations exist . When each type of relation is considered separately , OptRank U , OptRank T and OptRank I improve the top 1 precision by around 1 % based on OptRank EN , which is not very significant compared with previous improvement . However , as we can see from Figure 4 , the top 10 performance of OptRank I is significantly improved compared with OptRank EN . Since OptRank U , OptRank T and OptRank I are comparable , only OptRank I is shown in Figure 4 . When all the relations are combined , we can see that OptRank UTI achieves the best performance at all top k performance . In terms of AUC , OptRank UTI also achieves the best performance .
Results on Lastfm The results are shown in Figure 5 and Table 2 . The results are significantly better than the results on Delicious . This can be explained in terms of data sparsity . When only inter relations are considered , a post can be viewed as an entry in the three dimension array spanned by users , tags and items . 1.05 × 10(−7 ) and 0.83 × 10(−7 ) of the entries in Last.fm and Delicious are known , respectively . Thus Last.fm is less sparse and more predictable than Delicious . In Last.fm , all algorithms have comparable performance at top 10 . So we mainly focus on the top 5 performance in this experiment and this is reasonable since users usually annotate an item within 5 tags . From Figure 5 we can know that FolkRank and RWR have comparable performances in term of precision , which is different from the results on Delicious . When node features and edge features are both considered , OptRank EN improves P@1 , P@2 and P@3 by 1.2 % , 1.5 % , 1.5 % respectively compared with FR and RWR . Although Last.fm is less sparse than Delicious ,
Table 2 : Precision and AUC on Last.fm
P@1 Algorithm 0.495 FR 0.495 RWR OptRank EN 0.507 OptRank U 0.532
P@2 0.410 0.410 0.425 0.436
P@3 0.355 0.355 0.369 0.373
AUC 0.9509 0.9969 0.9973 0.9975 when the social network is combined , OptRank U successfully improves the top 1 precision by 3.7 % compared with the two baselines . In terms of AUC , empirically designed FR still falls behind other methods . OptRank U achieves the highest AUC .
To sum up , we have two conclusions from the experiments : ( 1 ) When only <user , tag , item> is available , OptRank outperforms RWR and FolkRank . ( 2 ) OptRank successfully combined extra relations to improve the performance . Now we discuss some details about the training process . Since Delicious is bigger and takes more time , the training size and running time are reported according to Delicious . Over fitting Issues . Over fitting does not seem to be a problem in our model since we only have 18 parameters when all the relations are combined8 . OptRank UTI achieves nearly the same top 1 precision in the cross validation set and test set . Training Size . The training size is really small compared with tensor factorization . OptRank EN achieves its best performance when 600 training instances are passed . OptRank UTI achieves its best performance when 1200 training instances are passed . Running Time . The experiments were conducted on a single PC with a 2 core 3.2GHz CPU and 2G main memory . We implemented the algorithm in Matlab with full vectorization . When all the relations are combined , each training instance takes nearly 3.5 seconds . Prediction takes around 0.1 seconds per instance and most of the time is spent on computing the gradients . Training with 5000 instances would take 4.8 hours at most . However , all the algorithms in our experiments achieve their best performance within 2000 training instances .
6 . RELATED WORK
There are mainly three approaches for personalized recommendation in social tagging systems : ( 1 ) Graph based approach [ 4 , 5 , 17 ] . ( 2 ) Tensor decomposition [ 12 , 13 , 15 ] . The annotation relation is modeled as a cube with many
8Each inter relation has 2 parameters , user relation has 3 parameters , tag relation and item relation has 4 parameters , respectively .
1283 unknown entries . After performing tensor decomposition , we can predict the unknown entries by low rank approximations . ( 3 ) User/Item based collaborative filtering [ 8 , 11 , 18 ] . The original user item matrix is extended by including tag information so that we can apply user/item based collaborative filtering methods .
Besides annotation behaviors , user space , tag space and item space have also been explored . [ 9 ] has studied trust networks and proposed a factor analysis approach based on probabilistic matrix factorization . [ 6 ] incorporates social network for item recommendation , but fails to improve the performance significantly . [ 14 ] links social tags from Flickr into WordNet . [ 7 ] introduces item taxonomies into recommender systems .
This paper is mainly inspired by two recent work on graphbased learning [ 1 ] and semi supervised learning [ 3 ] . [ 1 ] proposes supervised random walks to learn the edge weights for link prediction in homogenous graph . This paper extends [ 1 ] with multi type edges and nodes . [ 3 ] has proposed similar idea to learn edge weights and node weights with an inductive learning framework in homogenous graph . Since a recommender should have the ability to predict for future events , our framework is different from [ 3 ] in that ours belongs to transductive learning .
7 . CONCLUSION AND FUTURE WORK
In this paper , we propose an optimization based graph method for personalized tag recommendation . To alleviate data sparsity , different sources of information are incorporated into the optimization framework . There are some problems unsolved for future work : ( 1 ) Reducing the graph size . Since the random walker frequently restarts at u and i , nodes that are far away from u and i may be cut without influencing the final ranking . ( 2 ) Comparing with tensor factorization methods under a suitable experiment setting . ( 3 ) More features can be explored to further improve the results , such as the temporal factors .
8 . ACKNOWLEDGMENTS
This work was supported in part by National Basic Research Program of China ( 973 Program ) under Grant No . 2011CB302206 , and National Natural Science Foundation of China under Grant No . 60833003 .
9 . REFERENCES
[ 1 ] L . Backstrom and J . Leskovec . Supervised random walks : predicting and recommending links in social networks . In WSDM , pages 635–644 , 2011 .
[ 2 ] I . Cantador , P . Brusilovsky , and T . Kuflik . Workshop hetrec 2011 . RecSys 2011 . ACM , 2011 .
[ 3 ] B . Gao , T Y Liu , W . Wei , T . Wang , and H . Li .
Semi supervised ranking on very large graphs with rich metadata . In KDD , pages 96–104 , 2011 .
[ 4 ] Z . Guan , J . Bu , Q . Mei , C . Chen , and C . Wang .
Personalized tag recommendation using graph based ranking on multi type interrelated objects . In SIGIR , pages 540–547 , 2009 .
[ 5 ] R . J¨aschke , L . B . Marinho , A . Hotho ,
L . Schmidt Thieme , and G . Stumme . Tag recommendations in folksonomies . In PKDD , pages 506–514 , 2007 .
[ 6 ] I . Konstas , V . Stathopoulos , and J . M . Jose . On social networks and collaborative recommendation . In SIGIR , pages 195–202 , 2009 .
[ 7 ] H . Liang , Y . Xu , Y . Li , and R . Nayak . Personalized recommender system based on item taxonomy and folksonomy . CIKM ’10 , pages 1641–1644 , 2010 . [ 8 ] H . Liang , Y . Xu , Y . Li , R . Nayak , and X . Tao .
Connecting users and items with weighted tags for personalized item recommendations . HT ’10 , pages 51–60 . ACM , 2010 .
[ 9 ] H . Ma , T . C . Zhou , M . R . Lyu , and I . King .
Improving recommender systems by incorporating social contextual information . ACM Trans . Inf . Syst . , 29:9:1–9:23 , Apr . 2011 .
[ 10 ] D . Milne . An Open Source Toolkit for Mining
Wikipedia , volume 2889 . 2009 .
[ 11 ] J . Peng , D . D . Zeng , H . Zhao , and F y Wang .
Collaborative filtering in social tagging systems based on joint item tag recommendations . CIKM ’10 , pages 809–818 . ACM , 2010 .
[ 12 ] S . Rendle , L . B . Marinho , A . Nanopoulos , and
L . Schmidt Thieme . Learning optimal ranking with tensor factorization for tag recommendation . In KDD , pages 727–736 , 2009 .
[ 13 ] S . Rendle and L . Schmidt Thieme . Pairwise interaction tensor factorization for personalized tag recommendation . In WSDM , pages 81–90 , 2010 .
[ 14 ] B . Sigurbj¨ornsson and R . van Zwol . Flickr tag recommendation based on collective knowledge . WWW ’08 , pages 327–336 . ACM , 2008 .
[ 15 ] P . Symeonidis , A . Nanopoulos , and Y . Manolopoulos . Tag recommendations based on tensor dimensionality reduction . In RecSys , pages 43–50 , 2008 .
[ 16 ] P . Symeonidis , A . Nanopoulos , and Y . Manolopoulos . A unified framework for providing recommendations in social tagging systems based on ternary semantic analysis . TKDE , 22(2):179–192 , 2010 .
[ 17 ] H . Yildirim and M . S . Krishnamoorthy . A random walk method for alleviating the sparsity problem in collaborative filtering . In RecSys , pages 131–138 , 2008 .
[ 18 ] Y . Zhen , W J Li , and D Y Yeung . Tagicofi : tag informed collaborative filtering . RecSys ’09 , pages 69–76 . ACM , 2009 .
APPENDIX We prove the convergence of Equations 26 and 33 . Both the equations can be rewritten to a more general form : p(t+1 ) = λAp(t ) + µq where 0≤ λ , µ ≤1 , A is a transition matrix with each column summing to 1 and q can be any vector with the same dimension of p . Suppose p(0 ) = π , we have p(1 ) = λAπ + µq , p(2 ) = ( λA)2π + λAµq + µq , , p(n ) = ( λA)nπ + k=0 ( λA)kµq . Since 0≤ λ , µ ≤1 and the eigenvalues of the transition matrix A are in [ 1 , 1 ] , we have limn→∞(λA)n = k=0 ( λA)k = ( I − λA)−1 . So p(n ) finally
Pn−1 0 and limn→∞Pn−1 converges to p∗ = ( I − λA)−1µq .
1284
