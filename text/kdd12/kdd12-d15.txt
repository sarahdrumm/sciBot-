Active Learning for Online Bayesian Matrix Factorization
Dept . of Electrical and Computer Engineering
Dept . of Electrical and Computer Engineering
Lawrence Carin
Duke University
Durham , NC lcarin@duke.edu
Jorge Silva
Duke University
Durham , NC jgsilva@dukeedu
ABSTRACT The problem of large scale online matrix completion is addressed via a Bayesian approach . The proposed method learns a factor analysis ( FA ) model for large matrices , based on a small number of observed matrix elements , and leverages the statistical model to actively select which new matrix entries/observations would be most informative if they could be acquired , to improve the model ; the model inference and active learning are performed in an online setting . In the context of online learning , a greedy , fast and provably nearoptimal algorithm is employed to sequentially maximize the mutual information between past and future observations , taking advantage of submodularity properties . Additionally , a simpler procedure , which directly uses the posterior parameters learned by the Bayesian approach , is shown to achieve slightly lower estimation quality , with far less computational effort . Inference is performed using a computationally efficient online variational Bayes ( VB ) procedure . Competitive results are obtained in a very large collaborative filtering problem , namely the Yahoo! Music ratings dataset .
Categories and Subject Descriptors H28 [ Database management ] : Database applicationsData mining
Keywords Online learning , matrix factorization
INTRODUCTION
1 . There has been growing interest in the problem of matrix completion , ie , estimating unknown elements in matrices based on a subset of observed entries ( with the observed entries usually assumed observed at random ) . Concretely , assume that X ∈ RNu×Nv is a matrix , for which we know only the values of the elements xij at locations given by the set Ω = {(i , j ) : xij is observed} . In a collaborative filter
KDD 2012 Beijing , China ing/recommender system setting , Nu is often the number of users , while Nv is the number of items .
The matrix X can be very large ; also , the number of observations can be very small relative to Nu × Nv , but large in absolute terms , which poses computational and statistical challenges . For example , in the Netflix challenge [ 2 ] there are Nu = 480189 users , Nv = 17770 movies and the number of observed ratings is |Ω| = 100480507 , which corresponds to less than 1.18 percent of X . More recently , the even larger Yahoo! Music dataset [ 4 ] has been released . It contains |Ω| = 262810175 ratings ( integers between 0 and 100 ) pertaining to Nu = 1000990 users and Nv = 624961 items ( music tracks , albums , artists and genres ) .
X ≈ UT V ,
For many such real problems , the matrices of interest can be assumed to be approximately low rank , in which case it is appropriate to consider a matrix factorization model of the form
( 1 ) with U ∈ RK×Nu , V ∈ RK×Nv and K Nu , Nv . Recent advances in matrix completion theory [ 3 ] provide bounds on the number of observations needed for successfully recovering low rank matrices using convex optimization ( and assuming the observed entries are selected at random ) . However , existing convex optimization algorithms are incapable of handling the very large matrix sizes typical of real collaborative filtering problems .
Hence , the most popular approaches for large scale problems are based on solving ( 1 ) , or some variant thereof , for U , V through minimization of the 2 norm of the residual computed for the known locations Ω ( see , eg , [ 7] ) . Regularization is often employed , typically using the 2 or ∞ norm [ 9 ] of the parameters ( these regularizers are imposed on the columns of U and V ; the 1 or 0 sparseness regularizers characteristic of convex optimization solutions [ 3 ] are not used here , because we explicitly set the rank to K , with K Nu , Nv ) . Due to memory and speed considerations , the minimization is often performed through stochastic gradient descent . Stochastic gradient descent is an online learning method , in which the training examples are presented sequentially , obviating the need to store the entire dataset in memory . Typically , the order of presentation is random . Stochastic gradient descent has also been used successfully in other large scale problems such as image inpainting [ 11 ] and topic modeling [ 5 ] . It enjoys local convergence guarantees , as shown in [ 17 ] .
Alternative methods for solving ( 1 ) include Bayesian probabilistic matrix factorization [ 16 ] , which achieves state of theart performance on the Netflix dataset . However , since this is a batch method , scalability to even larger problems such as the Yahoo! Music dataset is less straightforward than with stochastic gradient descent . Additionally , [ 16 ] uses Markov chain Monte Carlo inference , for which it is harder to assess convergence .
In our work , we propose a statistical factor analysis ( FA ) model that extends the basic low rank factorization shown in ( 1 ) , and we develop an associated variational Bayesian ( VB ) [ 1 ] online inference algorithm , which incorporates the scalability of stochastic gradient descent while providing approximate posterior estimates of all model parameters . Other VB methods that have been applied to collaborative filtering , such as [ 10 , 14 ] , are based on batch learning . Our method is an online extension of the batch VB principal component analysis ( PCA ) approach proposed in [ 14 , 15 , 12 ] .
Another contribution of our paper is that we leverage the statistical model to actively select the best subset of observations at each step of the online learning process , instead of assuming that the training examples follow a random order of presentation as in stochastic gradient descent . This active learning procedure is motivated by the fact that each measurement xij is often obtained sequentially and requires user interaction , which may be expensive and time consuming . Therefore , by prioritizing the most informative users and items , we can potentially guide the data acquisition process in a more efficient way . In general , the problem of finding the m best locations of X to measure is NP complete . We avoid this difficulty by developing two types of greedy algorithms : ( i ) a near optimal method based on [ 8 ] , relying on the submodularity properties of mutual information ; ( ii ) a simpler algorithm based on the estimated variance of the user and item factors returned by the VB inference . A non Bayesian active algorithm is also used for comparison .
The remainder of the paper is organized as follows . Section 2 describes our proposed factor analysis model , as well as the associated VB inference . This section also briefly discusses how to incorporate time information in the model . The active learning algorithms are presented in Section 3 , which also contains an explanation of the submodularity property . Experimental results with online VB and active learning on the Yahoo! Music dataset are shown in Section 4 . Concluding remarks are presented in Section 5 .
2 . FACTOR ANALYSIS MODEL The matrix factorization problem expressed in ( 1 ) can be cast as factor analysis ( FA ) with xij = uT i vj + ij , where ij is a residual term , assumed small , ui ∈ RK is the ith column of U , and vj ∈ RK is the jth column of V . Previous work on collaborative filtering [ 7 , 6 ] shows that it is advantageous to also incorporate user and item biases , leading to the complete FA model xij = αi + βj + uT i vj + ij .
( 2 )
The scalars αi and βj allow the model to adapt to phenomena such as anomalous user behavior or different item popularities . A particular item j may be popular among all users , and therefore this item does not provide as much informa tion about individual preferences , which are captured in the feature vectors ui ; if this is the case for item j , the model should infer the associated βj as being large . Likewise , a given individual i may rate all items as being poor/good , and this individual therefore does not provide as useful information about the features of the items vj ; in this case αi would be correspondingly small/large . In the statistical literature , these inferred biases are often called random effects .
Defining the independent priors p(αi ) = N ( 0 , τ 2 α ) p(βj ) = N ( 0 , τ 2 β ) N ( uki ; 0 , 1 ) p(U ) =
K K k=1
NU NV i=1 p(V ) =
N ( vkj ; 0 , ρ2 k ) k=1 j=1 k ) = InvGamma(κ1 , κ2 ) p(ρ2 p( ij ) = N ( 0 , σ2 )
( 3 )
( 4 )
( 5 )
( 6 )
( 7 )
( 8 ) with hyperparameters σ2
, τ 2
α , τ 2
β , κ1 , κ2 , and the likelihood p(xij|α , β , U , V , ρ ) = N ( xij ; αi + βj + uT i vj , σ2 )
( 9 ) completes the model specification . In the above expressions , InvGamma denotes the inverse gamma distribution , and the notation uki , vkj refers to the ( k , i)th and ( k , j)th elements of U and V , respectively . For simplicity , we set the value of σ , although it would also be possible to define a corresponding inverse gamma prior . Note that we choose a unit variance prior for ui ; otherwise , the product of the variances of ui and vj would not be identifiable .
Our goal is to estimate posteriors for the model parameters λ = {α , β , U , V , ρ} given the observed data D = {xij : ( i , j ) ∈ Ω} at locations Ω .
2.1 Variational Bayes inference The posterior distribution of the model parameters satisfies p(α , β , U , V , ρ|D ) ∝p(D|α , β , U , V , ρ ) p(α)p(β)p(U)p(V)p(ρ ) ,
( 10 ) while the negative logarithm of the posterior is , up to constant terms , given by ij
( xij − αi − βj − uT i vj)2 +
1 2σ2 x
K k=1
( uk2
2 +
1 2
1 ρ2 k vk2 2 ) ,
( 11 ) where uk and vk are the kth rows of U and V , respectively . Hence , the statistical model is closely related to optimization based approaches with 2 regularization on the model components [ 7 ] . An important advantage of the statistical model is that it does not require cross validation for regularization terms ( Lagrange multipliers in optimizationbased methods ) . Moreover , it yields an approximate posterior on all model parameters , instead of maximum a posteriori ( MAP ) point estimates .
As the true posterior p(α , β , U , V , ρ|D ) is not tractable , we employ a variational approximation [ 1 ] . In general , assume that λ denotes parameters to be inferred , and D represents observed data . The likelihood of the data is p(D|λ ) and the prior on the parameters is p(λ ) . It follows that the posterior on the model parameters is p(λ|D ) = dλp(D|λ)p(λ ) p(D|λ)p(λ )
( 12 )
Let q(λ ; θ ) be a parametric distribution with parameters θ , and consider the variational expression
F ( θ ) = dλq(λ ; θ ) log q(λ ; θ ) p(D|λ)p(λ )
= DKL[q(λ ; θ)p(λ|D ) ] − log p(D ) .
( 13 )
Minimization of F ( θ ) in ( 13 ) with respect to θ corresponds to minimization of the Kullback Leibler divergence between q(λ ; θ ) and the true posterior p(λ|D ) . form q(λ ; θ ) = l q(λl ; θl ) .
For the parametric distribution , we use a fully factorized If q(λi ; θi ) and the prior for λi are selected in the conjugate exponential family , then we obtain closed form expressions for the θi , based on gradient descent of F ( θi ) [ 1 ] . This procedure is guaranteed to converge to a local optimum , and it extends MAP estimation of θ , yielding an approximate posterior .
The term variational comes from calculus of variations ; we choose a class Q such that q(λ ; θ ) ∈ Q and then minimize a functional over Q . As discussed above , minimization of the functional F ( θ ) is equivalent to minimization of the Kullback Leibler ( KL ) divergence between q and the true p(λ|D ) . We choose Q to be fully factorized distributions ; for the problem at hand , we write q(α , β , U , V , ρ ; θ ) = q(αi ) q(βj ) q(uki ) j k,i k,j q(ρk ) , i q(vkj )
( 14 )
( 15 )
( 16 )
( 17 )
( 18 )
( 19 ) where k q(uik ) = N ( µuki , σ2 uki ) q(vkj ) = N ( µvkj , σ2 vkj ) q(αi ) = N ( µαi , σ2 αi ) q(βj ) = N ( µβj , σ2 βj ) q(ρ2 k ) = InvGamma(ξ1k , ξ2k ) . vkj}} . uki},{σ2 k},{ξ1k},{ξ2k},{µuki},{µvkj},{σ2
The posterior parameters are θ = {{µαi} , {µβj} , {σαi} , {σβj},{ρ2 Defining the cost function CKL F ( θ ) , we build on [ 14 ] , where the gradients wrt the components of θ are derived . We depart from [ 14 ] in the following way : the dataset D is partitioned into smaller subsets S ( t ) , called mini batches , which change for each iteration t . The standard stochastic gradient approach [ 9 ] is to draw each mini batch S ( t ) uniformly at random from the ( fixed ) training set D . Then , in the sums over i and j below , only the indices in the current S ( t ) are considered . All mini batches have the same size m , which is chosen to yield the best trade off between computational speed and robustness to local minima .
Example components of the gradient so computed are
∂CKL ∂µuki
= µuki +
−(xij − αi − βj −K m=1 µumi µvmj )µvkj + µuki σ2 vkj j:(i,j)∈S
σ2
( 20 )
∂CKL ∂µvkj
=
+
µvkj ρ2 k
−(xij − αi − βj −K m=1 µumi µvmj )µuki + µvkj σ2 uki i:(i,j)∈S
σ2
( 21 )
∂CKL ∂µαi
=
µαi τ 2 α
+
∂CKL ∂µβj
=
µβj τ 2 β
+ j:(i,j)∈S i:(i,j)∈S
−(xij − αi − βj −K m=1 µmiµmj )
σ2
( 22 )
−(xij − αi − βj −K m=1 µmiµmj )
σ2
.
( 23 )
Once we have the gradients , it is then possible to sequentially update µuki , µvkj , µαi and µβj according to i:(i,j)∈S(t ) uki + η(t ) vkj + η(t ) αi + η(t ) + η(t ) i:(i,j)∈S(t ) i:(i,j)∈S(t ) uki ← µ(t−1 ) µ(t ) vkj ← µ(t−1 ) µ(t )
αi ← µ(t−1 ) µ(t )
µ(t ) βj
← µ(t−1 )
βj i:(i,j)∈S(t )
∂CKL ∂µ(t ) uki
∂CKL ∂µ(t ) vkj
∂CKL ∂µ(t ) αi
∂CKL ∂µ(t ) βj
( 24 )
( 25 )
( 26 )
( 27 ) where η(t ) is the learning step for the gradient descent procedure . The learning step follows the schedule η(t ) = τ η(t−1 ) , where τ ∈ ( 0.5 , 1 ] controls the rate of decay of the contribution of old mini batches .
The variances can be updated according to uki ← ( 1 − η(t))σ2 σ2 uki + η(t )
µ2 vkj + σ2 vkj
σ2 j:(i,j)∈S(t ) defining eij = xij − αi − βj − ( µui
+ µuitm we now have
+ µuith ( µvj
+ µuitd
)T
+ µvjth
+ µvitd
) , vkj ← ( 1 − η(t))σ2 σ2 vkj + η(t )
+
αi ← ( 1 − η(t))σ2 σ2
αi + η(t )
βj ← ( 1 − η(t))σ2 σ2
βj + η(t )
−1 −1
( 28 )
µ2 uki + σ2 uki
σ2
−1 −1
( 29 )
( 30 )
. ( 31 )
1 σ2
1 σ2
1 +  1  1  1
ρ2 k
τα
τβ
+
+ i:(i,j)∈S(t ) j:(i,j)∈S(t ) i:(i,j)∈S(t )
∂CKL ∂µuki
∂CKL ∂µvkj
= µuki + j:(i,j)∈S j:(i,j)∈S µvkj ρ2 k
=
+ j:(i,j)∈S
−eij(µvkj + µvkjth
σ2
µuki ( σ2 vkj + σ2 vkjth σ2
+ µvkjtd
)
+
+ σ2 vkjtd
)
( 38 )
Finally , the parameters of q(ρ2 k ) obey ξ1k ← ( 1 − η(t))ξ1k + η(t)(κ1 +
ξ2k ← ( 1 − η(t))ξ2k + η(t)(κ2 +
1 2 j:(i,j)∈S(t )
K 2
)
( 32 )
µ2 vkj ) .
( 33 ) j:(i,j)∈S(t )
2.2 Using time information Each rating in the Yahoo! Music dataset includes a time stamp . This is the case both for the training set and for each ( i , j ) pair in the test set , which means that it is possible to improve the predictions by incorporating temporal information into the factor model . The following approach is based on [ 6 ] , who obtained one of the best single model results on the Yahoo! dataset . The FA model in ( 2 ) is changed to xij = αi + βj + ( ui + uitm + uith + uitd )T ( vj + vjth + uitd ) ,
( 34 ) where tm , th and td are indices over the total number of minutes , hours and days in the dataset , respectively . The large number of user/time factors ( particularly uitm ) vectors poses computational challenges ; however , each user only has ratings for very few minutes on average , which makes the storage requirements feasible .
The priors for the new factors that depend on td are
K K k=1 p(uitd ) = p(vjtd ) =
N ( ukitd ; 0 , 1 )
N ( vkjtd ; 0 , ρ2 k )
( 35 )
( 36 ) k=1 and similarly for those factors that depend on th and tm . We apply the VB algorithm to ( 34 ) in much the same way as in the original formulation , with new variational posteriors q(uitd ) , q(vjtd ) , . . . , of the same form as in Section 21 Writing out ( 34 ) as a sum of cross products , we have xij = αi + βj + uT i vj + uT i vjth + uT i uitd + uT i vjtm + . . . ( 37 ) which means that the gradient updates for αi , βj , ui and vj are changed only slightly from Section 21 For example ,
−eij(µuki + µukith
+ µukitd σ2
+ µukitm
)
+
µvkj ( σ2 vkj + σ2 ukith
+ σ2 ukitd
+ σ2 ukitm j:(i,j)∈S
σ2
)
.
( 39 )
The gradients for the new time related factors are computed similarly to those for ui and vj .
3 . ACTIVE LEARNING In the following , we address the problem of finding the best mini batch S ( t ) = {(i , j ) : xij is observed at step t} of size m , thereby extending standard gradient descent . Instead of having a fixed training set D as before , the goal is now to incrementally construct a set of observed locations A by starting with A = ∅ and sequentially appending A ← A ∪ S ( t ) . Define V = {(i , j),∀i,j} to be the set of all entries of X , whether observed or not . Hence , V\A is the set of missing locations . It is known [ 8 ] that finding the best S ( t ) among V\A is , in general , an NP hard problem . The active selection of mini batches S ( t ) may be constituted in at least two forms . In one case , all of the ( sparsely sampled ) data may be available a priori , and rather than selecting S ( t ) from that data in a random manner , one may use active learning to select the most informative samples . In a second case , we may actually seek entries ( acquire the database ) actively and sequentially , based on the results of active learning . This may be done by asking selected customers to rate selected items . There may be other settings that are a combination of the above two cases .
We wish to leverage the current posterior estimate of θ for selecting the m most informative observations in V\A . One possible strategy is to select the observations xij for which the posterior implies the greatest variance , and thus uncertainty . This method , while simple , does not account for correlations between similar samples , ie , the fact that many high variance users/items may be very similar to each other , and therefore redundant . Moreover , selecting high variance users/items tends to unduly emphasize outliers .
A better alternative is to select the observations that are most informative about V\A . Toward this end , we build on [ 8 ] , where near optimal , polynomial time greedy algorithms are proposed . These algorithms exploit submodularity properties of mutual information , under a Gaussian process formulation .
3.1 Gaussian process formulation In general , assume that each observation xs ∈ R , where s is an index over elements of V , has an associated covariate rs ∈ Rd . We wish to impose that , when rs and rs are similar , then xs and xs are correlated . If we have a vector x = ( x1 , . . . , xN ) drawn from a Gaussian process ( GP ) , with covariance function given by a Mercer kernel K(·,· ) , then x ∼ N ( µ , Σ ) , with
Σs,s = K(rs , rs ) .
( 40 ) A frequent choice for K(·,· ) is the radial basis function ( RBF ) kernel
K(rs , rs ) = exp(− 1
σ2 rs − rs2 ) .
( 41 )
A key property of GPs is that , given a vector x = ( x1 , . . . , xN ) with associated covariates ( r1 , . . . , rN ) , one may readily draw xN +1 for any new covariate rN +1 . This property facilitates active learning in the following way . Assume that the set V defines a set of covariates and the associated data vector is x ∼ GP(µ , ΣVV ) . The active learning problem now becomes one of choosing a subset A ⊂ V of covariates at which to sample data .
To connect the GP formulation with our matrix factorization problem , it is appropriate to consider the user and item factors , ui and vj , as covariates . The ratings xij are considered to be drawn from a GP where the covariance matrix is related to the ui and vj covariates , which are latent , ie , non observed . The online VB procedure is employed to provide approximate posteriors for these latent covariates .
Accordingly , we wish to define kernels which make use of the estimated posterior distributions q(ui ) and q(vi ) . A natural choice consists of the symmetrized KL divergence kernel , which for user factors ui is defined as K(ui , ui ) = exp{DKL(q(ui)||q(ui ) ) + DKL(q(ui )||q(ui))} ( 42 ) i
[ tr(Φ
− µui i
− µui
T Φ
−1 i Φi)+ + log
|Φi| |Φi| − K ] ,
DKL(q(ui)||q(ui ) ) = 1 2 i µu µu −1 where Φi diag(σ2 similarly , substituting vj for ui and Ψj diag(σ2 for Φi . Note that the matrices Φi and Ψj are diagonal , which simplifies inversions and determinants . An attractive feature of the symmetrized KL divergence kernel is the absence of tuning parameters such as kernel bandwidths . uKi ) . Item factors vj are treated u1i , . . . , σ2
( 43 ) v1j , . . . , σ2 vKj ) h(xA|xV\A ) , with h(· ) denoting the differential entropy . Given A , it is straightforward to compute MI(A ) within the GP model . However , when |A| > 1 the computation to select the set A that maximizes this mutual information is NPcomplete . This difficulty can be overcome by using the fact that MI(A ) is submodular .
Definition of submodularity [ 13 ] : A set function F : A → F ( A ) is submodular if , for all A ⊆ B ⊆ V , and y ∈ V\B , it holds that F ( A ∪ y ) − F ( A ) ≥ F ( B ∪ y ) − F ( B ) .
Intuitively , F is submodular if it has a “ diminishing returns ” property , ie , a new datum y has more impact when the set A is smaller . The following theorem ensures that choosing A to maximize F ( A ) can be done in a near optimal manner by a greedy algorithm .
Theorem [ 13 ] : Let F be a monotone submodular set function over a finite ground set V with F ( ∅ ) = 0 . Let A be the set of the first m elements chosen to maximize F ( · ) by a greedy algorithm , and let OPT= maxA⊂V;|A|=m F ( A ) . Then
F ( A ) ≥ ( 1 − 1 e
)OPT .
( 44 )
Importantly , the mutual information MI(A ) I(A;V\A ) is submodular [ 8 ] , and MI(∅)=0 . There are conditions of practical relevance for which the mutual information metric is a monotone function , namely when |A| is small relative to the total number of entries that may searched over , which is certainly the case for the massive matrices of interest here ; see [ 8 ] for a related discussion , although that work did not consider the matrix completion problem . Therefore , there exist polynomial time greedy algorithms for finding A such that
MI(A ) > ( 1 − 1/e ) max
A⊂V,|A|=m
MI(A ) − m
( 45 ) for some small . The mutual information metric discourages acquisition of samples that are anticipated to be correlated to each other based upon the GP covariance K(·,· ) . Specifically , Algorithm 1 in [ 8 ] finds candidate y ∈ V\A to maximize the increase in mutual information
MI(A ∪ y ) − MI(A ) = h(xy|xA ) − h(xy|x ¯A ) ,
( 46 ) where ¯A denotes V\(A ∪ y ) . The conditional distributions needed to compute the conditional differential entropies in ( 46 ) are readily manifested by leveraging the ability of GP to compute such densities , as discussed above . This property is a key reason for imposing the GP representation for matrix values , with associated covariates defined by the inferred feature vectors ui and vj . In the GP model , the maximization is done by computing max y
δy =
K(y , y ) − ΣyAΣ K(y , y ) − Σy ¯AΣ
−1AAΣAy −1 ¯A ¯AΣ ¯Ay
.
( 47 )
3.2 Submodularity and mutual information An appropriate criterion for choosing A is to seek to maximize the mutual information MI(A ) I(A;V\A ) = h(xA)− y|A = K(y , y ) − ΣyAΣ
Equation ( 47 ) is a ratio of conditional covariances of the −1AAΣAy , which due to the GP form σ2 properties can be computed without first measuring x at location y .
Unfortunately , the aforementioned algorithm requires O(|V\A|4 ) operations , which is indeed polynomial time but infeasible in many situations of interest . For instance , in the case of the Yahoo! dataset , we have Nu ≈ 106 and Nv ≈ 6 × 105 , leading to |V\A| ≈ 6× 1011 . This problem can be mitigated by employing Algorithm 3 in [ 8 ] which uses local kernels , ie , only a small neighborhood around each y is considered . More specifically , in expression ( 46 ) the approximation h(y| ˜A ) ≈ h(y|A ) is used , where ˜A results from removing all but the k nearest neighbors of y from A . This approximation drastically reduces the size of all Σ(·,· ) matrices in ( 47 ) , to a maximum of k× k , at a small cost in the objective function [ 8 ] . The overall complexity is thus reduced to O(|V\A| ) , which nevertheless remains impractical for our purposes .
Our proposed approach circumvents these limitations by exploiting the structure of the matrix factorization problem . Instead of exploring all possible pairs ( i , j ) , of which there are approximately NuNv , our main idea is to choose the best row and the best column separately . The resulting computations are now O(Nu ) + O(Nv ) , which is feasible .
The objective function for rows of X is , therefore ,
δi = i − ΣiAu Σ σ2 i − Σi ¯Au Σ σ2
−1AuAu −1 ¯Au ¯Au
ΣAui Σ ¯Aui
,
( 48 ) where ¯Au denotes {1 , . . . , Nu}\(Au ∪ y ) , with y the candidate ith row . An identical objective function is defined for the columns of X , substituting j for i and v for u . The goal is now to find optimum sets Su = {i1 , . . . , im} , Sv = {j1 , . . . , jm} sorted by δi and δj , respectively . Then , we form S based on Su and Sv . There are multiple possibilities for combining Su and Sv . We choose to construct S = {(i1 , j1 ) , . . . , ( im , jm)} . We then sequentially build A ← A ∪ S , as prescribed initially . The entire procedure is summarized in Algorithm 1 , which we call VB MI .
Algorithm 1 Active learning for matrix factorization with VB MI 1 : Initialize q(U ) : µ , φ , and q(V ) : ν , ψ 2 : Initialize active set A ← ∅ 3 : while Stopping criterion is not met do for i ∈ {1 , . . . , Nu}\{i : i ∈ A} do 4 : 5 : 6 : 7 :
Compute δi based on µ , φ,A and kernel K end for Repeat steps 4–6 for j ∈ {1 , . . . , Nv}\{j : j ∈ A} , Su = {i1 , . . . , im} sorted in descending order of δi Sv = {j1 , . . . , jm} sorted in descending order of δj S = {(i1 , j1 ) , . . . , ( im , jm)} Collect observations xij,∀(i , j ) ∈ S A ← A ∪ S Update µ , φ and ν , ψ via online VB
8 : 9 : 10 : 11 : 12 : 13 : 14 : end while substitute δj , ν , ψ
3.3 Simplified active learning A simpler alternative to the aforementioned submodularity approach consists of finding Su and Sv by sorting the user and item factors in decreasing order of the posterior tracecovariance , given by tr(Φi ) and tr(Ψj ) , respectively . The mini batch S is then constructed as in VB MI and appended to A . The resulting algorithm makes direct use of q(ui ) and q(vj ) without necessitating any GP formulation or kernel , and the only overhead over online VB consists of two sorting steps per mini batch , which is negligible .
As discussed above , a limitation of this approach is that it does not account for correlations , and therefore many highvariance items may also have high correlation , and consequently it is redundant to sample all of them . Nevertheless , as discussed below , this has been found to work well in practice , at low computational expense , for the large scale examples considered . This approach explicitly exploits the products ( parameter variance ) from the VB analysis , and it is referred to below as VB Variance . 3.4 Non Bayesian method For the purpose of comparison , and also to isolate the contribution of the active learning method towards performance from that of the VB algorithm , we have implemented an active learning method capable of utilizing products from a non Bayesian matrix analysis ; in that analysis , the RMSE is directly minimized wrt {αi , βi , ui , vj} by traditional gradient descent ( we learn a “ point ” estimate for these parameters , rather than estimating a full posterior ) . This is distinct from the VB method , which minimizes the KL divergence between q(α , β , U , V , ρ ; θ ) and the posterior p(α , β , U , V , ρ|X ) wrt the posterior parameters θ .
We follow an approach similar to [ 9 ] and estimate the parameters αi , βj , ui , vj by solving the optimization problem min
αi,βj ,ui,vj
( i,j)∈A
( xij − αi − βj − uT i vj)2 subject to max{ui2 |αi|2 ≤ B,∀i ,
2,vj2
2} ≤ B,∀ij |βj|2 ≤ B,∀j
( 49 ) where the constraint on the norms of the factors ui , vj is equivalent to max norm regularization of UT V , controlled by the parameter B . The max norm of a matrix Z is defined as Zmax = max{|zij|} . The bias vectors α and β are regularized in the same way .
Problem ( 49 ) can be solved by slightly modifying the simple projected gradient method proposed in [ 9 ] to take αi and βj into account . Given one training example xij , the following updates are computed for ui and vj : ui ← PB[ui − η(xij − αi − βj − uT vj ← PB[vj − η(xij − αi − βj − uT with PB(· ) a projection operator defined by 2 ≤ B 2 > B fl z z2 z2
PB(z ) = z√ B i vj)vj ] i vj)ui ] ,
( 50 )
( 51 )
.
( 52 )
Note how the gradient term −(xij−αi−βj−uT i vj)vj is also present in the VB update equation ( 20 ) , where it is weighted by the noise level 1/σ2 and combined with other terms that depend on the model variances . The updates for αi and βj are given by
αi ← PB[αi + η(xij − αi − βj − uT βj ← PB[βj + η(xij − αi − βj − uT i vj ) ] i vj) ] ,
( 53 )
( 54 ) which also resemble the corresponding VB updates .
To perform active learning with this model , the user and item submodular objective functions δi and δj are computed as before , with the difference that we can no longer use the KL divergence kernel . Instead , we define standard RBF kernels
K(ui , ui ) = exp(− 1 K(vj , vj ) = exp(− 1
σ2 ui − ui2 σ2 vj − vj2
2 )
2 )
( 55 )
( 56 ) where σ2 is the bandwidth parameter . Typically , σ2 is set via cross validation ( which we emphasize is avoided with the VB inference ) . 4 . RESULTS We first present results for the online VB algorithm applied to the dataset of Yahoo! Music ratings provided for the KDD Cup 2011 challenge [ 4 ] . The purpose of this analysis is to examine the performance of the online VB solution on such large scale data . In that analysis the mini batches in the online analysis are selected randomly , as done in most previous related research ( although virtually none of that work was done with a VB analysis ) . We then compare results in which the mini batches for the online method are selected randomly versus actively , via the method discussed in Section 3 . 4.1 Results of online VB on Yahoo! dataset We consider the FA model and online VB inference from Section 2.1 on the Yahoo! Music dataset . We set the number of factors to K = 20 and choose the learning step size to follow the rule η(t ) = τ η(t−1 ) , with η(0 ) = 2.5 × 10−7 and τ = 09 The mini batch size was set to m = |S ( t)| = 100000 . Hyperparameter values were set to σ2 β = 1,κ1 = κ2 = 10−6 , which yield standard “ flat ” ( nearly noninformative ) priors . The variational posterior parameters θ were initialized at random , and the algorithm was executed for 40 epochs . Each epoch consists of a full pass through the training set , ie , approximately 252 million ratings . A further 6 million ratings is used for validation ( these validation ratings were supplied to the users ) , while the test set consists of 4 million ratings whose scores were withheld at the time of the KDD Cup 2011 challenge . These scores have been released after the competition . The performance measure is the root mean square error ( RMSE ) over the test dataset , defined as
= 10−6,τ 2
α = τ 2
( xij − µαi − µβj − µT ui
µvj
)2 ,
( 57 )
1
|Dtest| xij∈Dtest
RMSE = where the posterior means of θ are used to provide point estimates .
We show the RMSE and computation time per epoch on both the validation and test sets for our VB method in Table 41 For comparison , we also show the RMSE and time achieved by the baseline model supplied by Yahoo! , which models the ratings as xij ≈ ai + bj + c ,
( 58 ) with ai , bj and c learned by standard stochastic gradient descent . The performance gain over the baseline is over 10 % ,
Figure 1 : RMSE on the validation set for 40 epochs . Each epoch is a full pass over approximately 252M ratings . The total running time is slightly less than 10 hours . which is considered quite significant and places the method near the top 100 in the competition . Note that the initialization is random and that there are no separate learning steps for the various parameters . Moreover , this is a single model ( the best competitors employed a blend of dozens of different models ) and it has relatively few parameters .
The convergence behavior is illustrated in Figure 41 While it takes slightly less than 10 hours to execute 40 epochs ( we have used MATLAB code , non optimized , on a 2.4 GHz CPU ) , it is apparent that the algorithm has essentially converged after approximately 25 epochs .
Additionally , we have implemented the time dependent FA model described in Section 2.2 , and achieved a further RMSE drop from 25.94 to 248 The most demanding aspect of the time dependent model is the large number of user/minute factors utm , since tm ∈ {0 , . . . 5726101} , although the fact that , on average , each user only has ratings for104 minutes in the dataset makes the storage requirements feasible . Currently , we are pursuing the implementation of active learning methods with this model ( with time dependence ) , which will likely require extensive parallelization in order to overcome the large computational requirements .
4.2 Results with active learning We have applied the three active learning procedures described in Section 3 ( VB MI , VB Variance and Non Bayesian ) to the Yahoo! Music problem , and compared to online VB with random sampling . In this analysis we consider the model in ( 2 ) , without time dependence . These experiments differ from using online VB as in Section 41 Here we synthesize all ratings , in order to be able to measure any desired xij , and not limit ourselves to the fixed training dataset D supplied by Yahoo! . We first use online VB to learn a factor model of the form ( 2 ) using all available data from D , as in Section 41 The resulting posterior parameters θ∗ are withheld . Then , we discard the data supplied by Yahoo! and use the posterior mean components of θ∗ to synthesize
0510152025303540242526272829303132Validation RMSEEpoch Table 1 : Online VB method with random mini batches vs . Yahoo! baseline model
Model Yahoo!
Online VB
Validation RMSE Test RMSE Time/Epoch ∼ 0.5 min . ∼ 15 min .
28.98 25.94
26.68 24.34 user and item factors , respectively ui and vj . The model assigns low variance to most components , which can be seen as an indicator of good model fit .
Figure 2 : RMSE over 40 epochs . The VB MI algorithm is based on mutual information with the KL divergence kernel , VB Variance is based on sampling the users and items with highest variance and the Non Bayesian method uses mutual information with the RBF kernel . any observation xij on demand , by computing xij = µ
∗ αi + µ
∗ βj + ( µ
∗ ui )T ( µ
∗ vj ) .
( 59 )
We report the RMSE on a test set of size 4 million , separately drawn at random from the factor model and withheld from the algorithms .
In all cases , the algorithms were initialized with one single mini batch of online VB and then executed for 40 epochs . The mini batch size is m = 100000 . In this setting , since there no longer exists a dataset D over which to perform a full pass , we define an epoch as the number of steps necessary for the set A to have the same size as D . Once this happens , we reset A ← ∅ and begin a new epoch . The factor model parameters carry over between successive epochs .
As seen in Figure 2 , all active methods outperform random sampling by a significant margin . The differences in RMSE between the three active methods are less pronounced , with the mutual information based VB MI algorithm slightly outperforming the others . It is particularly notable that the simpler VB Variance method is competitive with the submodularity based approaches , at a fraction of the computational cost . The running times , per epoch , of VB MI , Non Bayesian and VB Variance are 5100 seconds , 4700 seconds and 1100 seconds , respectively . Thus , the VB Variance method is only slightly more demanding than online VB .
Figure 3 shows histograms of the ( scalar ) components of the
Figure 3 : Histograms of the variance of uki ( top ) and vkj ( bottom ) , where i , j , k are indices over users , items and factors , respectively . Shown in logarithmic scale . The majority of the components have low variance .
The plot in Figure 3 depicts the trace covariance of the item factors vj , as returned by the online VB algorithm . There exists a clear relationship with the number of item ratings . As anticipated , rarely rated items tend to have higher variance , although a few spikes in the variance for relatively highly rated items may warrant further investigation . We do not show an equivalent plot for user factors due to the fact that the relationship with the number of ratings is much less evident .
5 . CONCLUSIONS We have presented an online variational Bayesian approach to the problem of large scale matrix completion , with applications in collaborative filtering . Unlike standard matrix factorization approaches , the developed statistical model en
051015202530354025325425525625725825926261EpochRMSERandomNon−BayesianVB−VarianceVB−MI002040608101234567Variance of ukiLog−frequency01020304050607001234567Variance of vkjLog−frequency challenge . ACM SIGKDD Explorations Newsletter , 9(2):75–79 , 2007 .
[ 3 ] E . Cand`es and T . Tao . The power of convex relaxation : Near optimal matrix completion . Information Theory , IEEE Transactions on , 56(5):2053–2080 , 2010 .
[ 4 ] G . Dror , N . Koenigstein , Y . Koren , and M . Weimer .
The Yahoo! Music Dataset and KDD Cup’11 . In ACM International Conference on Knowledge Discovery and Data Mining ( KDD ) , KDD Cup Workshop , 2011 .
[ 5 ] M . Hoffman , D . Blei , and F . Bach . Online learning for latent Dirichlet allocation . Advances in Neural Information Processing Systems ( NIPS ) , 23:856–864 , 2010 .
[ 6 ] M . Jahrer and A . T¨oscher . Collaborative filtering ensemble . In ACM International Conference on Knowledge Discovery and Data Mining ( KDD ) , KDD Cup Workshop , 2011 .
[ 7 ] Y . Koren . Factorization meets the neighborhood : a multifaceted collaborative filtering model . In ACM International Conference on Knowledge Discovery and Data Mining ( KDD ) , pages 426–434 , 2008 .
[ 8 ] A . Krause , A . Singh , and C . Guestrin . Near optimal sensor placements in Gaussian processes : Theory , efficient algorithms and empirical studies . Journal of Machine Learning Research , 9:235–284 , 2008 .
[ 9 ] J . Lee , B . Recht , R . Salakhutdinov , N . Srebro , and
J . Tropp . Practical large scale optimization for max norm regularization . Advances in Neural Information Processing Systems ( NIPS ) , 23:1297–1305 , 2010 .
[ 10 ] Y . Lim and Y . Teh . Variational bayesian approach to movie rating prediction . In ACM International Conference on Knowledge Discovery and Data Mining ( KDD ) , KDD Cup Workshop , pages 15–21 , 2007 .
[ 11 ] J . Mairal , F . Bach , J . Ponce , and G . Sapiro . Online learning for matrix factorization and sparse coding . Journal of Machine Learning Research , 11:19–60 , 2010 .
[ 12 ] S . Nakajima and M . Sugiyama . Implicit regularization in variational Bayesian matrix factorization . In 27th International Conference on Machine Learning ( ICML ) , 2010 .
[ 13 ] G . Nemhauser , L . Wolsey , and M . Fisher . An analysis of approximations for maximizing submodular set functions . Mathematical Programming , 14(1):265–294 , 1978 .
[ 14 ] T . Raiko , A . Ilin , and J . Karhunen . Principal component analysis for large scale problems with lots of missing values . Machine Learning : ECML 2007 , pages 691–698 , 2007 .
[ 15 ] T . Raiko , H . Valpola , M . Harva , and J . Karhunen . Building blocks for variational Bayesian learning of latent variable models . Journal of Machine Learning Research , 8:155–201 , 2007 .
[ 16 ] R . Salakhutdinov and A . Mnih . Bayesian probabilistic matrix factorization using Markov chain Monte Carlo . In Proceedings of the 25th International Conference on Machine Learning ( ICML ) , 2008 .
[ 17 ] M . Sato . Online model selection based on the variational Bayes . Neural Computation , 13(7):1649–1681 , 2001 .
Figure 4 : Trace of covariance of vj ( item factors ) as a function of number of ratings . Rarely rated items tend to have higher variance . ables sequential selection of near optimal subsets of users and items through active learning . This can be done using efficient greedy algorithms which rely on submodularity .
We have also described an alternative method based directly on the inferred variance of the factors , which relaxes the near optimality guarantees and requires much lower computational effort , at the cost of a small performance penalty . The aforementioned methods have been compared with random sampling and with a non Bayesian submodularity based algorithm .
We have demonstrated the proposed framework using the challenging Yahoo! Music dataset , with promising results . Notably , all proposed active learning algorithms outperform random sampling . Comparison with the non Bayesian method shows comparable performance . However , the RBF kernel in non Bayesian method requires tuning of the bandwidth parameter , while the KL divergence kernel used in the Bayesian approaches is parameter free . Moreover , the computational overhead of the submodular methods far outweighs the difference in computations between the Bayesian and non Bayesian algorithms . Importantly , neither the KL divergence kernel nor the fast variance based active learning algorithm would be possible without the ( approximate ) posterior estimate provided by the Bayesian method .
Future research will focus on incorporating temporal information into the active learning algorithms . This should be possible via developments in parallel computation .
Acknowledgements The research reported here was supported by ARO , NGA , ONR and DARPA ( MSEE program ) .
6 . REFERENCES [ 1 ] H . Attias . A variational bayesian framework for graphical models . Advances in Neural Information Processing Systems ( NIPS ) , 12(1 2):209–215 , 2000 .
[ 2 ] R . Bell and Y . Koren . Lessons from the Netflix prize
050010001500200025003000350040004500050100150200250300Num . ratings ( thousands)Trace of covariance of Vj
