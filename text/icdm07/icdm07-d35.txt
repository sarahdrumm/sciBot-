Seventh IEEE International Conference on Data Mining Seventh IEEE International Conference on Data Mining Seventh IEEE International Conference on Data Mining Seventh IEEE International Conference on Data Mining Seventh IEEE International Conference on Data Mining
Mechanism Design for Clustering Aggregation by Selfish Systems
Department of Computer Science , Hong Kong Baptist University , Hong Kong SAR , China
Pinata Winoto , Yiu ming Cheung , Jiming Liu
{pinata , ymc , jiming}@comphkbueduhk
Abstract followed by mechanism design issue in Section 4 . Finally , Section 5 provides future work .
We propose a market mechanism that can be implemented on clustering aggregation problem among selfish systems , which tend to lie about their correct clustering during aggregation process . Our study is the preliminary step toward the development of robust distributed data mining among selfish systems .
1 . Introduction
In almost all the clustering aggregation algorithms , in order to make the clustering aggregation work , the locally obtained cluster labels are correctly reported [ 1 , 3 , 5 , 6 , 11 , 12 , 13 , 14 ] . However , in certain scenarios in distributed data mining , several systems performing data clustering locally may not be willing to report correct labels .
In general , we are interested in the situation where systems are unwilling to share complete data but limited information . An example of this setting is sharing cluster labels of bank customers . Suppose all banks have common customers who have different relationships with each bank , which has the classification of them . However , they will not share the classification due to privacy issue or in protecting their interest . Instead , cluster labels are shared .
The interpretation of clustering aggregation results is solely on the discretion of each bank . How to implement a mechanism so that each bank will report true cluster labels and thus to convince more banks to engage in aggregation activity is the goal of our recent work . To solve it , we adopt technique which has been developed in economics for decades and in multi agent systems recently : mechanism design .
Our analysis can be applied to selfish systems , such as e commerce systems . Our study can also be extended to the aggregation of multiple classifier systems . The rest of the paper is organized as follows . In the next section , we will present related work . Then in Section 3 is our clustering aggregation framework ,
2 . Related work
21 Mechanism design
Mechanism design is a branch of game theory aiming at designing a game so that it can attain the ( designer ’s ) social objective after being played for a certain period or when it reaches an equilibrium state , assuming all players are rational . The design includes the assignment of an appropriate set of admissible strategies and payoff functions to all players .
Despite extensive studies by economists and game theorists , mechanism design has been studied in artificial intelligence community as well , especially in the context of designing multi agent systems that can achieve a fair allocation , maximize the total utility ( social welfare ) , and be immune from deceitful strategies [ 2 , 9 ] . In computer science , mechanism design has been studied in the context of mobile ad hoc network [ 7 ] , e commerce [ 15 ] , grid computing [ 4 ] , etc . In this paper , we apply an ad hoc mechanism for our distributed clustering aggregation problem .
22 Clustering aggregation
Previous work on clustering aggregation aims for various goals , such as achieving robust results , reducing cost , protecting privacy , etc . [ 6 , 12 ] . In earlier work , various clustering methods are applied to a dataset where then integrated to get believably more robust results [ 13 ] . In distributed database , unifying heterogeneous datasets may not be feasible due to the large size of data . Hence , a possible solution is to perform clustering locally by each node to obtain class labels that can then be integrated to get an aggregate clustering [ 8 , 12 ] . their clustering results are
In most literature researchers considered various formulations for the problems , with a major goal to ensure the quality of the final clustering result . These
1550 4786/07 $25.00 © 2007 IEEE 1550 4786/07 $25.00 © 2007 IEEE 1550 4786/07 $25.00 © 2007 IEEE 1550 4786/07 $25.00 © 2007 IEEE 1550 4786/07 $25.00 © 2007 IEEE DOI 101109/ICDM200780 DOI 101109/ICDM200780 DOI 101109/ICDM200780 DOI 101109/ICDM200780 DOI 101109/ICDM200780
695 695 695 703 703 such studies made use of different clustering mechanisms including distance measurements to form the aggregate cluster labels . For instance , Fred and Jain [ 5 ] use a single linkage approach to unify the multiple runs from the k means algorithm performed locally ; Fern and Brodley [ 3 ] use a complete linkage approach in the aggregation ; Gionis et al . [ 6 ] and Johnson and Kargupta [ 8 ] also apply agglomerative algorithm in the aggregation ; Topchy et al . [ 14 ] treat the clustering aggregation into a maximum likelihood estimation problem , and adopt an EM algorithm to locate the final clustering . Other methods as dynamic programming [ 11 ] , hypergraph method [ 12 ] , and voting mechanism [ 13 ] are also used to improve the accuracy of clustering aggregation or to achieve scalability by reducing computational complexity .
In these prior works , the reported cluster labels are assumed to be correct and not strategically aligned . Our work complements them with respect to the distributed clustering of privacy data where systems may misreport their cluster labels .
3 . Clustering aggregation framework
31 Model description
Consider M systems {s1 , s2 , … , sM} , where each of them holds a set of private attributes of the common N records D = {d1 , d2 , … , dN} . We assume crisp partition based clustering . For a system sm holding a set of attributes of Dm , a partition based clustering Cm over D divides Dm into K disjoint sets , eg Clusterm1 , Clusterm2 , … , ClustermK . Suppose K is the same for all systems and M ≥ K . Since the cluster label could be arbitrary , we denote cmn to represent the cluster label given by system sm to dn , and for the sake of clarity , let the cluster label be integer ; ie , cmn ∈ K , where K ≡ {1 , 2 , … , K} . Suppose the notation ~cmn refers to any cluster label other than that assigned to dn . The cluster label reported by the system is denoted cmn’ , where Cm’ ≡ {cm1’ , … , cmN’} be the set of all reported labels by sm . Since a system is competing with others , it may lie by reporting cmn’ = ~ cmn . Also , let ln(k ) be the number of systems assigning dn to the cluster k , and ln(cmn’ ) be the total number of systems reporting dn as the same cluster as cmn’ including the system m , where Σk∈K ln(k ) = M for any k∈K .
Suppose system sm assigns confidence of clustering values to dn , denoted by a vector Bmn∈[0,1]K , with norm |Bmn| ≤ 1 , which its elements , denoted by bmn1 , … , bmnK , represent the confidence that dn belongs to Clusterm1 to ClustermK . In a crisp partitioning , the index of the greatest element in Bmn represents the cluster
696696696704704
32 Problems represents label cmn . Suppose each system uses its own criteria to generate this private value . Given this , sm may evaluate a cluster cmn = k in terms of utility , denote umn(bmnk , γmnk ) , where bmnk is the k th element of Bmn and γmnk ∈ R ≥0 than confidence considered in the valuation of a clustering on record dn , eg expected profit from a proper action after clustering . An intuitive yet simple utility function is : factors other umn(bmnk , γmnk ) = bmnk γmnk
( 1 ) Here , an accurate clustering means bmnk → 1 , which causes umn → γmnk . Likewise , umn → 0 when bmnk → 0 . Certainly , this utility function is not canonical to represent system preference . Rather , we use it in our analysis because of its simplicity .
If
[ 13 ] .
In prior work , the goal of clustering aggregation problem is to find a final clustering C such that to minimize the total number of disagreements between labels in C and those in C1’ , … , CM’ , or to maximize common information between them [ 12 , 13 ] . Here , we argue that minimizing disagreement among clusterings should not be the primary goal in our setting . approximates clustering Cmin
First , only if all systems believe that a minimalthe disagreement “ ground truth ” clustering C* , then it can be the ultimate goal of clustering aggregation problem . This is true only if the following conditions are satisfied : ( i ) C* exists ; ( ii ) the probability of error in reported clustering is less than 0.5 ; and ( iii ) we have enough participating the number of participating systems is small or some systems cheat , then Cmin ≠ C* . Hence , preventing cheat and increasing participation are very important . systems
Second , a system shall be granted autonomy in the processing its own data and standing aside from the final consensus . In fact , after receiving cluster labels from other systems , a system sm holds a set of private attributes of Dm plus C1’ , C2’ , … , Cm , … , CM’ . Since all systems hold different information , they have different interpretations . Even when all systems are truth tellers , the correctness of a shared cluster label is still affected by the reliability of the systems in processing the data . Thus , minimizing disagreement should not be adopted as the ultimate goal . Instead , a subjective criterion should be adopted in which each system is responsible for its own aggregation and interpretation .
Instead of minimizing disagreement , we believe that the clustering aggregation problem should maximize the social welfare of participating systems , viz . maxkΣmΣn umn(bmnk , γmnk ) . This approach conforms to to [ 10 ] , which argued that the data mining results should be valued by the decision makers .
If we only consider confidence and assume u(x ) = x , then the problem reduces to maxk ΣmΣnbmnk , namely confidence maximization problem . If for all systems inverse of the confidence value disagreement , the minimization of disagreement . Hence , minimizing disagreement is a special case of maximizing total utility . then our problem reduces is solely an
Since the systems are distributed and each has its own utility function umn(. ) , it is hard to maximize total utility by a central computation . Indeed , for some systems , information behind the reported cluster label is more important than the label itself . The problem that we want to solve is to find a clustering aggregation mechanism to ensure : ( i ) participating systems are more reluctant to lie ; ( ii ) it maximizes total utility of participating systems ; ( iii ) it promotes the information sharing beyond the cluster labels . To prevent lying , we design a mechanism with transferable utility ( eg by monetary payment ) .
4 . Mechanism design issues
41 Utilities , beliefs and decision structures umn
Suppose a system ’s prior confidence that dn 0 . Let v ≡ ln(1 ) be the belongs to cluster 1 is bmn1 number of systems that say dn belongs to cluster 1 , and v^ ≡ maxk∈K–{1}(ln(k ) ) be the largest number of votes that it belongs to another cluster , assuming that the system is telling the truth . After knowing v and v^ , the 0 , v , v^ ) system ’s posterior confidence is bmn1 which is updated independently from its own vote . But the posterior expected profit γmn1 0 , v , v^ ) depends on its own vote . The utility function now is
1(γmn1
1(bmn1
1(γmn1
1=(bmn1
1 = bmn1
1 = γmn1
0+(1–bmn1
0 + ( 1 – bmn1
0 , v , v^ ) γmn1 1 = bmn1
0 , v , v^ ) ( 2 ) 1(bmn1 0)(v – v^)/M Example 1 . Let bmn1 and γmn1 0(1 – ( v – v^)/M ) , where M is the total number of systems . Substituting them into equation ( 2 ) yields 0(1–(v–v^)/M ) ( 3 ) umn 0∈{0.3 , Figure 1 depicts equation ( 3 ) for various bmn1 0.4 , 0.5 , 0.6 , 0.7 , 0.8} and γmn1 0 = 100 . The x axis is the marginal voting ratio ( v – v^)/M , where the shaded area represents negative ratios , ie cluster 1 does not receive the majority vote . A zero ratio means a tie between the candidate and other(s ) , and +1 or –1 ratio means an absolute win or loss . It is shown from the figure that an increase of the marginal voting ratio
0)(v–v^)/M)γmn1 causes an increase of the utility when both the confidence and the ratio are low ( area circled in Figure 0 = 0.7 or 1 ) . However , when the confidence is high ( bji 0.8 ) , the utility decreases as the marginal ratio increases ( sharing profit with others ) . ■ y t i l i t u
120 100 80 60 40 20 0
0.3 0.4 0.5 0.6 0.7 0.8
0.95 0.75 0.55 0.35 0.15 0.05 0.25 0.45 0.65 0.85
( v v^)/m
Figure 1 . Utility values for various prior confidences
When a system lies , the utility only differs on the second term of equation ( 2 ) , or umn lie = bmn1
( 4 ) Taken equation ( 3 ) as an example , the following
1(bmn1 , v , v^ ) γmn1
0 , v , v^ ) lie(γmn1 utility function shows the effect of lying : umn
0)(v–v^)/M)γmn1
0+(1–bmn1 lie = ( bmn1
0(1–(v–v^–a)/M )
0 → 0 . lie > umn
( 5 ) where a = {1 , 2} depending on whether the vote by the lying system increases v^ ( a = 2 ) or not ( a = 1 ) . 0 > 0 , which means Nonetheless , umn all rational systems will lie when the data is profitable . However , the gain is insignificant when a/M → 0 or M is large , or when γmn1
1 when γmn1
In the rest of our analysis , we assume that the system will not lie for not valuable cluster(s ) . Without loss of generality , suppose our analysis is for the n th record and its cluster label is cmn = 1 , which represents a valuable cluster . Unless otherwise specified , we assume plurality voting in our setting . Lets denote majority = 1 when the largest group of participating cn systems ( hereafter the majority ) agrees that the cluster m label of record n is 1 after cluster alignment . Let qn1 majority be the belief ( subjective probability ) by sm that cn – m be the = 1 when it reports the truth ( cmn’ = 1 ) , and qn1 same belief when it lies . Depending on the domain , we may have various relations between bmn1 and qn1 • ∀m , n bmn1 ∝ qn1 • ∀m ∃n bmn1 ∝ 1/qn1 • ∀m,n bmn1 ∝ qn1 – m m ( uncertain belief )
( partial inconsistent belief )
– m ( consistent belief )
The first case will be discussed in this paper , while
– m : the second and third cases are for future work .
Suppose the minority will be punished to pay the majority the amount of y dollars . When a system sm lies by reporting cmn’ = K , two possibilities may
697697697705705
–m , or cn majority = 1 by probability qn1 majority ≠ 1 happen : cn –m ) . Since the system sm is not a by probability ( 1 – qn1 majority in the former case , it may be penalized to pay –m ; denote the utility in this y , also by probability qn1 case uC_lie . If the majority does not choose 1 , the system may receive xl dollars as a reward , ie when majority = K . Denote the utility in this case uI_lie . Both cji uC_lie and uI_lie can be derived from equation ( 4 ) with different estimated values of v and v^ . Hence , the expected utility of sm from lying Ulie is
Ulie = qn1
–m(uC_lie – y ) + qn2 + qnK 1
–m + qn2
–m(uI_lie – y ) + qnK –m + qnK where qn1 This equation can be simplified into –m(uC_lie – y ) + ( 1 – qn1
–m +… + qnK 1
Ulie = qn1
–m(uI_lie – y ) + …
–m(uI_lie + xl ) ( 6 ) –m = 1 . ( 7 )
–m)(uI_lie + x’ ) ( 8 )
–my + qnK
–mxl ) / ( 1 – qn1
–my – … – qnK 1 where –m ) ( 9 ) x’ = ( –qn2 Here , xl and y are transferable utility such as money which satisfies a payment property : xl ≥ x’ ≥ –y . In budget balance mechanism , the value of xl is not known in advanced , because we do not know the number of minority systems . m and ( 1 – qn1
Now , when the system sm reports the cluster label truthfully ( honest ) , viz . cmn’ = 1 , it also faces two possibilities : the majority choose cluster 1 or other m ) , respectively . label(s ) by probability qn1 Denote the utility in both cases uC_hon and uI_hon , which can be derived from equation ( 2 ) with different estimated values of v and v^ . Suppose the system majority = 1 . The expected utility of sm receives xh when cn from reporting its true label is m(uC_hon + xh ) + – m(uI_hon – y ) + … + qnK
– m(uI_hon – y ) ( 10 )
Uhon = qn1 qn2 which can be simplified into m(uC_hon + xh ) + ( 1 – qn1 m)(uI_hon – y ) ( 11 ) Uhon = qn1 Note , given equation ( 8 ) and ( 11 ) , a rational system may not always lying , even when uC_lie ≥ uC_hon and uI_lie ≥ uI_hon .
42 Proposed mechanism partial truth telling
The mechanism in Figure 2 provides a basic framework clustering aggregation among multiple selfish systems . A fully truth telling property may be assured when we choose an extremely large ymax . However , this may impede the participation of systems with less confidence . One may suggest a further mechanism to decide this value , which is beyond the scope of our current work . for
698698698706706
Step 1 . All systems bid Y1 , … , YN simultaneously , where Yn is the set of preferred penalties for record n , submitted by all M systems , |Yn| = M . Step 2 . All systems calculate max(Y1 ) , … , max(YN ) . Any system may decide the mechanism after calculating these values . If not , then it will proceed to Step 3 . Step 3 . All remaining systems report their clustering C1’ , C2’,… , CM’ simultaneously . Step 4 . All systems calculate C locally such that it minimizes disagreement with C1’ , C2’ , … , CM’ . to withdraw from
4.1 Permute label in C1’ , C2’ , … , CM’ so that they are consistently labeled ( cluster alignment ) .
4.2 For each record dn , use plurality voting to majority ; if it is tie , then leave it determine cn empty .
4.3 C = ∪n∈N { cn majority } . majority , where Step 5 . For each system sm , if cmn’ ≠ cn majority is a non empty value , then it pays max(Yn ) cn which is evenly distributed to all systems z m whose czn’ = cn Step 6 . Repeat Step 1 to Step 5 until C1’= C2’ = …= CM’ , or fewer than two systems remain in the loop . ■ majority .
Figure 2 . Proposed mechanism
43 Analysis of the mechanism
Consider m ≥ 3 and a system adopts utility function in equation ( 8 ) and ( 11 ) . Let uC_lie=uC_hon+∆C and uI_lie=uI_hon+∆I , ∆C ≥ 0 and ∆I ≥ 0 . Theorem 1 . The system with consistent belief will tell the truth if u ( >
( 12 )
∆+ hon hon q
)
I
_ y
_
C
− u qM m ⎛ ⎜⎜ n 1 l )1( ⎝ n
)( −
− m n 1 q m nK Kl ( n
− q m n 1 ⎞ ⎟⎟ ⎠
) where ∆ = qn1
–m(uC_lie – uC_hon ) + ( 1 – qn1
–m)(uI_lie – uI_hon ) ≥ 0 . The proof of all theorems is omitted here due to limited space . From the consistent belief property ln(K ) m ) , and ln(1 ) are directly proportional to f(qnK respectively . For instance , ln(K ) → M when qnK m → 1 , m → 0 . If we assume and decreases to M/K when qnK their relationship in a linear form , we have ln(1 ) = M[(1 m + 1/K ] . – 1/K ) qn1 m + 1/K ] and Theorem 2 . Let ln(1 ) = M[(1 – 1/K ) qn1 m + 1/K ] , the consistent belief ln(K ) = M[(1 – 1/K ) qnK system will tell the truth if m + 1/K ] and ln(K ) = M[(1 – 1/K ) qnK m ) and f(qn1
_ m n 1
− q )( Kq m nK m n 1 )
− u C q ( hon − m ≠ qnK
I
_ hon u (
> y where qn1 ∆ = qn1 q
− m n 1
)
∆+
[ (
K
−
)1 q m n 1
+
][(1
K
−
)1 q m nK
+
]1
( 13 ) m and m , qn1
–m , qnK m < qnK
Since qn1
–m(uC_lie – uC_hon ) + ( 1 – qn1 m + 1 ] > 0 because K > 1 , and qn1
–m)(uI_lie – uI_hon ) ≥ 0 . m , uC_hon , uI_hon , uC_lie , and uI_lie are privately known , a mechanism designer can only m + manipulate the penalty y . Note that [ (K – 1 ) qn1 m m > qnK 1][(K – 1 ) qnK when all other systems are believed to be honest . If the system believes that other system(s ) is lying , then there m , ie , the majority may vote is a chance that qn1 cluster K instead of cluster 1 . Hence , the necessary m is all other participants be m > qnK condition for qn1 believed honest , which to Bayesian Nash equilibrium . Theorem 3 . Suppose for all consistent belief systems m + 1/K ] and ln(K ) = M[(1 – 1/K ) ln(1 ) = M[(1 – 1/K ) qn1 m + 1/K ] . Telling the truth is the Bayesian Nash qnK equilibrium strategy when uC_hon ≥ uI_hon + ∆ ( qn1 m – –m uC_lie + qn1 ( 1 – qn1 m uC_hon + ( 1 – qn1 m ) uI_hon ≥ qn1
–m)–1 , or qn1
–m ) uI_lie . leads the
Theorem 3 shows the existence of equilibrium strategy , which is very important in a mechanism design . Note that Theorem 3 holds with or without penalty ( y ≥ 0 ) . Since uC_hon > uI_hon , uC_lie > uI_lie , uC_lie ≥ uC_hon and uI_lie ≥ uI_hon , the condition would be m is significantly greater than possibly met when qn1 –m , or when the vote by the system counts . When the qn1 condition is not met , we need a positive penalty to ensure equilibrium as shown in Theorems 1 and 2 .
From Theorems 1 and 2 we conclude that a penalty y that satisfies inequalities ( 12 ) and ( 13 ) is needed when bnm1 < 1 . This penalty should be reasonable to maintain to discourage the participation . From an economic perspective , systems with a lower confidence about their clustering results should pay more for updating their confidence . truth telling property , but not
To find a reasonable penalty for each record , we may ask each system to bid the amount of penalty that the minority should pay within a given range , ymn∈ [ ymin , ymax ] . A rational system will bid ymn such that the expected ynFinal maximizes Ulie or Uhon whichever is the highest . If the mechanism announces max(Yn ) to determine ynFinal , then each system knows that ymax ≥ ynFinal > ymn . In a special circumstance , the system may bid its indifferent penalty y* that makes it indifferent between lying and telling the truth , ie equal to the RHS of inequality ( 12 ) or ( 13 ) .
699699699707707
Theorem 4 . Given systems with consistent belief under Mechanism 1 with a range of allowed penalty [ ymin , ymax ] and ynFinal = max(Yn ) , then ( i )
Systems with linear or concave function ln(k ) bid ymin . Systems with convex function ln(k ) may bid ymin , ymax or any value within [ ymin , ymax ] .
( iii ) Systems with sigmoid ( S shape ) function ln(k )
( ii ) may bid y* or any value within [ ymin , ymax ] . the
In principle , Theorem 4 shows the difficulty to elicit the distribution of y* . If we can elicit the distribution of y* , we may optimize Yn so that to maximize truth telling of systems . A better elicitation mechanism is an open problem .
44 Simulation results
To analyze and visualize the relationship between confidence , maximum penalty and the effectiveness of mechanism , we have performed a simulation study . We assume seven systems using the mechanism . First , we generate a set of 100 synthetic records which may be put into two clusters . For each record , we also 0 , where cn = 1 generate its referential cn , bn 0 > 0 . Then , ( ie all records are valuable ) , bn for each system we create its own parameters : cmn , 0 , and γmn 0 bmn are generated based on their referential value , ie by randomly change the referential values . When the randomization is extensive , we get more heterogeneous m are generated –m , qn1 systems . Then , v , v^ , qn1 using predetermined formula .
0 > 0 and γn
0 , v , v^ , qn1
0 , and γn m . cmn , bmn m , and qn2 m , and qn2
–m , qn1
0 , γmn
Our simulation consists of two parts . In Part I , we study the effect of various penalties ymax = {1 , … , 100} , where ymin = 0 . We also use three groups of 0 , ie {low , medium , high} . In Part “ true ” confidence bn II , we arbitrary change the random parameters to some extreme values for stress analysis .
Figure 3 shows the results of Part I where we measure the percentage of truth telling and accuracy against ymax ( horizontal axis ) . The accuracy here refers to the correctness of the aggregated labels with respect to the referential labels cn . All plotted data are the average value from 10 repetitions . interesting increase both results are observed . First , excessive penalty does not the percentage of the truth telling and the accuracy of clustering aggregation , as shown by an erratic but nearly flat curve when ymax > 19 , which is the turning point of ymax . Indeed , this turning point is context dependant as we observed from the simulation results in Part II . Second , both the truth telling and the accuracy are bounded by the system ’s prior confidence
Two when ymax > 19 , where a higher bn better results .
0 can help to achieve
Moreover , in Part II we also observe that a low prior confidence and a high heterogeneity may reduce the accuracy to as low as 49 % , which may not be acceptable for the mechanism designer . Nonetheless , our simulation has demonstrated the potential of our proposed mechanism in promoting partial truth telling in clustering aggregation among selfish systems . high med low
1
21
41
Ymax
61
81
100 90 80 70 60 50 40 30 20
100
80
60
40
20
0 g n i l l e t h t u r T % y c a r u c c A % high med low
61
81
1
21
41
Ymax
Figure 3 . The percentage of truth telling and accuracy for various bn
0 and ymax
5 . Conclusion and future work
In this paper we have presented a mechanism design to solve the clustering aggregation problem among selfish systems . We have applied game theory and market mechanism that are commonly studied in micro economics to solve our problem . Although our current analysis focuses on special cases when systems have consistent belief , our approaches have opened up a new research direction to further promote distributed data mining beyond standard assumption that all systems are inherently honest . Simulation results indicate an optimal penalty may exist for a certain setting . This study can be extended by employing different voting and payment mechanisms . For example , rather than paying a flat penalty , we may set the penalty according to the proportion of the number of majority to the number of minority . Also , we may allow a negotiation on the penalty prior to the clustering aggregation . Further analysis to other cases including those with partial inconsistent belief , with soft clustering , with varying number of cluster labels , etc . are open issues . It is also interesting to perform further simulation and experiment involving ( human ) decision makers to find a better ( partially ) incentive compatible mechanism . We aim to address these issues in the future .
6 . Acknowledgement
This work is partially supported by a grant from the Research Grant Council of Hong Kong Government with the project code HKBU 210306 .
7 . References
[ 1 ] C . Boulis , and M . Ostendorf , “ Combining Multiple Clustering Systems ” , in Proc . PKDD’ 04 . pp . 63 74 . [ 2 ] E . Ephrati and J . Rosenschein , “ The Clarke Tax as a Consensus Mechanism among Automated Agents ” , in Proc . AAAI’91 , pp . 173 178 . [ 3 ] X . Z . Fern and CE Brodley , “ Random Projection for High Dimensional Data Clustering : A cluster Ensemble Approach ” , in Proc . ICML’03 , pp . 186 193 . [ 4 ] I . Foster , NR Jennings , and C . Kesselman , “ Brain Meets Brawn : Why Grid and Agents Need Each Other ” , Proc . AAMAS’04 , pp . 8 15 . [ 5 ] AL Fred and A . K . Jain , “ Combining Multiple Clusterings Using Evidence Accumulation ” , IEEE T . Pattern Analysis and Machine Intell . , 27(6 ) , 2005 , pp . 835 850 . [ 6 ] A . Gionis , H . Mannila and P . Tsaparas . “ Clustering Aggregation ” , ACM Tran . KDD , 1(1 ) , 2007 , pp . 1 30 . [ 7 ] M . Jakobsson , J . P . Hubaux , and L . Buttyan , “ A Micropayment Scheme Encouraging Collaboration in Multihop Cellular Networks ” , in Proc . Financial Crypt . ’03 . [ 8 ] EL Johnson and H . Kargupta , “ Collective , Hierarchical Clustering from Distributed , Heterogeneous Data ” , in MJ Zaki and CT Ho ( eds . ) Large Scale Parallel Data Mining , LNCS 1759 , Springer , 2000 , pp . 221 244 . [ 9 ] NE Kfir Dahav , D . Monderer , and M . Tennenholtz , “ Mechanism Design for Resource Bounded Agents ” , in Proc . ICMAS’00 , pp . 309 315 . [ 10 ] J . Kleinberg , C . Papadimitriou , and P . Raghavan , “ A Microeconomic View of Data Mining ” , Data Mining and Knowledge Discovery , 2(4 ) , 1998 , pp . 311 324 . [ 11 ] T . Mielikainen , E . Terzi , and P . Tsaparas , “ Aggregating Time Partitions ” , in Proc . KDD’06 , pp . 347 356 . [ 12 ] A . Strehl and J . Ghosh , “ Cluster Ensembles – a Knowledge Reuse Framework for Combining Multiple Partitions ” , J . of Machine Learning , 3 , 2003 , pp . 583 617 . [ 13 ] AP Topchy , MHC Law , AK Jain , and ALN Fred , “ Analysis of Consensus Partition in Cluster Ensemble ” , in Proc . ICDM ’04 , pp . 225 232 . [ 14 ] AP Topchy , AK Jain , and W . Punch , “ A Mixture Model for Clustering Ensembles ” , in Proc . SDM ’04 . [ 15 ] H . Varian , “ Economic Mechanism Design for Computerized Agents ” , in Proc . First Usenix Workshop on Electronic Commerce , 1995 .
700700700708708
