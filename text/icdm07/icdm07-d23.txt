Seventh IEEE International Conference on Data Mining Seventh IEEE International Conference on Data Mining Seventh IEEE International Conference on Data Mining Seventh IEEE International Conference on Data Mining Seventh IEEE International Conference on Data Mining
Using Significant , Positively Associated and Relatively Class Correlated Rules for
Associative Classification of Imbalanced Datasets
Florian Verhein
Sanjay Chawla
The School of Information Technologies
The School of Information Technologies
University of Sydney fverhein@itusydeduau
University of Sydney chawla@itusydeduau
Abstract
The application of association rule mining to classification has led to a new family of classifiers which are often referred to as “ Associative Classifiers ( ACs ) ” . An advantage of ACs is that they are rule based and thus lend themselves to an easier interpretation . Rule based classifiers can play a very important role in applications such as medical diagnosis and fraud detection where “ imbalanced data sets ” are the norm and not the exception .
The focus of this paper is to extend and modify ACs for classification on imbalanced data sets using only statistical techniques . We combine the use of statistically significant rules with a new measure , the Class Correlation Ratio ( CCR ) , to build an AC which we call SPARCCC . Experiments show that in terms of classification quality , SPARCCC performs comparably on balanced datasets and outperforms other AC techniques on imbalanced data sets . It also has a significantly smaller rule base and is much more computationally efficient .
1
Introduction
Since the introduction of CBA [ 8 ] many variations on Associative Classifiers ( ACs ) have been proposed in the literature [ 7 , 2 , 17 , 15 , 4 , 5 , 3 , 12 ] . Most of the ACs are based on rules discovered using the support confidence paradigm and the classifier itself is a collection of rules ranked using confidence or variation thereof . In many application domains , the data sets are imbalanced , ie , the proportion of samples from one class is much smaller than the other class(es ) . Additionally , the smaller class is the class of interest . Unfortunately , the support confidence framework does not perform well in such cases .
Recently Webb [ 16 ] has shown the value of using statistically significant rules and has demonstrated that many of the rules mined using support confidence are spurious and are irregularities in the data rather than properties of the underlying population . We believe that the same holds true from rules used for classification . It is also well known that confidence has non intuitive properties in imbalanced data sets . For example , high confidence rules can also be negatively correlated . In this paper we combine statistically significant rules with a new measure , the Class Correlation Ratio ( CCR ) , which leads to a better classifier . Furthermore , our method does not use the support confidence paradigm .
We make the following contributions : • We propose the Class Correlation Ratio ( CCR ) , which measures the relative class correlation of a rule . A high CCR is desirable because it means the rule is more positively correlated with the class it predicts than the alternative(s ) . CCR also forms the basis of an effective rule ranking method that can also be employed in other algorithms . • We prove that confidence and support are biased toward the majority class in imbalanced datasets in the context of CCR . • We propose an Associative Classifier that is based purely on statistical techniques . We call the method Significant , Positively Associated and Relatively Class Correlated Classification ( SPARCCC ) because we use only rules that are statistically significant and positively associated , and where the antecedent is more correlated with the class it predicts than with the other class(es ) . The classifier is parameter free , in the sense that it does not use thresholds – except standard levels of significance – to prune rules .
The the remainder of this paper is organised as follows : We first give a brief summary of ACs . Section 2 describes the class correlation ratio and the significance test we use . Section 3 proves that confidence ( and support ) is biased against the minority class under CCR . Section 4 describes our technique . Section 5 contains experimental results and we survey related work in Section 6 . In the Associative Classification problem , we assume a discrete dataset D with attributes A = {a1 , a2 , , a|A|} , one of which is the class attribute ac . In every instance
1550 4786/07 $25.00 © 2007 IEEE 1550 4786/07 $25.00 © 2007 IEEE 1550 4786/07 $25.00 © 2007 IEEE 1550 4786/07 $25.00 © 2007 IEEE 1550 4786/07 $25.00 © 2007 IEEE DOI 101109/ICDM200763 DOI 101109/ICDM200763 DOI 101109/ICDM200763 DOI 101109/ICDM200763 DOI 101109/ICDM200763
671 671 671 679 679 d ∈ D , each attribute ai ∈ A takes one of a finite number of possible values Vi = {vi,1 , , vi,|Vi|} . The Associative Classification Rule Mining task is to find interesting rules X → y where X is a set of legal ( an attribute cannot occur more than once ) attribute value pairs and y is one of the class attribute value pairs . By interesting , we mean rules that , in conjunction with other mined rules , are likely to perform well for classification of unseen data . The support of a set of attribute value pairs X is sup(X ) = |{di : X ⊆ di ∧ di ∈ D}| . The support of X → y is sup(X → y ) = sup(X ∪ y ) and its confidence is conf(X → y ) =sup(X → y)/sup(X ) .
2 Significance and Class Correlation Ratio
There are strong arguments for mining statistically significant rules [ 16 ] . These also hold true when the rules are used for classification , as we would like to make a decision based on significant evidence . We are interested in rules X → y that are statistically significant in the positively associated direction . Toward that end , we use Fisher ’s Exact Test ( FET ) on contingency tables of the form of Figure 1 . FET is an exact test ( permutation test ) . Given a table [ a , b ; c , d ] , FET will find the probability ( p value ) of obtaining the given table or a table where X and y are more positively associated under the null hypothesis that {X,¬X} and {y,¬y} are independent , and that the margin sums are fixed . The p value is given by : min(b,c ) i=0 p([a , b ; c , d ] ) =
( a + b)!(c + d)!(a + c)!(b + d)! n!(a + i)!(b − i)!(c − i)!(d + i)! We only use rules whose p values are below the level of significance desired as they are statistically significant in the positively associated direction . We also prune the search space using significance as outlined in Section 42 Correlation also forms a very important component of our technique . We are interested in rules X → y where X is more positively correlated with y than it is with ¬y . In this paper we use the following definition of correlation1 : ˆcorr(X → y ) = sup(X ∪ y ) · |D| sup(X ) · sup(y )
( a + c ) · ( a + b ) X and y are positively ( negatively ) correlated if ˆcorr(X → y ) > 1 ( < 1 ) , and independent otherwise . Note that ˆcorr(X → y ) =I ( X , y ) , where I(X , y ) is the Interest Factor [ 11 ] . This measure has downsides when used by itself . It is clear to see that increasing the size of the dataset by increasing d ( refer to Figure 1 ) will increase the correlation between X and y – even though it is actually increasing the association between ¬X and ¬y . The reverse holds 1To be more precise , ˆcorr(X → y ) this is the estimate of corr(X → P ( X⊂t)·P ( y∈t ) , where corr(X → y ) is defined over the underly y ) = P ( X∪y⊆t ) ing process that generates the data . a · n
=
X a c
¬X b d
Σrows a + b c + d a + c b + d n = a + b + c + d y ¬y Σcols
Figure 1 . 2 × 2 Contingency Table for X → y . We will often use the notation [ a , b ; c , d ] . for decreasing d . For example , consider the table T1 = [ 100 , 20 ; 20 , 10 ] where X and y are have a strong association but ˆcorr(X → y ) = 1.04 ( almost independent! ) . If we increase d to get T2 = [ 100 , 20 ; 20 , 200 ] then clearly ¬X and ¬y are strongly associated , but ˆcorr(¬X → ¬y ) = 1.4 while now ˆcorr(X → y ) = 2.36! This is clearly undesirable . This problem arises only in imbalanced datasets however – note how changing d changes the class distribution . We therefore do not search for positively correlated rules using it . When we speak of a rule being positively associated or correlated , we mean by using the one sided test of significance described above . The FET does not have this downside because of the constant margin sum restriction . Indeed , p(T1 ) = 0.041 ( significant at the 0.05 level ) and p(T2 ) = 1.07 · 10−44 ( highly significant ) . We measure how correlated X is with y compared to ¬y using what we call the Class Correlation Ratio ( CCR ) : = a · ( b + d ) b · ( a + c )
ˆcorr(X → y ) ˆcorr(X → ¬y )
CCR(X → y ) =
This measures how much more positively the antecedent is correlated with the class it predicts , relative to the alternative class(es ) . This avoids the downsides of using an absolute correlation measure – indeed , terms cancel out . It also makes a lot of sense intuitively – you would not want to use a rule that is more correlated with classes other than that it predicts! Returning to the example , CCR(· ) = 1.25 for T1 and CCR(· ) = 9.17 for T2 . This also says that X → y is a better rule under T2 than under T1 . This is true – it is much more discriminative because under T1 , y is already the majority class and therefore the rule does not provide much additional information . In fact , the Information Gain of using X → y over ∅ →y is only 0.072 bits under T1 but is 0.215 bits under T2 . Recall also that the rule was much more significant under T2 . We only use rules with CCR > 1 , so that no rules are used that are more positively associated with the classes they do not predict . Furthermore , we use CCR in our Strength Score .
3 Relative Correlation Bias of Confidence
( and Support ) on Imbalanced Datasets
Confidence is widely used as a measure of strength of a classification rule X → y because it is an estimate ( the dataset is a sample ) of the probability that , given the attribute value pairs in X appear in an instance d generated
672672672680680 sup(y ) < sup(¬y ) A CCR(X → y ) > 1 B B’ CCR(X → y ) < 1 conf ( X → y ) > conf ( X → ¬y ) C ≡ sup(X → y ) > sup(X → ¬y ) conf ( X → y ) < conf ( X → ¬y ) ≡ sup(X → y ) < sup(X → ¬y )
C’
Figure 2 . Statements for Lemma 1 . ¬y means all class attribute values other than y . by the underlying process , the instance will have the class label y . That is , conf(X → y ) ∼ P ( y ∈ d|X ⊂ d ) . The confidence of a significant rule ( it does not make sense to use insignificant rules , and their confidences are unlikely to mean anything ) is therefore a useful measure of the rule strength in classification – but only in balanced datasets : We show that confidence ( and support , while we’re at it ) are biased toward the majority class under the CCR . In our previous example , note that conf(X → y ) = 0.83 in both T1 and T2 , despite the rule being clearly better in T2 .
Lemma 1 Confidence ( and support ) are biased toward the majority class under the Class Correlation Ratio . Specifically ( statements in parentheses are defined in Figure 2 ) : 1 . If X → y is more positively correlated than X → ¬y but has a lower confidence ( support ) , then y must be the minority class : ( B ∧ C =⇒ A ) . 2 . If X → y is more positively correlated and more confident ( frequent ) than X → ¬y , we cannot say anything about whether y is the minority or majority class : ( B ∧ C =⇒ A and B ∧ C =⇒ ¬A ) . 3 . If y is the minority class and X → y is more confident ( frequent ) than X → ¬y , then it is also more positively correlated : ( A ∧ C =⇒ B ) . 4 . If y is the minority class and X → y is less confident ( frequent ) than X → ¬y , there is no relationship between the correlation of the rules : ( A ∧ C =⇒ B and A ∧ C =⇒ ¬B ) . 5 . If y is the minority class and X → y is less positively correlated than X → ¬y , it is also less confident ( frequent ) : ( A ∧ B =⇒ C6 . If y is the minority class and X → y is more positively correlated than X → ¬y , then we cannot say anything about their confidences ( supports ) : ( A ∧ B =⇒ CProof : Please see [ 14 ] . Suppose we have a two class problem and y describes the minority class . 3 ) tells us that if X → y is more confident than X → ¬y , then it is also more positively correlated . However , the reverse does not hold as described by 4 ) . That is , if X → ¬y is more confident than X → y , then it may or may not be more positively correlated . This means we may have a highly confident rule for the majority and A ∧ B =⇒ ¬C
) .
) . class , X → ¬y ( that is more confident than X → y ) , but is actually less positively correlated than X → y – very undesirable! In the opposite case , 5 ) tells us that a rule in the minority class , X → y , with lower relative correlation will also have lower confidence than X → ¬y . Again , this does not hold for the majority class . Since higher confidence ( support ) for a rule in the minority class implies higher relative correlation ( CCR > 1 ) , and lower relative correlation ( CCR < 1 ) in the minority class implies lower confidence , but neither of these are true for the majority class , we say that confidence ( support ) tends to bias the majority class – because confidence ( support ) and CCR can only ‘contradict’ each other in the majority class . In a related matter , 1 ) tells us that if X → y is more positively correlated than X → ¬y but is less confident , then y must be the minority class . Again , the reverse does not hold in general . Hence , if we choose high confidence ( support ) rules we are more likely to miss rules that have CCR > 1 applying to the minority class than in the majority class . Furthermore , when ranking by confidence ( support ) we are likely to use rules that with CCR < 1 predicting the majority class over rules with CCR > 1 predicting the minority class .
Example 1 Consider an imbalanced dataset with sup(y ) = 15 and sup(¬y ) = 100 . A possible contingency table is < conf ( X → [ 5 , 10 ; 10 , 90 ] . Despite conf ( X → y ) = 1 ¬y ) = 2 3 , X has a significant positive association with y ( pvalue = 002 ) Also , corr(X → y ) = 2.56 and corr(X → ¬y ) = 0.77 so this rule has a high CCR ( CCR = 3.32 >> 1 ) and is thus a very good rule at distinguishing between classes .
3
4 SPARCCC
There are four components to SPARCCC : 1 . The Interestingness and Rule Ranking technique ( Section 4.1 ) determines which potentially interesting rules are interesting and assigns them a Strength Score .
2 . The Search and Pruning Strategy ( Section 4.2 ) determines how the space of all possible rules is examined and pruned . This determines the candidate rules – the potentially interesting rules . The choice of strategy determines the computational performance .
3 . The Rule Selection Method determines which of the It interesting rules are to be used for classification . outputs selected rules .
4 . The Classification Method determines how we classify an unseen instance by using the selected rules .
Components 3 . and 4 . are based on using groups of equally highly ranked rules . Due to limited space , we refer the reader to [ 14 ] for details . 4.1 Interestingness and Rule Ranking
We perform the following tests to determine whether a potentially interesting rule is interesting :
673673673681681
• We check the significance of a rule X → y by performing Fisher ’s Exact Test on the contingency table of Figure 1 , as earlier described . We record the pvalue . • We check whether CCR(X → y ) > 1 . If this is not the case , the rule is not interesting because it is more correlated with the alternative class(es ) than it is with the class it predicts .
The interesting rules – those that pass the above two tests
– are candidates for the classification task .
In order to use the rules to make a classification , we need a ranking ( ordering ) of the rules that captures the ability of the rule to make a correct classification . This ordering is defined by the Strength Score of the rule . Based on the discussions in Sections 2 we may use :
SSp,CCR(X → y ) = ( 1 − pvalue ) · CCR(X → y ) Confidence is an estimate of the probability that , given X occurs , y will occur . Therefore in balanced datasets , choosing the rule with the highest confidence gives the highest expected probability of making a correct classification . Therefore , for comparison , we also evaluate :
SSp,conf ( X → y ) = ( 1 − pvalue ) · conf(X → y )
But as Lemma 1 shows , confidence has a bias toward the majority class . While SSp,conf performs well on balanced datasets , it performs very poorly on imbalanced datasets . Recall that a ) a highly confident rule predicting the majority class may in fact be more negatively correlated than the same rule predicting the other class(es ) , and b ) a rule that is more positively correlated but predicts the minority class may have much lower confidence than the same rule predicting the other class(es ) . Now , our interestingness criteria above excludes case a ) , but it does not correct for the bias in confidence for less extreme cases and it does nothing to fix case b ) . We propose to correct this using CCR :
SSp,conf,CCR(r ) = ( 1 − pvalue ) · conf(r ) · CCR(r ) For the rule r = X → y . This works by giving poor rules a lower score ( in comparison to better rules ) and scaling up cases of b ) : CCR(X → y ) > 1 . In terms of a suitable classification performance P ( · ) , experiments show that on relatively balanced datasets : P ( SSp,CCR ) ≈ P ( SSp,conf,CCR ) ≈ P ( SSp,conf )
While on imbalanced datasets ( as would be expected ) : P ( SSp,CCR ) >> P ( SSp,conf,CCR ) >> P ( SSp,conf )
That is , the use of CCR achieves the highest performance on imbalanced datasets while performing comparably on balanced datasets . Note that in a completely balanced dataset , CCR(X → y ) reduces to sup(X→y ) sup(X→¬y ) = conf ( X→y ) conf ( X→¬y ) which we call the Class Support Ratio and the Class Confidence Ratio respectively .
674674674682682
Finally , we note that the pvalue has little impact in the final score , because it varies at most by the significance level . It ’s inclusion therefore favors more significant rules only if the other components of SS are similar .
4.2 Search and Pruning Strategies
The overall strategy is a bottom up item enumeration technique , as all the rules X → y : X ⊂ X will be examined before X → y and the search is over the item space ( attribute value space ) . The underlying algorithm used to do this is a yet to be published variation of GLIMIT [ 13 ] . It performs this task in a depth first fashion . It uses linear space in the number of instances , linear time in the number of itemsets ( classification rules and their antecedents ) that need to be considered , and one pass over the dataset . While this is faster than alternatives such as Apriori [ 1 ] or FP Growth [ 6 ] , either of these could potentially be used .
The idea of a rule being statistically significant is not anti monotonic . To avoid examining all rules , we use search strategies that ensure the concept of being potentially interesting is anti monotonic – ie X → y might be considered as potentially interesting if and only if all {X → y|X ⊂ X} have been found to be potentially interesting :
• Select a new attribute value in such a way that it makes a significant positive contribution to the rule , when compared to all immediate generalizations . Specifically , Figure 3 describes how we test for the significance of the rule X → y in comparison to one of its generalizations X − {z} →y . The rule X → y is potentially interesting only if the test passes for all immediate generalizations {X − {z} →y : z ∈ X} . This technique prunes the search space most aggressively , as it performs |X| tests per rule . However , this also means that it greatly favors shorter rules , as they have fewer tests to pass . This approach is borrowed from Webb [ 16 ] . We call it Aggressive S .
• Use FET as described in Section 2 and force it to be anti monotonic2 . We call this Simple S . It performs one test per rule and examines more of the search space .
• For comparison , we also use a minimum support threshold . All rules with supp(X → y ) ≥ minSup are potentially interesting . We call this Support . For Aggressive S and simple S , we define sup(∅ ) = |D| so that we can evaluate a pvalue ( usually high ) for so called “ default rules ” – rules with no antecedent .
2That is , if and only if all rules {X − {z} → y : z ∈ X} are potentially interesting , then we use the contingency table of Figure 1 to determine whether X → y is potentially interesting . Note that this is recursive . t : y ∈ t t : ¬y ∈ t t : X ⊂ t a = sup(X → y ) c = sup(X → ¬y ) a + c = sup(X ) t : X − {z} ⊂ t ∧ z ff∈ t b = sup(X − {z} → y ) − sup(X → y ) d = sup(X − {z} → ¬y ) − sup(X → ¬y ) b + d = sup(X − {z} ) − sup(X ) t : X − {z} ⊂ t a + b = sup(X − {z} → y ) c + d = sup(X − {z} → ¬y ) a + b + c + d = sup(X − {z} )
Figure 3 . The contingency table [ a , b ; c , d ] used to test for the significance of the rule X → y in comparison to one of its generalizations X − {z} →y for the Aggressive S search strategy .
5 Experiments
We performed experiments on relatively balanced , well known UCI datasets [ 9 ] ( {Australia , breast , Cleve , Diabetes , Heart , Horse} ) as well as imbalanced variations of them . In the tables , our methods are denoted by “ SPARCCC ” with the search strategy in parentheses . For comparison we also use a purely support and confidence based technique denoted by “ Support Confidence ” . It finds all rules satisfying the support and confidence thresholds and uses confidence as the strength score . Due to limited space we show only average results . For more details and further discussion of our experiments please refer to [ 14 ] .
Original ( Balanced ) Datasets : Figure 4(a ) shows that ( on average ) SPARCCC performs comparably to CBA , CMAR and C4.53 , and is insensitive to the choice of SS . However , there are large differences in the search space examined and hence the run times , as shown in Figures 4(c ) . Also , much fewer rules are found as can be seen in Figure So picking the best accuracy ( 83.6 % , “ Aggressive4(d ) . S ” using significance of 0.001 and SSp,conf,CCR ) we can obtain comparable accuracy while searching only 1.3 % of the space , using 0.08 % of the time and finding 0.03 % of the rules , when compared to support based methods – for example ; CBA and CMAR .
Highly imbalanced versions of the datasets were obtained by keeping the majority class and randomly selecting a subset of the minority class so that the ratio was 1 : 9 . Figure 4(b ) shows the True Positive Rate ( TPR ) of the minority class4 . The effect of using CCR in the Strength Score is dramatic . Clearly : T P R(SSp,CCR ) >> T P R(SSp,conf,CCR ) >> T P R(SSp,conf )
For when using example ,
“ Aggressive S ” , SSp,conf,CCR is on average ( over datasets and significance levels ) 2.87 times better than SSp,conf and SSp,CCR is 1.58 times better than SSp,conf,CCR and 4.44 times better than SSp,conf .
Our methods also score much higher than other rule based techniques such as CBA and CCCS . The highest average TPR overall is for “ Aggressive S ” with a significance level of 005 This was 45.8 % better than CBA and 26.1 % better than CCCS . Finally , the computational performance favors our techniques even more on imbalanced datasets .
3The reported accuracy levels for C4.5 , CBA and CMAR were obtained from [ 7 ] .
4Accuracy is a poor performance measure for imbalanced datasets – however it remains high , which is also implied by Figure 4(a ) .
675675675683683
Figure 4(c ) for example shows that “ Aggressive S ” , at a significance level of 0.05 , explores only 0.29 % of the space considered by a support based method with minSup = 1 % – and the training time is even less .
6 Related Work
CBA [ 8 ] was the first Associative Classifier ( AC ) proposed and almost all other ACs are variations on the original CBA design . For rule mining , CBA mines all rules passing support and confidence thresholds ( minSup and minConf ) . Additionally , it ignores rules based on a “ pessimistic error based pruning method ” borrowed from C4.5 [ 10 ] . Unfortunately this still generates thousands of rules – most of which perform poorly . Therefore , a rule selection process is needed to select a small subset likely to perform well . New instances are classified according to the highest ranked rule that is applicable . Rules are ranked according to confidence , support , and size .
CMAR [ 7 ] is a variation of CBA which uses the chisquare measure for rule selection . A more detailed analysis of CMAR and related associate classifiers can be found in the longer version of the paper [ 14 ] . CCCS [ 3 ] is the first associative classifier to propose a way to handle imbalanced classes . However , it provides no guarantees about the statistical significance of the rules mined . We borrow the idea from Webb [ 16 ] in our Aggressive S pruning approach .
Acknowledgments : We are grateful to Bavani Arunasalam for providing the preprocessed data and the CCCS results . This research was partially funded by the Australian Research Council ( ARC ) Discovery Grant , Project ID : DP055900 . References
[ 1 ] R . Agrawal and R . Srikant . Fast algorithms for mining association rules . In Proceedings of 20th International Conference on Very Large Data Bases VLDB , pages 487–499 . Morgan Kaufmann , 1994 .
[ 2 ] M L Antonie and O . R . Zaiane . An associative classifier based on positive and negative rules . In 9th ACM SIGMOD workshop on Research Issues in Data Mining and Knowledge Discovery(DMKD 04 ) , pages 64–69 , 2004 .
[ 3 ] B . Arunasalam and S . Chawla . Cccs : a top down associative classifier for imbalanced class distribution . In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 517–522 , New York , NY , USA , 2006 . ACM Press .
[ 4 ] G . Cong , A . KHTung , X . Xu , F . Pan , and J . Yang . Farmer : In
Finiding interesting rule groups in microarray datasets .
( a ) Accuracy on Original Datasets . Average over datasets and folds .
( b ) True Positive Rate ( Recall , Sensitivity ) of the Minority Class on Imbalanced Versions of the Datasets . Average over datasets and folds .
( c ) Search space size on original datasets , training time on original datasets and search space size on imbalanced versions of the datasets . Average over all datasets and folds .
( d ) Number of rules found ( prior to rule selection ) on the original datasets . Average over all datasets and folds .
Figure 4 . Classification and computational performance on original and imbalanced datasets .
23rd ACM SIGMOD International Conference on Management of Data Proceedings , pages 145–154 , 2004 .
[ 5 ] G . Cong , K L Tan , A . KHTung , and X . Xu . Mining topIn ACM k covering rule groups for gene expression data . SIGMOD/PODS 2005 Proceedings , pages 670–681 , 2005 .
[ 6 ] J . Han , J . Pei , and Y . Yin . Mining frequent patterns without candidate generation . In 2000 ACM SIGMOD International Conference on Management of Data , pages 1–12 . ACM Press , May 2000 .
[ 7 ] W . Li , J . Han , and J . Pei . Cmar : Accurate and efficient classification based on multiple class association rules . In ICDM ’01 : Proceedings of the 2001 IEEE International Conference on Data Mining , pages 369–376 , Washington , DC , USA , 2001 . IEEE Computer Society .
[ 8 ] B . Liu , W . Hsu , and Y . Ma .
Integrating classification and association rule mining . In Knowledge Discovery and Data Mining , pages 80–86 , 1998 .
[ 9 ] P . M . Murphy and D . W . Aha . UCI repository of machine learning databases . Machine readable data repository , University of California , Department of Information and Computer Science , Irvine , CA , 1992 .
[ 10 ] R . Quinlan . C4.5 : Program for Machine Learning . Morgan
Kaufmann .
676676676684684
[ 11 ] P N Tan , M . Steinbach , and V . Kumar . Introduction to Data
Mining . Addison Wesley , 2006 .
[ 12 ] A . Veloso , W . M . Jr . , and M . J . Zaki . Lazy associative clasIn IEEE ICDM , volume 0 , pages 645–654 , Los sification . Alamitos , CA , USA , 2006 . IEEE Computer Society .
[ 13 ] F . Verhein and S . Chawla . Geometrically inspired itemset mining . In 2006 International Conference on Data Mining ( ICDM’06 ) , pages 655–666 . IEEE Computer Society , 2006 . [ 14 ] F . Verhein and S . Chawla . Using significant , positively associated and relatively class correlated rules for associative classification of imbalanced datasets . tr 614 . Technical report , School of Information Technologies , University of Sydney , Australia , 2007 .
[ 15 ] J . Wang and G . Karypis . Harmony : Efficiently mining the best rules for classification . In 2005 SIAM International Conference on Data Mining(SDM’05 ) Proceedings , 2005 .
[ 16 ] G . I . Webb . Discovering significant rules . In KDD ’06 : Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 434–443 , New York , NY , USA , 2006 . ACM Press .
[ 17 ] X . Yin and J . Han . CPAR : Classification based on predictive association rules . In D . Barbar´a and C . Kamath , editors , SDM . SIAM , 2003 .
