Preserving Privacy through Data Generation
Jilles Vreeken , Matthijs van Leeuwen and Arno Siebes
Universiteit Utrecht
{jillesv,mleeuwen,arno}@csuunl
Abstract
Many databases will not or can not be disclosed without strong guarantees that no sensitive information can be extracted . To address this concern several data perturbation techniques have been proposed . However , it has been shown that either sensitive information can still be extracted from the perturbed data with little prior knowledge , or that many patterns are lost .
In this paper we show that generating new data is an inherently safer alternative . We present a data generator based on the models obtained by the MDLbased KRIMP [ 12 ] algorithm . These are accurate representations of the data distributions and can thus be used to generate data with the same characteristics as the original data .
Experimental results show a very large patternsimilarity between the generated and the original data , ensuring that viable conclusions can be drawn from the anonymised data . Furthermore , anonymity is guaranteed for suited databases and the quality–privacy trade off can be balanced explicitly .
1 . Introduction
Many databases will not or can not be disclosed without strong guarantees that no sensitive information can be extracted from it . The rationale for this ranges from keeping competitors from obtaining vital business information to the legally required protection of privacy of individuals in census data . However , it is often desirable or even required to publish data , leaving the question how to do this without disclosing information that would compromise privacy .
To address these valid concerns , the field of privacy preserving data mining ( PPDM ) has rapidly become a major research topic . In recent years ample attention is being given to both defender and attacker stances , leading to a multitude of methods for keeping sensitive information from prying eyes . Most of these techniques rely on perturbation of the original data : altering it in such a way that given some external in formation it should be impossible to recover individual records within certainty bounds .
Data perturbation comes in a variety of forms , of which adding noise [ 2 ] , data transformation [ 1 ] and rotation [ 3 ] are the most commonly used . At the heart of the PPDM problem is the balance between the quality of the released data and the amount of privacy it provides . While privacy is easily ensured by strongly perturbing the data , the quality of conclusions that can be drawn from it diminishes quickly . This is inherent of perturbation techniques : sensitive information cannot be fully masked without destroying non sensitive information as well [ 6 ] . This is especially so if no special attention is given to correlations within the data by means of multidimensional perturbation [ 5 ] , something which has hardly been investigated so far [ 9 ] .
An alternative approach to the PPDM problem is to generate new data instead of perturbing the original . This has the advantage that the original data can be kept safe as the generated data is published instead , which renders data recovery attacks useless . To achieve this , the expectation that a data point in the generated database identifies a data point in the original database should be very low , whilst all generated data adhere to the characteristics of the original . Data generation as a means to cover up sensitivities has been explored in the context of statistical databases [ 8 ] , but that method ignores correlations as each dimension is sampled separately .
We propose a novel method that uses data generation to guarantee privacy while taking important correlations into account . For this we use the MDL based KRIMP algorithm [ 12 ] that has been shown to provide accurate pattern based approximations of data distributions . The high quality of the approximations was verified through classification [ 7 ] , and consequently put to use for determining and characterising dissimilarities between datasets [ 13 ] . Using the patterns picked by MDL , we construct a model that generates data very similar ( but not equal ) to the original data . Experiments show that the generative model is well suited for producing data that conserves the characteristics of the original data while preserving privacy .
2 . The Problem
A good PPDM technique should not only preserve privacy but also quality , which can be formulated as :
A database dbpriv induced from a database dborig is privacy and quality preserving iff : a . no sensitive information in dborig can be derived from dbpriv given a limited amount of external information ( privacy requirement ) ; b . models and patterns derived from dbpriv by data mining techniques are also valid for dborig ( quality requirement ) .
From this statement follows a correlated data generation approach to induce privacy and quality preserving databases , for which the above requirements can be translated into concrete demands .
It is hard to define an objective measure for the privacy requirement , as all kinds of ‘sensitive information’ can be present in a database . We guarantee privacy in two ways . Firstly , the probability that a transaction in dborig is also present in dbpriv should be small . Secondly , the more often a transaction occurs in dborig , the less harmful it is if it also occurs in dbpriv . This is encapsulated in the Anonymity Score , in which transactions are grouped by the number of times a transaction occurs in the original database ( support ) :
Definition 1 : for a database dbp based on dbo , define the Anonymity Score ( AS ) as :
AS
( db
, db o
) p
= ∑ supp
∈ db
1 supp o tP (
∈ db
| t
∈ db supp o
) p
( 1 )
In this definition , dbsupp is defined as the selection of db with only those transactions having a support of supp . For each support level in dbo , a score is obtained by multiplying a penalty of 1 divided by the support with the probability that a transaction in dbo with given support also occurs in dbp . These scores are summed to obtain AS . Note that when all transactions in dbo are unique ( ie , have a support of 1 ) , AS is equal to the probability that a transaction in dbo also occurs in dbp . Worst case is when all transactions in dborig also occur in dbpriv . In other words , if we choose dbpriv equal to dborig , we get the highest possible score for this particular database , which we can use to normalise between 0 ( best possible privacy ) and 1 ( no privacy at all ) :
To conform to the quality requirement , the frequent pattern set of dbpriv should be very similar to that of dborig . We will measure pattern similarity in two ways : 1 ) on database level through a database dissimilarity measure [ 13 ] and 2 ) on the individual pattern level by comparing frequent pattern sets . For the second part , pattern similarity is high iff the patterns in dborig also occur in dbpriv with ( almost ) the same support . So :
εδ <
)
|P ( supp supp
−
> priv orig
( 3 ) The probability that a pattern ’s support in dborig differs much from that in dbpriv should be very low : the larger d , the smaller e should be . Note that this second validation implies the first : only if the pattern sets are highly similar , the code tables become similar , which results in low measured dissimilarity . Further , it is computationally much cheaper to measure the dissimilarity than to compare the pattern sets .
|
3 . Preliminaries
In this paper we discuss categorical databases . A database db is a bag of tuples ( or transactions ) that all have the same attributes {A1,…,An} . Each attribute Ai has a discrete domain of possible values Di ∈ D .
The KRIMP algorithm operates on item set data , as which categorical data can easily be regarded . The union of all domains » Di forms the set of items I . Each transaction t can now also be regarded as a set of items t ∈ P(I ) . An item set I ∈ I occurs in a transaction t ∈ db iff I Œ t . The support of I in db is the number of transactions in the database in which I occurs .
KRIMP is a heuristic method based on MDL : it attempts to find that ( small ) set of patterns that compresses a database best . Such a KRIMP code table ( pattern set ) consists of item sets with a usage frequency . The compression process starts with an empty code table , a database and a set of candidate ( frequent ) patterns . Each of these patterns is tested individually : it is kept in the code table iff it helps to better compress the database . For more details , see [ 12 ] . The performance and effectiveness of the method was further investigated through classification [ 7 ] , recently we used the method to devise a database dissimilarity measure and several ways to characterise differences [ 13 ] .
4 . KRIMP Categorical Data Generator
In this section we present our categorical data generation algorithm . We start off with a simple example , after which we will detail the algorithm formally .
Definition 2 : for a database dbpriv based on dborig , define the Normalised Anonymity Score ( NAS ) as :
NAS
( db
, db orig
)
= priv
AS AS
( ( db db priv orig
, , db db orig orig
) )
( 2 ) requires : the original database , a Laplace correction value , a min sup value for mining candidates for the KRIMP algorithm and the number of transactions to generate . We present the full algorithm below .
Generation starts with an empty database gdb ( line 2 ) . To obtain a code table CT , the KRIMP algorithm is applied to the original database db ( 3 ) . A Laplace correction laplace is added to all elements in the code table ( 4 and 5 ) . We return the generated database when it contains num trans transactions ( 7 to 9 ) . Generation of a transaction is started with an empty transaction t ( line 11 ) . As long as D is not empty ( 12 ) , our transaction is not finished and we continue . First , a domain D is randomly selected ( 13 ) . From the selection CTD , one item set is randomly chosen , with probabilities defined by their relative frequencies ( 14 ) . After the chosen set is added to t ( 15 ) , we filter from CT all sets that would redefine a value – ie those sets that intersect with the definitions of the domains for which t already has a value ( 16 and 17 ) . Further , to avoid reconsideration we also filter these domains from D ( 18 ) . After this the next domain is picked from D and another item set is selected ; this is repeated until D is empty ( and t thus has a value from each domain ) .
Note that code table elements are treated fully independently , as long as they do not re assign values . Correlations between dimensions are stored explicitly in
ALGORITHM KRIMPGENERATOR
GenerateDatabase(db , laplace , min sup , num trans ) gdb = « CT = KRIMP(db , MineCandidates(db , min sup ) ) for each item set e in CT
Domain definition D = { D1 = { A , B } ; D2 = { C , D } ; D3 = { E , F } } Selections Code table CTD1
Freq
A3
CTD2 CTD3
A1 A
A2 C
B
A
B
D
C
C
D
3
3
2
1
2
1
1
1
1
F
E
F
–
–
–
–
–
–
–
–
–
–
–
–
–
–
–
Figure 1 . Example for 3 column database . Each frequency is Laplace corrected by 1 .
4.1 Generating a transaction , an example
Suppose we need to generate a new transaction for a simple three column categorical database . To apply our generation scheme , we need a domain definition D and a KRIMP code table CT , both shown in Figure 1 .
We start off with an empty transaction and fill it by iterating over all domains and picking an item set from the code table for each domain that has no value yet . We first want to assign a value for the first domain , D1 , so we have to select one pattern from those patterns in the code table that provide a value for this domain . This subset is shown as selection CTD1 .
Using the frequencies of the code table elements as probabilities , we randomly select an item set from CTD1 ; elements with high frequency occur more often in the original database and are thus more likely to be picked . Here we randomly pick ‘BD’ ( probability 3/9 ) . This set selects value ‘B’ from the first domain , but also assigns a value to the second domain , namely ‘D’ . To complete our transaction we only need to choose a value for the third domain . We do not want to change any values once they are assigned , as this might break associations within an item set previously chosen . So , we do not want to pick any item set that would reassign a value to one of the first two domains . Considering the projection for the third domain , CTD3 , we thus ignore set CF(2 ) , as it would re assign the second domain to ‘C’ . From the remaining sets E(3 ) and F(3 ) , both with frequency 3 , we randomly select one – say , ‘E’ . This completes generation of the transaction : ‘BDE’ .
4.2 Definition of the generator
Here we will detail our data generator more formally . First , define the projection CTD as the subset of item sets in CT that define a value for domain D ∈ D . To generate a database , our categorical data generator
1 2 3 4 5 6 7 8 9
10 11 12 13 14 15 16 17 18 19
20 21 22 23 gdb = gdb + GenerateTransaction(CT , D ) e.frequency += laplace
D = db.getDomains while(|gdb| < num trans ) return gdb
GenerateTransaction(CT , D ) t = « while D ∫ « pick a random D ∈ D is = PickRandomItemSet(CTD ) t = t » is for each domain C for which is has a value CT = CT \ CTC D = D \ C return t
PickRandomItemSet(CT ) weights = { e.frequency | e ∈ CT } is = WeightedSample(weights , CT ) return is the item sets and are thus taken into account implicitly . The two parameters laplace and min sup control the amount of privacy provided in the generated database . The Laplace correction parameter directly controls the data diversity and strength of the correlations within the data . Before the generation process , a small constant is added to the frequencies of all code table elements . As code tables always contain all single values , this ensures that all values have a small probability of being chosen . Thus , 1 ) a complete transaction can always be generated and 2 ) all possible transactions can be generated . For this purpose the correction needs only be small . However , the strength of the correction influences the chance an otherwise unlikely code table element is used ; with larger correction , the influence of the original data distribution is dampened and diversity is increased .
The second parameter , min sup , has a strong relation to the k anonymity blend in the crowd approach [ 11 ] . The min sup parameter has ( almost ) the same effect as k : patterns that occur less than min sup times in the original database are not taken into account by KRIMP . As they cannot get in the code table , they cannot be used for generation . Particularly , complete transactions have to occur at least min sup times in order for them to make it to the code table . In other words , original transactions that occur less often than min sup can only be generated by chance if often occurring patterns are combined . It follows that when more patterns have to be combined , it becomes less likely that such ‘private’ transactions are generated .
5.2 Results
To quantify the likeness of the generated databases to their original counterparts , we use a database dissimilarity measure [ 13 ] . To judge these measurements , we also provide the dissimilarity between the original
5 . Experiments
5.1 Experimental Setup
In our experiments , we use a selection of datasets from the UCI repository [ 4 ] . Table 1 reports the minimum support levels we use for mining the frequent item sets that function as candidates for KRIMP .
For all experiments we use a Laplace correction parameter of 0.001 , an arbitrarily chosen small value to ensure that all code table elements can be chosen in generation . All experimental results presented below are averaged over 10 runs and all generated databases have the same number of transactions as the originals . y t i r a l i m i s s i
D
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0 uncorrelated correlated chess ( kr k ) iris led7 nursery
Dataset page Blocks penDigits pima
Figure 2 . Dissimilarity scores between generated and original databases . database and independent random samples of half the size from the original database .
In Table 1 we show both these internal dissimilarity scores and the dissimilarity measurements between the original and generated databases . To put the reported dissimilarities in perspective , note that the dissimilarity measurements between the classes in the original databases range from 0.29 up to 12 [ 13 ] . The measurements thus indicate clearly that the generated databases adhere very closely to the original data distribution .
Databases generated at higher values of the min sup parameter show slightly larger dissimilarity . The bar diagram of Figure 2 shows a comparison of the dissimilarity scores between uncorrelated ( only single values in the code table ) and correlated generation ( regular code table obtained with KRIMP ) . As expected , when correlations are taken into account , the generated databases are far more similar to the originals .
Now , let us consider quality on the level of individual patterns ; for this , we mined frequent item sets from both the generated and original databases . A comparison between the resulting sets is presented in Table 1 .
Large parts of the generated and original frequent pattern sets consist of exactly the same items sets , as can be seen from the fifth column . For example , for Led7 and Nursery about 90 % of the mined item sets are equal . Due to the relatively high min sup used for PenDigits , a comparatively low 25 % of the original patterns is found – although more than 90 % of the sets mined from the generated database are original .
For item sets found in both cases , the average difference in support between original and generated is very small , as the next column shows . Iris is a bit of an outlier here , caused by the very small size of the dataset . Not only the average is low , standard deviation is also small : as can be seen from Figure 3 , almost all sets have a very small support difference . The generated databases thus fulfil the support difference demands we formulated in Equation 3 .
Table 1 . Dissimilarity measurements ( between original and generated datasets ) , frequent pattern set comparisons and Normalised Anonymity Scores for a range of UCI datasets . As candidates , frequent item sets up to the given minimum support level were used . Dataset Name
Min sup Gen . vs . orig . Orig . internal
Frequent Pattern Set Comparison
Dissimilarity
Anonymity
KRIMP
Chess ( kr k ) Iris Led7 Mushroom* Nursery PageBlocks PenDigits Pima * Only closed item sets used as candidates . No values for frequent pattern set comparison as it was infeasible to compute these .
0.104 0.158 0.171 0.139 0.045 0.164 0.124 0.177
0.037 0.047 0.028 0.010 0.011 0.067 0.198 0.110
1 1 1 20 1 1 50 1
% avg sup diff equal item sets 0.01 1.69 0.14 0.04 0.06 0.50 0.30
% equal item sets 71 83 89 90 75 25 60
% avg sup new item sets 0.01 0.80 0.06 0.03 0.02 0.59 0.14
Normalised Anonymity Score 0.30 0.72 0.66 0.09 0.49 0.77 0.22 0.64
The seventh column of Table 1 contains the average supports of item sets that are newly found in the generated databases ; these supports are very low . All this together clearly shows that there is a large patternsimilarity , thus showing a high quality according to our problem statement .
To measure the level of provided anonymity , we calculate the Normalised Anonymity Score as given by Definition 2 . These scores are presented in the last column of Table 1 . As lower scores indicate better privacy , some datasets ( eg Mushroom , PenDigits ) are anonymised very well , while other datasets ( such as PageBlocks ) are not . As discussed in Section 4 , the min sup parameter of our generation methods doubles as a k anonymity provider .
To show the effect of min sup in action , as an example we increase the min sup for the Chess database to 50 . While the so generated database is still very similar to the original ( dissimilarity of 0.19 ) , privacy is considerably increased which is reflected by a Normalised Anonymity Score of 015 For further evidence of the k anonymity obtained , we take a closer look at
PenDigits , for which we use a min sup of 50 . Of all transactions with support < 50 in the generated database , only 3 % is also found in the original database with support < 50 . It is thus highly unlikely that one picks a ‘real’ transaction from the generated database with support lower than min sup .
Although not all generated databases preserve privacy very well , the results indicate that privacy can be obtained . This brings us to the question when privacy can be guaranteed . This not only depends on the algorithm ’s parameters , but also on the characteristics of the data . It is difficult to determine the structure of the data and how the parameters should be set in advance , but during the generation process it is easy to check whether privacy is going to be good .
The key issue is whether transactions are generated by only very few or many code table elements . In Figure 4 we show this relation : for each dataset in Table 1 , a cross marks the average number of item sets used to generate a single transaction and the Normalised Anonymity Score . In the bottom right corner we find the generated databases that preserve privacy well , includ s t e s f o r e b m u n
400
350
300
250
200
150
100
50
0
0.000
0.005
0.010
0.015 frequent item set support difference ( % )
Figure 3 . Support differences , for identical item sets in generated and orig . Led7 . e r o c S y t i m y n o n A d e z i l a m r o N
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
1
2
3
4
5
Figure 4 . Average number of patterns to
Average number of sets to generate a transaction generate a transaction versus NAS .
6
7
8 ing PenDigits . At the top left reside those databases for which too few elements per transaction are used during generation , leading to bad privacy ; PageBlocks and Led7 are the main culprits . Thus , by altering the minsup , this relation allows for explicit balancing of privacy and quality of the generated data .
6 . Discussion
The experimental results in the previous section show that the databases generated by our data generator are of very high quality ; pattern similarity on both database level and individual pattern level is very high . Furthermore , we’ve shown that it is possible to generate high quality databases while privacy is preserved . The Normalised Anonymity Scores for some datasets are very low , showing that hardly any transactions that occur few times in the original database also exist in the generated database . As expected , increasing minsup leads to better privacy , while dissimilarity remains good . The trade off between quality and privacy can thus be balanced explicitly .
A natural link between our method and k anonymity is provided by the min sup parameter , of which we’ve shown that it works in practice . While we haven’t explored this parameter in this work , it is also possible to mimic l diversity [ 10 ] , as in our method the laplace parameter acts as diversity control . The higher the Laplace correction , the lesser the characteristics of the original data are taken into account ( thus degrading quality , but increasing diversity ) .
To obtain even better privacy , one can also directly influence model construction : for example , by filtering the KRIMP candidates prior to building the code table . Correlations between specific values and/or domains can be completely filtered .
7 . Conclusions
We introduce a pattern based data generation technique as a solution to the privacy preserving data mining problem in which data needs to be anonymised . Using the MDL based KRIMP algorithm we obtain accurate approximations of the data distribution , which we transform into high quality data generators with a simple yet effective algorithm . Experiments show that the generated data meets the criteria we posed in the problem statement . For more extensive results and analysis , see [ 14 ] .
Preserving privacy through data generation does not suffer from the same weaknesses as data perturbation . By definition , it is impossible to reconstruct the original database from the generated data , with or without prior knowledge . The privacy provided by the genera tor can be regulated and balanced with the quality of the conclusions drawn from the generated data . For suited databases , the probability of finding a ‘real’ transaction in the generated data is extremely low .
8 . References [ 1 ] Aggarwal , C . C . , and Yu . P . S . “ A condensation approach to privacy preserving data mining ” , Proc . EDBT , 2004 , pp183 199
[ 2 ] Agrawal , R . , and Srikant , R . “ Privacy preserving data mining ” , Proc . SIGMOD , 2000 , pp439 450
[ 3 ] Chen , K . , and Liu , L . “ Privacy Preserving Data Classification with Rotation Pertubation ” , Proc . ICDM , 2005 , pp589 592
[ 4 ] Coenen , F . The LUCS KDD Discretised/normalised ARM and CARM Data Library , http://wwwcsclivacuk/~frans/KDD/Software/ , 2003 .
[ 5 ] Huang , Z . , Du , W . , and Chen , B . “ Deriving private information from randomized data ” , Proc . SIGMOD , 2005 .
[ 6 ] Kargupta , H . , Datta , S . , Wang , Q . , and Sivakumar , K . “ Random data perturbation techniques and privacypreserving data mining ” , Knowledge and Information Systems 4(7 ) , 2005 , pp387 414
[ 7 ] Van Leeuwen , M . , Vreeken , J . , and Siebes , A . “ Compression Picks Item Sets That Matter ” , Proc . PKDD , 2006 , pp585 592
[ 8 ] Liew , CK , Choi , UJ , and Liew , CJ “ A data distortion by probability distribution ” , ACM Trans . Database Systems 3(10 ) , 1985 , pp395 411
[ 9 ] Liu , K . , Giannella , C . , and Kargupta , H . “ An Attacker ’s View of Distance Preserving Maps for Privacy Preserving Data Mining ” , Proc . PKDD , 2006 , pp297 308
[ 10 ] Machanavajjhala , A . , Gehrke , J . , Kifer , D . , and Venkitasubramaniam , M . “ l Diversity : Privacy Beyond kAnonymity ” , Proc . ICDE , 2006 , pp24 35
[ 11 ] Samarati , P . “ Protecting respondents’ identities in microdata release ” , IEEE Trans . Knowledge and Data Engineering , 2001 , pp1010 1027
[ 12 ] Siebes , A . , Vreeken , J . , and Van Leeuwen , M . “ Item Sets That Compress ” , Proc . SIAM SDM , 2006 , pp393 404
[ 13 ] Vreeken , J . , Van Leeuwen , M . , and Siebes , A . “ Characterising the Difference ” , Proc . SIGKDD , 2007 .
[ 14 ] Vreeken , J . , Van Leeuwen , M . , and Siebes , A . Privacy Preservation through Data Generation , Technical Report UU CS 2007 020 , Universiteit Utrecht , 2007 .
