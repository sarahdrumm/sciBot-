Mining Social Images with Distance Metric Learning for
Automated Image Tagging
Pengcheng Wu , Steven CH Hoi , Peilin Zhao , Ying He
{wupe0003,chhoi,zhao0106,yhe}@ntuedusg
School of Computer Engineering Nanyang Technological University
Singapore , 639798
ABSTRACT With the popularity of various social media applications , massive social images associated with high quality tags have been made available in many social media web sites nowadays . Mining social images on the web has become an emerging important research topic in web search and data mining . In this paper , we propose a machine learning framework for mining social images and investigate its application to automated image tagging . To effectively discover knowledge from social images that are often associated with multimodal contents ( including visual images and textual tags ) , we propose a novel Unified Distance Metric Learning ( UDML ) scheme , which not only exploits both visual and textual contents of social images , but also effectively unifies both inductive and transductive metric learning techniques in a systematic learning framework . We further develop an efficient stochastic gradient descent algorithm for solving the UDML optimization task and prove the convergence of the algorithm . By applying the proposed technique to the automated image tagging task in our experiments , we demonstrate that our technique is empirically effective and promising for mining social images towards some real applications .
Categories and Subject Descriptors H.4 [ Information Systems Applications ] : Miscellaneous
General Terms Algorithms , Experimentation
Keywords Social images , distance metric learning , inductive learning , transductive learning , automated image tagging
1 .
INTRODUCTION
Along with the popularity of digital cameras and high quality mobile devices as well as the advances of internet technologies , users can easily upload their images and photos over the World Wide Web ( WWW ) . Moreover , with the great success of social networks and social web sites recently , web users have been highly motivated to share their images with friends and public that allows other users to tag and comment on their image collections . Nowadays , web images , especially social images , which are often of high quality and rich user generated contents including good quality user tags , are playing a more and more important role in WWW . Mining web and social images thus has become an emerging popular research topic in web search and data mining area . In this paper , we investigate a machine learning scheme for mining social images , and its application to resolve a challenging task , automated image tagging , which is important and beneficial to many web and multimedia applications . The goal of an automated image tagging task is to assign a set of semantic labels or tags to a novel image with some pre trained image recognition models . The traditional approach typically has two steps : ( 1 ) representing images by extracting visual features [ 16 ] , and ( 2 ) pre training recognition models by building classification models from a collection of manually labeled training data [ 2 ] . In literature , numerous studies have been devoted to automated image annotation and object recognition tasks [ 15 , 20 ] .
Despite being studied extensively , regular image annotation approaches , which usually work well on small sized testbeds with high quality labels , often fail to handle largescale real photo tagging applications . One major challenge faced by large scale photo annotation is primarily due to the well known semantic gap between low level features and high level semantic concepts . Besides , it is also expensive and time consuming to collect a large set of manually labeled training data by conventional methods . Hence , it has become an urgent need to develop new paradigms for automated image tagging .
In this paper , we investigate an emerging retrieval based annotation paradigm [ 24 , 26 ] for automated photo tagging by mining massive social images freely available on the web . Unlike traditional web images , social images often contain tags and rich user generated contents , which offer a new opportunity to resolve some long standing challenges in multimedia , for instance the semantic gap . The idea of the retrieval based paradigm [ 24 ] is to first retrieve a set of k most similar images for a test photo from the social image repository , and then to assign the test photo with a set of t most relevant tags associated with the set of k retrieved social images . Figure 1 shows an example of tagging a novel image by the proposed technique in this paper . metrics from social images of multi modal contents . Section 4 gives experimental results and discussions . Section 5 briefly reviews some related work , and Section 6 concludes this work .
2 . MINING SOCIAL IMAGES FOR AUTO
MATED IMAGE TAGGING
We first introduce a generic retrieval based annotation framework for mining web/social images for automated image tagging [ 24 ] , followed by the discussion of some open challenges in this framework . 2.1 Overview of Retrieval based Annotation The basic assumption of a retrieval based annotation ap proach towards automated photo tagging is that similar/identical images would share the common/similar tags . Based on this assumption , one can attack automated photo tagging , a long standing challenging in multimedia and computer vision , by mining a large collection of web/social images . Specifically , Figure 2 shows a diagram to illustrate the process of a retrieval based annotation scheme for mining social images to tackle the automated photo tagging task .
Figure 2 : Block diagram for illustrating the process of a retrieval based annotation approach by mining social images with distance metric learning
As shown in the figure , when a novel image is given , we first conduct a similarity search step to find a subset of top k images most similar to the novel image from a social image database . Once obtaining a subset of top k similar images from the similarity search process , the next step is to summarize the tags associated with these similar images , and recommend the top relevant tags by some approach ( eg ranking the associated tags by majority voting ) . 2.2 Open Research Challenges
Despite the simplicity for the above retrieval based annotation framework , there are some open research challenges that have yet to be solved effectively . One important step of the whole framework is how to perform the similarity search process effectively , which is a key process that significantly affects the performance of the subsequent annotation process . In general , the similarity search process requires a distance metric for distance measure in the retrieval process . Hence , distance metric learning to find an optimal metric is an open challenge in this framework . Besides , there are also some other open issues , such as the efficiency and scalability of the retrieval process that often requires an effective indexing scheme , and an effective tag ranking scheme that ranks the tags associated with the top k similar images . In
Figure 1 : Example of automatically tagging a novel image by the proposed technique in this paper .
The crux of the retrieval based photo tagging paradigm is to effectively identify and retrieve a set of top k similar photos from social image database , which mainly relies on two key components : ( 1 ) a feature representation scheme to extract salient visual features , and ( 2 ) a distance measure scheme to compute distances for extracted features . This paper focuses on techniques to tackle the second challenge . In particular , by considering features that are represented in vector space , our goal is to study an effective distance measure scheme for improving the retrieval performance . To this end , we propose to apply Distance Metric Learning ( DML ) techniques to resolve this challenge .
DML has been actively studied in machine learning and data mining community , which usually assumes the learning task is provided with explicit side information given in the form of either class labels [ 10 ] or pairwise constraints [ 1 ] where each pairwise constraint indicates whether two examples are similar ( “ must link ” ) or dissimilar ( “ cannot link ” ) . Although DML has been extensively studied [ 10 , 1 , 13 , 4 ] , it is not straightforward to directly apply regular DML techniques as side information is not explicitly available in our learning task . Moreover , regular DML techniques may not be very effective for solving our task , primarily because social image data are often associated with rich contents ( including textual and visual contents ) that differ from typical single view data used in regular DML methods .
To this end , this paper presents a novel unified distance metric learning ( UDML ) framework , which aims to learn effective metrics from implicit side information of social images towards the application of automated photo tagging . Unlike the regular DML techniques , the proposed UDML technique aims to optimize metrics by integrating both textual and visual contents smoothly in a unified framework . Besides , this framework also unifies both inductive and transductive metric learning approaches together in a systematic approach .
As a summary , the key contributions of this paper include : ( 1 ) a novel unified distance metric learning framework to learn distance metrics from implicit side information of social images ; ( 2 ) an effective algorithm to solve the unified distance metric learning task ; ( 3 ) a new solution by applying the UDML technique to a real application of automated photo tagging ; ( 4 ) extensive experiments to compare our method with a number of state of the art DML algorithms , in which encouraging results were obtained .
The rest of this paper is organized as follows . Section 2 introduces the retrieval based annotation framework of mining social images for automated photo tagging . Section 3 presents the proposed unified distance metric learning framework and an effective algorithm to learn distance naturebirdegretwildlifeanimalreflectionbravobirdsanimalsheronA query imageTop 4 most similar imagesAnnotated tags this paper , we focus on addressing the first challenge of distance metric learning for improving the retrieval process in this framework .
3 . UNIFIED DISTANCE METRIC LEARN
ING FOR MINING SOCIAL IMAGES
3.1 Overview
In this section , we present a novel machine learning approach to learn distance metrics from social images to resolve the automated photo tagging task . Our goal is to attack the challenge of the similarity search process by optimizing the distance metrics from social images . In particular , given a novel image xq ∈ Rd that is represented in a d dimensional space , for any image x ∈ Rd in the database , we consider a family of Mahalanobis distances dM ( xq ; x ) to calculate distance between xq and x as follows :
> dM ( xq ; x ) = kxq − xk2
M = ( xq − x )
( 1 ) where M ∈ Rd.d is any pre defined positive semi definite matrix that parameterizes the Mahalanobis distance . For example , if we choose M as an identity matrix , the above formula reduces to ( square ) Euclidean distance .
M ( xq − x )
Therefore , the goal of distance metric learning is to learn an optimal matrix M from training data such as it can effectively tackle the similarity search process of the retrievalbased photo annotation paradigm . However , unlike conventional DML tasks where side information is often explicitly given a prior ( in the forms of either pairwise constraints or class labels ) , in our problem , side information is only implicitly available in the social image collection .
To facilitate the distance metric learning task , in the following , we first present a simple approach to generate explicit side information from a collection of social images . With the side information , we further present a unified distance metric learning approach that can combine both textual and visual contents smoothly in a systematic learning framework . 3.2 Generation of Side Information
As no explicit side information is given for our DML task , the first step before DML is to derive side information from a collection of N social images S = {si|i = 1 ; : : : ; N} . In general , a social image contains rich user generated contents , including visual images , textual tags , comments , rating , etc . To simplify the discussion , in our approach , we assume each social image si consists of two components : visual image and textual tags , ie , si = ( xi ; ti ) , where xi denotes the visual features extracted from the social image , and ti denotes the tag vector of the social image .
The basic idea of our side information generation approach is to extract side information in terms of “ triplet ” format , ie , ( x ; x+ ; x, ) , which indicates that image x and image x+ are similar/relevant to each other , while image x and image x , are dissimilar/irrelevant . To this purpose , we randomly pick a social image from the collection of social images as a query image qi = ( xqi ; tqi ) , and then generate a subset of triplets Pi with respect to qi as follows : Pi = {(xqi ; xk ∈ ¯Rk(tqi )} ( 2 ) where Rk(tqi ) denotes the set of top k social images that are most relevant with respect to a text based query tqi ,
∈ Rk(tqi );∀xk
)|∀xk
; xk
, i
, i
+ i
+ i and similarly ¯Rk(tqi ) denotes the set of top k least relevant social images . Finally , we repeat the generation process NQ times , and form a set of side information {Pi ; i = 1 : : : ; NQ} , which will be used as input training data for our distance metric learning task . 3.3 Formulation
We now present the formulation of the proposed distance metric learning method . The basic idea of the proposed unified DML method is to combine the ideas of both inductive and transductive learning principles for DML in order to fuse both textual and visual contents of social images smoothly in a systematic optimization framework . Below we first present two kinds of different objective functions for our DML tasks , respectively , and then show the final formulation of the unified distance metric learning method .
331 Inductive metric learning by maximizing margin First of all , following the similar idea of large margin learning principle [ 25 ] , we consider the following inductive learning formulation for optimizing distance metric from side information : min M0
J1(M ) , 1 Np
NQX i=1
X
;x
, i k k
+ i
8(xqi ;x
‘(M ; ( xqi ; x + k )2Pi i
; x
, k i
) ) ( 3 ) where Np denotes the total number of triplets , and ‘ is a typical hinge loss function defined as :
‘(M ; ( xqi ; xk
; xk
, i
+ i
) )
= max{0 ; 1 − [ dM ( xqi ; xk
) − dM ( xqi ; xk
+ i
)]}(4 )
, i
The above loss function indicates that we should optimize the metric by penalizing ( 1 ) large distance between two similar images , and ( 2 ) small distance between two dissimilar images . This clearly reflects the intuition of large margin learning principle .
332 Transductive fusion of text and visual contents Second , we also consider a transductive approach to integrate with both textual tags and visual contents of social images for learning distance metric as follows : wijkxi − xjk2
J2(M ) ,X
( 5 )
M min M0 i;j where wij is the cosine similarity between the two textual tag vectors of the two social images , ie , wij = cos(ti ; tj ) . The above formulation indicates that if two social images share similar textual tags , we expect to force their visual distance to be small .
We can further simplify the above formulation . In particular , we note that each valid metric M can be decomposed into a linear mapping A : Rd 7→ Rr where A = [ a1 ; : : : ; ar ] ∈ > Rd.r such that M = AA . With this representation , we can rewrite the distance measure as : dM ( xq ; x ) = kxq − xk2
M = ( xq − x ) >
= kA >
( xq − x)k
>
AA
( xq − x )
( 6 )
As a result , we can rewrite the formulation of the above objective function as :
J2(M ) = X rX
= i;j wijkxi − xjk2
M = rX k X(D − W )X > a
> ak
> k XLX a
> k=1 > ak = tr(A
XLX
>
A ) k=1
= tr(XLX
>
>
AA
) = tr(XLX
>
M )
( 7 ) where D is a diagonal matrix whose diagonal elements are the sums of the row entries of matrix W , and L = D − W is known as the Laplacian matrix . 333 Unified distance metric learning Finally , by unifying both the inductive formulation and the transductive formulation together , we can achieve the following formulation of unified distance metric learning : min M0
J(M ) , 1 2
> tr(M
M ) + CJ1(M ) + J2(M )
( 8 ) where C and are parameters to trade off between inductive and transductive objective functions , and the first regularization term is introduced to penalize the norm of the metric to prevent some values of the metric dominating all the other elements .
Since each part of the objective function is convex , the above formulation of the unified distance metric learning ( UDML ) problem is a convex optimization task . More exactly , it belongs to semi definite programming ( SDP ) , which in general can be resolved by some existing convex optimization techniques . Since it is often highly intensive to solve an SDP task by a generic SDP solver , it is not efficient and scalable to directly apply existing SDP solvers for our application . To develop an efficient and scalable solution , below we present an efficient algorithm to resolve the optimization of the unified distance metric learning . 3.4 Algorithm
The key challenge of the UDML optimization is to optimize the metric with respect to the inductive maximal margin learning term , which is related to a large set of triplets that can be potentially huge since a large amount of side information is available in practice . To overcome this challenge , we propose a stochastic gradient descent algorithm that resolves the optimization iteratively by randomly sampling a subset of active triplets at every optimization iteration .
Formally , for a particular iteration , we randomly choose a subset of triplets from the whole set of triplets :
)| i ∈ [ Q]}
At = {(xqi ; xk
, i
+ i
; xk
( 9 ) which satisfies |At| = Na Np . Further , from At , we can derive an active set of triplets whose values of the loss function are nonzero , ie , A+ t = {(xqi ; xk ) ) > 0} : ( 10 ) Based on the set of triplets At , we can rewrite the objective function as follows : J(M ;At ) = 1 2
) ∈ At| ‘(M ; ( xqi ; xk
M ) + tr(XLX tr(M
; xk
; xk
M )
, i
, i
>
>
+ i
+ i
X
;x
, i k k
+ i
+
C Na ( xqi ;x
‘(M ; ( xqi ; xk )2At
+ i
; xk
, i
) )
( 11 )
Algorithm 1 : The Stochastic Gradient Descent Algorithm for Unified Distance Metric Learning . ( UDML ) Input : parameter C ; and the number of iterations T Procedure
1 : Choose M1 st kM1k ≤ √
2C
2 : 3 : 5 :
6 : 7 :
8 : for t = 1 ; 2 ; : : : ; T do t = {(x
Randomly choose a set At , st |At| = Na Set A+ ) ∈ At| ‘(Mt ; ( xqi ; x Set a learning rate t = 1 Set Mt+1=2 = Mt − t[@J(Mt ; At)=@M ] t p Set Mt+1 = min{1 ; }Mt+1=2
, ; x k i
+ k i
2C kMt+1=2kF
) ) > 0}
, ; x k i
+ k i
9 : end for 10 : Project M psd Output : M psd T +1 End
T +1 = P SD(MT +1 )
Figure 3 : The Stochastic Gradient Descent Algorithm for Unified Distance Metric Learning .
To minimize the objective function , we adopt the gradient descent approach , which needs to compute the sub gradient of the above objective function as follows : @J(M ; At ) X
> − ( x
− xqi )(x
− xqi )(x
− xqi )
@M
>
, k i
= M + XLX − C Na ( xqi ;x
;x
, [ (x k )2A i + t
, i k k
+ i
+ k i
− xqi ) >
]
+ k i
We repeat the above stochastic gradient descent approach until the algorithm converges . Figure 3 summarizes the details of the proposed stochastic gradient descent algorithm for UDML . In the algorithm , at the end of each gradient descent step , we perform a scaling process by forcing the solution Mt+1 ≤ √
Mt+1 = minn1 ;
2C below : √
2C kMt+1=2kF oMt+1=2
( 12 )
The detailed reason for the above scaling step will be discussed in the subsequent analysis section ( referred to Lemma 1 and 2 ) . Besides , to further improve efficiency , we do not force the PSD constraint at every gradient descent step . At the end of the entire algorithm , to ensure that the final solution M is a valid metric , we perform a projection of the final matrix MT +1 onto the PSD domain : M psd T +1 = P SD(MT +1 ) . 3.5 Convergence Analysis
Below we theoretically analyze the convergence of the proposed algorithm . Our proofs and analysis mainly follow the principles and theory of online convex optimization [ 11 , 18 ] . Firstly , we present a lemma , which provides an upper bound for the norm of the optimal solution M , and explains why performing the scaling step in the algorithm .
Lemma 1 . The optimal solution of optimization problem ( 8 ) is in the convex close set BM = {M|kMkF ≤ √ k · kF denotes the Frobenius norm .
2C} , where
Proof . Let us denote by M fi the fact that J(M kM fik2
F = tr((M
1 2
1 2 the optimal solution . Using fi
; X ) ≤ J(0 ; X ) , we thus have fi fi fi
) ≤ J(M
; X ) ≤ J(0 ; X ) = C
> )
M
M ) =
As a result ,
√ k∇tkF ≤
1 := R In addition , it is easy to see that , when T ≥ 3
2C + 4R2
1 + 8CR2
1 + ln(T )
2T
≤ ln(T )
T
( 16 )
( 17 )
Pi;j wijkxi − xjk2
> The second inequality is guaranteed by tr(XLX ) ) ≥ 0 .
M ≥ 0 and ‘(M ; ( xk
; xk
+ i
, i
Before presenting the theorem , we first introduce an im portant lemma that generalizes a result from [ 11 ] . k · k2
Lemma 2 . Let g1 ; :: : ; gT be a sequence of strongly conF . Let B be a closed vex functions wrt the function 1 convex set and define ΠB(M ) = arg minM02B kM − M 0kF . 2 Let M1 ; : : : ; MT +1 be a sequence of matrices such that M1 ∈ B and for t ≥ 1 , Mt+1 = ΠB(Mt − t∇t ) , where ∇t is a subgradient of gt at Mt and t = 1=(t ) . Assume that for all t , k∇tk ≤ G . Then for all M ∈ B we have
TX t=1
1 T
TX t=1 gt(Mt ) ≤ 1 T gt(M ) +
G2(1 + ln(T ) )
2T
( 13 )
Based on Lemma 2 , we are now ready to bound the average of the stochastic objective function J(Mt;At ) . R1 ∀j ∈ [ N ] , and W is normalized such that Pi;j Wij = 1 . Theorem 1 . Assume that kxqi k ≤ R1 ∀i ∈ [ Q ] , kxjk2 ≤ be the optimal solution . Then , for T ≥ 3 we have TX J(Mt;At ) ≤ 1 T √
;At ) +
TX
R2 ln(T )
Let M
J(M
( 14 )
1 T t=1 t=1
T fi fi
2C + ( 4 + 8C)R2 1 . where R = Proof . To simplify our notation we use the shorthand Jt(M ) = J(M ;At ) . The update of the algorithm can be rewritten as Mt+1 = ΠBM ( Mt − t∇t ) , where BM is defined in Lemma 1 and ∇t = @J(Mt;At)=@M . Thus , we only need to prove the conditions in Lemma 2 are satisfied . kMk2 F )
Since gt is the sum of a 1 strongly convex function ( 1 2 and a convex function , it is also 1 strongly convex .
Next we would bound the norm of the sub gradient : k∇tkF ≤ kMtkF + kXLX >kF X X
C Na
( xqi ;x
, i
+ i
+
+
;x k k
C Na
)2A + t
( xqi ;x
;x
+ i
)2A + t
, i k(x
, k i
− xqi )(x
, k i
− xqi )
>kF k(x
+ k i
− xqi )(x
+ k i
− xqi )
>kF k k
Firstly , kMtkF ≤ √ 2C according to the design of the algorithm . And then , we would provide an upper bound on kXLX >kF . Before proving the bound , we note that ff =X xj)2 ≥ 0 ∀ff ∈ Rm.1 > xi − ff wij(ff
XLX
>
>
> ff ij
> is positive semi definite . We thus have
Thus , XLX =qtr(XLX>XLX> ) ≤qtr(XLX>)2 = tr(XLX >kF kXLX =X wij ( kxik + kxjk)2 ≤X wijkxi − xjk2 ≤X
>
) wij 4R2 1 ij ij ij
= 4R2 1 where the first inequality holds because tr(AB ) ≤ tr(A)tr(B ) , when A and B are positive semi definite matrices of the same order . Furthermore , we have k(x − xq)(x − xq ) ≤ ( kxk2 + kxqk2)2 ≤ 4R2
>kF = ( x − xq )
1
>
( x − xq ) = kx − xqk2
2 ( 15 )
Combining all of these results , the proof is done .
Since Theorem 1 only provides a comparison for the functions J(M ; At ) , now the following theorem will provide a comparison between J(M ) . For convenience , we denote Aj i = ( Ai ; : : : ; Aj ) . Then we have the following theorem : Theorem 2 . Assume that the conditions stated in Theorem 1 hold and for all t , At is chosen iid from the set of all triplets . Let r be an integer picked uniformly at random from [ T ] . Then
Er[J(Mr ) ] ≤ J(M fi
) +
EAT
1
R2 ln(T )
T
( 18 )
The proof of Theorem 2 can be found in the Appendix . Theorem 2 states that , in expectation , the SGD algorithm will converge quickly . The next theorem will provide a bound of the objective function in probability .
Theorem 3 . Assume that the conditions stated in Theorem 2 holds . Let ffi ∈ ( 0 ; 1 ) . Then , with probability of at least 1− ffi over the choices of A1 ; :: : ; AT and the index r , we have the following bound :
J(Mr ) ≤ J(M fi
R2 ln(T )
) +
Proof . Let Z := J(Mr ) − J(M
( 19 ) ffiT ) ≥ 0 be a random variable . Thus , from Markov inequality P ( Z ≥ a ) ≤ E[Z]=a and P ( Z ≤ a ) + P ( Z ≥ a ) = 1 , we have P ( Z ≤ a ) = 1 − P ( Z ≥ a ) ≥ 1 − E(Z ) a . As a result , we have fi
P ( Z ≤ R2 ln(T ) ffiT
) ≥ 1 − E(Z )
R2 ln(T )
≥ 1 − R2 ln(T )
R2 ln(T )
T
= 1 − ffi ( 20 ) ffiT ffiT
In the above , we apply Theorem 2 , ie , E(Z ) ≤ R2 ln(T )
.
T
We now use the above theorem to analyze the convergence of the last matrix MT +1 . We can treat T + 1 as a random index drawn from {1 ; : : : ; ˆT} , where ˆT > T + 1 . Since MT +1 does not depend on MT +2 ; : : : ; M ^T , we can terminate the algorithm after T iterations and return MT +1 . Using Theorem 3 , we know that fi ffi ˆT
) ≤ R ln( ˆT )
J(MT +1 ) − J(M
≤ R ln(T ) ( 21 ) decreases in [ 3 ; +∞ ) . where the last inequality holds as ln(T ) 3.6 Tagging Images with Optimized Metrics Finally , we briefly describe the process of automated image tagging by applying the optimized metric M learned by applying distance metric learning techniques . ffiT
T
In particular , given a novel unlabeled image xq for tagging , the first step is to conduct similarity search to retrieve a subset of similar images with tags from social image database . In our approach , we retrieve a set of k nearest neighbors of the query image , ie ,
Nk(xq ) = {i ∈ [ 1 ; : : : ; n]|xi ∈ kNN − List(xq)} ;
( 22 ) where n is the total number of images in the social image repository , and the kNN − List is found by measuring the distances with the optimized metric M , ie , kxq − xik2 M . With the set of similar social images Nk(xq ) , the next step is to perform a tag ranking by adapting the idea of majority voting . Specifically , we define a set of candidate tags Tw as : ( 23 )
Tw = [
Ti i2Nk(xq ) where Ti represents the set of tags associated with social image si . Further , we calculate the frequency of each candidate tag w ∈ Tw , denoted as f ( w ) , which indicates the number of times the tag is associated with the k social images . Finally , we conduct the automated image tagging by following the intuition : to assign the query image with a tag of high frequency and small average distance . Specifically , we tag the novel image xq by incrementally adding a tag using the following approach : fi w
= arg max w2Tw^w =2Tq f ( w ) avg dM ( xq ; w ) +
( 24 ) where avg dM ( xq ; w ) represents the average distance ( with optimized metric M ) between the query image and those candidate social images that have tag w , and is a smoothing parameter fixed to 1 in our experiments .
4 . EXPERIMENTS
In this section we discuss our experiments for evaluating the performance of our unified distance metric learning approach for automated photo tagging . 4.1 Experimental Testbed
We conducted our experiments on a real world social images testbed , which consists of 200,000 images crawled from Flickr website . These social images contain rich information , including user generated tags and other metadata .
To simplify the experiments , we employed tags and visual features to represent a social image . For text information , we sorted all tags in the dataset by their frequencies , the top 100,000 of which were used to construct a dictionary , and the others were abandoned . To improve the quality of annotation , we manually removed some clearly noisy tags from the dictionary by applying a list of stopwords . We adopted each image ’s associated tags in this dictionary as its text features . For visual features , we extracted four kinds of effective and compact visual features , including grid color moment , local binary pattern , Gabor wavelet texture , and edge direction histogram . In total , a 297 dimensional feature vector was used to represent each image . The set of features had been used in some previous CBIR studies [ 30 , 12 , 26 ] . We randomly split the 200,000 images data set into 3 sets : training set , test set and database set .
• The training set is used as input training data for distance metric learning . We randomly sampled 15,000 images with their associated metadata from the whole dataset . These social images were used to generate side information for DML .
• The test set is adopted to test the tagging performance . In particular , we randomly chose 2,000 images as query images and treated their associated tags in the dictionary as the annotation ground truth directly .
• The database set consists of the rest 183,000 images . It is used as social image repository for the retrievalbased tagging process .
4.2 Compared Methods
To evaluate the performance of the proposed UDML method , we compared it extensively with two major categories of metric learning techniques . One is to learn metrics with explicit class labels , such as NCA[10 ] , LMNN[25 ] . The other is to learn metrics from pairwise constraints , such as RCA[1 ] , DCA[13],OASIS[4 ] . Specifically , the compared schemes include :
• Euclidean : the baseline method . • DCA[13 ] : Discriminative Component Analysis , which leans a linear projection using only equivalent constraints .
• RCA[1 ] : Relevance Component Analysis that learns a linear projection using only equivalent constraints .
• ITML[5 ] : Information Theoretic Metric Learning which trains the metric with the goal that minimizes the differential relative entropy between two multivariate Gaussians under constraints on the distance function . • RDML[19 ] : Regularized Distance Metric Learning that adopts the correlation between users’ relevance feedback and low level image features .
• LMNN[25 ] : Large Margin Nearest Neighbor whose goal is that k nearest neighbors always belong to the same class while examples from different classes are separated by a large margin .
• NCA[10 ] : Neighbourhood Components Analysis which maximizes a stochastic variant of the leave one out kNN score .
• OASIS[4 ] : Online Algorithm for Scalable Image Similarity learning , which is an online dual approach based on the passive aggressive algorithm and is to learn a bilinear similarity measure over sparse representations . • LRML[12 ] : Laplacian Regularized Metric Learning whose goal is to leverage the unlabeled data information and to ensure metric learning smoothness through a regularization learning framework .
• pRCA[26 ] : probabilistic Relevant Component Analysis , which learns an optimal metric from probabilistic side information .
• UDML : the proposed Unified Distance Metric Learn ing method .
4.3 Experimental Setup
As no explicit side information is available in the experiments , in order to apply DML techniques , we applied the proposed side information generation approach described in Section 3.2 to derive side information from the training set of social images . In particular , we randomly chose one social image as query from the dataset , and generated a set of 100 triplets for each query . We ran the random sampling process 1000 times , and totally generated 100 ; 000 triplets as side information for our experiments . The same set of side information was used/converted to other appropriate formats ( eg chunklets ) for other DML methods . Regarding parameter settings , we simply fixed tradeoff parameters = 1 , C = 10000 , the size of active set Na = 100 , and the total number of iterations T = 1000 for the proposed UDML algorithm .
To evaluate performance of DML approaches for automated image tagging , we applied the retrieval based tagging procedure as described in Section 36 Specifically , a query image was chosen from the test set , and then used to search similar images from the database set by applying the optimized distance metrics . In particular , a set of top k ( we set k = 30 in default ) images were retrieved , and then top t tags ranked by equation ( 24 ) were suggested to tag the query image . The annotation performance was then evaluated based on the relevance of the top ranked tags ranging from top 1 to top 10 tags . The standard average precision ( AP ) and average recall ( AR ) were employed as the performance metrics . 4.4 Experimental Results
Figures 4 and 5 show the average precision and recall results achieved by different DML methods , where the horizontal axis denotes the number of the top t tags annotated . Figure 5 shows a comparison of the precision recall curves by different DML methods . For all these comparisons , we fixed the number of similar images k = 30 in the annotation procedure . From these experimental results , we can draw several observations as follows .
Figure 5 : Average recall at top t annotated tags the difficulty of retrieving the similar social images without a very large scale database ; ( 2 ) the associated tags of some social image are quite noisy that could degrade the tagging performance ; and ( 3 ) the optimized distance measure may be still not perfect to return the most similar social images relevant to the query image , which shows that there might be still a large room to study more effective distance metric learning techniques in the future .
Figure 4 : Average precision at top t annotated tags
First of all , we found that all the DML based approaches performed significantly better than the baseline tagging approach that simply adopts Euclidean distance . This shows that the approach of applying DML to optimize the metrics is beneficial and important for the retrieval based image tagging task .
Second , among all the compared methods , we observed that the proposed UDML method considerably surpassed all the other approaches for most cases . For instance , in terms of the average precision performance , UDML achieved about 29:6 % , while the baseline approach only had 23.2 % and the results of other DML methods ranged from 26.0 % to 278 % Lastly , despite the above encouraging improvements , we noticed that the average precision values of all the compared methods are still quite low . The possible reasons include ( 1 )
Figure 6 : The precision recall curves
4.5 Evaluation of Varied k Values
Figure 7 shows the performance of UDML at top t tags by varying k , the number of top retrieved similar images from 10 to 60 . From the results , we observed that k affects the annotation performance . In particular , when k is about 40 to 50 , the proposed method achieved the best average precision . This is reasonable because if k is too small , some relevant images may not be retrieved , while if k is too large , lots of irrelevant images could be retrieved , leading to engage many noisy tags in the list of candidate tags . Both of the above situations could degrade the annotation performance .
123450005010150202503035Top t annotated tagsAverage Precision BaselineDCARCAITMLRDMLLMNNNCAOASISLRMLpRCAUDML123450001002003004005006007Top t annotated tagsAverage Recall BaselineDCARCAITMLRDMLLMNNNCAOASISLRMLpRCAUDML001002003004005006007008009010120140160180202202402602803Average RecallAverage Precision BaselineDCARCAITMLRDMLLMNNNCAOASISLRMLpRCAUDML 5.2 Distance Metric Learning
In literature , DML has been actively studied in two major domains . One is to learn metrics with explicit class labels , which are often studied for classification tasks [ 14 , 8 , 9 , 25 , 29 ] . The other is to learn metrics from pairwise constraints that are mainly used for clustering and retrieval [ 1 , 13 , 27 ] . Moreover , from machine learning perspective , most existing DML studies belong to inductive learning methods , although there are some recent studies that have attempted to explore transductive learning for DML [ 12 ] .
Our study is quite different from existing DML approaches in data mining and machine learning . Unlike most existing DML methods that assume explicit side information is provided in the form of either class labels or pairwise constraints , in our DML problem , no explicit side information is directly given for the learning task . Hence , in our study , we actually learn metrics from implicit side information , which is hidden in the rich contents of social image data in our application . Finally , we unify both inductive and transductive learning principles in a systematic framework . 6 . CONCLUSIONS
This paper investigated a machine learning approach for mining social images towards the application of automated image tagging . In particular , we proposed a novel unified distance metric learning ( UDML ) method , which learns metrics from implicit side information hidden in massive social images available on the web . Unlike the regular metric learning studies , the proposed UDML method is able to fully exploit both textual and visual contents for learning an effective metric in a unified and systematic learning framework . To handle a real large scale web mining problem , we proposed an efficient stochastic gradient descent algorithm and showed its convergence property by providing theoretical proofs . Experimental results on a real social image testbed show that our UDML method is effective and promising for mining social images for solving automated image tagging applications . In future work , we plan to enlarge the social image database , and investigate more sophisticated tag ranking techniques for improving the annotation performance . Appendix : Proof of Theorem 2
Proof . Taking expectation of the inequality of Theorem
1 leads to the following :
E AT 1
[
1 T
J(Mt ; At ) ] ≤ E
AT 1
[
1 T fi
J(M
; At ) ] +
R2 ln(T )
T
Since M does not depend on the choice of triplets , we have
E AT 1
[
1 T fi
J(M
; At ) ] =
=
1 T
1 T fi
; At )
J(M
E AT 1
EAt J(M fi
; At ) = J(M fi
)
TX TX t=1 fi t=1 t=1
TX TX TX t=1
TX t=1
E AT 1
[
1 T
J(Mt ; At ) ] =
= t=1
1 T
1 T
TX TX t=1 t=1
E AT 1
E At 1
J(Mt ; At )
J(Mt ; At )
Figure 7 : Comparisons of average precision under different top k similar images used
4.6 Comparison of Qualitative Performance Our last experiment is to demonstrate the qualitative tagging performance achieved by different DML methods for automated image tagging tasks . To achieve this purpose , we randomly chose several images from the test set , and applied a number of different DML methods to annotate them using the proposed retrieval based annotation approach . Figure 8 shows the top 10 annotated tags under different metrics . The relevant tags are marked in “ blue ” font . The results show that UDML often achieves better quality among all the 11 approaches . 5 . RELATED WORK
Our work is related to several groups of research , including social image search and mining with applications to automated image/photo annotation and object recognition [ 17 , 21 , 28 ] , and distance metric learning ( DML ) studies [ 27 , 1 , 19 , 5 ] , etc . Due to limited space , we briefly review some most representative and relevant studies below . 5.1 Web/Social Image Mining
Our work is related to web/social image search and mining as well as automated image annotation . Image annotation has been actively studied over the past decade in multimedia community . Conventional approaches often train some classification models , eg SVM [ 7 ] , from a collection of humanlabeled training data for a set of predefined semantic concept/object categories [ 2 , 3 , 6 , 23 ] .
Recently , there is a surge of emerging interests in exploring web photo repositories for image annotation . A promising approach is the retrieval based ( or termed “ search based ” ) paradigm [ 17 , 24 , 21 , 22 ] . Russell et al . [ 17 ] built a large collection of web images with ground truth labels for helping object recognition research . Wang et al . [ 24 ] proposed a fast search based approach for image annotation by some efficient hashing technique . Torralba et al . [ 21 ] proposed efficient image search and scene matching techniques for exploring a large scale web image repository . These work usually concerned more on fast indexing and search techniques , while we focus on learning more effective distance metrics . Finally , our work mainly follow the recent study of exploring social images for automated photo tagging [ 26 ] , but we propose a new and empirically more effective method .
1 2 3 4 5 6 7 8 9 100005010150202503035Top t annotated tagsAverage Precision Top10Top20Top30Top40Top50Top60 Recall the law of total expectation implies that for any two random variables X , Y , EX [ J(X ) ] = EY EX [ J(X)|Y ] , thus
E At 1
[ J(Mt ; At ) ] = E = E
1
At,1 At,1
1
[ E [ J(Mt ) ] = E
[ J(Mt ; At)|At,1 [ J(Mt ) ]
At 1
] ]
1
AT 1
Putting the above together , we can obtain
TX t=1
E AT 1
[
1 T
J(Mt ; At ) ] = E
J(Mt ) ]
AT 1
[
1 T
TX T PT t=1
Furthermore , since Er[J(Mr ) ] = 1 all the above leads to complete our proof . t=1 J(Mt ) , combining
7 . REFERENCES [ 1 ] A . Bar hillel and D . Weinshall . Learning a
Mahalanobis Metric from Equivalence Constraints . Journal of Machine Learning Research , 6:937–965 , 2005 .
[ 2 ] G . Carneiro , A . B . Chan , P . Moreno , and
N . Vasconcelos . Supervised learning of semantic classes for image annotation and retrieval . IEEE Tran . PAMI , pages 394–410 , 2006 .
[ 3 ] G . Carneiro and N . Vasconcelos . Formulating semantic image annotation as a supervised learning problem . In IEEE CVPR , pages 163–168 , 2005 .
[ 4 ] G . Chechik , V . Sharma , U . Shalit , and S . Bengio .
Large Scale Online Learning of Image Similarity Through Ranking . Journal of Machine Learning Research , 11:1109–1135 , 2010 .
[ 5 ] J . V . Davis , B . Kulis , P . Jain , S . Sra , and I . S .
Dhillon . Information theoretic metric learning . In ICML , pages 209–216 , 2007 .
[ 6 ] P . Duygulu , K . Barnard , J . de Freitas , and D . A .
Forsyth . Object recognition as machine translation : Learning a lexicon for a fixed image vocabulary . In ECCV , pages 97–112 , 2002 .
[ 7 ] J . Fan , Y . Gao , and H . Luo . Multi level annotation of natural scenes using dominant image components and semantic concepts . In ACM Multimedia , pages 540–547 , 2004 .
[ 8 ] K . Fukunaga . Introduction to Statistical Pattern
Recognition . Elsevier , 1990 .
[ 9 ] A . Globerson and S . Roweis . Metric learning by collapsing classes . In NIPS’05 , 2005 .
[ 10 ] J . Goldberger , S . Roweis , G . Hinton , and
R . Salakhutdinov . Neighbourhood components analysis . In Advances in Neural Information Processing Systems , 17 , 2005 .
[ 11 ] E . Hazan , A . Agarwal , and S . Kale . Logarithmic regret algorithms for online convex optimization . Mach . Learn . , 69(2 3):169–192 , 2007 .
[ 12 ] S . C . Hoi . Semi supervised distance metric learning for Collaborative Image Retrieval . 2008 IEEE Conference on Computer Vision and Pattern Recognition , pages 1–7 , June 2008 .
[ 13 ] S . C . Hoi , W . Liu , M . R . Lyu , and W Y Ma .
Learning distance metrics with contextual constraints for image retrieval . In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition ( CVPR2006 ) , New York , US , June 17–22 2006 .
[ 14 ] G . H . J . Goldberger , S . Roweis and R . Salakhutdinov . Neighbourhood components analysis . In NIPS17 , 2005 .
[ 15 ] J . Jeon , V . Lavrenko , and R . Manmatha . Automatic image annotation and retrieval using cross media relevance models . In SIGIR’03 , pages 119–126 , Toronto , Canada , 2003 .
[ 16 ] D . G . Lowe . Distinctive image features from scale invariant keypoints . IJCV , 60:91–110 , 2004 .
[ 17 ] B . C . Russell , A . Torralba , K . P . Murphy , and W . T .
Freeman . Labelme : A database and web based tool for image annotation . Int . J . Comput . Vision , 77(1 3):157–173 , 2008 .
[ 18 ] S . Shalev Shwartz , Y . Singer , and N . Srebro . Pegasos :
Primal estimated sub gradient solver for svm . In ICML , pages 807–814 , New York , NY , USA , 2007 . ACM .
[ 19 ] L . Si , R . Jin , S . C . H . Hoi , and M . R . Lyu .
Collaborative image retrieval via regularized metric learning . ACM Multimedia Systems Journal , 12(1):34–44 , 2006 .
[ 20 ] A . W . M . Smeulders , M . Worring , S . Santini ,
A . Gupta , and R . Jain . Content based image retrieval at the end of the early years . IEEE Trans . PAMI , 22(12):1349–1380 , 2000 .
[ 21 ] A . Torralba , Y . Weiss , and R . Fergus . Small codes and large databases of images for object recognition . In CVPR , 2008 .
[ 22 ] C . Wang , L . Zhang , and H J Zhang . Learning to reduce the semantic gap in web image retrieval and annotation . In SIGIR’08 , pages 355–362 , Singapore , 2008 .
[ 23 ] M . Wang , X . Zhou , and T S Chua . Automatic image annotation via local multi label classification . In ACM CIVR , pages 17–26 , New York , NY , USA , 2008 . ACM .
[ 24 ] X J Wang , L . Zhang , F . Jing , and W Y Ma .
Annosearch : Image auto annotation by search . In CVPR’06 , pages 1483–1490 , 2006 .
[ 25 ] K . Weinberger , J . Blitzer , and L . Saul . Distance metric learning for large margin nearest neighbor classification . In NIPS , 2006 .
[ 26 ] L . Wu , S . Hoi , R . Jin , J . Zhu , and N . Yu . Distance metric learning from uncertain side information with application to automated photo tagging . In Proceedings of the seventeen ACM international conference on Multimedia , pages 135–144 . ACM , 2009 .
[ 27 ] E . P . Xing , A . Y . Ng , M . I . Jordan , and S . Russell .
Distance metric learning with application to clustering with side information . In NIPS2002 , 2002 .
[ 28 ] R . Yan , A . Natsev , and M . Campbell . A learning based hybrid tagging and browsing approach for efficient manual image annotation . In IEEE CVPR’08 , 2008 .
[ 29 ] L . Yang , R . Jin , R . Sukthankar , and Y . Liu . An efficient algorithm for local distance metric learning . In AAAI , 2006 .
[ 30 ] J . Zhu , S . C . Hoi , M . R . Lyu , and S . Yan .
Near duplicate keyframe retrieval by nonrigid image matching . Proceeding of the 16th ACM international conference on Multimedia MM ’08 , page 41 , 2008 . k c o l b g n i w o l l o f h c a e d n a e g a m i t s e t a s i e g a m i t s r fi e h t
, w o r h c a e r o F
. s d o h t e m t n e r e ff i d
1 1 y b s t l u s e r g n i g g a t e h t g n i w o h s s e l p m a x E
: 8 e r u g i F
. r o l o c e u l b y b d e t h g i l h g i h e r a s g a t t c e r r o c e h T
. d o h t e m e n o y b d e t a t o n n a s g a t
0 1 p o t s w o h s
BaselineDCARCAITMLRDMLLMNNNCAOASISLRMLpRCAUDMLnaturenaturenaturenaturenaturenaturenaturenaturenaturenaturenaturebluebirdwildlifereflectionbluebirdbluewildlifebirdreflectionbirdreflectionbravobirdbirdbirdreflectionbirdbirdwildlifewateregretbirdreflectionreflectionbravoreflectionwildlifebeachreflectionreflectionanimalwildlifeanimalbirdsspecanimalwildlifewatercanonspecanimalwaterbirdsbirdanimalwaterspecnatureanimalkingdomwaterwildlifeanimalreflectionbravoanimalegretreflectioncanonanimalanimalbirdsmountainspecanimalwildlifespecanimalegretbravobravoegretegretwateranimalspecanimalegretanimalspecnaturespecanimalanimalkingdombirdsspecanimalspecanimalbirdsegretegretblueplaneanimalspecnaturemountainanimalswildlifewateregretanimalkingdomspecnatureanimalkingdombravoegretjapanspecanimalheronforesttreesfogforestforesttreesforestforestfogforestforestnatureforesttreesfognatureforestfogtreesforestnaturefogtreesfogforesttreestreestreetreefogtreestreesnaturelightlightbravotreefognaturenaturetreemistexploretreetreeexploremistnaturetreefogtreesnaturetreetreetreesfogmorningtreelandscapelightblackmistgermanynaturefogwoodexploretreelightmorningsoecanonlightmorningalberilandscapemistbravonaturelandscapegermanywoodslightcanonlandscapeexplorebravogermanywoodssoenaturemistartwintermorningwoodmistymistlandscapelandscapelandscapemorningwoodvisionwhitewoodwinterparklightmorningnaturemacromacronaturenaturenaturemacrogreennaturemacrogreenmacronaturegreenmacromacromacronaturemacrogreengreenmacrogreeninsectnaturegreengreenbirdgreennaturemacronaturenatureinsectbutterflybuginsectcanoninsectcanoncanoncanoninsectbugcanonbokehinsectsoebutterflybutterflyinsectbugbirdleafinsectbravocanonleafdofbirdbestleafeoslightbravocanonbugsoeraindragonflyinsectbravobravoinsectlandscapecanondofbirdgreenwaterphotobravobugbutterflyexcapturemacrleafplantsoespecanimalbugdofexplorespecanimalbokeheosflowerwaterphotosbokehflowerflowercanonbutterflyflowertaiwanbirddragonflydofbutterflydragonflygardennatureautumntreesgardennaturegardentreesnaturegreentreesoldexploreforestnatureoldtreesparknaturetreestreesnaturevancouvercanonfallforestfallgreengreenspringfallriveroldparktreestreesautumnparkoldjapaneseoldautumnautumntreespringrivernaturegreenvancouvergardenwinnerforestforestgardenparkfallusaperfectrivertreeexplorebravoautumnsoesoebridgeexploretravellovebravofavoritegardenperfecttreesoeexplorenaturegreenfavoritegardenarttreelandscapewinnerlandscapecanadaparktreecanonleavescanonwoodleavesfallspringcanonlandscapebravoleavesleavescolorscarfallwaterfallspringgreenforestnaturejapanbravobravobravo
