Aspect and Sentiment Unification Model for Online Review Analysis
Department of Computer Science
Department of Computer Science
Alice Oh
KAIST
Daejeon , Korea aliceoh@kaistedu
Yohan Jo
KAIST
Daejeon , Korea yohanjo@kaistackr
ABSTRACT User generated reviews on the Web contain sentiments about detailed aspects of products and services . However , most of the reviews are plain text and thus require much effort to obtain information about relevant details . In this paper , we tackle the problem of automatically discovering what aspects are evaluated in reviews and how sentiments for different aspects are expressed . We first propose Sentence LDA ( SLDA ) , a probabilistic generative model that assumes all words in a single sentence are generated from one aspect . We then extend SLDA to Aspect and Sentiment Unification Model ( ASUM ) , which incorporates aspect and sentiment together to model sentiments toward different aspects . ASUM discovers pairs of {aspect , sentiment} which we call senti aspects . We applied SLDA and ASUM to reviews of electronic devices and restaurants . The results show that the aspects discovered by SLDA match evaluative details of the reviews , and the senti aspects found by ASUM capture important aspects that are closely coupled with a sentiment . The results of sentiment classification show that ASUM outperforms other generative models and comes close to supervised classification methods . One important advantage of ASUM is that it does not require any sentiment labels of the reviews , which are often expensive to obtain .
Categories and Subject Descriptors H33 [ Information Storage and Retrieval ] : Information Search and Retrieval—Retrieval models ; G.3 [ Probability and Statistics ] : Probabilistic algorithms ; I27 [ Artificial Intelligence ] : Natural Language Processing—Text analysis
General Terms Algorithms , Experimentation
Keywords aspect detection , sentiment analysis , topic modeling
Figure 1 : Example laptop review from Amazon.com
1 .
INTRODUCTION
The Web has an overwhelming amount of reviews of products , restaurants , books , and many other types of tangibles and intangibles . In those reviews , people praise and criticize a variety of aspects of the target of the review , such as the waiting time of a restaurant or the noise level of a vacuum cleaner . In Figure 1 , the reviewer evaluates aspects of a laptop such as the price , monitor size , and sound . Although some Websites ( eg , TripAdvisor ) are specifically designed for user reviews with a predefined evaluation form , most users express their opinion in online communities and personal blogs using plain text without any structure .
One big problem is to find aspects that users evaluate in reviews . From the perspective of a user reading the reviews to get information about a product , the evaluations of the specific aspects are just as important as the overall rating of the product . A user looking to buy a digital camera may want to know what a review says about the photo quality , brightness of lens , and shutter speed of a Panasonic Lumix , not just whether the review recommends the camera . Although sometimes the aspect information is available , it is unlikely to be a comprehensive set of all aspects that are evaluated in the reviews . Another important task in review analysis is discovering how opinions and sentiments for different aspects are expressed . The cell phone ’s battery lasts “ long ” , a laptop ’s screen “ reflects ” , and a restaurant ’s server is “ attentive ” . These are sentiment words at the level of the aspect . Previous efforts have mostly focused on sentiment words at the level of the domain ( eg , electronics , movies , restaurants ) .
Miguel A . Atuesta "Mig 21" ( Bogota ) See all myreviews Help other customers find the most helpful reviews Was this review helpful to you ? Report abuse | Permalink Comments ( 12)By Jessica L . Milbrett ( OR , USA ) See all my reviews Help other customers find the most helpful reviews Was this review helpful to you ? Report abuse | Permalink Comments ( 2)LaptopsLatest activity 1 day ago1,389 customers have contributed 782products and more› Explore the communityHewlett PackardLatest activity 20 hours ago1,374 customers have contributed 812products and more› Explore the communityHPLatest activity 2 hours ago4,065 customers have contributed 1,746products and more› Explore the communityThis review is from : HP Pavilion DV4 2161NR 14.1 Inch Laptop ( DigitalPlaid ) ( Personal Computers)I had have this computer for a month now , so here goesnothing : Pros : Excellent design 4GB Ram , enough for most tasks 500GB hard drive , for me that's enough for now Small size and little weight ( even lighter when DVD isremoved , which is an excellent feature in itself ) Windows 7 ( better than Vista , we'll see about XP ) EXCELLENT PRICE Cons : Battery life is about 2 hours , bound to decrease within 6months , not on par with most other laptops this size . Touchpad really has a mind of its own on ocassion . Glossy design is beautiful , but it's also a fingerprintmagnet Opening it is a cumbersome task , not really bad , but alittle . Windows 7 "64bit" Some old programs I use refuse towork in such environment . All in all a solid laptop , with excellent features ( and minorinconveniences ) , but please , HP , this is my third HP laptopand the batteries have never been your forte . ( yet I keepbuying HP ) DO SOMETHING! UPDATE : The battery won't last for more than an hour anda half , so I took two stars off my review for this majorinconvenience . Sorry to say this , but I no longerrecommend this purchase.59 of 62 people found the following review helpful : Excellent Computer for an Excellent Price,February 10 , 2010Amazon Verified Purchase(What's this?)This review is from : HP Pavilion DV4 2161NR 14.1 Inch Laptop ( DigitalPlaid ) ( Personal Computers)I've owned my computer for almost a week now , and I'mabsolutely loving it . For the money I almost bought an Hpwith a T6600 processor and 320GB hard drive etc etc . Ibought this for the same price as the other hp and gotMORE memory and a better processor . Why wouldn't youwant an upgrade of 180 GB hard drive for free ? If your astudent and like to have lots of music , videos and play lightgaming and still have tons of room for your homework andprojects , this is a great computer . I also love how its 14" monitor , so I can take it anywhereand fit it into any bag . It has a very sleek and glossyexterior . A little bit of work to keep clean , but that's noreason not to buy a computer . The speakers are great for alaptop . I was actually surprised how clear sounds and musicwas . As with most HP laptops , you get the lightscribeburner , which is great , but it also comes with a discreplacement thing so if you don't care to use a disc drive,you can remove it and save some weight . But really itdoesn't weigh that much . The only downfall I have with this computer is the slightlylow battery life . I think a little bit of that might be my faultcause I just plugged in and played rather than letting thebattery charge fully first before I started playing with it . Great laptop for the price.20 of 20 people found the following review helpful:8 used & newfrom $729.99 AccessoriesCase LogicVNA21414.1 InchLaptopAttache(Black ) byCase Logic ( 59 ) Buynew : $2999$2084 In Stock 29 used &new from$16.99 Case LogicVNA21414.1 InchLaptopAttache(Brown ) byCase Logic ( 59 ) Buynew : $2999$2241 In Stock 26 used &new from$16.76 HP 2.4GHzWirelessOptical MobileMouse(Black ) by HP ( 10 ) Buynew : $2430$1915 15 used &new Customer Communities We tackle these two problems at once with a unified generative model of aspect and sentiment . Probabilistic topic models are suitable for the following two reasons : first , they provide an unsupervised way of discovering topics from documents ( or aspects from reviews ) , and second , they result in language models that explain how much a word is related to each topic and possibly to a sentiment . We take the latent Dirichlet allocation ( LDA ) model [ 4 ] and adapt it to match the granularity of the discovered topics to the details of the reviews . In addition , we incorporate sentiment into our unified model so that the resulting language models represent the probability distributions over words for various pairs of aspect and sentiment .
An important observation is that in reviews , one sentence tends to represent one aspect and one sentiment . Figure 1 shows an example that supports this . The review is evaluating several aspects including the price , free upgrade , size , and sound , and each sentence expresses sentiment about one aspect . In the first sentence in the second paragraph , the words “ monitor ” and “ bag ” co occur . In general , these two words are not closely related , but the co occurrence of them signals that this sentence is evaluating the size of the monitor . We use this observation in our models .
In this paper , we propose two models : Sentence LDA
( SLDA ) and Aspect and Sentiment Unification Model ( ASUM ) . SLDA and ASUM model the generative process of reviews . Based on the observation above , SLDA and ASUM constrain that all words in a single sentence be generated from one topic . ASUM is an extension of SLDA into which sentiment is incorporated . In ASUM , the words in a sentence are generated from the same pair of aspect and sentiment , which we call senti aspect .
We applied our models to various tasks , and the experiments show that our models perform well in the following . • Aspect discovery : SLDA finds aspects that match the details of the reviews better than LDA .
• Senti aspect discovery : ASUM finds senti aspects that reflect both aspect and sentiment , and some aspects strongly related to a sentiment are discovered only by ASUM , not by SLDA .
• Aspect specific sentiment words : ASUM takes a set of general affective and evaluative words and finds aspect specific evaluative words . This is simple sentiment word expansion and adaptation without labeled data .
• Sentiment classification : Although ASUM is not specifically designed for sentiment classification , ASUM performs better than other generative models and almost matches the best performance of a supervised classifier . Much of Web review data is unlabeled , so unsupervised classification of sentiment is an important problem .
2 . TERMINOLOGY
This section defines the terminology used in this paper . • topic : a multinomial distribution over words that rep resents a coherent concept in text .
• aspect : a multinomial distribution over words that represents a more specific topic in reviews , for example , “ lens ” in camera reviews .
• senti aspect : a multinomial distribution over words that represents a pair of aspect and sentiment , for example , “ screen , positive ” in a laptop review .
• affective word : a word that expresses a feeling , for example “ satisfied ” , “ disappointed ” .
• evaluative word : a word that expresses sentiment by evaluating an aspect , for example , “ excellent ” , “ nice ” . • general evaluative word : an evaluative word that expresses a consistent sentiment every time it is used , for example , “ good ” , “ bad ” .
• aspect specific evaluative word : an evaluative word that may express different sentiments depending on the aspect , for example , a “ small ” font size on a monitor that is hard to read vs . a “ small ” vacuum that is portable .
• sentiment word : a word that conveys sentiment . It is either an affective word , general evaluative word , or aspect specific evaluative word .
3 . RELATED WORK
In this section , we describe related research fields of aspect discovery and domain adaptation of sentiment words . We also discuss several unified models of topic and sentiment and compare them with ASUM in details .
A widely used approach in aspect discovery is to extract a set of frequently occurring noun phrases ( NP ) as aspect candidates and then retain only relevant ones by applying various filtering methods [ 3 , 12 , 19 ] . The NP detection is a complex process that may be error prone and pose difficulties for cross domain and cross lingual applications . Another approach employs topic modeling , for example , fitting the latent Dirichlet allocation ( LDA ) model [ 4 ] to sentences instead of documents [ 6 , 26 ] . This approach does not consider the relationships among sentences , thus ignoring the fact that the same aspect may have quite different word usages in different sentences . Another way of using a topic model distinguishes between broad topics and fine grained ratable topics [ 23 ] . Our models do not discriminate the two types of topics , but have a simpler and more intuitive generative process to discover evaluative aspects in reviews .
Research on domain adaptation of sentiment words can be categorized into domain to domain adaptation and generalto domain adaptation . The domain to domain adaptation aims to obtain sentiment words in one domain by utilizing a set of known sentiment words in another domain [ 2 , 5 , 18 ] . The general to domain adaptation takes a set of known general sentiment words and learns domain specific sentiment words [ 7 , 13 ] . For sentiment seed words , existing sentiment word lexicons ( eg , SentiWordNet ) can be used or a new set of words may be obtained by using sentiment propagation techniques [ 14 , 17 , 20 ] . ASUM starts from a small set of general sentiment words and finds sentiment words related to specific aspects .
Several unified models of topic and sentiment have been proposed [ 15 , 16 , 22 ] . They extend basic topic models that do not consider sentiment [ 4 , 11 ] to explain the generative process of opinionated documents such as reviews and blogs . All these topic models posit that a document is a mixture over an underlying set of topics , and , in turn , a topic is represented as a multinomial distribution over words .
Topic Sentiment Mixture ( TSM ) model [ 16 ] represents sentiment as a language model separate from topics , and each word comes from either topics or sentiment . This separation cannot explain the intimate interplay between a topic and a sentiment . For ASUM , in contrast , a pair of topic and sentiment is represented as a single language model , where a word is more probable as it is closely related to both the topic and the sentiment . This provides a sound explanation of how much a word is related to certain topic and sentiment . Multi Aspect Sentiment ( MAS ) model [ 22 ] differs from the other models in that it focuses on modeling topics to match a set of predefined aspects that are explicitly rated by users in reviews . Sentiment is modeled as a probability distribution over different sentiments for each of the aspects , and this distribution is derived from a weighted combination of discovered topics and words . To fit the discovered topics and sentiment to the predefined aspects and their ratings , MAS requires training data that are rated by users for each aspect . ASUM does not use any user rated training data , which are often expensive to obtain . Joint Sentiment/Topic ( JST ) model [ 15 ] takes the most similar approach to ours . Sentiment is integrated with a topic in a single language model . JST does not limit individual words JST is different from ASUM in that individual words may come from different language models . In contrast , ASUM constrains the words in a single sentence to come from the same language model , so that each of the inferred language models is more focused on the regional co occurrences of the words in a document . Both JST and ASUM make use of a small seed set of sentiment words , but the exploitation is not explicitly modeled in JST . ASUM integrates the seed words into the generative process , and this provides ASUM with a more stable statistical foundation .
It is difficult to compare the aspects and sentiments found by the different models . We carried out sentiment classification for a quantitative comparison , although it is not the main goal of the models . The results , presented in Section 6.4 , show that ASUM outperforms TSM and JST .
4 . MODELS
We propose two generative models that extend LDA , one of the most widely used probabilistic topic models [ 4 ] . Our goal is to discover topics that match the aspects discussed in reviews . 4.1 Sentence LDA
In LDA , the positions of individual words are neglected for topic inference . As discussed in previous work [ 25 ] , this property may not always be appropriate . In reviews , words about an aspect tend to co occur within close proximity to one another . SLDA imposes a constraint that all words in a sentence are generated from one topic . This is not always true , but the constraint holds up well in practice . The graphical representation of SLDA is shown in Figure 2(a ) and the notations are explained in Table 1 .
In SLDA , the generative process is as follows : 1 . For every aspect z , draw a word distribution φz ∼
Dirichlet(β )
2 . For each review d ,
( a ) Draw the review ’s aspect distribution θd ∼ Dirichlet(α ) ( b ) For each sentence ,
( a ) SLDA
( b ) ASUM
Figure 2 : Graphical representation of SLDA and ASUM . Nodes are random variables , edges are dependencies , and plates are replications . Only shaded nodes are observable . i . Choose an aspect z ∼ Multinomial(θd ) ii . Generate words w ∼ Multinomial(φz )
We use Gibbs sampling [ 10 ] to estimate the latent variables θ and φ . At each transition step of the Markov chain , the aspect of the ith sentence , zi , is drawn from the conditional probability P ( zi = k|z−i , w ) ∝ dk + αk
T
C DT k=1 C DT dk + αk w=1 C T W kw + βw ) w=1 ( C T W kw + βw ) + mi ) w=1
Γ(C T W kw + βw + miw ) Γ(C T W kw + βw )
.
Γ(W Γ(W
W
The notations are described in Table 1 , with a minor exceptional use of notation that C DT kw in this expression exclude sentence i . dk and C T W
The approximate probability of aspect k in review d is
The approximate probability of word w in aspect k is
T V
θdk = dk + αk
C DT k=1 C DT dk + αk
.
φkw =
C T W kw + βw w=1 C T W kw + βw
.
4.2 Aspect and Sentiment Unification Model ASUM is an extension of SLDA that incorporates both aspect and sentiment . ASUM models the generative process of a review as illustrated in the following scenario of writing a review . A reviewer first decides to write a review of a restaurant that expresses a distribution of sentiments , for example , 70 % satisfied and 30 % unsatisfied . And he decides the distribution of the aspects for each sentiment , say 50 % about the service , 25 % about the food quality , and 25 % about the price for the positive sentiment . Then he decides , for each sentence , a sentiment to express and an aspect for which he feels that sentiment . For example , he writes that he is satisfied with the friendly service of the restaurant . The graphical representation of ASUM is shown in Figure 2(b ) . Formally , the generative process is as follows :
1 . For every pair of sentiment s and aspect z , draw a word distribution φsz ∼ Dirichlet(βs ) wzθαDφβTNMwzθαDφβγπsTSNMS Table 1 : Meanings of the notations
Table 2 : The properties of the data sets
D M N T S V w z s φ θ π
α(k ) the number of reviews the number of sentences the number of words the number of aspects the number of sentiments the vocabulary size word aspect sentiment multinomial distribution over words multinomial distribution over aspects multinomial distribution over sentiments Dirichlet prior vector for θ
β(w ) , βj(w ) Dirichlet prior vector for φ ( for sentiment j )
γ(j ) zi si z−i s−i wi w CDT dk
CT W kw
CDS dj
CDST djk
CST W jkw mi(w )
Dirichlet prior vector for π the aspect of sentence i the sentiment of sentence i the aspect assignments for all sentences except sentence i the sentiment assignments for all sentences except sentence i the word list representation of sentence i the word list representation of the corpus the number of sentences that are assigned aspect k in review d the number of words that are assigned aspect k the number of sentences that are assigned sentiment j in review d the number of sentences that are assigned sentiment j and aspect k in review d the number of words that are assigned sentiment j and aspect k the number of total words ( or word w ) in sentence i
2 . For each document d ,
( a ) Draw the document ’s sentiment distribution πd ∼
Dirichlet(γ )
( b ) For each sentiment s , draw an aspect distribution
θds ∼ Dirichlet(α ) ( c ) For each sentence , i . Choose a sentiment j ∼ Multinomial(πd ) ii . Given sentiment j , choose an aspect k iii . Generate words w ∼ Multinomial(φjk )
∼ Multinomial(θdj )
ASUM exploits prior sentiment information by using asymmetric β . For example , we expect that the words “ good , great ” are not probable in negative expressions , and similarly the words “ bad , annoying ” are not probable in positive expressions . This can be encoded into β such that the elements of β corresponding to general positive sentiment words have small values for negative senti aspects , and general negative sentiment words for positive senti aspects . From the inference perspective , this asymmetric setting of β leads the words that co occur with the general sentiment words to
Electronics Restaurants
# of reviews
24,184
27,458
# of reviews with 4+ stars
Avg . # of words/review
Avg . # of sentences/review
72 % 76 12
68 % 153 12 be more probable in the corresponding senti aspects . Symmetric β , which was often used in previous work , does not utilize this prior knowledge . A similar unified model [ 15 ] incorporated sentiment information at the initialization step of Gibbs sampling , but the effect becomes weak as the sampling progresses .
The latent variables θ , π , and φ are inferred by Gibbs sampling as in Section 41 At each transition step of the Markov chain , the sentiment and aspect of the ith sentence are chosen according to the conditional probability S P ( si = j , zi = k|s−i , z−i , w ) ∝ C DS C DS W jkw + βjw ) dj + γj w=1 C ST W
Γ(C ST W
T dj + γj k=1
C DST djk + αk j=1
C DST djk + αk
Γ(W Γ(W jkw + βjw + miw ) Γ(C ST W jkw + βjw )
. w=1 ( C ST W jkw + βjw ) + mi ) w=1
The notations are described in Table 1 , with a minor exceptional use of notation that C DS jkw in this expression exclude the sentence i . djk , and C ST W dj , C DST
The approximate probability of sentiment j in review d is
S dj + γj
C DS j=1 C DS dj + γj
πdj =
.
( 1 )
The approximate probability of aspect k for sentiment j in review d is
θdjk = djk + αjk
C DST k=1 C DST djk + αjk
.
The approximate probability of word w in senti aspect {k , j} is
T
V
φjkw =
C ST W jkw + βjw w=1 C ST W jkw + βjw
.
5 . EXPERIMENTAL SETUP
In this section , we describe our data sets and the sentiment seed words . 5.1 Data Sets
We use two different sets of reviews1 . One data set is a collection of electronic device reviews from Amazon2 , which we name Electronics , and the other data set is restaurant reviews from Yelp3 , which we name Restaurants . For Electronics , we collected all reviews in seven categories : air conditioner , canister vacuum , coffee machine , digital SLR , laptop , MP3 player , and space heater . We randomly selected at most 5,000 reviews from each category for balance , which resulted in about 22,000 total reviews . For Restaurants ,
1Available at http://uilabkaistackr/research/WSDM11 2http://wwwamazoncom 3http://wwwyelpcom
Table 3 : Full list of sentiment seed words in PARADIGM ( bold ) and PARADIGM+ ( all ) . The first row is the positive words , and the second row is the negative words . The words’ order is meaningless . good , nice , excellent , positive , fortunate , correct , superior , amazing , attractive , awesome , best , comfortable , enjoy , fantastic , favorite , fun , glad , great , happy , impressive , love , perfect , recommend , satisfied , thank , worth bad , nasty , poor , negative , unfortunate , wrong , inferior , annoying , complain , disappointed , hate , junk , mess , not good , not like , not recommend , not worth , problem , regret , sorry , terrible , trouble , unacceptable , upset , waste , worst , worthless we collected the reviews of the 320 most rated restaurants in four cities : Atlanta , Chicago , Los Angeles , and New York City . We randomly selected 30,000 reviews out of the collected reviews .
We pre processed the data by removing Web URLs and separating sentences by “ . ” , “ ? ” , “ ! ” , and “ newline ” . We removed words that contain non English alphabets and sentences that are longer than 50 words . We used the Porter stemmer4 for stemming . The properties of the data sets are summarized in Table 2 .
Negation is an important issue in sentiment analysis , especially with the bag of words features . For example , in a sentence “ the quality is not good ” , “ not good ” expresses negative sentiment , but without considering “ not ” and “ good ” collectively , it is hard to capture the negative sentiment . Previous work has proposed several approaches to this problem , including flipping the sentiment of a word when the word is located closely behind “ not ” [ 9 ] . We use simple regular expression rules to prefix “ not ” to a word that is modified by negating words , as was done in [ 8 ] . 5.2 Sentiment Seed Words
We carefully chose affective words and general evalutive words for sentiment seed words . The seed words should not be aspect specific evaluative words because they are assumed to be unknown . We use two sets of seed words . Paradigm is the sentiment oriental paradigm words from Turney ’s work [ 24 ] , containing seven positive words and seven negative words . Paradigm+ is Turney ’s paradigm words plus other affective words and general evaluative words . The full list of the seed words is in Table 3 .
6 . EXPERIMENTS
We performed four experiments to evaluate our models , SLDA and ASUM . In the first experiment , we evaluate the aspects discovered by SLDA , and in the second experiment , we evaluate the senti aspects discovered by ASUM . In the third experiment , we evaluate the sentiment words found by ASUM , and in the last experiment , we test the sentiment classification performance of ASUM .
It is worth noting that the aspects and senti aspects computed by SLDA and ASUM are language models that are based on the word frequencies in the corpus . Hence , some words that are frequently used regardless of aspects may take top positions of the ( senti )aspects . To make characteristic words more apparent , we computed the term scores
4http://tartarus.org/~martin/PorterStemmer/ on the discovered ( senti )aspects [ 21 ] , which gives a lower score to the words common across various ( senti )aspects and higher score to the words that occur exceptionally often in one ( senti )aspect . All the aspects and senti aspects shown in this section are based on the term scores , instead of the original probabilities calculated by the models .
6.1 Aspect Discovery
The first experiment is to automatically discover aspects in reviews using SLDA . We set three criteria for measuring the quality of the aspects . First , the discovered aspects should be coherent . Second , the aspects should be specific enough to capture the details in the reviews . Third , the aspects should be those that are discussed the most in the reviews . We applied SLDA to Electronics and Restaurants data sets and evaluated the modeling power of SLDA based on these criteria . We also compared the results with LDA to see the effect of our assumption that one sentence represents one aspect . We varied the number of aspects and found that 50 aspects per sentiment captures various aspects with few redundancies , which we used for all the experiments in this section . We also tried several values of α and β but found that they do not really affect the quality of the result , and we use symmetric α and β set to be 0.1 and 0.001 , respectively . Some examples of the discovered aspects are presented in Table 4 .
From Electronics , SLDA discovered aspects that are specific to the seven product categories as well as general aspects such as design , orders , and service . SLDA discovered seven aspects about laptops–OS , MacBook , peripherals , battery life , hardware , graphics , and screen–as shown in Table 4(a ) . Each aspect represents a specific detail of the laptop . The aspects also cover most of the important parts and features of the laptop that users often point out and discuss in laptop reviews . These aspects are representative of the 50 aspects found , most of which are closely related to the product categories . These coherent , specific , and important aspects that SLDA found would be effective for potential applications such as aspect level sentiment summarization and retrieval .
We compared the results of SLDA with the aspects found by LDA , and Table 5 presents the aspects related to cameras found by SLDA and LDA . For SLDA , we selected only five aspects out of 10 for space reasons . Both SLDA and LDA discovered the aspects “ lens ” and “ iso ” . However , LDA could not find the aspects such as “ grip ” , “ beginners ” , and “ ease of learning ” . These aspects are specific details that people evaluate about a camera . Overall , the aspects found by LDA tend to be more general and less coherent . This difference stems from our assumption built into SLDA that a single sentence represents one aspect . Accordingly , the aspects discovered by SLDA tend to account for the local positions of the words , which is an appropriate property for our goal . In contrast , LDA has a broader view that an aspect can be composed of any words in a review regardless of intra sential word co occurrences .
For Restaurants , many of the SLDA aspects are related to cuisine types such as Mexican , seafood , breakfast , and dessert . The rest include parking , waiting , evaluation , and other general aspects about restaurants . Examples are presented in Table 4(b ) . The aspects “ parking ” and “ waiting ” are two detailed points that people often describe in restaurant reviews . LDA also discovers similar aspects except for window vista softwar mac instal os xp run program driver pc comput microsoft boot laptop macbook keyboard batteri pro laptop appl inch screen mac aluminum unibodi new displai keyboard trackpad mbp glossi pad button kei mous touch trackpad finger touchpad scroll click screen type laptop gestur life hour charg last recharg power charger cell long hr laptop mode run fulli laptop ram processor graphic netbook drive core game batteri hp notebook gb comput intel screen usb port hdmi drive connect dvd screen bright displai color glossi lcd wireless keyboard video card extern tv movi laptop cabl speaker reflect light angl glare view led clear inch park street valet cash lot car find free block onli valid there walk meter weekend across
Table 4 : Example aspects discovered by SLDA .
( a ) Electronics
( b ) Restaurants wait line seat crowd long beer wine drink glass select bottl get tabl reserv your earli hour if there busi martini tap mojito margarita cocktail sangria juic list vodka yum oh no mmm mmmm ye wow love yeah lol holi haha omg not yuck camera hand feel grip weight size fit solid small bodi rebel light iso card raw imag camera shoot nois photo file print pictur jpeg shot comfort batteri resolut smaller memori
Table 5 : Discovered aspects regarding cameras for SLDA and LDA .
( a ) SLDA len kit lens zoom af camera canon ef nikon vr nikkor dx flash usm bodi camera dslr slr photographi photograph rebel digit shoot canon beginn amateur recommend profession nikon point camera learn easi manual menu mode set control shoot featur intuit auto pictur user photographi
( b ) LDA nikon len lens pentax olympu qualiti imag dslr bodi af kit soni focu zoom system light iso color imag nois low high set qualiti bright nikon raw white perform balanc flash camera card batteri memori digit shot set sd pictur speed fast mode shoot second camera pictur shoot photo point shot digit learn great manual slr photographi photograph set nikon camera canon len digit rebel slr pictur lens kit nikon xt qualiti xti film bodi camera canon shoot focu shot view imag iso lcd pictur mode auto len live sensor the last two aspects in the table , “ liquors ” and “ interjections ” . In the LDA result , the top words in “ liquors ” are spread out across different aspects . For example , “ beer ” appears in an aspect related to bars , and “ wine ” appears in an aspect related to desserts . This shows that LDA captures more global aspects from reviews . When we look at the interjections , they also appear across various aspects for LDA . Without considering sentence boundaries , the interjections didn’t have enough evidence to be formed into one aspect . In SLDA , on the other hand , the co occurrences of these words within sentence boundaries cause them to form an aspect . Interjections may be hard to be considered as an “ aspect ” . Yet , they play an important role of expressing sentiment in restaurant reviews , and knowing the usages of those words in the corpus and in each of the reviews leads to a better understanding of the reviews .
6.2 Senti Aspect Discovery
Our second experiment is to discover senti aspects , aspects coupled with a sentiment ( positive or negative ) . For example , the “ screen ” aspect discovered by SLDA ( Table 4(a ) ) contains the words “ screen , bright , displai , color , light , lcd , look , like , glossi ” , whereas a {screen , negative} sentiaspect discovered by ASUM ( Table 6(a ) ) contains the words “ screen , glossi , glare , reflect ” . We can apply the same criteria to evaluate senti aspects as the criteria in Section 6.1 for aspects . Additionally , each senti aspect should clearly represent its sentiment . We applied ASUM to Electronics and Restaurants . For both data sets , the number of aspects is set to be 70 for each sentiment .
ASUM needs two hyperparameters , γ and β , to be tuned carefully . γ is a prior for the sentiment distribution in a review . Because we assume no prior knowledge of the sentiment distribution , we simply use a symmetric γ of 1 , which means all possible sentiment distributions are equally likely . The second hyperparameter , β , is one of two key elements for integrating the sentiment seed words into ASUM , and the other key element is the initialization of Gibbs sampling . Both of these elements must be carefully chosen for the seed words to be effective . β is the prior of the word distributions of senti aspects , and we use asymmetric β for ASUM . For positive senti aspects , we set the elements of β to be 0 for the negative seed words and 0.001 for all the other words . Similarly , for negative senti aspects , we set the elements of β to be 0 for the positive seed words and 0.001 for all the other words . This indicates that we initially predict that no negative seed word appears in positive senti aspects , and vice versa . With these asymmetric priors , if we use a random initialization of Gibbs sampling , as it is usually done , the asymmetric priors would just be ignored . Therefore , in the initialization step , we assign the sentiment seed words their seed sentiment . We chose this setting because it is effective and simple , but the limitation is that the sentiment seed words can only be assigned to the senti aspects of the same
Table 6 : Example senti aspects discovered by ASUM . The labels are manually annotated .
( a ) Electronics price(p ) worth monei penni extra well everi price dollar spend pai save cost hundr buck definit price(n ) monei save notwast wast yourself notbui awai spend notworth stai time favor pleas heater headach screen(p ) screen(n ) screen color bright clear video displai crisp great resolut qualiti pictur sound sharp movi beauti screen glossi displai keyboard bright glare angl view color light lcd reflect matt edg macbook screen(n ) fingerprint glossi magnet screen show finger finish print smudg easili scratch reflect cover dust prone screen(n ) vacuum(p ) screen font point size easi light carri weight notebook lightweight ssd kei shoot smaller pictur sensor small sens lol photo suction small around vacuum power stair compact quiet move handl
( b ) Restaurants meat(p ) meat(n ) music(p ) music(n ) interjection(p ) interjection(n ) payment(n ) flavor tender crispi sauc meat juici soft dry bland too salti tast flavor meat perfectli chicken veri moist sweet perfect cook crust fresh bit littl pork sauc lack chewi disappoint music night group crowd loud bar atmospher peopl dinner fun good great date go plai loud tabl convers hear music nois talk sit close other each room can space peopl mouth mmm wow melt omg good holi nom water yummi yum oh mmmmm delici serious yuck sigh digress meh wtf boo yai mmmmmm dunno bummer wow notcool bleh haha hoorai cash onli card credit downsid park take accept bring wait dun neg complaint lack make sentiment . We can loosen the limitation by using different values for β and different initialization , and we leave this for future work . For the experiments in this section , we used Paradigm+ as the sentiment seed words . Examples of the senti aspects that ASUM discovered are in Table 6 .
The senti aspects found by ASUM from the Electronics data set illustrates how the consideration of sentiment affects the discovered aspects . While SLDA tends to find aspects according to the product categories ( laptop , mp3 player , DSLR camera ) , ASUM finds some aspects that span various product categories while invoking similar sentiments . An example is the “ screen ” aspect , shown in Table 4(a ) compared to the “ screen(p ) ” and “ screen(n ) ” senti aspects in Table 6(a ) . In the SLDA results , there is one aspect devoted to a general screen , and there are a few aspects about the screen of specific products , such as the “ macbook ” aspect and an “ mp3 player ” aspect ( not shown ) that are about product features including the screen . In the ASUM results , there is a “ screen(p ) ” senti aspect that represents the general positive sentiment about screens , and then there are three “ screen(n ) ” senti aspects , each about a different reason that might invoke a negative sentiment toward screens for various product categories . We can infer from these sentiaspects that users expressed negative sentiments because of the “ glare of the glossy screen ” , “ fingerprints easily left on the screen ” , and “ small size of the screen ” . The joint modeling of the sentiment and the aspect in ASUM gives rise to this different behavior , which would enable understanding of users’ sentiments at the level of common features across various product categories . The first two senti aspects in the table show how ASUM aligns relevant sentiment words with the sentiment seed words for an aspect . For example , in “ price(p ) ” , the seed word “ worth ” is aligned with other sentiment words such as “ extra , well , save ” . In “ price(n ) ” , the seed word “ not worth ” is aligned with the words “ not waste , not buy ” , which are used in reviews as “ Do not waste your money on this . ” The word “ save ” is probable in both positive sentiment and negative sentiment . It is because one word can indicate different sentiments depending on the syntax . A word may invoke different sentiments depending on the context or aspect as well . The “ vacuum(p ) ” senti aspect in the table is about portability . In this senti aspect , the word “ small ” is used positively , whereas “ small ” is used negatively in “ screen(n ) ” . This shows the power of our probabilistic approach that a word is not limited to one sentiment .
Results from running ASUM on Restaurants show that ASUM can discover senti aspects for which only one sentiment is present in the corpus . The example of “ payment ” , shown in Table 6(b ) , only exists for the negative sentiment , represented by the words “ cash , only , card , accept ” describing the negative sentiment of the users with the cash only policy of a restaurant . The Restaurants results also confirm that there are some aspects that surface with the interplay between sentiment and aspects , as we can see from the “ meat ” aspect . For example , to express positive sentiment on “ meat ” , people use words like “ tender ” , “ crispy ” , “ juicy ” , and
Table 7 : Automatically detected sentiment words . The senti aspects discovered by ASUM were utilized to illustrate different sentiment words for the same aspect .
Table 8 : Sentiment classification by the generative models and the supervised classifiers . The number of aspects is 70 for each sentiment .
Electronics Restaurants
Common Words screen color bright displai crisp qualiti sharp music song player video download itun zune file our us server waiter tabl she he waitress ask minut seat
Sentiment Words clear great pictur sound movi beauti good hd imag size watch rai nice crystal glossi glare light reflect matt edg macbook kei black bit peopl notlik minor radio listen fm movi record easi convert podcast album audio book librari watch problem updat driver vista system xp firmwar disk mac hard run microsoft appl water glass friendli brought sat veri arriv plate help staff nice said me want card get tell if would gui bad could rude pai becaus walk then refil wine attent
“ crust ” . To express negative sentiment , they use words such as “ dry ” , “ bland ” , and “ disappointed ” . These two aspects were discovered in ASUM but not in SLDA , and the reason is that people express their sentiment toward these aspects very clearly . In SLDA the words that convey a sentiment toward the quality of meat appear in various cuisine type aspects such as steak , burger , and pizza . Because people often evaluate specifically on the quality of meat , however , these words become apparent in ASUM . 6.3 Aspect Specific Sentiment Words
The joint modeling of aspect and sentiment means ASUM finds , as top probability words in each of the senti aspects , both aspect words , and sentiment words that are dependent on the aspect . Since we start with a set of general sentiment words , this yields the effect of bootstrapping the general sentiment words to discover aspect specific sentiment words . This is one advantage of ASUM over TSM [ 16 ] , in which all topics share one sentiment word distribution .
We introduce a simple method for employing the result of ASUM to automatically distinguish between positive and negative sentiment words for the same aspect . This increases the utility of ASUM by providing an organized result that shows why people express sentiment toward an aspect and what words they use . The process is as follows :
1 . Calculate the cosine similarity between every pair of senti aspects with different sentiments .
2 . If the similarity exceeds a certain threshold , two senti aspects are considered to represent the same aspect .
3 . If a word takes a high probability in both senti aspects , then this word is a common word .
4 . If a word takes a high probability in only one sentiaspect , then this word is a sentiment word whose sentiment follows the senti aspect .
We applied this method to our data sets and present the results in Table 7 . For a music player , people praised the converting process , but they did not like driver and firmware updates . In the restaurant reviews , people praised waiters and waitresses for being attentive and friendly , but they complained when the servers were rude . The overall results show that ASUM discovers aspect specific sentiment words ,
Baseline
LingPipe Uni LingPipe Bi
ASUM ASUM+
JST+ TSM+
0.81 0.71 0.79 0.78 0.84 0.65 0.48
0.85 0.81 0.87 0.79 0.86 0.60 0.52 which can be used in applications such as review summarization .
6.4 Sentiment Classification
In this section , we present the results of sentiment classification to quantitatively evaluate the quality of senti aspects discovered by ASUM . To determine the sentiment of a review , we use π ( Equation 1 ) , the probabilistic sentiment distribution in a review , such that a review is set to be positive if positive sentiment has the equal or a higher probability than negative sentiment , and set to be negative otherwise . Both Electronics and Restaurants use the 5 star rating system , and the ratings of 1 or 2 stars are treated as negative and 4 or 5 stars positive . We do not classify on the reviews with 3 stars , but they are still used to fit ASUM to the data . The hyperparameters of ASUM are set to be the same as in the experiments in Section 62
We compare the performance of ASUM with JST [ 15 ] , TSM [ 16 ] , LingPipe [ 1 ] ( Unigrams & Bigrams ) , and the baseline . LingPipe first separates subjective sentences from objective sentences , and then finds sentiment using word features . The baseline classifies each review according to the numbers of sentences that contain the positive and negative sentiment seed words .
The classification results are presented in Figure 3 in terms of accuracy . The baseline and LingPipe are not shown in the figure because of space , but they are shown numerically in Table 8 . In all settings , ASUM outperforms the other unsupervised models and even supervised LingPipe in the same condition of unigrams . The baseline with only the seed words performs quite well , but ASUM performs even better . In general , the accuracy increases as the number of aspects increases because the models better fit the data . JST had great performance on movie reviews in the original paper [ 15 ] , but did not perform well on our data . TSM is not intended for sentiment classification , and sentiment words are not adapted to aspects . In the original paper [ 16 ] , TSM was used to analyze topic life cycles and sentiment dynamics .
The visualization of the assignment of senti aspects to each sentence would help to understand and analyze the reviews . The posterior probability of the senti aspects for each sentence was used to visualize reviews . Two examples are shown in Figure 4 . The visualization shows that the sentiments were found to be quite accurate . It is worth noting that sentences that are too short are difficult to assign correct senti aspects because they may lack strong evidence for sentiment and aspects .
Figure 3 : Sentiment classification by the three unified models . “ ASUM ” uses PARADIGM , and “ ASUM+ ” , “ JST+ ” , and “ TSM+ ” use PARADIGM+ . The error bars represent the standard deviation from 10 samples . capable of capturing aspects that are closely coupled with a sentiment . We showed that the senti aspects found by ASUM can be used to illustrate different sentiments toward the same aspect , which would be utilized in applications such as review summarization . In the quantitative evaluation of sentiment classification , ASUM outperformed other generative models and came close to supervised classification methods .
There are several possibilities to improve our models . Since our models assume that one sentence contains exactly one aspect , we may split sentences not only by punctuations but also by conjunctions . In addition , we may use a partof speech tagger for more accurate negation detection [ 6 ] . To make each ( senti )aspect clearer , we can filter out words that are common across many ( senti )aspects by adding a background language model .
For future work , our models may be utilized for aspectbased review summarization . We can apply the models to other types of data such as editorials and art critiques , or use different seed words to capture different dimensions than sentiment . 8 . ACKNOWLEDGMENTS
The authors would like to thank Joonhee Kim and Dongwoo Kim for helpful discussions . This research was supported by Basic Science Research Program through the National Research Foundation of Korea ( NRF ) funded by the Ministry of Education , Science and Technology ( 2010 0025706 ) 9 . REFERENCES [ 1 ] Alias i . Lingpipe 401 http://alias i.com/lingpipe ,
2008 .
[ 2 ] A . Aue and M . Gamon . Customizing sentiment classifiers to new domains : A case study . In Proceedings of Recent Advances in Natural Language Processing ( RANLP ) , 2005 .
( a ) Electronics
( b ) Restaurants
Figure 4 : Visualization of reviews . The first column is the senti aspects of the sentences . ( + : positive , – : nagetive )
7 . CONCLUSION
In this paper , we proposed two generative models to discover aspects and sentiment in reviews . SLDA constrains that all words in a single sentence be drawn from one aspect . ASUM unifies aspects and sentiment and discovers pairs of {aspect , sentiment} , which we call senti aspects . The aspects and senti aspects discovered from reviews of electronic devices and restaurants show that SLDA and ASUM capture important evaluative details of the reviews . ASUM is also
03040506070809ELECTRONICSNumber of AspectsAccuracy305070100ASUM+ASUMJST+TSM+03040506070809RESTAURANTSNumber of AspectsAccuracy305070100ASUM+ASUMJST+TSM+{ , 61}When my old maker broke , I tried several ( at family and friends houses , bought and returned one ) , then decided on the steel Cuisinart.{ , 61}The coffee just wasn't as good as my old Krups.{+ , 56}Bought the FME2 ( just like the 4 ) and it has made amazing coffee for almost three years.{+ , 58}Better than starbucks by a mile , as good as Peets.{+ , 66}This one is a winner.{ , 39}The earlier negative reviews seem based on nothing but incompetence , if you actually read them.{+ , 52}The restaurant is really pretty inside and everyone who works there looks like they like it.{+ , 32}The food is really great.{+ , 17}I would recommend any of their seafood dishes.{+ , 33}Come during happy hour for some great deals.{ , 55}The reason they aren't getting five stars is because of their parking situation.{ , 57}They technically don't "make" you use the valet but there's only a half dozen spots available to the immediate left . [ 3 ] S . Blair Goldensohn , K . Hannan , R . McDonald ,
T . Neylon , G . A . Reis , and J . Reynar . Building a sentiment summarizer for local service reviews . In WWW Workshop on NLP in the Information Explosion Era ( NLPIX ) , New York , NY , USA , 2008 . ACM .
[ 4 ] D . M . Blei , A . Y . Ng , M . I . Jordan , and J . Lafferty .
Latent dirichlet allocation . Journal of Machine Learning Research , 3:993–1022 , 2003 .
[ 5 ] J . Blitzer , M . Dredze , and F . Pereira . Biographies , bollywood , boom boxes and blenders : Domain adaptation for sentiment classification . In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics , pages 440–447 , Prague , Czech Republic , June 2007 . Association for Computational Linguistics .
[ 6 ] S . Brody and N . Elhadad . An unsupervised aspect sentiment model for online reviews . In Proceedings of the 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics , pages 804–812 , Los Angeles , California , June 2010 . Association for Computational Linguistics .
[ 7 ] Y . Choi , Y . Kim , and S H Myaeng . Domain specific sentiment analysis using contextual feature generation . In Proceeding of the 1st international CIKM workshop on Topic sentiment analysis for mass opinion , pages 37–44 , New York , NY , USA , 2009 . ACM .
[ 8 ] S . R . Das , M . Y . Chen , and Efa . Yahoo! for amazon : Sentiment parsing from small talk on the web . Social Science Research Network Working Paper Series , August 2001 .
[ 9 ] K . Eguchi and V . Lavrenko . Sentiment retrieval using generative models . In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing , pages 345–354 , Sydney , Australia , July 2006 . Association for Computational Linguistics . [ 10 ] T . L . Griffiths and M . Steyvers . Finding scientific topics . Proceedings of the National Academy of Sciences of the United States of America , 101(Suppl 1):5228–5235 , 2004 .
[ 11 ] T . Hofmann . Probabilistic latent semantic indexing . In
Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval , pages 50–57 , New York , NY , USA , 1999 . ACM .
[ 12 ] M . Hu and B . Liu . Mining and summarizing customer reviews . In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining , pages 168–177 , New York , NY , USA , 2004 . ACM .
[ 13 ] V . Jijkoun , M . de Rijke , and W . Weerkamp .
Generating focused topic specific sentiment lexicons . In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics , pages 585–594 , Uppsala , Sweden , July 2010 . Association for Computational Linguistics .
[ 14 ] N . Kaji and M . Kitsuregawa . Building lexicon for sentiment analysis from massive collection of HTML documents . In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language
Learning ( EMNLP CoNLL ) , pages 1075–1083 , Prague , Czech Republic , June 2007 . Association for Computational Linguistics .
[ 15 ] C . Lin and Y . He . Joint sentiment/topic model for sentiment analysis . In Proceeding of the 18th ACM conference on Information and knowledge management , pages 375–384 , New York , NY , USA , 2009 . ACM .
[ 16 ] Q . Mei , X . Ling , M . Wondra , H . Su , and C . Zhai .
Topic sentiment mixture : modeling facets and opinions in weblogs . In Proceedings of the 16th international conference on World Wide Web , pages 171–180 , New York , NY , USA , 2007 . ACM .
[ 17 ] S . Mohammad , C . Dunne , and B . Dorr . Generating high coverage semantic orientation lexicons from overtly marked words and a thesaurus . In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing , pages 599–608 , Singapore , August 2009 . Association for Computational Linguistics .
[ 18 ] S . J . Pan , X . Ni , J T Sun , Q . Yang , and Z . Chen .
Cross domain sentiment classification via spectral feature alignment . In Proceedings of the 19th international conference on World wide web , pages 751–760 , New York , NY , USA , 2010 . ACM .
[ 19 ] A M Popescu and O . Etzioni . Extracting product features and opinions from reviews . In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing , pages 339–346 , Morristown , NJ , USA , 2005 . Association for Computational Linguistics .
[ 20 ] D . Rao and D . Ravichandran . Semi supervised polarity lexicon induction . In Proceedings of the 12th Conference of the European Chapter of the ACL ( EACL 2009 ) , pages 675–682 , Athens , Greece , March 2009 . Association for Computational Linguistics .
[ 21 ] A . Srivastava and M . Sahami , editors . Text Mining :
Classification , Clustering , and Applications , chapter 4 , page 75 . CRC Press , Boca Raton , FL , 2009 .
[ 22 ] I . Titov and R . Mcdonald . A joint model of text and aspect ratings for sentiment summarization . In Proc . ACL 08 : HLT , pages 308–316 , 2008 .
[ 23 ] I . Titov and R . McDonald . Modeling online reviews with multi grain topic models . In Proceeding of the 17th international conference on World Wide Web , pages 111–120 , New York , NY , USA , 2008 . ACM .
[ 24 ] P . D . Turney and M . L . Littman . Measuring praise and criticism : Inference of semantic orientation from association . ACM Transactions on Information Systems , 21(4):315–346 , 2003 .
[ 25 ] H . M . Wallach . Topic modeling : beyond bag of words . In Proceedings of the 23rd international conference on Machine learning , pages 977–984 , New York , NY , USA , 2006 . ACM .
[ 26 ] X . Zhao , J . Jiang , H . Yan , and X . Li . Jointly modeling aspects and opinions with a MaxEnt LDA hybrid . In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing , pages 56–65 , Cambridge , MA , October 2010 . Association for Computational Linguistics .
