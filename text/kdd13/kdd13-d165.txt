Social Influence Based Clustering of Heterogeneous
Information Networks
Yang Zhou
College of Computing
Georgia Institute of Technology
Atlanta , GA 30332 yzhou@gatech.edu
Ling Liu
College of Computing
Georgia Institute of Technology
Atlanta , GA 30332 lingliu@ccgatechedu
ABSTRACT Social networks continue to grow in size and the type of information hosted . We witness a growing interest in clustering a social network of people based on both their social relationships and their participations in activity based information networks . In this paper , we present a social influence based clustering framework for analyzing heterogeneous information networks with three unique features . First , we introduce a novel social influence based vertex similarity metric in terms of both self influence similarity and co influence similarity . We compute self influence and coinfluence based similarity based on social graph and its associated activity graphs and influence graphs respectively . Second , we compute the combined social influence based similarity between each pair of vertices by unifying the self similarity and multiple co influence similarity scores through a weight function with an iterative update method . Third , we design an iterative learning algorithm , SI Cluster , to dynamically refine the K clusters by continuously quantifying and adjusting the weights on self influence similarity and on multiple co influence similarity scores towards the clustering convergence . To make SI Cluster converge fast , we transformed a sophisticated nonlinear fractional programming problem of multiple weights into a straightforward nonlinear parametric programming problem of single variable . Our experiment results show that SI Cluster not only achieves a better balance between self influence and co influence similarities but also scales extremely well for large graph clustering . Categories and Subject Descriptors H28 [ Database Applications ] : Data Mining General Terms Algorithms , Experimentation , Performance Keywords Graph Clustering , Heterogeneous Network , Social Influence 1 .
INTRODUCTION
Social influence studies the impact of a group of people on an individual member of the group by their opinions or actions . Social influence analysis has great potential for understanding the ways in which information , ideas , experiences and innovations are spread across social networks . As more and more people are engaged in social networks , we witness many forms of heterogeneous social networks in which entities are of different types and are interconnected through heterogeneous types of links , representing different kinds of semantic relations . Analyzing and mining heterogeneous social networks can provide new insights about how people interact with and influence each other and why ideas and opinions on different subjects propagate differently on social networks .
Clustering a heterogeneous social network with multiple types of links , entities , static attributes and dynamic and inter connected activities demands for new clustering models and distance functions to address the following new challenges . • The large scale heterogeneous social network analysis often displays features of social complexity and involves substantial nontrivial computational cost . For example , a full version of the DBLP bibliography data contains 964 , 166 authors , 6 , 992 conferences , 363 , 352 keywords and 31 , 962 , 786 heterogeneous links . • Each type of entities usually associates to one primary social world but participates in many other social worlds , each with domain specific semantics . How to make good use of the information from various social worlds to provide more informative views of how people influence one another in a given social network ? For instance , we may want to utilize the original facebook people network as well as the associated activity networks in the facebook dataset to generate a better clustering of people based on their social influence in terms of both their circle of friends ( ie , self influence ) and their participations in multiple domain specific activity networks ( ie , multiple types of co influence ) . • The information flow between two social worlds may be bidirectional so that we should be careful in differentiating them when we integrate the results from different information networks . For example , Bob may influence his circle of friends ( direct or indirect ) by his blogs on certain subject and his participation in some tennis tournaments . On the other hand , direct links from a blog ( or a tournament ) to other blogs ( or tournaments ) can serve as a recommendation by Bob to its circle of friends . • As multiple social networks may be from arbitrary domains , it is challenging to efficiently integrate the multiple types of influences from multiple information networks into a unified distance space simultaneously . Moreover , social network clustering can be more meaningful if it is context aware and only the activity networks that are relevant to the context of interest will be utilized to perform the social influence based clustering analysis . With these new challenges in mind , in this paper we develop an innovative social influence based graph clustering approach for heterogeneous information networks , SI Cluster . It captures not only the complex attributes of people ( vertices ) in the social collaboration network but also the nested and complex relationships between people and other types of entities in different information networks in terms of their participations in different activities of interest .
Kun Lung Wu ( 106 )
Jiawei Han ( 472 )
Kun Lung Wu ( 106 )
Jiawei Han ( 472 )
Kun Lung Wu ( 106 )
Kun Lung Wu ( 106 )
Jiawei Han ( 472 )
SIGMOD
0.00947 ICDE
0.00937
VLDB
0.00977
Philip S . Yu ( 622 )
0.00897
ICDM
0.00967 KDD
0.00905
Philip S . Yu ( 622 )
Haixun Wang ( 123 )
Charu C . Aggarwal ( 139 )
Haixun Wang ( 123 )
Charu C . Aggarwal ( 139 )
SDM
SIGMOD
0.00947 ICDE
0.00937
0.00977
0.00897
ICDM
0.00967 KDD
0.00905
VLDB
SDM
Haixun Wang ( 123 )
SIGMOD
0.00947 ICDE
0.00937
VLDB
0.00977
Philip S . Yu ( 622 )
0.00897
ICDM
0.00967 KDD
0.00905
Haixun Wang ( 123 )
Charu C . Aggarwal ( 139 )
SDM
( d ) Influence Flow
( a ) Heterogeneous Graph
( b ) Social Graph
( c ) Activity Graph
Figure 1 : A Heterogeneous Network Example from DBLP
Concretely , we categorize the social influence based graph model into three categories : ( 1 ) the topological structure of the social network or the activity networks , ( 2 ) the single valued or multi valued vertex properties that represent relatively stable and static states of vertices in the social network ( such as name , sex , age , and multiple education degrees a person may achieve ) , ( 3 ) the nested and complex relationships between the social network and the activity networks ( such as multiple activities one may have participated ) . We show that the social influence based graph clustering for heterogeneous networks demands for a dynamic graph clustering method in contrast to conventional graph clustering algorithms . SI Cluster is designed to cluster large social network with two new criteria : ( 1 ) it takes into account both the complex vertex properties and the topological structure to define the initial influence of a vertex and the weights of its influence propagation to its circle of friends ; ( 2 ) it computes pairwise vertex closeness by considering not only the social influence patterns ( influence based similarities ) based on both direct and indirect social connections existing in the relevant social and activity networks but also the potentially new interactions that have high propagation probabilities based on the existing interactions . A unique characteristics of SI Cluster is its ability of integrating the self influence and multiple types of co influences into a unified influence based similarity measure through iteratively clustering and dynamic weight tuning mechanism . • We integrate different types of links , entities , static attributes and dynamic activities from different networks into a unified influence based model through the intra network or inter network social influences . • We compute influence based vertex similarity in terms of heat diffusion based influence propagation on both social graph ( selfinfluence ) and each of activity graphs ( co influence ) . • A dynamic weight tuning method is provided to combine various influence based similarities through an iterative learning algorithm , SI Cluster , for social influence based graph clustering . To make the clustering process converge fast , a sophisticated nonlinear fractional programming problem with multiple weights is transformed to a straightforward parametric programming problem of a single variable . • We perform extensive evaluation on real datasets to demonstrate that SI Cluster can partition the graph into high quality clusters with cohesive structures and homogeneous social influences .
This paper makes the following original contributions .
2 . RELATED WORK
The most closely related work to this research falls into three areas : social influence analysis , heterogeneous social network analysis and graph clustering . Social influence analysis is gaining attention in recent years . [ 1 ] proposed the first provable approximation algorithm for maximizing the spread of influence in a social network . [ 2 ] proposed a cascading viral marketing algorithm . [ 3 ] proposed a heat diffusion based viral marketing model with top K most influential nodes . [ 4 ] used a user ’s implicit social graph to generate a friend cluster , given a small seed set of contacts . [ 5 ] presented a model in which information can reach a node via the links of the social network or through the influence of external sources .
Recent works on heterogeneous social network analysis [ 6–10 ] combine links and content into heterogeneous information networks to improve the quality of querying , ranking and clustering . [ 6 ] proposed a method to model a relational database containing both attributes and links . [ 7 ] proposed to learn an optimal linear combination of different relations on heterogeneous social networks in terms of their importance on a certain query . [ 9 ] groups objects into pre specified classes , while generating the ranking information for each type of object in a heterogeneous information network . [ 10 ] presented a query driven discovery system for finding semantically similar substructures in heterogeneous networks .
Graph clustering has attracted active research in the last decade . Most of existing graph clustering techniques have focused on the topological structure based on various criteria , including normalized cuts [ 11 ] , modularity [ 12 ] , structural density [ 13 ] , stochastic flows [ 14 ] or clique [ 15 ] . K SNAP [ 16 ] and CANAL [ 17 ] presented OLAP style aggregation approaches to summarize large graphs by grouping nodes based on the user selected attributes . [ 18 ] exploited an information theoretic model for clustering by growing a random seed in a manner that minimizes graph entropy . [ 19 ] presented a clustering method which integrates numerical vectors with modularity into a spectral relaxation problem . SA Cluster [ 20 ] and BAGC [ 21 ] perform clustering based on both structural and attribute similarities by incorporating attributes as augmented edges to its vertices , transforming attribute similarity to vertex closeness . PathSelClus [ 22 ] utilizes limited guidance from users in the form of seeds in some of the clusters and automatically learn the best weights for each meta path in the clustering process . GenClus [ 23 ] proposed a model based method for clustering heterogeneous networks with different link types and different attribute types .
To our knowledge , this work is the first one to address the problem of social influence based clustering over heterogeneous networks by dynamically combining self influence from social graph and multiple types of co influence from activity graphs . 3 . PROBLEM STATEMENT
We consider three types of information networks in defining a social influence based graph clustering method : ( 1 ) the social collaboration network , which is the target of graph clustering and typically a social network of people , such as friend network , co author network , to name a few ; ( 2 ) the associated activity networks , such as product purchasing activity network , sport activity network or conference activity network ; ( 3 ) the influence networks representing bipartite graphs connecting social network and activity networks . We formally define the three types of networks as follows .
A social graph is denoted as S G = ( U , E ) , where U is the set of vertices representing the members of the collaboration network , such as customers or authors , and E is the set of edges denoting the collaborative relationships between members of the collaboration network . We use NS G to represent the size of U , ie , NS G = |U| . An activity graph is defined by AGi = ( Vi , S i ) , where v ∈ Vi denotes an activity vertex in the ith associated activity network AGi , and s ∈ S i is a weighted edge representing the similarity between two activity vertices , such as functional or manufacture similarity . We denote the size of each activity vertex set as NAGi
= |Vi| .
Philip S . Yu
Jiawei Han
KDD
SIGMOD
Raghu
Ramakrishan David DeWitt
Philip S . Yu
Jiawei Han mining database
Raghu
Ramakrishan David DeWitt
ICDM
VLDB frequent
DBMS
ICDE
NIPS
M . Tamer
Özsu
Christos Faloutsos pattern
IR
Peter L . Bartlett
W . Bruce
Croft
M . Tamer
Özsu query bayesian
Peter L . Bartlett
Christos Faloutsos
SDM
SIGIR
W . Bruce
Croft
Keith van Rijsbergen
CIKM
AAAI term learning
ECIR
IJCAI
John Lafferty
Keith van Rijsbergen retrieval markov
Andrei Broder
Michael Jordan
Andrei Broder
John Lafferty
Michael Jordan
( a ) Conference Influence Graph
( b ) Keyword Influence Graph
Figure 2 : An Illustrating Example of Influence Graphs
An influence graph is denoted as IGi = ( U , Vi , S i , Ti ) , where U , Vi and S i have the same definitions in the social graph S G and the activity graph AGi respectively . Every edge t ∈ Ti , denoted by ( u , v ) , connecting a member vertex u ∈ U to an activity vertex v ∈ Vi , representing an influence flow between S G and AGi , such as a purchasing or publishing activity . Thus , IGi is a bipartite graph . Given a social graph S G , multiple activity graphs AGi and various influence graphs IGi ( 1 ≤ i ≤ N ) , the problem of Social Influence based graph Clustering ( SI Cluster ) is to partition the K member vertices U into K disjoint clusters Ui , where U = i=1 Ui U j = φ for ∀1 ≤ i , j ≤ K , i . j , to ensure the clustering and Ui results in densely connected groups and each has vertices with similar activity behaviors . A desired clustering result should achieve a good balance between the following two properties : ( 1 ) vertices within one cluster should have similar collaborative patterns among themselves and similar interaction patterns with activity networks ; ( 2 ) vertices in different clusters should have dissimilar collaborative patterns and dissimilar interaction patterns with activities . fi
.
Figure 1 ( a ) provides an illustrating example of a heterogeneous information network extracted from the DBLP dataset . It consists of two types of entities : authors and conferences and three types of links : co authorship , author conference , conference similarity . In our SI Cluster framework , we reorganize a heterogeneous information network into a social graph , multiple activity graphs and multiple influence graphs without loss of information . The heterogeneous network in Figure 1 ( a ) is divided into three subgraphs : a social collaboration graph of authors , a conference activity graph , and an influence graph about author ’s publishing activity in conferences , as shown in Figures 1 ( b ) , ( c ) and ( d ) , respectively . A red number associated with a red dashed edge quantifies the number of publications that an author published in a conference . A green number on a green edge measures the similarity score between conferences . For ease of presentation , we removed the conference similarities with less than 0005 A number of mechanisms can be used to compute similarity of conferences . We use RankClus [ 24 ] to partition activities into clusters . According to activity ’s clustering distribution and ranking in each cluster , we calculate the similarities between activities in activity graph . Black numbers in the bracket represent the total amount of publications of an author . Other black numbers on co author edges denote the number of co authored papers . A more complex example of influence graph with 12 authors and 12 conferences ( or keywords ) is presented in Figure 2 .
4 .
INFLUENCE BASED SIMILARITY
This section describes how to measure the vertex closeness in terms of self influence and co influence models . We first utilize heat diffusion model to capture self influence based similarity between member vertices in the social graph . Then we use heat diffusion model to construct one co influence model for each influence graph using a probabilistic classification method to compute co influence similarities of two vertices in the social graph . Finally , we compute pairwise vertex similarities based on the influence similarity matrix and generate an influence based pairwise similarity matrix on the social graph for each of its N influence graphs .
4.1 Heat Diffusion on Social Graph
Heat diffusion is a physical phenomenon that heat always flows from an object with high temperature to an object with low temperature . In a large social graph S G , experts with many publications often influence other late authors . Consumers purchasing many products may influence other consumers with little purchasing . Thus the spread of influence resembles the heat diffusion phenomenon . Early adopters of a product with many friends or experts on a subject with many coauthors may act as heat sources , transfer their heat to others and diffuse their influence to other majority .
To effectively measure vertex closeness in the social graph in terms of heat diffusion model , we first define the non propagating heat diffusion kernel on social graph .
' j:(ui,u j)∈E pi j( f j(t ) − fi(t) ) , pi j =
Definition 1 . [ Non propagating Heat Diffusion Kernel on Social Graph ] Let S G = ( U , E ) denote a social graph where U is the set of member vertices and E is the edge set denoting the collaborative relationships between members . Let α be the thermal conductivity ( the heat diffusion coefficient ) of S G . The heat change at vertex ui ∈ U between time t + Δt and time t is defined by the sum of the heat that it receives from all its neighbors , deducted by what it diffuses . , ( ui , u j ) ∈ E0 , fi(t + Δt ) − fi(t ) otherwise . ( 1 ) where fi(t ) is the vertex ui ’s temperature at time t . pi j denotes the probability of heat diffusion from ui to u j . ni j denotes the weight on edge ( ui , u j ) , eg , the number of co authored publications , and ni ( or n j ) denotes the amount of heat/influence that ui ( or u j ) has within the social graph , eg , the number of authored publications.We express the above heat diffusion formulation in a matrix form . ( 2 ) where H is a NS G × NS G matrix , called a non propagating heat diffusion kernel on S G , as the heat diffusion process is defined in terms of one hop neighbors of heat source . f(t + Δt ) − f(t ) ni j√ nin j 0 ,
= αHf(t )
⎧⎪⎪⎪⎪⎨⎪⎪⎪⎪⎩
= α
Δt
Δt
⎧⎪⎪⎪⎪⎨⎪⎪⎪⎪⎩ pi j , −τi , 0 ,
( ui , u j ) ∈ E , i . j , i = j , otherwise .
Hi j = where τi = from ui to all its neighbors .
) ( ui,u j)∈E , j.i pi j . τi denotes the amount of heat diffused If we use H to define self influence similarity between vertices , then the similarity is based on one hop or direct influence . For those authors who have no joint publications , they are considered to have zero influence on one another , which is unrealistic .
( 3 )
This motivates us to utilize both direct and indirect influence paths between two vertices in computing their vertex similarity . Thus , we define the self influence similarity using the propagating heat diffusion kernel , where the heat diffusion process continues until vertices’ temperatures converge or the system defined convergence condition is met . Concretely , by Eq ( 2 ) , we have the following differential equation when Δt → 0 . = αHf(t )
( 4 ) Solving this differential equation , we obtain the following Eq ( 5 ) . df(t ) dt
Definition 2 . [ Propagating Heat Diffusion Kernel on Social Graph ]
Let α denote the thermal conductivity , H be the non propagating diffusion kernel of S G and f(0 ) denote an initial heat ( influence ) column vector at time 0 , which defines the initial heat distribution on S G . The vertex ’s thermal capacity at time t , denoted by f(t ) , is an exponential function with variable t for constant f(0 ) .
( 5 ) We call eαtH as the propagating heat diffusion kernel . It can be f(t ) = eαtHf(0 ) expanded as a Taylor series , where I is an identity matrix : eαtH = I + αtH +
H2 +
α2t2 2!
H3 + ···
α3t3 3!
( 6 ) where the heat diffusion reaches convergence , ie , thermal equilibrium , at time t . Since eαtH captures both direct and indirect relationships between objects , it reflects the vertex closeness on social graph . We treat it as the self similarity matrix W0 , ie , W0 = eαtH . Here , the thermal conductivity α is a user specific parameter . We use it as a weight factor for the self influence similarity in the unified similarity . Figure 3 follows the example of Figure 1 . In Figure 3 ( a ) , ochre dashed lines and associated blue numbers represent the self influence similarity by setting α and t equal to 1 . 4.2 Heat Diffusion on Influence Graphs ff
We have presented the use of propagating heat diffusion kernel to measure the self influence vertex closeness on social graph . In this section we describe how to compute pairwise co influence similarity for vertices in S G based on one of N associated influence graphs . Similarly , we first need to define the non propagating heat kernel on an influence graph . By the definition of influence graph in Section 3 , we should consider four types of one hop influence diffusion path in defining the non propagating heat kernel Hi .
A B Hi = C D ]T is a NAGi
Definition 3 . [ Non propagating Heat Diffusion Kernel on Influence Graphs ] We formulate Hi on the influence graph IGi associated to the social graph S G and the activity graph AGi by splitting it into four blocks . ( 7 ) where B = [ B1,··· , BNAGi × NS G matrix representing the social influence of vertices in AGi on members in S G , defined by Eq ( 8 ) ; C = [ C1,··· , CNSG]T is a NS G × NAGi matrix denoting the social influence of members in S G on vertices in AGi , defined × NAGi matrix representing the activity simby Eq ( 9 ) ; A is an NAGi ilarities , defined by Eq ( 10 ) ; and D is a NS G × NS G diagonal matrix . n jk)NAGi l=1 nlk 0 ,
, ( uk , v j ) ∈ Ti , where n jk is the weight on edge ( uk , v j ) and B jk computes the influence of v j on S G through uk and is defined by n jk normalized by the sum of weights on ( uk , vl ) for any vl in AGi . For example , the influence of a conference v j on the social graph through an author , say Philip S . Yu , is defined by the number of papers he published in v j normalized by the total number of papers authored by him and published in any conference of the conference graph . otherwise .
⎧⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎩
B jk =
( 8 )
C jk = n jk)NS G l=1 nlk 0 ,
, ( u j , vk ) ∈ Ti , otherwise .
( 9 )
( 10 )
⎧⎪⎪⎪⎪⎨⎪⎪⎪⎪⎩
⎧⎪⎪⎪⎪⎨⎪⎪⎪⎪⎩ where n jk denotes the weight on edge ( u j , vk ) and C jk computes the influence of u j on AGi through vk and is defined by n jk ( the amount of papers u j published in vk ) normalized by the sum of the weights on ( ul , vk ) for any ul .
A jk = n jk , −τ j , 0 ,
( v j , vk ) ∈ S i , j = k , otherwise .
)
) where n jk represents the similarity between two activity vertices v j ( ul,v j)∈Ti B jl and vk in the activity graph . τ j = where τ j summarizes the influence of activity vertex v j on other activity vertices and associated member vertices . ) In the diagonal matrix D , the diagonal entry D j j in each row is equal to −τ j where τ j = ( u j,vl)∈Ti C jl . τ j summarizes the influence of member vertex u j on all activity vertices .
( v j,vl)∈S i,l . j A jl +
Definition 4 . [ Propagating Heat Diffusion Kernel on Influence Graphs ] Let IGi denote the ith influence graph associated to S G and AGi , α denote the thermal conductivity , Hi denote the nonpropagating diffusion kernel of IGi and f(0 ) be an initial heat distribution on IGi . The vertex ’s thermal capacity at time t is defined by an exponential function f(t ) with variable t for constant f(0 ) . fi(t ) = eαtHi fi(0 )
( 11 )
( 12 ) where i represents the ith influence graph . eαtHi can be expanded as a Taylor series . eαtHi = I + αtHi +
α2t2 + NS G ) × ( NAGi 2!
+ ···
α3t3 3!
+
H2 i + NS G ) identity matrix .
H3 i where I is a ( NAGi
Figure 3 ( b ) shows the propagating heat diffusion kernel eαtHconf for the conference influence graph in our running example , where both α and t are set to 1 . For presentation clarity , we only show the bidirectional influence flow between authors and conferences with value less than 0.02 in eαtHconf . Associated blue numbers and green numbers quantify the influence flows from author to conference and the influence flows from conference to author respectively . 4.3 Co influence Model We have defined the propagating heat diffusion kernel eαtHi for the influence graph IGi ( 1 ≤ i ≤ N ) . According to Eq 11 , in order to conduct heat diffusion on an influence graph and compute pairwise co influence similarity , we need both eαtHi and fi(0 ) on IGi . fi(0 ) defines the heat sources from which the propagating heat kernel starts its diffusion process . fij(0 ) = ( pi j1 , pi j2,··· , pi jNAGi
We observe that the co influence between a pair of member vertices in the social graph can only be established through their interactions with activity vertices in one of the activity graphs . To make good use of the topological information of AGi , find good heat sources from AGi and reduce the commotional cost for largescale activity graph , we propose to start by partitioning AGi into Mi disjoint activity clusters , denoted by ci1 , ci2 , . . . , ciMi . Based on these activity clusters , the initial heat distribution column vector with the size of ( NAGi
+ NS G ) × 1 is defined as follow . , 0 , 0,··· , 0)T
( 13 ) where pi jk is the probability of activity vertex vk belonging to cluster ci j ( 1 ≤ k ≤ NAGi , 1 ≤ j ≤ Mi ) . If pi jk > 0 , then the activity vertex vk in cluster ci j is chosen as an initial heat source . Note that for each activity vertex vk , there exists one and only one ci j cluster among the Mi disjoint activity clusters , to which vertex vk belongs . Thus we have pi jk = 1 in fij(0 ) . The last NS G entries in fij(0 ) represent the initial heats of member vertices in S G with all 0s . Thus , the initial heat distribution matrix fi(0 ) is defined as [ fi(0 ) = [ fi1(0 ) , fi2(0),··· , fiMi(0) ] . We argue that two members are similar if both of them participate in many activities in the same clusters . We propose a probability based co influence classification method to classify members into the activity based clusters and generate the co influence similarity between members based on the member distribution in each class . We first use fij(0 ) ( 1 ≤ j ≤ Mi ) as the training data and the eαtHi as the classifier to execute influence propagation to generate member ’s probability in each activity based class . The heat distribution fi(t ) at time t is then given as follow . fi(t ) = [ fi1(t ) , fi2(t),··· , fiMi ( t ) ] = eαtHi [ fi1(0 ) , fi2(0),··· , fiMi ( 0 ) ] ( 14 ) Consider conference classes DM and DB in Figure 3 ( c ) , we have fconf(0 ) = [ fDM(0 ) , fDB(0 ) ] = the initial conference influence distribution matrix fconf(0 ) below . 0 0 ( 15 ) where 2 columns represent the conference classes DM and DB and 11 rows represent six conference vertices ( ICDM , KDD , SDM , SIGMOD , VLDB and ICDE ) , and five author vertices ( Philip S . Yu , Jiawei Han , Charu C . Aggarwal , Kun Lung Wu and Haixun Wang ) . By Eq ( 14 ) with α and time t set to 1 , we can generate the final heat distribution vectors fconf(t ) for them , which serve as their influencebased probabilities of belonging to each of DM and DB .
We can further reduce the influence propagation matrix fi(t ) with the size of ( NAGi i(t ) by removing the activity rows without loss of quality . Figure 3 ( d ) shows the
+ NS G)× Mi to a NS G× Mi matrix f
1 0
1 0
1 0
0 1
0 1
0 1
0 0 fi
0 0
0 0
0 0 flT
Kun Lung Wu ( 106 )
Jiawei Han ( 472 )
Kun Lung Wu ( 106 )
Jiawei Han ( 472 )
Kun Lung Wu ( 106 )
Jiawei Han ( 472 )
Kun Lung Wu ( 106 )
Jiawei Han ( 472 )
Kun Lung Wu ( 106 )
Jiawei Han ( 472 )
Philip S . Yu ( 622 )
SIGMOD
0.00947 ICDE
0.00937
VLDB
0.00977
Philip S . Yu ( 622 )
0.00897
ICDM
SIGMOD
0.00967 KDD
0.00947 ICDE
0.00905
0.00937
0.00977
Philip S . Yu ( 622 )
0.00897
ICDM
0.00967 KDD
0.00947 DB
0.00905
0.00937
0.00977
Philip S . Yu ( 622 )
0.00897
0.00967 DM
0.00905
Philip S . Yu ( 622 )
SDM
VLDB
SDM
Haixun Wang ( 123 )
Charu C . Aggarwal ( 139 )
Haixun Wang ( 123 )
Charu C . Aggarwal ( 139 )
Haixun Wang ( 123 )
Charu C . Aggarwal ( 139 )
Haixun Wang ( 123 )
Charu C . Aggarwal ( 139 )
Haixun Wang ( 123 )
Charu C . Aggarwal ( 139 )
( a ) Self influence Similarity
( b ) Kernel on Influence Graph
( d ) Influence Propagation
( e ) Co influence Similarity
( c ) Activity Partition
Figure 3 : Co influence Model influence distribution f conf(t ) represented by blue numbers in the two different conference classes . The larger the number is , the more influence author has on the conference class .
The pairwise vertex closeness is an important measure of clustering quality . Let Wi denote the co influence vertex similarity matrix for influence graph IGi , Mi be the number of activity classes in IGi , and f im(t)( j ) denote the row wise normalized influence distribution of member u j ∈ U on IGi at time t , ie , the probability of u j in the mth class of AGi . Wi( j , k ) representing the co influence similarity between members u j and uk is defined below . im(t)( j ) − f
M im(t)(k))2 mi=1(f
M im(t)(k ) mi=1 f im(t)( j ) + f + j ) − pim(NAGi M mi=1(pim(NAGi M + j ) + pim(NAGi mi=1 pim(NAGi
Wi( j , k ) = Wi(k , j ) = 1 − ffi ) ) ffi ) )
The green numbers in Figure 3 ( e ) represents the co influence
= 1 −
+k))2
( 16 )
+k ) based similarity from the conference influence graph . 4.4 Unified Influence based Similarity Measure The problem of integrating the influence based similarities on both social graph and multiple influence graphs into a cohesive and unified similarity measure is quite challenging . In this paper , we propose to use a unified influence based similarity measure together with an iterative learning algorithm to address this problem .
Let W0 denote the self influence similarity from the social graph S G with the weight factor α , Wi denote the co influence similarity from the influence graph IGi ( 1 ≤ i ≤ N ) with the weight ωi . The unified similarity function W is defined as follow . W = W0 + ω1W1 + ··· + ωNWN ( 17 ) ωi = N + 1 , α . 0 , ωi . 0 , i = 1,··· , N . where W0 = eαtH , α + The unified similarity between any pair of member vertices in S G is defined based on the set of N +1 influence based similarities . d(ui , u j ) = W(i , j ) = eαtH(i , j ) + ω1W1(i , j ) + ··· + ωNWN(i , j )
)
N i=1
∞' k=0
=
αktk k!
Hk(i , j ) +
N' k=1
ωkWk(i , j )
( 18 )
5 . CLUSTERING ALGORITHM
This section presents our clustering framework , SI Cluster , that partitions a social graph S G based on both self influence and coinfluence similarities through a unified similarity model among S G , the activity graphs AGi , and the influence graphs IGi . SI Cluster follows the K Medoids clustering method [ 25 ] by using the unified influence based similarity with the initial weights as an input . At each iteration , we select the most centrally located point in a cluster as a centroid , and assign the rest of points to their closest centroids . The weight update method computes the weighted contributions of each influence based similarity to both clustering convergence and clustering objective , and updates N + 1 weights accordingly after each iteration . This process is repeated until convergence . 5.1 Initialization
We will address two main issues in the initialization step : ( 1 ) initial weight setup and ( 2 ) cluster centroid initialization .
Choosing a weight assignment randomly often results in incorrect clustering results . In fact , we will prove that there exists one and only one optimal weight assignment to maximize the clustering objective . According to Definition 7 and Theorems 4 7 in Section 5.4 , we choose parameter β = 0 and weights α = ω1 = . . . = ωN = 1 as an initial input . Thus , the dynamic weight update scheme continuously increases weights to important influencebased similarities and decreases weights or assign zero weights to trivial influence based similarities at each iteration .
Good initial centroids are essential for the success of partitioning clustering algorithms . A member vertex which has a local maximum of the number of neighbors often can diffuse its heat to many vertices along multiple paths . A centroid based cluster is thus formed when heat is diffused to the margin of the social graph . Thus , we select such K members as the initial centroids {c0 } . , , c0 K 5.2 Vertex Assignment and Centroid Update With K centroids in the tth iteration , we assign each vertex ui ∈ U to its closest centroid c∗ = argmaxct j ) , ie , a centroid c∗ ∈ {ct } with the largest unified similarity from ui . When all vertices are assigned to some cluster , the centroid will be updated with the most centrally located vertex in each cluster . To find such a vertex , we first compute the “ average point" ui of a cluster Ui in terms of the unified similarity matrix as
, , ct K d(ui , ct
1
1 j d(ui , u j ) = 1|Ui| d(uk , u j),∀u j ∈ Ui
( 19 )
' uk∈Ui
Thus , d(ui , : ) is the average unified similarity vector for cluster
Ui . Then we find the new centroid ct+1 in cluster Ui as i d(u j , : ) − d(ui , : ) i ct+1 i
= argminu j∈Ui
Therefore , we find the new centroid ct+1
( 20 ) in the ( t + 1)th iteration whose unified similarity vector is the closest to the cluster average . 5.3 Clustering Objective Function
The objective of clustering is to maximize intra cluster similarity and minimize inter cluster similarity . We first define the intercluster similarity .
Definition 5 . [ Inter cluster Similarity ] Let S G = ( U , E ) be the social graph , W(i , j ) denote the unified influence based similarity between ui and u j , and Up and Uq be two clusters of U . The intercluster similarity between Up and Uq is defined as follow . W(i , j ) d(Up , Uq ) = d(ui , u j ) =
'
'
( 21 ) ui∈Up,u j∈Uq ui∈Up,u j∈Uq
This inter cluster similarity measure is designed to quantitatively measure the extent of similarity between two clusters of U .
. i=1 such that U =
Definition 6 . [ Graph Clustering Objective Function ] Let S G = ( U , E ) denote a social graph with the weight α and IG1 , IG2 , . . . , IGN denote N influence graphs with the weights ω1 , . . . , ωN where ωi is the weight for IGi , and K be a number of clusters . The goal of SIfi Cluster is to find K partitions {Ui}K K i=1 Ui and U j = φ for ∀1 ≤ i , j ≤ K , i . j , and the following objective Ui function O({Ul}K O({Ul}K )
, α , ω1 , . . . , ωN ) is maximized . ) K p=q=1 d(Up , Uq ) )
) )∞ ) ui∈Up,u j∈Uq ( k=0 ui∈Up,u j∈Uq ( ωi = N + 1 , α . 0 , ωi . 0 , i = 1,··· , N .
K q=1,q.p d(Up , Uq ) αktk ) )∞ k! Hk(i , j ) + ωkWk(i , j ) ) N k=1
, α , ω1 , . . . , ωN ) =
αktk k! Hk(i , j ) +
) ) subject to α +
K q=1,q.p N i=1
ωkWk(i , j ) )
K p=q=1
K p=1
K p=1
( 22 )
N k=1
)
)
) k=0 l=1 l=1
=
Thus the graph clustering problem can be reduced to three subproblems : ( 1 ) cluster assignment , ( 2 ) centroid update and ( 3 ) weight adjustment , each with the goal of maximizing the objective function . The first two problems are common to all partitioning clustering algorithms . Thus we focus on the third subproblem , weight adjustment , in the next subsection . 5.4 Parameter based Optimization
The objective function of our clustering algorithm is to maximize intra cluster similarity and minimize inter cluster similarity . Theorems 1 and 2 prove that our clustering objective is equivalent to maximize a quotient of two convex functions of multiple variables . It is very hard to perform function trend identification and estimation to determine the existence and uniqueness of solutions . Therefore , we can not directly solve this sophisticated nonlinear fractional programming problem .
)
)∞ ) ) ui∈Up,u j∈Uq( ) g(α , ω1 , . . . , ωN ) = k=0 K p=1
Definition 7 . Suppose that f ( α , ω1 , . . . , ωN ) = K p=q=1
) ) αktk k! Hk(i , j ) + K ui∈Up,u j∈Uq( q=1,q.p
N k=1
)∞
)
ωkWk(i , j ) ) and
αktk k! Hk(i , j ) + k=0
N k=1
ωkWk(i , j) ) , the original clustering goal is rewritten as the fol lowing optimization problem ( NFPP ) .
( 23 )
Max O({Ul}K l=1
)
, α , ω1 , . . . , ωN ) = f ( α , ω1 , . . . , ωN ) g(α , ω1 , . . . , ωN )
N i=1
ωi = N + 1 , α . 0 , ωi . 0 , i = 1,··· , N . subject to α + Lemma 1 . Let f be a function of a single variable on R . Then ( 1 ) f is concave iff for ∀x1 , x2 ∈ R and ∀λ ∈ ( 0 , 1 ) we have f ( (1 − λ)x1 + λx2 ) . ( 1 − λ ) f ( x1 ) + λ f ( x2 ) . ( 2 ) f is convex iff for ∀x1 , x2 ∈ R and ∀λ ∈ ( 0 , 1 ) we have f ( (1 − λ)x1 + λx2 ) fi ( 1 − λ ) f ( x1 ) + λ f ( x2 ) . Definition 8 . A set S of n vectors is convex if ( 1− λ)x + λx ∈ S whenever x , x ∈ S , and λ ∈ [ 0 , 1 ] .
)
Lemma 2 . Let f be a function of multiple variables with continuous partial derivatives of first and second order on the convex set S and denote the Hessian of f at the point x by Π(x ) . Then ( 1 ) f is concave iff Π(x ) is negative semidefinite for ∀x ∈ S . ( 2 ) if Π(x ) is negative definite for ∀x ∈ S , f is strictly concave . ( 3 ) f is convex iff Π(x ) is positive semidefinite for ∀x ∈ S . ( 4 ) if Π(x ) is positive definite for ∀x ∈ S , f is strictly convex . Lemmas 1 , 2 and the detailed proof can be found in [ 26 ] . Theorem 1 . {(α , ω1 , . . . , ωN)|α + ωi = N + 1 , α . 0 , ωi . 0 , i = 1,··· , N} . Proof . We first prove that the set S is a convex set . Suppose that two arbitrary ( n + 1) vectors x = ( μ1 , μ2 , . . . , μN+1 ) and x = ( ν1 , ν2 , . . . , νN+1 ) satisfy the following two constraints : μi = νi = N + 1 , νi . 0 , i = 1,··· , N + 1 . N + 1 , μi . 0 , For an arbitrary λ ∈ [ 0 , 1 ] , the ( n + 1) vector ( 1 − λ)x + λx = ( (1− λ)μ1 + λν1 , ( 1− λ)μ2 + λν2,··· , ( 1− λ)μN+1 + λνN+1 ) . The sum ) of each dimension for this ( n+1) vector is equal to ( 1−λ ) μi + νi = ( 1− λ)(N + 1 ) + λ(N + 1 ) = N + 1 . Thus , ( 1− λ)x + λx f ( α , ω1 , . . . , ωN ) is convex on the set S =
λ is still in S and S is a convex set .
)
)
)
N+1 i=1
N+1 i=1
N+1 i=1
N+1 i=1
N i=1
We then calculate the Hessian matrix of f as follows . Π( f )i j(α , ω1 , . . . , ωN ) = DiD j f ( α , ω1 , . . . , ωN )
( 24 ) where Di is the differentiation operator with respect to the ith argument .
The Hessian becomes Π( f ) = [ ∂2 f ∂α2 ) ∂2 f ∂2 f ∂ω2 N ) ui∈Up,u j∈Uq
∂ω1∂ωN only one non linear term is one non zero term ∂2 f in the Hessian matrix . We can easily prove that all of its eigenvalues are non negative . Thus , it is positive semidefinite for ∀α , ω1 , . . . , ωN ∈ S , and f ( α , ω1 , . . . , ωN ) is convex on the set S .
∂2 f ∂α∂ω1 )∞ ] . Since f ( α , ω1 , . . . , ωN ) has )∞ αktk k! Hk(i , j ) , there k=1 k(k−1 ) αk−2tk ui∈Up,u j∈Uq
) )
∂2 f ∂ω1∂α
; . . . ;
K p=q=1
K p=q=1
∂α2 =
∂2 f ∂ω2 1
∂ωN ∂ω1
∂ωN ∂α
∂α∂ωN
. . .
. . .
∂2 f
∂2 f
∂2 f k=0
;
. . . k! Hk(i , j )
Theorem 2 . g(α , ω1 , . . . , ωN ) is convex on S since its Hessian matrix Π(g ) is positive semidefinite for ∀α , ω1 , . . . , ωN ∈ S . The detailed proof is omitted due to space limit . This theorem can be testified by using the above mentioned similar method .
Theorem 3 . The NFPP problem is equivalent to a polynomial programming problem with polynomial constraints ( PPPPC ) .
)
( 25 ) ωi = N + 1 ,
Max γ f ( α , ω1 , . . . , ωN )
N i=1 subject to 0 fi γ fi 1/g(α , ω1 , . . . , ωN ) , α + α . 0 , ωi . 0 , i = 1,··· , N . Proof . If ( α , ω1 , . . . , ωN , γ ) is a possible solution of PPPPC , then γ = 1/g(α , ω1 , . . . , ωN ) . Thus γ f ( α , ω1 , . . . , ωN ) = f ( α , ω1 , . . . , ωN ) /g(α , ω1 , . . . , ωN ) . For any feasible solution ( α , ω1 , . . . , ωN ) of NFPP , the constraints of PPPPC are satisfied by setting γ = 1/ g(α , ω1 , . . . , ωN ) , so γ f ( α , ω1 , . . . , ωN ) fi γ f ( α , ω1 , . . . , ωN ) , ie f ( α , ω1 , . . . , ωN)/g(α , ω1 , . . . , ωN ) fi f ( α , ω1 , . . . , ωN)/g(α , ω1 , . . . , ωN ) .
Conversely , if ( α , ω1 , . . . , ωN ) solves NFPP , then for any feasible solution ( α , ω1 , . . . , ωN , γ ) of PPPPC we have γ f ( α , ω1 , . . . , ωN ) fi f ( α , ω1 , . . . , ωN)/g(α , ω1 , . . . , ωN ) fi f ( α , ω1 , . . . , ωN)/g(α , ω1 , . . . , ωN ) = γ f ( α , ω1 , . . . , ωN ) with γ = 1/g(α , ω1 , . . . , ωN ) .
N i=1
)
Although PPPPC is a polynomial programming problem , the polynomial constraints make it very hard to solve . We further simplify it as an nonlinear parametric programming problem ( NPPP ) . Theorem 4 . A nonlinear parametric programming problem ( NPPP ) is defined as .(β ) = Max { f ( α , ω1 , . . . , ωN)− βg(α , ω1 , . . . , ωN)} ωi = N + 1 , α . 0 , ωi . 0 , i = 1,··· , N . The subject to α + NFPP problem of Eq ( 23 ) is equivalent to this NPPP , ie , β is a maximum value of NFPP iff .(β ) = 0 . Proof . If ( α , ω1 , . . . , ωN ) is a possible solution of .(β ) = 0 , then f ( α , ω1 , . . . , ωN ) − βg(α , ω1 , . . . , ωN ) = 0 . Thus f ( α , ω1 , . . . , ωN ) − βg(α , ω1 , . . . , ωN ) fi f ( α , ω1 , . . . , ωN ) − βg(α , ω1 , . . . , ωN ) = 0 . We have β = f ( α , ω1 , . . . , ωN)/g(α , ω1 , . . . , ωN ) . f ( α , ω1 , . . . , ωN)/ g(α , ω1 , . . . , ωN ) . Therefore , β is a maximum value of NFPP and ( α , ω1 , . . . , ωN ) is a feasible solution of NFPP .
Conversely , if ( α , ω1 , . . . , ωN ) solves NFPP , then we have β = f ( α , ω1 , . . . , ωN)/g(α , ω1 , . . . , ωN ) . f ( α , ω1 , . . . , ωN)/g(α , ω1 , . . . , ωN ) . Thus f ( α , ω1 , . . . , ωN ) − βg(α , ω1 , . . . , ωN ) fi f ( α , ω1 , . . . , ωN ) − βg(α , ω1 , . . . , ωN ) = 0 . We have .(β ) = 0 and the maximum is taken at ( α , ω1 , . . . , ωN ) .
Now we have successfully transformed the original NFPP in Eq ( 23 ) into the straightforward NPPP . This transformation can help the algorithm converge in a finite number of iterations . Although it is not clear whether the original objective is concave or convex , the objective .(β ) of NPPP has the following properties .
Theorem 5 . .(β ) is a convex function . Proof : Suppose that ( α , ω1 , . . . , ωN ) is a possible solution of .((1 − λ)β1 + λβ2 ) with β1 . β2 and 0 fi λ fi 1 . .((1 − λ)β1 + λβ2 ) = f ( α , ω1 , . . . , ωN ) − ( (1 − λ)β1 + λβ2)g(α , ω1 , . . . , ωN ) = λ( f ( α , ω1 , . . . , ωN)−β2g(α , ω1 , . . . , ωN))+(1−λ)( f ( α , ω1 , . . . , ωN)− β1g(α , ω1 , . . . , ωN ) ) fi λ·max( f ( α , ω1 , . . . , ωN)−β2g(α , ω1 , . . . , ωN ) ) + ( 1 − λ ) · max( f ( α , ω1 , . . . , ωN ) − β1g(α , ω1 , . . . , ωN ) ) = λ.(β2 ) + ( 1 − λ)(β1 ) According to Lemma 1 , we know that .(β ) is convex .
Theorem 6 . .(β ) is a monotonic decreasing function . Proof : Suppose that β1 > β2 and ( α , ω1 , . . . , ωN ) is a possible solution of ( β1 ) Thus , .(β1 ) = f ( α , ω1 , . . . , ωN)−β1g(α , ω1 , . . . , ωN ) < f ( α , ω1 , . . . , ωN ) − β2g(α , ω1 , . . . , ωN ) fi ( β2 ) Theorem 7 . .(β ) = 0 has a unique solution . Proof : Based on the above mentioned theorems , we know .(β ) is continuous as well as decreasing . In addition , limβ→+∞.(β ) = −∞ and limβ→−∞.(β ) = +∞ . 5.5 Adaptive Weight Adjustment
The procedure of solving this NPPP optimization problem includes two parts : ( 1 ) find such a reasonable parameter β ( .(β ) = 0 ) , making NPPP equivalent to NFPP ; ( 2 ) given the parameter β , solve
Algorithm 1 Social Influence based Graph Clustering Input : a social graph S G , multiple influence graphs IGi , a cluster number K , initial weights α = ω1 = . . . = ωN = 1 and a parameter β = 0 . Output : K clusters U1 , , UK . 1 : Calculate W0 , W1 , W2,··· , WN , and W ; 2 : Select K initial centroids with a local maximum of #neighbors ; 3 : Repeat until the objective function .(β ) converges : Assign each vertex ui to a cluster C∗ with a centroid c∗ where 4 : c∗ = argmaxc j d(ui , c j ) ; Update the cluster centroids with the most centrally located point in each cluster ; Solve the NPPP of .(β ) ; Update α , ω1 , , ωN ; Refine β = f ( α , ω1 , . . . , ωN)/g(α , ω1 , . . . , ωN ) ; Update W ;
6 : 7 : 8 : 9 : 10 : Return K clusters U1 , , UK .
5 : a polynomial programming problem about the original variables . Our weight adjustment mechanism is an iterative procedure to find the solution of .(β ) = 0 and the corresponding weights α , ω1 , . . . , ωN after each iteration of the clustering process . We first generate an initial unified similarity matrix W with equal weights to initialize cluster centroids and partition the social graph . Since .(β ) is a monotonic decreasing function and .(0 ) = Max { f ( α , ω1 , . . . , ωN)} is obviously non negative , we start with an initial β = 0 and solve the subproblem .(0 ) by using existing fast polynomial programming model to update the weights α , ω1 , . . . , ωN . The updated parameter by β = f ( α , ω1 , . . . , ωN)/g(α , ω1 , . . . , ωN ) helps the algorithm enter the next round . The algorithm repeats the abovementioned iterative procedure until .(β ) converges to 0 . 5.6 Clustering Algorithm
By assembling different pieces together , we provide the pseudo code of our clustering algorithm SI Cluster in Algorithm 1 .
Theorem 8 . The objective function in Algorithm 1 converges to a local maximum in a finite number of iterations .
Proof . Existing work has studied the convergence properties of the partitioning approach to clustering , such as K Means [ 27 ] . Our clustering follows a similar approach . So the cluster assignment and centroid update steps improve the objective function . In addition , we have explained that nonlinear parametric programming optimization also fast converges a local maximum value . Therefore , the objective function keeps increasing ( but .(β ) keeps decreasing ) and converges to a local maximum in a finite number of iterations . 6 . EXPERIMENTAL EVALUATION
We have performed extensive experiments to evaluate the perfor mance of SI Cluster on real graph datasets . 6.1 Experimental Datasets
We use a full version of the DBLP bibliography data with 964 , 166 authors ( dblp.xml , 836MB , 05/21/2011 ) . We build a social graph where vertices represent authors and edges represent their collaboration relationships , and two associated activity graphs : conference graph and keyword graph . We make use of a multityped clustering framework , RankClus [ 24 ] , to partition both conferences and keywords into clusters respectively . According to the conference ’s or keyword ’s clustering distribution and ranking in each cluster , we calculate the similarities between conferences or keywords . The two associated influence graphs capture how authors in the social graph interact with the activity networks . We also use a smaller DBLP collaboration network with 100 , 000 highly prolific authors . The third dataset is the Amazon product co purchasing network with 20 , 000 products . The two activity networks are product category graph and customer review graph .
SI−Cluster BAGC Inc−Cluster SA−Cluster W−Cluster
40
60
K
80
100 y p o r t n E
12
10
8
6
4
2
0 y t i s n e D
1 0.8
0.6 0.4
0.2
0
SI−Cluster BAGC Inc−Cluster SA−Cluster W−Cluster
SI−Cluster BAGC Inc−Cluster SA−Cluster W−Cluster
I
B D
0 10
−1
10
−2
10
−3
10
−4
10
−5
10
40
60
K
80
100
40
60
80
100
K
( c ) DBI ( a ) density Figure 4 : Cluster Quality on Amazon 20,000 Products 6.2 Comparison Methods and Evaluation
( b ) entropy
We compare SI Cluster with three recently developed representative graph clustering algorithms , BAGC [ 21 ] , SA Cluster [ 20 ] and Inc Cluster [ 28 ] , and one baseline clustering algorithm , WCluster . The last three algorithms integrate entity , link and static attribute information into a unified model . SI Cluster is our proposed algorithm which incorporates not only links , entities , static attributes but also multiple types of dynamic and inter connected activities into a unified influence based model . BAGC constructs a Bayesian probabilistic model to capture both structural and attribute aspects . Both SA Cluster and Inc Cluster combine both structural and attribute similarities in the clustering decisions by estimating the importance of attributes . W Cluster combines structural and attribute similarities using the equal weighting factors . Evaluation Measures We use three measures of to evaluate the quality of clusters {Ul}K l=1 generated by different methods . The defK' initions of the metrics are given as follows . |{(up , uq)|up , uq ∈ Ui , ( up , uq ) ∈ E}| |E| N' |U j| |U| entropy(ai , U j ) density({Ul}K
ωi )
K' l=1 ) = l=1 ) =
( 26 )
( 27 ) i=1 i=1
N p=1
ωp j=1 where ωi is the weight of influence graph IGi , entropy(ai , U j ) = n=1 pi jnlog2 pi jn , ni ( or attribute ai ) is the number of IGi ’s activities ( or the number of ai ’s values ) and pi jn is the percentage of vertices in cluster U j which participate in the nth activity in IGi ( or have value ain on ai ) . entropy({Ul}K l=1 ) measures the weighted entropy from all influence graphs ( or attributes ) over K clusters . Davies Bouldin Index ( DBI ) measures the uniqueness of clusters entropy({Ul}K −)ni with respect to the unified similarity measure .
K' i=1
DBI({Ul}K l=1 ) = 1 K max j.i d(ci , c j ) σi + σ j
( 28 ) where cx is the centroid of Ux , d(ci , c j ) is the similarity between ci and c j , σx is the average similarity of vertices in Ux to cx . 6.3 Cluster Quality Evaluation
Figure 4 ( a ) shows the density comparison on Amazon 20 , 000 Products by varying the number of clusters K = 40 , 60 , 80 , 100 . The density values by SI Cluster , BAGC , Inc Cluster and SA Cluster remains 0.89 or higher even when k is increasing . This demonstrates that these methods can find densely connected components . The density values of W Cluster is relatively lower , in the range of 072 085 with increasing K , showing that the generated clusters have a very loose intra cluster structure . Figure 4 ( b ) shows the entropy comparison on Amazon 20 , 000 Products with K = 40 , 60 , 80 , 100 . SI Cluster has the lowest entropy , while other four algorithms have a much higher entropy than SI Cluster , since SICluster considers not only static attributes but also multiple types of dynamic and inter connected activities during the clustering process . Other methods can not handle dynamic activities and only treat them as static and isolated attributes . Figures 4 ( c ) shows the DBI comparison on Amazon 20 , 000 Products with different K values . SI Cluster has the lowest DBI of around 0.000008 − 0.000023 , while other methods have a much higher DBI than SICluster . This demonstrates that SI Cluster can achieve both high
SI−Cluster BAGC Inc−Cluster SA−Cluster W−Cluster
400
600
K
800
1000 y p o r t n E
10
8
6
4
2
0
SI−Cluster BAGC Inc−Cluster SA−Cluster W−Cluster
400
600
K
800
1000
SI−Cluster BAGC Inc−Cluster SA−Cluster W−Cluster
400
600
K
800
1000
) d n o c e S
( e m i t n u R
1200 1000 800 600 400 200 0
SI−Cluster BAGC Inc−Cluster SA−Cluster W−Cluster
40
60
K
80
100
) d n o c e S
( e m i t n u R
2000
1500
1000
500
0
SI−Cluster BAGC Inc−Cluster SA−Cluster W−Cluster
) d n o c e S
( e m i t n u R
8000
6000
4000
2000
SI−Cluster BAGC Inc−Cluster SA−Cluster W−Cluster
400
600
K
800
1000
0
4000
6000
8000
10000
K
I
B D
−3
10
−4
10
−5
10
−6
10
( a ) density Figure 5 : Cluster Quality on DBLP 100,000 Authors
( b ) entropy
( c ) DBI
( a ) Amazon 20,000
( b ) DBLP 100,000
Figure 7 : Clustering Efficiency
( c ) DBLP 964,166
SI−Cluster BAGC Inc−Cluster SA−Cluster W−Cluster
4000
6000
K
8000
10000 y p o r t n E
2.5
2
1.5
1
0.5
0
SI−Cluster BAGC Inc−Cluster SA−Cluster W−Cluster
4000
6000
K
8000
10000
SI−Cluster BAGC Inc−Cluster SA−Cluster W−Cluster
4000
6000
K
8000
10000
−6
10
I
B D
−7
10
) β ( F
8
6
4
2
0 0
5 x 10
10
K=400 K=600 K=800 K=1000 y t i s n e D
1
0.8
0.6
0.4
0.2
0
0.8 y t i s n e D
0.6
0.4
0.2
0
( a ) density Figure 6 : Cluster Quality on DBLP 964,166 Authors
( b ) entropy
( c ) DBI intra cluster similarity and low inter cluster similarity . This is because SI Cluster integrates self influence similarity as well as coinfluence similarity with the optimal weights assignment by parameterbased optimization . It fully utilizes the connections between activities and the interactions between members and activities so that the generated clusters have not only similar collaborative patterns but also similar interaction patterns with activities .
Figures 5 ( a ) , ( b ) and ( c ) show density , entropy and DBI on DBLP with 100 , 000 authors when we set K = 400 , 600 , 800 , 1000 . These three figures have similar trends with Figures 4 ( a ) , ( b ) and ( c ) respectively . As shown in the figures , SI Cluster achieves high density values ( > 0.63 ) , which is slightly lower than that of BAGC since the probabilistic clustering method partitions vertices into each possible cluster so that the density value by it often increases with K . SI Cluster achieves a very low entropy around 286 304 , which is obviously better than the other methods ( > 635 ) As K increases , the entropy by SI Cluster remains stable , while the density of SI Cluster decreases . In addition , SI Cluster achieves the lowest DBI ( < 0.000005 ) among different methods , while the DBI values by other methods are obviously larger than > 0000005
Figures 6 ( a ) , ( b ) and ( c ) show density , entropy and DBI comparisons on DBLP with 964 , 166 authors by varying K = 4000 , 6000 , 8000 , 10000 . Other four methods except SI Cluster do not work on this large dataset due to the “ out of memory" problem with our 8G main memory machine . However , SI Cluster still shows good performance with varying K . It achieves similar high density values ( > 0.55 ) , much lower entropy of about 2.45 , and very low DBI ( ≈ 0 ) for different K . 6.4 Clustering Efficiency Evaluation
Figures 7 ( a ) , ( b ) and ( c ) show the clustering time on Amazon 20,000 Products , DBLP 100 , 000 and 964 , 166 authors respectively . SI Cluster outperforms all other algorithms in all experiments . When facing with an extremely large dataset , such as DBLP964 , 166 , other algorithms cannot work due to the “ out of memory" error , while SI Cluster scales well with large graphs and shows good performance with varying K . We make the following observations on the runtime costs of different methods . First , SA Cluster is obviously worst than other methods since it needs to perform the repeating random walk distance calculation during each iteration of the clustering process and the distance computation takes more than 80 % of the total clustering time . Second , Inc Cluster , an optimized version of SA Cluster , is much slower than SI Cluster , BAGC and W Cluster since it still needs to incrementally calculate the random walk distance . Third , although W Cluster compute the random walk distance only once , it still runs on a large scale matrix . t h g e W i
1.2
1.1
1
0.9
0.8
0.7 0
K=4000 K=6000 K=8000 K=10000 K=4000 K=6000 K=8000 K=10000 K=4000 K=6000 K=8000 K=10000
1
2
Iteration
3
( b ) Weight Update
0.005 0.01 0.015 0.02 0.025
β
( a ) .(β )
Figure 8 : Clustering Convergence on DBLP 964,166 Authors Fourth , the performance by BAGC is better than other approaches except SI Cluster . Although it does not need to repeatedly compute the distance matrix , it needs to iteratively update lots of temporary matrices or interim variables and its computational cost is proportional to K2 so that it may not work well when facing large K value . In comparison , SI Cluster reorganizes a large scale heterogeneous network into multiple small scale subgraphs . It reduces the cost by partitioning activities with the topological information of the activity graph . Furthermore , SI Cluster calculates influence based similarity matrices only once . According to Theorems 4 7 , solving .(β ) for a given β is a polynomial programming problem which can be sped up by existing fast polynomial programming model . 6.5 Clustering Convergence
Figure 8 ( a ) shows the trend of clustering convergence in terms of the .(β ) value on DBLP 964 , 166 Authors . The .(β ) value keeps decreasing and has a convex curve when we iteratively perform the tasks of vertex assignment , centroid update and weight adjustment during the clustering process . .(β ) converges very quickly , usually in three iterations . These are consistent with Theorems 4 7 .
Figure 8 ( b ) shows the trend of weight updates on DBLP 964 , 166 Authors with different K values : the social graph ( red curve ) , the conference influence graph ( green curve ) and the keyword influence graph ( blue curve ) . We observe that the graph weights converge as the clustering process converges . An interesting phenomenon is that both the social weight and the keyword weight are increasing but the conference weight is decreasing with more iterations . A reasonable explanation is that people who have many publications in the same conferences may have different research topics but people who have many papers with the same keywords usually have the same research topics , and thus have a higher collaboration probability as co authors . 6.6 Case Study
We examine some details of the experiment results on DBLP 964 , 166 Authors when we set k = 100 for both conferences and keywords . Table 1 ( a ) shows author ’s influence score based on the social influence propagation between authors and keyword partitions . We only present most prolific DBLP experts in the area of data mining or database . When social influence propagation converges , each row represents the influence distribution of an author in each keyword category . We can look upon this influence distribution as a probability based clustering result . On the other hand , each column specifies the influence distribution of different authors in the same keyword category . This influence distribution is considered as a local ranking result .
( a ) Influence Scores Based on All Keywords
( b ) Influence Scores Based on Selected Top Conferences
Cluster 1 ( DB ) Cluster 2 ( DM )
AI Cluster DB Cluster DM Cluster
Author
Elisa Bertino
Christos Faloutsos
Jiawei Han Vipin Kumar
Bing Liu
David Maier
Hector Garcia Molina
M . Tamer Özsu
Jian Pei
Philip S . Yu
0.0568 0.0465 0.0585 0.0146 0.0153 0.0474 0.0603 0.0408 0.0386 0.0606
0.0249 0.0746 0.0960 0.0545 0.0511 0.0079 0.0047 0.0111 0.0653 0.0991
Author
Elisa Bertino
Christos Faloutsos
Jiawei Han Vipin Kumar
Bing Liu
David Maier
Hector Garcia Molina
M . Tamer Özsu
Jian Pei
Philip S . Yu
0.0047 0.0012 0.0883 0.2511 0.2648 0.1570 0.0031 0.0017 0.0876 0.0972
0.7135 0.4267 0.3724 0.1342 0.1001 0.8290 0.8217 0.5506 0.3768 0.3504
0.0055 0.3950 0.3766 0.5198 0.4004 0.0117 0.0075 0.1080 0.3717 0.3763
IR Cluster
0.2763 0.1771 0.1628 0.0949 0.2347 0.0023 0.1677 0.3397 0.1639 0.1761
Table 1 : Influence Scores of Authors Based on Conference and Keyword Partitions
Table 1 ( a ) actually presents an unbalanced result since the influence propagation process is based on the full DBLP dataset . We know that academic research in the area of database has a longer history and there are more academic conferences or forums focusing on database research . Thus , we choose the same number of top conferences for each research area to better evaluate the quality of our co influence model . Here , we choose three top conferences from four research areas of database , data mining , information retrieval and artificial intelligence , respectively . The detailed conference list is , DB : VLDB , SIGMOD , ICDE ; DM : KDD , ICDM , SDM ; IR : SIGIR , CIKM , ECIR ; AI : IJCAI , AAAI , ECAI . Table 1 ( b ) shows author ’s influence score normalized by conference partitions for each author , ie , a better probability based clustering result . 7 . CONCLUSIONS
In this paper , we present a social influence based clustering framework for heterogeneous information networks . First , we integrate different types of links , entities , static attributes and dynamic activities from different networks into a unifying influence based model . Second , an iterative learning algorithm is proposed to dynamically refine the K clusters by continuously quantifying and adjusting the weights on multiple influence based similarity scores towards the clustering convergence . Third , we transform a sophisticated nonlinear fractional programming problem of multiple weights into a straightforward nonlinear parametric programming problem of single variable to speed up the clustering process . Acknowledgement . This work is partially funded by grants from NSF CISE NetSE program and SaTC program and Intel Science and Technology Center on Cloud Computing . 8 . REFERENCES [ 1 ] D . Kempe , J . Kleinberg , and E . Tardos . Maximizing the spread of influence through a social network . In KDD , 2003 . [ 2 ] P . Domingos and M . Richardson . Mining the network value of customers . In KDD , pages 57–66 , 2001 .
[ 3 ] H . Ma , H . Yang , M . R . Lyu , and I . King . Mining social networks using heat diffusion processes for marketing candidates selection . In CIKM , pages 233–242 , 2008 .
[ 4 ] M . Roth , A . Ben David , D . Deutscher , G . Flysher , I . Horn ,
A . Leichtberg , N . Leiser , Y . Matias , and R . Merom . Suggesting friends using the implicit social graph . In KDD , pages 233–242 , 2010 .
[ 5 ] S . Myers , C . Zhu , J . Leskovec . Information Diffusion and
External Influence in Networks . In KDD , pages 33 41 , 2012 .
[ 6 ] B . Taskar , E . Segal , D . Koller . Probabilistic Classification and Clustering in Relational Data . In IJCAI , 2001 .
[ 7 ] D . Cai , Z . Shao , X . He , X . Yan , and J . Han . Community mining from multi relational networks . In PKDD , 2005 . [ 8 ] T . Yang , R . Jin , Y . Chi , and S . Zhu . Combining link and content for community detection : a discriminative approach . In KDD , pages 927–936 , 2009 .
[ 9 ] M . Ji , J . Han , and M . Danilevsky . Ranking based classification of heterogeneous information networks . In KDD , pages 1298–1306 , 2011 .
[ 10 ] X . Yu , Y . Sun , P . Zhao , and J . Han . Query driven discovery of semantically similar substructures in heterogeneous networks . In KDD , pages 1500–1503 , 2012 .
[ 11 ] J . Shi and J . Malik . Normalized cuts and image segmentation . In TPAMI , 22(8 ) , pages 888–905 , 2000 .
[ 12 ] M . E . J . Newman and M . Girvan . Finding and evaluating community structure in networks . In Phys . Rev . E 69 , 026113 , 2004 .
[ 13 ] X . Xu , N . Yuruk , Z . Feng , and T . A . J . Schweiger . Scan : a structural clustering algorithm for networks . In KDD , 2007 .
[ 14 ] V . Satuluri and S . Parthasarathy . Scalable graph clustering using stochastic flows : Applications to community discovery . In KDD , 2009 .
[ 15 ] K . Macropol and A . Singh . Scalable discovery of best clusters on large graphs . In PVLDB , 3(1 ) , 693–702 , 2010 .
[ 16 ] Y . Tian , R . A . Hankins , and J . M . Patel . Efficient aggregation for graph summarization . In SIGMOD , 567–580 , 2008 .
[ 17 ] N . Zhang , Y . Tian , and J . M . Patel . Discovery driven graph summarization . In ICDE , pages 880–891 , 2010 .
[ 18 ] E . C . Kenley and Y R Cho . Entropy based graph clustering : Application to biological and social networks . In ICDM’11 . [ 19 ] M . Shiga , I . Takigawa , H . Mamitsuka . A spectral clustering approach to optimally combining numericalvectors with a modular network . In KDD , 2007 .
[ 20 ] Y . Zhou , H . Cheng , and J . X . Yu . Graph clustering based on structural/attribute similarities . In VLDB , 718–729 , 2009 .
[ 21 ] Z . Xu , Y . Ke , Y . Wang , H . Cheng , and J . Cheng . A model based approach to attributed graph clustering . In SIGMOD , pages 505–516 , 2012 .
[ 22 ] Y . Sun , B . Norick , J . Han , X . Yan , P . Yu , X . Yu . Integrating Meta Path Selection with User Guided Object Clustering in Heterogeneous Information Networks . In KDD , 2012 .
[ 23 ] Y . Sun , C . C . Aggarwal , and J . Han . Relation strength aware clustering of heterogeneous information networks with incomplete attributes . PVLDB , 5(5):394–405 , 2012 .
[ 24 ] Y . Sun , J . Han , P . Zhao , Z . Yin , H . Cheng , and T . Wu .
Rankclus : Integrating clustering with ranking for heterogenous information network analysis . In EDBT , 2009 .
[ 25 ] L . Kaufman and P . J . Rousseeuw . Clustering by means of medoids . Statistical Data Analysis based on the L1 Norm , pages 405–416 , 1987 .
[ 26 ] R . T . Rockafellar . Convex Analysis . Princeton University
Press , 1997 .
[ 27 ] L . Botton and Y . Bengio . Convergence properties of the k means algorithms . In NIPS , pages 585–592 , 1994 .
[ 28 ] Y . Zhou , H . Cheng , and J . X . Yu . Clustering large attributed graphs : An efficient incremental approach . In ICDM , 2010 .
