Summarizing Probabilistic Frequent Patterns :
A Fast Approach
Chunyang Liu , Ling Chen , Chengqi Zhang
∗ QCIS , University of Technology , Sydney ChunyangLiu@studentutseduau ,
{Ling.Chen , ChengqiZhang}@utseduau
ABSTRACT Mining probabilistic frequent patterns from uncertain data has received a great deal of attention in recent years due to the wide applications . However , probabilistic frequent pattern mining suffers from the problem that an exponential number of result patterns are generated , which seriously hinders further evaluation and analysis . In this paper , we focus on the problem of mining probabilistic representative frequent patterns ( P RFP ) , which is the minimal set of patterns with adequately high probability to represent all frequent patterns . Observing the bottleneck in checking whether a pattern can probabilistically represent another , which involves the computation of a joint probability of the supports of two patterns , we introduce a novel approximation of the joint probability with both theoretical and empirical proofs . Based on the approximation , we propose an Approximate P RFP Mining ( APM ) algorithm , which effectively and efficiently compresses the set of probabilistic frequent patterns . To our knowledge , this is the first attempt to analyze the relationship between two probabilistic frequent patterns through an approximate approach . Our experiments on both synthetic and real world datasets demonstrate that the APM algorithm accelerates P RFP mining dramatically , orders of magnitudes faster than an exact solution . Moreover , the error rate of APM is guaranteed to be very small when the database contains hundreds transactions , which further affirms APM is a practical solution for summarizing probabilistic frequent patterns .
Categories and Subject Descriptors H28 [ DATABASE MANAGEMENT ] : Database Applications—Data Mining
General Terms Algorithms ∗
Centre for Quantum Computation and Intelligent Systems
Keywords Pattern Summarization , Uncertain Data
1 .
INTRODUCTION
Data uncertainty is inherent in various applications such as sensor network monitoring , moving object tracking , and protein protein interaction data [ 6 ] . It could be induced by different reasons including experimental error , artificial noise , and data incompleteness.Rather than cleaning the uncertain data using domain specific rules , modeling the uncertainty of data is more rational in many applications , such as medical diagnosis and risk assessment . As a consequence , data mining over uncertain data has become an active research area recently . A survey of state of the art uncertain data mining techniques may be found in [ 1 ] .
As one of the most fundamental data mining tasks , frequent pattern mining has also been introduced into uncertain databases [ 3 ] and received a great deal of research attention [ 4 , 5 , 6 , 10 , 11 , 12 ] . Generally , there exist two different definitions of frequent patterns in the context of uncertain data : expected support based frequent patterns [ 3 , 11 ] , and probabilistic frequent patterns [ 4 , 5 ] . Both definitions consider the support of a pattern as a discrete random variable . The former uses the expectation of the support as the measurement , while the latter considers the probability that the support of a pattern is no less than some specified minimum support threshold . Despite the different frequentness metrics employed , both the expected support based frequent patterns and the probabilistic frequent patterns enjoy the anti monotonic property [ 3 , 4 ] . That is , if a pattern is frequent in an uncertain database , then all of its sub patterns are frequent as well . This property leads to the generation of an exponential number of result patterns . The large number of discovered frequent patterns makes the understanding of , and further analysis of generated patterns troublesome . Therefore , similar to the counterpart of the problem in deterministic data , it is indeed important to find a small number of representative patterns to best approximate all other probabilistic frequent patterns .
Some initial research work has been undertaken to find a small set of representative patterns . For example , mining probabilistic frequent closed patterns over uncertain data has been studied in [ 7 , 8 , 9 ] . However , the number of probabilistic frequent closed patterns is still large because of the restrictive condition for a pattern being closed . For instance , in [ 9 ] , the closed probability of a pattern is computed as the sum of the probabilities of the possible worlds of an uncertain database where the pattern is closed .
527 In the context of deterministic data , Xin et al . [ 20 ] has proposed the notion of a ε covered relationship between patterns as a generalization of the concept of frequent closed patterns to further reduce the size of closed patterns . A pattern X1 is ε covered by another pattern X2 if X1 is a subset of X2 and ( Supp(X1 ) − Supp(X2))/Supp(X1 ) ≤ ε . The goal is then to find a minimal set of representative patterns that can ε cover all frequent patterns .
Motivated by this idea in deterministic data , in our previous work , we have proposed to relax the restrictive condition of probabilistic frequent closed patterns to mine probabilistic representative frequent patterns ( P RFP ) [ 25 ] . In particular , we extend the concept of ε cover to define the ( ε , δ)covered relationship between probabilistic frequent patterns , addressing the fact that the support of a pattern becomes a discrete random variable in an uncertain database . Informally , a pattern X1 is ( ε , δ) covered by another pattern X2 in an uncertain database if X1 is a subset of X2 , and the probability that the support distance between X1 and X2 is no greater than ε is no less than δ .
We have devised a dynamic programming based approach to discover the minimal set of P RFPs . Although this approach can compute exactly the probability that the support distance between two patterns is no greater than ε , it is not sufficiently efficient due to the bottleneck in examining whether a pattern ( ε , δ) covers another , which involves the computation of a joint probability of the supports of the two patterns . In this work , we analyze that the joint support probability follows a joint Poisson binomial distribution with both theoretical and empirical proofs . Based on the analysis , we propose an Approximate P RFP Mining ( APM ) algorithm that performs outstandingly faster than the dynamic programming based exact approach .
To our knowledge , this is the first attempt to analyze the relationship between two probabilistic frequent patterns through an approximate approach . Our experimental results show that our approach summarizes frequent patterns efficiently and effectively , and restores the patterns and their original frequency probability information with a guaranteed error bound . To summarize , our contributions are as follows . • We construct a mathematical model for the joint probability of the supports of a pattern pair and study an approximation of the joint support probability .
• We develop an efficient algorithm to discover the minimal set of P RFPs using accurate approximation techniques to estimate the probability that one pattern represents another .
• We conduct extensive experiments on both real world and synthetic data to evaluate the performance of the proposed approach by comparing against an exact solution .
The remainder of the paper is structured as follows . The next section reviews existing works related to this paper . We define important concepts and provide the problem statement in Section 3 . Section 4 describes the proposed data mining approach . The theoretical proof of the approximation of the joint support probability is demonstrated in Section 5 . We evaluate the performance of the proposed approach in Section 6 and close this paper with some conclusive remarks in Section 7 .
2 . RELATED WORK
In this section , we review related research from two subareas : frequent pattern mining over uncertain data and frequent pattern summarization .
Frequent pattern mining over uncertain data . Mining frequent patterns from uncertain databases has been studied extensively in the past years . Existing work on frequent pattern mining from uncertain data falls into two categories : expected support based frequent pattern mining [ 3 , 10 , 11 ] and probabilistic frequent pattern mining [ 4 , 5 ] . The former utilizes the expectation of support as the frequentness metric . That is , a pattern is frequent only if its expected support is no less than a specified minimum expected support . The latter considers the frequency probability as the measurement , which refers to the probability that a pattern appears no less than a specified minimum support times . Thus , a pattern is frequent only if its frequency probability is no less than a specified minimum probability ( ie Pr(Supp(X ) ≥ minsup ) ≥ minprob ) .
There are three representative algorithms for mining expected support based frequent patterns : UApriori [ 3 ] , UFPgrowth [ 10 ] and UH Mine [ 11 ] . UApriori is the uncertain version of the well known Apriori algorithm . Both UFPgrowth and UH Mine employ the divide and conquer framework that searches frequent patterns with depth first strategy . For mining probabilistic frequent patterns , there are two representative algorithms : DP − dynamic programmingbased Apriori algorithm [ 4 ] , and DC − divide and conquerbased Apriori algorithm [ 5 ] . Recently , Tong et al . [ 6 ] verified that the two types of definitions of frequent patterns mined from uncertain data are closely related from a mathematical perspective and can be unified when the size of data is sufficiently large .
Considering that the support of a pattern in an uncertain database follows a Poisson binomial distribution , some approximate algorithms for mining probabilistic frequent patterns have been proposed as well . For example , both the Normal and Poisson distribution have been used to approximate the frequency probabilities of patterns [ 12 , 13 ] . Compared with our work , existing approximate approaches focus on the approximation of the support probability of only one pattern . The approximation of joint probability of the supports of two patterns is much more challenging because the dependency of two random variables needs to be taken into account .
Frequent pattern summarization . Motivated by the fact that frequent pattern mining may generate an exponential number of patterns due to the anti monotonicity , numerous research work has been dedicated to frequent pattern summarization , which aims to obtain a much smaller set of patterns to represent the complete set of frequent patterns . A variety of definitions have been proposed , such as maximal patterns [ 14 ] , frequent closed patterns [ 15 ] and nonderivable patterns [ 16 ] . While all frequent patterns can be recovered from maximal patterns , the loss of support information is unacceptable in some circumstances . For frequent closed patterns , although the exact support of all frequent patterns can be preserved , the number of frequent closed patterns can still be tens of thousands , or even more . There are several generalizations of closed patterns , such as the pattern profiling based approaches [ 17 , 18 , 19 ] and the support distance based approaches [ 20 , 21 ] . It was observed in [ 21 ] that the profile based approaches [ 17 , 18 ] have some
528 drawbacks , such as no error guarantee on restored support . Hence , in our work , we borrow the framework of the support distance based approaches to find probabilistic representative frequent patterns .
Recently , some research work has been undertaken to summarize frequent patterns in the context of uncertain data . Tang and Peterson [ 8 ] proposed mining probabilistic frequent closed patterns , based on the concept called probabilistic support . Tong et al . [ 9 ] pointed out that frequent closed patterns defined on probabilistic support cannot guarantee the patterns are closed in possible worlds which contribute to their probabilistic supports . Instead , they defined the threshold based frequent closed patterns over probabilistic data , which considers the probabilities of possible worlds where a pattern is closed . Our research relaxes the condition to further reduce the size of patterns by considering the probabilities of possible worlds where a pattern can ε cover another one .
3 . BACKGROUND AND PRELIMINARY
In this section , we review the relevant concepts introduced in previous work and formally state the problem of probabilistic representative frequent pattern ( P RFP ) mining .
Xin et al . [ 20 ] defined a robust distance measure between patterns in deterministic data . definition 1 . ( distance measure ) Given two patterns X1 and X2 , the distance between them , denoted as dist(X1 , X2 ) , is defined as 1 − |T ( X1 ) ∩ T ( X2)|/|T ( X1 ) ∪ T ( X2)| , where T ( Xi ) is the set of transactions supporting pattern Xi .
Then , an ε covered relationship is defined on two patterns where one subsumes another . definition 2 . ( ε covered ) Given a real number ε ∈ [ 0 , 1 ] and two patterns X1 and X2 , we say X1 is ε covered by X2 if X1 ⊆ X2 and dist(X1 , X2 ) ≤ ε . if X2 ε covers X1 , then It can be proved easily that , ( Supp(X1 ) − Supp(X2))/Supp(X1 ) ≤ ε . The goal of representative frequent pattern mining then becomes finding the minimal set of patterns that ε cover all frequent patterns .
In the context of uncertain data , the support of a pattern , Supp(Xi ) , becomes a discrete random variable . Therefore , we cannot directly apply the ε cover relationship to probabilistic frequent patterns . Before explaining how to extend the concept of ε covered in the context of uncertain data , we examine an uncertain database where attributes are associated with existential probabilities .
Table 1 shows an uncertain transaction database where each transaction consists of a set of probabilistic items . For example , the probability that item a appears in the first transaction T1 is 07 Possible world semantics are commonly used to explain the existence of data in an uncertain database . For example , the database in Table 1 has eight possible worlds , which are listed in Table 2 . Each possible world is associated with an existential probability . For instance , the probability that the first possible world w1 exists is ( 1 − 0.7 ) × ( 1 − 0.2 ) × 1 × ( 1 − 0.5 ) = 012
Considering that the occurrences of items in every possible world are deterministic , we can define the probabilistic distance between two probabilistic frequent patterns based on their distance in possible worlds . definition 3 . ( probabilistic distance measure ) Given an uncertain database D , and two patterns X1 and X2 , let
ID Transactions T1 T2 a:0.7 b:0.2 a:1.0 c:0.5
Table 1 : An example of attribute uncertainty .
ID w1 w2 w3 w4 w5 w6 w7 w8
Possible World {T1 : φ , T2 : {a}} {T1 : {a} , T2 : {a}} {T1 : {b} , T2 : {a}} {T1 : {a , b} , T2 : {a}} {T1 : φ , T2 : {a , c}} {T1 : {a} , T2 : {a , c}} {T1 : {b} , T2 : {a , c}} {T1 : {a , b} , T2 : {a , c}}
Prob . 0.12 0.28 0.03 0.07 0.12 0.28 0.03 0.07
Table 2 : An example of possible worlds .
PW= {w1 , . . . , wm} be the set of possible worlds derived from D , the distance between X1 and X2 in a possible world wj ∈ PW is dist(X1 , X2 ; wj ) = 1 − |T ( X1 ; wj ) ∩ T ( X2 ; wj)| |T ( X1 ; wj ) ∪ T ( X2 ; wj)|
( 1 ) where T ( Xi ; wj ) is the set of transactions containing pattern Xi in the possible world wj . Then , the probabilistic distance between X1 and X2 , denoted by dist(X1 , X2 ) , is a random variable . The probability mass function of dist(X1 , X2 ) is :
.
Pr(dist(X1 , X2 ) = d ) =
Pr(wj )
( 2 ) wj∈PW dist(X1,X2;wj )=d
That is , the probability that the distance between two probabilistic frequent patterns is d can be computed by the sum of the probabilities of corresponding possible worlds . For example , consider the uncertain database in Table 1 . Let X1 = {a} and X2 = {a , b} . The probability that the distance between X1 and X2 is equal to 0.5 , Pr(dist(X1 , X2 ) = 0.5 ) , can be computed by adding the probabilities of the possible worlds w4 and w8 . This is because only in the two possible worlds , the distance between the two patterns is 05 Therefore , Pr(dist(X1 , X2 ) = 0.5 ) = 014
Based on the probabilistic distance measure , we define the
ε cover probability as follows . definition 4 . ( ε cover probability ) Given an uncertain database D , two patterns X1 and X2 , and a distance threshold ε , the ε cover probability of X1 and X2 is defined as Prcover(X1 , X2 ; ε ) = Pr(dist(X1 , X2 ) ≤ ε ) . definition 5 . ( (ε , δ) covered ) Given an uncertain database
D , two patterns X1 and X2 , a distance threshold ε and a εcover probability threshold δ , X2 ( ε , δ) covers X1 if and only if X1 ⊆ X2 and Prcover(X1 , X2 ; ε ) ≥ δ .
Our goal is then to obtain the minimal set of patterns that will ( ε , δ) cover all the probabilistic frequent patterns . The formal statement of the probabilistic representative frequent pattern ( P RFP ) mining is as follows . definition 6 . ( Problem Statement ) Given an uncertain database D , a set of probabilistic frequent patterns F , a probabilistic distance threshold ε and a ε cover probability threshold δ , the problem of probabilistic representative frequent pattern ( P RFP ) mining is to find the minimal set of patterns R so that , for any frequent pattern X ∈ F , there exists a representative pattern X fi ∈ R where X
( ε , δ) covers X . fi
529 It is obvious that when ε = 0 , the probabilistic representative pattern set is equivalent to the set of probabilistic closed patterns , and when ε = 1 , it is the same as probabilistic maximal pattern set .
4 . APPROXIMATE P RFP MINING
This section first describes the framework of our proposed approach . Then , we explain the details of the main steps of the Approximate P RFP Mining ( APM ) algorithm . 4.1 Framework of APM
Before presenting the framework of our approximate approach for P RFP mining , we develop some important lemmas between two patterns where one ( ε , δ) covers another . Lemma 1 . Given an uncertain database D and two patterns X1 and X2 st X2 ( ε , δ) covers X1 , the distance between X1 and X2 in the possible world wj can be represented by the support of the patterns in wj : dist(X1 , X2 ; wj ) = 1 − Supp(X2 ; wj ) Supp(X1 ; wj )
( 3 ) Lemma 2 . Given an uncertain database D and two patterns X1 and X2 st X2 ( ε , δ) covers X1 , the probabilistic distance dist(X1 , X2 ) can be represented by the support distribution of X1 and X2 : dist(X1 , X2 ) = 1 − Supp(X2 ) Supp(X1 )
( 4 ) Lemma 3 . Given an uncertain database D and two pat terns X1 and X2 st X2 ( ε , δ) covers X1 , we have Pr ( Supp(X2 ) ≥ ( 1 − ε)Supp(X1 ) ) ≥ δ
( 5 )
These lemmas are obvious expansions of the concepts in deterministic data . The detailed proofs are stated in [ 25 ] .
Lemma 4 . Given an uncertain database D , two patterns X1 and X2 , a support threshold minsup and a frequency probability threshold minprob , if X2 ( ε , δ) covers X1 , and X1 is a probabilistic frequent pattern wrt minsup and minprob , then X2 is a probabilistic frequent pattern wrt ( 1 − ε)minsup and ( δ · minprob ) . Proof . Since X1 is a probabilistic frequent pattern wrt minsup and minprob , we have Pr ( Supp(X1 ) ≥ minsup)≥ minprob , which infers ,
Pr((1 − ε)Supp(X1 ) ≥ ( 1 − ε)minsup ) ≥ minprob
( 6 )
From Lemma 3 , we have ,
Pr(Supp(X2 ) ≥ ( 1 − ε)Supp(X1 ) ) ≥ δ
( 7 ) Consider that the events in equation 6 and 7 are independent , we have Pr ( Supp(X2 ) ≥ ( 1 − ε)minsup ) ≥ δ·minprob . That is , X2 is a probabilistic frequent pattern wrt ( (1 − ε)minsup ) and ( δ · minprob ) .
Denoting the set of probabilistic frequent patterns as F , lemma 4 indicates that if pattern X can ( ε , δ) cover another pattern Y in F , then X must be probabilistic frequent wrt ( 1 − ε)minsup and minprob . We call such a pattern pseudo probabilistic frequent and denote the set of pseudo probabilistic frequent patterns as ˆF . In order to achieve the minimal set of probabilistic representative frequent patterns , we have to find a subset of ˆF that can ( ε , δ) cover all patterns of F . Given the two sets F and ˆF , our approach for P RFP mining consists of the following two steps .
1 . Generate the cover set for every pattern in ˆF . For each pattern X in ˆF , the cover set of X , denoted as C(X ) , is a set of probabilistic frequent patterns in F that can be ( ε , δ) covered by X . That is , C(X ) ⊆ F .
2 . Find the minimal pattern set R ⊆ ˆF to ( ε , δ) cover all probabilistic frequent patterns in F .
After finding the cover sets for patterns in ˆF in the first step , the second step is equivalent to finding a minimal number of cover sets that cover all patterns in F . This is known as a set covering problem , which is NP hard . Similar to [ 21 ] and [ 25 ] , we adopt a well known greedy set covering algorithm [ 22 ] , which achieves polynomial complexity . Therefore , in the following , we focus on describing the first step , which generates the cover set for each pseudo probabilistic frequent pattern in ˆF . 4.2 Cover Set Generation To generate the cover set for a pattern X2 in ˆF , for each pattern X1 in F such that X1 ⊆ X2 , we need to check if X2 ( ε , δ) covers X1 . That is , we need to examine whether the ε cover probability between X1 and X2 is no less than δ ( ie , Pr(dist(X1 , X2 ) ≤ ε ) ≥ δ ) . According to Lemma 3 , the εcover probability Prcover(X1 , X2 ; ε)=Pr(dist(X1 , X2 ) ≤ ε ) is equivalent to Pr(Supp(X2 ) ≥ ( 1 − ε)Supp(X1) ) . Then , the ε cover probability between X1 and X2 is equal to the following sum .
|D| . l . l=minsup k='(1−ε)lff
Pr(Supp(X1 ) = l , Supp(X2 ) = k )
( 8 )
To compute the ε cover probability to find out whether it is no less than δ , we introduce the joint support probability distribution as follows . definition 7 . ( joint support probability ) Given an uncertain database D and patterns X1 and X2 , the joint support probability mass function is
.
Pr ( Supp(X1 ) = l , Supp(X2 ) =k ) =
Pr(wi ) wi∈PW ,
Supp(X1;wi)=l Supp(X2;wi)=k
Although definition 7 implies a brute force solution , it is not feasible to implement because the number of possible worlds is exponential . Therefore , we establish the following approximation of joint support probability .
Theorem 1 . Given an uncertain database D and patterns X1 and X2 , the joint support probability can be approximated by a bivariate normal distribution , which means Pr(Supp(X1 ) = l , Supp(X2 ) =k ) ≈ φ
2 ( X − µ ) − 1
' fi
( 9 )
Σ ff
T l k where X = and Supp(X2 ) , and Σ is the covariance matrix of X1 and X2 .
, µ is the vector of mean values of Supp(X1 )
Theorem 1 provides a solution to compute the joint support probability of a pair of patterns via normal distribution , rather than mining in the complete database . The detailed theoretical proof is elaborated in Section 5 , and the empirical simulation is illustrated in Section 6 . Similar to univariate normal distribution , we can optimize our approach with the well known 3σ property [ 23 ] .
530 Corollary 1 . Given an uncertain database D , and patterns X1 and X2 , let the mean value and variance of Supp(Xj ) j , j = 1 , 2 , l1 = max{minsup , μ1 − 3σ1} , l2 = be μj , σ2 min{|D| , μ1 + 3σ1} , k1 = max{(1 − ε)lff , μ2 − 3σ2} , and k2 = min{l , μ2 + 3σ2} , then |D| . k2 . ≈ l2 .
Pr(Supp(X1 ) =l , Supp(X2 ) = k )
Pr(Supp(X1 ) = l , Supp(X2 ) = k ) k='(1−ε)lff l . l=minsup
( 10 ) l=l1 k=k1
Note that for better precision , we use σ1 to calculate the support lower bound and upper bound for both X1 and X2 because the contour of bivariate normal distribution is an ellipse , and σ1 is the length of semi major axis . Based on corollary 1 , we can reduce the computational complexity of ε cover probability from O(|D|2 ) to O(9σ2 1 ) significantly . To accelerate the progress of cover set generation further , we also take advantage of some optimization strategies in [ 25 ] . Lemma 5 . Given an uncertain database D , two patterns X1 and X2 st X1 ⊆ X2 , and a probabilistic distance threshold ε , Prcover(X1 , X2 ; ε ) computed on D is equal to that on D(X1 ) , where D(X1 ) is {t|P ( X1 ⊆ t ) > 0 , t ∈ D} ⊆ D . Lemma 5 is intuitive because only the transactions supporting at least the sub pattern X1 will contribute to the value of probabilistic distance , which in turn affects the ε cover probability . This lemma allows us to compute the ε cover probability on a projected sub database , which significantly reduces the runtime of computation . Lemma 6 . Given an uncertain database D and two patterns X1 and X2 st X1 ⊆ X2 , if X2 ( ε , δ) covers X1 , then ∀X st X1 ⊆ X ⊆ X2 , we have X2 ( ε , δ) covers X .
According to Lemma 6 , we have the following corollary . Corollary 2 . Given an uncertain database D and two patterns X1 and X2 , X1 ⊆ X2 , if X2 cannot ( ε , δ) cover X1 , then ∀X ⊆ X1 , X2 cannot ( ε , δ) cover X . Lemma 6 and corollary 2 reduce the number of pattern pairs , for which the ε cover probability needs to be computed . The complete proofs of lemma 5 , lemma 6 and corollary 2 are stated in [ 25 ] . 4.3 APM Algorithm
The overall framework of our APM algorithm is shown in Algorithm 1 . From line 3 to line 9 , we find the cover set for each pseudo probabilistic frequent pattern X2 in ˆF . The most important step is to check whether X2 covers X1 in F ( line 6 ) . The details of the function isCover is illustrated in Algorithm 2 , where lines 1 − 3 implement the optimization stated by Lemma 6 , and lines 4−6 apply the Corollary 2 . Finally , from line 7 to line 12 , we use the approximation based scheme to compute the ε cover probability . As mentioned before , the function setCover in Algorithm 1 is solved using the greedy algorithm in [ 22 ] . 5 . APPROXIMATION OF JOINT SUPPORT
PROBABILITY
In this section , we present the detailed proof of the bivariate normal distribution based approximation of the joint support probability of two patterns . Given an uncertain database D , two patterns X1 and X2 , st X1 ⊆ X2 , and the
Algorithm 1 APM Algorithm Framework Input : D , F , ˆF , ε and δ Output : Minimal P RFP Set R 1 : R ← Φ 2 : CoverSets ← Φ 3 : for all X2 ∈ ˆF do 4 : N oCoverSet ← Φ 5 : 6 : 7 : 8 : N oCoverSet.add(X1 ) 9 : 10 : R = setCover(CoverSets , F ) 11 : return R for all X1 ∈ F such that X1 ⊆ X2 do if isCover(X1 , X2 ) = T rue then
CoverSets[X2].add(X1 ) else
F alse if X ⊆ X1 then return T rue if X ⊇ X1 then return F alse
Algorithm 2 Function isCover Input : X1 , X2 , Output : If X2 ( ε , δ) covers X1 , then return T rue , else 1 : for all X ∈ CoverSets[X2 ] do 2 : 3 : 4 : for all X ∈ N oCoverSet[X2 ] do 5 : 6 : 7 : l1 = max{minsup , μ1 − 3σ1} 8 : l2 = min{|D(X1)| , μ1 + 3σ1} 9 : k1 = max{(1 − ε)lff , μ2 − 3σ2} 10 : k2 = min{l , μ2 + 3σ2} 11 : for l = l1 to l2 do 12 : 13 : 14 : 15 : 16 : return F alse for k = k1 to k2 do Pcover+ = Pr(Supp(X1 ) = l , Supp(X2 ) = k ) if Pcover ≥ δ then return T rue corresponding support random variables , denoted as Xn(1 ) and Xn(2 ) hereafter , where n is the size of D , our goal is to prove that [ Xn(1 ) Xn(2 ) ]T converges to a bivariate normal distribution when n → ∞ . 5.1 Preparation
Suppose the existence probabilities of patterns X1 and X2 in the ith transaction ti are pni(1 ) and pni(2 ) , then fi
'
∼ Bern
Xni(j ) pni(j )
, j = 1 , 2 because Xni(j ) follows Bernoulli distribution .
The support of pattern Xj , Xn(j ) , can be computed as i=1 Xni(j ) , j = 1 , 2 . Since both Xn(1 ) and Xn(2 ) Xn(j ) = follow Poisson binomial distribution , the mean value and variance of Xn(j ) are n . fi
'
1 − pni(j )
, j = 1 , 2 n n . fi
μn(j ) = pni(j ) , i=1
2 n(j ) =
σ pni(j ) i=1
The covariance of Xn(1 ) and Xn(2 ) is
'
N .
N .
Cov
Xn(1 ) , Xn(2 )
=
Cov(Xni(1 ) , Xni(2 ) ) i=1 j=1
531 Situation
X1 . ti , X2 . ti X1 ⊆ ti , X2 . ti X1 ⊆ ti , X2 ⊆ ti
Probability
1 − pni(1 ) − pni(2 ) pni(1 ) pni(2 )
Table 3 : All possible situations of X1 and X2 in ti .
Table 3 illustrates all possible existence situations of patterns X1 and X2 in transaction ti . Assuming for any i and j such that i = j , Xni(1 ) and Xnj(2 ) are indepen' dent , we have Cov(Xni(1 ) , Xnj(2 ) ) = 0 . Table 3 indicates N fi · Xni(2 ) ) =p ni(2 ) and Cov T
1 − pni(1 ) that E(Xni(1 )
Xn(1 ) , Xn(2 ) fifi
' ff pni(2 )
' i=1
=
For brevity , let Xni =
Xni(1 ) Xni(2 ) and denote the sum of Xni over database as n . ff
T
Xn =
( 11 ) Then , {Xn} , n = 1 , 2,··· is a sequence of random vectors :
Xn(1 ) Xn(2 )
Xni = i=1
X1 = X11 X2 = X21 + X22
···
···
Xk = Xk1 + Xk2 + Xk3 + ··· + Xkk
{Xni} is called a triangular array , which is manipulated commonly in the study of sum of independent vectors . Until now , we have laid the groundwork in preparation of the proof that {Xn} holds asymptotic normality in the next subsection . 5.2 Proof of Approximation
With the aforementioned concepts , we propose the following theorem , from which Theorem 1 can be induced directly . Theorem 2 . Let {Xni ∈ R2} , n = 1 , 2,··· , i = 1 , 2,··· , n be a triangular array of random vectors such that : ( 1 ) for all n ≥ 1 , Xn1,··· , Xnn are independent , ( 2 ) for all 1 ≤ n i ≤ n , Xni follows a bivariate Bernoulli distribution , Xn = i=1 Xni , then
− 1 n ( Xn − µn )
2
Σ d→ N(0 , I )
( 12 ) where µn and Σn are the mean nd covariance of Xn , respectively .
Theorem 2 provides an important bridge between the joint support distribution of a pair of patterns and the bivariate normal distribution . Noting that suppose the cumulative d→ X if density functions of Xn and X are Fn and F , Xn and only if for any continuous point x of F , limn→∞ Fn(x ) = F ( x ) . Before giving the detailed proof of theorem 2 , two necessary lemmas should be presented first .
Lemma 7 . Let Xni ∈ Rmi , i = 1,··· , kn , be independent random vectors with mi ≤ m ( a fixed integer ) , n = 1 , 2,··· , kn → ∞ as n → ∞ , and inf i,n λmin[Cov(Xni ) ] > 0 , where λmin[A ] is the smallest eigenvalue of A . Let cni ∈ Rmi be vectors such that
(
) kn max1≤i≤kn cni2 i=1 cni2 lim n→∞
= 0
( 13 )
If supi,n EXni2+δ < ∞ for some δ > 0 , then d→ N(0 , I ) ff1/2 ni(Xni − EXni ) kn kn i=1 cT i=1 Cov(cT niXni )
( 14 )
More details of lemma 7 are stated in [ 23 ] . Given a sequence of random vectors {Xn} , Lemma 7 provides a solution to prove the convergence of all possible linear combinations of {Xn} . Nevertheless , it is not equivalent to the convergence of the random vector itself . Hence , we refer to the next lemma to bridge the gap .
Lemma 8
( Cram´er Wold Theorem[26] ) . Suppose that d→ X
Xn and X are k dimensional random vectors . Then Xn if and only if d→ t
T
X
( 15 ) for all vectors t ∈ Rk .
T t
Xn
The Cram´er Wold theorem states that the convergence of a k dimensional random vector is closely related to the totality of its one dimensional projections . With lemma 7 and lemma 8 , the complete proof of theorem 2 is as follows . Proof of theorem 2 . Let kn = n , and ∀i , 1 ≤ i ≤ n , mi = 2 .
The determinant of covariance matrix is det[Cov(Xni ) ] = ( 1 − ρ)σ
2 ni(1 ) σ
2 ni(2 )
( 16 )
Considering that X1 and X2 are two patterns with different parameters , the correlation coefficient between their support distribution satisfies 0 < ρ < 1 . Consequently , Cov(Xni ) is a positive definite matrix and inf i,n λmin[Cov(Xni ) ] > 0 .
'2 Let δ = 2 , since all components of Xni are no greater than Xni4 4 ≤ ∞ ( 17 ) For all i = 1 , 2,··· , n , assume cni = ffl fl2 ≤ 4n ff ffi ffi c1 , c2 ∈ R . Then , the size of database n , we have fifi
, where
'2
T
Xni(1 )
Xni(2 ) ffl fi c2 c1
=
+ lim n→∞ n max1≤i≤n cni2 i=1 cni2 kn kn i=1 cT i=1 Cov(cT niXni )
Therefore , lemma 7 indicates that ff 1 ni(Xni − EXni )
= lim n→∞
= 0
1 n d→ N(0 , I )
2
With lemma 8 , finally we have − 1 n ( Xn − µn ) Σ
2 d→ X
To further improve the accuracy of our approximation , we should take the continuity correction [ 24 ] into account , because we are using a continuous distribution to approximate a discrete distribution . The final equation needs to be changed slightly as follows .
Pr ( Supp(X1 ) =l , Supp(X2 ) = k ) ≈ φ ff
T l k
, µ is the vector of mean values of where X = Supp(X1 ) and Supp(X2 ) , and Σ is the corresponding covariance matrix . Since theorem 2 is equivalent to theorem 1 , it is served as a solid theoretical background to support our algorithm . We will demonstrate the empirical proof and assess our approach subsequently .
(
)
X + 0.5 − µ
|Σ|
532 6 . PERFORMANCE STUDY
In this section , we first empirically study the performance of the joint support probability approximation , then evaluate the effectiveness and efficiency of the APM algorithm . 6.1 Empirical study of approximation
We evaluate the accuracy of the approximation of joint support probability with simulation . Two probability support vectors of a pattern X1 and its super pattern X2 are constructed from a synthetic uncertain database with N = 100 , 200,··· , 1000 transactions . The uncertainty is incorporated according to the standard normal distribution . Then , we perform both the exact and approximate algorithms to obtain all joint support probability on the sample space .
For each setting of N , we run the experiment for 500 times . Figure 1 ( a ) shows the average and maximum absolute error ( eg , |Pra(x , y ) − Pre(x , y)| , where Pra and Pre are the approximate and exact probability ) wrt the variation of the database size . Figure 1 ( b ) demonstrates the average , minimum and maximum error ( eg , Pra(x , y ) − Pre(x , y ) ) between the real and approximate value wrt the variation of the database size . It is shown that the error decreases rapidly when N is increasing . When N = 500 , which is much less than the size of a regular database , the average absolute error is less than 10
−7 .
Figure 1 : Empirical proof of approximation .
6.2 Result analysis
621 Data sets
Three datasets have been used in our experiments . Two of them , the Retail dataset and the Chess dataset , are from the Frequent Itemset Mining(FIMI ) Dataset Repository 1 . These are standard datasets used for frequent pattern mining in deterministic databases . In order to bring uncertainty into the datasets , we synthesize an existential probability for each item based on a Gaussian distribution with the mean of 0.9 and the variance of 0125 The two datasets are uncertain databases with uncertainties associated with attributes . The other one is the iceberg sighting record from 1993 to 1997 on the North Atlantic from the International Ice Patrol ( IIP ) Iceberg Sightings Database 2 . Each transaction in the database contains the information of date , location , size , shape , reporting source and a confidence level . There are 1http://fimicshelsinkifi/data/ 2http://nsidcorg/data/g00807html
Dataset #Transactions #Items Avg . Length
IIP
Retail Chess
35161 88162 3196
467
16470
75
4.0 10.3 6.7
Table 4 : Statistics of Datasets . six possible attributes of the confidence level , R/V(Radar and visual ) , R(Radar only ) , V(Visual ) , MEA(Measured ) , EST(Estimated ) and GBL(Garbled ) , which indicate different reliabilities . We convert the confidence levels to probabilities 0.8 , 0.7 , 0.6 , 0.5 , 0.4 and 0.3 , respectively . This dataset forms an uncertain database that associates uncertainties to tuples . The statistics of the datasets are shown in Table 4 .
622 Performance of APM algorithm
To analyze the performance of the APM algorithm , we carry out two sets of experiments . In the first set , we compare the effectiveness and efficiency of the APM against the dynamic programming based exact method [ 25 ] . Due to the low efficiency of the exact method , we randomly select 500 transactions respectively from two datasets , Retail and IIP . The sizes of F P the set of probabilistic frequent patterns , DP the set of P RFPs mined by the dynamic programming based approach , and AP M the set of PRFPs produced by the APM algorithm with respect to the variations of minsup , minprob , ε and δ , on the two datasets are shown respectively in Figures 2 and 3 . The default values of the four parameters are set to 0.5 % , 0.8 , 0.2 and 0.5 , respectively . It can be observed that the result of the APM algorithm is very close to that of the exact method , while both of them are able to reduce the size of the probabilistic frequent pattern set effectively . The runtime of two methods are demonstrated in Figures 4 and 5 . It is impressive that the APM algorithm accelerates P RFP mining significantly . Then , we examine the performance of the APM algorithm on the complete database of IIP , Retail , and Chess datasets . The comparisons between the number of P RFPs and the number of frequent patterns are illustrated in Figures 6 , 7 and 8 . These charts indicate that the APM algorithm can reduce the size of frequent pattern set effectively . Figures 9 , 10 and 11 show the runtime vs . minsup , minprob , ε , and δ curves of the APM algorithm without and with the 3σ pruning technique , which are called AP M and AP M +P runing , on the three datasets , respectively . The default values of the four parameters for the IIP and Retail datasets are 0.5 % , 0.8 , 0.2 , and 05 For the chess dataset , the default parameters are 0.6 % , 0.5 , 0.15 , and 08 It is intuitive that , when ε is increasing or minsup , minprob and δ are decreasing , the runtime will increase because more pattern pairs are engaged in the cover probability checking . We can find that the APM algorithm can mine P RFP set quickly , and the pruning technique accelerates it even further .
7 . CONCLUSIONS
Due to the downward closure property , the number of probabilistic frequent patterns mined over uncertain data can be so large that they hinder further analysis and exploitation . This paper proposes the APM algorithm , which aims to efficiently and effectively find a small set of patterns to represent the complete set of probabilistic frequent patterns . To address the high computational complexity in examining the joint support probability , we introduce an
533 Figure 2 : The Number of P RFP on IIP 500 .
Figure 5 : Log Runtime on Retail 500 .
Figure 3 : The Number of P RFP on Retail 500 .
Figure 6 : The Number of P RFP on IIP .
Figure 4 : Log Runtime on IIP 500 . approximation of the joint support probability with both theoretical and empirical proofs . Our experimental results demonstrate that the devised algorithm can substantially reduce the size of probabilistic frequent patterns efficiently . This work adopts the measure defined in deterministic databases to quantify the distance between two patterns in terms of their supporting transactions . Since the supports of patterns are random variables in the context of uncertain data , other distance measures , such as Kullback Leibler divergence , might be applicable . As an ongoing work , we will study the effectiveness of probabilistic representative frequent patterns defined on different distance measures .
Figure 7 : The Number of P RFP on Retail .
8 . ACKNOWLEDGEMENTS
This work was supported , in part , by the Australian Research Council ( ARC ) Linkage Project under Grant No . LP120100566 .
9 . REFERENCES [ 1 ] Aggarwal , CC , Yu , PS : A survey of uncertain data algorithms and applications . IEEE Transactions on Knowledge and Data Engineering 21(5 ) ( 2009 ) 609–623
[ 2 ] Aggarwal , CC : Managing and mining uncertain data .
Springer ( 2009 )
534 Figure 8 : The Number of P RFP on Chess .
Figure 11 : Runtime on Chess .
[ 8 ] Tang , P . , Peterson , EA : Mining probabilistic frequent closed itemsets in uncertain databases . ASRC ( 2011 ) 86–91
[ 9 ] Tong , Y . , Chen , L . , Ding , B . : Discovering threshold based frequent closed itemsets over probabilistic data . ICDE ( 2012 ) 270–281
[ 10 ] Leung , C . , Mateo , M . , Brajczuk , D . : A tree based approach for frequent pattern mining from uncertain data . Advances in Knowledge Discovery and Data Mining ( 2008 ) 653–661
[ 11 ] Aggarwal , CC , Li , Y . , Wang , J . : Frequent pattern mining with uncertain data . SIGKDD ( 2009 ) 29–38
[ 12 ] Calders , T . , Garboni , C . , Goethals , B . :
Approximation of frequentness probability of itemsets in uncertain data . ICDE ( 2010 ) 749–754
[ 13 ] Wang , L . , Cheng , R . , Lee , SD , Cheung , D . :
Accelerating probabilistic frequent itemset mining : a model based approach . CIKM ( 2010 ) 429–438
[ 14 ] Bayardo Jr . , R . J . : Efficiently mining long patterns from databases . SIGMOD ( 1998 ) 85–93
[ 15 ] Pasquier , N . , Bastide , Y . , Taouil , R . , Lakhal , L . :
Discovering frequent closed itemsets for association rules . ICDT ( 1999 ) 398–416
[ 16 ] Calders , T . , Goethals , B . : Mining all non derivable frequent itemsets . PKDD ( 2002 ) 74–85
[ 17 ] Yan , X . , Cheng , H . , Han , J . , Xin , D . : Summarizing itemset patterns : a profile based approach . SIGKDD ( 2005 ) 314–323
[ 18 ] Jin , R . , Abu Ata , M . , Xiang , Y . , Ruan , N . : Effective and efficient itemset pattern summarization : regression based approaches . SIGKDD ( 2008 ) 399–407 [ 19 ] Poernomo , AK , Gopalkrishnan , V . : Cp summary : a concise representation for browsing frequent itemsets . SIGKDD ( 2009 ) 687–696
[ 20 ] Xin , D . , Han , J . , Yan , X . , Cheng , H . : Mining compressed frequent pattern sets . VLDB ( 2005 ) 709–720
[ 21 ] Liu , G . , Zhang , H . , Wong , L . : Finding minimum representative pattern sets . SIGKDD ( 2012 ) 51–59 [ 22 ] Chvatal , V . : A greedy heuristic for the set covering problem . Mathematics of operations research 4(3 ) ( 1979 ) 233–235
[ 23 ] Shao , J . : Mathematical Statistics . Springer ( 2003 ) [ 24 ] Cox , DR : The Continuity Correction . Biometrika
57(1 ) ( 1970 ) 217–219
[ 25 ] Liu , C . , Chen , L . , Zhang C . : Mining Probabilistic Representative Frequent Patterns From Uncertain Data . SDM ( 2013 ) 73–81
[ 26 ] Cram´er , H . , Wold , H . : Some theorems on distribution functions . The Journal of the London Mathematical Society 11 ( 1936 ) 290–295
Figure 9 : Runtime on IIP .
Figure 10 : Runtime on Retail .
[ 3 ] Chui , CK , Kao , B . , Hung , E . : Mining frequent itemsets from uncertain data . PAKDD ( 2007 ) 47–58 [ 4 ] Bernecker , T . , Kriegel , HP , Renz , M . , Verhein , F . , Zuefle , A . : Probabilistic frequent itemset mining in uncertain databases . SIGKDD ( 2009 ) 119–128
[ 5 ] Sun , L . , Cheng , R . , Cheung , DW , Cheng , J . : Mining uncertain data with probabilistic guarantees . SIGKDD ( 2010 ) 273–282
[ 6 ] Tong , Y . , Chen , L . , Cheng , Y . , Yu , PS : Mining frequent itemsets over uncertain databases . VLDB Endowment 5(11 ) ( 2012 ) 1650–1661
[ 7 ] Peterson , EA , Tang , P . : Fast approximation of probabilistic frequent closed itemsets . ASRC ( 2012 ) 214–219
535
