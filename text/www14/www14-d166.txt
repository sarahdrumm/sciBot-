Defending against User Identity Linkage Attack across Multiple Online Social Networks
Yilin Shen
Samsung Research America
75 West Plumiera Dr .
San Jose , CA 95134 , USA yilinshen@samsungcom
Fengjiao Wang∗
Hongxia Jin
Dept . of Computer Science
University of Illinois at Chicago
Samsung Research America
75 West Plumiera Dr .
Chicago , IL 60607 , USA fwang27@uic.edu
San Jose , CA 95134 , USA hongxiajin@sisasamsungcom
ABSTRACT We study the first countermeasure against user identity linkage attack across multiple online social networks ( OSNs ) . Our goal is to keep as much as user ’s information in public and meanwhile prevent their identities from being linked on different OSNs via k anonymity . We develop a novel greedy algorithm , incorporating an efficient manner to compute the greedy function , and validate it in terms of both solution quality and robustness using real world datasets .
Categories and Subject Descriptors F22 [ Analysis of Algorithms and Problem Complexity ] : Nonnumerical Algorithms and Problems
Keywords User Identity Linkage Attack , Countermeasure , Algorithm
1 .
INTRODUCTION
More and more Online Social Networks ( OSNs ) have emerged for various purposes . People provide specific profiles , interact with particular types of friends and join distinct groups on different OSNs . However , a person ’s multiple user identities can be easily linked by a practical User Identity Linkage Attack , leading to user privacy breach and put the users at risks unconsciously [ 2 ] . For instance , when the attacker links a user ’s two identities on Facebook and Linkedin , his/her professional connections on Linkedin are disclosed to the attacker , although they are not his/her friends on Facebook . More seriously , based on the integrated profile and inferred private information from the friends of the linked user , the attacker could create fake accounts pretending to be this person on social networks and then solicit others to connect , referred to as an alternative identity theft . Therefore , it is of great importance to prevent the user identity linkage across OSNs by malicious users beforehand . In this paper , we develop the first countermeasure framework against user identity linkage attack [ 1 ] across multiple OSNs , in which we formulate an optimization problem to study the trade off between user information sharing and ∗Fengjiao Wang contributed to this work during her internship with Samsung Research America .
Copyright is held by the author/owner(s ) . WWW’14 Companion , April 7–11 , 2014 , Seoul , Korea . ACM 978 1 4503 2745 9/14/04 . http://dxdoiorg/101145/25679482577208 user privacy via k anonymity . We devise an effective algorithm to solve this problem and validate its performance and robustness on real world datasets . 2 . PROPOSED COUNTERMEASURE
We propose a countermeasure aiming to defend against the user identity linkage ( UIL ) attack , which can smartly generate features merely based on user ’s public information , thereby only needs 0.5 % of user linkage information to accurately predict over 85 % other user identity linkages . Our countermeasure is applied to each user on OSN1 ( service OSN ) by smartly hide his information for preventing him from being linked to their identities on OSN2 ( auxiliary OSN ) .
Problem Definition :
In order to tackle the trade off between user information sharing and user privacy , we define an optimization problem , named PRivacy aware User iNformation sElection ( PRUNE ) problem as follows : Given a positive integer k , a user w associated with two identities w1 and w2 on OSN1 and OSN2 respectively , ie , w = ( w1 , w2 ) . The objective of PRUNE problem is to maximize user w ’s information visibility in OSN1(service OSN ) and achieve the k anonymity for user w between his identity w1 and all user identities V2 on OSN2 ( auxiliary OSN ) . More specifically , a user w achieves k anonymity if and only if there exist at least k − 1 users S ( identical users ) on OSN2 such that m(w1 , w2 ) ≤ m(w1 , u ) for any u ∈ S , i∈F βi(·,· ) is determined by Adaboost ( Decision Stump ) classifier on features due to its most serious consequence in UIL attack . Here βi(·,· ) is the summation of coefficients in Adaboost classifier for each feature . The maxi∈S vw i , i = 1 means that user w prefers to release infor where m(·,· ) = imization of user information visibility is to max in which vw mation i to public and 0 otherwise .
Resist User LinkagE ( RULE ) Algorithm : We design the RULE algorithm based on our observation that most of users on OSN2 are distinctive users , ie , they have βi(w1 , w2 ) ≥ βi(w1 , u ) for all features between themselves and user w . Therefore , our proposed RULE algorithm iteratively hides a feature i which maximizes
I(βi(w1 , w2 ) − βi(w1 , u))/vw i u∈V j
2
λ(i ) = where V j 2 is the set of non identical users on OSN2 after iteration j . The indicator variable I(x ) = 1 if x > 0 and 0 if x = 0 . In order to efficiently find the feature i with maximum λ(i ) in each iteration , we propose three priority queues with respect to the distinctive and non distinctive users on OSN2 i∈F I(βi(w1 , w2 ) − i∈F βi(w1 , w2)−βi(w1 , u ) ; and feature sets : the priority of Qd is βi(w1 , u) ) ; the priority of Qn is the priority of Qf is λ(i ) .
375 In each iteration , RULE algorithm ( Algorithm 1 ) picks the feature in Qf with highest priority and updates Qd and Qn after removing the selected feature . The algorithm terminates if the number of users in Qd with priority 0 plus the number of users in Qd with non positive priority is larger than or equal to k . Otherwise , if there are users in Qn converting to distinctive users , remove them from Qn and insert to Qd . In Qf , we recompute the feature with highest priority if some users in Qd becomes to identical users to w , ie , their priorities change to 0 . If its new priority is invalid , we remove it from Qf and insert into the existing order . The process terminates until there is a valid feature in Qf . Note that in most cases , we only need to compute once to update Qf and this increases the efficiency of our RULE algorithm .
Algorithm 1 : RULE Algorithm Input : βi(w1 , w2 ) , βi(w1 , · ) , vw Output : visible features S
1 S ← F ; 2 Construct priority queues Qd , Qn , Qf ; 3 D ← {u|priority(u ) = 0 , u ∈ Qd} ; 4 Remove D from Qd ; 5 N ← {u|priority(u ) ≤ 0 , u ∈ Qn} ; 6 while |D ∪ N| < k do
7
8
9
10
11
12
13
Hide feature i with highest priority in Qf ( S ← S \ {i} ) ; Update Qd and Qn after removing feature i ; Insert {u|u ∈ Qn , βi(w1 , w2 ) > βi(w1 , · ) ∀i ∈ F \ S} into Qd ; N ← {u|priority(u ) ≤ 0 , u ∈ Qn} ; D ← D ∪ {u|priority(u ) = 0 , u ∈ Qd} ; Remove D from Qd ; Update mini∈F\S λ(i ) in Qf until validation ; we discussed in the above section . As for the visibility parameters , wlog , we randomly select either 0 or 1 for each of the user ’s information . the optimal solution , provided via Integer Programming :
We compare the solution quality of RULE algorithm with st vw i xi i∈F[βi(w1 , w2 ) − βi(w1 , u)]xi ≤ Ω(1 − yu ) ∀u ∈ V2 u∈V2 yu ≥ k max i∈F xi , yu ∈ {0 , 1},∀i ∈ F , u ∈ V2 where xi = 1 if feature i of user w is visible and 0 otherwise ; yu = 1 if m(w1 , w2 ) ≤ m(w1 , u ) and 0 otherwise ; V2 is the set of users on OSN2 and Ω is a large enough constant . The objective is to maximize the user information visibility as described in problem definition . The first constraint ensures m(w1 , w2 ) ≤ m(w1 , u ) for each user u ∈ S in the k anonymity , ie , yu = 1 for u ∈ S . The second constraint guarantees the k anonymity . This IP formulation is implemented using the CPLEX optimization suite from ILOG .
Table 2 : Performance of RULE ( visibility(% ) )
Dataset
Service OSN1 Auxiliary OSN2
RULE Optimality
Twitter
Google+
Foursquare
Foursquare
Google+
Foursquare
Twitter Google+ Twitter
99.231 99.578 99.202 83.287 47.729 49.254
99.231 99.582 99.202 83.620 47.729 49.312
14 return S ;
The running time of RULE algorithm is O(|F|(|F| log |F| + |V2| log |V2| ) ) in the worst case . Note that a more careful implementation can reduce the running time to O(|F|(|F| + |V2| ) ) by maintaining Qd , Qn and Qf within time O(|F| ) and O(|V2| ) respectively . In addition , RULE algorithm achieves k anonymity of user w for any k > 0 .
We test our RULE algorithm on these six datasets , with different k values from 90 % to 100 % users on OSN2 . As shown in Table 2 , the visibility returned by RULE algorithm is at most 0.5 % smaller than optimal solution , and reaches optimality in 3 datasets . And the running time of RULE algorithm is consistently less than 10 seconds , which is up to 20 times faster than solving the IP formulation .
3 . EXPERIMENTAL RESULTS
Datasets : We collect data ( Table 1 ) from three of the most popular OSNs , Google+ , Twitter and Foursquare . Due to the infeasibility of collecting the information of all users in these OSNs , we consider the user identity linkage between ego users , ie , the users we have crawled their complete profile and neighborhood information . Then we link the ego users on these three OSNs using their public API functions . Finally , we link all neighborhood of ego users , including friends , followers and followees , between these three OSNs .
Table 1 : Dataset Statistics
User Types
Ego Users
OSNs
Linked Crossing
Users
Google+ Twitter
Foursquare Twitter,G+ Fsq,Twitter
G+,Fsq
258
48,100 5,709 258 5,709 153
Neighborhood
Followers
Followees
86,652
11,485,756
138,872 875,054
11,448,961
71,664
86,297
6,319,928 138,872 1,459,621 6,352,896
67,797
Performance & Robustness : For each pair of OSNs ( OSN1 and OSN2 ) , we consider each one of them as service OSN ( and the other as auxiliary OSN ) respectively , that is , we run our algorithm on OSN1 and OSN2 separately . Therefore , we will evaluate the proposed algorithm on six datasets . In terms of the inputs , matching function is derived from UIL attack with Adaboost ( Decision Stump ) as
Figure 1 : Robustness of RULE
Figure 1 shows the robustness of RULE algorithm by measuring anonymity level with respect to different classifiers ( service OSN > auxiliary OSN ) . As this anonymity level remains consistently larger than 40 % , the application of our countermeasure can still anonymize a user with at least other 36 % users on average as we select k between 90 % and 100 % of all users in our experiments .
4 . REFERENCES [ 1 ] L . Bilge , T . Strufe , D . Balzarotti , and E . Kirda . All your contacts are belong to us : automated identity theft attacks on social networks . In Proceedings of WWW ’09 , pages 551–560 , 2009 .
[ 2 ] D . Irani , S . Webb , K . Li , and C . Pu . Large online social footprints–an emerging threat . In Proceedings of CSE ’09 , pages 271–276 , Washington , DC , USA , 2009 .
0 20 40 60 80 100AdaboostDecision TreeNaive BayesSVMAnonymity Level(%)ClassifierGoogle+>TwitterTwitter>Google+Foursquare>TwitterTwitter>FoursquareGoogle+>FoursquareFoursquare>Google+376
