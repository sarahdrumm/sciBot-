Timeline Generation : Tracking individuals on Twitter
∗ Jiwei Li
School of Computer Science Carnegie Mellon University
Pittsburgh , PA 15213 bdlijiwei@gmail.com
† Claire Cardie
Department of Computer Science
Cornell University Ithaca , NY 14850 cardie@cscornelledu
3 1 0 2 p e S 7 2
] I S . s c [
1 v 3 1 3 7
.
9 0 3 1 : v i X r a
ABSTRACT We have always been eager to keep track of what happened people we are interested in . For example , businessmen wish to know the background of his competitors , fans wish getting the first time news about their favorite movie stars or athletes . However timeline generation , for individuals , especially ordinary individuals ( not celebrities ) , still remains an open problem due to the lack of available data . Twitter , where users report real time events in their daily lives , serves as a potentially important source for this task . In this paper , we explore the task of individual timeline generation from twitter and try to create of a chronological list of personal important events ( PIE ) of individuals based on the tweets one published . By analyzing individual tweet collection , we find that what are suitable for inclusion in the personal timeline should be tweets talking about personal ( opposite to public ) and timespecific ( time general ) topics . To further extract these types of topics , we introduce a non parametric model , named Dirichlet Process mixture model ( DPM ) to recognize four types of tweets : personal time specific ( PersonTS ) , personal time general ( PersonTG ) , public time specific ( PublicTS ) and public time general ( PublicTG ) topics , which , in turn , are used for further personal event extraction and timeline generation . For evaluation , we build up a new golden standard Timelines based on Twitter and Wikipedia that contain PIE related events from 20 ordinary twitter users and 20 celebrities . Experiments on real Twitter data quantitatively demonstrate the effectiveness of our method .
Categories and Subject Descriptors H.0 [ Information Systems ] : General
General Terms Algorithm , Performance , Experimentation ∗Dr . Trovato insisted his name be first . †The secretary disavows any knowledge of this author ’s actions .
Keywords Event extraction , Individual Timeline Generation , Dirichlet Process , Twitter
1 .
INTRODUCTION
We have always been eager to keep track of people we are interested in . Businessmen want to know the past of his competitors to exactly know who he is competing with . Employees want to get access to what happened to their boss , so then can behave in a much properer way . More generally , fans , especially young people , are always crazy about getting the first time news about their favorite movie stars or athletes . To date , however , building a detailed chronological list or table of key events in the lives of individual remains largely a manual task . Existing automatic techniques for personal event identification , for example , rely on documents produced via a web search on the person ’s name [ 1 , 6 , 12 , 31 ] . The web search based approaches not only suffers from the failure to include important information neglected by the online media , but more importantly , are restricted to celebrities , whose information is collected by online media , and can never be applied to ordinary individuals .
Fortunately , Twitter1 , a popular social network , serves as an alternative , and potentially very rich , source of information for this task : people usually publish tweets describing their lives in detail or chat with friends on twitter . Figures 1 and 2 give examples of users talking about what happened to them on twitter . The first one corresponds to a NBA basketball player , Dwight Howard2 tweets about being signed by basketball franchise Houston Rockets and the other one corresponds to an ordinary twitter user , recording her being accepted by Harvard University on twitter . In particular , we know of no previous work that exploits Twitter to track events in the lives of individuals .
To do so , we have to answer the following question : what types of events reported on Twitter by an individual should be regarded as personal , important events ( PIE ) and , thus , be suitable for inclusion in the event timeline of an individual ? In the current work , we specify three criteria for PIE extraction . First , each PIE should be an important event , an event that is made multiple references by an individual and his or her followers . Second , each PIE should be a time specific event — a unique ( rather than a general , recurring ) event that is delineated by specific start and end points . Consider , for instance , the twitter user in Figure 2 , she frequently published tweets about being accepted by Harvard only when receiving acceptance letter . As a result , these tweets refer to a time specific PIE . In contrast , her exercise regime , about which she tweets reg
1https://twitter.com/ 2https://twitter.com/DwightHoward public personal time specific time general PublicTG PersonTG Table 1 : Types of tweets on Twitter
PublicTS PersonTS for Barack Obama and Mitt Romney .
Given the above criteria , we aim to characterize tweets into one of four event types : public time specific ( PublicTS ) , public timegeneral ( PublicTG ) , personal time specific ( PersonTS ) and personal time general ( PersonTG ) , as shown in Table 1 . In doing so , we can then identify PIEs related events based on the following criterion :
1 . For an ordinary twitter user , the PIEs would be his or here Per sonTS events .
2 . For a celerity , the PIEs would be PersonTS events along with his or her celebrity related PublicTS events .
Topic extraction ( both local and global ) on twitter is not a new task . Among existing approaches , Bayesian topic models such as LDA[3 ] , LabeledLDA[24 ] and HDP[29 ] have widely been used in topic mining task in twitter due to the ability of mining latent topics hidden in tweet dataset[7 , 9 , 13 , 18 , 20 , 23 , 25 , 35 ] . Topic models provide a principled way to discover the topics hidden in a text collection and seems well suited for our personal information analysis task .
Based on topic approaches , in this paper , we introduce a nonparametric topic model , named multi level Dirichlet Process Mixture Model ( DPM ) to identify tweets associated with the PublicTS , PublicTG , PersonTS and PersonTG events of individual Twitter users by modeling the combination of temporal information ( to distinguish time specific from time general events ) and user information ( to distinguish public from private events ) in the joint Twitter feed . The point of DP mixture model is to allow components ( or topics ) shared across corpus while the specific level ( i.e user and time ) information would be emphasized . Further based on topic distribution from DPM model , we characterize events ( topics ) according to criterion mentioned above and select the tweet that best represents each PIE topics into timeline .
To evaluate our approach , we manually generate gold standard PIE timelines . Since criteria for ordinary twitter users and celerities are a little bit different ( whether related PublicTS should be considered ) , we generate two PIE timelines , one for ordinary twitter users called T witSet−O and the other called T witSet−C for celebrity twitter users , both of which include 20 people from their respective Twitter stream . The PIE timelines cover a 21 month interval during 2011 2013 . For celerities , in addition to Twitter stream , we also generate golden standard timeline W ikiSet− C according to Wikipedia entries . In sum , this research makes the following main contributions : • We create golden standard timelines that contain PIEs for famous twitter users and ordinary twitter users based on Twitter stream and Wikipedia ( Detail see Section 52 ) To the best of our knowledge , our dataset is the first golden standard for personal event extraction or timeline generation in Twitter .
• We introduce a non parametric algorithm based on Dirichlet Process for individual timeline generation on Twitter stream . The performance of our approach outputs multiple baselines . It can be extended to any individual , ( eg friend , competitor or movie star ) , if only he or she has a twitter account .
The remainder of this paper is organized as follows : Section 2 briefly introduces Dirichlet Processes and Hierarchical Dirichlet Processes . Section 4 presents algorithm for timeline generation and
Figure 1 : Example of PIE for for basketball star Dwight Howard . Tweet labeled in red : PIE about Dwight joining Houston Rocket
Figure 2 : Example of PIE for an ordinary twitter user . Tweet labeled in red : PIE about getting accepted by Harvard University . ularly ( eg “ 11.5 km bike ride ? , “ 15 mins Yoga stretch? ) , is not considered a PIE — it is more of a general interest .
Third , the PIEs identified for an individual should be personal events ( ie an event of interest to himself or to his followers ) rather than events of interest to the general public . For instance , most people pay attention to and discuss about public events such as “ the US election" . For an ordinary person , we do not want “ the US election" to be identified as a PIE no matter how frequently he or she tweets about it ; it remains a public event , not a personal one . However , things become a bit complicated because of the public nature of stardom : sometimes an otherwise public event can constitute PIE for the celebrity — eg “ the US election" should not be treated as a PIE for ordinary individuals , but be treated as a PIE
Section 5 describes our dataset and creation of Gold standard timelines . Section 6 presents the experimental results . Section 7 briefly discusses related work and we conclude this paper in Section 8 .
2 . DP AND HDP
In this section , we briefly introduce DP and HDP . Dirichlet Process(DP ) can be considered as a distribution over distributions [ 8 ] . A DP denoted by DP ( α , G0 ) is parameterized by a base measure G0 and a concentration parameter α . We write G ∼ DP ( α , G0 ) for a draw of distribution G from the Dirichlet process . Sethuraman [ 28 ] showed that a measure G drawn from a DP is discrete by the following stick breaking construction .
{φk}∞ k=1 ∼ G0 , π ∼ GEM ( α ) , G =
πkδφk
( 1 )
∞ k=1
The discrete set of atoms {φk}∞ k=1 are drawn from the base measure G0 . δφk is the probability measure concentrated at φk . GEM(α ) refers the following process : k−1
ˆπk ∼ Beta(1 , α ) , πk = ˆπk
( 1 − ˆπi )
( 2 ) i=1
We successively draw θ1 , θ2 , from measure G . Let mk denotes the number of draws that takes the value φk . After observing draws θ1 , , θn−1 from G , the posterior of G is still a DP shown as follows :
G|θ1 , , θn−1 ∼ DP ( α0 + n − 1 , mkδφk+α0G0 α0 + n − 1
)
( 3 )
HDP uses multiple DP s to model multiple correlated corpora . In HDP , a global measure is drawn from base measure H . Each document d is associated with a document specific measure Gd which is drawn from global measure G0 . Such process can be summarized as follows :
G0 ∼ DP ( α , H ) Gd|G0 , γ ∼ DP ( γ , G0 )
( 4 )
Given Gj , words w within document d are drawn from the following mixture model :
{θw} ∼ Gd , w ∼ M ulti(w|θw )
G0 has the form G0 = ∞
Eq ( 4 ) and Eq ( 5 ) together define the HDP . And according to Eq ( 1 ) , k=1 βkδφk , where φk ∼ H , β ∼
( 5 )
GEM ( α ) . Then Gd can be constructed as
Gd ∼
πdkδφk , φj|β , γ ∼ DP ( γ , β )
( 6 ) k=1
Figure 3 : Graphical model of ( a ) DP and ( b ) HDP
3 . DPM MODEL
In this section , we get down to the details of DPM model . Suppose that we collect tweets from I users . Each user ’s tweet stream is segmented into T time periods . Here , each time period denotes a week . St j=1 denotes the collection of tweets that user i publishes , retweets or is @ed during epoch t . Each tweet v is comprised of a series of words v = {wi}nv i=1 where nv denotes the i denotes the tweet number of words in current tweet . Si = i = {vt ij}j=nt i t St
∞ collection published by user i and St = i St i denotes the tweet collection published at time epoch t . V is the vocabulary size . 3.1 DPM Model
In DPM , each tweet v is associated with parameter xv yv , zv , respectively denoting whether it is Public or Personal , whether it is time general or time specific and its topic3 . We use 4 different kinds of measures , which can be interpreted as different distribution over topics , to model the four different types of tweets according to their x and y value . Each measure presents unique distribution over topics .
Suppose that v is published by user i at time t . xv and yv conform to the binomial distribution with parameter πi y , which can be interpreted as a user ’s preference for publishing tweets about personal or pubic information , time general or time specific information . xv and yv conform to the binomial distribution πi x and y ∼ x ∼ Beta(ηx ) , πt y with a Beta prior ηx and ηy , where πi πt Beta(ηy ) . x and πi y=0 y=1 x=0 x=1
PublicTG PublicTS PersonTG PersonTS
Table 2 : Tweet type according to x ( public or personal ) and y ( time general or time specific )
The key of DPM model is how to model different measures ( or topic distribution ) over topics with regard to user and time information ( different value of x and y ) . Our intuitive idea is as shown in Figure 4 . There is a global measure G0 , which is drawn from base measure H . G0 is the measure over topics that any user at any time can talk about . A PublicTG topic ( x=0 , y=0 ) would be directly drawn from G0 ( also written as G(0,0) ) . For each time t , there is a time specific measure Gt ( also written as G(0,1 ) ) that describes topics discussed just at that time . Gt is drawn from the global measure G0 . Similarly , from each user i , a user specific Gi measure ( also written as G(1,0 ) ) is drawn from G0 . Further , Personal timesepcific topic measure Gt i ( G(1,1 ) ) is drawn from Gi . As we can see , all tweets from all users across all time epics share the same infinite set of mixing components ( or topics ) . The difference lies in the mixing weights in the four types of measure G0 , Gt , Gi and i . The whole point of DP mixture model is to allow sharing comGt ponents across corpus while the specific level ( i.e user and time ) of information can be emphasized . The plate diagram and generative story are illustrated in Figures 4 and 5 . α , γ , µ and κ are hyperparameters for Dirichlet Processes .
Figure 4 : Graphical illustration of DPM model .
3We follow the work of Grubber et al.,(2007 ) and assume that all words in a tweet are generated by a same topic .
• Draw PublicTG measure G0 ∼ DP ( α , H ) . • For each time t – draw PublicTS measure Gt ∼ DP ( γ , G0 ) . • For each user i – draw πi – draw πi – draw PersonTG measure Gi ∼ DP ( µ , G0 ) . – for each time t : x ∼ Beta(ηx ) y ∼ Beta(ηy )
∗ draw PersonTS measure Gt • for each tweet v , from user i , at time t i ∼ DP ( κ , Gi ) x ) , yv ∼ M ulti(πi y )
– draw xv ∼ M ulti(πi – if x=0 , y=0 : draw zv ∼ G0 – if x=1 , y=0 : draw zv ∼ Gt – if x=0 , y=1 : draw zv ∼ Gi – if x=1 , y=1 : draw zv ∼ Gt – for each word w ∈ v ∗ draw w ∼ M ulti(zv ) i
Figure 5 : Generative Story of DPM model
3.2 Stick breaking Construction
( 7 )
( 8 )
( 9 )
∞ k=1
∞ ∞ k=1 k=1
∞
According to the stick breaking construction in Eq ( 1 ) of DP , we can write the explicit form of G0 , Gi,Gt,Gt i as follows :
G0 = rkδφk , r ∼ GEM ( α )
Consequently , according to Eq ( 4 ) Gi and Gt have the form :
Gt =
Gi = t δφk , ψt ∼ DP ( γ , r ) ψk
βk i δφk ,
βi ∼ DP ( µ , r )
Similarly , we can also write the form of Gt i as
Gt i = itδφk , πit ∼ DP ( κ , βi ) πk k=1
In this way , we obtain the stick breaking construction for DPM . According to this perspective , DPM provides a prior where G0 , Gi,Gt and Gt i of all corpora at all times from all users share the same infinite topic mixture {φk}∞ 3.3
Inference k=1 .
In this subsection , we use Gibbs Sampling based on MCMC combined with Chinese Restaurant Franchise metaphor . Due to the space limit , we skip the mathematical deduction part for the sampler , the details of which can be found in Teh et al ’s work [ 29 ] . We first briefly go over Chinese restaurant metaphor for multilevel DP . A corpus is called a restaurant and each topic is compared a dish . Each restaurant is comprised of a series of tables and each table is associated with a dish . The interpretation for measure G in the metaphor is the dish menu denoting the list of topics served at specific restaurant . Each tweet is compared to a customer and when he comes into a restaurant , he would choose a table and shares the dish served at that table .
Sampling r : What are drawn from global measure G =∞ with dish k as Mk and the total number of tables as M• = are the dishes for customers ( tweets ) labeled with ( x=0 , y=0 ) for any user across all time epoches . We denote the number of tables k Mk . As G ∼ DP ( α , H ) . Assume we already know {Mk} , according k=1 rkδφk
H +∞ to Eq ( 3 ) , the posterior of G is denoted as follows :
G0|α , H,{Mk} ∼ DP ( α + M• , k=1 Mkδφk
α + M•
)
( 10 )
K is the number of distinct dishes appeared . Dir( ) denotes the Dirichlet distribution . G0 can be further represented as
G0 = rkδφk + ruGu ,
Gr ∼ DP ( α , H )
( 11 )
K k=1
( 12 ) r = ( r1 , r2 , , rK , ru ) ∼ Dir(M1 , M2 , , MK , α ) This augmented representation reformulates original infinite vector r to an equivalent vector with finite length of K + 1 vector . r is sampled from the Dirichlet distribution shown in Eq ( 12 ) . Sampling ψt , βi , πit : Fraction parameters can be sampled in the similar way as r . It is worth noting that due to the specific regulatory framework for each user and time , the posterior distribution for Gt , Gi and Gt i would be calculated by just counting the number of tables in correspondent user , or time , or user and time . Take βi for example : as βi ∼ DP ( γ , r ) , and assuming we have count variable {T k i denotes the number of tables with topic k in user i ’s tweet corpus , the posterior for βt is also a DP . i + γ· rK , γ· ru ) ( 13 ) ( β1 i , , βK Sample zv : Given the value of xv and yv , we directly sample zv i + γ· r1 , , T K i } , where T k i ) ∼ Dir(T 1 i , βu according to its correspondent measure Gxv ,yv . P r(zv = k|xv , yv , w ) ∝ P r(v|xv , yv , zv = k , w ) · P ( z = k|Gx,y ) ( 14 ) The first part P r(v|xv , yv , zv , w ) is the probability that tweet v is generated by topic z , which would be described in Appendix A and the second part denotes the probability that dish z select from Gxv ,yv is as follows :
 t ( if x = 0 , y = 1 ) rk ( if x = 0 , y = 0 ) ψk βk i ( if x = 1 , y = 0 ) πk i,t ( if x = 1 , y = 1 )
( 15 )
P r(zv = k|Gxv ,yv ) =
Sampling Mk , T k i : Table number Mk , T k i at different levels ( global , user or time ) of restaurants would be sampled from Chinese Restaurant Process ( CRP ) in Teh et al . ’s work [ 29 ] . The detail are not to be described here .
Sampling x and y
P r(xv = x|X−v , v , y ) ∝ E(x,y ) E(·,y ) i
+ ηx
+ 2ηx i
P ( v|xv , yv , zv = k ) · P ( z = k|Gx,y )
P r(yv = y|Y−v , v , x ) ∝ E(x,y ) E(x,· ) i
+ ηy
+ 2ηy
× t
P ( v|xv , yv , zv = k , w ) · P ( z = k|Gx,y ) i where E(x,y ) denotes the number of tweets published by user i with label ( x,y ) , and M ( ·,y ) denotes number of tweets labeled as y by summing over x . The first part for Eqns ( 16 ) and ( 17 ) can be interpreted as the user ’s preference for publishing different types of tweets while the second part is the probability that current tweet i
× z∈Gx,y
× z∈Gx,y
( 16 )
( 17 ) is generated by the measure by integrating out parameter topic z within that measure .
In our experiments , we set hyperparameters ηx = ηy = 20 . The sampling for hyperparameters α , γ , µ and κ are the same as that in Teh et al ’s work [ 29 ] by putting a vague gamma function prior on them . We run 200 burn in iterations through all tweets to stabilize the distribution of different parameters before collecting samples .
4 . TIMELINE GENERATION sonTS topics for user i , we have Pi =
In this section , we describe how the individual timeline is generated based on DPM model . Let Pi denote the collection of Peri . The basic idea for timeline generation is we select one tweet that best represents each PIE topic and put it into timeline . 4.1 Topic Merging t Gt
Topics mined from topic models can be correlated[14 ] , and sometimes can be really similar with each another . The correlated topics would have little negative influence in most applications , but will definitely result in timeline redundancy in our task . To deal with this problem , we use the hierarchical agglomerative clustering algorithm that merges step by step the current pair of mutually closest topics into a new topic until the stop condition is achieved . The distance between two components in agglomerative clustering are calculated based on Kullback Leibler ( KL ) divergence divergence . The KL divergence between two topics L1 and L2 and two tweets v1 and v2 as follows :
KL(L1||L2 ) =
KL(v1||v2 ) = p(w|L1 ) log p(v1|L ) log p(w|L1 ) p(w|L2 ) p(v1|L ) p(v2|L ) w
L∈Pi
The key point for agglomerative clustering in our task is the stop condition for the agglomerating process that would present us the best PIE topics for each user . Here , we take the stop condition introduced by Jung et al.[11 ] that tries to seeking the global minimum of clustering balance ε :
ε(χ ) = Λ(χ ) + Ω(χ )
( 19 ) where Λ and Ω denote intra cluster and inter cluster error sums for a specific clustering configuration χ . In our case , KL(v||CL )
Λ(Pi ) =
( 20 ) average of its containing tweets CL =
L∈Pi v∈L where CL denotes the center of topic L and is represented as the v∈L v/|L| .
Ω(Pi ) =
KL(L||CPi )
( 21 )
L∈Pi
L∈Pi where CPi can be treated as the center of all topics in Pi , where L/|Pi| . The agglomerate clustering algorithm is shown in Figure 10 where we try to find the clustering configuration χ with minimum value of clustering balance . After topic merging , topics that contain less than 3 tweets are discarded . 4.2 Selecting Celerity related PublicTS
As discussed in Section 1 , celebrity related PublicTS should be included in the timeline . To identify celebrity related PublicTS topics , we use the multiple criterion including ( 1 ) user name coappearance ( 2 ) p value for topic shape comparison and ( 3 ) clustering balance . For a celebrity user i , a PublicTS topic Lj would be
CPi =
( 18 )
5 . DATA SET CREATION
Input Pi = {L1 , L2 , } , G=φ Begin : Until |Pi| = 1
Calculate ε(Pi ) Merge the two cluster with smallest KL divergence . Add Pi to G
End : Output : Pi = argminχ∈G ε(χ )
Figure 6 : Agglomerate Clustering Algorithm for user i . considered as a celebrity related if it satisfies the following conditions :
1 . user i ’s name or twitter id appears in at least 1 % of tweets in Lj . 2 . The P − value for χ2 shape comparison between Gi and Lj is
3 . ε{D Lj , L1 , L2 , , Lj−1 , Lj+1 , } ≤ ε{D , L1 , L2 , Lj , } larger than 08
For Condition 3 , it expresses the point that if PublicTS topic Lj is a user i related topic , the merging of D and Lj would decrease the value of clustering balance . 4.3 Tweet Selection
The tweet that best represents the PIE topic L is selected into timeline as follows : vselect = argmax v∈L
P r(v|L )
( 22 )
Here we describe the Twitter data set and gold standard PIE timelines used to train and evaluate our models . 5.1 Twitter Data Set Creation
Construction of the DPM model ( as well as the baselines ) requires the tweets of famous and non famous people . Accordingly , we create an initial data set that contains the tweets of 323,922 twitter users by collecting all tweets that each user published , retweeted or was @ed by his followers . From this set , we identify 20 ordinary Twitter users and another 20 celebrities Twitter users ( details see Section 52 ) From the remaining users in the original set , we randomly select 30,000 users and select all tweets published between Jun 7th , 2011 and Mar 4th , 2013 . The time span totals 637 days , which we split into 91 time periods ( weeks ) .
The tweets are preprocessed to remove stop words and words that contain no standard characters . Tweets that then contain fewer than three words are discarded . The resulting data set contains 62 million tweets , of which 36 , 520 belong to 20 ordinary twitter users and 196,169 belong to the 20 famous people . 5.2 Gold Standard Timeline Creation
For evaluation purposes , we respectively generate gold standard PIE timelines for ordinary twitter users and celebrities based on twitter data and Wikipedia4 . Twitter Timeline for Ordinary Users ( T witSet − O ) .
For ordinary twitter users , we chose 20 different twitter users of different ages and genders ( Statistics shown in 7 ) . Each of them has the number of followers between 500 and 2000 and published more than 1000 tweets within the time period . In a sense that no 4http://enwikipediaorg/wiki player , according to his wiki entry6 .
Figure 7 : Statistics for T witSet − O . famous people
Lebron James , Ashton Kutcher , Lady Gaga , Russell Crowe , Serena Williams , Barack Obama , Russell Crowe , Rupert Grint , Novak Djokovi , Katy Perry , Taylor Swift , Nicki Minaj , Dwight Howard , Jennifer Lopez , Wiz Khalifa , Chris Brown , Mariah Carey , Kobe Bryant , Harry Styles , Bruno Mars
Table 3 : List of Celebrities in T witSet − C . one understand your true self better than you do , we ask users to identify each of his or her tweets as either PIE related according to their own experience after clarifying them what PIE is . In addition , each PIE tweet is labeled with a short string designating a name for the associated PIE . Note that multiple tweets can be labeled with the same event name . Twitter Timeline for CelebritY Users ( T witSet − C ) .
We first use workers from Amazon ’s Mechanical Turk5 to generate Gold standard timelines for 20 famous people ( shown in Table 3 ) . All the celebrities have more than 1,000,000 followers . For each famous person , F , Turker judges read F ’s portion of the Twitter data set ( see 5.1 ) and identify each tweet as either PIE related or not PIE related and label each PIE related tweet with a short string designating a event name . We assign tweets for each celebrity to 2 different workers . Unfortunately , t the average value for Cohen κ is 0.653 with standard deviation 0.075 in the evaluation , no showing substantial agreement . To address this , we further used the crowdsourcing service oDesk , which allows requesters to recruit individual works with specific skills . We recruited two workers for each celebrity based on their ability to answer certain questions about related fields or related celebrity , say “ who is the NBA regular season MVP for 2011" when labeling NBA basketball stars ( ie Dwight Howard , Lebron James ) , “ who won the championship for Men ’s single in French Open 2011" when labeling tennis stars ( ieNovak Djokovi , Serena Williams ) or “ at which year Russell Crowe ’s movie Gladiator won him Oscar best actor" when labeling Russell Crowe . These experts agree with a κ score of 0901 We further ask them to reach agreement on tweets which the two judges disagree over . The illustration for the generation of T witSet − C is shown in Figure 8 . Wikipedia Timeline for Celebrity Users ( W ikiSet− C ) . For each famous person , F , judges from oDesk examine the Wikipedia entry for F and identify all content that they believe describes an important and personal event for F that occurred during the designated time period . In addition , they provide a short name for each such PIE ( See Figure 4 ) . 8 judges are involved in this task . Each wiki entry is assigned to 2 of them . Since judges may not have consistent labeling with each other , we want them to reach an agreement for the label . Table 4 illustrates the example for generation of W ikiSet − C for Dwight Howard , the NBA basketball
Figure 8 : Example of Golden Standard timeline T witSet − C for basketball star Dwight Howard . Colorful rectangles denote PIEs given by annotators . Labels are manually given .
Finally , the PIE names across W ikiSet − C and T witSet − C are normalized ( aligned ) so that a single ( ie the same ) name is used for the same PIEs that occur in both Wikipedia and Twitter . Statistics are shown in Table 5 . Notably , W ikiSet − C contains 254 PIEs and T witSet−C contains 221 PIEs , of which 197 events are shared . Differences in the two sets are expected since F might not tweet about all events identified as PIEs in Wikipedia ; similarly , F might tweet about PIEs ( eg “ moving to a new house" ) that are not recorded in Wikipedia .
6 . EXPERIMENTS
In this section , we evaluate our approach to PIE timeline construction for both ordinary users and famous users by comparing the results of DPM with baselines . 6.1 Baselines
In this paper , we use the following approaches for baseline comparison . For fair comparison , we use identical processing techniques for each approach .
Multi level LDA : Multi level LDA is similar to HDM but uses LDA based topic approach ( shown in Figure 9(a) ) . Latent parameter x and y are used to control whether a tweet is personal or public , time general or time specific . Each combination of x and y is associated with a unique collection of topics z with topic word B for ( x=0,y=0 ) , distribution . There is a background distribution φz
5https://wwwmturkcom/mturkE/welcome
6http://enwikipediaorg/wiki/Dwight Howard
Manual Label NBA all star traded to Houston Rockets
Wiki text Howard ’s strong and consistent play ensured that he was named as a starter for the Western Conference All Star team On August 10 , 2012 , Howard was traded from Orlando to the Los Angeles Lakers in a deal that also involved the Philadelphia 76ers and the Denver Nuggets . Howard injured his right shoulder in the second half of the Lakers’ 107 102 loss to the Los Angeles Clippers when he got his arms tangled up with Caron Butler Howard announced on his Twitter account that he was joining the Rockets and officially signed with the team on July 13 , 2013 . Table 4 : Example of Golden Standard timeline W ikiSet − C for basketball star Dwight Howard according to wiki entry . Labels are manually given .
Sign Rockets
Houston
Injured
TwitSet O TwitSet C WikiSet C
# of PIEs avg # PIEs per person max # PIEs per person min # PIEs per person
112 6.1 14 2
221 11.7 20 3
254 12.7 23 6
Table 5 : Statistics for Gold standard timelines i for ( x=1,y=0 ) and time user topic distribution φz t for ( x=0 , y=1 ) , user specific distime specific distribution for φz tribution φz i,t for ( x=1,y=1 ) . Another difference between Multi level LDA with DPM is that , unlike DP , topic z between different x and y are not shared . Person DP : Personal DP is a simple version of DPM model where only temporal information is considered . As shown in Figure 9(b ) , the input to Personal DP is only comprised of tweets published by one specific user and the model tries to saperate Gt i from Gi .
Person LDA : Similar to Personal DP , but use a LDA to model events/topics across user . Topic number is set to 30 for each user . Public DP : Public DP tries to separate personal topics Gi from public events/topics G0 , but ignores temporal information , as shown in Figure 9(c ) .
Public LDA : Similar to Public DP , but uses a LDA for topic modeling .
Figure 9 : Graphical illustration for baselines : ( a ) Multi level LDA ( b ) Person DP ( c ) Public DP .
We also use the following supervised techniques as baselines :
SVM : We treat the prediction of x and y as a binary classification problem and use SVMlight [ 10 ] to train a linear classifier using unigram feature . The value for each feature is calculated using the strategy inspired by tf − idf . F x prediction ( whether a tweet is personal or public ) , the feature value Fx(w ) for word w is calculated as follows :
I i I(w ∈ Si ) denotes the total number of users and tf ( w , i ) is the number of replicates of w appearing in user i . I i I(w ∈ Si ) denotes the number of users that publish word w . So a word that everybody uses would get a low value for the second part in Equ(23 ) Similarly , for y prediction ( whether a tweet is personal or public ) , we have :
Fx(w ) = tf ( w , i ) · log
( 23 )
Fy(w ) = tf ( w , t ) · log
( 24 )
T t I(w ∈ St )
SV M is a supervised model which requires labeled training data . We use oDesk again and assign each tweet to two judges for x and y labeling . The average value for Cohen ’s kappa is 0.868 , showing substantial agreements . Tweets on which judges disagree over are discarded and we finally collect 17690 tweets as labelled data .
Logistic Regression : A type of regression analysis used for pre dicting x and y7 . 6.2 Results for PIE Timeline Construction
Performance on the central task of identifying the personal important events of celebrities is shown in the Event level Recall shown at Table 6 , which shows the percentage of PIEs from the Twitter based gold standard timeline ( Twiiter ) and the Wiki based gold standard timeline ( Wiki ) that each model can retrieved . As we can see from Table 6 , the recall rate for T wit − C is usually higher than that of T wit− O . As celebrities tend to have more followers , their PIE related tweets are usually followed , retweeted and replied by various followers , making them easier to be captured . The recall for T wit − C is usually higher than that of W iki − O in that wiki contains many events that celebrities do not mention in their tweets .
For baseline comparison , supervised learning algorithm ( SV M and Logistic Regression ) are not well suited for this task and attain poor performances since a large amount of manual effort is required to annotate tweets and the limited training labeled data makes the classification difficult . DP M is a little bit better than M ulti − level LDA due to its non parametric nature and ability in modeling topics shared across the corpus . This can also be verified when comparing P erson − DP to P erson − LDA and P ublic − DP to P ublic − LDA . Approaches ( DP M and M ulti − levelLDA ) that consider both personal public , time general time specific information at the same time perform better than those considering only one facet . 6.3 Results for Tweet Level Prediction
Although our main concern is what percentage of PIEs each model can retrieve , the precision for tweet level predictions of each model is also potentially of interest . There would be a trade − of f between Event level Recall and Tweet level Precision in that more tweets means more topics being covered , but more likely to
7http://enwikipediaorg/wiki/Logistic regression
T wit − O T wit − C W iki − C T wit − O T wit − C W iki − C T wit − O T wit − C W iki − C
Accuracy
Precision
Tweet Level
Approach
DPM
Multi level LDA
Person DP Person LDA Public DP Public LDA
SVM Logistic
0.872 0.836 0.822 0.812 0.788 0.792 0.621 0.630
Event Level
Recall
0.904 0.882 0.840 0.827 0.829 0.790 0.664 0.652
0.790 0.790 0.727 0.720 0.731 0.692 0.562 0.584
0.841 0.802 0.632 0.617 0.738 0.719 0.617 0.608
0.821 0.810 0.620 0.630 0.760 0.762 0.642 0.652
0.782 0.768 0.654 0.628 0.752 0.750 0.643 0.629
0.836 0.832 0.654 0.661 0.734 0.718 0.613 0.635
0.854 0.810 0.670 0678 0.746 0.746 0.632 0.636
0.788 0.744 0.645 0.628 0.752 0.727 0.614 0.620
Table 6 : Evaluation for different systems .
PublicTG PublicTS 22.2 %
37.8 %
PersonTG PersonTS
21.7 %
18.3 %
Table 7 : Percentage of different types of Tweets . include non PIE related tweets as well . As we do not have goldstandard labels with respect to the four tweet types , Table 6 instead reports the accuracy and precision of each model on the binary PIErelated/not PIE related classification wrt PIEs that appear in the W ikiSet and T witSet gold standards . The Tweet level Precision scores show the percentage of PIE related tweets identified by each model that are correct wrt each gold standard . Scoring high along this measure is more important than accuracy because only one PIE related tweet per PIE needs to be identified . As we can see from Table 6 , DP M and M ulti − level LDA outperform other baselines by a large margin with respect to TweetLevel Accuracy and Precision . Since the input to Personal DP and Personal LDA only consists of tweets by a single person , public topics ( i.e American Presidential Election ) concerned by individual users would also be selected as PIE , resulting in low accuracy and precision . Public DP and Public LDA ignore of temporal information , all PersonTG would be treated as PIE related tweets . Since PersonTG related tweets amount to 20 percent of the total number of tweets ( see Table 7 ) , treating PersonTG related tweets as PIES would result in very low tweet level accuracy and precision rate .
6.4 Sample Results and Discussion
In this subsection , we present part of sample results outputted . Table 7 presents percentage of different types of tweets according to DPM model . PublicTG takes up the largest portion , up to about 38 % . PublicTG is followed by PublicTS and PersonTG topics and then PersonTS .
Next , we present the time series results for PIE related topics extracted from an 22 year old female twitter user who is a senior undergraduate and a famous NBA basketball player , Lebron James in Figures 10 . The correspondent top words within the topics are respectively presented at Table 10 . Topic label is manually given . One interesting direction for future work is automatic labeling discovered PIE events and generating a much conciser timeline based on these automatic labels rather than extracting tweets [ 15 ] .
As we can see from Table 10 , each topic corresponds a specific PIE in user ’s life . For the ordinary twitter user , the 4 topics respectively talks about 1 ) her internship at Roland Beger in Germany 2 ) she played a role in drama “ A Midsummer Night ’s Dream" 3 ) graduation from her university 4 ) start a new job at BCG , New York City . Table 8 shows the timeline generated by our system for Lebron James . We can clearly see that PIE events such as NBA all Star , NBA finals or being engaged can be well detected . The tweet in italic font is a wrongly detected PIE . This tweet talks about the DallasCowboys , a football team which James is interested in . It should be regarded as an interest rather than a PIE . James published a lot of tweets about DallasCowboys during a very short period of time and they are wrongly treated as PIE related . Distinguishing PIE from short term interest is one of our futures works for personal event tracking .
Figure 10 : Topic Intensity over time for PIE topics extracted from ( a ) an ordinary twitter user ( b ) Lebron James . top word manual label summer intern
Topic 1
Topic 2
Topic 3 play a role in drama Midsummer , Hall , act cheers , Hippolyta graduation intern , Roland , tired
Berger , berlin farewell,Cornell,miss drunk,ceremony York , BCG , office new , NYC
Topic 4 begin working
Table 9 : Top words of topics from the ordinary twitter user
Topic 1 manual label
NBA 2012 finals
Topic 2 Ray Allen join Heat
Topic 3
2012 Olympic
Topic 4
NBA all star top word finals , champion,Heat
Lebron , OKC
Allan , Miami , sign
Heat , welcome
Basketball , Olympic Kobe , London , win All star , Houston new , NYC
Table 10 : Top words of topics from Lebron James
7 . RELATED WORK
Personal Event Extraction and Timeline Generation .
Individual tracking problem can be traced back to 1996 , when Plaisant et al . [ 22 ] tried to provide a general visualization for personal histories that can be applied to medical and court records .
Time Periods Feb.21 2011 Jun.13 2011
Tweets selected by DPM Can’t wait to see all my fans in LA this weekend for All Star . Love u all . Enough of the @KingJames hating . He ’s a great player . And great players don’t play to lose , or enjoy losing , even it is final game . AWww @kingjames is finally engaged!! Now he can say hey kobe I have ring too :P .
Jan.01 2012 Feb.20 2012 We rolling in deep to All Star weekend , let ’s go Jun.19 2012 Jul.01 2012 Jul.15 2012 Aug.05 2012 What a great pic from tonight @usabasketball win in Olypmic! Sep.02 2012
OMFG I think it just hit me , I’m a champion!! I am a champion! #HeatNation please welcome our newest teammate Ray Allen.Wow @KingJames won the award for best male athlete .
Big time win for @dallascowboys in a tough environment tonight! Great start to season . Game ball goes to Kevin Ogletree
Manually Label 2011 NBA All Star 2011 NBA Finals
Engaged 2012 NBA All Star . 2012 NBA Finals Welcome Ray Allen Best Athlete award Win Olympics Wrongly detected
Table 8 : Chronological table for Lebron James from DPM .
Previous personal event detection mainly focus on clustering and sorting information of a specific person from web search [ 1 , 6 , 12 , 31 ] . These techniques suffer from the disadvantages that they not only bring about the problem of name disambiguation , but also ignore those trivial events which are not collected by the media . Most importantly , these approaches can not be extended to ordinary people since whose information is not collected by digital media . The increasing popularity of social media ( eg twitter , Facebook8 ) , where users regularly talk about their lives , chat with friends , gives rise to a novel source for tracking individuals . A very similar approach is the famous Facebook Timeline9 , which integrates users’ status , stories and images for a concise timeline construction10 .
Topic Models and Dirichlet Process .
Because of its ability to model latent topics in a document collection , topic modeling techniques ( LDA [ 3 ] and HDP [ 29 ] ) have been employed for many NLP tasks in recent years . Here , our model is inspired by earlier work that uses LDA based topic models to separate background ( generall ) information from document specific information [ 5 ] and Rosen zvi et al ’s work [ 26 ] that to extract userspecific information to capture the interest of different users . HDP uses multiple DPs to model the multiple correlated corpus . Sethuraman [ 28 ] showed the stick breaking construction for DP . HDP can be used as an LDA based topic model , where the number of clusters can be automatically inferred from data [ 34 ] . Therefore , HDP is more practical when we have little knowledge about the content to be analyzed .
Event Extraction on Twitter .
Twitter , a popular microblogging service , has received much attention recently . Many approaches have been introduced based on twitter data for multiple real time applications such as public bursty topic detection [ 2 , 4 , 7 , 17 , 21 , 33 ] , local event detection [ 16 , 27 , 32 ] or political analysis [ 19 , 30 ] . Alan et al . [ 25 ] proposed a framework for timeline generation for open domain event on Twitter . Twitter serves as an alternative , and potentially very rich , source of information for individual tracking task since people usually publish tweets in real time describing their lives in details . One related work is the approach developed by Diao et al [ 7 ] , that tried to separate personal topics from public bursty topics . As far as we know , there is no existing works try to extract personal event or generate timelines for an individual based on twitter .
8 . CONCLUSION AND DISCUSSION 8https://wwwfacebookcom/ 9https://wwwfacebookcom/about/timeline 10The algorithm for Facebook Timeline generation still remains unreleased for public .
In this paper , we study the problem of individual timeline generation problem based on twitter and propose a DPM model for PIE detection by distinguishing four types of tweets including PublicTS , PublicTG , PersonPS and PersonPG . Our model can aptly handle the combination of temporal and user information in a unified framework . Experiments on real world Twitter data quantitatively and qualitatively the effectiveness of our model . Our approach provides a new perspective for tracking individuals .
Even though our model can be extended to any twitter user , there are limitations for our method . First , all existing algorithms , including ours , use word frequency for modeling . This requires a user publishing enough amount of tweets and having a certain number of followers , so that his or her PIE could be adequately talked about to be detected . Second , as for users that maintain a low profile and seldom tweet about what happened to them , our model can not work . Addressing these limitations would be our future work .
9 . REFERENCES [ 1 ] R . Al Kamha and D . W . Embley . Grouping search engine returned citations for person name queries . In Proceedings of the 6th annual ACM international workshop on Web information and data management , pages 96–103 . ACM , 2004 .
[ 2 ] H . Becker , M . Naaman , and L . Gravano . Beyond trending topics : Real world event identification on twitter . In ICWSM , 2011 .
[ 3 ] D . M . Blei , A . Y . Ng , and M . I . Jordan . Latent dirichlet allocation . the Journal of machine Learning research , 3:993–1022 , 2003 .
[ 4 ] M . Cataldi , L . Di Caro , and C . Schifanella . Emerging topic detection on twitter based on temporal and social terms evaluation . In Proceedings of the Tenth International Workshop on Multimedia Data Mining , page 4 . ACM , 2010 . [ 5 ] C . Chemudugunta and P . S . M . Steyvers . Modeling general and specific aspects of documents with a probabilistic topic model . In Advances in Neural Information Processing Systems : Proceedings of the 2006 Conference , volume 19 , page 241 . The MIT Press , 2007 .
[ 6 ] H . L . Chieu and Y . K . Lee . Query based event extraction along a timeline . In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval , pages 425–432 . ACM , 2004 .
[ 7 ] Q . Diao , J . Jiang , F . Zhu , and E P Lim . Finding bursty topics from microblogs . In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics : Long Papers Volume 1 , pages 536–544 . Association for
Computational Linguistics , 2012 .
[ 8 ] T . S . Ferguson . A bayesian analysis of some nonparametric problems . The annals of statistics , pages 209–230 , 1973 .
[ 9 ] L . Hong and B . D . Davison . Empirical study of topic modeling in twitter . In Proceedings of the First Workshop on Social Media Analytics , pages 80–88 . ACM , 2010 .
[ 10 ] T . Joachims . Making large scale svm learning practical .
1999 .
[ 11 ] Y . Jung , H . Park , D Z Du , and B . L . Drake . A decision criterion for the optimal number of clusters in hierarchical clustering . Journal of Global Optimization , 25(1):91–111 , 2003 .
[ 12 ] R . Kimura , S . Oyama , H . Toda , and K . Tanaka . Creating personal histories from the web using namesake disambiguation and event extraction . In Web Engineering , pages 400–414 . Springer , 2007 .
[ 13 ] K . Kireyev , L . Palen , and K . Anderson . Applications of topics models to analysis of disaster related twitter data . In NIPS Workshop on Applications for Topic Models : Text and Beyond , volume 1 , 2009 .
[ 14 ] J . D . Lafferty and D . M . Blei . Correlated topic models . In Advances in neural information processing systems , pages 147–154 , 2005 .
[ 15 ] J . H . Lau , K . Grieser , D . Newman , and T . Baldwin .
Automatic labelling of topic models . In ACL , volume 2011 , pages 1536–1545 , 2011 .
[ 16 ] R . Lee and K . Sumiya . Measuring geographical regularities of crowd behaviors for twitter based geo social event detection . In Proceedings of the 2nd ACM SIGSPATIAL International Workshop on Location Based Social Networks , pages 1–10 . ACM , 2010 .
[ 17 ] R . Li , K . H . Lei , R . Khadiwala , and K C Chang . Tedas : a twitter based event detection and analysis system . In Data Engineering ( ICDE ) , 2012 IEEE 28th International Conference on , pages 1273–1276 . IEEE , 2012 .
[ 18 ] E . Momeni , C . Cardie , and M . Ott . Properties , prediction , and prevalence of useful user generated comments for descriptive annotation of social media objects . In Seventh International AAAI Conference on Weblogs and Social Media , 2013 .
[ 19 ] B . O’Connor , R . Balasubramanyan , B . R . Routledge , and
N . A . Smith . From tweets to polls : Linking text sentiment to public opinion time series . ICWSM , 11:122–129 , 2010 .
[ 20 ] M . J . Paul and M . Dredze . You are what you tweet :
Analyzing twitter for public health . In ICWSM , 2011 .
[ 21 ] S . Petrovi´c , M . Osborne , and V . Lavrenko . Streaming first story detection with application to twitter . In Human Language Technologies : The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics , pages 181–189 . Association for Computational Linguistics , 2010 .
[ 22 ] C . Plaisant , B . Milash , A . Rose , S . Widoff , and
B . Shneiderman . Lifelines : visualizing personal histories . In Proceedings of the SIGCHI conference on Human factors in computing systems , pages 221–227 . ACM , 1996 .
[ 23 ] D . Ramage , S . T . Dumais , and D . J . Liebling . Characterizing microblogs with topic models . In ICWSM , 2010 .
[ 24 ] D . Ramage , D . Hall , R . Nallapati , and C . D . Manning .
Labeled lda : A supervised topic model for credit attribution in multi labeled corpora . In Proceedings of the 2009 Conference on Empirical Methods in Natural Language
Processing : Volume 1 Volume 1 , pages 248–256 . Association for Computational Linguistics , 2009 .
[ 25 ] A . Ritter , O . Etzioni , S . Clark , et al . Open domain event extraction from twitter . In Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 1104–1112 . ACM , 2012 .
[ 26 ] M . Rosen Zvi , T . Griffiths , M . Steyvers , and P . Smyth . The author topic model for authors and documents . In Proceedings of the 20th conference on Uncertainty in artificial intelligence , pages 487–494 . AUAI Press , 2004 . [ 27 ] T . Sakaki , M . Okazaki , and Y . Matsuo . Earthquake shakes twitter users : real time event detection by social sensors . In Proceedings of the 19th international conference on World wide web , pages 851–860 . ACM , 2010 .
[ 28 ] J . Sethuraman . A constructive definition of dirichlet priors .
Technical report , DTIC Document , 1991 .
[ 29 ] Y . W . Teh , M . I . Jordan , M . J . Beal , and D . M . Blei .
Hierarchical dirichlet processes . Journal of the american statistical association , 101(476 ) , 2006 .
[ 30 ] A . Tumasjan , T . O . Sprenger , P . G . Sandner , and I . M . Welpe . Predicting elections with twitter : What 140 characters reveal about political sentiment . ICWSM , 10:178–185 , 2010 .
[ 31 ] X . Wan , J . Gao , M . Li , and B . Ding . Person resolution in person search results : Webhawk . In Proceedings of the 14th ACM international conference on Information and knowledge management , pages 163–170 . ACM , 2005 .
[ 32 ] K . Watanabe , M . Ochi , M . Okabe , and R . Onai . Jasmine : a real time local event detection system based on geolocation information propagated to microblogs . In Proceedings of the 20th ACM international conference on Information and knowledge management , pages 2541–2544 . ACM , 2011 .
[ 33 ] J . Weng and B S Lee . Event detection in twitter . In ICWSM ,
2011 .
[ 34 ] J . Zhang , Y . Song , C . Zhang , and S . Liu . Evolutionary hierarchical dirichlet processes for multiple correlated time varying corpora . In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 1079–1088 . ACM , 2010 .
[ 35 ] W . X . Zhao , J . Jiang , J . Weng , J . He , E P Lim , H . Yan , and X . Li . Comparing twitter and traditional media using topic models . In Advances in Information Retrieval , pages 338–349 . Springer , 2011 .
APPENDIX A . CALCULATION OF F(V|X,Y,Z ) P r(v|x , y , x , z , w ) denotes the probability that current tweet is generated by an existing topic z and P r(v|x , y , znew , w ) denotes the probability current tweet is generated by the new topic . Let E(· ) ( z ) denote the number of words assigned to topic z in tweet type x , y and E(w ) ( z ) denote the number of replicates of word w in topic z . Nv is the number of words in current tweet and N w v denotes of replicates of word w in current tweet . We have :
P r(v|x , y , z , w ) =
( z ) + V λ )
Γ(E(· ) ( z ) + Nv + V λ )
Γ(E(· )
Γ(E(w ) v + λ )
( z ) + N w Γ(E(w )
( z ) + λ )
· · w∈v w∈v
P r(v|x , y , znew , w ) =
Γ(V λ )
Γ(Nv + V λ )
Γ(N w v + λ ) Γ(λ )
Γ( ) denotes gamma function and λ is the Dirichlet prior .
