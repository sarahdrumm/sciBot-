How to Influence People with Partial Incentives∗
Erik D . Demaine† MohammadTaghi Hajiaghayi‡
Hamid Mahini§
David L . Malec¶
S . Raghavank
Anshul Sawant∗∗
Morteza Zadimoghadam††
January 31 , 2014
Abstract
We study the power of fractional allocations of resources to maximize our influence in a network . This work extends in a natural way the well studied model by Kempe , Kleinberg , and Tardos ( 2003 ) , where a designer selects a ( small ) seed set of nodes in a social network to influence directly , this influence cascades when other nodes reach certain thresholds of neighbor influence , and the goal is to maximize the final number of influenced nodes . Despite extensive study from both practical and theoretical viewpoints , this model limits the designer to a binary choice for each node , with no chance to apply intermediate levels of influence . This model captures some settings precisely , such as exposure to an idea or pathogen , but it fails to capture very relevant concerns in others , for example , a manufacturer promoting a new product by distributing five “ 20 % off ” coupons instead of giving away a single free product .
While fractional versions of problems tend to be easier to solve than integral versions , for influence maximization , we show that the two versions have essentially the same computational complexity . On the other hand , the two versions can have vastly different solutions : the added flexibility of fractional allocation can lead to significantly improved influence . Our main theoretical contribution is to show how to adapt the major positive results from the integral case to the fractional case . Specifically , Mossel and Roch ( 2006 ) used the submodularity of influence to obtain their integral results ; we introduce a new notion of continuous submodularity , and use this to obtain matching fractional results . We conclude that we can achieve the same greedy ( 1 − 1/e − ε) approximation for the fractional case as the integral case , and that other heuristics are likely to carry over as well . In practice , we find that the fractional model performs substantially better than the integral model , according to simulations on real world social network data .
4 1 0 2 n a J
0 3
] T G . s c [
1 v 0 7 9 7
.
1 0 4 1 : v i X r a
∗This work was supported in part by NSF CAREER award 1053605 , NSF grant CCF 1161626 , ONR YIP award
N000141110662 , DARPA/AFOSR grant FA9550 12 1 0423 .
†MIT , Cambridge , MA , USA . edemaine@mitedu ‡University of Maryland , College Park , MD , USA . hajiagha@csumdedu §University of Maryland , College Park , MD , USA . hamidmahini@gmailcom ¶University of Maryland , College Park , MD , USA . dmalec@umiacsumdedu kUniversity of Maryland , College Park , MD , USA . raghavan@umdedu ∗∗University of Maryland , College Park , MD , USA . asawant@csumdedu ††MIT , Cambridge , MA , USA . morteza@csailmitedu
1 Introduction
The ideas we are exposed to and the choices we make are significantly influenced by our social context . It has long been studied how our social network ( ie , who we interact with ) impacts the choices we make , and how ideas and behaviors can spread through social networks [ 3 , 10 , 21 , 23 ] . With websites such as Facebook and Google+ devoted to the forming and maintaining of social networks , this effect becomes ever more evident . Individuals are linked together more explicitly and measurably , making it both easier and more important to understand how social networks affect the behaviors and actions that spread through a society .
A key problem in this area is to understand how such a behavioral cascade can start . For example , if a company wants to introduce a new product but has a limited promotional budget , it becomes critical to understand how to target their promotional efforts in order to generate awareness among as many people as possible . A well studied model for this is the Influence Maximization problem , introduced by Kempe , Kleinberg , and Tardos [ 15 ] . The problem ’s objective is to find a small set of individuals to influence , such that this influence will cascade and grow through the social network to the maximum extent possible . For example , if a company wants to introduce a new piece of software , and believes that friends of users are likely to become users themselves , how should they allocate free copies of their software in order to maximize the size of their eventual user base ?
Since the introduction of the Influence Maximization problem [ 15 ] , there has been a great deal of interest and follow up work in the model . While Kempe et al . [ 15 ] give a greedy algorithm for approximating the Influence Maximization problem , it requires costly simulation at every step ; thus , while their solution provides a good benchmark , a key area of research has been on finding practical , fast algorithms that themselves provide good approximations to the greedy algorithm [ 4 , 5 , 6 , 7 , 16 ] . The practical , applied nature of the motivating settings means that even small gains in performance ( either runtime or approximation factor ) are critical , especially on large , real world instances .
We believe that the standard formulation of the Influence Maximization problem , however , misses a critical aspect of practical applications . In particular , it forces a binary choice upon the optimizer , forcing a choice of either zero or complete influence on each individual , with no options in between . While this is reasonable for some settings — eg , exposure to an idea or pathogen – it is far less reasonable for other settings of practical importance . For example , a company promoting a new product may find that giving away ten free copies is far less effective than offering a discount of ten percent to a hundred people . We propose a fractional version of the problem where the optimizer has the freedom to split influence across individuals as they see fit .
To make this concrete , consider the following problem an optimizer might face . Say that an optimizer feels there is some small , well connected group whose adoption of their product is critical to success , but only has enough promotion budget remaining to influence one third of the group directly . In the original version of Influence Maximization , the optimizer is forced to decide which third of the group to focus on . We believe it is more natural to assume they have the flexibility to try applying uniform influence to the group , say offering everyone a discount of one third on the price of their product , or in fact any combination of these two approaches . While our results are preliminary , we feel that our proposed model addresses some very real concerns with practical applications of Influence Maximization , and offers many opportunities for important future research .
1
1.1 Our Results and Techniques
This work aims to understand how our proposed fractional version of the Influence Maximization problem differs from the integral version proposed by Kempe , Kleinberg , and Tardos [ 15 ] . We consider this question from both a theoretical and an empirical perspective . On the theoretical side , we show that , unlike many problems , the fractional version appears to retain essentially the same computational hardness as the integral version . The problems are very different , however : we give examples where the objective values for the fractional and integral versions differ significantly . Nonetheless , we are able to carry over the main positive results to the fractional setting , notably that the objective function is submodular and the problem therefore admits a greedy ( 1 − 1/e − ε) approximation . On the empirical side , we simulate the main algorithms and heuristics on real world social network data , and find that the computed solutions are substantially more efficient in the fractional setting .
Our main theoretical result shows that the positive results of Mossel and Roch [ 18 ] extend to our proposed fractional model . Their result states that , in the integral case , when influence between individuals is submodular , so too is the objective function in Influence Maximization . We show that , for a continuous analog of submodularity,1 the same results holds for our fractional case . First we consider a discretized version of the fractional Influence Maximization Problem , where each vertex can be assigned a weight that is a multiple of some discretization parameter ε = 1 N . Then we consider the final influenced set by choosing a weighted seed set S , where the weight of each element is a multiple of ε . We show that the fractional Influence Maximization objective is a submodular function of S for any N ≥ 1 ( Theorem 2 ) . We further extend this result to the fully continuous case ( Theorem 3 ) . Note that this result does not follow simply by relating the fractional objective function to the integral objective and interpolating , or other similar methods ; instead , we need to use a nontrivial reduction to the generalization of the influence maximization problem given by Mossel and Roch [ 18 ] . Not only does this result show that our problem admits a greedy ( 1 − 1/e − ε)appromixation algorithm , it furthermore gives us hope that we can readily adapt the large body of work on efficient heuristics for the integral case to our problem and achieve good results .
In addition to showing the submodularity of the objective persists from the integral case to the fractional case , we show that the hardness of the integral case persists as well . In the case of fixed thresholds , we show that all of the hardness results of Kempe et al . [ 15 ] extend readily to the fractional case . Specifically , we show that , for the fractional version of the linear influence model , even finding an n1−ε approximation is NP hard . First we prove NP hardness of the problem by a reduction from Independent Set ( Theorem 7 ) , and then we strengthen the result to prove inapproximability ( Corollary 8 ) . In addition , when thresholds are assumed to be independent and uniformly distributed in [ 0 , 1 ] , we show that it is NP hard to achieve better than a ( 1 − 1/e) approximation in the Triggering model introduced by Kempe et al . [ 15 ] . This holds even for the simple case where triggering sets are deterministic and have constant sizes , and shows that even for this simple case the greedy approximation is tight , just as in the integral case . An important aspect of all of these reductions is that they use very simple directed acyclic graphs ( DAGs ) , with only two or three layers of vertices .
Our last set of results focuses on the special case where the network is a DAG . Here , we focus on the linear influence model with uniform thresholds . In this case , we see that we can easily compute the expected influence from any single node via dynamic programming ; this closely resembles a previous result for the integral case [ 7 ] . In the fractional case , this gives us a sort of linearity result . Namely , if we are careful to avoid interference between the influences we place on nodes , we can conclude that the objective is essentially linear in the seed set . While the conditions on this theorem seem strong at first glance , it has
1Note that our notion of continuous submodularity is neither of the two most common continuous extensions of submodularity , namely the multilinear and Lov´asz extensions .
2 a very powerful implication : all of the hardness results we presented involved choosing optimal seed sets from among the sources in a DAG , and this theorem says that with uniform thresholds the greedy algorithm finds the optimal such seed set .
1.2 Related Work
Economics , sociology , and political science have all studied and modeled behaviors arising from information and influence cascades in social networks . Some of the earliest models were proposed by Granovetter [ 10 ] and Schelling [ 21 ] . Since then , many such models have been studied and proposed in the literature [ 3 , 20 , 23 ] .
The advent of social networking platforms such as Facebook , Twitter , and Flickr has provided researchers with unprecedented data about social interactions , albeit in a virtual setting . The question of monetizing this data is critically important for the entities that provide these platforms and the entities that want to leverage this data to engineer effective marketing campaigns . These two factors have generated huge interest in algorithmic aspects of these systems .
A question of central importance is to recognize “ important individuals ” in a social network . Domingos and Richardson [ 8 , 19 ] were the first to propose heuristics for selection of customers on a network for marketing . This work focuses on evaluating customers based on their intrinsic and network value . The network value is assumed to be generated by a customer influencing other customers in her social network to buy the product . In a seminal paper , Kempe et al . [ 15 ] give an approximation algorithm for selection of influential nodes under the linear threshold ( LT ) model . Mossel and Roch [ 17 ] generalized the results of Kempe et al . [ 15 ] to cases where the activation functions are monotone and submodular . Gunnec and Raghavan [ 12 ] were the first to discuss fractional incentives ( they refer to these as partial incentives/inducements ) in the context of a product design problem . They consider a fractional version of the target set selection problem ( ie , fixed thresholds , fractional incentives , a linear influence model , with the goal of minimizing the fractional incentives paid out so that all nodes in the graph are influenced ) . They provide an integer programming model , and show that when the neighbors of a node have equal influence on it , the problem is polynomially solvable via a greedy algorithm [ 11 , 12 , 13 ] .
Some recent work has directly tackled the question of revenue maximization in social networks by leveraging differential pricing to monetize positive externalities arising due to adoption of a product by neighbors of a customer [ 1 , 2 , 9 , 14 ] . The closest such work is by Singer [ 22 ] , but it still restricts the planner ’s direct influence to initial adoption . Other work has focused on finding faster algorithms for the target set selection problem [ 5 , 6 , 7 , 16 ] . A very recent theoretical result in this direction is an O( ( m+n ) log n ) algorithm giving an approximation guarantee of 1 − 1 e − ε [ 4 ] . While Leskovec et al . [ 16 ] do not compare their algorithm directly with the greedy algorithm of Kempe et al . [ 15 ] , the heuristics in other papers [ 5 , 6 , 7 ] approach the performance of the greedy algorithm quite closely . For example , in [ 6 ] , the proposed heuristic achieves an influence spread of approximately 95 % of the influence spread achieved by the greedy algorithm . An interesting fact on the flip side is that none of the heuristics beat the greedy algorithm ( which itself is a heuristic ) for even a single data set .
ε3
2 Model
Integral Influence Model We begin by describing the model used for propagation of influence in social networks used by Mossel and Roch [ 18 ] ; it captures the model of Kempe et al . [ 15 ] as a special case . While the latter described the spread of influence in terms of an explicit network , the former leaves the
3 underlying social network implicit . In this model , the social network is given by a vertex set V and an explicit description of how vertices influence each other . For each vertex v ∈ V , we are given a function fv : 2V → [ 0 , 1 ] specifying the amount of influence each subset S ⊆ V exerts on v . We denote the set of all influence functions by F = {fv}v∈V .
Given a social network specified by ( V , F ) , we want to understand how influence propagates in this network . The spread of influence is modeled by a process that runs in discrete stages . In addition to the influence function fv , each vertex v has a threshold θv ∈ [ 0 , 1 ] representing how resistant it is to being influenced . If , at a given stage , the currently activated set of vertices is S ⊆ V , then any unactivated v ∈ V \ S becomes activated in the next stage if and only if fv(S ) ≥ θv . Our goal is to understand how much influence different sets of vertices exert on the social network as a whole under this process ; we can measure this by running this process to completion starting with a particular seed set , and seeing how large the final activated set is . In some settings , we may value activating certain ( sets of ) vertices more highly , and to capture this we define a weight function w : 2V → R+ on subsets of V . We now define the value of a seed set S as follows . For an initially activated set S0 , let SΘ n be the activated sets after 1 , 2 , . . . , n = |V | stages of our spreading process , when Θ = ( θv)v∈V is our vector of thresholds . Our goal is understanding the value of w(SΘ n ) when we set S0 = S . Note this depends strongly on Θ : the exact values of thresholds have a significant impact on the final activated set . If the vector Θ can be arbitrary , finding the best seed set – or even any nontrivial approximation of it – becomes NP Hard ( see Section 5 for discussion and proofs of this ) . Thus , we follow the lead of Kempe et al . [ 15 ] and assume that each threshold is independently distributed as θv ∼ U [ 0 , 1 ] . Then , our goal in this problem is understanding the structure of the function σ : 2V → R+ given by
2 , . . . , SΘ
1 , SΘ with the goal of finding seed sets S maximizing σ(S ) .
σ(S ) = E Θ
[ w(SΘ n ) | S0 = S ] ,
Fractional Influence Model A major shortcoming of the model described above is that it isolates the effects of influence directly applied by the optimizer from those of influence cascading from other individuals in the network . In particular , note that every individual in the social network is either explicitly activated by the optimizer ( and influence from their neighbors has no effect ) , or is activated by influence from other individuals with no ( direct ) involvement from the optimizer . This separation is artificial , however , and in practical settings a clever optimizer could try to take advantage of known influences between the individuals they wish to affect . For example , if an optimizer is already planning to activate some set S of individuals , it should require notably less effort to ensure activation of any individual who is heavily influenced by the set S .
We propose the following modification of the previously described influence model in order to capture this phenomenon . Rather than selecting a set S of nodes to activate , the optimizer specifies a vector x ∈ [ 0 , 1]n indexed by V , where xv indicates the amount of direct influence we apply to v . We assume that this direct influence is additive with influence from other vertices in the network , in the sense that if the current activated set is S in a stage of our process , v becomes activated in the next stage if and only if fv(S)+xv ≥ θv . Here , we assume that no vertices are initially activated , that is S0 = ∅ . Note , however , that even without contributions from other nodes , our directly applied influence can cause activations . Notably , it is easy to see that
SΘ
1 = {v ∈ V : xv ≥ θv} .
We point out , however , that our process is not simply a matter of selecting an initial activated set at random with marginal probabilities x . The influence xv we apply to v not only has a chance to activate it at the
4 outset , but also makes it easier for influence from other vertices to activate it in every future stage of the process . Lastly , we observe that this model captures the model of Mossel and Roch [ 18 ] as a special case , since selecting sets to initially activate corresponds exactly with choosing x ∈ {0 , 1}n , just with a singleround delay in the process . This motivates us to term that original model as the integral influence model , and this new model as the fractional influence model . As before , we want to understand the structure of the expected value of the final influenced set as a function of how we apply influence to nodes in a graph . We extend our function to σ : [ 0 , 1]n → R+ by
σ(x ) = E Θ
[ w(SΘ n ) | we apply direct influences x ] .
We want to both understand the structure of σ and be able to find ( approximately ) optimal inputs x .
Gap Between Integral and Fractional A natural question when presented with a new model is whether it provides any additional power over the previous one . Here , we answer that question in the affirmative for the fractional extension of the Influence Maximization model . In particular , we present two examples here that show that fractional influence can allow a designer to achieve strictly better results than integral influence for a particular budget . The first example shows that with fixed thresholds , this gap is linear ( perhaps unsurprisingly , given the hardness of the problem under fixed thresholds ) . The second example , however , shows that even with independent uniform thresholds an optimizer with the power to apply fractional influence can see an improvement of up to a factor of ( 1 − 1/e ) .
Example 1 . The following example shows that when thresholds are fixed , the optimal objective values in the fractional and integral cases can differ by as much as a factor of n , where n is the number of vertices in the graph . The instance we consider is a DAG consisting of a single , directed path of n vertices . Each edge in the path has weight 1/(n + 1 ) , and every vertex on the path has threshold 2/(n + 1 ) . Note that since thresholds are strictly greater than edge weights , and every vertex , being on a simple path , has in degree at most one , it is impossible for a vertex to be activated without some direct influence being applied to it .
Consider our problem on the above graph with budget 1 .
In the integral case , we cannot split this influence , and so we may apply influence to – and hence activate – at most one vertex . On the other hand , in the fractional case the following strategy guarantees that all vertices are activated . Apply 2/(n+1 ) influence to the earliest vertex , and 1/(n + 1 ) influence to the remaining ( n − 1 ) vertices . Now , this activates the earliest vertex directly ; furthermore , every other vertex has sufficient direct influence to activate it any time the vertex preceding it does . Thus , a simple induction proves the claim , giving us a factor n gap between the optimal integral and fractional solutions .
Example 2 . Consider solving our problem on a directed graph consisting of a single ( one directional ) cycle with n vertices . Assume that every edge has weight 1 − K/n , where K is some parameter to be fixed later , and that thresholds on nodes are drawn from U [ 0 , 1 ] . We consider the optimal integral and fractional influence to apply .
In the fractional case , consider applying influence of exactly K/n to every node . Note that for any node , the amount of influence we apply directly plus the weight on its sole incoming edge sum to 1 . Thus , any time a node ’s predecessor on the cycle becomes activated , the node will become activated as well . Inductively , we can then see that any time at least one node is activated in the cycle , every node will eventually become activated . This means that the expected number of activated nodes under this strategy is precisely n · Pr[At least one node activates ] = n(1 − Pr[Every node ’s threshold is above K/n ] )
= n(1 − ( 1 − K/n)n ) .
5
In the integral case , however , we cannot spread our influence perfectly evenly . Each node we activate has some chance to activate the nodes that are after it but before the next directly activated node in the cycle . If we have an interval of length ℓ between directly activated nodes ( including the initial node we activate directly as one of the ℓ nodes in the interval ) , we can see that the expected number of nodes activated in the interval is
ℓ
Xi=1
Pr[Node i in the interval is activated ] = 1 +
ℓ
ℓ
Xi=2
Pr[Nodes 2 , 3 , . . . , i have thresholds below 1 − K/n ]
=
( 1 − K/n)i−1 =
Xi=1
1 − ( 1 − K/n)ℓ
K/n
.
While this tells us the expected value for a single interval , we want to know the expected value summed over all intervals . Observing from the above calculation that the benefit of adding another node to an interval is strictly decreasing in the length of the interval , we can see that we should always make the lengths of the intervals as close to equal as possible . Noting that the lengths of the intervals always sum to n , then , we can see that the total number of nodes activated in expectation is bounded by
K
1 − ( 1 − K/n)n/K
K/n
= n(1 − ( 1 − K/n)n/K ) .
Note , however , that if we choose K ≈ ln n , we get that
1 − ( 1 − K/n)n/K 1 − ( 1 − K/n)n ≈ 1 − 1/e .
3 Reduction
In this section , we extend the submodularity results of Mossel and Roch [ 18 ] for the integral version of Influence Maximization to the fractional version ; this implies that , as in the integral version , the fractional version admits a greedy ( 1 − 1/e − ε) approximation algorithm . At a high level , our approach revolves around reducing a fractional instance to an integral one , such that evolution of the process and objective values are preserved . Thus , before presenting our extension , we begin by stating the main result of [ 18 ] . Before stating the theorems , however , we give definitions for the function properties each requires . Finally , we note that our main result of the section ( Theorem 2 ) considers a discretization of the input space ; at the end of this section we show that such discretization cannot affect our objective value by too much .
We begin by giving definitions for the following properties of set functions . Given a set N and a function f : 2N → R , we say that :
• f is normalized if f ( ∅ ) = 0 ;
• f is monotone if f ( S ) ≤ f ( T ) for any S ⊆ T ⊆ N ; and
• f is submodular if f ( S ∪ {x} ) − f ( S ) ≥ f ( T ∪ {x} ) − f ( T ) for any S ⊆ T ⊆ N and x ∈ N \ T .
We say that a collection of functions satisfies the above properties if every function in the collection does . With the above definitions in hand , we are now ready to state the following result of Mossel and Roch .
6
Theorem 1 . ( Restatement of [ 18 , Theorem 1.6 ] ) Let I = ( V , F , w ) be an instance of integral Influence Maximization . If both w and F are normalized , monotone , and submodular , then σ is as well .
We want to extend Theorem 1 to the fractional influence model . We proceed by showing that for arbitrarily fine discretizations of [ 0 , 1 ] , any instance of our problem considered on the discretized space can be reduced to an instance of the original problem . Fix N ∈ Z+ , and let δ = 1/N > 0 be our discretization parameter . Let ∆ = {0 , δ , 2δ , . . . , 1} . We consider the fractional objective function σ restricted to the domain ∆n . Lastly , let δv be the vector with δ in the component corresponding to v , and 0 in all other components . We extend the relevant set function properties to this discretized space as follows :
• we say f is normalized if f ( 0 ) = 0 ;
• we say f is monotone if x ≤ y implies f ( x ) ≤ f ( y ) ; and
• we say f is submodular if for any x ≤ y , and any v ∈ V , either yv = 1 or f ( x + δv ) − f ( x ) ≥ f ( y + δv ) − f ( y ) , where all comparisons and additions between vectors above are componentwise . We get the following extension of Theorem 1 .
Theorem 2 . Let I = ( V , F , w ) be an instance of fractional Influence Maximization . For any discretization ∆n of [ 0 , 1]n ( as defined above ) , if both w and F are normalized , monotone , and submodular , then σ is normalized , monotone , and submodular on ∆n .
Proof . We prove this by reducing an instance of the ( discretized ) fractional problem for I to an instance of the integral influence problem and then applying Theorem 1 . We begin by modifying I to produce a new instance ˆI = ( ˆV , ˆF , ˆw ) . Then , we show that ˆF and ˆw will retain the properties of normalization , monotonicity , and submodularity . Lastly , we show a mapping from ( discretized ) fractional activations for I to integral activations for ˆI such that objective values are preserved , and our desired fractional set function properties for σ correspond exactly to their integral counterparts for the objective function ˆσ for ˆI . The result then follows immediately from Theorem 1 .
We begin by constructing the instance ˆI . The key idea is that we can simulate fractional activation with integral activation by adding a set of dummy activator nodes for each original node ; each activator node applies an incremental amount of influence on its associated original node . Then , for each original node we just need to add the influence from activator nodes to that from the other ( original ) nodes , and truncate the sum to one . Fortunately , both of the aforementioned operations preserve the desired properties . Lastly , in order to avoid the activator nodes interfering with objective values , we simply need to give them weight zero . With this overview in mind , we now define ˆI = ( ˆV , ˆF , ˆw ) formally .
First , we construct ˆV . For each node v ∈ V , create a set Av = {v1 , v2 , . . . , v1/δ} of activator nodes for v . We then set
We now proceed to define the functions ˆfˆv for each ˆv ∈ ˆV . If ˆv is an activator node for some v ∈ V , we simply set ˆfˆv ≡ 0 ; otherwise , ˆv ∈ V and we set
ˆV = V ∪,Sv∈V Av .
ˆfˆv(S ) = min ( fˆv(S ∩ V ) + δ|S ∩ Aˆv| , 1 ) for each S ⊆ ˆV . Lastly , we set
ˆw(S ) = w(S ∩ V )
7 for all S ⊆ ˆV . Together , these make up our modified instance ˆI .
We now show that since w and F are normalized , monotone , and submodular , ˆw and ˆF will be as well . We begin with ˆw , since it is the simpler of the two . Now , ˆw is clearly normalized since ˆw(∅ ) = w(∅ ) . Now , fix any S ⊆ T ⊆ ˆV . First , observe we have that S ∩ V ⊆ T ∩ V , and so by the monotonicity of w . Second , let ˆu ∈ ˆV \ T . If ˆu ∈ V ,
ˆw(S ) = w(S ∩ V ) ≤ w(T ∩ V ) = ˆw(T ) ,
ˆw(S ∪ {ˆu} ) − ˆw(S ) = w((S ∩ V ) ∪ {ˆu} ) − w(S ∩ V ) ≥ w((T ∩ V ) ∪ {ˆu} ) − w(T ∩ V ) = ˆw(T ∪ {ˆu} ) − ˆw(T ) , since w is submodular . On the other hand , if ˆu /∈ V , we immediately get that
ˆw(S ∪ {ˆu} ) − ˆw(S ) = 0 = ˆw(T ∪ {ˆu} ) − ˆw(T ) .
Thus , ˆw is normalized , monotone , and submodular .
Next , we show that ˆF is normalized , monotone , and submodular . For ˆv ∈ ˆV \ V , it follows trivially since ˆF is identically 0 . In the case that ˆv ∈ V , it is less immediate , and we consider each of the properties below .
• ˆfˆv normalized . This follows by computing
ˆfˆv(∅ ) = min ( fˆv(V ∩ ∅ ) + δ|Aˆv ∩ ∅| , 1 ) = min ( fˆv(∅ ) + δ|∅| , 1 ) = 0 , since fˆv is normalized .
• ˆfˆv monotone . Let S ⊆ T ⊆ ˆV . Then we have both S ∩ V ⊆ T ∩ V and S ∩ Aˆv ⊆ T ∩ Aˆv . Thus , we can see that fˆv(V ∩ S ) ≤ fˆv(V ∩ T ) and |Aˆv ∩ S| ≤ |Aˆv ∩ T | , where the former follows by the monotonicity of fˆv . Combining these , we get that fˆv(V ∩ S ) + δ|Aˆv ∩ S| ≤ fˆv(V ∩ T ) + δ|Aˆv ∩ T | .
Note that if we replace the expression on each side of the above inequality with the minimum of 1 and the corresponding expression , the inequality must remain valid . Thus , we may conclude that ˆfˆv(S ) ≤ ˆfˆv(T ) .
• ˆfˆv submodular . For any S ⊆ ˆV and ˆu ∈ ˆV \ S , define the finite difference
Dˆu ˆfˆv(S ) = ,fˆv(V ∩ ( S ∪ {ˆu} ) ) + δ|(S ∪ {ˆu} ) ∩ Aˆv| − ,fˆv(V ∩ S ) + δ|S ∩ Aˆv| .
Observe that whenever ˆu /∈ V , we immediately have that
Similarly , since ˆu /∈ S , it is easy to see that the difference fˆv(V ∩ ( S ∪ {ˆu} ) ) − fˆv(V ∩ S ) = 0 .
|(S ∪ {ˆu} ) ∩ Aˆv| − |S ∩ Aˆv| = 1
8 whenever ˆu ∈ Aˆv , and is 0 otherwise . With the above two observations in hand , we can simplify our finite difference formula as fˆv,S ∪ {ˆu} ) − fˆv(S )
δ 0 if ˆu ∈ V ; if ˆu ∈ Aˆv ; and otherwise .
Dˆu ˆfˆv(S ) = 
Now , fix some S ⊆ T ⊆ ˆV , and ˆu ∈ ˆV \ T . By the submodularity of fˆv , the above equation immediately implies that Dˆu ˆfˆv(S ) ≥ Dˆu ˆfˆv(T ) . Applying case analysis similar to that for the monotonicity argument , we can see that this implies that
ˆfˆv(S ∪ {ˆu} ) − ˆfˆv(S ) ≥ ˆfˆv(T ∪ {ˆu} ) − ˆfˆv(T ) , ie that ˆfˆv is submodular .
Thus , ˆF is normalized , monotone , and submodular on ˆV , exactly as desired . As such , we can apply Theorem 1 to our function and get that for our modified instance ˆI = ( ˆV , ˆF , ˆw ) , the corresponding function ˆσ must be normalized , monotone , and submodular . All that remains is to demonstrate our claimed mapping from ( discretized ) fractional activations for I to integral activations for ˆI .
We do so as follows . For each v ∈ V and each d ∈ ∆ , let Ad v = {v1 , v2 , . . . , vd/δ} . Then , given the vector x ∈ ∆n , we set v , where xv is the component of x corresponding to the node v .
S x =Sv∈V Axv
We first show that under this definition we have that σ(x ) = ˆσ(S x ) . In fact , as we will see the sets influenced will be the same not just in expectation , but for every set of thresholds Θ for the vertices V . Note that in the modified setting ˆI we also have thresholds for each vertex in ˆV \ V ; however , since we chose ˆfˆv ≡ 0 for all ˆv ∈ ˆV \ V , and thresholds are independent draws from U [ 0 , 1 ] , we have that with probability 1 we have ˆfˆv(S ) < θˆv for all S and all ˆv ∈ ˆV \ V . Thus , in the following discussion we do not bother to fix these thresholds , as their precise values have no effect on the spread of influence . n and ˆSΘ n be the influenced sets in each round in the setting I with influence vector x and in the setting ˆI with influence set S x , respectively . We can show by induction that for all i = 0 , 1 , . . . , n , we have ˆSΘ i . By the definition of ˆw , this immediately implies that w(SΘ
Fix some vector Θ of thresholds for the vertices in V . Let SΘ i ∩ V = SΘ
1 , . . . , ˆSΘ
1 , . . . , SΘ
We prove our claim by induction . For i = 0 , the equality follows simply by our definitions of the processes , since S0 = ∅ and ˆS0 = S x . Now , assuming the claim holds for i − 1 , we need to show that it holds for i . By our definition of the processes , we know that n ) = ˆw( ˆSΘ n ) , as desired .
SΘ i = SΘ i−1 ∪ {v ∈ V \ SΘ i−1 : fv(SΘ i−1 ) + xv ≥ θv} ; similarly , we have that i = ˆSΘ ˆSΘ i−1 ∪ {ˆv ∈ ˆV \ ˆSΘ i−1 : ˆfˆv( ˆSΘ i−1 ) ≥ θˆv} .
Recall , however , that for all ˆv ∈ ˆV \ V , we have that ˆfˆv ≡ 0 , and it follows that ˆSΘ Thus , we can rewrite the second equality above as i \ V = S x for all i .
ˆSΘ i = ˆSΘ i−1 ∪ {v ∈ V \ ˆSΘ i−1 : ˆfv( ˆSΘ i−1 ) ≥ θv} .
9
Consider an arbitrary v ∈ V \ SΘ i−1 = V \ ˆSΘ i−1 . Now , we know that v ∈ ˆSΘ i if and only if
θv ≤ ˆfv( ˆSΘ i−1 ) = min(fv( ˆSΘ i−1 ∩ V ) + δ| ˆSΘ i−1 ∩ Av| , 1 ) .
Recall , however , that ˆSΘ i−1 ∩ V = SΘ i−1 by assumption . Furthermore , we can compute that
| ˆSΘ i−1 ∩ Av| = |S x ∩ Av| = |Axv v | = |{v1 , . . . , vxv }| = xv/δ .
Thus , since we know that θv ≤ 1 always , we can conclude that v ∈ ˆSΘ i ∩ V if and only if
θv ≤ fv(SΘ i−1 ) + xv , which is precisely the condition for including v in SΘ i . Thus , we can conclude that ˆSΘ i ∩ V = SΘ i .
We have now shown that for all vectors of thresholds Θ for vertices in V , with probability 1 we have n ) . for i = 0 , 1 , . . . , n . In particular , note that ˆSΘ n , and so ˆw( ˆSΘ n ∩ V = SΘ n ) = w(SΘ i ∩ V = SΘ i that ˆSΘ Thus , we may conclude that ˆσ(S x ) = σ(x ) .
Lastly , we need to show that for our given mapping from ( discretized ) fractional activation vectors x to set S x , we have that the desired properties for σ are satisfied if the corresponding properties are satisfied for ˆσ . So we assume that ˆσ is normalized , monotone , and submodular ( as , in fact , it must be by the above argument and Theorem 1 ) , and show that σ is as well . We begin by noting that x = 0 implies S x = ∅ , and so σ(0 ) = ˆσ(∅ ) = 0 . Now , let x , y ∈ ∆n such that x ≤ y componentwise . First , we must have that S x ⊆ S y and so
σ(x ) = ˆσ(S x ) ≤ ˆσ(S y ) = σ(y ) .
Second , pick some v ∈ V such that yv < 1 . Recall our definition of ˆfˆv ; by inspection , we have ˆfˆv(S ) = ˆfˆv(T ) any time both S ∩ V = T ∩ V and |S ∩ Av| = |T ∩ Av| , for any S , T ∈ ˆV . Thus , we have S x+δv = S x ∪ {v(xv /δ)+1} and S y+δv = S y ∪ {v(yv /δ)+1} . So we have
σ(x + δv ) − σ(x ) = ˆσ(S x ∪ {v(xv /δ)+1} ) − ˆσ(S x ) = ˆσ(S x ∪ {v(yv /δ)+1} ) − ˆσ(S x ) ≥ ˆσ(S y ∪ {v(yv /δ)+1} ) − ˆσ(S y ) = σ(y + δv ) − σ(y ) .
Thus , σ has the claimed properties on ∆n ; the result follows .
In fact , we can use the same technique to achieve the following extension to fully continuous versions of our properties . We define the following properties for σ on the continuous domain [ 0 , 1]n :
• we say f is normalized if f ( 0 ) = 0 ;
• we say f is monotone if x ≤ y implies f ( x ) ≤ f ( y ) ; and
• we say f is submodular if for any x ≤ y , any v ∈ V , and for any ε > 0 such that yv + ε ≤ 1 , we have that f ( x + εv ) − f ( x ) ≥ f ( y + εv ) − f ( y ) , where εv is the vector with a value of ε in the coordinate corresponding to v and a value of 0 in all other coordinates . As before , all comparisons and additions between vectors above are componentwise . The same techniques immediately give us the following theorem .
10
Theorem 3 . Let I = ( V , F , w ) be an instance of our problem . If both w and F are normalized , monotone , and submodular , then σ is normalized , monotone , and submodular on [ 0 , 1]n .
Proof . We use the exact same technique as in the proof of Theorem 2 . The only difference is how we define the activator nodes in our modified instance ˆI . Here , rather than trying to model the entire domain , we simply focus on the points we want to verify our properties on . To that end , fix some x ≤ y , as well as an ε > 0 and some v ∈ V . We will only define three activator nodes here : ax , ax−y , and aε . The first two contributes amounts of xv′ and ( yv′ − xv′ ) ≥ 0 , respectively , to the modified influence function for vertex v′ ∈ V . The last contributes an amount of ε to the influence function for vertex v , and makes no contribution to any other influence functions . As before , all influence functions get capped at one . Our modified weight function is defined exactly as before , and it is easy to see that exactly the same argument will imply that the modified weight and influence functions will be normalized , monotone , and submodular , allowing us to apply Theorem 1 .
Thus , all that remains is to relate the function values between the original and modified instances . Note , however , that here it is even simpler than in the discretized case . If ˆσ is the objective for ˆI , then we can compute that :
σ(0 ) = ˆσ(∅ ) ; σ(x ) = ˆσ({ax} ) ; σ(y ) = ˆσ({ax , ay−x} ) ; σ(x + εv ) = ˆσ({ax , aε} ) ; and σ(y + εv ) = ˆσ({ax , ay−x , aε} ) .
We can use the above inequalities to show the desired qualities for σ , via a simple case analysis and their discrete counterparts for ˆσ .
One concern with discretizing the space we optimize over as in Theorem 2 is what effect the discretization has on the objective values that can be achieved . As the following theorem shows , however , we can only lose a δn/K factor from our objective when we discretize the space to multiples of δ .
Theorem 4 . Let I = ( V , F , w ) be an instance of our problem . Then for any discretization ∆n of [ 0 , 1]n ( as defined above ) , if σ is normalized , monotone , and submodular on ∆n , we have that max x∈∆n : kxk1≤K
σ(x ) ≥ ( 1 − δ n
K ) max x∈[0,1]n : kxk1≤K
σ(x ) , for any K .
Proof . Let x∗ be an optimal solution to our problem on [ 0 , 1]n , ie we have x∗ = argmax x∈[0,1]n:kxk1≤K
σ(x ) . v = min{d ∈ ∆ : d ≥ x∗
Let ¯x∗ be the result of rounding x∗ up componentwise to the nearest element of ∆n . Formally , we define ¯x∗ by ¯x∗ v} . Note that by monotonicity , we must have that σ(¯x∗ ) ≥ σ(x∗ ) ; we also have that k¯x∗k1 ≤ kx∗k1 + δn . Now , consider constructing ¯x∗ greedily by adding δ to a single coordinate in each step . Formally , set x0 = 0 , and for each i = 1 , 2 , . . . , k¯x∗k1/δ set xi = xi−1 + δv for some v ∈ argmax v <¯x∗ v : xi−1 v
( σ(xi−1 + δv ) − σ(xi−1) ) ,
11 where ( as before ) δv is a vector with δ in the component corresponding to v and 0 in all other components . Note that the submodularity of σ implies that σ(xi)−σ(xi−1 ) is decreasing in i . An immediate consequence of this is that , for any i , we have that
Invoking the above for i = K/δ we get that
σ(xi ) ≥ i k¯x∗k1/δ
σ(¯x∗ ) .
σ(xK/δ ) ≥
K/δ k¯x∗k1/δ
σ(¯x∗ ) ≥
K
K +δn
σ(¯x∗ ) ≥ ( 1 − δ n
K )σ(¯x∗ ) .
We observe that kxK/δk1 = K , and xK/δ ∈ ∆n , and so the desired theorem follows .
By combining the above theorems , we can apply the same results as [ 15 ] to get the following corollary
( see that paper and references therein for details ) .
Corollary 5 . There exists a greedy ( 1 − 1/e − ε) approximation for maximizing σ(x ) in both the discretized and continuous versions of the fractional influence model .
4 DAGs
In this section , we focus on a special case of fractional influence model called the linear influence model , and argue that some aspects of the problem become simpler on DAGs when the thresholds are uniformly distributed . Our interest in DAGs is motivated by the fact that the hardness results presented in the next section all hold for DAGs . In the linear variant of the problem , our influence functions are computed as follows . We are given a digraph G = ( V , E ) and a weight function w on edges . We use δ ( v ) to denote the sets of nodes with edges to v and edges from v , respectively . Then , we denote the influence function fv for v by
( v ) and δ
−
+ fv(S ) = Xu∈S∩δ− ( v ) wuv .
In this model , we assume that Pu∈δ− ( v ) wuv ≤ 1 always . Similar to the fractional influence model , our goal is to pick an influence vector x ∈ [ 0 , 1]|V | indexed by V to maximize
σ(x ) = E Θ
[ |SΘ n | | we apply direct influences x ] ,
1 , . . . , SΘ where SΘ n is the sequence of sets of nodes activated under thresholds Θ and direct influence x . We sometimes abuse notation and use σ(S ) to denote σ applied to the characteristic vector of the set S ∈ 2V . Given a DAG G = ( V , E ) and a fractional influence vector x ∈ [ 0 , 1]|V | indexed by V , we define the sets
I(x ) = {v ∈ V : xv > 0} , and
S(x ) = {v ∈ V : xv +Pu∈δ− ( v ) wuv > 1} , as the sets of nodes influenced by x and ( over )saturated by x . Note that S(x ) ⊆ I(x ) . Next , we show that under specific circumstances , σ becomes a linear function and therefore the influence maximization problem efficiently solvable .
12
Theorem 6 . Given a DAG G and influence vector x , if G contains no path from an element of I(x ) to any element of S(x ) , then we have that and therefore the influence maximization problem can be solved efficiently restricted to vectors x meeting this condition .
σ(x ) =Pv∈V xvσ(1v ) ,
Proof . We prove this by induction on the number of vertices . In the case that V contains only a single vertex , the claim is trivial . Otherwise , let G = ( V , E ) and x satisfy our assumptions , with |V | = n > 1 , and assume out claim holds for any DAG with ( n − 1 ) or fewer nodes . Let s ∈ V be a source vertex ( ie have in degree 0 ) in G . Now , if s /∈ I(x ) , we know that s is never activated . Let ˆσ and ˆx be σ on G restricted to V \ s and x restricted to V \ s , respectively , and observe that we may apply our induction hypothesis to ˆσ(ˆx ) since removing s from G cannot cause any of the requirements for our theorem to become violated . Thus , since xs = 0 , we can see that
σ(x ) = ˆσ(ˆx ) = Xv∈V \s xv ˆσ(1v ) = Xv∈V xvσ(1v ) .
Now , assume that s ∈ I(x ) . Recall that our conditions on G ensures it contains no path from s to any elements of S(x ) . Furthermore , this implies none of the nodes in δ ( s ) have paths to elements of S(x ) either , and so applying influence to them does not violate the assumptions of our inductive hypothesis , as long as we ensure we do not apply enough influence to ( over )saturate them .
+
In order to prove our claim , we focus on G restricted to V \ {s} , call it ˆG . Let ˆσ be σ over ˆG , and consider the following two influence vectors for ˆG . Define ˆx to simply be the restriction of x to ˆG ; define ( s ) and 0 otherwise . Letting ˆI and ˆS be I and S , respectively , restricted to ˆG , we ˆy by ˆyv = wsv if v ∈ δ have
+
( 1 )
ˆI(ˆx ) , ˆI(ˆy ) , ˆI(ˆx + ˆy ) ⊆ I(x ) ∪ δ ˆS(ˆx ) , ˆS(ˆy ) , ˆS(ˆx + ˆy ) ⊆ S(x ) .
+
( s ) , and
)
The observation that gives the above is that , compared to x , the only vertices with increased influence applied to them are the elements of δ ( s ) , and the amounts of these increases are precisely balanced by the removal of s ( and its outgoing edges ) from ˆG . In particular , note that for any v ∈ V \ {s} , by our definition of ˆy we have that
+ xv + Xu∈δ− ( v ) wuv = ˆxv + ˆyv + Xu∈δ− ( v)\{s} wuv .
+
As previously noted G contains no paths from an element of δ
( s ) to any element of S(x ) ; this combined with ( 1 ) allows us to conclude that we may apply our induction hypothesis to ˆG with any of ˆx , ˆy , or ˆx + ˆy . We proceed by showing that for any vector Θ of thresholds for G ( and its restriction to ˆG ) , we have that the set activated under x in G always corresponds closely to one of the sets activated by ˆx or ( ˆx + ˆy ) in ˆG . To that end , fix any vector Θ . We consider the cases where xs ≥ θs and xs < θs separately . We begin with the case where xs < θs , since it is the simpler of the two . Let SΘ n and n denote the sets activated in G under x and in ˆG under ˆx , respectively , in stages 0 , . . . , n . Note 0 , . . . , ˆSΘ ˆSΘ that since s is a source , and xs < θs , we know that s /∈ SΘ for all i . However , this means that every node i in V \ {s} has both the same direct influence applied to it under x and ˆx , and the same amount of influence applied by any activated set in both G and ˆG . So we can immediately see that since SΘ 0 , by induction we will have that SΘ for all i , and in particular for i = n .
0 = ∅ = ˆSΘ
0 , . . . , SΘ i = ˆSΘ i
13
The case where xs ≥ θs requires more care . Let SΘ n denote the sets activated in G under x and in ˆG under ˆx + ˆy , respectively , in stages 0 , . . . , n . Note that our assumption implies that s will be activated by our direct influence in the first round , and so we have s ∈ ˆSΘ for all i ≥ 1 . Fix some i v ∈ V , v 6= s , and let fv(S ) and ˆfv(S ) denote the total influence – both direct and cascading – applied in G and ˆG , respectively , when the current active set is S . Then , for any S ⊆ V \ {s} we have
0 , . . . , SΘ
0 , . . . , ˆSΘ n and ˆSΘ
ˆfv(S ) = ˆxv + ˆyv + Xu∈δ
−
( v ) u∈S wuv
= xv + Xu∈δ
−
( v ) u∈S∪{s} wuv = fv(S ∪ {s} ) .
( 2 ) i for all i in this case , we will instead show that SΘ
Furthermore , note that both fv and ˆfv are always monotone nondecreasing . While we cannot show that i = ˆSΘ SΘ i+1\{s} for all i = 0 , . . . , n−1 . Recall that the propagation of influence converges by n steps . That is , if we continued the process for an n+1 = ˆSΘ additional step to produce activated sets SΘ n . However , our claim would extend to this extra stage as well , and so we conclude that we must have that n = ˆSΘ SΘ n ∪ {s} . We prove our claim inductively . First , observe that it holds trivially for i = 0 , since we 0 = ˆSΘ have SΘ 1 . Now , the claim holds for some i . Note , however , that by ( 2 ) and monotonicity we must have that for all v ∈ V , v 6= s
0 = ∅ , and previously observed that s ∈ SΘ n+1 , we would have that SΘ i \{s} ⊆ ˆSΘ n+1 and ˆSΘ n+1 = SΘ n and ˆSΘ i ⊆ SΘ fv(SΘ i ) = ˆfv(SΘ ≤ ˆfv(SΘ i \ {s} ) ≤ ˆfv( ˆSΘ i ) i+1 \ {s} ) = fv(SΘ i+1 ) .
From the above , we can conclude that Si+1 \ {s} ⊆ ˆSΘ of the above sets if and only if fv(SΘ i ) , or fv(SΘ i ) , ˆfv( ˆSΘ i+1 ⊆ SΘ i+1 ) , respectively , exceeds θv . i+2 \ {s} since such a v in included in each
Thus , by observing that θs is an independent draw from U [ 0 , 1 ] , we can see that taking expectations over
Θ and conditioning on which of θs and xs is larger gives us that
σ(x ) = ( 1 − xs)ˆσ(ˆx ) + xs(1 + ˆσ(ˆx + ˆy ) ) xvσ(1v ) + xs(1 + ˆσ(ˆy) ) .
= Xv∈V v6=s
We complete our proof by observing that σ(1s ) is precisely equal to 1 + ˆσ(ˆy ) . We can show this , once again , by coupling the activated sets under any vector Θ of thresholds . In particular , let SΘ n and n denote the sets activated in G under 1s and in ˆG under ˆy , respectively , in stages 0 , . . . , n . ˆSΘ 0 , . . . , ˆSΘ Arguments identical to those made above allow us to conclude that for all i , we have SΘ i ∪ {s} . Thus , by again noting that influence cascades converge after n steps we have SΘ n ∪ {s} , and taking expectations with respect to Θ gives precisely the desired equality . i+1 = ˆSΘ
0 , . . . , SΘ n = ˆSΘ
Since we have that σ is linear , we can maximize σ(x ) by greedily applying influence to the vertex with the highest σ(1v ) until the budget is exhausted . Estimating σ(1v ) can be done by repeating the process with influence vector 1v several times , and averaging the number of activated nodes in these trials .
14
In particular , note that the above theorem says that if we want to find the best set of vertices to influence among those in the first layer of a multi layer DAG , we can efficiently solve this exactly.2
We may also express our optimization problem on DAGs in the integral case as the following MIP :
( Xv + Yv ) subject to maximizeXv
Xv + Yv ≤ 1
Yv − Xu∈δ− ( v ) wuv(Yu + Xu ) ≤ 0
Xv
Xv ≤ K
Xv ∈ {0 , 1} Yv ∈ [ 0 , 1 ]
∀v
∀v
∀v ∀v
5 Hardness
In this section , we present NP hardness and inapproximability results in the linear influence model . We assume that thresholds are not chosen from a distribution , and they are fixed and given as part of the input . We note that this is the main assumption that makes our problem intractable , and to achieve reasonable algorithms , one has to make some stochastic ( distributional ) assumptions on the thresholds . In Section 4 , we introduced the linear influence model as a special case of the fractional influence model , but it makes sense to define it as a special case of the integral influence model as well . In the fractional linear influence model , we are allowed to apply any influence vector x ∈ [ 0 , 1]n on nodes . By restricting the influence vector x to be in {0 , 1}n ( a binary vector ) , we achieve the integral version of the linear influence model . Our hardness results in Theorem 7 and Corollary 8 work for both fractional and integral versions of the linear influence model . We start by proving that the linear influence model is NP hard with a reduction from Independent Set in Theorem 7 . We strengthen this hardness result in Corollary 8 by showing that an n1−ε approximation algorithm for the linear influence problem yields an exact algorithm for it as well for any constant ε > 0 , and therefore even an n1−ε approximation algorithm is NP hard to achieve . At the end , we show that it is NP hard to achieve any approximation factor better than 1 − 1/e in the Triggering model ( a generalization of the linear threshold model introduced in [ 15] ) . We will elaborate on the Triggering Model and this hardness result at the end of this section .
Theorem 7 . If we allow arbitrary , fixed thresholds , it is NP hard to compute for a given instance of the integral linear influence problem ( G , k , T ) ( graph G , budget k , and a target goal T ) whether or not there exists a set S of k vertices in G such that σ(S ) ≥ T . Furthermore , the same holds in the fractional version of the problem ( instead of a set S of size k , we should look for a influence vector with ℓ1 norm equal to k in the fractional case ) . Additionally , this holds even when G is a two layer DAG and only vertices in the first layer may be influenced .
Proof . We show hardness by reducing from Independent Set . Given a problem instance ( G , k ) of IS , we construct a two layer DAG as follows . Let G = ( V , E ) denote the vertices and ( undirected ) edges of G . The first layer L1 consists of one vertex for every vertex v ∈ V ; we abuse notation and refer to the vertex in L1
2Note that the hardness results Theorem 7 and Corollary 8 in the next section hold exactly for such DAG problems , but with fixed thresholds instead of uniform ones .
15 corresponding to v ∈ V as v as well . The second layer contains vertices based on the edges in E . For each unordered pair of vertices {u , v} in V , we add vertices to the second layer L2 based on whether {u , v} is an edge in G : if {u , v} ∈ E , then we add a single vertex to L2 with ( directed ) edges from each of u , v ∈ L1 to it ; if {u , v} /∈ E , then we add two vertices to L2 , and add ( directed ) edges going from u ∈ L1 to the first of these and from v ∈ L1 to the second of these . We set all activation thresholds and all edge weights in our new DAG to 1/2 . We claim that there exists a set S ⊆ L1 ∪ L2 satisfying |S| ≤ k and σ(S ) ≥ kn if and only if G has an independent set of size k .
First , we note that in our constructed DAG , sets S ⊆ L1 always dominate sets containing elements outside of L1 , in the sense that for any T ⊆ L1 ∪ L2 there always exists a set S ⊆ L1 such that |S| ≤ |T | and σ(S ) ≥ σ(T ) . Consider an arbitrary such T . Now , consider any vertex v ∈ T ∩ L2 . By construction , there exists some u ∈ L1 such that ( u , v ) is an edge in our DAG . Note that |T \ {v} ∪ {u}| ≤ |T | and σ(T \ {v} ∪ {u} ) ≥ σ(T ) . Thus , if we repeatedly replace T with T \ {v} ∪ {u} for each such v , we eventually with have the desired set S .
With the above observation in hand , we can be assured that there exists a set S of k vertices in our constructed DAG such that σ(S ) ≥ nk if and only if there exists such an S ⊆ L1 . Recall how we constructed the second layer of our DAG : each vertex v ∈ L1 has precisely ( n−1 ) neighbors ; and two vertices u , v ∈ L1 share a neighbor if and only if they are neighbors in the original graph G , in which case they have exactly one shared neighbor . Thus , we can see that for any set of vertices S ⊆ L1 , we have that
σ(S ) = n|S| − |{{u , v} ∈ E : u , v ∈ S}| .
Thus , we can see that for any set S ⊆ L1 , we have σ(S ) ≥ n|S| if and only if {u , v} /∈ E for any u , v ∈ S , ie S is an independent set in G . The main claim follows .
Furthermore , recall that in our constructed DAG , every edge weight and threshold was exactly equal to 1/2 . It is not hard to see , therefore , that in the fractional case it is never optimal to place an amount of influence on a vertex other than 0 or 1/2 . It follows , therefore , that there is a 1 − 1 correspondence between optimal optimal solutions in the integral case with budget k and in the fractional case with budget k/2 . Thus , as claimed , the hardness extends to the fractional case .
Corollary 8 . If we allow arbitrary , fixed thresholds , it is NP hard to approximate the linear influence problem to within a factor of n1−ε for any ε > 0 . Furthermore , the same holds for the fractional version of our problem . Additionally , this holds even when G is a three layer DAG and only vertices in the first layer may be influenced .
Proof . We show that given an instance ( G , k ) of Target Set Selection , and a target T , we can construct a new instance ( G′ , k ) , such that if we can approximate the optimal solution for the new instance ( G′ , k ) to within a factor of n1−ε , then we can tell whether the original instance ( G , k ) had a solution with objective value at least T . The claim then follows by applying Theorem 7 .
Fix some δ > 0 . Let n be the number of vertices in G . Note that we must have that 0 < k < T ≤ n , since if any one of these inequalities fails to hold , the question of whether or not ( G , k ) has a solution with objective value at least T can be answered trivially . Let N = ⌈(2n2)1/δ⌉ ; we construct G′ from G by adding N identical new vertices to it . Let v be one of our new vertices . For every vertex u that was present in G , we add an edge from u to v in G′ , with weight 1/n . We set the threshold of v to be precisely T /n .
Consider what the optimal objective value in ( G , k ) implies about the optimal objective value in ( G′ , k ) . If there exists some solution to the former providing objective value at least T , then we can see that the same solution will activate every one of the new vertices in G′ as well , and so produce an objective value of at least T +N . On the other hand , assume every solution to G has objective value strictly less than T . Note that
16 in the case of fixed thresholds , the activation process is deterministic , and so we may conclude that every solution has objective value at most T −1 . Now , this means that no matter what choices we make in G′ about the vertices inherited from G , every one of the new vertices will require at least 1/n additional influence to become activated . Thus , no solution for ( G′ , k ) can achieve objective value greater than ( T − 1 ) + kn , in either the integral or fractional case . By our choice of N , however , we can then conclude that the optimal solution for ( G′ , k ) in the first case has value at least
T + N > N ≥ ( 2n2)1/δ > ( T − 1 + kn)1/δ , the value of the optimal solution for ( G′ , k ) in the latter case raised to the power of 1/δ . Thus , for any fixed ε > 0 , we can choose an appropriate δ > 0 such the new instance ( G′ , k ) has increased in size only polynomially from ( G , k ) , but applying an n1−ε approximation to ( G′ , k ) will allow us to distinguish whether or not ( G , k ) had a solution with objective value at least T , exactly as desired .
Before stating Theorem 9 , we define the triggering model introduced in [ 15 ] . In this model , each node v independently chooses a random triggering set Tv according to some distribution over subsets of its neighbors . To start the process , we target a set A for initial activation . After this initial iteration , an inactive node v becomes active in step t if it has a neighor in its chosen triggering set Tv that is active at time t − 1 . For our purposes , the distributions of triggering sets have support size one ( deterministic triggering sets ) . We also show that our hardness result even holds when the size of these sets is two .
Theorem 9 . It is NP hard to approximate the linear influence problem to within any factor better than 1 − 1/e , even in the Triggering model where triggering sets have size at most 2 . Furthermore , this holds even when G is a two layer DAG and only nodes in the first layer may be influenced .
Proof . We prove this by reducing from the Max Coverage problem , which is NP hard to approximate within any factor better than 1 − 1/e . Let ( S , k ) be an instance of Max Coverage , where S = {S1 , . . . , Sm} and Sj ⊆ [ n ] for each j = 1 , . . . , m . We begin by showing a reduction to an instance of Target Set Selection in the Triggering model ; later , we argue that we can do so while ensuring that triggering sets have size at most 2 .
We construct a two layer DAG instance of Target Set Selection as follows . First , fix a large integer N ; we will pick the exact value of N later . The first layer L1 will contain m vertices , each corresponding to one of the sets in S . The second layer L2 contains nN vertices , N of which correspond to each i ∈ [ n ] . We add directed edges from the vertex in L1 corresponding to Sj to all N vertices in L2 corresponding to i for each i ∈ Sj . We set all thresholds and weights in the DAG to 1 . Note that this corresponds exactly to the triggering model , where each vertex in the first layer has an empty triggering set and each vertex in the second layer has a triggering set consisting of exactly the nodes in L1 corresponding to Sj that contain it . This completes the description of the reduction .
Now , we consider the maximal influence we can achieve by selecting k vertices in our constructed DAG . First , we note that we may assume without loss of generality that we only consider choosing vertices from L1 . This is because we can only improve the number of activated sets by replacing any vertex from L2 with a vertex that has an edge to it ; if we have already selected all such vertices , then we can simply replacing it with an arbitrary vertex from L1 and be no worse off . Note , however , that if we select some set W ⊆ L1 of vertices to activate , we will have that
σ(W ) = |W | + N |∪j∈W Sj| .
17
Let W ∗ ∈ argmaxW ⊂L1:|W |≤k σ(W ) . Now , if we have an α approximation algorithm for Target Set Selection , we can find some W ⊆ L1 such that |W | ≤ k and σ(W ) ≥ ασ(W ∗ ) . But this means that
|W | + N |∪j∈W Sj| ≥ α ( |W ∗| + N |∪j∈W ∗Sj| ) , which implies that
|∪j∈W Sj| ≥ α|∪j∈W ∗Sj| − m/N .
( 3 )
Thus , for any ε > 0 , by picking N = ⌈m/ε⌉ we can use our α approximation algorithm for Target Set Selection to produce an α approximation for Max Coverage with an additive loss of ε . Since the objective value for our problem is integral , we may therefore conclude it is NP hard to approximate Target Set Selection within a factor of 1 − 1/e .
In the above reduction , our targeting sets could be as large as m . We know show that we can , in fact , ensure that no targeting set has size greater than 2 . In particular , the key insight is that activation effectively functions as an OR gate over the targeting set . We can easily replace an OR gate with fan in of f by a tree of at most log(f ) OR gates , each with fan in 2 . It is easy to see that if we add such trees of OR gates before L2 , we increase the loss term in Equation ( 3 ) to at most m log(m)/N . We can easily offset this by increasing N appropriately , and so retain our conclusion even when targeting sets have size at most 2 .
6 Experimental Results
Datasets . We use the following real world networks for evaluating our claims . Table 1 gives some statistical information about these networks .
• NetHEPT : An academic collaboration network based on “ High Energy Physics — Theory ” In this network , nodes repThis network is available at section of the e print arXiv3 with papers from 1991 to 2003 . resent authors and edges represent co authorship relationships . http://researchmicrosoftcom/en us/people/weic/graphdatazip
• NetPHY : “ Physics ” edges http://researchmicrosoftcom/en us/people/weic/graphdatazip
Another section represent network , Again , academic the of co authorship e print arXiv . the authors available nodes represent is network taken from collaboration relationships .
The full and at
• Facebook : A surveyed portion of the Facebook friend network . The nodes are anonymized The data is available at
Facebook users and edges represents friendship relationships . http://snapstanfordedu/data/egonets Facebookhtml
3http://wwwarXivorg
Network # nodes NetHEPT 15,233 NetPHY 37,154 Facebook 4,039 Amazon 262,111
# edges Avg . deg . Directed
58,891 231,584 88,234 1,234,877
7.73 12.46 21.84 4.71
No No No Yes
Table 1 : Information about the real world networks we use .
18
• Amazon : Produced by crawling the Amazon website based on the following observation : customers who bought product i also bought product j . In this network , nodes represent products and there is a directed edge from node i to node j if product i is frequently co purchased with product j . This network is based on Amazon data in March 2003 . The data is available at http://snapstanfordedu/data/amazon0302html
Facebook
NetHEPT
12000
10000
8000
6000
4000
2000 s r e t p o d a f o r e b m u n d e t c e p x E
0
0
2500
2000
1500
1000
500 s r e t p o d a f o r e b m u n d e t c e p x E
0
0
DegreeInt
DiscountInt
RandomInt
UniformFrac
DegreeFrac
DiscountFrac
500
1000
1500
Budget
2000
2500
3000
Amazon
DegreeInt
DiscountInt
RandomInt
UniformFrac
DegreeFrac
DiscountFrac
50
100
Budget
150
200
250 s r e t p o d a f o r e b m u n d e t c e p x E
4000
3500
3000
2500
2000
1500
1000
500
0
DegreeInt
DiscountInt
RandomInt
UniformFrac
DegreeFrac
DiscountFrac
0
200
400
600
800
1,000
Budget
NetPHY
DegreeInt
DiscountInt
RandomInt
UniformFrac
DegreeFrac
DiscountFrac
200
400
600
Budget
800
1000
1200
12000
10000
8000
6000
4000
2000 s r e t p o d a f o r e b m u n d e t c e p x E
0
0
Figure 1 : Performance of different algorithms on Facebook , NetHEPT , NetPHY , and Amazon . The weights of edges are defined based on the weighted cascade model . The x axis is the budget and the y axis is the expected number of adopters .
Algorithms . We compare the following algorithms in this study . The first three algorithms are for the integral influence model , and the last three algorithms work for the fractional influence model .
• DegreeInt : A simple greedy algorithm which selects nodes with the largest degrees . This method was used by Kempe et al . [ 15 ] and Chen et al . [ 5 ] as well .
• DiscountInt : A variant of DegreeInt which selects node u with the highest degree in each step . Moreover , after adding node u to the seed set , the algorithm decreases the degrees of neighbors of u by 1 . This method was proposed and evaluated by Chen et al . [ 5 ] .
• RandomInt : This algorithm randomly adds B nodes to the seed set , ie , by spending 1 on each of them . We use this algorithm as a baseline in our comparisons . Other works [ 5 , 6 , 15 ] also use this algorithm as a baseline .
• DegreeFrac : This algorithm selects each node fractionally proportional to its degree . In particular , is the out degree of node i , and m is the this algorithm spends on node i where B is the budget , d− i
19 s r e t p o d a f o r e b m u n d e t c e p x E
3400
3200
3000
2800
00
2
2400
2200
2000 s r e t p o d a f o r e b m u n d e t c e p x E
7000
6500
6000
5500
5000
4500
4000
3500
3000
2500
2000
Facebook
DegreeInt
DiscountInt
RandomInt
UniformFrac
DegreeFrac
DiscountFrac
0
200
400
600
800
1,000
Budget
NetPHY
DegreeInt
DiscountInt
RandomInt
UniformFrac
DegreeFrac
DiscountFrac
NetHEPT
DegreeInt
DiscountInt
RandomInt
UniformFrac
DegreeFrac
DiscountFrac
0
500
1000
1500
Budget
2000
2500
3000
Amazon
DegreeInt
DiscountInt
RandomInt
UniformFrac
DegreeFrac
DiscountFrac s r e t p o d a f o r e b m u n d e t c e p x E
5000
4500
4000
3500
3000
2500
2000
1500
1000
500
0 s r e t p o d a f o r e b m u n d e t c e p x E
400
350
300
250
200
150
100
50
0
0
200
400
600
Budget
800
1000
1200
0
50
100
Budget
150
200
250
Figure 2 : Performance of different algorithms on Facebook , NetHEPT , NetPHY , and Amazon . The weights of edges are defined based on the TRIVALENCY model . The x axis is the budget and the y axis is the expected number of adopters . total number of edges4 .
• DiscountFrac : A heuristic for the fractional case given by Algorithm 1 . Let Γ− v ( A ) be the total sum of the weight of edges from node v to set A , and Γ+ v ( A ) be the total sum of the weight of edges from set A to node v . This algorithm starts with an empty seed set S , and in each step it adds node v 6∈ S with the maximum Γ− v ( S)} on node v . Note that in each step the total influence from the current seed set S to node v is Γ+ v ( S ) , and it is enough to spend 1 − Γ+ v ( S ) for adding node v to the current seed set S . Note that no node would pay a positive amount , and the algorithm spends max{0 , 1 − Γ+ v ( V − S ) to seed set S by spending max{0 , 1 − Γ+ v ( S)} on node v .
• UniformFrac : This algorithm distributes the budget equally among all nodes . We use this algorithm as another baseline in our comparisons .
All these heuristic algorithms are fast and are designed for running on large real world networks . In particular , algorithms DegreeInt and DegreeFrac only need the degree of nodes . We can use a Fibonacci heap to implement DiscountInt , resulting in a running time of O(B log n + m ) . Similarly , the running time of DiscountFrac is O(n log n + m ) using a Fibonacci heap.5 Algorithms RandomInt and UniformFrac are linear time algorithms . It also has been shown that the performance of DiscountInt almost matches the performance of the greedy algorithm which maximizes a submodular function [ 5 ] . Since the greedy
4If the graph is undirected , the cost is 2m instead of m 5In DiscountFrac , the while loop ( lines 4–9 of Algorithm 1 ) may run for n steps even when budget B is less than n . Hence , the running time is O(max{n , B} log n + m ) = O(n log n + m ) instead of O(B log n + m ) .
20
Algorithm 1 DiscountFrac Input : Graph G = ( V , E ) and budget B Output : Influencing vector x
1 : S ← 0 , b ← B , x ← 0 2 : while b > 0 do 3 : 4 : 5 : 6 : 7 : end while 8 : return x u ← argmaxv∈V −S{Γ− xu ← min{b , max{0 , 1 − Γ+ b ← b − xu S ← S ∪ {u} v ( V − S)} u ( S)}} algorithm becomes prohibitively expensive to run for large networks , this motivates us to use DiscountInt as a reasonable benchmark for evaluating the power of the integral influence model .
Results . We have implemented all algorithms in C++ , and have run all experiences on a server with two 6 core/12 thread 3.46GHz Intel Xeon X5690 CPUs , with 48GB 1.3GHz RAM . We run all of the aforementioned algorithms for finding the activation vector/set , and compute the performance of each algorithm by running 10,000 simulations and taking the average of the number of adopters . v the weight of the edge from u to v is 1 d−
We first examine the performance of a fractional activation vector in the weighted cascade model , where , where d− v is the in degree of node v . Note , the total weight of 1 = 1 . This model was proposed by Kempe et al . [ 15 ] , d− v incoming edges of each node isPuv wuv = Puv and it has been used in the literature [ 5 , 6 , 7 ] . See Figure 1 for results .
We then compare the performance of various algorithms when the weight of edges are determined by the TRIVALENCY model , in which the weight of each edge is chosen uniformly at random from the set {0.001 , 0.01 , 01} Here 0.001 , 0.01 , and 0.1 represent low , medium , and high influences . In this model , the total sum of the weights of incoming edges of each node may be greater than 1 . This model and its variants have been used in [ 5 , 6 , 15 ] . We run all proposed algorithms on real world networks when their weights are defined by TRIVALENCY model . See Figure 2 for results .
Discussion .
In most of the plots , algorithms for the fractional influence model do substantially better than algorithms for the integral influence model . Overall , for most datasets , DiscountFrac is the best algorithm , with the only exception being the Facebook dataset . As a simple metric of the power of the fractional model versus the integral model , we consider the pointwise performance gain of fractional model algorithms versus the integral model algorithms . ie , for a given budget , we compute the ratio of expected number of adopters for the fractional model with the most adopters and the expected number of adopters for the integral model algorithm with the most adopters . Depending on the dataset , we get a mean pointwise performace gain between 3.4 % ( Facebook dataset , TRIVALENCY model ) and 142.7 % ( Amazon dataset , weighted cascade model ) with the mean being 31.5 % and the median being 15.7 % over all the datasets and both models ( weighted cascade and TRIVALENCY ) . Among the heuristics presented for the integral model , DiscountInt is probably the best . If we compare just it to its fractional adaptation , DiscountFrac , we get a similar picture : the range of average performace gain is between 9.1 % ( Facebook , TRIVALENT model ) and 397.6 % ( Amazon , weighted cascade model ) with a mean of 64.1 % and a median of 156 %
In summary , the experimental results clearly demonstrate that the fractional model leads to a significantly higher number of adopters across a wide range of budgets on diverse datasets .
21
References
[ 1 ] Hessameddin Akhlaghpour , Mohammad Ghodsi , Nima Haghpanah , Vahab S Mirrokni , Hamid Mahini , and Afshin Nikzad . Optimal iterative pricing over social networks . In WINE , pages 415–423 . 2010 .
[ 2 ] David Arthur , Rajeev Motwani , Aneesh Sharma , and Ying Xu . Pricing strategies for viral marketing on social networks . In WINE , pages 101–112 . 2009 .
[ 3 ] Sushil Bikhchandani , David Hirshleifer , and Ivo Welch . A theory of fads , fashion , custom , and cultural change as informational cascades . Journal of Political Economy , 100:992–1026 , 1992 .
[ 4 ] Christian Borgs , Michael Brautbar , Jennifer T . Chayes , and Brendan Lucier . Maximizing social influ ence in near optimal time . to appear in SODA 2014 .
[ 5 ] Wei Chen , Yajun Wang , and Siyu Yang . Efficient influence maximization in social networks . In KDD , pages 199–208 . ACM , 2009 .
[ 6 ] Wei Chen , Chi Wang , and Yajun Wang . Scalable influence maximization for prevalent viral marketing in large scale social networks . In KDD , pages 1029–1038 . ACM , 2010 .
[ 7 ] Wei Chen , Yifei Yuan , and Li Zhang . Scalable influence maximization in social networks under the linear threshold model . In ICDM , pages 88–97 . IEEE , 2010 .
[ 8 ] Pedro Domingos and Matt Richardson . Mining the network value of customers . In KDD , pages 57–66 .
ACM , 2001 .
[ 9 ] Shayan Ehsani , Mohammad Ghodsi , Ahmad Khajenezhad , Hamid Mahini , and Afshin Nikzad . Optimal online pricing with network externalities . Information Processing Letters , 112(4):118 – 123 , 2012 . ISSN 0020 0190 .
[ 10 ] Mark Granovetter . Threshold models of collective behavior . American journal of sociology , 83:1420–
1443 , 1978 .
[ 11 ] Dilek Gunnec . Integrating social network effects in product design and diffusion . Phd thesis , Univer sity of Maryland , College Park , 2012 .
[ 12 ] Dilek Gunnec and S . Raghavan .
Integrating social network effects in the share of choice problem .
Technical report , University of Maryland , College Park , 2012 .
[ 13 ] Dilek Gunnec , S . Raghavan , and Rui Zhang . The least cost influence problem . Technical report ,
University of Maryland , College Park , 2013 .
[ 14 ] Jason Hartline , Vahab Mirrokni , and Mukund Sundararajan . Optimal marketing strategies over social networks . In WWW , pages 189–198 . ACM , 2008 .
[ 15 ] David Kempe , Jon Kleinberg , and ´Eva Tardos . Maximizing the spread of influence through a social network . In KDD , pages 137–146 . ACM , 2003 .
[ 16 ] Jure Leskovec , Andreas Krause , Carlos Guestrin , Christos Faloutsos , Jeanne VanBriesen , and Natalie
Glance . Cost effective outbreak detection in networks . In KDD , pages 420–429 . ACM , 2007 .
22
[ 17 ] Elchanan Mossel and Sebastien Roch . On the submodularity of influence in social networks . In STOC , pages 128–134 . ACM , 2007 .
[ 18 ] Elchanan Mossel and S´ebastien Roch . Submodularity of influence in social networks : From local to global . SIAM J . Comput . , 39(6):2176–2188 , 2010 .
[ 19 ] Matthew Richardson and Pedro Domingos . Mining knowledge sharing sites for viral marketing . In
KDD , pages 61–70 . ACM , 2002 .
[ 20 ] Everett M Rogers . Diffusion of innovations . Simon and Schuster , 2010 .
[ 21 ] Thomas C Schelling . Micromotives and macrobehavior . WW Norton & Company , 2006 .
[ 22 ] Yaron Singer . How to win friends and influence people , truthfully : influence maximization mechanisms for social networks . In Proceedings of the fifth ACM international conference on Web search and data mining , pages 733–742 . ACM , 2012 .
[ 23 ] Thomas W Valente . Network models of the diffusion of innovations ( Quantitative methods in commu nication series ) . Hampton Press , 1995 .
23
