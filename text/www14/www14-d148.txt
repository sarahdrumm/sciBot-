An Article Level Metric in the Context of Research
Yu Liu
School of Software Dalian University of
Technology
Dalian , China 116600 yuliu@dluteducn
Community
Zhen Huang
School of Software Dalian University of
Technology
Dalian , China 116600 kobe_hz@163.com
Yizhou Yan
School of Software Dalian University of
Technology
Jing Fang
Datang Telecom Technology
Co . , Ltd .
Beijing , China 100000 fangjing066385@163.com
Dalian , China 116600 yizhouyan9132@gmail.com
ABSTRACT With the rapid increase of research papers , article level metrics are of growing importance for helping researchers select papers . Classical metrics have a significant drawback of just using single factor , which limits the effectiveness of assessing papers in different periods after publication . Moreover , with the development of web 2.0 , some new factors are introduced to assess papers . So , a novel article level metric in the context of research community ( ALM_RC ) is proposed . It integrates the impact of different factors comprehensively , because different factors have different time features and can complement each other in different periods after publication . In addition , as a research community is based on certain research directions , it is a relatively stable environment with related journals and scholars contributing their efforts to development of this research field . So in the context of research community , it is consistent , practical and reasonable to calculate the impact of the journals and scholars under relatively fair criteria . Experimental results show the novel metric is effective and robust in assessing papers .
Categories and Subject Descriptors H33 [ Information Storage and Retrieval ] : Information Search and Retrieval—information filtering
Keywords research community , article level metrics , citation , social bookmark
1 .
INTRODUCTION
Since the 21st century , research in every field has developed rapidly . Not only has the number of papers increased dramatically
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author ’s site if the Material is used in electronic media . WWW’14 Companion , April 7–11 , 2014 , Seoul , Korea . ACM 978 1 4503 2745 9/14/04 . http://dxdoiorg/101145/25679482579030 but the research community , a diverse network of interacting scientists , has grown too . Given the current situation , the sheer number of papers makes it impossible for any researcher to read every paper relevant to his research community . So how to effectively assess and choose papers becomes an urgent need .
Usually , we choose papers from some specific journals with high reputation . Although the Thomson ISI Journal Impact Factor ( JIF ) [ 9 ] is a classical metric for assessing the impact of journals , this impact factor just average citations of each paper published in journals , which means that it is not for assessing the impact of individual papers . In this situation , it makes sense that we need article level metrics for us to assess the impact of individual papers . With the development of article level metrics , including the traditional indicators and metrics based on web 2.0 , researchers appeal to use effective article level metrics to assess and filter articles [ 14 ] .
The traditional metrics of assessing the quality of individual papers are citation metric and usage metric [ 11 , 5 ] . The inherent time delay of citations strongly reduces the effectiveness of using citations , especially for newly published papers . Usage metric can provide a quick feedback , but it is a crude measure for actual use [ 14 ] . With the development of the web 2.0 , it introduces some new factors for assessing papers like comments , blog coverages , social citations and social bookmarks . These metrics complement the traditional metrics and provide multiple dimensional assessments of the impact of papers in different periods after publication [ 16 , 18 ] . Although these new metrics have attracted a lot of researchers’ attention to use them , how to systematically use them to assess and choose article is increasingly critical . At the same time , we should note that each research has its certain research directions , which have many interacting researchers following behind , so that research directions guide the formation of research community and gather some journals and scholars , as well as their research results in this research community . Research community is a relatively stable environment with the journals and scholars contributing their efforts to development of this research field . So research community provide a relatively reasonable and fair way to calculate the impact of journals and scholars , and how to make use of it for helping assess articles is increasingly important .
Thus , in this paper , we propose a new metric called article level metric in a research community ( ALM_RC ) , which systematically integrates different dimensional factors and makes full use of the
1197 research community ’s list of articles . Researchers who write articles have an influence on the quality of the articles ; journals publishing papers also have an influence on the articles’ judgement ; social bookmarks decide the popularity of new papers ; citations become persuasive evidence to evaluate the articles . So the new metric takes into account the impact of researchers , journals , social book markings and citations to comprehensively assess articles .
This paper is structured as follows . In the following section , we provide a general introduction to related work on article level metrics . The third section describes the new proposed metric , followed by experiments’ results . Finally , we will give a conclusion .
2 . RELATED WORK
There are more and more article level metrics today , from traditional metrics to promising metrics on the basis of web 2.0 [ 16 ] . The traditional methods to assess papers are citation metric and usage metric . The fact that articles with more citations are of higher quality is generally recognized . Although citation is the most classical article metric , it has some disadvantages . The greatest drawback is time delay inherent in citations . The first citation to the papers usually appears several months after publication , which limits the effectiveness especially for newly published papers [ 17 , 19 , 1 ] . Usage metric is the number of downloads or views by users . This metric has a rapid feedback by assessing interest in a paper through comparing the average counts . But how many the downloaded or viewed papers are actual read or digested in detail cannot be determined , that is to say this metric may not assess the quality of papers accurately [ 14 ] .
As the development of web 2.0 , new metrics based on web 2.0 tools has developed [ 16 , 17 , 19 , 1 , 14 ] . Metrics based on social networks and social bookmark systems are representative ones , which provide rapid feedbacks and compensate the drawbacks of the traditional metrics [ 16 ] . Some representative metrics based on social media are comment metric , blog coverage metric and social citation metric . Comment metric is based on the commenting function of social networks , where everyone is able to voice ideas in a less formal setting . Although many journals have made use of this characteristic , [ 15 , 16 ] have pronounced that comment metric is a failure mainly because participants are lack of interest in commenting and comment data is not generally available via API . Blog coverage metric is the number of blog writings about the scientific posts [ 8 ] . And RearchBlogging and Postgenomic have aggregated posts from scholarly blogs and have provided APIs for others to reuse this data . However , blogs are spread out across the entire Web , obtaining this data is challenging [ 16 ] . The most successful metric based on social media is social citation metric which comes from the development of microblog . Because of the instant feature , the social citation attracts many researchers’ attention . Twitter is the best known microblog application which is a real time information network connecting users to the latest stories , ideas , opinions and news they are interested in . Twitter has attracted attention of many researchers to use it for scholar [ 7 ] . Although [ 21 , 12 ] have proved that social citation may predict the citations of paper , how to comprehensively identify scientific microblogs limits the accuracy of social citation .
Social bookmark metric is the best develop metric based on social bookmark systems enabling users to add , annotate , edit and share bookmarks of articles by Internet , which means that social bookmark metric can provide a quick feedback about popularity of articles [ 16 ] . Social bookmark metric is the number of people marking an article , which is a good hint of the popularity of articles . Many web applications have provided the bookmark feature . Mendeley is an excellent social bookmark application providing the data of social bookmark statistic . It provides a free client indexing and organizing users’ library of PDF articles . At the same time , the collection of articles can be used to recommend new articles [ 3 , 13 ] . Bogers and Bosch use CiteUlike , which is also a remarkable tool , for filtering scientific articles for users [ 4 ] . Social bookmark metric provides a quick collected high quality information but a big problem is that there is no clear incentive for sharing valuable information .
Although article level metrics are increasingly diverse to assess articles from different dimensions , the problem is how to assess the quality of articles systematically and effectively . In this paper , we assess the quality of a paper by placing a paper in its research community and systematically integrate the impact of researchers , journals , social bookmarks and citations . Our experimental results show that this metric not only comprehensively provides multiple dimensions to assess the quality of papers during different period after publication but also is a robust metric .
3 . METHOD
In this paper , we propose a new article level metric for assessing papers in the context of research community , which is shorted as ALM_RC . That is to say , we assess the quality of each paper in the context of its research community . The research community is a diverse network of interacting scientists with same research interest . Some research communities maintain a list of papers in their own research field in order to better organize and show their research achievements , as well as provide a convenient way for scholars to read and reference their papers . Based on this situation , ALM_RC evaluates articles using the research community ’s list , which not only effectively assesses the quality of articles but also ensures the consistency of assessment .
ALM_RC systematically integrates the impact of researchers , journals , social bookmarks , and citations . Researchers’ own achievements imply papers’ quality to some extent ; journals’ impact influences general judgement of papers ; social bookmarks’ favorite by community users indicate popularity ; finally , citations strongly decide the quality after a long period . Thus , these four factors assess papers from different dimension . In the following , we will provide an introduction to each factor .
3.1 Impact of researchers
If papers are written by researchers with high research impact , other researchers tend to choose these papers to read , which is because that the research impact of researchers reflects the impact of articles to some extent . So we take into account the impact of researchers and use R index to evaluate it . In researcher level metrics , H index is widely used [ 10 ] . But H index is weakly sensitive to the number of citations of papers , which reduces the effectiveness of assessing researchers publishing few articles with more citations [ 2 ] . However a variant of H index , R index , successfully solves this problem . R index is defined as :
R = vuut h ∑ i=1
( citi )
( 1 ) where h is the H index , and citi is the number of citations of i th most cited paper in h core . From this formula , we can see that each paper ’s citations in h core are involved into the calculation , thus R index has a better ability of differentiating researchers . In this paper , R index is used to assess the impact of researchers in the research community ’s list . Moreover , when the article has been written by several researchers , we only select the highest R index of the researchers .
1198 3.2 Impact of journals
When researchers choose papers to read , they tend to read papers from high quality journals . As the impact of journals is a good hint for the quality of articles , we take into account the impact of journals . JIF is commonly used to assess the impact of journals , which measures the average citations of articles published on each journal about a discipline with different research fields [ 9 ] . However , when journals are assessed in a certain research field , JIF may reduce the effectiveness of assessment [ 20 ] . With the development of h type index , many researchers propose to use h type index to evaluate the impact of journals [ 6 ] . H type index can well evaluate the quality of journals by a list maintained by researchers in a research community . R index is used to assess the quality of journals to better take into account the actual number of citations . So we use R index to assess the impact of journals .
3.3 Impact of social bookmark
When researchers choose recently published articles to read , social bookmarks can help choose popular articles because social bookmarks can rapidly collect and measure articles’ popularity . So we take the impact of social bookmarks into account . Mendeley , a representative social bookmark system , is taken to get the number of social bookmarks of papers .
3.4 Impact of citations
The number of citations is an important indicator , which has been accepted by most scientists when filtering or evaluating papers . Citations need a period of time to accumulate . With time passing by , the number of citations gradually becomes the most influential factor that helps us to choose papers . Although the above three factors influence the impact of papers , they tend to guide researchers’ choices in the initial period . After a paper has been published for several years , the number of citations is the main standard of assessment . So we still reserve the number of citations to assess articles . Citation data in this papers is extracted from Google Scholar .
3.5 Article level metrics for a research com munity
Under the context of research community , we integrate the above four factors that influence the impact of papers to propose a new metric called article level metric in the context of research community(ALM_RC ) . ALM_RC is calculted by the following formula :
ALM_RC = ω1 ∗ A1 + ω2 ∗ A2 + ω3 ∗ A3 + A4
( 2 ) where A1 , A2 , A3 and A4 respectively represent the impact of researchers , journals , social bookmarks and citations . Because the impact of citations mainly reflects the quality of papers after some months or years of publication , coefficients are added to A1 , A2 and A3 . At the same time , because the value ranges of A1 , A2 and A3 may be quite different , different coefficients , ω1 , ω2 and ω3 , are set to A1 , A2 and A3 to ensure an approximately similar range . In order to get the coefficients , firstly we respectively rank all the values of impact of researchers , journals and social bookmarks in descending order to get corresponding impact lists . In particular , social bookmarks are ranked according to the year . Then we respectively get the critical impacts’ value of A1 and A2 at the top 20 % ’s point in respective impact list by 80/20 rule . The 80/20 rule states that for many events , roughly 80 % of the effects come from 20 % of the causes . In particular , the critical impact ’s value of A3 is calculated by the top 20 % ’s point in the social bookmarks’ impact list according to the recent year . Here , we just take the reciprocals of these three critical impacts’ values to get ω1 , ω2 and ω3 . The following formulas show how to calculate ω1 , ω2 and ω3 .
ω1=1/(the critcal impact ′s value o f top 20%′s point in researchers′ impact list )
ω2=1/(the critcal impact ′s value o f top 20%′s point in journals′ impact list )
ω3=1/(the critcal impact ′s value o f top 20%′s point in social bookmarks′ impact list in the recent year )
( 3 )
( 4 )
( 5 )
4 . EXPERIMENTS AND RESULTS
In this section , we take a research community specialized in Hindex to check whether the new metric is effective and robust to assess articles . H index , a simple and intuitively attractive indicator for the assessment of a scientist ’s individual research performance , was first proposed by Jorge E . Hirsch in 2005 [ 10 ] . Through eight years’ development in this field , the number of papers about the Hindex becomes to be very large . Only when the number of articles is large , are article level metrics valuable .
In order to better show the papers of H index research community , we get the article list from http://sci2sugres/hindex/biblio Then , we collect related information of each article from Internet and organize as well as analyze it according to its publication year . The information constitute the basic data and are arranged in Table 1 . Here , the number of citations and social bookmarks respectively come from Google Scholar and Mendenley in October , 2012 .
Table 1 : Basic statistics for 820 articles in the research community of H index
Years
PublicationsCitations
Reseachers
Journals
Bookmarks
2005 2006 2007 2008 2009 2010 2011
8 26 56 108 160 200 262
2854 2587 2724 2398 1740 1516 849
8 42 82 151 261 376 537
7 12 31 45 69 81 123
494 440 495 1028 1402 1643 1230
From Table 1 , we can see that the number of scientists in the field of H index research is increasing with time elapsing . At the same time , more and more journals publish papers about the H index . It also can be seen that the number of papers in the research community of H index has a dramatic increase from the beginning to nowadays . So article level metrics are valuable for assessing the quality of articles in this research community . In the following experiments , we get the specific formula of ALM_RC in the research community of H index by calculating the values of ω1 , ω2 and ω3 . And then we respectively verify that whether or not ALM_RC is rationally designed , effective and robust .
Firstly , in order to get the value of ω1 , we calculate each researcher ’s R index in this community and rank researchers by the R index in descending order . Figure 1 shows the ranking . In Figure 1 , the horizontal axis and the vertical axis respectively represent the order and researchers’ R index in this field . The critical impact value of the top 20 % ’s point in researchers’ impact list is about 4 . So the value of ω1 is 0.25 according to the formula 3 . And from this figure , we can see that there are about 1175 authors doing research in the field of H index . Moreover , the top 10 researchers with high
1199 impact in the H index research community are clearly seen . In the meantime , some details of top 10 researchers are listed in Table 2 . From Table 2 , it can be clearly seen that Hirsch has written only 3 papers in the field of the H index , but has the highest impact in this field , which well explains the reason of using the R index for assessing researchers’ achievements . x e d n − H i f o y t i n u m m o c h c r a e s e r n i x e d n − R i
Hirsch JE
60
50
40
Egghe L .
30
Glanzel W . authors’ R−index in research community of H−index
Rousseau R .
Daniel HD
Bornmann L .
Schubert A . Meho LI
Ball P .
Liang LM
X= 235 Y= 4
50 100 150 200 250 300 350 400 450 500 550 600 650 700 750 800 850 900 950 1000 1050 1100 1150 1200 author
20
10
0
0
Figure 1 : Impacts of authors in the research community of Hindex
Table 2 : Top 10 authors in the research community of H index
Order Authors
Publications
Citations
R index
1 2 3 4 5 6 7 8 9 10
Hirsch J.E Egghe L Glanzel W RousseauR Daniel H.D Bornmann L Schubert A Meho L.I Ball P Liang L.M
3 40 13 25 13 22 12 6 3 4
2802 1385 722 602 558 570 548 472 376 339
52.93 36.35 26.80 23.85 23.47 23.41 23.22 21.73 19.39 18.41
Secondly , we calculate each journal ’s R index in this community and rank them in descending order to get the value of ω2 . Figure 2 sorts all the impact of journals publishing about H index research field . In Figure 2 , the horizontal axis shows the order of journals and the vertical one represents the impact of each journal calculated by the R index . It can be clearly seen that the critical impact value of the top 20 % ’s point in the journals’ impact list is about 4 . So the value of ω2 is 0.25 according to the formula 4 . We can also see that there are about 273 journals that publish the articles about H index from this figure . In this figure , the top 10 journals in this field can be clearly seen . In order to show the details of top 10 papers , Table 2 is made . x e d n − H i f o y t i n u m m o c h c r a e s e r n i x e d n i
R
60
50
40
30
20
10
0
0 journals’ R−index in research community of H−index
SCIENTOMETRICS
PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED STATES OF AMERICA
JOURNAL OF THE AMERICAN SOCIETY FOR INFORMATION SCIENCE AND TECHNOLOGY
JOURNAL OF INFORMETRICS
NATURE CHINESE SCIENCE BULLETIN PLOS ONE JOURNAL OF INFORMATION SCIENCE
ARCHIVUM IMMUNOLOGIAE ET THERAPIAE EXPERIMENTALIS SCIENCE FOCUS
X= 55 Y= 4.2426
25
50
75
100
125
150
Jounal
175
200
225
250
275
300
Figure 2 : Impacts of journals in the research community of Hindex
Table 3 : Top 10 journals in the research community of H index Publications Citations R index
Order Journal
1 2
3
4
5 6
7 8
9
10
STATES
SOCIETY
SCIENTOMETRICS PROCEEDINGS OF THE NATIONAL ACADEMY OF SCIENCES OF THE UNITED OF AMERICA JOURNAL OF THE AMERICAN FOR INFORMATION SCIENCE AND TECHNOLOGY JOURNAL OF INFORMETRICS NATURE CHINESE SCIENCE BULLETIN PLOS ONE JOURNAL OF INFORMATION SCIENCE ARCHIVUM IMMUNOLOGIAE ET THERAPIAE EXPERIMENTALIS SCIENCE FOCUS
7 1
15 11
7
2
182 4
4339 2902
58.25 53.87
98
2213
41.69
101
1235
30.64
21.21 16.19
13.42 11.62
11.45
450 262
191 143
135
115
10.72
Table 4 : Basic statistics for social bookmarks and citations at top 20 % ’s point
Year
2005 2006 2007 2008 2009 2010 2011
Publications
Social bookmarks
Citations
8 26 56 108 160 200 262
13 23 15 13 12 12 7
2524 210 82 34 16 11 5
Next , we calculate the critical impact value of top 20 % ’s point in social bookmarks’ impact list of different years in order to get the value of ω3 . Table 4 shows these information every year from 2005 to 2011 . From Table 4 , the value of ω3 is 0.14 using the critical
1200 Table 5 : Percentage of each factor in the new article level metric
Year
2005 2006 2007 2008 2009 2010 2011
A1 percentage
0.87 % 3.97 % 5.67 % 9.81 % 11.71 % 13.72 % 15.05 % avg
13.11 18.13 13.27 13.08 9.70 9.82 6.48
A2 percentage
1.75 % 6.75 % 9.05 % 19.54 % 29.75 % 37.36 % 48.62 % avg
26.23 30.81 21.18 26.07 24.65 26.74 20.94
A3 percentage
2.35 % 2.12 % 2.15 % 4.08 % 6.04 % 6.56 % 6.23 %
A4 percentage
95.03 % 87.16 % 83.13 % 66.57 % 52.50 % 42.36 % 30.10 % avg
356.75 99.50 48.64 22.20 10.88 7.58 3.24 avg
61.75 16.92 8.84 9.52 8.76 8.22 4.69 impact value of top 20 % ’s point in the social bookmarks’ impact list of 2011 according to the formula 5 .
Finally , we get the specific formula of ALM_RC in this research community . The formula 2 can be written according the values of ω1 , ω2 and ω3 :
ALM_RC = 0.25 ∗ A1 + 0.25 ∗ A2 + 0.14 ∗ A3 + A4
( 6 )
In order to verify that the new metric is rationally designed , we calculate the percentage of each factor in the new metric . Table 5 shows relevant information . From Table 5 , it can be seen that the number of citations , A4 , has less influence on recently published papers , while the other three ones have more influence . And for papers published from 2005 to 2009 , researchers , journals , and social bookmarks have less influence on the new metric than the number of citations . This situation accords with our analysis that citations need time to become the leading factor to reflect the quality of papers and the potential quality of recently published papers is mainly reflected by researchers , journals , and the social bookmarks . As time passes , the impact of citations best decides the quality of papers . These results prove that ALM_RC is rationally designed and able to evaluate articles .
900
800
700
600
500
400
300
200
100
C R _ M L A
0
0 w1=0.25 w2=0.25 w3=0.14 w1=0.30 w2=0.30 w3=0.15 w1=0.20 w2=0.20 w3=0.20 w1=0.20 w2=0.30 w3=0.10 w1=0.25 w2=0.25 w3=0.20
X : 164 X : 164 X : 164 X : 164 X : 164 Y : 32.01 Y : 28.31 Y : 28.18 Y : 28.07 Y : 24.41
100
200
300
400
PAPER
500
600
700
800
Figure 3 : Articles’ impact by ALM_RC with different values of parameters
In order to study whether or not ALM_RC is sensitive to the coefficients , we make a sensitivity analysis for papers in the list by adjusting the values of ω1 , ω2 and ω3 . The basic values of ω1 , ω2 and ω3 are respectively 0.25 , 0.25 and 014 We randomly choose the values of ω1 and ω2 in the range of 0.2 and 0.3 and randomly choose the values of ω3 in the range of 0.1 and 02 We get other four random sets of ω1 , ω2 and ω3 , which are ( 0.30 , 0.30 , 0.15 ) ,
( 0.20 , 0.20 , 0.20 ) , ( 0.20 , 0.30 , 0.10 ) and ( 0.25 , 0.25 , 020 ) Then we respectively calculate the impact of articles using the four different sets by the formula 2 . Figure 3 shows the impact of papers with different coefficients . From Figure 3 , we can see that the values of ω1 , ω2 and ω3 change on a small range , it has little influence on the ranking of papers , which shows the novel metric is enough robust to assess the quality of recently published papers and help researchers to choose papers .
Based on the above analysis , it can be clearly seen that ALM_RC is robust and available for assessment of articles’ quality . So , we calculate the impact of papers published in 2011 according to the formula 6 to show top 10 popular articles , and list them in Table 6 to better guide researchers’ choices .
Table 6 : Top 10 papers published in 2011 by ALM_RC
Order
Paper
1 2
3
4
5 6
7
8
9
10
Towards a new crown indicator : Some theoretical considerations Integrated impact indicators compared with impact factors : an alternative research design with policy implications Indicators of the interdisciplinarity of journals : Diversity , centrality , and citations A multilevel meta analysis of studies reporting correlations between the h index and 37 different h index variants Detecting h index manipulation through self citation analysis What makes a great journal great in the sciences ? Which came first , the chicken or the egg ? A new indicator for international visibility : exploring Brazilian scientific community Scientific collaboration and endorsement : Network analysis of coauthorship and citation networks National scale research performance assessment at the individual level Thoughts on uncitedness : nobel laureates and fields medalists as case studies
5 . CONCLUSIONS
We propose a novel article level metric in the context of research community as called ALM_RC . Compared to the traditional metrics , ALM_RC integrates the impact of factors like researchers , journals , social bookmarks and citations from web 2.0 by making the most of the characteristic that different dimensional factors have different time features and complement each other in different periods after publication . The experiments show that the impact of researchers , journals and social bookmarks have more influence on recently published papers , while citations will be a leading factor with time passes , which also verifies effectiveness of ALM_RC for assessing articles no matter how long it has been since their publication date . And at the same time , in our sensitivity experiment , ALM_RC is proven to be robust to assess the quality of papers .
1201 In addition , ALM_RC also has the characteristic of assessing papers in the context of research community . Because a certain research community gather certain related journals and scholars as well as their research results so that it is relatively stable environment with the journals and scholars contributing their efforts to development of this research field . ALM_RC can be consistent , practical and reasonable to get or calculate the impact of the journals and scholars under relatively fair criteria in actual fact . Moreover , it also provides information of the most influential journals and scholars in the research community , which guides novice researchers to obtain more knowledge and development trends in this research direction .
In the end , as the research community ’s list of articles provides a convenient way to calculate ALM_RC , we hope that more and more researchers take part in maintaining different lists of articles belonged to different research fields and take full advantage of ALM_RC in the articles’ list to assess the quality of articles .
6 . REFERENCES
[ 1 ] E . Adie and W . Roe . Altmetric : enriching scholarly content with article level discussion and metrics . Learned Publishing , 26(1):11–17 , 2013 .
[ 2 ] S . G . Aoun , B . R . Bendok , R . J . Rahme , R . G . Dacey Jr , and
H . H . Batjer . Standardizing the evaluation of scientific and academic performance in neurosurgery critical review of the "h" index and its variants . World Neurosurgery , 2012 .
[ 3 ] J . Bar Ilan , S . Haustein , I . Peters , J . Priem , H . Shema , and J . Terliesner . Beyond citations : Scholars’ visibility on the social web . arXiv preprint arXiv:1205.5611 , 2012 .
[ 4 ] T . Bogers and A . Van den Bosch . Recommending scientific articles using citeulike . In Proceedings of the 2008 ACM conference on Recommender systems , pages 287–290 . ACM , 2008 .
[ 5 ] J . Bollen , M . Rodriquez , and H . Van de Sompel . Journal status . Scientometrics , 69(3):669–687 , 2006 .
[ 6 ] L . Bornmann , W . Marx , A . Y . Gasparyan , and G . D . Kitas . Diversity , value and limitations of the journal impact factor and alternative metrics . Rheumatology international , 32(7):1861–1867 , 2012 .
[ 7 ] G . Eysenbach . Can tweets predict citations ? metrics of social impact based on twitter and correlation with traditional metrics of scientific impact . Journal of Medical Internet Research , 13(4 ) , 2011 .
[ 8 ] S . Fausto , F . A . Machado , L . F . J . Bento , A . Iamarino , T . R . Nahas , and D . S . Munger . Research blogging : Indexing and registering the change in science 20 PloS one , 7(12):e50109 , 2012 .
[ 9 ] E . Garfield . Journal impact factor : a brief review . Canadian
Medical Association Journal , 161(8):979–980 , 1999 .
[ 10 ] J . Hirsch . An index to quantify an individual ’s scientific research output . Proceedings of the National Academy of Sciences of the United states of America , 102(46):16569 , 2005 .
[ 11 ] R . Leimu and J . Koricheva . What determines the citation frequency of ecological papers ? Trends in Ecology & Evolution , 20(1):28–32 , 2005 .
[ 12 ] J . Letierce , A . Passant , J . Breslin , and S . Decker .
Understanding how twitter is used to spread scientific messages . 2010 .
[ 13 ] X . Li and M . Thelwall . F1000 , mendeley and traditional bibliometric indicators . In Proceedings of the 17th International Conference on Science and Technology Indicators . Montréal , Canada , pages 451–551 , 2012 .
[ 14 ] C . Neylon and S . Wu . Article level metrics and the evolution of scientific impact . PLoS biology , 7(11):e1000242 , 2009 .
[ 15 ] M . Nielsen . Doing science in the open . 2011 . [ 16 ] J . Priem and B . Hemminger . Scientometrics 2.0 : New metrics of scholarly impact on the social web . First Monday , 15(7 ) , 2010 .
[ 17 ] J . Priem , H . A . Piwowar , and B . M . Hemminger . Altmetrics in the wild : Using social media to explore scholarly impact . arXiv preprint arXiv:1203.4745 , 2012 .
[ 18 ] D . Taraborelli . Soft peer review : Social software and distributed scientific evaluation . 2008 .
[ 19 ] D . Torres , Á . Cabezas , and E . Jiménez . Altmetrics : New indicators for scientific communication in web 20 Comunicar , 21(41 ) , 2013 .
[ 20 ] E . Van Nierop . Why do statistics journals have low impact factors ? Statistica Neerlandica , 63(1):52–62 , 2009 .
[ 21 ] K . Weller , E . Dröge , and C . Puschmann . Citation analysis in twitter . approaches for defining and measuring information flows within tweets during scientific conferences . In Proceedings of Making Sense of Microposts Workshop ( # MSM2011 ) . Co located with Extended Semantic Web Conference , Crete , Greece , 2011 .
1202
