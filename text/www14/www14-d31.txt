Random Walks in Recommender Systems :
Exact Computation and Simulations∗
Colin Cooper
Sang Hyuk Lee
Tomasz Radzik
Yiannis Siantos
Department Of Informatics
King ’s College London , UK namesurname@kclacuk
ABSTRACT A recommender system uses information about known associations between users and items to compute for a given user an ordered recommendation list of items which this user might be interested in acquiring . We consider ordering rules based on various parameters of random walks on the graph representing associations between users and items . We experimentally compare the quality of recommendations and the required computational resources of two approaches : ( i ) calculate the exact values of the relevant random walk parameters using matrix algebra ; ( ii ) estimate these values by simulating random walks . In our experiments we include methods proposed by Fouss et al . [ 8 , 9 ] and Gori and Pucci [ 11 ] , method P 3 , which is based on the distribution of the random walk after three steps , and method P 3 α , which generalises P 3 . We show that the simple method P 3 can outperform previous methods and method P 3 α can offer further improvements . We show that the time and memory efficiency of direct simulation of random walks allows application of these methods to large datasets . We use in our experiments the three MovieLens datasets .
INTRODUCTION
1 . We view a recommender system as an algorithm which takes a dataset of relationships between a set of users and a set of items and attempts to calculate how a given user might rank all items . For example , the users may be the customers who have bought books from some ( online ) bookstore and the items the books offered . The core information in the dataset in this case would show who bought which books , but it may also include further details of transactions ( the date of transaction , the books bought together , etc. ) , in
∗This research is part of the project “ Fast Low Cost Meth ods to Learn Structure of Large Networks , ” supported by the 2012 SAMSUNG Global Research Outreach ( GRO ) program . formation about the books ( authors , category , etc. ) , and possibly some details about customers ( age , address , etc ) For a given customer , a recommender system would compute a list of books m1 , m2 , . . . , mk which this customer might be interested in buying , giving the highest recommendations first . Recommender systems viewed as algorithms for computing such personalised rankings of items ( rather than overall “ systems , ” which would also include methods for gathering data ) are often referred to as scoring , or ranking algorithms .
Recommender systems are part of everyday online life . Whenever we buy a movie , or a new app for our mobile phone , a recommender system would suggest other items of potential interest to us . A good recommender system improves the user ’s experience and increases commercial activity , while consistently unhelpful recommendations may make the users look for other sites . This significant commercial value coupled with the challenging theoretical and practical aspects of modelling , designing and implementing appropriate algorithms , has made recommender systems a fast growing research topic .
In this paper , we focus on a simple scenario with two main entity sets , Users ( U ) and Items ( I ) , and a single relationship R of pairs u , m , where u ∈ U and m ∈ I . The fact that u , m ∈ R means that u has some preference for m . The pairs u , m ∈ R may have additional attributes which indicate the degree of preference . The relationship R can be modeled as a bipartite graph G = ( U ∪ I , R ) , possibly with edge weights , which would be calculated on the basis of the attributes of pairs u , m ∈ R . A scoring algorithm for a user u ∈ U orders the items in I according to some similarities between vertex u and the vertices in I , which are defined by the structure of graph G . More precisely , a scoring algorithm is defined by a formula or a procedure for calculating a p× q matrix M = M ( G ) which expresses those similarities , where p = |U| and q = |I| . For a user u ∈ U , the items m ∈ I are ranked according to their M ( u , m ) values ( in increasing or decreasing order , depending whether a lower or a higher value M ( u , m ) indicates higher or lower similarity between vertices u and m ) . Matrix M is called the scoring matrix or the ranking matrix of the algorithm . We also note that the methodology of designing ranking algorithms of this type , which use the whole relationship between users and items rather than user and item profiles , is often referred to as collaborative filtering .
Fouss et al . [ 8 , 9 ] proposed various scoring algorithms which are based on parameters of random walks in G , or more generally on the Laplacian matrix of G . They showed theoretical properties of the proposed algorithms , discussed their computational complexity , and evaluated experimentally their performance . Their experiments were based on a dataset of movie ratings composed by GroupLens Research Lab [ 5 ] from the data gathered by the MovieLens web site [ 4 ] . Let Wu = Wu(0 ) , Wu(1 ) , . . . , Wu(t ) , . . . be a random walk on graph G starting from vertex u . That is , Wu(0 ) = u and Wu(t + 1 ) is a randomly selected neighbour of Wu(t ) . Let h(u , v ) denote the first step t ≥ 1 such that Wu(t ) = v . The hitting time of v from u is the expectation H(u , v ) of the random variable h(u , v ) . The Laplacian matrix of graph G is defined as L = D − A , where A is the adjacency matrix of G and D is the diagonal matrix of the vertex degrees . The main scoring algorithms considered in Fouss et al . [ 8 , 9 ] are the hitting time algorithm , the reverse hitting time algorithm , the commute time algorithm and the L pseudoinverse algorithm . The scoring matrices M of these algorithms are obtained from matrices H , H T , C = H + H T and L+ , respectively . Matrix L+ is the Moore Penrose pseudoinverse of L , in this paper referred to as simply the inverse Laplacian . For example , the scoring matrix M for the hittingtime algorithm is the U × I part of the matrix H . For all these matrices , a lower value of M ( u , m ) indicates higher similarity between vertices u and m , and a higher rank of m in the ranking list of items for the user u . For example , the commute time algorithm ranks the items for a user u according to the expected commute times C(u , m ) = H(u , m ) + H(m , u ) = H(u , m ) + H T ( u , m ) , putting an item m1 ahead of an item m2 , if C(u , m1 ) < C(u , m2 ) .
Fouss et al . [ 8 , 9 ] reported that for the MovieLens dataset which they used in their experiments , the L+ algorithm ( and its variants ) performed the best . The hitting time and the commute time algorithms performed similarly to the simple user independent algorithm which orders the items according to their vertex degrees in the graph G . The reverse hitting time algorithm showed the worst performance .
Our work expands Fouss et al . [ 8 , 9 ] in several ways . We propose simpler and faster scoring algorithms and show that they can match , and sometimes exceed , the best performance of the previous algorithms . Our experiments show a good performance of method P 3 , which ranks the items for a user u according to the distribution of the third vertex on the random walk starting at vertex u . An item m1 gets a higher rank than an item m2 , if Pr(Wu(3 ) = m1 ) is greater than Pr(Wu(3 ) = m2 ) . That is , there is a higher probability of the random walk arriving at vertex m1 at the third step than at vertex m2 – a natural measure of importance . We generalise method P3 to a parameterised method P 3 α , for an empirically optimised value α , can offer further improvements . While including in our experiments the same MovieLens dataset with 100K entries which was used in [ 8 , 9 ] , to be able to compare results , we use also two larger MovieLens datasets with 1M and 10M entries to see how the performance of ranking algorithms scale up ( these larger datasets were not used in [ 8 ,
α and demonstrate that P 3
9] ) . Using those larger datasets required special computational considerations because of the high running time and memory usage .
Our experimental results show , for example , that methods L+ and P 3 perfom equally well ( and clearly better than the other methods ) on the small 100K dataset , but P 3 outperforms L+ on the medium 1M dataset . For the large 10M dataset , method P 3 again shows the best performance , while method L+ could not be tested because the memory and computational time requirements were too high . We evaluate the performance of scoring algorithms using two different measures to strengthen the conclusions ( only one measure was used in [ 8 , 9] ) .
Our algorithms are based directly on random walks and can be efficiently implemented by simulating random walks . This approach can potentially be used for much larger datasets than the algorithms based on costly ( time wise and space wise ) algebraic matrix manipulations involving the matrix L . Our experimental results include comparison of the performance and required computational resources of methods P s , which compute the exact distribution of the random walk after s steps ( for a small value of s ) , and methods ˆP s , which estimate this distribution by simulating a number of short random walks .
2 . RELATED WORK Kunegis and Schmidt [ 13 ] extend Fouss’ work of [ 9 ] by taking user ratings into account while computing a similarity measure on users items bipartite graph . The similarity measure used in the paper is resistance distance , which is equivalent to the commute time distance used in [ 9 ] . They adapt a rescaling method proposed in [ 7 ] , in which the user ratings are rescaled into 1 ( good ) to 1 ( bad ) . The authors conduct experiments on two datasets : 100K MovieLens dataset [ 4 ] and Jester [ 1 ] and the performance is measured by two evaluation metrics , the mean squared error and the root mean squared error .
Gori and Pucci [ 10 , 11 ] present a random walk based scoring algorithm for the recommendation systems . In [ 11 ] the algorithm is applied to movie recommendation whilst in [ 10 ] , the algorithm is used for recommending research papers . For the movie recommendation , 100K ( small ) MovieLens dataset is used for the experiments and for the research paper recommendation , they use the dataset that is derived from the crawling of ACM portal website . The algorithm is based on the Pagerank algorithm applied to an item similarity graph called a correlation graph . The correlation graph is constructed in [ 11 ] from the users items bipartite graph , and in [ 10 ] from citation graph . Zhang et al . [ 21 , 20 ] extend Gori and Pucci ’s work [ 11 ] by taking into account user ’s preference on item categories . The proposed algorithm computes the ranking scores based on the item genre and user interest profile .
Singh et al . [ 19 ] present an approach of combining a relations graph ( friendship graph ) with the ownership data ( user item graphs ) to make recommendations . The combined graph is represented as an augmented bipartite graph and is treated as a Markov chain with an absorbing state . The items are ranked according to the approximated absorbing distribu tion . This method is tested and evaluated for on line gaming recommendation .
Lee et al . [ 14 ] consider a multidimensional recommendation problem , which allows some additional contextual information as an input . They present a random walk based method , which adapts the Personalized PageRank algorithm . They conduct experiments on two datasets : last.fm [ 2 ] and LG ’s OZ Store [ 3 ] . The performance is evaluated using hit at top k evaluation metric . Further work in this direction is reported in [ 15 , 16 ] .
3 . SUMMARY OF FINDINGS We made an analysis based on all three MovieLens datasets provided from [ 5 ] , and summarise now our primary findings . Using the data collected by the MovieLens service [ 4 ] , the GroupLens Research lab composed three datasets of user produced movie ratings of increasing sizes [ 5 ] . These datasets are collections of quadruples UserId , MovieId , Rating , Timestamp , which we view as pairs UserId , MovieId with attributes Rating and Timestamp . For each UserId ( User ) and each MovieId ( Item ) , each dataset has at most one observation U serId , M ovieId , Rating , T imestamp . The size of the graph associated with the dataset is n = |U sers| + |Items| These sizes are n = 2625 ( Small Dataset ) , n = 9940 ( Medium Dataset ) and n = 82248 ( Large Dataset ) . The work of Fouss et al . [ 8 , 9 ] was done only on the small dataset . The number of observations in the datasets was 100K , 1M , 10M , respectively .
We started by reproducing and confirming the experimental results given in [ 8 , 9 ] . We expanded the evaluation of performance of their methods by also including an alternative measure of result quality , based on number of correct entries among the top recommendations returned by the algorithm ( see Table 1 ) .
The method which performed particularly well in [ 9 ] was the pseudoinverse Laplacian L+ ( see Table 1 ) . The quantity L+ has no clear intuitive meaning in terms of the structure of the graph G , and we could find no direct random walk equivalent . We found , however , that the third power P 3 of the transition matrix P = D−1A of a random walk was an equally effective measure ( compare columns L+ and P 3 in Table 1 and Table 2 ) . P 3 has the straightforward interpretation of ’What Movies we expect a random walk to be at after 3 steps from a given start User’ . ( The walk is of the form : User Movie User Movie ) . We generalised the P 3 method to a parameterised method P 3 α , which is based on the third power of the matrix Pα with entries equal to the entries in matrix P raised to the power of α . Our experiments with the P 3 α method show that for suitable values of α , ( typically for α in the range 1.5 to 2.5 ) , this method can offer further improvements over the P 3 method . At present our method for optimizing α is by empirical tuning . Details of all matrix based methods and results are given in Section 5 . of the P 3 method , but finding out that the computational performance of matrix based techniques did not scale well , as the matrix operations were now large . For example , we could not run the L+ method on the 10M dataset because the computational time and memory requirements were too high .
Exact parameter of random walks can be obtained by matrix manipulation but this is costly in time and memory . Therefore we estimate the parameter using short random walks . We based our experiments around repeated short random walks from a given start . The details of these experiments are given in Section 6 . In common with our findings that P 3 gave best results among matrix based methods , we find that random walks of length 3 give best results . For s equal to 3 and 5 , we compare the performance of the P s method , which computes the s th power of matrix P , with the performance of the ˆP s method , which estimates the s th power of P by simulating random walks of length s . For example , in the small dataset we can approximate P 3 with a relative difference of 0.05 after 20n walk steps ( See Equation 4 ) . The large dataset reaches this accuracy in sublinear time ( see Figures 3 and 5 )
4 . EVALUATION METHODOLOGY To ensure reproducibility of results and to facilitate comparison between various recommender systems , each MovieLens dataset is partitioned into two parts : a training , or base , set B and a test set T . The test set is obtained by selecting 10 random user movie ratings for each user . The training set consists of all remaining ratings . To make this partitioning feasible , the small dataset has more than 10 ratings per each user . The medium and large datasets have at least 20 ratings per each user .
The methodology for evaluating the performance of a recommender system is to consider the training set as the information about the past ( which movies have been watched , and ranked , by each user ) and the test set as the ( hidden ) information about who will watch what in the future . A recommender system is run on the training set to compute for each user a ranking of movies , and then the computed rankings are compared with the test set . A better recommender system would be more effective in reconstructing the hidden information , that is , would give a closer fit between the computed rankings and the test set . More precisely , for each user u , the ranking of movies computed for this user tu } of the test is compared with the set {m(u ) 2 , . . . , movies for this user . The pairs u , m(u ) u , m(u ) tu are this user ’s ratings excluded from the training set and included in the test set . A better recommender system would place the movies m(u ) higher in the ranking . It is not obvious , however , how the closeness between the computed rankings and the test set should be quantified and a number of measures have been proposed .
1 , u , m(u ) i
1 , m(u )
2 , . . . , m(u )
We evaluated the performance of the methods from [ 8 , 9 ] as well as some additional methods using a larger dataset ( MovieLens 1M ) , which was not used in [ 8 , 9 ] . The main observation from this experiment is that the P 3 method has overtaken the L+ method ( see Table 2 ) . We used also the largest 10M MovieLens dataset , again observing superiority
Herlocker et al . [ 12 ] discusses different measures of the performance of ranking algorithms . Among the most common ones are the percentage of correctly placed pairs ( used in [ 8 , 9 ] ) and the number of hits in the top k recommendations . We use both these measures in this paper . To define these measures , we assume the general evaluation methodology described earlier ( the bipartite graph G = ( U ∪ I , R ) partitioned into the training set B and the test set T ) , and |U| = p , |I| = q , |R| = r , we use the following notation : I ( u ) = {m ∈ I : u , m ∈ R} is the set of all items associB = {m ∈ I : u , m ∈ B} is the set of ated with user u , I ( u ) T = {m ∈ I : u , m ∈ T} is the training items for user u , I ( u ) the set of the test items for user u , |I ( u)| = iu , |I ( u ) B | = bu , |I ( u ) T | = tu . For example , for a MovieLens dataset , I ( u ) is the set of all movies watched ( rated ) by user u , while I ( u ) is the set of the movies watched by user u but put aside in the test set . For all three MovieLens dataset , tu = 10 for each user u . For a given ranking algorithm A , Rank ( u ) = m(u ) 2 , . . . , qu denotes the ranking of items computed for user u , and m(u ) m <u m means that item m appears in Rank(u ) before item m ( so is ranked higher than item m ) .
1 , m(u )
T
Metric I : The number of correctly placed pairs This measure requires that the ranking algorithm A computes for each user a full ranking , that is , a ranking which includes all items . Hence we assume qu = q , for each user u . To calculate the score for a given user u , consider all pairs and m ∈ I \ I ( u ) . We of items m , m , with m ∈ I ( u ) say that such pair m , m is correctly placed , if m <u m , that is , if the ( test ) item m is ranked higher than ( appears before ) the item m . The score for user u is the percentage of correctly placed pairs : |{m , m : m ∈ I ( u )
T , m ∈ I \ I ( u ) , m <u m}| tu(q − iu )
· 100 % .
T
The score of the ranking algorithm is the average user score , over all users . If the tu test items for user u are the first items , in any order , in the ranking Rank(u ) \ I ( u ) B , then the score for this user is the perfect 100 % . For the MovieLens dataset , the score of 100 % means that the top tu movies recommended for user u , on the basis of the training set , are exactly the movies which this user has actually already watched , but have been hidden in the test set .
Metric II : The number of hits in the top k recommendations
An alternative evaluation measure is the number of hits in the top k recommendations . This measure is based on the simple all or nothing concept of counting only the test items which have made into the top k recommendations , ignoring their exact positions in the top k , and ignoring the positions of the test items outside the top k . The parameter k is either an absolute value , usually ranging between 10 and 100 , or a fraction of the total number of items , usually ranging between 1 % and 10 % . In this paper we use the relative values for k since this is more appropriate when using datasets of varied sizes . The number of hits is usually reported as the fraction of the test items in the top k recommendations , that is the fraction of the items from I ( u ) T which are among the first k items in the list Rank(u ) \ I ( u ) B .
5 . MATRIX BASED METHODS 5.1 Ranking algorithms
The input for the ranking methods is the bipartite graph G = ( U ∪ I , R ) . The methods are general , but we describe them using the terminology of the MovieLens datasets , since the evaluation presented in [ 8 , 9 ] and our evaluation are based on those datasets . Thus we refer to U as the set of users , to I as the set of movies , and the edges in G show which movies the users have watched . A ranking algorithm computes for each user a ranking of movies .
Fouss et al . [ 8 , 9 ] applied several ranking methods to the small 100K MovieLens dataset using Metric I to evaluate their performance . The methods which they used include : ranking by degree ( MaxF ) , Hitting time ( Hit← , Hit→ ) , Commute time ( AVC ) and Pseudo Inverse Laplacian ( L+ ) . They reported that the simple degree based ranking performed reasonably well , scoring 85 % , which is significantly above the 50 % score of the random permutation . The degree based ranking is probably the simplest possible method based fully only on the popularity of individual movies and requires little computation . The hitting time based rankings are considerably more costly to compute , but they did not perform better than the degree based ranking . The hitting time ranking could only match the performance of the degree based ranking , while the reverse hitting time ranking performed actually worse , scoring only 80 % . The best ranking method was the L+ ranking , scoring 90 % .
We have experimented with a number of ranking methods , looking for simple and intuitive methods which would match , or ideally exceed , the performance of the methods investigated in Fouss et al . [ 8 , 9 ] . We include in this paper experimental results the five ranking methods mentioned above and considered in [ 8 , 9 ] , the ItemRank ( IR ) method described in [ 11 ] , and the following methods .
The s step random walk distribution ( Ps ) : if u was the starting vertex .
Movies that the user u has not watched are ranked based on the probability distribution P s(u , . ) of the random walk If P s(u , m ) > at step s , P s(u , m ) , then movie m is ranked higher than movie m . The matrix P s can be computed by raising the matrix P of the transition probabilities of the random walk on G to the power of s . Observe that only odd numbers s ≥ 3 should be considered : for a user u and a movie m not watched by u , the probability P s(u , m ) can be positive only for an odd s ≥ 3 . In this paper we include experimental results only for the P 3 and P 5 rankings ( the rankings based on the distribution of the random walk after 3 and 5 steps , respectively ) , since they performed the best among the P s rankings .
Number of paths of length 3 ( #3 Paths ) :
Movies that the user has not watched are ranked based on the number of distinct paths of length 3 from that user to the movies in graph G . A movie m with the greater number of paths has a higher ranking . The numbers of paths of length 3 can be simply computed as the third power of the adjacency matrix A .
Inverse Laplacian of the transition matrix ( Z/πππ ) :
Matrix Z is defined by letting
Zij =
P ( t)(i , j ) − πj t≥0
,
( 1 ) where P ( t)(i , j ) is the probability that the random walk starting at vertex i is at vertex j at step t , and π is the stationary distribution . Matrix Z appears in some identities characterizing the parameters of the random walk . For example , Zjj/πj is the expected hitting time of vertex j from the stationary distribution ; see Chapter 2 of Aldous and Fill [ 6 ] for further details . For a user u , the Z/π method ranks the movies according to their Zu,m/πm values , with higher values indicating higher ranks . It can be shown that Zij/πj is the expected hitting time of j from the stationary distribution minus the expected hitting time of j from i , that is ,
Zij/πj =
πxH(x , j )
− H(i , j ) . x
Matrix Z can be obtained from the inverse Laplacian of the transition matrix P , as opposed to the inverse Laplacian of the adjacency matrix A used in [ 9 ] : Z = ( I − P + Π )
−1 − Π , where I is the identity matrix and Πij = πj . The details are given in Lov´asz [ 17 ] . Since the sums ( 1 ) converge rapidly , the inverse Laplacian of the transition matrix P can be obtained easily by numeric means .
Implementation details
5.2 In this section , we discuss the technical issues that arise when implementing the ranking methods discussed above . The scoring matrices for the hitting time ( Hit→ ) , reverse hitting time ( Hit← ) and commute time ( AVC ) methods can be obtained from the hitting time matrix H . Fouss et al . in [ 8 , 9 ] suggest a method to compute this hitting time matrix through the pseudo inverse of the Laplacian matrix ( L+ ) . However , this approach has a high computational cost . In addition to the computation of an inverse of a matrix , the formulas for the hitting times used in [ 8 , 9 ] requires O(n3 ) arithmetic operations , where n is the size of a Laplacian matrix . In order to compute the hitting time matrix H faster , we adopt the method presented in [ 17 ] , which is based on the following formulas .
X = ( I − P + π ) H = X − ( e ∗ λT )
−1(J − 2rD
−1 ) where I is the identity matrix of size n , P is the transition probability matrix , π is stationary distribution , J is the matrix of ones of size n × n , r is the total number of edges , D is the diagonal matrix of vertex degrees , λ is the column vector containing the diagonal entries of matrix X , and e is the column vector of ones . need 75 GB memory , or even 150GB , depending on the precision required . To reduce the computational costs of both time and space , instead of computing the full matrix P s , we compute the U × I part of this matrix ( required for scoring ) using the following formula .
U×I = PU×I ( PI×U · PU×I )(s−1)/2 , for odd s , P s
( 2 ) where PU×I and PI×U are the U × I and I × U parts of matrix P .
This improves the computation for the 100K and 1M datasets , but is not sufficient for the 10M dataset . For this large dataset , we split matrices PU×I and PI×U into 9 blocks and compute P s U×I by an appropriate sequence of multiplications and additions of these blocks .
5.3 Experimental results for matrix methods In this section we present our experimental results for the matrix based ranking methods described in Section 51 All three datasets discussed in Section 4 are used in the experiments . We used MATLAB for matrix based calculations .
Table 1 shows the performance of the ranking algorithms on the small 100K MovieLens dataset evaluated with the metric I ( the percentage of correctly placed pairs ) and the metric II ( the number of hits in the top k ) . We obtained the same metric I scores as in [ 8 , 9 ] for the methods considered there . Regarding the additional methods , the P 3 ranking method turns out to perform very well , matching the performance of the L+ method .
Table 1 also shows the scores of the ranking algorithms obtained using the metric II . We varied the parameter k of this metric – the number of top recommendations taken into account – from 1 % to 10 % . It turns out that the relative performance of the ranking algorithms in our experiments is exactly the same in both metrics . The scores computed by the metric II , however , seem to be easier to interpret .
For example , it is not immediately clear how significant the difference between the metric I scores for the hitting time ranking ( Hit→ , 85 % ) and the reverse hitting time ranking ( Hit← , 80 % ) is . However , the metric II scores in Table 1 clearly show that the reverse hitting time ranking is much weaker than the hitting time ranking . Metric II is also computationally easier than Metric I , since it does not involve sorting the rows of the computed ranking matrix .
Table 2 shows the performance of ranking algorithms on the medium 1M MovieLens dataset . The most interesting finding here is that P 3 has become the best method , overtaking slightly but clearly , the L+ method . We also observe that the performance of the MaxF and the hitting time methods are almost the same on both datasets . The performance of the reverse hitting time method is somewhat better on the larger dataset , but still clearly behind the other methods .
Matrix multiplication requires O(n2 ) space , therefore if the size of graph increases , computing the P s matrix may require impractical amount of memory space . For example , in the large 10M MovieLens dataset , there are 82 , 248 nodes in total , therefore a naive approach of computing P 3 would
Table 3 shows the score of ranking algorithms obtained using the Metric I and Metric II for the large 10M MovieLens dataset . Note that for the large dataset , due to insufficient memory space the ranking algorithms , Hit← , Hit← , AVC , L+ , IR , and Z/π are not included from the experiments .
Small size Dataset
Hit←
Evaluation MaxF Hit→ 90.99 % Metric I 90.99 % 88.19 % 87.95 % 85.79 % 85.74 % 80.45 % 85.76 % 90.94 % 89.03 % 85.72 % 90.99 % 0.261 MetricII@1 % 0.193 0.261 0.169 0.261 0.452 0.350 0.452 MetricII@3 % 0.294 0.452 MetricII@5 % 0.381 0.559 0.444 0.609 0.699 MetricII@10 % 0.543
0.214 0.445 0.582 0.582 0.582 0.736 0.736 0.736
0.197 0.362 0.460 0.616
0.160 0.292 0.381 0.542
0.212 0.376 0.478 0.637
0.007 0.051 0.125 0.341
0.161 0.293 0.382 0.543
0.161 0.294 0.382 0.544
AVC
IR1
Z/πππ
L+L+L+
P3
P5
3 Paths
Table 1 : Small size dataset ( User , Movie ) .
Medium size Dataset
Hit←
Evaluation MaxF Hit→ 89.62 % 89.62 % 86.68 % 85.93 % 85.93 % 82.28 % 85.93 % 88.10 % 88.04 % 85.93 % 89.62 % Metric I 0.234 0.181 0.234 0.173 0.234 MetricII@1 % 0.416 0.333 0.416 0.319 0.416 MetricII@3 % 0.518 0.425 0.518 MetricII@5 % 0.409 0.518 0.671 MetricII@10 % 0.567 0.671 0.671 0.586
0.198 0.374 0.466 0.604
0.173 0.319 0.409 0.567
0.206 0.370 0.464 0.624
0.076 0.159 0.211 0.309
0.173 0.320 0.409 0.567
0.039 0.171 0.279 0.458
AVC
Z/πππ
L+L+L+
P3
P5
IR
#3 Paths
87.35 % 0.198 0.356 0.449 0.606
Table 2 : Medium size dataset ( User , Movie ) .
Large size Dataset
Evaluation MaxF
P3
P5 #3 Paths
93.94 Metric I 0.353 MetricII@1 % 0.569 MetricII@3 % MetricII@5 % 0.679 MetricII@10 % 0.816
95.98 95.98 95.98 0.481 0.481 0.481 0.680 0.680 0.680 0.778 0.778 0.778 0.885 0.885 0.885
94.64 0.405 0.604 0.714 0.839
94.69 0.407 0.607 0.714 0.842
Table 3 : Large size dataset ( User , Movie ) .
In order to compare the performance of ranking algorithms in terms of the computational time , we have measured the running time of ranking algorithms by applying the MATLAB tic toc method . For the simplicity and fairness , every algorithm is measured from the moment that the training set is loaded into memory to the moment that algorithms produce ( unsorted ) ranking matrix . The measurements are repeated 5 times for each algorithm . The average values are presented in Table 4 .
5.4 Parametrised method P3 In this section we present a method for improving the performance of P s by introducing a parameter α , which ranges over the real numbers . We define matrix Pα as derived from the transition probability matrix P by raising every entry to the power of α . That is ,
α
1
α pα(u , v ) = du
0 ,
, ∃(u , v ) ∈ E otherwise
We rank the movies for the users using matrices P 3 α with the values of α ranging from 0 to 4 in steps of 01 The quality of
Figure 1 : Small Dataset : Optimisation of the performance of P 3 using parameter α the obtained rankings for the small and medium MovieLens datasets is plotted in Figures 1 and 2 , respectively . The quality is measured in both Metric I and II . Note that the vertical lines at α = 0 and α = 1 denote the performance of the #3 Path and P 3 ranking algorithms , since P0 = A and P1 = P , respectively . For the small 100K dataset , the performance measured in Metric I is improved from 90.99 % to 91.72 % for α = 1.6 and for the medium 1M dataset , it is improved from 89.62 % to 90.90 % for α = 19 These are small , but not negligible improvements . The performance evaluated in Metric II is also increased compared to the performance of P 3 , for example , for the medium size dataset , the performance is improved by an average of 0039 We observed similar improvements for the small size dataset .
The P 3 and P 3 α methods compute recommendations for a user u based only on the neighbourhood of u in graph G of diameter 3 . A closer look at the general structure of graph G can give some justification why these methods perform so
Dataset MaxF Hit→ Hit← AVC L+L+L+ 2.25 Small
3.48
3.48
0.15
3.48
IR
32.91
Z/πππ
3.10
P3
1.44
P5
1.69
#3 Paths
0.40
11.51
Medium
Large
0.39
3.05
89.24
89.24
89.24
64.42
852.26
77.20
46.70
60.03
1748.99
3504.47
1838.04
Table 4 : Running time of the ranking algorithms ( in seconds ) .
Figure 2 : Medium Dataset : Optimisation of the performance of P 3 using parameter α well . The diameter of G is small – for example , the training set subgraph for the small MovieLens dataset has diameter 6 , and on average 70 % of the users are at distance 2 from a given user . Another evident characteristic of the MovieLens datasets is their relatively high density . For example , the average degree of a user in the training set of the small MovieLens dataset is 95 . Thus another interesting question is how the ranking algorithms ” scale down ” when the density of the dataset decreases .
6 . RANKING METHODS BASED ON SIM
ULATION OF RANDOM WALKS
Ranking algorithms based on matrix manipulations have their natural limit : the sizes of the matrices may quickly become too large to fit in the computer memory . Even if the graph G modelling the dataset is sparse , matrix operations involving the adjacency matrix can easily lead to dense matrices . For example , the pseudoinverse matrix L+ and the hitting time matrix H are both dense . We did not have problems with running the ranking algorithms from the previous section on the small MovieLens dataset , but some technical issues of insufficient memory started appearing when we moved on to the medium size dataset ( the MovieLens 1M set ) , and became a major obstacle for computing matrices in the largest MovieLens dataset .
An alternative approach is to gather information about the structure of a graph from simulations of random walks in this graph . For example , the hitting times used in the ranking methods in the previous section can obviously be estimated by simulating random walks . Such simulations require only O(r ) space , to store the adjacency lists of the graph , with r n2 for sparse graphs ( n is the number of vertices and r is the number of edges ) . Furthermore , the computation can be organised in a distributed manner , if the graph is
Figure 3 : Convergence on small dataset scattered over a network .
6.1 Data capture We consider ranking methods which compute the ranking of items for a user u on the basis of the information gathered by random walks starting from vertex u . To obtained ranking algorithms which are not only space efficient but also time efficient , we set the limit of n on the total number of steps of all random walks performed for one user ( called the “ budget ” ) . That way the ranking lists for all users can be computed in O(n2 ) time , beating the time of algebraic operations on n × n matrices . The required time to produce the recommendation per user grows linearly with the budgets .
More precisely , we perform w = n/s random walks starting from a given vertex u , with each walk having s steps , for some fixed parameter s . Taking into account all w walks , we rank vertices on the basis of how often they are hit on average , or how quickly they are hit on average . For each vertex v and each random walk i = 1 , 2 , . . . , w , we keep the following information : ( a ) the step sv(i ) when vertex v was visited by walk i for the first time . ( b ) the indicator nv(i ) , which is equal to 1 , if vertex v was visited by walk i , and 0 otherwise , and ( c ) the degree d(v ) of vertex v .
6.2 Short Random Walk Evaluation Method ology
Similarly to the work of Sarkar and Moore [ 18 ] , we estimate the truncated hitting time hT ( u , v ) of vertex v starting from vertex u by w i=1
1 w sv(i ) .
( 3 )
To use this estimator , we have to decide what should be the value of sv(i ) , if vertex v was not visited during walk i . Vertices which have not been visited by any of the walks are not ranked ( or they are put in arbitrary order at the end of the ranking list , if a full ranking list is required ) , so we do not need to worry about their sv(i ) values . We consider now a vertex v which was visited by some walks , but was not visited by , say , walk i . A choice of sv(i ) = 0 seems incorrect , as this would imply v = u . Some hitting time penalty should be imposed for unvisited vertices , and we experimented with various values for this penalty . ( a ) Set the penalty to ˆm , our estimate of the number of edges incident with the subgraph we can visit in s steps . ( b ) Set the penalty to 2 ˆm/d(v ) where ˆm is the estimated number of edges . The reasoning behind this penalty is to approximate the first hitting time from stationarity of a vertex . We do not use the total number of edges of a graph to cover the cases when this is unknown . The value ˆm is our best estimate of the size of the sub graph we are expected to see within s steps , and approximates the number of edges in the breadth first search tree of depth s + 1 ( c ) Set the penalty to s , the walk length . This penalty used in [ 18 ] . ( d ) Do not impose any penalty ( set the penalty to zero ) . We include this option in our experiments as a reference point .
Having estimated hT ( u , v ) with ( 3 ) and using one of the above penalties , we can rank the movies in ascending order of their hT ( u , v ) values .
Figure 4 : Convergence on medium dataset
In addition to estimates of hT ( u , v ) we rank movies based on the number of times they were hit on average . We calculate the average number of hits of a vertex v from vertex u as w i=1 n(u , v ) =
1 w nv(i ) .
For example , if a movie m is hit w/2 times by w walks , then the number of hits is 05 Intuitively , movies which were hit often are more relevant to a user and should be ranked higher . Movies are ranked for recommendation in the descending order according to their average number of hits . We also consider some heuristics for re weighting of average number of hits , such as ( number of hits)*(degree ) .
We can also rank movies based on an estimate of the s step transition probability . We can estimate this simply by counting ˆP ( k)(u , v ) – the number of walks which hit vertex v at step s divided by the total number of walks w . If we let the number of walks increase to infinity , ˆP ( s)(u , v ) converges to P s(u , v ) . We rank movies in the descending order of values ˆP ( s)(u , v ) .
6.3 Experimental results for random walk methods
In order to estimate random walk properties without using matrix operations we made use of many short random walks of various lengths . The experiments were ran on a personal computer with an Intel Quad core CPU at 3 GHz ( specifically Intel Core 2 Quad Q9650 ) and 8 GB DDR2 800
Figure 5 : Convergence on large dataset
Length of Walk
Evaluation
Method
Small size dataset
Truncated hitting times
#Hits #Hits
ˆPs penalty : Edges ˆr penalty : 2ˆr/degree Walk length penalty :
* degree
Metric I
78.98 % 0.1642 MetricII@1 % 0.3034 MetricII@3 % MetricII@5 % 0.3903 MetricII@10 % 0.5382 79.44 % 0.1501 MetricII@1 % 0.2906 MetricII@3 % MetricII@5 % 0.3830 MetricII@10 % 0.5319
Metric I
79.64 % 0.1592 0.2962 0.3896 0.5545 80.12 % 0.1602 0.2948 0.3819 0.5410
79.08 % 0.1621 0.3056 0.3885 0.5376 79.31 % 0.1472 0.2916 0.3780 0.5253
79.17 % 0.1607 0.3029 0.3887 0.5389 79.33 % 0.1474 0.2877 0.3766 0.5232
80.45 % 0.1760 0.3300 0.4286 0.5812 80.47 % 0.1657 0.3123 0.4113 0.5723
79.02 % 0.1617 0.3028 0.3905 0.5356 70.88 % 0.0905 0.1947 0.2755 0.3959
Table 5 : Short Random Walks On the Small Dataset
Length of Walk
Evaluation
Method
Medium size dataset
Truncated hitting times
#Hits #Hits
ˆPs penalty : Edges ˆr penalty : 2ˆr/degree Walk length penalty :
* degree
Metric I
82.15 % 0.1729 MetricII@1 % 0.3214 MetricII@3 % 0.4131 MetricII@5 % MetricII@10 % 0.5620 81.92 % 0.1600 MetricII@1 % 0.3043 MetricII@3 % MetricII@5 % 0.3947 MetricII@10 % 0.5450
Metric I
82.80 % 0.1729 0.3203 0.4102 0.5688 82.97 % 0.1729 0.3196 0.4093 0.5673
82.14 % 0.1728 0.3208 0.4142 0.5621 81.74 % 0.1597 0.3036 0.3946 0.5389
82.12 % 0.1834 0.3368 0.4344 0.5893 81.72 % 0.1751 0.3214 0.4163 0.5741
83.23 % 0.1727 0.3206 0.4139 0.5617 83.09 % 0.1581 0.3002 0.3908 0.5358
82.10 % 0.1731 0.3213 0.4143 0.5618 74.89 % 0.1124 0.2269 0.3068 0.4427
Table 6 : Short Random Walks On The Medium sized dataset
( s )
3
5
( s )
3
5
( s )
3
5
Length of Walk
Evaluation
Method
Large size dataset
Truncated hitting times
#Hits #Hits
ˆPs penalty : Edges ˆr penalty : 2ˆr/degree Walk length penalty :
* degree
Metric I
91.83 % 0.1769 MetricII@1.0 % 0.4074 MetricII@3.0 % MetricII@5.0 % 0.5471 MetricII@10.0 % 0.7461 91.04 % 0.1495 MetricII@1.0 % 0.3693 MetricII@3.0 % MetricII@5.0 % 0.5122 MetricII@10.0 % 0.7157
Metric I
93.65 % 0.3507 0.5681 0.6766 0.8117 93.55 % 0.3496 0.5675 0.6751 0.8109
91.84 % 0.1769 0.4074 0.5471 0.7461 91.06 % 0.1495 0.3693 0.5122 0.7157
94.90 % 0.4681 0.6645 0.7590 0.8657 94.37 % 0.4347 0.6333 0.7315 0.8474
94.52 % 0.4210 0.6206 0.7281 0.8471 94.15 % 0.3985 0.6022 0.7103 0.8349
94.90 % 0.4681 0.6644 0.7585 0.8655 92.30 % 0.3823 0.5821 0.6813 0.8032
Table 7 : Short random walks on the large dataset s equal to 3 or 5 , led to reasonably good performance . We observe that the scores of these two methods are very close to the scores of the hitting time method Hit→ given in Table 1 . It would be of independent interest to investigate if these two methods give actually good estimators of the hitting times for these type of graphs .
6.4 Convergence of 3 step random walks to P 3 In this section we show experimental results obtained from c ∈ varying the budget of the short random walk to b = cn , N . What was done for this experiment is the same as was done to obtain the results of Tables 5 7 but specifically to estimate P s with s = 3 . These results were then compared to the results obtained using the matrix multiplication to obtain P 3 ( as seen in Table 1 ) .
The comparison was done using the formula :
Relative difference =
|Score of ˆP 3 − Score of P 3|
Score of P 3
( 4 ) where ˆP 3 is the estimated P 3 obtained via short random walks while P 3 is the matrix obtained from matrix multiplication .
The results for the small dataset can be seen in Figure 3 , for the medium dataset in Figure 4 and for the large dataset in Figure 5 , where the relative difference is the value obtained by Equation ( 4 ) . The x axis is on a log scale to emphasize how the increase of the budget greatly diminishes the benefit on the score . It is made especially apparent in the case of the large dataset ( Figure 5 ) that the budget required to get a low relative difference is sub linear in the size of the graph .
Additionally , in Figures 3,4,5 convergence is assumed to be achieved when the short random walk ranking yields the same evaluation score as the matrix operation score . However , we also want to confirm that the short random walk estimations of p3(u , m ) ( where u ∈ U and m ∈ I ) indeed converge to the real p3(u , m ) entry of P 3 . This is done using the following a form of total variation distance :
V ( P 3 ) = ||P 3 − ˆP 3||∞
( 5 )
We note that the value range of Equation ( 5 ) is [ 0 . . . 2 ] with 0 indicating identical distributions . The results of Equation ( 5 ) applied to the small dataset can be seen in Figure 6 .
Figure 6 : Total variation distance memory . We developed our implementations using the C# programming language .
The training and test set graphs were loaded into memory as adjacency lists . There were W random walks performed , each of length s . Each individual walk visited a number of vertices within s steps of the starting user . For each of these vertices , if they corresponded to movies , we recorded the number of times they were visited by the walk at a specific step . All movies were evaluated based on properties such as Truncated hitting times , number of Hits , number of hits at step s then ranked accordingly . The ranking was done using radix sort with two radices , the first being the property in which we evaluated against , and the second being a random number . This resulted in all movies to be ranked according to the evaluated property . In the case that two ( or more ) movies had the same score , they were ranked randomly . This was done to ensure that the ranking only indicated the performance of the methods being checked and not any secondary characteristics . The ranking obtained through each method was evaluated using both metrics described in Section 4 .
For most experiments the values of s were s = 3 , 5 , 7 , 9 . The values of W varied according to s based on the budget/step allowance of each experiment . For the results in Tables 5 7 the budget was set to be the number of vertices in the graph n . Walks of length s = 7 , 9 had diminishing scores and due to space limitations are not included .
Recall that our ranking methods based on simulating random walks perform for each user n/s random walks , each of length s . We experimented with various values of s and found out that small values ( that is , many short random walks ) give the best results .
The method ˆP 3 has the best performance . This method would converge to the method P 3 considered in Section 5 , if the number of walks was increasing . The method based on the number of hits weighted with the vertex degrees comes second . Among the methods based on the truncated hitting times , the penalties ˆm and 2 ˆm/degree , combined with
7 . REFERENCES [ 1 ] Anonymous ratings data from the jester online joke recommender system . http://goldbergberkeleyedu/jester data
[ 2 ] Lastfm http://wwwlastfm/ [ 3 ] Lg u+ oz store . http://ozstoreupluscokr/ [ 4 ] Movielens . http://movielensumnedu [ 5 ] Movielens data sets . GroupLens Research Lab , Dept .
Computer Science and Engineering , University of Minnesota . http://wwwgrouplensorg/node/73
[ 6 ] D . Aldous and J . A . Fill . Reversible markov chains and random walks on graphs . http://statwwwberkeleyedu/pub/users/aldous/RWG/bookhtml , 1995 .
[ 7 ] D . Billsus and M . J . Pazzani . Learning collaborative information filters . In ICML , pages 46–54 , 1998 .
[ 8 ] F . Fouss , A . Pirotte , J M Renders , and M . Saerens .
Random walk computation of similarities between nodes of a graph with application to collaborative recommendation . IEEE Trans . Knowl . Data Eng . , 19(3):355–369 , 2007 .
[ 9 ] F . Fouss , A . Pirotte , and M . Saerens . A novel way of computing similarities between nodes of a graph , with application to collaborative recommendation . In A . Skowron , R . Agrawal , M . Luck , T . Yamaguchi , P . Morizet Mahoudeaux , J . Liu , and N . Zhong , editors , Web Intelligence , pages 550–556 . IEEE Computer Society , 2005 .
[ 10 ] M . Gori and A . Pucci . Research paper recommender systems : A random walk based approach . In Web Intelligence , pages 778–781 , 2006 .
[ 11 ] M . Gori and A . Pucci . Itemrank : A random walk based scoring algorithm for recommender engines . In IJCAI , pages 2766–2771 , 2007 .
[ 12 ] J . L . Herlocker , J . A . Konstan , L . G . Terveen , John , and T . Riedl . Evaluating collaborative filtering recommender systems . ACM Transactions on Information Systems , 22:5–53 , 2004 .
[ 13 ] J . Kunegis and S . Schmidt . Collaborative filtering using electrical resistance network models . In Industrial Conference on Data Mining , pages 269–282 , 2007 .
[ 14 ] S . Lee , S . il Song , M . Kahng , D . Lee , and S . goo Lee .
Random walk based entity ranking on graph for multidimensional recommendation . In RecSys , pages 93–100 , 2011 .
[ 15 ] S . Lee , S . Park , M . Kahng , and S . goo Lee . Pathrank : a novel node ranking measure on a heterogeneous graph for recommender systems . In CIKM , pages 1637–1641 , 2012 .
[ 16 ] S . Lee , S . Park , M . Kahng , and S . goo Lee . Pathrank :
Ranking nodes on a heterogeneous graph for flexible hybrid recommender systems . Expert Syst . Appl . , 40(2):684–697 , 2013 .
[ 17 ] L . Lov´asz . Random walks on graphs : A survey . Bolyai
Society Mathematical Studies , 2:353–397 , 1996 .
[ 18 ] P . Sarkar and A . W . Moore . A tractable approach to finding closest truncated commute time neighbors in large graphs . In R . Parr and L . C . van der Gaag , editors , UAI , pages 335–343 . AUAI Press , 2007 .
[ 19 ] A . P . Singh , A . Gunawardana , C . Meek , and A . C .
Surendran . Recommendations using absorbing random walks . North East Student Colloquium on Artificial Intelligence ( NESCAI ) , 2007 .
[ 20 ] L . Zhang , J . Xu , and C . Li . A random walk based recommendation algorithm considering item categories . Neurocomputing , 120(0):391 – 396 , 2013 . [ 21 ] L . Zhang , K . Zhang , and C . Li . A topical pagerank based algorithm for recommender systems . In SIGIR , pages 713–714 , 2008 .
