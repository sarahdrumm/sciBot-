Efficient RDF Stream Reasoning with Graphics Processing
Units ( GPUs )
University of Maryland
Vrije Universiteit Amsterdam
Chang Liu
USA liuchang@csumdedu
Jacopo Urbani
The Netherlands jacopo@csvunl
Guilin Qi
Southeast University gqi@seueducn
China
ABSTRACT In this paper , we study the problem of stream reasoning and propose a reasoning approach over large amounts of RDF data , which uses graphics processing units ( GPU ) to improve the performance . First , we show how the problem of stream reasoning can be reduced to a temporal reasoning problem . Then , we describe a number of algorithms to perform stream reasoning with GPUs .
1 .
INTRODUCTION
Recently , a new research area , called stream reasoning , has emerged to address the problem of performing reasoning for very dynamic inputs . Currently , stream reasoning is visioned as a promising research area with many potential applications such as monitoring and traffic patterns detection , financial transaction audits , wind power plant monitoring , or situation aware mobile services [ 5 ] .
So far , several approaches have been proposed to tackle this problem [ 1 ] . However , they mostly propose serial algorithms , and thus leave unsolved the problem whether it is possible to leverage modern parallel computing architectures to achieve shorter responding time and better scalability . The work presented in [ 3 ] is the first to describe a RDFS reasoning engine using a GPU architecture . However , it does not target stream reasoning and optimize the computation to perform large batch computations .
In this work , we propose a system to perform stream reasoning on RDF data using the GPU computing architecture . In this context , there is both a theoretical and a practical challenge . The former is grounded on a lack of a formalization of the problem , and we address it by showing how stream reasoning can be formalized into a temporal reasoning problem , and consequently proposing a compact representation of the data under such formalization . The latter is more technical since it requires to design methods to perform reasoning very quickly before new data becomes available . Since the efficiency of a GPU hinges on the data alignment of the input , we first propose a hash based GPU encoding
Copyright is held by the author/owner(s ) . WWW’14 Companion , April 7–11 , 2014 , Seoul , Korea . ACM 978 1 4503 2745 9/14/04 . Include the http://DOI string/url which is specific for your submission and included in the ACM rightsreview confirmation email upon completing your IW3C2 form . algorithm that can efficiently translate the string terms into integer IDs of a fixed length . Then , we present a number of novel parallel algorithms using the CUDA1 programming language to perform reasoning over dynamic data . Our preliminary evaluation shows that our approach can compute the closure for an input of hundred thousand LUBM triples in a few milliseconds , making possible to reason over large streams of structured data .
2 . STREAM REASONING AS A TEMPORAL
REASONING PROBLEM
First , we define a RDF stream as a pair s = KB,S where KB is the background knowledge , which is a RDF graph , while S is the stream , which is defined as a sequence of ( τi , ti ) , where τi is a triple , and ti ∈ N is a timestamp . We say τi is observed or arrives at time ti . We assume ∀i.ti ≤ ti+1 .
In this work we consider a minimal fragment of RDFS , called ρdf [ 4 ] to perform the inference . ρdf has a deductive system which can be used to compute all triples that can be entailed from a given graph in polynomial time . The deductive system contains several rules such as the following one :
( X , sp , Y )
( Y , sp , Z ) ⇒ ( X , sp , Z )
Here sp is in the ρdf vocabulary , meaning a relationship of subproperty between two properties . The deductive system naturally defines a proof of H from G , denoted as G H , ie each triple in H is either in G , or can be derived from G using ρdf rules .
In a typical stream reasoning scenario , we are required to perform inference on a RDF graph composed by the background knowledge base and all RDF triples in a window of a RDF stream over time . A window is a time interval [ t1 , t2 ] , where t1 < t2 , t1 , t2 ∈ N . A window [ t1 , t2 ] has size t2 − t1 . The snapshot of the stream S in window [ t1 , t2 ] , denoted as S[t1 , t2 ] is the set {τ : ∃t.t1 ≤ t ≤ t2 ∧ ( τ , t ) ∈ S} . More formally , given a RDF stream KB,S , and a fixed window size w , a stream reasoning program is required to decide RDF graph Gt , such that KB ∪ S[t − w , t ] Gt for each moment t = 0 , 1 , 2 2.1 From RDF Stream Reasoning to Tempo ral RDF Reasoning
1http://wwwnvidiacom/object/cuda_home_newhtml 2Here , for t < w , we treat t − w as equivalent to 0 value . The hash function is carefully chosen ( eg SHA 1 ) so that the collision probability is negligible . While this still does not guarantee each string is mapped to a unique ID , we argue that it is a good compromise for efficiency . 3.1 Rules Execution on a RDF Stream
Our system applies each rule in the order illustrated in Figure 1 on both the stream and background knowledge data . This is the same execution order as the one used in [ 3 ] .
However , differently from [ 3 ] , our system needs to deal with the incremental part . Since TBox is usually much smaller than ABox , we cache all TBox triples in the GPU memory . We implemented two strategies in case the TBox is either static or present in the stream .
Static TBox . If the TBox is static , then we can omit all rules that deal with only TBox triples ( ie the rules in grep box in Figure 1 ) . All the other rules require a join between TBox and ABox . In our case , the TBox is cached in the GPU memory before the stream arrives , and this allows us to perform some preprocessing on the TBox ( eg sorting and building hash table ) , so that computing the join between a dynamic ABox ( only the incremental part ) and the static TBox can be executed using well known join algorithms like sort join or hash join . In our experiment , an hash join has achieved the best performance .
Dynamic TBox . If the TBox is not static , then we cannot omit the TBox rules like the ones required to compute the transitive closure of sp and sc . Since computing the transitive closure requires an iterative process until fixpoint where each iteration produces redundant computation . To reduce such a redundancy , we employ incremental algorithms that computes only the join result over triples derived within two iterations . This reduces the computation and allows a substantial increase of performance .
Acknowledge Guilin Qi is partially supported by the Marie Curie IRSES project SemData 612551 . Jacopo Urbani is funded by the Dutch VENI project 639021335
4 . REFERENCES [ 1 ] D . F . Barbieri , D . Braga , S . Ceri , E . D . Valle , and
M . Grossniklaus . Incremental Reasoning on Streams and Rich Background Knowledge . In Proc . of ESWC ’10 , pages 1–15 , 2010 .
[ 2 ] M . Billeter , O . Olsson , and U . Assarsson . Efficient stream compaction on wide SIMD many core architectures . In Proc . of HPG ’09 , 2009 .
[ 3 ] N . Heino and J . Z . Pan . RDFS Reasoning on Massively
Parallel Hardware . In Proceedings of ISWC , pages 133–148 , 2012 .
[ 4 ] S . Mu˜noz , J . P´erez , and C . Gutierrez . Minimal
Deductive Systems for RDF . In Proceedings of ESWC , pages 53–67 , 2007 .
[ 5 ] E . D . Valle , S . Ceri , F . van Harmelen , and D . Fensel .
It ’s a Streaming World! Reasoning upon Rapidly Changing Information . IEEE Intelligent Systems , 24(6):83–89 , 2009 .
Figure 1 : The general workflow of the stream reasoning engine .
A temporal RDF triple τ : λ is a pair of a RDF triple τ and a temporal annotation λ . A temporal annotation λ is a union of a finite number of intervals .
Temporal RDF has a deductive system which is an extension of ρdf rules . The temporal RDF deductive system also naturally defines a proof of H from G , denoted as G t H . Given a RDF stream s = KB,S , the temporal correspondence of s at moment t denoted as T ( s , t ) , is a temporal graph defined by {τ : [ 0 , +∞]|τ ∈ KB} ∪ {τ : [ t , t + w]|(τ , t ) ∈ S ∧ t ≤ t} . We can show the following result : Given a RDF stream s = KB,S , a RDF graph Gt , and a moment t , KB ∪ S[t − w , t ] Gt , if and only if ∀τ.τ ∈ Gt ⇔ ∃λ.t ∈ λ ∧ T ( s , t ) t τ : λ . This result allows us to use a temporal RDF deductive system to compute the closure avoiding the expensive deletions required in the incremental process . To further speed up the inference process , we use a compressed representation of the temporal annotation : Instead of storing the temporal interval , we only store t + w for a triple τ arriving at t .
3 . STREAM REASONING USING CUDA
If we treat a RDF graph as a three column table , then the execution of a rule translates in computing a relational join over the tables . The premises of each rule contains at most one ABox triple ( ie the triples that do not contain sp , sc , etc ) Furthermore , the number of TBox triples ( ie the triples that are not ABox triples ) is small and there is a static knowledge base , that will never change while new stream triples are arriving .
First , our system executes the transitive closure rules over the ABox triples in the static knowledge base . Then , it executes the following steps after new triples arrive in the stream : Removing the expired triples ; Encoding the new triples ; Executing the rules . The system workflow is reported in Figure 1 , and in the following we describe each phase in more detail . Removing the expired triples . As discussed above , all expired triples are those τ : t where t+w < t . Therefore when a triple τ : t is arrived , we keep track of t + w as τ ’s annotation . Then , we remove all triples whose annotation is less than the current time t . This operation can be computed in parallel using a parallel stream compaction algorithm like the one described in [ 2 ] .
Compression of the RDF Stream . Before performing reasoning , our system encodes the textual terms of the triples into numeric IDs . We propose a two phase hash based algorithm to perform this operation : in the first phase , we compute the hash value of each variant length string , while in the second phase we assign a unique ID to each hash
