Modeling Contextual Agreement in Preferences
Loc Do
School of Information Systems
Singapore Management University hldo2012@phdissmuedusg
Hady W . Lauw
School of Information Systems
Singapore Management University hadywlauw@smuedusg
ABSTRACT Personalization , or customizing the experience of each individual user , is seen as a useful way to navigate the huge variety of choices on the Web today . A key tenet of personalization is the capacity to model user preferences . The paradigm has shifted from that of individual preferences , whereby we look at a user ’s past activities alone , to that of shared preferences , whereby we model the similarities in preferences between pairs of users ( eg , friends , people with similar interests ) . However , shared preferences are still too granular , because it assumes that a pair of users would share preferences across all items . We therefore postulate the need to pay attention to “ context ” , which refers to the specific item on which the preferences between two users are to be estimated . In this paper , we propose a generative model for contextual agreement in preferences . For every triplet consisting of two users and an item , the model estimates both the prior probability of agreement between the two users , as well as the posterior probability of agreement with respect to the item at hand . The model parameters are estimated from ratings data . To extend the model to unseen ratings , we further propose several matrix factorization techniques focused on predicting agreement , rather than ratings . Experiments on real life data show that our model yields context specific similarity values that perform better on a prediction task than models relying on shared preferences .
Categories and Subject Descriptors H33 [ Information Search and Retrieval ] : Information filtering ; H28 [ Database Applications ] : Data Mining
Keywords user preference ; contextual agreement ; generative model
1 .
INTRODUCTION
Users face a dizzying array of choices for almost any decision they make on the Web today , eg , which movie to see ,
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author ’s site if the Material is used in electronic media . WWW’14 , April 7–11 , 2014 , Seoul , Korea . ACM 978 1 4503 2744 2/14/04 . http://dxdoiorg/101145/25664862568006 which book to purchase , which job to pursue next and when [ 40 ] , which tag to use [ 26 ] . In exploring options , the limiting factor is often not affordability or availability , but rather the user ’s time and attention . Many Web platforms deal with this scarce resource through personalization , by focusing the user ’s attention on things most likely to be of interest .
In order to provide a personalized experience to each user , we first need to know the user ’s preferences . To some extent , this is provided by the user ’s own past activities , such as which Facebook posts she liked or disliked , or which products on Amazon she purchased , or which movie on Netflix she rated high or low . However , these preference signals are too sparse . They are expressed over a very limited number of items . For instance , most Netflix users would have assigned ratings to only tens of movies , as compared to the thousands of available movies . Hence , there is a need to extrapolate from these signals to build a more general preference model . Most of the previous work in this area focus on modeling individual preferences . The aim is to derive user specific models from preference data , eg , ratings , which will help predict future adoptions or ratings by the user . There are several well known classes of methods , such as aspect model [ 8 , 9 ] , matrix factorization [ 15 ] , and content based model [ 1 , 31 , 21 ] ( see Section 2 for a more expansive review ) . These methods are still actively being researched , and their use is prevalent in industrial recommender systems .
Beyond individual preferences , there is also a significant body of work on the complementary issue of shared preference between pairs of users . For instance , neighborhoodbased collaborative filtering systems [ 12 , 33 , 5 ] predict a user ’s rating on an item as the weighted average of ratings by her neighbors . Here , neighbors are other users with high similarity in preferences , and the weights are proportional to the degrees of similarity between a pair of users . Shared preference is useful , because some individuals may not have established a sufficiently long record of activities ( eg , ratings ) for a reasonably accurate individual model to be built . However , the limited record may already be sufficient to infer her similarity to another user with a longer record or more accurate model , which can then be “ borrowed ” to help in the predictions for the former user . Alternatively , there may be extra information , eg , social network , to induce preference sharing between friends [ 24 , 22 ] .
While shared preference is helpful , it also makes the implicit assumption that the similarity between two users applies equally to all items under consideration . More realistically , users have diverse preferences . Even a similar pair of users do not agree at all times . We therefore postulate the
Movie
Rating by Rating by talyseon youngchinq
Paranormal Activity Payback Coraline Pan ’s Labyrinth Memento Gran Torino The Hurt Locker Jurassic Park III Twilight Inception Daredevil I Am Legend Rosemary ’s Baby The Day After Tomorrow 300 Moulin Rouge Seven Pounds The Dark Knight The Last Samurai Star Wars Episode III : Revenge of the Sith
5 3 5 5 5 5 5 3 3 5 3 4 5 4 4 5 4 5 5 5
5 3 5 5 4 4 4 2 1 3 1 2 2 1 1 2 1 1 1 1
Table 1 : Epinions users talyseon and youngchinq need to pay attention to “ context ” , arguing that while a pair of users may agree in their preferences in one “ context ” , they may disagree in a different “ context ” . There are many ways to define “ context ” . For instance , the product category or the time of day could each be a specific context . However , these definitions assume the presence of additional information in the data . To retain the most common framework in the literature , which is to rely on rating data alone , in this paper , by “ context ” , we refer to each specific item . In other words , we are interested in the contextual agreeement of preferences between two users in the context of one item . To illustrate this more clearly , we use a real life example from Epinions.com , an online rating site for various products , eg , movies ( used in this example ) . In Table 1 , we show the rating profiles of two users : talyseon and youngchinq , on twenty movies that both of them had rated . The ratings are from 1 ( low ) to 5 ( high ) . The traditional approach of shared preference is to use these ratings to measure the overall similarity between the two users . Using Pearson ’s correlation , their similarity is 053 Using Cosine similarity , their similarity is 088 ( See Section 2 for the definitions of these measures . ) These similarities are considered high as Pearson ranges from 1 to 1 , and Cosine ranges from 0 to 1 . On one hand , the two users do share some preferences . The top few movies in the list are movies that both assign high ratings to , which tend to be dramas and thrillers . On the other hand , a single similarity value cannot reveal the full picture of their preference sharing . The last few movies in the list are those that talyseon likes but youngchinq dislikes . These tend to be fantasy types ( eg , Star Wars III , Dark Knight ) . Therefore , agreement on preference should be seen in the context of individual items . For instance , we say that talyseon and youngchinq agree on their preference in the context of “ Paranormal Activity ” movie . However , they disagree in the context of “ The Last Samurai ” movie .
Problem . Given a set of users ( eg , u ) , a set of items ( eg , i ) , and some ratings by users on items ( eg , rui ) , we seek to model the contextual agreement between a pair of users u and v on a specific item i ( collectively denoted as a triplet u , v , i ) . Instead of just another similarity measure , we model this contextual agreement as a probability measure , with a binary random variable yuvi with two outcomes : agreement ( yuvi = 1 ) or disagreement ( yuvi = 0 ) .
One key observation is that the observed rating values , eg , rui and rvi , provide signals of the agreement or disagreement between u and v on item i . To represent this more succintly , we derive a quantity xuvi , which is a function of rui and rvi , ie , xuvi = F(rui , rvi ) , through some function F ( to be defined later ) . Our problem can thus be restated as estimating the probability of agreement P(yuvi = 1|xuvi ) . This gives rise to two sub problems . The first is the probabilistic modeling of P(yuvi = 1|xuvi ) . This is akin to probabilistic clustering , whereby we seek to decide the latent “ class ” yuvi using the “ feature ” xuvi . Therefore , we adopt a generative modeling based on Gaussian mixtures , which has been applied to other unsupervised clustering problems . We call this model Contextual Agreement Model or CAM .
The second sub problem is that not all xuvi ’s are observed , arising directly from not having observed all possible ratings . For “ unseen ” triplets , where either rui or rvi is unobserved , we need to predict ˆxuvi ( the hat indicates predicted , rather than observed ) . For this , we adopt the framework of matrix factorization . The key to our approach is the minimization of a novel objective function based on optimizing for agreement , rather than rating , prediction . We call this method Differential Probabilistic Matrix Factorization or DPMF .
Application . The probability of contextual agreement allows for a better estimation of the contextual similarity between a pair of users on a specific item . This will come in useful in several potential applications . First , as we will explore in Section 3 , the agreement probability can be used in calibrating the similarities between neighbors in an itemspecific manner for a neighborhood based recommender system to derive a rating prediction . Second , it can support a more targeted social recommendation . When a user wants to recommend an item to her friends , instead of sharing with all friends , the contextual agreement probability can identify the subset of friends most in agreement on the item . Third , the model may be useful in a study of prevalence of agreement in different communities , product categories , etc . Scope . While our work is related to recommender systems , our focus is on modeling preferences , and not on rating prediction . The reader may also surmise that a similar contextual agreement framework may apply to triplets involving a user and two items . This is indeed the case , but to maintain focus , we will discuss only triplets involving two users and an item . As input , we assume only ratings data , and not other information such as categories or ontologies [ 28 ] . We also assume that ratings are truthful and reflective of user preferences ( and not artefacts of dishonesty or fraud [ 6] ) , which we believe is true for a vast majority of users .
Contributions . First , as far as we know , we are the first to propose modeling item specific context in estimating the agreement between a pair of users on an item . Second , to realize this modeling , in Section 4 , we develop a probabilistic generative model , called CAM , based on Gaussian mixtures . We enforce a monotonicity property that results in a specific parameter constraint , and describe how to learn the constrained parameters with Expectation Maximization . Third , to extend this model to unseen triplets , in Section 5 , we outline how several matrix factorization methods can be applied . We also propose a new method , called
DPMF , with a novel objective function that minimizes errors in rating differences , and describe its gradient descent learning algorithm . Fourth , in Section 6 , we validate these models comprehensively on three real life , publicly available rating datasets , showing how well the model parameters are learned , and how they improve upon shared preference models in a neighborhood based rating prediction task .
2 . RELATED WORK
In the following , we survey related work on modeling preferences , first focusing on individual users , and then on similarities between users , and finally on the role of context .
Individual preference . Most works on modeling individual preference are found in model based recommender systems [ 1 ] . The main step is to construct a preference model for each user , which is then used to derive predictions . Here , we review three popular modeling choices . The first is aspect model [ 8 , 9 ] . A user u ’s preference is modeled as a probability distribution {P(zk|u)}K k=1 over K latent aspects . Each aspect zk is associated with a distribution over items i to be adopted , ie , P(i|zk ) , or over ratings r , ie , P(r|zk , i ) .
The second is matrix factorization based model [ 15 ] . User u ’s preference is modeled as a column vector Su in a Kdimensional latent space . Each item i is also associated with a rank K column vector Qi . The rating prediction ˆrui by T Qi . There are different factorization u on i is given by Su methods [ 18 , 39 , 17 , 25 ] , which vary in their objective functions , including several probabilistic variants [ 29 , 34 ] .
The third is content based model [ 1 , 31 , 21 ] . User u ’s preference is modeled as a content vector whose dimensionality is the vocabulary size ( eg , tf · idf vector ) , derived from the content ( eg , meta data , text ) of items that u likes .
Shared preference . Modeling sharing of preferences is mostly found in neighborhood based recommender systems [ 11 ] . One approach is based on similarity . For user based collaborative filtering ( CF ) [ 12 ] , the similarity wuv is between a pair of users u and v . The higher wuv is , the more u and v share their preferences . The most common similarity measures in the literature are Pearson ’s correlation coefficient [ 33 ] , and vector space or Cosine similarity [ 5 ] . Given that ru and rv represent vectors of ratings , {rui} by u and {rvi} by v , on a set of items {i} , Pearson is determined as in Equation 1 ( where ¯ru and ¯rv are average ratings ) , and Cosine as in Equation 2 . Correspondingly , for item based CF [ 35 , 19 ] , the similarity is between a pair of items . i(rui − ¯ru)2 i(rui − ¯ru)(rvi − ¯rv ) i(rvi − ¯rv)2 wcosine uv
= ru · rv
||ru|| × ||rv||
( 1 )
( 2 ) wpearson uv
=
Another approach to model sharing of preferences is to exploit existing structures . For example , in a social network , each relationship ( eg , friends or follower followee ) is seen as inducing sharing of preferences between the two users [ 24 , 22 ] . Some exploit the taxonomy structure to induce sharing between items in the same category [ 36 , 2 , 13 , 27 , 14 ] .
Context . Most of the work discussed above base their approaches on the dyad of user item pair . In some cases , additional information or “ context ” may be available , ie , rather than pairs u , i , we observe triplets u , i , c where c refers to some context . There are different approaches to dealing with triplets . One approach is to break a triplet into multiple binary relations , eg , friend user item into user friend and user item such as done in [ 23 , 38 , 37 ] for rating cum link prediction . [ 41 , 20 ] suggest partitioning dyads into clusters based on context , and then learning a separate model for each cluster . Another approach is tensor factorization , such as done in [ 10 ] for cross domain rating prediction . Yet another approach , such as ours , is to model triplets directly . Differently from [ 32 , 30 , 16 ] targeting user item item triplets for personalized ranking of items ( asymmetric ) , we target user user item triplets to model agreement .
3 . OVERVIEW Notations . The universal set of users is denoted as U , and we use u or v to refer to a user in U . In turn , we use i or j to refer to an item in the universal set of items I . The rating by u on i is denoted as rui . The set of all ratings observed in the data is denoted R . We seek to model user user item triplets u , v , i . The universal set of triplets comprises U × U × I , excluding triplets involving the same users , eg , u , u , i . Each triplet u , v , i is associated with two quantities ( modeled as random variables ) : xuvi and yuvi , which are essential to our probabilistic modeling .
The variable xuvi ∈ R is real valued .
It represents the indicator of agreement between u and v on i , some of which are observed in the data . The closer xuvi is to 0 , the more likely it is that u and v agree on i . If xuvi 0 or xuvi * 0 , then disagreement is more likely . xuvi can be expressed as a function of ratings , ie , xuvi = F(rui , rvi ) . While there are many possible definitions of F , in this paper , we simply use the rating difference between two users on the same item , as shown in Equation 3 . This choice of function also implies the symmetry of xuvi = −xvui . xuvi = rui − rvi
( 3 ) The second variable yuvi ∈ Y = {0 , 1} is binary . yuvi = 1 represents the event of agreement between u and v on their preference for i . yuvi = 0 is the event of disagreement . These events are latent , and never observed . They are to be estimated from the observed xuvi ’s . The closer xuvi is to 0 , the more likely we expect yuvi = 1 . The further xuvi is away from 0 , the more likely we expect yuvi = 0 .
Problem Formulation . Given ratings data R , and the above xuvi definition , we seek to estimate the probability P(yuvi|xuvi ) for all triplets . Not all xuvi ’s can be observed . xuvi is not observed if either rui /∈ R or rvi /∈ R . This gives rise to two sub problems . The first is how to estimate P(yuvi|xuvi ) given the observed xuvi values . The second sub problem is how to predict the un observed ˆxuvi values . For the first sub problem , we propose the probabilistic CAM model in Section 4 . Since yuvi is latent , it is not possible to employ discriminative modeling . We therefore turn to generative modeling , by representing xuvi as a random variable , whose generative process is related to yuvi . Our approach is thus to model the joint probability P(yuvi , xuvi ) . The conditional probability P(yuvi|xuvi ) can afterwards be estimated from the joint probabilities as follows :
P(yuvi|xuvi ) =
P(yuvi , xuvi ) uvi∈Y P(y y uvi , xuvi )
( 4 )
The second sub problem is how to predict the unseen ˆxuvi . We will then use the predicted ˆxuvi with the parameters
Figure 1 : Distributions of P(x|y ) and P(y|x )
Figure 2 : Plate Diagram for CAM v=u,rvi=φ wuvi × rvi v=u,rvi=φ wuvi
ˆrui =
( 5 ) learned in the first sub problem , to estimate P(yuvi|ˆxuvi ) . Our key insight is that the ˆxuvi ’s are not independent from one another . All triplets involving the same item i or the same user pair ( u , v ) will share some dependency . Furthermore , the triplet should model the interaction of users and items . Our approach is to model the generation of xuvi based on user or item specific parameters so as to generate/predict unseen ˆxuvi through matrix factorization in Section 5 . The framework can accommodate different predictive methods . Indeed we outline several potential methods , including a new proposed method called DPMF .
Application . One application of the agreement probabilities is as a similarity value in a neighborhood based collaborative filtering ( CF ) . User based CF [ 11 ] exploits the similarities between users to predict unseen ratings . Adopting the same rating prediction framework , we can use the contextual agreement to weigh the contributions of neighbors . To predict an unseen rating ˆrui , we use Equation 5 , which is the weighted average of ratings on i by u ’s neighbors . Neighbor v can be any user , weighted by wuvi .
In our case , we use wuvi = P(yuvi = 1|ˆxuvi ) , which is specific to every item i . In Section 6 , we will compare this to the traditional case of shared preference , where the weight wuvi is set to the similarity between u and v , which is then applied to all items . The most popular similarity functions are Pearson ’s coefficient [ 33 ] and Cosine similarity [ 5 ] . This comparison is fair as both approaches are given exactly the same set of ratings to use , but differ only in the relative weights of the ratings . Note that in this application , our objective is not to propose a new rating prediction algorithm , but rather to illustrate the utility of contextual agreement , and enable comparison to appropriate baselines .
4 . CONTEXTUAL AGREEMENT MODEL 4.1 Generative Model Given the observed xuvi ’s , we want to estimate the probability distribution of contextual agreement P(yuvi|xuvi ) . When the context is clear , we simplify the notations for yuvi and xuvi to y and x respectively . Because y is latent , we estimate the conditional probability P(y|x ) from the joint probability P(y , x ) . In a generative modeling framework , we decompose P(y , x ) into P(x|y)P(y ) . P(y ) corresponds to the prior probability of agreement between u and v on i . P(x|y ) is the likelihood that x has been generated from y .
The prior of agreement P(y ) is the base level of agreement between u and v before seeing the item i . Given that there are two probable events , ie , agreement ( y = 1 ) and disagreement ( y = 0 ) , we model this as a Bernoulli process with a parameter α . In other words , the prior of agreement is P(y = 1 ) = α , and of disagreement is P(y = 0 ) = 1 − α . In the event of agreement ( y = 1 ) , x will be generated according to a probability P(x|y = 1 ) . Because x is realvalued , and we expect that its values in the event of agreement will cluster together , we model the generation of x as a Gaussian , with an underlying mean µ1 and variance σ2 1 . As mentioned in Section 3 , the closer is xuvi to 0 , the more likely it is that u and v agree on i . Therefore , we make a simplifying step , and set µ1 = 0 . We learn σ1 from data . The blue curve in Figure 1(a ) illustrates the probability density function ( pdf ) of P(x|y = 1 ) , which is a Normal distribution centered at µ1 = 0 ( in this example , σ1 = 09 ) In the event of disagreement ( y = 0 ) , x will be generated according to to a probability P(x|y = 0 ) . Since x * 0 or x 0 indicates disagreement , the mean of this Gaussian should be away from 0 . Due to the symmetric property xuvi = −xvui , we model this as a bimodal distribution , such as an equally weighted mixture of two Gaussians with positive mean at µ0 and negative mean −µ0 , and a variance of σ2 0 . The red curve on Figure 1(a ) illustrates the bimodal pdf of P(x|y = 0 ) ( in this example , µ0 = 2.5 , σ0 = 1 ) . P(y|x ) can therefore be expressed in terms of these components as shown in Equation 6 . The green curve on Figure 1(a ) illustrates the “ decision function ” or the pdf of P(y = 1|x ) , estimated from the respective prior P(y ) and likelihood P(x|y ) . As expected , P(y = 1|x ) is highest when x ≈ 0 . As x moves away from 0 , the probability of agreement decreases , which fits the modeling objective .
P(y|x ) =
P(x|y)P(y ) y∈Y P(x|y)P(y )
( 6 ) tive process for a set of observed triplets X = {x} .
Generative Process . We now describe the full generaFor every triplet x ∈ X : 1 . Draw an outcome for y ∈ {0 , 1} : y ∼ Bernoulli(α )
2 . Draw an outcome for x ∈ R :
(cid:30) (cid:36) * (cid:30) * * (cid:30) fi * fi fi * (cid:30) (cid:36) * (cid:30) * * (cid:30) fi * fi fi * ff '(()ff( fiffflffff(ffl(flffi (cid:30) * flflfffiffl fiffflffff(ffl(flffi *(cid:36) (cid:30) * yuvixuviuvU×Ui I uv uv ( a ) In the event of agreement , ie , y = 1 : x ∼ N ( µ1 , σ2 1 )
( b ) Else , in the event of disagreement , ie , y = 0 : x ∼ 1 2
N ( µ0 , σ2
0 ) +
N ( −µ0 , σ2 0 )
1 2
Based on this generative process , the distribution of x can be expressed as a mixture of three Gaussians with weights α , 1−α respectively , as shown in Equation 7 .
1 − α
2
N ( µ0 , σ2
0 ) +
1 − α
2
N ( −µ0 , σ2 0 )
( 7 )
1 ) +
2 , and 1−α x ∼ αN ( µ1 , σ2
2
Parameters . For the above generative process , the set of parameters can be encapsulated by θ = α , µ1 , σ1 , µ0 , σ0 . The question arises whether there is a unique θ for every triplet u , v , i . Because θ is a distributional parameter , it is not feasible to estimate θ from a single observation of x . Another approach is to tie together the parameters of a group of triplets . In this paper , we propose to tie the parameters of triplets corresponding to each pair of users . In other words , there is a specific θuv for each pair of users u and v that applies to all items . As shown in the plate diagram in Figure 2 , αuv and θuv are within the plate of each pair of users . For clarity , we draw αuv separately to show that yuvi only depends on αuv , although αuv ∈ θuv . xuvi is shaded , because it is observed . 4.2 Monotonicity Property We would like to model P(y = 1|x ) that increases as x → 0 , and decreases as x → ∞ or x → −∞ . We refer to this as the monotonicity property of the conditional probability of agreement . This monotonicity property does not always hold for any or all parameter settings . There are errant parameter settings that may cause this property to be violated . As an example , in Figure 1(b ) , we show a case where P(y = 1|x ) ( the green curve ) initially decreases as x goes away from zero , but as x continues moving away , it starts to increase again . This is not intuitive , as it suggests that the probability agreement is very high even as x → ∞ . To enforce the monotonicity property , we propose introducing some constraint to the parameters of the Gaussian mixtures . By expanding Equation 6 according to the generative process , we can express the pdf of P(y = 1|x ) as in Equation 8 . Here , N ( x ; µ , σ2 ) denotes the pdf of Normal distribution , ie ,
2σ2 } . 2πσ2 exp{− ( x−µ)2 1√ αN ( x ; 0 , σ2 1 ) 2 N ( x ; µ0 , σ2 0 ) + 1−α
1 ) + 1−α
G(x ) =
αN ( x ; 0 , σ2
2 N ( x;−µ0 , σ2 0 ) ( 8 ) Because the pdf G(x ) is continuous and differentiable , one way to ensure that monotonicity holds is to constrain the gradient of G(x ) to be negative for all x > 0 , as shown in Equation 9 . Note that due to the symmetric property of the Gaussian mixtures , it is sufficient to enforce this monotonicity for x > 0 , as the other case x < 0 is met by default .
∂G(x ) ∂x
( 9 ) By taking the derivative of G(x ) with respect to x , Equa
< 0 , for all x > 0 tion 9 can be reduced into the inequality in Equation 10 . fl 4xµ0 x
2σ2 0
σ2 1 exp
+ x
σ2 1
− x − µ0
σ2 0
− x + µ0
σ2 0
> 0 ( 10 )
This inequality still contains the variable x . We need to reduce it to an inequality involving only the parameters . We discover a simple constraint that meets that objective .
Proposition 1.The constraint σ1 < σ0 ensures that Equa
σ2 1
2σ2 0
}( x
− x−µ0
Proof . Let us first consider the first additive term in ) . Because tion 10 always holds for any x > 0 . LHS of Equation 10 , ie , exp{ 4xµ0 x , µ0 , and σ0 are all positive , we have 4xµ0 2σ2 have exp{ 4xµ0 0 x−µ0 σ2 0
> 0 . In turn , we − ) > 0 . We can therefore take Step 1 in Equation 11 . From Step 1 , we can go to Step 2 by a simple addition of the terms . Finally , because x > 0 , and σ1 < σ0 , we have 2x( 1 σ2 1
} > 1 . Because σ1 < σ0 , we also have ( x
) > 0 in Step 3 , which concludes the proof .
− 1
2σ2 0
σ2 1
σ2 0 x
σ2 1
− x − µ0 x
σ2 0 − x + µ0
+
+
σ2 1
σ2 0
− x + µ0
σ2 0
σ0 exp
2σ2 0 x fl 4xµ0 x
− x − µ0
1 σ2 0 − 1 σ0
σ2 1
σ2 1
σ2 1
≥
=2x
>0
( 11 )
( Step 1 )
( Step 2 )
( Step 3 )
We have shown that with the constraint of σ1 < σ0 , Equation 9 holds , guaranteeing the monotonicity property for x > 0 ( and simultaneously for x < 0 ) . This constraint σ1 < σ0 is also intuitive , as when two users are agreeing their rating difference is likely to be small and not vary as widely as when they are disagreeing . 4.3 Parameter Estimation Parameter estimation deals with learning the parameters θ that best “ describes ” the observed data X = {x} . Because every x is assumed to have been generated independently in the generative process , the likelihood can be expressed as the joint probability shown in Equation 12 .
P(X|θ ) =
P(x|θ )
( 12 ) x∈X
The strategy employed in this paper is to find the parameters that maximize the likelihood of observing X . Due to the presence of constraints , the objective is to also find θ that meets the constraints , as shown in Equation 13 . The first constraint ensures the mixture weights of the Gaussians sum to 1 , by setting the mixture weights to α1 = α and α0 = 1 − α respectively . The second constraint ensures the monotonicity of P(y = 1|x ) by setting σ1 < σ0 .
P(X|Θ ) , arg max
θ subject to : α0 + α1 = 1 , and σ1 < σ0
( 13 )
To maximize the likelihood , we can equivalently maximize the log likelihood . As it is a constrained optimization problem , we employ the use of Lagrangian multipliers [ 4 ] to enforce the constraint . In Equation 14 , we show the updated log likelihood function L . Both λα and λσ are Lagrangian multipliers for the constraints . We also introduce a slack variable s2 , whose positive value ensures that σ1 < σ0 .
L = ln P(x|θ ) + λα(α1 + α0− 1 ) + λσ(σ0− σ1− s2 ) ( 14 ) x∈X
To learn the parameters that maximize the log likelihood function L , we turn to Expectation Maximization ( EM ) algorithm [ 3 ] . It can be shown that the derivation of L with respect to each parameter leads to the following computations in the E step and M step .
In the E step , we compute the following quantities ( to be used in the next M step ) :
0 ) + N ( x|µ0 , σ2 0 ) )
2P(x|Θ ) ( N ( x| − µ0 , σ2
• c(x ) = 1−α • d(x ) = αP(x|y=1 ) P(x|Θ ) 2P(x|Θ)N ( x| − µ0 , σ2 • e1(x ) = ( 1−α ) 0 ) 2P(x|Θ)N ( x|µ0 , σ2 • e2(x ) = ( 1−α ) 0 ) x∈X ( e1(x)− e2(x))x , where C = x∈X d(x ) · x2 , where D = x∈X ( e1(x)·(x+µ0)2 +e2(x)·(x−µ0)2))− 1
In the M step we compute µ0 , σ1 , σ0 and s . • µ0 = 1 • α = 1|X| • σ2 1 = 1 D • σ0 = ( 1 x∈X d(x )
σ1 , where E =
E x∈X ( e1(x ) + e2(x ) ) x∈X d(x )
C x∈X c(x )
2 +
Once the parameters are learned , we can make inferences for the posterior probability of agreement P(y = 1|x ) , based on Equation 6 , and substituting the learned parameters θ .
5 . RATING DIFFERENCE PREDICTION
While CAM could explain the distributive properties of xuvi ’s and provide an estimation of the contextual agreement probability P(yuvi|xuvi ) , it assumes that xuvi is known . This is true only for a relatively small subset of triplets . In order to extend the model to unseen triplets , we need to estimate the unseen ˆxuvi from ratings data . Inspired by previous work on recommender systems , we adopt an approach based on matrix factorization . While related , our problem is different from traditional recommender systems in two ways . First , the object of interest is a triplet u , v , i , instead of a pair u , i . Second , the value to be estimated xuvi is rating difference ( see Equation 3 ) , instead of ratings .
We outline three matrix factorization approaches to solve this problem . The first , PMF , is an existing approach repurposed for our problem . The second , PPMF , is a modification . The third , DPMF , is a new proposed method . 5.1 Probabilistic Matrix Factorization ( PMF ) One way to predict ˆxuvi is to first predict ˆrui and ˆrvi , and subsequently taking their difference . As a representative of this approach , we employ the Probabilistic Matrix Factorization or PMF [ 29 ] . The set of ratings R can be represented as a matrix of size |U| × |I| , where each element corresponds to a rating rui . This matrix is incomplete , and the goal is to fill up the missing entries with predicted ˆrui . The approximation uses two rank K matrices S ∈ RK×|U| and Q ∈ RK×|I| .
Let Su be a column vector in S for user u . Let Qi be a column vector in Q for item i . PMF places zero mean spherical Gaussian prior distributions on Su and Qi ( with standard deviations ϕU and ϕI ) to control the complexity of the parameters , ie , Su ∼ N ( 0 , ϕ2 I I ) . The plate diagram of PMF is shown in Figure 3(a ) . It shows how ratings are generated by the parameters Su and Qi . Each ˆrui is assumed to be drawn from a Gaussian distribution centered at Su
T Qi with variance γ2 ( Equation 15 ) .
U I ) and Qi ∼ N ( 0 , ϕ2
ˆrui ∼ N ( Su
T Qi , γ2 )
( 15 )
Parameter estimation is by maximizing the log posterior distribution over item and user vectors with hyper parameters , which is equivalent to minimizing the sum of squared errors function in Equation 16 . IR(u , i ) is an indicator function of whether u has rated i . Equation 16 contains two components . The first summand is the fitting constraint , while the rest constitutes the regularization . The fitting constraint keeps the model parameters fit to the training data whereas the regularizers avoid overfitting , making the model generalize better [ 7 ] . λU , λI are the regularization parameters . u∈U i∈I
1 2
E =
IR(u , i)(rui−Su
T Qi)2+ u∈U
λU 2
||Su||2+
λI 2 i∈I
||Qi||2
( 16 ) The estimation is done using gradient descent [ 29 ] , with the following gradients . Once the parameters are learned , we then predict each ˆxuvi as Su
T Qi − Sv
T Qi .
= −(rui − Su = −(rui − Su
∂E ∂Su ∂E ∂Qi
T Qi)Qi + λU Su
T Qi)Su + λI Qi
( 17 )
( 18 )
5.2 Pairwise PMF ( PPMF )
One potential issue with the previous approach using PMF is the indirection of going through ratings , instead of predicting ˆxuvi directly . The second approach is to instead fit another matrix X , of size |U×U|×|I| . Each row corresponds to a pair of users uv . Each column relates to an item i . Each element xuvi is the rating difference rui − rvi .
To approximate X , we associate each user pair with a rankK vector Suv , and each item with Qi . To generate ˆxuvi , we draw it from a Normal distribution , as in Equation 19 .
ˆxuvi ∼ N ( Suv
T Qi , γ2 )
( 19 )
We call this approach Pairwise PMF or PPMF . The plate diagram is shown in Figure 3(b ) , which clearly illustrates the difference from PMF . In PPMF , the observations ( shaded ) are xuvi ’s , instead of ratings . The objective function of PPMF is specified in Equation 20 . uv∈U×U ,u=v uv∈U×U ,u=v
E =
1 2
λU 2
IR(u , v , i)(xuvi − Suv
T Qi)2+ i∈I ||Suv||2 + i∈I
λI 2
||Qi||2
( 20 )
Figure 3 : Plate Diagrams : Matrix Factorization Models for Rating Difference Prediction
The estimation is done using gradient descent , with the following gradients .
∂E ∂Suv ∂E ∂Qi
= −(xuvi − Suv = −(xuvi − Suv
T Qi)Qi + λU Suv
T Qi)Suv + λI Qi
( 21 )
( 22 )
Once the parameters are learned , we then predict each
T Qi .
ˆxuvi as Suv 5.3 Differential PMF ( DPMF )
While PPMF estimates ˆxuvi directly , it suffers from two design issues . First , it blows up the number of parameters , as we now have to learn the Suv for every pair , instead of every user . Second , it assumes that the vectors Suv and Suv are independent , even as they share the same user u .
To address these deficiencies , we propose a new factorization model , which we call Differential Probabilistic Matrix Factorization or DPMF . The plate diagram is shown in Figure 3(c ) . In this approach , we will still associate each user u with a latent vector Su , and each item i with Qi . The key distinction is that we consider ratings to be latent , and fit the rating difference xuvi directly . In other words , ˆxuvi is a draw from the following Normal distribution ( Equation 23 ) .
ˆxuvi ∼ N ( Su
T Qi − Sv
T Qi , γ2 )
( 23 )
The objective function of DPMF in Equation 24 shows v Qi to the
T Qi − ST that we fit the prediction ˆxuvi = Su observation xuvi = rui − rvi .
E =
1 2 u∈U λU 2 u∈U
+ v∈U ,v=u i∈I ||Su||2 + i∈I
λI 2
IR(u , v , i)((rui − rvi ) − ( Su
T Qi − Sv
T Qi))2
||Qi||2
( 24 )
Estimation by gradient descent uses the gradients below .
∂E ∂Su ∂E ∂Sv ∂E ∂Qi
= −((rui − rvi ) − ( Su
T Qi − ST v Qi))Qi + λU Su
( 25 )
= ( (rui − rvi ) − ( Su
T Qi − ST
= −((rui − rvi ) − ( Su
T Qi − ST v Qi))Qi + λU Sv v Qi))(Su − Sv ) + λI Qi
( 26 )
( 27 )
6 . EXPERIMENTS
Our objective in the experiments are three fold . First , we investigate the learning of CAM . Second , we study the effectiveness of different methods in predicting rating differences . Third , we test the combined model against baselines on an evaluative rating prediction task . In addition , we include a case study to better illustrate the workings of CAM . Our focus here is on effectiveness , rather than on computational efficiency . We will briefly comment on the runtime of the learning algorithms in the appropriate sections . 6.1 Experimental Setup
Datasets . We conduct experiments on three real life , publicly available rating datasets , namely : Ciao1 , Epinions1 , and Flixster2 . Flixster contains ratings on movies . Ciao and Epinions both contain ratings on various categories such as books , electronics , movies , etc . We deliberately do not split the ratings by category to see if the model can contextualize the ratings per item basis without this information . Ratings are normalized into a 5 point scale . In all cases , only ratings ( and not other information ) are used in learning .
We pre process the raw data as follows . First , we retain only pairs of users who have co rated at least 20 items . This is to ensure that there is sufficient data to learn the model parameters reasonably accurately . For each co rated item , we derive xuvi from rui − rvi . In addition , since Flixster has timestamps , we decide to split the ratings into four annual subsets : 2006 2009 , and retain only user pairs who exist in all four subsets . This is to see if the results will be consistent across subsets of the data . The data sizes are shown in Table 2 . After pre processing , all the datasets are still sizeable , with thousands of users/items , and tens to hundreds of thousands rating differences .
Training vs . Testing . For each data set we create two types of training/testing data . For Sections 6.2 and 6.3 , we work with rating difference triplets xuvi ’s . We split the observed triplets X into two subsets : 80 % training set Xtrain and 20 % testing set Xtest . We average all the experimental results across 30 such folds ( created by random sampling ) . For Section 6.4 , we work with user item ratings rui ’s . To form the corresponding training set for ratings Rtrain for
1http://wwwpublicasuedu/~jtang20/datasetcode/ truststudy.htm 2http://wwwcsubcca/~jamalim/datasets/
SuQiruiu Ui I U I SuvQixuviuvU×Ui I U I SuQixuviv Ui I U I ruirviSvu U) ff'fi ) ffff'fi () ff'fi Dataset
Users
Original
Items
Ratings
10,980 127,771 147,612
112,832 331,642 48,794
301,534 1,185,975 8,196,077
Ciao Epinions Flixster Flixster06 Flixster07 Flixster08 Flixster09
Preprocessed
User pairs 3,312 10,997 1,682 1,682 1,682 1,682
Items
7,425 24,453 3,421 3,642 3,018 2,127
Rating Differences 91,277 369,998 307,044 106,312 65,210 44,863
Table 2 : Datasets
Figure 4 : Perplexity of CAM on Testing Set each Xtrain , we “ decompose ” each xuvi into the original rui and rvi . Similarly , Rtest is created from Xtest , but with an additional step of removing any rating that also exists in Rtrain . Since there are 30 samples for Xtrain and Xtest , correspondingly there are 30 samples for Rtrain and Rtest . 6.2 Contextual Agreement Model
N
Perplexity . First , we study the parameter learning for CAM . As mentioned in Section 4 , there is a set of parameters θuv , for every pair of users . One measure of effectiveness for a probabilistic model is perplexity , or the ability N of model parameters learned from training data ( Xtrain ) to fit the testing data ( Xtest ) . Perplexity is measured as m=1 log p(xm)} , where N is the number of triplets exp{− 1 in the held out testing data ( Xtest ) , and p(xm ) is the likelihood of observing the value of a triplet xm based on the parameter θ . If a model is well trained , the perplexity will be lower as it gets better at generalizing over the held out data . To investigate if this is the case , in Figure 4 , we plot these perplexity values ( averaged over 30 folds each ) . For each dataset , we measure the perplexity of learned model parameters after every iteration of the EM algorithm . The perplexity decreases quickly in the first few iterations , and then stabilizes . As the EM algorithm converges quickly in improving the fitness of the model parameters to the training data , it also improves the fit with the held out data .
Distribution of Agreement Prior . To get some sense of the learned parameters , we also inspect the distribution of parameter αuv ’s ( for different user pairs ) . This parameter is the prior probability of agreement P(yuvi = 1 ) for a pair of users u and v . We show the distribution as a series of white box plots in Figure 5 . It shows that in all six datasets , there are diverse types of users . Some user pairs tend to agree ( α → 1 ) while others tend to disagree ( α → 0 ) . Most users are somewhere in between . The median hovers around 06 In most datasets , the inter quartile range around the median is 0.3 to 04 This result supports our intuition that
Figure 5 : Distribution of P(yuvi = 1 ) or αuv user pairs do not agree all the time . Most will have some disagreements , and therefore it is important to contextualize their agreement on per item basis . Note that this , as well as the earlier conclusion , generally holds for all the annual subsets of Flixster datasets .
Friendship . Since the datasets also contain the social network links among users , we also test the frequently made hypothesis that friendship or trust relationship can help in learning the preferences of users [ 24 , 22 ] . In the same Figure 5 , we draw the distributions of αuv , narrowing down the population to only those user pairs sharing friendship or trustor trustee relationship . These are drawn as red box plots . One observation is that friendship does contain some information . The comparison of every pair of white ( all pairs ) vs . red ( friends only ) box plots , show that friends have greater agreement in general . This is especially evident in the Flixster datasets . However , another interesting observation is that even some friends disagree a lot , as shown by the lower whiskers of the box plots . Hence , just because a pair of users are friends , it does not mean they always agree . Therefore , it is helpful to know the context of agreement .
The EM learning algorithms are relatively efficient . For each fold , the parameters for all user pairs can be learned in 1 to 4 minutes on an Intel(R ) Xeon(R ) Processor E5 2667 2.90GHz machine . 6.3 Rating Difference Prediction
We study the efficacy of different matrix factorization methods outlined in Section 5 ( PMF , PPMF and DPMF ) in deriving good predictions for unseen triplets . PPMF and DPMF are trained on Xtrain , while PMF is trained on the corresponding Rtrain , all using the same parameter choices as in the original paper for PMF [ 29 ] ( learning rate = 0.005 , number of latent factors = 30 , regularization coefficient = 0002 ) All three are tested on the same Xtest .
For every triplet xuvi in the test set Xtest , we derive a prediction ˆxuvi using each method , and compare the accuracy of their predictions in terms of root mean squared error commonly used in matrix factorization . RM SEdif f is defined in Equation 28 . Lower value indicates better performance .
( ˆxuvi − xuvi)2
|Xtest|
( 28 )
RM SEdif f = xuvi∈Xtest
Vary Epochs . In Figure 6 , we plot the RM SEdif f at different epochs . One epoch corresponds to a full iteration
fifffffffflfi fiffff'fl)( ff fiff))fl '(fflflffifi '(fflflffifi '(fflflffifi '(fflflffififl ffff ff ff( ff) ff ff fiff ffi flfi ) (ff' rui∈Rtest
( ˆrui − rui)2
|Rtest|
( 29 )
Dataset
Number of latent factors K
Ciao Epinions Flixster06 Flixster07 Flixster08 Flixster09
10 0.87 0.77 0.78 0.65 0.62 0.58
20 0.43 0.45 0.55 0.47 0.42 0.35
30 0.36 0.35 0.41 0.40 0.35 0.30
40 0.36 0.34 0.33 0.38 0.34 0.29
50 0.35 0.33 0.29 0.37 0.33 0.28
100 0.34 0.32 0.23 0.35 0.32 0.28
Table 3 : DPMF : Vary Latent Factors ( RM SEdif f )
1 minute for each fold on the same Intel(R ) Xeon(R ) Processor E5 2667 2.90GHz machine . 6.4 Application : Collaborative Filtering
Here , we use the model parameters of CAM , combined with the rating difference predictions by DPMF to generate contextual agreement probabilities wuvi = P(yuvi = 1|ˆxuvi ) . These probabilities are used as similarity in neighborhoodbased collaborative filtering , as outlined in Section 3 . In the rating prediction task , for every rating rui ∈ Rtest , we predict ˆrui as a weighted average of neighbors’ ratings in Rtrain . The accuracy of rating prediction is measured by RM SErating defined in Equation 29 .
Figure 6 : PMF vs . PPMF vs . DPMF ( RM SEdif f )
RM SErating = over the whole training set . For all , the error goes down with the epochs , and eventually converges . DPMF performs the best in two respects . First , its converged error is the lowest of the three , followed by PMF , and PPMF ( worst ) . Second , it achieves convergence much faster ( by 30 epochs ) . Although by 100 epochs , PMF narrows down the error gap somewhat , it converges very slowly , requiring more epochs . We hypothesize that this is due to the differences in the objective functions . PMF tries to make its prediction as close to the observed rating as possible , without consideration on the level of difference between ratings . For example , suppose users u and v give ratings of 4 and 1 respectively to the same item in the test set . If the predicted ratings are 4.5 and 0.5 , these are close enough to the actual ratings ( 4 and 1 ) . However , in terms of the rating difference , it has widened from 4− 1 = 3 to 4.5− 0.5 = 4 . In contrast , DPMF tries to fit the rating difference directly , for instance by predicting 4.5 and 1.5 , which has the same error in terms of rating , but zero error in terms of rating difference .
We perform one tailed t test with 0.01 significance level on the RM SEdif f values of PMF and DPMF over different epochs . The result confirms that the outperformance by DPMF over PMF is statistically significant .
Vary Latent Factors . We conduct a separate experiment on DPMF on different numbers of latent factors K . The RM SEdif f at 100 epochs are shown in Table 3 . It shows that by around K = 30 , the errors have converged . There is no significant gain by running higher latent factors ( which will make the learning algorithms slower ) . Subsequently , we will use DPMF in conjunction with CAM with the same parameter settings ( K = 30 , 100 epochs ) .
The gradient descent learning algorithms are also efficient . For all three methods , the parameters can be learned within
Contextual vs . Shared . First , we compare the efficacy of item specific contextual agreement ( labeled CAMDPMF ) as compared to baselines relying on shared preference that applies to all items of the same user pair , as measured by Pearson and Cosine functions ( see Section 2 ) . The prediction accuracies in terms of RM SErating are listed in Table 4 . For each dataset , we indicate with an ‘∗’ the best method with the lowest error , which is significantly different from the second best ( using t test significance test at 0.01 significance level ) . For all of the datasets , CAMDPMF has the lowest errors . For Ciao , CAM DPMF has a lower error than Cosine or Pearson , but not statistically significant at p = 001 As all the comparative methods work with exactly the same set of ratings , the only difference is how each method weighs the contribution of each rating . This result shows that paying attention to context , as CAMDPMF does , helps to gain a lower prediction error .
Combination vs . Components . CAM DPMF uses a combination of CAM ’s model parameters and DPMF ’s predicted rating differences . To show that this joining of the two components is really necessary , it is instructive to see how each respective component performs on the same task . We therefore construct two more baselines based on each component respectively . The first , called CAM α , uses the αuv of each pair as a non contextual similarity value in Equation 5 . The second is the factorization model DPMF described in Section 5 . We also include PMF for completeness . We use the users’ and items’ parameters Su and Qi to predict unobserved ratings ˆrui . Table 5 shows a comparison between the combined approach CAM DPMF and the two components , CAM α and factorization models on the rating prediction task . In five out of six datasets , CAMDPMF has a lower error than both components . One exception is Flixster06 , where PMF performs slightly better . Interestingly , DPMF performs very badly on its own . This flfl fl* fl * fl fl *fl flfl 'fiffffiff) (flfi ff ff fiff flfl fl* fl * fl fl *fl flfl 'fiffffiff) (flfi ff ff fiff flfl fl* fl * fl fl *fl flfl 'fiffffiff) (flfi ff ff fiff ( ffi( ) 'ffiffi fffflffififl(cid:30) flfl fl* fl * fl fl *fl flfl 'fiffffiff) (flfi ff ff fiff flfl fl* fl * fl fl *fl flfl 'fiffffiff) (flfi ff ff fiff flfl fl* fl * fl fl *fl flfl 'fiffffiff) (flfi ff ff fiffff fffflffififl fi fffflffififl fl fffflffififl Dataset
CAM DPMF
Ciao
Epinions Flixster06 Flixster07 Flixster08 Flixster09
1.110∗ 1.141∗ 1.084∗ 1.011∗ 1.051∗ 1.087∗
Shared Preference Cosine Pearson 1.119∗ 1.118∗ 1.180 1.180 1.143 1.144 1.058 1.060 1.079 1.081 1.148 1.146
Table 4 : Versus Shared Preference ( statistically significant best performing entries are asterisked )
Dataset Ciao Epinions Flixster06 Flixster07 Flixster08 Flixster09
CAM DPMF CAM α DPMF PMF 1.110∗ 1.183 1.141∗ 1.194 1.046∗ 1.084 1.011∗ 1.073 1.051∗ 1.095 1.087∗ 1.152
1.129 1.198 1.150 1.073 1.095 1.152
4.181 4.075 3.446 3.532 3.617 3.595
Table 5 : Versus Model Components ( RM SErating ) is because it is optimized for predicting rating differences , and not ratings . The results emphasize the improvement of CAM DPMF over shared preference comes from the complementary combination of both components , and not from the sole contribution of either one . 6.5 Case Study
To illustrate the workings of CAM , we now show a case study drawn from the Epinions dataset , involving the same pair of users as in Section 1 . Table 6 shows the ratings of user u ( talyseon ) and v ( youngchinq ) on twenty movies .
Based on these ratings , the CAM parameters for this pair are as follows : α = 0.40 , µ0 = 2.9 , σ0 = 0.83 , σ1 = 081 The relatively low α suggests that this pair do not always agree . That µ0 = 2.9 suggests that when they disagree their rating difference is around 3 . This is evident from the fourth column labeled |xuvi| , which tracks their rating differences . The lower half of the table shows rating differences around 3 , suggesting that these are movies the pair disagree on .
CAM uses these parameters to estimate the contextual probability of agreement shown in the fifth column . As expected , the contextual probability of agreement is high ( close to 1 ) for the movies at the upper half of the table ( where rating differences are low ) , and is low ( close to 0 ) for the movies at the lower half . In contrast to the item specific agreement produced by CAM , the baselines Pearson and Cosine each assign a single similarity value that applies to all items , inadequately describing the nature of agreement between users . To see that such cases of varying rating differences are common , we employ the concept of entropy from information theory . For each pair , we count the frequencies of rating i=1 p(xi ) ln p(xi ) where p(xi ) is the normalized frequency of each rating difference value . If the entropy is high , the pair has rating differences that are varied , rather than uniform ( if entropy is low ) . For instance , the user pair in the case study above has an entropy of 23 Figure 7 plots a histogram of user pairs binned by their entropies . There is a significant proportion of the population with high entropies . In fact , the low entropies are the exception , rather than the norm . differences , and measure the entropy , ie ,
|xuvi| P(yuvi = 1| Pear Cosine son
0.53
0.88
Movie rui rvi
Paranormal Activity Payback Coraline Pan ’s Labyrinth Memento Gran Torino The Hurt Locker Jurassic Park III Twilight Inception Daredevil I Am Legend Rosemary ’s Baby The Day After Tomorrow 300 Moulin Rouge Seven Pounds The Dark Knight The Last Samurai Star Wars Episode III : Revenge of the Sith
5 3 5 5 5 5 5 3 3 5 3 4 5 4 4 5 4 5 5 5
5 3 5 5 4 4 4 2 1 3 1 2 2 1 1 2 1 1 1 1
0 0 0 0 1 1 1 1 2 2 2 2 3 3 3 3 3 4 4 4 xuvi ) 1.00 1.00 1.00 1.00 0.89 0.89 0.89 0.89 0.10 0.10 0.10 0.10 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00
Table 6 : Epinions Case Study
Figure 7 : Entropy of Rating Differences in Epinions
7 . CONCLUSION
We address the novel problem of estimating the contextual agreement between two users in the context of one item , by probabilistic modeling with two major components . The first , called CAM , models contextual agreement in generative form , as a mixture of Gaussians . To ensure monotonic behavior of the agreement probability , we propose a specific constraint , and describe how the constrained parameters can be learned through EM . To extend the use of CAM to unseen triplets , the second component predicts rating differences between two users on the same item . We outline three different matrix factorization approaches , including a proposed model called DPMF with a novel objective function . The models are shown to be effective through experiments on real life rating datasets . As future work , we plan to investigate how the two components of our model can be joined more tightly together , such that the learning for one can help reinforce the other . In addition , just as we could apply CAM DPMF in similarity based collaborative filtering , it may be feasible to apply it in matrix factorization for rating prediction as well , which requires further investigation .
8 . ACKNOWLEDGMENTS
This research is supported by the Singapore National Research Foundation under its International Research Centre @ Singapore Funding Initiative and administered by the IDM Programme Office , Media Development Authority ( MDA ) . ffffi ffffi ffffi (ffffi )ffffi ffl ) ff ff fiffiffff) fi( 'fflffi fiffffiffl ffffififl 9 . REFERENCES
[ 1 ] G . Adomavicius and A . Tuzhilin . Toward the next generation of recommender systems : A survey of the state of the art and possible extensions . TKDE , 17(6 ) , 2005 .
[ 2 ] A . Ahmed , B . Kanagal , S . Pandey , V . Josifovski , L . G .
Pueyo , and J . Yuan . Latent factor models with additive and hierarchically smoothed user preferences . In WSDM , 2013 .
[ 3 ] C . M . Bishop and N . M . Nasrabadi . Pattern
Recognition and Machine Learning . Springer , 2006 .
[ 4 ] S . P . Boyd and L . Vandenberghe . Convex optimization . Cambridge University Press , 2004 .
[ 5 ] J . S . Breese , D . Heckerman , and C . Kadie . Empirical analysis of predictive algorithms for collaborative filtering . In UAI , 1998 .
[ 6 ] H . Fang , Y . Baoy , and J . Zhang . Misleading opinions provided by advisors : Dishonesty or subjectivity . In IJCAI , 2013 .
[ 7 ] T . J . Hastie , R . J . Tibshirani , and J . H . Friedman . The Elements of Statistical Learning : Data Mining , Inference , and Prediction . Springer , 2011 .
[ 8 ] T . Hofmann . Collaborative filtering via gaussian probabilistic latent semantic analysis . In SIGIR , 2003 . [ 9 ] T . Hofmann . Latent semantic models for collaborative filtering . TOIS , 22(1 ) , 2004 .
[ 10 ] L . Hu , J . Cao , G . Xu , L . Cao , Z . Gu , and C . Zhu .
Personalized recommendation via cross domain triadic factorization . In WWW , 2013 .
[ 11 ] D . Jannach , M . Zanker , A . Felfernig , and G . Friedrich .
Recommender Systems : An Introduction . Cambridge University Press , 2010 .
[ 12 ] R . Jin , J . Y . Chai , and L . Si . An automatic weighting scheme for collaborative filtering . In SIGIR , 2004 . [ 13 ] B . Kanagal , A . Ahmed , S . Pandey , V . Josifovski ,
J . Yuan , and L . Garcia Pueyo . Supercharging recommender systems using taxonomies for learning user purchase behavior . PVLDB , 5(10 ) , 2012 .
[ 14 ] N . Koenigstein , G . Dror , and Y . Koren . Yahoo! music recommendations : modeling music ratings with temporal dynamics and item taxonomy . In RecSys , 2011 .
[ 15 ] Y . Koren , R . Bell , and C . Volinsky . Matrix factorization techniques for recommender systems . Computer , 42(8 ) , 2009 .
[ 16 ] Y . Koren and J . Sill . OrdRec : An ordinal model for predicting personalized item rating distributions . In RecSys , 2011 .
[ 17 ] N . D . Lawrence and R . Urtasun . Non linear matrix factorization with gaussian processes . In ICML , 2009 .
[ 18 ] D . D . Lee and H . S . Seung . Learning the parts of objects by non negative matrix factorization . Nature , 401(6755 ) , 1999 .
[ 19 ] G . Linden , B . Smith , and J . York . Amazon.com recommendations : Item to item collaborative filtering . IEEE Internet Computing , 7(1 ) , 2003 .
[ 20 ] X . Liu and K . Aberer . SoCo : a social network aided context aware recommender system . In WWW , 2013 .
[ 21 ] P . Lops , M . de Gemmis , and G . Semeraro .
Content based recommender systems : State of the art and trends . In Recommender Systems Handbook , pages 73–105 . Springer , 2011 .
[ 22 ] H . Ma , I . King , and M . R . Lyu . Learning to recommend with social trust ensemble . In SIGIR , 2009 .
[ 23 ] H . Ma , H . Yang , M . R . Lyu , and I . King . SoRec : Social recommendation using probabilistic matrix factorization . In CIKM , 2008 .
[ 24 ] H . Ma , D . Zhou , C . Liu , M . R . Lyu , and I . King .
Recommender systems with social regularization . In WSDM , 2011 .
[ 25 ] L . W . Mackey , D . Weiss , and M . I . Jordan . Mixed membership matrix factorization . In ICML , 2010 .
[ 26 ] L . B . Marinho , A . Nanopoulos , L . Schmidt Thieme ,
R . J¨aschke , A . Hotho , G . Stumme , and P . Symeonidis . Social tagging recommender systems . In Recommender Systems Handbook , pages 615–644 . Springer , 2011 .
[ 27 ] A . K . Menon , K P Chitrapura , S . Garg , D . Agarwal , and N . Kota . Response prediction using collaborative filtering with hierarchies and side information . In KDD , 2011 .
[ 28 ] R . Missaoui , P . Valtchev , C . Djeraba , and M . Adda . Toward recommendation based on ontology powered web usage mining . IEEE Internet Computing , 11(4 ) , 2007 .
[ 29 ] A . Mnih and R . Salakhutdinov . Probabilistic matrix factorization . In NIPS , 2007 .
[ 30 ] W . Pan and L . Chen . GBPR : Group preference based bayesian personalized ranking for one class collaborative filtering . In IJCAI , 2013 .
[ 31 ] M . J . Pazzani and D . Billsus . Content based recommendation systems . In The Adaptive Web , pages 325–341 . Springer , 2007 .
[ 32 ] S . Rendle , C . Freudenthaler , Z . Gantner , and
L . Schmidt Thieme . BPR : Bayesian personalized ranking from implicit feedback . In UAI , 2009 .
[ 33 ] P . Resnick , N . Iacovou , M . Suchak , P . Bergstrom , and
J . Riedl . GroupLens : an open architecture for collaborative filtering of netnews . In CSCW , 1994 .
[ 34 ] R . Salakhutdinov and A . Mnih . Bayesian probabilistic matrix factorization using markov chain monte carlo . In ICML , 2008 .
[ 35 ] B . Sarwar , G . Karypis , J . Konstan , and J . Riedl .
Item based collaborative filtering recommendation algorithms . In WWW , 2001 .
[ 36 ] H . Shan , J . Kattge , P . B . Reich , A . Banerjee ,
F . Schrodt , and M . Reichstein . Gap filling in the plant kingdom trait prediction using hierarchical probabilistic matrix factorization . In ICML , 2012 .
[ 37 ] Y . Shen and R . Jin . Learning personal + social latent factor model for social recommendation . In KDD , 2012 .
[ 38 ] A . P . Singh and G . J . Gordon . Relational learning via collective matrix factorization . In KDD , 2008 .
[ 39 ] N . Srebro , J . Rennie , and T . S . Jaakkola .
Maximum margin matrix factorization . In NIPS , 2004 .
[ 40 ] J . Wang , Y . Zhang , C . Posse , and A . Bhasin . Is it time for a career switch ? In WWW , 2013 .
[ 41 ] E . Zhong , W . Fan , and Q . Yang . Contextual collaborative filtering via hierarchical matrix factorization . In SDM , 2012 .
