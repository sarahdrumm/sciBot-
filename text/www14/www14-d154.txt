Formalisation and Experiences of R2RML based SPARQL to SQL query translation using Morph
Freddy Priyatna
Oscar Corcho
Ontology Engineering Group Facultad de Informática , UPM
Ontology Engineering Group Facultad de Informática , UPM
Madrid , Spain fpriyatna@fiupmes
Madrid , Spain ocorcho@fiupmes
Juan Sequeda
Dept . of Computer Science University of Texas at Austin jsequeda@csutexasedu
Austin , USA
ABSTRACT R2RML is used to specify transformations of data available in relational databases into materialised or virtual RDF datasets . SPARQL queries evaluated against virtual datasets are translated into SQL queries according to the R2RML mappings , so that they can be evaluated over the underlying relational database engines . In this paper we describe an extension of a well known algorithm for SPARQL to SQL translation , originally formalised for RDBMS backed triple stores , that takes into account R2RML mappings . We present the result of our implementation using queries from a synthetic benchmark and from three real use cases , and show that SPARQL queries can be in general evaluated as fast as the SQL queries that would have been generated by SQL experts if no R2RML mappings had been used .
1 .
INTRODUCTION
Making relational database content available as RDF has played a fundamental role in the emergence of the Web of Data . Several approaches have been proposed in this direction since the early 2000s , focusing on the creation of mapping languages , models and supporting technology to enable such transformations ( eg , R2O [ 2 ] , D2R [ 3 ] , Triplify [ 1] ) . In September 2012 , the W3C RDB2RDF Working Group released the R2RML W3C Recommendation [ 9 ] , a language to specify transformations of data stored in relational databases into materialised or virtual RDF datasets , so that relational databases can be queried using SPARQL , and several R2RMLaware implementations have been reported [ 19 ] .
The R2RML specification does not provide any formalisation of the SPARQL to SQL query translation process that needs to be followed by R2RML aware query translators , and the aforementioned implementations do not describe the formalizations of their query translation algorithms . In any case , some attemps have been done in the past to provide such a formalisation . For instance , Garrote and colleagues [ 11 ] provide a draft of the transformation of SPARQL SELECT queries to SQL based on the query
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author ’s site if the Material is used in electronic media . WWW’14 , April 7–11 , 2014 , Seoul , Korea . ACM 978 1 4503 2744 2/14/04 . http://dxdoiorg/101145/25664862567981 translation algorithm defined in [ 7 ] . As their focus is to provide an R2RML based RESTful writable API , the query translation algorithm that they describe is limited . For example , projections and conditions for those queries are built only for variable components of the triple pattern . However , a triple pattern may involve URIs and constants in their components , and these have to be taken into account when translating SPARQL queries . Rodr´ıguez Muro and colleagues have recently presented Quest/Ontop [ 15 ] , which translates R2RML mappings and SPARQL queries into a set of Datalog rules , where optimizations based on query containment and Semantic Query Optimisation are applied , before transforming them into SQL queries . However , the process of how R2RML mappings are translated into Datalog rules has not been described at the moment of writing . Unbehauen and colleagues [ 18 ] define the process of binding triple patterns to the mappings and the process of generating column groups ( a set of columns ) for every RDF term involved in the graph pattern . Using the calculated bindings and column groups , they define how to translate each of the SPARQL operators ( AND , OPTIONAL , FILTER , and UNION ) into SQL queries . However , the function joinCond(s1,s2 ) , in which two patterns are joined , is not clearly defined . In fact , one fundamental aspect that distinguishes SPARQL queries from SQL queries is the semantics of the joins , as discussed in [ 8 , 7 ] , which corresponds to the treatment of NULL values in the join conditions . None of the aforementioned systems explain how to deal with RefObjectMap mappings , where a triples map is joined with another triples map ( parent triples map ) , and consequently the generated SQL query has to take into account the logical source of the parent triples map and join condition specified in the mapping .
Furthermore , the performance of virtual RDF datasets based on RDB2RDF mapping languages has not always been satisfactory , as reported by Gray et . al . [ 12 ] . This experience has also been confirmed empirically by us in projects like R´epener [ 17 ] , BizkaiSense1 , or Integrate2 , for which we have had access to the data sources and mappings in languages like D2R . In all cases , some of the SQL queries produced by the translation algorithm could not be evaluated ( eg , too many joins are involved ) or their evaluation takes too much time to complete , what makes their use in a virtual RDF dataset context unfeasible . The main reason for this is that the resulting queries are not sufficiently optimised to be efficiently evaluated over the underlying database engines .
1http://wwwtecnologicodeustoes/projects/bizkaisense/ 2http://wwwfp7 integrateeu
479 In the context of RDF data management , some works [ 7 , 10 ] have focused on using relational databases as the backend for triple stores , with the idea of exploiting the performance provided by relational database systems . They normally work with schema oblivious layouts ( using a triple table layout containing columns corresponding to the triple elements ) or vertical partitioned layouts ( using different tables to store triples corresponding to the same predicate ) . They provide translation algorithms from SPARQL to SQL using the aforementioned layouts specifically designed to store triple instances . This is out of the scope of our work .
While R2RML specifies custom mappings defined by users , it comes with a companion standard called Direct Mapping [ 14 ] , which defines the RDF representation of data in a relational database . The generated RDF instances will have their classes and properties reflecting the structure and contents of the relational database . Using Direct Mappings , Sequeda and colleagues [ 16 ] define the process of translating SPARQL into SQL efficiently , by removing self joins and unnecessary conditions .
The contribution of our paper is threefold : first , we extend an existing SPARQL to SQL query rewriting algorithm [ 7 ] , originally proposed for RDBMS backed triple stores , by considering R2RML mappings . This implies allowing the algorithm to work with arbitrary layouts , such as the ones normally used in legacy systems . This work is complementary to [ 11 ] and provides an alternative to the one presented in [ 18 ] and [ 15 ] . Second , we implement and evaluate several versions of our algorithm ( with different types of optimisations ) , using queries from the BSBM benchmark [ 4 ] , a widely used synthetic benchmark for RDB2RDF systems , and show that the evaluation of such rewritten SPARQL queries is generally as fast as the corresponding native SQL queries specified in the benchmark . Third , we report our experience with queries from real projects , which show performance issues when using state of the art RDB2RDF systems , and use our implementation to produce a better translation that allows them to be evaluated in an appropiate time .
The paper is structured as follows . In the following section , we review the R2RML language and Chebotko ’s approach to SPARQL to SQL query rewriting and data translation . In Section 3 we formalise our extension to consider R2RML mappings . In Section 4 we describe our evaluation using the BSBM synthetic benchmark , and three positive experiences of applying our approach in real case projects . Finally , we present our conclusions and future work in Section 5 .
2 . BACKGROUND : R2RML AND
CHEBOTKO’S QUERY TRANSLATION
2.1 R2RML
As discussed in the introduction , R2RML [ 9 ] is a W3C Recommendation that allows expressing customized mappings from relational databases to RDF . An R2RML mapping document M , as shown in Figure 1 , consists of a set of rr:TriplesMap3 classes . The rr:TriplesMap class consists of three properties ; rr:logicalTable , rr:subjectMap , and rr:predicateObjectMap .
3From now on , we use prefix rr to denote R2RML namespace http://wwww3org/ns/r2rml
• rr:logicalTable specifies the logical table to be mapped , whether it is a SQL table , a SQL view , or an R2RML view .
• rr:subjectMap specifies the target class and the URI generation form .
• rr:predicateObjectMap specifies the target property and the generation of the object via rr:objectMap , whose value can be obtained by constant ( rr:constant ) , column ( rr:column ) or template ( rr:template ) . Linking with another table is accomodated by the use of rr:refObjectMap , which specifies the parent triples map and the join conditions .
Figure 1 : An overview of R2RML , based on [ 9 ]
Appendix 6 gives an example of a mapping document that maps Product and Offer tables to ex:Product and ex:Offer respectively , which we will use throughout this paper to illustrate our definitions and algorithms . 2.2 Chebotko and colleagues ’s approach
Our approach is based on the formalisation and algorithm from Chebotko and colleagues [ 7 ] . Other RDB2RDF query translation approaches lack a clear formalisation of the approach ( eg , [ 2 ] , [ 3 ] ) or they are not focused on RDF generation and/or SPARQL querying ( eg , [ 6] ) .
Chebotko ’s approach proposes the use of a set of mappings ( α and β ) and functions ( genCondSQL , genP RSQL , and name ) to translate SPARQL into SQL . Its formal definition is available at [ 7 ] . We now give an example of how those mappings and functions work in the absence of R2RML mappings . In Section 3 we provide the formal definition of these mappings and functions with R2RML mappings .
Example 1 . Without R2RML Mappings . Consider a triple table Triples(s , p , o ) that uses its columns to store the subject , predicate , and object of RDF triples . A user poses a SPARQL query with the triple pattern tp1 = :Product1 rdfs:label ?plabel .
• Mapping α returns the table that holds the triples that correspond to this triple pattern tp1 . That is , α(tp1 ) = Triples .
• Mapping β returns the column that corresponds to each triple pattern position ( sub , pre or obj ) . That is , β(tp1 , sub ) = s , β(tp1 , pre ) = p , and β(tp1 , obj ) = o .
480 • Function genCondSQL filters the table Triples returned by α(tp1 ) so that only those records that match the triple pattern tp are returned . genCondSQL(tp1 , β ) = {s = :Product1 AND p = rdfs:label} .
• Function name generates alias for each triple pattern element . That is , name(ex:Product1 ) = iri_Product1 , name(rdfs:label ) = iri_rdfs_label , and name(plabel ) = var_plabel .
• Function genP RSQL projects the β column as the value returned by function name for each triple pattern position . That is , genP RSQL(tp1 , β , name ) = { s AS iri_Product1 , p AS iri_rdfs_label , o AS var_plabel} .
• Function trans(tp1 , α , β ) finally returns the SQL query using the values returned by the previous mappings and functions . That is , trans(tp1 , α , β ) = SELECT s AS iri_Product1 , p AS iri_rdfs_label , o AS var_plabel FROM TRIPLES WHERE s = :Product1 AND p = rdfs:label.4
3 . AN R2RML BASED EXTENSION OF
CHEBOTKO’S APPROACH
We have seen from the previous example how the algorithm defined in [ 7 ] is used to translate SPARQL queries into SQL queries for RDBMS backed triples stores . As mentioned in the Introduction section , this approach has to be extended so that all the functions and mappings used in the algorithm take into account user defined R2RML mappings . Before we present the detail of how to extend the algorithm , we give an illustrative example that is comparable to the previous example . 3.1 Illustrative Example
Example 2 . With R2RML Mappings . Consider a table Product(nr , label ) that is mapped into an ontology concept bsbm:Product . The column nr is mapped as part of the URI of the bsbm:Product instances and column label is mapped to the property rdfs:label . The same triple pattern tp1 = :Product1 rdfs:label ?plabel in the previous example produces the following mappings/functions :
• Mapping α returns the table that holds the triples that correspond to this triple pattern tp1 . α(tp1 ) = Product .
• Mapping β returns the column/constant that corresponds to each triple pattern position ( sub , pre or obj ) . β(tp1 , sub ) = nr , β(tp1 , pre ) = ‘rdfs:label’ , and β(tp1 , obj ) = label .
• Function genCondSQL filters the table Product returned by α(tp1 ) so that only the records that match the triple pattern tp1 are returned . That is , genCondSQL(tp1 , β ) = {nr = 1 AND label IS NOT NULL} .
• Function name generates alias for the triple pattern element . In this case , name(:Product1 ) = iri_Product1 , name(rdf s : label ) = iri_rdfs_label , and name(plabel ) = var_plabel .
4For the sake of simplicity , we omit the aliases that have to be prefixed on each column name .
• Function genP RSQL projects the β column as the alias name of each triple pattern element . That is , genP RSQL(tp1 , β , name ) = {nr AS iri_Product1 , ‘rdfs:label’ AS iri_rdfs_label , label AS var_plabel} .
• Function trans(tp1 ) finally returns the SQL query using the values returned by the previous mappings and functions . That is , trans(tp1 , α , β ) = SELECT nr AS iri_Product1 , ‘rdfs:label’ AS iri_rdfs_label , label AS var_plabel FROM Product WHERE nr = 1 AND label IS NOT NULL .
Figure 2 illustrates our two examples on using the Chebotko ’s algorithm in the context of triple stores and R2RML based query translation .
Next , describe how we extend the translation function of a triple pattern in Chebotko ’s approach taking into account R2RML mappings . We then go into more detail explaining the mappings/functions used in the translation algorithm5 . 3.2 Function trans under M
Definition 1 . Given the set of all possible triple patterns T P = ( IV ) × ( I ) × ( IV L ) and tp ∈ T P , mappings α and β , functions name , genCondSQL , and genP RSQL , trans(tp ) generates a SQL query that can be executed by the underlying RDBMS to return the answer for gp .
Listing 1 : trans(tp ) under M transm ( T P , α , β , name , Queries ) :− getT riplesM aps(T P , M , T M List ) , transT M List(T P , α , β , name , T M List , Queries ) . transT M List(T P , α , β , name , [ ] , [ ] ) . transT M List(T P , α , β , name , [ T M|T M ListT ail ] , Queries ) :− transT M ( T P , α , β , name , T M , QHead ) , transT M List(T P , α , β , name , T M ListT ail , QT ail ) , createU nionQuery(QHead , QT ail , Queries ) . transT M ( T P , α , β , name , T M , Queries ) :− getGroundedP redicates(T P , T M , P reU RIList ) , transP reU RIList(T P , α , β , name , T M , P reU RIList , Queries ) . transP reU RIList(T P , α , β , name , T M , [ ] , [ ] ) . transP reU RIList(T P , α , β , name , T M , P reU RIList , Queries ) :−
P reU RIList = [ P reU RIsHead | P reU RIsT ail ] , trans(T P , α , β , name , T M , P reU RIsHead , QHead ) , transP reU RIList(T P , α , β , name , T M , P reU RIsT ail , QT ail ) , createU nionQuery(QHead , QT ail , Queries ) . trans(T P , α , β , name , T M , P reU RI , Query ) :− genP RSQL(T P , α , β , name , T M , P reU RI , SelectP art ) , α(T P , T M , P reU RI , F romP art ) , genCondSQL(T P , α , β , T M , P reU RI , W hereP art ) , buildQuery(SelectP art , F romP art , W hereP art , Query ) .
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26
The algorithm ( see Listing 16 ) for translating a triple pattern T P = ( IV )×(IV )×(IV L)7 can be explained as follows : • A triple pattern can be mapped to several triples maps in the mapping document , thus all results from the possible mappings will be put in a single UNION query ( line 1 7 ) .
5While the order of presenting the mappings/functions is not important , we start by explaining trans(tp ) , so as to facilitate understanding . 6We use Prolog syntax to present our listings 7For compactness , we write IRI as I , Variable as V , Literal as L , and combinations of those letters .
481 pings ( α , β ) and functions ( genCondSQL , genP RSQL ) ( line 22 26 ) . Those mappings and functions are explained in the following subsections .
The translation function trans for other patterns ( AND , OPTIONAL , UNION , FILTER ) follows the algorithm described in [ 7 ] . 3.3 Mapping α under M
Definition 2 . Given the set of all possible triple patterns T P = ( IV )× ( I)× ( IV L ) , a set of relations REL , and a set of all possible mappings M defined in R2RML , a mapping α is a many to many mapping α : T P × M → REL , where given a triple pattern tp ∈ T P and a mapping m ∈ M , αm(tp ) returns a set of relations that generate all the triples that match tp.8
( a ) Chebotko ’s in RDBMS backed Triple Store
1 2 3
4 5 6 7
8 9 10
11 12
13
( b ) Chebotko ’s in R2RML based Query Translation
Figure 2 : Chebotko ’s algorithm in Database backed Triples Store and R2RML based Query Translation
• The same process occurs if the predicate part of the triple map is unbounded . Then the variable of the predicate part will be grounded according to available mappings , and results will be merged as a UNION query ( line 11 20 ) .
• In the case where the triples map is defined and the predicate of the triple pattern is bounded , trans(tp ) builds a SQL query using the result of auxiliary map
Listing 2 : α under M αm ( T P , T M , P reU RI , [ AlphaSub , AlphaP reObj ] ) :−
αm αm sub ( T M , AlphaSub ) , preobj ( T P , T M , P reU RI , AlphaP reObj ) .
αm sub ( T M , T M.logicalT able ) . preobj ( T P , T M , P reU RI , AlphaP reObj ) :− αm getP redicateObjectM ap(T M , P reU RI , P OM ap ) , ROM ap = P OM ap.ref ObjectM ap , αm preobj ( T M , P reU RI , [ ROM ap ] , AlphaP reObj ) .
αm αm preobj ( T M , P reU RI , [ ] , [ ] ) . preobj ( T M , P reU RI , [ ROM ap ] , ROM ap.parentT riplesM ap.logicalT able ) .
The algorithm for computing mapping α under a set of R2RML mappings is provided in Listing 2 . The output of this algorithm is used as the FROM part of the generated SQL query . This algorithm is divided into two main parts ; calculating α for the subject ( αm sub(T M ) ) ( line 5 ) , and for the predicate object part αm preobj(P OM ap ) ( line 7 13 ) .
• The function αm sub(T M ) returns the logical table prop erty logicalT able of a triples map T M ( line 5 ) .
• A logical table from a triple may be joined with another logical table through the refObjectMap property . This case is handled by an auxiliary function αm property P OM ap of T M that corresponds to the predicate of the triple pattern tp , and then returns the parent logical table of refObjectMap property ROM ap ( line 7 13 ) . preobj(P OM ap ) that retrieves the predicateObjectMap
The output of mapping α is a set of logical tables with the result from the two auxiliary functions ( line 1 3 ) . Table 1 presents some examples of mapping α results . 3.4 Mapping β under M
Definition 3 . Given a set of all possible triple patterns T P = ( IV )×(I)×(IV L ) , a set of positions in a triple pattern P OS = {sub , pre , obj} , a set of relational attributes AT T R , and a set of all possible R2RML mappings M , a mapping β is a many to one mapping βm : T P ×P OS×M → AT T R , if 8If the set REL contains more than one relation , the join conditions are specified in the genCondSQL( ) function , described in Section 3.5
482 given a triple pattern tp ∈ T P , a position pos ∈ P OS , and m ∈ M , AT T R is a relational attribute whose value may match the triple pattern tp at position pos .
The algorithm for computing the mapping β under M is provided in Listing 3 and some examples of β results can be seen on Table 1 . The output of mapping β is used in the functions genP RSQL and genCondSQL to select the relational attribute corresponding to the triple pattern position : • If the position pos is subject , then the auxiliary function βm sub returns the corresponding relational attributes attached to the subject map SM of T riplesM ap ( line 1 2 , 8 9 ) .
• If the position pos is predicate , then URI of tp.predicate is returned as a constant . ( line 3 4 , 11 ) .
• If the position pos is object , then the function βm obj ( line 13 16 ) checks whether the argument P OM ap contains a Reference Object Map ROM ap .
– If P OM ap contains ROM ap , the parent triple map P arentT riplesM ap of ROM ap is retrieved and the relational attributes corresponding to the subject map of P arentT riplesM ap are returned ( line 20 21 ) .
– Otherwise , the corresponding relational attributes of object map objectM ap are returned ( line 1819 ) .
1 2 3
4 5 6 7 8 9 10 11 12 13 14
15 16 17 18 19
20 21
22
23 24
25 26 27 28
29
30 31 32
33 34 35 36
37 38 39 40 41
1 2 3 4 5 6
7 8 9 10 11 12 13
14 15 16
17 18
19 20
21
Listing 3 : β under M
βm ( T P , pos.sub , T M , P redicateU RI , α , BetaResult ) :− βm ( tp , pos.pre , tm , predicateU RI , α , BetaResult ) :− sub ( T M , α , BetaResult ) .
βm
βm pre(P redicateU RI , BetaResult ) .
βm ( tp , pos.obj , tm , predicateU RI , α , BetaResult ) :− obj ( T M , P redicateU RI , α , BetaResult ) .
βm sub ( T M , α , BetaResult ) :− βm databaseColumn(T M.subjectM ap , BetaResult ) .
βm pre(P redicateU RI , P redicateU RI ) . obj ( T M , P redicateU RI , α , BetaResult ) :− βm obj ( T M , P redicateU RI , α , P OM ap , [ ROM ap ] , BetaResult ) . getP redicateObjectM ap(T M , P redicateU RI , P OM ap ) , ROM ap = P OM ap.ref ObjectM ap , βm obj ( T M , P redicateU RI , α , P OM ap , [ ] , BetaResult ) :− βm obj ( T M , P redicateU RI , α , P OM ap , [ ROM ap ] , BetaResult ) :− βm databaseColumn(P OM ap.objectM ap , BetaResult ) . databaseColumn(ROM ap.parentT riplesM ap.subjectM ap , BetaResult ) .
3.5 Function genCondSQL under M
Definition 4 . Given a set of all possible triple patterns T P , a mapping β , and a set of all possible mappings M defined in R2RML mapping document , genCondSQL generates a SQL expression that is evaluated to true if and only if tp matches a tuple represented by relational attributes βm(tp , sub ) , βm(tp , pre ) , and βm(tp , obj ) where tp ∈ T P and m ∈ M .
The algorithm of function genCondSQL under M is provided in Listing 4 . The output of this function is used as the WHERE part of the generated SQL query . This function calls and returns the result of two auxiliary functions : genCondSQLm sub and genCondSQLm preobj .
Listing 4 : genCondSQL under M genCondSQLm ( T P , α , β , T M , P reU RI , CondSub ) :− genCondSQLm genCondSQLm Conds = [ CondSub , CondP reObj ] . sub ( T P , α , β , T M , CondSub ) , preobj ( T P , α , β , T M , P reU RI , CondP reObj ) , genCondSQLm sub ( T P , α , β , T M , CondSub ) :− type(T P.subject , IRI ) , SM = T M.subjectM ap , inverseExpr(T P.subject , SubjectId ) , βm genSQLExpr(equals , SubjectId , BetaSub , CondSub ) . sub ( SM , α , BetaSub ) , genCondSQLm genCondSQLm sub ( T P , α , β , T M , [ ] ) :− type(T P.subject , T ype ) , T ype = IRI . preobj ( T P , α , β , T M , P reU RI , Cond ) :− getP redicateObjectM ap(T M , preU RI , P OM ap ) , OM ap = P OM ap.objectM ap , ROM ap = P OM ap.ref ObjectM ap , ObjT ype = type(T P.object ) , genCondSQLm preobj ( T P , α , β , T M , P reU RI , ObjT ype , ROM ap , Cond ) . genCondSQLm preobj ( T P , α , β , T M , P reU RI , var , [ ] , CondP reObj ) :− obj ( tp , preU RI , α , BetaObj ) ,
βm genSQLExpr(isN otN ull , BetaObj , CondP reObj ) . genCondSQLm preobj ( T P , α , β , T M , P reU RI , var , ROM ap , EqCond ) :− joinElements = ROM apjoinCondchild , ROM apjoinCondparent , genSQLExpr(equals , joinElements , EqCond ) . genCondSQLm preobj ( T P , α , β , T M , P reU RI , literal , , CondP reObj ) :− obj ( T P , P reU RI , α , BetaObj ) ,
βm genSQLExpr(equals , T P.object , BetaObj , CondP reObj ) . genCondSQLm preobj ( T P , α , β , T M , P reU RI , iri , [ ] , CondP reObj ) :− sub ( ROM ap , α , BetaObj ) ,
βm inverseExpr(T P.object , ObjId ) , genSQLExpr(equals , ObjId , BetaObj , CondP reObj ) . genCondSQLm preobj ( T P , α , β , T M , P reU RI , iri , ROM ap , CondP reObj ) :− inverseExpr(T P.object , ObjId ) , joinElements = ROM apjoinCondchild , ROM apjoinCondparent , genSQLExpr(equals , joinElements , EqCond ) , βm genSQLExpr(and , EqCond , BetaSub , condP reObj ) . sub ( ROM ap , α , BetaSub ) ,
The function genCondSQLm sub checks the term type of tpsubject If tp.subject is an IRI ( line 6 11 ) , then the identifier of this subject is obtained by a function inverseExpression , a function that takes an IRI and returns only the corresponding values that can be related to database values . For example , inverseExpression will return 1 or 3847 for IRIs :Product1 or :Offer3847 , respectively . genCondSQLm sub returns nothing if the subject is not an IRI ( line 12 ) .
The auxiliary function genCondSQLm preobj(tp , P OM ap ) checks the term type of tpobject
• If tp.object is a variable , two cases are evaluated .
– In the case that P redicateObjectM ap doesn’t have any Reference Object Map , then the SQL expression stating that the β of P redicateObjectM ap IS NOT NULL is returned ( line 21 23 ) . This is to guarantee that we do not return NULL values . Only in case that the value is used in some filter expressions ( eg FILTER(!bound(?label ) ) that we must remove the IS NOT NULL expression so that genCondSQL returns NULL , what will be interpreted as unbounded values .
– If Ref ObjectM ap of P redicateObjectM ap is spec ified , then a SQL expression that is the JoinCondition property from Ref ObjectM ap is returned ( line 24 26 ) .
• If tp.object is a literal , then a SQL equality expression of tp.object and the output of β for P redicateObjectM ap is returned ( line 28 30 ) .
483 • If tp.object is an IRI , then OBJID as the identifier of tp.object is evaluated using the inverse expression . Then two cases are evaluated .
– If no Reference Object Map is specified , the function returns an SQL equality expression of OBJID and βm obj mapping of P OM ap ( line 32 35 ) .
– If an instance of Reference Object Map is specified , then the function returns 1)JoinCondition and 2)an SQL equality expression between OBJID and the βm sub(ROM ap ) mapping of ROM ap ( line 36 41 ) .
Table 1 illustrates the result of calculating genCondSQL for our example . 3.6 Function genP RSQL under M
Definition 5 . Given a set of all possible triple pattern T P and tp ∈ T P , a mapping β , a function name , and a set of all possible mappings M defined in R2RML and m ∈ M , genP RSQL generates SQL expression which projects only those relational attributes that correspond to distinct tp.subject , tp.predicate , tp.object and renames the projected attributes as βm(tp , sub ) → name(tp.subject ) , βm(tp , pre ) → name(tp.predicate ) , and βm(tp , obj ) → name(tpobject )
Listing 5 : genP RSQL under M genP RSQLm ( T P , α , β , name , T M , P reU RI , Result ) :− sub ( T P , α , β , name , T M , P reU RI , RSub ) , pre(T P , α , β , name , T M , P reU RI , RP re ) , obj ( T P , α , β , name , T M , P reU RI , RObj ) , genP RSQLm genP RSQLm genP RSQLm Result = [ RSub , RP re , RObj ] . genP RSQLm sub ( T P , α , β , name , T M , P RSQLSub ) :− sub ( T M , α , BetaSub ) , name(T P.subject , SubjectAlias ) ,
βm generateSQLExpression(as , BetaSub , SubjectAlias , P RSQLSub ) . genP RSQLm genP RSQLm pre(T P , α , β , name , T M , P reU RI , [ ] ) :− pre(T P , α , β , name , T M , P reU RI , P RSQLP re ) :−
T P.subject = T Ppredicate
T P.subject = T P.predicate , βm name(T P.predicate , P redicateAlias ) , generateSQLExpression(as , BetaP re , P redicateAlias , P RSQLP re ) . pre(P reU RI , BetaP re ) , genP RSQLm
T P.object = T Psubject genP RSQLm obj ( tp , α , β , name , T M , P reU RI , [ ] ) :− obj ( tp , α , β , name , T M , P reU RI , P RSQLObj ) :−
T P.object = T P.subject , T P.object = T P.predicate , βm obj ( T M , P reU RI , α , BetaObj ) , name(T P.object , ObjectAlias ) , generateSQLExpression(as , BetaObj , ObjectAlias , P RSQLObj ) .
The algorithm for computing genP RSQL under M is provided in Listing 5 . The outputs of this function are used in the SELECT part of the generated SQL as the select items of the SQL queries together with its aliases , which are generated by function name . As defined in [ 7 ] , given a term in IVL , a function name generates a unique name , such that the generated name conforms to the SQL syntax for relational attribute names . In our examples , name(t ) generates term type appended by the name of the term . For example , the result of name(?lbl ) is var_lbl and the result of name(hasOf f er ) is iri_hasOffer . The function genP RSQL projects all the β attributes and assigns them unique aliases generated from the name function ( line 9 , 16 , and 25 ) . Some examples of genP RSQL( ) results can be seen in Table 1 .
1 2 3 4
5 6 7 8 9 10 11 12 13 14 15 16 17 18
19 20
21 22 23
24 25
3.7 Query Rewriting Optimizations
The translation mappings/functions that we have pre sented so far can be evaluated directly over relational database systems ( RDBMS ) . Taking into account that many of these RDBMS have already implemented a good number of optimisations for their query evaluation , most of the resulting queries can be evaluated at the same speed as the native SQL queries what would have been generated using SQL directly . However , there are RDBMS that need special attention ( eg , MySQL , PostgreSQL ) , because the resulting queries contain some properties that affect the capabilities of the database optimizer . For this reason , whenever it is possible , we remove non correlated subqueries from the resulting queries by pushing down projections and selections ( as advocated by [ 10] ) . We also remove self joins that occur in the rewritten queries such as when the graph patterns contain alpha mappings coming from the same table(s ) . Those translations are illustrated in Listing 6 .
Listing 6 : Examples of translation queries
SELECT DISTINCT ?pr ?productLabel ?productComment ?productProducer p.comment AS productComment , p.producer AS productProducer
AND p.comment IS NOT NULL AND p.producer IS NOT NULL
4 . EVALUATION
We separate our evaluations into two categories , using a synthetic benchmark and using three real projects . Their details are available in the following sub sections . Our query translation algorithm has been implemented in our latest version of Morph , which is available as a Java/Scala opensource project in Github9 . The query translation types supported by Morph are the na¨ıve translation queries ( C ) , which 9https://github.com/fpriyatna/morph
SELECT DISTINCT pr , productLabel , productComment , productProducer FROM (
( SELECT nr AS pr , label AS productLabel FROM product
WHERE nr IS NOT NULL AND label IS NOT NULL ) p 1 ,
( SELECT p 2.pr , p 2.productComment , p 3.productProducer FROM
( SELECT nr AS pr , comment AS productComment FROM product
WHERE nr IS NOT NULL AND comment IS NOT NULL ) p 2 ,
( SELECT nr AS pr , producer AS productProducer FROM product
WHERE nr IS NOT NULL AND producer IS NOT NULL ) p 3
}
) gp
FROM
WHERE p 2.pr= p 3.pr ) p 2 3
SELECT p 1.pr , p 1.productLabel , p 2 3 . productComment , p 2 3.productProducer
?pr hasLabel ?label . ?pr hasComment ?comment . ?pr hasProducer ?producer .
1 #SPARQL 2 3 WHERE { 4 5 6 7 8 9 −− naive translation ( C ) 10 11 12 13 14 15 16 17 18 19 20 21 22 23 WHERE p 1.pr = p 2 3.pr 24 25 26 −− subquery elimination ( SQE ) 27 28 29 FROM product p1 , product p2 , product p3 30 WHERE p1.nr = p2.nr AND p2.nr = p3.nr 31 32 33 34 35 −−self−join elimination ( SJE ) 36 37 38 39 40 41 42 43 44 45 −−subquery and self−join elimination ( SQE + SJE ) 46 47 48 49 WHERE p.nr IS NOT NULL AND p.label IS NOT NULL 50
SELECT p1.nr AS pr , p1.label AS productLabel ,
( SELECT p.nr AS pr , p.label AS productLabel
SELECT p.nr AS pr , p.label AS productLabel ,
FROM product p
SELECT pr , productLabel , productComment , productProducer FROM
, p.comment as productComment , p.producer AS productProducer
FROM product p WHERE p.nr IS NOT NULL AND p.label IS NOT NULL AND p.comment IS NOT NULL AND p.producer IS NOT NULL ) gp p2.comment AS productComment , p3.producer AS productProducer
AND p1.nr IS NOT NULL AND p2.nr IS NOT NULL AND p3.nr IS NOT NULL AND p1.label IS NOT NULL AND p2.comment IS NOT NULL AND p3.producer IS NOT NULL
484 tp ?product rdfs:label ?label
T riplesM ap TMProduct
αm {PRODUCT}
βm sub:{PRODUCT.nr} , pre:{’rdfs:label’} , obj:{PRODUCT.label} genCondSQLm {PRODUCT.label NULL}
IS NOT
:Product1 hasOffer :Offer3847
TMProduct
{PRODUCT , OFFER} sub:{PRODUCT.nr} , pre:{’hasOffer’} , obj:{OFFER.nr}
{PRODUCT.nr = 1 AND PRODUCT.nr OFAND OFFER.product FER.nr = 3847}
=
AS ’rdfs:label’ iri rdfs label , PROD genP RSQLm {PRODUCT.nr var product , AS UCT.label AS var label} {PRODUCT.nr AS iri Product1 , ’hasOffer’ AS iri has offer , OFFER.nr AS iri Offer2847}
Table 1 : Example of mappings and functions results under R2RML document m are the result of the query rewriting algorithm described in Section 3 , together with three variants of it ; with subquery elimination ( SQE ) , self join elimination ( SJE ) , and both types of eliminations ( SQE+SJE ) . 4.1 Synthetic Benchmark Evaluation
The BSBM benchmark [ 5 ] focuses on the e commerce domain and provides a data generation tool and a set of twelve SPARQL queries together with their corresponding SQL queries generated by hand . The data generator is able to generate datasets with different sizes containing entities normally involved in the domain ( eg , products , vendors , offers , reviews , etc ) . For the purpose of our benchmark , we work with the 100 million triple dataset configuration .
All these queries have been evaluated on the same ma chine , with the following configuration : Pentium E5200 2.5GHz processor , 4GB RAM , 320 GB HDD , and Ubuntu 1304 The database server used for the synthetic benchmark queries is PostgreSQL 919 We normalize the evaluation time over the native evaluation time . We have run all queries with 20 times with different parameters , in warm mode run.The resulting sets of queries together with query plans generated by PostgreSQL919 , and the resulting query evaluation time are available at http://bitly/15XSdDM
The BSBM SPARQL queries are designed in such a way that they contain different types of queries and operators , including SELECT/CONTRUCT/DESCRIBE , OPTIONAL , UNION . In the same spirit , the corresponding SQL queries also consider various properties such as low selectivity , high selectivity , inner join , left outer join , and union among many others . Out of the 12 BSBM queries , we focus on all of the 10 SELECT queries ( that is , we leave out DESCRIBE query Q09 and CONSTRUCT query Q12 ) . We compare the native SQL queries ( N ) , which are specified in the BSBM benchmark with the ones resulting from the translation of SPARQL queries generated by Morph . Although not included here , we also evaluated those queries using D2R 081 with the –fast option enabled . The reason why we do not include here the results from these evaluations is because in many queries ( such as in Q2 , Q3 , Q4 , Q7 , Q8 , and Q11 ) , D2R produces multiple SQL queries and then the join/union operations are performed at the application level , rather than in the database engine , what prevents us from doing direct comparisons . Nevertheless , this approach is clearly not scalable ( eg , in Q07 and Q08 the system returned an error while performing the operations , while the native and the translation queries could be evaluated over the database system ) .
411 Discussion We can observe that all translation types ( native , C , SQE , SJE , SQE+SJE ) have similar performance in most of BSBM queries , ranging from 0.67 to 2.60 when normalized accord
Figure 3 : BSBM query evaluations ( normalized time to native query ) ing to the native SQL queries . To understand this behaviour better , we analyzed the query plans generated by the RDBMS . Our observation tells us that in many of the queries ( Q01 , Q02 , Q03 , Q05 , Q06 , Q10 , and Q11 ) , C produces identical query plans to SQE ’s , and SJE produces identical query plans to SQE+SJE ’s . Additionally , SQE also produces identical query plans to SQE+SJE in Q07 and Q08 . The reason for this is the capability of the database ’s optimizer to eliminate non correlated subqueries . The difference between the query plans produced by C/SQE and the ones produced by SJE/SQE+SJE is the number of joins to be performed . However , as the join conditions are normally perfomed on indexed columns , there is small overhead in terms of their performance . This explains why all the translation results have similar performance .
However , in some queries the translation results show sig nificant differences , such as in Q04 and Q05 .
• BSBM SQL 4 contains a join between two tables ( product and producttypeproduct ) and three subqueries , two of them are used as OR operators . The SPARQL equivalent of this query is a UNION of two BGPs ( a set of triple patterns ) . We note that the native query contains a correlated subquery and the generated query plan requires a table scan to find a specific row condition . The query plans generated by the translation algorithm , on the other hand , produce joins , instead of a correlated subquery , and the joins are able to exploit the indexes defined .
• BSBM SQL 5 is a join of four tables ( product , product , productfeatureproduct , and productfeatureproduct ) . The size of table productfeatureproduct is significantly bigger than the table product ( 280K rows vs 5M rows ) . The generated query plan by the native query joins bigger tables ( productfeatureproduct and productfeatureproduct ) before joining the intermedi
485 ate result with the smaller table ( product and product ) . This join order is specified in the query itself . The join orders of the translation queries are different ; C and SQE join based on the order of triple patterns in the graph , SJQ and SQE+SJE join based on the smaller tables first ( which is an effect of the self joins elimination process ) .
These explain why the translation queries perform better than the native queries in Q04 and Q05 and in fact show that the native queries proposesd in the benchmark should have been better optimised when proposed for the benchmark . 4.2 Real Cases Evaluation
While the BSBM benchmark is considered as a standard way of evaluating RDB2RDF approaches , given the fact that it is very comprehensive , we were also interested in analysing real world queries from projects that we had access to , and where there were issues with respect to the performance of the SPARQL to SQL query rewriting approach . In all the cases , we compare the queries generated by D2R Server with –fast enabled with the queries generated by Morph with subquery and self join elimination enabled . All the resulting queries together with their query plans are also available at http://bitly/15XSdDM 421 BizkaiSense Project The BizkaiSense project is an effort to measure various environmental properties coming from sensors that are deployed throughout Greater Bilbao , Spain . Some of the most common queries that are needed in this project are :
• Q01 obtains all observations coming from a particular weather or air quality station together with the time of the observation . We set 100 , 1000 , and 10000 as the maximum number of rows to be returned .
• Q02 extends Q01 by returning the sensor results generated from those observations obtained . We set 100 , 1000 , and 10000 as the maximum number of rows to be returned .
• Q03 returns the average measures by property for a given week in a given station ( with the units of measure ) .
• Q04 returns the average measures by property for a given week in a given station ( without the units of measure ) .
• Q05 returns the maximum measure in all the stations for each property in a given day ( returning also the station in which it happened ) .
• Q06 returns the maximum measure in all the stations for each property in a given day ( without the station in which it happened ) .
• Q07 returns the maximum measure in all the stations for a given property in a given day ( returning the station in which it happened ) avoiding the use of the ” MAX ” clause .
CPU E5640 2.67GHz x 16 , 48GB RAM , Ubuntu 12.04 LTS 64 bits and MySQL 5.5 with a 10 minutes timeout . The evaluation time of those queries ( in some cases with a limit in the number of returned bindings ) is shown in Figure 4 . We note that the database server failed to evaluate the queries Q03 , Q05 , Q06 , and Q07 generated from D2R Server and in all cases , the queries generated by Morph take significantly less time to be evaluated compared to the ones generated by D2R Server .
Figure 4 : BizkaiSense query evaluation time ( in seconds )
422 RÉPENER Project R´EPENER [ 17 ] is a Spanish national project that provides access to energy information using semantic technology called SEiS . Two of the most common queries that are consulted through SEiS are the following :
• Q01 retrieves all buildings and their climatezone and building life cycle phase
• Q02 retrieves all buildings and their climatezone , build ing life cycle phase , and conditioned floor area .
The corresponding SPARQL queries are shown in Listing 8 . All queries generated by D2R and Morph are evaluated on a machine with the following specification : Intel Core 2 Quad Q9400 2.66 GHz , 4 GB RAM , Windows 7 Professional 32 bits , and MySQL 5.5 as the database server . As shown in Figure 5 , all queries are successfully evaluated by the database server , with queries generated by Morph being 2 3 faster than those generated by D2R server .
Figure 5 : SEiS query evaluation time ( in seconds )
The corresponding SPARQL queries can be seen in Listing 7 . All queries generated by D2R and Morph are evaluated on a machine with the following specification : Intel(R ) Xeon(R )
Integrate Project
423 Integrate is an FP7 project for sharing and integrating clinical data using HL7 RIM [ 13 ] , a model that represents
486 Listing 7 : BizkaiSense queries
Listing 8 : SEiS queries dc:date ?date ; ssn :observedProperty ?prop ; ssn :observationResult ?obsres . dul : isClassifiedBy ?unit . && ?date <= ” 2011−01−07T00:00:00 ” ˆˆxsd:date ) dc:date ?date ; ssn :observedProperty ?prop ; ssn :observationResult ?obsres .
?obsres ssn :hasValue ?val .
&& ?date < ” 2011−01−02T00:00:00 ” ˆˆxsd:date )
SELECT ( AVG(?datavalue ) AS ?avg month ) ?prop ?unit WHERE { ?medition ssn:observedBy <http://localhost:2020/resource/station/BETONO> ;
SELECT DISTINCT ?medition ?date WHERE { ?medition ssn:observedBy <http://localhost:2020/resource/station/ANORGA> . ?medition dc:date ?date . } LIMIT 10 # 100 , 1000
?val dul:hasDataValue ?datavalue ; dul : isClassifiedBy ?unit . && ?date <= ” 2011−01−07T00:00:00 ” ˆˆxsd:date )
FILTER ( ?date >= ” 2011−01−01T00:00:00 ” ˆˆxsd:date } GROUP BY ?prop
?obsres ssn :hasValue ?val . ?val dul:hasDataValue ?datavalue ; FILTER ( ?date >= ” 2011−01−01T00:00:00 ” ˆˆxsd:date } GROUP BY ?prop ?unit
SELECT DISTINCT ?medition ?date ?res WHERE { ?medition ssn:observedBy <http://localhost:2020/resource/station/ANORGA> . ?medition dc:date ?date . ?medition ssn:observationResult ?res . } LIMIT 10 # 100 , 1000
1 #Q01 obtains all observations coming from a particular weather 2 # or air quality station together with the time of the observation . 3 4 5 6 7 #Q02 extend Q01 by returning the sensor results generated 8 # from those observations obtained . 9 10 11 12 13 14 #Q03 returns the average measures by property for a given week 15 # in a given station ( with the units of measure ) . 16 17 18 19 20 21 22 23 24 25 26 27 28 #Q04 returns the average measures by property for a given week 29 # in a given station ( without the units of measure ) . SELECT ( AVG(?datavalue ) AS ?avg month ) ?prop WHERE { 30 ?medition ssn:observedBy <http://localhost:2020/resource/station/BETONO> ; 31 32 33 34 35 36 37 38 39 40 41 42 #Q05 returns the maximum measure in all the stations for each property 43 # in a given day ( returning also the station in which have happened ) . 44 45 46 47 48 49 50 51 52 53 54 55 56 #Q06 returns the maximum measure in all the stations for each property 57 # in a given day ( without the station in which have happened ) . 58 59 60 61 62 63 64 65 66 67 68 #Q07 returns the maximum measure in all the stations for a given property 69 # in a given day ( returning the station in which have happened ) 70 # −avoiding the use of MAX clause . 71 72 73 74 75 76 77 78 79 80 81 82
?obsres ssn :hasValue ?val . ?val dul:hasDataValue ?datavalue . FILTER ( ?date >= ” 2011−01−01T00:00:00 ” ˆˆxsd:date } GROUP BY ?prop ?station
?obsres ssn :hasValue ?val . ?val dul:hasDataValue ?datavalue . FILTER ( ?date >= ” 2011−01−01T00:00:00 ” ˆˆxsd:date } ORDER BY DESC(?datavalue ) LIMIT 1
&& ?date < ” 2011−01−02T00:00:00 ” ˆˆxsd:date )
?obsres ssn :hasValue ?val . ?val dul:hasDataValue ?datavalue . FILTER ( ?date >= ” 2011−01−01T00:00:00 ” ˆˆxsd:date
&& ?date < ” 2011−01−02T00:00:00 ” ˆˆxsd:date ) }
SELECT ?datavalue ?station WHERE { ?medition a ssn:Observation ; dc:date ?date ; ssn :observedBy ?station ; ssn :observedProperty
SELECT ( MAX(?datavalue ) AS ?max ) ?prop WHERE { ?medition a ssn:Observation ; dc:date ?date ; ssn :observedProperty ?prop ; ssn :observationResult ?obsres .
SELECT ( MAX(?datavalue ) AS ?max ) ?prop ?station WHERE { ?medition a ssn:Observation ; dc:date ?date ; ssn :observedBy ?station ; ssn :observedProperty ?prop ; ssn :observationResult ?obsres .
<http://sweetjplnasagov/23/matrCompoundowl#NO> ; ssn :observationResult ?obsres . entities and relationships commonly involved in clinical activities . Some commonly used queries in this project are :
• Q01/Q02/Q03 are similarly structured , with a code that specifies whether to obtain tumor size , tumor stage , or pregnant women .
• Q04 obtains multiple participants who have been treated with Antracyclines
• Q05 obtains demographic information ( people that are older than 30 years old )
SELECT DISTINCT ∗ WHERE { ?a repener:hasBuilding ?building . ?a repener:value ?climatezone . ?building a sumo:Building . ?building repener:hasProjectData ?projectData . ?projectData repener:hasBuildingLifeCyclePhase ?buildingLifeCyclePhase . ?buildingLifeCyclePhase repener:value ?phase . }
1 #Q01 Retrieve all buildings and their climatezone 2 # and building life cycle phase 3 4 5 6 7 8 9 10 11 #Q02 . Retrieve all buildings and their building life cycle phase 12 # and conditioned floor area 13 14 15 16 17 18 19 20 21
?b rdf : type sumo:Building . ?b repener:hasProjectData ?b1 . ?b1 repener:hasBuildingLifeCyclePhase ?b2 . ?b2 repener:value ?phase . ?b repener:hasBuildingProperties ?b3 . ?b3 repener:hasBuildingGeometry ?b4 . ?b4 repener:hasConditionedFloorArea ?b5 . ?b5 repener:conditionedFloorAreaValue ?conditionedFloorArea . }
SELECT DISTINCT ∗ WHERE {
• Q06 obtains images and information that a diagnosis is based on
The corresponding SPARQL queries are shown in Listing 9 . All queries generated by D2R and Morph are evaluated on a machine with the following specification : Intel QuadCore processor 2 GHz , 4 GB of RAM , 126GB SSD HD , Ubuntu 64 bits operating system and MySQL 56 The evaluation time can be seen in Figure 6 . For Q01/Q02/Q03 , the queries generated by D2R could not be evaluated by the database server because they returned an error message saying that too many tables needed to be joined . For the other queries , the queries generated by Morph were evaluated in less time than the ones generated by D2R .
Figure 6 : Integrate query evaluation time ( in seconds )
5 . CONCLUSION AND FUTURE WORK
In this paper we have shown that the query translation approaches used so far for handling RDB2RDF mapping languages may be inefficient . For instance , systems like D2R normally produce multiple queries to be evaluated and then perform the join operations in memory rather than in the database engine , or generate SQL queries where the number of joins inside the query is so large that the underlying database engine cannot evaluate them , producing an error . We have proposed an extension of one of the most detailed approaches for query rewriting , Chebotko ’s , which was not originally conceived for RDB2RDF query translation but for RDBMS backed triple stores . Now we consider R2RML
487 cess by exploiting more indexes . Our evaluation setup will be also made available as a service for other researchers to use , so that they can evaluate their R2RML query rewriting implementations with low effort in a number of RDBMSs .
Acknowledgements . This research was supported by the Spanish project myBigData and by PlanetData ( FP7257641 ) . Juan Sequeda was supported by the NSF Graduate Research Fellowship . We also thank Boris , Jean Paul , and Jose Mora for the valuable discussions and people responsible of the Integrate ( Raul Alonso , David Perez del Rey ) , BizkaiSense ( Jon L´azaro , Oscar Pe˜na , and Mikel Emaldi ) and Repener ( Alvaro Sicilia ) projects for providing us the RDB2RDF mappings and queries used in these projects .
6 . MAPPING DOCUMENT EXAMPLE
@prefix rr : <http://wwww3org/ns/r2rml#> . @prefix bsbm : <http://localhost:2020/resource/vocab/> .
<TMProduct> a rr:TriplesMap ; rr:logicalTable [ rr:tableName "Product" ] ; rr:subjectMap [ a rr:Subject ; rr:class bsbm:Product ; rr:template "http://localhost:2020/resource/Product/{nr}" ; ] ; rr:predicateObjectMap [ rr:predicateMap [ rr:constant rdfs:label ] ; rr:objectMap [ rr:column "label" ; ] ; ] ; rr:predicateObjectMap [ rr:predicateMap [ rr:constant rdfs:comment ] ; rr:objectMap [ rr:column "comment" ; ] ; ] ; rr:predicateObjectMap [ rr:predicateMap [ rr:constant bsbm:productOffer ] ; rr:objectMap [ rr:parentTriplesMap <TriplesMapOffer> ; rr:joinCondition [ rr:child "nr" ; rr:parent "product" ; ] ] ;
] .
<TMOffer> a rr:TriplesMap ; rr:logicalTable [ rr:tableName "Offer" ] ; rr:subjectMap [ a rr:Subject ; rr:class bsbm:Offer ; rr:template "http://localhost:2020/resource/Offer/{nr}" ; ] ; rr:predicateObjectMap [ rr:predicateMap [ rr:constant bsbm:price ] ; rr:objectMap [ rr:column "price" ; ] ; ] .
Listing 9 : HL7 RIM query hl7rim : participation role ? obs role .
?livSubj hl7rim : livingSubject id ?entityId ; hl7rim:livingSubject birthTime ?birthTime .
} LIMIT 100
?obs part hl7rim : participation entityId ?entityId ;
? obs role ? obs entity hl7rim : role entity ? obs entity . hl7rim:entity code ?entityCode .
SELECT DISTINCT ?id ?code ?entityId ?birthTime ?effectiveTime ?valueST ?valuePQ WHERE { ?instObs hl7rim:observation code ?code ; hl7rim : observation id ?id ; hl7rim:observation effectiveTime ?effectiveTime ; hl7rim:observation targetSiteCode ?tarSiteCode ; hl7rim:observation targetSiteCodeTitle ? tarSiteTitle ; hl7rim:observation targetSiteCodeVocId ?tarSiteVocId ; hl7rim:observation methodCode ?methodCode ; hl7rim:observation methodCodeTitle ?methodTitle ; hl7rim:observation methodCodeVocId ?methodVocId ; hl7rim:observation valueST ?valueST ; hl7rim:observation valuePQ ?valuePQ ; hl7rim : observation units ?units ; hl7rim:observation refRangeMin ?rangeMin ; hl7rim:observation refRangeMax ?rangeMax ; hl7rim : observation title ? title ; hl7rim:observation actionNegationInd ?actNegInd ; hl7rim:observation codeVocId ?codeVocId ; hl7rim : observation participation ?obs part .
1 #Q01/Q02/Q03 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 #Q01to obtain tumor size of patients , code value is 263605001 30 # FILTER ( ?code IN ( 263605001 ) ) 31 32 #Q02:to obtain tumor stage of patients , code value is 58790005 33 # FILTER ( ?code IN ( 58790005 ) ) 34 35 #Q03:to obtain patients that are/have been pregnant , code value is 77386006 36 # FILTER ( ?code IN ( 77386006 ) ) 37 38 39 #Q04 to retrieving multiple participants who have been treated 40 # with Antracyclines ( Family of drugs ) 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 #Q05 to obtain patient demographics information : people older than 30 years 60 61 62 63 64 65 66 67 #Q06 tobtain images and information where a diagnosis are based in 68 69 70 71 72 73 74 75 76 77
SELECT ∗ WHERE { ?substanceAdm a hl7rim:substanceAdministration . ?substanceAdm hl7rim:substanceAdministration code ?substanceAdmCode . ?substanceAdm hl7rim:substanceAdministration code ” 432102000 ” . ?substanceAdm hl7rim:substanceAdministration participation ?partDevice . ?device a hl7rim:entity . ?device hl7rim : entity id ?deviceId . ?device hl7rim:entity code ” 417916005 ” . ?device hl7rim : entity role ?deviceRole . ?deviceRole hl7rim : role participation ?partDevice . ?substanceAdm hl7rim:substanceAdministration participation ?partPatient . ?patient a hl7rim:livingSubject . ?patient hl7rim : livingSubject id ?livingSubjectId . ?patient hl7rim : livingSubject role ?patientRole . ?patient hl7rim : livingsubject classCode ” PSN ” . ?patientRole hl7rim:role classCode ” PAT ” . ?patientRole hl7rim : role participation ?partPatient . }
SELECT DISTINCT ?entityId ?birthTime ?gender WHERE { ?subject hl7rim : livingSubject id ?subjectId . ?subject hl7rim:livingSubject birthTime ?birthTime . ?subject hl7rim:livingSubject administrativeGenderCode ?gender . ?subject hl7rim : livingsubject classCode ” PSN ” . FILTER ( ?birthTime < ” 1983−10−02T00:00:00 ” ˆˆxsd:date ) }
SELECT DISTINCT ?observationId ?code ?title ?imagId ?xml WHERE { ?obsInst hl7rim : observation id ” ee3606f9−9dd1−11e2−9bba−0155938d90a2 ” ; hl7rim : observation id ?observationId ; hl7rim:observation code ?code ; hl7rim : observation title ? title ; hl7rim:observation actRelationship ?instRel .
?obsInstB hl7rim:act id ?imagId ; hl7rim:actRelationship actB ?obsInstB . hl7rim : act text ?xml }
?instRel hl7rim:actRelationship typeCode ” EXPL ” ; mappings in the query translation process . We have also shown through our empirical evaluation that in all of the BSBM queries and real cases queries , our approach behaves in general similarly to native queries , and better than other existing approaches .
There is still room for improvement in our work , which we will address in the near future . For instance , some of the optimised translated queries perform better than the native ones , due to the introduction of additional predicates , what is common in the area of Semantic Query Optimization ( SQO ) . In this sense , we will deepen in the design of our algorithm so as to take into account other SQO techniques that can be useful in query translation . For instance , predicate introduction may speed up the query evaluation pro
488 7 . REFERENCES
[ 1 ] S . Auer , S . Dietzold , J . Lehmann , S . Hellmann , and
D . Aumueller . Triplify : lightweight Linked Data publication from relational databases ( 2009 ) . In 18th International Conference on World Wide Web , pages 621–630 , 2009 .
[ 2 ] J . Barrasa and A . G´omez P´erez . Upgrading relational legacy data to the semantic web . In 15th International Conference on World Wide Web , pages 1069–1070 . ACM , 2006 .
[ 3 ] C . Bizer and R . Cyganiak . D2R Server : Publishing relational databases on the web . In The 5th International Semantic Web Conference , 2006 .
[ 4 ] C . Bizer and A . Schultz . The berlin SPARQL benchmark .
International Journal on Semantic Web and Information Systems ( IJSWIS ) , 5(2):1–24 , 2009 .
[ 5 ] C . Bizer and A . Schulz . Benchmarking the performance of storage systems that expose sparql endpoints . In 4th International Workshop on Scalable Semantic Web knowledge Base Systems ( SSWS2008 ) , 2008 .
[ 6 ] D . Calvanese , G . De Giacomo , D . Lembo , M . Lenzerini , and
R . Rosati . Tractable reasoning and efficient query answering in description logics : The DL Lite family . Journal of Automated reasoning , 39(3):385–429 , 2007 .
[ 10 ] B . Elliott , E . Cheng , C . Thomas Ogbuji , and Z . Ozsoyoglu . A complete translation from SPARQL into efficient SQL . In Proceedings of the 2009 International Database Engineering & Applications Symposium , pages 31–42 . ACM , 2009 .
[ 11 ] A . Garrote and M . Garc´ıa . Restful writable APIs for the web of linked data using relational storage solutions . In WWW 2011 Workshop : Linked Data on the Web ( LDOW2011 ) , 2011 .
[ 12 ] A . Gray , N . Gray , and I . Ounis . Can RDB2RDF tools feasibily expose large science archives for data integration ? In Proceedings of the 6th European Semantic Web Conference on The Semantic Web : Research and Applications , pages 491–505 . Springer Verlag , 2009 .
[ 13 ] A . Hasman et al . HL7 RIM : an incoherent standard . In
Ubiquity : Technologies for Better Health in Aging Societies , Proceedings of Mie2006 , volume 124 , page 133 . IOS Press , 2006 .
[ 14 ] E . P . Marcelo Arenas , Alexandre Bertails and J . Sequeda . A direct mapping of relational data to RDF . W3C Recommendation , http://wwww3org/TR/rdb direct mapping/
[ 15 ] M . Rodrıguez Muro , J . Hardi , and D . Calvanese . Quest :
Efficient SPARQL to SQL for RDF and OWL . Poster presented at International Semantic Web Conference , ISWC 2012 .
[ 7 ] A . Chebotko , S . Lu , and F . Fotouhi . Semantics preserving
[ 16 ] J . Sequeda and D . P . Miranker . Ultrawrap : SPARQL execution
SPARQL to SQL translation . Data & Knowledge Engineering , 68(10):973–1000 , 2009 . on relational data . Web Semantics : Science , Services and Agents on the World Wide Web , 2013 .
[ 8 ] R . Cyganiak . A relational algebra for sparql . Technical Report
HPL 2005 170 , Digital Media Systems Laboratory HP Laboratories Bristol . https://wwwhplhpcom/techreports/2005/HPL 2005 170pdf [ 9 ] S . Das , S . Sundara , and R . Cyganiak . R2RML : RDB to RDF mapping language . W3C Recommendation , http://http://wwww3org/TR/r2rml/
[ 17 ] A . Sicilia , G . Nemirovskij , M . Massetti , and L . Madrazo . R´EPENER ’s linked dataset ( in revision ) . Semantic Web Journal , 2013 .
[ 18 ] J . Unbehauen , C . Stadler , and S . Auer . Accessing relational data on the web with sparqlmap . In JIST , pages 65–80 . Springer , 2013 .
[ 19 ] B . Villaz´o´on Terrazas and M . Hausenblas . RDB2RDF implementation report . W3C Editor ’s Draft , http://wwww3org/2001/sw/rdb2rdf/implementation report/
489
