Tensor based Item Recommendation using Probabilistic
Ranking in Social Tagging Systems
Noor Ifada* , Richi Nayak
Queensland University of Technology
Gardens Point Campus , 2 George St , Brisbane , Queensland 4000 , Australia noorifada@{iftrunojoyoacid , quteduau} , rnayak@quteduau
ABSTRACT A common problem with the use of tensor modeling in generating quality recommendations for large datasets is scalability . In this paper , we propose the Tensor based Recommendation using Probabilistic Ranking method that generates the reconstructed tensor using block striped parallel matrix multiplication and then probabilistically calculates the preferences of user to rank the recommended items . Empirical analysis on two real world datasets shows that the proposed method is scalable for large tensor datasets and is able to outperform the benchmarking methods in terms of accuracy .
Categories and Subject Descriptors H33 [ Information Search and Retrieval ] : Information Filtering
Keywords Tensor Model ; Item Recommendation ; Probabilistic Ranking ; Folksonomy ; Social Tagging Systems
1 . INTRODUCTION The Social Tagging Systems ( STS ) play significant role in helping users to manage their resources ( called as items ) online by adding tags [ 1 ] . Tags , which are reusable and shareable , reveal user interest and allow users to recognize items . This additional source of information helps online systems for building improved user profiles that can be used in recommendation [ 2 , 3 ] . This type of system called as the tag based recommender system uses Folksonomy , a triplet called as tag assignment , for representing the correlation between users , items , and tags . The success of a tagbased recommender system depends on how the correlation in Folksonomy will be exploited [ 4].* A two dimensional user profiling approach , modeling the users and items correlation , cannot be directly employed to build a tagbased recommender system . This approach cannot efficiently
* Noor Ifada is currently on leave from the Informatics Engineer ing Department , University of Trunojoyo Madura , Indonesia .
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author's site if the Material is used in electronic media . WWW’14 Companion , April 7–11 , 2014 , Seoul , Korea . ACM 978 1 4503 2745 9/14/04 . http://dxdoiorg/101145/25679482579243 capture the three dimensional characteristic and , fails to model the many to many relationships that exist among these dimensions [ 5 ] . Researchers have solved this problem by projecting the <user , item , tag> correlation into three two dimensional matrices , <user , item> , <user , tag> , and <item , tag> [ 4 ] . This approach , however , is unable to capture the total interaction among dimensions and cannot expose their latent relationship . It can result in poorer recommendation quality [ 5 , 6 ] . Since folksonomy is a multi dimensional data , user profiles can be naturally modeled with higher order data models . Tensor modeling is a well known approach to represent and analyze latent relationships inherent in the multi dimensions data [ 7 ] . The approach consists of three steps : ( 1 ) tensor construction for modeling multi dimension data ; ( 2 ) tensor decomposition to derive latent relationships inherent in the data ; and ( 3 ) tensor reconstruction to reveal the latent relationships between dimensions of tensor model . Using tensor modeling for generating recommendation is challenging due to the following reasons :  Reconstructing large size tensor . Tensor reconstruction is computed by multiplying all decomposed element . This process is memory expensive and , therefore , reconstructing large size tensors ( for instance , more than the size of 1000(cid:3400 ) 1000(cid:3400)1000 for a 3 D tensor model ) is infeasible [ 5 , 6 , 8
10 ] . Several memory efficient methods for enabling decomposition process have been proposed [ 11 ] and they fulfill the purpose of many applications that do not need a tensor to be reconstructed . The decomposed elements are sufficient for their purpose ; however , the tensor based recommendation methods , as proposed in this paper , require the tensor to be reconstructed for identifying new entries and , that so , in large sizes .
 Utilizing reconstructed tensor to generate recommendation . Existing approaches assume that tag assignment value in the reconstructed tensor represents the level of user preference for an item based on the tag , and generate the recommendations based on the maximum values of tag assignments in each user item combinations [ 5 , 9 ] . However , these approaches ignore the user ’s past tagging activities that have been found most influencive in forming user likelihood for the recommended items [ 4 ] .
In this paper we address the aforementioned challenges of scalability and accuracy , and propose a novel Tensor based Recommendation using Probabilistic Ranking ( TRPR ) method . The block striped parallel matrix multiplication is proposed for combining the decomposed elements of the tensor model to enable a scalable tensor reconstruction . The list of candidate items and tag preferences for each user are then generated . The probabilistic approach is proposed for calculating the preferences of users to
805 rank the recommended items . The proposed TRPR method is evaluated on two real world STS datasets , namely Delicious and LastFM . Experiments have been conducted to find the effectiveness of the method over the benchmarking methods . Empirical analysis shows that the proposed method is scalable and is able to outperform the benchmarking methods in accuracy of recommendation . The contribution of this paper can be summarized as : ( 1 ) a novel method of scalable tensor reconstruction , and ( 2 ) an effective tagbased recommender system using tensor modeling and probabilistic approach .
2 . RELATED WORK Tensor modeling has been used to build recommender systems for offering various types of outputs . In the STS , researchers have used tensor models to generate tags recommendations [ 5 , 8 , 12 , 13 ] and items recommendations [ 5 , 6 , 9 ] based on the usage of tags . The task of recommending tags to a user for an item differs from the task of recommending an item to a user . Tag recommendation is generated using the user item predefined combination , while the item recommendation is generated with only the user specified [ 14 ] . Therefore , the recommender system for each type should be developed using different approach . Scalability is a common problem in generating recommendations for large datasets using tensor modeling . Rendle & SchmidtThieme applied the PITF technique [ 13 ] which models the pairwise interaction between users , items , and tags . The method able to perform better in terms of runtime and recommendation quality than other factorization techniques . Nevertheless , this approach is not applicable to this study since our focus is to generate item recommendation while their work is designed for generating tag recommendation . Kolda & Sun [ 11 ] solve the construction and decomposition memory problems by storing only the non zeros values and then implementing a memory efficient method . However , the tensor based recommendation methods , as proposed in this paper , require the tensor to be reconstructed by multiplying all decomposed elements for identifying new entries . Consequently , the process of reconstructing , especially when the data is large , is very expensive . This has not been properly addressed yet . The current item recommendation methods [ 5 , 6 , 9 ] either use the decomposition factors or the reconstructed tensor directly for generating the recommendations . These approaches disregard the previous activities [ 15 ] of items and tags for the users , and solely use the final result of tensor model . This affects the recommendation quality . The method by Symeonidis et al [ 5 ] comes closest to our work . The method builds tensor model from a relatively small size data ( 105(cid:3400)246(cid:3400)591 representing users , items , tags ) and directly utilizes the reconstructed tensor after decomposition to generate item recommendation based on the maximum values of tensor elements . Although the method is promising compared to the non tensor methods , it has two inherent limitations : ( 1 ) not scalable for reconstructing large tensor ; and ( 2 ) uses the reconstructed tensor result directly to generate recommendations and disregards the user past tagging activities which possibly affect the recommendation quality . To the best of our knowledge , this paper is the first tensor based study of tag based item recommender system that proposes to improve the quality of recommendations after the candidate items is achieved from the reconstructed tensor .
3 . TENSOR BASED RECOMMENDATION
3.1 Preliminaries be the set of all tags . In STS , a vector of tag assignment ,
USING PROBABILISTIC RANKING the set of all users , ( cid:1835 ) Let ( cid:1847)(cid:3419),(cid:2870),(cid:2871),…,|(cid:3022)|(cid:3423 ) be ( cid:3419)(cid:1861),(cid:1861)(cid:2870),(cid:1861)(cid:2871),…,(cid:1861)|(cid:3010)|(cid:3423 ) be the set of all items and ( cid:1846)(cid:3419),(cid:2870),(cid:2871),…,||(cid:3423 ) ( cid:1853)(cid:4666),(cid:1861),(cid:4667)(cid:1488)(cid:1827 ) represents the tagging activity of user who has tagged item ( cid:1861 ) with tag . For each tag assignment , possible value of ( cid:3002 ) for ( cid:1853)(cid:4666),(cid:1861),(cid:4667 ) is {0 , 1} where 1 indicates that ( cid:1853)(cid:4666),(cid:1861),(cid:4667 ) exists and 0 indicates otherwise . The post ( cid:1841)(cid:3002 ) denotes the set of all distinct user item combinations in ( cid:1827 ) as a user can tag an item with multiple values For each post , the possible value of ( cid:3016)(cid:3250 ) for ( cid:1867)(cid:3028)(cid:4666),(cid:4667 ) is {0 , 1} where 1 indicates a posting activity for a user who tagged item ( cid:1861 ) with any tags and 0 indicates user has not tagged item ( cid:1861 ) . The value set ( cid:3016)(cid:3250)is used for ranking the recommendations , whereas , the value set ( cid:3002 ) is used in generating candi date items as well as in ranking item recommendations . the tensor using a decomposition method , and then reconstruction
3.2 Overview of the TRPR Method Figure 1 illustrates the proposed Tensor based Recommendation using Probabilistic Ranking ( TRPR ) method for generating item recommendation to users based on their tagging activities . The first step is building tensor model that includes construction of a third order tensor from the tag assignment data ( cid:1827 ) , factorization of of the decomposed elements . Given ( cid:1847 ) as User dimension , ( cid:1835 ) as Item dimension and ( cid:1846 ) as Tag dimension , a third order tensor ( cid:2291)(cid:1488)(cid:1337)(cid:3022)(cid:3400)(cid:3010)(cid:3400 ) is represented . The tensor is populated with the value of tag assignment ( cid:3002 ) . Accordingly , the next step is ranking the users to rank the Top (cid:1840 ) list of item recommendations . candidate items for recommendation . It includes the generation of list of candidate items and tag preferences from the reconstructed tensor , and then probabilistically calculating the preferences of
Figure 1 : Overview of the Proposed TRPR Method
3.3 Initial Tensor Construction
From the ( cid:1827 ) triplets dataset , an initial third order tensor ( cid:2291)(cid:1488 ) ( cid:1337)(cid:3022)(cid:3400)(cid:3010)(cid:3400 ) is constructed , where |(cid:1847)| , |(cid:1835)| , and |(cid:1846)| are the number of a binary initial value of ( cid:3002 ) ( which will change to a continuous users , items and tags respectively . Each element of tensor is given value illustrating the importance of this triplet in the tensor model when the tensor will be reconstructed ) . As scalability and sparsity are the well known issues in building tensor models [ 11 ] , only the non zeros values are uploaded when constructing the tensor . In this way , even the large tensor size can be uploaded as the majority of tensor entries are usually zero .
806 rows in each subtask results . This technique results in a memory efficient loop approach for scalable tensor reconstruction . assignment data that contain a total of 3 users , 3 items , and 5 tags . Tensor is constructed using only non zeros values , showing the
Example : Tensor Modeling . Let us consider the toy problem in Table 1 and 2 to explain the processes in tensor modeling . Table 1 cations of ( cid:1849)(cid:3015 ) ( using block strip of size ( cid:1869)(cid:4666)|(cid:1846)|(cid:1840)(cid:4667)⁄ iteration ) with matrix ( cid:1851)(cid:2870)(cid:3553 ) ( the mode 3 matricization of tensor ( cid:2291)(cid:2870)(cid:3554) ) . We obtain the complete reconstructed tensor ( cid:2291)(cid:3552 ) by combining all The reconstructed tensor ( cid:2291)(cid:3552 ) is able to reveal the latent relationship of users , items , and tags in the form of new entries , ( cid:1841)(cid:3002)(cid:3552)(cid:1841)(cid:3002 ) . The reconstructed tensor ( cid:2291)(cid:3552 ) includes a set of triplets ( cid:1853)(cid:3548)(cid:4666),(cid:1861),(cid:4667)(cid:1488 ) A(cid:3553 ) , where ( cid:1827 ) ( cid:1599)(cid:1827)(cid:4632 ) . Each ( cid:1853)(cid:3548)(cid:4666),(cid:1861),(cid:4667)(cid:1488 ) A(cid:3553 ) will have a value ( cid:3002)(cid:3552 ) which represents the likeliness that user will tag item ( cid:1861 ) with tag . Each post in ( cid:1827)(cid:4632 ) ( (cid:1841)(cid:3002)(cid:3552 ) ) is assigned the binary value of ( cid:3016)(cid:3250)(cid:3553 ) . shows an initial third order tensor ( cid:2291)(cid:1488)(cid:1337)(cid:2871)(cid:3400)(cid:2871)(cid:3400)(cid:2873 ) populated with tag existence of 8 tagging activities , represented as ( cid:3002 ) , of user who has tagged item ( cid:1861 ) with tag . Likewise , there are exist 5 posting activities , represented as ( cid:3016)(cid:3250 ) , of user who tagged item ( cid:1861 ) with ing process . Applying the decomposition technique to tensor ( cid:2291 ) will result in three factor matrices of ( cid:3022)(cid:1488)(cid:1337)(cid:2871)(cid:3400)(cid:2870 ) , ( cid:3010)(cid:1488)(cid:1337)(cid:2871)(cid:3400)(cid:2870 ) , and ( cid:1488)(cid:1337)(cid:2873)(cid:3400)(cid:2870 ) and one core tensor ( cid:1829)(cid:1488)(cid:1337)(cid:2870)(cid:3400)(cid:2870)(cid:3400)(cid:2870 ) when we choose 2 as the reduction size . Table 2 shows the reconstructed tensor ( cid:2291)(cid:3552 ) detensor decomposition has recalculated the value ( (cid:3002)(cid:3552)(cid:4667 ) for each structed tensor ( cid:2291)(cid:3552 ) generates three new entries that are not present in the original tensor ( cid:2291 ) and , consequently , the items in these Table 1 : Toy Dataset for Initial Tensor ( cid:2339 ) Construction Value of ( cid:2172)(cid:2157 ) ( cid:4666)(cid:2203)(cid:4667 ) ( cid:4666)(cid:2204)(cid:2172)(cid:2157)(cid:4667 ) rived by multiplying the core tensor and factor matrices . For ease of illustration , we are only showing the top 11 entries out of a total 45 entries in the reconstructed tensor . It can be noted that existing entry as well as it has identified some new entries showing the latent relationships . As highlighted in Table 2 , the recon any tags . This latter information is used in the probabilistic rank
Value of ( cid:2157 ) ( cid:4666)(cid:2204)(cid:2157)(cid:4667 ) entries become the candidate items for recommendation .
( cid:4666)(cid:2202)(cid:4667 )
( cid:4666)(cid:2191)(cid:4667 )
Item
User
Tag
Table 2 : Reconstructed Tensor ( cid:2339)(cid:3553 ) from Toy Dataset Value of ( cid:2172)(cid:2157)(cid:3553 ) ( cid:4666)(cid:2203)(cid:4667 ) ( cid:4666)(cid:2204)(cid:2172)(cid:2157)(cid:3553)(cid:4667 )
Value of ( cid:2157)(cid:3553 ) ( cid:4666)(cid:2204)(cid:2157)(cid:3553)(cid:4667 )
( cid:4666)(cid:2202)(cid:4667 )
( cid:4666)(cid:2191)(cid:4667 )
Item
User
Tag
1 1 1 1 1 2 2 3
1 1 1 1 1 2 2 2 2 3 3
1 1 1 2 3 1 1 1
1 1 1 2 3 1 1 2 3 1 2
1 2 3 5 2 2 4 2
1 2 3 5 2 2 4 5 2 2 5
1 1 1 1 1 1 1 1
1.35 1.02 0.89 1.22 0.98 0.99 1.54 0.45 0.66 1.28 0.77
1
1 1 1 1
1
1 1 1 1 1 1 1
( 1 ) as follows :
3.4 Tensor Decomposition
Figure 2 : Tucker Decomposition for Third Oder Tensor corresponding factor matrices . The Tucker decomposition for the
( 2 ) Core tensor defines the interaction between the users , items and known Tucker based techniques is Higher Order Orthogonal Iteration ( HOOI ) [ 7 ] which generalizes Singular Value Decomposition ( SVD ) into a higher order form by performing SVD on the matricized data for each dimension and then uses an iterative least latent relationship between users , items , and tags . In this paper , we explained the TRPR method by applying Tucker decomposition technique to derive latent relationships inherent in multidimensions of the tensor data . Tucker factorizes a third order
Given tensor ( cid:2291 ) , a decomposition technique is applied to derive tensor ( cid:2291)(cid:1488)(cid:1337)(cid:3022)(cid:3400)(cid:3010)(cid:3400 ) into one core tensor ( cid:2269)(cid:1488)(cid:1337)(cid:3017)(cid:3400)(cid:3018)(cid:3400)(cid:3019 ) and three factor matrices of ( cid:1839)(cid:4666)(cid:4667)(cid:1488)(cid:1337)(cid:3022)(cid:3400)(cid:3017 ) , ( cid:1839)(cid:4666)(cid:2870)(cid:4667)(cid:1488)(cid:1337)(cid:3010)(cid:3400)(cid:3018 ) , and ( cid:1839)(cid:4666)(cid:2871)(cid:4667)(cid:1488)(cid:1337)(cid:3400)(cid:3019 ) ( cid:2291)(cid:3406)(cid:2269 ) ×1 ( cid:1839)(cid:4666)(cid:4667 ) ×2 ( cid:1839)(cid:4666)(cid:2870)(cid:4667 ) ×3 ( cid:1839)(cid:4666)(cid:2871)(cid:4667 ) The core tensor ( cid:2269 ) must satisfy : ( cid:2269 ) = ( cid:2291 ) ×1 ( cid:1839)(cid:4666)(cid:4667 ) ( cid:4593 ) ×2 ( cid:1839)(cid:4666)(cid:2870)(cid:4667 ) ( cid:4593 ) ×3 ( cid:1839)(cid:4666)(cid:2871)(cid:4667 ) ( cid:4593 ) tags [ 7 ] while |(cid:1842)| , |(cid:1843)| , and || is the number of columns in the third order tensor ( cid:2291)(cid:1488)(cid:1337)(cid:3022)(cid:3400)(cid:3010)(cid:3400 ) is illustrated in Figure 2 . A wellsquare optimization approach to optimize the core tensor ( cid:2269 ) [ 7 ] . reconstructed tensor ( cid:2291)(cid:3552 ) . The mode ( matrix ) product of a tensor ( cid:2291)(cid:1488)(cid:1337)(cid:3010)(cid:3117)(cid:3400)(cid:3010)(cid:3118)(cid:3400)…(cid:3400)(cid:3010)(cid:3263 ) with a matrix V(cid:1488)(cid:1337)(cid:3011)(cid:3400)(cid:3010)(cid:3289 ) is denoted by ( cid:2291)(cid:3400)(cid:1848 ) with a tensor of size ( cid:1835)(cid:3400)…(cid:3400)(cid:1835)(cid:3400)(cid:1836)(cid:3400)(cid:1835)(cid:3400)…(cid:3400)(cid:1835)(cid:3015 ) . This means that each mode fiber is multiplied by matrix ( cid:1848 ) . The mode ( matrix ) product of tensor ( cid:2291 ) with matrix ( cid:1848 ) is equivalent to multiplying ( cid:1848 ) by the appropriate matricization of tensor ( cid:2291 ) into matrix ( cid:1851 ) [ 7 ] : ( cid:2268 ) = ( cid:2291 ) ×n ( cid:1848 ) ( cid:3643 ) ( cid:1828)(cid:4666)(cid:4667)(cid:1848)(cid:1851)(cid:4666)(cid:4667 ) Due to the memory overflows during mode matrix product , cess into three parts . In the first two parts , we implement 1 mode and 2 mode ( matrix ) products to the core tensor ( (cid:1829 ) ) with first two factor matrices ( (cid:3022 ) , ( cid:3010 ) ) sequentially and clear the memory after implement a 3 mode block ( matrix ) product when multiplying the last factor matrix ( ) with the intermediate tensor result ( (cid:2291)(cid:2870)(cid:3554)(cid:4667 ) obtained from the previous step . The 3 mode block ( matrix ) the multiplication task is split into ( cid:1840 ) number of subtask multipli product is based on the block parallel matrix multiplication operation [ 16 ] . Using the row wise block striped matrix decomposition scheme , reconstruction becomes non scalable for large data . Given that decomposed elements consist of one core tensor and three factor matrices ( for user , item , and tag ) , we split the reconstruction pro
3.5 Tensor Reconstruction The core tensor and factor matrices are multiplied to generate the each multiplication once the results are saved . In the third part , we
( 3 )
807 calculated as follows : tion Generation
Existing tensor based recommendation approaches rank the rec
3.6 Probabilistic Ranking and Recommenda accuracy results as they disregard the previous activities [ 15 ] of each item and tag , and solely use the final result of tensor model . We propose to rank the result of tensor modeling for generating
Bayes [ 17 ] . Naïve Bayes generates a probabilistic model based on previously observed data . It is an efficient approach [ 18 ] if the problem of item recommendation can be treated as a classification problem . ommendations based on the maximum value of ( cid:3002)(cid:3552 ) within every ( cid:1841)(cid:3002)(cid:3552 ) for all new entries [ 5 , 6 , 9 , 10 ] . These approaches give poor the Top (cid:1840 ) list of item recommendations to user using Naïve Using the reconstructed tensor ( cid:2291)(cid:3552 ) , for each user , two lists are created : ( 1 ) a list of candidate items that the user might be interested in , ( cid:1852)(cid:4668)(cid:1861),(cid:1861)(cid:2870 ) ,(cid:1861)(cid:2871),…,(cid:1861)(cid:3045)(cid:4669 ) from each ( cid:1841)(cid:3002)(cid:3552 ) where ( cid:1852)(cid:1603)(cid:1835 ) ; and ( 2 ) a list of tag preferences ( cid:1850)(cid:4668),(cid:2870),(cid:2871),…,(cid:3046)(cid:4669 ) based on the maximum values of ( cid:3002)(cid:3552 ) which are sorted in descending order where ( cid:1850)(cid:1603)(cid:1846 ) of size such that |(cid:1850)| . The probabilistic model calculates the posterior probability , ( cid:1868)(cid:4666)(cid:1852)|(cid:1850)(cid:4667 ) using the Bayes’ theorem for predicting the class candidate item ( cid:1852 ) that have the highest posterior probability conditioned on ( cid:1850 ) . It is ( cid:1868)(cid:4666)(cid:1852)|(cid:1850)(cid:4667)(cid:1868)(cid:4666)(cid:1852)(cid:4667)(cid:1868)(cid:4666)(cid:1850)|(cid:1852)(cid:4667 ) ( 4 ) ( cid:1868)(cid:4666)(cid:1850)(cid:4667 ) Where prior ( cid:1868)(cid:4666)(cid:1852)(cid:4667 ) is the prior distributions of parameter set ( cid:1852 ) before ( cid:1850 ) is observed ; ( cid:1868)(cid:4666)(cid:1850)|(cid:1852)(cid:4667 ) is the likelihood probability of observing the tag preference ( cid:1850 ) given ( cid:1852 ) ; and ( cid:1868)(cid:4666)(cid:1850)(cid:4667 ) is the probability of observing the instance ( cid:1850 ) . We will use the posterior probability as the preference probability of user to select candidate item ( cid:1852 ) by observing the tagging activity data of user within ( cid:1827 ) . ( cid:1868),(cid:3293 ) of user who has tag preference ( cid:1850 ) on an item ( cid:1861)(cid:3045 ) by multiplying the prior probability of candidate item ( cid:1861)(cid:3045 ) , ( cid:1868)(cid:4666)(cid:1852)(cid:1861)(cid:3045)(cid:4667 ) , with the likelihood probability of tag preference ( cid:3030 ) within the candidate item ( cid:1861)(cid:3045 ) , ( cid:1868)(cid:4666)(cid:3030)|(cid:1852)(cid:1861)(cid:3045)(cid:4667 ) : ( cid:1868),(cid:3293)(cid:1868)(cid:4666)(cid:1861)(cid:3045)|(cid:1850)(cid:4667 ) ( cid:1868)(cid:4666)(cid:1852)(cid:1861)(cid:3045)(cid:4667)(cid:3537)(cid:1868)(cid:4666)(cid:3030)|(cid:1852)(cid:1861)(cid:3045)(cid:4667)(cid:3436)(cid:4672)∑ ( cid:4673)(cid:3440 ) ( 5 ) ( cid:3046 ) ( cid:3030)(cid:2880 ) Where ( cid:3028)(cid:4666),(cid:1499),(cid:3047)(cid:3278)(cid:4667 ) denotes the value of assignment ( cid:1827 ) for user who has used tag preference ( cid:3030 ) to tag any item ( cid:1861 ) . The ( cid:1868)(cid:4666)(cid:1852)(cid:1861)(cid:3045)(cid:4667 ) and ( cid:1868)(cid:4666)(cid:3030)|(cid:1852)(cid:1861)(cid:3045)(cid:4667 ) are determined as : ( cid:1868)(cid:4666)(cid:1852)(cid:1861)(cid:3045)(cid:4667 ) ∑ ( cid:3016)(cid:3276)(cid:4666)(cid:3296)(cid:1499),(cid:3284)(cid:3293)(cid:4667 ) ( 6 ) |(cid:3022)|(cid:2880 ) ∑ ∑ ( cid:3016)(cid:3276)(cid:4666)(cid:3296)(cid:1499),(cid:3284)(cid:1499)(cid:4667 ) |(cid:3022)|(cid:2880 ) |(cid:3010)|(cid:2880 ) 1(cid:3397)∑ ( cid:3028)(cid:4666)(cid:1499),(cid:3293),(cid:3047)(cid:3278)(cid:4667 ) ( cid:1868)(cid:4666)(cid:3030)|(cid:1852)(cid:1861)(cid:3045)(cid:4667 ) ( 7 ) |(cid:3022)|(cid:2880 ) |(cid:1846)|(cid:3397)∑ ∑ ( cid:3028)(cid:4666)(cid:1499),(cid:3293),(cid:3047)(cid:1499)(cid:4667 ) ||(cid:3047)(cid:2880 ) |(cid:3022)|(cid:2880 ) Where ( cid:3016)(cid:3276)(cid:4666)(cid:3296)(cid:1499),(cid:3284)(cid:3293)(cid:4667 ) and ( cid:3016)(cid:3276)(cid:4666)(cid:3296)(cid:1499),(cid:3284)(cid:1499)(cid:4667 ) denote the value of post ( cid:1841)(cid:3002 ) for any user who has tagged candidate item ( cid:1861)(cid:3045 ) and any item ( cid:1861 ) , respectively . The ( cid:3028)(cid:4666)(cid:1499),(cid:3293),(cid:3047)(cid:3278)(cid:4667 ) and ( cid:3028)(cid:4666)(cid:1499),(cid:3293),(cid:3047)(cid:1499)(cid:4667 ) denote the value of assignment ( cid:1827 ) where the candidate item ( cid:1861)(cid:3045 ) has been tagged by any user using tag preference ( cid:3030 ) and any tag , respectively . We apply the
Using the assumption of multinomial event model distribution for the Naïve Bayes classifier , we calculate the posterior probability
( cid:3276)(cid:4666)(cid:3296),(cid:3284)(cid:1499),(cid:3295)(cid:3278)(cid:4667 )
|(cid:3258)|(cid:3284)(cid:3128)(cid:3117 ) scribed in Figure 3 . b . Size reduction by choosing : a . Left singular factor matrices :
( cid:3028)(cid:4666)(cid:1499),(cid:3293),(cid:3047)(cid:3278)(cid:4667 )
Algorithm : Tensor based Recommendation using Probabilistic Ranking ( TRPR ) in Equation ( 5 ) and ∑ |(cid:3022)|(cid:2880 )
Laplacean estimate [ 18 ] as a smoothing method by adding one to in Equation ( 7 ) to avoid zero values . When the probabilities of a target user for items are calculated , the list of recommended items are sorted in descending order
∑ ( cid:3028)(cid:4666),(cid:1499),(cid:3047)(cid:3278)(cid:4667 ) |(cid:3010)|(cid:2880 ) based on the values of ( cid:1868),(cid:3293 ) . The Top (cid:1840 ) recommendation is an ordered set of ( cid:1840 ) items , ( cid:1846)(cid:1867)(cid:1868)(cid:1840 ) , that may be of interest to the target user . The complete algorithm of TRPR method is deInput : Tag assignment triplets ( (cid:1827 ) ) with |(cid:1847)| , |(cid:1835)| , and |(cid:1846)| as the number of users , items and tags ; block strip row size ( (cid:1869) ) , |(cid:1846)| ( cid:1856)(cid:1861 ) ( cid:1869)(cid:1840 ) and |(cid:1846)| ( cid:1865)(cid:1867)(cid:1856 ) ( cid:1869)0 ; tag preference size ( ) Output : ( cid:1846)(cid:1867)(cid:1868)(cid:1840 ) list of item recommendation 1 . Construct initial tensor ( cid:2291)(cid:1488)(cid:1337)(cid:3022)(cid:3400)(cid:3010)(cid:3400 ) from ( cid:1827 ) where each element presents the existence of user who has tagged item ( cid:1861 ) with tag 2 . Apply a decomposition technique to tensor ( cid:2291 ) to get : ( cid:1839)(cid:3022),(cid:1839)(cid:3010),(cid:1839 ) ( cid:1488)(cid:4668)1,|(cid:1847)|(cid:4669),(cid:1863)(cid:1488)(cid:4668)1,|(cid:1835)|(cid:4669),(cid:1864)(cid:1488)(cid:4668)1,|(cid:1846)|(cid:4669 ) ( cid:3022)(cid:1488)(cid:1337)(cid:3022)(cid:3400),(cid:3010 ) ( cid:1488)(cid:1337)(cid:3010)(cid:3400)(cid:3038),(cid:1488)(cid:1337)(cid:3400)(cid:3039 ) ( cid:1829 )  ( cid:2291)(cid:3400)(cid:3022)(cid:1314)(cid:3400)(cid:2870)(cid:3010)(cid:1314)(cid:3400)(cid:2871)(cid:1314 ) where ( cid:1829 ) ( cid:1488)(cid:1337)(cid:3400)(cid:3038)(cid:3400)(cid:3039 ) a . 1 mode ( matrix ) product : ( cid:2291)(cid:3554) ( cid:1829)(cid:3400)(cid:3022 ) , ( cid:2291)(cid:3552)(cid:1488)(cid:1337)(cid:3022)(cid:3400)(cid:3038)(cid:3400)(cid:3039 ) ; Clear ( cid:1829 ) b . 2 mode ( matrix ) product : ( cid:2291)(cid:2870)(cid:3554 )  ( cid:2291)(cid:3554)(cid:3400)(cid:2870)(cid:3010 ) , ( cid:2291)(cid:2870)(cid:3554)(cid:1488)(cid:1337)(cid:3022)(cid:3400)(cid:3010)(cid:3400)(cid:3039 ) ; Clear ( cid:2291)(cid:3554 ) c . For  1 to ( cid:1840 ) ( cid:1849 )  ( cid:3435)(cid:4666)(cid:4667)(cid:3044),(cid:3039)(cid:3439 ) , ( cid:1849)(cid:1488)(cid:1337)(cid:3044)(cid:3400)(cid:3039 ) 3 mode block ( matrix ) product : ( cid:2291)(cid:2871)(cid:3554 ) ( cid:1370)(cid:2291)(cid:2870)(cid:3554)(cid:3400)(cid:2871)(cid:1849 ) , ( cid:2291)(cid:2871)(cid:3554 ) ( cid:1488)(cid:1337)(cid:3022)(cid:3400)(cid:3010)(cid:3400)(cid:3044 ) ; ( cid:2291)(cid:3552 )  ( cid:2291)(cid:2871)(cid:3554 ) ; Clear ( cid:1849 ) , ( cid:2291)(cid:2871)(cid:3554 ) End for /* ( cid:2291)(cid:3552)(cid:1488)(cid:1337)(cid:3022)(cid:3400)(cid:3010)(cid:3400 ) */ ( cid:1852 )  new item in ( cid:1841)(cid:3002)(cid:3552 ) from ( cid:2291)(cid:3552 ) with ( cid:1841)(cid:3002)(cid:3552)(cid:1841)(cid:3002 ) 5 . Get the list of tag preferences such that ( |(cid:1850)| ) : ( cid:1850 )  max(cid:3250)(cid:3553)(cid:2291)(cid:3552 ) with ( cid:1841)(cid:3002)(cid:3552)(cid:1841)(cid:3002 ) ( cid:1868),(cid:3293) ( cid:1868)(cid:4666)(cid:1861)(cid:3045)(cid:4667)(cid:1868)(cid:4666)(cid:1850)(cid:4667 ) 7 . Generate Top (cid:1840 ) item recommendation using posterior If ( cid:1868),(cid:3293)(cid:1488)(cid:1846)(cid:1867)(cid:1868)(cid:1840 ) then ( cid:1846)(cid:1867)(cid:1868)(cid:1840 )  ( cid:1846)(cid:1867)(cid:1868)(cid:1840)(cid:1515)(cid:4668)(cid:1861)(cid:3045)(cid:4669 )
6 . Calculate posterior probability of each item in candidate
4 . Get the list of candidate items :
The reduced matrices : c . Core tensor :
3 . Reconstruct tensor : item list : probability value :
End if
Figure 3 : The Algorithm of TRPR Method
Example : Recommendation Generation . The reconstructed tensor of toy problem as shown in Table 2 generates three new entries that correspond to User 2 and User 3 . In order to generate
Top (cid:1840 ) list of items , we derive the list of candidate items and tag preferences for both users . User 2 ( cid:4666)(cid:2870)(cid:4667 ) gets candidate items , ( cid:1852)(cid:2870)(cid:4668)(cid:1861)(cid:2870),(cid:1861)(cid:2871)(cid:4669 ) , and tag preferences ( cid:1850)(cid:2870)(cid:4668)(cid:2870),(cid:2873)(cid:4669 ) . User 3 ( cid:4666)(cid:2871)(cid:4667 ) receives candidate item , ( cid:1852)(cid:2871)(cid:4668)(cid:1861)(cid:2870)(cid:4669 ) , and tag preference ( cid:1850)(cid:2871)(cid:4668)(cid:2873)(cid:4669 ) .
Equation 5 is used to calculate the posterior probability values of
808 ( cid:2870 ) of item ( cid:1861)(cid:2870 ) and item ( cid:1861)(cid:2871 ) . Since ( cid:1868)(cid:3118),(cid:3118 ) : 0.0063 > ( cid:1868)(cid:3118),(cid:3119 ) : 0.0031 , item ( cid:1861)(cid:2870 ) is more likely to interest user ( cid:2870 ) than ( cid:1861)(cid:2871 ) . As a result , the Top (cid:1840 ) list of recommended items to ( cid:2870 ) shall be in the sequence order of ( cid:1861)(cid:2870 ) , ( cid:1861)(cid:2871 ) . This result differs from the existing tensor based recommendation approaches which rank the Top (cid:1840 ) list of recommended items to ( cid:2870 ) as a sequence order of ( cid:1861)(cid:2871 ) , ( cid:1861)(cid:2870 ) .
4 . EXPERIMENTAL RESULT 4.1 Dataset and Evaluation Criteria We Delicious from ( hhtp://delicious.com/ ) and LastFM ( http://wwwlastfm/ ) websites for the experiments . The datasets are refined by selecting users , items , and tags that have occurred in at least ( cid:1863 ) number of real world datasets used
Score . F1 Score is a harmonic mean of overall precision and recall . Precision is the ratio of number of relevant items ( all items posts from the original set . The Delicious dataset is generated with 32,839 tag assignments and 17,077 posts resulted from 15 posts refinement , and is consisted of 1,609 users , 719 items and 1,761 tags . The LastFM dataset is generated with 99,211 tag assignments and 37,163 posts resulted from 10 posts refinement , and is consisted of 867 users , 1,715 items and 1,423 tags . To evaluate the quality of recommendation , we implemented 2fold cross validation and divided the dataset randomly into a training set ( cid:1830)(cid:3047)(cid:3045)(cid:3028 ) ( 80 % ) and a test set ( cid:1830)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) ( cid:4666)20 % ) based on the number of posts data . ( cid:1830)(cid:3047)(cid:3045)(cid:3028 ) and ( cid:1830)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) do not overlap in posts , ie , there exist no triplets for a user item combination ( cid:4666),(cid:1861)(cid:4667 ) in the training set if a triplet ( cid:4666),(cid:1861),(cid:1499)(cid:4667 ) is present in the test set . The recommendation task is to predict and rank the Top (cid:1840 ) items for the users present in ( cid:1830)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) . The performance is measured using F1in the post by the user in ( cid:1830)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) ) in the Top (cid:1840 ) list to the total number of Top (cid:1840 ) recommended items . Recall is the ratio of the number of relevant items in the Top ( cid:1840 ) list to the total number of ( cid:1842)(cid:1857)(cid:1855)(cid:1861)(cid:1861)(cid:1867)(cid:4666)(cid:1830)(cid:3047)(cid:3032)(cid:3046)(cid:3047),(cid:1840)(cid:4667)(cid:1853)(cid:1859)(cid:4666),(cid:4667)(cid:1488)(cid:3005)(cid:3295)(cid:3280)(cid:3294)(cid:3295)|(cid:3032)(cid:3046)(cid:3047)(cid:3296)(cid:1514)(cid:3042)(cid:3043)(cid:3015)(cid:3296)| |(cid:3042)(cid:3043)(cid:3015)(cid:3296)| ( cid:1857)(cid:1855)(cid:1853)(cid:1864)(cid:1864)(cid:4666)(cid:1830)(cid:3047)(cid:3032)(cid:3046)(cid:3047),(cid:1840)(cid:4667)(cid:1853)(cid:1859)(cid:4666),(cid:4667)(cid:1488)(cid:3005)(cid:3295)(cid:3280)(cid:3294)(cid:3295)|(cid:3032)(cid:3046)(cid:3047)(cid:3296)(cid:1514)(cid:3042)(cid:3043)(cid:3015)(cid:3296)| |(cid:3032)(cid:3046)(cid:3047)(cid:3296)| ( cid:1832)1(cid:4666)(cid:1830)(cid:3047)(cid:3032)(cid:3046)(cid:3047),(cid:1840)(cid:4667)(cid:2870)· ( cid:3017)(cid:3045)(cid:3032)(cid:3030)(cid:3046)(cid:3042)(cid:4666)(cid:3005)(cid:3295)(cid:3280)(cid:3294)(cid:3295),(cid:3015)(cid:4667)· ( cid:3019)(cid:3032)(cid:3030)(cid:3028)(cid:3039)(cid:3039)(cid:4666)(cid:3005)(cid:3295)(cid:3280)(cid:3294)(cid:3295),(cid:3015)(cid:4667 ) ( cid:3017)(cid:3045)(cid:3032)(cid:3030)(cid:3046)(cid:3042)(cid:4666)(cid:3005)(cid:3295)(cid:3280)(cid:3294)(cid:3295),(cid:3015)(cid:4667)(cid:3019)(cid:3032)(cid:3030)(cid:3028)(cid:3039)(cid:3039)(cid:4666)(cid:3005)(cid:3295)(cid:3280)(cid:3294)(cid:3295),(cid:3015)(cid:4667 ) Where ( cid:1846)(cid:1857 ) is the set of items tagged by target user in the ( cid:1830)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) and ( cid:1846)(cid:1867)(cid:1868)(cid:1840 ) is the Top (cid:1840 ) list of items recommended to user from the reconstructed tensor ( cid:2291)(cid:3552 ) which do not exist in the original tensor ( cid:2291 ) . relevant items .
( 10 )
( 8 )
( 9 )
4.2 Benchmarking Methods Results of the proposed method are benchmarked with the standard tensor based method ( denoted as “ Max ” ) [ 5 ] and the state ofthe art matrix based method ( denoted as “ CTS ” ) [ 4 ] . We also used other tensor based methods which applied CP and HOOI decomposition techniques ( denoted as “ CP ” and “ HOOI ” ) for benchmarking . Decomposition techniques were implemented using Matlab Tensor Toolbox [ 19 ] .
4.3 Empirical Analysis Firstly , we evaluate the effectiveness of TRPR method for large size tensor reconstruction by comparing the scalability of TRPR with the Max method [ 5 ] . Using the 15 , 50 , 80 and 100 post refinements ( selecting users , items , and tags that have occurred in dimensions for the Delicious dataset . The four tensor models were at least ( cid:1863 ) number of posts ) , we built the tensor models of different of 1,609(cid:3400)719(cid:3400)1,761 ; 665(cid:3400)52(cid:3400)422 ; 362(cid:3400)13(cid:3400)189 ; and 250(cid:3400)7(cid:3400)125 dimension sizes which give the tensor total dimension sizes of 2,037,249,831 ; 14,592,760 ; 889,434 ; and 218,750 , respectively . Accordingly , the bigger the number of ( cid:1863 ) ( when tensor total dimension size is 2,037,249,831 derived with ( cid:1863 ) being used , the smaller the tensor total dimension size is achieved . Figure 4 demonstrates the scalability analysis of TRPR and Max methods on a single processor . Note that for the largest data
= 15 ) , only TRPR can run while the Max method failed due to memory overflow . The trends show that TRPR is scalable for large tensor size with a linear time computation to the tensor total dimensionality size . The implementation of the block matrix operation [ 16 ] simplifies the conventional 3 mode ( matrix ) product into a memory efficient loop approach . This result also confirms that it is not feasible to apply Tensor models directly on the large datasets as used in this paper .
10,000
100
1
0 218,750
 
0 0 1 x   ) c e s (   e m i t n u r   g o l
CPU Runtime
Out of Memory
TRPR Max [5 ]
889,434
14,592,760 Tensor Total Dimension Sizes
2,037,249,831
Figure 4 : Scalability Comparison by Varying the Tensor Total
Dimensionality Sizes of the Delicious Dataset
Delicious
TRPR CP HOOI Max [5 ] CTS [4 ]
4.0
2.0
1.0
)
%
(   e r o c S ‐ 1 F
5
10
15
20 25 Top‐N
50
100 all
Figure 5 : F1 Score Comparison on Top N list of Recommen dations on Delicious Dataset
LastFM
TRPR CP HOOI Max [5 ] CTS [4 ]
4.0
2.0
1.0
)
%
(   e r o c S ‐ 1 F
5
10
15
20 25 Top‐N
50
100 all
Figure 6 : F1 Score Comparison on Top N list of Recommen dation on LastFM Dataset
809 In order to compare the recommendation quality , we had to implement the block striped parallel matrix multiplication for scalable tensor reconstruction to the tensor based benchmarking methods making it applicable for Delicious and LastFM datasets . Us ing F1 score values , we compare the Top (cid:1840 ) lists recommendation quality between TRPR and the benchmarking methods . Figure 5 shows that the proposed method outperforms the benchmarking methods on the Delicious dataset . Likewise , on the LastFM dataset ( Figure 6 ) , TRPR is superior compared to other methods , although Max [ 5 ] performance is quite comparable with it . It is to be noted that , in general , F1 Scores achieved for the offline experiments are low . Our experimental setting may be the reason behind this as the dataset has been randomly divided into ( cid:1830)(cid:3047)(cid:3045)(cid:3028 ) and ( cid:1830)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) based on the number of posts data . This does not guarantee that for each user in ( cid:1830)(cid:3047)(cid:3045)(cid:3028 ) , at least one of its post will be selected as ( cid:1830)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) . Consequently , a target user in ( cid:1830)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) may not possibly exist in ( cid:1830)(cid:3047)(cid:3045)(cid:3028 ) ( the target user is actually a completely new user ) .
5 . CONCLUSION AND FUTURE WORK For generating item recommendation in the Social Tagging Systems , we proposed a novel Tensor based Recommendation using Probabilistic Ranking ( TRPR ) method by addressing the scalability and accuracy challenges in using tensor models . TRPR developed the simple but effective concept of block striped parallel matrix multiplication to enable scalable tensor reconstruction as well as it advanced the concept of probabilistic ranking to achieve higher recommendation accuracy . The proposed method is extensively evaluated with the real world datasets and compared with the state of the art benchmarking methods . Empirical analysis shows that the proposed method is scalable and is able to outperform the benchmarking methods in terms of accuracy . This ascertains that recommendation quality can be improved by using the probabilistic approach after tensor reconstruction . In the future , we are planning to combine the before and after tensor reconstruction approaches by implementing a semantic tag clustering method before we build the tensor model .
6 . ACKNOWLEDGEMENTS This work is supported by the Directorate General of Higher Education ( DGHE ) Indonesia . Computational resources and services were provided by the HPC and Research Support Group , Queensland University of Technology , Brisbane , Australia .
7 . REFERENCE [ 1 ] Mezghani , M . , Zayani , CA , Amous , I . , and Gargouri , F . A User Profile Modelling using Social Annotations : A Survey . In Proceedings of The 21st International Conference Companion on World Wide Web , pages 969 976 , Lyon , France , 2012 .
[ 2 ] Lü , L . , Medo , M . , Yeung , CH , Zhang , Y C , Zhang , Z K , and Zhou , T . , Recommender Systems . Physics Reports , 519(1 ) : 1 49 , 2012 .
[ 3 ] Zhang , Z K , Zhou , T . , and Zhang , Y C , Tag Aware
Recommender Systems : A State of the Art Survey . Journal of Computer Science and Technology , 26(5 ) : 767 777 , 2011 .
[ 4 ] Kim , H N , Ji , A T , Ha , I . , and Jo , G S , Collaborative
Filtering based on Collaborative Tagging for Enhancing the Quality of Recommendation . Electronic Commerce Research and Applications , 9(1 ) : 73 83 , 2010 .
[ 5 ] Symeonidis , P . , Nanopoulos , A . , and Manolopoulos , Y . , A
Unified Framework for Providing Recommendations in Social Tagging Systems Based on Ternary Semantic Analysis . IEEE Transactions on Knowledge and Data Engineering , 22(2 ) : 179 192 , 2010 .
[ 6 ] Rafailidis , D . and Daras , P . , The TFC Model : Tensor
Factorization and Tag Clustering for Item Recommendation in Social Tagging Systems . IEEE Transactions on Systems , Man and Cybernetics , Part A : Systems and Humans , 43(3 ) : 673 688 , 2013 .
[ 7 ] Kolda , T . and Bader , B . , Tensor Decompositions and
Applications . SIAM Review , 51(3 ) : 455 500 , 2009 .
[ 8 ] Leginus , M . , Dolog , P . , and Žemaitis , V . , Improving Tensor
Based Recommenders with Clustering . In User Modeling , Adaptation , and Personalization , pages 151 163 , Springer Berlin Heidelberg , 2012 .
[ 9 ] Nanopoulos , A . , Item Recommendation in Collaborative
Tagging Systems . IEEE Transactions on Systems , Man and Cybernetics , Part A : Systems and Humans , 41(4 ) : 760 771 , 2011 .
[ 10 ] Kutty , S . , Chen , L . , and Nayak , R . A People to people
Recommendation System using Tensor Space Models . In Proceedings of The 27th Annual ACM Symposium on Applied Computing , pages 187 192 , Trento , Italy , 2012 .
[ 11 ] Kolda , TG and Sun , J . Scalable Tensor Decompositions for Multi aspect Data Mining . In Proceedings of The 8th IEEE International Conference on Data Mining , pages 363 372 , Pisa , Italy , 2008 .
[ 12 ] Symeonidis , P . , Nanopoulos , A . , and Manolopoulos , Y . Tag
Recommendations based on Tensor Dimensionality Reduction . In Proceedings of The 2008 ACM Conference on Recommender Systems , pages 43 50 , Lausanne , Switzerland , 2008 .
[ 13 ] Rendle , S . and Schmidt Thieme , L . Pairwise Interaction
Tensor Factorization for Personalized Tag Recommendation . In Proceedings of The 3rd ACM International Conference on Web Search and Data Mining , pages 81 90 , New York , USA , 2010 .
[ 14 ] Peng , J . , Zeng , DD , Zhao , H . , and Wang , F y
Collaborative Filtering in Social Tagging Systems based on Joint Item Tag Recommendations . In Proceedings of The 19th ACM International Conference on Information and Knowledge Management , pages 809 818 , Toronto , Canada , 2010 .
[ 15 ] Jain , V . and Varma , M . Learning to Re rank : Query dependent Image Re ranking using Click Data . In Proceedings of The 20th International Conference on World Wide Web , pages 277 286 , Hyderabad , India , 2011 .
[ 16 ] Golub , GH and Loan . , CFV , Matrix Computations , 4 ed .
Baltimore , Maryland , The John Hopkins University Press , 2013 .
[ 17 ] Baker , LD and McCallum , AK Distributional Clustering of Words for Text Classification . In Proceedings of The 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval , pages 96 103 , Melbourne , Australia , 1998 .
[ 18 ] Lops , P . , Gemmis , M . , and Semeraro , G . , Content based
Recommender Systems : State of the Art and Trends . In Recommender Systems Handbook , pages 73 105 , Springer US , 2011 .
[ 19 ] Bader , BW , Kolda , TG , and others . MATLAB Tensor Toolbox Version 25 [ Available online , January 2012 ] , URL : http://wwwsandiagov/~tgkolda/TensorToolbox/
810
