.,I);‘ ) ; : ,‘,/
‘ , ,
, , , From : KDD 96 Proceedings . Copyright © 1996 , AAAI ( wwwaaaiorg ) All rights reserved .
Automated
Discovery of Medical Expert
System
Rules from Clinical Databases based on Rough Sets
Shusaku Tsumoto and .Hiroshi Tanaka
Department of Information Medicine , Medical Research Institute ,
Tokyo Medical and Dental University , l 5 45 Yushima , Bunkyo city Tokyo 113 Japan .
E mail : tsumotocom@mritmdacjp , tanaka@cimtmdacjp
Abstract
Automated knowledge acquisition is an important research issue to solve the bottleneck problem in developing expert systems . Although many inductive learning methods have been proposed for this purpose , most of the approaches focus only on inducing classification rules . However , medical experts also learn other information important for diagnosis from clinical cases . In this paper , a rule induction method is introduced , which extracts not only classification rules but also other medical knowledge needed for diagnosis . This system is evaluated on a clinical database of headache , whose experimental results show that our proposed method correctly induces diagnostic rules and estimates the statistical measures of rules .
Introduct ion
One of the most important problems in developing expert systems is knowledge acquisition from experts(Buchanan and Shortliffe 1984 ) . In order to automate this problem , many inductive learning methods , such as induction of decision trees(Breiman , et al . 1984 ; Quinlan 1993 ) ) rule induction methods(Michalski 1983 ; Michalski , et al . 1986 ; Quinlan 1993 ) and rough set theory(Pawlak 1991 ; Ziarko 1993 ) , are introduced and applied to extract knowledge from databases , which shows that these methods are appropriate .
However , most of the approaches focus only on inducing classification rules , although medical experts also learn other information important for medical diagnostic procedures . Focusing on their learning procedures , Matsumura et al . propose a diagnostic model , which consists of three reasoning processes , and develop an expert system , called RHINOS( Rule based Headache and facial pain INformation Organizing System ) ( Matsumura , et al . 1986 ) .
Since RHINOS diagnostic processes are found to be based on the concepts of set theory , it is expected that a set theoretic approach can describe this diagnostic model and knowledge acquisition procedures .
In order to characterize these procedures , we introduce the concepts of rough set theory , which clarifies set theoretic characteristics of the classes over combinatorial patterns of the attributes , precisely discussed by ( Pawlak 1991 ) . Based on this theory , we develop a program , called PRIMEROSE REX ( Probabilistic Rule Induction Method based on Rough Sets and Resampling methods for Expert systems ) , which extracts rules for an expert system from clinical databases , and applies resampling methods to the estimation certainty factors of derived ru1es.r
This system is evaluated on the datasets of RHINOS domain . The results show that the proposed method induces RHINOS diagnostic rules correctly from databases and that resampling methods can estimate the performance of these rules and certainty factors .
The paper is organized as follows : in Section 2 , we discuss RHINOS diagnostic model . Section 3 shows rough set theory and representation of RHINOS rules based on this theory . Section 4 presents an algorithm for induction of RHINOS diagnostic rules . Section 5 gives experimental results . Section 6 and Section 7 discusses the problems of our work and related work , respectively . Finally , Section 8 concludes this paper .
RHINOS
RHINOS is an expert system which diagnoses clinical cases on headache or facial pain from manifestations . In this system , a diagnostic model proposed by Matsumura(Matsumura , et al . 1986 ) consists of the following three kinds of reasoning processes : exclusive reasoning , inclusive reasoning , and reasoning about complications .
First , exclusive reasoning excludes a disease from candidates when a patient does not have a symptom which is necessary to diagnose . Secondly , inclusive reasoning suspects a disease in the output of the exclusive process when a patient has symptoms specific to a disease . Finally , reasoning about complications suspects complications of other diseases when some symptoms which cannot be explained by the diagnostic conclusion are obtained .
‘This system is an extension of PRIMEROSE , which induces classification rules from databases , based on rough sets and resampling methods(Tsumoto and Tanaka 1995 ) .
Data Mining Applications
63
Each reasoning is rule based , and all the rules needed for the diagnostic processes are acquired from medical experts in the following way .
Rules
The premise of an exclusive ( 1)Exclusive rule is equivalent to the necessity condition of a diagnostic conclusion . From the discussion with medical experts , we select the following six basic attributes which are minimally indispensable to defining the necessity condition : 1 . Age , 2 . Pain location , 3 . Nature of the pain , 4 . Severity of the pain , 5 . History since onset , 6 . Existence of jolt headache . For example , the exclusive rule of common migraine is defined as : In order the pain nature history : jolt to suspect common migraine , symptoms are required : not eyes , or or sudden and following location : or persistent paroxysmal headache :
:throbbing radiating , positive .
One of the reason why we select the six attributes is to solve the interface problem of expert systems : if the whole attributes are considered , we also have to input the symptoms which are not needed for diagnosis . To make exclusive reasoning compact , the only minimal requirements are chosen . It is notable that this kind of selection can be viewed as the ordering of given attributes , which can be induced from databases automatically . Therefore we intend td formulate induction of exclusive rules by using the whole given attributes . After the induction , the minimal requirements for describing exclusive rules can be acquired . the rule
This
Rules the probability is derived by asking
The premises of inclusive rules ( 2)Inclusive are composed of a set , of manifestations specific to a disease to be included . If a patient satisfies one set of symptoms , we suspect this disease with some probability . following items for each disease to the medical experts : 1 . a set of manifestations by which we strongly suspect a disease . 2 . that a patient has the disease this set of manifestations:SI(Satisfactory Index ) with 3 . the ratio of the patients who satisfy the set to all the patients of this disease:CI(Covering Index ) 4 . If is equal to 1.0 the total sum of the derived CI(tCI ) then end . Otherwise , goto 5 . 5 . For the patients of this disease who do not satisfy all the collected set of manifestations , goto 1 . Therefore a positive rule is described by a set of manifestations , its satisfactory index ( SI ) , which corresponds to accuracy measure , and its covering index ( CI ) , which corresponds to total posrate . Note that SI and CI are given empirically itive by medical experts .
For example , one of three positive rules for common is given as follows . migraine If history : nature : prodrome throbbing : no , paroxysmal , jolt headache : yes , or persistent , intermittent symptom : no ,
64
KDD 96
Tazle 1 : A Small Database age class 1 mch 1 mch migra 0 migra 0 1 mch 1 mch prod 0 0 1 1 0 0 nau Ml 0 0 1 1 0 1 nat per 1 50 59 occ 2 40 49 who per thr lat 3 40 49 thr 4 40 40 who 5 40 49 who rad 6 50 59 who per DEFINITIONS : prodrome , nau : nausea , Ml : who : whole , occ : occular , lat : lateral , per : persistent , thr : throbbing , rad : radiating , mch : muscle contraction headache , migra : migraine , 1 : Yes , 0 : No . lot : location , nat : nature , prod : tenderness of Ml , location : time : more not eye , persistent and then common migraine ( X=0.9 ) accuracy 60 percent the
0.9 of total than 6 hours , is suspected with and this cases rule ( CI=O6 ) covers
Image
This rule is used to detect com(3)Disease plications of multiple diseases , acquired fromm all the possible manifestations of the disease . Using this rule , we search for the manifestations which cannot be explained by the conclusions . Those symptoms suggest complications of other diseases . For example , the disease image of common migraine is : The following common migraine : depressing : symptoms can be explained any or pain jolt headache : location : yes or not or
. . . by
Therefore , when a patient who suffers from common that he or she it is suspected migraine may also have other disease . is depressing ,
As shown above , three kinds of rules are straightforward , and an inducing algorithm is expected to be implemented on computers easily . Thus , we introduce rough set theory in order to describe these algorithms as shown in the next section .
Formalization of Rules
Probabilistic
Rules
In order to describe three kinds of diagnostic rules , we first define probabilistic rules , using the following three notations of rough set theory(Pawlak 1991 ) . To illustrate the main ideas , we use a small database shown in Table 1 .
First , a combination of attribute value pairs , which is corresponding to a complex in AQ ( Michalski 1983 ) , is denoted by an equivalence relation Rf , which is defined as follows . Let U be a Definition universe , and V be a set of values . A total function f from U to V is called an assignment function of an
1 ( Equivalence
Relation ) iff j(u ) = j(v ) .
Then , we introduce an equivalence relation attribute . Rf such that for any u,v E U , uRfv For example , [ age = 50 59]&[loc = occular ] will be one equivalence relation , denoted by Rf = [ age = 50 59]&[Zoc = occular ] . Secondly , a set of samples which satisfy Rf corresponding to a star in AQ terminology . For example , when {2,3,4,5} is a set of samples which satisfy = 40 491 , [ ~1;1[~~~=40 49~ is denoted by [ z& , is equal to {2,3,4,5 ] .
Finally , thirdly , U , which stands for “ Universe ” , de age 6 notes all training samples .
Rules )
According to these notations , probabilistic rules are
2 ( Probabilistic defined as follows : Definition Let Rf be an equivalence relation specified by some assignment function j , D denote a set whose elements belong to a class d , or positive examples in all training samples ( the universe ) , U . Finally , let IDI denote the cardinality of is defined as a quadruD . A probabilistic ple , < Rf v d satisfies the following conditions : 3 d , ( YJQ ( D ) , IQ+(D ) > , where Rf v rule of D
In the above definition , Q corresponds to the accuracy measure : if Q! of a rule is equal to 0.9 , then the accuracy is also equal to 09 On the other hand , IG is a statistical measure of how proportion of D is covered by this rule , that is , a coverage or a true positive rate : when K is equal to 0.5 , half of the members of a class belong to the set whose members satisfy that equivalence relation .
For example , let us consider a case of a proposition [ age = 40 491 + mch Since [ ~][,~~=40 491 is equal to ( 2,3,4,5 ) and D is equal to {1,2,5,6} , = 0.5 and qage=40 4q@‘ ) = 2,5,6)l = 05 Thus , qage=40 491(D ) = if a patient , who complains a headache , is 40 to 49 years old , then mch is suspected , whose accuracy and coverage are equal to 05
1~~,5)1/1~~,3,4,5)1
I{23 5)1/l&
Diagnostic Rules
RHINOS By the use of these notations , RHINOS diagnostic rules are described in the following way .
21n this notation , “ n ” denotes the nth sample in a dataset ( Table 1 ) .
31t is notable that this rule is a kind of probabilistic proposition with two statistical measures , which is an extension of Ziarko ’s variable precision model(VPRS ) ( Ziarko 1993 ) .
( 1 ) Exclusive rules :
AVj
[ aj = vk ] , and FERN
R v d st R = &Ri = ( D ) = 10 4 In the above exam ple , the relation R for migraine is described as : [ age = 40 491 A ( [location = lateral ] V [ Eocation = whole ] ) A = paroxysmal ] V [ nature = [ history = yes ] A [ prod = yes ] A [ nau = yes ] A [ Ml = no ] A [ iId2 = no ] . throbbing ] A ( [history A [ jolt
= persistent ] )
Inclusive
( 2 ) v/if vk[O+ = Q ] , CIR~(D ) > & , rules :
R “ Ai d st R = viRi = and KR~(D ) > 6 , .
[ nature =
In the above example , the simplest relation R for migraine , is described as : throbbing ] V [ history = paroxysmal ] V bolt = yes ] V [ Ml = yes ] . However , induction of inclusive rules gives us two problems . First , SI and CI are overfitted to the training samples . Secondly , the above rule is only one of many rules which are induced from the above training samples . Therefore some of them should be selected from primary induced rules under some preference criterion . These problems will be discussed in the next section .
( 3 ) Disease ~j ] , and Q& ( D ) > 0 ( K& ( D ) > 0 ) .
Image :
R *1 ; ” d st R = VRiV[ai =
In the above example , the relation R for migraine is described as : [ age = 40 491 V [ location = lateral ] V [ location = whole ] V [ nature = throbbing ] V [ severity = strong ] V [ severity V [ nausea = yes ] V bolt = yes ] V [ Ml = no ] V jM2 = no ] . As shown in the formal definition of these rules , a coverage /CR ( 13 ) play an important role in ClaSSifiCatiOn of diagnostic rules .
= weak ] V [ history paroxysmal ]
=
Induction of Rules
An induction algorithm of RHINOS rules consists of two procedures . One is an exhaustive search procedure to induce the exclusive rule and the disease image for each disease through all the attribute value pairs , corresponding to selectors in AQ ( Michalski 1983 ) ) and the other is a postprocessing procedure to induce inclusive rules through the combinations of all the attributevalue pairs , which corresponds to complexes in AQ .
Search
Exhaustive Let D denote training samples of the target class d , or positive examples . This search procedure is defined as shown in Figure 1 . In the above example in Table 1 , let d be migraine and [ age = 40 491 be selected as [ ui = vj ] . Since the intersection [ ~]l,~~=40 49~ n D(=
4Strictly Speaking , this proposition should be written as : d + R . However , for comparison with other two rules , we choose this notation .
Data Mining Applications
65 procedure
Exhaustive Search ;
VEU begin
L : List ; /* A list of elementary relations */ L := PO ; w;Fg/f
/* PO : A list of elementary relations */ # 0 ) do
Select one pair [ ai = vj ] from L ; if ( [x][,~=~~I II D # 4 ) then do
/* D : a set if positive examples */ begin &j
:= Rdj V [ ai = vj ] ; /* Disease Image */ if ( qajcvjl(D ) > 6 , ) then Li , /* Candidates for Inclusive Rules */
:= Lo + {[ai = vj] ) ; if ( K[,+=~~I(D ) = 1.0 ) then Rer := R , , A [ ai = q ] ; /* Exclusive Rule */ end
L := L [ aj = vj ] ; end end {Exhaustive Search ) ;
Postprocesiing Procedure ;
‘ , procedure var begin
M , Li : List ; i : integer ; Lr := Li , ; /* Candidates for Inclusive Rules */ i := 1 ; M := {} ; i := 1 to n do for /* n : Total number of attributes */ begin
Select one pair R = A[ai = vj ] from Li ; Li := Li {R} ; if
( w(D ) > L ) do Si , then /* Include R as Inclusive Rule */
:= Si , + {R} ; else M := A4 + {R} ; end end
L i+~ := ( A list of the whole combination of the conjunction formulae in M ) ; end {Postprocessing Procedure } ;
Figure 1 : An Algorithm for Exhaustive Search
{3,4} ) is not equal to 4 , this pair is included in the disease image . However , since alage=4s 4gl(D ) = 0.5 , this pair is not included in the inclusive rule . Finally , since D c [ z]lase.4c 4sl ( = {2,3,4,5} ) , this pair is also included in the exclusive rule .
Next , the other attribute value pair for age , [ age = 50 591 is selected . However , this pair will be abandoned since the intersection of [ z]lage=50 5s~ and D is empty , or [ 4[age=50 59 ] n D = 4 .
When all the attribute value pairs are examined , not only the exclusive rule and disease image shown in the above section , but also the candidates of inclusive rules are also derived . The latter ones are used as inputs of the second procedure .
Procedure
Postprocessing Because the definition of inclusive rules is a little weak , many inclusive rules can be obtained . In the above example , an equivalence relation [ nau = l ] satisfies D fl [ x ] naU=rl # 4 , so it is also one of the inclusive rules o 1 “ mch “ , although SI of that rule is equal to l/3 . In order to suppress induction of such rules , which have low classificatory power , only equivalence relations whose SI is larger than 0.5 are selected . For example , since the above relation [ age = 40 491 is less than this precision , it is eliminated from the candidates of inclusive rules . Furthermore , PRIMEROSE REX minimizes the number of attributes not to include the attributes which do not gain the classificatory power , called dependent variables . This procedure can be described as shown in Figure 2 . In the above example in Table 1 , the coverage of an attribute value pair [ prod =
66
KDD 96
Figure 2 : An Algorithm for Postprocessing Procedure
0 ] for “ mch ” takes a maximum value . Furthermore , since the accuracy ~h,~~d=s ( D ) is equal to 1.0 , it is included in inclusive rules o 1 “ mch ” . The next maximum one is [ Ml = 11 , whose coverage is equal to 10 Since this accuracy is also equal to 1.0 , it is also included in inclusive rules . At this point , we have two inclusive rules as follows : [ prod = 0 ] a=l’Y=l’O “ 7nch ” and [ Ml = l ] or=l’~=l’o “ mch ” Repeating these procedures , all the inclusive rules are acquired . samples . of Statistical Measures
Estimation The above definition of statistical measures shows that small training samples causes their overestimation . In the above example , both of the measures are equal to 10 This means that this rule correctly diagnoses and covers all the cases of the migrane . However , in general , these meanings hold only in the world of the small training In this sense , accuracy and coverage are biased . Thus , we should correct these biases by introducing other estimating methods , since the biases cannot be detected by the induced method . Note that this problem is similar to that of error rates of discriminant function in multivariate analysis ( Efron 1982 ) , the field in which resampling methods are reported to be useful for the estimation .
Hence the resampling methods are applied to estimation of accuracy and coverage , as shown in the following subsection . and the Bootstrap
Cross Validation Cross validation method for error estimation is performed as following : first , all training samples C are split into V blocks : {Lr , La , a . . , Lv} . Secondly , repeat for V times the procedure in which rules are induced from the training samples .C L ; ( i = 1 , . . . , V ) and examine the error rate erri of the rules using Ci as test samples . Finally , the whole error rate err is derived by averaging erri over i , that is , err = CF= , em i/V ( this method is called V fold cross validation ) . Therefore this method for estimation of coverage and accuracy can be used by replacing the calculation of err by that of coverage and accuracy , and by regarding test samples as unobserved cases .
On the other hand , the Bootstrap method is executed as follows : first , empirical probabilistic distribution ( Fn ) is generated from the original training samples ( Efron 1982 ) . Secondly , the Monte Carlo method is applied and training samples are randomly taken by using Fn . Thirdly , rules are induced by using new training samples . Finally , these results are tested by the original training samples and statistical measures , such as error rate are calculated . These four steps are iterated for finite times . Empirically , it is shown that repeating these steps for 200 times is sufficient for estimation ( Efron 1982 ) .
Interestingly , Efron shows that estimators by 2 fold cross validation are asymptotically equal to predictive estimators for completely new pattern of data , and that Bootstrap estimators are asymptotically equal to maximum likelihood estimators and are a little overfitted to training samples ( Efron 1982 ) . Hence , the former estimators can be used as the lower bounds of both measures , and the latter as their upper bounds . Furthermore , in order to reduce the high variance of estimators by cross validation , we introduce repeated cross validation method , which is firstly introduced by Walker ( Walker and Olshen 1992 ) . In this method , cross validation methods are executed repeatedly ( safely , 100 times)(Tsumoto and Tanaka 1995 ) , and estimates are averaged over all the trials . In summary , since our strategy is to avoid the overestimation and the high variabilities , combination of repeated a fold cross validation and the Bootstrap method is adopted in this paper .
Experimental
Results to the following three We apply PRIMEROSE REX medical domains : headache(RHINOS domain ) , whose training samples consist of 1477 samples , 10 classes , and 20 attributes , cerebulovasular diseases , whose training samples consist of 620 samples , 15 classes , and 25 attributes , and meningitis , whose training samples consists of 213 samples , 3 classes , and 27 attributes . In these experiments , 6 , and S , are set to 0.75 and 0.5 , respectively . The experiments are performed by the following four procedures . First , these samples are randomly split into half ( new training samples ) and half ( new test samples ) . For example , 1477 samples are split into 738 training samples and 739 training samples . Secondly , PRIMEROSE REX , AQ15 and CART are applied to the new training samples . Thirdly ,
ER A
DI A 93.2 % 97.4 %
Table 2 : Experimental Results ( Headache ) IR A Method PIE REX 95.0 % 88.3 % 98.0 % 95.0 % Experts CART 85.8 % AQ15 86.2 % R CV 78.7 % 72.9 % BS 98.4 % 91.6 % DEFINITIONS : PR REX : PRIMEROSE REX , ER A : Exclusive Rule Accuracy , IR A : Inclusive Rule Accuracy , DI A : Disease Image Accuracy
83.8 % 95.6 %
Table 3 : Experimental Results ( Cerebulovasculuar Diseases )
Method PR REX Experts CART AQ15 R CV BS
IR A
ER A DI A 91.0 % 84.3 % 94.3 % 97.5 % 92.9 % 93.6 %
79.7 % 78.9 % 78.7 %
72.9 % 83.8 % 93.4 % 92.5 % 95.9 % the repeated cross validation method and the bootstrap method are applied to the new training samples in order to estimate the accuracy and coverage of PRIMEROSE REX . Finally , the induced results are tested by the new test samples . These procedures are repeated for 100 times and all the estimators are averaged over 100 trials .
Experimental results are shown in Table 2 to 4 . Exclusive rule accuracy(ER A ) means how many training samples that do not belong to a class are excluded correctly from the candidates . Inclusive rule accuracy(IR A ) is equivalent to the averaged classification accuracy . Finally , disease image accuracy(DIA ) shows how many symptoms , which cannot be explained by diagnostic conclusions , are detected by the disease image . The first row is the results obtained by using PRIMROSE REX , and the second one is the results derived from medical experts . And , for comparison , we compare the classification accuracy of inclusive rules with that of CART and A& 15 , which is shown in the third and fourth row . Finally , in the fifth and sixth row , we present the results of estimation by repeated cross validation method ( R CV ) and the bootstrap method ( BS ) . These results can be summarized to the following three points . First , the induced rules perform a little worse than those of medical experts . Secondly , our method performs a little better than classical empirical learning methods , CART and AQ15 . Finally , thirdly , R CV estimator and BS estimator can be regarded as the lower boundary and
Data Mining Applications
67
Table 4 : Experimental Results ( Meningitis )
Method PR REX Experts CART AQ15 R CV BS
IR A
DI A ER A 88.9 % 82.5 % 92.6 % 95.4 % 93.2 % 96.7 %
81.4 % 82.5 %
64.3 % 61.3 % 73.8 % 89.5 % 93.2 % 98.2 % the upper boundary of each rule accuracy . Hence the interval of these two estimators can be used as the estimators of accuracy and coverage of each rule .
Discussion
Rule
Exclusive As discussed in Section 3 , we intend to formulate induction of exclusive rules by using the whole given attributes , although the original exclusive rules are described by the six basic questions . Therefore induced exclusive rules have the maximum number of attributes whose conjunction R also satisfies ICR(D ) = 10 If this maximum combination includes the six basic attributes as a subset , then this selection of basic attributes is one of good choices of attributes , although redundant . Otherwise , the given six attributes may be redundant or the induced results may be insufficient . For the above example shown in Table 1 , the maximum combination of attributes is {age , location , nature , history , jolt , prod , nau , Ml , M2 } . 5 Since this set does not include an attribute “ severity ” , the six given attributes or the induced results are insufficient in this small database . In this case , however , the sixth attributes are acquired by medical experts through a large number of experienced cases . Thus , the induced attributes should be revised by using additional samples in the future .
On the contrary , in the database on headache , the maximum combination is 13 attributes , derived as follows : Age , Pain location , Nature of the pain , Severity of the pain , History since onset , Existence of jolt headache , Tendency of depression , and Tenderness of Ml to M6 , which is a superset of the six basic attributes . Thus , this selection can be a good choice .
In this way , the induction of maximum combination can be also used as a “ rough ” check of induced results or our diagnosing model on exclusive rules , which can be formulated in the following way . 6
Let A and E denote a set of the induced attributes for exclusive rules and a set of attributes acquired from ‘Severity cannot be a member , since [ sewer = weak ] V
[ sewer = strong ] is included in both exclusive rules . ‘This discussion assumes that the whole attributes are sufficient to classify the present and the future cases into given classes .
68
KDD 96 domain experts . Thus , the following four relations can be considered . First , if A c E , then A is insufficient or E is redundant . Second , if A = E , then both sets are sufficient to represent a diagnosing model in an applied domain . Third , if A > E , then A is redundant or E is insufficient . Finally , fourth , if intersection of A and E is not empty ( An E # b ) , then either or both sets are insufficient .
Reader may say that the above relations are weak and indeterminate . However , the above indefinite parts should be constrained by information on domain knowledge . For example , let us consider the case when A C E . When E is validated by experts , A is insufficient in the first relation . However , in general , E can be viewed as A obtained by large samples , and A > E should hold , which shows that a given database is problematic . Moreover , the constraint on exclusive rules , KR(D ) = 1.0 , suggests that there exist a class which does not appear in the database , because the already given classes cannot support &R(D ) = 1.0 , that is , [ + n D # D will hold in the future .
On the other hand , when E is not well given by experts and A is induced from sufficiently large samples , E will be redundant , which means that the proposed model for E does not fit to this database or this domain .
This kind of knowledge is important , because we sometimes need to know whether samples are enough to induce knowledge and whether an applied inducing model is useful to analyze databases .
Thus , the above four relations give a simple examination to check the characteristics of samples and the applicability of a given diagnosing model . It is our future work to develop more precise checking methodology for automated knowledge acquisition .
Related Work
Rules of Association
Discovery Mannila et al.(Mannila , et al . 1994 ) report a new algorithm for discovery of association rules , which is one class of regularities , introduced by Agrawal et al.(Agrawal , et al . 1993 ) . Their method is very similar to our method with respect to the use of set theoretical operations .
Rules :
The concept of association ( 1 ) Association rules is similar to our induced rules . Actually , association rules can be described in the rough set framework . That is , we say that an association rule over T ( train ing samples ) satisfies W =+ B with respect to y and CT , if
I [ XIW n [ xl13 I 2 an ,
( 1 ) and
( 2 ) where n , y , and rs denotes the size of training samples , a confidence threshold , and a support threshold , respectively . Also , W and B denote an equivalence relation and a class , respectively . Furthermore , we also say that W is covering , if
Ibl~l
2 gn .
( 3 ) It is notable that the left side of the above formulae ( 6 ) and ( 8 ) correspond to the formula ( 3 ) as to K , coverage , and the left side of the formula ( 7 ) corresponds to ( 2 ) as to a , accuracy . The only difference is that we classify rules , corresponding to association rules , into three categories : exclusive rules , inclusive rules , and disease image .
The reason why we classify these rules is that this classification reflects the diagnostic model of medical experts , which makes the computational speed of diagnostic reasoning higher .
Algorithm :
Mannila introduces an ( 2 ) Mannila ’s algorithm to find association rules based on Agrawal ’s algorithm ( Mannila , et al . 1994 ) . The main points of their algorithm are the following two procedures : database pass and candidate generation . Database pass produces a set of attributes L , as the collection of all covering sets of size s in C , . Then , the candidate generation calculates Cs+i , which denotes the collection of all the sets of attributes of size s , from L , . Then , again , the database pass procedure is repeated to produce Ls+l . The effectiveness of this algorithm is guaranteed by the fact that all subsets of a covering set are covering .
The main difference between Mannila ’s algorithm and PRIMEROSE REX is that Mannila uses the check algorithm for covering to obtain association rules , whereas we use both accuracy and coverage to compute and classify rules .
In the discovery of association rules , all the combinations of attribute value pairs in C , have the property of covering . On the other hand , our algorithm does not focus on the above property of covering . It selects an attribute value pair which has both high accuracy and high coverage . That is , PRIMEROSE REX does not search for regularities which satisfy covering , but search for regularities important for classification .
Thus , interestingly , when many attribute value pairs have the covering property , or covers many training samples , Mannila ’s algorithm will be slow , although PRIMEROSE REX algorithm will be fast in this case . When few pairs cover many training samples , Mannila ’s algorithm will be fast , and our system will not be slower .
Acknowledgements This research is supported by Grants in Aid for Scientific Research No.08680388 from the Ministry of Education , Science and Culture in Japan .
References
( SIGMOD
Informatics ,
11 , 145 157 . in Databases ( KDD 9 ) ,
Agrawal , R . , Imielinski , T . , and Swami , A . ( 1993 ) . Mining association rules between sets of items in large databases , Proceedings of the 1993 International Conference on Management of Data 93 ) , pp . 207 216 . Breiman , L . , F’reidman , J . , Olshen , R . , and Stone , C . ( 1984 ) . Classification And Regression frees . Belmont , CA : Wadsworth International Group . Buchanan , B . G . and Shortliffe , E . H(eds ) ( 1984 ) . Rule Based Expert Systems , Addison Wesley . Efron , B . ( 1982 ) . The Jackknife , the Bootstrap and Other Resampling Plans . Society for Industrial and Applied Mathematics , Pennsylvania . Mannila , H . , Toivonen , H . , Verkamo , AI ( 1994 ) . Efficient Algorithms for Discovering Association Rules , Proceedings of the AAAI Workshop on Knowledge pp.181 192 , AAAI Discovery press , CA . Matsumura , Y . , et al . ( 1986 ) . Consultation system for diagnoses of headache and facial pain : RHINOS . Medical Michalski , R . S . ( 1983 ) . A Theory and Methodology of Machine Learning . Michalski , RS , Carbonell , JG and Mitchell , TM , Machine Learning An Artificial IntelZigence Approach . Morgan Kaufmann , Palo Alto . Michalski , R . S . , Mozetic , I . , Hong , J . , and Lavrac , N . ( 1986 ) . The Multi Purpose Incremental Learning System A&15 and its Testing Application to Three Medical Domains . Proceedings of the fifth National ConIntelligence , 1041 1045 , AAAI ference on Artificial Press , Palo Alto . Pawlak , Z . ( 1991 ) . Rough Sets . Kluwer Academic Publishers , Dordrecht . Quinlan , JR ( 1993 ) . C4.5 Programs for Machine Learning , Morgan Kaufmann , CA . Tsumoto , S . and Tanaka , H(1994 ) Induction of Medical Expert System Rules based on Rough Sets and Resampling Methods . Proceedings of the 18th Symposium on Computer Applications on Medical Care(Washington , DC ) , pp1066 1070 Philadelphia : Hanley & Belfus , INC . , November . Tsumoto , S . and Tanaka , H . ( 1995 ) . PRIMEROSE : Probabilistic Rule Induction Method based on Rough Sets and Resampling Methods . Computational Intelligence , 11 , 389 405 . Walker , M . G . and Olshen , R . A . ( 1992 ) . Probability for Biomedical Classification Problems . Estimation the sixteenth Symposium on ComProceedings of on Medical Care , McGrawHill , puter Applications New York . Ziarko , W . ( 1993 ) . Variable Precision Rough Set Model . Journal of Computer and System Sciences , 46 , 39 59 .
Data Mining Applications
69
