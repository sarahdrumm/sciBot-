From : AAAI Technical Report WS 94 03 . Compilation copyright © 1994 , AAAI ( wwwaaaiorg ) All rights reserved .
Predicting Equity.Returns from Securities Data with
’ Minimal Rule Generation
Chidanand Apt~
Se June Hong
IBM Research Division
TJ Watson Research Center Yorktown Heights , NY 10598 apteQwatsonibmcom
IBM Research Division
TJ Watson Research Center Yorktown Heights , NY 10598 hong@watsonibmcom
Abstract
. Based on our experiments with financial market data , we have demonstrated that the domain can be effectively modeled by classification rules induced from available historical data for the purpose of making gainfu.l predictlons for equity investments , and thatnew techniques developed atiBM Research , including minimal rule generation ( I~MINI} and contextual feature analysis , are robust enough to consistently extract useful information from noisy domains such as financial markets . We will briefly introduce the rationale for our rule minimisation technique , and the motivation for the use of contextual information in analysing features . We will then describe our experience from several experiments with the S&P 500data , Showing the general methodology , and the restdts of Correlations and managed investment based on classification rules generated by R MINLWe will sketch how the rules for clauificationscan be effectively used for numerical prediction , and eventually to an investment policy . Both the development of robust ~minimai" classification rule generation , ms well as its applir~ation to the financial markets , are part of a continuing study .
Keywords
Financial Markets Data l~;~g , DNF l~J~al Rule Generation , Contextual Feature Analysk ,
Predictive Performance Evaluation ,
Investment Portfolio Management
1
Introduction
There is currently a surge of interest in financial markets data mining . Large amounts of historical data is available for this domainin machine readable form . Analyses of this data for the purpose of abstracting and understanding market behavior , and usingthe abstractions about future market movements , is being seriously explored [ AI on Wall St . , 1991 , AI on Wall St . , 1993 ] . Some firms have also deployeddata mining analytical methods for actual investment portfolio management [ Barr and Maul , 1993 ] . We report here on our recent experiments with applying classification rule generation to S&P 500 data . for making predictions
The R MINI rule generation system can be used for generating Uminimal" classification rules from tabular data sets where one of the columns is a "class" variable and the remaining columns are "independent" features . The data set is completely discretized by a feature discretization subsystem prior to rule generation . The feature discretization performs feature ranking as well as the conversion of numerical valued features into discretizedfeatures using a optimal cutting algorithm . Once rule generation is ComPleted , the R MINI system can be used for classifying unseen data sets and measuring the performance using various error metrics .
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 407
The R MINI rules are in Disjunctive Normal Form ( DNF ) . There have been many approaches to generating DNF rules from data . These include [ Michalski e~ a/ . , 1986 , Clark and Niblett , 1989 , Weiss and Indurkhya , i993 ] which work in principle by iteratively forming one rule at a time to cover some examples from the training datawhich are removed from consideration before repeating the iteration . The other primary approach [ Pagallo , 1989 , Quln]an , 1993 ] is decision tree based , ie , a decision tree is created that classifies the training examples , and the rules are then derived selecting and prll~ing the paths from the root to the leaf nodes .
While theR MINi approach to generating classification rules is slml]ar to the former , it differs from both approaches in its primary goal , which is to strive is complete and consistent with the training data . Completeness implies that the rules cover all of the examples in the training data while consistency implies that the rules cover no counter examples for their respective intended classes . Others too have argued for generating complete and consistent classification models before applying error minimizing pruning processes [ Breiman et ai . , 1984 , Weiss and Kulikowski , 1991 ] . The R MINI system goes beyond current technology in its attempt to generate "minimal" complete and consistent rules . The merits of striving for minimality have been well discussed [ Blumer et al . , i989 , Pdssanan , 1989 ] . Minimality of the representation will favor accuracy and interpretability . for a "minimal" rule set that
2 Minimal Rule Generation to rule generatlon . The rule generation technique is based upon a highly success
The R MINI rule generation technique works with tra|~i~g data in which all features are categorical in nature . AII numeric features are therefore discretized by a feature analysis and discretization sub system .prior ful heuristic minimization technique that was used for minimizing large switching functions ( MINI minimization techniques have been developed for a com[Hong et d . , 1974] ) . Similar heuristic met ".ciplly available switching function minimization package , ’ESPItESSO [ Brayton et al . , 1984 ] . The core heuristics used in the MINI system for achieving minimalRy consists of iterating reasonable number of rounds ) over three key sub steps :
( for
’
1 . Generalization step , EXPAND , which takes each rule in the current set ( initially each example is a rule ) and opportunistically generalizes it to remove other rules that are subsumed .
2 . Specialization step , ttEDUCE , which takes each rule in the current set and specializes it to the most specific rule necessary to continue covering only the unique examples it covers .
3 .
Iteformulation pairs that can be thus transformed . step , ItESHAPE , which transforms a pair of rules into another pair for all
The It MINI rule generation technique is in principle based upon this approach . Experiments to date indicate that it is quite robust in its mlnimality ; Since the rule generation relies on iterative improvements , one can potentially use as much computing time as is affordable . have observed that It MINI starts converging in 5 6 iterations on most well known test data sets as well as on some of the specific real applications in which we have been using the system .
In practice , we
It MINI has been applied to several real data sets , up to thosewith a few hundred features and tens of thousands of examples . Preliminary evaluations suggest that complete and consistent full cover rule setsthat result from applying other known techniques can be several times larger . Initial
Page 408
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94 benchmarking studies have also indicated that the predictive powerof R MINI ’s rule sets is always ahead of the "best" DNF rule sets generatedby other well known methods . An in depth detailed discussion of the rule generation component of R MINI appears in [ Hong , 1993 ] .
3 Contextual Feature Analysis
As mentioned in the previous section , K.MINI rule :generation requires all features to be in categorical form , and hence the reason for discretiZing an numerical features employing a feature analysis and discretization sub system . There is also another important reason for applying this step prior to rule generation . Classilication model generators ~ typically work only as well as the quality of the features from which they axe trYing to generate a model . Poor features will ~|most always result in weakly performing classification models . Various approaches have been used to alleviate this problem , The decision tree based methods have relied On information theoretic measures ( such aS the "entropy" and "glul" functions ) determine the best feature to use at each node while expanding the decision tree [ Brelman et al . , lookahead algorithm that determines 1984]’ This basic principle may be thought of as a :l level the best feature the trv~ing examples into their respective classes . Variants of this method include 2 1evel and more lookahead methods as well as employing simple conjuncts of features ( instead of single features ) as decision tests for nodes . to use at a node based on how well the feature partitlons and Indurkhya , 1993 ] . This method works in principle by attempting to constantly the performance of a rule while being c0nstructed by swapping member tests tests . Although this method appears more powerful than the decision perform well , in the presence of extremely large numbers of features . improve ( features ) with new tree methods , it may not so as to maximize that feature ’s ability
The R MINI system employs a contextual feature analyzer that simultaneously ranks the features in terms of their classificatory power as well as determining the "optimal" number of cuts for each numerical feature for discretization to discriminate . Features are ranked based upon merits that are computed for each of them . Merits are computed by taking for each example in a class a set of "best" counter ex:tmples , , and accumulating a figure that is a function of the example.pair feature values . Dyna~c program m|ng is for each feature then used forproducing optimum cuts [ Aggarwal eta/ . , !993 ] for the numeric vaxiables by sxmultaneously looking at all numerical features emd their value spans , This process is iteratively repeated until a reasonable level of convergence emerges in the merits :and the cut values . In comparison to the tree based : methods , the R MINI Contextual feature analyzer may be thought of as a full level looks head feature analyzer.~ It will : not suffer from falling into false local minima because of its ability to analyze merits of features in a global context . An in depth discussion of contextual feature analysis appears in [ Hong , 1994 ] .
4 Experiments with S&P 500 Data
In cooperation with the IBM Retirement Fund group , we are undertaking a study to determine the feasibility Initial of applying DNF rule generation technology to managing equity investment portfolios . results appear quite promising .
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 409
( S~P deletes and adds new securities
All our experiments have been conducted with S&P 500 data , for a contiguous period of 78 to its 500 index over months . The data spans 774 securities time , so that the index continues to reflect the true market capitalization of large cap . firms ) . The data comprises of 40 variables for each month for each security . The type of information conveyed through these variables is both fundamental ( company performance data ) as well as technical ( stock performance data ) . Some of the variables providetrend’information ( ranging from month to month trends to 5 yearly trends ) . With the exception of one variable , the industry sector identifier , which is categorical , all the rest are numerical .
Also available for each monthly stream of data for a security is the monthly total return for that security , where the variables values are all at,the beginning of a month while the monthly total return ( stock change + dividends ) is at the end of the month . From this 1 month return variable , one can compute 3 month , 6 month , as well as 12 month returns , for each security for each month . One can also compute the difference between these returns and the capitalization weighted mean as weU as simple mean for each of the returns . Thus , ff one can envision the basic 40 variable set as the "features’ , then we have available several ways to assign classes to ee~.h of the examples ( a monthly stream of feature values for a security ) by pick|~g from one of the computed returns .
We have conducted a series of compute intenslve classification experiments with this data , using different ways to assign class labels ~ well as different ways to partition the data . We will focus in the rest of this paper on one pazticular study , which attempts to generate rules for classifying examples based upon the differential between monthly return and simple mean of monthly returns for unseen for agiven stre~ of data . The idea here is to use these rules to predict the differential in a portfolio management scheme for data for the following year(s ) and utilize maximizing the investment returns . The portfolio management strategy strives to remain constantly above the average market return , and therefore the use of the differential as a class label . A positive differential merely implies a return that is higher than the market average . The actual return could be pa~itive or negative . the predictions
4.1
Generating
Classification
Rules for Equity Returns
Class c0 CI C2 C3 C4’
Returns
Year .
880 >_ 6 & < .2 110!’ _> ’2&’< 2~ " 1344 _>2&<6 S74 699 _>6
1 . Year 2 Year3 559 1188 1533 977 560
857 997 1180 883 808
Year 4
674 936 1295 1015 847
Table 1 : Number of S&P 500 data examples per class for years 1 4
There are several issues at hand for determining how much data to choose for generating DNF classifiCation rules for this domain . A routinely used approach would be to hide a portion of the data , ranging from 10 30~ , and generate rules from the remaining "training" data , and evaluate their performance on the hidden "test" data . However , that approach is not adequate for the financial markets domain . There is a strong time dependent behavior in the securities market which needs to be accounted for . An accepted practice is to use the "sliding window" approach , in
Page 410
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94 which the data is laid out in temporal sequence , sad the classification generation sad performance evaluation experiments are repeatedly performed on successive sets of training sad test data . This method can be used for determining whether th e performance of a particular approach withstands the time dependent variations that are encountered as one moves from set to set .
Adopting this latter methodology in on of our experiments , we chose to generate classification the rate of decline
For the class label , we chose the differential the performance of those rules on the rules from a consecutive 12 months of data , sad tested in the following sets of 12 month streams . The idea here was to evaluate rules as one moved forward in time . Once this rate is known , predictive power of classification one can establish a policy of re generating the rules once every "n" years from the immediate past data so as to continue holding up the predictive performance . Our data provided us with over 6 consecutive streams of 12 month data . We axe conducting our experiments from the earliest point onwards , ie , generate classification rules from the earliest available 12 month data ( year 1 ) , apply those rules to year 2 , year 3 , etc . until the performance becomes unacceptable , say at year "n’ . Then re generate classification rules from the 12=month data for year "n l" , sad repeat the process . return a numericalvalued assignment . and the S&P 500 average 1 month return . This label is essentially We further discretized this assignment by attempting to emulate typical security analysts’ categorization method for stocks , which Would include the range %trongly performing" , "moderately performing" , "neutral" , sad "strongly underperforming" . Based upon pr~l~m~nm7 analysis Of the data distribution , we chose to assign the cut point 6 , 2 , +2 , and +6 . That is , all examples who had a class label value of 6 % or more were put in one class ( the "strongly performing" class ) , all examples with class label values of 2~ or more and less than 6~ were put in another class ( the Umoderately performing" class ) and so on . Using this class partihow the first 4 years of data break up by class . Note that tioning scheme , Table 4.1 illustrates although 12 months worth of data for 500 securities to about 6000 examples , the a~:tuals vary t’or each time period because we chose to discard examples which had one or more missing values for the 40 features . The actual examples that we worked with are 4901 for year 1 , 4725 for year 2 , 4817 for year 3 , sad 4767 for year 4 . between the next month ’s 1 month total
"moderately underperforming’ , should translate in the transformation of input raw features
Before proceeding to apply R MINI ’s feature analysis sad discretization step , we tried to carefully adjust the features based upon discussions with the domain experts . As we pointed out in the previous section , the quality of features is of extreme importance in ensuring the quality of the generated classification model . Some of our adjustments to the raw data included the normalization of trend indicating features . This preprocessing usually some features and the inclusion of additional into a new set of features , sad cannot be done results in the absence of domain experts . However , if this expertise is available , then utilizing it to refine the features feature discretization step to the data for Year I , which corresponds to 4901 examples . The result of this step is the assignment of merits to all the features sad the assignment of cut points to the numerical features . Table 4.1 illustrates the merit and cut assignment for this experiment . Note that features with a 0 value for cutpoints indicates that the feature is categorical . Also , we chose the merit values to discard certain features from the rule generation step . These features appear the lower end of the table . Their cut points are not important , since they do not play a subsequent role in the classification experiments , sad are therefore not indicated . is always very desirable . Once these transformations were made , we applied R MINrs
Using the selected features and fully discretized data values , we then apply R MINI ’s rule generation step to the training data , which is now essentially a 5 class problem with 4901 examples
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 411
Feature ’ r , tlbylm monthrl2 pr2 retlmretl retl prl pr3 pr6 wdueprice dowprlce earntr epeprlce bookprlce epe8 sprlce hsz per cap beta epsl~r]ce roe z~veq sects fund Pq odl yld sabhr epsYed" du derat Spr&t quslty growth cne
Merit 322 277 230 229 228 223 216 201 197 152 131 122 121 11S 112 111 110 105 105 105 100 94 91 90 ?8 77 67 66 61 61 58 S2 48 42 40 40 29 21
T~ble 2 : Feature Merits and Cut Points for Year 1 Data a~d 30 features . Since R MINI uses a randomization process in its minimization phase , we run 1tMINI several times ( typically 5 6 ) on the same data set , and go with the smallest rule set that was generated . In this particular case , the smallest rule set size w~ 569 . That is , 569 rules completely and consistently Classified the 4901 training examples , Table 4.1 i]/ustrate just 2 of these rules , where the first rule , Rule 1 ; is for Cius 0 , which corresponds to "strongly underperforming" and the second rule , 11ule 481’ , is for Class 4 , which Corresponds to "strongly performing" .
411 Rule based Regression
To be able to precisely quantify the predictive performance , especially from an investment mansgement point of view , it rules predict the actual return , and not the discretized class segments . We have developed a metric for assigning numeric predictions rules . While primarily motiwted by the current set of experiments , for the 11 MINI classification is necessary that the classification
Page 412
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94
Rule 1 :
,nont~12" NOT’( 5.50 < X < 9.60 ; ) aprice : ( X < 4&10 ; beta : ( X < 1.101 qmprice : NOT ( 0.06 < X < 0.06 ; ~,6 : ( s.~ <_ x pes : ( 1.54 ~_ X ) pr3 : NOT ( 0.93 _< X < 1.011 1.07 _< X < 1.171 ¯ ~luq.~ce : ( 0.S6 < X ) v~ : ( 2.S7 < X ) retlmretl : ( 1086 ~ X ) ~tlb¥1m : ( 1.03 < X )
Then ==~ . CO
Rule 481 : beta : ( 1.10 _< X cap : ( X < 274&60 ; e]~,v= : ( e.~6 < X ) italy : NOT ( 4.89 <_ X < 9.46 ; ) peg : ( X < 1.64 ; prl : ( X < 1.1o ; pr2:.NOT ( 1.06 <_ X < 1.141 pr$ : NOT ( 0.03 _< X < 1.011 ) 1~6 : NOT ( 0.91 < X < 1.021 rlnveq : NOT ( 6.63 < X < 10.641 ) valueprlce : NOT ( 0.70 _< X < 0.86 ; vur : NOT ( 2~7 <_ . X < 0.84 ; ) retlmretl : NOT ( 10.86 < X < 4.05 ; retlbylm : ( X < 1.03 ; 1.06 __ X < 1.06 ;
Then ==* ( 34
Table 3 : Examples of R MINI Classification Rules Generated from Year I Data
.e it is conceivable that this approach could be used in any domain where it is required to predict numerical values . In a sense , this metric extends our R MINI classh~¢ation system for applications in non linear multi vari~te regression .
What we do is associate with each rule three parameters ; ~ , the mean of all actual class values
( in this case , the differential between 1 month total return and mean S&P 500 1 month total return ) of training examples covered by that rule ; # , the standard deviation of these values ; and N , the total number of training covered by that exa~nples rule . class
When a rule Set of this nature is applied for each example the simple average of/~ of all value the numeric compute for each example of 0.0 ~ no rules ( ass|gning w hted usigna , e elK of 0.0 if no rules cover it ) . to smoother correlations between predicted and actual values . to hidden "test" data ,
~ prediction predlctionofth ag " ¯ of vW of all cover
. , rules
’ ~ aver it ) . in the test
/~ data , we have two metrics In averaging the simple approach , we value in the weighted average approach , we compute and its predicted it as cover rules that for predicting that cover
" ( "g st ass :
; g p " " nm a redictlon
In genera ] , we have noticed that the weighted average approach leads
4,2
Investment
Portfolio
Management with R MINI Rules
To evaluate the performance of the generated rules , we applied them to subsequent year data . For example , rules generated from data for months 1 12 , after some minimal pruning , are applied to
KDD 94
AAA/ 9# Workshop on Knowledge Discovery in Databases
Page 413
0
’°i
!
°
°°°°°"°°°°*
i
Total Return
~
: : :
0
’ : ¯ : ( 20) : ; l
! i
! i
: . : :
~ :
: . : : ; 4
.:o ooO,Oo oO . % OoO° : ¯ . ." oo ¯ oo*
° %
, o : o . = , o~=
: : . . _ .
.
;
oOooo"
" : "’ ’’"
140~ : i Vl
10
’ : ’ : * : | ~ i 60
40
20
50
30
Months
R MINI Active Portfolio Simulated S&P 500 Index Fund eIeHII*HO*O0
Figure I : Comparing Total Returns of Simulated S~¢P 500 Index Fund Portfolio Based Active Portfolio and R MINI Rule the the following two years of data . We pruned out rules that cover 3 or less examples , since they are assllmed to be covering the noise component in the data . For the remaining set of rules , we computed the ~ , ~ , and N for each rule , and then applied them to data for months 13 48 .
For effective comparison of how these rules would perform if realistically used , we constructed to a simulated Sg~P 500 a portfolio management scheme based upon these rules , and compared it ¯ index fund performance . A index fund is passive in nature , and all that a Sg~P 500 index fund does is to constantly try and reflect the make up of the Sg~P 500 index , by investing in those companies ¯ in proportion of their capitalization I . In contrast to this passively managed approach , a portfolio management scheme based upon I~ MINI rules Will need to be highly active , since every month the ¯ rules will be making predictions which will need to be acted upon . What this active management policy does in principle is to start out with a investment which reflects the Sg~P 500 index fund ,
:The simulation of the passive index fund was performed on only that subset of the available S&P 500 that did not have missing information , ie , the data in Table 41 This simulation may not correspond exactly to the zeal S~P 500 performance , although it is very close .
Page 414
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94
Monthly Return 20
0
°
|
’°°°
0
! . i
( 20 )
( 30 ) ;
10 t
’ l
:
I
20
30
; 40
!
"
I
50
. 60
Months
R MINI Active Portfolio Simulated S&P 500 Index Fund
**oHeeo,oJl
Figure 2 : Comparing Monthly Returns of Simulated Step 500 Index Fund Portfolio Rule Based Active portfolio and R MINI but then make trades every month based upon the rule predictions . One strategy shown to be successful is as follows : that we have
1 . Generate rules ( and use only those that cover > 3 examples ) .
2 , Start with $1 mi11ion S&P 500 index portfolio .
3 . Execute monthly action at the end of month as follows :
( a ) Update portfolio value for each equity position based upon the month ’s actual total return for that equity .
( b ) Apply rules to month end data for making predictions . ( c ) Sort predictions in descending order . ( d ) Sell bottom 50 % of sorted list provided the values are less than 4 % .
KDD 94
AAAI 9# Workshop on Knowledge Discovery in Databases
Page 415
( e ) Buy top 5 % of sorted list provided the values are greater using funds available from the sale . than 4 % , in equal amounts
The buy and sell cutoff points and thresholds ( 50 % , 5 % , 4 % , 4 % ) are parameters that can adjusted for controlling the behavior of the portfolio . For example , they can be adjusted to make the portfolio "aggressive" or "conservative" . Aggressive portfolioe are characterized by high turnover and large positions in limited equities . Conservative portfolios hold relatively larger number of equities and trade less . The buy/sell cutoff points and thresholds for our investment portfolio simulator can be varied to achieve different behaviors on this spectrum .
For the above settings , Figures 1 and 2 illustrate for months 13 36 , as compared to a 12 % return using a passive how our active portfolio performs against a on a monthly basis as well as a c11mulative basis . We can see that the active pas~ve portfolio , management portfolio returned 44 % return for months 13 48 , as compared to a 4 % return using a passive indexed portfolio . On the other hand , we can also see that the active management portfolio returned 56 % return indexed portfolio . One could argue that the rules that were generated from data for months 1 12 held up well for months 13 36 , but started weakening out thereafter . One therefore will need re generation of rules from data for months up to 36 for applying to months 37 onwards , and repeating the process at the end of every two years . Our full performance evaluation exercise therefore will be done using the regime of generating rules for years 1 , 3 , and 5 . The rules from year 1 will be used for making predictions for years 2 3 , year 3 rules will be used for predicting returns for years 4 5 , and year 5 rules will be used for years 6 and beyond .
Although we make a few simplifying assumptions when constructing the portfolio management simulations , we feel that they win not adversely affect the comparison . For example , we ignored the issue of fees and transaction costs of trading securities . However , these costs apply both to the passive as well as active portfolios . We expect that with the inclusion of such costs , the narrowing of the gap between the two will be a function of the portfolio settings . For a "conservative" setting , the g£p may narrow , while it may still take all such factors strategy that will compensate for additional constraining factors such as these . remainsizable for an "aggressive" setting . To be realistic and into consideration , we are developing a more powerful portfolio management
5 Discussion
We can draw two key conclusions based upon our experiments . First , characterized by the features usdul classification extract the S&P 500 data , as in Table 2 , seem to provide adequate information for to rule generation . Second , our techniques and methodology have the ability information from what is well known to be noise prone data . illustrated this
The application of DNF classification regression applications to explore . The advantages of using DNF rules for these is in itself another interesting direction applications is dear ; they provide a superior level of representation and interpretability in contrast to black box style mathematical functions . Expert analysts can examine and understand these rules , and potentially even hand edit them for improved performance . ru~es in non linear multi variate
We have demonstrated the predictive power of K MINI ’s minimal rule generation philosophy in conjunction with its contextual feature analysis . We have observed that the K MINI generated rules , when embedded in an appropriate portfolio management scheme , can outstrip passive index funds in performance .
Page 416
AAAl 94 Workshop on Knowledge Discovery in Databases
KDD 94
We are also beginning to gain insight into temporal longevity of classification rules generated from historical data in the financial markets . Our initial the nature of decay in predictiv e performance ~s one goes out further into time . We are nearing the completion of our ,sliding window" rule generation and performance evaluation , and the promising results continue to hold . We have begun to explore options for embedding our methodology into an actual deployment . experiments have dearly illustrated
References
[ Auarwal et al . , 1993 ] A . Aggarwal , B . Schieber , and T . Tokuyama . Finding a Minimum Weight K,link Path in GTaphe with Monge Property and Applications . Technical report , IBM Research Division , 1993 .
[ AI on Wall St . , 1991 ] Artificial
Intelligence Applications on Wall Street . IEEE Computer Society ,
1991 .
[ AI on WMI St . , 1993 ] Artificial
Intelligence Applications on Wall Street . Software Engineering
Press , 1993 .
[ Barr and Ma~i , 1993 ] D . Barr and G . Maul . Neural Nets in Investment Management : Multiple
Uses . In Artificial
Intelligence Applications on Wall Street , pages 81 87 , 1993 .
[ Blumer et aL , 1989 ] A . Blumer , A . Ehrenfeucht , D . Haussler , and M . Warmuth . Learnability and the Vapnik Chervonenkis Dimension . JACM , 36:929 965 , 1989 .
[ Brayton et a/ . , 1984 ] It . Brayton , G . Hachtel , C . McMullen , and A . Sangiovsnni Vincenteili . Logic
Minimization Algorithms for VLSI Syntheais . Kluwer Academic Publishers , 1984 .
[ Breiman et al . , 1984 ] L . Breiman , J . Priedman , It . Olshen , and C . Stone . Classification and Re . gression Trees . Wadsworth , Monterrey , CA . , 1984 .
[ Clark and Niblett , 1989 ] P . Clark and T . Niblett . The CN2 Induction Algorithm . Machine Learn ing , 3:261 283 , 1989 .
[ Hong et aL , 1974 ] SJ Hong , It . Cain , and D . Ostapko . MINI : A Heuristic Algorithm for TwoLevel Logic Minimization . IBM Journal of Research and Development , 18(5):443 458 , September 1974 .
[ Hong , 1993 ] SJ Hong . It MINI ; A Heuristic Algorithm for Generating Minimal Rules from Ex amples . Technical Report ItC 19145 , IBM Research Division , 1993 .
[ Hong , 1994 ] SJ Hong . Use of Contextual Information for Feature Ranking and Discretization .
Manuscript in preparation , 1994 .
[ Michalski etal . ,
1986 ] R . Michalski ,
Incremental Learning System AQ15 and its Testing Application Proceedings of the AAAI 86 , pages 1041 1045 , 1986 .
I . Mozetic , J . Hong , and N . Lavrac . The Multi Purpose to Three Medical Domains . In
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 417
[ Pagallo , 1989 ] G . Pagallo . Learning DNF by Decision Trees . In Proceedings of the Eleventh IJCAI , pages 639 644 , 1989 .
[ Quinlan , 1993 ] JR Qulnlan . 04.5 : Programs ]or Machine Learning . Morgan Kaufmann , 1993 .
[ Rissanaa , 1989 ] J . Rissanan . StochMtic Complexity in Statistical
Inquiry . World Scientific Series in Computer Science , 15 , 1989 .
[ Weiss and Indurkhya , 1993 ] S . Weiss and N . Indurkhya . Optimized Rule Induction .
IEEE EX
PERT , 8(6):61 69 , December 1993 .
[ Weiss and K,dileowski , 1991 ] SM Weiss and CA Kullkowski . Computer Systems That Learn .
Morgan Kaufmann , 1991 .
Page 418
AAM 94 Workshop on Knowledge Discovery in Databases
KDD 94
