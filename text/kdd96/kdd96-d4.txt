From : KDD 96 Proceedings . Copyright © 1996 , AAAI ( wwwaaaiorg ) All rights reserved .
An Overview of Issues and Knowledge
Gregory
Piatetsky Shapiro
GTE Laboratories 40 Sylvan Road
Waltham , MA 02154 gps@gte.com in Developing Discovery Ron Brachman AT&T Research
600 Mountain Avenue Murray Hill , NJ 07974 rjb@researchattcom
Industrial Applications
Data Mining
Tom Khabaza
ISL
Berk House , Basing View Basingstoke RG21 4RG
UK , tomk@islcouk
Willi Kloesgen GMD , D 53757
Sankt Augustin , Germany kloesgen@gmd.de Abstract
This paper surveys the growing number of indu5 trial applications of data mining and knowledge discovery . We look at the existing tools , describe some representative applications , and discuss the major issues and problems for building and deploying successful applications and their adoption by business users . Finally , we examine how to assess the potential of a knowledge discovery application .
1
Introduction
A significant need exists for a new generation of techniques and tools with the ability to intelligently and automatically assist humans in analyzing the mountains of data for nuggets of useful knowledge . These techniques and tools are the subject of the emerging field of data mining and knowledge di5 covery in databases ( Fayyad et al . 1996 ) . This paper examines a growing number of industrial applications in this field ( see Fayyad , Haussler , and Stolorz 1996 for a survey of scientific applications ) . We survey the existing data mining tools , describe some representative applications , and discuss the major issues and problems for building and deploying successful applications .
Knowledge Discovery in Databases ( KDD ) is an umbrella term used to describe a large variety of activities for making sense of data . We will use the term knowledge discovery to describe the overall process of finding useful patterns in data , which includes not only the data mining step of running the discovery algorithms , but also pre and postprocessing , and various other activities ( see Section 3 ) . The knowledge discovery goals are defined by the intended use of the system . We can distinguish two where the system is types of goals : verification , limited to verifying the user ’s hypothesis ( the most prevalent type of data analysis to date ) , and discovery , where the system autonomously finds new
Evangelos Simoudis
IBM Almaden Research Center
650 Harry Road , San Jose , CA 95120 simoudis@almadenibmcom patterns . We further subdivide the Discovery goal into prediction , where the system finds patterns for the purpose of predicting the future behaviour of some entities ; and description , where the sy5 tern finds patterns for the purpose of presenting them to a user in a human understandable form . Although the boundaries between prediction and description are not sharp some of the predictive models can be descriptive ( to the degree that they are understandable ) , and some of the descriptive models could be used for prediction this distinction is useful for understanding the discovery goal . The framework for knowledge discovery and the data mining tasks of classification , regression , clu5 tering , summarization , dependency modeling , and deviation detection are discussed in more detail in ( Fayyad , Piatetsky Shapiro , & Smyth 1996 ) .
2 Data Mining
Tools
Data mining in the industry today is still primarily verification oriented and performed mainly by analysts whose primary training and professional duties are in statistics or data analysis . By and large , the tools used are not expressly “ data mining tools ” , but rather statistical analysis tools like S and SAS , graph and chart drawing software and spreadsheets , and database query engines . Direct programming in languages like C and awk is typically used for complex analyses , usually on data selected from a database , but dumped into a flat file for further manipulation .
Among the tools that support data mining1 see
Chttp://infogtecom/Nkdd/siftwarehtml> for a catalog , the first group is generic , singletools . There are many dozens of such tools task available , especially for classification , using primarily decision trees , neural networks , exampl+based , and rule discovery approaches . Such tools mainly ‘sometimes called siftware because this is software for sifting through the data
Data Mining General Overview
89 tools . support only the data mining step in the knowledge discovery process and require significant preand post processing . The target user of such tools is typically a consultant or a developer who would integrate them with other modules as part of a complete application ,
The next group is generic , multi task combining classification than one approach ) ,
These tools perform a variety of discovery tasks , ( perhaps typically u5 visualization , ing more query/retrieval , clustering , and more . They include Clementine , Darwin , IBM Intelligent Miner , IMACS , MLC++ , MOBAL , and SGI MineSet .
These tools support more of the KDD Process and simplify embedding of discovered knowledge in the application . Usually , the target user of such tools is a “ power ” analyst who understands data manipulation . Generally such tools require appropriate training and some tool customization before being used by domain experts , but there are some exceptions . is reported
Clementine , in particular , to have been widely used without customization by a variety of end users ranging from business analysts to biochemists . This is made possible by Clementine ’s highly graphical user interface to data mining functions .
Another example is the IMACS system ( Brachman et al . 1993 ) , which used a knowledge representation system to represent domain and task objects and integrate various aspects of the discovery process . IMACS allowed the user to create new , object centered views over data that was stored in arbitrary ways ( relational database , flat files ) . Data could be segmented in a simple way using these views , and new segments could be defined easily from old ones . This was one big step towards allowing a business user to interact with data in terms s/he was familiar with , since the views ( or “ concepts ” ) were expressed entirely in the user ’s terms rather than being slaved to database schemas cre ated for other purposes . the the talk
Finally , last group the analysis process . is domain specific These tools support discovery only in tools . lana specific domain and already the end user , who needs to know guage of about Exvery little amples of such tools include Opportunity Explorer ( Anand 1995 ) which generates reports on changes in retail sales , IBM Advanced Scout <http://wwwresearchibmcom/xw scout> which analyzes basketball game statistics and finds patterns of play that coaches can use , and HNC Falcon <http : //www . hnc . corn/> , a neural networkbased system for credit card fraud detection ,
These systems and others represent a growing trend in moving data mining technology into the business world . The key elements that help make the core statistical , machine learning , and other
90
KDD 96 data mining stream user include technologies accessible to a main putting the problem in the business user ’s terms , including viewing the data from a business model perspective ( both concepts and rules ) ; support for specific key business analyses like segmentation ; presentation of results in a form geared to the business problem being solved ; and support for an iterative exploratory process protracted in time , as examined in the next section ,
3
Knowledge
Discovery
Process
The core of the knowledge discovery process is the set of data mining tasks , used to extract and verify patterns in data . However , we should emphasize that this core takes only a small part ( estimated as 15 to 25 % of the overall effort ) of the entire process of knowledge discovery . No complete methodology for this process yet exists , but knowledge discovery takes place in a number of stages ( more about this in Brachman & Anand , 1996 ) :
Data and task discovery the process of becoming familiar with both the data that will be analyzed and the task that the business user needs to accomplish . This is more significant than it may sound , especially when the data is to be pulled from multiple sources , and when the analysis will not be done by the business user ; Acquisition bringing the data into the appropriate environment for analysis ; Integration and checking confirming the expected form and broad contents of the data , and integrating into tools as required ; Data cleaning removing records with errors or ( if considered insignificant ) , etc . ; looking outliers for obvious flaws in the data and removing them ; Model and hypothesis development simple exploration of techniques , and elaboration by deriving new data attributes where necessary ; selection of an appropriate to do analysis ; development of model initial hypotheses to test ; Data mining step application of the core discovery procedures to discover patterns and new knowledge , or to verify hypotheses developed prior to this step ; Testing and verification assessing the discovered knowledge : testing predictive models on test sets , analyzing segmentation etc . ; Interpretation and use integration with existing domain knowledge , which may confirm , deny or challenge the newly discovered patterns ; if pre dictive , subsequent use on novel data sets . the data by passive in which
Throughout the process , we also have presents tion or visualization of results as an integral activity . A key thing to note about this process is that it is not simple and linear , but thoroughly iterative and interactive , the results of analysis being fed back into the modeling and hypothesis derivation process to produce improved results on subsequent iterations . This activity takes time , and if it is applied to data generated on a regular basis or yearly results ) can have a very ~;egg,l;u.;~ly
4 Representative
Applications
Numerous knowledge discovery applications and prototypes have been developed for a wide variety of domains including marketing , finance , manufacturing , banking , and telecommunications . A majority of the applications have used predictive modeling approach , but there were also a few notable applications using other methods . Here we describe some of the representative examples . 4.1 Marketing Leading market research companies such as AC Nielsen and Information Resources in USA , GfK and Infratest Burke in Europe apply KDD tools to the rapidly growing sales and marketing databases . Because of a strong competitive pressure , the often saturated market potential and maturity of products , there is a shift from a quality to an information competition where detailed and comprehensive knowledge on the behavior of customers and competitors is crucial .
Market research companies collect data on special markets , analyze this data and sell data and analyses to their clients . The clients add their own data for further analyses . Medium sized datasets are captured when market research companies perform surveys ( eg 2000 persons interviewed each month ) or organize test samples of households . BehaviorScan approaches provide test households with special alternative TV commercials . Much larger data sets are available in the form of point of sale data , when eg purchases in supermarkets are captured by scanners .
Marketing , which has been a long time user of statistical and other quantitative methods , has been in the forefront of adopting new knowledge discovery techniques . Most marketing applications fall into the broad area called “ Database Marketing ” ( or “ mailshot response ” in Europe ) . This is an approach which relies on analysis of customer databases , using a number of techniques including interactive querying , market segmentation to identify different customer groups , and predictive modeling to forecast their behaviour . Business Week ( Berry 1994 ) has estimated that over half of all retailers are using or planning to use database marketing , and those who do use it have good results such as lo 15 % increase in credit card use reported by American Express .
An interesting application to predict television audiences using neural networks and rule induction was developed by Integral Solutions for the BBC . Rule induction was used to examine which factors play the most important role in relating the size of a program ’s audience to its scheduling slot . The final models were equivalent to the best performance of human experts , but highly robust against change , because the models could be retrained from uptodate data ( Fitzsimons , Khabaza , & Shearer 1993 ) . Other applications are more descriptive their focus is to find patterns that will help market analysts make better decisions . Among the first systems developed and deployed in this area were Coverstory ( Schmitt , Armstrong , & Little 1990 ) and Spotlight ( Anand & Kahn 1992 ) , which analyzed supermarket sales data and produced reports , using natural language and business graphics , on the most significant changes in a particular product volume and share broken down by region , product type , and other dimensions . In addition , causal factors such as distribution channels and price changes were examined and related to changes in volume and share . These systems were quite successful Spotlight was reported to be among the best selling products of AC . Nielsen . the advantages for the retailer
Spotlight was later extended into Opportunity Explorer system ( Anand 1995 ) , which supports the sales representative of a consumer packaged good company in examining the business with a single retailer . This is accomplished by presentations that highlight if additional products are stocked or special promotions are performed . A new feature of Opportunity Explorer was generation of interactive reports with hyperlinks ( even before the Web! ) , which allowed easy navigation between different report sections . The MDT ( Management Discovery Tool ) system , a product under development at AT&T and NCR , incorporates several other innovative ideas to allow a business person to directly interface with data . MDT incorporates a set of business rules ( encoded as metadata ) that make it easy to set up monitors that detect significant deviations in key business indicators . To accommodate the mainstream business user , MDT provides a limited set of analysis types , including summarization , trend analysis , and measure and segment comparison .
Another marketing area is Market basket analysis , which looks at associations between different products bought by the customer . These methods are generally based on the association discovery algorithms ( Agrawal et al . 1996 ) . A number of companies , including IBM and SGI offers tools for Market basket analysis .
Data Mining General Overview
91
Investment
4.2 Many financial analysis applications employ predictive modeling techniques , such as statistical regression or neural networks , for tasks like portfolio creation and optimization and trading model creation . Such applications have been in use for several years . To maintain a competitive advantage , the users and developers of such applications rarely publicize their exact details and effectiveness .
We can , however , mention a few examples . Fidelity Stock Selector fund is using neural network models to select investments and has performed quite well until recently . However the output of those models is evaluated by the fund manager Brad Lewis before the action is taken , so it is not clear how to divide the credit between man and machine .
Investor ) system which
Morgan Stanley and Co . has developed AI ( Automated identifies good trading opportunities by using clustering , visualization , and prediction . The system has been deployed and is being evaluated . toolkit
Daiwa Securities used MATLAB to build a portfolio management tool which analyzes a large number of stocks and selects an optimal portfolio based on the stock risk and expected rate of return ( Pittaras 96 ) .
LBS Capital Management uses expert systems , neural nets and genetic algorithms to manage portfolios totalling $600 million and since its start in 1993 , their system has outperformed the broad stock market ( Hall , Mani , & Barr 1996 ) .
Carlberg & Associates have developed a neural network model for predicting S&P 500 Index , <http://carlassoc . rates , earnings , dividends , the dollar index , and oil prices . The model was surprisingly successful and explained 96 % of the variation in the S&P 500 index from 1986 to 1995 . corn/> using interest these applications , predictive accuracy is paramount compared to the ability to use the extracted knowledge to explain a recommended action . Thus , the main focus is ensuring that modeling methods do not overfit the data .
In
Fraud Detection
4.3 Not all the systems developed for this have been publicized , for obvious reasons , but several are worth mentioning .
The HNC Falcon credit risk assessment system , developed using a neural network shell , is used by a large percentage of retail banks to detect suspicious credit card transactions . Falcon deployment was facilitated by the fact that credit card transaction data is captured by just a few companies . Even though each such company uses its own data format , every bank issuing credit cards uses one of these few formats . Therefore , an application that
92
KDD 96 can work with even one format effectively can easily be adopted by a large number of banks .
The FAIS system ( Senator et al . 1995 ) from US Treasury ’s Financial Crimes Enforcement Network , is used to identify financial transactions that may be indicative of money laundering activity . FAIS uses data from common government forms and consists of a combination of off the shelf and custom built components . Its use is expected to expand to a variety of government agencies that are concerned with the detection of suspicious financial transactions indicative of money laundering operations . FAIS has the hardest data quality problem because much of its data comes from poorly handwritten notes .
AT&T has developed a system for detecting the international calling fraud by displaying the calling activity in a way that lets the user quickly see the unusual patterns ( Eick & Fyock 1996 ) .
The Clonedetector system , developed by GTE ( Davis & Goyal 1993 ) , is using customer profiles to detect the cellular cloning fraud . If a particular customer suddenly starts calling in a very different way , fraud alert automatically kicks in .
Another cellular fraud detection system is under development at NYNEX . The developers first mine the data to discover indicators of fraudulent usage . Subsequently , they automatically generate detection systems by feeding these indicators into a detector constructor program , which uses the indicators to instantiate detector templates . Finally , the system learns how to combine the detectors for optimal performance .
5 Manufacturing and Production
Controlling and scheduling technical production processes is a an application of KDD with a high potential profit . The goal is to discover process conditions that lead to good quality products . At present , large volumes of data generated during a production process are often only poorly exploited . Also , the relations between the control , process , and quality variables are not completely understood by the engineers . In addition , time and space constraints , which play an especially important role in manufacturing , are not well handled by most data mining tools .
A typical example is a project which is run in a large chemical company in Europe to analyze a production process in a plant for polymeric plastics . Data includes control variables ( eg quantities of raw material , the process variables ( temperatures , pressures , and chemical reaction times ) , and quality variables measured in a laboratory . Quality variables are determined several times a day , process and control variables nearly continuously . Even simple approach of introducing separate variables for distinct time points the heating parameters ) , the CASSIOPEE
Another example
( process variables measured every hour ) , and ap plying rule inducing discovery methods to the resulting data can lead to valuable insights into the manufacturing process . is troubleshooting system , developed by a joint venture of General Electric and SNECMA using the KATE discovery tool . The system is applied by three major European airlines to diagnose and predict problems for BOEING 737 . To derive families of faults , clustering methods are used . CASSIOPEE received the European first prize for innovative applications ( Manago and Aurio196 ) . 5.1 Telecommunication Another application area involving a strong time component is the management of telecommunication networks . These large and complex networks produce large amounts of alarms daily . The sequence of alarms contains valuable knowledge about the behavior of the network . Regularities in the alarms can be used in fault management systems for filtering redundant alarms , locating problems in the network , and predicting severe faults . At the University of Helsinki , the Telecommunication Alarm Sequence Analyzer ( TASA ) was built in cooperation with a manufacturer of telecommunication equipment and three telephone networks ( Mannila , Toivonen , & Verkamo 1995 ) . The system uses a novel framework for locating frequently occurring alarm episodes from the alarm stream and presenting them as rules . Large sets of discovered rules can be explored with flexible information retrieval tools supporting interactivity and iteration . In this way , TASA offers pruning , grouping , and ordering tools to refine the results of a basic brute force search for rules . The system has discovered rules that have been integrated into the alarm handling software of the telephone networks . 5.2 Health care is an information rich and high payoff area , ripe for data mining . One of the first applications in this area is KEFIR ( Matheus , PiatetskyShapiro , & McNeil1 1996 ) . The system performs an automatic drill down through data along multiple dimensions to determine the most interesting deviations of specific quantitative measures relative to their previous and expected values . It explains “ key ” deviations through their relationship to other deviations in the data , and , where appropriate , generates recommendations for actions in response to these deviations . KEFIR uses a Web browser to present its findings in a hypertext report , using natural language and business graphics .
Other Areas
Improving data quality is another important ap plication area . One aspect of data quality is the automatic detection of errors . A number of applications were developed for checking data ( in par
” titular financial trading data ) , detecting errors currently impossible to detect by conventional means . Another aspect of data quality is the identificac tion of related and duplicate entities an especially acute problem for database marketers and catalog senders . Identification of duplicate claims was performed by Merge/Purge system ( Hernandez & Stolfo 1995 ) ) successfully used on data from Welfare Department of the State of Washington .
Basketball statistics are also plentiful , and IBM Advanced Scout helps NBA coaches and league officials organize and interpret the data amassed at every game . A sample finding from a Jan 6 , 1995 game between Knicks and Cavaliers is that when Mark Price played the 1Guard position , John Williams attempted four jump shots and made each one . Advanced Scout not only finds this pattern , but explains that it is interesting because it differs considerably from the average shooting percentage of 49.30 % for the Cavaliers during that game . This is the kind of pattern that coaches might not ordinarily detect , yet it conveys valuable information about possible improvements in their strategy . Scout has been used by several NBA teams ( US News 95 ) .
Agents
Discovery
5.3 Finally , a novel and very important type of discovery system has appeared recently Discovery Agents . Although the idea of active triggers has long been analyzed in the database field , really successful applications of this idea appeared only with the advent of the Internet . These systems ask the user to specify a profile of interest and search for related information among a wide variety of public domain and proprietary sources .
To mention a few examples , the Firefly is personal music recommendation agent asks user their opinion of several music pieces and then suggests other music like <http://wwwfflycom/> the user may that
Crayon <http :
//www . f arcast
//crayon . net/> allows users to create their own free newspaper ( supported by ads ) . Farcast <http : . corn/> and NewsHound from San Jose Mercury automatically search information from a wide variety of sources , including newspapers and wire services , and email relevant documents directly to the user .
<http://wwwsjmercurycom/hound/>
Development
6 Application While the data mining and knowledge discovery technology is quite well developed , its practical application in industry is hampered by a number of difficulties , reviewed below .
Issues
Insufficient graduates of business schools will be familiar with verification driven analysis techniques , occasionally with predictive training :
Data Mining General Overview
93 and very Extending to acknowledge can alleviate by making modeling , techniques . alysts available addressed ily available to business training of business seldom with other discovery an the the full range of techniques this problem ; the discovery it can also be eas techniques users
( see sec . 2 ) .
Inadequate tool support : most available data at most one of the core disOther detection , only prediction . typically tools support techniques , such as clustering , summarization mining covery methods , visualization , well as methods cases ) which may be significant tions . knowledge discovery process a user Some than now emerging which satisfy technologists . tools must interface suitable deviation are also needed , as ( rare in some applicathe complete ( section 3 ) and provide rather are users for business integrated toolkits these requirements . for dealing with exceptions also support
The data the required
Data inaccessibility : data in a variety is often poorly organized reason , acquisition play a very significant lem , the organization and this usually edge discovery becoming widespread , such problems . Both warehousing often serve ity them . in an organization , to highlight project .
Overabundance for a given business prob across formats , For is often distributed of different or maintained . and pre processing part
Data warehousing and can potentially the problems but can also help in any knowlis now alleviate and data mining of data qualto solve of patterns : has a wide scope , a very Proper can be discovered . to avoid discoveries can help knowledge findings . refinement 1995 ) and other generalization
Rule when search large number for of statistical condue to chance , to focus on the ( Major & methods patterns patterns trols are needed while domain interesting Mangano could be used
On time over
Changing to further compress and time oriented that changes findings . data : many ap signif(eg or fashions ) . are on one hand more challenging for flat tables algorithms timesuch appliit is the other hand , and other suitable patterns . stock market deal with behaviour can become especially plications icantly Such applications because common do not work well with sequential oriented cations easier The ular updating to as “ volatility ing methods tection and 1995 , Berndt & Clifford 1996 , Mannila , & Verkamo 1995 ) . Space oriented benefit ” . are designed time oriented to retrain improvement in decision making of decision making for handling a system successful , to retrain since a human . to regis referred A few recent data minde(Agrawal & Psaila Toivonen , deviation data : other tools than data due manufacturing , in pecially geographically oriented spatial data . Here again patterns which require applications , biology , esand are dealing with types of ( Stolorz systems , there are special algorithms special
94
KDD 96 et al . 1995 ) . Geographical have been very successful types of spatial patterns in helping visually . information systems to find some
Complex data : Other types of information , including text , images , audio , video , and anything related to the Web present an even grander challenge with potentially great rewards .
Scalability :
Although many papers ( including this one ) talk about needing to mine vast amounts of data , none of the tools can do that today . Data warehouses that start at 200GB are not infrequent today , yet current tools can at best deal with 1GB at a time . Progress , however , is being made t* wards using massively parallel and high performance computing which will help to deal with large databases . information ,
Privacy : When dealing with databases of pergovernments and businesses sonal have to be careful to adequately address the legal and ethical issues of invasion of privacy ( see Piatetsky Shapiro 1995 ) .
7 Assessing Benefits Of KDD
Applications are factors . suitable applica decisions , of a potential for data mining costs and benefits rich , have a changing at the following there should be no simpler alterna those environrequire and provide high payoff domain , we
The domains that are information ment , do not already have existing models , knowledge based for the right decisions . Given a suitable examine tion by looking Alternatives : tive solutions . Relevance : relevant factors should be included . Volume : there should be a sufficient number of cases ( several thousands at least ) . Extremely large databases may be a problem when the results are needed quickly . Complexity : the more variables ( fields ) there are the more complex is the application . Complexity is also increased for time series data . Quality : Error rate should be relatively low . Accessibility : data should be easily accessible accessing data or merging data from different sources increases the cost of an application . Change : although dealing with change is more difficult , it can also be more rewarding ( the volatility benefit ) since the application can be automatically and regularly “ re trained ” on up to date data . Expertise : The more expertise available , the easier is the project . It should be emphasized that expertise on the form and meaning of the data is just as important as knowledge of problemsolving in the domain .
Although the challenges are many and the difficulties are substantial , the future of data mining applications looks bright . There is a widespread realization of the potential value of data mining and a growing number of researchers and developers are working on the topic . However , data mining by itself is only a part of the overall application and all other components , as described in Section 3 need to be addressed for a successful application .
We thank Usama Fayyad Acknowledgments : and Sam Uthurusamy for encouraging us to put together this survey , a version of which will also appear in Communications of ACM . Robert Golan helped with information on financial data mining . Colin Shearer ( ISL ) has contributed much useful material to this article .
8 References
Anand , T . and Kahn , G . 1992 . SPOTLIGHT : A Data Explanation System . In Proceedings Eighth IEEE Conference on Applied AI , 2 8 . Washington , DC : IEEE Press .
Anand , T . 1995 . Opportunity Explorer : Navigating Large Databases Using Knowledge Discovery Templates . Journal of Intelligent Systems 4(1):27 38 .
Agrawal , R . , Mannila , H . , Srikant , R . , Toivonen , H . , Verkamo , A . 1996 . Fast Discovery of Association Rules . In AKDDM , Cambridge , MA : AAAI/MIT
Information
Press .
Agrawal , R . , and Psaila , G . 1995 . Active Data 3 8 , Menlo
In Proceedings of KDD 95 ,
Mining . Park , CA : AAAI Press .
Brachman , R . , et al . 1993 . Integrated Support In Proceedings of KDD 9J for Data Archaeology . Workshop , Menlo Park , CA : AAAI Press .
Brachman , R . and Anand , T . 1996 . The Process of Knowledge Discovery in Databases : A Human In AKDDM , Cambridge , MA : Centered Approach . AAAI/MIT Press .
Berndt , D . and Clifford , J . 1996 . Finding Patterns in Time Series : A Dynamic Programming Ap preach . In AKDDM , Cambridge , MA : AAAI/MIT Press .
Berry , J . 1994 . Database Marketing . Business
Week , 56 62 , Sep 5 .
Codd , EF 1993 . Providing OLAP ( On line Analytical Processing ) to User Analysts : An IT Mandate . EF Codd and Associates .
Davis , A . and Goyal , S . 1993 . Management of Cellular Fraud : Knowledge Based Detection , Classification and Prevention . In Proceedings of 19th Int . Conf . on AI , Expert Systems and Natural Language , Avignon , France , Vol . 2 , pp . 155 164 .
Eick , S . and Fyock , D . 1996 .
Technical Journal ,
Visualizing Jan
Corporate Data , AT&T uary/February , pp . 74 86 .
Fayyad , U . , Piatetsky Shapiro , G . , Smyth , P . , 1996 . Advances in and Uthurusamy , R . eds .
Knowledge Discovery and Data Mining Cambridge , MA : AAAI/MIT Press .
( AKDDM ) .
Fayyad , U . , Piatetsky Shapiro , G . , and Smyth , P . 1996 . Knowledge Discovery and Data Mining : Towards a Unifying Framework . In Proceedings of KDD 96 , Menlo Park , CA : AAAI Press .
Fayyad , U , , Haussler , D . , and Stolorz , P . 1996 . KDD for Science Data Analysis : Issues and Examples . In Proceedings of KDD 96 , Menlo Park , CA : AAAI Press .
Fitzsimons , M . , Khabaza , T . , and Shearer , C . 1993 . The Application of Rule Induction and Neural Networks for Television Audience Prediction . In Proc . Symposa’um on Information Paris , November , pp 69 82 .
Based Decision Making in Marketing , of ESOMAR/EMAC/AFM
Hall , J . , Mani , G . , and Barr , D . 1996 . ApplyIntelligence to the Investment of CIFER 96 :
Computational in Financial Engineering .
Piscataway , ing Computational Process . In Proc . Intelligence NJ : IEEE Press .
Hernandez , M . and Stolfo , S . 1995 .
Merge/Purge Problem for Large Databases . Proc . of the 1995 ACM SIGMOD 138 . NY : ACM Press .
The In Conference , 127
Major , J . , and Mangano , J . 1995 . Selecting among Rules Induced from a Hurricance Database . Systems 4(1):39Journal of Intelligent 52 .
Manago , M . and Auriol , M . 1996 . Mining for OR . ORMS Today , February , Special issue on Data Mining , 28 32 .
Information
Mannila , H . , Toivonen , H . , and Verkamo , A . 1995 . Discovering Frequent Episodes in Sequences , In Proceedings of KDD 95 , 210 215 . Menlo Park , CA : AAAI Press .
Matheus , C . , Piatetsky Shapiro , G . , and McNeill , D . 1996 . Selecting and Reporting What is Interesting : The KEFIR Application to Healthcare Data . Press , 495 516 .
In AKDDM , Cambridge , MA : AAAI/MIT
Piatetsky Shapiro , G . 1995 . Knowledge Discovery in Personal Data vs . Privacy a Minisymposium . IEEE Expert , April 1995 .
Schmitz , J . , Armstrong , G . and Little , J . D . C . 1990 . CoverStory Automated News Finding in ed . L . Volino , Marketing . 46 54 . Providence , RI : Institute of Management Sciences .
In DSS Transactions ,
Senator , T . et al . 1995 . The Financial Crimes Enforcement Network AI System ( FAIS ) , AI Magazine , Winter 1995 , 21 39 .
Stolorz , P . et al . 1995 . Fast Spatio Temporal In Data Mining of Large Geophysical Datasets . Proceedings of KDD 95 , 300 305 , Menlo Park , CA : AAAI Press .
US News & World Report , December 11 , 1995 . “ Basketball ’s new high tech guru : IBM software is changing coaches’ game plans . ”
Data Mining General Overview
95
