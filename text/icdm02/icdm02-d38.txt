DOI TR 211 June 2002
Department of Informatics , Kyushu Univeristy ftp://ftpikyushu uacjp/pub/tr/trcs211psgz
Online Algorithms for Mining Semi structured Data
Stream
( To appear in Proc . 2002 IEEE Int’l Conf . on Data Mining ,
ICDM’02 )
Tatsuya Asai†
Hiroki Arimura†,‡
Kenji Abe†
Shinji Kawasoe†
Setsuo Arikawa†
†Department of Informatics , Kyushu University , Japan
‡PRESTO , JST , Japan
{t asai , arim , k abe , s kawa , arikawa}@ikyushu uacjp
Abstract
In this paper , we study an online data mining problem from streams of semi structured data such as XML data . Modeling semi structured data and patterns as labeled ordered trees , we present an online algorithm StreamT that receives fragments of an unseen possibly infinite semi structured data in the document order through a data stream , and can return the current set of frequent patterns immediately on request at any time . A crucial part of our algorithm is the incremental maintenance of the occurrences of possibly frequent patterns using a tree sweeping technique . We give modifications of the algorithm to other online mining model . We present theoretical and empirical analyses to evaluate the performance of the algorithm .
Correspondence : Tatsuya Asai Department of Informatics , Kyushu University Fukuoka 812 8581 , Japan EMAIL : t asai@ikyushu uacjp TEL : +81 92 642 2688 , FAX : +81 92 642 2698
1
Introduction
Recently , a new class of data intensive applications such as network monitoring , web site management , sensor networks , and e commerce emerged with the rapid growth of network and web technologies . In these applications , the data are modeled not as static collections but as transient data streams , where the data source is an unbounded stream of individual data items , eg , transaction records or web page visits , which may arrive continuously in rapid , time varying way [ 18 ] .
Particularly in data communication through internet , it is becoming popular to use semi structured data based communication technologies [ 2 ] , eg , SOAP [ 19 ] , to send heterogeneous and ill structured data through networks . Since traditional database technologies are not directly applicable to such data streams , it is important to study efficient information extraction methods for semi structured data streams .
In this paper , we model such semi structured data streams by sequences of labeled ordered trees , and study the frequent pattern discovery problem in online setting . We model a semi structured data stream as an infinite sequence of the nodes generated by the depth first scanning of a possibly infinite data tree . An online algorithm has to continuously work on the data stream , and has to quickly answer queries on request based on the portion of the data received so far . This formulation captures typical situations for web applications reading a sequence of XML tags or SAX events element by element from a data stream . Since this is a finest grained online model , the results of this paper can be easily generalized to coarser grained models where , eg , XML documents are processed page by page .
We present an online algorithm StreamT for discovering labeled ordered trees with frequency at least a given minimum threshold from an unbounded data stream . A difficulty lies in that we have to continuously work with unbounded data streams using only bounded resources . A key idea is a technique of sweeping a branch , called the sweep branch , over the whole virtual data tree to find all embeddings of candidate patterns intersecting it . Using this sweep branch as a synopsis data structure , we achieve incremental and continuous computation of all occurrences of patterns with bounded working space .
As another idea , we adopt a candidate management policy similar to Hidber [ 11 ] for online association mining to limit the number of candidate patterns as small as possible . We also use the enumeration technique for labeled ordered trees that we recently proposed in [ 4 ] , a generalization of a technique by Bayardo [ 6 ] . Combining these ideas , our algorithm StreamT
1 works efficiently in both time and space complexities in online manner . Furthermore , we extend our algorithm to the forgetting model of online data stream mining , where the effect of a past data item decays exponentially fast in its age . We also give theoretical analysis on the accuracy of the discovered patterns as well as an empirical analysis on the scalability of the algorithms .
The rest of this paper is organized as follows . In Section 2 , we give basic definitions , and in Section 3 , we present our online algorithm . In Section 4 , we modify this algorithm in the forgetting model . In Section 5 , we report experimental results , and in Section 6 , we conclude . For proofs not found here , see [ 5 ] .
1.1 Related Works
Emerging technologies of semi structured data have attracted wide attention of networks , e commerce , information retrieval and databases [ 2 , 19 ] . In contrast , there have not been many studies on semi structured data mining [ 1 , 4 , 7 , 9 , 13 , 15 , 16 , 20 , 22 ] . There are a body of researches on online data processing and mining [ 10 , 14 , 18 ] . Most related work is Hidber [ 11 ] , who proposed a model of continuous pattern discovery from unbounded data stream , and presented adaptive online algorithm for mining association rules . Parthasarathy et al . [ 17 ] and Mannila et al . [ 14 ] studied mining of sequential patterns and episode patterns . Yamanishi et al . [ 21 ] presented an efficient online outlier detection system SmartSifter with a forgetting mechanism .
Zaki [ 22 ] and Asai et al . [ 4 ] independently developed efficient pattern search techniques , called rightmost expansion , for semi structured data , which is a generalization of the set enumeration tree technique [ 6 ] . Although our algorithm partly uses this technique , its design principle is different from previous semi structured data mining algorithms [ 4 , 7 , 9 , 13 , 15 , 16 , 20 , 22 ]
2 Preliminaries
2.1 Model of Semi Structured Data
Semi structured data are heterogeneous collections of weakly structured data [ 2 ] , which are typically encoded in a markup language such as XML [ 19 ] . We model semi structured data and patterns [ 2 ] by labeled ordered trees . For the basic terminologies on trees , we refer to , eg [ 3 ] .
Labeled Ordered Trees . We define labeled ordered trees according to [ 4 , 12 ] . Let L = {ℓ , ℓ0 , ℓ1 , . . .} be a fixed alphabet of labels . Then , a
2 labeled ordered tree on L ( tree , for short ) is a labeled , rooted , connected directed acyclic graph T = ( V , E , B , L , v0 ) with the following properties [ 3 ] . Each node v ∈ V of T is labeled by an element L(v ) of L , and all node but the root v0 have the unique parent by the child relation E ⊆ V 2 . For each node v , its children are ordered from left to right by an indirect sibling relation B ⊆ V 2 [ 3 ] . Note that the term ordered means the order not on labels but on children .
The size of a tree T is the number of its nodes |T | = |V | . Throughout this paper , we assume that a tree of size k has the node set V = {1 , . . . , k} and the nodes are ordered in the pre order by the depth first search order on T . We refer to the node i as the i th node of T . This assumption is crucial in our discussion . By this assumption , the root and the rightmost leaf of T , denoted by root(T ) and rml(T ) , are always 1 and k , respectively . For a tree T of size k , the rightmost branch of T , denoted by RM B(T ) , is the path from the root 1 to the rightmost leaf k of T .
We denote by T the class of all labeled ordered trees on L . We also refer to V , E , B and L as VT , ET , BT and LT , respectively , if it is clear from context .
Matching and Occurrences . Next , we define the notion of matching between two labeled ordered trees T and D . A pattern tree T matches a data tree D if T can be embedded in D with preserving the labels , the ( direct ) child relation , the ( indirect ) sibling relation by a non collapsing mapping , that is , there exists some function ϕ : VT → VD that satisfies the following ( i)–(iv ) for any v , v1 , v2 ∈ VT :
( i ) ϕ is one to one .
( ii ) LT ( v ) = LD(ϕ(v) ) . ( iii ) ( v1 , v2 ) ∈ ET iff ( ϕ(v1 ) , ϕ(v2 ) ) ∈ ED . ( iv ) ( v1 , v2 ) ∈ BT iff ( ϕ(v1 ) , ϕ(v2 ) ) ∈ BD .
Then , we say that ϕ is a matching function of T to D , or T occurs in D . We assume the empty tree ⊥ such that |⊥| = 0 and ⊥ matches to any tree at any node . An embedding of T in D wrt ϕ is the image ϕ(T ) ⊆ VD of T into D , whose induced subgraph is isomorphic to T . We define the root occurrence and the rightmost leaf occurrence of T in D wrt ϕ by the nodes ϕ(1 ) and ϕ(k ) of D to which the root and the rightmost leaf of T map , respectively . If ϕ is not irrelevant then we simply omit ϕ .
For example , Fig 1 shows examples of labeled ordered trees D and T on L = {A , B} . We see that the pattern tree T matches the data tree D , where the matching is designated with a set of arrows from T to D . The
3
1
R
D
2
A
3
A
4
B
5
A
6
B
8
A
7
9
A
A
T
1
A
10
B
2
A
3
B
Figure 1 : A data tree D and a pattern tree T on the set L = {A , B} of labels root occurrences of T in D are 2 and 7 , while the rightmost occurrences are 4 , 6 , and 10 .
Semi structured Data Streams . Let D be a labeled ordered tree , called a data tree with finite depth and possibly infinite width . Given a collection of trees as a data source , we always treat them as a single tree by combining trees with appending the imaginary common root . Recall that the nodes of D are numbered in the preorder traversal of D .
We introduce a convenient sequential representation of labeled ordered trees . The depth of node v of tree T is the number of edges on the path from the root to v . The depth label representation of a node v of D is the pair ( d , ℓ ) ∈ N × L of the depth d and the label ℓ of v . Then , a data tree D is encoded as the sequence π = ( (d1 , ℓ1 ) , ( d2 , ℓ2 ) , . . . ) of depth label pairs corresponding to the nodes on the pre order traversal of T . This depthlabel representation π also linearly related to the open close parentheses representation as in XML [ 19 ] .
Conversely , we can uniquely decode a depth label representation π into a labeled ordered tree as follows .
Definition 4 ( [4 , 22 ] ) Let S be a tree of size k ≥ 1 . Then , a rightmost expansion of S is any tree T of size k + 1 obtained from S by ( i ) attaching a new node w with a label in L as a child of a parent node p on the rightmost branch of S so that ( ii ) w is the rightmost sibling of p . Then , we say that T is a successor of S , or S is a predecessor of T . If the depth and the label of w is d ∈ N and ℓ ∈ L , resp . , then T is called the ( d , ℓ) expansion of S . The ( 0 , ℓ) expansion of ⊥ is the single node tree with label ℓ .
Thus , the empty sequence ε transforms to the empty tree ⊥ , and if the sequence π transforms to a tree S , then the sequence π · ( d , ℓ ) to the ( d , ℓ)expansion of S . The notion of depth label representation is motivated by the tree expansion technique [ 4 , 22 ] , and plays an important role in the following discussion .
4
For example , in the previous example of Fig 1 , the data tree D trans forms to the depth label representation π = ( 0 , R ) , ( 1 , A ) , ( 2 , A ) , ( 2 , B ) , ( 2 , A ) , ( 2 , B ) , ( 1 , A ) , ( 2 , A ) , ( 2 , A ) , ( 2 , B ) , and vice versa .
We model a semi structured data stream as an infinite sequence of the nodes generated by the depth first scanning of a possibly infinite data tree as follows . For a set A , we denote by A∞ the sets of all infinite sequences on A . A semi structured data stream for D is an infinite sequence S = ( v1 , v2 , . . . , vi , . . . ) ∈ ( N × L)∞ , where for every i ≥ 1 , the i th element vi = ( di , ℓi ) is the depth label representation of the i th node vi = i of D . Then , vi is called the i th node of S and i is called the time stamp . The i th left half tree , denoted by Di , is the labeled ordered tree that is the induced subgraph of D consisting of the first i nodes ( v1 , v2 , . . . , vi ) of the traversal . Online Data Mining Problems . Now , our online data mining problem is stated as follows . The definition of the frequency of a pattern T at time i will be specified later .
Definition 5 ( Online Frequent Pattern Discovery from Semi structured Data Streams ) Let 0 ≤ σ ≤ 1 be a nonnegative number called the minimum support . In our online mining protocol , for stages i = 1 , 2 , . . . , an online mining algorithm A iterates the following process : A receives the i th node vi from the stream S , updates its internal state based on the first i nodes v1 , . . . , vi received so far , and then on request by a user A reports a set Fi of frequent patterns that appears in Di with frequency no less than σ .
The goal of an online algorithm is to continuously work on unbounded stream for arbitrary long time with bounded resources , and to quickly answer user ’s queries at any time .
We define the models of the frequency of patterns as follows . Let i ≥ 1 be any time . For every 1 ≤ j ≤ i , we define the indicator function hit(i ) j ( T ) = 1 if the pattern T has a root occurrence at the node vj in Di . Otherwise , we define hit(i ) j ( T ) = 0 . For a technical reason , we require not only ϕ(1 ) but also the whole ϕ(T ) to be contained in Di .
Definition 6 Let S be a given semi structured data stream and T ∈ T be any pattern . Below , counti(T ) and f reqi(T ) denote the count and the frequency of T at time i , resp .
• Online Model ( OL ) . In this model motivated by Hidber [ 11 ] , we count the number of distinct root occurrences of T in Di . The frequency of T at time i is : f reqi(T ) = 1 j=1 hit(i ) j ( T ) i counti(T ) = 1 i Pi
5
• Forgetting Model ( FG ) . In the forgetting model , eg , [ 21 ] , the contribution of the past event decays exponentially fast . For positive number 0 < γ < 1 called a forgetting factor , the frequency of T is defined by : j=1 γi−j hit(i ) j ( T ) .
( 1 ) f req fg γ,i(T ) = 1
Zi Pi
Although we used a simplified normalization factor Zi = i instead of a more precise one Zi = Pi j=1 γi−j , most of the discussion in the later sections also holds .
A difference of above models is the speed of decay . Since the effect of a past event decays exponentially faster in FG than in OL , the former is more trend conscious than the latter . We can deal with the sliding window model in this framework in a similar manner . For details , see [ 5 ] .
3 Online Mining Algorithms
In this section , we present an online algorithm StreamT for solving the online frequent pattern discovery problem from semi structured data stream .
3.1 Overview of the Algorithm
In Fig 2 , we show our algorithm StreamT in the online model . Let S = ( v1 , v2 , . . . , vi , . . . ) ∈ ( N × L)∞ be a possibly infinite data stream for a data tree D . Through the stages i = 1 , 2 , . . . , StreamT receives the i th node vi = ( di , ℓi ) from S , updates a pool C ⊆ T of candidate patterns and the internal state , and on request reports a set of frequent labeled ordered trees Fi ⊆ T with frequency no less than a given threshold 0 ≤ σ ≤ 1 .
To continuously compute the set of frequent patterns on an unbounded stream , the algorithm uses a technique , similar to plane sweeping in computational geometry [ 8 ] , to find all root occurrences of candidate patterns in D . A basic idea of our algorithm is explained as follows . To detect all embeddings of a set of patterns in D , we sweep a path from the root to the currently scanned node vi , called the sweep branch , rightwards over the data tree D by increasing the stage i = 1 , 2 , . . While we sweep the plane , we keep track of all embedding of patterns that intersect the current sweep branch .
The algorithm incrementally maintains the following data structures dur ing the computation .
• A set C ⊆ T of patterns , called the candidate pool .
6
Algorithm StreamT Input : A set L of labels , a data stream ( v1 , v2 , . . . , vi , . . . ) of a data tree D , and a frequency threshold 0 ≤ σ ≤ 1 .
Output : A sequence ( F1 , F2 , . . . , Fi , . . . ) of sets of frequent patterns , where Fi is the set of frequent patterns for every i .
Variables : The candidate pool C ⊆ T , and the bucket stack B = ( B[0 ] , . . . , B[T op] ) . Method :
1 . C := the class of all single node patterns ;
B := ∅ and T op = −1 ; i := 1 ;
2 . While there is the next node vi = ( d , ℓ ) , do the followings :
( a ) Update the bucket stack B[0 ] · · · B[d − 1 ] :
( B , EXP ) := UpdateB(B , C , ( d , ℓ ) , i ) ;
( b ) Update the candidate pool C and the bucket B[d ] :
( B , C ) := UpdateC(EXP , B , C , ( d , ℓ ) , i ) ;
( c ) Output the set Fi = { T ∈ C | f reqi(T ) ≥ σ } of frequent patterns ; i = i + 1 ;
Figure 2 : An online mining algorithm for semi structured data stream
• A stack B = ( B[0 ] , B[1 ] , . . . , B[T op ] ) of buckets , called the sweep branch stack ( SB stack , for short ) .
For each candidate T ∈ C , the following features are associated : A counter count(T ) of the root occurrences of T in Di . A vector RtoT = ( RtoT [ 0 ] , RtoT [ 1 ] , . . . ) of the latest root occurrences RtoT [ d ] = ρ of T with depth d .
3.2
Incremental Pattern Discovery Using Tree Sweeping
To keep track of all embeddings of candidate patterns , we do not need the whole information on them . Instead , we record the information on the intersections of these embedding and the current sweep branch at every stage .
Let i ≥ 1 be any stage . In what follows , we denote by vi , Di and SBi the present node , the left half tree and the sweep branch at stage i . In other words , SBi is the rightmost branch of Di .
For pattern T , let ϕ(T ) be an embedding of T with some matching ϕ : VT → VD of T to Di . Since an embedding of a tree is also an ordered tree
7
D
Di
SBi i 1 i
Figure 3 : The i th left half tree Di and i th sweep branch SBi for the data tree D
T
Di r b
φ(T )
SBi
Figure 4 : The root and the bottom occurrences r and b of pattern T on Di wrt the sweep branch SBi with matching φ . in Di , we can define the rightmost branch , denoted by RM B(ϕ(T ) ) ⊆ VD , of ϕ(T ) in Di . During the scan of D , the sweep branch SBi ⊆ VD may have nonempty intersection SBi ∩ RM B(ϕ(T ) ) with RM B(ϕ(T ) ) .
Lemma 1 For any embedding ϕ(T ) of a pattern T and the sweep branch SBi , the intersection SBi ∩ RM B(ϕ(T ) ) is a consecutive path in D .
From the above lemma , we define the root and the bottom occurrences of T wrt ϕ to be the highest and the lowest nodes in the intersection SBi ∩ RM B(ϕ(T ) ) ( Fig 4 ) . We can easily see that if the intersection SBi ∩ RM B(ϕ(T ) ) is contained in SBi then the corresponding bottom occurrence becomes the rightmost occurrence of T wrt ϕ . The next lemma gives an incremental characterization of the rightmost occurrences , which enables us to detect all rightmost occurrences of candidate patterns by maintaining all bottom occurrences of their predecessors on the sweep branch using the SB stack .
Lemma 2 Let T ∈ T be any pattern of size k > 1 . At every time i ≥ 1 , T has a rightmost occurrence at the current node vi in Di iff there exists some
8 pattern S of size ( k − 1 ) that has a bottom occurrence at the parent of vi in Di and such that T is the ( d , ℓ) expansion of S , where d is the depth of the current node vi , r is the depth of the root occurrence of T corresponding to the bottom occurrence , and ℓ = L(vi ) is the label of vi . This is also true even if k = 1 .
To implement this idea , we use the sweep branch stack B = ( B[0 ] , B[1 ] , . . . , B[T op ] ) to record the intersections of embeddings of patterns with the current sweep branch SBi . T op ≥ 0 is the length of SBi . Each bucket B[b ] ( 0 ≤ b ≤ T op ) contains a set of triples of the form τ = ( T , r , b ) such that pattern T has the root and the bottom occurrences of the depths r and b , respectively , on SBi . For each bucket B[d ] , the time stamp B[d].time ∈ N of the last time is associated with the bucket .
For any stage i ≥ 1 , the SB stack B = ( B[0 ] , B[1 ] , . . . , B[T op ] ) is said to be up to date wrt the present sweep branch SBi if T op is the length of SBi , and for every 0 ≤ b ≤ T op , the bucket B[b ] contains all triples ( T , r , b ) ∈ T × N × N for some T ∈ C and r ∈ N such that the pattern T appears in Di and has the root and the bottom occurrences on SBi of the depths r and b , respectively ( Fig 4 ) . Then , we also say that each bucket B[b ] is up to date if no confusion arises . Note that the up to date stack is unique at time i . Now , we give a characterization of the contents of the current SB stack Bi inductively .
Lemma 3 Let i ≥ 1 and vi = ( d , ℓ ) be the current node of the data stream S for D . Let Bk = ( Bk[0 ] , Bk[1 ] , . . . , Bk[T opk ] ) be the SB stack at time k ∈ {i − 1 , i} . Suppose that both of the SB stacks Bi and Bi−1 are up todate . Then , the following 1 – 4 hold :
1 . For any 0 ≤ b < d − 1 , τ ∈ Bi[b ] if and only if τ ∈ Bi−1[b ] . 2 . For b = d − 1 , τ ∈ Bi[d − 1 ] if and only if either ( i ) or ( ii ) below holds :
( i ) τ ∈ Bi−1[d − 1 ] . ( ii ) τ is represented as τ = ( T , r , d − 1 ) for some tuple ( T , r , b ) ∈
Bi−1[d ] ∪ · · · ∪ Bi−1[T opi−1 ] such that r ≤ d ≤ b .
3 . τ ∈ Bi[d ] if and only if τ = ( T , r , b ) and either ( i ) or ( ii ) below holds :
( i ) T is the single node tree with the label ℓ . ( ii ) T is the ( d − r , ℓ) expansion of S for some triple ( S , r , d − 1 ) ∈
Bi[d − 1 ] .
4 . For any b > d , Bi[b ] is undefined .
9
0 1 d 1 d Top
Bi 1
UNCHANGE
REMOVE
CHANGE
Bi
EXP
Figure 5 : SB stacks from time i − 1 to i
Fig 5 illustrates how to update the sweep branch stack Bi−1 based on Lemma 3 . Suppose that we receive the i th node ( d , ℓ ) from a data stream . Then , the triples in UNCHANGE buckets , ie , B[0 ] ∪ · · · ∪ B[d − 1 ] , stay unchanged . The buckets in B[d]∪· · ·∪B[T op ] are partitioned into REMOVE and CHANGE . The triples in REMOVE buckets are discarded , and triples in CHANGE buckets move to the bucket B[d − 1 ] . For all triples in B[d − 1 ] , we apply the rightmost expansion and then insert obtained expansions into EXP .
In Fig 6 , we show the algorithm UpdateB for incrementally updating the SB stack . At any stage i ≥ 1 , UpdateB updates the first d − 1 buckets Bi[0 ] · · · Bi[d − 1 ] of new one . The d th bucket is not immediately updated , but the updated contents are separately returned as EXP for computing the bucket Bi[d ] in further processing . The following corollary is immediately from Lemma 3 .
Corollary 4 For every time invoked in the while loop in StreamT of Fig 2 at time i ≥ 1 with the current node vi = ( d , l ) , the algorithm UpdateB(B , C , ( d , ℓ ) , i ) returns the followings : ( i ) The sequence B[0 ] , . . . , B[d − 1 ] of buckets that are up to date at time i up to depth d − 1 . ( ii ) The set EXP of all triples corresponding to the bottom occurrences on SBi whose depth is d and predecessors belong to C .
3.3 Duplicate Detection for the Root Occurrences
From the observations above , the algorithm UpdateB ( Fig 6 ) detects all rightmost leaf occurrences of the patterns whose predecessors belong to C at Step 2 and Step 3 .
10
Algorithm UpdateB(B , C , ( d , ℓ ) , i ) Input : A bucket stack B = ( B[0 ] , B[1 ] , . . . , B[T op] ) , a candidate pool C , a depthlabel representation vi = ( d , ℓ ) ∈ N × L of the ith node of the data stream S , and the current time i ;
Output : A set EXP ⊆ T × N × N of triples ; Method :
1 . If d ≤ T op , then do the followings : – BELOW := B[d ] ∪ . . . ∪ B[T op ] ; – /* Discard the triples below the branching point */
REM OV E := { ( T , r , b ) ∈ BELOW | r ≥ d } ;
– /* Collect the triples across the branching point */
CHAN GE := { ( T , r , b ) ∈ BELOW | r ≤ d − 1 } ; – /* Change the bottom occurrences of the triples */
B[d − 1 ] := B[d − 1 ] ∪ { ( T , r , d − 1 ) | ( T , r , b ) ∈ CHAN GE } ;
2 . EXP := {(Tℓ , d , d)} , where Tℓ is the single node tree with the label ℓ ; 3 . For each ( S , r , d − 1 ) ∈ B[d − 1 ] do the followings :
– T is the ( d − r , ℓ) expansion of S ; – EXP := EXP ∪ { ( T , r , d ) } ;
4 . Return ( B , EXP ) ;
Figure 6 : Updating the SB stack
11
Then , the next step is to compute the corresponding root occurrences from these rightmost occurrences . Let b ∈ VD be a rightmost occurrence of pattern T whose triple ( T , r , b ) is detected at Step 2 or Step 3 of UpdateB . Recall that a list RtoT = ( RtoT [ 0 ] , RtoT [ 1 ] , . . . ) is associated with each T ∈ C and it is initially empty . Then , we can obtain the root occurrence corresponding to the triple by the following procedure FindRootOcc :
FindRootOcc(B , ( T , r , b ) )
• Let t := B[r].time and ρ := vt ; • If RtoT [ r ] = ρ then return UNDEF ; • Otherwise , RtoT [ r ] := ρ and return ρ as the root occurrence of T ; ( Duplicate check )
Figure 7 : Finding root occurrences
It is easy to observe that FindRootOcc correctly finds the root occurrence as follows . If the sweep branch SBi intersects an embedding of T wrt a matching ϕ then it also intersects the root occurrence of T wrt ϕ , and thus the component r of ( T , r , b ) correctly gives the depth of a root occurrence , say , w ∈ VD . By definition , B[r].time stores the time stamp , say t , of the node on SBi whose depth is r when it is first encountered . Thus , vt = w gives the root occurrence corresponding to the triple .
Furthermore for a fixed r , any node w′ occupies the bucket B[r ] in a consecutive period during the scanning of S . Thus , it is sufficient to record the last root occurrence of depth r for each depth r ≥ 0 in order to check the duplication of the occurrences . Hence , we see that FindRootOcc correctly detect the root occurrence of candidate patterns without duplicates .
3.4 Candidate Management
The algorithm StreamT stores candidate patterns in a candidate pool C ⊆ T . Fig 8 shows an algorithm UpdateC for managing C by updating the frequency count of each patterns . A root occurrence has monotonicity that if pattern T is a rightmost most expansion of pattern S then the root count of S is greater than or equal to the root count of T . Based on this observation , the algorithm UpdateC uses a candidate management policy similar to Hidber [ 11 ] , which is summarized as follows .
• Initialize . We insert all single node patterns into C . This is done at
Step 1 of the algorithm StreamT
12
• Increment . We increment count(T ) for all pattern trees T ∈ C that has the rightmost occurrence at the current node vi , ie , count(T ) = count(T ) + 1 .
• Insert . We insert a pattern of size more than one if its unique predecessor S is already contained in C and becomes frequent , ie , f req ( S ) ≥ σ based on the monotonicity of f req ( S ) wrt rightmost expansion . This is an on demand version of the insertion policy of [ 11 ] . If some pattern becomes frequent then insert all of its successors to the candidate pool .
• Delete . We delete a pattern T from C when its unique predecessor P becomes infrequent , ie , f req ( T ) < σ . To be consistent to the initialization and the insertion policy , we do not delete any single nodes . As suggested in [ 11 ] , we postpone the deletion of the patterns from C until the algorithm requires additional space .
As summary , our algorithm StreamT tries to maintain the negative border [ 17 ] , the set of all patterns that are infrequent but whose predecessors are frequent .
3.5 Time Analysis
We give theoretical analysis of the update time of the algorithm StreamT at stage i . Let Bi−1 be the previous SB stack of top T op and Nj = |Bi−1[j]| be the number of triples in the j th bucket . If a node of depth d is received , then UpdateB updates the SB stack in O(PT op j=d−1 Nj ) time . Then , UpdateC updates pattern pool C in O(kC + D ) time , where k is the maximum pattern size , C is the number of candidates in C that occur at the current node vi by the rightmost leaf occurrence , and D is the number of removed candidates in the stage .
4 Modification to the Forgetting Model
The algorithm StreamT in Fig 2 is an online algorithm for the online frequent pattern discovery problem in the online model of Definition 6 . Now we present modification of StreamT to the forgetting model also introduced in Definition 6 .
Recall that in the forgetting model , the contribution of the past event decays exponentially fast . For a forgetting factor 0 < γ < 1 , the frequency of T at time i is given by Eq 1 in Section 2 . At first look , implementation of
13
Algorithm UpdateC(EXP , B , C , ( d , ℓ ) , i ) Input : A set EXP of triples , a bucket stack B = ( B[0 ] , B[1 ] , . . . , B[T op] ) , a candidate pool C , the i th node vi = ( d , ℓ ) ∈ N × L of the data stream , and the time i ;
Output : The updated pair ( B , C ) ; Method :
1 . /* Increment candidates */
For each triple ( T , r , b ) ∈ EXP , do :
If ρ := FindRootOcc(B , ( T , r , b ) ) is not UNDEF then – If T ∈ C then count(T ) := count(T ) + 1 ; – If T 6∈ C and the predecessor of T is frequent , then count(T ) := 1 and C := C ∪ {T } ; 2 . B[d ] := ∅ ; T op := d ; B[d].time := i ; f req(T ) := count(T )/i ; 3 . /* Delete candidates */
For each pattern T ∈ C and the predecessor of T is infrequent at time i and frequent at time i − 1 ,
– C = C\{T } ;
4 . /* Insert candidates in B[d ] */ For each triple ( T , r , b ) ∈ EXP ,
– If T ∈ C then B[d ] := B[d ] ∪ {(T , r , b)} ;
5 . Return ( B , C ) ;
Figure 8 : Updating the candidate pool the forgetting model is as easy as the online model above because they only differ in the definition of the frequency . In the forgetting model , however , the frequency at time i depends on all of the weights γi−j of past events changing as i ≥ 1 goes larger . Thus , it seems that an algorithm have to maintain all of these weights at every time . Fortunately , this is not true .
We abbreviate the frequency f req fg j ( T ) , respectively , to f ri and hitj . Below , we give an incremental method to compute the frequency . Let lt(i ) = max{ j ≤ i | hitj = 1 } be the last time stamp at which T appeared . Then , we have the following lemma .
γ,i(T ) and the event hit(i )
Lemma 5 For every T ∈ T and every i ≥ 1 , we have the recurrence f r0 = 0 , f ri = lt(i ) i−1 γi−lt(i ) f rlt(i ) + 1 i hiti
( i > 0 )
( 2 )
14
IncFreq(T , i )
• If hiti(T ) = 1 then F r(T ) := lt(T ) • If T 6∈ C then f t(T ) := i ; i−1 γ i−lt(T ) f r(T ) + 1 i hiti(T ) and lt(T ) := i ;
GetFreq(T , i )
• If hiti(T ) = 1 then IncFreq(T , i ) and return F r(T ) ; • Otherwise , return lt(T ) i−1 γ i−lt(T ) f r(T ) ;
Figure 9 : Updating and Computing the Frequency
0.14 0.12 0.10 0.08 0.06 0.04 0.02 0.00
1
10
100
1000
 !  
10000
100000
Figure 10 : The upper bound of the frequency error against the life time with γ = 0.999
Proof . We first derive the recurrence for the consecutive steps . Then , derive the recurrence of the lemma by expanding f ri using lt(i ) . Since hitu = 0 for any u with lt(i ) < u < i , the claim immediately follows . 2
Now , we present a modified version of StreamT in the forgetting model . We modify the algorithms StreamT and UpdateC ( Fig 8 ) as follows . StreamT maintains the three parameters f r(T ) , f t(T ) , lt(T ) , the frequency , the first and the last time stamps of the updates for T . UpdateC uses IncFreq to update these parameters whenever a root occurrence of pattern T is detected at Step 1 , and Stream uses GetFreq to compute the frequency of T whenever it receives a request at Step 2(c ) . We can see IncFreq(T , i ) and GetFreq(T , i ) can be executed in constant time when invoked by these procedures .
Then , we will present an upper bound of the error to estimate the true frequency of a pattern in this model . The life time of a pattern T is the period ∆i = i − f t(T ) ≥ 0 . The following theorem says that the error
15
WW
W
«
ªË ¼ «
P º ¼ Ê
M ¼
  Ë
Ì
WW
Y W
YWW
X W
XWW
W
W
W
YWWWW
WWWW
WWWW
WWWW
XWWWWW
XYWWWW
X WWWW
X WWWW
Ì ¼ M ½M »¼Ê
Figure 11 : the online scale up experiment becomes exponentially smaller in the forgetting model as the life time ∆i of T goes longer .
Theorem 6 Let i ≥ 1 , 0 < γ < 1 , and ε = 1 − γ . For any T ∈ C with the life time ∆i = i − f t(T ) at time i , the following inequality holds :
GetFreq(T , i ) ≤ f req fg γ,i(T ) ≤ GetFreq(T , i ) +
1 εi e−ε∆i .
Proof . By standard arguments using elementary calculus , Eqs . 1 − γx ≤ 1 and ( 1 − ε)x ≤ e−εx ( x ≥ 0 ) . 2
In Fig 10 , we plot the upper bound of the frequency error given by Theorem 6 varying the life time from ∆i = 1 to ∆i = 100 , 000 , where γ = 0.999 and i = 1000 , 000 . A half value period is about seven thousands for γ .
5 Experimental Results
In this section , we present preliminary experimental results on real life datasets to evaluate the algorithm StreamT . We prepared a dataset Citeseers by collecting cgi generated Web pages from an online bibliographic archive Citeseers 1 . This dataset consists of 189 HTML documents of 5.6MB and its data tree had 143,250 nodes . All experiments were performed on PC ( PentiumIII 500MHz , 512MB RAM , Windows2000 ) and the algorithm was implemented in Java ( SUN JDK131 , JIT compiler ) .
We studied the scalability of StreamT . Fig 11 shows the running times of the online version StreamT and the offline version FREQT [ 4 ] of frequent tree
1http://citeseernjneccom/
16 miners with the same frequency threshold σ = 2( % ) on the data stream for the dataset Citeseers varying the data size from 16K(nodes ) to 143K(nodes ) . From this experiment , the proposed online algorithm StreamT seems to be much more efficient than the offline algorithm FREQT . However , this is possibly because our algorithm computes approximate answers due to candidate management policy in Sec 3.4 due to [ 11 ] and two algorithms may generate different sets of patterns . Therefore , to compare the performance of those algorithms , we require further research .
6 Conclusion
In this paper , we studied an online data mining problem from unbounded semi structured data stream . We presented efficient online algorithms that are continuously working on an unbounded stream of semi structured data with bounded resources , and find a set of frequent ordered tree patterns from the stream on request at any time .
Our labeled ordered trees can be seen as a generalization of serial episodes of Mannila et al . [ 14 ] , and of itemsets and sequential patterns with a preprocessing of data as used for encoding XML attributes in [ 4 ] . Thus , it will be an interesting problem to study the relationship of our algorithms to other online algorithms for classes of patterns such as sequential patterns and episodes .
It is also a future problem to examine the online property of the proposed algorithms using long and trend changing semi structured data streams in the real world .
Acknowledgments
Hiroki Arimura is grateful to Masaru Kitsuregawa for his direction of the author ’s interests to online data processing . The authors would like to thank Hiroshi Motoda , Takeshi Tokuyama , Akihiro Yamamoto , Yoshiharu Ishikawa , and Mohammed Zaki for fruitful discussions on web mining .
References
[ 1 ] K . Abe , S . Kawasoe , T . Asai , H . Arimura , and S . Arikawa . Optimized Substructure Discovery for Semi structured Data , In Proc . PKDD’02 , 1–14 , LNAI 2431 , Springer , 2002 .
17
[ 2 ] S . Abiteboul , P . Buneman , D . Suciu , Data on the Web , Morgan Kauf mann , 2000 .
[ 3 ] Aho , A . V . , Hopcroft , J . E . , Ullman , J . D . , Data Structures and Algo rithms , Addison Wesley , 1983 .
[ 4 ] T . Asai , K . Abe , S . Kawasoe , H . Arimura , H . Sakamoto , and S . Arikawa . Efficient Substructure Discovery from Large Semistructured Data . In Proc . the 2nd SIAM Int’l Conf . on Data Mining ( SDM2002 ) , 158–174 , 2002 .
S . Arikawa .
[ 5 ] T . Asai , K . Abe , S . Kawasoe , H . Arimura , H . Sakamoto , SemiDOI Technical Report , Dept . of 2002 . and structured Data Stream , Informatics , ftp://ftpikyushu uacjp/pub/tr/trcs211psgz
Kyushu Univ . ,
Online Algorithms for Mining
DOI TR
211 ,
June
[ 6 ] R . J . Bayardo Jr . , Efficiently Mining Long Patterns from Databases ,
In Proc . SIGMOD98 , 85–93 , 1998 .
[ 7 ] G . Cong , L . Yi , B . Liu , K . Wang , Discovering Frequent Substructures from Hierarchical Semi structured Data , In Proc . SDM2002 , 175–192 , 2002 .
[ 8 ] M . de Berg , M . van Kreveld , M . Overmars , O . Schwarzkopf , Compu tational Geometry , Algorithms and Applications , Springer , 2000 .
[ 9 ] L . Dehaspe , H . Toivonen , R . D . King , Finding Frequent Substructures in Chemical Compounds , In Proc . KDD 98 , 30–36 , 1998 .
[ 10 ] P . B . Gibbons and Y . Matias , Synopsis Data Structures for MasIn External Memory Algorithms , DIMACS Series in sive Data Sets , Discr . Math . and Theor . Compt . Sci . , Vol . 50 , AMS , 39–70 , 2000 .
[ 11 ] C . Hidber , Online Association Rule Mining ,
In Proc . SIGMOD’99 ,
145–156 , 1999 .
[ 12 ] P . Kilpelainen , H . Mannila , Ordered and Unordered Tree Inclusion ,
SIAM J . Comput , 24(2 ) , 340–356 , 1995 .
[ 13 ] M . Kuramochi , G . Karypis ,
Frequent Subgraph Discovery ,
In Proc . ICDM’01 , 313–320 , 2001 .
[ 14 ] H . Mannila , H . Toivonen , and A . I . Verkamo , Discovering Frequent
Episode in Sequences , In Proc . KDD 95 , 210–215 , AAAI , 1995 .
18
[ 15 ] T . Matsuda , T . Horiuchi , H . Motoda , T . Washio , K . Kumazawa , N . Arai , Graph Based Induction for General Graph Structured Data , In Proc . DS’99 , 340–342 , 1999 .
[ 16 ] T . Miyahara , Y . Suzuki , T . Shoudai , T . Uchida , K . Takahashi , H . Ueda , Discovery of Frequent Tag Tree Patterns in Semistructured Web Documents . In Proc . PAKDD 2002 , 341–355 , 2002 .
[ 17 ] S . Parthasarathy , M . J . Zaki , M . Ogihara , S . Dwarkadas , Incremental and Interactive Sequence Mining , In CIKM’99 , 251–258 , 1999 .
[ 18 ] R . Rastogi , Single Path Algorithms for Querying and Mining Data
Streams , In Proc . SDM2002 Workshop HDM’02 , 43–48 , 2002 .
[ 19 ] W3C , Extensive Markup Language ( XML ) 1.0 ( Second Edition ) , W3C
Recommendation , 06 October 2000 . http://wwww3org/TR/REC xml
[ 20 ] K . Wang , H . Liu , Discovering Structural Association of Semistructured
Data , TKDE , 12(2 ) , 353 371 , 2000 .
[ 21 ] K . Yamanishi , J . Takeuchi , A Unifying Framework for Detecting OutIn liers and Change Points from Non Stationary Time Series Data , Proc . SIGKDD 2002 , ACM , 2002 .
[ 22 ] M . J . Zaki .
Efficiently mining frequent trees in a forest ,
In
Proc . SIGKDD 2002 , ACM , 2002 .
19
A Appendix : Modification to the Sliding Window
Model
In addition to the forgetting model , we can deal with the sliding window model , defined as follows , in a similar manner .
In this model Definition 7 ( Sliding Window Model ) motivated by Mannila et al . [ 14 ] , we count the number of the distinct root occurrences in the i th sliding window Wi = ( vi−w+1 , . . . , vi ) of most recent w nodes of S . If we define δw k = 0 otherwise . Then , the frequency is defined by : k = 1 if 0 ≤ k < w and δw
Let w ≥ 1 . f req sw w,i(T ) =
1 w countsw w,i(T ) =
1 w i X j=1 i−j hit(i ) δw j ( T ) .
It is easy to modify StreamT into a mining algorithm in the sliding window model . In this model , we replace the calculation of the frequency f reqi(T ) = counti(T )/i with f req sw i,w(T ) = counti(T )/w , where i is the current time and w is the given window size . Therefore , the modified algorithm for the sliding window model computes the frequent patterns in the i th window Wi = ( vi−w+1 , . . . , vi ) of width w for any stage i . To remove an old root occurrence out of the window , we store the list RT O(T ) of the root occurrences in the window Wi for all trees T . To manage the root occurrence lists RT O(T ) in the sliding window model , we add the following operations to the algorithm UpdateC of Fig 8 in the online model : ( i ) remove the node from the occurrence lists that is out of the window Wi before Step 1 , ie , RT O(T ) := RT O(T )\{i − w} for any T ∈ C , ( ii ) at Step 1 , add the root occurrence ρ of T to RT O(T ) for all T ∈ C satisfying the conditions in Step 1 , if ρ 6= rto(T ) , ie , RT O(T ) := RT O(T ) ∪ {ρ} , ( iii ) at Step 4 , create the occurrence list RT O(T ) consisting of the only element ρ for any new candidate T , where ρ is the root occurrence of T .
B Appendix : Proofs of Lemmas
Lemma 1 For any embedding ϕ(T ) of a pattern T and the sweep branch SBi , the intersection SBi ∩ RM B(ϕ(T ) ) is a consecutive path in D .
Proof . Since an embedding ϕ(T ) of a pattern T is also an ordered tree in D , RM B(ϕ(T ) ) is a consecutive path in D . Thus the lemma trivially holds . 2
20
Lemma 2 Let T ∈ T be any pattern of size k > 1 . At every time i ≥ 1 , T has a rightmost occurrence at the current node vi in Di iff there exists some pattern S of size ( k − 1 ) that has a bottom occurrence at the parent of vi in Di and such that T is the ( d − r , ℓ) expansion of S , where d is the depth of the current node vi , r is the depth of the root occurrence of T corresponding to the bottom occurrence , and ℓ = L(vi ) is the label of vi . This is also true even if k = 1 .
Proof . Suppose that ET is an embedding of T in D and its rightmost branch RM B(ET ) intersects SBi with the bottom depth b = d . Then , T has the rightmost occurrence at the current node vi = i . Clearly , ET itself is a tree of size k and the rightmost leaf vi . Let CT is the tree obtained from ET by removing vi . Then , CT is an embedding of the predecessor of T with size k − 1 with the bottom occurrence at the parent of vi = i . Moreover , T is the ( d − r , ℓ) expansion of S , and thus the lemma follows . 2
Lemma 3 Let i ≥ 1 and vi = ( d , ℓ ) be the current node of the data stream S for D . Let Bk = ( Bk[0 ] , Bk[1 ] , . . . , Bk[T opk ] ) be the SB stack at time k ∈ {i − 1 , i} . Suppose that both of the SB stacks Bi and Bi−1 are up to date . Then , the following 1 – 4 hold :
1 . For any 0 ≤ b < d − 1 , τ ∈ Bi[b ] if and only if τ ∈ Bi−1[b ] . 2 . For b = d − 1 , τ ∈ Bi[d − 1 ] if and only if either ( i ) or ( ii ) below holds :
( i ) τ ∈ Bi−1[d − 1 ] . ( ii ) τ is represented as τ = ( T , r , d − 1 ) for some tuple ( T , r , b ) ∈
Bi−1[d ] ∪ · · · ∪ Bi−1[T opi−1 ] such that r ≤ d ≤ b .
3 . τ ∈ Bi[d ] if and only if τ = ( T , r , b ) and either ( i ) or ( ii ) below holds :
( i ) T is the single node tree with the label ℓ . ( ii ) T is the ( d − r , ℓ) expansion of S for some triple ( S , r , d − 1 ) ∈
Bi[d − 1 ] .
4 . For any b > d , Bi[b ] is undefined .
Proof . Since the case 1 , 2 , 3(i ) , and 4 are obvious , we only show the case 3(ii ) . Let τ = ( T , r , b ) ∈ Bi[d ] be a triple in the d th bucket . Then , we can easily see from Lemma 2 that the predecessor S of T is embedded in D with bottom depth d − 1 , and thus ( S , r , d − 1 ) ∈ Bi[d − 1 ] holds . 2
21
