CrowdTC : Crowdsourced Taxonomy Construction
Rui Meng∗ , Yongxin Tong† , Lei Chen∗ , Caleb Chen Cao∗
∗Department of Computer Science and Engineering , HKUST , Hong Kong SAR , China
†SKLSDE Lab and IRI , Beihang University , China
∗{rmeng,leichen,caochen}@cseusthk †yxtong@buaaeducn
Abstract—Recently , taxonomy has attracted much attention . Both automatic construction solutions and human based computation approaches have been proposed . The automatic methods suffer from the problem of either low precision or low recall and human computation , on the other hand , is not suitable for large scale tasks . Motivated by the shortcomings of both approaches , we present a hybrid framework , which combines the power of machine based approaches and human computation ( the crowd ) to construct a more complete and accurate taxonomy . Specifically , our framework consists of two steps : we first construct a complete but noisy taxonomy automatically , then crowd is introduced to adjust the entity positions in the constructed taxonomy . However , the adjustment is challenging as the budget ( money ) for asking the crowd is often limited . In our work , we formulate the problem of finding the optimal adjustment as an entity selection optimization ( ESO ) problem , which is proved to be NP hard . We then propose an exact algorithm and a more efficient approximation algorithm with an approximation ratio of 1 e ) . We conduct extensive experiments on real datasets , the results show that our hybrid approach largely improves the recall of the taxonomy with little impairment for precision .
2 ( 1 − 1
I . INTRODUCTION
With the advanced semantic web and Web 2.0 , significant interests have been growing in using taxonomies to ease information management . Many applications have been observed to benefit from using taxonomies , such as webpage classification [ 1 ] and short term understanding [ 2 ] . In the past few years , many works have been conducted to construct taxonomies , ie , Freebase [ 3 ] , YAGO [ 4 ] , Probase [ 5 ] , etc .
Existing approaches for taxonomy construction can be categorized mainly into two mainstreams : machine based automatic construction [ 5 ] , [ 6 ] , [ 4 ] and human based manual construction [ 7 ] , [ 3 ] . Each approach has its own advantages and disadvantages , in terms of accuracy , efficiency and cost , respectively . Furthermore , the machine based automatic approaches have two categories : pattern based and clusteringbased . Pattern based approaches adopt syntactic patterns to extract and discover relationships , which have high accuracy if the patterns are carefully chosen . However , these approaches suffer from the sparse coverage problem since high quality patterns are rare . A . Ritter [ 8 ] tries to improve the recall by exploring coordinate relations to learn more potential “ isA ” patterns . However , adopting more patterns would induce noises and impair the accuracy . Therefore , pattern based approaches often suffer from the issue of either low recall or low precision . Clustering based approaches cluster terms based on semantic similarities on some quantifiable features .
These approaches can have a high coverage , however , they do not have high accuracy compared to pattern based approaches . Recently , crowdsourcing has gained its popularity in various domains to handle human intrinsic tasks , such as data cleaning [ 9 ] , [ 10 ] , topic discovery [ 11 ] , etc . Some works have been conducted to explore the power of the crowd in knowledge extraction [ 12 ] , [ 13 ] . However , they either let the crowd to carry the whole burden of the taxonomy construction or target at fact extraction which employs the crowd to fill in the relationships between given entity pairs .
Based on the above discussion , we find that neither automatic techniques nor the crowd based approaches could derive a satisfactory taxonomy . To address the challenges , we propose a hybrid machine crowdsourcing framework to construct a taxonomy with high accuracy and coverage . Note that the coverage of our work is defined as the number of entities the taxonomy covers [ 5 ] . In our framework , we divide the taxonomy construction into two steps . The first step is to build a taxonomy automatically which aims at a high coverage . We first construct a partial taxonomy based on syntactic patterns , then incrementally cluster all extracted entities based on the semantic features . Though have a higher coverage , the enriched taxonomy has much noise which impair its precision . Therefore , in the second step , we take advantage of the crowd power to adjust the entity positions in the “ complete but noisy ” taxonomy , constructed in the first step .
However , it is impossible to employ the crowd to adjust every entity in the taxonomy when processing large scale corpus with limited budget . To assist the crowd and reduce the burden of adjustment , we judiciously select entities to be adjusted and give candidate positions for each selected entity . Therefore , we need to make a decision and pick the most “ beneficial ” entities to ask and adjust . To evaluate the benefit , we model the utility function ; also , each adjustment task is associated with a cost , which is proportional to the number of human intelligence tasks ( HITs ) needed for the adjustment operation . Finally , the adjustment problem is formulated as an entity selection optimization ( ESO ) problem . We prove the ESO problem is NP hard and propose an exact algorithm and an approximation algorithm subsequently .
To summarize , we have made the following contributions : • To the best of our knowledge , we are the first to explore the hybrid framework to combine machine crowd intelligence towards completeness in taxonomy construction
• We formulate the taxonomy adjustment problem as an entity selection optimization ( ESO ) problem and prove it is NP hard . Then , we design an exact solution and an approximation algorithm .
• We conduct extensive experiments to demonstrate that our approach outperforms existing automatic approach and is scalable enough for large corpus .
II . PROBLEM DEFINITION
Definition 1 ( Hypernym/Hyponym Relation ) : A word or a noun phrase X is a hyponym of a word or noun phrase of Y if X is a subtype or instance of Y . It ’s also called an “ isA ” relation .
Definition 2 ( Entity , Concept and Instance ) : Each entity corresponds to a noun or noun phrase extracted from the given corpus . These entities have hypernym/hyponym relations . An instance is such an entity that has no hyponym and a concept ( also a category ) is an entity that has instances or concepts as its hyponyms .
Definition 3 ( Taxonomy ) : Given the corpus of a certain domain , denoted as DC , a taxonomy is a tree structure , denoted as T = ( N , R ) . Each node ei ∈ N represents an entity ( a concept or an instance ) extracted from DC ; each directed edge rij ∈ R represents a hypernym/hyponym relation , ie , rij = ( ei , ej ) means that ei is the hypernym of ej .
Definitions 1 , 2 and 3 give the concepts of hypernym , entity and taxonomy . We regard the taxonomy containing all entities in N as the full taxonomy and a partial taxonomy is a tree containing only a subset of entities in N . The workflow of the hybrid human machine framework is shown in Figure 1 . The main focus of our work is on the crowdasssited entity adjustment , which improves the quality of the taxonomy constructed automatically . Now we formally define the problem of crowd assisted taxonomy adjustment .
Problem Statement . Given a taxonomy Tn constructed automatically from a domain specific corpus and a crowdsourced budget B0 , the problem of crowd assisted taxonomy adjustment aims at improving the quality of Tn as much as possible under the given budget constraint B0 .
III . A HUMAN MACHINE FRAMEWORK
A . Machine based Taxonomy Construction
In this subsection , we focus on the machine based taxonomy construction . The syntactic patterns are first adopted to construct an initial , partial taxonomy and the entities extracted from the corpus are added to enrich the taxonomy based on the taxonomy metric scores .
Partial Taxonomy Construction . We construct the partial taxonomy based on syntactic patterns . In our work , we adopt “ Hearst Patterns ” , which have been widely used and shown to have a high of precision [ 14 ] .
Taxonomy Enrichment . Due to the limited coverage of syntactic patterns , we further improve the coverage of the taxonomy through enrichment procedure . We extract all entities in the corpus through NLP techniques , then use contextual and co occurrence features to derive the taxonomy metric scores . We then incrementally add the entities into the taxonomy . A full taxonomy is constructed by adding entities one by one , which yields a series of partial taxonomies . For each entity , we need to find its optimal position in the partial taxonomy . In our work , we adopt the technique of [ 15 ] , which followed the minimum evolution tree selection criteria to guide the position selection during enrichment process .
When adding an entity , the partial taxonomy T l+1 is the one that induces the least change against the previous one T l : fifiInfo(T l ) − Info(T )fifi
( 1 )
T l+1 = arg min T
Info(T ) =
Info(T ) is the information score of T , which is defined as the sum of the taxonomy metrics among all entity pairs , i≤j,ei,ej∈E d(ei , ej ) . Where , d(ei , ej ) is the semantic distance between entity ei and ej . We use cosine similarity for contextual feature and normalized Pointwise Mutual Information ( nPMI ) for co occurrence feature , the similarity scores is a weighted combination of different feature functions . Note that we convert the similarity score to distance metric through Inverse Min Max Normalization .
Based on the selection strategy in Equation 1 , each entity can find its optimal position . By incrementally insert all entities into the initial , partial taxonomy , we construct a “ complete but noisy ” taxonomy .
B . Crowd assisted Taxonomy Adjustment
1 ) Entity Adjustment Utility : We measure the utility of adjusting an entity as the linear combination of information gain for entity position decision and the expected amendment entity numbers .
Entity Position Uncertainty . In the enrichment procedure , each entity can have a set of candidate positions , the normalized similarity score can be considered as a distribution among all the candidates . The more skewed distribution , the lower uncertainty of a distribution . We adopt Shannon Entropy as the evaluation metric for the uncertainty , denoted as :
U ( ei ) = − ej∈CL(ei ) sim(ei , ej )
Z log sim(ei , ej )
Z
( 2 ) where sim(ei , sj ) is the similarity score of ei and ej and Z is the normalization factor computed by Z = ej∈CL(ei ) sim(ei , ej ) . After adjustment , the correct position is fixed and therefore the entity position uncertainty is reduced to 0 , ie U(e ) = 0 . The information gain of the candidates equals to the delta of uncertainty which is exactly the entity position uncertainty , ie , U ( ei ) = U ( ei ) − U(ei ) = U ( ei ) .
Fig 1 . Hybrid Machine Human Workflow
Position Amendment Benefit . For adjustment operation , we adopt the subtree based adjustment , which means that if ei is moved from pa to pb , then all nodes in the subtree rooted at ei will be moved simultaneously . That is , adjusting an entity is equivalent to adjusting the subtree rooted at that entity , denoted as STRi . As the automatic taxonomy induction techniques incrementally add new entities into the partial taxonomy , an error position would affect the decision of subsequent entities . Furthermore , due to the hierarchical structure of taxonomy , if an entity ei the “ isA ” relationship between ei and its parent P a(ei ) is wrong ) , then all the descendants of ei are misled and therefore should also be adjusted . As the taxonomies usually have shallow depth , eg the maximum and average level of Probase are 7 and 1.086 and the maximum and average level of Freebase are both 1 . Therefore , in our work , we only consider the effect on the selected entity and its direct descendants . is in the wrong position ( eg ,
Consider adjusting an entity ei . If the position of ei is moved from a wrong position to an appropriate position , then we regard the position of this entity as being improved . There are two cases for the adjustment : 1 ) if the position is unchanged according to the crowd answer , no improvement of the position ; 2 ) if the position of ei is changed , position of ei is improved , and the position improvement of its children , e.g , ej , is the probability that “ isA ” relationship between ei and ej is correct . We use expected number of improved entities to define the position amendment benefit . Given an entity set E , the adjustment of each entity will benefit itself and its children , which are not in the selection set , in probability , denoted as :
BE(ei ) = Pchange(ei)[1 +
P r(ei , ej ) ]
( 3 ) ej∈Child(ei)\E where , P r(ei , ej ) is the probability that the “ isA ” relation between ei and ej is correct , P r(ei , ej ) = sim(ei,ej ) , where sim(ei , ej ) and Z are similar to those in Equation 2 and Pchange(ei ) = 1 − P r(ei , P a(ei) ) . Based on the Equation 3 , we have the aggregated benefit of the selected entity set E :
Z
B(E ) =
BE(ei )
( 4 ) ei∈E ei∈E
The utility of adjusting an entity should take both the entity position uncertainty and position amendment benefit into consideration . We model the utility of each entity as follows :
U tiE(ei ) = λ · U ( ei ) + ( 1 − λ ) · BE(ei )
( 5 ) where λ ∈ ( 0 , 1 ) is a parameter used to balance of U ( ei ) and BE(ei ) . Similar with the aggregated position amendment benefit , the aggregated utility of a given set is :
U ti(E ) =
U tiE(ei )
( 6 )
2 ) Cost Modelling : For each adjustment task , the crowd needs to pick the “ best ” hypernym from the candidate list , known as the Max Discovery Problem [ 16 ] .
It is not practical to show the crowd worker a large number of entities , we need to decompose the task into a number of sub tasks , each of which has the cardinality less or equal to HIT size limit s , and then aggregate the results . Therefore , different entity adjustment tasks could be decomposed into various numbers of sub tasks which leads to different costs . As the taxonomy is a tree structure , each entity ( node ) in the taxonomy has one parent , therefore , we need a “ single winner ” among the candidate entities . We adopt the plurality rule as our voting strategy . For each sub task t , we ask k workers to vote for the best one , the entity with maximum votes is selected . For decomposing and aggregating algorithm , we adopt Tournament Max Algorithm [ 16 ] to get the optimal single winner .
Cost Function . For the entity e , with the hypernym candidate list CL of size N , the cost of conducting entity adjustment task is proportional to the total number of HITs . For obtaining the single winner , the number of HITs needed is :
Nh(e ) = k · m i=1 si ( cid:100 ) N
( 7 ) where , m satisfies s(m−1 ) ≤ N ∧ sm ≥ N , s is the microtask size threshold and k is the replication factor . Based on the HIT numbers , given each HIT price is p , then we can have the cost of each entity adjustment : cost(e ) = p · Nh(e )
( 8 )
3 ) Entity Selection Optimization : According to utility and cost models , which entities should be chosen to ask the crowd can be considered as the following Entity Selection Optimization problem .
Definition 4 ( Entity Selection Optimization ( ESO) ) : Given a complete but noisy taxonomy Tn = ( N , R ) , where N denotes the entities , R denotes the hypernym/hypomyn relations and a specific budget B0 , this problem is to select a set of entities E to adjust under the given budget B0 so that the utility function is maximized . max Uti(E ) m st cost(ei ) ≤ B0
( 9 ) i=1 where , Uti(E ) is defined in Equation 6 and E is the subset of N that we picked for conducting entity adjustment tasks . The ESO problem is a NP hard problem , which can be proved by a reduction from Knapsack problem .
Theorem 1 : The Entity Selection Optimization ( ESO ) prob lem is NP hard .
The proof could be found in the full version of this paper [ 17 ] .
IV . SOLUTIONS OF ENTITY SELECTION OPTIMIZATION
Since the ESO problem is NP hard , we propose an exact algorithm as well as a more efficient approximation algorithm .
Algorithm 1 : Dynamic Programming Algorithm ( DP ) Input : A set of entities {e1 , e2 , · · · , en} , a given budget B0 Output : Maximum utility value and corresponding selection set E Initialize UtiD1 ( 1 , b ) according to Equation 11 ; for i=0 to N − 1 do for b=0 to B0 do
Si ← F indSelection(i , b , U ti ) ; for each all Di ⊂ Child(ei ) ∩ Si do if cost(i + 1 ) ≤ b and UtiDi ( ei+1)+UtiDi ( i , b − cost(i + 1 ) ) ≥ UtiDi ( i , b ) then Di+1 ← Di ∩ Child(ei+1 ) ∪ ei+1 ; UtiDi+1 ( i + 1 , b ) = UtiDi ( ei)+UtiDi ( i , b − cost(i ) ) SelectionDi+1 ( i + 1 , b ) = true ; else
Di+1 ← Di ∩ Child(ei+1 ) ; UtiDi+1 ( i + 1 , b ) = UtiDi ( i , b ) ; SelectionDi+1 ( i + 1 , b ) = f alse ;
13 E = F indSelection(N − 1 , B0 , U ti ) ; 14 return E
Algorithm 2 : FindSelection Input : Entity index i,Budget b , Utility result U tility Output : Selection set E Initialize : E ← ∅ ; 1 2 while i ≥ 1 ∧ b ≥ 0 do 3 4 for all Di do if U tiDi ( i , b ) = max U ti(i , b ) ∧ SelectionDi ( i , b ) == true then
E ← E ∪ ei ; b ← b − cost(ei ) ; i ← i − 1 ;
7 8 return E ;
1 2 3 4 5 6
7 8
9 10 11 12
5 6
A . Exact Algorithm
Brute Force Algorithm . The straightforward approach for the problem is to enumerate all the subsets of N in brute force . There are totally 2N possible combinations for entity selection . For each combination , we need to compute the cost and utility , the complexity is O(N·p ) , where p is the maximum number of children among all entities in N , therefore the time complexity of this algorithm is O(p · N · 2N ) . subset selecting optimal
Dynamic Programming ( DP ) Algorithm . To solve the problem of from N = {e1 , e2,··· , en} , we decompose the given instance into smaller sub problems and obtain the solution recursively . Our problem differs from the traditional knapsack problems in that the utility of each entity changes with each choice decision . Here , we use UtiDi(i , b ) to denote the optimal utility value of first i entities , with the budget less than or equal to b and set Di , where the set Di = Child(ei)∩Ei . Firstly , we number the entities by post order traversal which ensures if one entity ’s number is i then all its children ’s number is less than i . We use Ei to denote the selection result of first i entities . When considering entity ei+1 , its children entities have already been processed , which means Di is fixed . For the optimal solution of first ( i+1 ) entities , we consider all subsets of first i entities , which is equivalent to all subsets of entity i ’s children set . For each situation , we can get the current selection result with first i entities , ie , Ei , and Di , then the utility of ( i + 1)th entity can be computed . The recursive step is defined as follows : UtiDi+1(i + 1 , b ) = max
∀Di:Di∩Child(ei+1)⊆Di+1 if ei+1 /∈ Di+1 UtiDi(i , b ) UtiDi(i , b−cost(i + 1))+UtiDi(ei+1 ) if ei+1 ∈ Di+1 The initial settings are :
Uti∅(e1 )
0 ∞
UtiD1(1 , b)= if D1={e1}∧b≥ cost(e1 ) if D1 ∧0≤ b≤ B0 others(illegal )
Note that to get the selection result , we use SelectionDi+1(i+ 1 , b ) to record the selection strategy of ( i + 1)th entity under the budget of b and set Di . And the selection result of different situations can be obtained recursively , the algorithm for computing the selection result is shown in Algorithm 2 and the pseudocode of the DP algorithm is shown in Algorithm 1 .
Complexity . As shown in Algorithm 1 , line 2 has N loops , line 3 has B0 loops and line 5 has 2p loops for each subset of children set . The complexity in line 5 and lines 6∼ 11 are O(N ) , respectively . Therefore the total time complexity is O(N 2 · B0 · 2p ) . In real cases , p N , therefore , the DP algorithm is more efficient than the brute force algorithm . The space complexity of algorithm 1 is O(N · B0 · 2p ) . B . Approximation Algorithm
Although , the DP gives optimal solution to the ESO problem , the space complexity is O(N · B0 · 2p ) , which is intractable , especially when the n is large in practice . Therefore we explore an approximation algorithm which significantly enhances the efficiency and has the approximation guarantee . Theorem 2 : The utility function defined is monotone and
The proof could be found in the full version of this
( 10 )
( 11 ) submodular . paper [ 17 ] .
Based on the Theorem 2 , the greedy algorithm is shown in Algorithm 3 . Starting from an empty set , each time we select the entity which gives best utility increase for each unit .
Lemma 1 : The greedy algorithm achieves an approximation factor of 1
2 ( 1 − 1 e ) .
Proof : According to Theorem 2 , the utility function of ESO problem is monotone and submodular , the greedy algo2 ·(1− 1 rithm in Algorithm 3 has the approximation ratio of 1 e ) as shown in Theorem 3 of [ 18 ] . Complexity . The greedy algorithm in Algorithm 3 takes O(N 2 ) , the while loop has N iterations and in each iteration ( lines 4 9 ) takes O(N ) time to select the s∗ . ( Note that the computation of U ( S1 , e ) is O(p ) , where p N ) .
V . EXPERIMENTS
A . Experimental Setup
Dataset . We conduct experiments on a real dataset of a corpus on Computer domain , which is a collection of academic paper abstracts , crawled from Springer 1 . The dataset is pre
1http://wwwcseusthk/∼rmeng/CrowdTC/Exzip
Algorithm 3 : Approximation Algorithm by Greedy Selection Input : A set of entities E = {e1 , e2 , · · · , en} , a given budget B0 Output : Maximum utility value and corresponding selection set S
1 S1 ← ∅ ; L ← E ; 2 S2 ← arg max ∀ei∈E 3 while L = ∅ do 4 5
Uti∅(ei ) ; for each entity e ∈ L do U ( S1 , e ) ← U ( S1 ∪ e ) − U ( S1 ) ; g(e ) ← U ( S1,e )
; cost(e ) g(e ) ; s∗ ← arg max e∈L if cost(S1 ) + cost(s∗ ) ≤ B0 then
S1 ← S1 ∪ s∗ ;
6
7
8 9
L ← L\s∗ ;
10 11 return arg max
S∈{S1 ,S2}
Uti(S )
TABLE I
STATISTICS OF TAXONOMY # entities
Avg # of child Max # of child
Taxonomy Partial Taxonomy Enriched Taxonomy Sampled Taxonomy
10788 34420 27635
1.29 1.09 0.85
677 689 5 processed in several steps : first , we adopt syntactic based technique on the corpus and construct a partial taxonomy , among which only 3.38 % sentences are observed to have “ Hearst Patterns ” ; second , we extract all entities ( noun phrases ) from corpus as the candidates for subsequent enrichment . For entity extraction , we use NLTK Chunker .
The statistics of the partial taxonomy show that the maximum number of children is 677 . The DP algorithm is intractable due to the limited memory . Therefore , to illustrate the efficiency and effectiveness of DP algorithm , we sample a smaller taxonomy ( P = 5 ) from the enriched taxonomy . The detail information of the partial taxonomy and the sampled taxonomy is shown in Table I .
Evaluation Metric . For the taxonomy evaluation , we adopt precision and coverage as the evaluation metric : #of correct pairs
P recision =
#of totally extracted pairs
Coverage =
#of entitiesinthetaxonomy
#of entities extracted f rom corpus
( 12 )
( 13 )
As we do not have the ground truth for the taxonomy , we use coverage metric as the indicator of recall . For precision , we randomly sample 100 “ ancestor descendant ” pairs and check the correctness manually .
Parameters . There are several parameters needs evaluation : weight parameter λ , budget B0 and distance filter parameter θ for candidate filtering . For λ and θ , we vary it from 0∼1 ; for B0 , we compute the total cost for adjusting every entity in the taxonomy , Btotal = $69 , 011 and vary the cost budget from 2‰×Btotal to 10‰×Btotal .
Crowdsourcing on AMT . We use Amazon Mechanical Turk ( AMT ) to conduct crowdsourcing tasks . For each HIT , we design it as a single choice question and ask the worker to select the most appropriate hypernym of given word from several choices . The maximum number of choices of each HIT is set to 10 ( the maximum number of choices on AMT
( a ) Evaluation of θ
( b ) Evaluation of λ
Fig 2 . Parameter Evaluation for single choice questions ) . For those entities which have a candidate list size larger than 10 , we separate the candidates into several groups , size of each does not exceeds 10 . For these entities , the process of collecting answers has several rounds . In each round , we first separate the candidates into groups and generate a HIT for each group , then we collect the answers and aggregate the answers to produce a new candidate list , which is used to generate HITs for the next round . The collecting process will finish until we get the final answer . We pay $0.01 to each worker for a HIT . To make sure the quality of answers , we assign each HIT to three workers and aggregate their answers by majority voting strategy .
B . Evaluation of Techniques
Parameter Setting . By decreasing the θ value , the filtering power is increasing ( more entities have no candidate ) . We compare the coverage and accuracy of the enriched taxonomy with various θ values , as shown in Figure 2(a ) . For the weight parameter of utility function in the Equation 6 , we empirically learn the value of λ by varying it between 0∼ 1 . For each value of λ , we examine the accuracy under different budget settings . The results are shown in Figure 2(b ) . According to the results , we set θ = 0.8 to have a high coverage and λ = 02
Comparison Adjustment Algorithms . We compare the DP algorithm and greedy algorithm with the naive random selection strategy . In the naive algorithm , we select the entity that does not exceed the remaining budget randomly . As the DP algorithm has a space complexity of O(N·B0·2p ) , we only test it on the sampled taxonomy , due to the memory constraint . We vary the budget and examine the running time of entity selection , selection utility value , selection entity number and the precision of adjusted taxonomy based on the answers from crowd , the results are shown in Figures 3 , 4 . Due to the memory limit , for the DP part , we use a small budget range to conduct the comparison , 0.2‰∼ 10‰
In Figure 3 , we can see that the DP algorithm achieves better accuracy compared with the greedy selection algorithm . However , the DP solution is much more cost than the greedy one . Also , the memory cost is not scalability for large datasets . From Figure 3 and Figure 4 , we can see that the greedy algorithm outperforms the naive random selection algorithm in both accuracy , adjusted entity number and utility value . From the comparisons , we conclude that the taxonomy constructed by our method which combines machine techniques with crowdsourcing techniques achieves the precision nearly 75 % and coverage 87 % . Taxonomy constructed by our approach improves the accuracy of the noisy enriched taxonomy ( 61 % ) human computation ( the crowd ) to construct a complete and accurate taxonomy . In this work , the core problem is formulated as the Entity Selection Optimization ( ESO ) problem , which is proven to be NP hard . To solve this optimization problem , we propose an exact algorithm and a more efficient e ) approximation factor . approximation algorithm with a 1 Finally , we have verified our proposed algorithms through extensive experimental studies .
2 ( 1− 1
VIII . ACKNOWLEDGEMENT
This work is supported in part by the Hong Kong RGC Project N HKUST637/13 , National Grand Fundamental Research 973 Program of China under Grant 2014CB340303 , NSFC Grant No . 61328202/61502021 , NSFC Guang Dong Grant No . U1301253 , Microsoft Research Asia Gift Grant , Google Faculty Award 2013 and Microsoft Research Asia Fellowship 2012 .
REFERENCES
[ 1 ] T . Liu , Y . Yang , H . Wan , H . Zeng , Z . Chen , and W . Ma , “ Support vector machines classification with a very large scale taxonomy , ” SIGKDD , vol . 7 , 2005 .
[ 2 ] Y . Song , H . Wang , Z . Wang , H . Li , and W . Chen , “ Short text concep tualization using a probabilistic knowledgebase , ” in IJCAI , 2011 .
[ 3 ] K . D . Bollacker , C . Evans , P . Paritosh , T . Sturge , and J . Taylor , “ Freebase : a collaboratively created graph database for structuring human knowledge , ” in SIGMOD , 2008 .
[ 4 ] F . M . Suchanek , G . Kasneci , and G . Weikum , “ Yago : a core of semantic knowledge , ” in WWW , 2007 .
[ 5 ] W . Wu , H . Li , H . Wang , and K . Q . Zhu , “ Probase : a probabilistic taxonomy for text understanding , ” in SIGMOD , 2012 .
[ 6 ] X . Liu , Y . Song , S . Liu , and H . Wang , “ Automatic taxonomy construc tion from keywords , ” in SIGKDD , 2012 .
[ 7 ] D . Karampinas and P . Triantafillou , “ Crowdsourcing taxonomies , ” in
ESWC , 2012 .
[ 8 ] A . Ritter , S . Soderland , and O . Etzioni , “ What is this , anyway : Auto matic hypernym discovery . ” in AAAI , 2009 .
[ 9 ] Y . Tong , C . C . Cao , C . J . Zhang , Y . Li , and L . Chen , “ Crowdcleaner : Data cleaning for multi version data on the web via crowdsourcing , ” in ICDE , 2014 .
[ 10 ] C . J . Zhang , L . Chen , Y . Tong , and Z . Liu , “ Cleaning uncertain data with a noisy crowd , ” in ICDE , 2015 .
[ 11 ] Y . Tong , C . C . Cao , and L . Chen , “ Tcs : efficient topic discovery over crowd oriented service data , ” in SIGKDD , 2014 .
[ 12 ] L . B . Chilton , G . Little , D . Edge , D . S . Weld , and J . A . Landay ,
“ Cascade : crowdsourcing taxonomy creation , ” in CHI , 2013 .
[ 13 ] S . K . Kondreddi , P . Triantafillou , and G . Weikum , “ Combining information extraction and human computing for crowdsourced knowledge acquisition , ” in ICDE , 2014 .
[ 14 ] M . A . Hearst , “ Automatic acquisition of hyponyms from large text corpora , ” in COLING , 1992 .
[ 15 ] H . Yang and J . Callan , “ A metric based framework for automatic taxonomy induction , ” in ACL , 2009 .
[ 16 ] P . Venetis , H . Garcia Molina , K . Huang , and N . Polyzotis , “ Max algorithms in crowdsourcing environments , ” in WWW , 2012 . and C . C . Cao .
[ 17 ] R . Meng , Y . Tong , L . Chen ,
Crowdtc:crowdsourced taxonomy construction . http://wwwcseusthk/∼rmeng/CrowdTC/CrowdTC TechReportpdf
[ 18 ] S . Khuller , A . Moss , and J . Naor , “ The budgeted maximum coverage
( 2015 ) [ Online ] . Available : problem , ” Inf . Process . Lett . , vol . 70 , 1999 .
[ 19 ] N . Nakashole , G . Weikum , and F . Suchanek , “ Patty : a taxonomy of relational patterns with semantic types , ” in EMNLP , 2012 .
[ 20 ] K . Punera , S . Rajan , and J . Ghosh , “ Automatically learning document taxonomies for hierarchical classification , ” in WWW , 2005 .
[ 21 ] J . Bragg , D . S . Weld et al . , “ Crowdsourcing multi label classification for taxonomy creation , ” in HCOMP , 2013 .
( a ) Running Time
( b ) Precision
( c ) Selection Size
( d ) Utility
Fig 3 . Comparison of Algorithms on Sampled Taxonomy
( a ) Running Time
( b ) Precision
( c ) Selection Size Fig 4 . Comparison of Algorithms on Real Taxonomy
( d ) Utility and have a much larger coverage compared with the initial partial taxonomy ( 27% ) .
VI . RELATED WORK
Many study have been conducted on taxonomy construction , either manually or automatically . The manual approaches , which construct taxonomies by domain experts or collaboratively by community members , eg Freebase [ 3 ] , has the limitation of scalability . The automatic approaches [ 5 ] , [ 4 ] , [ 19 ] construct the works [ 20 ] , [ 6 ] build taxonomy via hierarchical classification or incremental clustering approaches . taxonomy based on syntactic patterns ;
Recently , the increasing popularity of crowdsourcing brings new trends to leverage the power of crowd in taxonomy construction . In [ 12 ] , [ 21 ] , the crowd is used for categorizing items for taxonomy construction . In [ 7 ] , each “ isA ” relationship is voted by the crowd and take it as the input for taxonomy induction . S . K . Kondreddi [ 13 ] proposes a hybrid approach that combines information extraction technique with human computation for knowledge acquisition , in which the crowd are asked to compile relationships between entities .
VII . CONCLUSION
In this paper , we propose a hybrid framework which combines the power of automatic machine based approaches and
