Measuring Large Scale Dynamic Graph Similarity by RICom : RWR with Intergraph Compression
†Electrical Engineering and Computer Science , Seoul National University , Seoul 151 744 , Korea
Jaekoo Lee† , Gunn Kim(cid:92 ) , and Sungroh Yoon†∗
( cid:92)Department of Physics , Sejong University , Seoul 143 747 , Korea
∗Correspondence : sryoon@snuackr
Abstract—‘By how much is a large scale graph transformed over time or by a significant event?’ or ‘how structurally similar are two large scale graphs?’ are the two questions that this paper attempts to address . The proposed method efficiently calculates and accurately produces graph similarity . Our approach is based on the well known random walk with restart ( RWR ) algorithm , which quantifies relevance between nodes to express the structural and connection characteristics of graphs . Intergraph compression , which is inspired by interframe compression , merges two input graphs and reorders their nodes contributing to improved process data storage efficiency and processing convenience . This is a boon to the RWR algorithm for large scale graphs . The representation of a graph transformed via intergraph compression can be used to accurately show similarity because sub matrix blocks are reordered to concentrate nonzero elements . In performing the RWR algorithm , which quantifies inter node relevance , transformed representation of graph with intergraph compression is efficient in space requirement and produces results more quickly and accurately over conventional graph transformation schemes . We demonstrate the validity of our method through experiments and apply it to the usage data of public transportation SmartCard in a large metropolitan area to suggest usefulness of the proposed algorithm .
I . INTRODUCTION
Graphs have been actively employed in attempts to analyze complex systems in a wide variety of applications such as traffic maps , the Internet , human brain maps , protein protein interaction ( PPI ) networks [ 1 ] , [ 2 ] . We pay special attention to efforts that compare and contrast two graphs by capturing their connectivity features . Research on graph similarity measurements is useful for the classification tools that exploit connectivity features extracted from static graphs , eg , a PPI network . In applications that can be abstracted with dynamic graphs , similarity in graph connectivity is monitored to detect anomalies that are manifest in the form of , for instance , accidents and intrusions [ 3 ] . Big data analysis has become an active area of research in recent years , and analyzing largescale interconnected data such as social networking service ( SNS ) data is already an intensely studied topic . In particular , this paper focuses on analyzing and measuring large scale graphs whose contents change dynamically over time or after an important event .
This paper proposes a method that efficiently measures the structural change of a dynamic large scale graph as well as the similarity between two graphs in a large graph set . Our initial goal is to analyze a dynamic graph changing in a continuum over time . In addition , we apply our method to static graph datasets from the real world to present an optimized analysis that can offer analysis tools based on similarity .
Fig 1 : Categorizing node and graph similarity measures [ 8 ]
The idea presented in this paper starts from a simple observation that perhaps some concepts in video processing could be borrowed for manipulating dynamic graphs . This is because image segmentation methods often abstract pixels into graphs and employ graph algorithms to produce meaningful results [ 4 ] . That is , there exist conceptual similarity between a video ( which consists of a sequence of still images ) and a dynamic graph ( which is a series of adjacency matrices of static graph ) . As an image sequence processing method , interframe compression [ 5 ] offers improved data storage efficiency and ease of operations because it compresses common pixel data in adjacent frames . Adapting the core idea of interframe compression for graph processing , we thus propose an intergraph compression method , which compresses adjacent static graphs in a dynamic graph by exploiting the shared structure features between graphs . The proposed method can measure changes in dynamic graphs with the RWR algorithm [ 4 ] via the Schur complement
[ 6 ] , [ 7 ] for efficiency and accuracy .
In our experiments , the proposed method indeed produced accurate results , and its processing time and storage requirement were also improved over existing state of the art methods . The validity and fitness of the proposed algorithm were experimentally tested using synthetic graph data [ 3 ] and real world graph data [ 9 ] . The method was also tested with the dynamically changing subway SmartCard data extracted from a large metropolitan public transportation system .
The rest of the paper is organized as follows : Section 2 provides background materials . Section 3 presents the details of our approach and compares it with existing state of theart methods . Section 4 shows our experimental results with both synthetic and real word datasets and also analyzes the time and space complexity of the proposed method . Section 5 concludes the paper . The descriptions of the symbols used in this paper are listed in Table I .
II . PRELIMINARIES
A . Graph Similarity Measure
As smart devices have become widespread , social network services such as Facebook or Twitter generate large scale
Similaritybetween Nodesbetween GraphsRolesProximityKnow Node CorrespondenceUnknown Node Correspondence TABLE I : The symbols and descriptions used in this paper symbol description
G or G(V , E ) graph , graph with V : set of node , E : set of edge n , m c k w sim(G1 , G2 )
GU or GU ( VU , EU ) union graph of graphs G1 and G2 number of nodes , number of edges probability of restarting number of hubs removed in node reordering method number of total hubs , w n similarity between graphs G1 and G2 [ n × n ] identity matrix [ n × n ] adjacency matrix of graph G [ n × n ] inter graph compressed adjacency matrix of A [ n × n ] diagonal degree matrix of graph G , [ n × n ] inter graph compressed diagonal degree matrix of D [ ni × nj ] ( i , j)th block matrix of B [ n × n ] matrix P = [ I − ( 1 − c)AD−1 ] [ n × n ] matrix P = [ I − ( 1 − c)AD−1 ] P = [ P [ n × 1 ] starting indicator ( seed ) vector [ n × 1 ] relevance vector of node i relevance value of node j wrt node i [ n × n ] matrix with elements rij R = [ R11 , R12 ; R21 , R22 ] 2 by 2 block partitioned matrix [ w × w ] Schur complement of block P
I A A D D Bij P P ∗ ei ri rij R S j aij ( dij = 0 f or i = j )
22 ] 2 by 2 block partitioned matrix dii =
11 , P
12 ; P
21 , P
11 of matrix P
∗ unit vector with 1 in the ith element . graph data , which has been the focus of active research . For example , the connectivity of networks can be expressed in a dynamically changing graph for analysis , or individuals can be grouped according to the brain connectivity graph [ 3 ] . In one study , data was collected from the functional parts of the human brain and converted into a graph for analysis to classify people . Such studies measure similarity between graphs in terms of structure and/or features and allow for intuitive comparisons [ 8 ] . This paper also attempts to capture and numerically represent graph similarity . We provide an overview of the general characteristics of conventional graph measures that pertain to our work . Fig 1 shows that our proposed method belongs to the category of graph research that excludes unknown node correspondence because it compares graphs based on approximated information of the structural role of node and connectivity features . So , it applies to graph research where node correspondence is assumed .
State of the art graph similarity measures satisfy the following properties [ 3 ] . Similarity measure needs to reflect Edge Importance , which states that insertion and removal of edges between graphs need to be accounted for . Weight Awareness also needs to be satisfied so that any change to the weight of each edge needs to be reflected . Similarity measure also needs to be sensitive to Edge Sub modularity , hence changes to higher degree nodes need to have less impact than changes to lower degree nodes . Assuming that changes in graphs due to accidents are more frequent than arbitrary changes in edges , the sensitivity measure needs to identify edge changes surrounding specific nodes , satisfying Focus Awareness . Through experiments , we verify that our method satisfies the four properties above .
B . Random Walk with Restart ( RWR )
The RWR algorithm attempts to measure the affinity or relevance of two nodes in a graph [ 4 ] . Conceptually , in RWR , a particle walks between nodes following randomly chosen edges . The particle starts walking in the initial node i and chooses the next node connected through the edges , each of which is assigned weighted probability , and then makes its move . Repeating moves in this fashion multiple times allows for estimation of the probability of each node having the particle on it . This is a quantified value tailored by the structure of graph connectivity , hence is used as a relevance measure between two nodes [ 10 ] . The relevance score produced by the RWR algorithm accounts for the entire connectivity structure of the graph , so is employed as an essential analysis tool .
Since its introduction , the RWR algorithm has developed to accommodate expanding graphs and to numerically measure the relevance of nodes in such graphs while improving on time complexity and accuracy [ 4 ] , [ 10 ] , [ 11 ] . Variations of the RWR algorithm have been employed in earlier applications such as automatic image captioning [ 4 ] , and are expanding into various fields . Research on the RWR algorithm encompasses practical applications , optimization for computation , storage , and noticeably for large scale graphs as theoretical backgrounds . Some of the well known variations of the RWR algorithm include PageRank , electrical network analogy , and personalized RWR [ 10 ] . Related studies have been applied to discover user similarity or influential individuals in SNS [ 12 ] . The iterative form of a basic RWR algorithm [ 4 ] , [ 10 ] is : i ← ( 1 − c)AD−1r(t−1 ) r(t ) i
+ cei
( 1 ) where c is the probability of restarting the random walk from the initial node , ei is the starting indicator vector , ri is the unknown relevance ( affinity or influence ) column vector , and ( t ) is the number of renewal activities for r(t ) . i The vector r(t ) is obtained by repeatedly processing Eq 1 while |r(t ) − r(t−1)| < threshold holds true . The component i is the relevance of node j rij in the produced vector r(t ) i wrt node i . In other words , rij is the numerically translated value of influence by node i for node j in the context of a connectivity structure . Intuitively , node i has more influence on node j if the edge linking node i to node j is numerous , short , or heavily weighted . The RWR algorithm in an iterative method repeatedly performs multiplication operations for an [ n × n ] matrix in each iteration to compute r(t ) , hence is computationally inefficient .
When 0 < c < 1 , r(t ) generally approaches a unique solution [ 10 ] . Thus , the RWR algorithm can be defined as the following because r has a solution i
[ I − ( 1 − c)AD−1]ri = cei .
( 2 )
With this equation , ri can be rewritten by means of an inverse matrix operation in linear algebra as follows : ri = c[I − ( 1 − c)AD−1]−1ei = cP−1ei .
( 3 )
This RWR algorithm suffers from the fact that an inverse matrix operation has to be performed for an [ n × n ] matrix to obtain ri , and that its computational complexity O(n3 ) increases as n becomes larger [ 6 ] . There are several studies that have attempted to reduce time complexity , some of which are listed in Table II . As charted in the table , variations of
TABLE II : Related work on the RWR approach methods details r(t ) ← ( 1 − c)AD−1r(t−1 ) + ce Basic Iteration [ 10 ] r = c[I − ( 1 − c)AD−1]−1e Inversion [ 10 ] r = cR−1QT e QR Decomposition [ 11 ] r = cU−1L−1e LU Decomposition [ 3 ] r = c[I − ( 1 − c)A1 − ( 1 − c)A2]−1e B LIN [ 4 ] ≈ c[I − ( 1 − c)A1 − ( 1 − c)UΣV]−1e Fast Belief Propagation [ 3 ] r = c[I − 2D − A]−1e r = [ r1 ; r2 ] where r1 = H−1 BEAR [ 7 ] r2 = S−1(cq2 − H21H−1 11 ( cq1 ) ) r = c[I − ( 1 − c)AD−1]−1e
Proposed P = QR , Q−1 = QT ; P = LU ; divide AD−1 into inner community edges A1 and cross community edges A2 , A2 ≈ UΣV ( low rank matrix ) ; H is the partitioned matrix from Slashburn , and S = H22 − H21H−1 11 H12 ; = 1/(1 + maxi dii ) , positive constant ( < 1 ) encoding neighbor influence .
11 ( cq1 − H12r2 ) and
Fig 2 : Overview of proposed method
RWR include iterative methods , inversion methods [ 10 ] , QR decomposition methods [ 11 ] , RPPR/BRPPR methods [ 10 ] , B LIN/NB LIN methods [ 4 ] , fast belief propagation based ( DeltaCon ) methods [ 3 ] , and LU decomposition methods [ 7 ] . The RWR algorithm to measure the structural feature of graph for our method shows improved time/space efficiency over state of the art RWR variations , and it has been devised to fit for large scale graphs .
C . Schur Complement
The Schur complement [ 6 ] is applied as a part of the solution to a linear equation system , and is an important tool for numerical analysis and matrix operation . In graph mining , its use was pioneered by the block elimination approach for RWR ( BEAR ) [ 7 ] . In the proposed method , it is also an essential tool because it allows the RWR algorithm to perform efficiently . In case the size of a matrix M = [ W , X ; Y , Z ] is [ (p + q ) × ( p + q) ] , then its constituent block sub matrices W , X , Y , and Z have the sizes of [ p × p ] , [ p × q ] , [ q × p ] , [ q × q ] , respectively , where p q in general . If Z is invertible , then the Schur complement for block Z in matrix M can be defined as S = W − XZ−1Y , and can be used to calculate the inverse matrix of matrix M as follows :
.
−1
W X
Y
Z
M−1 =
=
S−1
−Z−1YS−1
−S−1XZ−1
Z−1+Z−1YS−1XZ−1
D . Measurement of Matrix Distance
There have been various attempts to find similarity or distance between matrices , such as using matrix correlation or cosine similarity [ 6 ] . In this paper , we choose Euclidean distance because it allows for finding distance , which represents the relevance of each node in the graph as calculated with the RWR algorithm ; the similarity between two graphs is intuitively represented .
III . PROPOSED METHOD
We present a method to efficiently measure ( 1 ) the change of a dynamic graph whose connectivity structure evolves over time and ( 2 ) the similarity of large scale graph datasets along with justification for our method . The definition of the problem we want to address can be stated briefly as follows [ 3 ] :
Given : two graphs G1(V1 , E1 ) and G2(V2 , E2 ) each consisting of node set V and edge set E , we assume that the node correspondence of sets V1 and V2 is known .
Find : sim(G1 , G2 ) that lies between 0 and 1 and intuitively signifies the structural similarity between two given graphs . Here , sim(G1 , G2 ) = 0 indicates that two graphs are structurally complementary , where sim(G1 , G2 ) = 1 means two graphs are completely identical . the provided dataset
Fig 2 summarizes the overall architecture of our method . In the first stage of our method , is converted to a dynamic graph , and the two adjacent static graphs G1(V1 , E1 ) and G2(V2 , E2 ) extracted from the given dynamic graph go through the following steps in sequence . Since intergraph compression borrows its core concept from interframe compression , the first task is creating the union set GU with the two input graphs so that the commonly shared structural features can be relocated for compression . Afterwards , a state of the art node reordering algorithm is applied to GU , which stores common edges . In the adjacency matrix , nonzero elements indicate edges between nodes . The nonzero elements are concentrated to a focused region . This not only brings in a compressing effect on the matrix , but also facilitates partitioning in applying the RWR algorithm and provides a basis for applying the Schur complement algorithm . Following the reordered sequence computed in intergraph compression , each graph is also reordered in the same node index , and matrix P is calculated to apply the RWR algorithm so that the connectivity between nodes can be identified . To P , a 2 by 2 block partitioned matrix , Schur complement algorithm is applied and the relevance matrix R is calculated , which shows the affinity between nodes in the structural context of the entire graph . The relevance matrices R1 and R2 are efficiently calculated with a partitioned inverse matrix operation through the Schur complement algorithm . Both R1 and R2 share an identical node index and are evaluated to numeric values following matrix distance measuring operations between corresponding block components due to the partitioning block properties . The value , which lies between 0 and 1 , intuitively expresses similarity between two graphs , and is the final result of our method . The numeric results obtained this way can be used as a tool to measure changes in a dynamic graph or to numerically express similarity between graphs .
1stStage PreprocessINPUT:ApplicationsTraffic , Computer Network , SNS,…Data CleansingExtraction of Raw Data(A ) Representing Graph Dataset(Dynamic or Static)Database2ndStage Inter Graph Compression(B ) Union Graph(C ) Reordering Nodes3rdStage Graph Similarity Measure(D ) Forming Matrix P’ for RWR(E ) Calculating RWR by SchurComplement(F ) Calculating Matrix Distanceand Similarity ScoreOUTPUT : Sim(G1 , G2 ) ∈[0,1]Compressed Matrices A’ and D’ a scale free network . Inspired by BEAR [ 7 ] , we thus choose SlashBurn [ 13 ] , a state of the art node reordering algorithm that concentrates nonzero components in adjacent matrices as much as possible , producing an excellent compression effect . Fig 3 clearly shows the compression effect of intergraph compression after applying this algorithm to GU , which is the union of the two given graphs . D . Forming Matrix P for RWR
We show that block form sub matrices belonging to one large scale matrix are created after compressing two input graphs with intergraph compression . Let matrix A be the output of intergraph compression . We apply the RWR algorithm [ 4 ] to matrix A to identify inter node connections and find matrix R , which consists of rij ( inter node relevance ) . For an arbitrarily selected node i , ri can be expressed as ri = c[I − ( 1 − c)AD−1]−1ei = cP−1ei .
( 4 )
After connecting each ri of node i contiguously ( 0 < i < n ) , we can calculate matrix R for all of the nodes in the graph that has each ri for its column vector [ 3 ] as follows :
R = . r1 fi = P−1 . e1
. . . rn
. . . en fi = P−1I = P−1 .
22 . P
The matrix P = [ I−(1−c)AD−1 ] is obtained from reordered adjacency matrix A . Thus , the blocks are similar , and can be expressed with 2 by 2 block matrices as in matrix A . With the compression effect present in A due to intergraph 11 , P compression , P is partitioned into sub matrices of P 12 , 11 of P is a smaller partition ( [w × w ] ) with 21 , and P P absolutely high concentration of nonzero components , whereas 21 ( [(n− w)× w ] ) the two blocks of P are symmetrical , like a pair of wings ; the nonzero components are thus appropriately scattered depending on the connectivity 22 , which takes most of the region with ( [(n− of the graph . P w ) × ( n − w) ] ) in the P matrix , has only a few nonzero components to form a sparse nonzero block diagonal . Such a block diagonal sub matrix is invertible because each sparse block is partitioned and approximated with that goal .
12 ( [w× ( n− w) ] ) and P
As the small sparse block matrix diagonal to matrix P
22 has a relatively much smaller size compared to the corresponding sub matrix in the original matrix , each block is treated as an independent matrix , and the inverse matrix of the sparse matrix is obtained . The inverse matrix of the sparse block diagonal matrix is then calculated with approximation reflecting the location of each block . Matrix P is a 2 by 2 block matrix . To find R , which signifies node relevance as a matrix , the inverse matrix of P is obtained with the Schur complement algorithm [ 6 ] , [ 7 ] . This offers the benefit of partitioning a large scale graph matrix into blocks for improved storage efficiency .
Fig 3 : Visualization of intergraph compression on real world graphs : Union graph is an example of the merged graph of GU ( V , E ) = G1(V1 , E1 ) ∪ G2(V2 , E2 ) for intergraph compression , and this is applicable when every single node in V1 of G1(V1 , E1 ) has its corresponding node in V2 of G2(V2 , E2 ) as well as when ( V1 = V2 ) because the node set of GU can be defined as V = V1 ∪ V2 . In reordering nodes , SlashBurn removes hubs with the highest degree and the edges connected to the removed hubs , and produces spokes with smaller degrees . The hub nodes are relocated to the front of the index and the spokes to the back repeatedly to reorder the nodes . As a result , the hubs with higher degrees in the adjacency matrix for the given graph , are concentrated closely together , producing compression and partition effects . With intergraph compression , it is possible to verify shared structural data between two graphs by merging the target graphs . Node reordering algorithm is applied on the merged graph to get the compression effect like in motion picture processing , hence improving space and computation efficiency .
A . Representing Graph Dataset
Several methods have been proposed to visually analyze the interactive relation of data components in a given dataset using graphs [ 1 ] . In the preprocessing stage of our method , each piece of data is converted to a node and the relation between data to edge to represent input data as a graph , which is one of the simplest approaches of graph conversion . This approach is valid in converting not only static datasets but also dynamic datasets , which change over time or after an event . To the generated graph , our method is applied for clustering ( static datasets ) or for tracing changes ( dynamic datasets ) .
B . Union Graph
The proposed method is inspired from an observation that commonly shared data between adjacent still frames of motion pictures can be processed in compressed form . The same approach may be applicable to two adjacent graphs in a dynamic graph setting . Note that for a dynamic graph in the real world [ 9 ] , changes almost always happen in a continuum , and abrupt changes virtually never arise . With this in mind , the concept of compressibility for shared pixel data between adjacent frames using interframe compression for motion pictures is applied to two dynamically changing graphs , capturing shared structural features between two input graphs . Our method is comparable to interframe compression in offering storage efficiency and ease of operations .
C . Reordering Nodes
Several node reordering methods are available for use : degree sort , cross association , spectral clustering , and shingle , all of which bring in compressing effects [ 13 ] . For our approach , we note that most real graphs possess the pattern of
E . Calculating RWR Matrix by Schur Complement
Calculating the inverse of matrix P for each graph with the RWR algorithm allows for finding R , which numerically indicates inter node relevance in the context of overall graph structure . Exploiting the techniques used in BEAR [ 7 ] , the reordered node indexreordered node indexintergraphcompressed G1intergraphcompressed GUintergraphcompressed G2G1(V1,E1)GU(VU,EU ) G2(V2,E2)Union GraphReordering Nodesoriginal node indexoriginal node index TABLE III : Details of real world datasets used [ 9 ] properties
RWR ours DC VEO SS GED λ D A λ D L λ D NL
O O O O edge importance weight awareness edge sub modularity focus awareness Similarity measures [ 3 ] : DeltaCon ( DC ) ; Vertex/Edge Overlap ( VEO ) ; Signature Similarity ( SS ) ; Graph Edit Distance ( GED ) ; λ D Adjacency ( λ D A ) ; λ D Laplacian ( λ D L ) ; λ D Normalized Laplacian ( λ D NL ) .
O O O O
X X O
O O O O
X O O
X X O
X O O
X O O
X O O
Fig 5 : Analysis of “ SmartCard big data ” by our approach : ( a ) Comparison similarity of a day of week is the result for the static graph analysis , and it depicts similarities between the flows for different days of the week . From Mon to Fri , morning rush hours between 07 and 09 have more similar passenger flows , but the passenger flow pattern on Fri evening between 18 and 20 was noticeably different from that on the other weekdays , signifying that passengers on Fri go to areas that are different from where they usually go on the other weekdays . Manually tracing passenger flow pattern on Fri verified that a significant portion of passengers do not return to the subway station from which they first left in the morning and instead go to stations near the downtown area , probably to enjoy Fri evening ; ( b ) Monitoring pattern of passenger movement on consecutive time shows the similarity of passenger flow for each time slot in a dynamic graph . Changes in the graph are depicted in a control chart , with its mid line and ±σ , ±2σ . The similarity of graphs increases during morning rush hours on weekdays until most commuters seem to have arrived at work . The graphs start to deviate from this point . The graphs start to look different after the time when most commuters are assumed to have arrived at work . In the afternoon after 15 , the graphs become similar until the peak at 18 . As the flow of passengers increases around 18 when commuters start returning home , the hourly graphs exhibited the highest similarity at that time . Late at night after 22 , the number of passengers drops , and passenger flow is irregular , so that the transportation graphs differ very much from each other . Unlike the passenger flow patterns during weekdays , the passenger flow does not change much during the daytime on Sat . Throughout Sun , the passenger flow pattern shows less similarity to the other days while being mixed with some irregularity .
IV . RESULTS AND DISCUSSION
We consider the four principled properties of graph similarity used in evaluating state of the art methods [ 3 ] : edge importance , weight awareness , edge submodularity , and focusawareness . Existing measures for graph similarity listed in Table III and our method are given the same simple synthetic graph as previous work [ 3 ] . We chart similarity measure results for each method and show that our method fulfills the four properties . Table III compares the experimental results of existing methods with ours in terms of the principled properties on graph similarity . Fig 4 presents the result from
Fig 4 : Comparison of the proposed and existing approaches : ( a ) average processing time ; ( b ) shows that the proposed method has faster performance in most cases over state of the art DC [ 3 ] , which uses approximations to calculate relevance with fast belief propagation for the RWR algorithm . This performance gap is increasingly significant for larger graphs . In the experiment to measure similarity with varying levels of corruption as shown in ( b ) and ( c ) , fluctuation in the performance speed of DC for arbitrary insertion/removal of edges is increasingly noticeable for larger graphs whereas the proposed method has a relatively stable performance speed . In the similarity measurement experiment , DC and our method show exponentially decreasing similarity in the same fashion , while the number of arbitrarily altered edges increased . In our experiment , the ratio of changed insertion/deletion edges varies from 1 % to 90 % . When edge connection is altered hundreds of times at each ratio , DC is insensitive to arbitrary changes to edges and thus produces values in a narrow range . In contrast , similarity values produced by our method are sensitive to random insertion/removal of edges , reflecting structural changes in the graph ; Real datasets [ 9] Facebook ( n=4039 , m=88234 , social network ) , Oregon ( n=11461 , m=32730 , autonomous systems graph ) , Enron ( n=36692 , m=183831 , communication network ) , AS Skitter ( n=1696415 , m=11095298 , Internet topology graph ) steps for obtaining an inverse matrix using the Schur complement algorithm is applied to P of each graph to find matrix R = cP−1 , which is given by
R = c
S−1 −P−1 22 P
21S−1 P−1
−S−1P 22 + P−1 22 P
12P−1 21S−1P
22
12P−1
22
.
The resulting matrix R has more accurate values over the existing approximation of RWR [ 3 ] in terms of inter node relevance . The computation also finishes more quickly while requiring less space . F . Calculating Matrix Distance and Similarity Score
In the previous subsection , matrix R , which numerically indicates inter node relevance in the context of overall graph structure , was obtained from a block partitioned matrix P by means of the Schur complement . Using a distance measuring method between matrices R1 and R2 [ 6 ] , the similarity between two graphs is calculated and numerically represented : sim(G1 , G2 ) = 1/(
ED(R1,ij , R2,ij ) + 1 ) .
( 5 ) i=1 j=1
Note that graph similarity reflecting overall graph structure ends up lying in between 0 and 1 , as governed by Eq 5 :
2
2
3.505time of proposed methodestimated line of propsed methodtime of deltaconestimated line of deltacon455565size of node on dataset ( log scale)(a ) time ( sec ) ( log scale)FacebookOregonEnronAs Skitternot completed(c ) time ( sec)level of corruption6141%90%level of corruption0701%90%level of corruption120001%90%(b ) similarity score01Correlation of Proposed and DeltaConp value<10 1001Correlation of Proposed and DeltaConp value<10 1001Correlation of Proposed and DeltaConp value<10 10FacebookOregonEnron(b ) similarity scoreconsecutive days ( with hour)�𝑠𝑠𝑠𝑠𝑠𝑠 σσ2σ 2σWedThuFriSatSunMonTuetime zone with high similaritybetween daystime zone with low similaritybetween days(a ) similarity scoretime ( hour)0706050403Mon vs TueMon vs WedMon vs ThuTue vs ThuTue vs WedWed vs ThuMon vs FriTue vs FriWed vs FriThu vs Fri6789101112131415161718192021222307060504030291521915219152191521915219152191521 TABLE IV : Complexity analysis of proposed approach action time space
O(m1 + m2 ) ≈ O(2m ) O(m + n log n|T| ) [ 13 ] O(mn + n )
Input : G1 and G2 from dynamic dataset , c probability of restarting Output : sim(G1 , G2 ) ∈ [ 0 , 1 ] represent graph set from ( A ) raw dataset union graph ( B ) ( C ) reordering nodes forming matrix P for ( D ) RWR calculating RWR by Schur Complement compute P−1 compute S compute R11 compute R12 compute R21 compute R22 calculating similarity score
O(q O(w2 + n2(q O(w2n(q O((q O(q ( q l=1 n2 ( l) ) ) ( l))nw2 ) ( l ) + l=1 n2 O(n2 + 1 )
( E ) ( E 1 ) ( E 2 ) ( E 3 ) l=1 n2 l=1 n2 l=1 n3 l=1 n2 l=1 n2
O(w3 )
( l) ) )
( l ) )
( F )
22
( l ) )
( l))n2w2(q ( l ) + n(q
O(1 ) l=1 n2
The time complexity of our method according to above is
O(nm + n log n|T| + w2 + w3 +q ( l)(1 + n2w2q q O(|m1 ∪ m2| +q ∗ m1 = |V1| of G1 , m2 = |V2| of G2 ; T is the number of iteration on slashburn ; sparse matrices multiplication ( A × D ) is O(mn ) ; n(l)( n ) is |V| of lth diagonal matrix : O(q block diagonal matrix ; inversion of [ n × n ] matrix : O(n3 ) ; inversion of q block l=1 n2 ( l)) ) ) and the space complexity is l=1 n2 ( l ) + w2 + nw + ( n − w)2 ) .
( l)(w2 + n ) + l=1 n2 l=1 n3 l=1 n3
( l) ) .
O(|m1 ∪ m2| ) O(n ) [ 13 ]
O(m + n )
O(q l=1 n2
( l ) )
O(w2 ) O(w2 ) O(nw ) O(nw ) O((n − w)2 ) applying the proposed method to processing real world data and compares it with existing state of the art methods . Refer to the caption for Fig 4 for more details .
We showcase a few implementations of our method for real world datasets in Fig 5 to suggest the possibility of applications to various fields . We collected the usage data of public transport SmartCard for a large metropolitan area between July 10 and 16 , 2013 . For tens of millions of transit passengers each day , the dataset contains passenger identifiers , departure points , departure times , arrival points , arrival times , and accompanying passengers . For analysis , we approached the dataset with both dynamic and static graphing . The flow of passengers through subway stations in this area and its vicinity were put in slots of 10 minute periods . One static graph was created for each time slot covering the seven day period , and we identified patterns of passenger flow for the same time slots in different days of week . We also traced the dynamic change in the graphs over the course of day to find out how passenger flow differs each day in a week . More details can be found in the caption for Fig 5 .
Table IV lists the complexity of the proposed approach . The analysis assumes that the input graph possesses the characteristics of real world datasets as in scale free networks . We believe that the proposed method provides a significant improvement in terms of time and space complexity over existing state of the art methods , especially when the size of the graph is large . To accommodate very large graphs with hundreds of millions of nodes , our future work includes the consideration of approximation and parallelization [ 14 ] along with graph sampling methods .
V . CONCLUSION
The purpose of this work is to offer an accurate and efficient similarity measure for dynamically changing largescale graphs and structurally comparable graphs . The proposed method relies on the idea of intergraph compression implemented as the RWR algorithm by the Schur complement and shows significant improvements in terms of time and space complexity for measuring graph similarity over existing stateof the art methods . Using the proposed method , medium sized dynamic graphs can be scrutinized for anomaly in real time , and structural similarity for graphs with millions of nodes can be measured in a relatively short period of time for applications such as grouping nodes for in depth analysis . Big data has been an emerging key word in recent years , and the proposed method offers an adequate basis for efficiently examining large scale real world data in graph forms . Our analysis of real world usage data of the public transportation SmartCard in a large metropolitan area showcases a successful application of the method , which can further be employed in analyzing data from various fields .
ACKNOWLEDGMENT
This work was supported by the NRF grant funded by the Korea government ( Ministry of Science , ICT and Future Planning , MSIP ) [ No . 2011 0009963 ] , by the ICT R&D program of MSIP/ITP [ 14 824 09 014 , Basic Software Research in Human level Lifelong Machine Learning ] , by the Brain Korea 21 Plus Project in 2015 , and by SAP Labs Korea .
REFERENCES
[ 1 ] D . J . Cook and L . B . Holder , Mining graph data . John Wiley & Sons ,
2006 .
[ 2 ] S . Yoon , J . C . Ebert , E Y Chung , G . De Micheli , and R . B . Altman , “ Clustering protein environments for function prediction : finding prosite motifs in 3d , ” BMC bioinformatics , vol . 8 , no . Suppl 4 , p . S10 , 2007 . [ 3 ] D . Koutra , J . T . Vogelstein , and C . Faloutsos , “ Deltacon : A principled massive graph similarity function , ” arXiv:1304.4657 , 2013 .
[ 4 ] H . Tong , C . Faloutsos , and J Y Pan , “ Fast random walk with restart and its applications , ” 2006 .
[ 5 ] V . Bhaskaran and K . Konstantinides , Image and video compression standards : algorithms and architectures . Springer Science & Business Media , 1997 .
[ 6 ] G . H . Golub and C . F . Van Loan , Matrix computations , vol . 3 . JHU
Press , 2012 .
[ 7 ] K . Shin , J . Jung , S . Lee , and U . Kang , “ Bear : Block elimination approach for random walk with restart on large graphs , ” in Proceedings of ACM SIGMOD , pp . 1571–1585 , 2015 .
[ 8 ] S . Soundarajan , T . Eliassi Rad , and B . Gallagher , “ A guide to selecting a network similarity method , ” SIAM , 2014 .
[ 9 ] J . Leskovec and A . Krevl , “ SNAP Datasets : Stanford large network dataset collection . ” http://snapstanfordedu/data , June 2014 .
[ 10 ] A . N . Langville and C . D . Meyer , Google ’s PageRank and beyond : the science of search engine rankings . Princeton University Press , 2011 .
[ 11 ] Y . Fujiwara , M . Nakatsuji , T . Yamamuro , H . Shiokawa , and M . Onizuka , “ Efficient personalized pagerank with accuracy assurance , ” in Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining , pp . 15–23 , ACM , 2012 .
[ 12 ] D . Koutra , T Y Ke , U . Kang , D . H . P . Chau , H K K . Pao , and C . Faloutsos , “ Unifying guilt by association approaches : Theorems and fast algorithms , ” in Machine Learning and Knowledge Discovery in Databases , pp . 245–260 , Springer , 2011 .
[ 13 ] Y . Lim , U . Kang , and C . Faloutsos , “ Slashburn : Graph compression and mining beyond caveman communities , ” 2013 .
[ 14 ] Y . Jeon and S . Yoon , “ Multi threaded hierarchical clustering by parallel nearest neighbor chaining , ” IEEE Transactions on Parallel and Distributed Systems , vol . 26 , no . 9 , pp . 2534–2548 , 2015 .
