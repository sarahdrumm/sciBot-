Hybrid pre query term expansion using Latent Semantic Analysis
Laurence A . F . Park Kotagiri Ramamohanarao ARC Centre for Perceptive and Intelligent Machines
Department of Computer Science
The University of Melbourne {lapark,rao}@csmuozau
Abstract
Latent semantic retrieval methods ( unlike vector space methods ) take the document and query vectors and map them into a topic space to cluster related terms and documents . This produces a more precise retrieval but also a long query time . We present a new method of document retrieval which allows us to process the latent semantic information into a hybrid Latent Semantic Vector Space query mapping . This mapping automatically expands the users query based on the latent semantic information in the document set . This expanded query is processed using a fast vector space method . Since we have the latent semantic data in a mapping , we are able to store and retrieve vector information in the same fast manner that the vector space method offers . Multiple mappings are combined to produce hybrid latent semantic retrieval which provide precision results 5 % greater than the vector space method and fast query times .
1 Introduction
The recent growth of latent semantic text retrieval methods [ 5 , 1 ] has generated much excitement in the information retrieval field . These methods use the content of the document sets to generate term topics by use of linear algebraic and probabilistic methods . The topics can then be used to query the documents , rather than the traditional set of key terms , to obtain high precision results . The problems found in these methods is in the query speed and the storage . Once we obtain the document and query vectors in terms of topics , we no longer can exploit the methods we have obtained based on the sparse term document index . This results in methods which scan through the whole topic document index to obtain a list of document scores .
In this paper we will be examining a new method of information retrieval that is fast , requires little storage space that is not dependent on the document count and allows us to utilise the intermediate topic space that the vector space methods ignore . By following this process , we are able to provide results of greater precision to the user . Section 2 introduces our query mapping concept and explains how we can use it in modern information retrieval systems . We follow this with experiments in section 3 displaying the increase in precision when using the query mapping for various document sets . In section 4 , we show how the query mappings can be successfully implemented while using vector space fast ranking techniques . Finally , we examine the computational complexity in section 5 .
2 Query Mappings
Vector space models ( VSM ) in document retrieval perform retrieval by comparing the query term set to each document term set . If there are terms in common , the document is ranked accordingly . This retrieval model assumes that a document is a sequence of words d = {w1 , w2 , w3 , . . . , wn} where each word is drawn independently from the pool of words W . This can be seen in figure 1 . In general this is not a valid assumption [ 5 , 3 ] . When writing a document , an author will have a certain set of topics in mind and write words according to those topics . This is where we include the intermediate topic selection stage for document creation . A document d consists of a set of topics dn = {Tn1 , Tn2 , Tn3 , . . . , Tnx} where each topic is selected from an existing topic set . Tm ∈ T where T = {T1 , T2 , T3 , . . . , Tl} The mth topic Tm is explained by a function of the set of words relevant to the topic Tm = fm(wm1 , wm2 , wm3 , . . . , wmy ) where the function fm describes the relationship of the terms to the topic , wm ⊂ W , and W = {w1 , w2 , w3 , . . . , wn} . This method of document creation builds the document from the selected set of topics . Therefore the words found in the document are not a set of randomly selected words , they are related through the topic they represent . This is shown in figure 2 . To overcome the problem of assumed term independence in the vector space model , Latent Semantic Analysis ( LSA )
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE
Word Set word 2
Document word 1 word 3 word n
Figure 1 . The assumed document creation process based on the current vector space methods . Each of the document words are randomly selected from a pool of words , where each word is independent of each other . has been used to provide mappings for the documents and queries into a reduced dimensional space . In this reduced space , we are able to find similarity of terms and documents by comparing the directions of each , similar directions imply that they are related to a similar topic . Hence this reduced dimensional space has been labeled the topic space , where each dimension in the space suggests a topic . If the mappings to the topic space are performed correctly we are able to retrieve document at a higher precision than the vector space method . These mapping methods are not widely used because they are not as efficient as the VSM . The VSM deals with sparse matrices , so it can perform very fast retrieval . Once we have mapped our data into the topic space , we are left with dense matrices containing positive and negative real numbers . When given a query , the whole document index must be processed to calculate the document scores .
Instead of mapping the query and documents into the topic space and calculating the document scores within the topic space , we can map the query in and back out of the topic space and calculate the document scores with the sparse document index in the term space . The advantages of this being :
• the document index is kept sparse as in the VSM . • the mapping is based on the terms ( not documents ) and does not grow with the document set .
• once we have the query terms from the topic space , we can deal with them as we wish . Eg only consider a subset of the new terms .
We will now show how LSA is as an extension to the VSM , by using this query mapping . To calculate the document score for document di , the vector space method applies the following equation : t∈T sdi,q = wdi,twq,t WdiWq
. . . fi
.
˜s = sdN ,q sd1,q sd2,q di , wq,t is the weight of term t in query q , Wdi and Wq are the document and query normalisation weights respectively , and T is the set of terms . If we represent the calculation of all document scores as a vector ˜s , where : sdN−1,q
( 2 ) and the set of document vectors as the matrix A , we obtain an equivalent matrix multiplication : ˜s = A˜q .
( 3 ) where s is the vector containing the resulting document scores , ˜q . is the transposed query vector where each element is wq,tj /Wq , A is the document index matrix consisting of elements Aij = wdi,tj /Wdi , where wdi,tj is the weighted frequency of term tj in document di and Wdi is the document normalisation weight . Note that we have used a tilde ( ˜ ) over a variable to represent a vector and a capital letter to represent a matrix . We will adhere to this notation throughout the paper .
To remove the assumption of term independence , we must map the query into the topic space using T and then back to the term space with T . . The documents are then ranked according to the new query . Our document score calculations now take the form :
˜s = AT T ˜q
( 4 ) where T is the mapping from the word space to the topic space and therefore T . ( the transpose of T ) is the mapping from the topic space back to the term space . We can observe from this equation that T ˜q is the query vector mapped into the topic space and that AT is the matrix of document vectors mapped into the topic space ( as done in LSA ) . Thereis τ × τ fore , our query mapping is given by M = T T . sized matrix , where τ is the number of terms . where sdi,q is the document score of document di with respect to query q , wdi,t is the weight of term t in document
2
2.1 Examining the Query Mapping
( 1 )
The relationship between the topic space and the term space cannot be shown by a simple expression . The cardinality of the term space is limited by the size of the lexicon ,
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE
Topic Set
Topic 2
Document
Topic 1
Topic 3
Topic m
Word set for Topic 2 word 2 word 1 word 3 word n
Figure 2 . The document creation process including topic selection . First the topics are selected , then the words related to each topic fill in the document . but the cardinality of the topic space ( being a latent variable ) is unknown .
2.2 Query Map Construction
We can apply a simplification to the topic term mapping by assuming a linear relationship . This allows us to express the mapping in terms of a simple matrix multiplication . The mapping is given by the matrix shown in equation 5 .
 
( 5 )
 
T =
τw1,t1 τw2,t1
τw1,t2 τw2,t2
τw1,tm τw2,tm
. . . . . . . . .
τwn,t1
τwn,t2
τwn,tm
The matrix consists of real valued elements ( τd,t ) , where each element represents the relevance of the term to the topic . A positive value represents that the term and the topic are related , a negative value represents that the term and the topic oppose each other . A zero value implies that the term and topic have no relationship .
The cardinality of the topic set must be chosen prior to constructing the mapping matrix . This value should be less than the number of terms , so that each topic can consist of many terms . The query process using the mapping M = T T . proceeds as follows :
1 . the rows corresponding to the query terms are extracted from the mapping matrix and multiplied with the query terms to obtain our modified query vector
2 . the rows corresponding to the terms found in the new query vector are extracted from the index and multiplied to provide the document scores .
This process is illustrated in figure 3 . We can see that each step is identical if we disregard the matrix involved . The modified query can be thought of as the set of word scores for the query , which is then given to the document index to obtain the set of document scores . This implies that we can store our query mapping in exactly the same way as we store our document index to obtain the speed and compression benefits that are offered .
3
To construct the query map we will have to extract the word topic relationships from the document set in order to derive the word topic matrix . Many methods of automatically extracting these semantic properties exist in the literature . These include Principle Component Analysis ( PCA ) , Independent Component Analysis ( ICA ) [ 6 ] , Singular Value Decomposition ( SVD ) [ 3 ] and Maximum Likelihood methods [ 5 , 1 ] . We will focus on the SVD method . The concepts shown using the SVD can be easily applied to each of the other methods .
221 Vector Space Method
As we have shown , the vector space method document scores are calculated by A˜q . . This implies that if we were to build a mapping to obtain the same results , we would simply use an Identity mapping ( M = I ) .
222 Latent Semantic Indexing
A = UΣV .
In Latent Semantic Indexing ( LSI ) , the topic space is found by calculating the Singular Value Decomposition ( SVD ) of the document index . For a real matrix A of rank s , the SVD is of the form :
( 6 ) where U.U = V .V = I , the identity matrix , and Σ is a square matrix of the form diag(σ1 , σ2 , . . . , σs ) . This decomposition provides us with the documents in the topic space ( UΣ ) and the terms in the topic space ( V Σ ) , where U and V and the document and term basis vector respectively . The SVD orders the document and term basis vectors according to their variance in A , where the most varying dimension of the original A matrix has the corresponding largest singular value found in the Σ matrix . The decomposition also has the feature that if we choose to reduce the dimension of the document and term basis by removing the elements corresponding to the smallest singular values , we obtain the least squares approximation of the A matrix in the new lower dimensional space .
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE
Query
Query Mapping
 
 
 
 
 
 
Modified Query
Document Index
Figure 3 . To use the query map , the query selects the rows from the map corresponding to its query terms and combines these to obtain a modified query term set . This modified query is then applied to the document collection index in the usual fashion . ff ˆV . = ˆD ˆV . ff
ˆA =
ˆU ˆΣ ff
ˆΣ ˆV .
= ˆU ˆW . ff
ˆA = ˆU
( 8 )
( 9 )
By labeling these new reduced dimensional matrices as
ˆU , ˆV and ˆΣ , we obtain the following :
ˆA = ˆU ˆΣ ˆV .
( 7 ) If we treat the A matrix as a set of document vectors , we can see that the SVD provides us with a mapping from the original space to the reduced space : is the mapping and where ˆV . is the new set of document vectors . The same applies for the term vectors found in the columns of A :
ˆU ˆΣ
ˆΣ ˆV . where ˆU is the mapping and is the new set of term vectors . To query a latent semantic index , we must map the documents in to the latent topic space ( A ˆV ) , map the query into the same space ( ˜q ˆV ) and apply the inner product to obtain the document scores : A ˆV ff ˆV ˜q
˜s = ff
( 10 )
If we let ˆV be our word topic mapping matrix , we obtain equation 4 . Therefore , we can represent the LSI process by use of a query map attached to the vector space method . Instead of calculating the document scores in the latent topic space , we can use the mapping to extract related query terms from the topic space and use an inverted index to calculate the document scores in a faster time . This is just one method of generating a query map , if we look further at types of mappings , we will realise that the possibilities are endless . In the next section , we show how we can generate an efficient retrieval system that may employ multiple query mappings .
223 Information Retrieval Hybrids
Ensemble methods for machine learning obtain results from multiple machine learning methods and chooses as the answer the class that obtains the most votes . If we apply this
4 idea to information retrieval , we would give our query to multiple retrieval systems and choose the documents that appear in most of the relevant document lists . To make the process simpler , we could obtain the document scores from each of the retrieval systems and simply add them . The documents that obtain high scores from all of the retrieval systems will have higher scores , while the ones which vary across the retrieval systems will not have such high scores . To perform this task in the usual manner , we would have to run multiple retrieval systems to obtain the hybrid results . Due to the linear nature of our retrieval methods , we can generate the hybrid results from a single query . If we can express our retrieval systems in terms of a query mapping and a document index , we achieve the following : fi fl
˜s =
AMi ˜q . = A
Mi
˜q .
( 11 ) i i
Therefore , for any set of retrieval systems in which we can represent as a query mapping and a document index , we are able to obtain hybrid document scores by simply summing the query mappings and performing the query as usual .
2.3 LSI Problems
In using a query map , we are able to eliminate some of the problems found in the LSI method .
231 LSI Sampling Problem
We have shown that LSI produces document feature vectors based on the frequency of the terms in each document , therefore , the resulting feature vectors will only be as effective as the data given in the initial set . The SVD organises the content of the document feature vectors based on the appearance of terms in the document in question and the rest of the document set . So , if each of the terms found in the original documents occur in many documents , the SVD will be able to organise the document feature vectors more effectively . If there are terms that have little occurrence in
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE the document set , the SVD will not have enough information about them to make effective use in the feature space . This implies that we should remove all of the terms that appear in a small number of documents , since they would only complicate the SVD calculations and add noise to the feature space .
By removing the under represented terms , we are removing terms that might define certain documents . For instance , if term y appeared in two documents and was removed from the SVD calculation , any search for term y would not provide any results . Therefore , we want to remove uncommon terms to increase the effectiveness of the SVD , but we also want to keep the uncommon terms to use directly . The solution we propose is to merge the LSI and VSM methods to obtain the best of both worlds .
1 . Index of all documents and terms A as in the VSM .
2 . Extract term vectors that have > C non zero elements into B .
3 . Perform SVD on B to obtain B = UΣV . 4 . Calculate MSV D = V V . 5 . Build M = MV SM ⊕ MSV D , where MV SM = αI . By removing the under represented terms from the SVD calculation , we should obtain better relationships between terms . The rare terms are included in the mapping through a merge ( ⊕ ) with the VSM mapping . In this method , ⊕ implies a matrix addition where the elements related to the same term are matched . If there is no related element , we add zero . I is the identity matrix and α is a predefined mixture constant . This operation gives us a hybrid LSA VSM retrieval method .
232 Pruning the query vector
After we perform the mapping , we obtain a query vector which consists of many non zero elements . Most of the elements being close to zero , with some positive values and some negative values . For each additional term that appears in the query , we must extract and add the elements of the corresponding inverted list . Therefore , it is not in our best interests to use such a populated query vector . To reduce the number of non zero elements , we simply chose to keep the T most significant valued elements and set the rest to zero .
3 Experimental Results
To test and verify our query mapping methods , we experimented with a set of small documents labeled CRAN ( 1398 abstracts from the Cranfield Institute of Technology ) , CACM ( 3204 abstracts from the Communications of the ACM journal ) , CISI ( 1460 abstracts from the Institute for
Scientific Information ) , and MED ( 1033 abstracts from the National Library of Medicine ) and ADI ( 82 abstracts)1 . We also experimented on the larger AP2 document set ( 79,919 newspaper articles from the Associated Press ) 2 . We chose to use the titles of the queries as the query terms to emulate Web style queries . The results found in this paper show the results from the AP2 set . We structured our initial experiments to determine the impact on the precision of our methods to the adjustment of the mapping file sizes . Therefore , the variables of our experiments were the number of terms included in the SVD mapping and the mixture of the VSM and SVD mapping . In each experiment , we used the Lnu.ltu weighting scheme from SMART [ 2 ] . Our experimental mappings were generated using the M = MSVD ⊕ MVSM matrix where MSVD = V V . is generated from the SVD of our index and MVSM = αI ( representing the combination of the VSM ) is the identity matrix of size T × T multiplied by a mixing factor and ⊕ is the merging operator . The results are displayed in sets of two graphs , showing precision after 10 documents and average precision respectively . To successfully encode the floating point values during the SVD calculation , we used 6 bit left geometric quantisation [ 8 ] . To sustain the symmetric nature of the matrix during the SVD , we chose to use the same quantisation table for the entire matrix ( rather than on a row by row basis ) . This provides us with a faster quantisation stage , but with larger error in our quantised values .
The number of terms included in the mapping were chosen by selecting terms that appeared in N or more documents . This allows us to choose the terms that are well represented in the document set . We experimented with this value of N using values of 10 , 20 , 50 , 100 , 200 , 300 , 500 , 800 and 1000 . We also experimented by varying the α mixing parameter from 0 ( pure LSI ) to 2 . A value of α = 0.2 was chosen for the AP2 document set .
Our initial interest was in the precision of the results over the precision of both the LSI and VSM document retrieval methods . The results we obtained from these experiments are found in the left of figure 4 . The mapped query vector was built by taking the top 50 and 1000 terms ordered by magnitude . Therefore , negative values were included . As expected , the precision decreases as the number terms in the mapping decreases .
We compared our method to both the VSM and LSI methods but have shown only the VSM method in the graphs . This was due to the VSM precision results being superior to LSI for all of the document sets we tested , except for the MED document set . The low precision LSI results we produced were not in agreement with previous reports which show improvements over the VSM . The previous re
1Available from from ftp://ftpcscornelledu/pub/smart/ 2Available on disk 2 of the TREC collection [ 4 ]
5
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE
AP2 Prec10 alpha=0.2
AP2 Prec10 alpha=0.2
AP2 Prec10 alpha=0.2 i n o s c e r P i n o s c e r P
0.29 0.28 0.27 0.26 0.25 0.24 0.23
0.12
0.11
0.1
0.09
50 terms 1000 terms VSM
200 400 600 800 1000
0 Min Documents for term inclusion
AP2 PrecAvg alpha=0.2
50 terms 1000 terms VSM
200 400 600 800 1000
0 Min Documents for term inclusion i n o s c e r P i n o s c e r P
0.28
0.27
0.26
0.25
0.24
0.23
0.12
0.11
0.1
0.09
400 components 100 components VSM
200 400 600 800 1000
0 Min Documents for term inclusion
AP2 PrecAvg alpha=0.2
400 components 100 components VSM
200 400 600 800 1000
0 Min Documents for term inclusion i n o s c e r P i n o s c e r P
0.28
0.27
0.26
0.25
0.12
0.11
0.1
No bound Bounded VSM
4000 8000 12000 16000 20000
0 Max Documents for term inclusion
AP2 PrecAvg alpha=0.2
No bound Bounded VSM
4000 8000 12000 16000 20000
0 Max Documents for term inclusion
Figure 4 . Precision using a query mapping versus the terms included in the mapping . The top and bottom rows show Precision after 10 documents and Average Precision respectively . Min and Max documents for term inclusion are the minimum and maximum number of documents a term must appear in to be included in the mapping . The left plots compare the number of expanded query terms chosen , the centre plot compares the number of SVD components chosen for the mapping , and the right plot compares the inclusion of common terms in the mapping . The dashed line is our precision benchmark using the VSM .
. ports used inferior weighting schemes ( such as simple tfIdf weights ) to weight both the LSI elements and VSM . By using these weights , the LSI displayed higher precision over the VSM , but when using the Lnu.ltu weights ( as in our experiments ) the VSM surpasses LSI most of the time .
The results show that the precision decreases with a decrease in mapping terms ( increase in documents for term inclusion ) . We also observed that an increase in query terms ( choosing 1000 instead of 50 ) provides us with an increase in precision of the large document set ( AP2 ) , and small increases of precision for the smaller document sets . For each term selected for the query ( after the mapping is performed ) , we increase the query time . So this small increase in precision by choosing more query terms comes at a price . To examine the impact of the number of singular values chosen , we devised an experiment on the AP2 document set . We compared the effect on the precision by selecting 100 and 400 singular values . The results are shown in the centre of figure 4 . We can see from these plots that the increase in the number of singular values chosen increase the precision when many terms are included in the mapping , but as the number of terms decrease ( Documents for term inclusion increases ) the precision drops off rapidly . For the case where we have chosen a smaller number of singular values , the precision slowly drops off with a decrease in mapping terms .
Our first experiment examined the response of precision to the number of terms included in the query mapping . Terms were removed by ignoring those which were found in less than N documents ( rare terms ) . We will now extend the experiment by observing the response of precision by ignoring those that occur in more than M documents ( common terms ) . The right of figure 4 shows the results of using a mapping that includes terms found in at least 200 document and at most M documents , where M is the x axis . This shows a peak at about 10000 documents for both precision after 10 documents and average precision . This implies that by including too little or too many terms in the mapping will degrade the precision .
4 Query and Score Accumulation
In order it achieve fast query times , the VSM has adopted an accumulation process to obtain the top D documents related to the query . The accumulation process estimates the top N by selecting the documents with the greatest individual document term weights which are related to the greatest query term weight . Two methods of achieving this are
6
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE
AP2 Prec10 alpha=0.2
AP2 Prec10 alpha=0.2
AP2 Prec10 alpha=0.2 i n o s c e r P i n o s c e r P
0.3
0.25
0.2
0.15
0.1
0.05
0.12 0.1 0.08 0.06 0.04 0.02 0
50 terms +50 terms VSM
200 400 600 800 1000
0 Min Documents for term inclusion
AP2 PrecAvg alpha=0.2
50 terms +50 terms VSM
200 400 600 800 1000
0 Min Documents for term inclusion i n o s c e r P i n o s c e r P
0.28
0.27
0.26
0.25
0.12
0.11
0.1
0.09
Rank all Rank fast VSM
200 400 600 800 1000
0 Min Documents for term inclusion
AP2 PrecAvg alpha=0.2
Rank all Rank fast VSM
200 400 600 800 1000
0 Min Documents for term inclusion i n o s c e r P i n o s c e r P
0.28
0.27
0.26
0
0.12
0.11
0.1
0
Quit Mapping Continue Mapping VSM
400 800 1200 1600 2000 Query Accumulator size
AP2 PrecAvg alpha=0.2
Quit Mapping Continue Mapping VSM
400 800 1200 1600 2000 Query Accumulator size
Figure 5 . Precision using a query mapping using fast querying schemes . The top and bottom rows show Precision after 10 documents and Average Precision respectively . Min and Max documents for term inclusion are the minimum and maximum number of documents a term must appear in to be included in the mapping . The left plots compare choosing only positive weighted query terms and all query terms , the centre plot compares using an accumulator during the document ranking , and the right plot compares using an accumulator during the term expansion . The dashed line is our precision benchmark using the VSM .
. through the Quit accumulation method and the more refined Continue accumulation method [ 7 ] . Throughout our experimentation , we used Continue for our document rank accumulation . As we mentioned earlier , the mapping process is almost identical to the ranking process , therefore we are able to implement an accumulator for the mapping process as well . The mapping accumulator will store the expanded query term weights , therefore the size of the accumulator is set to the number of terms we wish to obtain from the mapping .
4.1 Score Accumulation
The accumulation methods allow us to estimate the top ranking documents by making the assumption that most of the document term weights will be small values and all the values are positive . The document weights are mostly small values close to zero . By taking the greatest weights first , we will be selecting rare weights that will most probably identify with the top ranked documents . The smaller weights will probably be not enough to introduce new documents into the top ranked set .
If we expand the space spanned by the query weights to cover the real domain , the fast ranking method mentioned above fails . A simple example of failure would be a one term query where the weight of the term is negative . Any document with a large positive weight will be chosen for the accumulator , but once multiplied by the negative query weight , the result is a large negative value for the accumulator . During the initial accumulation phase where we are building the list of relevant documents , the list will be populated by large negative values , and hence return documents which are not relevant to the query . To overcome this , we elected to choose only the positively weighted query terms . Using a document accumulator of size 1000 , the left of figure 5 shows a large degradation in choosing only the positive weighted terms from the mapping . This implies that we must base our accumulator weight selection policy on the query term weight and not the document term weights alone .
To investigate this fast ranking method , we ran experiments on the AP2 document with the same parameters as before . The resulting plots can be seen in the centre of figure 5 . We can see that by including the query weight in the accumulator element selection process , we achieve results similar to the slower full ranking method.The precision after 10 document shows a greater precision when terms that appear in 200 documents are placed in the mapping matrix ,
7
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE when compared to the full ranking method . If we look at the average precision , we can see that the fast ranking method follows the same path as the full ranking method , but it has a negative offset . From this we can deduce that the fast ranking method is able to organise the top few documents into their correct ranks . But as the document scores become lower it becomes harder to determine their position .
4.2 Query term Accumulation
During our previous experiments , we chose to select the top Q terms from the set of expanded terms based on their weight . To do this , we would calculate the weights of every term , sort the weights and choose the top set . From this process , many of the calculations are wasted , since we want only the top Q term weights . To speed up this process , we can use the fast document ranking methods ( Quit and Continue ) on our mapping to produce an estimate of the top Q terms . By storing the mapped query weights in order of magnitude , we are able to use an accumulator to establish an expanded query vector . We have experimented on the effect of changing the accumulation scheme ( from Quit to Continue ) . The results are shown in the right of figure 5 . The experiment compared the resulting precision from varying the accumulator size when using the Quit and Continue accumulation methods . We can see in each of the methods , the precision begin low and ascends to a stable precision for both precision after 10 documents and average precision . This implies that we only need an accumulator of size of about 300 terms to obtain a good approximate .
5 Computational Complexity
To obtain an idea of the query time differences between a text retrieval system using an inverted index compared to our system with a query mapping , we will examine the complexity due to the different accumulation methods that we have chosen . Since our retrieval method is simply a mapping to expand the users query attached to a traditional text index , we can split the complexity calculations into two stages . The first stage is retrieving the terms associated to the query terms from the term mapping . If we wish to expand our query from u to v terms , and we use Quit accumulation , we will examine at most ( u(v − 1 ) + 1 ) mapping entries . The Continue method will process at most uτ terms , where τ is the number of terms in the document set . The second stage is simply retrieving the documents from the index using the Continue accumulation method . The number of index elements examined will be at most vδ where δ is the number of documents in the set . If we combine these two steps we achieve O(u(v − 1 ) + 1 + vδ ) when using the Quit mapping and O(uτ + vδ ) when using the Continue mapping . These are compared to O(uδ ) for the vector space
8 method . Experimental results on a Pentium 4 with an average load of 0.15 have shown an average query time of 0.03 seconds for the mapping and 0.35 seconds for the ranking when mapping to 300 terms .
6 Conclusion
We have introduced the concept of a query map which takes the users query and maps it to an expanded query . We have shown a method of building a query map using Singular Value Decomposition which also incorporates the vector space method . We performed experiments using this mapping and we found that 1 ) we don’t have to include all of the terms in the mapping to produce high precision results , 2 ) the resulting mapped query vector can be pruned to keep only the significant values and still maintain high precision results , 3 ) more singular values does not mean greater precision , and 4 ) we can apply fast ranking methods to the mapped query results and receive the same high precision results in a fraction of the time of ranking using all of the documents . Based on these findings , we are able to construct the retrieval system using the query map and obtain all of the benefits of the vector space method ( including fast querying ) while producing the high precision results from using the query map .
References
[ 1 ] D . M . Blei , A . Y . Ng , and M . I . Jordan . Latent dirichlet allocation . Journal of Machine Learning Research , 3:993–1022 , January 2003 .
[ 2 ] C . Buckley , A . Singhal , M . Mitra , and G . Salton . New retrieval approaches using smart : TREC 4 . In D . Harman , editor , The Fourth Text REtrieval Conference ( TREC 4 ) , pages 25–48 , Gaithersburg , Md . 20899 , November 1995 . National Institute of Standards and Technology Special Publication 500 236 .
[ 3 ] S . T . Dumais .
Improving the retrieval of information from external sources . Behaviour Research Methods , Instruments & Computers , 23(2):229–236 , 1991 .
[ 4 ] D . Harman , editor . The Third Text REtrieval Conference ( TREC 3 ) , Gaithersburg , Md . 20899 , March 1994 . National Institute of Standards and Technology Special Publication 500 226 .
[ 5 ] T . Hofmann . Probabilistic latent semantic indexing . In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval , pages 50–57 . ACM Press , 1999 .
[ 6 ] A . Hyvarinen , J . Karhunen , and E . Oja . Independent compo nent analysis . Wiley Interscience , 2001 .
[ 7 ] A . Moffat and J . Zobel . Self indexing inverted files for fast text retrieval . ACM Transactions on Information Systems ( TOIS ) , 14(4):349–379 , 1996 .
[ 8 ] A . Moffat , J . Zobel , and R . Sacks Davis . Memory effiInformation Processing and Management , cient ranking . 30(6):733–744 , November 1994 .
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE
