Detection of Significant Sets of Episodes in Event Sequences
Mikhail Atallah ∗ Purdue University
Robert Gwadera † Purdue University
Department of Computer Sciences
Department of Computer Sciences mja@cspurdueedu gwadera@cspurdueedu
Wojciech Szpankowski ‡
Purdue University
Department of Computer Sciences spa@cspurdueedu
Abstract but did not consider more than one episode scanned simultaneously for an occurrence .
We present a method for a reliable detection of “ unusual ” sets of episodes in the form of many pattern sequences , scanned simultaneously for an occurrence as a subsequence in a large event stream within a window of size w . We also investigate the important special case of all permutations of the same sequence , which models the situation where the order of events in an episode does not matter , eg , when events correspond to purchased market basket items . In order to build a reliable monitoring system we compare obtained measurements to a reference model which in our case is a probabilistic model ( Bernoulli or Markov ) . We first present a precise analysis that leads to a construction of a threshold . The difficulties of carrying out a probabilistic analysis for an arbitrary set of patterns , stems from the possible simultaneous occurrence of many members of the set as subsequences in the same window , the fact that the different patterns typically do have common symbols or common subsequences or possibly common prefixes , and that they may have different lengths . We also report on extensive experimental results , carried out on the Wal Mart transactions database , that show a remarkable agreement with our theoretical analysis . This paper is an extension of our previous work in [ 8 ] where we laid out foundation for the problem of the reliable detection of an “ unusual ” episodes ,
∗Portions of this author ’s work were supported by Grants EIA9903545 , IIS 0219560 , IIS 0312357 , and IIS 0242421 from the National Science Foundation , Contract N00014 02 1 0364 from the Office of Naval Research , by sponsors of the Center for Education and Research in Information Assurance and Security , and by Purdue Discovery Park ’s eenterprise Center .
†The work of this author was supported by the NSF Grant CCR
0208709 , and NIH grant R01 GM068959 01 .
‡The work of this author was supported by the NSF Grant CCR
0208709 , and AFOSR Grant FA 8655 04 1 3074 .
1 Introduction
Detecting subsequence patterns in event sequences is important in many applications , including intrusion detection , monitoring for suspicious activities , and molecular biology . Whether an observed pattern of activity is significant or not ( ie , whether it should be a cause for alarm ) depends on how likely it is to occur fortuitously . A long enough sequence of observed events will almost certainly contain any subsequence , and setting thresholds for detecting significant patterns of activity is an important issue in a monitoring system .
In order to decide whether a particular sequence of events in the monitored event sequence is significant one must compare it to a reference model . In our work the reference model is a probabilistic model either generated by a memoryless ( Bernoulli ) source or a Markov source . The question is when is a certain number of occurrences of a particular subsequence in a monitored even sequence unlikely to be generated by the reference model ( ie , indicative of suspicious activity or statistically significant event ) ? A quantitative analysis of this question allows one to compute a threshold on line while monitoring the event sequence in order to detect significant patterns . By knowing the most likely number of occurrences and the probability of deviating from it , we can compute a threshold such that the probability of missing real unusual activities is small . Such a quantitative analysis can also help to choose the size of the sliding window of observation . Finally even in a court case one cannot consider certain observed “ bad ” activity as a convincing evidence against somebody if that activity is
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE quite likely to occur under the given circumstances . Therefore it is very important to quantify such probabilities and present a universal and reliable framework for analyzing a variety of event sources .
In [ 10 ] Mannila et al . introduced the problem of finding frequent episodes in event sequences , subject to observation window constraint , where an episode was defined as a partially ordered collection of events , that can be represented as a directed acyclic graph . The paper [ 10 ] defined the frequency f r(α , s , win ) of an episode α as the fraction of windows of length win in which the episode occurs in an event sequence s . Given a frequency threshold min f r , [ 10 ] considered an episode to be frequent if f r(α , s , win ) ≥ min f r . In the framework of [ 10 ] , our problem can be stated as follows . Given an episode α , what window size win and what frequency threshold min f r should we choose to ensure that the discovered frequent episode is meaningful ? Observe that for an appropriately low frequency min f r and large window size win the episode will certainly occur in the reference model . Our problem can also be stated as follows . Given a collection of frequent episodes C(w ) , discovered using the algorithm given in [ 10 ] , what is the rank of the episodes with respect to their significance ?
In our paper [ 8 ] the problem of the reliable detection of unusual episodes was investigated , where we considered an episode in the form of a single sequence occurring as an ordered subsequence of a large event stream within a window of a given fixed size . This kind of episode is called a “ serial episode ” in the terminology of [ 10 ] , and we henceforth adopt this terminology . In [ 8 ] we proposed a method for reliable detection of significant episodes , where as a measure of significance we used Ω∃(n , w , m ) the number of windows of length w which contain at least one occurrence of serial episode S of length m as a subsequence in event sequence T after n shifts of the window . We proved that appropriately normalized Ω∃(n , w , m ) has the Gaussian distribution , where the expected value E[Ω∃(n , w , m ) ] = nP ∃(w , m ) and P ∃(w , m ) is the probability that a serial episode S of length m occurs at least once in a window of length w in an event sequence T over an alphabet A . We also showed that the variance Var[Ω∃(n , w , m ) ] ≤ cn!P ∃(w , m ) − ( P ∃(w , m))2" for c > 0 . Given a reference model ( Bernoulli or Markov ) , and for a given probability β(b ) , we presented the upper threshold for detecting significant episodes τu(w ) = P ∃(w , m ) + b√Var[Ω∃(n,w,m ) ] , where P ∃(w , m ) and Var[Ω∃(n , w , m ) ] depend on the probabilistic model and episode type . For a given probability β(b ) of the cumulative normal probability distribution
>τ u(w)$ ≤ function , we select b such that P# Ω∃(n,w,m ) β(b ) . That is , if one observes more than τu(w ) · n occurrences of windows with certain episodes , it is highly n n n unlikely that such a number is generated by the reference source ( ie , its probability is smaller than β(b) ) . The quantity Ω∃(n,w,m ) corresponds to the frequency f r(S , T , w ) [ 10 ] and is an estimator of P ∃(w , m ) denoted P ∃e ( w , m ) . While developing the formula for P ∃(w , m ) we found a formula for the set of all distinct windows W∃(w , m ) of length w containing a serial episode S of length m at least once as a subsequence . The importance of W∃(w , m ) stems from the fact that P ∃(w , m ) = %x∈W∃(w,m ) P ( x ) for the Markov model of an arbitrary order including 0 th order ( Bernoulli ) , where P ( x ) is the probability of x as a string of symbols of length w in a given model . The advantage of the Bernoulli model versus the first order Markov or higher is that for the Bernoulli model P ∃(w , m ) can be computed efficiently exploiting the structure of W∃(w , m ) and the fact that the model requires only |A| probabilities of symbols of the alphabet A . Therefore in [ 8 ] we focused on the Bernoulli model for which we gave an efficient dynamic programming method for computing P ∃(w , m ) . Using generating functions and complex asymptotics we presented an asymptotic approximation of P ∃(w , m ) , which is of the form P ∃(w , m ) = 1 − Θ(ρw ) for large w and 0 <ρ< 1 . In experiments , we chose two apparently nonmemoryless sources ( the English alphabet and the web access data ) and showed that , even for these cases , P ∃(w , m ) closely approximated the actual P ∃e ( w , m ) , which proved that the memoryless assumption did not limit the practical usefulness of the formula . We tested τu(w ) by artificially injecting “ bad ” episodes into the monitored event sequence and observed that τu(w ) did indeed provide a sharp detection of intentional ( bad ) episodes . Our paper [ 8 ] laid out foundations , but did not consider the case of detecting more than one serial episode simultaneously .
This paper builds on [ 8 ] by extending it to the case of an arbitrary number of serial episodes , monitored simultaneously for an occurrence , including the important special case of all permutations of the same serial episode , called a “ parallel episode ” in the terminology of [ 10 ] . The parallel episode case captures situations where the ordering of the events within the window of observation does not matter , eg , the events correspond to basket items scanned by cashier . More formally , we analyze episodes in one of the following forms : 1 . An arbitrary set of episodes S = {S1 , S2 , . . . , S|S|} where every Si of length mi is a serial episode for 1 ≤ i ≤| S| and by an occurrence of the set S we mean a logical OR of occurrences of members of S within a window of size w .
2 . Set of all distinct permutations of an episode S = S[1]S[2 ] , . . . S[m ] of length m ( parallel episode ) , where by an occurrence we mean a logical OR of occurrences of permutations of S .
2
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE
The reason we distinguish the parallel episode case is because we will take advantage of the structure of permutations of S to design an efficient algorithm instead of representing the parallel episode as a set of serial episodes . Thus , the goal of the current paper is to quantify Ω∃(n , w , m1 , m2 , . . . , m|S| ) the number of windows containing at least one occurrence of S = {S1 , S2 , . . . , S|S|} as a subsequence within a window of size w in a event sequence T over an alphabet A . This analysis leads to a formula for the threshold for detecting significant sets of episodes . In the full version of this paper [ 3 ] we prove that Ω∃(n , w , m1 , m2 , . . . , m|S| ) is Gaussian . In order to compute P ∃(w , m1 , m2 , . . . , m|S| ) the probability that a window of length w contains an occurrence of S we need a formula for W∃(w , m1 , m2 , . . . , m|S| ) the set of all windows of length w containing an occurrence of S as a subsequence . However a considerable source of difficulty is the fact that W∃(w , m1 , m2 , . . . , m|S| ) for |S| > 1 is not equal to the enumeration of sets of W∃(w , mi ) for each Si ∈ S because in general W∃(w , mi ) ∩W ∃(w , mj ) ̸= ∅ for i ̸= j where i , j ≤| S| and considering W∃(w , mi ) and W∃(w , mj ) independently would lead to a failure of the probabilistic analysis of P ∃(w , m1 , m2 , . . . , m|S| ) due to double counting of respective probabilistic events . To appreciate the difficulty of this extension , consider the much simplified case when there are only two pattern sequences ( S = {S1 , S2} ) and no symbol is common to S1 and S2 . Even in this case the set of windows of length w containing S1 as a subsequence and the set of windows of length w containing S2 as a subsequence do have some elements in common , ie , W∃(w , m1 ) ∩W ∃(w , m2 ) ̸= ∅ for appropriately large w . Add to this the fact that the different patterns typically do have common symbols or common subsequences or possibly common prefixes , that they may have different lengths , and the problem becomes fraught with nasty interactions that prevent any straightforward analytical solution to the case |S| > 1 . The main contribution of the current paper is a computational formula for P ∃(w , m1 , m2 , . . . , m|S| ) for and arbitrary set of episodes including the special case of the parallel episode . We provide a recurrence system for constructing W∃(w , m1 , m2 , . . . , m|S| ) . Because the recurrence contains conditional statements representing interactions of symbols of members of S we cannot find a practical analytical solution to the recurrence . Therefore we propose an efficient algorithmic method for enumerating W∃(w , m1 , m2 , . . . , m|S| ) using recursion graphs , which leads to a formula for P ∃(w , m1 , m2 , . . . , m|S| ) for an arbitrary order of Markov model . However , we focus on Bernoulli model in this paper because of its compactness and efficiency . Our current work builds on [ 8 ] and provides the first probabilistic analysis that quantifies Ω∃(n , w , m1 , m2 , . . . , m|S| ) the number of windows
3 of length w containing at least one occurrence of S = {S1 , S2 , . . . , S|S|} as a subsequence . This analysis allows to compute the threshold for detecting significant sets of episodes scanned simultaneously for an occurrence . We also proposed a new O(n log(m ) ) tree based algorithm for discovering parallel episodes , presented in the full version of the paper [ 3 ] . We applied our theoretical results by running an extensive series of experiments on real data . We used a part of Wal Mart sales data for the years 1999 and 2000 . We first show that our formulas for the probability closely approximate the experimental data . Then we demonstrate an application of the upper threshold by keeping inserting a given episode into random positions in the event sequence , until the episode gets detected as significant through our threshold mechanism ( cf . Fig 9 ) .
The paper is organized as follows .
In section 2 we present our main results containing theoretical foundation . Section 3 contains experimental results demonstrating applicability of the derived formulas . Proofs were omitted because of space limitations and are included in the full version of the paper in [ 3 ] . Interested readers can visit our on line threshold calculator at http://www cgics purdueedu/cgi bin/gwadera/democgi for a demonstration of the reliable threshold computation .
2 Main Results
Given an alphabet A = {a1 , a2 , . . . , a|A|} and a set of patterns S = {S1 , S2 , . . . S|S|} where Si = Si[1]Si[2 ] . . . Si[mi ] and Si[j ] ∈A for 1 ≤ i ≤| S| , we are interested in occurrences of members of S as a subsequence within a window of size w in another sequence known as the event sequence T = T [ 1]T [ 2 ] . .
We analyze the number of windows of length w containing at least one occurrence of S when sliding the window along n consecutive events in the event sequence T , where by an occurrence of S we mean a logical OR of occurrences of S1 , S2 , . . . , S|S| . We use Ω∃(n , w , m1 , m2 , . . . , m|S| , S,A ) to denote this number , that can range from 0 to n . the paper , whenever A , S or Notation : Throughout m1 , m2 , . . . , m|S| are implied and we do not reference them in our notations , we simplify our notations by dropping them accordingly using Ω∃(n , w ) , W∃(w ) and P ∃(w ) instead . We also occasionally use index mi−k to mean “ dropping the last k symbols of Si ” , eg , P ∃(w , m1 − k , m2 ) implies a pattern that is the prefix of S1 of length m1 − k and that the second pattern is all of S2 . Given a probabilistic model of the reference source ( in this paper we use Bernoulli model with probabilities P ( ai ) for ai ∈A , i = 1 , 2 , . . . ,|A| ) , a frequent episode S , Ω∃(n , w ) and a probability β(b ) ( eg , β(b ) = 10−5 ) we compute the upper threshold τu(w ) for
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE n as follows
P# Ω∃(n,w ) ⎧⎨⎩
≥ τu(w)$ ≤ β(b ) , using the equation system τu(w ) = P ∃(w ) + b√Var[Ω∃(n,w ) ] β(b ) e −t2
2 dt
= n
1√2π ) b
∞ n which follows from the fact that Ω∃(n , w ) is Gaussian as we proved in [ 3 ] . Also , P ∃(w ) and Var[Ω∃(n , w ) ] depend on the episode type and the probabilistic model ( Bernoulli or Markov ) . Once the threshold τu(w ) is computed if Ω∃(n,w ) ≥ τu(w ) then the probability that the episode S is not significant is less than β(b ) , ie , the probability of an false alarm is less than β(b ) . Given a collection of frequent episodes C(w ) we can rank their significance using β(b ) . For the sake of the presentation we focus throughout the paper on the case where either S = {S1 , S2} , or S is the set corresponding to a parallel episode S but our derivations will easily be seen to generalize to an arbitrary set of episodes S .
2.1 Analysis of P ∃(w )
Let W∃(w , m1 , m2 ) be the set of all possible dislength w containing S1 or S2 at tinct windows of least once as a subsequence then P ∃(w , m1 , m2 ) = %x∈W∃(w,m1,m2 ) P ( x ) . Because in the memoryless model P ( x ) is a product of individual probabilities of symbols , to any recursive formula for W∃(w , m1 , m2 ) there corresponds a similar formula for P ∃(w , m1 , m2 ) ( and vice versa ) . We now show that P ∃(w , m1 , m2 ) for the set A = {S1 , S2} satisfies the following recurrence then if S1[m1 ] ̸= S2[m2 ] P ∃(w , m1 , m2 ) = P ( S1[m1])P ∃(w − 1 , m1 − 1 , m2)+ P ( S2[m2])P ∃(w − 1 , m1 , m2 − 1)+ ( 1 − P ( S1[m1 ] ) − P ( S2[m2]))P ∃(w − 1 , m1 , m2 ) for w > 0 , m1 , m2 > 0 then if S1[m1 ] = S2[m2 ] P ∃(w , m1 , m2 ) = P ( S1[m1])P ∃(w − 1 , m1 − 1 , m2 − 1)+ ( 1 − P ( S1[m1]))P ∃(w − 1 , m1 , m2 ) for w > 0 , m1 , m2 > 0
P ∃(w , 0 , 0 ) = 1 P ∃(0 , m1 , m2 ) = 0 P ∃(1 , m1 , 0 ) = 1 P ∃(1 , 0 , m2 ) = 1 P ∃(0 , 0 , 0 ) = 1 for w > 0 for m1 , m2 > 0 for for m1 > 0 m2 > 0
⎧⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
Indeed , consider a window of size w containing S1 or S2 as a subsequence . Then depending on whether the last sym bols of S1 and S2 are equal or not there are two cases . If S1[m1 ] ̸= S2[m2 ] then there are three cases : either S1[m1 ] is the last symbol in the window giving the term P ( S1[m1])P ∃(w − 1 , m1 − 1 , m2 ) , or S2[m2 ] is the last symbol in the window giving the term P ( S2[m2])P ∃(w − 1 , m1 , m2 − 1 ) , or none of the above which leads to the term ( 1− P ( S1[m1])− P ( S2[m2]))P ∃(w − 1 , m1 , m2 ) . If S1[m1 ] = S2[m2 ] then there are two cases depending on whether the last symbol of the window is equal to S1[m1 ] or not . From the above discussion it is clear that the shape of the “ recursion graph ” is determined by interactions between symbols in S1 and S2 , ie , whether their symbols at pairs of positions are equal or not . Therefore in order to find a solution to P ∃(w , m1 , m2 ) we have to enumerate all pairs of indices ( i , j ) such that P ∃(k , i , j ) appears in the recursion tree ( not all such pairs of indices qualify ) . This recursion graph is now described more formally ( as stated earlier , in addition to depicting the recurrence , the graph also describes all elements of W∃(w , m1 , m2) ) . Let G(S ) = ( V , E ) be an edge labeled directed graph defined as follows . The vertex set V is a subset of all the pairs ( i , j ) , 0 ≤ i ≤ m1 , 0 ≤ j ≤ m2 . That subset , as well as E , are defined inductively as follows .
• ( 0 , 0 ) is in V . • If ( i , j ) is in V , i < m1 , and S1[i+1 ] ̸= S2[j +1 ] then ( i + 1 , j ) is also in V , and an edge from from ( i , j ) to ( i + 1 , j ) labeled S1[i + 1 ] exists in E .
• If ( i , j ) is in V , j < m2 , and S1[i + 1 ] ̸= S2[j + 1 ] then ( i , j + 1 ) is also in V , and an edge from ( i , j ) to ( i , j + 1 ) labeled S2[j + 1 ] exists in E .
• If ( i , j ) is in V , i < m1 and j < m2 , and S1[i + 1 ] = S2[j + 1 ] then ( i + 1 , j + 1 ) is also in V , and an edge from ( i , j ) to ( i+1 , j+1 ) labeled S1[i+1 ] ( = S2[j+1 ] ) exists in E .
• A self loop from vertex ( i , j ) to itself exists and has label equal to ( i ) A if i = m1 or j = m2 , ( ii ) A− {S1[i + 1]}−{ S2[j + 1]} if i < m1 and j < m2 .
The following observations , in which we do not count selfloops towards the in degree and out degree of a vertex , follow from the above definition of G(S ) .
• The in degree of vertex ( 0 , 0 ) ( start vertex ) equals zero , the out degree of vertices ( m1 , j ) , ( i , m2 ) for i ≤ m1 , j ≤ m2 ( end vertices ) equals zero .
• The in degree and out degree of every vertex ( i , j ) is at most three ; if S consisted of |S| > 2 serial episodes then the in degree and out degree of any vertex would be at most |S| + 1 .
• |V | = O(m1m2 ) and |E| = O(|S|m1m2 ) .
4
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE
Let Edges(path ) and V ertices(path ) denote the sequence of consecutive edges and ( respectively ) vertices in any path , except that V ertices(path ) does not include the last vertex on path ( why this is so will become apparent below ) . In what follows , if vertex ( i , j ) is in V ertices(path ) , then we use ni,j(path ) to denote the number of times the selfloop at ( i , j ) is used ; if path is understood and there is no ambiguity , then we simply use ni,j rather than ni,j(path ) . Let R be the set of all distinct simple paths ( ie , without self loops ) from the start vertex to any end vertex . Now let Lw be the set of all distinct paths of length w , including self loops , from the start vertex to all end vertices ( that is , self loops do count towards path length ) . Then we have W∃(w , m1 , m2 ) = {Edges(path ) : path ∈L w} . Examples of G(S ) are shown in Figure 1 and in Figure 2 .
( A− b − c)n1,0
1 , 0 b c
An2,0
2 , 0
( A− b − d)n1,1
( A− a − c)n0,0 a
0 , 0
( A− a − d)n0,1 a c
0 , 1 d b d
1 , 1
An0,2
0 , 2
An2,1
2 , 1
An1,2
1 , 2
Figure 1 . G(S ) for S = {ab , cd}
( A− a)n0,0
( A− b − c)n1,1
0 , 0 a
1 , 1 b c
An2,1
2 , 1
An1,2
1 , 2
Figure 2 . G(S ) for S = {ab , ac} n
In our experiments , we implemented an efficient dynamic programming algorithm based on Theorem 1 . In section 312 we present evidence how Theorem 1 works well on real data by comparing it to the estimate P ∃e ( w ) = Ω∃(n,w ) given the actual Ω∃(n , w ) . We also solved P ∃(w ) for an important special case when S consist of all permutations of one pattern S , which is the case of a parallel episode . Using Theorem 1 directly to design an algorithm in such an unordered case would be inefficient because we would then need to consider a graph having a disastrous |V | = O(mm! ) . In order to simplify the graph G(S ) that would result from all permutations , and bring its number of vertices down to a manageable size ( quantified below ) , we exploit the structure of a set of all permutations to design a different graph . Notice that , for a parallel episode , every path in R is a permutation of symbols in S . In addition , the outdegree of a vertex is at most m if all symbols of S are different . Furthermore a transition from from P ∃(k , i , j , . . . ) to P ∃(k + 1 , i′ , j′ , . . . ) takes place for any symbol of S not seen so far since the order of symbols does not matter . This observations allow us to introduce a variant of G(S ) called G∥(S ) . Let G∥(S ) = ( V , E ) be a directed edge labeled graph defined as follows . The vertex set V consist of submultisets of size i = 0 , 1 , . . . , m of the multiset of sorted symbols in S denoted as {S[1 ] , S[2 ] , . . . , S[m]} . We represent the submultisets equivalently as binary vectors of the form ( i1 , i2 , . . . , im ) , where ij = 1 if the vertex contains symbol S[ij ] in its submultiset or ij = 0 otherwise . V and E can be defined inductively as follows .
• ( 0 , 0 , . . . , 0 ) and ( 1 , 1 , . . . , 1 ) are in V . • If ( i1 , i2 , . . . , im ) is V and %m j=1 ij < m then j=1 i′j =%m ( i′1 , i′2 , . . . , i′m ) is in V if%m j=1 ij + 1 and an edge with label equal to {i′1 · S[1 ] , i′2 · S[2 ] , . . . , i′m · S[m]}− {i1 · S[1 ] , i2 · S[2 ] , . . . , im · S[m]} exists in E .
• A self loop from vertex ( i1 , i2 , . . . , im ) to itself exists and has label equal to ( i ) A for ( 1 , 1 , . . . , 1 ) , ( ii ) A− ij =0{S[ij]} otherwise .
The following observations , in which we do not count selfloops towards the in degree and out degree of a vertex , follow from the above definition of G∥(S ) .
• The in degree of the start vertex ( 0 , 0 , . . . , 0 ) equals zero , the out degree of the end vertex ( 1 , 1 , . . . , 1 ) equals zero . The in degree and out degree of every vertex is at most m .
·
• |V | = O(2m ) and |E| = O(|V |m ) .
Theorem 1 Consider a memoryless source with P ( Si[k ] ) being the probability of generating the k th symbol of S i ∈ S = {S1 , S2} . Let also P ( Edges(path ) ) =
+edge∈Edges(path ) Then for m1 , m2 and w ≥ mi we have P ∃(w , m1 , m2 ) =%path∈R P ( Edges(path))%w−|Edges(path)| %P ni,j ( path)=g,(i,j)∈V ertices(path ) ( 1 − P ( {S1[i + 1]}∪{ S2[j + 1]}))ni,j ( path ) .
P ( label(edge) ) . g=0
5
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE
Examples of G∥(S ) are shown in Figure 3 and in Figure 4 . The next theorem is an adoption of Theorem 1 to the case of a parallel episode .
( A− b − c)n1,0,0
( A− c)n1,1,0
( A− a − b − c)n0,0,0,0 a
( A− a − c)n0,1,0 c
{a} b a
{} b c
{b}
( A− a − b)n0,0,1 c a
{a , b} ( A− b)n1,0,1 c b
{a , c} ( A− a)n0,1,1 a
An1,1,1
{a , b , c}
{c} b
{b , c}
Figure 3 . G∥(S ) for S = abc and A = {a , b , c , d}
( A− c)n1,0,0
( A− c)n1,1,0 c
{a}
{a , c} c
( A− a − c)n0,0,0 a
{}
( A− a − c)n0,1,0 a
( A− a)n0,1,1 a c
{c} c
{c , c}
An1,1,1
{a , c , c} selected Wal Mart data available on the departmental Oracle server in the Department of Computer Sciences , Purdue University . The database contains part of Wal Mart sales data for the years 1999 and 2000 in 135 stores . We selected one of the stores , one category of items of cardinality 35 ( |A| = 35 ) and extracted 9.66 million records from table Item Scan , sorted by scan time . We divided our sources into training sets and testing sets . Training sets are data sets , which we consider to constitute the reference source . We used the first 9.56 million records as a training set to compute P ( ai ) for ai ∈A , i = 1 , 2 , . . . ,|A| for the Bernoulli reference source . Once the probability model of the reference source has been built , we can start monitoring unknown data called testing data . In section 3.1 we tested how well the formulas for P ∃(w ) worked on the WalMart data by comparing P ∃e ( w ) = Ω∃(n,w ) to the computed P ∃(w ) for different values of w . We used the following n error metric d = . 1 r%r w1 < w2 < . . . wr are the tested window sizes . In section 3.2 we tested the detection properties of the threshold τu(w ) as a function of the window length w . All our algorithms have been implemented in C++ and run under Linux operating system . i=1 |P ∃e ( wi)−P ∃(wi)|
P ∃e ( wi )
/ 100 % where
3.1 Estimation of P ∃(w )
Figure 4 . G∥(S ) for S = acc and A = {a , b , c , d}
In all experiments in this section we used the same test ing source of length n = 105 events .
Theorem 2 Consider a memoryless source with P ( S[k ] ) being the probability of generating the k th symbol of S where S is a parallel episode with
P ( S ) =
P ( S[i ] ) m+i=1 g=0 then for all m and w ≥ m we have P ∃(w ) =%path∈R P ( S)%w−m %P ni1 ,i2,,im ( path)=g,(i1,i2,,im)∈V ertices(path ) · #1 − P# ij =0{S[ij]}$$ni1,i2 ,,im ( path )
In our experiments we implemented an efficient dynamic programming algorithm based on Theorem 2 for computing P ∃(w ) . In section 311 we presented how Theorem 2 works well on real data where the formula for P ∃(w ) agrees with P ∃e ( w ) on the Wal Mart transactions .
.
3 Experiments
The purpose of our experiments was to test applicability of the analytical results for real sources . Therefore we
6
311 The case of a parallel episode S We set S = {it0 , it4 , it5 , it6 , it9 , it10 , it17} and then ran the tree based detection algorithm [ 3 ] for finding Ω(105 , w ) for w ∈ [ 10 , 180 ] and compared Pe(w ) to the analytically computed P ∃(w ) using our algorithm based on Theorem 2 . The results are shown in Figure 5 , which indicate an exceptionally close fit between P ∃(w ) and P ∃e ( w ) with the difference d of order 2 % . The results confirm our expectations that the Bernoulli model and parallel episode models well sources as the Wal Mart item scans where the source seems to generate events independently .
312 The case of a set of two serial episodes We set S1 = {it0 , it4 , it5 , it6 , it9 , it10 , it17} and S2 = {it0 , it6 , it5 , it4 , it10 , it9 , it17} where S2 is a permuted version of S1 . This case reflects a situation when a pattern of interest is only partially restricted and the serial case is too restrictive but the parallel case too relaxed . We ran an algorithm for finding Ω(105 , w ) for S for w ∈ [ 10 , 180 ] . Then compared Pe(w ) to the analytically computed P ∃(w ) using our algorithm based on Theorem 1 . The results are shown in Figure 6 , which indicate a very close fit between P ∃(w )
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE
1
0.9
0.8
0.7
) w
(
∃
P i
: e c n a t s x e f o y t i l i b a b o r p
0.6
0.5
0.4
0.3
0.2
0.1
P∃(w ) for a parallel episode S
∃(w ) ( estimated ) Pe P∃(w ) ( computed ) shown in Figure 8 . The figures clearly indicate that the serial and parallel cases of an episode S establish the lower and upper bound on the probability of existence of S in window of size w .
P∃(w ) for three cases : S parallel , S1 , S2 serial , S serial
1
0.9
0.8
0.7
) w
0
0
20
40
60
80 100 window size : w
120
140
160
180
Figure 5 . P ∃e ( w ) = Ω∃(n,w ) allel episode S , using Wal Mart data and P ∃(w ) for a par n
(
∃
P
: e c n a i t s x e f o y t i l i b a b o r p
0.6
0.5
0.4
0.3
0.2
0.1
P∃(w ) ( S parallel ) P∃(w ) ( S1 , S2 serial ) P∃(w ) ( S serial ) and P ∃e ( w ) with d of order 13 % but not so close as in the parallel case ( d = 2% ) . The reason may be the fact that this set of episodes is too restricted comparing to the parallel episode given the unordered nature of the item scans .
0
0
20
40
60
80 100 window size : w
120
140
160
180
Figure 7 . P ∃(w ) for three cases : S parallel , {S1 , S2} serial and S serial , using Wal Mart data
P∃(w ) for a set of two serial episodes S1 , S2
1
0.9
0.8
0.7
) w
(
∃
P
: e c n a t s x e i f o y t i l i b a b o r p
0.6
0.5
0.4
0.3
0.2
0.1
∃(w ) ( estimated ) Pe P∃(w ) ( computed )
0
0
20
40
60
80 100 window size : w
120
140
160
180
Figure 6 . P ∃e ( w ) = Ω∃(n,w ) and P ∃(w ) for a set S = {S1 , S2} of serial episodes , using Wal Mart data n
313 Comparison of the three cases : parallel , two se rial and one serial
In this experiment we investigate the relationship between the formulas for P ( w ) and the experimental Pe(w ) for the episode S in the three cases : parallel , partially ordered ( S2 is a permutation of S1 ) and serial ( investigated in [ 8] ) . For the first two cases we use the results obtained in the previous experiments . For the third case we ran an algorithm for discovering a serial episode in the event sequence for w ∈ [ 10 , 180 ] as in the previous experiment to create Ω(105 , w ) at the same points . The results for P ∃(w ) are shown in Figures 7 and the corresponding estimates are
7
∃(w ) for three cases : S parallel , S1 , S2 serial , S serial Pe
1
0.9
0.8
) w
(
0.7 e∃
P
: e c n a i t s x e f o y t i l i b a b o r p e t a m i t s e
0.6
0.5
0.4
0.3
0.2
0.1
∃(w ) ( S parallel ) Pe ∃(w ) ( S1 , S2 serial ) Pe ∃(w ) ( S serial ) Pe
0
0
20
40
60
80 100 window size : w
120
140
160
180
Figure 8 . P ∃e ( w ) = Ω∃(n,w ) for three cases : S parallel , {S1 , S2} serial and S serial , using Wal Mart data n
3.2 Threshold τu(w )
This experiment demonstrates an application of the upper threshold τu(w ) for detecting a significant number of occurrences of a parallel episodes S . It also shows the relationship between τu(w ) and w in detecting unusual episodes . We set S = {it8 , it12 , it14 , it15 , it19 , it20 , it26} and consider the parallel case of S . We selected a part of the scans of length n = 50000 as the test source . We compute the threshold τu(w ) = P ∃(w ) + b for
√Var[Ω∃(n,w ) ] n
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE
References
[ 1 ] A . Aho and M . Corasick ( 1975 ) , Efficient String Matching : An Aid to Bibliographic Search Programming Techniques .
[ 2 ] A . Apostolico and M . Atallah ( 2002 ) , Compact RecInformation and ognizers of Episode Sequences , Computation , 174 , 180 192 .
[ 3 ] M . Atallah , R . Gwadera and W . Szpankowski . Detection of significant sets of episodes in event sequences . http://wwwcspurdueedu/ homes/gwadera/icdm2fullps
[ 4 ] P . Billingsley ( 1986 ) , Probability and measure , John
Wiley , New York .
[ 5 ] L . Boasson , P . Sequels , I . Guessarian , and Y . Matiyasevich ( 1999 ) , Window Accumulated Subsequence Matching Problem is Linear , Proc . PODS , 327 336 .
[ 6 ] G . Das , R . Fleischer , L . G asieniec , D . Gunopulos , and J . K¨arkk¨ainen ( 1997 ) , Episode Matching , In Combinatorial Pattern Matching , 8th Annual Symposium , Lecture Notes in Computer Science vol . 1264 , 12–27 .
[ 7 ] P . Flajolet , Y . Guivarc’h , W . Szpankowski , and B . Vall´ee ( 2001 ) , Hidden Pattern Statistics , ICALP 2001 , Crete , Greece , LNCS 2076 , 152 165 .
[ 8 ] R . Gwadera , M . Atallah , and W . Szpankowski . Reliable detection of episodes in event sequences . In Third IEEE International Conference on Data Mining , pages 67 74 , Melbourne , Florida .
[ 9 ] J . Han , J . Pei , Y . Yin , R . Mao , Mining Frequent Patterns without Candidate Generation : A FrequentPattern Tree Approach , Data Mining and Knowledge Discovery , 8 , 53 87 , 2004
[ 10 ] H . Mannila , H . Toivonen , and A . Verkamo ( 1997 ) , Discovery of frequent episodes in event sequences Data Mining and Knowledge Discovery , 1(3 ) , 241258 .
[ 11 ] M . R´egnier and W . Szpankowski ( 1998 ) , On pattern frequency occurrences in a Markovian sequence Algorithmica , 22 , 631 649 .
[ 12 ] W . Szpankowski ( 2001 ) , Average Case Analysis of Al gorithms on Sequence , John Wiley , New York .
β(b ) = 10−6 for which we obtained b = 4.26 using an algorithm for computing the inverse of β(b ) . We repeated the threshold computation for three values of w = 40 , 30 , 25 for the same episode S . We simulated an attack by keeping inserting the episode S as a string into the testing source until we exceeded the threshold . We normalized the number of insertion by n . Figure 9 presents results . We conclude that the if w increases then the number of attacks causing Ω∃(n,w ) to rise above the τu(w ) increases exponentially which is caused by the exponential growth of P ∃(w ) in the formula for τu(w ) . n
Simulated attacks by a parallel episode S for thresholds τ(40 ) , τ(30 ) , τ(25 )
τ(40 )
τ(30 )
τ(25 )
8
6 14 ( number of inserted episodes ) x 1/50000
10
12
∃(40 ) Pe ∃(30 ) Pe ∃(25 ) Pe
16
18
20
0.025
0.02
0.015
0 0 0 0 5
/ ) w
,
0 0 0 0 5 (
∃ Ω = e
P
0.01
0.005
0
0
2
4
Figure 9 . The upper threshold τu(w ) as a function of w for a parallel episode S , using the Wal Mart database
4 Conclusions
We presented the exact formulas for the probability of existence P ∃(w ) , for an arbitrary set of serial episodes S including the case of a parallel episode S . Using the formulas we showed how to compute the upper threshold τu(w ) to measure significance of S . Since we adopted a computational probability approach it is valid for the Markov model of any order . The choice of the 0 the order ( Bernoulli ) was dictated only by its compactness and suitability to implementation through efficient dynamic programming algorithms . However in experiments on Wal Mart transactions we showed that formulas for the Bernoulli model very closely approximated the real life data . Realization of Markov model of order higher then 0 would require computation of P ∃(w ) using conditional probabilities of the respective order .
Acknowledgment
The authors are very grateful to Prof . Chris Clifton for many valuable remarks and encouragements .
8
Proceedings of the Fourth IEEE International Conference on Data Mining ( ICDM’04 ) 0 7695 2142 8/04 $ 20.00 IEEE
