Longitudinal LASSO : Jointly Learning Features and
Temporal Contingency for Outcome Prediction
Tingyang Xu
Department of Computer Science and Engineering University of Connecticut
Storrs , CT , USA tix11001@engruconnedu
Jiangwen Sun
Department of Computer Science and Engineering University of Connecticut javon@engruconnedu
Storrs , CT , USA
∗
Jinbo Bi
Department of Computer Science and Engineering University of Connecticut jinbo@engruconnedu
Storrs , CT , USA
ABSTRACT Longitudinal analysis is important in many disciplines , such as the study of behavioral transitions in social science . Only very recently , feature selection has drawn adequate attention in the context of longitudinal modeling . Standard techniques , such as generalized estimating equations , have been modified to select features by imposing sparsity inducing regularizers . However , they do not explicitly model how a dependent variable relies on features measured at proximal time points . Recent graphical Granger modeling can select features in lagged time points but ignores the temporal correlations within an individual ’s repeated measurements . We propose an approach to automatically and simultaneously determine both the relevant features and the relevant temporal points that impact the current outcome of the dependent variable . Meanwhile , the proposed model takes into account the non iid nature of the data by estimating the within individual correlations . This approach decomposes model parameters into a summation of two components and imposes separate block wise LASSO penalties to each component when building a linear model in terms of the past τ measurements of features . One component is used to select features whereas the other is used to select temporal contingent points . An accelerated gradient descent algorithm is developed to efficiently solve the related optimization problem with detailed convergence analysis and asymptotic analysis . Computational results on both synthetic and real world problems demonstrate the superior performance of the proposed approach over existing techniques .
Categories and Subject Descriptors G16 [ Numerical Analysis ] : Optimization—Gradient methods ; H28 [ Database management ] : Database Application—Data mining
∗Correpsondence should be adressed to Jinbo Bi .
General Terms Algorithms , Performance , Experimentation
Keywords Longitudinal modeling ; regularization methods ; sparse predictive modeling ; regression
1 .
INTRODUCTION
A longitudinal study collects and analyzes repeated measurements of a set of features for a group of subjects through time . Longitudinal analyses are important in many areas , such as in social and behavioral science [ 20 , 7 , 4 ] , in economics [ 18 , 2 ] , in climate[13 , 2 ] , and in genetics [ 21 ] . For example , to predict binge drinking of college students , a longitudinal study may be designed to monitor them weekly or even daily in terms of multiple covariates , such as , the level of stress , status of negative affects and social behaviors [ 4 , 1 ] . The fluctuation of these covariates is used to analyze and predict binge drinking ( the dependent or outcome variable ) of a student at the current observation time point . Changes of the covariates in the proximal time points are anticipated to alter the likelihood that a student binge drinks at the current observation point . To precisely understand how covariates affect the outcome , the analysis has to model not only the current values of the covariates but also their proximal values as well as take into account the correlation structure in the repeated measurements .
Typically , longitudinal data are analyzed by extending generalized linear models ( GLM ) with different assumptions , such as marginal models , random effects models , and transition models [ 6 ] . For example , a marginal model regresses the outcome on the current observation of features but factors in a within subject correlation matrix that is estimated for a few proximal time points . In contrast , a random effects model reflects the variability among individuals rather than the population average comparing with marginal models . For marginal modeling , generalized estimating equations ( GEE ) are the most widely used methods which estimate a predictive model to predict the current outcome together with correlations among different outcomes observed temporally . The resultant predictive models are generally more accurate than those of classic regression analysis that assumes independently and identically distributed ( iid ) observations [ 12 ] . Research on feature selection in longitudinal data leads to a new family of methods based on the
1345 penalized GEE ( PGEE)[8 ] . For random effects models , generalized linear mixture model(GLMM)[11 , 15 ] is the major method . It explores natural heterogeneity across individuals in the regression coefficients and represents this heterogeneity by a probability distribution .
None of those extensions of GLM aim to detect causal relationships from temporal changes of covariates to the outcomes of the current effect . In many studies , it is however necessary and insightful to model simultaneously the correlation among outcome records and the lagged causal effects of covariates [ 1 ] . For example , psychologists have identified that there is lagged effect in the alcohol use behavior . An individual ’s drinking today may be a response to an elevated level of stress two days back rather than the current day . It is actually an important question for psychologists to find out both which temporal points and which covariates influence the current outcome the most . This lagged effect is not used by temporal marginal modeling to make predictions .
On the other hand , researchers have developed machine learning approaches for longitudinal analysis that predict an outcome using feature values at multiple time points [ 2 , 13 ] . For example , graphical Granger modeling [ 2 ] , and grouped graphical Granger modeling[13 ] are insightful to explore the influences from past temporal information present in time series data in the modeling and understanding of the causal relationships . These methods assume that past values of certain time series features causally affect an outcome variable , and hence construct a model based on these values to predict future outcomes . Often , they estimate causality relationship ( causal graph ) among all features . However , these methods assume iid samples which are clearly violated in longitudinal data , and moreover they are incapable of selecting the most influential time points .
All existing methods either assume iid samples in Granger causality modeling or assume correlated samples but do not model temporal causal effects . Therefore , we propose a new learning formulation that constructs predictive models as functions of covariants not only from the current observation but also from multiple previous consecutive observations , and simultaneously determine the temporal contingency and the most influential features . The proposed method has the following advantages :
1 . The proposed method makes predictions based on lagged data from current and previous time points . It decomposes the model coefficients into a summation of two components and impose different block wise least absolute shrinkage and selection operators ( LASSO ) to the two components . One regularizer is used to detect the contingency of specific time points whereas the other is used to select covariates .
2 . The proposed method also learns simultaneously a struc tured correlation matrix from the data . The correlations among the outcomes themselves imply the changing trend of the outcomes in the proximal time points within each subject .
3 . We develop a family of methods where the outcome variable is assumed to follow a distribution from the exponential family , including Bernoulli , Gaussian and Poisson distributions . The formulations for these distributions are discussed in Section 33
4 . We provide the convergence analysis in Section 3.1 and asymptotic analysis in Section 3.2 to show that the proposed algorithm can find the optimal solution for the predictive models .
We have empirically compared the proposed method against the state of the art on both synthetic and real world datasets . The computational results demonstrate the effectiveness and the capability of our approach .
Figure 1 : The outcome yt at time t can be relevant to multiple covariates x1 , x2,··· , xd observed at current and several previous time points t − 1 , t − 2,··· , t − τ , which forms a data matrix X ( left ) . If we associate with each entry of this matrix a weight in our additive prediction model , then our model coefficients form a matrix W ( right ) . If the coefficient matrix is sparse , then the resultant model will be selective in terms of covariates and time points . 2 . METHOD
In our approach , the predictive model takes the form of the trace of the product of the lagged data X and the model coefficient matrix W as shown in Figure 1 . The model coefficients are organized into a matrix rather than a vector used in traditional analysis because this way reflects the structure in the lagged data . Note that the lagged observations of y can also be included in the data matrix X to be used in the predictive model . For notational convenience , we just use X to represent the data that are used to form the model .
We first briefly review two most relevant sets of longitudinal analytics in Section 2.1 which will help elucidate the advantages of our proposed formulation . 2.1 Preliminaries as vp = ( d
We introduce the notation that is used through out the paper . A bold lower case letter denotes a vector , such as v . The vp refers to the p norm of a vector v , which is formed i=1 |vi|p)1/p , where vi is the i th component of v and d is the length of v . A bold upper case letter denotes a matrix such as M . Similarly , m(i, ) , m(,j ) and mij represent the i th row , j th column and ( i , j) th component of M , respectively . The Frobenius norm and p,q norm of a matrix M refer , respectively , to MF , which is equal to
( tr(MM))1/2 , and Mp,q , defined by,n
( ,1),··· , m where n is the number of rows in M , and tr(M ) indicates the trace of M . We assume that vect(M ) is the columnmajor vectorization of M , which is defined as vect(M ) = ( m ( ,k ) ) assuming k columns are in M . Then , M1 , M2 is the inner product of two matrices M1 and M2 that is computed as the inner product of vect(M1 ) and vect(M2 ) . The operator reshape(v ) re shapes v into a matrix of a proper size determined by the specific context .
,m(i,)q
p 1/p , i=1
1346 t
Assume that we are given data of m number of individuals on d number of features ( independent variables ) that are repeatedly measured at ni time points for each individual i . The data of each individual i is represented by a matrix X(i ) of size d × ni , and x(i ) refers to the d entry data vector of individual i at time point t . Without loss of generality , we assume that all individuals have data at the same consecutive time points ( ni = n ) to simplify the notation and the subsequent analysis . Data on the dependent variable ( outcome ) is also given in y(i ) of length n that contains the observations at the n time points for individual i . Typically , a longitudinal study aims to estimate the effect of covariates on the dependent variable .
211 Granger Causality The notion of Granger Causality was introduced by the
Nobel prize winning economist , Clive Granger , and has proven useful in time series analysis [ 10 ] . It is based on the intuition that if a time series variable causally affects another , the past observations of the former should be useful in predicting the future outcome of the latter .
Specifically , a time series observation x is said to Granger cause another time series outcome , y , if the regressing for y in terms of past y and x is significantly better than the regressing just with past values of y . The so called Granger test first performs two regressions : y(i ) t = ajy(i ) t−j + w j x(i ) t−j
,
( 1 )
τ j=1 t = τ j=1 ajy(i ) and y(i ) t−j , where τ is the maximum “ lag ” in the past observations , and then uses a hypothesis test such as an F test to determine if the outcome yt can be predicted significantly better from the past covariate x . Recent graphical Granger models [ 2 , 13 ] extend it from a single time series covariate x to multiple covariates X . They learn the coefficients a and w ’s with LASSO type of regularizers and evaluate if coefficients are non zero for Granger causality .
212 Generalized Estimating Equations ( GEE ) GEE estimates the parameters of a GLM while taking into account the correlations in the training examples . Similar to GLM , it assumes that the dependent variable comes from a class of distributions known as the exponential family . For each member in this family , there exists a link function that can be used to translate the nonlinear model into a linear model . The expectation of the outcome y(i ) for subject i at time t is computed as : t
−1(η(i ) t ) ,
E(y(i ) t ) = µ(i ) t = g
( 2 ) represents the mean model , g−1 is the inverse of w . The where µ(i ) t a link function g in a GLM [ 14 ] , and η(i ) variance of y(i ) t )/φ where φ is a scaling parameter that may be known or estimated . x(i ) t t ) = var(µ(i ) is computed as var(y(i ) t = t
GEE presumes a so called working correlation structure , typically denoted by R(α ) , where α is a parameter to be determined from data . The common choices of R(α ) include exchangeable , tri diagonal and the first order autoregressive ( AR(1 ) ) formula [ 12 ] . The exchangeable correlation structure , also called equi correlation , assumes that corr(yit , yit ) = α for all t = t . The tri diagonal structure uses a tridiagonal matrix as R(α ) where corr(yit , yit ) = α if t = t±1 or 0 otherwise . The AR(1 ) formula assumes a correlation structure along continuous time , and uses corr(yit , yit ) = α|t−t| .
To estimate the regression coefficients w , GEE uses the the estimating equations that are formulated , in general , by setting the derivative of an appropriate loss function to 0 . Although a loss function may not be explicitly written out , the estimating equations always can be computed by
D(i )
Σ(i)−1 m i=1
EE(w , α ) = s(i ) = 0 .
( 3 ) where the n×d matrix D(i ) = ∂µ(i)/∂w where µ(i ) combines ,∀t = 1,··· , n into a vector , s(i ) = y(i)−µ(i)(w ) . The all µ(i ) t n × n matrix Σ(i ) is the estimated covariance structure as :
A(i)1/2
A(i)1/2
Σ(i)(α ) =
R(α )
/φ
( 4 ) where A(i ) is an n × n diagonal matrix with var(µ(i ) t ) as the t th diagonal element . Algorithms are given in [ 12 ] to compute w and α for the different choices of R(α ) . 2.2 The Proposed Formulation
In our approach , each training example consists of the current and τ previous records of the repeated measurements . Let
X(i;t ) = [ x(i ) t
, x(i ) t−1,··· , x(i ) t−τ ] be a d × ( τ + 1 ) data matrix for subject i . Given T total measurements for each subject , the index t of X(i;t ) starts from τ + 1 in order to have enough previous observations in the first training example . Hence , there are totally n = T − τ training examples for each subject . If X(i;t ) includes previous τ + 1 values of y(i ) as a feature , then the model y(i ) gives the same model like Eq ( 1 ) in the graphical Granger models .
( i;t)W where W = [ w0 , w1,··· , wτ ] essentially t = tr,X
The Granger models would assume that the training examples are iid However , the consecutive examples are not mutually independent because they contain overlapping , ··· , records ( eg , X(i;t ) and X(i;t+1 ) share τ −1 records x(i ) x(i ) t−τ +1 ) . GEE provides a mechanism to estimate the sample correlation simultaneously while constructing predictive models , and to extend the linear models to generalized linear models . To apply GEE to our model , we replace η(i ) used in GEE by the following formula t t
η(i ) t = tr
( i;t)W
X
.
( 5 )
Substituting Eq ( 5 ) for η in Eq ( 2 ) yields a formulation similar to GEE . The regression coefficients W can be estimated through the well developed GEE estimators . In particular , the quasi likelihood methods of GEE estimate W by minimizing a loss function that is defined via the model deviance . The model deviance measures the difference between the log likelihood of the estimated mean model µ(i ) and that of the observed values y(i ) . For instance , the model deviance for a linearly regressive response is written by Dev(i)(W , α ) = ( y(i)−µ(i))R(α)(y(i)−µ(i ) ) where y(i ) contains the observed responses for subject i , and µ(i ) is the estimated expectations of y for subject i . If the response follows an arbitrary distribution , the model deviance may
1347 function ofm not correspond to an explicit function . For the exponential family , it takes a special form as discussed in Theorem 1 below , which is still complicated . We denote by Dev(i)(W , α ) the deviance occurred on subject i . GEE minimizes a loss i=1 Dev(i)(W , α ) for the optimal W by solving the estimating equations , ie , taking the derivatives of the loss function and setting them to 0 .
Now , to select among features and discover the most influential time points in predicting y over time , ( and also to control the model capacity , ) we apply regularizers to the model parameters . We first decompose W into a summation of two components as W = U + V and apply different regularizers to U and V . The block wise LASSO , such as the 1,2 matrix norm , is widely used in multi task learning or feature selection with group structures , but has not been explored within the GEE setting . To the best of our knowledge , it has not been studied in longitudinal analytics how to produce shrinkage effects simultaneously on both features and contingent temporal records through proper regularization . The general 1,p matrix norm [ 23 ] calculates the sum of the p norms of the rows in a matrix . Regularizers based on the 1,p norms encourage row sparsity by shrinking the entire rows to have zero entries .
In our parameter matrix W , rows correspond to features and columns correspond to the observation time points . If we apply the 1,2 norm to U ( row wisely ) , the optimal solution of U will contain rows with all zero entries . Thus , a selected subset of features in the τ + 1 observations will be used in the predictive model to predict the current outcome . The 1,2 norm of V ( column wisely ) encourages to select among columns of V . If the k th column of V contains the largest values in the selected columns , the current outcome is most contingent on the previous ( k − 1) th record , thus having the ( k − 1 ) “ lagged ” effect . Overall , we solve the following optimization problem for the best model parameters W which is computed as U + V :
Dev(i)(U + V , α ) + λ1U1,2 + λ2V
1,2
( 6 ) m i=1 min U,V where W in the deviance is simply replaced by U + V .
The optimization of Eq ( 6 ) is challenging .
In general , even solving the GEE formulation is not easy as it estimates not only the model expectation but also the variance term Σ(i ) . The algorithm that solves the GEE ( ie , the estimating equations ) applies the Newton Raphson method in the iterative reweighted least squares ( IRLS ) procedure [ 8 ] to estimate w and Σ(i ) . However , this method does not solve any formula that uses regularizers . By modifying the Newton Raphson method or shooting algorithm [ 8 ] , it can be extended only to the regularizers that are decomposable into individual parameters wj . For instance , the 1 vector norm of w can be decomposed into the summation of individual |wj| , j = 1,··· , d . The 1,2 matrix norm , unfortunately , can not be decomposed in such a way . Therefore , we have developed an accelerated gradient descent method based on the fast iterative shrinkage thresholding algorithm ( FISTA ) [ 3 ] . Further , the following theorem shows that Eq ( 6 ) is a convex optimization problem in terms of W . Our algorithm can be proved to find the global optimal solution W of Eq ( 6 ) when α is fixed ( to a consistent estimate given by GEE ) .
Theorem 1 . The first term of Eq ( 6 ) is convex and continuously differentiable with respect to U and V if the dis tribution of y(i ) is in a natural exponential family and the link function is continuous .
Proof . First , let us recall that the probability density function of a distribution in the exponential family takes the following form : f ( y(i ) t ) = exp
+ c(y(i ) t
, φ )
, t − b(η(i ) y(i ) t η(i ) t ) a(i ) t ( φ ) t ( φ ) , b(η(i ) t ) , and c(y(i ) where a(i ) , φ ) are known functions and specified for each member of the exponential family , and η(i ) is a parameter in the mean as defined in Eq ( 2 ) . Typically , a(i ) t ( φ ) = φ . Then , the deviance of the exponential family can be computed as t t
Dev = 2 y(i ) t ( ˜η(i ) i=1 t ) − b(˜η(i ) t − ˆη(i ) φ t ) + b(ˆη(i ) t ) m
, t t ) = µ(i ) t where ˜η(i ) t denotes the true value under a saturated model , ˆη(i ) t denotes the fitted values of the model . Thus , ˜η(i ) and b(˜η(i ) t ) are constant in model fitting . The derivative of b always satisfies b(η(i ) . Moreover , it has been proved that b(ˆη(i ) t ) is a convex function on the natural parameter space H = {ˆη|b(ˆη ) < ∞} [ 19 ] . Thus , the deviance contains either linear terms or a convex term with respect to ˆη . In our model ( 5 ) , ˆη is linear with respect to W . Hence , the deviance term in Eq ( 6 ) is convex with respect to U and V . t ) which is the inverse of a continuous link function [ 19 ] . The first term of Eq ( 6 ) is continuously differentiable with respect to U and V . Thus , theorem 1 holds . 2.3 Optimization Algorithm
Moreover , it is true that b(ˆη(i ) t = g−1(ˆη(i ) t ) = ˆµ(i )
To solve Eq ( 6 ) , we design an alternating optimization algorithm that alternates between optimizing two working sets of variables : one set consisting of U and V and the other consisting of α . ( a ) Find U and V when α is fixed
When α is fixed , the objective function of Eq ( 6 ) , denoted by f ( U , V ) , is convex with a continuously differentiable part ( U , V ) that is the deviance and a nonsmooth part R(U , V ) that constitutes the two regularizers . We hence have f ( U , V ) = ( U , V ) + R(U , V ) .
Denote the iterates at the k th iteration by Uk and Vk .
We develop a FISTA algorithm in the following iterative procedure to find optimal U and V . Let ∇U(U , V ) , ∇V(U , V ) be the partial derivative of ( U , V ) with respect to U and V , respectively , For any given point ( ˜U , ˜V ) , the following QL , ˜U , ˜V(U , V ) is a well defined proximal map for the non smooth R
QL , ˜U , ˜V(U , V ) = ( ˜U , ˜V ) + R(U , V )
+ ∇U( ˜U , ˜V ) , U − ˜U + + ∇V( ˜U , ˜V ) , V − ˜V +
U − ˜U2 V − ˜V2 F .
F
L 2 L 2
If ( U , V ) has Lipschitz continuous gradient with Lipschitz modulis L . Then , according to the Lemma 2.1 in [ 3 ] , the inequality f ( U , V ) ≤ QL , ˜U , ˜V(U , V ) .
1348 ( 7 )
( 8 )
( 9 ) holds indicating that QL , ˜U , ˜V(U , V ) is the upper bound of f ( U , V ) .
Starting from an initial point ( U0 , V0 ) , we iteratively search for the optimal solution . At each iteration k , we first use the iterates ( Uk−1 , Vk−1 ) and ( Uk−2 , Vk−2 ) to compute ( at the first iteration , ( ˜U1 , ˜V1 ) = ( U0 , V0 ) )
˜Uk = Uk−1 +
˜Vk = Vk−1 +
( Uk−1 − Uk−2 ) ,
( Vk−1 − Vk−2 ) , tk tk−1 − 1 tk−1 − 1 1 +1 + 4t2 tk tk+1 = k
.
2 where tk is a scalar and updated at each iteration as :
Then , we solve the following problem min U,V
∇Uk , U − ˜Uk + L 2 + ∇Vk , V − ˜Vk + + R(U , V )
U − ˜Uk2
F
V − ˜Vk2
F
L 2 for a solution ( Uk , Vk ) , where ∇Uk and ∇Vk are respectively the partial derivatives of computed at ( ˜Uk , ˜Vk ) , and L acts as a learning step size .
Since there is no interacting term between U and V in Eq ( 9 ) , the problem can be decomposed into two separate subproblems as follows : ∇Uk , U − ˜Uk +
F + λ1U1,2 ,
U − ˜Uk2
( 10 ) min
U
∇Vk , V − ˜Vk + min
V
L 2
F + λ2V
1,2 .
( 11 )
The two subproblems share the same structure and thus can be solved following the same procedure . Hence , we only show how to solve ( 10 ) for the best U .
Eq ( 10 ) is equivalent to the following problem
L 2 V − ˜Vk2 min
U
1 2
˜Uk − 1 L
∇Uk
+
λ1 L
U1,2 after omitting constants , and this problem has a closed form solution where each row of Uk , Uk
( i , ) is :
Uk
( i , ) = max
0 , 1 −
λ1 ( i,)2 LP(k )
P(k ) ( i, ) , and P(k ) = ˜Uk − 1 the gradient of the deviance ) can be computed by Eq ( 3 ) with the fixed α , ie
L∇Uk . The gradient vector ∇Uk ( ie , m
D(i )
Σ(i)−1
∇Uk = reshape s(i ) k
( 12 ) i=1 where s(i ) t = g−1(tr(X k = y(i)−µ(i ) , and µ(i )
( i;t)( ˜Uk + ˜Vk)) ) . In the above discussion , the Lipschitz modulus L is computed and given . However , the calculation of L can be computational expensive . We therefore follow the similar argument in [ 9 ] to find a proper approximation Lk at each iteration k starting from L0 > 0 . Recall that the Lipschits constant L is defined :
L = max W
λmax ( ∇∇W ) flflflflU − flflflfl2
F where λmax(· ) indicates the maximum singular value of the Hessian of . Decompose the Hessian matrix ∇∇W|W→0 into MM where M ∈ Rd(τ +1)×q and q is the rank of the Hessian matrix . We have an upper bound of L as follows :
L ≤ ||M||∞,1||M
||∞,1 .
( 13 )
We use the upper bound ˜L in Eq ( 13 ) as L in our iterations . Using this upper bound may increase the number of iterative steps for convergence . Algorithm 1 summarizes the steps for finding optimal U and V with fixed α .
Algorithm 1 Search for optimal U and V with fixed α
Input : X , y , Σ , λ1 , λ2 Output : U , V 1 . k = 1 , compute ˜L and initialize t1 = 1 , U0 = ˜U1 = 0 and V0 = ˜V1 = 0 ; 2 . Solve Eq ( 9 ) to obtain Uk and Vk . 3 . Compute tk+1 by Eq ( 8 ) . 4 . Compute ˜Uk+1 and ˜Vk+1 by Eq ( 7 ) . 5 . k = k + 1 . Repeat 2 ∼ 5 until convergence .
( b ) Find α when U and V are fixed
When U and V are fixed , the regularizers no longer appear in the objective of Eq ( 6 ) . Eq ( 6 ) is degenerated into just the GEE formula with α as the variables . Hence , α can be estimated via the standard GEE procedure , ie , from the current Pearson residuals defined by : t − tr y(i )
γ(i ) t =
,X(i;t )
( σ(i ) t,t )(1/2 )
.
( U + V ) where σ(i ) t,t is the t th diagonal entry in the matrix Σ(i ) [ 12 ] . The specific estimator of α depends on the choices of R(α ) . This GEE based procedure has been shown to find a consistent estimate of α [ 12 ] .
Let N = mn be the total number of training examples , and p = d(τ + 1 ) be the practical number of parameters in W . A general approach to estimating R is given by : rj,k = j γ(i ) γ(i ) N − p k
,
( 14 ) m n
2 for j = 1,··· , n , and k = 1,··· , n . In addition , the scaler parameter φ in Eq ( 4 ) can be estimated as follows :
φ = ( N − p)/
γ(i ) t
.
( 15 )
Algorithm 2 depicts the overall procedure for solving Eq ( 6 ) . i=1 t=1
Algorithm 2 Main algorithm Jointly select features and temporal points
Input : X , y , λ1 , λ2 Output : U , V 1 . Set R(α ) = I ; 2 . Solve for U and V using Algorithm 1 . 3 . Estimate α using a proper estimator in [ 12 ] and compute R(α ) by Eq ( 14 ) and φ by Eq ( 15 ) . Repeat 2 ∼ 3 until convergence . m i=1
1349 3 . THEORETICAL ANALYSIS yields
We provide a convergence analysis for Algorithm 1 and an
||U0 − ˆU||2
F + ||V0 − ˆV||2
F
( k + 1)2 vk ≤ 2Lk asymptotic analysis for the proposed formulation . 3.1 Convergence Analysis
We show that Algorithm 1 converges to the optimal solution with a convergence rate of O(1/k2 ) . The proof follows largely the arguments in [ 3 ] . We only provide a sketch here .
Theorem 2 . Let Uk and Vk be the pair of the matrix generated by Algorithm 1 . Then for any k ≥ 1 f ( Uk , Vk ) − f ( ˆU , ˆV ) ≤ 2 ˜L
||U0 − ˆU||2
F + ||V0 − ˆV||2
F
( k + 1)2 where ( ˆU , ˆV ) is a globally optimal solution of Eq ( 6 ) .
Proof . We start with defining the following quantities vk =f ( Uk , Vk ) − f ( ˆU , ˆV ) ,
2 Lk t2 kvk , ak = bk =||tkUk − ( tk − 1)Uk−1 − ˆU||2 +||tkVk − ( tk − 1)Vk−1 − ˆV||2 F , c =|| ˜U1 − ˆU||2 =||U0 − ˆU||2
F + || ˜V1 − ˆV||2 F + ||V0 − ˆV||2 F ,
F
F where ˜U1 = U0 , ˜V1 = V0 , and subsequent ˜Uk and ˜Vk are defined by Eq ( 7 ) . Following the proof of Theorem 4.4 in [ 3 ] , in the first iteration , given t1 = 1 , we have a1 = 2 v1 , and L1 F . We show that a1 + b1 ≤ c b1 = ||U1 − ˆU||2 by applying Lemma 2.3 in [ 3 ] , which yields
F − ||V1 − ˆV||2 f ( ˆU , ˆV ) − f ( U1 , V1 ) = −v1 ≥ L1 2
F + L1 ˜U1 − ˆU , U1 − ˜U1
||V1 − ˜V1||2
F + L1 ˜V1 − ˆV , V1 − ˜V1
||U1 − ˜U1||2 L1 2 ( ||U1 − ˆU||2 L1 2
( ||V1 − ˆV||2
=
+
L1 2
+
F − || ˜U1 − ˆU||2 F ) F − || ˜V1 − ˆV||2
F ) .
Reorganizing the above inequality yields
2 L1
1v1 + ||U1 − ˆU||2 t2
F + ||V1 − ˆV||2
F ≤ F + || ˜V1 − ˆV||2
F
|| ˜U1 − ˆU||2
Thus , a1 + b1 ≤ c holds . Then , according to Lemma 4.1 in [ 3 ] , we have for every k ≥ 1 , ak − ak+1 ≥ bk+1 − bk , together with a1 + b1 ≤ c , which derives into the following inequality , c ≥ a1 + b1 ≥ a2 + b2 ≥ ··· ≥ ak + bk ≥ ak .
Therefore , we obtain that kvk ≤ ||U0 − ˆU||2 t2
F + ||V0 − ˆV||2 F ,
( 16 )
2 Lk
Given tk is updated according to Eq ( 8 ) , it is easy to show that tk ≥ ( k + 1 )
. Substituting this inequality into Eq ( 16 )
2
By the Remark 3.2 in [ 3 ] and the inequality ( 13 ) , we also know that an upper bound of Lk is ˜L . Hence , f ( Uk , Vk ) − f ( ˆU , ˆV ) ≤ 2 ˜L In our algorithm , we set Lk = ˜L,∀k .
||U0 − ˆU||2
F + ||V0 − ˆV||2
( k + 1)2
F
Remark 1 . The loss function , ( U , V ) , of an exponential distribution has Lipschitz continuous gradient within the range {||U||1,2 ≤ δ1,||V||1,2 ≤ δ2} where δ1 , δ2 are constant values in terms of λ1 , λ2 , respectively to guarantee the non trivial step size λ L . Otherwise , it may lead to a suboptimal solution . 3.2 Asymptotic Analysis
To facilitate the asymptotic analysis , we re write the no tation as follows : let
β = [ vect(U )
, vect(V )
]
, H(i ) = [ h(i )
τ +1,··· , h(i ) n ] and h(i ) t = [ vect(Xi;t )
, vect(Xi;t )
] where one block Xi;t corresponds to U and the other to t )β , and V . Then , correspondingly , we have η(i ) f ( U , V ) can be re written as f ( β ) = ( β ) + R(β ; λ1 , λ2 ) . t = ( h(i )
Solve Eq ( 6 ) yields a solution to the penalized estimating equations : i
( D(i ) )
( Σ(i ) )
−1s(i ) + λ
∂R(β )
∂β
= 0
( 17 ) assuming λ1 = λ2 = λ for notational convenience which will not change the property . Given our model definition ( 5 ) , D(i ) = A(i)(H(i) ) . The first term in ( 17 ) is the estimating functions in GEE [ 12 ] whereas the second term corresponds to the regularizers . The asymptotic property of Eq ( 6 ) can be naturally derived from the results in [ 12 ] which have proved that the estimating equations L(β ) = i(D(i))(Σ(i))−1s(i ) of GEE gives a consistent estimator tions : H(i ) is bounded , and limm→∞( of β . We extend the same argument to our formulation Eq ( 6 ) in Theorem 3 under the following regularity condii H(i))/m = H(0 ) , and ( H(i))H(i ) are not singular , and the following limit is also not singular i lim m→∞(
( H(i ) )
H(i))/m ;
Moreover , L(β ) is twice continuously differentiable with respect to β , and ∂L/∂β is positive definite .
Theorem 3 . Assume that : ( 1 ) ˆα is a consistent estima√ tor given β ; ( 2 ) ˆφ is a consistent estimator given β ; and ( 3 ) the tuning parameter λm = o( m ) . Under the regularity conditions listed above , optimizing Eq ( 6 ) yields an asymptotically consistent and normally distributed estima tor ˆβ , that is:√ m(ˆβ − β
∗
) →d N ( 0 , Σ ) as m → ∞
1350 i
1 m where β∗ is the true model coefficients in a model of E(y(i ) g−1((h(i ) matrix ( see [ 12 ] for details of Σ ) . t ) = t )β ) and Σ is a positive definite variance covariance
Proof . Multiplying 1/m to both sides of Eq ( 17 ) yields
( D(i ) )
( Σ(i ) )
−1s(i ) +
λm m
∂R(β )
∂β
= 0 .
( 18 ) i(D(i))(Σ(i))−1s(i ) = 0 yields It is known that solving 1 m an estimate of ˆβ that is asymptotically consistent with β∗ :
√ m(ˆβ − β
∗
) →d N ( 0 , Σ ) as m → ∞ [ 12 ] .
Since our regularizer R ( based on the 1,2 matrix norm ) is Lipschitz continuous , its partial derivative ∂R(β)/∂β is bounded . The second term of Eq ( 18 ) vanishes when m → ∞ , and thus the conclusion holds .
Recall how ˆα and ˆφ are estimated in the proposed method . Those estimates from the Pearson residuals are consistent . Thus , the estimate ˆβ in the proposed method is asymptotically consistent and normally distributed according to Theorem 3 . 3.3 Exemplar Exponential Families with Lip schitz Condition
The purposed algorithm is suitable to optimize any loss function that has Lipschitz continuous gradient . In this section , we discuss that three exemplar exponential families : Gaussian , Bernoulli , and Poisson , satisfy the Lipschitz condition . We specify how to compute the gradient of the loss function for these distributions . The gradients will instantiate ( and replace ) Eq ( 12 ) used in our algorithm .
331 Gaussian Distribution If the outcome follows a Gaussian distribution , then the outcome y is linearly regressive in terms of the covariates in the observations . The mean and the conditional covariance of y with a working correlation structure R(α ) are calculated as :
E(y(i ) t ) = µ(i ) t = tr
( i;t)W
X
, cov(y(i ) ) = Σ(i ) = R(α ) , so the gradient ∇Uk in Eq ( 12 ) at the k th iteration can be computed as m D(i )
=.vect,X(i;1 ) D(i ) i=1
∇Uk = reshape where D(i ) = ∂µ(i )
∂vect( ˜Uk ) k = y(i ) −
, . . . , vect,X(i;n )
−1 s(i ) k
,
( R(α ) )
fi
, vect( ˜Uk ) . The gradient ∇Vk can and s(i ) be similarly computed . Hence , the gradient is linear in terms of β , and thus Lipschitz continuous .
332 Bernoulli Distribution If the generalized variables µ follow a Bernoulli distribution and the outcomes are binary variables . The relationship between the outcome and covariates can be learned by a logistic regression which is a special case of the GLM with the Bernoulli assumption . Hence , the mean and the conditional covariance of y with the working correlation structure R(α ) exp(η(i ) t ) 1 + exp(η(i ) t )
A(i)1/2
R(α )
φ are formulated as t =
E(y(i ) t ) = µ(i ) where A(i ) = diag cov(y(i ) ) = Σ(i ) =
A(i)1/2 µ(i ) , 1 − µ(i )
2
D(i ) ( A(i ) ) , . . . , vect,X(i;n ) = A(i).vect,X(i;1 ) ∂η(i ) × ∂η(i ) where D(i ) = ∂µ(i )
) ( i ) 1+exp(η t and η(i )
∂vect( ˜Uk ) reshape
( i ) exp(η t
= diag
)
fi
The gradient ∇Uk in Eq ( 12 ) can be written as : t = tr(X
( i;t)W ) .
−1/2R(α )
−1(A(i ) )
−1/2s(i ) k
( 19 )
, and s(i ) k = y(i ) − µ(i)( ˜Uk ) . The gradient ∇Vk can be similarly computed . 333 Poisson Distribution If the generalized variables µ follow a Poisson distribution and the outcomes contain count values . The relationship of the outcome and covariates is learned by a Poisson regression . The mean and the conditional covariance of y with the working correlation structure R(α ) are formulated as
E(y(i ) t ) = µ(i ) t = exp(η(i ) t )
( µ(i ) )
A(i)1/2
R(α )
φ
A(i)1/2 cov(y(i ) ) = Σ(i ) =
= diag exp(η(i ) t ) where A(i ) = diag . The gradient ∇Uk can be computed using the general formula Eq ( 12 ) . The loss function of Poisson regression does not have globally Lipschitz continuous gradient . But the regularized loss function is equivalent to requiring the constraints , ||U||1,2 ≤ δ1 and ||V||1,2 ≤ δ2 [ 17 ] for appropriate values of δ1 and δ2 that are determined according to λ1 and λ2 . The loss function of Poisson regression does have Lipschitz continuous gradient within the confined region . 4 . EMPIRICAL EVALUATION
We validated the proposed approach by comparing it to several most relevant and recent methods . Three GLMbased [ 16 ] methods : GEE [ 12 ] , GLMM [ 11 , 15 ] , and RE EM tree1 [ 18 ] were compared . The recent graphical Granger modeling2 [ 13 ] and a support vector machine based method called CSVM were also used . RE EM tree and graphical Granger modeling could only be applied to regression problems ( linearly regressive data from Gaussian distributions ) , and CSVM was only suitable to classification tasks ( logistically regressive data from Bernoulli distributions ) . We named our approach by LGL ( longitudinal group lasso ) . The normalized mean squared error ( nMSE ) , which is the MSE divided by the variance of y [ 22 , 9 ] , was used to measure regression performance . The area under the ROC curve ( AUC ) [ 5 ] was used to measure classification performance . 1An R package is available in the Comprehensive R Archive Network ( CRAN ) 2downloaded from the author ’s website http://wwwbcfuscedu/∼liu32/codehtml
1351 ing performed reasonably well but lacked of consideration of temporal correlation in the consecutive records . When the simulated noise increased , the performance of all methods had dropped as expected . We further demonstrate the selected features and temporal contingency . Figure 2 shows the constructed U , V , and W by the LGL on the regression data with the AR(1 ) covariance structure and N ( 0 , 32 ) residual where darker colors indicate larger values ( and white means 0 ) . Most of the features from 150 to 200 were selected in U and the correct columns ( ie , 1 , 3 , 4 ) were selected in V . We compared our approach with the Granger model that also learned W in Figure 3 . Obviously , the Granger model excluded too many variables in the model . These results demonstrate the capability of LGL in terms of simultaneously capturing the important features and lagged effects . 4.2 Real world Data
We tested our approach on two real world datasets : the college alcohol use dataset ; and the national longitudinal survey of youth ( NLSY ) dataset3 . All comparison methods were used except GLMM due to its prohibitive computational costs . The college alcohol use dataset consisted of data from 504 college students on 52 variables in a period of continuous 30 days . The 52 variables measured each subject on daily stress , moods , emotion and substance use behavior . One of the variables measured the number of night time drinks , which was our outcome variable , forming a regression problem . We also predicted the binge drinking behavior which is defined as having 5 or more night time drinks , which formed a classification problem . The NLSY dataset consisted of 11 yearly data for 3,376 subjects on 27 variables . The outcome variable measured the number of days that a subject had binge drinking in past 30 days , forming a regression problem . The other 26 variables measured features , such as smoking , drug use , family support and education .
For the college alcohol use data , we experimented with using the last t = 3 , 5 , 8 , 10 days of records as test data , and the rest for training . We found τ = 3 was feasible . Larger τ would not change the results because the extra time points would be excluded by our model . However , it practically would cut down the sample size of each subject . The parameters λ1 and λ2 in our approach and any tuning parameters in other methods were tuned in a three fold cross validation within the training data . Table 2 shows the results where our approach LGL outperformed other methods in most settings . Among the four different correlation assumptions , LGL with AR(1 ) obtained the best performance on three of the four settings . The results also confirmed that modeling the correlation among repeated observations improved prediction performance [ 12 ] . We also observed that for instance , 16 out of 51 variables were selected when we used the last 5 days to test binge drinking prediction . Features related to exited mood , under stress and interacting with friends during night time were the risk factors for binge drinking . The past 3 days were all included in the model , showing there was “ lagged ” effects in alcohol use . The effect of past days was reduced with prolonged time lag .
For the NLSY dataset , we experimented respectively with using the last one , two and three years from each subject for test and the rest in training . We also considered τ = 3 , which means we used 3 year lagged data to predict the current year ’s behavior . All tuning parameters were tuned us3http://wwwblsgov/nls/nlsy97htm
Figure 2 : The model constructed by our approach LGL on a synthetic dataset .
Figure 3 : Comparison between the constructed models by LGL and Granger . 4.1 Synthetic Data
We generated a data matrix X ∈ Rd×T m from the normal distribution N ( 0 , 16 ) , where d = 200 , T = 30 , and m = 400 . All training examples X(i;t)(i = 1,··· , m , ∀t = τ +1,··· , T ) and τ = 4 were formed from the matrix X . Then , U and V were generated from the normal distribution N ( 0 , 49 ) . We set the rows corresponding to features from 1 to 150 in U to zero and the columns 2 and 5 of V to zero , and computed W = U + V . The residuals s(i ) of every subject were generated from a multivariate normal distribution of different variances , N ( 0 , 12 ) , N ( 0 , 22 ) , N ( 0 , 32 ) . The covariance matrix of the residual followed different working correlation structures R(α ) with the parameter α = 064 We generated 9 sets of regression residuals by choosing different combinations of the variances and the working correlation structures . Finally , the outcome variables y(i ) were computed as y(i ) =.vect,X(i;τ +1 )
, . . . , vect,X(i;n )
fi vect(U+V)+s(i ) . t
The above procedure produced regression data . Using the same data X , the outcome y(i ) of a classification problem was generated from the Bernoulli Distribution with B(1 , µ(i ) t ) where we used Eq ( 19 ) with the regression y(i ) to obtain µ(i ) . We hence obtained totally 18 synthesized data with 9 datasets for each distribution . We used the 25 early records of each subject to compose the training data and the rest 5 records to form test data .
Table 1 shows the results where we can see that LGL outperformed all other methods on all the simulated datasets . The proposed method with correct correlation assumptions always performed the best . The graphical Granger model
1352 Table 1 : Comparison of different algorithms on synthetic data : ( top ) regression ; ( bottom ) classification .
LGL
GEE n o i s s e r g e R n o i t a c fi i s s a l C
Structures e
AR(1 )
N ( 0 , 12 ) N ( 0 , 22 ) N ( 0 , 32 ) N ( 0 , 12 ) exchangeable N ( 0 , 22 ) N ( 0 , 32 ) N ( 0 , 12 ) N ( 0 , 22 ) N ( 0 , 32 )
Tri diag ind
AR(1 ) exchangeable Tri diag 0.0018 0.0020 0.0019 0.0025 0.0039 0.0028 0.0032 0.0036 0.0038 0.0015 0.0022 0.0018 0.0024 0.0024 0.0025 0.0028 0.0027 0.0032 0.0021 0.0022 0.0021 0.0013 0.0026 0.0018 0.0031 0.0041 0.0033
0.0020 0.0026 0.0034 0.0016 0.0023 0.0026 0.0021 0.0023 0.0035 ind
AR(1 ) exchangeable Tri diag 0.6613 0.7223 0.7191 0.6872 0.6927 0.7204 0.7514 0.6790 0.7226
0.6615 0.7236 0.7185 0.6875 0.6930 0.7204 0.7514 0.6792 0.7235
0.6614 0.6617 0.7224 0.7242 0.7182 0.7192 0.6872 0.6873 0.6927 0.6930 0.7204 0.7205 0.7514 0.7514 0.6791 0.6793 0.7226 0.7226
GLMM RE EM tree Granger 0.0664 0.6657 0.0667 0.7323 0.0676 0.7179 0.0656 0.6914 0.6931 0.0691 0.0635 0.7204 0.0665 0.7515 0.0680 0.6840 0.7222 0.0660
0.9873 0.9998 0.9924 0.9977 0.9982 0.9797 0.9925 0.9991 0.9998
LGL
GEE ind ind e
AR(1 )
Structures
AR(1 ) exchangeable Tri diag
CSVM N ( 0 , 12 ) 96.490 % 96.485 % 96.485 % 96.417 % 77.691 % 77.700 % 77699%77715 % 76.644 % N ( 0 , 22 ) 96.442 % 96.431 % 96.432 % 96.653 % 74.682 % 74.727 % 74682%74731 % 75.249 % N ( 0 , 32 ) 95.921 % 95.917 % 95.917 % 95.805 % 77.704 % 77.746 % 77708%77754 % 77.547 % N ( 0 , 12 ) 95.913 % 95.937 % 95.912 % 95.883 % 76.115 % 75.812 % 76114%75923 % 75.232 % exchangeable N ( 0 , 22 ) 95.139 % 95.161 % 95.147 % 95.150 % 70.290 % 70.231 % 70275%70206 % 71.687 % N ( 0 , 32 ) 94.127 % 94.091 % 94135%93470 % 73.839 % 73.782 % 73831%73776 % 73.894 % N ( 0 , 12 ) 95.976 % 95.941 % 95978%95889 % 77.628 % 77.634 % 77625%77617 % 76.778 % N ( 0 , 22 ) 95.231 % 95.231 % 95245%94395 % 72.132 % 72.060 % 72126%72054 % 71.615 % N ( 0 , 32 ) 95.092 % 95.087 % 95094%94231 % 77.755 % 77.533 % 77748%77637 % 77.572 %
AR(1 ) exchangeable Tri diag
Tri diag
Table 2 : Comparison of different algorithms on the college alcohol use dataset : ( top ) predicting the number of night time drinks ( regression ) ; ( bottom ) predicting the occurrence of binge drinking ( classification ) .
LGL
GEE
# observations
AR(1 ) exchangeable tri diag ind
AR exchangeable tri diag ind
3 5 8 10
0.933513 0.951999 0.759935 0.769303
0.933863 0.954740 0.760450 0.769492
0.935120 0.961841 0.951953 0.976299 0.760136 0.762205 0.769428 0.774937
1.064792 1.051219 0.787731 0.812622
1.073358 1.067303 0.793329 0.818834
1.063948 1.065760 1.049305 1.072745 0.787497 0.794089 0.812011 0.806301
RE EM tree Granger 1.369948 1.420547 0.909706 0.940940
1.115627 1.005753 0.759968 0.774797
LGL
GEE exchangeable tri diag ind
AR exchangeable tri diag ind n o i s s e r g e R n o i t a c fi i s s a l C
# observations
3 5 8 10
AR(1 ) 79.737 % 75.677 % 83.290 % 77.237 % 88.570 % 87.331 % 89.484 % 87.574 %
79.772 % 78.579 % 78.401 % 74.145 % 78.650 % 77.831 % 83.070 % 82.323 % 80.371 % 78.363 % 80.646 % 80.438 % 87.936 % 87.787 % 85.999 % 86.330 % 85.714 % 86.014 % 88.853 % 88.578 % 85.979 % 86.622 % 85.721 % 85.783 %
CSVM
80.698 % 83.187 % 88.017 % 89.041 % with the independent correlation assumption had the worst performance among all LGL variants ) .
The gray map of U , V and W constructed by LGL is shown in Figure 4 to illustrate an example for the tri diagonal working correlation assumption . Out of the 26 features , 12 were selected by LGL and we list them below . F2 : # days of smoking a cigarette in the past 30 days F3 : Received a training certificate or vocational license F7 : The grade began during the academic year F8 : # months that respondent did not attend school during the academic year F12 : The college degree working toward or attained F13 : The highest grade completed as of the survey year F15 : The highest grade attended as of the survey day F16 : The highest grade completed as of the survey day F17 : # days of using marijuana in the past 30 days F19 : # times of using some drug or other substance right before school or during school or work hours F25 : As the victim of a violent crime in the survey year F26 : Divorced parents . This list shows that a subject ’s smoking , drug use , education background and family support influenced his or her drinking behavior . Figure 4 demonstrates that the data in the third prior year might be obsolete to predict this year ’s behavior as LGL only selected the past two years for use in the model as seen in the plot of V .
Figure 4 : The model constructed by our approach on the NLSY dataset . ing a within training two fold cross validation . The results are reported in Table 3 . For any assumption of the working correlation structure , LGL had comparative performance with RE EM tree and consistently outperformed GEE in all of the three experiments . LGL with tri diagonal correlation performed the best on this dataset . The results here again show that taking care of the correlation among repeated observations improves the performance ( given we see that LGL
1353 Table 3 : Comparison of different algorithms on the NLSY dataset in terms of test nMSE values .
# observations
AR(1 ) exchangeable tri diag ind
AR exchangeable tri diag ind
1 2 3
0.906552 0.888608 0.885448
0.908932 0.891761 0.885814
0.904760 0.909446 0.887294 0.891051 0.883617 0.887579
0.911543 0.898132 0.892963
0.918691 0.904225 0.895863
0.911885 0.914043 0.897920 0.898320 0.892633 0.890937
RE EM tree Granger 1.370135 1.363714 1.360430
0.904260 0.888822 0.883958
LGL
GEE
5 . DISCUSSION
We have proposed a new learning formulation for longitudinal analytics . Unlike existing methods , the proposed approach can simultaneously determine the temporal contingency and the influential features in predicting an outcome over time . The model parameter matrix is computed by the summation of two component matrices : one matrix reflects the selection among covariates ; and the other characterizes the dependency along the temporal line . Moreover , our approach simultaneously models the sample correlations in the longitudinal data while constructing a predictive model . The related optimization problem can be efficiently solved by a new accelerated gradient descent algorithm . Convergence analysis shows that the algorithm can find the global optimal solution for the model with a quadratic convergence rate . An asymptotic analysis shows that the solution of our formulation is a consistent estimate of the model parameters . Hence , the proposed approach solves an underdeveloped problem jointly learning the relevant features and determining how current outcome relies on past observations . Empirical studies on both synthetic and real world problems demonstrate the superior performance of the proposed approach over the state of the art .
Acknowledgments This work was supported by NSF grants IIS 1320586 , DBI1356655 and NIH grant R01DA037349 . Jinbo Bi was also supported by NSF grants IIS 1407205 and IIS 1447711 .
6 . REFERENCES [ 1 ] S . Armeli , T . S . Conner , J . Cullum , and H . Tennen . A longitudinal analysis of drinking motives moderating the negative affect drinking association among college students . Psychology of Addictive Behaviors , 24(1):38–47 , 2010 .
[ 2 ] A . Arnold , Y . Liu , and N . Abe . Temporal causal modeling with graphical granger methods . In Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 66–75 , New York , NY , USA , 2007 . ACM .
[ 3 ] A . Beck and M . Teboulle . A fast iterative shrinkage thresholding algorithm for linear inverse problems . SIAM Journal on Imaging Sciences , 2(1):183–202 , 2009 .
[ 4 ] J . Bi , J . Sun , Y . Wu , H . Tennen , and S . Armeli . A machine learning approach to college drinking prediction and risk factor identification . ACM Trans . Intell . Syst . Technol . , 4(4):72:1–72:24 , Oct . 2013 . [ 5 ] C . D . Brown and H . T . Davis . Receiver operating characteristics curves and related decision measures : A tutorial . Chemometrics and Intelligent Laboratory Systems , 80(1):24–38 , 2006 .
[ 6 ] P . Diggle , P . Heagerty , K Y Liang , and S . Zeger . Analysis of Longitudinal Data . Oxford University Press , 2002 .
[ 7 ] J . H . Fowler and N . A . Christakis . Dynamic spread of happiness in a large social network : Longitudinal analysis over 20 years in the framingham heart study editorial comment . Journal of Urology , 181(5):2258–2259 , 2009 .
[ 8 ] W . J . Fu . Penalized estimating equations . Biometrics ,
59(1):pp . 126–132 , 2003 .
[ 9 ] P . Gong , J . Ye , and C . Zhang . Robust multi task feature learning . In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 895–903 , New York , NY , USA , 2012 . ACM .
[ 10 ] C . W . Granger . Testing for causality : a personal viewpoint . Journal of Economic Dynamics and Control , 2:329–352 , 1980 .
[ 11 ] N . M . Laird and J . H . Ware . Random effects models for longitudinal data . Biometrics , 38(4):963–974 , 1982 .
[ 12 ] K . Y . Liang and S . L . Zeger . Longitudinal data analysis using generalized linear models . Biometrika , 73(1):13–22 , 1986 .
[ 13 ] A . Lozano , N . Abe , Y . Liu , and S . Rosset . Grouped graphical granger modeling methods for temporal causal modeling . Proceedings of the 15th ACM International Conference on Knowledge Discovery and Data Mining , pages 577–585 , 2009 .
[ 14 ] P . McCullagh and J . A . Nelder . Generalized linear models ( Second edition ) . London : Chapman & Hall , 1989 .
[ 15 ] C . McCulloch and S . Searle . Generalized , Linear , and
Mixed Models . Wiley , New York , NY , USA , 2001 .
[ 16 ] U . Olsson . Generalized linear models , volume 18 . 2002 . [ 17 ] M . R . Osborne , B . Presnell , and B . A . Turlach . On the lasso and its dual . Journal of Computational and Graphical statistics , 9(2):319–337 , 2000 .
[ 18 ] R . J . Sela and J . S . Simonoff . Re em trees : a data mining approach for longitudinal and clustered data . Machine Learning , 86(2):169–207 , 2012 .
[ 19 ] T . A . Severini . Elements of Distribution Theory , volume 17 . Cambridge University Press , 2005 .
[ 20 ] C . A . Stappenbeck and K . Fromme . A longitudinal investigation of heavy drinking and physical dating violence in men and women . Addict Behav , 35(5):479–85 , 2010 .
[ 21 ] L . Wang , J . H . Zhou , and A . N . Qu . Penalized generalized estimating equations for high dimensional longitudinal data analysis . Biometrics , 68(2):353–360 , 2012 .
[ 22 ] Y . Zhang and D Y Yeung . Multi task learning using generalized t process . In Proceedings of the 13th International Conference on Artificial Intelligence and Statistics , 2010 .
[ 23 ] Y . Zhang , D Y Yeung , and Q . Xu . Probabilistic multi task feature selection . In Advances in Neural Information Processing Systems , pages 2559–2567 , 2010 .
1354
