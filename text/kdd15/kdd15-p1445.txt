Panther : Fast Top k Similarity Search on Large Networks
Jing Zhang† , Jie Tang†♯ , Cong Ma† , Hanghang Tong‡ , Yu Jing† , and Juanzi Li†
†Department of Computer Science and Technology , Tsinghua University
♯Tsinghua National Laboratory for Information Science and Technology ( TNList )
‡School of Computing , Informatics , and Decision Systems Engineering , ASU
{zhangjing12 , ma c11}@mailstsinghuaeducn , {jietang , yujing5b5d,lijuanzi}@tsinghuaeducn , hanghangtong@asuedu
ABSTRACT Estimating similarity between vertices is a fundamental issue in network analysis across various domains , such as social networks and biological networks . Methods based on common neighbors and structural contexts have received much attention . However , both categories of methods are difficult to scale up to handle large networks ( with billions of nodes ) . In this paper , we propose a sampling method that provably and accurately estimates the similarity between vertices . The algorithm is based on a novel idea of random path . Specifically , given a network , we perform R random walks , each starting from a randomly picked vertex and walking T steps . Theoretically , the algorithm guarantees that the sampling size R = O(2ε−2 log2 T ) depends on the error bound ε , the confidence level ( 1 − δ ) , and the path length T of each random walk . We perform extensive empirical study on a Tencent microblogging network of 1,000,000,000 edges . We show that our algorithm can return top k similar vertices for any vertex in a network 300× faster than the state of the art methods . We also use two applications—identity resolution and structural hole spanner finding—to evaluate the accuracy of the estimated similarities . Our results demonstrate that the proposed algorithm achieves clearly better performance than several alternative methods .
Categories and Subject Descriptors H28 [ Database applications ] : Data Mining ; J.4 [ Social and Behavioral Sciences ] : Miscellaneous ; H4m [ Information Systems Applications ] : Miscellaneous
General Terms Algorithms , Experimentation
Keywords Vertex similarity ; Social network ; Random path
1 .
INTRODUCTION
Estimating vertex similarity is a fundamental issue in network analysis and also the cornerstone of many data mining algorithms such as clustering , graph matching , and object retrieval . The problem is also referred to as structural equivalence in previous work [ 24 ] , and has been extensively studied in physics , mathematics , and computer science . In general , there are two basic principles to quantify similarity between vertices . The first principle is that two vertices are considered structurally equivalent if they have many common neighbors in a network . The second principle is that two vertices are considered structurally equivalent if they play the same structural role—this can be further quantified by degree , closeness centrality , betweenness , and other network centrality metrics [ 9 ] . Quite a few similarity metrics have been developed based on the first principle , eg , the Jaccard index [ 16 ] and Cosine similarity [ 2 ] . However , they estimate the similarity in a local fashion . Though some work such as SimRank [ 17 ] , VertexSim [ 23 ] , and RoleSim [ 18 ] , use the entire network to compute similarity , they are essentially based on the transitivity of similarity in the network . There are also a few studies that follow the second principle . For example , Henderson et al . [ 13 ] proposed a feature based method , named ReFeX , to calculate vertex similarity by defining a vector of features for each vertex .
Despite much research on this topic , the problem remains largely unsolved . The first challenge is how to design a unified method to accommodate both principles . This is important , as in many applications , we do not know which principle to follow . The other challenge is the efficiency issue . Most existing methods have a high computation cost . SimRank results in a complexity of O(I|V |2 ¯d2 ) , where |V | is the number of vertices in a network ; ¯d is the average degree of all vertices ; I is the number of iterations to perform the SimRank algorithm . It is clearly infeasible to apply SimRank to large scale networks . For example , in our experiments , when dealing with a network with 500,000 edges , even the fast ( top k ) version of SimRank [ 22 ] requires more than five days to complete the computation for all vertices ( as shown in Figure 1(b) ) .
Thus , our goal in this work is to design a similarity method that is flexible enough to incorporate different structural patterns ( features ) into the similarity estimation and to quickly estimate vertex similarity in very large networks .
We propose a sampling based method , referred to as Panther , that provably and quickly estimates the similarity between vertices . The algorithm is based on a novel idea of random path . Specifically , given a network , we perform R random walks , each starting from a randomly picked vertex and walking T steps . The idea behind this is that two vertices have a high similarity if they frequently appear on the same paths . We provide theoretical proofs for the error bound and confidence of the proposed algorithm . Theoretically , we obtain that the sample size , R = c δ ) , only depends on the path length T of each random walk , for a given error bound ε and confidence level 1 − δ . To capture the informa
2 +1+ln 1
ε2 ( log2,T
1445 ( a ) Top k similarity search
( b ) Efficiency performance
( c ) Application : identity resolution
Figure 1 : Example of top k similarity search across networks and performance comparison . ( a ) Top k similarity search across two disconnected networks ; ( b ) Efficiency comparison of Panther and several comparison methods on a Tencent subnetwork of 443,070 vertices and 5,000,000 edges ; and ( c ) Accuracy performance when applying Panther++ to identity resolution [ 11 ] , an important application in social network . Please refer to § 4 for definitions of all the comparison methods in ( b ) and ( c ) . tion of structural patterns , we extend the proposed algorithm by augmenting each vertex with a vector of structure based features . The resultant algorithm is referred to as Panther++ . Panther++ is not only able to estimate similarity between vertices in a connected network , but also capable of estimating similarity between vertices from disconnected networks . Figure 1(a ) shows an example of topk similarity search across two disconnected networks , where v4 , v6 and v5 are top 3 similar vertices to v0 .
We evaluate the efficiency of the methods on a microblogging network from Tencent.1 Figure 1(b ) shows the efficiency comparison of Panther , Panther++ , and several other methods . Clearly , our methods are much faster than the comparison methods .
Panther++ achieves a 300× speed up over the fastest comparison method on a Tencent subnetwork of 443,070 vertices and 5,000,000 edges . Our methods are also scalable . Panther is able to return top k similar vertices for all vertices in a network with 51,640,620 vertices and 1,000,000,000 edges . On average , it only need 0.0001 second to perform top k search for each vertex .
We also evaluate the estimation capability of Panther++ . Specifically , we use identity resolution and top k structural hole spanner finding , two important applications in social networks , to evaluate the accuracy of the estimated similarities . Figure 1(c ) shows the accuracy performance of Panther++ and several alternative methods for identity resolution . Panther++ achieves clearly better performance than several alternative methods . All codes and datasets used in this paper are publicly available.2
Organization Section 2 formulates the problem . In Section 3 , we detail the proposed methods for top k similarity search , and provide theoretical analysis . Section 4 presents experimental results to validate the efficiency and effectiveness of our methods . Section 5 reviews the related work . Finally , Section 6 concludes the paper .
2 . PROBLEM FORMULATION
We first provide necessary definitions and then formally formu late the problem .
Definition 1 . Undirected Weighted Network .
Let G = ( V , E , W ) denotes a network , where V is a set of |V | vertices and E ⊂ V × V is a set of |E| edges between vertices . We use vi ∈ V to represent a vertex and eij ∈ E to represent an edge between vertices vi and vj . Let W be a weight matrix , with each element wij ∈ W representing the weight associated with edge eij . 1http://tqqcom 2http://aminer.org/Panther
We use N ( vi ) to indicate the set of neighboring vertices of vertex vi . We leave the study of directed networks to future work . Our purpose here is to estimate similarity between two vertices , eg , vi and vj . We focus on finding top k similar vertices . Precisely , the problem can be defined as , given a network G = ( V , E , W ) and a query vertex v ∈ V , how to find a set Xv,k of k vertices that have the highest similarities to vertex v , where k is a positive integer .
A straightforward method to address the top k similarity search problem is to first calculate the similarity s(vi , vj ) between vertices vi and vj using metrics such as the Jaccard index and SimRank , and then select a set Xv,k of k vertices that have the highest similarities to each vertex v . However it is in general difficult to scale up to large networks . One important idea is to obtain an approximate set X ∗ v,k for each vertex . From the accuracy perspective , we aim to minimize the difference between X ∗ v,k and Xv,k . Formally , we can define the problem studied in this work as follows .
Problem 1 . Top k similarity search .
Given an undirected weighted network G = ( V , E , W ) , a similarity metric s(. ) , and a positive integer k , any vertex v ∈ V , how to quickly and approximately retrieve the top k similar vertices of v ? How to guarantee that the difference between the two sets X ∗ v,k and Xv,k is less than a threshold ε ∈ ( 0 , 1 ) , ie ,
Diff(X ∗ v,k , Xv,k ) ≤ ε with a probability of at least 1 − δ .
The difference between X ∗ v,k and Xv,k can be also viewed as the error bound of the approximation . In the following section , we will propose a sampling based method to approximate the top k vertex similarity . We will explain in details how the method can guarantee the error bound and how it is able to efficiently achieve the goal .
3 . PANTHER : FAST TOP K SIMILARITY
SEARCH USING PATH SAMPLING
We begin with considering some baseline solutions and then propose our path sampling approach . A simple approach to the problem is to consider the number of common neighbors of vi and vj . If we use the Jaccard index [ 16 ] , the similarity can be defined as
SJA(vi , vj ) =
|N ( vi ) ∩ N ( vj)| |N ( vi ) ∪ N ( vj)|
.
This method only considers local information and does not allow vertices to be similar if they do not share neighbors .
To leverage the structural information , one can consider algorithms like SimRank [ 17 ] . SimRank estimates vertex similarity by
1446 iteratively propagating vertex similarity to neighbors until convergence ( no vertex similarity changes ) , ie ,
SSR(vi , vj ) =
C
|N ( vi)||N ( vj)| Xvl∈N ( vi ) Xvm∈N ( vj ) s(vl , vm ) , where C is a constant between 0 and 1 .
SimRank similarity depends on the whole network and allows vertices to be similar without sharing neighbors . The problem with SimRank is its high computational complexity : O(I|V |2 ¯d2 ) , which makes it infeasible to scale up to large networks . Though quite a few studies have been conducted recently [ 21 , 22 ] , the problem is still largely unsolved .
We propose a sampling based method to estimate the top k similar vertices . In statistics , sampling is a widely used technique to estimate a target distribution [ 35 ] . Unlike traditional sampling methods , we propose a random path sampling method , named Panther . Given a network G = ( V , E , W ) , Panther randomly generates R paths with length T . Then the similarity estimation between two vertices is cast as estimating how likely it is that two vertices appear on a same path . Theoretically we prove that given an error bound , ε , and a confidence level , 1 − δ , the sample size R is independent of the network size . Experimentally , we demonstrate that the errorbound is dependent on the number of edges of the network .
3.1 Random Path Sampling
The basic idea of the method is that two vertices are similar if they frequently appear on the same paths . The principle is similar to that in Katz [ 19 ] .
Path Similarity . To begin with , we introduce how to estimate vertex similarity based on T paths . A T path is defined as a sequence of vertices p = ( v1 , · · · , vT +1 ) , which consists of T + 1 vertices and T edges.3 Let Π denotes all the T paths in G . Let w(p ) be the weight of a path p . The weight can be defined in different ways . Given this , the path similarity between vi and vj is defined as :
SRP ( vi , vj ) = Pp∈Pvi ,vj w(p )
Pp∈Π w(p )
,
( 1 ) where Pvi,vj is a subset of Π that contain both vi and vj .
Estimating Path Similarity with Random Sampling . To calculate the denominator in Eq ( 1 ) , we need to enumerate all T paths in G . However , the time complexity is exponentially proportional to the path length T , and thus is inefficient when T increases . Therefore , we propose a sampling based method to estimate the path similarity . The key idea is that we randomly sample R paths from the network and recalculate Eq ( 1 ) based on the sampled paths .
SRP ( vi , vj ) = Pp∈Pvi ,vj w(p )
Pp∈P w(p )
,
( 2 ) where P is the set of sampled paths .
To generate a path , we randomly select a vertex in G as the starting point , and then conduct random walks of T steps from v using tij as the transition probability from vertex vi to vj . tij =
,
( 3 ) wij
Pvk∈N ( vi ) wik where wij is the weight between vi and vj . In a unweighted network , the transition probability can be simplified as 1/|N ( vi)| .
3Vertices in the same path are not necessary to be distinct .
Figure 2 : Illustration of random path sampling .
Based on the random walk theory [ 7 ] , we define w(p ) as
T w(p ) = tij .
Yi=1,j=i+1
The path weight also represents the probability that a path p is sampled from Π ; thus , w(p ) in Eq ( 2 ) is absorbed , and we can rewrite the equation as follows :
SRP ( vi , vj ) =
|Pvi,vj |
R
.
( 4 )
Algorithm 3 summarizes the process for generating the R random paths . To calculate Eq ( 4 ) , the time complexity is O(RT ) , because it has to enumerate all R paths . To improve the efficiency , we build an inverted index of vertex to path [ 2 ] . Using the index , we can retrieve all paths that contain a specific vertex v with a complexity of O(1 ) . Then Eq ( 4 ) can be calculated with a complexity of O( ¯RT ) , where ¯R is the average number of paths that contain a vertex and ¯R is proportional to the average degree ¯d . Figure 2 illustrates the process of random path sampling . Details of the algorithm are presented in Algorithm 1 , where lines 1 5 are processing , and line 6 is top k similarity searching for a vertex .
3.2 Theoretical Analysis
We give theoretical analysis for the random path sampling algorithm . In general , the path similarity can be viewed as a probability measure defined over all paths Π . Thus we can adopt the results from Vapnik Chernovenkis ( VC ) learning theory [ 35 ] to analyze the proposed sampling based algorithm . To begin with , we will introduce some basic definitions and fundamental results from Vapnik Chernovenkis theory , and then demonstrate how to utilize these concepts and results to analyze our method .
Preliminaries . Let ( D , R ) be a range space , where D denotes a domain , and R is a range set on D . For any set B ⊆ D , PR(B ) = {B ∩ A : A ∈ R} is the projection of R on B . If PR(B ) = 2B , where 2B is the powerset of B , we say that the set B is shattered by R . The following definitions and theorem derive from [ 28 ] .
Definition 2 . The Vapnik Chervonenkis ( VC ) dimension of R , denoted as V C(R ) , is the maximum cardinality of a subset of D that can be shattered by R .
Let S = {x1 , · · · , xn} be a set of iid random variables sampled according to a distribution φ over the domain D . For a set A ⊆ D , let φ(A ) be the probability that an element sampled from φ belongs to A , and let the empirical estimation of φ(A ) on S be
φS(A ) =
1 n n
Xi=1
1A(xi ) , where 1A is the indicator function with the value of 1A(x ) equals 1 if x ∈ A , and 0 otherwise .
1447 The question of interest is that how well we can estimate φ(A ) using its unbiased estimator , the empirical estimation φS(A ) . We first give the goodness of approximation in the following definition .
Definition 3 . Let R be a range set on D , and φ be a probability distribution defined on D . For ε ∈ ( 0 , 1 ) , an ε approximation to ( R , φ ) is a set S of elements in D such that supA∈R|φ(A ) − φS(A)| ≤ ε .
One important result of VC theory is that if we can bound the V C dimension of R , it is possible to build an ε approximation by randomly sampling points from the domain according to the distribution φ . This is summarized in the following theorem .
Theorem 1 . Let R be a range set on a domain D , with V C(R ) ≤ d , and let φ be a distribution on D . Given ε , δ ∈ ( 0 , 1 ) , let S be a set of |S| points sampled from D according to φ , with
|S| = c ε2 ( d + ln
1 δ
) , where c is a universal positive constant . approximation to ( R , φ ) with probability of at least 1 − δ .
Then S is a ε
In our setting , we set the domain to be Π— Range Set of Path . the set of all paths with length T in the graph G . Accordingly , we define the range set RG on domain Π to be
RG = {Pvi,vj : vi , vj ∈ V } .
It is a valid range set , since it is the collection of subsets Pvi,vj of domain Π . We first show an upper bound of the VC dimension of RG in Lemma 1 . The proof is inspired by Riondato and Kornaropoulos [ 28 ] .
PROOF . We prove the lemma by contradiction .
Lemma 1 . V C(RG ) ≤ log2,T V C(RG ) = l and l > log2,T
2 + 1 2 + 1 . By the definition of VC dimension , there is a set Q ⊆ Π of size l that can be shattered by RG . That is , we have the following statement :
Assume
∀Si ⊆ Q , ∃Pi ∈ RG , st Pi ∩ Q = Si , where Pi is the i th range . Since each subset Si ⊆ Q is different from the other subsets , the corresponding range Pi that making Pi∩ Q = Si is also different from the other ranges . Moreover , the set Q is shattered by RG if and only if {Pi ∩ Q : Pi ∈ R} = 2Q . Thus ∀p ∈ Q , there are 2l−1 non empty distinct subsets S1 , · · · , S2l−1 of Q containing the path p . So there are also 2l−1 distinct ranges in RG that contain the path p , ie
|{Pi|p ∈ Pi and Pi ∈ RG}| = 2l−1 .
In addition , according to the definition of range set , RG = {Pvi,vj : vi , vj ∈ V } , a path belongs to the ranges corresponding to any pair of vertices in path p , ie , to the pairwise combinations of the vertices in p . This means the number of ranges in RG that p belongs to is equal to the combinatorial number,T 2 , ie , 2! . |{Pi|p ∈ Pi and Pi ∈ RG}| = T
On the other hand , from our preliminary assumption , we have l > log2,T
2 + 1 , which is equivalent to,T |{Pi|p ∈ Pi and Pi ∈ RG}| = T
2 < 2l−1 . Thus , 2! < 2l−1 .
Algorithm 1 : Panther Input : A network G = ( V , E , W ) , path length T , parameters
ε , c , δ , a vertex v , and k .
Output : top k similar vertices with regard to v . Calculate sample size R = c GenerateRandomPath(G , R ) ; foreach pn ∈ Pv do
ε2 ( log2,T
2 + 1 + ln 1
δ ) ; foreach Unique vj ∈ pn do
SRP ( v , vj)+ = 1
R ;
Retrieve top k similar vertices according to SRP ( v , vj ) .
Algorithm 2 : Panther++ Input : A network G = ( V , E , W ) , path length T , parameters
ε , c , δ , vector dimension D , a vertex v , and k .
Output : top k similar vertices with regard to v . Calculate sample size R = c GenerateRandomPath(G , R ) ; foreach vi ∈ V do
ε2 ( log2,T
2 + 1 + ln 1
δ ) ; foreach pn ∈ Pvi do foreach Unique vj ∈ pn do
SRP ( vi , vj)+ = 1
R ;
Construct a vector θ(vi ) by taking the largest D values from {SRP ( vi , vj ) : vj ∈ pn and pn ∈ Pvi } ;
Build a kd tree index based on the Euclidean distance between any vectors θ(vi ) and θ(vj ) ; Query the top k similar vertices from the index for v .
1
2
3
4
5
6
1
2
3
4
5
6
7
8
9
Hence , we reach a contradiction : it is impossible to have 2l−1 distinct ranges Pi ∈ RG containing p . Since there is a one to one correspondence between Si and Pi , we get that it is also impossible to have 2l−1 distinct subset Si ⊆ Q containing p . Therefore , we prove that Q cannot be shattered by RG and V C(RG ) ≤ log2,T
2 + 1 .
Sample Size Guarantee . We now provide theoretical guarantee for the number of sampled paths . How many random paths do we need to achieve an error bound ε with probability 1 − δ ? We define a probability distribution on the domain Π . ∀p ∈ Π , we define w(p )
.
φ(p ) = prob(p ) =
Pp∈Π w(p )
We can see that the definition of SRP ( vi , vj ) in Eq ( 1 ) is equivalent to φ(Pvi,vj ) . This observation enables us to use a samplingbased method ( empirical average ) to estimate the original path similarity ( true probability measure ) .
Plugging the result of Lemma ( 1 ) into Theorem ( 1 ) , we obtain :
R = c
ε2 ( log2 T
2! + 1 + ln
1 δ
) .
That is , with at least R random paths , we can estimate the path similarity between any two vertices with the desired error bound and confidence level . The above equation also implies that the sample size R only depends on the path length T , given an error bound ε , and a confidence level 1 − δ .
3.3 Panther++
One limitation of Panther is that the similarities obtained by the algorithm have a bias to close neighbors , though in principle it con
1448 Algorithm 3 : GenerateRandomPath Input : A network G = ( V , E , W ) and sample size R . Output : Paths {pr}R Calculate transition probabilities between every pair of vertices according to Eq ( 3 ) ; Initialize r = 0 ; repeat r=1 and vertex to path index {Pvi }N i=1 .
Sample current vertex v = vi uniformly at random ; Add v into pr and add pr into the path set of v , ie , Pv ; repeat
Randomly sample a neighbor vj according to transition probabilities from v to its neighbors ; Set current vertex v = vj ; Add v into pr and add pr into Pv ;
1
2
3
4
5
6
7
8
9
10
11
12 until |pr| = T + 1 ; r+ = 1 ; until r = R ; siders the structural information . We therefore present an extension of the Panther algorithm . The idea is to augment each vertex with a feature vector . To construct the feature vector , we follow the intuition that the probability of a vertex linking to all other vertices is similar if their topology structures are similar [ 14 ] . We select the top D similarities calculated by Panther to represent the probability distribution . Specifically , for vertex vi in the network , we first calculate the similarity between vi and all the other vertices using Panther . Then we construct a feature vector for vi by taking the largest D similarity scores as feature values , ie ,
θ(vi ) = ( SRP ( vi , v(1) ) , SRP ( vi , v(2) ) , . . . , SRP ( vi , v(D)) ) , where SRP ( vi , v(d ) ) denotes the d th largest path similarity between vi and another vertex v(d ) .
Finally , the similarity between vi and vj is re calculated as the reciprocal Euclidean distance between their feature vectors :
SRP ++ ( vi , vj ) =
1 kθ(vi ) − θ(vj)k
.
Index of Feature Vectors Again , we use the indexing techniques to improve the algorithm efficiency . We build a memory based kdtree [ 36 ] index for feature vectors of all vertices . Then given a vertex , we can retrieve top k vertices in the kd tree with the least Euclidean distance to the query vertex efficiently . At a high level , a kd tree is a generalization of a binary search tree that stores points in D dimensional space . In level h of a kd tree , given a node v , the h%D th element in the vector of each node in its left subtree is less than the h%D th element in the vector of v , while the h%D th element of every node in the right subtree is no less than the h%Dth element of v . Figure 3 shows the data structure of the index built in Panther++ . Based on the index , we can query whether a given point is stored in the index very fast . Specifically , given a vertex v , if the root node is v , return the root node . If the first element of v is strictly less than the first element of the root node , look for v in the left subtree , then compare it to the second element of v . Otherwise , check the right subtree . It is worth noting that we can easily replace kd tree with any other index methods , such as r tree . The algorithms for calculating feature vectors of all vertices and the similarity between vertices are shown in Algorithm 2 , where lines 1 8 are preprocessing , and line 9 is top k similarity searching for a vertex .
Figure 3 : Data structure of the index built in Panther++ .
Table 1 : Time and space complexity for calculating top k similar vertices for all vertices in a network . I— number of iterations , ¯d—average degree , f —feature number , D — vector dimension , and T — path length .
Time Complexity
Space Complexity
O(I|V |2 ¯d2 ) O(|V |T ¯dT ) O(I|V |2 ¯d ) O(I|V |2 ¯d2 )
RoleSim [ 18 ] ReFex [ 13 ] O(|V | + I(f |E| + |V |f 2 ) )
O(RT c + |V | ¯dT )
Method
SimRank [ 17 ] TopSim [ 22 ] RWR [ 27 ]
Panther
Panther++
O(|V |2 )
O(|V | + |E| )
O(|V |2 ) O(|V |2 )
O(|V | + |E|f ) O(RT + |V | ¯d )
O(RT c + |V | ¯dT + |V |c ) O(RT + |V | ¯d + |V |D )
In our experiments , we empirically set Implementation Notes . the parameters as follows : c = 0.5 , δ = 0.1 , T = 5 , D = 50 and
ε = p1/|E| . The optimal values of T , D and ε are discussed in section 4 . We build the kd tree using the toolkit ANN.4
3.4 Complexity Analysis
In general , existing methods result in high complexities . For example , the time complexity of SimRank [ 17 ] , TopSim [ 22 ] , Random walk with restart ( RWR ) [ 27 ] , RoleSim [ 18 ] , and ReFex [ 13 ] is O(I|V |2 ¯d2 ) , O(|V |T ¯dT ) , O(I|V |2 ¯d ) , O(I|V |2 ¯d2 ) , and O(|V | + I(f |E| + |V |f 2) ) , respectively . Table 1 summarizes the time and space complexities of the different methods . For Panther , its time complexity includes two parts :
• Random path sampling : The time complexity of generating random paths is O(RT log ¯d ) , where log ¯d is for randomly sampling a neighbor and can be simplified as a small constant c . Hence , the time complexity is O(RT c ) .
• Top k similarity search : The time complexity of calculating top k similar vertices for all vertices is O(|V | ¯RT + |V | ¯M ) . The first part O(|V | ¯RT ) is the time complexity of calculating Eq ( 4 ) for all pairs of vertices , where ¯R is the average number of paths that contain a vertex and is proportional to the average degree ¯d . The second part O(|V | ¯M ) is the time complexity of searching top k similar vertices based on a heap structure , where ¯M represents the average number of co occurred vertices with a vertex and is proportional to ¯d . Hence , the time complexity is O(|V | ¯dT ) .
The space complexity for storing paths and vertex to path index is O(RT ) and O(|V | ¯d ) , respectively .
Panther++ requires additional computation to build the kd tree . The time complexity of building a kd tree is O(|V | log |V | ) and querying top k similar vertices for any vertex is O(|V | log |V | ) , where log |V | is small and can be viewed as a small constant c . Additional space ( with a complexity of O(|V |D ) ) is required to store |V | vectors with D dimension . 4http://wwwcsumdedu/~mount/ANN/
1449 4 . EXPERIMENTS
4.1 Experimental Setup
In this section , we conduct various experiments to evaluate the proposed methods for top k similarity search .
Datasets . We evaluate the proposed method on four different networks : Tencent , Twitter , Mobile , and co author .
Tencent [ 37 ] : The dataset is from Tencent Weibo,1 a popular Twitter like microblogging service in China , and consists of over 355,591,065 users and 5,958,853,072 “ following ” relationships . The weight associated with each edge is set as 1.0 uniformly . This is the largest network in our experiments . We mainly use it to evaluate the efficiency performance of our methods .
Twitter [ 15 ] : The dataset was crawled in the following way . We first selected the most popular user on Twitter , ie , “ Lady Gaga ” , and randomly selected 10,000 of her followers . We then collected all followers of these users . In the end , we obtained 113,044 users and 468,238 “ following ” relationships in total . The weight associated with each edge is also set as 1.0 uniformly . We use this dataset to evaluate the accuracy of Panther and Panther++ .
Mobile [ 6 ] : The dataset is from a mobile communication company , and consists of millions of call records . Each call record contains information about the sender , the receiver , the starting time , and the ending time . We build a network using call records within two weeks by treating each user as a vertex , and communication between users as an edge . The resultant network consists of 194,526 vertices and 206,934 edges . The weight associated with each edge is defined as the number of calls . We also use this dataset to evaluate the accuracy of the proposed methods .
Co author [ 33 ] : The dataset is from AMiner.org,5 and contains 2,092,356 papers . From the original citation data , we extracted a weighted co author graph from each of the following conferences from 2005 to 2013 : KDD , ICDM , SIGIR , CIKM , SIGMOD , ICDE , and ICML.6 The weight associated with each edge is the number of papers collaborated on by the two connected authors . We also use the dataset to evaluate the accuracy of the proposed methods .
Evaluation Aspects . methods , we consider the following performance measurements :
To quantitatively evaluate the proposed
Efficiency Performance : We apply our methods to the Tencent network to evaluate the computational time .
Accuracy Performance : We apply the proposed methods to recognize identical authors on different co author networks . We also compare our results to common neighbors and apply the methods to find top k structural hole spanners on the Twitter and Mobile networks .
Parameter Sensitivity Analysis : We analyze the sensitivity of different parameters in our methods : path length T , vector dimension D , and error bound ε .
Finally , we also use several case studies as anecdotal evidence to further demonstrate the effectiveness of the proposed method . All codes are implemented in C++ and compiled using GCC 482 with O3 flag . The experiments were conducted on a Ubuntu server with four Intel Xeon(R ) CPU E5 4650 ( 2.70GHz ) and 1T RAM .
Comparison methods . We compare with the following methods : RWR [ 27 ] : Starts from vi , iteratively walks to its neighbors with the probability proportional to their edge weights . At each step , it
5http://aminer.org/citation 6Numbers of vertices/edges of different conferences are : KDD : 2,867/7,637 , ICDM : 2,607/4,774 , SIGIR : 2,851/6,354 , CIKM : 3,548/7,076 , SIGMOD : 2,616/8,304 , ICDE : 2,559/6,668 . also has some probability to walk back to vi ( set as 01 ) The similarity between vi and vj is defined as the steady state probability that vi will finally reach at vj . We calculate RWR scores between all pairs and then search the top k similar vertices for each vertex . TopSim [ 22 ] : Extends SimRank [ 17 ] on one graph G to finding top k authoritative vertices on the product graph G × G efficiently . RoleSim [ 18 ] : Refines SimRank [ 17 ] by changing the average similarity of all neighbor pairs to all matched neighbor pairs . We calculate RoleSim scores between all pairs and then search the topk similar vertices for each vertex .
ReFeX [ 13 ] : Defines local , egonet , and recursive features to capture the structural characteristic . Local feature is the vertex degree . Egonet features include the number of within egonet edges and the number of out egonet edges . For weighted networks , they contain weighted versions of each feature . Recursive features are defined as the mean and sum value of each local or egonet feature among all neighbors of a vertex . In our experiments , we only extract recursive features once and construct a vector for each vertex by a total of 18 features . For fair comparison , to search top k similar vertices , we also build the same kd tree as that in our method .
The codes of TopSim , RoleSim , and ReFex are provided by the authors of the original papers . We tried to use the fast versions of TopSim and RoleSim mentioned in their paper .
4.2 Efficiency and Scalability Performance
In this subsection , we first fix k = 5 , and evaluate the efficiency and scalability performance of different comparison methods using the Tencent dataset . We evaluate the performance by randomly extracting different ( large and small ) versions of the Tencent networks . For TopSim and RoleSim , we only show the computational time for similarity search . For ReFex , Panther , and Panther++ , we also show the computational time used for preprocessing .
Table 2 lists statistics of the different Tencent sub networks and the efficiency performance of the comparison methods . Clearly , our methods ( both Panther and Panther++ ) are much faster than the comparison methods . For example , on the Tencent6 sub network , which consists of 443,070 vertices and 5,000,000 edges , Panther achieves a 390× speed up , compared to the fastest ( ReFeX ) of all the comparative methods .
Figure 4(a ) shows the speed up of Panther++ compared to ReFeX on different scales of sub networks . The speed up is moderate when the size of the network is small ( |E| ≤ 1 , 000 , 000 ) ; when continuing to increase the size of the network , the obtained speedup is even superlinear . We conducted a result comparison between ReFeX and Panther++ . The results of Panther++ are very similar to those of ReFex , though they decrease slightly when the size of the network is small . Figure 4(b ) shows the efficiency performance of Panther and Panther++ on Tencent5 by varying the values of k from 5 to 100 . We can see that , when k is much smaller than the number vertices in the network , the time costs of Panther and Panther++ are not very sensitive to k . The growth of time cost is slow when k gets larger . This is because k is only related to the time complexity of top k similarity search based on a heap structure . When k gets larger , the time complexity approximates to O( ¯M log ¯M ) from O( ¯M ) , where ¯M is the average number of co occurred vertices on the same paths . We can also see that the time cost is not very stable when k gets larger , because the paths are randomly generated , which results in different values of ¯M each time .
From Table 2 , we can also see that RWR , TopSim and RoleSim cannot complete top k similarity search for all vertices within a reasonable time when the number of edges increases to 500,000 . ReFeX can deal with larger networks , but also fails when the edge number increases to 10,000,000 . Our methods can scale up to han
1450 Table 2 : Efficiency performance ( CPU time ) of comparison methods on different sizes of the Tencent sub networks . The time includes all computational cost for processing and top k similarity search for all vertices . The time before “ + ” denotes the time used for processing and the time after “ + ” denotes that used for top k similarity search . “ — ” indicates that the corresponding algorithm cannot finish the computation within a reasonable time . Sub network |V| Tencent1 Tencent2 Tencent3 Tencent4 Tencent5 Tencent6 Tencent7 Tencent8 Tencent9 Tencent10 Tencent11
TopSim RoleSim ReFeX +28.58m +37.26s +11.20hr +30.94hr +>120hr — — — — — — —
RWR |E| +7.79hr 10,000 +>150hr 50,000 — 100,000 — 500,000 — 1,000,000 — 5,000,000 — 10,000,000 — 50,000,000 — 100,000,000 — 500,000,000 1,000,000,000 —
385s+007s +12.98m 2609s+040s 202m+057s +1.06hr 1718m+251s +>72 hr 3150m+329s — — 2415hr+855s >48hr — — — — — — — — —
Panther++ 099s+021s 245s+421s 530s+596s 2794s+2417s 4983s+2286s 401m+129m 860m+658m 160hr+217hr 5.61hr +6.47hr 32.90hr +47.34hr 98.15hr +120.01hr
6,523 25,844 48,837 169,209 230,103 443,070 702,049 2,767,344 5,355,507 26,033,969 51,640,620
Panther 007s+026s 028s+153s 0.58s+ 3.48s 819s+1608s 1531s+3063s 5091s+282m 221m+624m 1578m+136hr 44.09m +4.50hr 4.82hr +25.01hr 13.32hr +80.38hr including Degree , Clustering Coefficient , Closeness , Betweenness and Pagerank . In our methods , Panther is not applicable to this situation . We only evaluate Panther++ here . Additionally , we also show the performance of random guess .
Figure 5 presents the performance of different methods on the task of identity resolution across co author networks . We see that Panther++ performs the best on all three datasets . ReFex performs comparably well ; however , it is not very stable . In the SIGMODICDE case , it performs the same as Panther++ , while in the KDDICDM and SIGIR CIKM cases , it performs worse than Panther++ , when k ≤ 60 .
Approximating Common Neighbors . We evaluate how Panther can approximate the similarity based on common neighbors . The evaluation procedure is described as follows :
1 . For each vertex u in the seed set S , generate top k vertices TopA,k(u ) that are the most similar to u by the algorithm A .
2 . For each vertex v ∈ TopA,k(u ) , calculate g(u , v ) , where g is a coarse similarity measure defined as the ground truth .
Define fA,k =PuPv g(u , v ) .
3 . Similarly , let fR,k denotes the result of a random algorithm .
4 . Finally , we define the score for algorithm A as score(A , k ) = , which represents the improvement of algorithm fA,k−fR,k
|S|×k
A over a random based method .
Specifically , we define g(u , v ) to be the number of common neighbors between u and v on each dataset .
Figure 6 shows the performance of Panther evaluated on the ground truth of common neighbors in Twitter and Mobile networks . Some baselines such as RWR and RoleSim are ignored on the datasets , because they cannot complete top k similarity search for all vertices within a reasonable time . It can be seen that Panther performs better than any other methods on both the datasets . Panther++ and ReFex perform worst since they are not devised to address the similarity between near vertices . Our method Panther performs as good as TopSim , the top k version of SimRank , because they both based on the principle that two vertices are considered structurally equivalent if they have many common neighbors in a network . However , according to our previous analysis , TopSim performs much slower than Panther .
( a ) Speed up
( b ) Effect of k
Figure 4 : ( a ) Performance ratio is calculated by Score(Panther++ ) , where score is evaluated by the application of structural hole spanner finding ( see § 4.3 for details. ) ; Speed up is calculated Time(Panther++ ) ; ( b ) Effect of k on the efficiency performance by of Panther and Panther++ .
Time(ReFex )
Score(ReFex ) dle very large networks with more than 10,000,000 edges . On average , Panther only needs 0.0001 second to perform top k similarity search for each vertex in a large network .
4.3 Accuracy Performance It is difficult to find a ground truth to evalIdentity Resolution . uate the accuracy for similarity search . To quantitatively evaluate the accuracy of the proposed methods and compare with the other methods , we consider an application of identity resolution on the co author network . The idea is that we first use the authorship at different conferences to generate multiple co author networks . An author may have a corresponding vertex in each of the generated networks . We assume that the same authors in different networks of the same domain are similar to each other . We anonymize author names in all the networks . Thus given any two co author networks , for example KDD ICDM , we perform a top k search to find similar vertices from ICDM for each vertex in KDD by different methods . If the returned k similar vertices from ICDM by a method consists of the corresponding author of the query vertex from KDD , we say that the method hits a correct instance . A similar idea was also employed to evaluate similarity search in [ 11 ] . Please note that the search is performed across two disconnected networks . Thus , RWR , TopSim and RoleSim cannot be directly used for solving the task . ReFex calculates a vector for each vertex , and can be used here . Additionally , we also compare with several other methods
1451 ( a ) KDD ICDM
( b ) SIGIR CIKM
( c ) SIGMOD ICDE
Figure 5 : Performance of identity resolution across two coauthor networks with different comparison methods .
( a ) Twitter
( b ) Mobile
( a ) Twitter
( b ) Mobile
Figure 6 : Performance of approximating common neighbors on the Twitter and Mobile networks with different methods .
Figure 7 : Performance of mining structural hole spanners on the Twitter and Mobile networks with different methods .
Top k Structural Hole Spanner Finding . The other application we consider in this work is top k structural hole spanner finding . The theory of structural holes [ 5 ] suggests that , in social networks , individuals would benefit from filling the “ holes ” between people or groups that are otherwise disconnected . The problem of finding top k structural hole spanners was proposed in [ 25 ] , which also shows that 1 % of users who span structural holes control 25 % of the information diffusion ( retweeting ) in Twitter .
Structural hole spanners are not necessarily connected , but they share the same structural patterns such as local clustering coefficient and centrality . Thus , the idea here is to feed a few seed users to the proposed Panther++ , and use it to find other structural hole spanners . For evaluation , we use network constraint [ 5 ] to obtain the structural hole spanners in Twitter and Mobile , and use this as the ground truth . Then we apply different methods—Panther++ , ReFex , Panther , and TopSim—to retrieve top k similar users for each structural hole spanner . If an algorithm can find another structural hole spanner in the top k returned results , it makes a correct search . We define g(u , v ) = 1 , if both u and v are structural hole spanners , and g(u , v ) = 0 otherwise .
Figure 7 shows the performance of comparison methods for finding structural hole spanners in different networks . Panther++ achieves a consistently better performance than the comparison methods by varying the value of k . TopSim , the top k version of SimRank seems inapplicable to this task . This is reasonable , as the underlying principle of SimRank is to find vertices with more connections to the query vertex .
( a ) Twitter
( b ) Mobile
Figure 8 : Effect of path length T on the accuracy performance of Panther++ . length T as 2 , 5 , 10 , 20 , 50 and 100 . A too small T ( < 5 ) would result in inferior performance . On Twitter , when increasing its value up to 5 , it almost becomes stable . On Mobile , the situation is a bit complex , but in general T = 5 seems to be a good choice .
Figure 9 shows the accuracy Effect of Vector Dimension D . performance of Panther++ for mining structural hole spanners by varying the vector dimension D as 2 , 5 , 10 , 20 , 50 and 100 . Generally speaking , the performance gets better when D increases and it remains the same after D gets larger than 50 . This is reasonable , as Panther estimates the distribution of a vertex linking to the other vertices . Thus , the higher the vector dimension , the better the approximation . Once the dimension exceeds a threshold , the performance gets stable .
4.4 Parameter Sensitivity Analysis
We now discuss how different parameters influence the perfor mance of our methods .
Figure 8 shows the accuracy perforEffect of Path Length T . mance of Panther++ for mining structural holes by varying the path
Figure 10 shows the accuracy perEffect of Error Bound ε . formance of Panther and Panther++ on the Tencent networks with different scales by varying error bound ε from 0.06 to 00001 We evaluate how Panther can estimate the similarity by approximating common neighbors and evaluate how Panther++ can estimate the similarity by structural hole finding . We see that when the ratio
1452 baiesi , m corral , a paczuski , m bassler , k korniss , g kozma , b hengartner , n toroczkai , z frauenfelder , h
Barabasi gorman , s kulkarni , r golding , i shefi , o segev , r ayali , a makse , h bennaim , e stroud , d benjacob , e rozenfeld , a leyvraz , f vazquez , f song , c erez , k shochet , o marodi , m cohen , i havlin , s antal , t cohen , r almaas , e dovidio , f ergun , g czirok , a moukarzel , c benavraham , d krapivsky , p redner , s dezso , z macdonald , p darbydowman , k schwartz , n kovacs , b rodgers , g martinez , n demenezes , m williams , r mongru , d dobrin , r vicsek , t beg , q thurner , s penna , t dunne , j kim , j somera , a berlow , e ravasz , e wuchty , s oltvai , z farkas , i ye , n liu , z gregoire , g lai , y hoppensteadt , f dasgupta , p demoura , a nishikawa , t grebogi , c chate , h rudzick , o motter , a ilmoniemi , r lounasmaa , o timmermann , l kujala , j hari , r hamalainen , m knuutila , j salmelin , r schnitzler , a weule , m pikovsky , a gross , j freund , h tass , p heagy , j barahona , m carroll , t johnson , g digarbo , a allaria , e zhou , c meucci , r volkmann , j rosenblum , m kurths , j pecora , l fink , k schafer , c osipov , g arecchi , f valladares , d zaks , m abel , h park , e maza , d vallone , a pelaez , a
Kahng derenyi , i yook , s schubert , a neda , z tu , y podani , j szathmary , e tombor , b mason , s tadic , b nakarado , g caruso , f porta , s usai , l fortuna , l bucolo , m cosenza , s pluchino , a jeong,h albert , r albert , i kinney , r rapisarda , a crucitti , p stagni , c larosa , m frasca , m spata , a lee , d jung , s ghim , c kim , d park , y goh , k kim , s rho , k oh , e mancini , h bragard , j vannucchi , f mendoza , c hentschel , h chavez , m amann , a hwang , d lopezruiz , r
Boccaletti bianconi , g hong , h huss , m yoon , c park , h han , s kim , b choi , m tieri , p valensin , s marchiori , m remondini , d franceschi , c castellani , g fortunato , s yusong , t lingjiang , k muren , l vragovic , i perez , c cabrales , a guardiola , x louis , e vegaredondo , f giralt , f vazquezprada , m gomez , j floria , l pacheco , a moreno , y llas , m diazguilera , a gleiser , p danon , l arenas , a camacho , j turtschi , a liljeros , f aberg , y chung , j gonzales , m herrmann , c guimera , r gondran , b amaral , l edling , c holme , p capocci , a dearcangelis , l trusina , a herrmann , h sousa , a minnhagen , p hong , d roux , s mossa , s provero , p guichard , e scala , a stanley , h andrade , j colaiori , f petermannn , t bottaccio , m gomezgardenes , j echenique , p nekovee , m barthelemy , m moreira , a boguna , m rubi , m mantegna , rcaldarelli , g delosrios , p servedio , v pietronero , l montuori , m rosvall , m donetti , l battiston , s munoz , m delucia , m torres , j coetzee , f upfal , e sivakumar , d castri , m garlaschelli , d catanzaro , m garrido , p bak , p dickman , r barrat , a coccetti , f leicht , e marro , j sneppen , k vazquez , a vespignani , a stata , r weigt , m maghoul , f pastorsatorras , r bonanno , g lillo , f
Latora mel , b svoboda , k reigl , m sjostrom , p koulakov , a diambra , l jedynak , m aleksiejuk , a fronczak , a nelson , s itzkovitz , s song , s chklovskii , d montagne , r amengual , a hernandezgarcia , e sanmiguel , m zimmermann , m suchecki , k klemm , k eguiluz , v sigman , m cecchi , g payne , b grant , s baddeley , r baliki , m grant , a blackmore , c scannell , j apkarian , a chialvo , d martin , r sager , j haga , p hilgetag , c kamper , l oneill , m kaiser , m burns , g young , m bozkurt , a andras , p stephan , k csardi , g falchier , a vezoli , j sporns , o kotter , r knoblauch , k zwi , j sommer , f jouve , b kennedy , h imbert , m sthepan , k passingham , r rosentiehl , p edelman , g tononi , g mcintosh , a russell , d huber , m moss , f neiman , a wojtenek , w braun , h voigt , k wilkens , l pei , x
( a ) Twitter
( b ) Mobile
Newman
Figure 9 : Effect of vector dimension D on the accuracy performance of Panther++ . gulia , m dimitrova , d kalbfleisch , t vijayadamodar , g knight , j yang , m salaff , j judson , r giot , l garton , l srinivasan , m cagney , g qureshiemili , a johnston , m fields , s godwin , b haythornthwaite , c wellman , b rothberg , j uetz , p conover , d pochart , p lockshon , d narayan , v li , y mansfield , t arabie , p lorrain , f breiger , r nazer , n boorman , s white , h taylor , j green , d bonney , m zimmermanroger , h rothenberg , r muth , s potterat , j phillipsplummer , l trotter , r baldwin , j muth , j maldonadolong , t darrow , w zimmerman , h woodhouse , d klovdahl , a ghoshal , g loffredo , m simonsen , i eriksen , k zaliznyak , a martin , m forrest , s ancelmeyers , l stauffer,d araujo , a dafontouracosta , l sienkiewicz , j holyst , j maslov , s aharony , a fronczak , p costa , u bernardes , a meyerortmanns , h adler , j alava , m kertesz , j lahtinen , j kaski , k szabo , g chakraborti , a onnela , j jarisaramaki , j kanto , a levitt , r kashtan , n ayzenshtat , i sheffer , m milo , r shenorr , s ziv , g alon , u mangan , s bashkin , p mayo , a rosenberg , r leiber , s zaslaver , a surette , m tsalyuk , m sberro , h barkai , n friedlander , g ofersarig , y ihmels , j bergmann , s
Robert giles , c flake , g soffer , s lawrence , s leone , m raghavan , p kumar , r wiener , j rajagopalan , s tomkins , a pennock , d rigon , r glover , e flammini , a zecchina , r rodrigueziturbe , i maritan , a vilone , d giacometti , a rinaldo , a cieplak , m mitra , m holter , n castellano , c broder , a ramasco , j dorogovtsev , s kepler , t banavar , j fedroff , n parisi , d goltsev , a mendes , j kumar , s kleinberg , j hopcroft , j park , j smith , e mirollo , r callaway , d lusseau , d schrag , s strogatz , s sabel , c balthrop , j moore , c matthews , p watts , d clauset , a porter , m jin , e warmbrand , c girvan , m yeung , m sole , r gastner , m dodds , p mucha , p kalapala , v loreto , v samukhin , a janssen , c kohler , r montoya , j muhamad , r sanwalani , v radicchi , f cecconi , f gautrais , j buhl , j salazarciudad , i cancho , r ferrericancho , r valverde , s deneubourg , j garciafernandez , j theraulaz , g rothman , d kuntz , p defraysseix , h restrepo , j crick , f hunt , b hess , m ress , g glot , l rosa , e ott , e meester , r kreiman , g koch , c rohlf , t vanwiggeren , g kammen , d yang , j zhan , m liu , w zheng , z hu , g cerdeira , h deshazer , d roy , r breban , r fabiny , l laurent , g bornholdt , s hu , b yao , y zhang , y schuster , h niebur , e reichardt , j gao , z chen , s braun , t buzsaki , g wang , x lu , j thornburg , k rogister , f moller , m davidsen , j mielsch , l ebel , h li , x li , c morgenstern , b mayer , k frishman , d emili , a krogan , n jaakkola , t fraenkel , e bettenbrock , k stelling , j chrobak , j chen , g guldener , u yu , x rudd , s weil , b chen , d munsterkotter , m mannhaupt , g mokrejs , m gerstein , m snyder , m greenbaum , d mewes , h tornow , s greenblatt , j jansen , r chung , s kluger , y yu , h yoo , j young , r lee , t gordon , d gerber , g barjoseph , z rinaldi , n gilles , e klamt , s schuster , s pfeiffer , t koch , i moldenhauer , f dandekar , t henze , d geisler , c xu , j challet , d
Rinzel anderson , c hauert , c sigmund , k habib , m konig , p henriques , m lucena , l arfanakis , k meyerand , m zhang , f chatterjee , a selkovjr , e hally , j sander , l tyler , j mukherjee , g overbeek , r fonstein , m dasgupta , s houart , g gonze , d sreeram , p manna , s larsen , n selkov , e maltsev , n sen , p dsouza , m dupont , g pusch , g kyrpides , n leloup , j goldbeter , a igoshin , o koopman , j simon , c warren , c sokolov , i wilkinson , d xulvibrunet , r wu , f huberman , b lukose , r banerjee , k chakrabarti , b kaiser , d oster , g biswas , t jespersen , s blumen , a puniyani , a adamic , l adar , e keck , t clewley , r netoff , t white , j arno , s thompson , j crouch , b wasserman , s faust , k skvoretz , j lieberman , e nowak , m rowlee , d hehl , u mehring , c aertsen , a palm , g singer , w fries , p decarvalho , t deaguilar , s moritz , c turski , p medeirossoares , m haughton , v kubo , m diesmann , m gerstein , g engel , a gray , c delimaesilva , d cordes , d corso , g quigley , m yan , g schivanialves , m carew , j southgate , e brenner , s pattison , p willert , k may , r anderson , r lloyd , a gupta , s fried , i moll , c ojemann , g wang , b fu , z wang , j zhou , t dewilde , p xenarios , i baron , m schensul , j hufnagel , l radda , k marcotte , e yeates , t rice , d everett , m borgatti , s clair , s herrmann , j brockmann , d willinger , w chen , q vu , v chung , f bhan , a newman , d lynch , v jamin , s lu , l galas , d vanvreeswijk , c eisenberg , d salwinski , l weeks , m geisel , t carreras , b govindan , r shenker , s kopell , n sompolinsky , h foster , p dodel , s wolf , f dolrou , i timme , m poole , a tangmunarunkit , h aiello , w ermentrout , b buhl , e whittington , m traub , r crisanti , a golomb , d hansel , d quilichini , p gozlan , h krause , a frank , k chiba , t yoshida , m ito , t rzhetsky , a wolf , y levanquyen , m benari , y bernard , c ulanowicz , r hattori , m koonin , e karev , g berezovskaya , f baird , d gleiss , p fell , d stadler , p taylor , w ozawa , r wagner , a dobson , i sachtjen , m chang , h dewey , t borgers , c gomez , s esclapez , m mason , d sakaki , y berg , j frackowiak , r coull , j lassig , m friston , k frith , c buchel , c liddle , p criado , r flores , j garciadelamo , a bray , d alberts , b chang , c pello , j hernandezbermejo , b romance , m watson , j lewis , j roberts , k raff , m kruger , t dealbuquerque , m walkenstein , j billings , l ko , j belew , r trinath , t gardner , e flyvbjerg , h lourenc , g karp , p irish , w yoo , m changizi , m mccarty , c blanchard , p tsallis , c soares , d volchenkova , l dasilva , l volchenkov , d mariz , a ticos , c monti , m rosajr , e schwartz , i otsuka , k chern , j kawai , r menczer , f ruiz , m oeltermann , a logothetis , n bollt , e roberson , d pauls , j derrida , b zippelius , a pardo , w hwong , s augath , m pant , g srinivasan , p kree , r lima , g stilwell , d kinouchi , o risaugusman , s riley , m martinez , a demers , a larson , j greene , d krummenacker , m baker , w faulkner , r kang , d mokhtarzada , z rodriguezesteban , r bernard , h shelley , g killworth , p paley , s pellegrinitoole , a hauser , c davis , g greve , h cherniak , c evans , m
( a ) Panther
( b ) Panther++ ritort , f zheng , b alonso , f oosawa , c rodriguez , e grinvald , a campbell , s chammah , a gelatt , c shinomoto , s tsimring , l koput , k motwani , r herzel , h zanette , d konno , n huerta , r zheng , d yehia , a varela , f tsodyks , m rulkov , n powell , w brin , s aihara , k lagofernandez , l acebron , j spigler , r bonilla , l trimper , s jeandupreux , d lachaux , j kenet , t hui , p guevara , m martinerie , j arieli , a wang , d jayaprakash , c rapoport , a horvath , w vecchi , m sakaguchi , h abarbanel , h owensmith , j winograd , t sushchik , m white , d page , l savageau , m hiavacek , w sherrington , d kirkpatrick , s nakao , h kuramoto , y perezvicente , c wall , m terman , d solomonoff , r patzak , a mrowka , r morelli , l kuperman , m holste , d abramson , g miwa , h masuda , n corbacho , f siguenza , j paturi , r klyachko , v atay , f lai , p mazur , c ripeanu , m svennenfors , b raftery , a leibler , s bahar , s bourgine , p avery , l oki , b jung , p amblard , f rivest , r mcphee , r jia , l holmgren , c jones , j harwell , l guelzim , n goodman , m goldberg , d gammaitoni , l deffuant , g corman , s komlos , j bekessy , a stevens , c bchklovskii , d bekessy , p schikorski , t joy , m jost , j wende , a sano , m chan , c lozowski , a londei , a jankowski , s kesselman , c foster , i iamnitchi , a zilberter , y harkany , t hoff , p handcock , m hopfield , j murray , a hall , g kepes , f lockery , s terry , d marchesoni , f weisbuch , g bottani , s hall , d nichols , d hanggi , p neau , d bienfang , j gauthier , d leiserson , c cormen , t stein , c kuhn , t dooley , k
Figure 10 : Effect of error bound ε on the performance of Panther and Panther++ on different sizes of Tencent networks .
|E|
( 1/ε)2 ranges from 5 to 20 , scores of Panther are almost convergent on all the datasets . And when the ratio ( 1/ε)2 ranges from 0.2 to 5 , the scores of Panther++ are almost convergent on all the datasets . Thus we can reach the conclusion that the value of ( 1/ε)2 is almost linearly positively correlated with the number of edges in
|E| a network . Therefore we can empirically estimate ε = p1/|E| in our experiments .
4.5 Qualitative Case study
We apply Panther++ to a scientific network [ 12 , 26 ] to find researchers who play different roles in the network . It is interesting that Mark Newman and Vito Latora have similar structural patterns to that of Dr . Barabási . Some other researchers like Robert form a tight knit group with him . Panther++ successfully recognizes those researchers with similar structural positions .
5 . RELATED WORK
Early similarity measures , including bibliographical coupling [ 20 ] and co citation [ 31 ] are based on the assumption that two vertices are similar if they have many common neighbors . This category of methods cannot estimate similarity between vertices without common neighbors . Several measures have been proposed to address this problem . For example , Katz [ 19 ] counts two vertices as similar if there are more and shorter paths between them . Tsourakakis et al . [ 34 ] learn a low dimension vector for each vertex from the adjacent matrix and calculate similarities between the vectors . Jeh and Widom [ 17 ] propose a new algorithm , SimRank . The algorithm follows a basic recursive intuition that two nodes are similar if they are referenced by similar nodes . VertexSim [ 26 ] is an extension of SimRank . However , all the SimRank based methods share a common drawback : their computational complexities are too high . Further studies have been done to reduce the computational complexity of SimRank [ 21 , 22 ] . Fast random walk based graph similarity , such as in [ 10 , 30 ] , has also been studied recently . Sun et al . [ 32 ] measure similarities between vertices based on their
Figure 11 : Case study in a scientific co author network [ 26 ] . The authors in similar positions to that of Barabási are denoted in green , similar to that of Robert are in red , and similar to that of Rinzel are in blue . Others are in yellow . inter paths instantiated from different schemes defined in a heterogeneous information network . The setting is different from ours and the algorithm is not efficient .
Most aforementioned methods cannot handle similarity estimation across different networks . Blondel et al . [ 3 ] provide a HITSbased recursive method to measure similarity between vertices across two different graphs . RoleSim [ 18 ] can also calculate the similarity between disconnected vertices . Similar to SimRank , the computational complexity of the two methods is very high . Feature based methods can match vertices with similar structures . For example , Burt [ 4 ] counts the 36 kinds of triangles in one ’s ego network to represent a vertex ’s structural characteristic . In the same way , vertex centrality , closeness centrality , and betweenness centrality [ 8 ] of two different vertices can be compared , to produce a structural similarity measure . Aoyama et al . [ 1 ] present a fast method to estimate similarity search between objects , instead of vertices in networks . ReFex [ 13 , 12 ] defines basic features such as degree , the number of within/out egonet edges , and define the aggregated values of these features over neighbors as recursive features . The computational complexity of ReFex depends on the recursive times . More references about feature based similarity search in networks can be found in the survey [ 29 ] .
6 . CONCLUSION
In this paper , we propose a sampling method to quickly estimate top k similarity search in large networks . The algorithm is based on the idea of random path and an extended method is also presented to enhance the structural similarity when two vertices are completely disconnected . We provide theoretical proofs for the error bound and confidence of the proposed algorithm . We perform an extensive empirical study and show that our algorithm can obtain top k similar vertices for any vertex in a network approximately 300× faster than state of the art methods . We also use identity resolution and structural hole spanner finding , two impor
1453 tant applications in social networks , to evaluate the accuracy of the estimated similarities . Our experimental results demonstrate that the proposed algorithm achieves clearly better performance than several alternative methods .
Acknowledgements . The authors thank Pei Lee , Laks VS Lakshmanan , Jeffrey Xu Yu ; Ruoming Jin , Victor E . Lee , Hui Xiong ; Keith Henderson , Brian Gallagher , Lei Li , Leman Akoglu , Tina Eliassi Rad , Christos Faloutsos for sharing codes of the comparation methods . We thank Tina Eliassi Rad for sharing the datasets . The work is supported by the National High tech R&D Program ( No . 2014AA015103 ) , National Basic Research Program of China ( No . 2014CB340506 , No . 2012CB316006 ) , NSFC ( No . 61222212 ) , NSFC ANR ( No . 61261130588 ) , National Social Science Foundation of China ( No.13&ZD190 ) , the Tsinghua University Initiative Scientific Research Program ( 20121088096 ) , a research fund supported by Huawei Inc . , and Beijing key lab of networked multimedia .
7 . REFERENCES [ 1 ] K . Aoyama , K . Saito , H . Sawada , and N . Ueda . Fast approximate similarity search based on degree reduced neighborhood graphs . In KDD’11 , pages 1055–1063 , 2011 . [ 2 ] R . Baeza Yates , B . Ribeiro Neto , et al . Modern information retrieval , volume 463 . ACM press , 1999 .
[ 3 ] V . D . Blondel , A . Gajardo , M . Heymans , P . Senellart , and
P . Van Dooren . A measure of similarity between graph vertices : Applications to synonym extraction and web searching . SIAM review , 46(4):647–666 , 2004 .
[ 4 ] R . S . Burt . Detecting role equivalence . Social Networks ,
12(1):83–97 , 1990 .
[ 5 ] R . S . Burt . Structural holes : The social structure of competition . Harvard university press , 2009 .
[ 6 ] Y . Dong , Y . Yang , J . Tang , Y . Yang , and N . V . Chawla .
Inferring user demographics and social strategies in mobile social networks . In KDD’14 , pages 15–24 , 2014 .
[ 7 ] W . Feller . An introduction to probability theory and its applications , volume 2 . John Wiley & Sons , 2008 .
[ 8 ] L . C . Freeman . A set of measures of centrality based on betweenness . Sociometry , pages 35–41 , 1977 .
[ 9 ] L . C . Freeman . Centrality in social networks conceptual clarification . Social networks , 1(3):215–239 , 1979 .
[ 10 ] Y . Fujiwara , M . Nakatsuji , H . Shiokawa , T . Mishima , and
M . Onizuka . Efficient ad hoc search for personalized pagerank . In SIGMOD’13 , pages 445–456 , 2013 .
[ 11 ] S . Gilpin , T . Eliassi Rad , and I . Davidson . Guided learning for role discovery ( glrd ) : framework , algorithms , and applications . In KDD’13 , pages 113–121 , 2013 .
[ 12 ] K . Henderson , B . Gallagher , T . Eliassi Rad , H . Tong ,
S . Basu , L . Akoglu , D . Koutra , C . Faloutsos , and L . Li . Rolx : structural role extraction & mining in large graphs . In KDD’12 , pages 1231–1239 , 2012 .
[ 13 ] K . Henderson , B . Gallagher , L . Li , L . Akoglu ,
T . Eliassi Rad , H . Tong , and C . Faloutsos . It ’s who you know : graph mining using recursive structural features . In KDD’11 , pages 663–671 , 2011 .
[ 14 ] P . W . Holland and S . Leinhardt . An exponential family of probability distributions for directed graphs . Journal of the american Statistical association , 76(373):33–50 , 1981 .
[ 15 ] J . Hopcroft , T . Lou , and J . Tang . Who will follow you back ? reciprocal relationship prediction . In CIKM’11 , pages 1137–1146 , 2011 .
[ 16 ] P . Jaccard . Étude comparative de le distribution florale dans une portion de alpes et du jura . Bulletin de la Société Vaudoise des Sciences Naturelles , 37:547–579 , 1901 .
[ 17 ] G . Jeh and J . Widom . Simrank : a measure of structural context similarity . In KDD’02 , pages 538–543 , 2002 .
[ 18 ] R . Jin , V . E . Lee , and H . Hong . Axiomatic ranking of network role similarity . In KDD’11 , pages 922–930 , 2011 .
[ 19 ] L . Katz . A new status index derived from sociometric analysis . Psychometrika , 18(1):39–43 , 1953 .
[ 20 ] M . M . Kessler . Bibliographic coupling between scientific papers . American Documentation , 14(1):10–25 , 1963 . [ 21 ] M . Kusumoto , T . Maehara , and K i Kawarabayashi .
Scalable similarity search for simrank . In SIGMOD’14 , pages 325–336 , 2014 .
[ 22 ] P . Lee , L . V . Lakshmanan , and J . X . Yu . On top k structural similarity search . In ICDE’12 , pages 774–785 , 2012 .
[ 23 ] E . Leicht , P . Holme , and M . E . Newman . Vertex similarity in networks . Physical Review E , 73(2):026120 , 2006 .
[ 24 ] F . Lorrain and H . C . White . Structural equivalence of individuals in social networks . The Journal of mathematical sociology , 1(1):49–80 , 1971 .
[ 25 ] T . Lou and J . Tang . Mining structural hole spanners through information diffusion in social networks . In WWW’13 , pages 837–848 , 2013 .
[ 26 ] M . E . Newman . Finding community structure in networks using the eigenvectors of matrices . Physical review E , 74(3):036104 , 2006 .
[ 27 ] J Y Pan , H J Yang , C . Faloutsos , and P . Duygulu .
Automatic multimedia cross modal correlation discovery . In KDD’04 , pages 653–658 , 2004 .
[ 28 ] M . Riondato and E . M . Kornaropoulos . Fast approximation of betweenness centrality through sampling . In WSDM’14 , pages 413–422 , 2014 .
[ 29 ] R . A . Rossi and N . K . Ahmed . Role discovery in networks .
IEEE TKDE , 2015 .
[ 30 ] P . Sarkar and A . W . Moore . Fast nearest neighbor search in disk resident graphs . In KDD’10 , pages 513–522 , 2010 . [ 31 ] H . Small . Co citation in the scientific literature : A new measure of the relationship between two documents . Journal of the American Society for information Science , 24(4):265–269 , 1973 .
[ 32 ] Y . Sun , J . Han , X . Yan , P . S . Yu , and T . Wu . Pathsim : Meta path based top k similarity search in heterogeneous information networks . VLDB’11 , pages 992–1003 , 2011 .
[ 33 ] J . Tang , J . Zhang , L . Yao , J . Li , L . Zhang , and Z . Su .
Arnetminer : Extraction and mining of academic social networks . In KDD’08 , pages 990–998 , 2008 .
[ 34 ] C . E . Tsourakakis . Toward quantifying vertex similarity in networks . Internet Mathematics , 10(3 4):263–286 , 2014 .
[ 35 ] V . N . Vapnik and A . Y . Chervonenkis . On the uniform convergence of relative frequencies of events to their probabilities . Theory of Probability & Its Applications , 16(2):264–280 , 1971 .
[ 36 ] I . Wald and V . Havran . On building fast kd trees for ray tracing , and on doing that in o ( n log n ) . In Interactive Ray Tracing 2006 , IEEE Symposium on , pages 61–69 , 2006 .
[ 37 ] Y . Yang , J . Tang , C . W k Leung , Y . Sun , Q . Chen , J . Li , and
Q . Yang . Rain : Social role aware information diffusion . In AAAI’14 , 2014 .
1454
