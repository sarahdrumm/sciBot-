Gas Concentration Reconstruction for Coal Fired Boilers
Using Gaussian Process
Chao Yuan
Siemens Corporate Research
Princeton , United States chaoyuan@siemenscom
Matthias Behmann
Siemens Energy
Karlsruhe , Germany matthiasbehmann@siemenscom
Bernhard Meerbeck
Siemens Energy
Offenbach am Main , Germany bernhardmeerbeck@siemenscom
ABSTRACT The goal of combustion optimization of a coal fired boiler is to improve its operating efficiency while reducing emissions at the same time . Being able to take measurements for key combustion ingredients , such as O2 , CO , H2O is crucial for the feedback loop needed by this task . One state of the art laser technique , namely , Tunable Diode Laser Absorption Spectroscopy ( TDLAS ) is able to measure the average value of gas concentration along a laser beam path . A active research direction in TDLAS is how to reconstruct gas concentration images based on these path averages . However , in reality the number of such paths is usually very limited , leading to an extremely under constrained estimation problem . Another overlooked aspect of the problem is that how can we arrange paths such that the reconstructed image is more accurate ? We propose a Bayesian approach based on Gaussian process ( GP ) to address both image reconstruction and path arrangement problems , simultaneously . Specifically , we use the GP posterior mean as the reconstructed image , and average posterior pixel variance as our objective function to optimize the path arrangement . Our algorithms have been integrated in Siemens SPPA P3000 control system that provides real time combustion optimization of boilers around the world .
Categories and Subject Descriptors J.6 [ Computer Applications ] : COMPUTER AIDED ENGINEERING ; I45 [ Computing Methodologies ] : IMAGE PROCESSING AND COMPUTER VISION—Reconstruction
Keywords Gaussian process ; TDLAS ; combustion optimization
1 .
INTRODUCTION
The capability of reconstructing gas ( eg , of O2 , CO ) concentration images inside the combustion zone is very useful
Figure 1 : Illustration of gas concentration reconstruction . The left plot shows the geometry of an operating coal fired boiler . Our goal is to reconstruct 2D cross section gas concentration images ( bottom right ) . To achieve this , TDLAS paths are installed on the wall of a boiler . Each path reads the average gas value along the path ( top right ) . for visualizing , optimizing and monitoring the performance of a coal fired boiler . The technique of tunable diode laser absorption spectroscopy ( TDLAS ) has received increasing interests due to its fast responsive speed , high sensitivity and non invasiveness[7 ] . A single TDLAS setup consists of a laser transmitter sending laser beams over a path through the combustion region to a laser receiver . Each TDLAS path measures an average value of the gas concentrations along the path . Our goal is to reconstruct the 2D gas concentration image based on multiple path averages ( or projections ) , as illustrated in Fig 1 .
There are two challenges for this task . First , given the paths , how can we accurately reconstruct the image ? This concept is similar to that of computed tomography ( CT ) ( Chapter 3 in [ 9] ) . However , most widely used CT algorithms such as filtered back projection require a lot of projections ( multiple views and dense projections per view ) to achieve a good resolution . In contrast , only a very small number of paths are typically set up on a boiler ; for example , it is not uncommon that we only have five to 15 paths ( projections ) , which leads to an extremely under constrained problem . Second , how do we best arrange paths such that the reconstructed image is even more precise ? In reality ,
2247 there are some constraints to consider . For example , a path may not be installed at a location or a direction ( view ) that we desire because of certain restrictions or mounting difficulties of a boiler . For the first estimation problem , many previous methods have been proposed , however , few of them have tackled the case with only about ten paths that we study here [ 12 , 11 , 1 , 6 , 20 ] . In addition , to the best of our knowledge , we haven’t seen an existing approach addressing the second optimization problem .
In this paper , we present a Bayesian approach based on Gaussian process to tackle both estimation and optimization problems under the same framework . The 2D unknown image is modeled by a Gaussian process , a multivariate Gaussian distribution with pixel coordinates as its inputs . This naturally introduces long range smoothness constraints such that neighboring pixels have similar values . Given the path projections , the image has a posterior Gaussian distribution with a posterior mean and covariance . We use the mean as the reconstructed image because it is optimal in terms of mean squared error . The posterior covariance indicates the uncertainty of the image . We propose to use the trace of this covariance matrix , or the sum of posterior variances for all pixels , as the objective function of a path arrangement . By minimizing this function , we become more certain about our reconstruction and thus expect to get more accurate results . In addition , our objective function offers a fast and effective way to evaluate and compare existing path arrangements . Our algorithms have been integrated in Siemens SPPA P3000 control system for real time combustion optimization applications .
The rest of this paper is organized as follows . In Sect.2 , we review previous work . In Sect.3 , we define our reconstruction problem . The proposed model is described in Sect4 We present test results in Sect.5 and conclude this paper in Sect6
2 . RELATED WORK
Tomographic techniques such as algebraic reconstruction technique ( ART ) have been proposed to handle the issue of a small number of projections [ 9 , 20 , 12 ] . However , ART updates the estimate only using one path in each iteration , which usually leads to a slow convergence and “ salt andpepper ” noise [ 6 ] . Extensions such as simultaneous iterative reconstructive technique ( SIRT ) [ 9 ] , simultaneous algebraic reconstruction technique ( SART ) [ 9 ] and multiplicative algebraic reconstruction technique ( MART ) [ 6 ] can update estimation using all paths in each iteration . Although proven to find an image complying to path projections , these ARTbased approaches don’t offer a way to check if the reconstructed image is realistic or not .
Smoothness constraints among neighboring pixels are introduced as prior information to help addressing this underconstrained problem . Smoothness can be incorporated via smooth basis functions [ 15 , 3 ] . [ 15 , 3 ] also apply 1D smooth basis functions to multiple path averages under the same view . [ 1 ] correlates two pixels if they are both close to a path . However , such smoothness constraints are local and cannot capture long range correlation among pixels .
Longer range smoothness can be achieved via the Tikhonov regularization ( TR ) [ 6 ] . This algorithm explicitly enforces a local smoothness constraint : every pixel value should be similar to the average of its neighbors’ . Two pixels far apart are implicitly linked via all such local smoothness constraints
Figure 2 : Gas concentration reconstruction problem definition . Paths , available regions and region of interest ( ROI ) are denoted by blue lines , red lines and green boxes , respectively . The boiler cross section , as shown , has a width of 1 and a height of 1 . There are M = 5 paths . The image size is N = 10× 10 = 100 . between them . The TR method can be viewed as a special case of Gaussian random fields [ 22 ] , which assign weights to every pair of pixels in the image ( instead of only neighboring pixels as done in the TR ) . Gaussian process is widely used in computer vision for applications such as super resolution [ 18 , 17 ] , which motivates our previous work [ 21 ] . It has been revealed that both Gaussian random fields and Gaussian process model long range smoothness via the covariance matrix of a Gaussian distribution , but they do this differently . The former models the inverse of the covariance while the latter directly depicts the covariance [ 22 ] .
Finally , all previous gas concentration approaches assume a fixed path arrangement . The most widely used configurations involve multiple views , each with multiple parallel paths [ 12 , 11 , 1 , 6 , 20 ] . These approaches may not be feasible if there are mounting restrictions about where a path can or cannot be installed . In contrast , we present an optimization approach , taking these restrictions into consideration , to find the best path arrangement that can produce more accurate reconstruction results .
3 . PROBLEM DEFINITION
Our goal is to reconstruct an w × h gas concentration image v from M path averages ( projections ) , denoted by an M dimensional vector b . w and h are the width and height of the image , respectively . The projections b and image v have the following relation b = Av .
( 1 ) A is an M ×N projection matrix . Once the paths are configured , A becomes a constant matrix . Typically , we represent the image v as a N dimensional vector for easy algebraic manipulation , where N = w × h . To visualize the image , we then convert it into the matrix format . In the example shown in Fig 2 , we have w = h = 10 , M = 5 paths and we want to estimate the gas concentration at each of the N = 100 grid pixels . There are two tasks involved , reconstruction and path arrangement optimization .
00001102203304405606707808910000001102203304405606707808910012345Wall 1Wall 2Wall 3Wall 42248 3.1 Reconstruction of A are respectively defined by Am,+ = N A+,n =M
If the paths are already configured , how can we reconstruct the image ? We first introduce some terminology . The sum of the m th row and the sum of the n th column n=1 Am,n and m=1 Am,n . A m th pixel is termed as observed if there is at least one path crossing it or A+,n > 0 . Otherwise , it is unobserved .
We now describe how to determine a projection weight Am,n in the projection matrix A . One way is to treat each pixel as a small rectangle , and then compute the ratio of the length of the m th path intercepted by the n th pixel to the total length of the m th path in the domain of interest [ 21 , 6 ] . One drawback of this approach is that if a pixel doesn’t intersect with a path , it has no impact on the path average even if they are next to each other . We adopt a new strategy by treating each pixel as a point ( as in Fig 2 ) . We evenly place 1000 sample points along each path . For each sample point , we locate the closest four pixels ( vertices of a small rectangle ) and compute the bilinear weights of the four pixels regarding this sample point . Then the contribution of a pixel is the sum of its weights for all sample points . By doing this , we can get a smoother projection matrix because more pixels are involved . Finally , we normalize every row such that Am,+ = 1 , because path projection is a weighted average along the path .
Our reconstruction problem is essentially solving a linear equation ( 1 ) with both A and b known . If A is an invertible square matrix , where M = N , then we have v = A−1b as done by [ 11 ] . If M > N and A has full rank , based on linear least square we have v = ( AT A )
−1AT b .
( 2 )
However , our problem is very under constrained because of M N . In such a case , we have multiple solutions satisfying the same equation ( 1 ) .
Simultaneous algebraic reconstruction technique ( SART ) is one of the most widely used ART algorithms [ 9 ] . It has the following iterative procedure
M m=1 v(q+1 ) n
= v(q ) n +
λ
A+,n
Am,n bm − ( Av(q))m
Am,+
.
( 3 ) n v(q ) n denotes the current reconstructed image after the q th iteration . ( Av(q))m indicates the estimated m th projection from the current image . Note that in our problem Am,+ = 1 and can be omitted from ( 3 ) , but in general it has a non zero value . ( 3 ) can be understood as follows . The residual between the true projection bm and the estimated projection ( Av(q))m indicates in which direction v(q+1 ) should move from v(q ) n to reduce this residual . The final direction is determined by the weighted average of all M projections , each with a weight of Am,n normalized by A+,n . The magnitude of this movement is adjusted by a parameter λ . The SART algorithm is proven to converge to a solution of ( 1 ) if A+,n = 0 [ 8 ] . However , there is no guarantee whether the found solution , out of all possible solutions , is realistic or not . In addition , in our application , the path configuration can be arbitrary . It often happens that A+,n = 0 for some columns so the n th pixel is unobserved . In such cases , division by zero problem will happen and ( 3 ) will stop working .
Tikhonov regularization ( TR ) is another technique to regularize linear equations [ 6 ] . TR adds another set of equations Lv = 0 to enforce smoothness constraint . L is a N × N regularization matrix , where each row requires a pixel ’s value to be identical to the average of its neighbors . Av = b and Lv = 0 are treated similarly in the objective function of ( Av − b)T ( Av − b ) + λ(Lv)T ( Lv ) ( to be minimized ) . λ is a parameter . It can be proved that the solution of TR is v = ( AT A + λLT L )
−1AT b .
( 4 )
The only difference between ( 4 ) and ( 2 ) is due to the regularization term . 3.2 Path arrangement optimization
We previously assume that paths are already configured . How can we arrange paths such that we can get better reconstruction results . The boiler cross section is denoted by a rectangle . It has four walls with ID=1 , 2 , 3 , 4 as shown in Fig 2 . For some applications , users may only focus on certain region of interest ( ROI ) ( green boxes in Fig 2 ) . By default , ROI is the whole cross section .
Ideally , for every path , it can be mounted between any of these wall pairs . However , under certain circumstances , some regions on a particular wall are not available and thus cannot be used to install a path . The red lines in Fig 2 indicates available regions that can be used for installation . In other words , every end point of a path must be located within an available region .
In either case , we have a combinatorial optimization problem . Suppose that there are K available regions , leading to about of ( K − 1)K/2 region pairs . Then there are about ( (K − 1)K/2)M possible arrangements just for assigning region pairs to paths . This complexity has not included the efforts about where the end point of a path should be in a particular available region .
To the best of our knowledge , no prior work has addressed this path arrangement optimization problem . One possible solution is to randomly generate many path arrangements and evaluate each of them against a large number of tests to see which one produce the most accurate reconstruction results . However , due to the aforementioned complexity , it is prohibitive for this approach to find the best path arrangement especially for a relatively large M .
4 . MODEL DESCRIPTION 4.1 Reconstruction using Gaussian process
In our previous study [ 1 ] , we presented a Bayesian algorithm about how to reconstruct v from b . We model v as a multivariate Gaussian distribution
P ( v ) = N ( v|m , C ) ,
( 5 ) where m and C are the N dimensional mean vector and N ×N covariance matrix , respectively . Because v represents a 2D image , its distribution is also referred to as a Gaussian process ( GP ) [ 14 ] . We assume that this GP is homogeneous since we don’t have a priori knowledge about the differences between different pixels . Thus , the cross covariance Cn1,n2 between vi and vj in v , where 1 ≤ i , j ≤ N , is defined as
Ci,j = f exp(− ( xi − xj)2 + ( yi − yj)2 r2
) .
( 6 )
2249 ( xi , yi ) and ( xj , yj ) are the coordinates for pixels i and j , respectively . f and r are two parameters . ( 6 ) indicates that if neighboring pixels should have high correlation while far apart pixels should have low correlation . This global smoothness constraint aids us to solve our extremely underconstrained reconstruction problem .
We introduce noise to the projection model in ( 1 ) to make it probabilistic
P ( b|v ) = N ( b|Av , σ2I ) .
( 7 ) σ2 is the noise variance and I is a M × M identity matrix . The projections b can thus be modeled as another multivariate Gaussian distribution given the 2D image v and projection b , P ( v , b ) = P ( v)P ( b|v )
We can now write the joint probability between image v
P ( v , b ) = N (
Am
AC ACAT + σ2I
CAT
) .
( 8 )
From ( 8 ) , we can write the posterior distribution of v v b
| m
C
, given b
P ( v|b ) = N ( v|m,C ) ,
−1(b − Am ) + m ,
−1AC , where the posterior mean and covariance are m = CAT ( ACAT + σ2I ) C = C − CAT ( ACAT + σ2I ) mean m as the reconstructed image v = m . respectively .
In our previous work [ 21 ] , we propose to use the posterior
( 9 )
( 10 )
( 11 )
( 12 )
This is our solution to the reconstruction problem and is optimal in the sense of minimizing mean squared error . The complexity of calculating ( 10 ) is O(M N 2 ) ( assuming M < N ) . ( 10 ) can also be rewritten as
−1m ) .
−1 )
−1(AT b + σ2C v = ( AT A + σ2C
( 13 ) If we set m = 0 and let C−1 = LT L , ( 13 ) has a identical form to ( 4 ) , the solution of TR . The difference is that we model the covariance C directly while TR models the inverse of covariance by LT L . In practice , we dynamically set each element of m equally to the average of all M path projections .
We note that one prior approach also models the image as a Gaussian distribution [ 13 ] . However instead of using parametric covariance matrix as we do in ( 6 ) , they propose to estimate the covariance via images simulated by computational fluid dynamics ( CFD ) . This demands a large number of training images , which can be expensive to obtain . 4.2 Reconstruction uncertainty
We have assumed that the path arrangements are already given and thus A is known . In this section , we describe how to find the best path arrangements or to determine the projection matrix A that can produce more accurate reconstruction . 421 Approximating projection matrix We define the reconstruction uncertainty as the average posterior pixel variance
F ( Θ ) =
1 N trace(C − CAT ( ACAT + σ2I )
−1AC ) ,
( 14 ) which is proportional to the trace of the posterior covariance in ( 11 ) . Since posterior variance indicates the uncertainty of our prediction , minimizing such variance is expected to reduce uncertainty and thus improve our reconstruction result . Here Θ = {θ1 , θ2 , , θM} are path arrangement parameters for all paths and determine projection matrix A . Each θm = [ xm,1 ym,1 xm,2 ym,2]T is a column vector indicating the coordinates of two end points for the m th path . Note that because an end point is located on a wall so either x or y is a constant . Therefore , each θm only has two tunable parameters . If we have a ROI smaller than the whole cross section , we simply process the pixels within that ROI ( instead of applying the trace operator for the whole image ) . Using the posterior covariance or variance of GP has been considered in other applications . For example , [ 5 ] propagates such uncertainty into multi step ahead forecasting of time series . [ 10 ] performs clustering based the principle that highly populated area should have low uncertainty while less populated area should have high uncertainty .
We now describe how to compute F ( Θ ) . Because C is a constant , we just need to compute the projection matrix A . We have been using sample points and bilinear weights to compute the contributions of a pixel to a path and then determine A as noted in Sect31 However , using the same method is not a good option here , because then we don’t have an analytical form to work with . Therefore , we propose the following approximation for computing A based on the distance between a pixel and the path .
The m th path is a line and every point ( x , y ) on this line can be represented by the following equation gm(x , y ) = ( ym,2 − ym,1)x − ( xm,2 − xm,1)y+ ym,1(xm,2 − xm,1 ) − xm,1(ym,2 − ym,1 ) = 0
( 15 ) To compute the contribution of the n−th pixel ( xn , yn ) ( a grid point in Fig 2 ) , where n = 1 , 2 , , N . to this path , we first compute the squared distance between the pixel to the line d2 m,n = gm(xn , yn)2
( ym,2 − ym,1)2 + ( xm,2 − xm,1)2 .
( 16 )
The contribution of this pixel to the path is defined as exp(−γd2 m,n ) , where γ is a parameter . The rationale behind this is that the smaller the distance is , the higher impact the pixel has on the path . Finally , we define the m th row of the projection matrix Am as
( 17 ) The normalization term in ( 17 ) is to make sure that the sum of this row is equal to one , because the projection is the weighted average of all pixel values on the path . Now the full projection matrix A is simply A = [ AT
1 AT
M ]T .
The largest advantage of using this approximated project matrix is that now our objective function F ( Θ ) is differentiable with respective to parameter Θ . Thus , we can easily compute gradient and employ gradient based algorithm such as interior point algorithm to solve the problem [ 2 , 19 ] . This greatly speeds up the optimization process . The error introduced by this approximation is mainly due to pixels located at corners . When we compute the distance between such a pixel and a path , the projection of this pixel on the path can be located outside the cross section . Therefore , ideally ,
N n=1 exp(−γd2
1 m,n )
Am =
[ exp(−γd2 m,1 ) exp(−γd2 m,N ) ] .
2250 such a pixel should not have any impact on the path average . However , our approximation method is not able to check this . Fortunately , the number of such pixels is very small and we don’t expect such error to be a big issue .
Note that our reconstruction uncertainty can be used to compare existing path arrangements and help selecting the best one . This is much faster and more effective than simulating and evaluating against a large number of test images as we show in Sect54
422 Adding region pair constraints We have introduced an unconstrained objective function F ( Θ ) . However , the end points of a path can only be located on a wall or certain regions of a wall and cannot go unbounded . We will add such constraints to our optimization problem .
Suppose that we have K available regions R1 , R2 , , RK . Each region is a line segment indicated by Rk = [ wallk , xk,1 , yk,1 , xk,2 , yk,2 ] . wallk = 1 , 2 , 3 , 4 denotes which wall this region is located on ( see Fig 2 ) . ( xk,1 , yk,1 ) and ( xk,2 , yk,2 ) denote the starting and ending points of the region , respectively . They have a fixed order such that ( xk,1 ≤ xk,2 ) and ( yk,1 ≤ yk,2 ) . Note that either xk,1 = xk,2 or yk,1 = yk,2 because an available region must be located on one of the four walls .
For example , the available region on Wall 4 in Fig 2 is ( 4 , 0 , 0.2 , 0 , 0.5 ) indicating wallk = 4 , xk,1 = 0 , yk,1 = 0.2 , xk,2 = 0 and yk,2 = 05 We will use k to exclusively indicate an available region , not to be confused with the path indicator m . So xk,1 and xm,1 are referring to locations on a region and a path differently even if k = m . The red lines on each wall of Fig 2 show such available regions . Every end point of all paths must be located within an available region . We define region pair as a pair of available regions ( Rk1 , Rk2 ) All region pairs are denoted by a set Ω={(Rk1 , Rk2 )|wallk1 < wallk1} . We require that wallk1 < wallk1 because ( Rk1 , Rk2 ) is the same as ( Rk2 , Rk1 ) and only needs to be considered once . Conceptually , each path can span two regions to form a total of K(K − 1)/2 possible region pairs . However , the number is usually smaller because we do not consider two regions on the same wall . We use |Ω| to indicate the cardinality of the set Ω . The region pair where the m th path is located is denoted by Hm satisfying Hm ∈ Ω . By considering region pairs , we define our final constrained optimization problem as follows min Hm∈Ω for m=1,2,,M min
LB(Hm)≤θm≤U B(Hm ) for m=1,2,,M
F ( θ1 , θ2 , , θM )
.
( 18 ) LB( . ) and U B( . ) are lower bound and upper bound operators , respectively . They ensure that end points of a path are located within an available region . If we denote Hm = ( Rk1 , Rk2 ) , we have LB(Hm ) = [ xk1,1 yk1,1 xk2,1 yk2,1]T and U B(Hm ) = [ xk1,2 yk1,2 xk2,2 yk2,2]T to bound four parameters in θm . Because the end points of both available regions and paths are located on a wall , two parameters in θm are actually constants and don’t need to be optimized over . If we let H = {H1 , H2 , , HM} , we can write bounds in a more compact form by LB(H ) ≤ Θ ≤ UB(H ) . 423 Optimization using simulated annealing The constrained optimization problem defined by ( 18 ) requires us to search for both M region pairs H1 , H2 , , HM and M path arrangement θ1 , θ2 , , θM . This problem is challenging to solve because it is a combinatorial optimization problem . There are |Ω|M possible cases for region pair assignment H . For each assignment , the gradient based search takes O(M N 2 ) . Therefore , the total complexity is O(|Ω|M M N 2 ) . This is prohibitive for slightly large M and K value .
Therefore , we resort to stochastic optimization scheme [ 4 ] . It works as follows . For each iteration , we randomly perturb the current path arrangement by changing the region pair assignment and also initializing the end point positions of affected paths . Then we find the new best objective function in ( 18 ) by fixing the pair assignment . Next , we make a decision whether we keep this perturbation or switch back to the previous iteration result . The above process is then repeated until certain criterion is met . Different stochastic optimization methods differ in how we perturb and how we make a decision about the perturbation .
In this paper , we use simulated annealing ( SA ) . For perturbation , we randomly select a path , randomly assign a region pair to it and then randomly initialize its end point positions on this region pair . For the decision , suppose that the newly optimized objective function value is Fnew and the previous objective function value is Fold . We keep the new change if exp(
) ≥ δ .
( 19 )
Fold − Fnew
T0 q
Here T0 and 0 < < 1 are two constants . q is the current iteration number . 0 ≤ δ ≤ 1 is a randomly generated number during each iteration . The idea behind ( 19 ) is that if new object function Fnew is no more than Fold ( indicating a nice move ) the left side is no less than 1 . So no matter what the value δ is , ( 19 ) is satisfied and we will keep the new perturbation . Otherwise , the left side of ( 19 ) will be a value between 0 and 1 , so whether we keep the change is determined randomly on how large δ is . The concept of annealing is to reduce the temperature term T0 q gradually so the left side of ( 19 ) is less likely to be larger than δ over time unless Fnew is surely no more than Fold . We exit SA if the number of consecutive iterations without improvement exceeds 100 . By using the simulated annealing , we finally reduce the complexity from O(|Ω|M M N 2 ) to O(QM N 2 ) , where Q is the maximum number of iterations needed and is typically smaller than 1000 . This makes our algorithm practical . Alternatively , one can use Genetic algorithm to search for region pair assignments [ 4 ] . Algorithm 1 shows the pseudo codes of the complete optimization process .
5 . TEST RESULTS
5.1 Test setup
Simulated datasets .
In order to evaluate our algorithms , we need to compare the reconstructed image with the ground truth image . However , it is difficult to measure gas concentration inside the combustion region if not impossible . Thus , we resort to simulated tests . In all our tests , the resolution of an image is 200× 200 , representing a square boiler cross section with a width of 1 and a height of 1 . Note that the proposed methodology can be applied to any rectangular cross section .
2251 input : M , Ω output : Fbest,Hbest , Θbest Fbest ← inf , Fold ← inf , i = 0 , q = 0 ; Randomly select Hnew from Ω ; while i ≤ 100 do
Apply interior point algorithm to solve Θnew = arg minLB(Hnew )≤Θ≤UB(Hnew ) F ( Θ ) ; Fnew ← F ( Θnew ) ; if Fnew < Fbest then
Fbest ← Fnew , Hbest ← Hnew , Θbest ← Θnew ; i = 0 ; i ← i + 1 ; else end δ ← random number between 0 and 1 ; if exp( Fold−Fnew Fold ← Fnew , Hold ← Hnew , Θold ← Θnew ;
) ≥ δ then
T0 q end m ← random number from [ 1 , 2 , , M ] ; m ← random item from Ω ; H∗ Randomly sample θ∗ m ; Hnew ← Hold with Hm replaced by H∗ m ; Θnew ← Θold with θm replaced by θ∗ m ; q ← q + 1 ; m based on H∗ end
Algorithm 1 : The proposed path arrangement optimization algorithm . q is the current total number of iterations . i indicates the consecutive number of iterations without improvement ; the algorithm exits if i > 100 .
A ground truth image is generated by summing L 2D smooth functions ( similar to the covariance function in ( 6) ) . In particular , the n th pixel value vn is produced as follows hl exp(− ( xn − µxl)2 + ( yn − µyl)2 s2 l
) .
( 20 )
L l=1 vn =
( xn , yn ) is the corresponding 2D coordinates of vn . The l th smooth function is defined by hl exp(− ( x−µxl)2+(y−µyl)2 ) , where l = 1 , 2 , , L . There are four parameters for each function , hl , sl , µxl and µyl , representing the peak , width and center locations of the function , respectively . s2 l
We fix L = 10 for all our tests . To produce a 2D image , we randomly create each of the L = 10 smooth functions by randomly selecting hl between 0 and 1 , sl between 0.1 and 0.4 , µxl and µyl between 0 and 1 , respectively . Then all the L functions are summed to form the final groundtruth image v as in ( 20 ) . The image created in this way is smooth , and usually multi peaked and with an irregular shape , which resembles a realistic gas concentration image . We create a total of 100 images using this approach . One example is shown in Fig 6g .
Reconstruction algorithms We compare our GP algorithm with SART and TR . For our algorithm , we fix the GP parameters f = 1 , σ2 = 0.001 and r = 10 This setting gives us high enough signal to noise ratio f /σ2 = 1000 and at the same time helps to avoid matrix singularity before the matrix inverse in ( 10 ) and ( 11 ) . Our algorithm is not sensitive to r when it is between 0.5 and 15 We set γ = 300 used in projection matrix approximation such that only pixels right next to a path will have impact on its projection . Parameters in simulated annealing are set as T0 = 1 and = 095 For SART , we set its λ = 1 in ( 3 ) and for TR , we set its λ = 0.1 in ( 4 ) . Both values produce the best results for these two algorithms . To further reduce computation , for all three algorithms , we reconstruct images with a lower resolution of N = 10 × 10 and then apply bi cubic interpolation to render the 200 × 200 image .
Path arrangement methods Before our study , most previous methods have been using view based path arrangement scheme . In an orthogonal path arrangement , there are two views and a path is parallel to one of the four walls like top right plot in Fig 1 . In a diagonal path arrangement , there are also two views and a path is parallel to one of the two diagonal directions ( via rotating the orthogonal arrangement by 45 degrees ) . Siemens energy has mostly used these two simple methods to configure paths . We can combine these two schemes and form the multi view path arrangement such that all paths will be arranged under four evenly spaced views . Note that these view based approaches will not work in the case of mounting restrictions . m=1 d2 n=1 minM
We also consider two additional baseline methods . The first one is to replace our objective function in ( 14 ) with a much simpler maxN m,n . The rationale behind it is that each pixel should have at least one path nearby . We will refer to this method as “ max min ” . The second one is a random path arrangement by randomly selecting a region pair and randomly generating end point positions on the region pair for a path . We will compare our optimized path arrangement with all above five path arrangement schemes . Evaluation Note that a reconstruction algorithm and a path arrangement method can be arbitrarily combined . For each such combination , we conduct 100 tests . For each test , we use one of the 100 simulated image as our ground truth . Based on the path arrangement , the projections are generated . Then different reconstruction algorithm is applied to produce the reconstructed image . We compare this image v with the ground truth image v using root mean squared
N
N
. After all 100 tests , the error RM SE = average RMSE is used to judge the performance of this combination . All tests conducted in this paper are implemented in Matlab . 5.2 Reconstruction test n=1(vn−vn)2
In this test , we focus on comparing the performances of three reconstruction algorithms based on the same path arrangement method ( orthogonal , diagonal , multi view , random or optimized ) . Fig 3 shows the average RMSE scores for different algorithms for different number of paths ( M from 5 to 100 ) . More details about the optimized path arrangement will be given in the next section .
Our GP algorithm produces the lowest RMSE for all six tests . Note that due to the way we generate synthetic images ( Sect51 ) , a ground truth pixel value is usually between 0 and 3 . Thus , RMSE=0.028 roughly means a relative error of 0.01(= 0028/3 ) To check the statistical significance , we conduct the one sided paired t test of GP vs . TR which appears to be the second performer . Table 1 shows the p value for all six tests for different number of paths . With a confidence level at 0.05 , our results are significantly better than those of TR except five cases . SART performs worst for all
2252 ( b )
( c )
( c )
( d )
( e )
Figure 3 : Comparing reconstruction algorithms using different path arrangement methods .
# paths
5
Orth Diag M ult
M axM in
Rand Opti
0.039 0.127 0.048 0.056 0.269 0.005
10
0.013 0.025 0.023 0.006 0.002 0.006
15
0.006 0.001 0.001 0.123 0.003 0.002
20
0.004 0.000 0.000 0.001 0.000 0.003
50
0.032 0.001 0.000 0.001 0.000 0.000
70
0.045 0.002 0.000 0.000 0.000 0.000
100
0.057 0.003 0.006 0.001 0.000 0.000
Table 1 : p value of one sided paired t test on RMSE scores comparing our GP algorithm to TR . 0.000 indicates that p value is smaller than 0001 A bold entry indicates a failed t test with a confidence interval of 005
# paths
5
Mult Rand Opti
0.335 0.369 0.250
10
0.212 0.193 0.163
15
0.155 0.172 0.126
20
0.119 0.114 0.107
50
0.069 0.061 0.043
70
0.068 0.050 0.033
100 0.068 0.034 0.028
Table 2 : RMSE scores for three path arrangement methods using GP reconstruction algorithm . The best score for each column is highlighted in bold . cases . In addition , due to the previously noted division byzero problem SART often fails to produce scores . Therefore , using smoothness regularization like GP and TR helps to overcome this severely under constrained situation .
If we look across all plots in Fig 3 , it appears that the best path arrangement method is our optimization method , followed by random method and then multi view method . The performance of the diagonal scheme does not improve after 20 paths . The orthogonal method ( not shown ) follows a similar trend but is worse than the diagonal method . The multi view method also stops improving after 50 paths . This implies that when the number of paths increases , we should distribute them using more views . Therefore , when the number of paths is more than 50 , more than 4 views should help to further improve the multi view approach . However , this is not the focus of this paper and is not explored here . The “ max min ” method doesn’t perform well , most likely due to the fact that it only focuses on the closest path to a pixel by ignoring the others . Table 2 compares the performance of top three path arrangement methods using the same GP algorithm . Our path optimization method produces the best results for all cases , which also passes the t test against both multi view and random methods with a confidence interval of 005 5.3 Path optimization test
We now test the performance of our path arrangement optimization algorithm with different number of paths from 5 to 100 . We assume that all walls are available for installing a path and the ROI is the whole cross section .
We initialize the simulated annealing by randomly assigning a region pair to a path and randomly selecting the path ’s end points within the corresponding available region . Fig 4a shows the total time taken by our optimization algorithm to converge . When the number of paths is very small such as 5 , the optimization time is only one and half minute . When the number of paths increases to 100 , the time increases to 20 hours . The number of iterations needed ranges between 200 and 600 . Fig 4b shows how the current lowest uncertainty ( best objective function value ) varies with the number of iterations for the case of M = 10 , which takes a total of 359 iterations . The uncertainty usually improves quick at the beginning , but improvement slows down gradually .
( a )
( b )
Figure 4 : Path arrangement optimization results . ( a ) shows the optimization time for different number of paths . ( b ) shows the evolution of objective function value over number of iterations ( in log scale ) for the case of M = 10 paths .
Fig 5 shows the optimized path arrangements for M = 5 and M = 10 cases . It worthy noting that for both cases , corner areas have more path presence than some center areas . We attribute this to the fact that it is harder to infer corner areas from other areas because they are less correlated with others . Therefore , dedicating some paths to corner areas help to reduce the overall uncertainty .
( a ) 5 paths
( b ) 10 paths
Figure 5 : Examples of optimized path arrangements .
By using the optimized path arrangements , we can also evaluate reconstruction algorithms as already shown in Fig 3e .
510152050701000005010150202503035Number of pathsRMSEDiagonal path arrangement SARTTRGP510152050701000005010150202503035Number of pathsRMSEMulti view path arrangement SARTTRGP510152050701000005010150202503035Number of pathsRMSEMax min path arrangement SARTTRGP510152050701000005010150202503035Number of pathsRMSERandom path arrangement SARTTRGP510152050701000005010150202503035Number of pathsRMSEOptimized path arrangement SARTTRGP5101520507010002468101214161820Number of pathsOptimization time ( hours)102050100200300013013501401450150155016Number of iterationsLowest uncertainty0000110220330440560670780891000000110220330440560670780891000000110220330440560670780891000000110220330440560670780891002253 Fig 6 visually shows how reconstruction improves with the increasing number of paths using GP . The ground truth image ( Fig 6g ) appears to have four peaks . When M is small such as 5 and 10 , the algorithm is only able to recover two peaks due to limited projection information . When M increases to 50 , three peaks are recovered . The reconstructed image with M = 100 closely resembles the ground truth image .
5.4 Path optimization test with restrictions
In this section , we consider a more realistic test case as shown in Fig 2 . First , mounting restrictions exist . On the first wall , there are four available regions with a range of [ 0.1 0.2 ] , [ 0.25 0.4 ] , [ 0.45 0.65 ] and [ 0.7 0.9 ] , respectively . There is no available region on the second wall . The third wall has three available regions : [ 0.2 0.4 ] , [ 0.7 0.8 ] and [ 0.85 095 ] There is only one available region [ 0.2 0.5 ] on the fourth wall . In addition , ROI consists of two rectangles . The lower left corner and upper right corner of the first rectangle are located at ( 0.1 , 0.6 ) and ( 0.4 , 0.9 ) , respectively . The lower left corner and upper right corner of second rectangle are located at ( 0.35 , 0.35 ) and ( 0.65 , 0.65 ) , respectively . Our objective function will only sum up the posterior variances for pixels within ROI . We only consider M = 5 , 10 , 15 paths , because these small numbers are of more practical use .
So far , we show that our optimized path arrangement is better than multi view and random path arrangement . This is not so impressive considering that the latter two methods are very simple and straightforward . Even if we don’t have other path arrangement algorithms to compare with , we seek the answer to the following question : how does our result compare with ground truth best path arrangement in terms of RMSE measure ? Because such ground truth is never known to us , we may attempt to randomly sample paths in the hope that one of the randomly generated path arrangements might be close to the ground truth .
To be able to achieve this , we randomly generate 10000 path arrangements . For each arrangement , we apply a reconstruction algorithm and compute the average RMSE . The random arrangement with the lowest RMSE is treated as the best random path arrangement . Fig 7 compares the RMSE of the best random path arrangement with that of our optimization result . Only TR and GP are used as the reconstruction algorithms , which leads to four RMSE curves . The GP based on optimized path arrangement ( represented by “ Optimized+GP ” ) produces the lowest RMSE . This is significantly better than the second performer “ Optimized+TR ” with the highest p value at 0.002 for all cases . Note that for this test , there are 19 region pairs . Even with M = 5 , we have a total of 195 ≈ 2.5 × 106 region pair to path assignments . This hasn’t considered the end point locations of a path on an available region ( continuous numbers ) . Therefore , the pool of 10000 random samples is too small to be able to include the ground truth best path arrangement . However , even with this “ small ” pool size , it takes 16 hours to find the best random path arrangement in the case of M = 5 . In contrast , our optimization algorithm takes about 1 minute , 2 minutes and 4 minutes to converge for M = 5 , M = 10 and M = 15 , respectively .
Fig 2 show the final optimized path arrangement in the case of M = 5 paths . Comparing Fig 2 with Fig 5a , the optimization result without restrictions , we can see that in Fig 5a , paths tend to cover wider regions . This is because
Figure 7 : Comparing our optimized path arrangement with best random path arrangement . the ROI for Fig 5a is the whole cross section while the ROI for Fig 2 is mostly upper left corner and center area . One may expect that in this case with such a small number of paths , all paths should cross the ROI area . Surprisingly , the 2 th path in Fig 2 doesn’t follow this intuition . This can be attributed to the fact that a good path arrangement should not only gain information about ROI but also remove ambiguity caused by non ROI areas . Path 1 , 3 , 4 and 5 already have a good coverage over ROI , but their projection values are also influenced by pixels around lower left corner . Instead of using path 2 to gain additional information for ROI , our algorithm chooses to use it to gain information about those non ROI pixels . This turns out to reduce the overall uncertainty even more .
6 . SUMMARY
Gas concentration reconstruction for coal fired boiler is an important task in power industry . There are two aspects of this problem : how do we construct the image and how do we arrange paths . We propose to use Gaussian process to address both aspects under the same framework . We use the posterior mean as the reconstructed image and average posterior pixel variance as the objective function for path arrangement . A variety of tests are conducted to show the advantages of the proposed method .
Our algorithms have been implemented in Java and deployed in Siemens SPPA P3000 control system as a important component in its combustion optimization module [ 16 ] . Combustion optimization is aimed at improving boiler efficiency and reducing emissions . A closed loop optimization is achieved by manipulating fuel and air levels , with the help of our reconstructed image for key combustion components such as O2 , CO , H2O and temperature . Fig 8a shows the work flow diagram of combustion optimization . Our algorithm is located in the block of “ distribution calculation based on CAT ” ( CAT represents computer aided tomography ) . Fig 8b shows that O2 distribution becomes better balanced with the closed loop control , which improves the boiler efficiency .
Fig 9 shows a separate user interface for path arrangement optimization , which mainly runs off line . This software takes a boiler configuration file ( with boiler geometry , number of paths , constraints and etc . ) as input and exports the optimized path arrangement in an output file . The user can then use the output to design the TDLAS layout plan .
510150101201401601802Number of pathsRMSE BestRandom+TROptimized+TRBestRandom+GPOptimized+GP2254 ( a)M = 5
( b)M = 10
( c)M = 15
( d)M = 20
( e)M = 50
( e)M = 70
( f)M = 100
( g)Ground truth
Figure 6 : Comparing the reconstructed results with the ground truth with different number of paths .
Note that in our reconstruction algorithm , the reconstructed image is unbounded , which may cause a pixel value to be negative . This is against reality : a gas concentration cannot have negative values . We have improved this by converting the Gaussian process posterior distribution in ( 9 ) into a quadratic loss function . After introducing user specified lower and upper bound ( e.g , lower bound is zero ) , we form a quadratic programming problem , which can be easily solved . The details are omitted here .
Figure 9 : Path arrangement optimization user interface .
7 . REFERENCES [ 1 ] S . Angeli and E . Stiliaris . An accelerated algebraic reconstruction technique based on the Newton Raphson scheme . In IEEE Nuclear Science Symposium Conference Record , 2009 .
[ 2 ] S . Boyd and L . Vandenberghe . Convex Optimization .
2004 .
[ 3 ] K . B . Chung , F . C . Gouldin , and G . J . Wolga .
Experimental reconstruction of the spatial density distribution of a nonreacting flow with a small number of absorption measurements . Applied Optics , 34:5492–5500 , August 1995 .
[ 4 ] D . Fouskakis and D . Draper . Stochastic optimization : a review . International Statistical Review , 2002 .
[ 5 ] A . Girard , J . Candela , R . Murray smith , and C . E . Rasmussen . Gaussian process priors with uncertain inputs application to multiple step ahead time series forecasting . In Advances in Neural Information Processing Systems , 2002 .
[ 6 ] A . Guha and I . Schoegl . Simulation of 2D tomographic TDLAS using algebraic reconstruction and Tikhonov regularization . In 8th US National Combustion Meeting , 2013 .
[ 7 ] R . K . Hanson , P . A . Kuntz , and C . H . Kruger .
High resolution spectroscopy of combustion gases using a tunable IR diode laser . Applied Optics , 16:2045–2048 , August 1977 .
[ 8 ] M . Jiang and G . Wang . Convergence of the simultaneous algebraic reconstruction technique ( SART ) . IEEE Trans . on Image Processing , 12:957–961 , August 2003 .
[ 9 ] A . C . Kak and M . Slaney , editors . Principles of
Computerized Tomographic Imaging . SIAM Press , 2001 .
[ 10 ] H . Kim and J . Lee . Clustering based on Gaussian processes . Neural Computation , 19:3088–3107 , 2007 .
[ 11 ] C . Liu , L . Xu , Z . Cao , and H . McCann .
Reconstruction of axisymmetric temperature and gas
010203040506070809 0020406081 002040608112 002040608112 00204060811214 00204060811214 00204060811214 02040608112142255 Figure 8 : Integration of the proposed algorithm in Siemens SPPA P3000 control system ( copied from [ 16] ) . ( a ) system work flow diagram . ( b ) combustion optimization example .
( a )
( b ) concentration distributions by combining fan beam TDLAS with onion peeling deconvolution . IEEE Transactions on Instrumentation and Measurement , 63:3067–3074 , 2014 .
[ 22 ] X . Zhu , J . Lafferty , and Z . Ghahramani .
Semi supervised learning : From Gaussian fields to Gaussian processes . Technical Report CMU CS 03 175 , Carnegie Mellon University , 2003 .
[ 12 ] C . Liu , L . Xu , and ZCao Measurement of axisymmetric temperature distributions using single view fan beam TDLAS tomography . In IEEE International Instrumentation and Measurement Technology Conference , 2013 .
[ 13 ] Z . Nadir , M . S . Brown , M . L . Comer , and C . A .
Bouman . Tomographic reconstruction of flowing gases using sparse training . In IEEE International Conference on Image Processing , 2014 .
[ 14 ] C . E . Rasmussen and C . K . I . Williams . Gaussian Processes for Machine Learning . MIT Press , 2006 .
[ 15 ] M . Ravichandran and F . C . Gouldin . Reconstruction of smooth distributions from a limited number of projections . Applied Optics , 27:4084–4097 , October 1988 .
[ 16 ] S . Thavamani , M . Behmann , and T . Spaeth . Plant performance improvements by enhanced combustion through laser based optimization . In ISA Power Industry Division ( POWID ) Symposium , 2012 .
[ 17 ] J . Tian and K . Ma . A survey on super resolution imaging . Signal , Image and Video Processing , 5:329–342 , 2011 .
[ 18 ] M . E . Tipping and C . M . Bishop . Bayesian image super resolution . In Advances in Neural Information Processing Systems , 2002 .
[ 19 ] A . W¨achter and L . T . Biegler . On the implementation of a primal dual interior point filter line search algorithm for large scale nonlinear programming . Mathematical Programming , 106:25–57 , 2006 .
[ 20 ] F . Wang , Q . Wu , Q . Huang , H . Zhang , J . Yan , and
K . Cen . Simultaneous measurement of 2 dimensional H2O concentration and temperature distribution in premixed methane/air flame using TDLAS based tomography technology . Optics Communications , 346:53–63 , 2015 .
[ 21 ] C . Yuan . A Bayesian approach for gas concentration reconstruction based on tunable diode laser absorption spectroscopy . In International Conference on Acoustics , Speech , and Signal Processing , 2012 .
2256
