Multi View Incident Ticket Clustering for Optimal Ticket
Dispatching
Mirela Botezatu
IBM Research
Zurich Switzerland bot@zurichibmcom
Jasmina Bogojeska
IBM Research
Zurich Switzerland jbo@zurichibmcom
Ioana Giurgiu IBM Research
Zurich Switzerland igi@zurichibmcom
Hagen Voelzer
IBM Research
Zurich Switzerland hvo@zurichibmcom
Dorothea Wiesmann
IBM Research
Zurich Switzerland dor@zurichibmcom
ABSTRACT We present a novel technique that optimizes the dispatching of incident tickets to the agents in an IT Service Support Environment . Unlike the common skill based dispatching , our approach also takes empirical evidence on the agent ’s speed from historical data into account .
Our solution consists of two parts . First , a novel technique clusters historic tickets into incident categories that are discriminative in terms of agent ’s performance . Second , a dispatching policy selects , for an incoming ticket , the fastest available agent according to the target cluster . We show that , for ticket data collected from several Service Delivery Units , our new dispatching technique can reduce service time between 35 % and 44 % .
Categories and Subject Descriptors I53 [ Pattern Recognition ] : Clustering algorithms ; I27 [ Natural Language Processing ] : Text analysis ; I28 [ Problem Solving , Control Methods , and Search ] : Scheduling
Keywords Combined affinity matrix ; Graph Cut ; Spectral Clustering ; Fuzzy Clustering , Ticket clustering ; Ticket dispatching
1 .
INTRODUCTION
Enterprises and IT service providers are constantly striving to improve the quality of service and in the same time maintain or reduce the cost of service delivery . One of the major challenges in service delivery is resolving the hundreds of incidents as efficiently as possible . This is an important but labor intensive task , assigned to the service agents that are responsible for solving the customer ’s incident reports .
In our setting , incidents in the customer environment are submitted to the IT Service Provider in the form of a ticket which is a snipPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than the author(s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee . Request permissions from Permissions@acmorg KDD’15 , August 10 13 , 2015 , Sydney , NSW , Australia . Copyright is held by the owner/author(s ) . Publication rights licensed to ACM . ACM 978 1 4503 3664 2/15/08 $1500 DOI : http://dxdoiorg/101145/27832582788607 .
Figure 1 : Integration of the clustering and dispatching component . pet of text describing a particular IT problem . The reported problems range widely from authentication errors , application crashes , to broken transactions or server unavailabilities .
The dispatching to the service agent is generally done on two levels . First , a human dispatcher reviews the problem description text and decides which delivery unit ( a team of service agents ) is responsible for addressing that type of ticket . Second , within the delivery unit , a service agent is either chosen by the group leader or on a voluntary basis . The dispatching at this level is based on the qualification of the agents , the availability and the workload of the agents , as well as the complexity of the ticket . At this level we have identified an opportunity for automation and optimization of the dispatching process . Empirical evidence on which agent is most efficient in solving a certain category of tickets is not explicitly taken into consideration . Therefore we derive a method for ticket clustering , which identifies ticket topics ( categories ) that are discriminative in terms of an agent ’s performance and dispatches each ticket from every category to the agent that is the most efficient in executing it .
The clustering and dispatching component is designed to be integrated in the IT Service Delivery Environment as shown in Figure 1 . In this paper , we show that the existence of such a component that takes informed dispatching decisions , can reduce the resolution time and by extension , the business costs . We demonstrate this by conducting experiments on real data collected from different ser
1711 vice delivery units . This data comprises the ticket description and its complexity , the agent who resolved it , the duration recorded for resolving it , etc .
Figure 2 : Illustration of a desirable partitioning .
Our approach partitions the tickets into clusters that are relevant with respect to the problem they describe and that are also homogeneous in terms of the agent ’s performance . We achieve this by leveraging multiple views of the ticket data . A cluster is homogeneous in terms of an agent ’s performance if the variation in the time it takes for an agent to solve tickets from that cluster is small ( the distribution is narrow , as illustrated in Figure 2 ) . This way , we can infer the approximate duration needed for an agent to solve the tickets that pertain to a certain cluster from the historical data . Further , we use this information in the dispatching process , by always assigning the ticket of a given cluster , to the agent that is the most efficient in solving tickets of that cluster . The difficulty in finding these clusters is that applying a standard algorithm that groups the tickets based solely on their most prominent topics , leads to clusters that are non homogenous in terms of the agent ’s performance . Therefore , we propose a clustering approach that performs a partitioning that can discover meaningful ticket categories with homogeneous agent performance . Our contributions are manifold : • A clustering method capable to identify ticket categories that are homogeneous in terms of the agent ’s performance ;
• A data informed dispatching policy that assigns an incoming ticket to the agent that is the most efficient in resolving it ;
• An integrated solution to reduce the service costs . The outline of this paper is as follows . Section 2 presents the incident ticket clustering method . Section 3 provides an overview of the data informed dispatching policy . The experimental evaluation on real world datasets is presented in Section 4 , followed by the related work in section 5 and the conclusions in Section 6 .
2 .
INCIDENT TICKET CLUSTERING
We devise a method that partitions the set of tickets into groups of similar tickets both in terms of the incident they report and the time needed for an agent to resolve them . The method utilizes both the matrix of semantic similarities between tickets , and the divergence matrix a matrix which captures information on the difference in the duration of resolution of two tickets assigned to the same agent . More specifically , we first modify the semantic similarity matrix based on the information represented in the divergence matrix , and then , we run a clustering algorithm that operates on the resulting matrix . For each cluster , we derive an estimate for the time each agent needs to resolve tickets pertaining to that cluster . Ultimately , we devise a dispatching policy that assigns each ticket to the agent who is the fastest at resolving it and compute the achieved reduction in terms of service time due to the new assignment .
In the method described above , a small variation in the agent ’s performance for the clusters is part of the output . We also propose an algorithm that takes a clustering and a target variation for the clusters as an input and then adjusts the clusters structure to achieve the target variation specified in the input .
In Figure 3 we show an example of the desired clustering assuming we had only four tickets . Even though the semantic similarity between tickets T1 and T3 and tickets T2 and T4 is high , we do not put them in the same cluster due to the large difference in the resolution times . Instead we cut the edge that links them in the similarity graph . Therefore , for this example , instead of reporting the two clusters “ servers issues" and “ DB issues" , we would discover “ network issues" ( as denoted by bigrams “ lost connection" or “ ping statistics" ) and “ functional errors" ( as denoted by bigrams “ server crashed" or “ inconsistent state" ) .
Figure 3 : Example of similarity demotion .
2.1 Preliminaries Let T be a ticket consisting of |T| words w1,··· , w|T| and let K = {T1 , T2,··· , Tn} be a set of n tickets . Also , let A = {a1 , a2,··· , a|A|} denote the set of agents who resolved the tickets . Each ticket Ti , is associated with several fields : d(i ) the duration for resolving it , a(i ) the agent who resolved it and c(i ) ∈ W = { “ A" , “ B" , “ C"} the complexity of the ticket ( where “ A" denotes the highest complexity and “ C" the lowest ) . For each agent ai there is a mapping to its skill level s(ai ) ∈ W . An agent with skill level “ A" is entitled to resolve tickets of any complexity class , an agent with skill level “ B" is entitled to resolve tickets of complexity “ B" and “ C" , and an agent with skill level “ C" is entitled to resolve only tickets of complexity “ C" . 2.2 Multi view similarity matrix with induced sparsity
The typical approach to measuring the similarity between two blocks of text is to use a lexical matching method , and compute a similarity score based on the number of lexical units ( words ) that occur in both input texts . Pre processing the texts via stemming , removal of the stop words , longest subsequence matching and addi
1712 tional normalization and weighting factors have shown to improve the results of such lexical methods [ 18 , 10 ] . However the lexical similarity measures alone have an important limitation : they fail in identifying the semantic similarity between texts ( ie , the similarity score between “ process shutdown" and “ application terminated" would be zero ) .
In this section , we describe the method we used to compute the semantic similarity metric between tickets [ 19 ] . It is derived from the semantic similarity metric between words , described in the next section . We define the semantic similarity between two tickets Ti and Tj , given the semantic similarity between words . Each word w in Ti is assigned a semantic similarity score maxSim(w , Tj ) , based on the most similar word in Tj . The procedure is applied symmetrically , for each word in Tj . The word similarity scores for each ticket are added and each summation is normalized with the length of its corresponding ticket . The final result is the average of the normalized summation of each ticket :
Similarity(Ti , Tj ) =
1 2
(
+ w∈Ti w∈Tj maxSim(w , Tj )
|Ti| maxSim(w , Ti ) |Tj|
+
)
( 1 )
Let S ∈ Rn×n denote the ticket ticket semantic similarity ma trix , where Sij = Similarity(Ti , Tj ) .
Another type of proximity relation between tickets is given by the divergence matrix described below . If two tickets Ti and Tj , that are annotated with the same complexity level ( ie , c(i ) = c(j ) ) have been resolved by the same agent ( a(i ) = a(j ) ) and the ratio in their corresponding resolution times is higher than a certain threshold λ then they have different level of difficulty and they should not be clustered in the same group of incidents . We define the divergence matrix D ∈ Rn×n :
1 if a(i ) = a(j ) and c(i ) = c(j ) and min(d(i ) , d(j ) ) > λmax ( d(i ) , d(j) ) ;
0 otherwise
Dij =
( 2 )
Two tickets which are similar in terms of both their topics and the duration it took an agent to resolve them may reveal stronger connection than two other tickets which are similar only in terms of topic . Motivated by this statement we combine the two proximity relations ( views ) into one matrix S ∈ Rn×n as follows :
( 3 ) We induced sparsity on S by setting the similarity scores in S to
S
= S − S ◦ D .
0 when Dij = 1 . 2.3 Semantic similarity metric between words As the same incident may be documented with different words , we are interested in assessing the degree of similarity between words in the specific IT Service Delivery domain .
For extracting the semantic similarity scores between pairs of words , we have explored three corpus based methods which have been reported to give good results [ 22 , 8 ] . The methods are : PMIIR [ 14 ] , the Google similarity distance ( GSD ) [ 6 ] and LSA [ 26 ] .
PMI IR only requires simple statistics about two words : their marginal frequencies and their co occurrence frequency in a corpus .
PMIIR(w1 , w2 ) = log p(w1 , w2 ) p(w1 ) ∗ p(w2 )
( 4 ) where p(wi , wj ) denotes the probability that words w1 , w2 cooccur in the same ticket , p(w ) is the probability that the word w occurs in a ticket . Please note that we do not need to specify a window size for estimating the co occurrence frequencies of w1 and w2 as the ticket descriptions are usually short ( < 20 words ) .
GSD is based on information distance and Kolmogorov complexity . In the original paper , the authors rely on Google to retrieve pages for co occurrence statistics . We adapt the extraction of cooccurrence statistics to our setting , as follows : max{log(|f ( w1)| , log(|f ( w2)|}
GSD(w1 , w2 ) = log(|f ( w1 , w2)| ) log(Q ) − min{log(|f ( w1)| ) , log(|f ( w2)|)}− − log(Q ) − min{log(|f ( w1)| ) , log(|f ( w2)|)} ( 5 ) |f ( w1 , w2)| ( the sum of the numbers of occurrences of search terms in each ticket , summed over all tickets ) and f ( w1,··· , wk ) represents the set of all tickets in which the words w1,··· , wk appear together . where Q = w1∈T1,w2∈T2
In LSA , term co occurrences in a corpus are captured via dimensionality reduction operated by a singular value decomposition ( SVD ) on the term by document matrix representing the corpus .
While all the methods gave meaningful results regarding the relatedness of words in a broader sense ( ie , flagging associations between pairs of words such as “ hung" and “ ping" or “ disk" and “ full" as significant ) , LSA outperformed the other two methods in identifying synonyms . In order to perform a quantiative evaluation of how well each method performs on our corpus ( comprised of a large set of ticket descriptions and ticket resolutions ) we did the following :
• We have tagged the words in the corpus into their parts of speech and labeled them accordingly ( pos tagging [ 25] ) ;
• We selected pairs of words with the same pos tag and with high association score with any of the three methods ;
• We asked a domain expert to select out of the pairs given above , pairs of words that are synonyms in the IT Service Delivery domain ;
• We evaluated the methods based on their performance in de tecting these pairs of synonyms .
The process described above has resulted in a list of 72 pairs of words that are synonyms in the IT Service Delivery domain ( eg , “ pingable" and “ responsive" or “ archive" and “ backup" ) . We consider a method has identified a pair of synonyms ( w1 , w2 ) if the scaled semantic similarity score between ( w1 , w2 ) is above the mean of the semantic similarity scores between w1 and any other word in the corpus ( or w2 and any other word in the corpus ) .
We count the number of synonyms identified by each method and divide the result by the total number of pairs of synonyms . The results are shown in Table 1 .
LSA GSD PMI IR 0.83
0.42
0.3
Table 1 : Percentage of synonyms identified .
There are several reasons why LSA outperformed the other two methods . First , the conventional wisdom is that synonym words , with a high degree of relatedness are unlikely to co occur in a small window size . Second , it is plausible to represent the meaning of a
1713 for the two latter algorithms we use the silhouette statistic , a wellbalanced coefficient introduced in [ 11 ] and which has shown good performance in experiments . Let C = {C1 , C2,··· , Ck} be a clustering of the set of tickets . For each cluster Ci ∈ C , for each complexity class c ∈ W and for each agent ac ∈ A ( such that ac has solved tickets in Ci of complexity c ) , one can measure the dispersion in the duration of resolution . The metric we propose for this is the coefficient of variation ( CV ) , defined as the ratio of the standard deviation of these durations to their mean :
CV = sx x
( 6 ) where sx is the standard deviation of a set of samples xi and x is their mean .
The motivation for using the coefficient of variation is the following : the standard deviations of two sets are not comparable to each other in a meaningful way to determine which set has greater dispersion because the values in the sets may have different magnitudes . The coefficient of variation does however show the extent of variability in relation to the mean .
241 Hierarchical Clustering with Complete Link age
The agglomerative hierarchical clustering algorithm with complete linkage , works as follows:(i ) the algorithm starts with n clusters , each containing one object ; ( ii ) the most similar pair of clusters Ci , Cj is found using the combined similarity matrix S and merged into a single cluster . ( iii ) the similarity matrix is updated ( its order is reduced by one by substituting the individual clusters with the newly merged one ) . Steps ( ii ) and ( iii ) are repeated until a certain stopping criterion is reached .
This method is relevant for our study because of the distance measure that is used between two clusters in the merging step in the algorithm : Ci , Cj : dcomplete(Ci , Cj ) = maxl∈Ci,m∈Cj ( 1 − S lm ) . If sk denotes the similarity of the two clusters merged in step k , this distance measure ensures that no pair of tickets with similarity 0 ( distance 1 ) will be put in the same cluster . The clusters at step k are maximal sets of points that are completely connected with each other by edges of weights ( similarity ) s ≥ sk . 242 Using the combined similarity matrix S in a spectral clustering algorithm there will result a partitioning obtained by minimizing the cuts in the input graph and thus implicitly maximally satisfying the objective II above .
Spectral Clustering
Spectral clustering works as follows :
2 where Dii =n
2 SD− 1 ity matrix S : L = D− 1
1 . Construct the Graph Laplacian L from the combined similarij ; 2 . Select the first k eigenvalues λ1,··· , λk and determine their corresponding eigenvectors to form a new matix M ∈ Rn×k , which needs to be normalized ; j=1 S
3 . Perform clustering in the new subspace using K means .
243 Homogeneity Optimized Fuzzy K means We use the similarity matrix S to perform the soft clustering with fuzzy k means . The resulting clusters will not be homogeneous in terms of duration because we only pass the semantic similarity matrix to the algorithm . In the following , we propose an approach that utilizes the clusters returned by fuzzy k means and reduces
Figure 4 : Sparsity : similarity matrix ( left ) , divergence matrix ( right ) . word by a context vector of co occuring words and the corresponding co occurrence counts measured in a text window context . LSA performs this and in addition , it transforms the context vectors to a lower dimensional space by applying singular value decomposition ( SVD ) . The similarity is further reduced to the similarity of the context vectors where the cosine of the angle is employed as a similarity metric . 2.4 Clustering
The tickets are related via two types of similarity measures that originate from different sources : one that comes from the ticket content the ticket similarity matrix S , and one that comes from the agents who resolved the tickets the divergence matrix D .
Due to the extreme sparsity shown in Figure 4 , the divergence matrix alone does not contain complete information of the structure of the clusters . Since both matrices capture important information , we propose an approach that uses the two matrices in the combined matrix S as defined in equation ( 3 ) and has the following objectives :
I Cluster similar tickets together ( we want to be able to extract topic information from these clusters ) ;
II Minimize the number of pairs of tickets in the same cluster that have similarity equal to zero ( we want homogeneous clusters in terms of the agent ’s performance , which is why we enforced the S ij = 0 when Dij = 1 ) .
We achieve this using three candidate clustering algorithms namely : hierarchical clustering with complete linkage [ 7 ] , spectral clustering [ 20 ] and our adjusted version of fuzzy k means [ 3 ] : homogeneity optimized fuzzy k means .
Mij ≥ 0 andk
Hierarchical clustering and spectral clustering are hard clustering algorithms , ie , each ticket is a member of exactly one cluster . The input for these algorithms is the matrix S . Fuzzy k means is a soft clustering algorithm and therefore returns a partition of the n tickets {T1 , T2,··· , Tn} into k clusters {C1 , C2,··· , Ck} specified by a membership matrix M ∈ Rn×k , j=1 Mij = 1 , whose components quantify the membership degree of ticket Ti in cluster Ck . The input for fuzzy k means is the similarity matrix S . We optimize the homogeneity of these clusters by iteratively moving tickets from their most probable clusters to the second , third , up to the least probable clusters , as will be described later on . We selected fuzzy k means and not LDA [ 4 ] because the ticket descriptions are very short , which is too sparse for traditional topic modeling . Therefore we used a soft clustering algorithm that is able to leverage the similarity matrix S . While hierarchical clustering does not require the specification of the number of clusters , k , spectral clustering and fuzzy k means take k as input . In order to estimate the optimal number of clusters
1714 the variation in duration inside the cluster by iteratively removing tickets . Let C = {C1 , C2,··· , Ck} be the clusters returned by fuzzy kmeans and Pr ( T | Ci ) denote the probability of ticket T belonging to cluster Ci . At each step , the algorithm selects the ticket that ⊆ Ci ( subset of minimizes the variation from a sub cluster C ( a)(c ) tickets in Ci that have been solved by agent a and have complexity c ) and removes it from the cluster . The ticket is then tentatively inserted in the the next most probable clusters in an order given by the ranking from fuzzy k means . A ticket is inserted in another cluster if the variation in duration of the cluster with the ticket does not increase . If the ticket can not be inserted in any of the clusters it is dropped . This procedure continues until the variation in duration inside C ( a)(c ) reaches a target value τ . These steps are formalized in Algorithm 1 and Algorithm 2 : i i
Algorithm 1 Optimize homogeneity of the clusters . 1 : function OPTIMIZE(C ) for all Ci ⊆ C do 2 : for all C ( a)(c ) 3 : while CV 4 : 5 :
⊆ Ci do
≥ τ do
( a)(c ) i
C i
T = argminT CV ← C ( a)(c ) C ( a)(c ) MOVE(T ) i i
\{T}
C
( a)(c ) i
\ {T}
6 : 7 : 8 : 9 : 10 : 11 : end function end for end for end while
Algorithm 2 Move a ticket . 1 : function MOVE(T ) 2 : for Ci ⊆ C\{T} sorted in decreasing order of Pr ( T | Ci ) if CV
C
( a)(c ) i
C ( a)(c ) i
∪{T} ≤ CV ← C ( a)(c )
( a)(c ) C i then ∪ {T} return i do
3 : else
4 : 5 : 6 : 7 : 8 : 9 : end function end for end if
DROP(T )
Homogeneity optimized fuzzy k means has the following properties : ( i ) the variation inside the final clusters is not an output of the algorithm but an input parameter of the algorithm and that enables finer control . The variation of the resulting clustering will not exceed the one given as an input . ( ii ) The algorithm can be used for identifying the outliers in the data set . To achieve this we only move the ticket to the second or the third most probable clusters and drop it if it cannot be placed . The advantage of doing this is that the coherence of the clusters with respect to the topics remains unaltered ( unlike the base algorithm where we tradeoff topic relevance for high homogeneity ) . Additionally one can inspect the set of dropped tickets and observe which type of incidents have inherently higher variation in the resolution time .
3 . DISPATCHING
For a given partitioning C = {C1 , C2,··· , C|C|} , we build a matrix P ∈ R|A|×|C|×|W| which stores the median duration for the execution time for each agent in resolving a ticket pertaining to
Figure 5 : Agent ’s performance for a given cluster and complexity level . one of the clusters for a certain complexity class . Some entries in this matrix will be −1 . When an entry Pijk = −1 it means that there are no records in the data of agent ai working on a ticket from cluster Cj of complexity k where k is an id for each complexity class { “ A ” , “ B ” , “ C ” } .
We implement the data informed dispatching policy and the non data informed dispatching policy . Unlike the non data informed dispatching policy , the data informed policy , dispatches a ticket Tj ∈ Cj to the agent that is the most efficient in resolving it from all the agents that are available , ie , it selects ai . such that Pijk is minimal . The implementation of the dispatching aligns to the following setting :
• The maximum working number of hours of an agent is less than 8 hours . When an agent reaches the 8 hours of work in one day , the agent is removed from the pool of available agents to which tickets can be dispatched on that day ;
• No tickets are passed from one day to another . This assumption is enforced by the original data , where the ticket resolution is started and completed in the same day in 99.5 % of the cases ;
• The complexity of the ticket must match the qualification of the resolving agent . Therefore , an agent with skill level “ A" is entitled to resolve tickets of any complexity class , an agent with skill level “ B" is entitled to resolve tickets of complexity “ B" and “ C" , and an agent with skill level “ C" is entitled to resolve only tickets of complexity “ C" ;
• When summing up for the total duration of execution ( ser vice time ) we did not add any waiting time ;
• The arrival order of the tickets based on which we perform the dispatching is the original order , as documented in the dataset .
For the implementation of the dispatching , we split the data in separate chunks for each working day . For every chunk , we store a list with all the agents available that day by mining the log for agents that have tickets associated to their id in that particular day . We also maintain a queue with the tickets that need to be completed that day by extracting the list of tickets from the logs that were recorded as started and completed that day . Ultimately , we run the data informed dispatching policy and the policy that works under exactly the same assumptions , but without being data informed ( equivalent to the setting when an agent voluntarily selects the next ticket to resolve , provided that the agent has the necessary qualification skill based dispatching [ 27] ) , and compare the recorded service times for each delivery unit .
1715 4 . EMPIRICAL EVALUATION 4.1 Data preparation
We use three datasets : DU1 , DU2 , DU3 from three service de livery units comprising 3696 , 2373 and 1916 tickets respectively .
The first step in the analysis is the data cleaning procedure where we take the raw unstructured data and remove unnecessary information such as , email headers , punctuation , html formatting , server names , stop words and we also do stemming . This step is important as it severely impacts the performance of the algorithms . The ticket descriptions are a mixture of machine and human generated text and contain many domain specific technical words , some of which are not present in a standard dictionary ( eg , “ unpingable" , “ ssd" , “ hw" ) , but are still relevant in identifying the incident category . Some examples of ticket descriptions are given in Table 2 . serverXYXY error : DISK Utilization :Object = /dev/sda3/var : percent full : 95 % : MB free : 219 MB New User Request Form : XYXY backup missed on this server We are unable to connect to hosts serverXYXY . Please investigate
Table 2 : Examples of ticket descriptions .
4.2 Experiments
In the experiments we set the threshold to λ = 0.8 , meaning that for two tickets from the same cluster , solved by the same agent and of the same complexity the variation of duration of executing them is within 20 % . Using such small variation is reflected in the connectedness of the similarity graph . In Figure 6 we show how the percentage of deleted edges increases by increasing the value of λ .
Figure 6 : Percentage of edges removed when increasing λ ( for DU1 ) .
421 Clustering In what follows , we show that spectral clustering and homogeneity optimized fuzzy k means exhibit the best performance for this task .
We run hierarchical clustering with complete linkage ( stopped at dissimilarity threshold 08 ) For DU1 we obtain a large set of clusters ( 176 clusters ) with a low abundance of tickets ( on average 19 tickets per cluster ) , and also the clusters tend to have similar sizes . This is illustrated in Figure 7 where we observe skewed distribution when plotting the cluster abundances . The results remain similar when varying both λ and the dissimilarity threshold for stopping ( ie , for λ = 0.8 , dissimilarity threshold=0.9 we obtain 130 clusters , or for λ = 0.5 , dissimilarity threshold=0.8 we obtain 92 clusters ) . The resulting clusters are small and with low variation in both topic and resolution time per agent , but they are not unique , ie , they are fragments of larger clusters .
Figure 7 : Cluster abundances density plot .
With spectral clustering we obtain 12 clusters with sizes between 193 and 659 tickets for DU1 , 7 clusters with sizes between 232 and 601 for DU2 and 5 clusters with sizes between 134 and 385 for DU3 . By analyzing the frequent words in the clusters we observe that the algorithm is able to correctly capture relevant incident ticket categories in each cluster . This is shown in the Table 3
Cluster Frequent words C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 C11 C12 lost , contact , agent ssd , internal , error file , system , space , full prod , issue , faulty , disk cluster , bottleneck system , restart , request backup , error scsi , retry , failed server , physical , failure application , problem , not , responding node , down , power , supply limit , exceeded , file
Table 3 : Frequent words in the clusters obtained by spectral clustering using S for DU1 .
Homogeneity optimized fuzzy k means exhibits also good performance in identifying incident categories . We obtain 12 clusters with sizes between 195 and 429 tickets for DU1 , 7 clusters with sizes between 206 and 387 for DU2 and 5 clusters with sizes between 127 and 368 for DU3 .
Delivery Unit DU1 DU2 DU3 0.21
0.17
0.23
τmin
Table 4 : Values for τmin for each delivery unit
1716 We first run the algorithm such that no tickets are dropped . We choose the minimum value for the target coefficient of variation , τmin , for each delivery unit , such that all the tickets are assigned to a cluster . The values for τmin when no tickets are dropped for each delivery unit are given in Table 4 . Note that the values for the coefficient of variation are small , due to the fact that we allow tickets to be assigned to less probable clusters . The frequent words in the clusters discovered are presented in Table 5 . We observe that
Cluster Frequent words C1 C2 C3 C4 C5 C6 C7 C8 C9 C10 C11 C12 monitoring , cluster , disk , replacement fsd , code , error command , retry , reboot , server client , backup , file ssd , database , memory , corruption disk , error , scsi node , down , agent , contact disk , fan , sensor , faulty docket , frame , replacement power , supply , fault transport , lost , retry limit , exceeded , file
Table 5 : Frequent words in the clusters obtained homogeneity optimized fuzzy k means for DU1 . both clustering approaches identify ticket categories documenting “ file limit exceeded" , problems related to the “ power supply" , or “ backup" related issues . While the clusters obtained with spectral clustering place all the disk related tickets in one single cluster , with the homogeneity optimized fuzzy k means we obtain two clusters documenting disk errors : one which was documenting disk replacement , and one reporting disk fan sensor issues . Also for homogeneity optimized fuzzy k means it is not always straightforward to establish the incident category of a certain cluster . One such example is the cluster with top words “ ssd , database , memory , corruption" . Also , it merged tickets documenting “ node down" with tickets documenting “ lost , contact , agent" . This hints to the fact that for an agent , these two categories of incidents take similar amount of time to be resolved .
When we introduced homogeneity optimized fuzzy k means we also mentioned the possibility of identifying outliers , tickets that take either too long or too little time to be resolved by an agent relative to the cluster they pertain to . This can be achieved by modifying the algorithm to move tickets only in the first three most likely clusters . This leads to a significant number of tickets dropped and this grows inversely proportional with the value of τ as illustrated in Figure 8 . By inspecting the dropped tickets we observe that they mostly document disk errors , and filesystem issues . The recorded duration for the dropped tickets is either very short either very large . This indicates that in the dispatching , for those tickets with larger duration one needs to have some margin with respect to filling the day completely .
In the following we evaluate the quality of the clustering obtained from running spectral clustering with the combined similarity matrix , and homogeneity optimized fuzzy k means with the minimum values of τ for which no tickets are dropped , τmin . We inspect both the reduction in service time from implementing the data informed dispatching policy and the homogeneity in agent ’s performance . 422 Speed up in service time Let C = {C1 , C2,··· , Ck} be the partitioning of the corpus of tickets C . We measure the service time which is the total number of working hours needed for resolving all the tickets in a given period of time . We use the matrix P that for each cluster and for each complexity level stores the agent ’s performance ( as depicted in the Figure 5 ) , and we run the data informed dispatching policy , both on the clustering obtained with spectral clustering and with the homogeneity optimized fuzzy k means . The data informed dispatching policy is evaluated against the dispatching that does not take the insight from the data into account ( which agent is fastest in resolving an incoming ticket ) .
We observe a major reduction in the service time up to 44 % ( for DU2 ) when running the data informed dispatching policy compared to the dispatching policy that does not consider the insight from the data . The reductions are apparent for dispatching based on both the homogeneity optimized fuzzy k means clustering and the spectral clustering , slightly better in the former one ( possibly due to the more uniform cluster sizes ) . The speedup is shown in Figure 9 where we denote by ( DI ) the data informed dispatching policy and by ( non DI ) the non data informed dispatching policy . Figure 11 shows that the discrepancies in agent ’s performance for a given cluster and complexity are large and exploiting these differences in dispatching leads to a significant reduction in the service time . Also we have identified that agents with skill level “ B" are faster than agents with skill level “ A" in solving tickets documenting “ network errors" of complexity “ B" , shown in Figure 10 . This illustrates that a higher skill ( which is established based on experience or training level ) does not directly translate into higher speed ( which can only be established empirically , by analyzing the historical data ) . Note that we did not include service level agreements in both dispatching policies In particular we only kept the order of ticket arrival , but assumed that a ticket can be resolved by the optimal agent even if that meant ticket resolution could only start when this agent becomes free . Naturally this might delay ticket resolution potentially conflicting with SLA requirements on resolution times . In contexts with such SLA constraints , a simulation taking arrival patterns into account can yield more precise assessments . Please note however that both dispatching policies considered in our experiments , work under exactly the same assumptions and are therefore comparable . 423 Homogeneity in terms of agent ’s performance As the quality of the clustering is given by the qualities of the individual clusters we define the homongeneity of a clustering as the average of the homogeneity of each cluster : hom(C ) =
1 |C| hom(Ci )
( 7 )
Ci⊂C
The homogeneity of the cluster Ci is defined as the average coefficient of variation for the durations recorded for a certain agent = {d(k ) for Tk ∈ and complexity class . Formally , let C ( a)(c ) Ci|a(k ) = a and c(k ) = c} and CV denote the coefficient of variation of C ( a)(c ) Ci as :
. Then , we define the homogeneity of a cluster
( a)(c ) i
C i i
( a)(c ) i
∈Z = ∅} hom(Ci ) =
1 |Z|
C
CV
( a)(c ) C i
( 8 ) where Z = {C ( a)(c ) i
⊆ Ci | C ( a)(c ) i
For the spectral clustering , the results are shown in Figure 12 where we compared the homogeneity in terms of agent ’s performance for the algorithm that uses the combined matrix S to the algorithm ran on the semantic similarity matrix S .
1717 Figure 8 : Number of tickets to move , tickets successfully placed in other clusters and tickets dropped for each delivery unit .
Figure 9 : Speed up in service time for each delivery unit .
Figure 10 : Differences in agent ’s performance in resolving tickets of the same complexity from different clusters .
Figure 11 : Example of agent with skill level “ A" being slower than agent with skill level “ B" .
1718 mendations . In [ 1 ] supervised learning techniques ( SVM ) and a discriminative term based heuristic are used to analyze ticket descriptions and predict the most appropriate resolution group . While we also investigate optimal ticket routing based on ticket descriptions , our focus is not matching the correct resolution group for a given ticket but rather on matching the most cost effective agent to resolve the ticket within a resolution group .
Researchers have also previously looked into clustering alerts and incident tickets [ 16 , 17 ] for both structured and unstructured text using either graph theoretic approaches [ 16 ] or a combination of a latent semantic indexing based technique with a hierarchical n gram based technique [ 17 ] . We have observed that standard text similarity measures as Jaccard used by the authors in [ 16 ] perform poorly when used in clustering tasks due to data sparseness and the lack of context . We differentiate from these approaches by proposing a similarity metric between tickets that tries to overcome the vocabulary mismatch problem , by using semantic similarity between words inferred from a large corpus .
We are not aware of any previous work on ticket clustering that aims at discovering topics with high homogeneity in the agent ’s performance . From a theoretical point of view , the problem we are trying to solve is similar to clustering with multiple graphs . Clustering with multiple graphs aims to fully exploit the links between different dimensions of a given network . While there is a rich body of work in the context of single graph clustering [ 2 , 5 , 12 , 9 , 13 ] the problem of clustering with multiple graphs has gained interest only recently [ 24 , 21 , 28 ] . In [ 24 ] the authors propose a factorization method based on linked matrices to solve the multi graph clustering problem . In this model , each graph is approximated by a graph specific factor with a common factor shared by all the graphs . In [ 21 ] the authors propose two multi graph clustering techniques ( one tailored for unweighted graphs and one that performs well also on weighted graphs ) with the goal of finding well defined clusters across all the views of the graph . In [ 28 ] the authors propose a generalization of normalized cut for multi dimensional graphs . Their model leads to a mixture of Markov chains defined on the different graphs .
We want to identify clusters that persist under different measures . Leskovec et al . have shown in [ 15 ] that strong communities are still identifiable under various measures . We choose to combine the adjacency matrices in one in a way such that the information in the divergence matrix is manifested in the final matrix as pairwise cannot link constraints ( constraints that express that entity i and entity j should be in different clusters ) . Having a single matrix , the problem becomes again a single graph clustering problem which we try to solve employing matrix factorization based clustering algorithms or by iteratively adjusting a fuzzy partitioning .
Work by Leskovec et al . has recently demonstrated that , although different quality measures produce differences in terms of specific communities , strong communities persist under a variety of measures
6 . CONCLUSION
In this paper , we presented a novel approach that optimizes the service time in IT Service Delivery industry . We demonstrated on real data that considering empirical evidence on which agent is the most efficient on resolving certain incident tickets in the dispatching process significantly reduces service time .
We first build a model able to cluster the tickets into categories that both reflect the problem they document and are homogeneous in the duration time for an agent to solve them . Then we devise a data informed dispatching policy that assigns an incoming ticket to the agent that is the fastest in resolving it . Experiments conducted
Figure 12 : Homogeneity of different clustering methods .
We compare these two version to illustrate the homogeneity gain obtained when using the divergence matrix . This also demonstrates that topics alone are not informative enough for estimating the agent ’s performance .
For homogeneity optimized fuzzy k means , the coefficient of variation provided as input will reflect the homogeneity of the final clustering . The minimum values for the coefficient of variation for which no tickets are dropped , for each delivery unit , were given previously in Table 4 . 424 Deployment As mentioned previously , the clustering and dispatching component is designed to be integrated in the IT Service Delivery Environment and a depiction of the elements the component interfaces with is shown in Figure 1 . Our method succeeded in the evaluation phase , demonstrated effectiveness and we work on its deployment . One important aspect that must be noted in deploying the dispatcher is the handling of a new agent . A new agent is assigned a default duration for solving a ticket of a particular topic , more precisely the median duration across agents for solving tasks of that topic . This way we ensure that enough tickets are sent to the new agent and therefore , the system can rapidly estimate the agent ’s actual speed .
Another aspect of the dispatching component is that since it favors the best agent for each ticket category , this may potentially lead to uneven workload distribution . To avoid this , one can adjust the greedy dispatching policy to include some regularization .
The performance gaps between agents need to be continuously reduced . Apart from its utility in the automatic dispatching , our system finds execution differences among agents and can show agent training needs and best practices . It can serve in targeted mentoring for ramp up of skills for new employees which is very useful in a high turn over environment .
5 . RELATED WORK
Several works have previously addressed the possibility of improving the efficiency of ticket routing by mining ticket resolution sequence data or ticket descriptions [ 23 , 1 ] . The authors in [ 23 ] capture the ticket transfer decisions embedded in ticket resolution sequences to develop a model to generate ticket routing recom
1719 on real data from several IBM Service Delivery Units demonstrate the benefits of our approach . More specifically , we compare the data informed dispatching with the non data informed dispatching and observe that the former exhibits 35 % to 44 % reduction in the service time . 7 . REFERENCES [ 1 ] S . Agarwal , R . Sindhgatta , and B . Sengupta . Smartdispatch :
Enabling efficient ticket dispatch in an it service environment . In Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ’12 , pages 1393–1401 , New York , NY , USA , 2012 . ACM .
[ 2 ] C . C . Aggarwal and H . Wang . Managing and Mining Graph
Data . Springer Publishing Company , Incorporated , 1st edition , 2010 .
[ 3 ] J . C . Bezdek . Pattern Recognition with Fuzzy Objective
Function Algorithms . Kluwer Academic Publishers , Norwell , MA , USA , 1981 .
[ 4 ] D . M . Blei , A . Y . Ng , and M . I . Jordan . Latent dirichlet allocation . J . Mach . Learn . Res . , 3:993–1022 , Mar . 2003 .
[ 5 ] Y . Chen , S . Sanghavi , and H . Xu . Clustering sparse graphs .
In F . Pereira , C . Burges , L . Bottou , and K . Weinberger , editors , Advances in Neural Information Processing Systems 25 , pages 2204–2212 . Curran Associates , Inc . , 2012 .
[ 6 ] R . Cilibrasi and P . Vitanyi . The google similarity distance . Knowledge and Data Engineering , IEEE Transactions on , 19(3):370–383 , March 2007 .
[ 7 ] D . Defays . An efficient algorithm for a complete link method . Comput . J . , 20(4):364–366 , 1977 .
[ 8 ] R . El Yaniv and D . Yanay . Supervised learning of semantic relatedness . In P . Flach , T . De Bie , and N . Cristianini , editors , Machine Learning and Knowledge Discovery in Databases , volume 7523 of Lecture Notes in Computer Science , pages 744–759 . Springer Berlin Heidelberg , 2012 .
[ 9 ] A . Gionis , H . Mannila , and P . Tsaparas . Clustering aggregation . ACM Transactions on Knowledge Discovery from Data , 1(1 ) , Mar . 2007 .
[ 10 ] T . H . Haveliwala , A . Gionis , D . Klein , and P . Indyk .
Evaluating strategies for similarity search on the web . In Proceedings of the 11th International Conference on World Wide Web , WWW ’02 , pages 432–442 , New York , NY , USA , 2002 . ACM .
[ 11 ] L . Kaufman and P . J . Rousseeuw . Finding Groups in Data :
An Introduction to Cluster Analysis , pages 1–67 . John Wiley and Sons , Inc . , 2008 .
[ 12 ] J . Kleinberg . An impossibility theorem for clustering . pages
446–453 . MIT Press , 2002 .
[ 13 ] H P Kriegel , P . Kröger , and A . Zimek . Clustering high dimensional data : A survey on subspace clustering , pattern based clustering , and correlation clustering . ACM Trans . Knowl . Discov . Data , 3(1):1:1–1:58 , Mar . 2009 .
[ 14 ] T . K . Landauer , P . W . Foltz , and D . Laham . An introduction to latent semantic analysis . Discourse Processes , 25:259–284 , 1998 .
[ 15 ] J . Leskovec , K . J . Lang , and M . Mahoney . Empirical comparison of algorithms for network community detection . In Proceedings of the 19th International Conference on World Wide Web , WWW ’10 , pages 631–640 , New York , NY , USA , 2010 . ACM .
[ 16 ] D . Lin , R . Raghu , V . Ramamurthy , J . Yu , R . Radhakrishnan , and J . Fernandez . Unveiling clusters of events for alert and incident management in large scale enterprise it . In Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ’14 , pages 1630–1639 , New York , NY , USA , 2014 . ACM .
[ 17 ] S . Mani , K . Sankaranarayanan , V . S . Sinha , and P . Devanbu .
Panning requirement nuggets in stream of software maintenance tickets . In Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering , FSE 2014 , pages 678–688 , New York , NY , USA , 2014 . ACM .
[ 18 ] D . Metzler , S . Dumais , and C . Meek . Similarity measures for short segments of text . In Proceedings of the 29th European Conference on IR Research , ECIR’07 , pages 16–27 , Berlin , Heidelberg , 2007 . Springer Verlag .
[ 19 ] R . Mihalcea , C . Corley , and C . Strapparava . Corpus based and knowledge based measures of text semantic similarity . In Proceedings of the 21st National Conference on Artificial Intelligence Volume 1 , AAAI’06 , pages 775–780 . AAAI Press , 2006 .
[ 20 ] A . Y . Ng , M . I . Jordan , and Y . Weiss . On spectral clustering :
Analysis and an algorithm . In T . Dietterich , S . Becker , and Z . Ghahramani , editors , Advances in Neural Information Processing Systems 14 , pages 849–856 . MIT Press , 2002 .
[ 21 ] E . E . Papalexakis , L . Akoglu , and D . Ience . Do more views of a graph help ? community detection and clustering in multi graphs . In FUSION , pages 899–905 . IEEE , 2013 .
[ 22 ] G . Recchia and M . Jones . More data trumps smarter algorithms : Comparing pointwise mutual information with latent semantic analysis . Behavior Research Methods , 41(3):647–656 , 2009 .
[ 23 ] Q . Shao , Y . Chen , S . Tao , X . Yan , and N . Anerousis . Efficient ticket routing by resolution sequence mining . In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ’08 , pages 605–613 , New York , NY , USA , 2008 . ACM .
[ 24 ] W . Tang , Z . Lu , and I . Dhillon . Clustering with multiple graphs . In Data Mining , 2009 . ICDM ’09 . Ninth IEEE International Conference on , pages 1016–1021 , Dec 2009 .
[ 25 ] K . Toutanova , D . Klein , C . D . Manning , and Y . Singer .
Feature rich part of speech tagging with a cyclic dependency network . In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology Volume 1 , NAACL ’03 , pages 173–180 , Stroudsburg , PA , USA , 2003 . [ 26 ] P . D . Turney . Mining the web for synonyms : Pmi ir versus lsa on toefl . In Proceedings of the 12th European Conference on Machine Learning , EMCL ’01 , pages 491–502 , London , UK , UK , 2001 . Springer Verlag .
[ 27 ] R . B . Wallace and W . Whitt . A staffing algorithm for call centers with skill based routing . Manufacturing & Service Operations Management , 7(4):276–294 , Oct . 2005 . [ 28 ] D . Zhou and C . J . C . Burges . Spectral clustering and transductive learning with multiple views . In Proceedings of the 24th International Conference on Machine Learning , ICML ’07 , pages 1159–1166 , New York , NY , USA , 2007 . ACM .
1720
