Stock Constrained Recommendation in Tmall
Wenliang Zhong
Alibaba Group
Hangzhou , Zhejiang , China yice.zwl@alibaba inc.com
Xiaowei Yan Alibaba Group
Rong Jin
Alibaba Group inc.com Qi Zhang Alibaba Group
Hangzhou , Zhejiang , China xiaowei.yanxw@alibaba
Hangzhou , Zhejiang , China john.zhangq@alibaba inc.com inc.com
Hangzhou , Zhejiang , China jinrong.jr@alibaba
Hangzhou , Zhejiang , China charis.yangc@alibaba
Cheng Yang Alibaba Group inc.com Qiang Li
Alibaba Group
Hangzhou , Zhejiang , China zaikuan@tmall.com
ABSTRACT A large number of recommender systems have been developed to serve users with interesting news , ads , products or other contents . One main limitation with the existing work is that they do not take into account the inventory size of of items to be recommended . As a result , popular items are likely to be out of stock soon as they have been recommended and sold to many users , significantly affecting the impact of recommendation and user experience .
This observation motivates us to develop a novel aware recommender system . It jointly optimizes the recommended items for all users based on both user preference and inventory sizes of different items . It requires solving a non smooth optimization involved estimating a matrix of n× n , where n is the number of items . With the proliferation of items , this approach can quickly become computationally infeasible . We address this challenge by developing a dual method that reduces the number of variables from n2 to n , significantly improving the computational efficiency . We also extend this approach to the online setting , which is particularly important for big promotion events . Our empirical studies based on a real benchmark data with 100 millions of user visits from Tmall verify the effectiveness of the proposed approach .
Categories and Subject Descriptors H10 [ Information Systems Applications ] : Models and Principles General ; I26 [ Artificial Intelligence ] : Learning
General Terms Model,Optimization
Keywords Recommendation ; Tmall ; Online Learning
INTRODUCTION
1 . Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page . Copyrights for components of this work owned by others than the author(s ) must be honored . Abstracting with credit is permitted . To copy otherwise , or republish , to post on servers or to redistribute to lists , requires prior specific permission and/or a fee . Request permissions from Permissions@acmorg KDD’15 , August 10 13 , 2015 , Sydney , NSW , Australia . Copyright is held by the owner/author(s ) . Publication rights licensed to ACM . ACM 978 1 4503 3664 2/15/08 $1500 DOI : http://dxdoiorg/101145/27832582788565 .
Tmall ( wwwtmallcom ) , a business unit of Alibaba group , is the largest third party platform for brands and retailers in China . Since 2008 , it has served more than 100 millions of costumers and 100 thousands of merchants , including a large number of Chinese and international famous brands . According to the public report 1 , the Gross Merchandise Volume ( GMV ) of Tmall exceeds 45 billion dollars in the last quarter of 2014 , and 9 billion dollars for the 11/11 day of 2014 .
In order to help customers find products of interests and improve the chance of making online purchase , online recommendation techniques have been studied and deployed extensively on the Tmall platform , resulting in significant increase in revenue . In this paper , we are focused on the recommendation function on detailed pages , named “ also view ” : before a consumer decides to purchase an item ( ie a product ) from Tmall , he/she will first visit the “ detail page ” of the item that contains information such as title , description and reviews of items . To effectively utilize the traffic to detail pages , “ also view ” recommends to consumers a subset of items that are closely related to the displayed item on the detailed page . Fig 1 shows the detail page of a silk blouse as an example , together with recommended items highlighted by a circle . Many computational approached have been developed to support the recommendation function in literature . For example , click through rate ( CTR ) models have been developed [ 9 , 30 , 15 ] that aim to recommend items with the largest CTRs . Multiple similarity functions have been explored [ 10 , 27 , 28 ] recommend items with the largest similarities to the displayed one . Markov chain or matrix factorization methods [ 22 , 31 , 20 ] have been developed to recommend items with the highest potential for next to buy .
One main limitation of the existing works in e commerce is that they did not take into account the inventory size of items to be recommended . Given the limited number of items stocked by merchants , a naive recommender system could encounter the situation where all/most the recommended items for certain user visits are out of stock , significantly reducing the impact of recommendation . We found that this issue is particularly severe when coming to the big promotion day , in which popular items are often sold out in the first a few hours and as a result , our recommendation system was unable to make appropriate recommendation for many user visits . This observation motivates to develop a stock aware recommender system that select recommended items based on both the user pref
1http://wwwalibabagroupcom/en/global/home
2287 tablished [ 5 , 16 ] . Multiple settings of budget restricted advertising , eg “ unreliable estimation ” and “ random permutation ” , have been proposed and studied in [ 14 , 7 ] . Besides revenue , Karande et al . [ 11 ] develop a system and algorithms for various objectives , such clicks and ad quality . Recently , Agarwal et al . [ 1 ] propose a budget pacing algorithm such that the advertisers may stay on the platform longer before using up their budgets .
Although budget restricted online advertising share similarity with stock aware recommend , the specific approaches developed for online advertising are unsuitable for our problem due to the following reasons
• Most online advertising approaches model the relationship between queries and ads by a bipartite graph , while we examine a more general graph among items , ie item to item recommendation ;
• Most online advertising approaches employ a generalized second price [ 26 ] as a reward , which is absent from our setting ; • A budget constraint is usually related to a large number of queries while each stock constraint corresponds to a unique item . As a result , the computational approaches developed for budget restricted advertising may be too complicated for stock aware recommendation .
3 . STOCK AWARE RECOMMENDATION Let n be the number of items to be purchased online , and each item i ∈ {1 , 2 , . . . , n} is associated with an unique detail page . For each item i , we introduce a tuple {pi , si , fi , ri} to represent its price , its inventory size , its expected traffic flow , and its estimated conversion rate , respectively . In particular ,
• fi ≥ 0 , the expected traffic flow , ie the average number of visits to the detail page of item i from different sources ( e.g web search and online advertisement and etc . ) except for the recommendation from “ also view ”
• ri ∈ [ 0 , 1 ] , the conversion rate , ie the probability for any to purchase the corresponding item after visiting the detail page .
We note that both fi and ri are estimated from the historical data . Let C = ( c1 , c2 , . . . , cn ) ∈ [ 0 , 1]n×n be the CTR matrix , where Ci,j denotes the probability of clicking the ad for item j from the detail page of item i , and can be estimated from the log data . Note that C is usually extremely sparse . Throughout this work , we assume that CTR matrix C is pre computed .
The objective of stock aware recommendation is to revise the CTR matrix C by explicitly taking into the stock information in si as well as other information of items ( ie the price pi , expected traffic flow fi , and conversation rate ri ) . To this end , we introduce the recommendation matrix A = ( a1 , a2 , . . . , an ) ∈ [ 0 , 1]n×n , where Ai,j represents the chance of recommending item j when someone is visiting the detailed page of item i . Our goal is to optimize A , based on C and the stock information of items . 3.1 Recommendation with Stock Constraints Using the introduced notations , the expected sales for item i can be computed as follows : and.(C ◦ A)ffi min fi + si , ri
( 1 ) where C ◦ A is the element wise product between two matrices , i measures the additional number of visits to the f
, i
( C ◦ A )
Figure 1 : An example of detail page and recommendations by “ also view ” . erence and the inventory size of items . The key contributions of this work are :
• To the first of our knowledge , this is the first recommendation work that takes into account the inventory size of items .
• The computational problem requires solving an optimization problem with matrix of size n× n , where n is the number of items . With the proliferation of item intensive applications , this approach will quickly become computationally infeasible . We address this limitation by developing a dual method that reduces the number of variables from n2 to n , significantly improving the computational efficiency . We also extend this approach to the online setting .
• We have successfully deployed the algorithm to the Tmall platform and carry out an experiment with more than 100 millions of user visits .
The rest of this paper is organized as follows . Section 2 gives reviews on recommendation systems and budget constrained advertising methods . Section 3 then describes the proposed model , followed by its online extension . Experimental results are presented in Section 5 , and the last section gives some concluding remarks . Notations : In the sequel , we denote by ‘’ the transpose of vector/matrix , by ‘◦’ the elementwise matrix ( vector ) multiplication and by πΩ the projection onto convex set Ω .
2 . RELATED WORK 2.1 Recommender System
In the past decade , recommender system has been examined extensively in literature [ 3 , 23 ] . Most recommender systems can be classified into four categories , including demographic filtering [ 12 ] , collaborative filtering [ 6 , 24 ] , content based filtering [ 13 , 25 ] and hybrid filtering [ 21 ] . None of these methods take into account the stock condition either on training or recommending stage . 2.2 Online Advertising
Our work is also closely related to online advertising systems [ 1 , 11 , 16 ] . Given a query , the search engine will display proper ads to users based on their relevance scores and the auction result , and advertisers will pay for every click they receive . Once the budget constraints are taken into consideration , the problem becomes similar to ours . Without assuming the distribution of queries , budget restricted advertising can be approximately casted into an online learning problem , and multiple error bounds have been es
2288 j=1 n j=1
.(C ◦ A)ffi detail page of item i via our recommender system . Since fi + i computes the expected traffic , including both the di rect visits and the traffics through recommendation ,
( C ◦ A ) f ri fi + calculates the average number of sales for item i . By taking the minimum value between si and ri pression in ( 1 ) yields the sales for item i that takes into account the stock size . By adding up the expected sales from all items , the total sales is computed as i i
,fi +.(C ◦ A)ffi
( C ◦ A ) fi + f
, the ex
.
R(A ) := pi min si , ri i n i=1
Directly optimizing R(A ) may not be desirable because CTR matrix C , traffic flow fi , and conversation rate ri are estimated from historical data and are therefore noisy when computing A . To alleviate the impact of estimated noise in C , fi and ri , we regularize the solution for A by introducing the entropy function as a regularizer , which is defined for probability vector a as
H(a ) = − n aj log aj .
Combining the objective R(A ) and the regularizer H(a ) , we have the following optimization for stock aware recommendation where parameter β balanced the tradeoff between the objective and the regularizer , and domain Ω is defined as max A∈Ω
R(A ) + β
 Ai,j ≥ 0 , n j=1 Ai,j = 1 , Ai,j = 0 ,
Ω =
 .
∀i , j ∈ {1 , 2 , . . . , n} ∀i ∈ {1 , 2 , . . . , n} if Ci,j = 0 or i = j
The first set of constraints Ai,j ≥ 0 ensures that all elements in A are non negative . The second set of constraints enforces each column vector to be a probability distribution . This follows the fact that the recommendation in one detail page is modeled as a unit resource to be allocated to all other items . The last set of constraints ensures that both A and C share the same sparse pattern , which is very important for reducing computational cost given hundreds of millions of items to be handled in our case . 3.2 Optimization Algorithm
There are two challenges in solving the optimization problem in ( 2 ) . First , the number of variables to be optimized in ( 2 ) is O(n2 ) , making it computationally challenging . Second , the objective function R(A ) is piece wise linear and therefore non smooth in terms of variable A , leading to relatively slow convergence rate . We address the computational challenges by developing a dual formation for ( 2 ) in which the objective function is smooth and the number of variables to be optimized is linear in n . proposition to deal with min(·,· ) .
To develop our dual formation for ( 2 ) , we need the following
PROPOSITION 1 . Given any scalar {a , b} , following equality holds : p min[a , b ] ≡ min κ∈[0,p ]
( p − κ)a + κb . n j=1 n i=1 n j=1
⇒ min 0κp max A∈Ω
−κ g + f
( C ◦ A)(κ ◦ r ) + β fiH(ai ) ( 5 ) where g = s − ( r ◦ f ) and the last step follows the Von Newman lemma . To compute the optimization over A , we use the following lemma .
LEMMA 1 . The optimization problem i=1 ai=1 admits a unique optimal solution min ai≥0,n
−bi exp ai =
β
Z and Z = b − βH(a ) a n i=1 exp
−bi
β
.
The above lemma can be found in the standard literature for convex optimization , eg [ 18 , 29 ] . Using Lemma 1 , it is straightforward to obtain the expression for A in ( 4 ) . Zi is the normalization factor that ensure the sum of each row of A is 1 and is given by
Zi(κ ) =
I(Ci,j > 0 ) exp
κjrjCi,j
.
β
Since Ai,j can be expressed in terms of dual variables κ , for each row i we obtain
Ai,jfiκjrjCi,j + βfiH(ai )
= fi
( Ai,j(κ)κjrjCi,j − βAi,j(κ ) log(Ai,j(κ ) ) max Ai· n n j=1 problem in ( 2 ) as an optimization problem in terms of dual variables κ , as revealed by the following theorem .
THEOREM 1 . The dual problem of ( 2 ) is given by min κp −κ
G(κ ) = n n g + β fi log
I(Ci,j > 0 ) exp i=1 j=1 and the solution to A is given by
Ai,j(κ ) =
I(Ci,j > 0 )
Zi(κ ) exp
κjrjCi,j
β
( 3 )
( 4 )
κjrjCi,j κjrjCi,j
β
. where where I(z ) is an indicator faction that outputs 1 if z is true and zero otherwise , and
Zi(κ ) =
I(Ci,j > 0 ) exp
PROOF . Using the dual variable κ , we rewrite ( 2 ) into convex concave optimization problem max A∈Ω min 0κp
{(pi − κi)si+ i
κiri fi +
( C ◦ A ) f
+ βfiH(ai )
β n n i=1 i=1 fiH(ai ) ,
( 2 )
⇒ max A∈Ω min 0κp
−κ g + f
( C ◦ A)(κ ◦ r ) + β fiH(ai )
Using the above proposition , we introduce dual variables κ = {κ1 , κ2 , . . . , κn} to [ min(·)]s’ in ( 2 ) and rewrite the optimization j=1
= fiβ log(Zi(κ ) )
= fiβ
Ai,j(κ ) log(Zi(κ ) )
2289 Plug above equation into ( 5 ) , we can find the optimal κ by solving the following the optimization problem min κp −κ
G(κ ) = n g + β fi log i=1 j=1 n
κjrjCi,j
β
I(Ci,j > 0 ) exp
Algorithm 1 Accelerated Gradient Descent 1 : Initialization : p = q = 1 , κ0 = κ1 = p 2 : Compute the diagonal Hessian
2 , ηmax = 10000
( 6 ) w =
1 β fi(r ◦ ci).2
3 : for t = 1 , . . . , T do 4 :
Compute auxiliary solution ˆκ as n i=1 n i=1
One nice feature of the dual formulation in ( 6 ) is that its objective function is smooth , making it possible to solve the optimization problem significantly more efficiently than the one in ( 2 ) . This property is revealed by the following theorem .
THEOREM 2 . The optimization problem ( 6 ) is convex and smooth wrt κ . Moreover , the Hessian matrix H(κ)of the objective function is upper bounded by
H(κ ) 1 β fidiag((r ◦ ci).2 ) ,
( 7 ) where diag(v ) denotes a diagonal matrix V with Vi,i = vi and v.2 = ( v2
1 , v2
2 , . . . , v2 n ) is elementwise square for a vector v .
PROOF . To prove the theorem , we need to introduce two useful lemmas .
LEMMA 2 . [ 17 ] The duality of a β strongly convex function 2 is convex and 1
β smooth . result , the negative of ( 2 ) is ( β mini fi) strongly convex , thus its dual(ie ( 6 ) ) is convex and (
) smooth .
1
Now we consider the second part . Noting that the Hessian of
LEMMA 3 .
[ 4 ] The maximum over a set of linear function is convex , ie F(a ) ≡ maxi Fi(a ) is wrt a when Fis’ are linear functions .
It is well known that −H(a ) is a 1 strongly convex wrt norm i=1 fiH(ai ) is also strongly convex as fi ≥ 0,∀i . Moreover,using Lemma 3 we have i
· 1 over the simplex [ 18 , 29 ] , then −n ,fi +.(C ◦ A)ffi the function max.−si,−ri n κjrjCi,j  rj rkCi,j Ci,kAi,j ( κ)Ai,k(κ ) i,j Ai,j ( κ)(1−Ai,j ( κ ) )
I(Ci,j > 0 ) exp is H i with j,k(κ ) =
β mini fi r2 j C2
H i log j=1
β2
β
,
,
β2
fi convex . As a if j = k , otherwise .
5 : 6 : 7 :
8 : 9 :
10 : 11 : 12 : 13 :
˜κt = κt + q(p
−1 − 1)(κt − κt−1 )
Set p = q Compute matrix A(˜κt ) as ( 4 ) Compute the gradient as
∇G(˜κt ) = −g + r ◦
( A(˜κt ) ◦ C ) f
Set η = ηmax Update the solution of κ by
κt+1 i = π[0,pi ]
, i − η[∇G(˜κt)]i
˜κt wi if the inequality ( 8 ) fails to hold then
Set η = η/10 and goto 9 end if Compute q4 + 4q2 − q2
2 q =
14 : end for Return solution A(κT )
Together with the upper bound of Hessian matrix , we have the solution updated from κt to κt+1 by
κt+1 i = π[0,pi ] i − [ ∇G(κt)]i
κt wi where wi =
1 β fj(riCj,i)2 .
This update scheme admits a special case of adaptive gradient descent methods [ 8 ] and has a strong convergence guarantee .
We can further improve the convergence of the above algorithm by exploring the accelerated gradient methods [ 2 , 19 ] . In particular , we introduce a parameter η and auxiliary solution ˜κ into the algorithm , such that n j=1
,
It is easy to show that H i 1 summation over i = 1 , 2 , . . . , n , the conclusion follows .
β2 diag((r ◦ ci).2 ) , and taking the
κt+1 i = π[0,pi ] i − [ ∇G(˜κt)]i
˜κt
Lwi
Finally , since our approach is a first order method In addition , we need to calculate the gradient of G(· ) , which is given as
∇G(κ ) = −g + r ◦
( A(κ ) ◦ C ) f
.
2A function F(a ) is α strongly convex wrt some norm over a compact set S if the following inequality holds for any a , ˜a ∈ S
F(a ) ≥ F ( ˜a ) + ∇F(˜a )
( a − ˜a ) + a − ˜a2 .
β 2
˜κ is a combination of κt and κt+1 . It is introduced to take advantage of the smoothness of the objective function to speed up the convergence . One of the key component of the accelerated gradient descent method is to determine the step size . We follow the Nesterov ’s approach . It starts with a large step size η and gradually reduces it until the following inequality holds
G(κt+1 )
≤ G(˜κ ) + ( κt+1 − ˜κ )
∇G(˜κ ) + n i=1
1 2η wi(κi − ˜κi)2.(8 )
2290 More details are given in Algorithm 1 . Note that since diag(w ) is the upper bound of Hessian , L in Algorithm 1 is lower bounded by 1 . The convergence rate of accelerated gradient descent method is O(1/T 2 ) [ 17 , 19 , 2 ] . It is also known that the Nesterov ’s method achieves the optimal convergence rate for optimizing smooth objective function .
4 . EXTENSION TO ONLINE SETTING
One problem with the offline optimization method presented in the last section is that it relies on the estimated quantities for f and r . It is known that these quantities , despite the best efforts , can not be estimated accurately and reliably . Below , we list two examples that illustrate these quantities can be seriously affected by unpredictable things :
• There is a famous website call “ what are worth to buy ” in China , which recommends economic but popular items to costumers everyday . For items recommended by this website , their traffic flows are dramatically underestimated ;
• Many Tmall sellers run big promotions occasionally ( eg 50+ % discounts and cash coupons ) in order to attract a large number of fresh buyers . As a result , the conversion rate of corresponding items will be significantly changed .
The above observations motivate us to develop an online learning framework for stock aware recommendation that can utilize online information to make better estimation for quantities f and r . But , on the other hand , due to the limited computational resources that are available for online updating , we need to develop efficient updating algorithms that allow us to effectively update the dual variables without having to accurately solve the optimization problem in ( 6 ) .
Let t = 1 , . . . , T be T different time points , and let st , rt , f t and C t be the stock , conversation rate , traffic data , and CTR that are online computed based on the real time user feedbacks . Using the online data st , rt , f t , and C t , the regularized overall sales revenue can be written as min A∈Ω pi min st i , rt i f t i +
( C t ◦ A ) f t i f t i
H(ai )
.
T t=1
+β n n i=1 i=1
T t=1
+β n n i=1 i=1
It is easy to verify that the objective is indeed the same to ( 2 ) in the view of optimization .
Now , instead of using the same solution A over all time points , m ) as the solution at time t , and we introduce At = ( at therefore the objective function becomes
1 , . . . , at min At∈Ω pi min st i , rt i f t i +
( C t ◦ At )
H(at i )
.
Similar to that in Section 3.2 , we rewrite the objective as where Gt(κt ) = −[κt ] gt
+βn n i=1 f t i log j=1 I(C t i,j > 0 ) exp
Gt(κt ) ,
T t=1
κt j rt j Ct i,j β
As a result , we will online update the dual variables , instead of the dual variables , because the number of dual variables is significantly smaller than the number of primal variables .
Our online updating approach is based on the fact that function Gt(κt ) is smooth . In particular , its Hessian H t is upper bound in a similar way :
H t 1 β n n i=1 where L = max matrix . j
1 β i diag((rt ◦ ct f t i).2 ) LI , i=1 f t i ( rt i ◦ C t i,j)2 and I is a proper identity
ˆκt
At the beginning of the t−th time slot , we do not know the true traffic flow f t , rt and C t then have to estimate from the past information . One possible estimation will be
ˆC t = C t−1 , rt = rt−1 , ˆf t = f t−1 , gt = st − ( rt−1 ◦ f t−1 )
Since s , the total inventory stock , is known before hand , we can compute st based on the difference between the consumption and st−1 . Thus , we will assume s1 , . . . , sT are known to the online updating process .
Our algorithm is based on the extra gradient algorithm that was originally developed for smooth objective function . Different from most optimization algorithm , it maintains two sets of solutions , ie real solutions κ1 , κ2 , . . . , κT and auxiliary solution ˆκ1 , ˆκ2 , . . . , ˆκT . We start with some initial solution κ1 = ˆκ1 . At each time point t , we employ {ˆrt , ˆf t , ˆC t} to construct a function ˆGt(ˆκ ) that aims to approximate the function Gt(κ ) . Formally , we define ˆGt as
ˆGt(ˆκt ) = −[ˆκt ]
+βn
ˆgt n
ˆf t i log i=1 j=1 I( ˆC t i,j > 0 ) exp
ˆCt j ˆrt j β i,j
Using ˆGt(· ) , we update the solution κt by
κt = πκ∈ ˜Ω
ˆκt − η∇ ˆGt(ˆκt )
√ where η > 0 is the step size and is often set as 1/
2L and
˜Ω = {κ : 0 κ p}
This computed κt will then be used to compute At(κt ) for recommendation . After time point t , we observe the true quantities rt , f t , C t , and update the auxiliary solution ˆκt by
,ˆκt − η∇Gt(κt) .
ˆκt+1 = π ˆκ∈ ˜Ω
The auxiliary step can be regarded as a calibration ˆGt(· ) .
REMARK 1 . As there may be not enough traffic flow at time t − 1 to estimate an accurate {rt , f t , C t} , one may use a decay update as rt = λrt−1 + ( 1 − λ)˜rt , where ˜rt the true conversion rate at time t . Moreover , we set ˜rt rt−1 i is little . So do f t and C t . if ˜f t i = i
5 . EXPERIMENTAL RESULTS 5.1 Comparison with CTR first Approach
We deployed the Algorithm 1 on wwwTmallcom , and perform experiments on a large volume of real traffic . Our first baseline is the CTR first recommender system that always recommends items with highest Ci,js .
2291 511 Data and Setting
• Training phase : In this experiment , millions of items sold on our platform are taking into consideration , covering more than 10 fashion categories , such as clothing and shoes , electronic and computers , beauty and healthy , etc . Since the “ out of stock ” usually occurs among popular items , we filter out those extremely unpopular goods ( eg the amount of impression is less than 30 in the past month ) . As introduced in Section 3 , the proposed method takes parameter β and {p , s , f , r , C} as input . Price p and inventory size s are provided by sellers and stored in our system . The expected traffic flow f is computed by taking the average of the impressions in the past week while the conversion rate r is the average number over last month . Estimation of the CTR C could be computationally demanding , as it needs to estimate for n2 pairs variables , which is larger than 1 , 000 , 000 , 000 , 000 in our case . Since the observed data is far beyond enough for a full approximation , only the top 50 CTRs from the same shop are considered for each item . This finally leads to a block diagonal and sparse matrix C , with O(108 ) non zero elements . To choose a proper β , an off line tuning stage is carried out on a relative small data set with millions impressions and thousands items . Training is performed at the begging of everyday , and the resulted model is used for testing . • Testing phase : The online status can be quite complex and fluctuates significantly from day to day . For example , the user behavior on work days may vary a lot compared with that on weekend . And the promotion and advertisement may also affect the result , not to mentioned the modification of price and stock condition during our experimental period . To get a reliable result , around 10 millions of registered users are randomly divided into two groups : one will be severed with the CTR first algorithm while the proposed method for the other group . Roughly speaking , for every result reported below , it is calculated based on at least 1 million impressions . • Measurements : The proposed method is designed to maximize the sale revenue while the baseline method is in favor of CTR . To have a fair evaluation , we trace both the revenues and the numbers of clicks on the recommended items for one week . Namely , only the impressions induced by the recommender system and its following actions will be counted for comparison . We then scale the numbers such that the CTRfirst method always receives a unit of click or revenue at the end of each day . In this way , the improvements made by the proposed method is more obvious to observe .
512 Results We first report the result for all item as a whole and then zoom in on four representative categories to see more details .
• Overall Comparison : Figure 2 shows the comparison in terms of clicks . The vertical axis represents the ( scaled ) number of clicks while the horizontal one represents the running time ( hours ) . Since only a small portion of costumers logs in Tmall.com during 00:00 − 08:00 , the gap between two models is small , while it stably increases after eight O’clock . As expected , the CTR first method ( red curve ) outperforms the proposed method by 14 % on average under in terms of clicks ( see Table 1 ) . On the other hand , opposite results are observed when coming to revenue , ie the proposed stock aware recommendation method is leading the CTRfirst method by 16 % , indicating it results in more deals even with fewer clicks . Moreover , we observe that the improvement in revenue is closely related to the loss in clicks : according to Figure 5(h ) , 2(f ) , 3(d ) and 3(f ) , the larger the gap in clicks the bigger the improvement in revenue is also greater ( see Figure 3(d ) and Figure 3(f) ) .
• Comparison across different categories : Another interesting question is whether the improvement in revenue is consistent across different categories . The answers lie in Figure 4 , where each point corresponds to a ratio between two models in revenue . As can be seen , though overall the proposed model enjoys better revenue than the CTR first method , the improves fluctuate in a wide range . Take the category “ electronics and computer ” as example . The improvement can be as high as 80 % for some day . On the other hand , the result for “ clothing and shoes ” is fairly stable over different days . As to the “ Furniture and Decoration ” , negative optimization can take place , reminding us training different models for various categories may be necessary .
Table 1 : Performance wrt “ Scaled #clicks ” and “ Scaled sales revenue ” at the end of each day .
Day
Monday Tuesday Wednesday Thursday Friday Saturday Sunday
1 1 1 1 1 1 1
Scaled #clicks
Scaled sales revenue CTR first Our Batch CTR first Our Batch 1.121998 1.136914 1.164695 1.162689 1.137332 1.230340 1.143656
0.898201 0.906122 0.908609 0.748895 0.921550 0.725727 0.887555
1 1 1 1 1 1 1
Improvement
14.33 %
15.76 %
5.2 Comparison with CTR*CVR Approach
Since considering the conversion rate ( CVR ) may help the improvement of sale revenue , our second baseline is the CTR*CVR approach . The experimental setting is identical to that in Section 51 Due to the space limitation , we only report results of four days . As can be seen in Figure 5 , the proposed stock aware recommendation system outperforms the CTR*CVR method in terms of both the number of clicks and the sales revenue in all cases , where the overall improvements for clicks and revenue are 11.31 % and 12.48 % , respectively . This result indicates that the proposed approach is more effective than a simple CTR*CVR based method in making the tradeoff between CTR and revenue . 5.3 Evaluation for the Online Setting
Due to engineering issues , we don’t have the evaluation result for the proposed online algorithm with live traffic . Instead , we demonstrate the effectiveness of online stock aware recommendation using synthetic data sets with 100 items that are generated as follows : price p , the inventory size s and conversion rates r are generated by sampling numbers from a uniform distribution while traffic flows f and CTR matrix C are created by sampling numbers from Gaussian distributions . The parameter β is manually chosen to maximize the performance .
At the prediction stage , a stream of customers ( as the traffic flow f but in random order ) arrives and takes actions following param
2292 ( a ) Monday .
( b ) Tuesday .
( c ) Wednesday .
( d ) Thursday .
( e ) Firday .
( f ) Saturday .
( g ) Sunday .
Figure 2 : Scaled amount of clicks versus running time on seven consecutive days .
( a ) Monday .
( b ) Tuesday .
( c ) Wednesday .
( d ) Thursday .
( e ) Friday .
( f ) Saturday .
( g ) Sunday .
Figure 3 : Scaled sales revenue versus running time on seven consecutive days .
( a ) Electronic and Computers .
( b ) Clothing and Shoes .
( c ) Furniture and Decoration .
( d ) Beauty and Care .
Figure 4 : Performance versus running time in different categories .
2293 ( a ) Monday .
( b ) Tuesday .
( c ) Wednesday .
( d ) Thursday .
( e ) Monday .
( f ) Tuesday .
( g ) Wednesday .
( h ) Thursday .
Figure 5 : Comparison with CTR*CVR approach . Upper:Scaled amount of clicks . Bottom : Scaled sales revenue . eters {p , s , r , C} . The sales revenue is then recorded as performance measure . Since the main motivation of online algorithm is to catch the changes in traffic flow and conversion rate 3 , we modify f and r before testing as following .
• Adding traffic flow with mean ∆f to a few items ( to simulate looming costumers for suddenly hot items ) ;
• Increase the conversion rate with mean ∆r of a few items ( to simulate discounts/coupons ) ;
• Modification of both above at the same time . The online algorithm uses its batch counterpart as an initial solution , and updates the dual solutions based on the procedure described in Section 4 . To reduce the impact of variance , all the experiments are repeated for 10 times . Average results are shown in Figure 6 . We observe the results that are consistent with the ones reported in the previous subsections : the CTR*CVR method performs slightly better than the CTR first method in terms of sales revenue , while the proposed batch learning algorithm outperforms both methods , particularly when the number of impression is sufficiently large . It is not surprising to observe that the proposed online learning method yields the best performance since it can catch the change in information and therefore is most sensitive to the case of out of stock . The advantage of the proposed online learning algorithm is further illustrated in Figure 7 where we show the number of out of stock views . We clearly observe that the online learning algorithm yields the smallest number of out of stock views . It is slightly to our surprise that the CTR*CVR performs even worse than CTR first in terms of out of stock views .
6 . CONCLUSION
In this paper , we propose a stock aware recommender system in e commerce and extend it to online setting . The key idea is to optimize the recommendation selection for individual users based on both user preference and the limit of stock supply . We deploy 3The CTR of “ click ads of item j in the detail page of item i ” is relative stable , so we keep it as constant here . this system to Tmall.com , the Chinese largest B2C platform , and verify the effectiveness of our approach using the live traffic from Tmall . Experiments with more than 100 million use visits shows that the proposed method can significantly improve the sales revenue of item to item recommendation . In the future , we will continue working on the online setting for stock aware recommendation and verify its effectiveness using the real traffic from Tmall .
7 . ACKNOWLEDGEMENTS
Our research was partially supported by Tianchi Research platform "http://tianchialiyuncom/" We thank the reviewers for very detailed and valuable comments .
References [ 1 ] D . Agarwal , S . Ghosh , K . Wei , and S . You . Budget pacing for targeted online advertisements at linkedin . In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 1613–1619 . ACM , 2014 .
[ 2 ] A . Beck and M . Teboulle . A fast iterative shrinkagethresholding algorithm for linear inverse problems . SIAM Journal on Imaging Sciences , 2(1):183–202 , 2009 .
[ 3 ] J . Bobadilla , F . Ortega , A . Hernando , and A . Gutiérrez . Recommender systems survey . Knowledge Based Systems , 46:109–132 , 2013 .
[ 4 ] S . Boyd and L . Vandenberghe . Convex optimization . Cam bridge Univ Pr , 2004 .
[ 5 ] N . Buchbinder , K . Jain , and J . S . Naor . Online primal dual algorithms for maximizing ad auctions revenue . In Algorithms– ESA 2007 , pages 253–264 . Springer , 2007 .
[ 6 ] L . Candillier , F . Meyer , and M . Boullé . Comparing stateof the art collaborative filtering systems . In Machine Learning and Data Mining in Pattern Recognition , pages 548–562 . Springer , 2007 .
2294 ( a ) ∆f = 025f
( b ) ∆f = 05f
( c ) ∆f = 075f
( d ) ∆f = f .
( e ) ∆r = 05r
( f ) ∆r = r .
( g ) ∆r = 15r
( h ) ∆r = 2r .
( i ) ∆f = 0.25f , ∆r = 05r
( j ) ∆f = 0.5f , ∆r = r .
( k ) ∆f = 0.75f , ∆r = 15r
( l ) ∆f = f , ∆r = 2r .
Figure 6 : Revenue versus number of impressions in online setting .
( a ) ∆f = 025f
( b ) ∆f = 05f
( c ) ∆f = 075f
( d ) ∆f = f .
( e ) ∆r = 05r
( f ) ∆r = r .
( g ) ∆r = 15r
( h ) ∆r = 2r .
( i ) ∆f = 0.25f , ∆r = 05r
( j ) ∆f = 0.5f , ∆r = r .
( k ) ∆f = 0.75f , ∆r = 15r
( l ) ∆f = f , ∆r = 2r .
Figure 7 : Number of out of stock views versus number of impressions in online setting .
2295 [ 7 ] N . R . Devanur and T . P . Hayes . The adwords problem : online keyword matching with budgeted bidders under random permutations . In Proceedings of the 10th ACM conference on Electronic commerce , pages 71–78 . ACM , 2009 .
[ 22 ] S . Rendle , C . Freudenthaler , and L . Schmidt Thieme . Factorizing personalized markov chains for next basket recommendation . In Proceedings of the 19th international conference on World wide web , pages 811–820 . ACM , 2010 .
[ 23 ] A . Said and A . Bellogín . Comparative recommender system evaluation : benchmarking recommendation frameworks . In Proceedings of the 8th ACM Conference on Recommender systems , pages 129–136 . ACM , 2014 .
[ 24 ] X . Su and T . M . Khoshgoftaar . A survey of collaborative filtering techniques . Advances in artificial intelligence , 2009:4 , 2009 .
[ 25 ] R . Van Meteren and M . Van Someren . Using content based filtering for recommendation . In Proceedings of the Machine Learning in the New Information Age : MLnet/ECML2000 Workshop , pages 47–56 , 2000 .
[ 26 ] H . R . Varian . Position auctions . international Journal of in dustrial Organization , 25(6):1163–1178 , 2007 .
[ 27 ] W . Wu , H . Li , and J . Xu . Learning query and document similarities from click through bipartite graph with metadata . In Proceedings of the sixth ACM international conference on Web search and data mining , pages 687–696 . ACM , 2013 .
[ 28 ] W . Wu , Z . Lu , and H . Li . Learning bilinear model for matching queries and documents . The Journal of Machine Learning Research , 14(1):2519–2548 , 2013 .
[ 29 ] L . Xiao . Dual averaging methods for regularized stochastic learning and online optimization . Journal of Machine Learning Research , 11:2543–2596 , 2010 .
[ 30 ] C . Xiong , T . Wang , W . Ding , Y . Shen , and T Y Liu . Relational click prediction for sponsored search . In Proceedings of the Fifth ACM International Conference on Web Search and Data Mining , WSDM ’12 , pages 493–502 , New York , NY , USA , 2012 . ACM .
[ 31 ] G E Yap , X L Li , and S . Y . Philip . Effective next items recommendation via personalized sequential pattern mining . In Database Systems for Advanced Applications , pages 48– 64 . Springer , 2012 .
[ 8 ] J . Duchi , E . Hazan , and Y . Singer . Adaptive subgradient methods for online learning and stochastic optimization . Manuscript , 2010 .
[ 9 ] T . Graepel , J . Q . Candela , T . Borchert , and R . Herbrich . Web scale bayesian click through rate prediction for sponsored search advertising in microsoft ’s bing search engine . In Proceedings of the 27th International Conference on Machine Learning , pages 13–20 , 2010 .
[ 10 ] T . Hofmann . Learning the similarity of documents : An information geometric approach to document retrieval and categorization . In Advances in Neural Information Processing Systems 13 . Citeseer , 2000 .
[ 11 ] C . Karande , A . Mehta , and R . Srikant . Optimizing budget In Proceedings of constrained spend in search advertising . the sixth ACM international conference on Web search and data mining , pages 697–706 . ACM , 2013 .
[ 12 ] B . Krulwich . Lifestyle finder : Intelligent user profiling using large scale demographic data . AI magazine , 18(2):37 , 1997 .
[ 13 ] N . Landia and S . Anand . Personalised tag recommendation . pages 83–86 , 2009 .
[ 14 ] M . Mahdian , H . Nazerzadeh , and A . Saberi . Allocating onIn Proline advertisement space with unreliable estimates . ceedings of the 8th ACM conference on Electronic commerce , pages 288–294 . ACM , 2007 .
[ 15 ] H . B . McMahan , G . Holt , D . Sculley , M . Young , D . Ebner , J . Grady , L . Nie , T . Phillips , E . Davydov , D . Golovin , et al . Ad click prediction : a view from the trenches . In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining , 2013 .
[ 16 ] A . Mehta , A . Saberi , U . Vazirani , and V . Vazirani . Adwords and generalized online matching . Journal of the ACM , 54(5):22 , 2007 .
[ 17 ] Y . Nesterov . Introductory lectures on convex optimization : A basic course . Springer Netherlands , 2004 .
[ 18 ] Y . Nesterov . Smooth minimization of non smooth functions .
Mathematical Programming , 103(1):127–152 , 2005 .
[ 19 ] Y . Nesterov . Gradient methods for minimizing composite objective function . Technical Report 76 , Catholic University of Louvain , 2007 .
[ 20 ] M . Nickel , V . Tresp , and H P Kriegel . Factorizing yago : Scalable machine learning for linked data . In Proceedings of the 21st International Conference on World Wide Web , WWW ’12 , pages 271–280 , New York , NY , USA , 2012 . ACM .
[ 21 ] C . Porcel , A . Tejeda Lorente , M . Martínez , and E . HerreraViedma . A hybrid recommender system for the selective dissemination of research resources in a technology transfer office . Information Sciences , 184(1):1–19 , 2012 .
2296
