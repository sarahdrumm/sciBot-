Hierarchical Graph Coupled HMMs for Heterogeneous
Personalized Health Data
Kai Fan
Computational Biology &
Bioinformatics , Duke
University
Durham , NC 27708 kaifan@dukeedu
Marisa Eisenberg
University of Michigan School of Public Health , Ann Arbor marisae@umich.edu
Ann Arbor , MI 48109
Alison Walsh
University of Michigan School of Public Health , Ann Arbor aliwalsh@gmail.com
Ann Arbor , MI 48109
Allison Aiello
Gillings School of Global Public Health , University of North Carolina Chapel Hill
Chapel Hill , NC 27599 aaiello@unc.edu
Katherine Heller
Department of Statistical Science , Duke University kheller@statdukeedu
Durham , NC 27708
ABSTRACT The purpose of this study is to leverage modern technology ( mobile or web apps ) to enrich epidemiology data and infer the transmission of disease . We develop hierarchical Graph Coupled Hidden Markov Models ( hGCHMMs ) to simultaneously track the spread of infection in a small cell phone community and capture personspecific infection parameters by leveraging a link prior that incorporates additional covariates . In this paper we investigate two link functions , the beta exponential link and sigmoid link , both of which allow the development of a principled Bayesian hierarchical framework for disease transmission . The results of our model allow us to predict the probability of infection for each persons on each day , and also to infer personal physical vulnerability and the relevant association with covariates . We demonstrate our approach theoretically and experimentally on both simulation data and real epidemiological records . Categories and Subject Descriptors J.3 [ Computer Applications ] : LIFE AND MEDICAL SCIENCES— Health ; I21 [ Computing Methodologies ] : ARTIFICIAL INTELLIGENCE—Applications and Expert Systems : Medicine and science
Keywords Dynamic Bayesian Modeling ; Social Networks ; Heterogenous Infection ; burn in Gibbs EM 1 .
INTRODUCTION
Recently , much emphasis has been placed on personalized medical treatment and advice , encouraging prediction of disease on an individual level . However , the majority of research on detecting patterns in and discovering the risks of infectious disease has been at the population level . The purpose of this paper is to use population data from social networks to develop individualized predictions for infectious disease risk and transmission .
Social network data at the population levels provides a framework for identifying interactions and transmission and has been used to populate complex systematic models and individual level risk models . [ 6 ] utilized fixed social network analysis on susceptibleinfectious recovered ( SIR ) models to identify high risk individuals . [ 20 ] ’s work on close proximity interactions ( CPIs ) of dynamic social networks at a high school indicated immunization strategies is more credible if extra contact network data were provided .
However , the preponderance of available social network data relies primarily on reported network connections , resulting in a missing data problem and reducing the robustness of inferences that can be made with this data . In this study , we sought to overcome these problems by utilizing a novel cell phone bluetooth network contact app to infer dynamic social network interaction , infection probability and transmission . Location and time based information from this app allow us to track personal daily contacts between participants . Proximity can be measured by the contact duration within a certain range . Similar social experiments have been conducted and mentioned in [ 1 , 9 , 8 ] , but these prior models assumed homogeneous individuals or global parameter sharing within the networks , and did not include data on potential modifying factors , such as personal health habits and demographic features of individuals in the network .
The intuition of hierarchies to improve model flexibility is extensively studied in topic modeling , in models such as latent Dirichlet allocation ( LDA ) [ 5 , 2 , 17 ] . [ 5 ] used a sigmoid link function , introduced in Relational Topic Model to learn fixed networks of documents . These , and further works have exemplified a trend in data driven machine learning applications – hierarchical modeling applied in order to infer complex data structure . Our work can be considered as a hierarchical extension of either GCHMMs [ 9 ] or topic HMMs [ 11 ] with a nested transition function .
The main contribution of this paper is to characterize personspecific infection parameters under a covariate dependent hierarchical structure on GCHMMs . Our link function is associated with covariates referring to personal features , such as gender , weight ,
239 x1,t−1 x1,t x1,t+1 y1,t−1 x2,t−1 y2,t−1 y3,t−1 y3,t−1 y1,t y1,t+1 x2,t y2,t x3,t y3,t
1
2
3 x2,t+1 y2,t+1 x3,t+1 y3,t+1
Gt−1
3
Gt
3
1
2
1
2 n ∈ [ N ] t ∈ [ T ] s ∈ [ S ] zn
Gt−1 γ(γn ) α(αn ) β(βn )
ξ xn,t ∈ X = {0 , 1} yn,t ∈ Y = {0 , 1}S
θxn,t,s
Notations index for participants index for timestamp index for symptoms of observation covariates indicating personal features dynamic social networks between t − 1 and t recovery probability if infectious at pervious timestamp probability being infected from some one outside networks probability being infected from some one inside networks infection probability of initial hidden state xn,1 latent variable indicates whether infection reported symptoms during each time interval emission probability of symptom s onset given xn,t and Et is a set of undirected edges in Gt , where ( ni , nj ) ∈ Et if two participants ni and nj have a valid contact between time t and t + 1 . The generative model of GCHMMs is then defined in a fully bayesian way ( Notations in above Table ) .
Figure 1 : Illustration of GCHMMs including 3 people . 1 and 3 have social contact between t − 1 and t . The infection states of 1 and 3 at t are then both influenced by each others’ infection states at time t − 1 . hygiene habits , and diet habits , with the hypothesis that better personal hygiene , diet , and lower weight , should be result in lower susceptibility to influenza . However , it is difficult to choose an appropriate link function or distribution to obtain a conjugate prior for inference . Our proposed link function can be easily generalized to Dirichlet exponential or softmax link . Inspired by [ 7 ] , a burnin Gibbs sampling Expectation Maximization ( bGEM ) algorithm is developed for parameter estimation in hGCHMMs , and additional infection network inference simultaneously . Specifically , a faster version of our EM algorithm when binary latent variables are appropriate is primarily used for our experimental tests , which significantly accelerates the computational speed without a significant impact on accuracy . In the case of unavailable covariates , our model is easily reduced to a no link version by simply inferring each infection parameter from a common prior , the same as in standard GCHMMs .
The rest of the paper is organized as follows . In Sec 2 , we describe the basic idea of GCHMMs and our proposed hGCHMMs , explicitly discussing the two different link schemes . In Sec 3 , we show how to modify the EM algorithm for a burn in Gibbs sampling version . In Sec 4 , we report empirical results by implementing our algorithm and applying it to synthetic and real world datasets . Conclusions and future research directions are discussed in Sec 5 .
2 . GENERATIVE MODELING
We first briefly introduce the standard graph coupled hidden Markov model ( GCHMM ) ( evolving from coupled hidden Markov model [ 3] ) , a dynamic model for analyzing the discrete time series data by leveraging the interactions of a non fixed social network ( see Figure 1 for an example , where filled in nodes are observed ) . 2.1 Graph Coupled Hidden Markov Models Let Gt = ( N , Et ) be a network structure at time t , where each agent or participant is represented by a node n ∈ N in graph Gt ,
ξ ∼ Beta(aξ , bξ ) α ∼ Beta(aα , bα ) β ∼ Beta(aβ , bβ ) γ ∼ Beta(aγ , bγ ) θ1,s ∼ Beta(a1 , b1 )
θ0,s ∼ Beta(a0 , b0 ) xn,0 ∼ Bernoulli(ξ ) xn,t ∼ Bernoulli,φn,xn :(n,n)∈Gt ( α , β , γ ) yn,t,s ∼ Bernoulli(θxn,t,s )
( 1 ) where the transition probability φn,xn :(n,n)∈Gt ( α , β , γ ) is a function of the infection parameters and the dynamic graph structure . Figure 1 also indicates that the transition of the hidden state is not only dependent on the previous state of its own HMM but also influenced by states from other HMMs that have edges connected to it . One undirected edge in Gt indicates a valid contact in time interval [ t , t + 1 ] , thus leading to a directed edge in GCHMMs . Recalling the definition in terms of γ , α , β , we have the transition probability as follows :
φn,xn :(n,n)∈Gt ( γ , α , β ) =

γ
1 − γ xn,t = 1 , xn,t+1 = 0 ; xn,t = 1 , xn,t+1 = 1 ; 1 − ( 1 − α)(1 − β)Cn,t xn,t = 0 , xn,t+1 = 1 ; ( 1 − α)(1 − β)Cn,t xn,t = 0 , xn,t+1 = 0 .
( 2 )
I{xn ,t=1} is the count of possible inwhere Cn,tsumn:(n,n)∈Et fectious sources for node n in Gt , and I{} is the indicator function . This Bayesian formulation of the GCHMMs can be applied to fit homogenous susceptible infectious susceptible ( SIS ) epidemic dynamics . Next we will generalize this basic model for other related purposes by leveraging hierarchical structure and the relevant covariates . 2.2 Extending GCHMMs to Hierarchies It is assumed that personal health features ( covariates ) are present , as well as the observed symptoms , denoted as zn ∈ RK , where K is the dimension of the covariate feature space . Without loss of generalization , the feature space includes a default feature being constant at 1 . An appropriate mapping f : RK → [ 0 , 1 ] or transformation from the feature space to infection parameters is necessarily introduced to construct a correlation between personal condition and vulnerability , ( see Figure 2 , notice that node Gt is shared by rectangle template of each person , thus being represented by partially intersection ) . In this section , we propose two link function
240 γn , αn , βn zn h
θX xn,t−1 xn,t xn,t+1
η yn,t−1 yn,t yn,t+1
N
Gt−1
Gt
Figure 2 : Template Representation of hGCHMM : The graphical model renders a clear structure visualization on the dependence between all variables and parameters . constructions . A natural way to go is to extend the beta prior of the standard GCHMM to a beta exponential link .
Beta exponential link
η·,· ∼ N ( µ , Σ ) γn ∼ Beta(exp(z n ηr,1 ) , exp(z n ηr,2 ) ) αn ∼ Beta(exp(z n ηa,1 ) , exp(z n ηa,2 ) ) βn ∼ Beta(exp(z n ηb,1 ) , exp(z n ηb,2 ) )
1 where η·,· is distributed as multivariate Gaussian playing the role of the regression coefficients , since the expectation n ( η·,1−η·,2 ) can be considered as an approximation for logistic regression with coefficients −(η·,1 − η·,2 ) . This link also enables the exponential term exp(z n η·,· ) to take the place of the hyper parameter of beta prior . The usual count update to the hyper parameter will implicitly update η via our EM algorithm .
1+ez
Once γ , α , β are allowed to be indexed by n , the arguments in Equation ( 2 ) need index modification , but the other terms remain the same . We put an individual level distribution on transition but not on emission because it makes more sense that everyone has the same probability of physical behavior given an infection state . Patients should have corresponding symptoms , such as cough or throat pain , or the flu cannot be discovered or diagnosed . The advantage of this setting is that it allows for the Gibbs sampling of infection parameters in a way that still holds from previous models , except for η , so that the original Gibbs sampling scheme to update the beta distribution by event counts is the same in the later E step . Another advantage is , when X is generalized to categorical variables , a similar construction also works . Furthermore , rather than do approximate logistic regression , we next propose a real logistic regression link . Sigmoid link
η· ∼ N ( µ , Σ ) γn = σ(z n ηr ) , αn = σ(z n ηa ) ,
βn = σ(z n ηb ) where σ(x ) = 1
1+e−x is the sigmoid function .
In the generative process of infection parameters , less ηs are present , thus leading to a simpler model . Instead of sampling , the equations for γ , α , β will actually make these parameters vanish in the model . In other words , φn,xn :(n,n)∈Gt ( γn , αn , βn ) is replaced by φn,xn :(n,n)∈Gt ( zn , η· , σ(·) ) . From an implementation perspective , the EM derivation will be easier , and the experimental n)N results imply its outperformance of competing methods . Additionally , this link function inspires another two step model : first , the infection parameters in Equation ( 1 ) are enforced to be individually indexed by n , and the inference process is run in a similar Gibbs sampling scheme [ 9 ] ; second , a standard logistic regression is fit between the learned individual parameters and covariates Z . n ηr,1 , ez n , γf n , since γf
Remark ( 1 ) The beta exponential generative model is not well defined for one time step data simulation , because we need a unique sample from this generative model , which actually uses a set of n=1 to sample X and Y . Take γn fixed parameters ( αf n , βf for example , E(γn ) = γf n is one realization of the generative model . What our algorithm aims to learn is a generative distribution Beta(ez n ηr,2 ) , with expectation equal to γf n , not E(γn ) . ( 2 ) Therefore , our simulation dataset is always generated from the sigmoid link model . However , it is reasonable to use the beta exponential link model for inference to eliminate the inconsistency . It has been mentioned previously the expectation of beta exponential is virtually an approximation logistic regression . An EM like algorithm can perform a good point estimation for this expectation , which in turn would be an estimator of the sigmoid link . ( 3 ) Another way to make the beta exponential generative and the inference process work is to sample αn , βn , γn both individually and dynamically , ie γn,t , αn,t , βn,t . A number of realizations are sufficient to learn the true generative distribution , though the new inference algorithm will necessarily become more difficult .
Another interpretation of βn In above two extensions , it is implicitly assumed that βn means the individual infection probability from another person within the network , is as given in Equation ( 3 ) . From the biological side , the contagiousness of the infected person varies , meaning that βn can be interpreted as the probability of spreading illness to any other person in the social network . This interpretation results in a slightly complicated mathematical calculation ( details in EM algorithm section ) , since both the total count of infectious contacts and specific diffusion sources are required for Equation ( 4 ) . P ( xn,t+1 = 1|xn,t = 0 ) = 1 − ( 1 − αn)(1 − βn)Cn,t P ( xn,t+1 = 1|xn,t = 0 ) = 1 − ( 1 − αn )
( 3 ) ( 1 − βn ) ( 4 ) n∈Sn,t where the nodes set of infection contacts is defined as Sn,t = {n ∈ [ N ] : ( n , n ) ∈ Et , xn,t = 1} . 3 . 3.1 Approximate Conjugate for Beta exponential
INFERENCE link
The inference process is designed to invert the generative model and to discover the η and X that best explain G and Y . In our hierarchical extension , however , a fully conjugate prior is not present and it has been mentioned that knowing what the right prior is can be difficult . Thus an approximate conjugate is developed by introducing the auxiliary variable Rn,t , representing the non specific infection source ( inside or outside networks ) . The idea is to decompose infection probability 1− ( 1− αn)(1− βn)Cn,t into the summation of three terms , αn(1−βn)Cn,t , ( 1−αn)(1−(1−βn)Cn,t ) and αn(1−(1−βn)Cn,t ) , indicating infection from outside , inside and both respectively . Rn,t follows categorical distribution :

P ( Rn,t ) =
αn(1−βn)Cn,t
1−(1−αn)(1−βn)Cn,t , ( 1−αn)(1−(1−βn)Cn,t ) 1−(1−αn)(1−βn)Cn,t , α(1−(1−βn)Cn,t ) 1−(1−αn)(1−βn)Cn,t , if Rn,t = 1 if Rn,t = 2
( 5 ) if Rn,t = 3
241 The exact distribution of Rn,t is still difficult to use . Thus by taylor expansion we have P ( Rn,t = 2)P ( xn,t+1 = 1|xn,t = 0 ) ≈ Cn,t(1 − αn)βn and P ( Rn,t = 3)P ( xn,t+1 = 1|xn,t = 0 ) ≈ Cn,tαnβn . The two approximations attain the fact that local full conditionals can be analytically obtained by discarding η temporarily . In practice the term involving P ( Rn,t = 3 ) can be approximated as 0 for Gibbs sampling . Because of the biological application , αn and βn are both the positive real value close to 0 , resulting in their product being quite small . Even if this probability is taken into consideration in the Gibbs sampling , there is a very small chance that Rn,t = 3 . This approximation allows the posterior distribution of αn , βn to be much easier to compute given the current value of η . Concretely , we have the following posteriors , which will benefit the EM algorithm described later : n ηa,1 + Cn,Rn=1,3 , ez ez αn ∼ Beta n ηb,1 + Cn,Rn=2,3 , ez ez βn ∼ Beta n ηr,1 + Cn,1→0 , ez γn ∼ Beta(ez n ηb,2 + Cn,R=2,3 n ηr,2 + Cn,1→1 ) n ηa,2 + Cn,Rn=2 + Cn,0→0
Cn,i→j = Cn,Rn=1,3 = Cn,Rn=2,3 = Cn,R=2,3 = t where the count notations are defined as follows . I{xn,t=i,xn,t+1=j} , i , j ∈ {0 , 1}
I{Rn,t=1,3} ≈ Cn,Rn=1 = I{Rn,t=2,3} ≈ Cn,Rn=2 = .I{Rn,t=1} + I{xn,t=0,xn,t+1=0}fi
I{Rn,t=1} I{Rn,t=2} t t t t Cn,t t
Note that auxiliary variable R did not appear in the posterior of γn , which is exactly computed due to conjugacy . Utilizing these approximate posteriors , the complete likelihood P ( X , R , η|Z ) is obtained by integrating out the infection parameters .
P ( R|X , α , β)P ( X|γ , α , β)P ( γ , α , β|η , Z)P ( η)dγdαdβ
=P ( η ) n ηr,1 + Cn,1→0 , ez n ηr,1 , ez
B(ez n
B(ez n ηa,1 + Cn,Rn=1,3 , ez · B(ez · B(ez n ηb,1 + Cn,Rn=2,3 , eZ n ηb,1 , ez
B(ez
B(ez n ηa,1 , ez n ηa,2 ) n ηr,2 + Cn,1→1 ) n ηr,2 ) n ηa,2 + Cn,Rn=2 + Cn,0→0 ) n ηb,2 + Cn,R=2,3 ) n ηb,2 )
( 6 ) where B(· ) is beta function , and P ( η ) is a multinomial Gaussian distribution . The integral result enables the analytical computation of the gradient ∇η and Hessian ∂2 of the log likelihood , then contributing to Newton ’s method . 3.2 Gibbs Sampling for Conjugate Part
Sampling Infection States Given all αn , βn , γn , the generative model implies a conjugate prior for xn,t . The unnormalized posterior probability of xn,t = i can be represented as pi n,t , i = 0 , 1 .
θ
I ( yn,t,s=1 ) 0,s
I ( 1 − θ0,s )
1 − ( 1 − αn)(1 − βn)Cn,tI
( xn,t+1=1 )
( yn,t,s=0 ) × γ
I ( xn,t−1=1 ) n
( 7 ) p0 n,t ∝ · s
· ( 1 − αn ) ( 1 − βn)Cn,t−1I
I{xn,t−1=0,xn,t+1=0} ( xn,t−1=0)+Cn,tI
( xn,t+1=0 ) p1
I
θ
( yn,t,s=1 ) 1,s n,t ∝ 1 − ( 1 − αn)(1 − βn)Cn,t−1I ·
I ( xn,t+1=0 ) n
· ( 1 − γn )
( 1 − θ1,s )
γ s
I ( yn,t,s=0 )
I{xn,t−1=1,xn,t+1=1}
( xn,t−1=0 )
( 8 ) where the normalized posterior of p(xn,t = 1 ) is . There needs to be some caution of the boundary condition since xn,1 and xn,T do not have this form . xn,1 is generated by xn,1 ∼ Bernoulli(ξ ) , where ξ ∼ Beta(aξ , bξ ) . The full conditional depends on the initial event occurrence rate ξ , further requiring some mild modification . The full conditional of ξ can be computed . n,1 p1n,t p0 n,t+p1
I(xn,1=1 ) , bξ + N − n n
I(xn,1=1 )
ξ|X ∼ Beta aξ +
For state xn,T , the posterior is easily computed since terms associated with t + 1 cancel out immediately .
Sampling Missing Observation For real world data , a missing value problem commonly arises because of underreporting in data collection . Bayesian schemes can successfully fill in missing values by drawing yn,t,s according to the distribution Bernoulli(θxn,t,s ) , if they are NA . Sampling yn,t,i , the posterior of θi,s , ( i = 0 , 1 ) is from a beta distribution . θi,s|X , Y ∼ Beta
I{yn,t,s=1,xn,t=i} , bi ai + n,t
+
I{yn,t,s=0,xn,t=i}
3.3 Burn in Gibbs EM Algorithm n,t
As far as we know , previous works on CHMMs or GCHMMs have not included the sampling scheme for global parameters η . One possible solution is the Metropolis Hastings ( MH ) algorithm due to the approximate likelihood in Equation ( 6 ) ; however , the transition kernel is difficult to choose for MH , and running large numbers of iterations is usually required to achieve good mixing .
In this section , we propose a fast algorithm based on expectationmaximization . Expected sufficient statistics are computationally intractable since there is no closed form in our case . Stochastic Approximation ( SA ) EM [ 7 ] is an alternative introduced to simulate the expectation , and able to obtain convergence to a local minimum with a theoretical guarantee under mild conditions . The basic idea of this computation is using a Monte Carlo sampling approximation ; however , we replace this step with Gibbs sampling by utilizing the approximate conjugacy property . j=1 and {R(j)}J
E step : Sampling {X ( j)}J j=1 follows
αn , βn , γn|Z , η(k−1 )
X|αn , βn , γn , Y R|X , αn , βn , γn , G
( 9 )
The true expectation integration Q(k)(η ) is approximately calculated by a stochastic averaging in a burn in representation ˆQ(k)(η ) , taking advantage of Gibbs sampling with form ( 11 ) . During each Gibbs sampling step , infection parameters are in fact always updated at each inner iteration , thus making the latent variables X , R update based on different posterior distributions at each sampling , which disagrees with SAEM . Therefore the samples at later iterations are closer to the true posterior given current η(k−1 ) . In ordinary SAEM , latent variables are sampled from a fixed posterior , which is the reason why burn in modification is not necessary . From this perspective , the burn in Gibbs sampling in E step may accelerate the convergence rate in the next maximization step .
242 M step : Maximize with respect to η , ie arg max ˆQ(k)(η ) . However , directly optimizing ˆQ(k)(η ) will suffer from the same drawback as in standard EM . Pathological surfaces of the log likelihood may be present via saddle points and local optima , meaning that the algorithm is sensitive to initialization . [ 7 ] argued that the aug+δ(k ) ˆQ(k)(η ) mented objective function Q(k ) can avoid this problem partially , where ˆQ(k)(η ) usually takes one sample to introduce a stochastic property , and δ(k ) is a small positive step size , essentially requiring the conditions in ( 10 )
η = ( 1−δ(k))Q(k−1 )
η k→∞ δ(k ) = 0 , lim lim k→∞ δ(k)/δ(k+1 ) = 1 ,
δ(k ) = ∞ ( 10 ) k
The intuition to solve this intractable objective lies in [ 4 ] , showing that this optimization can be updated by η(k+1 ) = ( 1−δ(k+1))η(k+1 ) EM + δ(k+1)η(k+1 ) is the true EM result approximated by Monte Carlo ( MC ) EM [ 22 ] with large sampling size , and η(k+1 ) is the special case of MCEM in a unique sample .
SEM , where η(k+1 )
SEM
EM
Generalizing MC to Gibbs sampling , we formalize Algorithm 1 , where ˆQbGEM takes the sample average of Gibbs algorithm and ˆQSEM takes the last sample . ˆQSEM is a stochastic perturbation of EM , and is expected to search more stable points . The algorithm starts from the completely optimized ˆQSEM with δ(1 ) = 1 , making the search area large for the first few steps . Then it focuses more weight on optimizing ˆQbGEM . Theorem 1 provides a theoretical guarantee , and can be proved by using two convergence bounds ; Birkhoff Ergodic theory [ 10 ] and Theorem 7 in [ 7 ] .
THEOREM 1 . Under certain conditions with exponential family for log likelihood function and the step size constraint ( 10 ) , the sequence generated by bGEM for sufficient large J converges a.s to a local maximizer , whatever the initial point ( convergence towards saddle point is avoided with probability 1 ) .
Conditions : ( 1 ) The complete data likelihood function is expo
PROOF . Sketch : With abusing notations , ˆQSEM(x ; η ) means it depends on the single sample and parameter optimized parameter at previous step , where s denotes all latent variables . The conditions follow the definition appearing in [ 7 , 14 ] and we have Lemma 1 . nential family given by f ( x ; η ) = exp{−ψ(η)+ < S(x ; η ) , φ(η ) >} , where functions ψ , φ , S are twice continuously differentiable . ( 2 ) The expected log likelihood l(η ) is continuously differentiable and ∂η f ( x ; θ)µ(dx ) = ∂ηf ( x ; η)µ(dx ) . ( 3 ) For all η ∈ Θ , the integral ˆQSEM(x , η)2 p(x|η)µ(dx ) < ∞ , and function Γ(η ) =
Covη( ˆQSEM(x , η ) ) is continuous wrt η . ( 4 ) The stationary points of l(η ) are isolated : any compact subset contains only a finite number of such points .
LEMMA 1 . Assume that above listed conditions hold and the sequence {ηk} converge to some proper maximizer η∗ . If in addition , limk→∞ kaδ(k ) = δ∗ and δ(k)/δ(k+1 ) = 1 + O(k−1 ) , √ kI(limk→∞ η(k ) − η∗ = 0 ) has a limiting distribution the N ( 0 , Σ)I(limk→∞ η(k)−η∗ = 0 ) , where Σ = [ ∂2 ηl(η∗)]−1[∂2 ηL(¯s(η∗))][∂2 ∂2 In our algorithm we pick up the single sample every J iterations SEM and use the burn in J − B samples to compute ˆQ(k ) as ˆQ(k ) to approximate the true Q(η|η(k−1 ) ) = E[log P ( X|η) ] . Thus we ( J−B)→∞ −−−−−−−→ Q(η|η(k−1 ) ) holds . only need to argue that ˆQ(k ) Birkhoff Khinchin Ergodic theorem [ 10 ] ensures this conclusion .
ηl(η∗)]−1 bGEM bGEM
ηl(η∗)−
Faster version of binary latent variable Because the first order derivative with respect to η has no analytical root , the inverse
Data : Z , Y , G , sampling size J , burn in iteration B , step size series {δ(k)}∞ k=1
Result : η and X Initialize coefficient parameter η(0 ) ; repeat sampling {X ( j ) , R(j)}J j=1 according to ( 9 ) ;
/*E step*/ ; for i ← 1 to J do end /*M step*/ ; Compute ˆQ(k ) bGEM(η ) =
J
1
J − B j=B+1
SEM(η ) = log and ˆQ(k ) Optimization
P ( X ( j ) , R(j ) , η|Z , η(k−1 ) ) log
( 11 )
P ( X ( J ) , R(J ) , η|Z , η(k−1 ) )
; bGEM = arg max ˆQ(k ) η(k ) SEM = arg max ˆQ(k ) η(k ) Combination η(k ) = ( 1 − δ(k))η(k ) bGEM(η ) SEM(η ) ; bGEM + δ(k)η(k ) SEM ; until η(k ) Convergence ;
Algorithm 1 : burn in Gibbs EM Algorithm of the Hessian matrix is computed with computational complexity O(K 3 ) . The dimensionality of H is K independent of N , and a PCA preprocessing will reduce it significantly , leading to a lower matrix inverse computation . Though K is small in most cases , there may still be a high cost to computing the Hessian itself ( O(JK 2 ) ) for matrix addition , unless there is a parallelized implementation . [ 18 ] prove a theorem to address the exchangeablity of the derivatives and expectations for random Gaussian variables . [ 19 ] implemented this idea in a non Gaussian posterior likelihood and obtained good performance . An improved SAEM coupled with MCMC is discussed in [ 13 ] , which argued that only one sample is required in the E step if an appropriate Markov transition kernel is also used .
Consequently , we follow these two ideas to design our single sample algorithm by taking the posterior mean . Technically , using the fact that P ( R = 3 ) ≈ 0 , latent R is also considered as binary variable without harm . Therefore , at the kth iteration of EM , the pseudo sample can be constructed via a Bayesian decision rule based on the burn in posterior mean in Gibbs sampling , ie
ˆxn,t = I{
1
J − B n,t > 0.5} x(j )
ˆRn,t = I{
1
J − B n,t > 05} R(j )
J J j=B+1 j=B+1
This means that a unique set ( ˆX , ˆR ) is sufficient to approximate ˆQ(k)(η ) , that is to say , log(P ( ˆX , ˆR , η)|Z , η(k−1 ) ) substitutes for ˆQ(k ) bGEM . This trick applied on non Gaussian variables is not theoretically guaranteed but has been broadly used in EM or other optimization problems , by assuming a fully factorized joint distribution . In our binary variable case we found that it made no significant difference on accuracy whenever this trick applies , in practice . *EM at the kth M step , the update formula by Newton Raphson Method is briefly outlined in this para
Optimization To optimize η(k )
243 graph , excluding the analytical gradient G and Hessian H computation . For efficiency , we update parameters as follows , with a few iterations .
η(k ) *EM:new = η(k )
*EM:old − δH
−1G where *EM varies according to different estimators , bGEM or SEM . It is unnecessary for there to be complete convergence in order to guarantee Q(η(k ) ) > Q(η(k−1) ) . A similar idea with a single iteration is mentioned in [ 14 ] . The step size δ ensures that the Wolfe conditions [ 16 ] are satisfied . The intuition in adding in step size here is , compared with gradient descent , Newton ’s Method tends to make more progress in the right direction of local optima , due to the property of affine invariance . This probably leads an update where the step size is too large , so it is better for stochastic algorithms to enlarge the search domain at first then shrink later . 3.4 Simpler Algorithm on Sigmoid link
As has been previously discussed , a sigmoid link function benefits from model simplicity and hiding infection parameters without integrating them out . The likelihood P ( η , X|Z ) can thus be exactly computed as Equation ( 12 ) . It means that , in parameter estimation , we can either apply standard SAEM by getting rid of latent variable R immediately , or bGEM by introducing R as well in E step and faster version M step by keeping ˆX alone .
P ( η )
N P ( xn,1 ) × N T−1 I{xn,t=1,xn,t+1=0} n=1 t=1 n=1
σ(z
· · n ηr ) 1 − ( 1 − σ(z ( 1 − σ(z n ηa))(1 − σ(z n ηa))(1 − σ(z
( 12 ) n ηr )
1 − σ(z
I{xn,t=1,xn,t+1=1} n ηb))Cn,tI{xn,t=0,xn,t+1=1} n ηb))Cn,tI{xn,t=0,xn,t+1=0}
.
3.5 Discussion on Another Interpretation
In the second biological interpretation of βn ( probability of infecting others ) , transition function φn,xn :(n,n)∈Gt will depend on the extra parameter set {βn : n ∈ Sn,t} . Consequently , the posterior of each βn requires both a count number and source tracking ( like the concept of a "pointer" in the C programming language ) . However , the likelihood of the beta exponential model can be simplified to integrate out these parameters due to the auxiliary variable R as well , corresponding to the new categorical distribution in Equation ( 13 ) , though P ( R ) in Equation ( 5 ) can also have this formulation .
( 1 − βn ) n∈Sn,t
( 1 − βn )
,
αn n∈Sn,t
1 − ( 1 − αn ) 1 − ( 1 − αn )
B(ez n ηa,1 + Cn,Rn=0 , ez
( 1 − αn)βn n∈Sn,t
B(ez n
( 1 − βn )
, . . .
( 13 ) n ηr,1 + Cn,1→0 , ez n ηr,1 , ez n ηr,2 + Cn,1→1 n ηr,2 ) n ηa,2 + Cn,Rn=0 + Cn,0→0
B(ez n ηa,1 , ez n ηa,2 ) n ηb,1 + Cn,R=n , ez n ηb,1 , ez
B(ez n ηb,2 + Cn,R=n n ηb,2 )
P ( Rn,t ) ≈ Cat
P ( X , R , η|Z ) = P ( η ) · B(ez · B(ez
( 14 ) Rn,t takes the value {0 , 1 , , Cn,t} , where 0 means there is an outside network source and other integers mean specific infection in network sources . The categorical distribution makes the beta prior for the infection parameters conjugate in the posterior . However , the integral for the likelihood is actually difficult and needs some algebraic tricks , especially for βn because of the source tracking . We show the result of the beta exponential model in 14 , while the sigmoid model is straightforward and obtained without too many tricks . The new count notations are listed below .
Cn,Rn=0 = Cn,Rn=0 = Cn,R=n = Cn,R=n = t t
I{Rn,t=0} n∈Sn,t n,t:n∈Sn ,t n,t:n∈Sn ,t
I{Rn,t=n} I{Rn ,t=n} [ I{Rn ,t=0} + I{xn,t=0,xn ,t+1=0} ]
4 . EXPERIMENTAL RESULTS
In this section we illustrate , on simulated data , the performance of our approach , hGCHMMs and the burn in Gibbs EM algorithm on three datasets for the purposes of predicting the hidden infectious state X , filling in missing data – observation Y , and inferring an individual ’s physical condition based on parameter estimation . Further application on the public real world Social Evolution Dataset [ 15 ] and our mobile apps survey dataset are also shown . 4.1 Semi Simulation Dataset 411 Data Generation Differing from completely simulated data or a totally artificial setting , we employed a generative model to synthesize X,Y based on the real dynamic social network Gt and covariates Z from the real Social Evolution dataset . The predefined X then plays the role of ground truth , making evaluation for all above points possible .
Real Part Public MIT Social Evolution dataset contains the dynamic networks G including 84 participants over 107 days , Gt indexes 1 to 107 , and covariates zn exist for each participant , including 9 features , weight , height , salads per week , veggies fruits per day , healthy diet level , aerobics per week , sports per week , smoking indicator , and default feature 1 . The quantity per week is frequency . Weight and height are taken as real values . Healthy diet includes 6 levels ranging from very unhealthy to very healthy based on self evaluation . Smoking indicator is literally a binary variable . Real symptoms Y are temporarily discarded since the true infection states X are unavailable for this dataset .
Synthesized Part X and Y are then generated based on a Sigmoid link generative model . It is noticed that hyperparamter η needs to be predefined , which means synthesized infection parameters γn , αn , βn are known because of the sigmoid function . Only synthesized data Y with 6 symptoms is given to learning model , but the evaluation is done on other variables . The proportion of missing values in Y is set to 0.5 , i.e , the observations yn,t,s are NA with probability 05 Our generated X ( an 84 × 108 matrix , including initial states ) is shown in Figure 3(a ) . Each row vector represents a person ’s infection states during the entire observation period . 412 Model Evaluation We ran the algorithm 10 times . The prediction performance on latent variable X is the byproduct of the E step , and when xn,t is larger than the threshold 0.5 the person is diagnosed as being infected . Since X is completely unknown to the algorithm , held out test data prediction is unnecessary but all X is used to evaluate prediction accuracy . Figure 3(a c ) shows the difference between the truth and the inferred results from each of the two linked models . The posterior mean from Gibbs sampling for prediction , in both
244 ( a ) Synthesized X
( b ) ˆX by Sigmoid link
( c ) ˆX by Beta exp link
( d )
( e )
( f )
( g )
( h ) γn
( i ) αn
( j ) βn
Figure 3 : Prediction performance on X , α , β,γ . ( a c ) represent the true latent states , sigmoid and beta exp model learned states respectively . Redder means more likely to be infectious . ( d ) Accuracy on X comparison . ( e g ) Quantitatively error measurement of person specific parameters . ( h j ) Scatter plot illustration of ( e g ) Horizontal axis : estimation ; Vertical axis : ground truth . beta exponential and sigmoid models , leads to a real value in the interval [ 0 , 1 ] . Figure 3(d ) reveals a quantitative measurement on accuracy with standard deviation . As mentioned before , a two step algorithm including standard GCHMM and further logistic regression is also implemented and compared to . The rightmost error bar in Figure 3(d ) shows its predictive performance . GCHMM needs to run at least 2000 iterations of Gibbs sampling to obtain good mixing , while in our approach , we only run about 50 inner iterations in E step and less than 10 outer EM iterations .
Figure 3(e g ) display the predictive error of the forecasted infection parameters . Since the infection parameters are individual specific , the estimation is in fact a vector of length N . Therefore we used the 2 norm of the error vector for comparison . It is apparent that the sigmoid model shows the best performance on latents X or γn , αn , βn , in terms of the generative model . The Beta exponential Model , mentioned in Sec 2 , as an approximated substitute for logistic regression on infection parameters , proves its competitive for parameter estimation . However , standard GCHMM with logistic regression , as two independent parts of the sigmoid model , provides an unreliable prediction on individual specific parameters , albeit its excellent latent variable inference . All three inference methods use Gibbs sampling to infer X . This is most likely the reason why they share equivalent performance .
Individual Parameters Analysis
413 From the perspective of general health care or disease control for large populations , η is of concern ( discussion on a real biological dataset later ) . However , as for individual treatment and personal medical advice , γn , αn , βn should be more significant for physical health . Better immunity usually indicates a smaller αn , βn but a larger γn . In our model , these parameters are designed to correlate with personal health habits by using a link with influence coefficient η . The prediction of the infection parameters on raw data Z is shown in Figure 3(h j ) . This illustration is consistent with the error bar plot in Figure 3(e g ) . The predicted values of our proposed models are distributed with higher concentration on the diagonal ( y = x ) , while standard GCHMM + logistic regression has relatively larger variance . The underlying linear slope for γn seems inconsistent with y = x . This phenomenon can be blamed on the colinearity of Z if taking the names of covariates literally . Thus , we apply Principal component analysis ( PCA ) on Z , and then select the first 4 components ( explaining 99.9 % ) and the default feature 1 . We next run the program again and obtain the scatter plot of
08980909020904090609080910912Beta−exp linkSigmoid linkGibbs logregPrediction accuracy on infection states X0650707508085090951Beta−exp linkSigmoid linkGibbs logregNorm of error vector : gamma010150202503035Beta−exp linkSigmoid linkGibbs logregNorm of error vector : alpha010150202503Beta−exp linkSigmoid linkGibbs logregNorm of error vector : beta0010203040506070010203040506 Beta−exp linkSigmoid linkGibbs logreg00005001001500200250000500100150020025 Beta−exp linkSigmoid linkGibbs logreg0001002003004005000050010015002002500300350040045005 Beta−exp linkSigmoid linkGibbs logreg245 Figure 4 : Colinearity elimination on γn : PCA justification on Figure 3 ( h ) is to obtain the regressed slope close to 1 .
( a ) y·,5
( b ) ˆy·,5
( c ) Predicted X
Figure 5 : Epidemics state inference on real Data : ( a ) shows the true reported symptoms by 84 participants at day 5 ; ( b ) gives the one step ahead prediction of ( a ) ; ( c ) is predicted infection .
γn ( Figure 4 ) . Result imply that PCA can eliminate the colinearity effectively . 4.2 MIT Social Evolution Dataset
This real world dataset [ 15 ] is collected from a college dormitory building by web survey and contains the dynamic graphs Gt , covariates Z , and daily symptoms Y , where yn,t is a 6 dimensional vector including sore throat and cough , runny nose , congestion and sneezing , fever , nausea , vomiting and diarrhea , sadness and depression , and openly stressed . The proportion of missing values Y is about 06 The purpose is to infer latent variables X and infection parameters , and making tentative health suggestions to students . Even if we cannot evaluate the performance on the true Xs , the Google search of "flu" [ 9 ] implies a underlying correlation with this result . Since Y can be partially observed ( no NA ) , one step ahead prediction on Y is possible , and obtains an accuracy at 92.09 % ( threshold is also 05 ) Results are shown in Figure 5 . 4.3 eX Flu Dataset
Evaluation on the public MIT dataset seems only partially useful , since true diagnoses are unavailable . We describe the design , study population characteristics , and social network structure of a chain referral sample of 590 students living in University of Michigan residence halls who were randomized to an intervention of isolation over a 10 week period during the 2013 influenza season . In our experiment , diagnoses are recorded immediately at onset . 431 Design Description 590 students living in six eligible residence halls on the University of Michigan campus enrolled in the eX FLU study during
Figure 6 : Overall Social Network a chain referral recruitment process carried out from September 2012 January 2013 . 262 of these , as "seed" participants , nominated their social relations to join the study as well . The rest , 328 , were nominees that enrolled . Participants have to fill out weekly surveys on web apps about their health behaviors and social interactions with other participants , and a symptoms indicator report of influenza like illness ( ILI ) . A subsample of 103 students were provided with smartphones with a mobile application , iEpi [ 12 ] , which is able to collect location sensor and contextually dependent survey information , implying social contacts that are used in our computational model . This sub study experiment perfectly fits our proposed model , so the main evaluation will be performed on this sub dataset . Generally speaking , the underlying cumulative distribution of degree for the overall social network on 590 students is shown in Figure 6 . The distribution of three degree measurements ( in , out , or total ) , were heavily right skewed and over dispersed . Consequently , the network appears scale free , with a log log plot and linear trend line ( R2 = 0.91 ) illustrating the approximately power law distribution for total degree . iEpi Sub Study and Networks Analysis
432 103 ( 17.5 % ) students of the 590 enrolled participants were equipped with provided smartphones and joined the iEpi sub study . They were required to use their iEpi smartphone and could report their symptoms , meeting the study criteria for ILI . A total of 4843 contextuallybased surveys were administered on all sub study smartphones ( mean 62.09/day ) , 1743 ( 36.0 % ) of which were responded to by iEpi substudy participants ( mean 2235/day ) There were a total of 60131 Bluetooth contacts between smartphones within the iEpi sub study , and 148,333 total Bluetooth contacts with other devices of any kind , averaging 7.48 contacts/phone/day and 20.95 contacts/person/day , respectively .
The bluetooth detector can automatically collect contacts occurring between iEpi installed smartphones , or to other smart devices . Each node ( circle ) in Figure 7 represents an individual in the substudy , and the links ( edges ) between nodes represent bluetooth detections between smartphones of individuals within the sub study networks . Node size is proportional to the total number of contacts detected by bluetooth data ( equivalent to degree ) , and the link thickness indicates the contact duration between the two nodes
0010203040506070010203040506 Beta−exp linkSigmoid linkGibbs logreg246 Figure 7 : iEpi Bluetooth network ( N=103 ) . Network of Bluetooth contacts between smartphones in the iEpi sub study
Figure 8 : Dynamic Social Networks derived from Figure 7 . 103 dots uniformed distribute as a large circle . Contacts within the network account for edges between solid dots .
( equivalent to weight on edge ) . During the experiment period , we also conducted a comparison test . Some participants ( yellow nodes in Figure 7 ) were isolated for three days at the onset of illness , which means no social contacts during these period .
The next step is to extract daily social networks . We use the 77 days of the iEpi survey data which is relatively complete , and its corresponding bluetooth data to construct dynamic networks . Figure 8 illustrates 4 independently sampled sub networks , ie Gt , t = 2 , 27 , 52 , 77 . To make more sense of the edges , only the bluetooth data showing the total contact duration between two participants lasting more than 10 minutes will contribute to an edge on that day . The threshold of 10 minutes can be adjusted to make the graph denser or sparser , thus leading to a higher or lower computational cost .
Model
Table 1 : exFlu Epidemics State Inference Performance Accuracy 0.9978 ± 0.00 0.9912 ± 0.00 0.9912 ± 0.00
Recall 0.8974 ± 0.00 0.7436 ± 0.00 0.7436 ± 0.00
Sigmoid link Beta exp link
GCHMMs+LogReg
1Gender 1 means female ; Alc_Day : average times of hand washing by sanitizer ; Vacc_Ever : take vaccination before ; Flushot_Yr : take vaccination this year ; Act_Days : exercise in broad sense per day ; Wash_Opt : whether wash hands exceeding 20s ; High_Risk : contact with impaired immunity patient .
Figure 9 : Left is true Onset and its Duration . Right is predicted by Sigmoid Model .
Table 2 : Coefficients Estimation on exFlu Dataset
Feature1 Default=1 Gender Age Alc_Day Vacc_Ever Flushot_Yr Smoker Drinker Act_Days Sleep_Qual Wash_Opt High_Risk
Recovery ηr Outside Infect ηa 5.1517 ± 0.0024 0.2428 ± 0.0074 0.2376 ± 0.0051 0.1534 ± 0.0003 0.1092 ± 0.0095 0.3209 ± 0.0073 0.0536 ± 0.0008 0.0628 ± 0.0030 0.0054 ± 0.0063 0.3686 ± 0.0051 0.0816 ± 0.0132 0.1252 ± 0.0058
1.3022 ± 0.0146 0.1575 ± 0.0118 0.0074 ± 0.0082 0.1090 ± 0.0078 0.0698 ± 0.0104 0.0769 ± 0.0092 0.1080 ± 0.0029 0.1335 ± 0.0092 0.0356 ± 0.0099 0.0225 ± 0.0069 0.0024 ± 0.0103 0.1274 ± 0.0116
Inside Infect ηb 4.1619 ± 0.0281 0.1457 ± 0.0078 0.0181 ± 0.0017 0.0410 ± 0.0018 0.0382 ± 0.0085 0.0837 ± 0.0055 0.0773 ± 0.0021 0.1408 ± 0.0029 0.0622 ± 0.0078 0.0162 ± 0.0077 0.0714 ± 0.0048 0.0727 ± 0.0007 iEpi Flu Diffusion Analysis
433 Available illness onset diagnoses in our experiment allows for the evaluation of inferred infection states . We tried all three models , Sigmoid link , Beta exponential link and standard GCHMMs+LogReg on this dataset . Because of the specific quantized distribution of diagnosed flu onset ( see red short pattern of left graph in Figure 9) ) , the three methods perform stably , but give different results over 10 runs with no standard deviation . Though they all heavily rely on Gibbs sampling , the sigmoid link model can detect more short term patterns than the other two . Table 1 gives both precision and recall for prediction , since the proportion of positive instances , unlike our simulation , is about one tenth . Even the sigmoid model missed some very short patterns . Two reasons may contribute to this phenomena ; the first is that HMMs are a long distance dependent model ; second is that we find symptom reports for short period disease courses are always low severity .
In contrast to other models , and serving as the mainstay and novelty of this paper , we aimed to learn how personal features ( first column in Table 2 ) were associated with individual flu vulnerability , ie coefficients η . A Sigmoid transform on η will immediately give infection parameters . Larger γn implies better body resistance , while larger αn , βn indicates more vulnerability . Because body resistance or vulnerability is not an experimental quantity ( difficult to measure in real world dataset ) , we prefer to evaluate coefficients η ( Table 2 ) rather than actual infection parameters . The right three columns are the estimated ηs associated with different biological meaning ( indicated by their subscripts ) in the Sigmoid model–possessing the best performance in both the simulation and real cases . Looking at the feature column , we can see that females seems suffer from a slower recovery but are not as likely to catch a cold . Another important factor is an indicator of participants addicted to alcohol . Drinkers significantly aggravate body immunity . However , whether or not one washes their hands for more than 20s , interestingly , seems not to be significant to the model , especially
Day 2Day 27Day 52Day 77247 to the recovery rate . This may blamed on an overly long washing duration–20s in the experimental design . Overall , the sign consistency with respect to η makes sense , with the exception of a few counter intuitive relationships . For the sigmoid function , positive coefficients will enlarge infection parameters , and vice versa .
5 . CONCLUSIONS AND FUTURE WORKS We propose hierarchical GCHMMs to simultaneously predict individual infection and physical constitution by observing how flu spreads within dynamic social networks . The heterogeneous model is validated on semi synthetic data and epidemiological tracking data in college dormitories , and outperforms existing GCHMMs ( plus logistic regression ) . On semi simulation data , we evaluate our model on a number of metrics , including on the ability to correctly infer parameters . On the MIT social evolution data , we mainly focus on one step ahead prediction of the observed states ( or symptoms ) . In our eX Flu study , we successfully discovered the underlying social network pattern and personal feature relationships with respect to influenza vulnerability .
The variant of the EM algorithm we developed for inference proved to work well both from a theoretical view and in experimental results . Future research might explore belief propagation and variational inference methods for parameter estimation . Another possible area of future research would be to implement Remark ( 3 ) or investigate infection network learning by detecting the disease spread path ( auxiliary variable R ) . We can further relax the heterogeneity assumption to a cluster assumption . Inspired by HDPHMMs [ 21 ] , this tradeoff can be realized by constructing a nonparametric version GCHMMs , enforcing similar HMMs to share the same parameters .
6 . ACKNOWLEDGMENTS
We would like to thank Dylan Knowles , under the supervision of Dr . Nathaniel Osgood and Dr . Kevin Stanley , and the aid of other students and fellows developed the iEpi application and helped oversee the iEpi app smartphone upload , data collection procedures , and trouble shooting for the eXFLU study . This work was supported by Duke NSF grant #3331830 . Any opinions , findings and conclusions or recommendations expressed in this material are the authors’ and do not necessarily reflect those of the sponsor .
7 . REFERENCES [ 1 ] R . Beckman , K . R . Bisset , J . Chen , B . Lewis , M . Marathe , and P . Stretz . Isis : A networked epidemiology based pervasive web app for infectious disease pandemic planning and response . In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 1847–1856 . ACM , 2014 .
[ 2 ] D . M . Blei , T . L . Griffiths , and M . I . Jordan . The nested chinese restaurant process and bayesian nonparametric inference of topic hierarchies . Journal of the ACM ( JACM ) , 57(2):7 , 2010 .
[ 3 ] M . Brand , N . Oliver , and A . Pentland . Coupled hidden markov models for complex action recognition . In Computer Vision and Pattern Recognition , 1997 . Proceedings . , 1997 IEEE Computer Society Conference on , pages 994–999 . IEEE , 1997 .
[ 4 ] G . Celeux , D . Chauveau , J . Diebolt , et al . On stochastic versions of the em algorithm . 1995 .
[ 5 ] J . Chang , D . M . Blei , et al . Hierarchical relational models for document networks . The Annals of Applied Statistics , 4(1):124–150 , 2010 .
[ 6 ] R . M . Christley , G . Pinchbeck , R . Bowers , D . Clancy ,
N . French , R . Bennett , and J . Turner . Infection in social networks : using network analysis to identify high risk individuals . American journal of epidemiology , 162(10):1024–1031 , 2005 .
[ 7 ] B . Delyon , M . Lavielle , and E . Moulines . Convergence of a stochastic approximation version of the em algorithm . Annals of Statistics , pages 94–128 , 1999 .
[ 8 ] W . Dong , B . Lepri , and A . S . Pentland . Modeling the co evolution of behaviors and social relationships using mobile phone data . In Proceedings of the 10th International Conference on Mobile and Ubiquitous Multimedia , pages 134–143 . ACM , 2011 .
[ 9 ] W . Dong , A . Pentland , and K . A . Heller . Graph coupled hmms for modeling the spread of infection . Association for Uncertainty in Artificial Intelligence , 2012 .
[ 10 ] R . Durrett . Probability : theory and examples . Cambridge university press , 2010 .
[ 11 ] A . Gruber , Y . Weiss , and M . Rosen Zvi . Hidden topic markov models . In International Conference on Artificial Intelligence and Statistics , pages 163–170 , 2007 .
[ 12 ] D . L . Knowles , K . G . Stanley , and N . D . Osgood . A field validated architecture for the collection of health relevant behavioural data . In Healthcare Informatics ( ICHI ) , 2014 IEEE International Conference on , pages 79–88 . IEEE , 2014 .
[ 13 ] E . Kuhn and M . Lavielle . Coupling a stochastic approximation version of em with an mcmc procedure . ESAIM : Probability and Statistics , 8:115–131 , 2004 .
[ 14 ] K . Lange . A gradient algorithm locally equivalent to the em algorithm . Journal of the Royal Statistical Society . Series B ( Methodological ) , pages 425–437 , 1995 .
[ 15 ] A . Madan , M . Cebrian , S . Moturu , K . Farrahi , and
A . Pentland . Sensing the" health state" of a community . IEEE Pervasive Computing , 11(4):36–45 , 2012 .
[ 16 ] J . Nocedal and S . Wright . Numerical optimization , series in operations research and financial engineering . Springer , New York , USA , 2006 .
[ 17 ] J . Paisley , C . Wang , D . M . Blei , and M . I . Jordan . Nested hierarchical dirichlet processes . 2012 .
[ 18 ] R . Price . A useful theorem for nonlinear devices having gaussian inputs . Information Theory , IRE Transactions on , 4(2):69–72 , 1958 .
[ 19 ] D . J . Rezende , S . Mohamed , and D . Wierstra . Stochastic backpropagation and approximate inference in deep generative models . In Proceedings of The 31st International Conference on Machine Learning , pages 1278–1286 , 2014 .
[ 20 ] M . Salathé , M . Kazandjieva , J . W . Lee , P . Levis , M . W .
Feldman , and J . H . Jones . A high resolution human contact network for infectious disease transmission . Proceedings of the National Academy of Sciences , 107(51):22020–22025 , 2010 .
[ 21 ] Y . W . Teh , M . I . Jordan , M . J . Beal , and D . M . Blei .
Hierarchical dirichlet processes . Journal of the american statistical association , 101(476 ) , 2006 .
[ 22 ] G . C . Wei and M . A . Tanner . A monte carlo implementation of the em algorithm and the poor man ’s data augmentation algorithms . Journal of the American Statistical Association , 85(411):699–704 , 1990 .
248
