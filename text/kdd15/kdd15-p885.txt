Quick Sensitivity Analysis for Incremental Data Modification and Its Application to
Leave one out CV in Linear Classification Problems
Nagoya Institute of Technology
Nagoya Institute of Technology
Nagoya Institute of Technology
Shota Okumura
Nagoya , Japan okumuramllabnit@ gmail.com
Yoshiki Suzuki
Nagoya , Japan suzukimllabnit@ gmail.com
∗ Ichiro Takeuchi
Nagoya , Japan takeuchi.ichiro@ nitechacjp
ABSTRACT We introduce a novel sensitivity analysis framework for large scale classification problems that can be used when a small number of instances are incrementally added or removed . For quickly updating the classifier in such a situation , incremental learning algorithms have been intensively studied in the literature . Although they are much more efficient than solving the optimization problem from scratch , their computational complexity yet depends on the entire training set size . It means that , if the original training set is large , completely solving an incremental learning problem might be still rather expensive . To circumvent this computational issue , we propose a novel framework that allows us to make an inference about the updated classifier without actually re optimizing it . Specifically , the proposed framework can quickly provide a lower and an upper bounds of a quantity on the unknown updated classifier . The main advantage of the proposed framework is that the computational cost of computing these bounds depends only on the number of updated instances . This property is quite advantageous in a typical sensitivity analysis task where only a small number of instances are updated . In this paper we demonstrate that the proposed framework is applicable to various practical sensitivity analysis tasks , and the bounds provided by the framework are often sufficiently tight for making desired inferences .
Categories and Subject Descriptors I52 [ Pattern Recognition ] : Design Methodology–Classifier design and evaluation
General Terms Algorithms
Keywords sensitivity analysis ; incremental learning ; leave one out cross validation ∗ Corresponding author c⃝ 2015 ACM . ISBN 978 1 4503 3664 2/15/08 $1500
DOI : http://dxdoiorg/101145/27832582783347
1 .
INTRODUCTION
Given a large number of training instances , the initial training cost of a classifier such as logistic regression ( LR ) or support vector machine ( SVM ) would be quite expensive . In principle , there is no simple way around this initial training cost except when suboptimal approximate classifiers ( eg , trained by using random small sub samples ) are acceptable . Unfortunately , such an initial training cost is not the only thing we must care about in practice . In many practical data engineering tasks , the training set with which the initial classifier was trained might be slightly modified . In such a case , it is important to check the sensitivity of the classifier , ie , how the results would change when the classifier is updated with the slightly modified training set .
Machine learning algorithms particularly designed for updating a classifier when a small number of instances are incrementally added or removed are called incremental learning [ 3 ] . For example , when a single instance is added or removed , the solution of a linear predictor can be efficiently computed ( see , eg , [ 8] ) . Incremental learning algorithms for SVMs and other related learning frameworks have been intensively studied in the literature [ 3 , 7 , 17 , 12 , 11 , 13 ] . Even for problems whose explicit incremental learning algorithm does not exist , warm start approach , where the original optimal solution is used as an initial starting point for the updating optimization problem , is usually very helpful for reducing incremental learning costs [ 5 , 18 ] .
However , the computational cost of incremental learning is still very expensive if the original training set is large . Except for special cases1 , any incremental learning algorithms must go through the entire training data matrix at least once , meaning that the complexities depend on the entire training set size . When only a small number of instances are modified , spending a great amount of computational cost for re optimizing the classifier does not seem to be a well worthy effort because inference results on the updated classifier would not be so different from the original ones . Furthermore , in practical applications , it might be computationally intractable to completely update the classifier every time there is a tiny modification of the training set . In such a situation , it would be nice if we could quickly check the sensitivity of the classifier without actually updating it . Unless the sensitivity is unacceptably large , we might want to use the original classifier as it is .
Our key observation here is that the goal of sensitivity analysis is not to update the classifier itself , but to know how much the results of our interest would change when the classifier is updated with the
1For example , in incremental learning of SVM , adding or removing an instance whose margin is greater than one can be done without any cost because such a modification does not change the solution .
885 ⊤ fi
⊤ fi fi slightly modified training set . Suppose , for example , that we have a test instance . Then , we would be interested in whether there is a chance that the class label of the test instance could be changed by a minor data modification or not . In order to answer such a question , we propose a novel approach that can quickly compute the sensitivity of a quantity depending on the unknown updated classifier without actually re optimizing it .
In this paper we study a class of regularized linear binary classification problems with convex loss . We propose a novel framework for this class of problems that can efficiently compute a lower and an upper bounds of a general linear score of the updated classifier . Specifically , denoting the coefficient vector of the updated linear ∗ new , our framework allows us to obtain a lower and classifier as fi ∗ an upper bounds of a general linear score in the form of new , where is an arbitrary vector of the appropriate dimension . An advantage of our framework is that the complexity of computing the bounds depends only on the number of updated instances , and does not depend on the size of the entire training set . This property is quite advantageous in a typical sensitivity analysis where only a small number of instances are updated .
Bounding a linear score in the form of
∗ new is useful in a wide range of sensitivity analysis tasks . First , by setting = e j , where e j is a vector with all 0 except 1 in the jth position , we can obtain a lower and an upper bounds of each coefficient β∗ new , j , j = 1 , . . . , d , where d is the input dimension . Another interesting example is the case where = x , where x is a test instance of our interest . ∗ ⊤ new is positive/negative , Note that , if the lower/upper bound of x then we can make sure that the test instance is classified as positive/negative , respectively . It means that the class label of a test instance might be available even if we do not know the exact value ⊤ of x
To the best of our knowledge , there are no other existing studies on sensitivity analysis that can be used as generally as our framework . However , there are some closely related methods designed for particular tasks . One such example that has been intensively studied in the literature is leave one out cross validation ( LOOCV ) . In each step of an LOOCV , a single instance is taken out from the original training set , and we check whether the left out instance is correctly classified or not by using the updated classifier . This task exactly fits into our framework because we are only interested in the class label of the left out instance , and the optimal updated classifier itself is not actually required . Efficient LOOCV methods have been studied for SVMs and other related learning methods [ 9 , 10 , 20 , 23]2 . Some of these existing methods are built on a similar idea as ours in the sense that the class label of a left out test instance is efficiently determined by computing bounds of the linear score ⊤ ∗ new . The bounds obtained by our proposed framework are difx ferent from the bounds used in these existing LOOCV methods . We empirically show that LOOCV computation algorithm using our framework is much faster than existing methods .
∗ new .
The bound computation technique we use here is inspired from recent studies on safe feature screening , which was introduced in the context of L1 sparse feature modeling [ 6 ] . It allows us to identify sparse features whose coefficients turn out to be zero at the optimal solution . The key idea used there is to bound the Lagrange multipliers before actually solving the optimization problem for model fitting3 . The idea of bounding the optimal solution without actually solving the optimization problem has been recently extended to various directions [ 6 , 22 , 15 , 14 , 21 , 16 ] . Our main technical fi fi
2In these works , the main focus is not on computing LOOCV error itself , but on deriving an upper bound of LOOCV error . 3Lagrange multiplier values at the optimal solution tell us which features are active or non active . contribution in this paper is to bring this idea to sensitivity analysis problems and develop a novel framework for efficiently bounding general linear scores with the cost depending only on the number of updated instances .
The rest of the paper is organized as follows . In §2 , we describe the problem setup and present three sensitivity analysis tasks that our framework can be applied to . In §3 we present our main result which enables us to compute a lower and an upper bounds of ∗ a general linear score new with the computational cost depending only on the number of updated instances . In addition , we apply the framework to the three tasks described in §2 . In §4 , we discuss how to tighten the bounds when the bounds provided by the framework are not sufficiently tight for making a desired inference . §5 is devoted for numerical experiments . § 6 concludes the paper and discuss a few future directions of this work . All the proofs are presented in Appendix A . fi
⊤
2 . PRELIMINARIES AND BASIC IDEA
In this section we first formulate the problem setup and clarify the difference between the proposed framework and conventional incremental learning approaches . Then , we discuss three sensitivity analysis tasks in which the proposed framework is useful . 2.1 Problem setup
In this paper we study binary classification problems . We consider an incremental learning setup , where we have already trained a classifier by using a training set , and then a small number of instances are added to and/or removed from the original training set . The goal of conventional incremental learning problems is to update the classifier by re training it with the updated training set . Hereafter , we denote the original and the updated training sets as {(xi , yi)}i∈Dold and {(xi , yi)}i∈Dnew , respectively , where Dold and Dnew are the set of indices of the instances in old and new training sets with the sizes nold := |Dold| and nnew := |Dnew| , respectively . The input xi is assumed to be d dimensional vector and the class label yi takes either −1 or +1 . We denote the set of added and removed instances as {(xi , yi)}i∈A and {(xi , yi)}i∈R , where A ⊂ Dnew and R ⊂ Dold are the set of indices of the added and removed instances with the sizes nA := |A| and nR := |R| , respectively . Note that , if one wants to modify an instance in the training set , one can first remove it and then add the modified one . We consider a linear classifier in the form of
{
ˆy =
+1 if f ( x ; fi ) ≥ 0 , ⊤ −1 if f ( x ; fi ) < 0 , with f ( x ; fi ) = x fi , where the classifier predicts the class label ˆy ∈ {−1 , +1} for the given input x ∈ Rd , while fi ∈ Rd is a vector of classifier ’s coefficients . In this paper we consider a class of problems represented as a minimization of an L2 regularized convex loss . Specifically , the old and the new classifiers are defined as
ℓ(yi , f ( xi ; fi ) ) +
ℓ(yi , f ( xi ; fi ) ) + i∈Dnew
∥fi∥2 ,
λ 2
∥fi∥2 ,
λ 2
( 1 )
( 2 )
∑ ∑ i∈Dold and fi
∗ old := arg min fi∈Rd
1 nold fi
∗ new := arg min fi∈Rd
1 nnew where the first and the second terms of the objective function represent an empirical loss term and an L2 regularization term , respectively , and λ > 0 is a regularization parameter that controls the balance between these two terms . We assume that ℓ(·,· ) is differentiable and convex with respect to the second argument . Examples
886 of such a loss function includes logistic regression loss ℓ(yi , f ( xi ; fi ) ) := log(1 + exp(−yi f ( xi ; fi)) ) ,
( 3 ) and L2 hinge loss
ℓ(yi , f ( xi ; fi ) ) := max{0 , 1 − yi f ( xi ; fi)}2 .
( 4 ) For any i ∈ Dold ∪ Dnew and any fi0 ∈ Rd , we denote the gradient of the individual loss as
∇ℓi(fi0 ) :=
∂ ∂fi
ℓ(yi , f ( xi ; fi ) )
. fi=fi0 fifififi
∗ old and fi
Our main interest is in the cases where the number of added instances nA and removed instances nR are both much smaller than the entire training set size nold or nnew . In such a case , we expect ∗ that the difference between fi new is small . However , if the training set size nnew is large , solving the optimization problem ( 2 ) by using an incremental learning algorithm is still very expensive because any incremental learning algorithms require working through the entire training data matrix at least once , meaning that the complexity of such an incremental learning is at least O(nnewd ) . Our approach is different from conventional incremental learning . In this paper we propose a novel framework that enables us to ∗ make inferences about the new solution fi new without actually solving the optimization problem ( 2 ) . The proposed framework can efficiently compute a lower and an upper bounds of , what we call , a linear score
⊤
∗ new , fi
( 5 ) where ∈ Rd is an arbitrary vector of dimension d . An advantage of this framework is that the computational cost of computing these bounds depends only on the number of updated instances nA + nR and does not depend on the entire training set size nold or nnew , ie , the complexity is O((nA+nR)d ) . This property is quite advantageous in a typical sensitivity analysis where nnew is much larger than nA + nR . These bounds are computed based on the old optimal solution ∗ ∗ old . We denote the lower and the upper bounds as L( new ) and fi U( fi fi
⊤
⊤
∗ new ) , respectively , ie , they satisfy new ≤ U( ∗ new ) ≤ ∗
L( fi fi
⊤
⊤
⊤
∗ new ) . fi
⊤ fi
∗ new and
The proposed framework can be kernelized for nonlinear classi⊤∇ℓi(fi ∗ fication problems if the inner products old ) for any i ∈ Dold ∪ Dnew can be represented by the kernel function . In the following three subsections , we discuss three sensitivity analysis tasks in which the above proposed framework might be useful . 2.2 Sensitivity of coefficients Let e j ∈ Rd , j ∈ [ d ] , be a vector of all 0 except 1 in the jth element . Then , by setting := e j in ( 5 ) , we can compute a lower and an upper bounds of the new classifier ’s coefficient β∗ new , j
⊤ = e j fi new , j ∈ [ d ] such that ∗ L(β∗ new , j ) ≤ β∗ new , j ≤ U(β∗ j ∈ [ d ] . new , j ) ,
Figure 1 illustrates such coefficient ’s bounds for a simple toy dataset . Given a lower and an upper bounds of the coefficients , we can , in ∗ principle , obtain the bounds of any quantities depending on fi new . Bounding the largest possible change of the new classifier ’s coefficients or a quantity depending on it would be beneficial for making decisions in practical tasks .
Figure 1 : Examples of coefficient bounds L(β∗ new , j ) , j ∈ [ 5 ] , for an artificial toy dataset with nold = 1000 and d = 5 . The blue , red and pink error bars indicate the bounds when nA + nR = 1 ( 0.1% ) , 5 ( 0.5% ) , and 10 ( 1% ) , respectively . The unknown true coefficients β∗ new , j , j ∈ [ 5 ] , are indicated by × . new , j ) and U(β∗
2.3 Sensitivity of class labels Next , let us consider sensitivity analysis of the new class label for a test instance x ∈ Rd , ie , we would like to know ∗ new ) .
∗ ⊤ new ) ) = sgn(x
ˆy := sgn( f ( x ; fi fi
By setting := x in ( 5 ) , we can compute a lower and an upper bounds such that
⊤ fi
L(x new ) ≤ x ∗ ⊤ new ≤ U(x ∗ fi
⊤
∗ new ) . fi
( 6 )
Here , it is interesting to note that , using the following simple facts :
⊤ fi ⊤ fi
L(x U(x new ) ≥ 0 ⇒ ˆy = +1 , ∗ new ) < 0 ⇒ ˆy = −1 , ∗
( 7a ) ( 7b ) ∗ the class label ˆy can be available without actually obtaining fi new if the bounds are sufficiently tight such that the signs of the lower and the upper bounds are same . If the number of updated instances nA + nR is relatively smaller than the entire training set size nold ∗ or nnew , we expect that the two solutions fi new would not be so different . In such cases , as we demonstrate empirically in §5 , the bounds in ( 6 ) are sufficiently tight in many cases . Figure 2 illustrates the tightness of the bounds in a toy dataset . 2.4 Leave one out cross validation ( LOOCV ) One of the traditional problem setups to which our proposed framework can be naturally applied is leave one out cross validation ( LOOCV ) . The LOOCV error is defined as
∗ old and fi
1 LOOCV error := n where sgn(· ) is the sign , and fi ing out the hth instance , which is defined as
I(yh , sgn(x
⊤ i fi
∗ ( −h)) ) , h∈[n ] ∗ ( −h ) is the optimal solution after leav fi
∗ ( −h ) := arg min fi∈Rd
1 nold − 1
ℓ(yi , f ( xi , fi ) ) +
∥fi∥2 .
λ 2
∑
∑ i∈Dold\{h}
15 10 5 0 5 10 15 20 1 2 3 4 5coefficients and their bounds feature ID 887 Then , for an arbitrary vector ∈ Rd , the linear score isfies
⊤ fi
⊤ fi
⊤
∗ new ) ⊤
2nnew ∥∥ new ≥ L( ∗ fi nnew + nold := − 1 2 new ≤ U( ∗ fi nnew + nold := flflflflfl nA − nR flflflflfl nA − nR
2nnew ∥∥ nnew ∗ ⊤ new ) ⊤
+
1 2 nnew old − λ−1 nA + nR ∗ 2nnew old + λ−1 nA + nR ∗ nnew fi fi
⊤
∆s
∆s fi fi old − λ−1 nA + nR ∗ 2nnew old + λ−1 nA + nR ∗ nnew
⊤
∆s
∆s
⊤
∗ new sat fi
( 10a )
( 10b ) flflflflfl , flflflflfl .
The proof is presented in Appendix A .
An advantage of the bounds in ( 10 ) is that the computational complexity does not depend on the total number of instances , but only on the number of modified instances . It is easy to confirm that the main computational cost of these bounds is in the computation of ∆s in ( 9 ) , and its complexity is O((nA + nR)d ) . The tightness of the bounds , ie , the difference between the upper and the lower bounds is written as new ) − L( ⊤ ∗ = ∥∥ flflflflfl nA − nR
∗ new ) ∗ old flflflflfl .
U(
( 11 )
∆s fi fi fi
⊤
+ λ−1 nA + nR nnew nnew
In a typical sensitivity analysis where nA and nR are much smaller than nnew , the tightness in ( 11 ) would be small . Note also that the tightness depends inversely on the regularization parameter λ . If λ is very small and close to zero , the bounds become very loose . 3.1 Sensitivity analysis of coefficients As discussed in §2.2 , by substituting := e j , j ∈ [ d ] , into ( 10 ) , we obtain a lower and an upper bounds of the jth coefficient of the new classifier . Note that the tightness of the bounds in ( 11 ) is new , j , j ∈ [ d ] . Given a lower and common for all the coefficients β∗ new , j , j ∈ [ d ] , we can obtain an upper bounds of the coefficients β∗ ∗ the bounds of any quantities depending on fi new . For example , it is straightforward to know how much the classifier ’s coefficients can change by the incremental operation when the amount of the change is measured in terms of some norm of fi new − fi ∗
Corollary 2 . For any q > 0 , let ∥z∥q be the Lq norm of a vector z . Then the difference between the old and the new classifier ’s coefficients in Lq norm is bounded from above as
∗ old .
( ∑ new − fi ∗
∥q ∗ old max{β∗
∥fi ≤ q . old , j old , j
}q j∈[d ]
− L(β∗ new , j ) − β∗ new , j ) , U(β∗ where ∥z∥q is the Lq norm of a vector z 4 . The upper bound in ( 12 ) would be useful for judging whether one should actually update the classifier or not . If the amount of the change is guaranteed to be sufficiently small , one might want to use the old classifier as it is for circumventing the computationally demanding incremental learning operation . If the bounds of the coefficients or any quantities of our interest such as ∥fi ∥q are not tight enough , then we can use the approach discussed in §4 . 4For q = 2 , we can obtain tighter bounds than ( 12 ) , but we do not pursue this issue here . new − fi ∗
∗ old
) 1
( 12 )
⊤
⊤ fi fi
∗ new ) and Figure 2 : Examples of test instance score bounds L(x ∗ new ) for 10 test instances in the same dataset as in FigU(x ure 1 . The blue , red and pink error bars indicate the bounds when nA + nR = 1 ( 0.1% ) , 5 ( 0.5% ) , and 10 ( 1% ) , respec⊤ ∗ tively , and the unknown true scores x new are indicated by × . Note that , except for the 2nd and the 3rd test instances with nA +nR = 10 ( pink ) , the signs of the lower and the upper bounds are same , meaning that the class labels of these test instances are immediately available without actually updating the classifier . fi
∗ old , and fi
Here , our idea is to regard the solution obtained by the whole train∗ ∗ new . By setting := yhxh in ( 5 ) , we ( −h ) as fi ing set as fi can compute the bounds such that ( −h ) ) ≤ yhx ∗ ⊤ h fi
≤ U(yhx ⊤ h fi
⊤ L(yhx h fi
∗ ( −h) ) .
∗ ( −h )
( 8 )
These bounds in ( 8 ) can be used to know whether the left out instance is correctly classified or not . If the lower bound is positive , the left out instance will be correctly classified , while it will be mis classified if the upper bound is negative .
Using ( 8 ) , we can also obtain the bounds on the LOOCV error itself :
LOOCV error ≥ 1 n h∈[n ] LOOCV error ≤ 1 − 1 n
∑
( ∑
I
I h∈[n ]
(
)
)
⊤ U(yhx h fi
∗ ( −h ) ) < 0
,
⊤ L(yhx h fi
∗ ( −h ) ) > 0
, where I(· ) is the indicator function . In numerical experiments , we illustrate that this approach works quite well .
3 . QUICK SENSITIVITY ANALYSIS
In this section we present our main results on our quick sensitivity analysis framework . The following theorem tells that we can compute a lower and an upper bounds of a general linear score
∗ new by using the original solution fi fi
∗ old .
⊤
Theorem 1 . Let
∆s :=
1 nA + nR
∑ i∈A
∑ i∈R
∇ℓi(fi
∇ℓi(fi old ) − ∗
 .
∗ old )
( 9 )
30 20 10 0 10 20 30 1 2 3 4 5 6 7 8 9 10test instance scores and their bounds test instance ID 888 3.2 Sensitivity analysis of class labels Next , we use Theorem 1 for sensitivity analysis of new class labels . As discussed in §2.3 , for an input vector x ∈ Rd , we can ∗ ⊤ obtain a lower and an upper bounds of a linear score x new by setting = x . From ( 7 ) , we can know the new class label if the signs of the lower and the upper bounds are same . fi
Corollary 3 . Let x ∈ Rd be an arbitrary d dimensional input vector . Then , the classification result
ˆy := sgn( f ( x ; fi
⊤ ∗ new ) ) = sgn(x
∗ new ) fi satisfies
ˆy =
 +1 new ) ≥ 0 , ∗ ⊤ if L(x fi −1 ∗ ⊤ if U(x new ) < 0 , fi unknown otherwise ,
Corollary 3 is useful in transductive setups [ 19 ] where we are only interested in the class labels of the prespecified set of test inputs . 3.3 Quick leave one out cross validation
In LOOCV , we repeat leaving out a single instance from the training set , and check whether it is correctly classified or not by the new classifier which is trained without the left out instance . Thus , each step of LOOCV computation can be considered as an incremental operation with nA = 0 and nR = 1 . Denoting the left out instance as ( xh , yh ) , h ∈ [ nold ] , the task is to inquire whether the left out instance is correctly classified or not , which is known by checking the sign of yh f ( xh ; fi
∗ ⊤ new ) = yhx h fi
∗ new .
Corollary 4 . Consider a single step of LOOCV computation where an instance ( xh , yh ) , h ∈ [ nold ] , is left out . Then ,
L(yh f ( xh ; fi U(yh f ( xh ; fi new ) ) > 0 ⇒ ( xh , yh ) is correctly classified ∗ new ) ) < 0 ⇒ ( xh , yh ) is mis classified ∗
4 . TIGHTENING LINEAR SCORE BOUNDS
VIA A SUBOPTIMAL SOLUTION
In the previous section we introduced a framework that can quickly fi compute a lower and an upper bounds of a linear score of the new classifier . Unfortunately , it is not always the case that these bounds are sufficiently tight for making a desired inference on the new clas∗ ⊤ sifier . For example , if the lower and the upper bounds of x new do not have the same sign for a test input x , we cannot tell which class it would be classified to . In this section we discuss how to deal with such a situation .
The simplest way to handle such a situation is just to use conventional incremental learning algorithms . If we completely solve the optimization problem ( 2 ) by an incremental learning algorithm , ∗ we can obtain fi new itself . However , if our goal is only to make a particular inference about the new classifier , we do not have to solve the optimization problem ( 2 ) completely until convergence . In this section we propose a similar framework for computing a lower and an upper bounds of a linear score by using a suboptimal solution before convergence which would be obtained during the optimization of problem ( 2 ) .
We denote such a suboptimal solution as ˆfinew . In order to compute the bounds , we use the gradient information of the problem ( 2 ) , which we denote g( ˆfinew ) :=
1 nnew
∇ℓi( ˆfinew ) + λ ˆfinew .
( 13 )
∑ i∈Dnew
⊤ fi
:=
⊤ fi
⊤ fi new ≥ ˆL( ∗ ⊤ ˆfinew − λ−1 new ≤ ˆU( ∗ ⊤ ˆfinew − λ−1
2 ⊤ fi
∗ new ) ⊤
∗ new ) ⊤ g( ˆfinew ) − λ−1
2
∥∥∥g( ˆfinew)∥ ,
( 14a )
( 14b )
The complexity of computing the gradient vector from scratch is O(nnewd ) . However , if we are using a gradient based optimization algorithm such as conjugate gradient or quasi Newton methods , we should have already computed the gradient vector in each iteration of the optimization algorithm . The following theorem provides a lower and an upper bound of a linear score by using the current gradient information . If we already have computed g( ˆfinew ) , these bounds can be obtained very cheaply . Theorem 5 . For an arbitrary vector ∈ Rd , the linear score ∗ ⊤ new satisfies fi
:=
∥∥∥g( ˆfinew)∥ . A nice property of the bounds in ( 14 ) is that the tightness g( ˆfinew ) +
2
λ−1 2
ˆU(
⊤ new ) − ˆL( ∗
⊤ fi new ) = λ−1∥∥∥g( ˆfinew)∥ ∗ fi is linear in the norm of the gradient ∥g( ˆfinew)∥ . It means that , as the optimization algorithm for ( 2 ) proceeds , the gap between the lower and the upper bounds in ( 14 ) decreases , and it converges to zero as the solution converges to the optimal one . Theorem 5 can be used as a stopping criterion for incremental learning optimization problem ( 2 ) . For example , in a sensitivity analysis of class labels , one can proceed the optimization process until the signs of the lower and the upper bounds in ( 14 ) become same .
5 . NUMERICAL EXPERIMENTS
In this section we describe numerical experiments . In §5.1 we illustrate the tightness and the computational efficiency of our bounds in two sensitivity analysis tasks described in §2.2 and §23 In §5.2 we apply our framework to LOOCV computation as described in §2.4 and compare its performance with conventional LOOCV computation methods .
Table 1 summarizes the datasets used in the experiments . They are all taken from libsvm dataset repository [ 4 ] . For the experiments in §5.1 , we used larger datasets D5 D8 . For LOOCV experiments in §5.2 , we used smaller datasets D1 D4 . As examples of the loss function ℓ , we used LR loss ( 3 ) and SVM loss ( 4 ) . In §5.1 we only show the results on logistic regression . In §5.2 we compare our results on SVMs with conventional LOOCV methods particularly designed for SVMs . For logistic regression , we only compare our framework with conventional incremental learning algorithm because there is no particular LOOCV computation method for logistic regression . As an incremental learning algorithm , which is used as competitor and as a part of our algorithm for LOOCV computation , we used the approach in [ 18 ] . All the computations were conducted by using a single core of an HP workstation Z820 ( Xeon(R ) CPU E5 2693 ( 3.50GHz ) , 64GB MEM ) . 5.1 Results on two sensitivity analysis tasks
Here we show the results on two sensitivity analysis tasks described in §2.2 and §23 We empirically evaluate the tightness of the bounds and the computational costs for larger datasets D5D8 . First , we see how the results change as the number of added and/or removed instances changes among nA +nR ∈ {0.01 % , 0.02 % , 0.05 % , 0.1 % , 0.2 % , 0.5 % , 1%} of the entire training set size nold . Next , we see the results when the number of the entire training set
889 Table 1 : Benchmark datasets used in the experiments . dataset name sonar splice w5a a7a a9a ijcnn cod rna kdd2010
D1 D2 D3 D4 D5 D6 D7 D8 ntrain 208 1000 9888 16100 32561 49990 59535 d 60 60 300 123 123 22 8 ntest not used not used not used not used 16281 91701 271617
> 8 million
>20 million
> 0.5 million
∗ all
←solve ( 1 ) , h ← 1 , err ← 0
Algorithm 1 Proposed LOOCV method ( op1 ) Input : {(xi , yi)}i∈[nold ] 1 : fi 2 : while h ≤ nold do ∗ if U(yh f ( xh ; fi ( −h ) ) < 0 then 3 : err ← err + 1 4 : else if L(yh f ( xh ; fi 5 : ←solve ( 2 ) by incremental learning algorithm ∗ 6 : ( −h ) fi ⊤ if yhx 7 : h fi err ← err + 1 8 : 9 : 10 : 11 : 12 : end while Output : LOOCV error : err/nold end if end if h ← h + 1
∗ ( −h ) ) < 0 then
< 0 then
∗ ( −h ) size changes among nold ∈ {10 % , 20 % , . . . , 90 % , 99%} of ntrain , while the number of added and/or removed instances is fixed to nA + nR = 0001ntrain new , j ) − L(β∗
In the first sensitivity analysis task about coefficients ( see §2.2 and §3.1 ) , we simply computed the difference between the upper and the lower bounds U(β∗ new , j ) for evaluating the tightness of the bounds . For the second sensitivity analysis task about class labels ( see §2.3 and §3.2 ) , we examined the percentage of the test instances for which the signs of the lower and the upper bounds are same . Remember that the class label can be immediately available when the lower and the upper bounds have same sign .
Table 2 shows the results for the former task . ( Figure 3 depicts the results on D8 as an example)5 . These results indicate that the bounds are fairly tight if the nA + nR is relatively smaller than nold . The computational costs of our proposed framework ( blue thick curves ) are negligible compared with the costs of actual incremental learning ( red thick curves ) .
Table 3 shows the results for the latter task ( Figure 4 depicts the results on D8 as an example ) . The results here indicate that , in most cases , the bounds are sufficiently tight for making the signs of the lower and the upper bounds same . It means that , in most cases , the new class labels after incremental operation are available without actually updating the classifier itself .
The results presented here were obtained with the regularization parameter λ = 001 5.2 Leave one out cross validation
We applied the proposed framework to LOOCV task , and compare its computational efficiency with existing approaches . We consider two options . In the first option ( op1 ) , we only used the method described in §33 In the second option ( op2 ) , we also used the method described in §4 . Algorithm 1 is the pseudo code for
5Due to the space limitation , Tables 2 and 3 only show the results obtained when nA + nR was changed . computing LOOCV errors by using the proposed framework with op1 .
For SVMs , several LOOCV methods have been studied in the literature [ 19 , 10 ] . For the experiments with SVM loss , we thus compare our approach with the methods in [ 19 ] and [ 10 ] . The former approach merely exploits the fact that adding and/or removing nonsupport vectors does not change the classifier . The method called ∗ ξ α estimator [ 10 ] also provides a lower bound of yh f ( xh ; fi new ) ∗ without actually obtaining fi new . For the experiments with logistic regression loss , we compare our approaches only with incremental learning approach [ 18 ] because there are no other competing methods .
We used the above LOOCV computation methods in model selection tasks for linear and nonlinear classification problems . In linear case , the task is to find the regularization parameter λ ∈ {2−20 , 2−19 , . . . , 20} that minimizes the LOOCV error . In nonlinear case , we used Gaussian RBF in the form of ϕk(x ) = exp(−γ∥x − xk∥2 ) , where k ∈ [ 100 ] were randomly selected from [ nold ] . Here , the task is to select the optimal combination of ( λ , γ ) ∈ {2−15 , 2−14 , . . . , 2−5} × {2−5 , 2−4 , . . . , 25} that minimizes the LOOCV error .
For further speed up , we also conducted experiments with two simple tricks . In the first trick we used the lower and the upper bounds of the LOOCV error itself6 . If the lower bound of one model is greater than the upper bound of another model , the former model would never be selected as the best model , meaning that the LOOCV error computation process can be stopped . The second simple trick is to conduct incremental learning operations in the in∗ creasing order of yh f ( xh ; fi old ) . It is based on a simple observation ∗ that the class label of an instance whose yh f ( xh ; fi old ) value is small tends to be mis classified . Note that these two tricks can be used not only for our proposed framework , but also for other competing approaches .
Tables 4 and 5 show the results without and with the tricks , respectively . We see that the computational cost of our proposed framework ( especially op2 ) are much smaller than competing methods . It indicates that our bounds for LOOCV is tighter in many cases than the existing bounds for LOOCV error computation .
6 . CONCLUSIONS AND FUTURE WORKS In this paper we introduced a novel framework for sensitivity analysis of large scale classification problems . The proposed framework provides a lower and an upper bounds of a general linear score on the updated classifier without actually re optimized it . The advantage of the proposed framework is that the computational cost only depends on the sizes of the modified instances , which is particularly advantageous in typical sensitivity analysis task where only relatively small number of instances are updated . We discussed three tasks to which the proposed framework can be applied . As a future work , we plan to apply the proposed framework to stream learning .
7 . ACKNOWLEDGEMENT
For this work , IT was partially supported by JST CREST , MEXT
Kakenhi 26106513 , and MEXT Kakenhi 26106513 .
8 . REFERENCES [ 1 ] P . D . Bertsekas . Nonlinear Programming . Athena Scientific ,
1999 .
6Note that , when one already knows that some of the left instances are correctly classified or not , the LOOCV error itself can be bounded .
890 0.01 %
Incremental
D5 tightness
NA time [ sec ]
4.57e 02 ( ±6.38e 03 )
D6 tightness
NA time [ sec ]
8.42e 02 ( ±1.87e 02 )
D7 tightness
NA time [ sec ]
1.30e 01 ( ±2.88e 02 )
D8 tightness
NA time [ sec ]
8.51e+01 ( ±3.00e+00 ) proposed 5.68e 03 ( ±3.29e 03 ) 4.47e 06 ( ±4.99e 07 ) 1.31e 03 ( ±8.35e 04 ) 6.37e 06 ( ±2.50e 06 ) 2.00e 03 ( ±7.78e 04 ) 6.47e 06 ( ±1.18e 06 ) 2.98e 04 ( ±8.96e 06 ) 1.53e 01 ( ±8.24e 03 )
( nA + nR)/nold
0.1 %
Incremental
NA
5.41e 02 ( ±2.37e 03 )
NA
8.58e 02 ( ±8.23e 03 )
NA
1.65e 01 ( ±2.13e 02 )
NA
1.32e+02 ( ±1.13e+01 ) proposed 1.94e 02 ( ±5.69e 03 ) 2.26e 05 ( ±4.96e 07 ) 5.08e 03 ( ±9.33e 04 ) 3.21e 05 ( ±1.38e 06 ) 6.83e 03 ( ±2.33e 03 ) 3.03e 05 ( ±3.34e 06 ) 9.45e 04 ( ±2.11e 05 ) 1.82e 01 ( ±1.17e 02 )
1 %
Incremental
NA
6.16e 02 ( ±5.32e 03 )
NA
9.97e 02 ( ±1.73e 02 )
NA
1.90e 01 ( ±2.36e 02 )
NA
1.78e+02 ( ±2.13e+01 ) proposed 6.63e 02 ( ±1.72e 02 ) 1.95e 04 ( ±7.45e 07 ) 1.56e 02 ( ±2.92e 03 ) 2.84e 04 ( ±7.55e 06 ) 2.27e 02 ( ±9.20e 03 ) 2.38e 04 ( ±2.31e 05 ) 2.98e 03 ( ±3.89e 05 ) 3.59e 01 ( ±1.63e 02 )
Table 2 : Results on sensitivity analysis of coefficients . The tightness of the bounds and the computation time in seconds are listed ( λ = 001 )
Figure 3 : Results on sensitivity analysis of coefficients for D8 . The tightness of the bounds and the computation time in seconds are plotted ( λ = 001 )
[ 2 ] S . Boyd and L . Vandenberghe . Convex optimization .
Cambridge University Press , 2004 .
[ 3 ] G . Cauwenberghs and T . Poggio . Incremental and decremental support vector machine learning . In Advances in Neural Information Processing Systems , 2001 .
[ 4 ] C . Chang and C . Lin . LIBSVM : A Library for Support
Vector Machines . ACM Transactions on Intelligent Systems and Technology , 2:1–39 , 2011 .
[ 5 ] D . DeCoste and K . Wagstaff . Alpha seeding for support vector machines . In ACM SIGKDD Conference on Knowledge Discovery and Data Mining , 2000 .
[ 6 ] L . El Ghaoui , V . Viallon , and T . Rabbani . Safe feature elimination in sparse supervised learning . Pacific Journal of Optimization , 2012 .
[ 7 ] S . Fine and K . Scheinberg . Incremental learning and selective sampling via parametric optimization framework for SVM . In Advances in Neural Information Processing Systems , 2001 .
[ 8 ] T . Hastie , R . Tibshirani , and J . Friedman . The elements of statistical learning . Springer , 2001 .
[ 9 ] T . Jaakkola and D . Haussler . Probabilistic kernel regression models . In International Conference on Artificial Intelligence and Statistics , 1999 .
[ 10 ] T . Joachims . Estimating the generalization performance of a
SVM efficiently . In International Conference on Machine Learning , 2000 .
[ 11 ] M . Karasuyama and I . Takeuchi . Multiple incremental decremental learning of support vector machine . In Advances in Neural Information Processing Systems , 2009 .
[ 12 ] P . Laskov , C . Gehl , S . Krüger , and K . R . Müller . Incremental support vector learning : analysis , implementation and applications . Journal of Machine Learning Research , 7:1909–1936 , 2006 .
[ 13 ] Z . Liang and Y . Li . Incremental support vector machine learning in the primal and applications . Neurocomputing , 72:2249–2258 , 2009 .
[ 14 ] J . Liu , Z . Zhao , J . Wang , and J . Ye . Safe Screening with Variational Inequalities and Its Application to Lasso . In International Conference on Machine Learning , volume 32 , 2014 .
0 0.0005 0.001 0.0015 0.002 0.0025 0.003 0.01 0.02 0.05 0.1 0.2 0.5 1 0 50 100 150 200tightness of the boundscomputation time 100(nA + nR)/nold tightness of the bounds computation time of the incremental learning computation time of the proposed framework 0 0.002 0.004 0.006 0.008 0.01 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0.99 0 20 40 60 80 100 120 140tightness of the boundscomputation time nold/ntrain tightness of the bounds computation time of the incremental learning computation time of the proposed framework 891 0.01 %
Incremental
D5 fraction of “ same sign"
NA time [ sec ]
6.80e 02 ( ±1.09e 02 )
D6 fraction of “ same sign"
NA time [ sec ]
1.13e 01 ( ±2.13e 02 )
D7 fraction of “ same sign"
NA time [ sec ]
1.40e 01 ( ±3.26e 02 )
D8 fraction of “ same sign"
NA time [ sec ]
1.25e+02 ( ±7.47e+00 ) proposed 9.96345e 01 ( ±1.68e 03 ) 4.15e 04 ( ±1.90e 05 ) 1.00000e+00 ( ±0.00e+00 ) 2.80e 03 ( ±1.50e 04 ) 9.99728e 01 ( ±5.51e 05 ) 5.30e 03 ( ±4.20e 04 ) 9.99869e 01 ( ±7.49e 06 ) 1.40e 01 ( ±9.27e 03 )
( nA + nR)/nold
0.1 %
Incremental
NA
7.89e 02 ( ±1.78e 02 )
NA
1.10e 01 ( ±1.38e 02 )
NA
1.55e 01 ( ±3.42e 02 )
NA
1.48e+02 ( ±1.80e+01 ) proposed 9.88742e 01 ( ±4.33e 03 ) 4.36e 04 ( ±1.04e 05 ) 1.00000e+00 ( ±0.00e+00 ) 2.86e 03 ( ±1.63e 04 ) 9.99354e 01 ( ±1.71e 04 ) 5.15e 03 ( ±1.31e 04 ) 9.99583e 01 ( ±1.76e 05 ) 1.67e 01 ( ±8.01e 03 )
Incremental
NA
8.82e 02 ( ±1.98e 02 )
NA
1.37e 01 ( ±1.37e 02 )
NA
1.96e 01 ( ±2.45e 02 )
NA
1.67e+02 ( ±1.25e+01 )
1 % proposed 9.65412e 01 ( ±1.01e 02 ) 6.38e 04 ( ±3.84e 05 ) 1.00000e+00 ( ±0.00e+00 ) 3.14e 03 ( ±1.20e 04 ) 9.98612e 01 ( ±4.63e 04 ) 5.76e 03 ( ±4.57e 04 ) 9.98672e 01 ( ±9.61e 05 ) 3.49e 01 ( ±2.14e 02 )
Table 3 : Results on sensitivity analysis on class labels . The fraction of the test instances whose lower and upper bounds of the decision score have same signs , and the computation time in seconds are listed ( λ = 001 )
Figure 4 : Results on sensitivity analysis of class labels for D8 . The fraction of the test instances whose lower and upper bounds of the decision score have same signs , and the computation time in seconds are plotted ( λ = 001 )
[ 15 ] K . Ogawa , Y . Suzuki , and I . Takeuchi . Safe screening of non support vectors in pathwise SVM computation . In International Conference on Machine Learning , 2013 .
[ 16 ] A . Shibagaki , Y . Suzuki , and I . Takeuchi . Approximately optimal selection of regularization parameters in cross validation for regularized classifiers . arXiv , 2015 . [ 17 ] A . Shilton , M . Palaniswami , D . Ralph , and A . C . Tsoi . Incremental training of support vector machines . IEEE Transactions on Neural Networks , 16:114–131 , 2005 .
[ 18 ] C . H . Tsai , C . Y . Lin , and C . J . Lin . Incremental and decremental training for linear classification . In ACM SIGKDD Conference on Knowledge Discovery and Data Mining , 2014 .
[ 19 ] V . Vapnik . The Nature of Statistical Learning Theory .
Springer , 1996 .
[ 20 ] V . Vapnik and O . Chapelle . Bounds on Error Expectation for
Support Vector Machines . Neural Computation , 12:2013–2036 , 2000 .
[ 21 ] J . Wang , J . Zhou , J . Liu , P . Wonka , and J . Ye . A Safe
Screening Rule for Sparse Logistic Regression . In Advances in Neural Information Processing Sysrtems , 2014 . [ 22 ] Z . Xiang , H . Xu , and P . Ramadge . Learning sparse representations of high dimensional data on large scale dictionaries . In Advances in Neural Information Processing Sysrtems , 2011 .
[ 23 ] T . Zhang . Leave one out bounds for kernel methods . Neural computation , 15:1397–1437 , 2003 .
APPENDIX A . PROOFS
In this section we prove Theorems 1 . First we present the fol lowing proposition .
Proposition 6 . Consider the following general problem :
ϕ(z ) st z ∈ Z , min z
( 15 )
0 0.2 0.4 0.6 0.8 1 0.01 0.02 0.05 0.1 0.2 0.5 1 0 50 100 150 200Fraction of ’s ame sign’ computation time 100(nA + nR)/nold Fraction of ’s ame sign’ computation time of the incremental learning computation time of the proposed framework 0 0.2 0.4 0.6 0.8 1 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 0.99 0 20 40 60 80 100 120 140 160Fraction of ’s ame sign’ computation time nold/ntrain Fraction of ’s ame sign’ computation time of the incremental learning computation time of the proposed framework 892 incremental
13.76 33.19 52.87 337.87 1167.65 96317.45 18824.74 > 3 days existing [ 19 ] 10.46 24.53 51.04 312.44 458.12 77562.37 14303.27 > 3 days
SVM
[ 10 ] 10.37 15.63 44.28 246.10 229.57 66427.27 12177.41 183208.76
D1
D2
D3
D4 linear nonlinear linear nonlinear linear nonlinear linear nonlinear proposed op1 7.74 17.33 29.01 201.58 203.60 58480.90 8506.30 202972.55 op2 5.17 8.48 15.93 124.79 123.69 46301.53 2088.63 106169.25 existing incremental
13.95 29.31 58.22 268.71 4075.96 91503.32 25197.11 > 3 days
Logistic regression proposed op1 8.32 17.23 28.63 165.42 726.68 34972.51 10563.92 125300.26 op2 2.78 6.55 13.25 120.57 346.30 28856.92 1219.36 47474.64
Table 4 : Computation time [ sec ] of model selection based on LOOCV ( without tricks ) . incremental
8.88 14.59 17.88 164.39 693.34 9018.88 6132.45 168806.92 existing [ 19 ] 8.69 13.13 17.88 151.57 345.10 5805.36 5536.21 139810.43
SVM
[ 10 ] 8.53 10.26 16.65 138.15 226.65 4772.59 4121.21 122264.81
D1
D2
D3
D4 linear nonlinear linear nonlinear linear nonlinear linear nonlinear proposed op1 5.79 9.00 1.44 106.15 197.68 1898.11 353.21 46166.76 op2 4.45 4.50 0.83 47.66 124.81 1352.38 93.67
23032.34 existing incremental
5.41 12.32 20.49 125.23 2012.49 8495.91 12027.28 143660.82
Logistic regression proposed op1 3.96 7.42 1.20 76.95 563.09 1184.83 663.19 35676.66 op2 1.66 2.54 0.55 44.44 322.47 745.02 187.13 14920.24
Table 5 : Computation time [ sec ] of model selection based on LOOCV ( with tricks ) . where ϕ : Z → R is a differentiable convex function and Z is a convex set . Then a solution z∗ is the optimal solution of ( 15 ) if and only if
∗ − z ) ≤ 0 ∀ z ∈ Z , where ∇ϕ(z∗ ) is the gradient vector of ϕ at z = z∗ .
∇ϕ(z ∗
⊤ )
( z
See , for example , Proposition 212 in [ 1 ] or Section 423 in [ 2 ] for the proof of Proposition 6 . fi
(
Proof of Theorem 1 . From Proposition 6 and the optimality of ∗ new for the problem ( 2 ) ∇ℓi(fi
∑
∗ new ) + λfi old ) ≤ 0 . ∗ new − fi ∗
)⊤
∗ new
( 16 )
( fi
1 nnew i∈Dnew
− fi ∗ ∗ ( fi new ) , old new − fi ∗ ∗ old ) . ( fi new − fi ∗
∗ old ) .
ℓi(fi ℓi(fi new ) + ∇ℓi(fi ⊤ ∗ ∗ new ) old ) + ∇ℓi(fi ∗ ∗ ⊤ old )
From the convexity of ℓi , old ) ≥ ℓi(fi ∗ new ) ≥ ℓi(fi ∗ Using ( 17 ) and ( 18 ) , old ) ≥ ∇ℓi(fi ∇ℓi(fi ∗ ∗ ⊤ old ) By summing up ( 19 ) for all i ∈ Dnew , new − fi ∗ ( fi new − fi ∗ ∗ old ) . new − fi ∗ ∑ ∑
∇ℓi(fi ∇ℓi(fi
∗ new )
∗ new ) i∈Dnew
∗ old )
∗ old )
( fi
( fi
( fi
≥
⊤
⊤
⊤ i∈Dnew
( 17 ) ( 18 )
( 19 )
( 20 )
Substituting ( 20 ) into ( 16 ) ,
∑ i∈Dnew
1 nnew
∇ℓi(fi
∗ ⊤ old ) new − fi ∗
( fi
∗ old ) + λfi
∗⊤ new(fi new − fi ∗ old ) ≤ 0 . ∗
( 21 )
)flflflflflfl2 flflflflflflfi
≤
By completing the square of ( 21 ) , we have
(
∑ new − 1 ( ∗ 2 flflflflflflfi
1 2
∗ old
∗ old fi
+
− λ−1 ∑ nnew
∗ old )
∇ℓi(fi )2 flflflflflfl i∈Dnew ∇ℓi(fi
∗ old )
λ−1 nnew ∗ old is the optimal solution of ( 1 ) , i∈Dnew
.
Furthermore , noting that fi λ−1 nold
∗ old fi
+
∑ i∈Dold
Using ( 24 ) and ( 9 ) ,
∇ℓi(fi
∗ old ) = 0 .
∑ i∈A
∗ old ) + old ) − ∗
) ∇ℓi(fi
∑ i∈R
∇ℓi(fi
∗ old )
∗ old
+ ( nA + nR)∆s
( nA + nR)λ−1
∆s
( 22 )
( 23 )
( 24 )
( 25 )
)
( 26 )
( 27 )
( 28a )
∗ old )
∇ℓi(fi
λ−1 nnew
∑ ( ∑ ∇ℓi(fi ( i∈Dold − λnoldfi ∗ old fi
+
= i∈Dnew λ−1 nnew λ−1 nnew = − nold nnew
=
Substituting ( 26 ) into ( 22 ) , flflflflflflfi nnew
( flflflflflfl nA − nR nnew
( new − ∗
1 2 nold + nnew
2nnew ∗ old fi fi
+
≤
Let
)flflflflflfl2
∗ old
− ( nA + nR)λ−1 )2 2nnew ( nA + nR)λ−1
∆s
∆s flflflflflfl nnew m = nold + nnew
2nnew
∗ old fi
− ( nA + nR)λ−1
2nnew
∆s
893 flflflflflfl nA − nR nnew
1 2 r =
∗ old fi
+
( nA + nR)λ−1 nnew flflflflflfl .
∆s
( 28b )
Then , ( 27 ) is compactly written as fi new ∈ Ω , where Ω := {fi | ∥fi − m∥2 ≤ r2} . ∗
( 29 ) indicates that the new optimal solution fi
( 29 ) ∗ new is within a ball with center m and radius r . Thus , we have a lower and an upper ⊤ bounds of a linear score ⊤
∗ new as follows : fi ⊤ ∗ new ) := min fi∈Ω ∗ new ) := max fi∈Ω fi , ⊤ fi .
L( fi
⊤
U( fi
( 30 )
( 31 )
In fact , the solutions of ( 30 ) and ( 31 ) can be analytically obtained , ∗ and thus the lower bound L( new ) can be explicitly obtained by using Lagrange multiplier method . Using a Lagrange multiplier α > 0 , the problem ( 30 ) is rewritten as
∗ new ) and the upper bound U( fi fi
⊤
⊤
⊤
⊤ max α>0
( fi st ∥fi − m∥2 ≤ r2 ( − αr2 + min
) fi + α(∥fi − m∥2 − r2 ) α∥fi − m∥2 + ⊤
( ( − αr2 − ∥∥2
H(α ) :=
+ fi
⊤ fi
) m
,
) )
4α min fi = min fi
= max α>0
= max α>0 where α is strictly positive because the constraint ∥fi− m∥2 ≤ r2 is strictly active at the optimal solution . By letting ∂H(α)/∂α = 0 , the optimal α is written as
α∗
:= Substituting α∗ into H(α ) ,
∥∥ 2r
= arg max α>0
H(α ) .
⊤ m − ∥∥r = max
H(α ) .
α>0
Therefore ,
L(
⊤
∗ new ) = min fi∈Ω fi
⊤
⊤ m − ∥∥r fi =
( 31 ) can be similarly obtained as ∗ new ) = max fi∈Ω
U( fi
⊤
⊤ fi =
⊤ m + ∥∥r .
( 32 )
( 33 )
By substituting m and r in ( 27 ) into ( 32 ) and ( 33 ) , we have ( 10a ) and ( 10b ) .
Theorem 5 can be shown in a similar way as above .
894
