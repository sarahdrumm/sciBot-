A Decision Tree Framework for Spatiotemporal
Sequence Prediction
Taehwan Kim
Yisong Yue
Toyota Technological Institute at Chicago
California Institute of Technology taehwan@ttic.edu
Sarah Taylor
Disney Research Pittsburgh sarahtaylor@disneyresearchcom yyue@caltech.edu
Iain Matthews
Disney Research Pittsburgh iainm@disneyresearch.com
ABSTRACT We study the problem of learning to predict a spatiotemporal output sequence given an input sequence . In contrast to conventional sequence prediction problems such as part of speech tagging ( where output sequences are selected using a relatively small set of discrete labels ) , our goal is to predict sequences that lie within a highdimensional continuous output space . We present a decision tree framework for learning an accurate non parametric spatiotemporal sequence predictor . Our approach enjoys several attractive properties , including ease of training , fast performance at test time , and the ability to robustly tolerate corrupted training data using a novel latent variable approach . We evaluate on several datasets , and demonstrate substantial improvements over existing decision tree based sequence learning frameworks such as SEARN and DAgger .
Categories and Subject Descriptors : I26 Artificial Intelligence : Learning Induction General Terms : Algorithms ; Experimentation . Keywords : Decision Trees ; Sequence Prediction .
1 .
INTRODUCTION
Contextual sequence prediction is an important problem in many domains , ranging from natural language processing tasks such as part of speech tagging and named entity recognition [ 1 , 6 , 17 ] , to computational biology tasks such as sequence alignment [ 10 , 28 , 38 ] . The basic setting can be defined as generating a sequential output given a sequential input . For example , in part of speech tagging , the input can be a sequence of words ( ie , a sentence ) , and the output is the corresponding sequence of part of speech tags .
In this paper , we study the problem of spatiotemporal sequence prediction . In contrast to conventional sequence prediction where output sequences are typically selected using a relatively small set of discrete labels ( eg , a set of part of speech tags ) , our goal is to predict sequences that lie within a high dimensional continuous output space . One example is visual speech generation , where the goal is to predict a sequence of face configurations given a sequence of audio or phonetic inputs [ 33 , 40 ] . Other example applications include speech synthesis [ 34 ] and human motion prediction [ 15 ] .
Predicting spatiotemporal sequences presents several technical challenges . First , outputs can vary continuously , which leads to a high dimensional sequential regression problem . Most notably , specific spatial patterns can develop over multiple frames . For example , accurate visual speech animation requires capturing a wide range of “ temporal curvature ” in lip motions , from smoothly to sharply varying . A second challenge stems from the fact that , for many applications , it can be difficult to specify a semantically meaningful feature representation . As such , conventional sequence prediction approaches ( cf . [ 1 , 6 , 17 ] ) are unlikely to produce accurate models , since they typically are designed to predict over discrete output labels , make strong Markovian assumptions , and are linear models with respect to the feature representation .
In this paper , we propose a simple yet effective decision tree framework for learning an accurate non parametric spatiotemporal sequence predictor . Decision trees are an attractive model class due their ability to capture near arbitrary non linear predictors based on the input features [ 21 , 24 ] . One challenge with decision trees is that they cannot be naturally applied to sequence prediction problems . We present an approach to decompose spatiotemporal sequence prediction into a series of overlapping fixed length multivariate regression problems , which can be naturally trained using decision trees . For example , in our experiments on visual speech animation , our base decision tree model is a 150 dimensional regressor . Our approach also enjoys attractive computational properties , including ease of training and fast performance at test time .
Our approach is complementary to existing decomposition approaches such as SEARN [ 7 ] and DAgger [ 25 ] . The main difference is that our decomposition focuses on capturing the local temporal curvature of spatiotemporal sequences , whereas SEARN and DAgger focus on controlling for cascading error effects due to longer range dependencies . We show empirically that our approach consistently outperforms or is competitive with SEARN and DAgger , while being significantly faster to train .
A third challenge of working with spatiotemporal sequence data is that such data is often partially corrupted , eg , with missing values or misalignments [ 20 , 36 ] . We further propose a latent variable extension to our decision tree framework that can robustly tolerate such corrupted data . Both our main framework as well as the latent variable extension are compatible with using ensemble methods such as random forests [ 3 ] as well as single decision trees .
Our contributions can be summarized as follows : • We propose a discriminative learning framework based on decision trees for spatiotemporal sequence prediction . Our approach decomposes the prediction task into a series of over
577 lapping fixed length multivariate regression problems , which can be naturally trained using decision trees . Our approach enjoys attractive computational properties , including ease of training and fast performance at test time .
• We propose a novel latent variable extension that can robustly tolerate corrupted training data such as missing values and misalignments . This extension is compatible with using random forests as well as decision trees .
• We evaluate our approach using several benchmark datasets and demonstrate competitive or substantially better performance over existing decomposition approaches such as SEARN [ 7 ] and DAgger [ 25 ] , as well as state of the art baselines based on HMMs [ 40 ] and semi Markov models [ 33 ] .
• We showcase the practicality of our approach for an application in data driven visual speech animation . In a user study , we found that our approach generates significantly more realistic animations when compared to several strong baselines .
• We evaluate the robustness of our latent variable extension in dealing with partially corrupted training data such as missing values and misalignments . Our experiments demonstrate that our latent variable extension is resilient to a substantial amount of corrupted training data .
2 . RELATED WORK
The study of sequence prediction enjoys a long history within the machine learning and related communities . Early work in sequence labeling centered around the use of generative models such as hidden Markov models ( HMMs ) and stochastic grammars [ 10 , 22 ] . However , many sequence prediction tasks require conditioning on an input sequence or some other context . For example , in part ofspeech tagging , one must predict a sequence of part of speech tags conditioned on an input sequence of words ( ie , a sentence ) . Indeed , contextual or conditional sequence prediction problems are pervasive across the sciences , ranging from natural language processing [ 1 , 6 , 17 ] to computation biology [ 28 , 38 ] , and can be difficult to accurately model using generative models such as HMMs . The need to better tackle contextual sequence prediction has led to the development of discriminative learning methods such as structured perceptrons [ 6 ] , Conditional Random Fields [ 17 , 26 ] , MaxMargin Markov Networks [ 32 ] , and structural Support Vector Machines [ 1 , 35 ] , as well methods for modeling more complex output spaces [ 9 , 37 ] ( eg , higher order sequential models ) . These approaches typically learn linear models over sequence based features to directly maximize the accuracy of resulting contextual sequence predictor . From the perspective of our work , two important limitations of this line of research are the inability to naturally deal with the continuous nature of spatiotemporal outputs , and the reliance on having a semantically rich feature representation .
Spatiotemporal sequence modeling is an area of increasing interest due to the growing availability of spatiotemporal sequence data . Example domains include motion & pose tracking [ 15 , 27 , 33 , 40 ] , speech synthesis [ 34 ] , player tracking in sports [ 4 , 39 ] , and other behavioral tracking areas [ 11 , 42 ] . We are especially interested in settings where the goal is to predict a spatiotemporal output sequence given ( ie , conditioned on ) an input sequence or some other context . For example , in visual speech animation , the goal is to predict an animation sequence of a face given an audio or phonetic input sequence [ 27 , 33 , 40 ] . Because existing discriminative approaches for sequence prediction are largely limited to predicting discrete sequences , existing state of the art approaches to visual speech animation typically resort to continuous variants of generative approaches such as HMMs [ 40 ] and semi Markov models [ 33 ] .
Existing discriminative approaches for spatiotemporal modeling typically focus on predicting a discrete label over an entire spatiotemporal input sequence , such as predicting whether a given sequence belongs to a certain class ( cf . [ 11 , 14 , 19] ) . In contrast , we are interested in the “ reverse ” problem of predicting a spatiotemporal sequence , rather than classifying one .
Our approach is a decomposition or reduction approach that decomposes the spatiotemporal sequence prediction problem into a series of overlapping “ sliding window ” prediction problems . Decomposition approaches are attractive since they allow for utilizing powerful non parametric base models such as decision trees [ 21 , 24 ] ; such base models are difficult to apply directly to sequence prediction problems . Existing decomposition approaches for sequence prediction , such as SEARN [ 7 ] and DAgger [ 25 ] , are typically designed to control for cascading error effects from long range dependencies , and are complementary to our approach . Our approach instead focuses on accurately capturing the local temporal curvature of spatiotemporal sequences . Because of their selfrecurrent definition , SEARN and DAgger require iterative training of the base model , which can be quite slow . As we shall see in our experiments , our approach can dramatically outperform SEARN and DAgger , while being substantially faster to train .
Our work bears affinity to structured decision tree methods for tasks such as edge detection [ 8 ] and image labeling [ 16 ] , which also employ a sliding window approach . The main difference is that our output space is a continuous spatiotemporal sequence , with prediction goals such as generating realistic facial animations to match an accompanying audio track ; this leads to a different choice of decision tree base models . We also consider settings with corrupted training data , as described below .
One important challenge when dealing with spatiotemporal sequence data is the fact that the training data can often be partially corrupted . The two most common types of corruption are missing values [ 12 , 15 ] and misalignments [ 5 , 18 , 20 , 30 , 41 ] . Missing values commonly occur when the spatiotemporal data is generated from tracking data that has occlusions , such as in human motion capture and articulatory measurement datasets [ 15 , 36 ] . The typical approach to resolving missing values is data imputation , possibly using a low rank assumption [ 36 ] . Misalignments can arise due to imperfections in the tracking technology for generating the spatiotemporal training data [ 30 ] , or from natural temporal variability in the phonomenon being studied [ 18 , 20 , 41 ] , or both . Common techniques for resolving misalignment include variants of dynamic time warping [ 20 ] as well as curve alignment and clustering [ 13 ] .
For our setting , we consider the case where the output sequence ( ie , the spatiotemporal sequence to be predicted ) is corrupted in the training data , either due to missing values or misalignments . We propose a latent variable extension to our basic decomposition framework to jointly estimate a “ cleaner ” version of training data while learning a contextual spatiotemporal sequence predictor . Our extended framework can naturally incorporate many existing techniques for missing value imputation and misalignment correction . Other notable sequence modeling problems studied recently include machine translation [ 31 ] , and semantically aware sentiment analysis [ 29 ] . Such problems typically require modeling very longrange dependencies within the input sequence ( eg words far apart in the input sentence ) , and so are not well suited for our approach .
3 . THE LEARNING PROBLEM
Let x = hx1 , . . . , x|x|i denote an input sequence , and let y = hy1 , . . . , y|y|i denote a spatiotemporal output sequence . We use
578 bold face x and y to denote input and output sequences , respectively , and use unbolded x and y to refer to individual entries in the sequences , which we also refer to as tokens or frames . Each output frame y ∈ ℜD is represented as a point in some D dimensional space , and we use superscripts y(d ) to refer to individual dimensions in the output frame . We often think of the sequences as timevarying , ie , that frame yt temporally preceeds frame yt+1 . For example , in visual speech animation , x could correspond to an audio sequence , and y could correspond to an animation sequence of a face model with D degrees of freedom . Figure 1 depicts an illustration of x and y , which corresponds to a phonetic input sequence and a one dimensional spatiotemporal output sequence corresponding to one of the parameters of a face model animating to the word “ prediction ” .
Following the standard machine learning setup , our goal is to a learn a function h(x ) := y that maps input sequences to spatiotemporal output sequences . We restrict ourselves to the supervised learning scenario , where input/output pairs ( x , y ) are available for training and are assumed to come from some fixed distribution P ( x , y ) . The goal is to find a predictor h such that the risk ( ie , expected loss ) ,
LP ( h ) =Z ℓ(y , h(x))dP ( x , y ) ,
( 1 ) is minimized . In this paper , we take the view of spatiotemporal sequence prediction as a high dimensional regression problem , and thus use the squared L2 error ,
ℓ(a , b ) = ka − bk2
F ro , to measure imperfections in the predicton h(x ) when the true output sequence is y.1
Of course , P ( x , y ) is unknown . But given a training set of in put/output pairs drawn from P ( x , y ) ,
S = {(xi , yi)}N i=1 ,
( 2 ) we can instead approximately minimize ( 1 ) by minimizing the empirical risk ,
LS(h ) = X(x,y)∈S
ℓ(y , h(x) ) ,
( 3 ) which is equivalent to finding an h that minimizes the training loss .
3.1 Corrupted Training Data
We also consider the case where the output sequence ( ie , the training label ) may be corrupted in the training data . In particular , we can now rewrite our training set as
S = {(xi , ˜yi)}N i=1 ,
( 4 ) where each ˜yi is a potentially corrupted version of yi . Despite training on corrupted ˜y , our goal is to still learn a predictor that minimizes the risk on the original test distribution ( 1 ) . The two most common types of corruption are missing values [ 12 , 36 ] and misalignments [ 18 , 20 , 30 , 41 ] .
311 Missing Values
Missing values commonly occur when the spatiotemporal training data is generated from tracking data that has occlusions , such as in human motion and articulatory datasets [ 15 , 36 ] . For example , if y corresponds to an animation sequence of a hand performing fingerspelling , then each dimension in an output frame y can 1In general , one could employ any convex error function without significant modification to our approach .
Input speech :
“ P R E D I C T I O N ”
Frame 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22
( a ) x
Token p p r ih ih d d ih ih ih ih k k sh sh sh sh uh uh n
♣ r
✐✏
❞
✐✏
❦ s✏
✉✏
♥
( b ) y
✶✞✞
✎✞
✞
✲✎✞
✷
✹
✻
✽
✶✞
✶✷
✶✹
✶✻
✶✽
✷✞
✷✷
✷✹
❋ ✁✂✄ ☎✆✂✝✄ 
Figure 1 : Depicting an example ( a ) input x and ( b ) output y for the application of visual speech animation . Each dimension of y corresponds to a parameter of a face model . Only the first dimension of y is depicted . correspond to a specific tracked marker ( eg , the tip of a finger ) . Such markers naturally become occluded during the course of fingerspelling , which leads to missing values in the resulting y .
For any specific output frame y , the corresponding ( partially ) corrupted ˜y can be defined element wise as :
˜y(d ) =( ? y(d ) if y(d ) is missing otherwise
, where ? denotes a missing value that could take on any real value . More generally , one could also consider cases where the measurements for the output frames have been corrupted by noise ( eg , due to technology limitations ) , which leads to ˜y being defined as :
˜y(d ) = y(d ) + ǫ , for independently distributed random noise variables ǫ .
312 Misalignments
Misalignments can arise due to imperfections in the tracking technology for generating the spatiotemporal training data [ 30 ] , or from natural temporal variability in the phenomenon being studied [ 18 , 20 , 41 ] , or both . For simplicity , we restrict ourselves to nonwarping misalignments of the output spatiotemporal sequences . For example , if x corresponds to an audio sequence and y corresponds to the associated animation sequence , then x and y may not be perfectly aligned frame by frame .
For any y , the corresponding ˜y would be
˜y = shiftk(y ) , where shiftk(y ) is a shift operator that simply shifts the frames of y such that ˜yi = yi−k . We deal with boundary cases by padding the start and end of the spatiotemporal sequence y.2
More generally , one could also consider cases where the output sequences have been warped due to natural human variation or imperfections in performing certain actions [ 5 , 20 ] . For example , different people may form somewhat different lip shapes while speaking the same sentence . In that sense , one can consider all such observed trackings ˜y as some warping of an unobservable gold standard animation sequence y .
4 . DECISION TREE FRAMEWORK
Sequence prediction problems are distinguished from unstructured prediction problems ( eg , univariate regression or classification ) due to the assumption that there are salient dependencies 2Such practices are common in , eg , animation ( where a still pose is maintained at the start and end of the tracked sequence ) and audio synthesis ( where silence is maintained at the start and end of the output sequence ) .
579❉ ✟ ✠ ✡ ☛ ☞ ✟ ✌ ☛ ✍ 580 node . Each internal node is associated with a binary query on the input features ( eg , is the fifth input feature non negative? ) , with a positive query response leading to traversing one subtree , and a negative response leading to the other subtree . Each leaf node is associated with a static prediction . One can thus think of decision trees as a piece wise static ( wrt the input features ) function class that can approximate almost any prediction function .
For our setting , our base decision tree model h is a sliding window predictor that predicts ( D × Ky ) outputs in each leaf node ( D outputs for each of Ky frames ) . In essence , h is a ( D × Ky)−variate regression model . For example , in our application in visual speech animation , D = 30 and Ky = 5 , leading to a 150 variate regression problem .
We train h by creating a new training set ˆS of fixed length input/output pairs . For a specified input length Kx and output length Ky , we run Algorithm 1 over every x and y in S ( 2 ) to yield :
ˆS = {(ˆxj , ˆyj)}
ˆN j=1 .
( 5 )
Note that if the average length of ( x , y ) ∈ S is T , then ˆN ≈ T N . We can now rephrase our original learning goal ( 3 ) as finding an h to minimize the error on the new training set ˆS ( 5 ) : argminh∈H L ˆS(h ) ≡ argminh∈H X(ˆx,ˆy)∈ ˆS
ℓ(h(ˆx ) , ˆy ) ,
( 6 ) where H is the class of ( D×Ky)−dimensional multivariate regression trees , subject to some regularization constraint . Since decision trees define a partitioning over the training data ˆS , in practice , we regularize by enforcing a minimal leaf node size Nmin . Decision trees are typically trained via top down induction ( cf . [ 21 , 24 ] ) to greedily minimize the training loss .
Let ˆY denote a set of training labels ˆy that was partitioned to the same leaf node in h , and ˆX the corresponding inputs . Thus , we have that h(ˆx ) is the same for every ˆx ∈ ˆX , and the prediction of that leaf node is exactly the mean of ˆY ( in order to minimize squared loss ) . As such , one can rewrite the squared loss over any given leaf node of h with training labels ˆY as the unnormalized variance :
L2( ˆY ) = | ˆY|variance( ˆY )
= | ˆY|
Ky
D
Xt=1
Xd=1 i,tfififi variancen ˆy(d )
ˆyi ∈ ˆYo ,
( 7 ) where ˆy(d ) i,t is the d th dimension of t th frame of ˆyi , and | ˆY| corresponds to the number of training labels in ˆY . Our learning goal ( 6 ) then can be rewritten as : argminh∈H L2
ˆS(h ) ≡ argminh∈H
XˆY∈partitioning( ˆS,h )
L2( ˆY ) ,
( 8 ) where partitioning( ˆS , h ) corresponds to a partitioning of the training labels according to the leaf nodes of h . The variance formulation defined in ( 7 ) and ( 8 ) will be more convenient when developing our latent variable extension in Section 43
4.3 Latent Variable Extension
We now describe a latent variable extension to accommodate corrupted training data as described in Section 31 Each corrupted piece of training data is associated with a latent variable z that corresponds to the missing or corrupted information . In the case of missing values , each z corresponds to one specific missing value . In the case of misalignment , each z corresponds to the correct alignment of each complete input/output sequence pair ( x , y ) .
// with missing values // input and output window size // minimum leaf node size of base model
Algorithm 2 Training Procedure for Latent Variable Framework 1 : input : S 2 : input : Kx , Ky 3 : input : Nmin 4 : init : ˆS using Algorithm 1 5 : init : Z to default values 6 : repeat 7 : 8 : 9 : 10 : 11 : 12 : 13 : until convergence 14 : return : h , Z train h to minimize ( 9 ) repeat end for until convergence for z ∈ Z do infer z to minimize ( 9 )
The goal of the latent variable extension is to jointly infer the z ’s while training a good decision tree h . Let ˆS denote the decomposed version of the original training set S into overlapping fixedlength subsequences , and let Z denote the set of all latent variables . Given Z , one can produce a “ cleaned ” version of the training set , Φ( ˆS , Z ) . We instantiate Φ for missing values in Section 431 and for misalignments in Section 432 We can now extend our decomposed learning objective ( 8 ) to include latent variables Z : argminZ,h∈H L2
Φ( ˆS,Z)(h ) ,
( 9 ) where the goal now is to jointly learn h and infer Z . Note that when the training set S is not corrupted , then ( 9 ) reduces to ( 8 ) since there are no latent variables ( ie , Z = ∅ ) , and Φ( ˆS , Z ) = ˆS is just the identity function .
In practice , we solve ( 9 ) via alternating optimization , as described in Algorithm 2 . We first set Z to some default value ( Line 4 ) , and use the resulting Φ( ˆS , Z ) to train a decision tree h as decribed in Section 4.2 ( Line 6).3 Given a trained h , we then infer a better Z via coordinate descent on each z ∈ Z by finding a “ cleaner ” Φ( ˆS , Z ) that minimizes the loss of the leaf nodes of h ( Lines 7 11 ) .
The main novelty of our latent variable approach is that we can exploit a specific property that arises from combining our sliding window decomposition with a decision tree base model . In particular , our decomposition essentially creates Ky copies of each output frame y , which results in the same piece of corrupted training data z being placed into many different leaf nodes of the decision tree h . As a consequence , we can utilize the other training data in these leaf nodes to estimate a better z that can improve the purity ( ie , decrease the variance ) of the leaf nodes in h . We elaborate on this point below for missing values and misalignments .
431 Missing Values
In the missing values setting , each z ∈ Z corresponds to a specific missing measurement of some output frame ˜y(d ) in the original training set S . At a high level , we infer z by averaging over all the labels that belong to the same leaf nodes of h that z belongs to ( see ( 11 ) below ) . Figure 3 shows an illustration of this procedure . For this section , we use the index i to refer to a specific partially corrupted training example ˜yi from the original training set S , index t to refer to a specific frame ˜yi,t of ˜yi , and index d to refer to a specific dimension of the output frame ˜y(d ) i,t . We use the notai,t to refer to the z that corresponds to ˜y(d ) tion z(d ) i,t . In other words ,
3In the first iteration , we often train an overly regularized h ( ie , with larger Nmin ) to use for inferring the first set of “ cleaner ” Z .
581 582 190
185
180
175
170
165
160
155
150 r o r r
E d e r a u q S
145
150
Visual Speech Generation
DAgger+DT SEARN+DT SSW+DT
13
12
11
10
9
8
7
6 r o r r
E d e r a u q S
Camera Control
DAgger+DT SEARN+DT SSW+DT
Player Movement Prediction
DAgger+DT SEARN+DT SSW+DT
115
110
105
100
95
90
85
80 r o r r
E d e r a u q S
75 30 Leaf Node Size
10
5 100
30
Leaf Node Size
10
75
100
30
Leaf Node Size
10
Figure 5 : Showing a comparison of SSW+DT with SEARN and DAgger over a range of minimum leaf node sizes Nmin for the three benchmark datasets . We see that SSW+DT consistently outperforms or is competitive with SEARN and DAgger . cedurally , Φ( ˆS , Z ) is generated by running Algorithm 1 on the shifted training set {(xi , shiftzi ( ˜yi))}N i=1 .
For the remainder of this section , we focus on optimizing ( 9 ) for a single zi ( ie , Line 9 in Algorithm 2 ) . Similar to Section 431 , inferring zi only depends on the leaf nodes affected by zi . Thus , we simply choose the value of zi that minimizes the unnormalized variance of the affected leaf nodes . Each choice of zi generates a new set of subsequences ˆyji that is a shifted version of the default . Note for a fixed decision tree h , shifting the output does not change which leaf node each subsequences ˆyji belongs to , since that is determined based solely on the input ˆyji which was not modified . ˆxji In essence , the latent variables Z are trying to correct any framewise misalignments between the input and output sequences . We chose a default of zi = 0 , which is used in Line 4 in Algorithm 2 .
, . . . , ˆyji Ti
, . . . , ˆyji Ti t t
1
1
4.4 Using Random Forests
Ensembles of decision trees , such as Bagging [ 2 ] and Random Forests [ 3 ] , can often improve upon the accuracy of a single decision tree . Furthermore , Random Forests are particularly useful for inputs that contain real valued attributes , since randomly sampling the splitting criteria is an attractive alternative to exhaustively iterating over all possible splitting criteria ( which tends to grow proprotional to the training set size for real valued inputs ) .
Our framework extends in a straightforward manner to ensemble decision tree base models . In the case without latent variables , one simply replaces the decision tree base model with an ensemble . In the case with latent variables , inferring the latent variables Z simply requires considering more leaf nodes from multiple trees .
5 . BENCHMARK EXPERIMENTS
We evaluate our approach , which we refer to as SSW+DT ( “ Spatiotemporal Sliding Window with Decision Trees ” ) , using a number of benchmark datasets . We take the view of spatiotemporal sequence prediction as a high dimensional regression problem , and thus evaluate primarily using squared error .
5.1 Datasets
Visual Speech Animation . Our main benchmark dataset is the KB 2k visual speech dataset from [ 33 ] . KB 2k is a large audiovisual dataset containing an actor speaking approximately 2500 sentences in a neutral tone while having his face tracked . The inputs x are phoneme sequences ( sampled at 30 Hz ) , and the outputs y are parameter sequences of a 30 dimensional Active Appearance Model [ 23 ] of the actor ’s lower face ( also sampled at 30 Hz ) . Following the setup in [ 33 ] , we used 50 sentences for testing and the rest for training . For SSW+DT , we use Kx = 11 and Ky = 5 , which results in a 150 variate base regression model . The total size of the decomposed training set is | ˆS| ≈ 200K .
Automated Camera Control . Our next dataset is the camera control dataset from [ 4 ] . The input sequences x are noisy detections of basketball players on a basketball court . The output sequences y are the tracked pan angle states of a broadcast camera operated by a human expert to track the interesting action on the court . The dataset comprises seventeen minutes worth of frames sampled at 25 Hz . Following the setup in [ 4 ] , we use 16 minutes for training and the remaining minute for testing . For SSW+DT , we use Kx = 11 and Ky = 5 , which results in a 5 variate base regression model . The total size of the decomposed training set is | ˆS| ≈ 34k .
Team Sports Player Movement Prediction . Our final dataset is a player position prediction dataset derived from [ 39 ] . The input sequences x are the tracked positions of nine basketball players on the basketball court . The output sequences y are the tracked position of the remaining basketball player ( who is the ballhandler ) . The data comprises 2600 half court possessions sampled at 5 Hz . We use 2000 posssesions for training and 600 possesions for testing . For SSW+DT , we use Kx = 11 and Ky = 5 , which results in a 10 variate base regression model . The total size of the decomposed training set is | ˆS| ≈ 77K .
5.2 Evaluating Prediction Quality
We first evaluate the effectiveness of SSW+DT on uncorrupted training data ( see Section 5.3 for experiments on corrupted training data ) . We primarily compare against existing decision tree based decomposition approaches for sequence prediction , such as SEARN [ 7 ] and DAgger [ 25 ] .
SEARN and DAgger are designed to control for cascading error effects from long range dependencies , and are complementary to our SSW+DT approach which instead focuses on accurately capturing the local temporal curvature of spatiotemporal output sequences . SEARN and DAgger both define a self recurrent base model that predicts a single frame y using both the standard input subsequence ˆx as well as the previously predicted frames for the entire input sequence x . For both SEARN and DAgger , the base decision tree model takes as input the exact same Kx input subsequence as SSW+DT , as well as the previous Ky predicted frames . Note that , because of their self recurrent definition , SEARN and DAgger require iterative training of the base model , and thus take an order of magnitude longer to train than SSW+DT . All three approaches have the same computational costs at test time.4
Figure 5 shows the test results . We see that SSW+DT consistently outperforms or is competitive with DAgger and SEARN
4Although the prediction procedure of SSW+DT is more easily parallelized than that of SEARN and DAgger .
583 SSW+DT SEARN+DT DAgger+DT HMM Dynamic Visemes r o r r
E d e r a u q S
300
280
260
240
220
200
180
160
140
120
100
Figure 6 : Showing a comparison with previous state of theart methods for visual speech generation . For decision tree based approaches ( SSW+DT , DAgger+DT , SEARN+DT ) , the base model was trained using minimum leaf node size Nmin = 10 . We see that SSW+DT significantly outperforms Dynamic Visemes[33 ] and HMM based approaches [ 40 ] .
SSW+DT SSW+SEARN+DT SSW+DAgger+DT SEARN+DT DAgger+DT r o r r
E d e r a u q S
200
190
180
170
160
150
140
130
120
Figure 7 : Evaluating the performance of combining SSW+DT with DAgger or SEARN on the visual speech dataset . For all methods , the base decision tree model was trained using minimum leaf node size Nmin = 10 . We see that combining SSW+DT with other decomposition approaches does not improve performance .
( while being significantly faster to train ) . The gains of SSW+DT are particularly notable on our main benchmark dataset for visual speech generation , where even a heavily regularized SSW+DT outperforms every version of SEARN and DAgger .
Figure 6 shows a comparison on the visual speech dataset with existing state of the art visual speech approaches , such as Dynamic Visemes [ 33 ] and HMM based approaches [ 40 ] . We observe that SSW+DT substantially outperforms all baselines . In Section 6 , we provide additional evidence of the practicality of our approach via a user preference study on the generated animation sequences .
521 Combining Decomposition Frameworks
Since SEARN and DAgger employ complementary decomposition approaches to the decomposition employed by SSW+DT , we also evaluate combining SSW+DT with SEARN and DAgger . We combine in the straightforward way : the decision tree base model is a recurrent sliding window predictor that predicts a length Ky subsequence using both the standard input subsequence ˆx as well as the previous Ky predicted frames . In other words , combining SSW+DT with SEARN or DAgger results in a multi frame extension of conventional SEARN or DAgger , respectively .
Figure 7 shows the results for our main benchmark setting of visual speech . We used base models trained with minimum leaf node size Nmin = 10 . We observe that combining SSW+DT with SEARN or DAgger does not improve performance .
210
200
190
180
170
160
150 r o r r
E d e r a u q S
140
0
SSW+DT SSWL+DT
0.1
0.3
0.5
Portion of Missing Entries
0.8
Figure 8 : Showing squared error on the visual speech dataset with missing entries in the training labels . We see that SSWL+DT can robustly tolerate many missing values .
Table 1 : Evaluating the ability of SSWL+DT to infer the missing entries in the training set . The table below shows the mean squared error of SSW+DT and SSWL+DT when predicting on every missing entry in the training set .
Frac . w/ Missing Entries
SSW+DT SSWL+DT
0.1
184.42 185.21
0.3
191.32 186.02
0.5
206.97 189.24
0.8
235.82 199.24
531 Missing Values
For the missing values setting , we randomly remove a fraction of the training labels from the training set . Specifically , each output frame y is a 30 dimensional output , and each dimension of each frame is independently eligible for being missing . We instantiate SSWL+DT as described in Section 431
Figure 8 shows the results comparing SSWL+DT with SSW+DT ( which ignores missing values during training ) . We observe that SSWL+DT can more robustly tolerate a substantial amount of missing entries in the training set . Table 1 analyzes how well SSWL+DT can infer the missing entries in the training set , where we again observe that SSWL+DT is more robust than SSW+DT .
532 Misalignments
For the misalignments setting , we randomly choose training sentences to misalign , and we randomly shift a misaligned training sentence by one of {−3 , −2 , −1 , +1 , +2 , +3} frames . We instantiate SSWL+DT as described in Section 432 , and we specify the range of each latent variable as z ∈ [ −3 , +3].5
Figure 9 shows the results comparing SSWL+DT with SSW+DT ( which assumes that all sentences are correctly aligned during training ) . We observe that SSWL+DT is surprisingly robust to misalignments in the training set , and actually achieves slightly better performance than SSW+DT on the uncorrupted training set ( although the difference is not statistically significant ) . One possible interpretation is that the visual speech dataset from [ 33 ] actually does suffer from a small degree of misalignment in the data generation process . Table 2 analyzes how well SSWL+DT can infer the correct alignments in the training set ( assuming that the gold standard is properly aligned ) , and we see that SSWL+DT is able to recover a substantial fraction of the correct alignments .
5.3 Evaluating Robustness to Corrupted Train ing Data
We now evaluate the robustness of our latent variable extension , which we refer to as SSWL+DT , to corrupted training data . We evaluate for both missing values and misalignments , as described in Section 31 We focus on the visual speech dataset for this analysis .
6 . VISUAL SPEECH USER STUDY
While squared error is a standard measure of prediction quality , it may not be fully indicative of which method achieves better performance in the target application domain . For instance , one
5When the range of misalignments is not known exactly , one can conservatively overspecify the the range of z , eg , z ∈ [ −5 , +5 ] .
584 585 References [ 1 ] Y . Altun , I . Tsochantaridis , and T . Hofmann . Hidden markov support vector machines . In International Conference on Machine Learning ( ICML ) , 2003 .
[ 2 ] L . Breiman . Bagging predictors . Machine learning , 24(2):123–140 ,
1996 .
[ 3 ] L . Breiman . Random forests . Machine Learning , 45(1):5–32 , 2001 .
[ 4 ] P . Carr and J . Chen . Mimicking human camera operators . In IEEE
Workshop on Applications of Computer Vision ( WACV ) , 2015 .
[ 5 ] A . Coates , P . Abbeel , and A . Ng . Learning for control from multiple In International Conference on Machine Learning demonstrations . ( ICML ) , 2008 .
[ 6 ] M . Collins . Discriminative training methods for hidden markov models : Theory and experiments with perceptron algorithms . In Empirical Methods in Natural Language Processing ( EMNLP ) , 2002 .
[ 7 ] H . Daumé III , J . Langford , and D . Marcu . Search based structured prediction . Machine Learning , 75(3):297–325 , 2009 .
[ 8 ] P . Dollár and C . L . Zitnick . Structured forests for fast edge detection . In IEEE International Conference on Computer Vision ( ICCV ) , 2013 .
[ 9 ] J . R . Doppa , A . Fern , and P . Tadepalli . Structured prediction via output space search . Journal of Machine Learning Research ( JMLR ) , 15(1):1317–1350 , 2014 .
[ 10 ] R . Durbin . Biological sequence analysis : probabilistic models of pro teins and nucleic acids . Cambridge university press , 1998 .
[ 11 ] E . Eyjolfsdottir , S . Branson , X . Burgos Artizzu , E . Hoopfer , J . Schor , D . Anderson , and P . Perona . Detecting social actions of fruit flies . In European Conference on Computer Vision ( ECCV ) , 2014 .
[ 12 ] M . Farhadloo and M . Á . Carreira Perpinán . Learning and adaptation of a tongue shape model with missing data . In IEEE International Conference on Acoustics , Speech and Signal Processing ( ICASSP ) , 2012 .
[ 13 ] S . Gaffney and P . Smyth .
Joint probabilistic curve clustering and alignment . In Neural Information Processing Systems ( NIPS ) , 2004 .
[ 14 ] J . Grabocka , N . Schilling , M . Wistuba , and L . Schmidt Thieme . In ACM Conference on Knowledge
Learning time series shapelets . Discovery and Data Mining ( KDD ) , 2014 .
[ 15 ] T . Kim , G . Shakhnarovich , and R . Urtasun . Sparse coding for learnIn Neural Information ing interpretable spatio temporal primitives . Processing Systems ( NIPS ) , 2010 .
[ 16 ] P . Kontschieder , S . R . Bulo , H . Bischof , and M . Pelillo . Structured class labels in random forests for semantic image labelling . In IEEE International Conference on Computer Vision ( ICCV ) , 2011 .
[ 17 ] J . Lafferty , A . McCallum , and F . Pereira . Conditional random fields : Probabilistic models for segmenting and labeling sequence data . In International Conference on Machine Learning ( ICML ) , 2001 .
[ 18 ] R . Lajugie , D . Garreau , F . Bach , and S . Arlot . Metric learning for temporal sequence alignment . In Neural Information Processing Systems ( NIPS ) , 2014 .
[ 19 ] S . Lenser and M . Veloso . Non parametric time series classification . In IEEE International Conference on Robotics and Automation ( ICRA ) , 2005 .
[ 20 ] J . Listgarten , R . Neal , S . Roweis , and A . Emili . Multiple alignment of continuous time series . In Neural Information Processing Systems ( NIPS ) , 2004 .
[ 21 ] O . Maimon and L . Rokach . Chaper 9 : Decision trees . In Data Mining and Knowledge Discovery Handbook . Springer , 2005 .
[ 22 ] C . Manning and H . Schütze . Foundations of statistical natural lan guage processing . MIT press , 1999 .
[ 23 ] W . Mattheyses , L . Latacz , and W . Verhelst . Comprehensive many tomany phoneme to viseme mapping and its application for concatenative visual speech synthesis . Speech Communication , 55(7–8):857– 876 , 2013 .
[ 24 ] J . R . Quinlan . Induction of decision trees . Machine learning , 1(1):81–
106 , 1986 .
[ 25 ] S . Ross , G . Gordon , and J . A . Bagnell . A reduction of imitation learning and structured prediction to no regret online learning . In Conference on Artificial Intelligence and Statistics ( AISTATS ) , 2011 .
[ 26 ] S . Sarawagi and W . Cohen . Semi markov conditional random fields for information extraction . In Neural Information Processing Systems ( NIPS ) , 2004 .
[ 27 ] D . Schabus , M . Pucher , and G . Hofer . Speaker adaptive visual speech synthesis in the HMM framework . In Interspeech , 2012 .
[ 28 ] B . Schölkopf , K . Tsuda , and J P Vert . Kernel methods in computa tional biology . MIT press , 2004 .
[ 29 ] R . Socher , A . Perelygin , J . Wu , J . Chuang , C . Manning , A . Ng , and C . Potts . Recursive deep models for semantic compositionality over a sentiment treebank . In Empirical Methods in Natural Language Processing ( EMNLP ) , 2013 .
[ 30 ] Y . Su , H . Ai , and S . Lao . Real time face alignment with tracking in video . In IEEE International Conference on Image Processing ( ICIP ) , 2008 .
[ 31 ] I . Sutskever , O . Vinyals , and Q . V . Le . Sequence to sequence learning with neural networks . In Neural Information Processing Systems ( NIPS ) , 2014 .
[ 32 ] B . Taskar , C . Guestrin , and D . Koller . Max margin markov networks .
In Neural Information Processing Systems ( NIPS ) , 2003 .
[ 33 ] S . Taylor , M . Mahler , B J Theobald , and I . Matthews . Dynamic units of visual speech . In ACM/Eurographics Symposium on Computer Animation ( SCA ) , 2012 .
[ 34 ] K . Tokuda , T . Yoshimura , T . Masuko , T . Kobayashi , and T . Kitamura . Speech parameter generation algorithms for hmm based speech synthesis . In IEEE International Conference on Acoustics , Speech and Signal Processing ( ICASSP ) , 2000 .
[ 35 ] I . Tsochantaridis , T . Hofmann , T . Joachims , and Y . Altun . Support vector machine learning for interdependent and structured output spaces . In International Conference on Machine Learning ( ICML ) , 2004 .
[ 36 ] W . Wang , R . Arora , and K . Livescu . Reconstruction of articulatory measurements with smoothed low rank matrix completion . In Spoken Language Technology Workshop , 2014 .
[ 37 ] D . Weiss , B . Sapp , and B . Taskar . Structured prediction cascades . In Conference on Artificial Intelligence and Statistics ( AISTATS ) , 2012 .
[ 38 ] C N J . Yu , T . Joachims , R . Elber , and J . Pillardy . Support vector training of protein alignment models . Journal of Computational Biology , 15(7):867–880 , 2008 .
[ 39 ] Y . Yue , P . Lucey , P . Carr , A . Bialkowski , and I . Matthews . Learning In fine grained spatial models for dynamic sports play prediction . IEEE International Conference on Data Mining ( ICDM ) , 2014 .
[ 40 ] H . Zen , T . Nose , J . Yamagishi , S . Sako , T . Masuko , A . Black , and K . Tokuda . The HMM based speech synthesis system version 20 In Speech Synthesis Workshop , 2007 .
[ 41 ] F . Zhou and F . De la Torre . Generalized time warping for multi modal alignment of human motion . In IEEE Conference on Computer Vision and Pattern Recognition ( CVPR ) , 2012 .
[ 42 ] B . Ziebart , A . Dey , and J . A . Bagnell . Probabilistic pointing target prediction via inverse optimal control . In International Conference on Intelligent User Interfaces ( IUI ) , 2012 .
586
