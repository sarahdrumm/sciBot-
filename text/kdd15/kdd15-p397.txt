Learning Tree Structure in Multi Task Learning
Lei Han
Department of Computer Science
Hong Kong Baptist University leihan@comphkbueduhk
ABSTRACT In multi task learning ( MTL ) , multiple related tasks are learned jointly by sharing information according to task relations . One promising approach is to utilize the given tree structure , which describes the hierarchical relations among tasks , to learn model parameters under the regularization framework . However , such a priori information is rarely available in most applications . To the best of our knowledge , there is no work to learn the tree structure among tasks and model parameters simultaneously under the regularization framework and in this paper , we develop a TAsk Tree ( TAT ) model for MTL to achieve this . By specifying the number of layers in the tree as H , the TAT method decomposes the parameter matrix into H component matrices , each of which corresponds to the model parameters in each layer of the tree . In order to learn the tree structure , we devise sequential constraints to make the distance between the parameters in the component matrices corresponding to each pair of tasks decrease over layers , and hence the component parameters will keep fused until the topmost layer , once they become fused in a layer . Moreover , to make the component parameters have chance to fuse in different layers , we develop a structural sparsity regularizer , which is the sum of the 2 norm on the pairwise difference among the component parameters , to learn layer specific task structure . In order to solve the resulting non convex objective function , we use the general iterative shrinkage and thresholding ( GIST ) method . By using the alternating direction method of multipliers ( ADMM ) method , we decompose the proximal problem in the GIST method into three independent subproblems , where a key subproblem with the sequential constraints has an efficient solution as the other two subproblems do . We also provide some theoretical analysis for the TAT model . Experiments on both synthetic and real world datasets show the effectiveness of the TAT model .
Categories and Subject Descriptors I26 [ Artificial Intelligence ] : Learning ; H28 [ Database Management ] : Database Applications—Data mining
∗Both authors contributed equally .
Yu Zhang∗
Department of Computer Science
Hong Kong Baptist University yuzhang@comphkbueduhk
Keywords Multi Task Learning , Learning Tree Structure
1 .
INTRODUCTION
Multi task learning ( MTL ) [ 2 ] seeks to improve the generalization performance of multiple learning tasks by sharing information according to task relations . MTL has been applied in a wide range of applications including medical risk evaluation , image annotation , speech recognition , disease progression predication and so on . From the perspective of information sharing , MTL models can be classified into two categories based on task relations . The methods in the first category utilize some domain knowledge on the task relations to devise learning models . For example , if tasks are known to be positively correlated to each other , this knowledge can be encoded into some novel regularizers [ 7 , 6 ] . Moreover , some domain knowledge which specifies the tree structure among tasks has been utilized in [ 17 , 9 , 13 ] . However , such knowledge is rarely available in most MTL applications , which limits the use of those approaches . On the other hand , MTL methods in the second category can identify the task relations and learn the model parameters from data simultaneously . Those methods can provide insights for the problems under investigation based on the task relations revealed without any domain knowledge and hence they are the main focus of our work .
Many algorithms belonging to the second category have been proposed and shown good performance in a large number of applications . For example , low rank structure based methods in [ 1 , 3 ] can learn model parameters sharing a low dimensional subspace for multiple tasks , probabilistic MTL models [ 27 , 25 ] place probabilistic priors on multiple tasks to learn the model parameters as well as identifying the task relations , regularized methods [ 26 , 24 ] can reveal pairwise task relations in term of a matrix , task grouping methods [ 14 , 16 , 18 ] can detect the underlying task groups , robust MTL model proposed in [ 4 ] can identify the existence of outlier tasks , and some hierarchical models [ 15 , 9 , 21 , 28 , 12 ] organize the task structure into hierarchies . All the works in the second category are capable of learning some specific task structure when the domain knowledge is absent .
As discussed previously , the use of the given tree structure , which defines the task relations , has been investigated by some methods [ 17 , 9 , 13 ] in the first category and it leads to significant improvement in the performance . Even though learning the tree structure is claimed by those works as one promising future direction , due to the difficulty of defining and modeling the tree structure among tasks , we are not aware of any existing work that can learn the model parameters and tree structure from data simultaneously under the regularization framework . Moreover , there is even no formal definition for the tree structure in the MTL regime .
397 Notation x ∈ Rm X ∈ Rd×m xi , xj , xi j · q
· p,q
Table 1 : Notations i=1 |xi|q )
Description A vector x with length m . A matrix X with size d × m . The ith row , jth column , and ( i , j)th element of a matrix X . The q norm defined on any vector x ∈ Rm , ie , xq = ( m d j=1(m
The p,q norm defined on a matrix X ∈ Rd×m , ie , Xp,q = The matrix Frobenius norm . The inner product between matrices/vectors . The trace of a square matrix . An identity matrix with appropriate size . A set of integers {1 , · · · , m} . Normal distribution with mean µ and variance σ2 . i=1 |xi
1
1 q . j|q ) p q p .
A sequence with n identical elements a . The concatenate operator between two sequences , ie , A B = ( A , B ) for sequences A and B .
· F · , · tr(· ) I Nm N ( µ , σ2 ) ( a1 , · · · , an ) A sequence . ( a , · · · , a)|n
In this paper , we aim to fill this gap . Firstly we formally define the task tree structure for MTL . Based on the task tree , we develop a TAsk Tree ( TAT ) method for MTL to learn the underlying task tree and the model parameters simultaneously . By specifying the number of layers in the tree or equivalently the height of the tree as H , the TAT method decomposes the parameter matrix into H component matrices , each of which corresponds to the parameters in a layer of the tree . In order to learn the tree structure among tasks , we devise sequential constraints each of which makes the distance between the component parameters in the component matrices for a pair of tasks decrease over layers and as a consequence , the corresponding component parameters will keep fused until the topmost layer once they become fused in a layer . Moreover , to make the component parameters have chance to fuse together in some layers , a structural sparsity regularizer , which is defined as the sum of the 2 norm on the pairwise difference among the component parameters , is used to learn layer specific task structure . Learning the parameters in the proposed TAT model is very challenging due to the complex fused regularizer and the sequential constraints which are non convex . To solve the resulting objective function , we propose to use the general iterative shrinkage and thresholding ( GIST ) method [ 8 ] , which needs to solve a proximal problem . With the help of the alternating direction method of multipliers ( ADMM ) , we can decompose the proximal problem into three independent subproblems , where a key subproblem with the sequential constraint has an efficient solution as the other two subproblems do . Moreover , we provide theoretical analysis for the TAT model . Experiments on both synthetic and real world datasets show that the TAT model has competitive performance over state of the art MTL methods and additionally it can provide meaningful task tree structure to demonstrate the interpretability .
2 . THE TAT MODEL
For clear presentation , we list the frequently used notations in Table 1 . Suppose we have m learning tasks in a d dimensional space . The training data for the ith task is denoted by ( Xi , yi ) , where Xi ∈ Rni×d is the data matrix with ni training samples stored in the rows , and yi ∈ Rni is a vector of labels for the ni training samples in Xi . If the labels are continuous , this problem is a multi task regression problem and otherwise a multi task classification problem . The linear function for the ith task is defined as
Figure 1 : An example of the task tree with 3 layers . i x , where an offset is assumed to be absorbed into wi . µi(x ) = wT W = [ w1,··· , wm ] ∈ Rd×m is defined as the parameter matrix . First , we assume that the parameter matrix W can be decomposed into H component matrices as
H
W =
Wh ,
( 1 ) h=1 where Wh = [ wh,1,··· , wh,m ] ∈ Rd×m is the component matrix corresponding to the hth layer and wh,i is the parameter for the ith task at the hth layer . Then based on the decomposable structure of W , we can define a task tree used to specify the tree structure in MTL as follows .
DEFINITION 1
( TASK TREE ) . By assuming H layers in the tree structure ( H ≥ 2 ) , ie the height of the tree being H , {Wh}H form a task tree if they satisfy the following conditions : h=1
• The model parameters of different tasks corresponding to the hth layer are stored in the component matrix Wh ;
• For any pair of tasks , for example , the ith and jth tasks , if the corresponding component parameters in the hth layer satisfies that wh,i = wh,j , then wh,i = wh,j should hold in all the above layers where h ≥ h .
Note that the task tree in definition 1 can be any type of tree . Fig 1 shows an example of the task tree with 3 layers . The leaf nodes in the tree represent tasks , whose relations with each other are represented by a task tree . Each internal node reveals the relations among tasks corresponding to the leaf nodes of a subtree rooted at it . By assuming that the feature dimensionality d equals 1 , then each Wh reduces to a vector for h ∈ {1 , 2 , 3} . The component parameters Wh ’s corresponding to each layer are shown at the right side of Fig 1 , where the component parameters with identical values are plotted in the same color .
In order to make the component parameters {Wh}H h=1 form a task tree , we devise sequential constraints on them as
|wh−1,i − wh−1,j| |wh,i − wh,j| , ∀h ≥ 2 , ∀i < j ,
( 2 ) where | · | denotes the elementwise absolute value and is the elementwise ‘no smaller than’ operation . The sequential constraints in Eq ( 2 ) impose a non increasing order for the pair distance between tasks from the bottom layer to the top one . It is easy to see that once wh,i = wh,j for one pair of tasks at the hth layer for some h , then the sequential constraints in Eq ( 2 ) can guarantee that wh,i = wh,j for any h > h . So the component parameters {Wh}H Moreover , in order to make the component parameters of each pair of tasks possible to be fused , eg , wh,i becoming identical to wh,j , we use a structurally sparse regularizer Ω(W ) on the component matrices as h=1 satisfying Eq ( 2 ) can form a task tree .
H d
Ω(W ) =
λh h=1 i<j wh,i − wh,j2 ,
398 where λ1,··· , λH are positive regularization parameters to specify the importance of different layers . Based on the use of the 2 norm , Ω(W ) encourages each pair of the columns wh,i and wh,j to be identical . If this happens , the condition in Definition 1 can be satisfied .
By combining the above considerations , we formulate the objec tive function of the TAT model as
L(W ) + min W
λh wh,i − wh,j2
H d h=1 i<j
1 i=1 st |wh−1,i − wh−1,j| |wh,i − wh,j| , ∀h ≥ 2 , ∀i < j ,
( 3 ) where L(· ) denotes a loss function . In this paper , we consider the 2 , and oth square loss L(W ) =m
H h=1 wh,i2 yi− Xi er loss functions can be accordingly adopted in a similar way . mni
The regularization parameter λh control the strength of the task similarity at the hth layer . A larger λh will lead to more identical task parameters in the corresponding component matrix . Therefore , it is intuitive to define a non decreasing order for the λh ’s from the bottom layer to the top one to help construct the tree structure . In practice , we set λh = φλh−1 for h ≥ 2 with some constant φ > 1 . It is easy to show that problem ( 3 ) is non convex due to the nonconvexity of the sequential constraints and the regularizer Ω(W ) is non smooth , making solving it very challenging . In the next section , we show how to solve problem ( 3 ) efficiently .
3 . OPTIMIZATION PROCEDURE
In this section , we discuss how to solve problem ( 3 ) . The main idea is to use the GIST method [ 8 ] , which involves solving a proximal problem via the ADMM , to solve problem ( 3 ) .
Since problem ( 3 ) is non convex , we adopt the GIST method to solve it . The GIST method solves a problem with the following form : min W f ( W ) + r(W ) , where f ( · ) is convex and Lipschitz continuous , and r(· ) can be non convex . In order to apply the GIST method , we define f ( W ) = L(W ) and r(W ) as a non convex extended real value function with the formulation as
 Ω(W ) ,
+∞ , r(W ) = if |wh−1,i − wh−1,j| |wh,i − wh,j| for any h ≥ 2 , i < j , otherwise .
According to [ 8 ] , the proximal operator at the ( k + 1)th iteration in the GIST method is
W(k ) ∇Wh f ( W(k) ) , Wh − W(k )
Wh − W(k ) h 2
τk 2
+ h h
F + r(W )
,
( 4 )
W(k+1 ) = arg min W f
+ h where W(k ) denotes the estimation in the kth iteration with W(k ) h as its hth component matrix , ∇Wh f ( W(k ) ) denotes the gradient of f ( W ) with respect to Wh at W(k ) , and τk is determined via a line search method as described in Algorithm 1 . By omitting the constant part , problem ( 4 ) can be simplified as
W(k+1 ) = arg min W
τk 2
Wh − Vh2
F + r(W ) ,
( 5 ) h h − 1
∇Wh f ( W(k) ) . For all h ∈ NH , the where Vh = W(k ) gradients ∇Wh f ( W(k ) ) ’s are identical , where the ith column of i − yi ) ∇Wh f ( W(k ) ) can be easily computed as i ( Xiw(k ) for any h . The GIST algorithm is presented in Algorithm 1 .
XT mni
τk
2
Algorithm 1 The GIST algorithm for solving problem ( 3 ) . Input : X , Y , H ;
Output : W =
H , η > 1 , τmin , τmax , ϕ ∈ ( 0 , 1 ) , k = 0 ; h Wh ; 1 , · · · , W(0 )
τk ∈ [ τmin , τmax ] ; repeat
1 : Initialize W(0 ) 2 : repeat 3 : 4 : 5 : 6 : 7 : 8 : 9 : until Some convergence criterion is satisfied ; until F ( W(k+1 ) ) ≤ F ( W(k ) ) − ϕ k := k + 1 ;
Solve the proximal problem ( 5 ) with τk ; τk = ητk ;
2 τkW(k+1 ) − W(k)2 2 ;
3.1 Solving Proximal Problem ( 5 ) In the GIST algorithm , we only need to solve the proximal problem ( 5 ) . Since r(· ) is an extended real value function , problem ( 5 ) can be reformulated as min W
τ 2
Wh − Vh2 wh,i − wh,j2 , st |wh−1,i − wh−1,j| |wh,i − wh,j| , h ≥ 2 , i < j ,
F +
λh i<j h h
( 6 ) where for notational simplicity we omit the index k . Unfortunately , problem ( 6 ) is still non convex due to the sequential constraints and it is still non smooth . By introducing new variables , we use the ADMM method to solve problem ( 6 ) . We define an auxiliary sparse matrix · · · · · ·
 ∈ R m(m−1 )
 1 −1
0 0 −1
×m ,
C =
0 0
1
2 where each row of C contains only two non zero entries 1 and −1 at corresponding locations . By defining new variables {Qh}H h=1 as Qh = CWT h , we can get
Qh1,2 = wh,i − wh,j2 . i<j
Similarly , by introducing variables {Ph}H h=1 as a copy of {Qh}H problem ( 6 ) can be reformulated as Wh − Vh2 h , ∀h , st Ph = Qh , Qh = CWT
λhPh1,2 min W
F +
τ 2 h h h=1 , h| , ∀h ≥ 2 , i ∈ Nm(m−1)/2 .
( 7 )
In order to use the ADMM method , we define the augmented
|qi h−1| |qi
τ 2
+ h h
+
F +
Wh − Vh2
ρ
2 h ( Ph − Qh ) ΘT tr tr h ( Qh − CWT ΓT h )
Qh − CWT h 2
F h
+
ρ 2
+
Ph − Qh2
F
λhPh1,2 ,
Lagrangian function as ¯L(W , P , Q ) = h h where P denotes the set of {Ph}H h=1 , Q denotes the set of {Qh}H {Θh}H h=1 acts as Lagrangian multipliers , and ρ is a penalty parameter . Then we need to solve the following problem as h=1 and {Γh}H h=1 , min
¯L(W , P , Q ) , st |qi h−1| |qi h| , h ≥ 2 , i ∈ Nm(m−1)/2 .
W,P,Q In the ADMM algorithm whose procedure is presented in Algorithm 2 , problem ( 8 ) can be solved alternatively with respect to W , P , and Q . In the following , we discuss how to solve those three subproblems corresponding to steps 4 6 in the ADMM algorithm .
( 8 )
399 h , Θ(0 )
Output : W =
Algorithm 2 The ADMM algorithm for solving problem ( 8 ) . Input : X , Y , H , W(0 ) h ; h Wh ; 1 : Initialize {P(0 ) h , Q(0 ) 2 : Set ρ = 0.1 and t = 0 ; 3 : repeat 4 : 5 : 6 : 7 :
Solve W(t+1 ) Solve P(t+1 ) Solve Q(t+1 ) Update Θ(t+1 ) with fixed P(t ) with fixed W(t ) with fixed W(t ) h , Γ(0 ) h }H
= Θ(t ) h=1 ; h h h
; h + ρ h h and Q(t ) h ; h and Q(t ) h ; h and P(t ) h ; h − Q(t ) P(t ) h − C Q(t ) h
Update Γ(t+1 ) h t := t + 1 ;
8 : 9 : 10 : until Some convergence criterion is satisfied ;
= Γ(t ) h + ρ
T
;
W(t ) h h
ρ 2 h h
Solving Problem ( 8 ) wrt W
311 With fixed P and Q , we need to solve the following subproblem with respect to W as min W
τ 2
+
Wh − Vh2
F +
Qh − CWT h 2
F tr
ΓT h
Qh − CWT h
.
( 9 )
Problem ( 9 ) can be decomposed into H separable problems , each of which can be solved analytically based on the stationary condition where the solution can computed as
Wh =
τ Vh + ( ρQh + Γh)T C
( τ I + ρCT C)−1 .
( 10 )
Since ( τ I+ρCT C)−1 is a constant matrix , it can be pre computed and stored , leading to efficient computation of Eq ( 10 ) . 312 Solving Problem ( 8 ) wrt P With fixed W and Q , P can be obtained by solving the follow ing problem : min
P
ρ 2
Ph − Sh2
F +
λhPh1,2 ,
( 11 ) h h where Sh = Qh − 1 ρ Θh . Problem ( 11 ) can be decomposed into 2 Hm(m−1 ) independent problems with one problem correspond1 ing to a row of matrix Ph formulated as
ρ 2 min pi h pi h − si h2
2 + λhpi h2 ,
( 12 ) where si the group Lasso and admits a closed form solution as h is the ith row of Sh . Problem ( 12 ) is widely studied in pi h =
1 − λh ρsi h2 si h ,
+
( 13 ) where ( x)+ = max(0 , x ) is a thresholding operator . 313 Solving Problem ( 8 ) wrt Q The remaining problem is to solve Q , which is a key step . In problem ( 8 ) , the sequential constraints bring challenges to solve it . With the given W and P , we can update Q by solving the following problem as
Qh − Uh2
F , st |qi h−1| |qi h| , ∀h ≥ 2 ,
( 14 ) h min Q
ρ 2 h
ρ Θh
. Obviously probρ Γh + 1 2 m(m − 1)d independent prob
Ph + CWT h − 1 where Uh = 1 2 lem ( 14 ) can be decomposed into 1 2 lems each of which is formulated as
{qi min h,j}H h=1 h h,j − ˆui qi h,j
, st |qi h−1,j| ≥ |qi h,j| , ∀h ≥ 2 ,
( 15 ) h,j and ˆui where qi h,j are the ( i , j)th elements of Qh and Uh respectively . For simplicity , we omit the scripts i and j in problem ( 15 ) , and get min {qh}H h=1
( qh − ˆuh)2 , st |qh−1| ≥ |qh| , ∀h ≥ 2 .
( 16 )
Note that we have
( qh − ˆuh)2 = ( sign(qh)|qh| − ˆuh)2 = ( |qh| − sign(qh)ˆuh)2 , where sign(· ) denotes the sign function . qh must have the same sign as ˆuh since otherwise we can change the sign of qh to achieve a lower objective function value for problem ( 16 ) . So by defining ¯qh = |qh| and ¯uh = |ˆuh| , problem ( 16 ) is equivalent to the following problem :
( ¯qh − ¯uh)2 , st ¯q1 ≥ ¯q2 ≥ · · · ≥ ¯qH .
( 17 ) h min {¯qh}H h=1
After solving problem ( 17 ) , we can recover the solution of problem ( 16 ) as qh = sign(ˆuh)¯qh . Note that problem ( 17 ) is convex . In the next section , we show that problem ( 17 ) can be solved efficiently in O(H ) complexity . 3.2 Solving Problem ( 17 ) In each iteration of the ADMM method , problem ( 17 ) needs to be solved for m(m− 1)d/2 times , hence it requires a very efficient solution . In the following analysis , a sequence ( ¯q H ) is said to be better ( worse ) than another sequence ( ¯q H ) for problem ( 17 ) if both the sequences are feasible for problem ( 17 ) , ie satisfying the sequential constraints , and the objective value of problem 1 ,··· , ¯q ( 17 ) at ( ¯q H ) . In order to solve problem ( 17 ) , we first introduce some useful
H ) is smaller ( larger ) than that at ( ¯q
1,··· , ¯q 1 ,··· , ¯q
1,··· , ¯q lemmas to reveal interesting properties .
LEMMA 1 . Problem ( 17 ) has the following properties : 1 . if ¯u1 ≥ ¯u2 ≥ ··· ≥ ¯uH , then the optimal solution ( ¯q∗
1 , ¯q∗ 2 ,
··· , ¯q∗
H ) is ( ¯u1 , ¯u2,··· , ¯uH ) ;
2 . if ¯u1 ≤ ¯u2 ≤ ··· ≤ ¯uH , then the optimal solution ( ¯q∗ h=1 ¯uh .
H ) is ( u∗,··· , u∗)|H , where u∗ = 1
··· , ¯q∗
H
1 , ¯q∗ 2 ,
H
LEMMA 2 . For any sequence ( ¯u1,··· , ¯uH ) , if the optimal solution of problem ( 17 ) is ( u∗,··· , u∗)|H , then for any u∗ ≥ u ≥ b1 or bH ≥ u ≥ u∗ , the sequence ( b1,··· , bH ) , where b1 ≥ ··· ≥ bH , is not better than ( u,··· , u)|H .
Based on the properties revealed in Lemmas 1 and 2 , we can present the following important theorem .
THEOREM 1 . For any two sequences ( ¯u1,··· , ¯ul ) and ( ¯ul+1 , ··· , ¯un ) which define two instances of problem ( 17 ) , if the optimal solutions for them are ( ˙u∗,··· , ˙u∗)|l and ( ¨u∗,··· , ¨u∗)|n−l , respectively , then
1 . if ˙u∗ ≥ ¨u∗ , the optimal solution for the concatenated sequence ( ¯u1,··· , ¯ul ) ( ¯ul+1,··· , ¯un ) , ie ( ¯u1,··· , ¯ul , ¯ul+1,··· , ¯un ) , is ( ˙u∗,··· , ˙u∗)|l ( ¨u∗,··· , ¨u∗)|n−l ;
400 2 . otherwise , the optimal solution for the concatenated sequence is ( u∗,··· , u∗)|n , where u∗ = 1 i=1 ¯ui . n n
Theorem 1 implies that we can obtain the solution of any sequence ( ¯u1,··· , ¯un ) in problem ( 17 ) , if the sequence is a concatenation from two sub sequences , where the optimal solutions corresponding to the two sub sequences take the form that the entries in a solution have the same value . Finally , based on Theorem 1 , we devise Algorithm 3 to solve problem ( 17 ) with its correctness guaranteed by the following theorem .
THEOREM 2 . For any input sequence ( ¯u1,··· , ¯uH ) in prob lem ( 17 ) , Algorithm 3 can find the optimal solution .
Algorithm 3 The algorithm for solving problem ( 17 ) . Input : ( ¯u1 , · · · , ¯uH ) ; 1 , · · · , q∗ Output : ( q∗ H ) ; 1 : Scan the sequence ( ¯u1 , · · · , ¯uH ) once to split it into K non decreasing sub sequences ( S1 , · · · , SK ) and calculate the solutions for those subsequences based on Lemma 1 ;
2 : Push S1 into a stack ; 3 : for k = 2 : K do 4 : 5 : 6 :
7 : 8 :
Push Sk into the stack ; while there are at least two sequences in the stack do
Pop the first and second sequences from the stack and denote the solutions for them as ¨u∗ and ˙u∗ separately ; if ˙u∗ < ¨u∗ then
Concatenate the two sequences under the second condition in Theorem 1 and then push the concatenated sequence into the stack ; else
Push the two sequences into the stack without any operation ; Break ;
9 : 10 : 11 : 12 : 13 : 14 : end for 15 : Concatenate the solutions of the sequences in the stack from bottom to end if end while top and output the concatenated solution ;
3.3 Time Complexity
In this section , we analyze the time complexity of the whole op timization procedure for solving the TAT model .
We first discuss the time complexity of Algorithm 3 , since it is the inner most one . In Algorithm 3 , step 1 only needs to scan the input sequence once and thus it needs O(H ) time . Although there exist two loops from step 3 to 14 , the maximum number of the concatenation operations in step 8 is K − 1 and this step costs O(H ) . For the concatenation operation , the computation of the analytical solution in Theorem 1 is very efficient , since it only needs to compute the average of the entries in two sequences . We can record the average and the number of the entries in each sequence , and then each concatenation operation only needs O(1 ) time . Therefore , Algorithm 3 can be executed in O(H ) time complexity . component Wh in Eq ( 10 ) takes O,m3Hd time . The computation in Algorithm 2 is O,m3Hd . By assuming that Algorithms 1 time complexity for solving the TAT model is O,N1N2m3Hd . tion of the solution for matrix P needs O(m2H ) time . For solving Q , Algorithm 3 needs to be executed for m(m−1)d/2 times , hence the time cost is O(m2Hd ) . So the time complexity of each itera and 2 need N1 and N2 iterations to converge , respectively , the total
In Algorithm 2 , the computation of the solution for W with each
In our experiments , we empirically find that both Algorithm 1 and Algorithm 2 need very small numbers of iterations to converge . Therefore , the overall algorithm for solving the TAT model is very efficient . Moreover , according to Section 3.1 , the subproblems for W , P , and Q can be decomposed into a large number of independent problems , which can be parallelized to further improve the efficiency .
4 . THEORETICAL ANALYSIS j
In this section , we provide theoretical analysis for the TAT model . For notational simplicity , we assume that the numbers of training samples for all the tasks are the same and denote it by n . The general case that different tasks have different numbers of training samples can be similarly analyzed . j )T w∗
W∗ = H
We assume that the true relation between the data sample and its label is a linear function plus a Gaussian noise , which is defined as i + ji , i ∈ Nm , j ∈ Nn , where x(i ) yji = ( x(i ) is the jth data point of the ith task with yji as its label , W∗ = [ w∗ 1 , . . . , w∗ m ] is the true parameter matrix , and all the ji ’s are independent Gaussian noises sampled from N ( 0 , σ2 ) . We assume that W∗ can be 1 , . . . , W∗ decomposed into H true component matrices W∗ H as h=1 W∗ h , where those component matrices satisfy the sequential constraints in problem ( 3 ) . We define f∗ i = Xiw∗ i + i for i ∈ Nm , where i = [ 1i , . . . , ni]T . i and yi = f∗ Let X ∈ Rdm×mn be a diagonal block matrix with XT i as the ith block for i ∈ Nm . We define a vectorization operator vec(· ) over an arbitrary matrix X ∈ Rd×m to concatenate its columns as vec(X ) = [ xT For any matrix X ∈ Rd×m , we define E(X ) = {(i , j)|xi = xj , i , j ∈ Nm} and its complement Ec(X ) = {(i , j)|xi = xj , i ∈ Nm , j ∈ Nm , i = j} . For any matrix X ∈ Rd×m , since each pair ( i , j ) corresponds to one row in CXT ∈ R m(m−1 ) ×d , which is i − xT j , the projections of the rows in CXT onto the set E(X ) , xT denoted by ,CXT E(X ) , consist of the rows with non zero 2 m]T . Let F∗ = [ f∗ m ] ∈ Rn×m .
1 ,··· , xT
1 , . . . , f∗
2 norms in CXT , and similar definitions can be made for the set Ec(X ) . We define D(X ) as the set of indices for distinct column vectors in X , ie , for any i , j ∈ D(X ) , xi = xj . We denote by XD(X ) the projection of the columns of X onto the set D(X ) and the complement of D(X ) by Dc(X ) . sumption .
In order to analyze the TAT model , we need the following as
ASSUMPTION 1 . Let ˆW = H tion of problem ( 3 ) . For any matrix W = H
ˆWh be the optimal soluh=1 Wh ∈ Rd×m and h ∈ NH , we define matrix ∆h as ∆h = Wh − ˆWh and h=1 ∆h . We matrix Γh as Γh = CWT assume that there exist positive scalars βh , θh ≥ 1 , and γh ≥ 1 such that h . Let ∆ = H h − C ˆWT h=1
βh = min ∆h=0
√
,
XT vec(∆)2 mn∆D(Wh ) F F , 1,2 . h h
∆hF = θh∆D(Wh ) Γh1,2 = γhΓE(Wh ) h
Assumption 1 refers to the restricted eigenvalue assumption as introduced in [ 20 ] and similar assumptions are commonly used in the MTL literature , eg , [ 4 , 12 ] . Based on Assumption 1 , we can analyze the TAT model in the following theorem.1
THEOREM 3 . Let ˆW =H problem ( 3 ) and define C =H h=1 h=1
ˆWh be the optimal solution of λh ( θh +1 ) . If the regulariza
βh
1Due to page limitations , we put the proof at http://wwwcomphkbu eduhk/~leihan/
401 tion parameters λh for any h ∈ NH satisfies2
λh ≥ 2σm + δ/d m(m − 1)n
,
( 18 ) then under Assumption 1 , the following results hold with probability at least 1 − exp(− 1
2 ( δ − dm log(1 + δ dm )) ) :
XT vec( ˆW ) − vec(F∗)2 ˆWh − W∗ hF ≤ θh(m − 1 )
√ dC
,
2 ≤ m(m − 1)2ndC2 ,
C ˆWT h − C(W∗ h)T 1,2 ≤ γh(m − 1)2dC
.
βh
βh
( 19 )
( 20 )
( 21 )
( 22 )
( 23 ) min
C(W∗
( i,j)∈E(W∗ h ) h)T(i,j)flflflfl2
In addition , if the following condition holds for h ∈ NH : 2dγh(m − 1)2C flflflfl where.C(W∗ h)Tfi(i,j ) denotes one row in C(W∗ fl ing to the pair ( i , j ) , then with probability at least 1−exp(− 1 dm log(1 + δ dm )) ) , the following set
βh
>
, dγh(m − 1)2C
ˆEh =
( i , j )
C ˆWh
( i,j)flflflfl2
> fififififlflflfl
βh h)T correspond2 ( δ− can recover the true task structure E(W∗ task tree , ie ˆEh = E(W∗ h ) and ( ˆEh)c = Ec(W∗ h ) . h ) at the hth layer of the well as the true parameter matrix W∗ = H
Theorem 3 provides important theoretical guarantees for the TAT model . Specifically , those bounds measure how well our model can approximate the ground truth of the component matrix W∗ h as h . Moreover , if the assumptions in Eq ( 22 ) can be satisfied , the TAT model can recover the true task tree with high probability based on Eq ( 23 ) . h=1 W∗
5 . RELATED WORK
The proposed TAT model is related to some hierarchical MTL methods [ 15 , 9 , 28 , 12 ] , since those works assume the tasks are organized as hierarchies , which in some sense are a bit similar to the layers in the proposed task tree . However , the hierarchical structure proposed in those works cannot be organized as a tree and different hierarchies in them are independent of each other , which is totally different from the proposed TAT model where different layers in the task tree follow the sequential constraints in Eq ( 2 ) .
The TAT model is also related to some task grouping methods [ 14 , 16 , 18 ] . The task grouping methods aim to learn clusters for tasks , and therefore they are just corresponding to the bottom layer of the task tree in the TAT model .
6 . EXPERIMENTS
In this section , we conduct empirical experiments on both synthetic and real world problems to study the proposed TAT method . We compare the TAT method with several state of the art MTL models , including the multi task feature learning ( MTFL ) model [ 19],3 the dirty model ( Dirty ) [ 15],3 the Cascade model [ 28 ] , the clustered multi task learning ( CMTL ) model [ 14],4 the grouping and overlap MTL ( GOMTL ) model [ 18 ] , and the multi level task grouping ( MeTaG ) model [ 12 ] . Among these competitors , the 2In the TAT model , we assume an increasing order for {λ1 , · · · , λH} and hence only λ1 needs to satisfy Eq ( 18 ) .
3http://wwwyelabnet/software/ 4http://cbioensmpfr/~ljacob/documents/cmtl codetgz
MTFL method learns common feature representation for multiple tasks , the Dirty and Cascade models are representatives of the hierarchical MTL models , the CMTL and GOMTL models are belonging to the task grouping approach , and the MeTaG model is a combination of those two types .
The regularization parameters of all the methods in comparison are determined via the validation dataset with the set of candidate values as {10−8 , 10−7,··· , 103} . Moreover , in the same way we , from a set {1.2 , 2 , 10} for the TAT choose φ , which defines λh λh−1 model . In addition to the regularization parameters , some of the competitors include some additional hyper parameters , including the number of groups in the CMTL method , the dimension of latent subspace in the GOMTL method , the number of cascades in the Cascade method , the number of levels in the MeTaG method , and the number of layers in our TAT model . Those hyper parameters are selected from a candidate set {1 , 2,··· , 10} because empirically we find that any value larger than 10 will lead to worse performance for all the models under all the settings . In all the experiments , we use the least square solution to initialize the parameter matrix in the TAT model as a warm start . 6.1 Results on Synthetic Data
We first evaluate all the models on synthetic data . In order to simulate different structures of the task tree , we adopt the binary tree structure and vary the height of the tree , which equals the number of layers , according to the number of tasks . The number of tasks m is equal to m = 2H∗−1 , where H∗ denotes the height of the tree . We vary the number of tasks as m ∈ {4 , 8 , 16 , 32 , 64} and the height of the tree H∗ ∈ {3 , 4 , 5 , 6 , 7} accordingly . Fig 2 shows two examples of the task tree when H∗ = 4 and H∗ = 6 . We set the feature dimensionality to be d = 100 . Then , based on the task tree , we generate each component matrix W∗ h according to the hth layer in the task tree . If there are k internal nodes in the hth layer , the columns in W∗ h corresponding to the tasks , whose corresponding leaf nodes belong to the subtree rooted at each internal node , form a group and will have the same value . To achieve this , we generate the component matrices from the top layer to the bottom one . For the component matrix corresponding to the top layer , all the columns are set to be identical and the entries in the columns are generated from N ( 1 , 1 ) . Then , for any layer below , the corresponding component matrix is generated based on the component matrix in the upper layer by adding different noises corresponding to different groups in current layer . The noises in the column are absolute values of samples from N ( 0 , 02 ) Fih W∗ h . Based on W∗ , the label vector yi for the ith task is generated as yi = Xiw∗ i + i , where each entry in Xi is generated from N ( 0 , 1 ) and i is a vector of noises with its entries generated from N ( 0 , 1 ) . We use the mean square error ( MSE ) to measure the performance of the estimation ˆW , which is defined as MSE = i ) . In each setting , we gen1 mn erate ntr = 100 samples for training , nte = 100 samples for testing , and nv = 100 samples as a validation set to select the hyper parameters in all the methods . nally , we generate the parameter matrix W∗ as W∗ = m i=1( ˆwi − w∗ i Xi( ˆwi − w∗ i )T XT
Table 2 shows the average performance of all the methods over 10 random simulations . As shown in Table 2 , the MTFL has high estimation errors under all the settings . One possible reason is that it simply learns common feature representations but cannot capture the complex task tree structure . The task grouping models , ie the CMTL and GOMTL methods , achieve lower estimation errors than the hierarchial MTL models , ie the Dirty and Cascade methods , since the task structure in each level of the task tree can be viewed as task groups . The MeTaG model is a combination of
402 Table 2 : The average MSE ’s of different methods over 10 random simulations on synthetic data ( mean ± standard derivative ) . The highlighted numbers stand for the best results under the significance t test with 95 % confidence . a t a D l e d o M
Num . of samples Num . of features Num . of tasks Num . of layers
MTFL Dirty
Cascade CMTL GOMTL MeTaG
TAT
Best H in TAT ntr , nte , nv = 100 ntr , nte , nv = 100 ntr , nte , nv = 100 ntr , nte , nv = 100 ntr , nte , nv = 100 d = 100 m = 4 H∗ = 3
21878±01316 09972±00611 08950±00475 01632±00676 01807±00163 02123±00177 01548±00113
H = 3 d = 100 m = 8 H∗ = 4
23961±01322 10694±00763 09049±00435 02689±00190 02236±00366 02696±00178 02020±00165
H = 4 d = 100 m = 16 H∗ = 5
28297±01429 11847±00772 09173±00348 02633±00093 04767±00337 03427±00225 02401±00105
H = 5 d = 100 m = 32 H∗ = 6
64354±01565 13951±00754 09487±00230 03132±00129 04976±00481 03000±00136 02647±00101
H = 6 d = 100 m = 64 H∗ = 7
102075±02035 19000±00661 09690±00395 03684±00069 03444±00168 03446±00087 03352±00066
H = 6
Figure 2 : Two examples of the task tree in the synthetic data , where m = 2H∗−1 . Left : m = 8 , H∗ = 4 ; right : m = 32 , H∗ = 6 .
Figure 3 : The top 4 layers in the learned task tree ( H = 6 ) with two representations for the synthetic data when H∗ = 6 . the task grouping and the hierarchical approaches and it can learn multi level task groups , which is similar to the task tree structure , hence , it outperforms both the hierarchical MTL models and the task grouping methods when the height of the task tree is high , eg , H∗ = 6 or 7 . Among all those methods , the proposed TAT model has the best performance under all the settings . In Table 2 , we record the best H in the TAT model selected based on the candidate set . From the results , we see that the estimated H ’s perfectly match the ground truths , which implies that the proposed TAT model can well capture the tree structure . This also explains why the TAT model can consistently achieve good performance . The left figure in Fig 4 also reports the sensitivity analysis of the TAT model with respect to H under different settings where each line corresponds to a setting with the ground truth H∗ depicted in the legend and the best selected H ’s are denoted by solid markers . From the results , we can find that the performance is not very sensitive to the number of layers on this synthetic data .
Moreover , since the learned component matrices can be obtained from the TAT model , we can obtain the learned task tree based on
Figure 4 : Sensitivity analysis of the TAT model wrt H . Left figure : Results on synthetic data where H∗ = 3 , 4 , 5 , 6 , 7 according to Table 2 . Right figure : Results on the microarray , school and traffic datasets .
Figure 5 : Left figure : The number of iterations required in Algorithm 2 . Right figure : The change of Err when varying the number of iterations in Algorithm 1 . the component matrices . Due to the limited precision in the numerical computation , the component parameters for tasks can not be exactly identical and we use the normalized cut algorithm [ 22 ] to discover the tree structure layer by layer where in each layer , tasks from a group are assumed to belong to an internal node . Fig 3 shows the top 4 layers of the learned task tree when H∗ = 6 . We provide two representations for the learned task tree . The first one is the conventional tree representation and the second one is a layerwise representation where the nodes in each layer denote the component parameters in the corresponding component matrix and they have the same color if they belong to one group or equivalently share the same parent node . By comparing with the true task tree at the right side of Fig 2 , we can find that the TAT model has good recovery for the binary tree in the top 4 layers . The left figure in Fig 5 plots the number of iterations required by Algorithm 2 in each iteration of Algorithm 1 , while the right figure shows the change of the relative estimation error ( Err ) , which is defined as Err = ˆW − W∗F /W∗F , by varying the number of iterations in Algorithm 1 . From the results , we find that both algorithms converge in a fast rate . 6.2 Results on Microarray Data
In this section , we conduct experiments on the microarray data [ 23],5 a benchmark dataset for MTL . The microarray data is
5http://wwwncbinlmnihgov/pmc/articles/PMC545783/
16Layer 616Layer 581624Layer 4481216202428Layer 323456789100150202503035HMSE H*=7H*=6H*=5H*=4H*=3234567891003035040450505506H(n)MSE MicroarraySchoolTraffic0510152025303512345Number of iterations in Algorithm 1Needed number of iterations in Algorithm 2051015202530350102030405060708Number of iterations in Algorithm 1Err403 6.3 Results on School and Traffic Data
In this section , we experiment on the school and traffic data . The school data6 is a data set with the exam scores of 15,362 students from 139 secondary schools , where each student is described by 27 attributes . Each learning task is a regression problem to predict the students’ exam scores at a school , leading to 139 regression tasks . We randomly select 30 % , 50 % and 20 % samples for training , testing , and validation separately .
The traffic data [ 11 ] is to help understand the casual relationships from the entries to the exits of vehicle flows , which is an important problem in traffic systems . This dataset is collected from 272 sensors placed in a highway network , where 136 sensors are placed in the exits of the highways and the others are in the entries . Each exit corresponds to one task and the information collected in entries is considered as the data matrix shared by all the tasks . In each task , there are 384 data samples . We randomly select 20 % , 60 % and 20 % samples for training , testing and validation separately . i 2
All the experiments are repeated for 10 times and the average 2 , of difnormalized MSE ’s ( nMSE ) , ie MSE/ 1 m ferent models are reported in Table 3 . Similar to the microarray data , the TAT method has the best performance on both datasets . The best selected H ’s on the two dataset are 6 and 7 , respectively , which are shown in the right figure of Fig 4 . m y∗
1 ni i=1
Microarray
Model MTFL Dirty
Table 3 : The average ( n)MSE ’s of different methods over 10 random splits on the microarray , school and traffic data . 04393±00055 04445±00051 04366±00058 04374±00066 06466±00444 04227±00049 04169±00032
03523±00117 03299±00077 03228±00070 03367±00096 03258±00052 03116±00068 03107±00069
06342±00913 06141±01104 06112±00866 06127±00887 06121±00877 06088±00881 05966±00784
Cascade CMTL GOMTL MeTaG
TAT
School
Traffic
Figure 7 : Sensitivity analysis of the TAT model on the CIFAR 10 and CIFAR 100 datasets wrt H . The best selected H ’s are denoted by solid markers . 6.4 Results on CIFAR Data
In this section , two popular object recognition databases , the CIFAR 10 and CIFAR 100 datasets,7 are used in our experiments . Each dataset consists of 50,000 color images with size 32 × 32 for training and 10,000 images for testing . The CIFAR 10 data contains 10 classes and in the CIFAR 100 data , there are 100 classes . Each class in those two datasets corresponds to a task and all the tasks share the same training images . By following [ 5 ] , we use the nonlinear features derived from the k means algorithm instead of the raw pixels , where d = 6401 . The GOMTL model fails to work on those two datasets , since the Kronecker product that it requires between two big matrices related to the feature dimensionality is
6http://wwwcsuclacuk/staff/AArgyriou/code/ 7http://wwwcstorontoedu/~kriz/cifarhtml
Figure 6 : The visualization of the task tree on the microarray data . Top : tree obtained from the hierarchical clustering algorithm . Middle : the learned task tree obtained from the TAT model with two representations . Bottom : the names of the genes . a gene expression data set related to isoprenoid biosynthesis in plant organism . One major challenge in this problem is to find the cross talks between two isoprenoid pathways : the mevalonate pathway and the plastidial pathway . The tasks are regression problems where the data features are the expression levels of 21 genes in the mevalonate pathway and the labels are the expression levels of 18 genes in the plastidial pathway , resulting in 18 tasks . There are 118 samples with each feature log transformed and normalized to have mean 0 and variance 1 . According to [ 23 ] , the genes exhibit tree structure , making it suitable for learning the task tree . We randomly select 60 % , 20 % , and 20 % samples for training , testing , and validation respectively . All the experiments are repeated for 10 times and the average MSE ’s of different models are reported in Table 3 . From Table 3 , we see that the TAT model achieves the best performance over all the methods in comparison . We plot the change of the performance of the TAT model with respect to H in the right figure of Fig 4 and find that the TAT model achieves the best performance when setting H to be 5 .
Moreover , we show the top 3 layers of the learned task tree in Fig 6 for the case that H = 5 . Since there is no ground truth for the tree structure among tasks , we compare with a tree structure learned from a hierarchical clustering method , which first uses the k means clustering method to cluster different tasks into 3 clusters and then groups to 2 clusters based on the clustering results in the first step . From the results shown in Fig 6 where the hierarchical clustering result is at the top and the task tree is in the middle , we see that the learned task tree by the TAT model is very similar to the tree obtained from the hierarchical clustering method , which in some sense demonstrates the ability of the TAT method to find the underlying tree structure among tasks .
24681012141618Layer 524681012141618Layer 424681012141618Layer 3234567891075875976761762763764765766HAccuracy CIFAR−10234567891048248448648849492494496498HAccuracy CIFAR−100404 6.5 Efficiency Testing for Algorithm 3
Table 5 : Comparison on the total running time ( in seconds ) . Length 10000
5
1000 10 39.7 0.6 66.2
5000 10
131.3 2.9 45.3
10
303.8 5.6 54.3
Num . of seq .
CVX
Algorithm 3
Speedup
1000 178.8 0.27 662.2
10 1000 195.4 0.69 283.1
20 1000 220.8 0.94 234.9
In this section , we test the efficiency of Algorithm 3 , which is a key step in the whole optimization procedure and needs to be executed frequently . We compare Algorithm 3 with the CVX solver [ 10 ] since problem ( 17 ) is convex . The experimental platform is the Matlab 2013b running on a machine with Intel i7 CPU and 8GB RAM .
We generate random sequences to test Algorithm 3 . The sequence in the sequential constraints is of length H and from the previous experiments , we can see that it is usually small , eg , a constant between 2 and 10 . We randomly generate 1000 sequences with length 5 , 10 , and 20 respectively , and test the algorithms on them . Moreover , we also do some experiments under the setting that the length of the sequence is large and generate 10 sequences with length 1000 , 5000 , and 10000 respectively . The total running time for the two settings is reported in Table 5 , from which we see that the proposed Algorithm 3 is very efficient under all the settings .
7 . CONCLUSION AND FUTURE WORK
In this paper , we proposed a novel TAT model to learn the underlying tree structure for multi task learning . We developed an efficient algorithm to solve the non convex problem in the proposed TAT model and provided theoretical analysis . Experimental results show that the task tree learned by the TAT model can provide deep understanding on the task relations contained in the data .
Currently , the number of layers in the TAT model needs to be predefined . In future work , we are interested in learning the number of layers from data automatically .
Acknowledgments This work is supported by Natural Science Foundations of China under Grant No . 61305071 .
2 ) , where ¯q∗
2 ) , which contradicts the fact that ( ¯q∗
APPENDIX A . PROOF OF LEMMA 1 Proof . The first statement is obvious . We now adopt the induction technique to prove the second statement . When H = 2 and ¯u1 ≤ ¯u2 , we assume the optimal solution is 1 ≥ ¯q∗ 1 , ¯q∗ ( ¯q∗ 1 > ¯q∗ 2 . If ¯q∗ 2 , there must exist a ˇq that 2 and ¯u1 ≤ ˇq ≤ ¯u2 . Otherwise , if ¯u1 ≤ ¯u2 < ˇq < ¯q∗ ¯q∗ 1 > ˇq > ¯q∗ 1 , 2 = ¯u2 , and then ( ¯q∗ we can immediately get ¯q∗ 2 , ¯q∗ 2 ) is better than ( ¯q∗ 1 , ¯q∗ 1 , ¯q∗ 2 ) is the optimal so2 < ˇq < ¯u1 ≤ ¯u2 can be proved similution . The case that ¯q∗ 2 and ¯u1 ≤ ˇq ≤ ¯u2 . Assume 1 > ˇq > ¯q∗ larly . Now we have ¯q∗ , we can immediately obtain that ( ˇq , ˇq ) is better than ˇq = ¯u1+¯u2 1 , ¯q∗ ( ¯q∗ 2 ) is the optimal solution . Therefore , we must have ¯q∗ Then we assume that the statement holds for any H ≤ n − 1 . We will show that when H = n , the statement also holds . Actually , given H = n and ¯u1 ≤ ··· ≤ ¯un , the optimal solution must have the form ( ˇq,··· , ˇq)|n−1 ¯q∗ n ) , where ˇq ≥ ¯q∗ n . Otherwise , suppose the optimal solution is denoted by
2 ) , which again contradicts the fact that ( ¯q∗ n , ie ( ˇq,··· , ˇq , ¯q∗
1 = ¯q∗
2 = ¯u1+¯u2
.
2
1 , ¯q∗
2
Figure 8 : Two representations of the task tree on the CIFAR 10 data . computationally prohibited and hence we do not include it in the comparison . The classification accuracies of different models are shown in Table 4 . From the results , we can see that the TAT method has the best performance on those two datasets . Moreover , Fig 7 shows how the TAT model performs when varying H and we can find that the best H ’s in those two datasets are both equal to 8 .
Moreover , the best learned task tree , which has 8 layers , on the CIFAR 10 data is shown in Fig 8 . From Fig 8 , we can find some interesting results . For example , tasks ‘automobile’ and ‘truck’ are identified to belong to a group at the 7th layer while the other tasks belong to another one . Tasks ‘cat’ and ‘dog’ always belong to the same group in the task tree and all the tasks related to animals ( ie , bird , cat , deer , dog , frog , and horse ) are discovered to belong to a group at the 5th layer and above . Moreover , almost all the tasks related to manufactures ( eg automobile , ship , and truck ) are always identified to belong to different groups below the 5th layer due to their different shapes . All the above findings are intuitively reasonable and this shows that the TAT model can find meaningful task relations contained in the data .
Table 4 : The accuracies of different methods on the CIFAR 10 and CIFAR 100 datasets .
Data
CIFAR 10 CIFAR 100
MTFL Dirty 72.56 71.15 39.61 42.45
Cascade 74.76 46.12
CMTL MeTaG 75.99 74.49 46.70 48.62
TAT 76.49 49.63
12345678910Layer 812345678910Layer 712345678910Layer 612345678910Layer 512345678910Layer 412345678910Layer 312345678910Layer 212345678910Layer 1405 2 ≥ ··· ≥ ¯q
2,··· , ¯q 1 ≥ ¯q 2,··· , ¯q
( ¯q 1 , ¯q n ) with at least one equality dissatisfied in inequalities ¯q n . Then we can immediately obtain a contradiction that the sequence ( ˇq,··· , ˇq)|n−1 ¯q n is better than n ) where ( ˇq,··· , ˇq)|n−1 is the optimal solution of ( ¯q 1 , ¯q the problem of size H = n − 1 corresponding to the sequence ( ¯u1 , . . . , ¯un−1 ) . Similarly , we can get that the optimal solution 1 , ˇq,··· , ˇq ) , where have the form ¯q∗ 1 ≥ ˇq . Combing those results we complete the proof . ' ¯q∗
1 ( ˇq,··· , ˇq)|n−1 , ie ( ¯q∗
B . PROOF OF LEMMA 2 Proof . We first prove it when u∗ ≥ u ≥ b1 . Given any H = n and the sequence ( ¯u1,··· , ¯un ) , we consider the feasible sequence ( b1,··· , bn ) for problem ( 17 ) , where b1 ≥ ··· ≥ bn . Then , we can obtain that the sequence ( b1,··· , b1)|n is not worse than ( b1,··· , bn ) , because if ( b1,··· , b1)|n is worse , there must exist a sequence ( ˇb2,··· , ˇbn ) , where u∗ > ˇb2 ≥ ··· ≥ ˇbn , such that the optimal solution for the sub sequence ( ¯u2,··· , ¯un ) is ( ˇb2,··· , ˇbn ) , and in that case ( u∗ , ˇb2,··· , ˇbn ) is better than ( u∗,··· , u∗)|n , which contradicts with the fact that ( u∗,··· , u∗)|n is the optimal solution . Therefore ( b1,··· , b1)|n is better than ( b1,··· , bn ) . Furthermore , since u∗ ≥ u ≥ b1 , it is easy to see that ( u,··· , u)|n is not worse than ( b1,··· , b1 ) due to the h(x − ¯uh)2 . So we complete the proof when u∗ ≥ u ≥ b1 . The case that bH ≤ u ≤ u∗ can be ' proved similarly and we finish the proof . convexity of the function f ( x ) =
1 ,··· , ¯q∗ l , ¯q∗ l+1,··· , ¯q∗ l ≥ ˙u∗ , because if ¯q∗ l+1 ≥ ··· ≥ ¯q∗ l ) with ( ˙u∗,··· , ˙u∗)|l in ( ¯q∗
C . PROOF OF THEOREM 1 Proof . The case that ˙u∗ ≥ ¨u∗ is obvious . Then we prove the case that ˙u∗ < ¨u∗ . In this case , we denote the optimal solution for the concatenated sequence by ( ¯q∗ n ) , where l ≥ ¯q∗ 1 ≥ ··· ≥ ¯q∗ ¯q∗ n . Then it is easy to show l < ˙u∗ , substituting the sub sequence that ¯q∗ 1 ,··· , ¯q∗ l+1,··· , ¯q∗ 1 ,··· , ¯q∗ ( ¯q∗ n ) will lead to a better feasible solution , which makes a contradicl+1 ≤ ¨u∗ . Then based on tion . Similarly , we can show that ¯q∗ Lemma 2 , substituting the two sub sequences ( ¯q∗ l ) and l+1)|n−l rel+1,··· , ¯q∗ ( ¯q∗ spectively will generate a new solution that is not worse than the previous one . Note that ¯q∗ ˙u∗ < ¨u∗ and l ≥ ¯q∗ l = ¯q∗ ¯q∗ l+1 due to the convexity of the objective function , making the optimal solution have the form ( u∗,··· , u∗)|n . Plugging the form into problem ( 17 ) , we get u∗ = , in which we reach the con' clusion . l+1 . Then the optimal solution is achieved when ¯q∗ l ≥ ˙u∗ , ¯q∗ l ,··· , ¯q∗ l )|l and ( ¯q∗ l+1 , ··· , ¯q∗ l+1 ≤ ¨u∗ , n i=1 ¯ui n l , ¯q∗
1 ,··· , ¯q∗ n ) with ( ¯q∗
D . PROOF OF THEOREM 2 Proof . In Algorithm 3 , step 1 splits the initial sequence ( ¯u1 , ··· , ¯uH ) into non decreasing sub sequences . According to Lemma 1 , the solutions for those non decreasing sub sequences take the form that the entries in the solution are identical . Then , steps 2 14 concatenate the solutions of these sub sequences according to Theorem 1 iteratively . According to Theorem 1 , the global optimality can be guaranteed for any concatenation operation . So Algorithm ' 3 can find the optimal solution in step 15 for problem ( 17 ) .
References [ 1 ] R . K . Ando and T . Zhang . A framework for learning predictive structures from multiple tasks and unlabeled data . JMLR , 6:1817–1853 , 2005 .
[ 2 ] R . Caruana . Multitask learning . MLJ , 28(1):41–75 , 1997 .
[ 3 ] J . Chen , L . Tang , J . Liu , and J . Ye . A convex formulation for learning shared structures from multiple tasks . In ICML , 2009 .
[ 4 ] J . Chen , J . Zhou , and J . Ye . Integrating low rank and group sparse structures for robust multi task learning . In KDD , 2011 .
[ 5 ] A . Coates , A . Y . Ng , and H . Lee . An analysis of single layer networks in unsupervised feature learning . In AISTATS , pages 215–223 , 2011 .
[ 6 ] T . Evgeniou , C . A . Micchelli , M . Pontil , and J . Shawe Taylor . Learn ing multiple tasks with kernel methods . JMLR , 6(4 ) , 2005 .
[ 7 ] T . Evgeniou and M . Pontil . Regularized multi task learning . In KDD ,
2004 .
[ 8 ] P . Gong , C . Zhang , Z . Lu , J . Huang , and J . Ye . A general iterative shrinkage and thresholding algorithm for non convex regularized optimization problems . In ICML , 2013 .
[ 9 ] N . Görnitz , C . K . Widmer , G . Zeller , A . Kahles , G . Rätsch , and S . Sonnenburg . Hierarchical multitask structured output learning for large scale sequence segmentation . In NIPS , 2011 .
[ 10 ] M . Grant and S . Boyd . CVX : Matlab software for disciplined convex programming , version 21 http://cvxr.com/cvx , 2014 .
[ 11 ] L . Han , G . Song , G . Cong , and K . Xie . Overlapping decomposition for causal graphical modeling . In KDD , 2012 .
[ 12 ] L . Han and Y . Zhang . Learning multi level task groups in multi task learning . In AAAI , 2015 .
[ 13 ] L . Han , Y . Zhang , G . Song , and K . Xie . Encoding tree sparsity in multi task learning : A probabilistic framework . In AAAI , 2014 .
[ 14 ] L . Jacob , F . Bach , and J P Vert . Clustered multi task learning : A convex formulation . In NIPS , 2008 .
[ 15 ] A . Jalali , P . Ravikumar , S . Sanghavi , and C . Ruan . A dirty model for multi task learning . In NIPS , 2010 .
[ 16 ] Z . Kang , K . Grauman , and F . Sha . Learning with whom to share in multi task feature learning . In ICML , 2011 .
[ 17 ] S . Kim and E . P . Xing . Tree guided group lasso for multi task regres sion with structured sparsity . In ICML , 2010 .
[ 18 ] A . Kumar and H . Daume III . Learning task grouping and overlap in multi task learning . In ICML , 2012 .
[ 19 ] J . Liu , S . Ji , and J . Ye . Multi task feature learning via efficient 2,1 norm minimization . In UAI , 2009 .
[ 20 ] K . Lounici , M . Pontil , A . B . Tsybakov , and S . van de Geer . Taking advantage of sparsity in multi task learning . In COLT , 2009 .
[ 21 ] A . C . Lozano and G . Swirszcz . Multi level lasso for sparse multi task regression . In ICML , 2012 .
[ 22 ] J . Shi and J . Malik . Normalized cuts and image segmentation . TPAMI ,
22(8):888–905 , 2000 .
[ 23 ] A . Wille , P . Zimmermann , E . Vranová , A . Fürholz , O . Laule , S . Bleuler , L . Hennig , A . Preli´c , P . von Rohr , L . Thiele , E . Zitzler , W . Gruissem , and P . Bühlmann . Sparse graphical Gaussian modeling of the isoprenoid gene network in arabidopsis thaliana . Genome Biol , 5(11):R92 , 2004 .
[ 24 ] Y . Zhang . Heterogeneous neighborhood based multi task local learn ing algorithms . In NIPS , 2013 .
[ 25 ] Y . Zhang and J . G . Schneider . Learning multiple tasks with a sparse matrix normal penalty . In NIPS , 2010 .
[ 26 ] Y . Zhang and D Y Yeung . A convex formulation for learning task relationships in multi task learning . In UAI , 2010 .
[ 27 ] Y . Zhang , D Y Yeung , and Q . Xu . Probabilistic multi task feature selection . In NIPS , 2010 .
[ 28 ] A . Zweig and D . Weinshall . Hierarchical regularization cascade for joint learning . In ICML , 2013 .
406
