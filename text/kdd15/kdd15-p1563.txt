Integrating Vertex centric Clustering with Edge centric
Clustering for Meta Path Graph Analysis
Yang Zhou
Georgia Institute of
Technology
Atlanta , GA 30332 yzhou@gatech.edu
Ling Liu
David Buttler
Georgia Institute of
Lawrence Livermore National
Technology
Laboratory
Atlanta , GA 30332 lingliu@ccgatechedu
Livermore , CA 94550 davidbuttler@llnl.gov
ABSTRACT Meta paths are good mechanisms to improve the quality of graph analysis on heterogeneous information networks . This paper presents a meta path graph clustering framework , VEPathCluster , that combines meta path vertex centric clustering with meta path edge centric clustering for improving the clustering quality of heterogeneous networks . First , we propose an edge centric path graph model to capture the meta path dependencies between pairwise path edges . We model a heterogeneous network containing M types of meta paths as M vertex centric path graphs and M edge centric path graphs . Second , we propose a clustering based multigraph model to capture the fine grained clustering based relationships between pairwise vertices and between pairwise path edges . We perform clustering analysis on both a unified vertex centric path graph and each edge centric path graph to generate vertex clustering and edge clusterings of the original heterogeneous network respectively . Third , a reinforcement algorithm is provided to tightly integrate vertex centric clustering and edge centric clustering by mutually enhancing each other . Finally , an iterative learning strategy is presented to dynamically refine both vertex centric clustering and edge centric clustering by continuously learning the contributions and adjusting the weights of different path graphs . Categories and Subject Descriptors
H28 [ Database Applications ] : Data Mining Keywords
Meta Path Graph Clustering ; Vertex/Edge centric Path Graph/Multigraph ; Edge centric Random Walk ; Vertex/Edge centric Clustering
1 .
INTRODUCTION
Heterogeneous information networks are graphs with heterogeneous types of entities and links . A meta path is a path connecting multiple types of entities through a sequence of heterogeneous meta links , representing different kinds of semantic relations among different types of entities . DBLP dataset has four types of entities : authors ( A ) , publishing venues ( V ) , papers ( P ) and paper terms ( T ) . Figure 1 ( a ) gives nine example meta paths between authors in the DBLP dataset , each is composed of three types of meta links : A P , V P and T P , representing different types of relationships between authors . More meta paths between authors can cfl 2015 Association for Computing Machinery . ACM acknowledges that this con tribution was authored or co authored by an employee , contractor or affiliate of the United States government . As such , the United States Government retains a nonexclusive , royalty free right to publish or reproduce this article , or to allow others to do so , for Government purposes only . KDD’15 , August 10 13 , 2015 , Sydney , NSW , Australia . cfl 2015 ACM . ISBN 978 1 4503 3664 2/15/08 $1500
DOI : http://dxdoiorg/101145/27832582783328
A
A
A
A
A
A
A
A
P
P
P
P
P
P
P
P
A
V
T
A
V
V
T
T
P
P
P
P
P
P
P
A …
P …
A P … …
A
A
A
T
A
A
T
A …
P
P
P
P
P …
A
A
A
A
A … u W g n u L n u K p1 p1 p2 p2 p17 p17 u Y
.
S p i l i h P u W g n u L n u K u Y
.
S p i l i h P
( a ) Meta Paths between Authors
( b ) Example Vertex centric Path Graph
Figure 1 : Example Meta Paths and Path Graphs from DBLP be generated through link combination and propagation . The meta path A P A captures the coauthor relationship , whereas the path A P V P A represents the relationship between a pair of authors through their papers published on the common venues . For each type of meta paths , we can construct a vertex centric path graph to capture an individual type of relationships between authors . For example , Figure 1 ( b ) shows that we join one type of links ( A P ) and its opposite form ( P A ) to generate a vertex centric A P A path graph , where vertices represent authors and edges denote the coauthor relationships between authors . For each pair of coauthors , say Kun Lung Wu and Philip S . Yu , we can represent the A P A path by using parallel edges , each representing one of their coauthored papers ( p1 , · · · , p17 ) . By join composition , we obtain the total number of their coauthored papers ( 17 ) . Clearly , mining heterogeneous information networks through multiple path graphs can provide new insights about how ideas and opinions on different subjects propagate differently among the same set of people .
Meta path based social network analysis is gaining attention in recent years [ 1–6 ] . Existing efforts utilize a selection of meta paths between the same type of entities to improve the quality of similarity search , classification , clustering , link prediction and citation recommendation in heterogeneous networks . However , none of the existing methods have addressed all of the following challenges . • Vertex centric clustering wrt multiple path graphs . As shown in Figure 1 , different meta paths exhibit different semantic meanings about the same type of entities . Thus , the vertex clustering results based on different path graphs are typically not identical . It is critical to develop a unified clustering model that can efficiently integrate the clustering results from multiple path graphs and improve the overall clustering quality . Specifically , a dynamic weight assignment scheme should be employed to assign different weights to different path graphs to reflect their possibly different contributions towards the clustering convergence .
• Fine grained vertex assignment and clustering objective . Metapath graph analysis differentiates the semantics carried by different meta paths in a heterogeneous network . Consequently , it demands fine grained vertex assignment and clustering objective to further improve the clustering quality . However , existing partitioning clustering approaches , such as K Means and K
1563 Medoids [ 7 ] , usually assign each vertex to its closest center . We argue that this kind of vertex assignment may not always produce an accurate clustering result . Consider Figure 2 ( a ) , by performing K Means on the A P A path graph to assign Kun Lung Wu to two centers of Bugra Gedik and Philip S . Yu , Figure 2 ( b ) shows a vertex assignment , ie , by simply using the coarse path edge weight ( the total number of coauthored papers ) to measure vertex closeness , Kun Lung Wu and Philip S . Yu are closer than Kun Lung Wu and Bugra Gedik . However , in reality , Kun Lung Wu and Bugra Gedik are known as database researchers with no or very few data mining papers but Philip S . Yu is a well known expert on data mining with much more data mining papers than database publications , thus the vertex assignment in Figure 2 ( c ) is more accurate and better quality . This is because the similarity measures used in vertex assignment and clustering objective of existing methods are too coarse to reflect the above ground truth . • Edge centric clustering wrt multiple path graphs . Conventional graph clustering models are usually based on the existence of vertex homophily . However , we argue that vertex homophily without edge clustering is insufficient for meta path graph analysis on heterogeneous networks . Consider Figures 2 ( b ) and ( c ) again , there is only one of 17 coauthored papers between KunLung Wu and Philip S . Yu published on DM conference ( KDD ) but all 8 coauthored papers between Kun Lung Wu and Bugra Gedik are published on DB conferences , indicating that KunLung Wu , Bugra Gedik and the path edge between them belong to cluster DB with very high probability . In comparison , it is highly probable that Philip S . Yu and the path edge between KunLung Wu and Philip S . Yu belong to different clusters . Without considering edge clustering , the vertex homophily alone can lead to inaccurate vertex clustering .
• Integrating vertex centric clustering and edge centric clustering . Vertex clustering and edge clustering on heterogeneous networks may have individual clustering goals and due to the different semantic relationships implied by different meta paths . Relying on either of them alone may result in incomplete and possibly inaccurate clustering results . However , none of existing methods study how to effectively combine the above two techniques into a unified meta path graph clustering model .
To address the above challenges , we develop an efficient vertex/edge centric meta path graph clustering approach , VEPathCluster , with four original contributions . • We model a heterogeneous network containing multiple types of meta paths in terms of multiple vertex centric path graphs and multiple edge centric path graphs . Each meta path corresponds to one vertex centric path graph and one edge centric path graph . • We propose a clustering based multigraph model to capture the fine grained clustering based relationships between pairwise vertices and between pairwise path edges about given K clusters .
• We integrate multiple types of vertex centric path graphs with different semantics into a unified vertex centric path graph in terms of their contributions towards the clustering objective . We cluster both the unified vertex centric path graph and each edgecentric path graph to generate vertex clustering and edge clusterings of the original heterogeneous network respectively .
• We design a reinforcement algorithm to tightly integrate vertexcentric clustering and edge centric clustering by mutually enhancing each other : ( 1 ) good vertex centric clustering promotes good edge centric clustering and ( 2 ) good edge centric clustering elevates good vertex centric clustering . We devise an iterative learning method to dynamically refine both vertex centric clustering and edge centric clustering by continuously learning the contributions and adjusting the weights of different path graphs .
Kun Lung Wu
Charu C . Aggarwal
Kun Lung Wu
Charu C . Aggarwal
Kun Lung Wu
Charu C . Aggarwal
2 DB Papers
2 DM Papers
Bugra Gedik ( a ) A P A Vertex Graph
Philip S . Yu
Bugra Gedik
Philip S . Yu
Bugra Gedik
Philip S . Yu
( b ) Clustering 1
( c ) Clustering 2
Figure 2 : Coarse Vertex Assignment/Clustering Objective
• Empirical evaluation over real datasets demonstrates the competitiveness of VEPathCluster against the state of the art methods .
2 . PROBLEM DEFINITION
We define the problem of vertex/edge centric meta path graph clustering in terms of the following four concepts . of s types of entity vertices , ie , V = Ss
A heterogeneous information network is denoted as G = ( V , E ) , where V is the set of heterogeneous entity vertices in G , consisting i=1 Vi , each Vi ( 1 ≤ i ≤ s ) represents the ith types of entity vertices . E is the set of heterogeneous meta links denoting the relationships between entity vertices in V . Due to heterogeneous entity vertices with s types , E can be divided into s×s subsets Ei j ( 1 ≤ i , j ≤ s ) such that E = Ss i=1 , j=1 Ei j , where Ei j is the set of meta links connecting vertices of the ith type ( Vi ) to vertices of the jth type ( V j ) . E ji is the opposite form of Ei j , specifying the set of meta links from V j to Vi .
The mth meta path of length l , denoted by MPm =< Ea0 a1 , Ea1 a2 , · · · , Eal−1 al > , is a sequence of different types of meta links , with source vertex type Va0 and destination vertex type Val ( 1 ≤ a0 , a1 , · · · , al ≤ s ) , such that < Ea0 a1 , Ea1 a2 , · · · , Eal−1 al > are l meta link types connected through join composition . For example , meta path A P A is of length 2 and comprises two meta link types : A P and P A .
For each meta path in G , we construct a vertex centric path graph to capture the meta path based relationships between vertices . Formally , a vertex centric path graph for MPm is denoted as VGm = ( Va0 , Val , Em ) , where Va0 ∈ V is the set of source vertices and Val ∈ V is the set of destination vertices in MPm , and Em ∈ E is the set of path edges between Va0 and Val . For the path edge set Em , we compute its adjacency matrix Pm by multiplying adjacency matrix of each type of composite meta links Ea0 a1 , Ea1 a2 , · · · , Eal−1 al , denoted by Wa0a1 , Wa1a2 , · · · , Wal−1al respectively . For Figure 1 ( b ) , we use WAP and WPA to denote the adjacency matrices of two types of meta links A P and P A respectively . We calculate an adjacency matrix PAA = WAP × WPA to obtain the path edge between KunLung Wu and Philip S . Yu with a value of 17 . For presentation brevity , when the type of source vertices is the same as the type of destination vertices in VGm , ie , Va0 = Val = Vc ∈ V , we simplify VGm = ( Va0 , Val , Em ) as VGm = ( Vc , Em ) , and path edges in Em measure the pairwise closeness between vertices in Vc . We denote the size of Vc as NVc = |Vc| and denote the size of Em as NEm = |Em| . In VEPathCluster , for a specific clustering task , users can select a subset of entity vertices of a certain type as the set of target vertices , denoted by Vc , and a subset of M target meta paths MPm . We construct M vertex centric path graphs VGm . The problem of Vertex/Edge centric meta Path graph Clustering ( VEPathCluster ) is to simultaneously perform two clustering tasks : ( 1 ) assign all entity vertices in Vc to K soft clusters with an NVc × K clustering membership matrix X with each row summing to 1 , and ( 2 ) cluster all path edges in each Em ( 1 ≤ m ≤ M ) into K soft clusters with an NEm × K clustering membership matrix Ym with each row summing to 1 . The desired clustering result should achieve the two goals : ( 1 ) both path edges and their associated vertices should belong to the same clusters , and vertices within each cluster are close to each other in terms of path edges between them in the same cluster ; and ( 2 ) vertices belonging to different clusters are relatively distant from each other in terms of clustered path edges between them .
1564 Kun Lung Wu
Charu C . Aggarwal
Kun Lung Wu
Charu C . Aggarwal
Kun Lung Wu
Charu C . Aggarwal
Kun Lung Wu
Charu C . Aggarwal
Kun Lung Wu
Charu C . Aggarwal
Bugra Gedik
Philip S . Yu
Bugra Gedik
Philip S . Yu
Bugra Gedik
Philip S . Yu
( a ) A P A Path Graph
( b ) A P V P A Path Graph
( a ) A P A Path Graph
Bugra Gedik ( b ) A P V P A Path Graph
Philip S . Yu
Bugra Gedik
Philip S . Yu ( c ) Unified Path Graph
Figure 3 : Vertex centric Path Graph
Figure 4 : Unified Vertex centric Path Graph
Figure 3 gives an illustrative example of two vertex centric path graphs about authors . For A P A path graph in Figure 3 ( a ) , the number associated with an author vertex represents the number of coauthored papers by this author . Here , we only consider coauthored papers on three DB conferences : SIGMOD , VLDB , ICDE and three DM conferences : KDD , ICDM , SDM . For A P V P A meta path graph in Figure 3 ( b ) , the number associated to an author , eg , Philip S . Yu ( 199 ) , represents the total number of papers published by this author on the above six venues . Similarly , the number on a path edge specifies the value of this path edge through link composition by multiplying adjacency matrices , eg , WAP × WPA in Figure 3 ( a ) , and WAP × WPV × WV P × WPA ) in Figure 3 ( b ) . 3 . THE VEPathCluster APPROACH
VEPathCluster improves the clustering quality by utilizing four novel mining strategies : ( 1 ) edge centric random walk model ; ( 2 ) clustering based multigraph model ; ( 3 ) integration of vertex centric clustering and edge centric clustering ; and ( 4 ) dynamic weight learning . VEPathCluster iteratively performs the following three tasks to achieve high quality clustering : ( 1 ) fix edge clustering and weight assignment to update vertex clustering ; ( 2 ) fix vertex clustering and weight assignment to update edge clustering ; and ( 3 ) fix vertex clustering and edge clustering to update weight assignment .
3.1 Initialization
Given a heterogeneous network G = ( V , E ) , the set of target vertices Vc ⊂ V , and the M target meta paths , the number of clusters K , we first construct the M vertex centric path graphs : VG1 , · · · , VGM . Then we initialize the weight assignment and produce the initial vertex clustering of Vc on K clusters .
Let ω(1 ) m ( 1 ≤ m ≤ M ) be the weight for the mth vertex centric path graph VGm at the first iteration , and Pm be the adjacency matrix of VGm . We use the initial weights ω(t ) M to integrate M vertex centric path graphs into a unified vertex centric path graph VG . The matrix form of VG , denoted by P(1 ) , is defined below .
1 , · · · , ω(t )
P(1 ) = ω(1 )
1 P1 + · ·· + ω(1 )
M PM st
M
X m=1
ω(1 ) m = 1 , ω(1 )
1 , · ·· , ω(1 )
M
> 0
( 1 )
Random weight assignment often performs poorly and results in incorrect clustering results due to the sharp difference in edge values from path graph to path graph , eg , the edge values in Figure 3 ( a ) are between 1 and 32 but the edge values in Figure 3 ( b ) are between 79 and 2219 . We normalize edge values in each VGm by assigning an initial weight for each VGm in terms of its maximal edge value , ie , ω(1 ) , where max Pm represents the maximal element in Pm .
1/ max P1 PM m=1 1/ max Pm
M = 1/ max PM
PM m=1 1/ max Pm
, . . . , ω(1 )
1 =
For two path graphs in Figure 3 , we multiply the edge values by the initial weights = 0.014 to generate two path graphs in Figures 4 ( a ) and ( b ) . Figure 4 ( c ) shows the combination of them with the above initial weights .
= 0.986 and
1/32+1/2219
1/32+1/2219
1/2219
1/32 at the first iteration . Figure 6 ( a ) exhibits the FCM clustering result of author vertices in Figure 4 ( c ) , where each green number and ochre number in the bracket denotes the membership probability of an author belonging to cluster DB or DM respectively .
3.2 Edge centric Random Walk Model
Edge centric random walk model is constructed by performing two tasks : ( 1 ) for each vertex centric path graph , construct an edgecentric path graph and define its vertex values and edge values ; and ( 2 ) define the transition probability on the edge centric path graph . Let VGm be a vertex centric path graph corresponding to the mth meta path MPm . We build an edge centric path graph EGm by converting the edges and vertices of VGm to the vertices and edges of EGm respectively . For example , we first transform the vertexcentric graph in Figure 5 ( a ) into a vertex/edge bipartite graph in Figure 5 ( b ) where rectangle vertices and circle vertices correspond to the vertices and the edges in Figure 5 ( a ) . The circle vertex ( W , Y ) ( 17 ) in Figure 5 ( b ) corresponds to the edge between Kun Lung Wu and Philip Yu with weight of 17 in Figure 5 ( a ) .
Next we convert the bipartite graph in Figure 5 ( b ) to the edgecentric graph in Figure 5 ( c ) by shrinking each common rectangle vertex shared by any pair of circle vertices to an edge between these two circle vertices , and assign the edge value with the value of the common rectangle vertex in Figure 5 ( b ) . For instance , a common rectangle vertex W ( 18 ) shared by two circle vertices ( W , Y ) ( 17 ) and ( W , G ) ( 8 ) in Figure 5 ( b ) is converted to the edge between ( W , Y ) ( 17 ) and ( W , G ) ( 8 ) in Figure 5 ( c ) . In addition , to capture the fact that a circle vertex connects to two rectangle vertices in Figure 5 ( b ) , we build a spin edge for each circle vertex in Figure 5 ( c ) . The value of this spin edge is the sum of the values of two rectangle vertices linked to this circle vertex in the bipartite graph . We define the transition probability on EGm such that the edgecentric random walk model can be employed to measure the closeness between a pair of edge vertices in EGm .
Definition 1 . [ Transition Probability on Edge centric Path Graph ] Let VGm = ( Vc , Em ) be a vertex centric path graph where Vc is the set of target vertices , E is the set of path edges between vertices in Vc and EGm = ( Em , Em × Em ) is a corresponding edge centric path graph . The transition probability on EGm is defined below .
Tm(emi , em j ) =
Qm(emi , em j ) NEm l=1 Qm(eml , em j )
, ( emi , em j ) ∈ Em × Em ,
0 , otherwise .
P
, 1 ≤ m ≤ M

( 2 ) where Qm is the adjacency matrix of EGm and Tm(emi , em j ) represents the transition probability from vertex emi to vertex em j in EGm . Consider Figure 5 , we compute the transition probabilities from l=1 Qm(eml , em j ) = ( 18 + 49 ) + 18 + 18 + 49 + 49 = 201 , the transition probability from ( W , Y ) to ( W , G ) is 18/201 = 009
( W , Y ) to all five circle vertices : Given that PNEm
Next we employ a soft clustering method , Fuzzy C Means ( FCM ) [ 8 ] , on the unified vertex centric path graph VG , to cluster each vertex to K clusters such that it has up to K membership probabilities . We use symbol X(1 ) k ( i ) to represent the membership probability of a vertex vi ∈ Vc ( 1 ≤ i ≤ NVc ) belonging to cluster ck ( 1 ≤ k ≤ K )
We express the above transition probability in a matrix form .
Tm = QmD−1 , 1 ≤ m ≤ M where D is a diagonal matrix D = diag(d1 , · · · , dNEm PNEm l=1 Qm(eml , em j ) ( 1 ≤ j ≤ NEm ) .
( 3 )
) and d j =
1565 Charu C . Aggarwal
W ( 18 )
A ( 32 )
G ( 10 )
Y ( 49 )
( W , A ) ( 2 )
( A , Y ) ( 32 ) u W g n u L n u K u Y
.
S p i l i h P
Bugra Gedik
( W , A ) ( 2 )
( W , G ) ( 8 )
( W , Y ) ( 17 )
( A , Y ) ( 32 )
( G , Y ) ( 9 )
( a ) Vertex centric Graph
( b ) Vertex/Edge Bipartite Graph
2 3 + 8 1
0 1 + 8 1
32
18
18+49
49
18
49
( W , Y ) ( 17 )
18
49
10
( W , G ) ( 8 ) ( G , Y ) ( 9 ) ( c ) Edge centric Graph
9 4 + 2 3
9 4 + 0 1
Figure 5 : Random Walk on Edges
W
A
G
( W , A ) ( 2 )
( A , Y ) ( 32 )
Y
0.09
0.33
0.24
( W , Y ) ( 17 )
0.09
0.24
( d ) Transition between Edges
( W , G ) ( 8 ) ( G , Y ) ( 9 ) ( e ) Transition Probability
3.3 Clustering based Multigraph Model
The second novelty is to perform clustering analysis on vertexcentric multigraph and edge centric multigraph to effectively combine vertex homophily with edge homophily . Recall Figure 2 ( b ) , assigning Kun Lung Wu to Philip S . Yu is due to the using of aggregated edge weight ( ie , the total number of coauthored papers ) to measure the vertex closeness . We address this problem by introducing two clustering based multigraph models , one for vertex centric path graphs and another for edge centric path graphs . m
Given that a vertex centric path graph VGm = ( Vc , Em ) , and the clustering result on the corresponding edge centric path graph EGm = ( Em , Em × Em ) obtained at the previous iteration . A vertexcentric path multigraph ie , Y(t−1 ) , denoted as V MGm = ( Vc , Fm ) , is an edge augmented multigraph , where Fm is the set of edges satisfying the following condition : for each edge ( vi , v j ) ∈ Em in VGm , we create a set of parallel edges between vi and v j in Fm . Each set of edges has up to K clustered edges and each of the parallel edges corresponds to a certain cluster ck . The value of the parallel edge with label ck between vi and v j in V MGm at the tth iteration , denoted by P(t ) mk(vi , v j ) , are computed as follow . P(t ) mk(vi , v j ) = Pm(vi , v j ) × Y(t−1 ) mk
( (vi , v j) ) , 1 ≤ m ≤ M , 1 ≤ k ≤ K
( 4 ) m mk where Pm(vi , v j ) represents the value of the edge between vi and v j in VGm . Y(t−1 ) mk denotes the kth column vector of the edge clustering membership matrix Y(t−1 ) ( (vi , v j ) ) specifies the membership probability of vertex ( vi , v j ) belonging to cluster ck in EGm at the last iteration . P(t ) mk is essentially a projection of Pm on ck . and Y(t−1 )
Similarly , let X(t ) ( t ≥ 1 ) be the soft clustering result on the unified vertex centric path multigraph V MG at the current iteration . For each edge centric path graph EGm = ( Em , Em × Em ) , we create an edge centric path multigraph EMGm : for each edge ( emi , em j ) ∈ Em × Em , we create a set of up to K parallel edges . Each of parallel edges corresponds to cluster ck . The edge values on EMGm at the tth iteration are defined as follow .
Q(t ) mk(emi , em j ) =
Qm(emi , em j ) × X(t ) k ( emi ∧ em j ) , k ( va ) + Rm(vb ) × X(t )
Rm(va ) × X(t )
1 ≤ m ≤ M , 1 ≤ k ≤ K emi , em j , k ( vb ) , emi = em j .
,
( 5 ) where Qm(emi , em j ) specifies the edge value between two vertices emi and em j in EGm , X(t ) k denotes the kth column vector of the vertex clustering membership matrix X(t ) and X(t ) k ( (emi ∧ em j ) ) specifies the membership probability of common vertex of two edges emi and em j belonging to cluster ck in the unified vertex centric path graph VG at the tth iteration . Q(t ) mk is essentially a projection of Qm on cluster ck . When emi = em j , edge ( emi , em j ) is a spin edge associated to emi in EGm . In this situation , emi and em j correspond to the same edge in VGm , and emi and em j will have the same two endpoints ( va and vb ) in VGm , eg , the spin edge ( (W , Y ) , ( W , Y ) ) in Figure 5 ( b ) and the edge between Kun Lung Wu and Philip S . Yu in Figure 5 ( a ) . Rm(vx ) represents the value of endpoint vx in VGm , say 18 for KunLung Wu in Figure 5 ( a ) , and X(t ) k ( vx ) denotes the probability of vx belonging to ck in VG or V MG at the tth iteration .
For ease of presentation , we omit all spin edges in Figure 6 . Based on the A P A edge centric path graph in Figure 6 ( b ) and its vertex soft clustering result in Figure 6 ( a ) , we generate the AP A edge centric path multigraph in Figure 6 ( c ) . Using the probabilities of Kun Lung Wu on clusters DB and DM : ( 0.96 , 0.04 ) in Figure 6 ( a ) and the edge between ( W , Y ) and ( W , A ) in Figure 6 ( b ) , we produce two parallel edges between ( W , Y ) and ( W , A ) in Figure 6 ( c ) as 18× 0.96 = 17.28 and 18× 0.04 = 0.72 respectively . 3.4 Edge centric Clustering
We perform edge centric soft clustering in two steps : ( 1 ) convert each edge centric path graph EGm to an edge centric path multigraph EMGm based on the vertex soft clustering X(1 ) on the unified vertex centric path graph VG or X(t ) ( t > 1 ) on the unified vertexcentric path multigraph V MG ; and ( 2 ) compute the edge soft clustering Y(t ) m on each edge centric path multigraph EMGm .
Different from traditional unsupervised graph clustering methods , at the first clustering iteration , we adopt a semi supervised manner on each EGm with the geometric mean of the probabilities of two endpoints belonging to cluster ck as the initial membership probability of an edge on ck . This is motivated by the observation that if the membership probabilities of two associated endpoints of an edge belonging to ck are very large , then it is highly probable that this edge also has a large probability on ck .
Formally , we convert each EGm to an EMGm by converting the adjacency matrix of EGm to up to K independent adjacency matrices in terms of the cluster labels of the edges in EGm , and then learns the cluster probabilities of edge vertices in EGm on ck based on the kth adjacency matrix . Let ( vi , v j ) be an edge vertex in EGm where vi and v j are the target vertices in the corresponding VGm = ( Vc , Em ) , and X(1 ) k ( vx ) be the cluster membership probability of vx ∈ Vc belonging to cluster ck at the first iteration . We define the initial edge clustering membership matrix Y(0 ) m for EMGm below .
Y(0 ) mk((vi , v j ) ) = qX(1 ) l=1 qX(1 ) PK l k ( vi ) × X(1 ) k ( v j ) ( vi ) × X(1 ) l
( v j )
, 1 ≤ m ≤ M , 1 ≤ k ≤ K ( 6 ) m , Y(0 ) mk is the kth column vector of Y(0 ) where Y(0 ) mk((vi , v j ) ) represents the initial membership probability of edge vertex ( vi , v j ) on ck in EMGm , and X(1 ) k ( vx ) specifies the probability of vx on ck in VG .
Based on the initial vertex clustering membership matrix X(1 ) for VG or the vertex clustering membership matrix X(t ) ( t > 1 ) for V MG , we transform each EGm into an edge centric path multigraph EMGm by Eq ( 5 ) . In the first clustering iteration , we update Y(1 ) m based on X(1 ) for VG through label propagation and update Y(t ) in each subsequent iteration t ( t > 1 ) . m with Y(0 ) m with Y(t−1 ) m
Similar to Eq ( 2 ) , the transition probability on each EMGm at the current iteration is defined by normalizing each kind of parallel edges with the same cluster labels in EMGm as follow .
T(t ) mk(emi , em j ) =
 mk(emi , em j )
Q(t ) NEm l=1 Q(t ) mk(eml , em j ) 0 ,
P
, Q(t ) mk(eml , em j ) , 0 , otherwise .
,
( 7 )
1 ≤ m ≤ M , 1 ≤ k ≤ K
1566 ( 0.96 , 0.04 )
Kun Lung Wu
Charu C . Aggarwal
W Y
W A
W Y
DB Cluster
W A
( 0.83 , 0.17 ) W Y
DB Cluster DM Cluster
( 0.46 , 0.54 ) W A
G
W
DB Cluster DM Cluster
G
W
Y
A
) 4 0 0
.
,
6 9 0 (
.
G
W
Y
A
) 7 4 0
.
,
3 5 0 (
.
Y
A
Bugra Gedik
Philip S . Yu
G A
G Y
G A
DM Cluster
G Y
G A
( 0.31 , 0.69 )
G Y
( 0.80 , 0.20 )
( a ) Vertex Clustering wrt Fig 4 ( c )
( b ) A P A Edge centric Path Graph wrt Fig 3 ( a )
( c ) A P A Edge centric Path Multigraph wrt Fig 6 ( a ) + Fig 6 ( b )
( d ) A P A Edge Clustering wrt Fig 6 ( a ) + Fig 6 ( c )
( 0.78 , 0.22 ) W Y
DB Cluster DM Cluster
( 0.31 , 0.69 ) W A
) 4 0 0
.
,
6 9 0 (
.
G
W
) 8 3 0
.
,
2 6 0 (
.
Y
A
G A ( 0.19 , 0.81 )
G Y ( 0.77 , 0.23 )
Kun Lung Wu
Charu C . Aggarwal
Kun Lung Wu
Charu C . Aggarwal
Kun Lung Wu
Charu C . Aggarwal
0.92 1+67.58 2 1.08 1+150.42 2
D M C u s t e r l
D B C u s t e r l
D M C u s t e r l
D B C u s t e r l
2
4 8
.
5 7 + 1
8 6
.
7
2
6 1
.
3 + 1
2 3 0
.
2.8
9
1+
1
6
3.0
2
2
2
7
1.4
2
1 +
1
0.3
2
3
1.5
9
1 +
9
0.6
1
4.1
1
1+
5
7
7.9
8
2
.
2 2 3 4 8 + 1
4 0
.
5 1
2
.
8 7 5 7 3 1 + 1
6 9
.
6 1
D M C u s t e r l
D B C u s t e r l
Bugra Gedik
Philip S . Yu
Bugra Gedik
Philip S . Yu
Bugra Gedik
Philip S . Yu
2
1.8 1+89.01 2 7.2 1+297.99 2
( e ) A P V P A Edge Clustering wrt Fig 3 ( b ) + Fig 6 ( a )
( f ) A P A Vertex centric Path Multigraph wrt Fig 3 ( a ) + Fig 6 ( d )
( g ) A P V P A Vertex centric Path Multigraph wrt Fig 3 ( b ) + Fig 6 ( e )
( h ) Unified Vertex centric Path Multigraph wrt Fig 6 ( f ) + Fig 6 ( g )
Figure 6 : Iterative Vertex Clustering on Vertex centric Path Multigraph and Edge Clustering on Edge centric Path Multigraph where T(t ) mk(emi , em j ) denotes the transition probability with cluster label ck on one of parallel edges between edge vertices emi and em j in EMGm . The transition matrix on EMGm is given below .
T(t ) mk
= Q(t ) mk(D−1 mk)(t ) , 1 ≤ m ≤ M , 1 ≤ k ≤ K
( 8 ) mk(eml , em j ) ( 1 ≤ j ≤ NEm ) . mk)(t ) = diag(d1 , · · · , dNEm mk)(t ) is a diagonal matrix ( D−1 l=1 Q(t ) where ( D−1 and d j = PNEm Thus , we produce K edge clustering kernels T(t ) mk , each corresponding to cluster ck ( 1 ≤ k ≤ K ) . The transition operation in each edge centric path multigraph is divided into two steps : ( 1 ) choose those parallel edges with the objective cluster label by clustering objective ; and ( 2 ) select an edge with the largest probability from the above edges to jump .
) ,
Let Ym = [ Ym1 , Ym2 , · · · , YmK ] ∈ RNEm ×K be the edge clustering membership matrix for Em in EMGm ( 1 ≤ m ≤ M ) . For each edge clustering membership vector Ymk ( 1 ≤ k ≤ K ) based on cluster ck , we use an individual clustering kernel T(t ) mk to iteratively infer the membership probabilities of all edge vertices in Em on ck .
Initilization : Ymk = Y(t−1 ) Iteration : Ymk = T(t ) mk
Ymk mk
( 9 )
Based on the edge clustering membership matrix Y(t−1 ) mk at the last clustering round , VEPathCluster iteratively infers the membership probabilities of vertices in Em until Ymk converges . We then normalize each entry Ymk(emi ) ( 1 ≤ i ≤ NEm ) in Ymk as follow .
Y(t ) mk(emi ) =
Ymk(emi ) PK l=1 Yml(emi )
( 10 ) where emi ∈ Em represents an edge vertex in EMGm and Y(t ) mk specifies the normalized edge clustering membership vector based on ck . Thus , the edge clustering membership matrix is updated below .
Y(t ) m = hY(t ) m1 Y(t ) m2
· · · Y(t ) mKi , 1 ≤ m ≤ M
( 11 )
For example , based on the vertex clustering in Figure 6 ( a ) and the edge centric path multigraph in Figure 6 ( c ) , we produce the A P A edge clustering in Figure 6 ( d ) .
3.5 Vertex centric Clustering
The vertex clustering on the unified vertex centric path multigraph V MG follows the heuristic rule : if vertex vi ∈ Vc in each vertex centric path graph VGm has many neighbors with large probabilities on cluster ck and the edges between vi and these neighbors have large probabilities on ck , then it is highly probable that vi belongs to ck with a larger probability . In each iteration , we use the edge clustering result on each edge centric path graph EGm at the previous iteration ( Y(t−1 ) ) to perform the vertex clustering on V MG at the current iteration ( X(t ) ) in three steps . m m
( 1 ) Based on Y(t−1 ) and Eq ( 4 ) , we first convert each VGm to an vertex centric path multigraph V MGm by transforming the adjacency matrix of VGm into K independent adjacency matrices in terms of the cluster labels of parallel edges . For example , based on the edge clustering result on the edge centric path multigraph in Figure 6 ( d ) ( or Figure 6 ( e) ) , we convert the vertex centric path graph in Figure 3 ( a ) ( or Figure 3 ( b ) ) to the vertex centric path multigraph in Figure 6 ( f ) ( or Figure 6 ( g) ) .
( 2 ) We combining M vertex centric path multigraphs V MGm into the unified vertex centric path multigraph V MG based on each of K edge clusters with weighting factors ω(t ) N . A dynamic weight tuning mechanism will be detailed in Section 36 Thus , we compute the value of the unified parallel edge between vertices vi and v j in V MG about cluster ck at the tth iteration as follow . Mk(vi , v j ) , 1 ≤ k ≤ K
1 , · · · , ω(t )
P(t ) k ( vi , v j ) = ω(t )
1 P(t )
M P(t )
M
1k(vi , v j ) + ·· · + ω(t ) 1 ,· · · , ω(t )
> 0
M
( 12 ) st
ω(t ) m = 1 , ω(t )
X m=1 where ω(t ) m ( 1 ≤ m ≤ M ) represents the weight for the mth vertexcentric path multigraph V MGm at the tth iteration , and P(t ) mk(vi , v j ) specifies the value of the parallel edge with label ck between vi and v j in V MGm . Note that P(t ) 1 , · · · , ω(t ) through dynamic weight learning during each iteration . k ( vi , v j ) keeps changing with ω(t )
M
The matrix form of V MG is defined based on K kinds of clus tered parallel edges .
P(t ) 1
P(t ) K st
= ω(t )
1 P(t )
11
2 P(t )
21
+ · ·· + ω(t )
M P(t )
M1
+ ω(t ) · ·· + ω(t )
= ω(t )
1 P(t )
1K
2 P(t )
2K
M
X m=1
ω(t ) m = 1 , ω(t )
1 , · ·· , ω(t )
M
> 0
+ ·· · + ω(t )
M P(t )
MK
,
( 13 )
Figure 6 ( h ) shows the unified vertex centric path multigraph by combining the two vertex centric path multigraphs in Figure 6 ( f ) and ( g ) with the weights of ω1 and ω2 respectively such that the clustered path edges with the same labels between the same pair of vertices from two vertex centric path multigraphs are combined .
1567 of O are both polynomial functions of the above variables . Without loss of generality , we rewrite Eq ( 19 ) as follow . max ω1,··· ,ωM
O(X , Y1 , · ·· , YM , ω1 , · ·· , ωM ) = max ω1,··· ,ωM
Pp i=1 ai QM Pq i=1 oi QM j=1(ω j)bi j j=1(ω j)ri j
, 1 ≤ k ≤ K
( 14 ) ai , bi j , oi , ri j ≥ 0 , bi j , ri j ∈ Z , st
M
X m=1
ωm = 1 , ω1 , ·· · , ωM > 0
( 20 ) where there are p polynomial terms in the numerator and q polynomial terms in the denominator , ai and oi are the coefficients of the ith terms respectively , and bi j and ri j are the exponents of corresponding variables in the ith terms respectively .
For ease of presentation , we revise the original objective as the following nonlinear fractional programming problem ( NFPP ) .
Definition 3 . [ Nonlinear Fractional Programming Problem ] Let i=1 oi f ( ω1 , · · · , ωM ) = P p QM j=1(ω j)ri j , the clustering goal is revised as follow . j=1(ω j)bi j and g(ω1 , · · · , ωM ) = Pq i=1 ai QM max ω1 ,··· ,ωM f ( ω1 , · ·· , ωM ) g(ω1,· · · , ωM )
, st
M
X m=1
ωm = 1 , ω1 , ·· · , ωM > 0
( 21 )
Our clustering objective is equivalent to maximize a quotient of two polynomial functions of multiple variables . It is very hard to perform function trend identification and estimation to determine the existence and uniqueness of solutions . Therefore , we want to transform this sophisticated NFPP into an easily solvable problem . Definition 4 . [ Nonlinear Parametric Programming Problem ] Let i=1 oi j=1(ω j)bi j and g(ω1 , · · · , ωM ) = Pq f ( ω1 , · · · , ωM ) = P p QM j=1(ω j)ri j , the NPPP is defined as follow . ̥(γ ) = max ω1 ,··· ,ωM f ( ω1 , · ·· , ωM )−γg(ω1,· · · , ωM ) , st i=1 ai QM
M
X m=1
ωm = 1 , ω1 , · · · , ωM > 0 ( 22 )
( 17 )
( 3 ) We compute the vertex clustering membership matrix X = [ X1 , X2 , · · · , XK ] ∈ RNVc ×K for the target vertices Vc in V MG . We below define the transition probability on V MG in terms of each of K edge clusters .
S(t ) k ( vi , v j ) =
P(t ) k ( vi , v j ) NVc l=1 P(t ) k ( vl , v j )
, P(t ) k ( vi , v j ) , 0 ,
0 , otherwise .
P
 where S(t ) k ( vi , v j ) denotes the transition probability with cluster label ck on one of parallel edges between vertex vi and vertex v j in V MG .
The transition matrix on V MG is given as follow .
S(t ) k
= P(t ) k ( D−1 k )(t ) , 1 ≤ k ≤ K
( 15 ) k ( vl , v j ) ( 1 ≤ j ≤ NVc ) . k )(t ) = diag(d1 , · · · , dNVc k )(t ) is a diagonal matrix ( D−1 l=1 P(t ) where ( D−1 and d j = PNVc Similar to edge centric clustering , we produce K vertex clustering kernels S(t ) k , each corresponding to cluster ck . The transition operation in the unified vertex centric path multigraph V MG is divided into two steps : ( 1 ) choose those parallel edges with the objective cluster label ; and ( 2 ) select an edge with the largest probability from the above edges to move .
) ,
For each vertex clustering membership vector Xk ( 1 ≤ k ≤ K ) to itera based on ck , we utilize an individual clustering kernel S(t ) tively infer the membership probabilities of vertices in Vc on ck . k
Initilization : Xk = X(t−1 ) Iteration : Xk = S(t ) k k Xk
( 16 )
When the iterative vertex clustering converges , we further nor malize each entry Xk(vi ) ( 1 ≤ i ≤ NVc ) in Xk ( 1 ≤ k ≤ K ) below .
X(t ) k ( vi ) =
Xk(vi ) PK l=1 Xl(vi ) where vi ∈ Vc denotes a target vertex in V MG and X(t ) represents the normalized vertex clustering membership vector based on ck . Thus , the vertex clustering membership matrix is updated below . k
X(t ) = hX(t )
1
X(t ) 2
K i · ·· X(t )
X(t ) will be used to enter the next vertex clustering round .
( 18 )
3.6 Clustering with Weight Learning
The objective function of VEPathCluster is defined to maximize fuzzy intra cluster similarity [ 22 , 23 ] for both vertex clustering in the unified vertex centric path multigraph V MG and edge clustering on each edge centric path multigraph EMGm .
Definition 2 . [ VEPathCluster Clustering Objective Function ] Let V MG be a unified vertex centric path multigraph , V MGm ( m ∈ {1 , · · · , M} ) be M vertex centric path multigraphs , EMGm ( m ∈ {1 , · · · , M} ) be M edge centric path multigraphs , ω1 , · · · , ωM be the weighting factors for V MG1 , · · · , V MGM and EMG1 , · · · , EMGM defined in Eqs.(12 ) and ( 13 ) respectively , given K vertex soft clusters for V MG with a membership matrix X and K path edge soft clusters for each EMGm with a membership matrix Ym , the goal of VEPathCluster is to maximize the following objective function .
O(X , Y1,· · · , YM , ω1 , ·· · , ωM ) =
+
NVc
X i=1
NVc
X j=1
K
X k=1
Xk(vi)Xk(v j)Pk(vi , v j )
M
X m=1
NEm
X i=1
NEm
X j=1
K
X k=1
Ymk(emi)Ymk(em j)Qmk(emi , em j ) max ω1,··· ,ωM
O(X , Y1 , · ·· , YM , ω1 , ·· · , ωM ) , st
M
X m=1
ωm = 1 , ω1,· · · , ωM > 0
( 19 ) According to Eqs.(4) (18 ) , the objective function O is a fractional function of multi variables ω1 , · · · , ωM with non negative real coefficients . On the other hand , the numerator and the denominator
P in Definition 4 , ie , γ = max ω1 ,··· ,ωM
Theorem 1 . The NFPP in Definition 3 is equivalent to the NPPf ( ω1 ,··· ,ωM ) g(ω1,··· ,ωM ) if and only if ̥(γ ) = f ( ω1 , · · · , ωM ) − γg(ω1 , · · · , ωM ) = 0 . max ω1,··· ,ωM Proof . If ( ω1 , · · · , ωM ) is a feasible solution of ̥(γ ) = 0 , then f ( ω1 , · · · , ωM)−γg(ω1 , · · · , ωM ) = 0 . Thus f ( ω1 , · · · , ωM)−γg(ω1 , · · · , ωM ) 6 f ( ω1 , · · · , ωM ) − γg(ω1 , · · · , ωM ) = 0 . We have γ = f ( ω1 , · · · , ωM)/g(ω1 , · · · , ωM ) > f ( ω1 , · · · , ωM)/g(ω1 , · · · , ωM ) . Thus γ is a maximum value of NFPP and ( ω1 , · · · , ωM ) is an optimal solution of NFPP . Conversely , if ( ω1 , · · · , ωM ) solves NFPP , then we have γ = f ( ω1 , · · · , ωM)/g(ω1 , · · · , ωM ) > f ( ω1 , · · · , ωM)/g(ω1 , · · · , ωM ) . Thus f ( ω1 , · · · , ωM)−γg(ω1 , · · · , ωM ) 6 f ( ω1 , · · · , ωM )−γg(ω1 , · · · , ωM ) = 0 . We have ̥(γ ) = 0 and the maximum is taken at ( ω1 , · · · , ωM ) . Now the original NFPP has been successfully transformed into the straightforward NPPP . This transformation can efficiently speed up the clustering convergence due to the following properties .
Theorem 2 . ̥(γ ) is convex . Proof : Suppose that ( ω1 , · · · , ωM ) is an optimum of ̥((1− λ)γ1 + λγ2 ) with γ1 , γ2 and 0 6 λ 6 1 . ̥((1−λ)γ1+λγ2 ) = f ( ω1 , · · · , ωM )− ( (1−λ)γ1+λγ2)g(ω1 , · · · , ωM ) = λ( f ( ω1 , · · · , ωM)−γ2g(ω1 , · · · , ωM))+ ( 1−λ)( f ( ω1 , · · · , ωM )−γ1g(ω1 , · · · , ωM ) ) 6 λ max f ( ω1 , · · · , ωM)− ω1 ,··· ,ωM γ2g(ω1 , · · · , ωM)+(1−λ ) max f ( ω1 , · · · , ωM)−γ1g(ω1 , · · · , ωM ) = ω1,··· ,ωM λ̥(γ2 ) + ( 1 − λ)̥(γ1 ) . Thus , ̥(γ ) is convex .
Theorem 3 . ̥(γ ) is monotonically decreasing . Proof : Suppose that γ1 > γ2 and ( ω1 , · · · , ωM ) is an optimal solution of ̥(γ1 ) . Thus , ̥(γ1 ) = f ( ω1 , · · · , ωM ) − γ1g(ω1 , · · · , ωM ) < f ( ω1 , · · · , ωM)−γ2g(ω1 , · · · , ωM ) 6 max f ( ω1 , · · · , ωM)−γ2g(ω1 , ω1 ,··· ,ωM · · · , ωM ) = ̥(γ2 ) .
1568 Algorithm 1 Vertex/Edge centric meta PATH graph Clustering
Input : M vertex centric path graphs VGm , M edge centric path graphs EGm , a clustering number K , and a parameter γ(1)=0 . Output : vertex clustering membership matrix X , M edge clustering membership matrices Y1 , ·· · , YM . 1 : Initialize weights ω(1 )
M in terms of the scales of edge values in else if t = 1 each VGm ;
1 ,· · · , ω(1 ) 2 : for t=1 to ̥(γ(t ) ) converges to 0 3 : 4 : 5 : 6 : 7 : 8 : 9 : 10 : 11 : 12 : 13 : 14 : 15 : 16 : 17 : 18 : 19 : 20 : Return X(t ) and Y(t )
Initialize Y(t−1 ) if t = 1 m
1
1 ,· · · , Y(t ) M .
Combine Pm of each VGm into P(t ) of VG with Eq ( 1 ) ; Invoke FCM to cluster vertices Vo in VG to generate X(t ) of VG ;
Convert Pm of each VGm into P(t ) Combine each V MGm into V MG by computing all P(t ) Calculate S(t ) Update X(t ) of VG with Eqs.(16) (18 ) ; k of V MG for each cluster ck in Eqs.(14) (15 ) ; mk of each V MGm with Eq ( 4 ) ; k in Eq ( 13 ) ; of each EGm with Eq ( 6 ) ; mk of each EMGm with Eq ( 5 ) ; mk of each EMGm for each cluster ck in Eqs.(7) (8 ) ; m of each EGm with Eqs.(9) (11 ) ;
Convert Qm of each EGm into Q(t ) Calculate T(t ) Update Y(t ) Compute O(X , Y1 , ·· · , YM , ω1 , ·· · , ωM ) in Eq ( 19 ) ; Solve ̥(γ(t ) ) in Eq ( 22 ) ; Update ω(t+1 ) , ·· · , ω(t+1 ) M ; Refine γ(t+1)= f ( ω(t+1 ) , ·· · , ω(t+1 )
, · ·· , ω(t+1 ) M ) ;
M )/g(ω(t+1 )
1
1
̥(γ ) = +∞ .
Theorem 4 . ̥(γ ) = 0 has a unique solution . Proof : Based on the above mentioned theorems , we know ̥(γ ) is ̥(γ ) = −∞ continuous as well as decreasing . In addition , limγ→+∞ and limγ→−∞ The procedure of solving this NPPP includes two parts : ( 1 ) find such a reasonable parameter γ ( ̥(γ ) = 0 ) , making NPPP equivalent to NFPP ; ( 2 ) given the parameter γ , solve a polynomial programming problem about the original variables ω1 , · · · , ωM . Our weight adjustment mechanism is an iterative procedure to find the solution of ̥(γ ) = 0 and the corresponding weights after each clustering iteration . We first generate an initial matrix P(1 ) with initial weights in terms of the scales of edge values in each vertex centric path graph VGm to produce an initial vertex clustering result through FCM [ 8 ] on the unified vertex centric path graph VG . Based on the initial vertex clustering result , we construct an edge centric path multigraph EMGm for each edge centric path graph EGm . We then generate an initial edge clustering result on each EMGm . According to the initial result of both vertex clustering and edge clusterings , we then calculate an initial ̥(γ ) . Since ̥(γ ) is a monotonic f ( ω1 , · · · , ωM ) is obviously decreasing function and ̥(0 ) = max ω1 ,··· ,ωM non negative , we start with an initial γ = 0 and solve the subproblem ̥(0 ) by using existing fast polynomial programming model to update the weights ω1 , · · · , ωM . The parameter γ is gradually increased by γ = f ( ω1 , · · · , ωM)/g(ω1 , · · · , ωM ) to help the algorithm enter the next round . The algorithm repeats the above mentioned iterative procedure until ̥(γ ) converges to 0 .
By assembling all the pieces in Section 3 together , we provide the pseudo code of our VEPathCluster algorithm in Algorithm 1 .
4 . EXPERIMENTAL EVALUATION
We have performed extensive experiments to evaluate the perfor mance of VEPathCluster on three real graph datasets .
4.1 Experimental Datasets
The first real dataset is extracted from the DBLP Bibliography data 1 , which contains 112,483 authors ( A ) , 728,497 papers ( P ) , 1http://dblpuni trierde/xml/ n n u D
2.5
2
1.5
1
0.5
0 e t t e u o h l i
S
0.8
0.6
0.4
0.2
0
VEPathCluster VEPathCluster−VE VEPathCluster−VW PathSelClus GK FCM
800
1000
400
600
K
VEPathCluster VEPathCluster−VE VEPathCluster−VW PathSelClus GK FCM
800
1000
400
600
K
0.8
0.6
I
M N
0.4
0.2
0
VEPathCluster VEPathCluster−VE VEPathCluster−VW
400
600
K
PathSelClus GK FCM
800
1000
( a ) Dunn
( b ) Silhouette
( c ) NMI
Figure 7 : Vertex Clustering Quality on DBLP
2,633 venues ( V ) , and 45,968 terms ( T ) . We choose three meta paths : A P A , A P V P A and A P T P A , to cluster authors and three kinds of path edges into soft clusters simultaneously .
IMDb 2 is a searchable database of movies , TV and entertainment programs . We extract 48,975 actors ( A ) , 31,188 movies ( M ) , 4,774 directors ( D ) , and 28 movie genres ( G ) from the original IMDb dataset . Three candidate meta paths : A M A , A M D MA and A M G M A , are used to assign each actor and three types of path edges to soft clusters .
The third real world dataset is extracted from the Yelp ’s academic dataset 3 , which includes 15,715 businesses ( B ) , 470,212 reviews ( R ) , 138,969 users ( U ) , and 30,475 review terms ( T ) . We select two meta paths : B R U R B and B R T R B , to generate the soft clusterings of businesses and two kinds of path edges .
4.2 Comparison Methods and Measures
We compare VEPathCluster with two representative soft clustering algorithms , Fuzzy C Means ( FCM ) [ 8 ] , Gustafson Kessel ( GK ) [ 24 ] , and one recently developed method PathSelClus [ 4 ] . For the first two clustering methods , we add the adjacency matrices of all vertex centric path graphs together to get one single matrix . The first two methods perform vertex centric soft clustering on a single graph and PathSelClus performs vertex centric soft clustering on multiple graphs based on the assumption of vertex homophily .
We also evaluate three partial versions of VEPathCluster to show the strengths of edge clustering and weight learning respectively : ( 1)VEPathCluster VE with only vertex clustering and edge clustering ; ( 2 ) VEPathCluster VW with only vertex clustering and weight update ; and ( 3 ) VEPathCluster EW with only edge clustering and weight update .
Evaluation Metrics We use three measures to evaluate the quality of vertex clustering by different methods . The fuzzy Dunn index [ 25,26 ] is defined as the ratio between the minimal fuzzy intracluster similarity and the maximal fuzzy inter cluster similarity .
Dunn(X ) =
( Σ min
1≤k≤K 1≤k<l≤K max
1
Xk(vi))(Σ
NVc j=i+1
NVc i=1
1
( Σ
NVc i=1
Xk(vi))(Σ
NVc j=1
NVc
Xk ( v j ) ) P Xl(v j ) ) P i=1 P i=1 P
NVc
NVc j=i+1 Xk(vi))Xk(v j))P(vi , v j ) j=1 Xk(vi))Xl(v j))P(vi , v j )
NVc
( 23 ) where X is the vertex soft clustering membership matrix and Dunn(X ) is bounded in the range [ 0 , +∞ ) . A larger value of Dunn(X ) indicates a better clustering . The following two metrics are often used to evaluate the hard clustering result , we thus map the soft clustering results by various methods into hard clustering results with the maximum probability of each vertex as its hard cluster labels . b(vi ) =
P(vi , v j ) , a(vi ) = max
1
|VCk| − 1 X S ilhouette({VCk}K v j∈VCk , j,i k=1 ) =
1≤l≤K,l,k 1
|VCl| X b(vi ) − a(vi ) v j∈VCl max{a(vi ) , b(vi)}
P(vi , v j )
( 24 )
1 K
K
X k=1
1 |VCk| X vi∈VCk
2http://wwwimdbcom/interfaces 3http://wwwyelpcom/academic_dataset
1569 n n u D
1
0.8
0.6
0.4
0.2
0
0.6
0.5 n n u D
0.4
0.3
0.2
0.1
0 e t t e u o h l i
S
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
I
M N
0.6
0.5
0.4
0.3
0.2
0.1
0
VEPathCluster VEPathCluster−VE VEPathCluster−VW PathSelClus GK FCM
240
280
160
200
K
VEPathCluster VEPathCluster−VE VEPathCluster−VW PathSelClus GK FCM
240
280
160
200
K
VEPathCluster VEPathCluster−VE VEPathCluster−VW
160
200
K
PathSelClus GK FCM
240
280
( a ) Dunn
( b ) Silhouette
( c ) NMI
Figure 8 : Vertex Clustering Quality on IMDb e t t e u o h l i
S
0.4
0.3
0.2
0.1
0
−0.1
−0.2
−0.3
I
M N
0.6
0.5
0.4
0.3
0.2
0.1
0
VEPathCluster VEPathCluster−VE VEPathCluster−VW PathSelClus GK FCM
80
100
40
60
K
VEPathCluster VEPathCluster−VE VEPathCluster−VW
40
60
K
PathSelClus GK FCM
80
100
VEPathCluster VEPathCluster−VE VEPathCluster−VW
40
60
K
PathSelClus GK FCM
80
100
1.5 n n u D
1
0.5
0 n n u D
0.6
0.5
0.4
0.3
0.2
0.1
0 e t t e u o h l i
S
0.8
0.6
0.4
0.2
0
I
M N
0.7 0.6 0.5 0.4 0.3 0.2 0.1
0
VEPathCluster VEPathCluster−VE VEPathCluster−EW
800
1000
400
600
K
VEPathCluster VEPathCluster−VE VEPathCluster−EW
800
1000
400
600
K
VEPathCluster VEPathCluster−VE VEPathCluster−EW
800
1000
400
600
K
( a ) Dunn
( b ) Silhouette
( c ) NMI
Figure 10 : Edge Clustering Quality on DBLP e t t e u o h l i
S
0.5
0.4
0.3
0.2
0.1
0
I
M N
0.6
0.5
0.4
0.3
0.2
0.1
0
VEPathCluster VEPathCluster−VE VEPathCluster−EW
80
100
40
60
K
VEPathCluster VEPathCluster−VE VEPathCluster−EW
80
100
40
60
K
VEPathCluster VEPathCluster−VE VEPathCluster−EW
80
100
40
60
K
( a ) Dunn
( b ) Silhouette
( c ) NMI
Figure 9 : Vertex Clustering Quality on Yelp where {VCk}K k=1 represents the mapped hard clustering of the target vertices Vc , ie , Vc = SK k=1 VCk and VCk T VCl = φ for ∀1 ≤ k , l ≤ K , k , l . P(vi , v j ) is the edge value between two vertices vi and v j in the unified vertex centric path graph VG . The silhouette coefficient [ 27 ] with the bound of [ 1 , 1 ] contrasts the average intra cluster similarity with the average inter cluster similarity . The larger the value , the better the quality .
Following the same strategy used in [ 4 ] , we use N MI(X , Y ) = I(X;Y ) to compare the generated vertex clustering with the ground √H(X)H(Y ) truth , where X and Y represent two cluster label vectors for the ground truth clustering and the calculated clustering by a clustering method respectively . N MI(X , Y ) is in the interval [ 0 , 1 ] and a larger N MI value indicates a better clustering .
Similarly , we use the same three measures to evaluate the quality of edge clustering by VEPathCluster . We report the average metric value for each measure based on M edge clustering results .
4.3 Vertex Clustering Quality
Figures 7 9 exhibit the vertex clustering quality on DBLP , IMDb and Yelp by varying the number of clusters . We divide six soft clustering methods into three categories : ( 1 ) FCM and GK perform the basic vertex clustering only based on the matrix of the unified vertex centric path graph ; ( 2 ) PathSelClus , VEPathClusterVW and VEPathCluster VE utilize partial optimization techniques to further improve the quality of vertex clustering ; and ( 3 ) VEPathCluster makes use of both techniques of edge clustering and weight learning to achieve the promotion as much as possible .
First , PathSelClus , VEPathCluster VW and VEPathCluster VE significantly outperform FCM and GK on all three evaluation measures . We know that the edges in different vertex centric path graphs usually have values with different scales . As vertex centric clustering methods , both PathSelClus and VEPathCluster VW efficiency integrates the matrices of multiple vertex centric path graphs through the iterative weight learning mechanism to learn the optimal weight assignment for these matrices . Thus , the measure scores obtained by them are often comparable to each other . On the other hand , VEPathCluster VE integrates vertex clustering and edge clustering to mutually enhance each other . These results demonstrate that the importance of exploiting both edge clustering and weight learning for meta path graph clustering .
Second , it is observed that VEPathCluster VE outperforms Path
SelClus and VEPathCluster VW on three graph datasets , even though the dynamic weight refinement is not used in VEPathCluster VE while both PathSelClus and VEPathCluster VW employed some
( a ) Dunn
( b ) Silhouette
( c ) NMI
Figure 11 : Edge Clustering Quality on Yelp iterative weight learning method to find the optimal weight assignment and improve the clustering quality . This is because both PathSelClus and VEPathCluster VW are based solely on vertex homophily , without incorporating and integrating edge homophily into the clustering analysis . These results illustrate that employing edge clustering is more important than exploit weight learning in solve the meta path graph clustering problem .
Finally , among all six clustering methods , VEPathCluster achieves the best clustering performance for all three evaluation measures in most cases . Compared to other algorithms , VEPathCluster averagely achieves 18.7 % Dunn increase , 14.1 % Silhouette boost and 22.4 % NMI improvement on DBLP , 10.6 % Dunn growth , 10.4 % Silhouette increase and 8.7 % NMI boost on IMDb , and 17.7 % Dunn increase , 23.9 % Silhouette boost and 11.6 % NMI improvement on Yelp , respectively . Concretely , there are three critical reasons for high accuracy of VEPathCluster : ( 1 ) the clusteringbased multigraph model integrates both vertex centric clustering and edge centric clustering to accurately capture the cluster specific relationships between vertices and between edges ; ( 2 ) the edgecentric random walk model provides a natural way to capture the dependencies among path edges within each vertex centric path graph ; and ( 3 ) the iterative learning algorithm help the clustering model achieve a good balance among different types of vertexcentric path graphs and edge centric path graphs .
4.4 Edge Clustering Quality
Given that FCM , GK , PathSelClus and VEPathCluster VW are vertex centric soft clustering methods , we skip the experimental evaluation of edge clustering for these four approaches . Figures 1011 present the edge clustering quality by three versions of VEPathCluster on two datasets with different K respectively . Similar trends are observed for the edge clustering quality comparison : VEPathCluster achieves the largest Dunn values ( >0.62 ) , the highest Silhouette around 039 089 , and the largest NMI ( >0.58 ) , which are obviously better than other two methods . As K increases , the measure scores achieved by VEPathCluster remains relatively stable , while the measure scores of other two methods oscillate in a fairly large range . In addition , in terms of three evaluation measures , VEPathCluster VE outperforms VEPathCluster EW in some cases but VEPathCluster EW performs better than VEPathCluster VE in some cases . These results demonstrate that each of vertex clustering , edge clustering and weight learning plays an important role in meta path clustering . Thus , we should integrate three optimization techniques to further improve the clustering quality .
1570 DBLP IMDb Yelp
3 10
2 10
) c e s ( e m i t n u R
DBLP IMDb Yelp
2500
2000
1500
1000
500
) c e s ( e m i t n u R
1 10
1 10
2 10 K
3 10
0 0
50K
100K 150K 200K
#Vertices
( a ) Varying K
( b ) Varying #Vertices
Figure 12 : Clustering Efficiency
2.5
2
1.5
1
0.5
Dunn Silhouette NMI
1.5
1
0.5
0 1
2
3
5
4 6 Iteration
7
8
9
0 1
2
3
5
4 6 Iteration
0.8
0.6
0.4
0.2
A−P−A A−P−V−P−A A−P−T−P−A
0 1
2
3
5
4 6 Iteration
7
8
9
Dunn Silhouette NMI
7
8
9
( a ) Vertex Clustering
( b ) Edge Clustering
( c ) Weight Assignment
Figure 13 : Clustering Convergence
4.5 Clustering Efficiency
Figure 12 ( a ) presents the clustering time achieved by VEPathCluster on DBLP , Last.fm and IMDb with the same K setups in the experiments of clustering quality in Figures 7 11 respectively . Figure 12 ( b ) exhibits the scalability test of VEPathCluster by varying the number of target vertices on three datasets respectively . For DBLP and IMDb , we test four different setups of #Vertices , ie , #Vertices = 15,715 , 48,975 , 112,483 , 200,000 respectively . However , we only test #Vertices = 15,715 , 42,153 for Yelp since the original Yelp dataset contains up to 42,153 businesses . We observe that VEPathCluster scales well with the size of graph for different graph datsets and shows good performance with varying K . A careful examination reveals that the bottleneck component of the overall time complexity for VEPathCluster is the execution time of iterative vertex clustering and edge clusterings , which mainly consist of a series of matrix vector multiplications . Let K be the number of clusters , NVc be the number of target vertices in the unified vertex centric path multigraph , NEk ( 1 ≤ k ≤ K ) be the number of parallel edges on the kth cluster in the unified vertex centric path multigraph , M be the number of edge centric path multigraphs , NEm ( 1 ≤ m ≤ M ) be the number of vertices in the mth edge centric path multigraph , NFmk ( 1 ≤ k ≤ K ) be the number of parallel edges on the kth cluster in the mth edge centric path multigraph , ti is the number of inner iterations , and to be the number of outer iterations in the clustering process . At the worst case , ie , the original graph dataset is relatively dense , the complexity of performing vertex clustering on the unified vertex centric path multigraph is equal to O(totiKN2 ) and the cost of performing edge clustering on each Vc of M edge centric path multigraphs is equal to O(to PM ) . However , when the original graph dataset is very spare , the complexity of matrix vector multiplication is approximately bounded by the size of edges . In this situation , the complexity of performk=1 NEk ) and the cost of performing edge clustering on all M edge centric path multigraphs ing vertex clustering is reduced to O(toti PK is decreased to O(to PM 4.6 Clustering Convergence m=1 ti PK m=1 tiKN2 Em k=1 NFmk ) .
Figure 13 ( a ) and ( b ) exhibit the convergence trend of vertex clustering and edge clustering in terms of three evaluation measures on DBLP . Both the Dunn values and the NMI scores in two figures keep increasing or relatively stable and have convex curves when we iteratively perform the tasks of vertex clustering , edge clustering and weight update during the clustering process . On the other hand , the Silhouette values first fluctuate slightly within a range of
IR
Jiawei Han
H . V . Jagadish
Christos Faloutsos
Author/Cluster Ming Syan Chen W . Bruce Croft
DB DM AI 0.258 0.588 0.021 0.134 0.058 0.006 0.026 0.909 0.346 0.539 0.012 0.102 0.373 0.459 0.057 0.111 0.904 0.048 0.014 0.034 Laks V . S . Lakshmanan 0.809 0.128 0.011 0.053 Hector Garcia Molina 0.810 0.028 0.021 0.141 0.009 0.123 0.830 0.038 0.012 0.265 0.512 0.210 0.358 0.507 0.027 0.108 0.023 0.744 0.140 0.093
Eric P . Xing Qiang Yang Philip S . Yu
Chengqi Zhang
Table 1 : Cluster Membership Probabilities of Authors Based on Three Meta Paths from DBLP [ 0.57 , 0.95 ] and then converge very quickly . The entire clustering process converges in nine iterations for DBLP . Figure 13 ( c ) shows the tendency of weight update for three meta paths on DBLP . We keep the constraint of weights for three meta paths unchanged , ie , PM m=1 ωm = 1 , during the clustering process . We observe that all three weights converge as the clustering process converges . An interesting phenomenon is that the weight for the A P A meta path first increases and then decreases with the iterations , the weight for the A P V P A meta path keeps decreasing and the weight curve for the A P T P A meta path has a converse trend . A reasonable explanation is that people who have many publications on the same conferences may have different research topics but people who have many papers with the same terms usually have the same research interests . On the other hand , for a pair of coauthors , their primary research areas are not always consistent in terms of the number of their coauthored papers , as illuminated in the example in Figure 2 . Another interesting finding is that the weight for the A P A meta path is relatively large and other two weights are fairly small . This is because that the edges in different path graphs usually have values with different scales , as shown in Figure 3 . In addition , the length of either of other two meta paths is larger than that of the AP A meta path , and there are many venues and terms in the DBLP dataset . To maintain a good balance among different meta paths , the algorithm needs to set larger weights for the path graphs with small scale edges to maintain their contributions to clustering . 4.7 Case Study
We examine some details of the experiment results based on DBLP . Table 1 exhibits the set of authors and their cluster membership probabilities after nine iterations based on three meta paths : A P A , A P V P A and A P T P A . We only present most prolific DBLP experts in the area of database ( DB ) , data mining ( DM ) , artificial intelligence ( AI ) and information retrieval ( IR ) . We observe that the predicted cluster memberships of authors are consistent with their actual research areas . For those researchers known to work in multiple research areas , the cluster membership distributions also correspond to their current research activities . For example , both Jiawei Han and Philip S . Yu are experts on data mining and database , though their DM probabilities are slightly higher since each of them and their circle of co authors have more DM papers . Table 2 shows the set of path edges between the above authors in the A P A vertex centric path graph and their cluster membership probabilities after nine clustering iterations . We have observed that most of author pairs associated to path edges usually have different primary research areas , eg , the primary research areas of W . Bruce Croft and Hector Garcia Molina are IR and DB respectively . In this situation , the cluster favorite of the path edges between the pairwise authors are often dominated by the primary research area of one associated author . For example , the path edge ( W . Bruce Croft , Hector Garcia Molina ) has a main cluster favorite of DB . An interesting phenomenon is that although both Ming Syan Chen and Philip S . Yu are experts on data mining , ie , they both have more research publications in the area of data min
1571 Path Edge/Cluster
IR
( Ming Syan Chen , Philip S . Yu )
( Christos Faloutsos , H . V . Jagadish ) ( Christos Faloutsos , Eric P . Xing )
DB DM AI 0.630 0.284 0.023 0.063 ( W . Bruce Croft , Hector Garcia Molina ) 0.702 0.035 0.065 0.199 0.547 0.365 0.017 0.072 0.238 0.713 0.015 0.034 ( Jiawei Han , Laks V . S . Lakshmanan ) 0.624 0.356 0.006 0.013 0.518 0.424 0.013 0.045 0.083 0.785 0.131 0.001 0.023 0.684 0.228 0.065
( Jiawei Han , Philip S . Yu ) ( Qiang Yang , Philip S . Yu )
( Qiang Yang , Chengqi Zhang )
Table 2 : Cluster Membership Probabilities of A P A Path Edges from DBLP ing than in any other academic area such as database . However , the path edge ( Ming Syan Chen , Philip S . Yu ) have a large probability on cluster DB . A careful examination reveals that most of coauthored publications between two experts are database specific .
5 . RELATED WORK
Meta path based social network analysis is gaining attention in recent years [ 1–6 ] . PathSim [ 1 ] presented a meta path based similarity measure for heterogeneous graphs . [ 2 ] proposed a meta pathbased ranking model to find entities with high similarity to a given query entity . HCC [ 3 ] is a meta path based heterogeneous collective classification method . PathSelClus [ 4 ] utilizes user guidance as seeds in some of the clusters to automatically learn the best weights for each meta path in the clustering . MLI [ 5 ] is a multi network link prediction framework by extracting useful features from multiple meta paths .
Graph clustering has been extensively studied in recent years [ 9– 21 ] . Shiga et al . [ 9 ] presented a clustering method which integrates numerical vectors with modularity into a spectral relaxation problem . SCAN [ 10 ] is a structural clustering algorithm to detect clusters , hubs and outliers in networks . MLR MCL [ 11 ] is a multilevel graph clustering algorithm using flows to deliver significant improvements in both quality and speed . TopGC [ 14 ] is a fast algorithm to probabilistically search large , edge weighted , directed graphs for their best clusters in linear time . BAGC [ 16 ] constructs a Bayesian probabilistic model to capture both structural and attribute aspects of graph . GenClus [ 17 ] proposed a modelbased method for clustering heterogeneous networks with different link types and different attribute types . CGC [ 18 ] is a multidomain graph clustering model to utilize cross domain relationship as co regularizing penalty to guide the search of consensus clustering structure . FocusCO [ 20 ] solves the problem of finding focused clusters and outliers in large attributed graphs .
To the best of our knowledge , VEPathCluster is the first one to tightly integrate vertex centric clustering and edge centric clustering by mutually enhancing each other with combining different types of meta paths over heterogeneous information network .
6 . CONCLUSIONS
We have presented a meta path graph clustering framework for mining heterogeneous information networks . First , we model a heterogeneous information network containing multiple types of meta paths as multiple vertex centric path graphs and multiple edgecentric path graphs . Second , we cluster both vertex centric path graph and edge centric path graphs to generate vertex clustering and edge clusterings . Third , a reinforcement algorithm is provided to tightly integrate vertex clustering and edge clustering by mutually enhancing each other . Finally , an iterative learning strategy is proposed to dynamically refine both clustering results by continuously learning the degree of contributions of different path graphs .
Acknowledgement . The first two authors are partially supported by the NSF CISE under Grants IIS 0905493 , CNS 1115375 , IIP1230740 and a grant from Intel ISTC on Cloud Computing . The third author performed this work under the auspices of the US
Department of Energy by Lawrence Livermore National Laboratory under Contract DE AC52 07NA27344 .
7 . REFERENCES [ 1 ] Y . Sun , J . Han , X . Yan , P . Yu , and T . Wu . PathSim : Meta path based top k similarity search in heterogeneous information networks . PVLDB , 4(11):992–1003 , 2011 .
[ 2 ] X . Yu , Y . Sun , B . Norick , T . Mao , and J . Han . User guided entity similarity search using meta path selection in heterogeneous information networks . In CIKM , pages 2025–2029 , 2012 .
[ 3 ] X . Kong , P . S . Yu , Y . Ding , and D . J . Wild . Meta path based collective classification in heterogeneous information networks . In CIKM , pages 1567–1571 , 2012 .
[ 4 ] Y . Sun , B . Norick , J . Han , X . Yan , P . Yu , X . Yu . Integrating meta path selection with user guided object clustering in heterogeneous information networks . In KDD , pages 1348–1356 , 2012 .
[ 5 ] J . Zhang , P . Yu , and Z . Zhou . Meta path based multi network collective link prediction . In KDD , pages 1286–1295 , 2014 .
[ 6 ] X . Ren , J . Liu , X . Yu , U . Khandelwal , Q . Gu , L . Wang , and J . Han .
ClusCite : effective citation recommendation by information network based clustering . In KDD , pages 821–830 , 2014 . [ 7 ] J . Han , M . Kamber , and J . Pei . Data mining : concepts and techniques , 3rd ed . Morgan Kaufmann , 2011 .
[ 8 ] J . C . Bezdek . Pattern recognition with fuzzy objective function algorithms . Plenum Press , 1981 .
[ 9 ] M . Shiga , I . Takigawa , H . Mamitsuka . A spectral clustering approach to optimally combining numericalvectors with a modular network . In KDD , pages 647–656 , 2007 .
[ 10 ] X . Xu , N . Yuruk , Z . Feng , and T . A . J . Schweiger . Scan : a structural clustering algorithm for networks . In KDD , pages 824–833 , 2007 .
[ 11 ] V . Satuluri and S . Parthasarathy . Scalable graph clustering using stochastic flows : Applications to community discovery . KDD , 2009 .
[ 12 ] Y . Sun and Y . Yu and J . Han . Ranking based clustering of heterogeneous information networks with star network schema . In KDD , pages 797–806 , 2009 .
[ 13 ] Y . Zhou , H . Cheng , and J . X . Yu . Graph clustering based on structural/attribute similarities . PVLDB , 2(1):718–729 , 2009 .
[ 14 ] K . Macropol and A . Singh . Scalable discovery of best clusters on large graphs . PVLDB , 3(1):693–702 , 2010 .
[ 15 ] Y . Zhou , H . Cheng , and J . X . Yu . Clustering large attributed graphs : An efficient incremental approach . In ICDM , pages 689–698 , 2010 .
[ 16 ] Z . Xu , Y . Ke , Y . Wang , H . Cheng , and J . Cheng . A model based approach to attributed graph clustering . In SIGMOD , 505–516 , 2012 .
[ 17 ] Y . Sun , C . C . Aggarwal , and J . Han . Relation strength aware clustering of heterogeneous information networks with incomplete attributes . PVLDB , 5(5):394–405 , 2012 .
[ 18 ] W . Cheng , X . Zhang , Z . Guo , Y . Wu , P . Sullivan , and W . Wang .
Flexible and robust co regularized multi domain graph clustering . In KDD , pages 320–328 , 2013 .
[ 19 ] Y . Zhou and L . Liu . Social influence based clustering of heterogeneous information networks . In KDD , pages 338–346 , 2013 . [ 20 ] B . Perozzi , L . Akoglu , P . Sanchez , and E . Muller . Focused clustering and outlier detection in large attributed graphs . In KDD , 2014 .
[ 21 ] Y . Zhou and L . Liu . Activity edge centric multi label classification for mining heterogeneous information networks . In KDD , 2014 .
[ 22 ] M . Roubens . Pattern classification problems and fuzzy sets . Fuzzy
Sets and Systems , 1(4):239–253 , 1978 .
[ 23 ] M S Yang . A survey of fuzzy clustering . Mathematical and
Computer Modelling , 18(11):1–16 , 1993 .
[ 24 ] D . E . Gustafson and W . C . Kessel . Fuzzy clustering with a fuzzy covariance matrix . In CDC , pages 761–766 , 1979 .
[ 25 ] J . C . Bezdek and N . R . Pal . Some new indexes of cluster validity .
TSMC , 28(3):301–315 , 1998 .
[ 26 ] H . Hassar and A . Bensaid . Validation of fuzzy and crisp c partitions .
In NAFIPS , pages 342–346 , 1999 .
[ 27 ] Y . Liu , Z . Li , H . Xiong , X . Gao , and J . Wu . Understanding of Internal
Clustering Validation Measures . In ICDM , pages 911–916 , 2010 . [ 28 ] Y . Zhou , L . Liu , C S Perng , A . Sailer , I . Silva Lepe , and Z . Su .
Ranking services by service network structure and service attributes . In ICWS , 2013 .
1572
