CoLe : A Cooperative Data Mining Approach and Its Application to Early Diabetes Detection
Jie Gao and J¤org Denzinger Dept of Computer Science
University of Calgary , AB , Canada fgaoj,denzingeg@cpscucalgaryca
Abstract
We present CoLe , a cooperative data mining approach for discovering hybrid knowledge . It employs multiple different data mining algorithms , and combines results from them to enhance the mined knowledge . For our medical application area , we analyse several focusing strategies that allowed us to gain medically signi.cant results .
1 . Introduction
Data mining is facing a challenging situation where large , heterogeneous and complex data sets are to be mined . We have developed CoLe ( Cooperative Learning ) to handle data of this kind . It uses a multi agent framework to run multiple data mining algorithms simultaneously and cooperatively . Results from these algorithms are combined into hybrid knowledge . Partial results are exchanged during the process of mining to maximize the synergetic effects in the cooperation . Other existing distributed/cooperative mining approaches , like [ 4 , 6 ] and others , emphasize handling already distributed data sources fiexibly and ef.ciently , while CoLe concentrates more on getting hybrid knowledge that cannot be generated by a single data mining algorithm .
2 . Our Cooperative Mining Approach
The CoLe model employs a multi agent system framework ( see Figure 1 ) . It works on a data set D using a mining agent ( miner ) set M and a combination agent AgCBN . An individual miner mi contains a data mining algorithm . Each mi works on a dedicated sub data set Di split from D to .t mi ’s algorithm . Miners are synchronized to work in iterations . In each iteration , mi creates a knowledge set Ki and sends it to AgCBN for combination . AgCBN puts good combined hybrid results in a .nal knowledge set K , and sends feedback ( summary of discoveries in this iteration ) to each mi to help their later work . AgCBN also controls how Di ’s are created for the next iteration . [ 3 ] described the CoLe
Aechidna Health Informatics
Winnipeg , MB , Canada
Robert C . James rob@aetiologic.ca
D1 m1
F e e d b a c k
K1
D2 m2
F e e d b a c k fi fi fi fi
K2 fi fi
AgCBN
D
M
Kn
Dn mn
F e e d b a c k
Combined knowledge
K
Figure 1 . CoLe model
F e e d b a c k a b o u t d a t a s e t s e l e c t i o n model and its cooperation schemes in detail .
The most important aspect of CoLe is the cooperation of miners , coordinated by AgCBN : it instructs how Di ’s are generated from D ; it receives results Ki from the miners ; the .nal result K is produced by AgCBN . AgCBN also synchronizes the iterative mining process . AgCBN collects useful information from each miner ’s results in one iteration and sends feedback to all miners to help them improve their mining in the next iteration ( cid:151 ) so , miners infiuence each others’ work indirectly via AgCBN .
3 . A Mining Problem and Our Mining Agents
We applied CoLe to a problem occurring at the Calgary Health Region : Patients have their health harmed before laboratory tests can detect diabetes . Data mining may help to diagnose diabetes earlier . The diabetes data set contains patients’ ( both diabetics , called cases , and non diabetics , called controls ) basic information and their time stamped medical record ( diagnostic codes ) . The records are windowed by a 5 year monitoring period . Medical researchers are expecting rules showing both static conditions infiuencing diabetes and the development of the disease .
We instantiate CoLe for this medical mining problem with two miners and one AgCBN . One miner ( mS ) uses a sequence mining algorithm to observe the development of diagnoses . The other ( mC ) uses a classi.cation algorithm to get rules with conjunctions of diagnoses . Their discovered rule sets are RS and RC respectively . Correspondingly , we split D into two sub sets . They are DS , which contains temporal data suitable for mS , and DC , a fiattened D with timestamps removed , for mC . The AgCBN takes RS and RC , validates them against D , and uses combination strategies to combine them into hybrid rules ( as rule set R ) that contain both sequence and conjunctive conditions .
31 Sequence Mining by mS
Our mS uses a genetic algorithm for sequence mining . A sequence contains ordered events ( diagnosis sets ) , which do not need to be consecutive in a matched record . The goal is to discover sequences to discriminate cases from controls . We do not use the well known Apriori based algorithms from [ 1 ] because our data amount is huge and the sequences can be long . With a GA , we also gain easy control of iterative mining and integration of feedbacks .
In the GA implementation , we use single sequences as individuals . The .tness is calculated by :
.tness = 10 £(cid:181 ) tp tp +fp¶ x
£ ln(tp ) ln(case num )
( 1 )
Here tp and fp are the counts of true ( case ) and false ( control ) positives respectively , case num is the total number of cases in the data set , and x is a real number parameter to control the weight of the two factors . This considers both the accuracy and signi.cance of a sequence . It is also used globally as an evaluation of rules’ quality .
In our GA , we use not only standard mutation and crossover but also two knowledge based genetic operators : knowledge based mutation and IntelliCut . In knowledgebased mutation , new events are chosen from sequence segments that frequently occur in cases . IntelliCut cuts off the ( cid:147)bad tail(cid:148 ) of a sequence : for a sequence , each possible tailcut is checked to .nd the ( cid:147)right(cid:148 ) cut point to maximize its tness This can remove low quality parts from a potentially good sequence .
32 Conjunctive Rule Mining by mC
In mC we use a classi.cation algorithm to discover conjunctive rules . There are quite a few ef.cient algorithms for this . We use an existing implementation , namely PART ( see [ 2] ) . The PART algorithm is very suitable for mC because it output results in our targeted format directly . And PART does not have global optimization . So we can interrupt it to suit out in our iterative CoLe mining process .
33 Combination Strategies in AgCBN
AgCBN uses both the data set and the already discovered rules by the two miners in its tasks . The output is a hybrid rule set R . ( cid:147)Byproducts(cid:148 ) are the feedbacks to the miners and instructions for generating the next DS and DC . The combination is done in 3 stages , namely direct combination , cross combination and rule pruning :
In direct combination we try to put a rule from RS and one from RC directly together . The new rule ’s condition is the conjunction of the two old ones . If the new one is a good rule according to Equation ( 1 ) , we will put it into R . The cross combination is to check if we can use segments of sequence ( classi.cation ) rules to combine with classi.cation ( sequence ) rules and get good hybrid rules . For each event e in a sequence rule , we convert it to a predicate e = true , and add it to each existing rule ’s condition to see if we can gain good new rules . This process is done repeatedly until no more new good rules can be obtained . We also try converting predicates to events .
We also prune rules in R to remove redundant parts . The following is done : 1 ) convert a single event sequence condition to a predicate ; 2 ) remove a predicate that also occurs in the sequence condition ; 3 ) remove duplicate rules .
AgCBN also generates feedback for mS and mC , according to the results of the combination . For mS , AgCBN mainly gathers diagnoses from RC , and enumerates their permutations . These permutations can then be used by mS as good sequence segments . For mC , events from RS are sent , to be used for mC to focus its DC ( see Section 43 ) 4 . Data Reduction and Focusing of the Mining
Due to the large size and sparseness of the diabetes data , we have used several focusing strategies , including feature aggregation , feature selection and instance reduction .
41 Feature Aggregation
Feature aggregation is a static step before our CoLe system starts its work . We reduce the number of possible diagnostic codes in the aggregation . The over 17000 possible diagnostic codes are aggregated into 307 disease groups . We also have a temporal aggregation to put all diagnoses in a given period ( eg a week ) into the same event .
42 Instance Reduction
To make the miners focus on the instances we are interested in and to prevent miners from discovering the same set of rules over and over again in their iterations , we dynamically do instance reduction to get DS and DC , to give the miners a smaller and focused work data set . In each iteration , DS and DC use the same group of patients , so that it is meaningful to combine RS and RC .
The core work is to decide on a set of patients I in each iteration . For an instance set Ii in iteration i , it is generated based on Ii¡1 and the results of iteration ( i ¡ 1 ) . We take from Ii¡1 patients that are not covered by any rules in iter ation ( i ¡ 1 ) , together with randomly chosen patients from D , to form Ii . This makes miners focus more on patients without covering rules .
43 Feature Selection
In mC , we also do a feature selection to further reduce the search space . The features are selected by their relevance factors against the case/control class label . We use Equation 2 , inspired by the work in [ 5 ] , to calculate each feature ’s relevance factor .
RF(A ) = Pr(A ) £ log(cid:181 ) Pr(Ajcase )
Pr(Ajcontrol)¶
( 2 )
A is a feature , and probabilities are estimated by frequencies . The absolute value of RF(A ) refiects the relevance of A . Positive value means an indication of cases , while an indicator of controls gets a negative value . When we select the relevant features , a dynamic threshold tRF is used . This suits our situation better because DC is dynamically generated , thus we can not presume an arbitrary threshold . The use of feedbacks in mS can also be taken as a feature selection strategy .
5 . Experiments
We conducted several experiments with our implementation of CoLe . The focus is to evaluate the advantages of our new cooperative model over the individual algorithms , the effect of our focusing strategies , and the signi.cance of the results for medical research . Run time is not a test focus here , because it is acceptable to have a run time as long as 2(cid:150)3 days in the public health data mining with large data sets ( and all our single tests .nished within 12 hours , which is quite acceptable ) .
51 Effects of Cooperation
To evaluate the effects of cooperation , we have run CoLe with different .tness thresholds , while all other parameters are kept the same . The .tness values listed in Table 1 show that not only the average .tness of hybrid rules is higher , but also the maximum .tness value of hybrid rules is higher . But when we have too high a .tness threshold , the hybrid rule quality decreases , because this results in less candidates from miners for later combination stages , and consequently limits the possibilities for combination .
Table 2 presents the detailed .tness values over iterations in one of the tests . We also list the average .tness of the top 10 .ttest rules . Most importantly , the average .tness of the top hybrid rules is signi.cantly higher than the average .tness of the top rules from the individual miners . This shows that combination plays a key role in enhancing the quality of knowledge discovered by individual miners .
Table 1 . Individual algorithm vs . cooperation
Test No . Fitness threshold Average .tness from mS Average .tness from mC Average hybrid rule .tness Max .tness from mS Max .tness from mC Max hybrid rule .tness
1 3.6 3.10 2.58 3.72 3.72 3.72 4.29
2 3.7 2.86 2.51 3.82 3.74 3.78 4.33
3 3.8 3.24 2.62 3.89 3.74 3.72 4.12
4 3.9 3.05 2.44 3.91 3.72 3.72 3.91
Table 2 . Average .tness over iterations in Test 2
A : Average .tness of all rules in an iteration ;
T : Average .tness of top 10 ( all if less than 10 ) rules in an iteration ;
( S ) : Rules from mS ; ( C ) : Rules from mC ; ( H ) : Hybrid rules T(H ) Iter . 3.71 1 3.74 2 3 3.72 3.73 4 3.73 5 3.72 6 3.78 7 3.75 8 9 3.72 3.73 10 3.73 11 3.81 12 4.23 13 3.89 14 15 3.72 3.90 16 4.00 17 3.72 18 3.72 19 20 3.73
A(H ) 3.71 3.73 3.72 3.72 3.73 3.72 3.75 3.75 3.72 3.72 3.73 3.76 3.88 3.80 3.72 3.80 3.81 3.72 3.72 3.73
A(C ) 2.74 2.45 2.38 2.73 2.20 2.17 2.09 2.48 2.61 2.62 2.57 2.05 2.76 2.93 2.51 2.94 2.46 2.63 2.73 2.20
T(C ) 3.39 3.22 3.20 3.27 3.42 3.28 3.31 3.44 3.21 3.34 3.33 3.50 3.57 3.57 3.21 3.28 3.20 3.33 3.27 3.30
A(S ) 0.78 3.25 2.54 3.49 3.22 3.22 3.08 2.48 3.08 3.41 3.43 3.39 2.78 2.57 2.69 2.81 2.41 2.51 2.60 3.51
T(S ) 2.40 3.65 3.52 3.65 3.64 3.62 3.59 3.60 3.62 3.65 3.64 3.66 3.64 3.53 3.61 3.60 3.52 3.57 3.56 3.65
52 Effects of Focusing
While the help of feature aggregation is obvious , we performed detailed tests on the instance reduction ( IR ) and feature selection ( FS ) .
Our experiment with IR is a comparison between a normal CoLe implementation ( with IR ) and an implementation without IR , ie , mS and mC run on the entire data set instead of DS and DC . All other parameters are the same . The run times in Table 3(a ) show that the implementation with IR ran much faster than the one without . The maximum and average .tness values in Table 3(b ) are comparable .
In mS , FS is used to get feedback ( hints ) from AgCBN , and use those sequence segments as good materials to construct sequence rule individuals . We ran two experiments , one with FS and the other without it . The average .tness values of the .rst 10 generations are plotted in Figure 2 . It is obvious that the mS with hints has a faster increase in average tness
In mC , FS is to select relevant features into DC . Our experiments consist of several test runs with two implementations , one with FS and the other without it . Table 4 reports 5 test runs for each implementation . The mC without FS runs 30 100 times longer than mC with it . This proves that our FS strategies help eliminate irrelevant data and let mC focus on the rules that we are interested in .
Table 3 . Test on instance reduction ( IR )
( a ) Run time comparison ( seconds ) With IR Without IR 42606
Overall
18098
Average run time per iteration mS mC AgCBN
269.85 83.20 622.90
2334.90 1759.25 1924.90
( b ) Mining result quality comparison ( .tness )
S : Rules from mS ; C : Rules from mC ; H : Hybrid rules
S rules average C rules average H rules average S rules max C rules max H rules max
With IR Without IR 2.91 2.81 3.85 3.72 3.72 4.36
2.86 2.51 3.82 3.74 3.78 4.33
Sequence miner with and without hints ( first 10 generations ) 3 s s e n t i f e g a r e v a n o i t a r e n e G
2.5
2
1.5
1
0.5
0
0
1
2
With hints Without hints 5 7
4
3 6 Generation number
8
9
Figure 2 . Average .tness of individuals over generations in mS ( with and without hints ) 53 Medical Signi.cance
An example for a discovered rule is in Table 5 : A patient is likely to have diabetes if he/she was born after 1939 , has ( cid:147)other diseases of the respiratory system(cid:148 ) , has ( cid:147)diseases of skin and subcutaneous tissue(cid:148 ) , and diagnoses in the temporal order : repeatedly hypertension diagnoses , and some general uncomfortable symptoms in between . We presented the results to medical experts for their opinion and got very positive feedbacks . The medical signi.cance is mainly in the following aspects .
Firstly , in our hybrid rules , almost 100 % of them contain ( cid:147)hypertensive disease(cid:148 ) conditions . This con.rms an already known fact that hypertension has a very tight relation with diabetes . There are also many other diabetesrelated diagnoses , eg diseases of skin and subcutaneous tissue . This is a strong indication that CoLe is able to produce knowledge valid to medical research . However , hypertension alone is not a good indicator for diabetes , showing the need for complex rules like our hybrid rules .
Secondly , there are phenomena new to medical experts . The diagnosis ( cid:147)other diseases of the respiratory system(cid:148 ) is one example . It appears frequently in the hybrid rules . Medical experts could not recall immediately how it is related to diabetes . But it seems interesting to them , and there seem to be some explanations .
Thirdly , our results urge the public health services to improve their quality . There are quite a few conditions like
Table 4 . Run time ( seconds ) of PART algorithm in mC ( with and without feature selection(FS ) )
Test With FS Without FS 1855.356 1638.292 1704.105 2205.108 1877.903 1856.153
19.416 49.304 32.436 29.663 40.456 34.255
1 2 3 4 5 Average
Table 5 . A representative rule
Part Condition yofb> 1939
Description Year of Birth
Conj . f466,480 519g=1 Other diseases of the respiratory system Diseases of skin and subcutaneous tissue Hypertensive disease Signs , symptoms and ill de.ned conditions Hypertensive disease Hypertensive disease f680 686g=1 f401 405g f780 799g Seq . f401 405g f401 405g
( cid:147)signs , symptoms and ill de.ned conditions(cid:148 ) . This can only indicate that the patient has uncomfortable feelings , which are indicators of diseases . Therefore we should improve them to be more specic They also reveal the potential of diagnosing diabetes earlier .
6 . Conclusion
We proposed the CoLe cooperative data mining approach . It is a multi agent system framework with multiple miner agents and a combination agent . The main goal of CoLe is to get hybrid knowledge that can describe given data from multiple aspects . Our application of CoLe was mining medical data on diabetes . The results prove that our CoLe approach and our combination and focusing strategies are ef.cient and promising . And we have discovered some rules that are of interest to the medical researchers . Future work will be aimed at using CoLe in other areas and enhancing the diabetes application .
References
[ 1 ] R . Agrawal and R . Srikant . Mining sequential patterns . Proc .
11th Intl . Conf . on Data Eng . , IEEE , 1995 , pp . 3(cid:150)14 .
[ 2 ] E . Frank and I . H . Witten . Generating accurate rule sets without global optimization . Proc . 15th Intl . Conf . on Machine Learning , Morgan Kaufmann , 1998 , pp . 144(cid:150)151 .
[ 3 ] J . Gao , J . Denzinger , and R . C . James . A cooperative multiagent data mining model and its application to medical data on diabetes . Proc . AIS ADM , LNAI 3505 , 2005 , pp . 93(cid:150)107 . [ 4 ] H . Kargupta , I . Hamzaoglu , and B . Stafford . Scalable , distributed data mining an agent architecture . Proc . KDD 97 , 1997 , pp . 211(cid:150)214 .
[ 5 ] H . Liu , H . Lu , and J . Yao . Toward multidatabase mining : Identifying relevant databases . IEEE Trans . Knowledge Data Eng . , 13(4):541(cid:150)553 , 2001 .
[ 6 ] S . J . Stolfo , A . L . Prodromidis , S . Tselepis , W . Lee , D . W . Fan , and P . K . Chan . JAM : Java agents for meta learning over distributed databases . Proc . KDD 97 , 1997 pp . 74(cid:150)81 .
