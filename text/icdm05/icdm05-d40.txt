Pairwise Symmetry Decomposition Method for Generalized Covariance Analysis
IBM Research , Tokyo Research Laboratory
1623 14 Shimo tsuruma , Yamato , Kanagawa 242 8502 , Japan
Tsuyoshi Id´e goodidea@jpibmcom
Abstract
We propose a new theoretical framework for generalizing the traditional notion of covariance . First , we discuss the role of pairwise cross cumulants by introducing a cluster expansion technique for the cumulant generating function . Next , we introduce a novel concept of symmetry decomposition of probability density functions according to the C4v group . By utilizing the irreducible representations , generalized covariances are explicitly defined , and their utility is demonstrated using an analytically solvable model .
1 . Introduction
Correlation analysis for multivariate systems is one of the major topics in data mining . In spite of the importance , however , most of the practical correlation analysis methods for real valued data are essentially based on the traditional Gaussian distribution . The ( partial ) covariance matrix is the measure of correlation between variables in Gaussian distributions . However , it is well known that the covariance can correctly describe phenomena only in the vicinity of a linear correlation . One typical example is the fact that the covariance is zero if ( x , y ) is distributed on a circle . Although x is strongly correlated with y in this case , the covariance clearly fails in capturing the correlation .
To capture the nonlinearities , kernel based methods have been actively studied for the last decade . However , kernel methods are essentially “ black boxes , ” where what kind of correlations one discovers depends greatly on a possibly accidental choice of a suitable kernel .
In this paper , we propose a new theoretical framework for generalizing traditional covariance analysis . First , in Section 2 , under an approximation called sparse correlation approximation , we show that pairwise cross cumulants can suffice to describe nonlinear correlations without unwanted disturbances of the heterogeneity . Next , in Section 3 , we introduce a novel concept of symmetry decom position of probability density functions ( pdf ) according to the C4v group . To generalize the notion of covariance , we propose an idea of regarding pairwise functional relationships as two dimensional ( 2D ) geometric patterns in the 2D configuration spaces , where the irreducible representations of the C4v group are utilized to characterize the patterns . To the best of the author ’s knowledge , this is the first attempt to reduce the task of pattern recognition to discovery of irreducible representations . After giving explicit definitions of the generalized covariances in Section 4 , we demonstrate the capability of the generalized covariances based on an analytically solvable model in Section 5 .
2 . Pairwise Cross Cumulants
Consider a system whose internal state is described with an n dimensional random vector x = ( x1 , , xn)T . We expect that the pdf p(x ) contains all of the information about the internal structure of the system . The statistical properties of p are completely determined by the cumulant generating function Ψ(s ) :
Ψ(s ) ≡ lnZ dx p(x ) exp(sTx ) = ln›exp(sTx)fi ,
( 1 ) where 〈·〉 denotes the expectation with respect to p(x ) . The multivariate cumulants are defined as the coefficients of the Taylor expansion with respect to s . For example , we have 〈xixj〉c = 〈xixj〉 and 〈x2 j〉 − 2〈xixj〉2 for zero mean data ( which we assume hereafter ) . Here we introduced a notation of cumulant average 〈·〉c to represent multivariate cumulants [ 4 ] . For the readers’ convenience , we summarize the relationships between the cross cumulants and the moments in Table 1 . For higher order cumulants , the following properties are well known [ 6 ] : j〉c = 〈x2 i x2 j〉 − 〈x2 i〉〈x2 i x2
Theorem 1 A cross cumulant is zero if there is at least one pair of statistically independent variables inside 〈 〉c . Theorem 2 All of the higher order cumulants of k ≥ 3 vanish for the Gaussian .
K2 =Xi̸=j• 1
2! sisj〈xixj〉c +
1 3! si
2sj〈xi
2xj〉c + . . .‚ .
Thus , one needs to take account of the higher cumulants in order to go beyond the Gaussian distribution . Conversely , one may think that approximating Ψ(s ) using a finite number of higher order terms might be reasonable , since traditionally the Gaussian has been used as a practical solution for real valued multivariate correlation analysis .
Let us rewrite Ψ(s ) as Ψ(s ) = K1 + K2 + + Ki + , where Ki denotes the summation of terms including i different variables . For instance , K2 is given by
We call each term of Ki an i body cluster after statistical physics [ 4 ] .
Now let us approximate Ψ(s ) using a finite number of clusters . We here make an assumption of sparse correlation . Under this assumption , the larger the number of different variables inside 〈 〉c , the greater the likelihood that the cumulant vanishes . Thus , the contribution of higher order clusters would be negligible in the cluster expansion . Therefore , the lowest nontrivial approximation should be Ψ(s ) ≅ K1 + K2 , which we call the sparse correlation approximation ( SCA ) . Mathematically , this approximation would be valid when the average number of correlated variables on each variable is on the order of one . However , the leading term which describe the correlation must be K2 , even when the condition does not exactly hold . Since the one body cluster K1 only gives us the information about the marginal distribution of the individual variables , our basic quantities for correlation analysis are the pairwise cross cumulants of the type ν〉c , where µ and ν are nonzero integers . To be ro〈xi bust against the diversity of nonlinear correlations , we further approximate K2 to include only the terms of µ+ν ≤ 4 , i . e . we confine ourselves within the fourth order SCA . According to Theorem 1 , the pairwise cross cumulants are zero if the two variables are statistically independent . Note that this fact has nothing to do with how independent they are . In fact , a constant distribution and an uncorrelated Gaussian distribution equally give the value zero . This is a very good property in that the heterogeneity is mitigated in terms of statistical independence .
µxj
3 . Symmetry Decomposition of pdf
Let r = ( x , y)T be a pair of variables arbitrarily chosen from x . To facilitate the discussion , we adopt Dirac ’s bra ket notation to represent the pairwise pdf p(r ) [ 3 ] . We define |p〉 , a state vector in a Hilbert space H , by 〈r|p〉 = p(r ) , where |r〉 ∈ H is the position eigenket [ 5 ] . The inner product between |f〉,|h〉 ∈ H can be calculated as 〈f|h〉 = R drf(r)h(r ) . Since 〈r|r′〉 equals to Dirac ’s delta function δ(r − r′ ) , we have 〈r|p〉 =R dr′〈r|r′〉〈r′|p〉 = p(r ) , order
2 3 3 4 4 4 cumulant moment 〈xy〉c 〈xy2〉c 〈x2y〉c 〈x2y2〉c 〈xy3〉c 〈x3y〉c
〈xy〉 〈xy2〉 〈x2y〉 〈x2y2〉 − 〈x2〉〈y2〉 − 2〈xy〉2 〈xy3〉 − 3〈xy〉〈y2〉 〈x3y〉 − 3〈x2〉〈xy〉
Table 1 . Relationships between the pairwise cumulants and the moments for 〈x〉 = 〈y〉 = 0 .
Figure 1 . Symmetry axes of the C4v group . as expected . A cross moment 〈xµyν〉 is now represented as 〈p|xµyν〉 , where |xµyν〉 is defined by 〈r|xµyν〉 = xµyν . It is quite interesting to study the symmetry properties of |xµyν〉 . Consider a set of symmetry operations defined within the xy space . We request the operations to satisfy the axioms of a group : For a group G associated with a product operation ◦ , ( 1 ) Closure . For ∀a ∈ G and ∀b ∈ G , ( a ◦ b ) ∈ G . ( 2 ) Associativity . ( a ◦ b ) ◦ c = a ◦ ( b ◦ c ) for all a , b , and c ∈ G . ( 3 ) Identity . There exists e ∈ G , such that e ◦ g = g = g ◦ e for all g ∈ G . ( 4 ) Inverse . For each g ∈ G , there exists the g′ , the inverse of g , such that g′ ◦ g = g ◦ g′ = e . Unexpectedly , there are only 32 groups that can satisfy the axioms with rotations and mirror reflections [ 2 ] . Among the 32 point groups , the most general one within the 2D xyspace is a group named C4v . Figure 1 shows the symmetry axes of this group , which contains eight symmetry operations :
C4v = {e , C4 , C2 , C4
3 , σx , σy , σξ , ση} , where e is the identity element . Operations C4 , C2 , and 3 are π/2 , π , and 3π/2 rotations around the z axis , reC4 spectively . Mirror reflections with respect to the xz , yz , ξz and ηz planes are represented as σx , σy , σξ , ση , respectively . Note that the sufficiency of such symmetry operations is not necessarily guaranteed when they are arbitrarily chosen . It is the axioms of a group that guarantees the sufficiency of symmetry operations .
For |f〉 ∈ H and g ∈ C4v , we define g|f〉 by 〈r|g|f〉 = 〈g−1r|f〉 = f(g−1r ) . A space spanned by a set of linearly independent bases {|φ1〉 , ,|φl〉} ⊂ H is said to be an in xyzzx45o45o variant subspace with respect to a group G if g|φj〉 =
|φi〉Dij(g )
( 2 ) lXi=1 is satisfied for ∀g ∈ G . Specifically , a state in this subspace remains in the same subspace even after transformation by any operation of G . The matrix Dij(g ) is called a representation matrix for g . Using the fact that 〈r|C4|xµyν〉 = yµ(−x)ν and 〈r|σx|xµyν〉 = xµ(−y)ν , etc . , one can easily see that the state vector |xy〉 spans a one dimensional ( 1D ) invariant In fact , the representation matrices are 1 for subspace . e , C2 , σξ , ση , and −1 for C4 , C4 3 , σx , σy . Since any directproduct space spanned by bases such as |φi〉⊗|φj〉 can be an invariant subspace , the dimension of an invariant subspace does not have an upper bound . On the other hand , some lower bounds exist : a fundamental result of the theory of finite groups is that any invariant subspace can be expressed as a direct sum of a finite number of types of irreducible representation spaces [ 2 ] . This fact leads to the orthogonal relation between the irreducible representations
〈ϕ(γ)|ϕ(γ′)〉 ∝ δγ,γ′ ,
( 3 ) where γ and γ′ are symbols to identify irreducible representations , and δγ,γ′ is Kronecker ’s delta function . Therefore , a pairwise marginal distribution function p(r ) can be decomposed with respect to the symmetries 1 as p(r ) =Xγ
π(γ)(r ) ,
( 4 ) where we used the r representation for clarity . These facts prove the following theorem : Theorem 3 A state vector |ϕ(γ)〉 in an irreducible representation subspace γ satisfies 〈ϕ(γ)|p〉 = 〈ϕ(γ)|π(γ)〉 , ie , it works as a symmetry filter for |p〉 . Generally , irreducible representations are classified by their characters , ıe , the trace of representation matrices . For the C4v group , there are known to be five irreducible representations named A1 , A2 , B1 , B2 , and E . The E representation is 2D while the others are 1D . For γ = E , the function ϕ(γ ) in Eq ( 4 ) can be understood as a linear combination of the two orthogonal bases of E . Comparing the aforementioned result with the character table in Table 2 , we have an important theorem : Theorem 4 {|xy〉} spans the B2 representation . This theorem clearly shows the way to generalize the notion of covariance . Out of the five irreducible representations , only a single symmetry has been used so far . Now , one can utilize the other symmetries to describe correlations .
1It is instructive to consider another group called Ci = {e , I} , where I denotes space inversion . In this case , this decomposition corresponds to that between even and odd functions .
C4v A1 A2 B1 B2 E e C4 , C4 1 1 1 1 2
1 1 −1 −1 0
3 C2 1 1 1 1 −2
σx , σy
1 −1 1 −1 0
σξ , ση
1 −1 −1 1 0
Table 2 . The character table of the C4v group .
4 Generalized Covariances
As an example beyond |xy〉 , consider a state vector |x2y2〉 ∈ H . It is easy to verify 〈r|g|x2y2〉 = x2y2 for ∀g ∈ C4v , so that all of the representation matrices are the 1 × 1 identity matrix . Table 2 shows that this state spans the A1 representation . Similarly , one can verify that |xy3〉 + |x3y〉 is A2 , and {|xy2〉 + |x2y〉,|xy2〉 − |x2y〉} span the E representation . Let us relate these states to the pairwise cross cumulants .
For C4v , the following theorem holds ( proof omitted ) : Theorem 5 〈p|xµyν〉 has the same symmetry as 〈xµyν〉c . Using this , we define the generalized covariances in the C4v sense as 2
C(B2 ) = 〈xy〉c C(E1 ) = £›xy2fic +›x2yfic⁄ /2 C(E2 ) = £›xy2fic −›x2yfic⁄ /2 C(A1 ) = ›x2y2fic C(A2 ) = £›xy3fic −›x3yfic⁄ /2
( 5 ) ( 6 ) ( 7 ) ( 8 ) ( 9 ) where the two degrees of freedom in the E representation are distinguished using the subscripts 1 and 2 . Clearly , these are symmetric cross cumulants up to the fourth order according to the C4v group . To make those quantities . Evidently , this normalization factor transforms according to A1 , so that the symmetries of the generalized covariances are not affected . We call the normalized covariances the generalized correlation coefficients . dimensionless , it is useful to divide by£〈x2〉〈y2〉⁄(µ+ν)/4
5 . Experiment
To see the capability of detecting nonlinear correlations , consider a theoretical model of a correlated time series as x(t ) = √2 cos(ω1t + α ) y(t ) = √2 sin(ω2t + β )
2One cannot construct a B1 representation using the quantities
〈xµyν〉c when µ , ν > 0 and µ + ν ≤ 4 . with a constant pdf over the time domain . Clearly , the averages 〈x〉 and 〈y〉 are zeros , and the variances 〈x2〉c and 〈y2〉c are ones . Utilizing the fact that 〈sin(at + b)〉 = 0 unless the constant a is zero , we can derive analytical expressions for the generalized covariance : sin Ωβ,α
2 sin Ωβ,α
2 sin Ωβ,α
,
3
1
δω1,2ω2√2 δω1,2ω2√2
C(B2 ) = δω1,ω2 sin Ωβ,α C(E1 ) = − C(E2 ) = − C(A1 ) = − 2 C(A2 ) = δω1,3ω2
δω1,ω2 cos Ωα,β cos Ωα,β
2 + δ2ω1,ω2√2 δ2ω1,ω2√2 2 − )i h1 + 2 sin2(Ωα,β
δ3ω1,ω2 sin Ωα,β
4
1
3 − 4 c = a − bc . where we used the symbol Ωa,b
Figure 2 shows trajectories and generalized covariances for several combinations of the parameters , as shown beside each of the trajectories . The trajectories are well known as Lissajous’ trajectories . It is remarkable that the generalized covariances effectively detects the nonlinearities in the trajectories from ( b ) through ( e ) , where the traditional covariance C(B2 ) takes the value of zero .
6 . Conclusion
We have proposed a new theoretical framework for generalized covariance analysis , considering the limitations of the existing methods . To summarize , first , we showed that the pairwise cross cumulants can be viewed as the nontrivial simplest correction terms to the Gaussian distribution .
Next , we have proposed a new method for extending the traditional covariance based on the C4v group . The key idea is to think of pairwise functional relationships as 2D geometric patterns . To the best of the author ’s knowledge , this is the first work to use the irreducible representations of a specific group as a tool for pattern recognition . We found that the traditional covariance exploits only one of the five irreducible representations , and we defined generalized covariances according to the other irreducible representations . Finally , we have demonstrated the utility of the generalized covariances using an analytically solvable model . An application to an anomaly detection task [ 1 ] using a realworld time series data set will be published elsewhere .
References
[ 1 ] T . Id´e and K . Inoue . Knowledge discovery from heterogeneous dynamic systems using change point correlations . In Proc . of 2005 SIAM International Conference on Data Mining ( SDM 05 ) , pages 571–575 , 2005 .
Figure 2 . Lissajous’ trajectories and their generalized covariance .
[ 2 ] T . Inui , Y . Tanabe , and Y . Onodera . Group Theory and Its Applications in Physics , 2nd ed . Springer Verlag Telos , 1996 .
[ 3 ] R . Kondor and T . Jebara . A kernel between sets of vectors . In Proc . the 20th International Conference on Machine Learning , 2003 .
[ 4 ] R . Kubo . Generalized cumulant expansion method . Journal of the Physical Society of Japan , 17(7):1100– 1120 , 1962 .
[ 5 ] J . J . Sakurai . Modern Quantum Mechanics . Addison
Wesley , 2nd Ed . , 1994 .
[ 6 ] A . Stuart and J . K . Ord . Kendall ’s Advanced Theory of Statistics , Volume 1 . Arnold Publishers , 6th ed . , London , 1998 .
−101B2E1E2A1A2β − α(ω2/ω1 ) = −π/2ω2/ω1 = 1−05005B2E1E2A1A2β − α(ω2/ω1 ) = 0ω2/ω1 = 1−05005B2E1E2A1A2β − α(ω2/ω1 ) = π/2ω2/ω1 = 2−05005B2E1E2A1A2β − α(ω2/ω1 ) = −π/2ω2/ω1 = 1/2−0250025B2E1E2A1A2β − α(ω2/ω1 ) = π/2ω2/ω1 = 3
