Mining Patterns That Respond to Actions∗
Yuelong Jiang and Ke Wang Simon Fraser University {yjiang,wangk}@cssfuca
Alexander Tuzhilin New York University atuzhili@sternnyuedu
Ada Wai Chee Fu
Chinese University of Hong Kong adafu@csecuhkeduhk
Abstract
Suppose that our goal is partitioning the following data for taking actions to maximize U :
Data mining focuses on patterns that summarize the data . In this paper , we focus on mining patterns that could change the state by responding to opportunities of actions .
1 . Introduction
Data mining is about extracting interesting patterns from raw data . To quote [ 2 ] , “ Merely finding the patterns is not enough . You must be able to respond to the patterns , to act on them , ultimately turning the data into information , the information into action , and the action into value ” . Recently , Kleinberg et al . presented a microeconomic view of data mining [ 5 ] ( the market segmentation ) : partition the customer base C into k parts C1,··· , Ck to maximize the 1maxx∈DΣi∈Cj ci · x , where ci · x desum of the optima Σk notes the utility of a decision x on a customer i . Their work assumes the total knowledge about the utility of a decision on a customer ( ie , ci · x ) . In some applications , however , such total knowledge is not available , and only the partial knowledge that certain “ actions ” affect certain “ features ” may be known . The following example makes our point concrete .
Example 1.1 Consider a miniature teaching evaluation database with two features F1 and F2 , and one utility U . F1 and F2 represent the score on grading fairness and communication skills . U represents the overall score of the instructor ’s evaluations . All scores are on the scale of 0,1,2 ( with 0 being the worst and 2 being the best ) . As the user knowledge , the action A1 of providing grading supervision can improve F1 if F1 = 0 , and the action A2 of sending the instructor to a communication workshop can improve F2 if F2 = 0 . Though this knowledge does not directly hint the utility U , we would expect A1 and A2 to improve U if there is a correlation between Fi and U .
∗
This work was supported by a grant from NSERC .
G1 : F1 = 0 , F2 = 0 , U = 0 ( 100 cases ) G2 : F1 = 1 , F2 = 0 , U = 1 ( 100 cases ) G3 : F1 = 1 , F2 = 1 , U = 1 ( 100 cases ) G4 : F1 = 2 , F2 = 2 , U = 2 ( 20 cases ) .
The classic decision tree [ 7 ] , which will partition the data according to F1 to minimize the prediction error , does not facilitate our goal well : only the partition for F1 = 0 correctly characterizes 100 cases for action A1 ; the partition for F1 = 1 does not characterize any action because taking the action A2 means sending a half of the partition to the workshop without any improvement ( since A2 is applicable only if F2 = 0 ) . A better partitioning is by F2 because the partition for F2 = 0 correctly characterizes the 200 cases for action A2 .
This example motivates the following problem : given the historical data about the features F1,··· , Fm and the utility U , and assuming that the user knows that some actions Ai affect some features Fj in a “ simple ” way , we want to find the patterns about applying actions to boost the utility U . Such patterns can help to understand the action/utility relationship and can be used to recommend actions for future cases . Unlike [ 5 ] , we do not assume the knowledge about the utility of actions ; in fact , finding and summarizing the action/utility relationship is our goal . Rather , we assume the knowledge about how actions affect features , which is usually simple and known to the user .
Given a future case , one obvious approach is simply applying all applicable actions to the case . Unfortunately , this does not necessarily increase the utility because several actions could be conflicting with each other in affecting the utility . In addition , such a case based approach does not produce any pattern that summarizes the action/utility relationship . The next example shows that finding such patterns requires examining both the user knowledge and the historical data .
Example 1.2 Consider a customer database in the long distance call application :
Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 )
1550 4786/05 $20.00 © 2005 IEEE
D(CustID , M arried , Rate,··· , U ) .
U represents the profit generated on a customer and has the domain {Low , High} . Rate represents the rate charged to a customer , with N ormal denoting the normal rate and Special denoting the promotional rate . Suppose that we observe the following two populations in the data
P : Rate = N ormal , M arried = N o → U = Low , fi : Rate = Special , M arried = N o → U = High . P fi
Intuitively , the customers in P generate a higher profit by making more calls at the lower rate . Comparing these two populations reveals that the telephone company can increase the profit by offering the special rate to the customers in P . The increase is expected because a higher profit was ) who shared similar observed on the customers ( ie , P characteristics ( ie , unmarried ) but were offered the special rate . fi
If certain features are correlated with the utility in some population ( ie , Rate is correlated with U for unmarried customers ) , a change in those features implies a certain change in the utility . Now if some actions can influence those features , the influence will cascade to the utility through the correlation . We are interested in summarizing those actions and populations where such cascaded influences increase the utility . In this paper , we formulate a new action mining problem , called AFU ( Action Feature Utility ) mining , to capture this notion of actionability .
Some previous work has been done on action mining . [ 6 ] defines actionability in terms of restoring deviations back to the norm in the specific context of healthcare application . A domain independent approach based on action hierarchy and pattern templates was presented in [ 1 ] . [ 8 ] presented a profit motivated ( as opposed to hit motivated ) recommender approach . [ 9 ] requires the user to provide a “ cost ” for changing a feature value . Obtaining such cost will be the bottleneck in practice . For example , it is difficult for the user to determine the cost required for converting a customer from the attrition state to the loyal state , or to tell the cost required to score higher on the teaching evaluation question “ Explain difficult concepts effectively ” . Our approach models the typically available action/feature knowledge , not the cost , therefore , is more scalable in practice .
2 . Overview
Consider a data set D(F1,··· , Fm , U ) , where Fi are features and U is the utility to be maximized . Fi and U have a ranked domain , consisting of a small number of linearly ordered scales , represented by the first few integers 0,1 ,
Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 )
1550 4786/05 $20.00 © 2005 IEEE
For example , donation scale , skill level , letter grade , performance evaluation , all can be abstracted into a ranked domain . Following [ 5 ] , we shall be calling elements of D “ customers ” . Available is a set of actions A1,··· , An . An action model , to be defined formally in Section 3 , specifies how an action Ai increases or decreases the current value of a feature Fj .
Suppose that , given a set of customers Di , we can determine a set of actions ASi , or an actionset , for Di . Further , suppose that there is a method that , given ASi and Di , estimates the actionability of increasing the utility U by taking the actions ASi on |Di| future customers randomly drawn from the same distribution as Di . Let P Acti denote this actionability . For example , P Acti in Example 1.2 is the estimated profit increase after offering the special rate to |P| future customers matching the description of the population P .
Definition 2.1 In the Action Feature Utility ( AFU ) mining problem , we want to find a partition of the data , {D1,··· , Dq} , that maximizes the aggregated actionability :
ΣiP Acti .
( 1 )
A solution consists of ASi , Di and the description of Di , 1 ≤ i ≤ q .
Given a future customer matching the description of Di , we can recommend the actionset ASi to the customer . The recommendation maximizes the utility over the underlying distribution of Di . For a large D , the AFU mining is a very hard problem , since it requires optimization over all partitions of D , therefore , computation exponential in the size of D . In fact , this problem seems to be harder than the market segmentation in [ 5 ] in that the utility of actions and the number of partitions are not specified , and the maximization is on future customers . Below , we focus on the action model , the actionability and an approximate solution .
3 . The Action Model
31 Influence Matrix
The action model , denoted {Mij} , specifies the influence of an action Ai on a feature Fj , where 1 ≤ i ≤ n and 1 ≤ j ≤ m . Mij , called the influence range of Ai on Fj , has the form [ a , b ] , where 1 . a = b = − , if Ai has no influence on Fj . 2 . a < b , if Ai increases the current value c in [ a , b ] for Fj to some target value in the destination range [ c , b ] . 3 . a > b , if Ai decreases the current value c in [ a , b ] for
Fj to some target in the destination range [ b , c ] .
F1 [ 1,5 ] [ 4,2 ] [ 0,5 ] [ , ]
F2 [ 1,6 ] [ 2,0 ] [ 0,5 ] [ 4,0 ]
F3 [ 2,4 ] [ 2,5 ] [ 2,6 ] [ 5,0 ]
A1 A2 A3 A4
Table 1 . Influence matrix
33 Actionability of an Actionset
| c fi ∈ D ∧ c
So far , we considered how actions may affect features . Ultimately , we are interested in their actionability in terms of increasing the utility U . Consider the population P ⊆ D described by the vector ˆf = ( f1 , . . . , fk ) . From Definition 3.1 , an actionset AS will change any customer c in P to the destination space DS1,k . To estimate the actionability of this change , we need to estimate the new utility of c after the change . Our approach is examining those customers that fall into fi ∈ the destination space DS1,k , ie , {c fi DS1,k} , and using their utility to estimate the new utility of c . Intuitively , such customers serve as a “ role model ” for how c would perform after taking the actions AS . We call this set of customers the role model of P and denote it by rm(P ) . The actionability of AS on a customer c in P then is measured by agg(rm(P ))−c.U , where agg(rm(P ) ) denotes some aggregate , such as average , maximum or minimum , of the utility of the customers in rm(P ) and c.U denotes the utility of c . The actionability of AS on P is the sum of the actionability of AS over the customers in P . Definition 3.2 Given a population P ⊆ D described by a vector ˆf , and an actionset AS , the actionability of AS on P is defined as :
Act(P , AS , ˆf ) = Σc∈P ( agg(rm(P ) ) − cU )
Note that Act(P , AS , ˆf ) refers to observed customers in the given data D , whereas P Act in Equation ( 1 ) refers to future customers .
Example 3.2 Consider the following data set D and the influence matrix in Table 1 . c1 : F1 = 0 , F2 = 0 , F3 = 1 , U = 0 c2 : F1 = 2 , F2 = 1 , F3 = 1 , U = 1 c3 : F1 = 3 , F2 = 2 , F3 = 2 , U = 2 c4 : F1 = 3 , F2 = 3 , F3 = 2 , U = 3 c5 : F1 = 3 , F2 = 3 , F3 = 3 , U = 5 c6 : F1 = 4 , F2 = 4 , F3 = 4 , U = 6 c7 : F1 = 5 , F2 = 5 , F3 = 4 , U = 6 c8 : F1 = 5 , F2 = 6 , F3 = 6 , U = 4
The NIL action has no influence on any feature . Ai changes the current value c to the trivial destination range [ c , c ] if Ai has no influence on Fj , or c is not in the influence range [ a , b ] , or Ai is the NIL action .
As an example , suppose that the user knows that attending the communication workshop increases any communication skill level f in the range [ 1 , 5 ] to some level in [ f , 5 ] . This knowledge can be represented by the entry Mij = [ 1 , 5 ] for the action and the feature , with the following implications . ( 1 ) The action has no influence on the instructors whose communication skill level is less than 1 or more than 5 . ( 2 ) The new level after the action is in the range [ f , 5 ] , but the exact level is not specified , as usually the case . ( 3 ) We make no prior assumption about the distribution of this value in [ f , 5 ] . As we will see shortly , the data itself will provide this information .
The above model implicitly assumes that the influence of an action on a feature is independent of the state of other features and the influence of other actions . We make this assumption because the human user tends to work better by dealing with one thing at a time . In practice , the user knowledge is largely imprecise and approximating due to the human bottleneck , and capturing complete user knowledge is neither desirable nor tractable . The naive Bayes classifier [ 3 ] is an example of making an independence assumption and achieving good performance results .
32 Actionsets
Under the independence assumption , applying an actionset will change the current feature value to a range given by the union of the destination range of applying each action separately .
Definition 3.1 Consider an actionset AS and a feature value Fj = fj . Let [ lij , hij ] be the destination range of applying Ai ∈ AS to Fj = fj . The destination range of applying AS to Fj = fj is [ lj , hj ] , where lj = min(lij ) and hj = max(hij ) .
In other words , DS1,k = ( [l1 , h1 ] , . . . , [ lk , hk ] ) describes the feature ranges after applying AS to any customer matching ˆf = ( f1 , . . . , fk ) . If AS contains no action , we assume that it contains the NIL action so that AS is non empty .
Example 3.1 Refer to the influence matrix in Table 1 . Assume that all features have the domain 0 6 . Consider the actionset {A1 , A2} and the vector ( F1 = 3 , F2 = 3 ) . A1 increases F1 = 3 to any value in [ 3 , 5 ] and increases F2 = 3 to any value in [ 3 , 6 ] ; A2 decreases F1 = 3 to any value in [ 2 , 3 ] and has no effect on F2 = 3 . Therefore , the destination space of applying {A1 , A2} to ( F1 = 3 , F2 = 3 ) is ( [2 , 5 ] , [ 3 , 6] ) . Note that A1 and A2 have conflicting influence on F2 .
Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 )
1550 4786/05 $20.00 © 2005 IEEE
Ni . The exact definition of ASi is a bit technical and is given in the full report [ 4 ] . Based on ASi , we can compute DS1,k , as in Definition 3.1 , and the role model rmi of Pi at Ni .
The above criterion is based on observed customers ( ie , Act ) , therefore , may not maximize the actionability on future customers due to potential over fitting . To address this issue , we need to prune the fully expanded tree to maximize the projected actionability over the entire population at a node N ( ie , P Act(N) ) . P Act(N ) can be estimated using a modification of the pessimistic error estimation adopted in [ 7 ] . The pruning process then is similar to the bottomup pruning of the decision tree [ 7 ] : at each node we check whether pruning the subtree can increase the projected actionability , if yes , prune the subtree immediately , and if not , keep the subtree . Our empirical evaluation shows that this method generates a higher utility than ignoring the opportunities of actions . The details are reported in [ 4 ] .
5 . Conclusion
Actionability mining is an important but under studied topic . A key issue is modeling the user knowledge in a scalable manner . Previous works assume the availability of the cost for actionability . Obtaining such cost will be the bottleneck in practice . A contribution of our work is the introduction of “ actions ” as a domain independent and scalable way to capture a certain type of user knowledge . We also presented a concrete framework for incorporating such knowledge to obtain utility function .
References
[ 1 ] G . Adomavicius and A . Tuzhilin . Discovery of actionable patterns in databases : The action hierarchy approach . In KDD , pages 111–114 , 1997 .
[ 2 ] C . Derman . Finite State Markov Decision Process . Academic
Press , New York , 1970 .
[ 3 ] R . Duda and P . Hart . Pattern classification and scence analy sis . In Wiley , 1983 .
[ 4 ] Y . Jiang , K . Wang , A . Tuzhilin , and A . Fu . Mining patterns that respond to actions . Technical Report , School of Computing Science , Simon Fraser University , 2005 .
[ 5 ] J . Kleinberg , C . Papadimitriou , and P . Raghavan . A microeconomic view of data mining . Journal of Knowledge Discovery and Data Mining , 2:311–324 , 1998 .
[ 6 ] G . Piatesky Shapiro and C . J . Matheus . The interestingness of deviations . In AAAI 94 Workshop on KDD .
[ 7 ] J . Quinlan . C4.5 : Programs for machine learning . In Morgan
Kaufmann , 1993 .
[ 8 ] K . Wang , S . Zhou , and J . Han . Profit mining : From patterns to actions . In EDBT , pages 70–87 , 2002 .
[ 9 ] Q . Yang and J . Yin . Postprocessing decision trees to extract actionable knowledge . In ICDM , 2003 .
The population described by ( F1 = 3 , F2 = 3 ) is P = {c4 , c5} . The destination space of applying {A1 , A2} to P is ( [2 , 5 ] , [ 3 , 6] ) , and the role model of P is rm(P ) = {c4 , c5 , c6 , c7 , c8} . If agg is the average function , agg(rm(P ) ) = 48 The actionability of applying {A1 , A2} to P is ( 4.8 − 3 ) + ( 4.8 − 5 ) = 16
4 . An Approximate Solution
We present an approximate solution to the AFU mining by iteratively partitioning the data to maximize the actionability in Equation ( 1 ) . Initially , we have a single node representing the whole data D . At each step , we partition a leaf node according to a feature selected by some selection criterion , ie , partitioning the customers at the parent node according to the values of the feature . This tree growth continues until for any leaf node either there is no available feature or the selection criterion becomes non positive .
Let us consider the selection criterion of features . Consider partitioning a leaf node Np into the child nodes Ni , 1 ≤ i ≤ u , according to the values fk1,··· , fku of some feature Fk . At the node Np , we have the vector ˆfp = ( f1 , . . . , fk−1 ) , the actionset ASp , the population Pp described by ˆfp , the destination space DS1,k−1 , and the role model rmp of Pp . ˆfp corresponds to the branching conditions on the path from the root to Np . Similarly , at each child node Ni , we have the vector ˆfi = ( f1 , . . . , fk−1 , fki ) , the actionset ASi , the population Pi described by ˆfi , the destination space DS1,k , and the role model rmi of Pi .
The usefulness of Fk at Np is measured by the promise of increasing the actionability ΣP Acti in Equation ( 1 ) after partitioning Pp into Pi and applying ASi to Pi . P Acti is the actionability of ASi on |Pi| future customers drawn from the same distribution as Pi , where Pi is a set of observed customers and ASi is the set of actions applicable to Pi . Since future customers are unknown , we can only heuristically maximize ΣP Acti using Act(Pp , ASp , ˆfp ) and Act(Pi , ASi , ˆfi ) ( Definition 3.2 ) , or simply Act(Np ) and Act(Ni ) , defined on the observed customers at Np and Ni . The usefulness of Fk can then be measured by the increase of Act after partitioning the data using Fk , called “ actionability gain ” below .
Definition 4.1 The actionability gain of Fk at Np , denoted ActGain(Fk , Np ) , is defined as
.u i=1 Act(Ni ) − Act(Np ) .
To partition the population Pp at the node Np , we select the feature Fk , among all available features , that maximizes ActGain . To compute ActGain , we need to determine the actionset ASi at a child node Ni so that Act(Ni ) can be computed . ASi is a set of actions that are “ applicable ” at
Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 )
1550 4786/05 $20.00 © 2005 IEEE
