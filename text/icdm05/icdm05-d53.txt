Finding Maximal Frequent Itemsets over Online Data Streams Adaptively
Daesu Lee
Department of Computer Science
Yonsei University , Korea dslee@databaseyonseiackr
Wonsuk Lee
Department of Computer Science
Yonsei University , Korea leewo@databaseyonseiackr
Abstract regardless of
Due to the characteristics of a data stream , it is very important to confine the memory usage of a data mining process the amount of information generated in the data stream . For this purpose , this paper proposes a CP tree ( Compressedprefix tree ) that can be effectively used in finding either frequent or maximal frequent itemsets over an online data stream . Unlike a prefix tree , a node of a CP tree can maintain the information of several itemsets together . Based on this characteristic , the size of a CP tree can be flexibly controlled by merging or splitting nodes . In this paper , a mining method employing a CP tree is proposed and an adaptive memory utilization scheme is also presented in order to maximize the mining accuracy of the proposed method for confined memory space at all times . Finally , the performance of the proposed method is analyzed by a series of experiments to identify its various characteristics .
1 . Introduction
With the rapid development of information technology , the amount of information has been increasing faster than ever in various domains . Furthermore , depending on the characteristics of an application domain , its information is produced in diverse forms . A data stream is one of such forms and is a massive unbounded sequence of data elements continuously generated at a rapid rate . Due to this reason , it is impossible to maintain all the elements of a data stream . Consequently , on line data stream processing should satisfy the following requirements [ 6 ] . First , each data element should be examined at most once to analyze a data stream . Second , memory usage for data stream analysis should be restricted finitely although new data elements are continuously generated in a data stream . Third , newly generated data elements should be pro cessed as fast as possible to produce the up to date analysis result of a data stream , so that it can be instantly utilized upon request . To satisfy these requirements , data stream processing sacrifices the correctness of its analysis result by allowing some error .
Recently , various algorithms [ 7,9,10 ] are actively proposed to extract different types of knowledge embedded in a data stream . The sticky sampling method [ 11 ] , the Lossy Counting algorithm [ 11 ] and the estDec method [ 4 ] focus on finding frequent itemsets over a data stream . In the Lossy Counting algorithm , to reduce the memory usage of a mining process , the counts of frequent itemsets can be kept in a secondary storage and only a buffer for the batch processing of transactions is kept in main memory . As the buffer is enlarged , more number of newly generated transactions can be batch processed together , so that the algorithm is more efficiently processed . When the number of frequent itemsets is large , accessing the information of frequent itemsets in a secondary disk needs more time . Due to this reason , this algorithm is not appropriate for an online data stream .
For finding frequent itemsets , we have proposed the estDec method [ 4 ] to minimize the number of itemsets to be monitored . In this method , an itemset whose support is greater than a predefined significant support Ssig ( Ssig(cid:148)Smin ) is regarded as a significant itemset where Smin is a given minimum support . Each significant item set in a data stream is represented by an individual node of a prefix tree . Consequently , the resulting set of frequent itemsets in a data stream can be found instantly at any moment . As the number of significant itemsets in a data stream is increased , the size of the prefix tree that represents these itemsets become larger . Consequently , the memory usage of the prefix tree is also increased . Once the size of a prefix tree becomes larger than the size of available memory space , no new significant itemset can be inserted to the prefix tree , so that the estDec method will not work properly any longer .
Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 )
1550 4786/05 $20.00 © 2005 IEEE
An itemset tree [ 8 ] is proposed to reduce the memory usage of finding frequent itemsets in an incrementally enlarged data set . Unlike a prefix tree , a node of an itemset tree maintains the subset of items in an individual transaction . Given an itemset tree for a set of transactions , if there exists a node representing any subset of items in a newly added transaction T , the node is shared to represent the subset of the items in T . Only a node corresponding to the remaining items of T is newly inserted into the itemset tree . By sharing the common subsets of transactions in a data set , it is possible to reduce the required size of memory space . Consequently , the size of an itemset tree is smaller than that of a prefix tree for the same data set . However , like a prefix tree , an itemset tree has no mechanism to confined memory space . its size adaptively to manipulate
To cope with this drawback of conventional tree structures , this paper proposes a CP tree ( Compressed Prefix tree ) to replace the role of a prefix tree in the estDec method . In addition , this paper also introduces the extended version of the estDec method , namely estDec+ for a CP tree . Unlike a prefix tree , two or more nodes of a prefix tree can be merged into a single node of a CP tree as long as the support difference of their corresponding itemsets is within a predefined threshold called a merging gap threshold ( cid:303)(cid:2866)(0,1 ) . In such a node of a CP tree , only the counts of two representative itemsets are maintained while those of the remaining itemsets are estimated based on the counts of the representative itemsets . By adaptively controlling the value of ( cid:303 ) , the number of nodes in a CP tree can be changed . As the value of ( cid:303 ) is increased , more significant itemsets can be represented by a single node of a CP tree . Consequently , the size of the CP tree is reduced while the mining result of the estDec+ method becomes less accurate . However , since the size of a CP tree can be flexibly controlled by merging or splitting nodes , the estDec+ method can fully utilize confined memory space at all times . This capability is valuable when the number of significant itemsets is fluctuated heavily .
The rest of this paper is organized as follows : Section 2 reviews the estDec method . Section 3 proposes the structure and operations of a CP tree in detail . Section 4 introduces the estDec+ method which employs a CP tree to find frequent or maximal frequent itemsets over an on line data stream . In Section 5 , the performance of the estDec+ method is evaluated by a series of experiments . Finally , Section 6 concludes this paper .
2 . Preliminaries
Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 )
1550 4786/05 $20.00 © 2005 IEEE
The estDec method examines each transaction in a data stream one by one without any candidate generation and keeps track of the occurrence count of an itemset in the transactions generated so far by a monitoring tree whose structure is a prefix tree [ 1,3 ] . Given the current data stream Dk , a prefix tree Pk has the following characteristics : i ) A prefix tree Pk has a root node nroot with a “ null ” value and each node except the root node has an item i(cid:143)I . ii ) Given a node n having an item in(cid:143)I in a prefix tree Pk , let s=nrootn1n2…nvn be the sequence of nodes in the path from the root nroot to the node n and let each node nj have its item ij(cid:143)I ( 1(cid:148)j(cid:148)v ) . The node n represents an itemset en=i1i2…ivin and maintains the current count Ck(en ) . The estDec method has two major operations : delayed insertion and pruning operations . Monitoring the count of a new itemset is started only in the following two cases . The first case is when a new 1itemset appears in a newly generated transaction Tk . In this case , monitoring its count is instantly started by inserting it to the monitoring tree Pk without any estimation . The second case is when an insignificant itemset just becomes a significant one due to its appearance of Tk . Since it becomes an significant itemset , it should be inserted into Pk for further monitoring . To find such an n itemset e ( n(cid:149)2 ) , only when all of its ( n(cid:237)1) subsets are currently maintained in Pk , the current support of the itemset e is estimated by those of its ( n(cid:237)1) subsets . If the estimated support is greater than a predefined insertion support Sins , the itemset e is inserted . Since the total number of the ( n(cid:237)1) subsets is n , let {c1 , c2 , … , cn} be the set of the current counts of the ( n(cid:237)1) subsets monitored in Pk . of the itemset e is The estimated current count =max(c1 , … , cn ) . obtained by the largest one ie The upper bound of the estimation error for e is c eC )( eCk )(ˆ eC k )(ˆ max( min(
, , eC |)(ˆ k
The above procedure is a delayed insertion operation . The upper bound of this estimation error is proven to be ignorable when k becomes infinite [ 4 ] . In this paper , estimating the current count of such an insignificant itemset is called as inserting count estimation . c
) n c
1
, ,
| k c
1
) n
On the other hand , a pruning operation is performed when the current support of an itemset maintained by Pk becomes less than a predefined pruning support Sprn . The itemset is regarded as an insignificant itemset that cannot be a frequent itemset in the near future . Upon identifying such an itemset , the node representing such an itemset and all of its descendent nodes are pruned from Pk based on the anti monotonicity of a frequent itemset [ 4 ] . Since Pk is located in main memory , its size should be kept smaller than the confined space of main memory at all times . However , its size totally depends on the density of significant itemsets in the current data stream Dk with respect to Ssig . Therefore , once the size of a prefix tree exceeds to the size of the confined memory space , it is impossible to monitor any new significant itemset by the delayed insertion operation . Due to this reason , the mining accuracy of the estDec method can be degraded without any upper bound in this situation .
3 . Compressible Prefix Tree : CP tree
31 CP tree
To reduce the size of a prefix tree , the information represented by the prefix tree needs to be compressed . Two consecutive nodes by a prefix tree are merged in a CP tree when the current support difference between their corresponding itemsets is less than or equal to a merging gap threshold ( cid:303)(cid:143)(0,1 ) . Ultimately , a subtree of a prefix tree can be compressed into a node of a CPtree .
Definition 1 . A mergeable subtree Suppose Pk be a prefix tree and S be a subtree of Pk . Let ev denote the itemset represented by the root of S and ej denote an itemset represented by a node of S . A leaf node of S is not necessarily to be a leaf node of Pk . Given a merging gap threshold ( cid:303 ) , if all the nodes of the subtree S satisfy the following condition , the subtree S is a mergeable subtree and compressed into a node of a CP tree Qk that is equivalent to Pk .
|Ck(ev)(cid:237)Ck(ej)|/|D|k(cid:148)(cid:303 ) , 1(cid:148)j(cid:148)|S| where |S| denotes the number of nodes in S .
( cid:401 )
The detailed structure of a node in a CP tree is defined in Definition 2 .
Definition 2 . CP node structure Given a mergeable subtree S of a prefix tree Pk in Dk , let a CP tree Qk be equivalent to Pk . To represent the information of S in Qk , a node m of Qk maintains the following four entries m((cid:306 ) , ( cid:652 ) , cS , cL ) as follows : i ) item list ( cid:306 ) : The items of the nodes in each level of S are lexicographically ordered and these levelwise lists of items are ordered according to their levels . Let |(cid:306)| denote the number of items in ( cid:306 ) and the jth item in ( cid:306 ) is represented by ( cid:306)[j ] ( 1(cid:148)j(cid:148)|(cid:306)| , |(cid:306)|=|S| ) . The item m.(cid:306)[1 ] is corresponding to the itemset represented by the root node of S . This itemset is called as the shortest itemset of the node m and denoted by meS On the other hand , the last item m.(cid:306)[|S| ] is corresponding to the itemset represented
Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 )
1550 4786/05 $20.00 © 2005 IEEE by the right most leaf node in the lowest level of S . The itemset is called as the longest itemset of the node m and denoted by meL ii ) parent index list ( cid:652 ) : ( cid:652 ) maintains an entry of a form p.q where p denotes a node identifier of Qk and q denote an index of the item list ( cid:306 ) of the node p . Suppose a node nx with an item x(cid:143)I is the parent of a node ny with an item y(cid:143)I in the mergeable subtree S . The nodes nx and ny of Pk are represented by their corresponding items x and y in the item list ( cid:306 ) of the node m . Let a and b denote the item list indexes of the items x and y respectively , ie , m.(cid:306)[a]=x and m(cid:306)[b]=y The parent child relationship of the nodes nx and ny in Pk is modeled by the two lists ( cid:306 ) and ( cid:652 ) in the node m since m.(cid:306)[b]=y and m(cid:652)[b]=ma imply the parent of the item y is m(cid:306)[a]=x On the other hand , suppose the parent of the root of S is a node nz with an item z in Pk and the node nz is in another mergeable subtree S . If S is represented by a node m of Qk and the itemlist index of the node nz in m is qz ie , m .(cid:306)[qz]=z , the entry of m.(cid:306)[1 ] is set to m qz iii ) largest count cL : the current count of the shortest itemset eS . iv ) smallest count cS : if |S|=1 , cS=cL . Otherwise , the ( cid:401 ) current count of the longest itemset eL .
( cid:149)(cid:87)(cid:71 )
Ø
( cid:149)(cid:71 )
( cid:136)(cid:97)(cid:87 )
( cid:149)(cid:71 )
( cid:137)(cid:97 )
( cid:138)(cid:97 )
( cid:139)(cid:97)(cid:92 )
( cid:149)(cid:71 )
( cid:149)(cid:71 )
( cid:149)(cid:94)(cid:71 )
( cid:138)(cid:97)(cid:92 )
( cid:139)(cid:97)(cid:92 )
( cid:140)(cid:97 )
( cid:149)(cid:71 )
( cid:149)(cid:92)(cid:71 )
( cid:148)(cid:87)(cid:71 )
Ø(cid:71 )
( cid:148)(cid:71 )
( cid:590 ) ( cid:136)(cid:137)(cid:138)(cid:71 ) ( cid:586 ) ( cid:148)(cid:87)(cid:85)(cid:148)(cid:85)(cid:148)(cid:85 ) ( cid:79)(cid:138)(cid:97)(cid:87)(cid:71)(cid:138)(cid:97)(cid:71 )
( cid:148)(cid:71 )
( cid:148)(cid:71 )
( cid:590 ) ( cid:138)(cid:139)(cid:71 ) ( cid:586)(cid:148)(cid:85)(cid:148)(cid:85)(cid:71 ) ( cid:79)(cid:138)(cid:97)(cid:92)(cid:71)(cid:138)(cid:97)(cid:92)(cid:71 )
( cid:590 ) ( cid:139)(cid:71)(cid:71 ) ( cid:586 ) ( cid:148)(cid:85)(cid:71 ) ( cid:79)(cid:138)(cid:97)(cid:92)(cid:71)(cid:138)(cid:97)(cid:92 )
( cid:148)(cid:71 )
( cid:590 ) ( cid:140)(cid:71)(cid:71 ) ( cid:586 ) ( cid:148)(cid:85)(cid:71 ) ( cid:79)(cid:138)(cid:97)(cid:71)(cid:138)(cid:97)(cid:71 )
( cid:71)(cid:119)(cid:153)(cid:140)(cid:141)(cid:144)(cid:159)(cid:71)(cid:155)(cid:153)(cid:140)(cid:140)(cid:71)(cid:119)(cid:146 )
( cid:149)(cid:71)(cid:140)(cid:152)(cid:156)(cid:144)(cid:157)(cid:136)(cid:147)(cid:140)(cid:149)(cid:155)(cid:71)(cid:106)(cid:119)(cid:84)(cid:155)(cid:153)(cid:140)(cid:140)(cid:71)(cid:120)(cid:146 )
Figure 1 . A CP tree and its equivalent prefix tree ( Smin=0.1 , ( cid:303)=0.2 , |D|=10 ) into
Figure 1 shows a prefix tree Pk and its equivalent CP tree Qk . The subtree formed by the nodes n1 , n2 , and n3 of Pk are compressed the node m1((cid:306)=<a,b,c> , ( cid:652)=<m01,m11,m11> , cL , cS ) of Qk . This is because the current support difference between the root node n1 of the subtree and each of its child nodes n2 and n3 is less than ( cid:303 ) . The root of the subtree represented by m1 is ( cid:306)[1]=a which is corresponding to the node n1 of Pk . Its parent node ( cid:652)[1]=m0.1 is the node m0 of the CP tree Qk . The fact that the node n1 is the parent of the node n2 in Pk can be inferred by m1.(cid:306)[2]=b and m1(cid:652)[2]=m11 which imply that the parent of the item b is m1.(cid:306)[1 ] ie a . The shortest and longest itemsets of m1 are a and ac respectively .
32 Merged count Estimation
Given the item list m.(cid:306)=<i1,i2,…,in> of a node m in a jie denote the itemset represented by ij CP tree , let ( 1(cid:148)j(cid:148)n ) . By the two counters cS and cL of the node , it is possible to trace the current supports of at most two 1ie and itemsets ie the shortest and longest itemsets nie as precisely as the estDec method does . Therefore , if more than three itemsets are compressed into a single node , the current counts of the remaining itemsets can be estimated by a formula eC ( i j
) c ( cid:170 ) L jmf ( cid:186 ) ),(
2(
( cid:100)(cid:100 ) n j
)1 where f(m , j ) denotes a count estimation function that in terms of the counts cL can model the count and cS of the shortest and longest itemsets eS and eL . A function meaningful in an application domain can be employed to define the function f(m , j ) . jieC
(
) the
To distinguish inserting count estimation defined in Section 2 , the above estimation is called as merged count estimation . When the current count of an itemset traced by a node of a CP tree is estimated by the above mechanism , there must be an error count but the possible range of this error count is totally influenced by the value of ( cid:303 ) .
33 CP tree Maintenance
Given a minimum support Smin and a merging gap threshold ( cid:303 ) , let Qk 1 denote a CP tree at a data stream Dk 1 . As in the estDec method , when a new transaction Tk is generated , those paths of Qk 1 that are induced by the items of Tk are traversed respectively and the counts of all the nodes in the paths are updated . Traversing a CP tree is virtually the same as traversing a prefix tree in [ 4 ] . The items of Tk are lexicographically ordered and matched with Qk(cid:237)1 by a depth first manner as in a prefix tree . Among the items in the item list ( cid:306 ) of a node m , a leaf level item is defined as an item i whose item list index j does not appear in the parent list of the node m . ie j(cid:143 ) m.(cid:652)[l ] ffl , 1(cid:148 ) l(cid:148 ) |(cid:306)| where m(cid:306)[j]=i
Upon visiting a node m of a CP tree , let mp denote its parent node and ip denote the last matched leaf level node in mp . If m(cid:652)[1]=mpip , the first item m.(cid:306)[1 ] is compared with those remaining items of Tk that are not yet matched . If the above condition is not met or the
Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 )
1550 4786/05 $20.00 © 2005 IEEE item m.(cid:306)[1 ] is not matched , the search is terminated and return to the parent node of the node m . If m.(cid:306)[1 ] is matched , the largest count cL of the node m is incremented by one . Let the item m.(cid:306)[1 ] be the first common item ci1 in the item list m.(cid:306 ) and the remaining items of Tk . Among the remaining items of Tk , only those items that are after the item ci1 are considered to be matched further . Subsequently , find the second common item ci2 in both the remaining items of ( cid:306 ) and those items in Tk that are considered to be matched . Let the item list indexes of the common items ci1 and ci2 be j1 and j2 . Only when the parent of ci2 is ci1 , ie m(cid:652)[j2]=mj1 , let ci2 be a new ci1 and find a new ci2 by the same manner until there is no such ci2 in m(cid:306 ) If the above recursive search in the node m is terminated by reaching one of the leaf level items of the node m , the child nodes of the node m are searched continuously . When the last ci2 item is not an leaf level item , the next common item in the remaining items of the two lists is searched by the same way . This procedure is recursively repeated until there is no item to be matched in either of the lists . Furthermore , only when the last item ( cid:306)[|(cid:306)| ] is matched as a leaf level item , the smallest count m.cS is also increased . If none of the leaf level items are matched , the search is terminated and returned to the parent of the node m . The traversing algorithm is presented in Section 4 .
While traversing a node m of Qk 1 , two major operations : node merge and node split can be performed additionally . Let m denote the parent node of m . A node merge operation is only invoked in the following two cases . One is when the current support difference between the shortest itemset of m and the longest itemset of the node m becomes less than or equal to ( cid:303 ) ie . This case happens only when the difference between the two counts remains the same and only |D|k is increased . The other one is when a new significant itemset e is identified by the inserting count estimation process , so that a new node for the itemset needs to be inserted as a child of the node m . If the current support difference of the estimated support of the new significant itemset and the largest itemset of the node m is less than or equal to ( cid:303 ) , the new node is merged into the node m . The detailed steps of a node merging operation are described in Figure 2 . On the other hand , a node m of a CP tree is split into two different nodes when the support differ ence between its shortest and longest itemsets becomes greater than ( cid:303 ) , ie , ( mcL(cid:237)mcS)/|D|k >(cid:303 ) . The difference is enlarged when only m.cL is increased . When a node is split , each of the leaf level items of the node m.(cid:306 ) is separated as an individual node of a CP tree . The detailed steps of a node split
( cid:71)(cid:100 ) cm . cm .
|/ )
D
| k
(
L
S operation are described in Figure 3 . node_merge(m1 and m2 ) 1 append m2.(cid:306 ) to the end of m2.(cid:306 ) ; 2 let a ( cid:312 ) m1.|(cid:306)| + 1 ; 3 append m2.(cid:652)[1 ] to m1.(cid:652)[a ] 4 for each entry in m2.(cid:652)[j ] ( 2 ( cid:148 ) j ( cid:148 ) |m2.(cid:306)| ) where m2.(cid:652)[j ] = m2.q 5 add an entry m1.(q + m1.|(cid:306)| ) to m1.(cid:652)[a + j ( cid:237 ) 1 ] ; 6 make the child nodes of m2 be those of m1 ; 7 Prune m2 from Qk ;
Figure 2 . Node_merge operation node_split(m ) let b1,…bw be the leaf level items of a node m and q1,…qw be their item list indexes 1 for each bk ( 1(cid:148 ) k(cid:148 ) w ) 2 create a child node mk of the m by initializing ; 3 mk.(cid:306)[1 ] ( cid:312 ) bk ; 4 mk.(cid:652)[1 ] ( cid:312 ) m.qk ; 5 mk.cL ( cid:312 ) estimate count of 6 eliminate those entries from m.(cid:306 ) and m.(cid:652 ) corresponding to bk ; 7 m.cS ( cid:312 ) estimate count of the new longest itemset of m ; kbe
;
Figure 3 . Node_split operation
4 . Finding Maximal Frequent Itemsets
In this section , a modified version estDec+ of the estDec method is proposed . The proposed method is basically based on the estDec method but the underlying memory structure of significant itemsets is changed from a prefix tree to a CP tree .
41 estDec+ Method
In the estDec method , the weight of information in a data stream is differentiated over time by a decay mechanism [ 4 ] , so that it can find recently frequent itemsets over the data stream [ 4 ] . To concentrate on developing a mining method based on a CP tree over a data stream , this paper does not mention about the decay mechanism precisely . However , the same decay mechanism applied to a prefix tree in the estDec method can also be employed to a CP tree in the estDec+ method . Furthermore , the estDec+ method employs delayed insertion and pruning operations to trace the current supports of only significant itemsets . However , the two thresholds : an insertion support Sins and a pruning support Sprn used in the estDec method are denoted by a significant support Ssig(cid:143)(0,Smin ) in this paper . In other words , delayed insertion and pruning operations in the estDec+ method are performed with respect to Ssig .
If every node which represents a significant itemset is allowed to be merged , an infrequent but significant itemset e , ie Ssig(cid:148)Sk(e)(cid:148)Smin can be merged with frequent itemsets . This can cause false positive or false
Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 )
1550 4786/05 $20.00 © 2005 IEEE negative errors in the course of merged count estimation . To reduce these types of error , a node whose current support is less than a predefined threshold called a merging threshold Smerge ( (cid:149)Smin ) is not considered as a candidate for a node merge operation . Since a node of a CP tree can represent multiple itemsets together , the current supports of all the itemsets induced by a node are estimated to find any maximal frequent itemset in the node . As the gap between Smerge and Smin is enlarged , the possibility that a node representing a maximal frequent itemset is not merged with any other node becomes high . Consequently , the counts of all the maximal frequent itemsets hardly include any estimation error caused by the merged count estimation .
Like the estDec method , the estDec+ method consists of four phases : parameter updating , node restructuring , itemset insertion , and frequent itemset selection . When a new transaction Tk in a data stream Dk 1 is generated , these phases except the frequent itemset selection phase are performed in sequence . The frequent itemset selection phase is performed only when the up to date result set of frequent or maximal frequent itemsets is requested .
Parameter updating phase : The total number of transactions in the current data stream Dk is updated . Count updating & node restructuring phase : This phase is performed by traversing Qk(cid:237)1 according to the lexicographic order of the items in Tk . For each visited node m , its smallest and largest counts m.cS and m.cL may be incremented as described in Section 33 If the updated support of the shortest itemset m.eS becomes less than Ssig ie m.cL/|D|k<Ssig , the node m and all of its descendent nodes are pruned since all the itemsets represented by these nodes are turned out to be insignificant . If the updated support of the longest itemset m.eL is less than Smerge or the support difference between the itemsets m.eS and m.eL becomes greater than ( cid:303 ) ie m.cS/|D|k<Smerge or ( mcL(cid:237)mcS)/|D|k>(cid:303 ) , the node m is split . On the other hand , if the updated support of m.eL is greater than Smerge and the support difference between m.eS and and m*.eL of its parent node m* is less than or equal to ( cid:303 ) ie m.cS/|D|k(cid:149)Smerge and ( m*cL(cid:237)mcS)/|D|k(cid:148)(cid:303 ) , these two nodes m and m* are merged . Itemset insertion phase : The itemset insertion phase is performed to insert any new significant itemset which has not been maintained in Qk(cid:237)1 . As in the estDec method , every single item should be maintained by Qk(cid:237)1 . Consequently , when Tk contains any new item that is not in Qk(cid:237)1 yet , a new node m for the item i(cid:143)Tk is inserted as follows : m.(cid:306)=<i> , m.(cid:652)=<root> , m.cS = m.cL =1
( n+1) itemset e
Subsequently , any insignificant item whose current support is less than Ssig is filtered out in the transaction Tk . Let the filtered transaction be denoted by kT . The monitoring tree Qk(cid:237)1 is traversed for the filtered transaction kT once again to find out any new signifikT . By the same cant itemset induced by the items in way as in the estDec method , for each significant nitemset e=i1i2…in ( n1 ) represented by a node m of Qk , every is examined . First of all , check whether all of its nsubsets of the itemset e are currently maintained in Qk(cid:237)1 . If the above condition is satisfied , the current support of the itemset e is estimated as as , a new node w described in Section 2 . If corresponding to the itemset e is inserted to Qk . The detailed description of this estimation process is presented in [ 4 ] . The entries of the new node w are initiated as follows : which eC )(ˆ
)(ˆ eC sigS i
( cid:137 ) ffi1 n is
( cid:143 )
T k e w.(cid:306)=<in+1> , w(cid:652)=<mq> , wcS=wcL=
)(ˆ eC where q denotes the item list index of the item in in the node m . Maximal frequent itemset selection phase : This phase retrieves all the currently frequent or maximal frequent itemsets by traversing the monitoring tree Qk . As in the estDec method , all the nodes whose largest counts cL are less than |D|k*Ssig can be pruned altogether by traversing the entire monitoring tree . It is called a force pruning operation , and can be performed periodically . traverse(m , mp , q , T , y ) mp : the parent node of a node m T[k ] : the kth item of a transaction T in lexicographical order q : the item list index of the last leaf level item T[y(cid:237)1 ] in node mp
1 if m.(cid:652)[1 ] = mp.q and m.(cid:306)[1 ] = T[y ] then 2 m.cL ( cid:312 ) m.cL + 1 ; 3 if ( m.cL / |D|k ) < Ssig then 4 pruning m ; // eliminate m and all of its descendent nodes 5 else 6 y ( cid:312 ) y + 1 ; x ( cid:312 ) 2 ; 7 ci1 ( cid:312 ) m.(cid:306)[1 ] ; 8 ci2 ( cid:312 ) find_com_item(m.(cid:306 ) , x , T , y ) ; 9 while m.(cid:652)[ci2 ] = m.v and x ( cid:148 ) |(cid:306)| and y ( cid:148 ) |T| do 10 if ci2 is a leaf level item then /* v m.(cid:306)[ci1 ] */ 11 if x = |(cid:306)| then 12 m.cS ( cid:312 ) m.cS + 1 ; 13 if ( mpcL(cid:237)mcS)/|D|k(cid:148 ) ( cid:303 ) and m.cS/|D|k(cid:149 ) Smerge then 14 node_merge(mp , m ) ; 15 if ( mcL(cid:237)mcS)/|D|k>(cid:303 ) then 16 node_split(m ) ; 17 if an unvisited child mc of m 18 traverse(mc , m , w , T , y ) ; /* m.(cid:306)[ci2]w */ 19 else return ; 20 else 21 ci1 ( cid:312 ) ci2 ; 22 ci2 ( cid:312 ) find_com_item(m , ( cid:306 ) , x , T , y ) ; find_com_item(m.(cid:306 ) , x , T , y ) returns the first common item ci in the items m.(cid:306)[i ] ( x(cid:148 ) i(cid:148 ) |m.(cid:306)| ) and T[j ] ( y(cid:148 ) j(cid:148 ) |T| ) where x and y are updated , st ( cid:306)[x(cid:237)1]=T[y(cid:237)1]=ci
Figure 4 . Traverse operation
42 Adaptive Memory Utilization
Since information embedded in a data stream is more likely to be changed over time , the number of currently significant itemsets is continuously varied . However , the size of memory space for a CP tree is confined . In order to minimize the estimation error caused by the merged count estimatioin , it is very important to keep the value of ( cid:303 ) as small as possible . The size of a CP tree is inversely proportional to the value of ( cid:303 ) . In order to adaptively control the memory utilization of the estDec+ method , the value of ( cid:303 ) should be dynamically changed in the parameter update phase of the estDec+ method .
Based on the ratio of the current memory usage over given confined memory space , the value of ( cid:303 ) is dynamically changed in the parameter updating phase of the estDec+ method . Let MU and ML denote the upper and lower bounds of desired memory usage respectively for given confined memory space MA . Whenever the current memory usage MC satisfies the following conditions , the new value ( cid:303)new of a merging gap threshold is adjusted adaptively as follows : new(cid:71 ) = old
( cid:173 ) ( cid:71 ) ( cid:176 ) ( cid:174 ) ( cid:71 ) ( cid:176)(cid:175 ) ffi old
M if M if
C
C
M M
U
L
M
(
A
M
U
M
L
)0 where denotes the step wise increment of ( cid:303 ) for each adaptation and is defined by a user . As the values MA(cid:237)MU and MU(cid:237)ML become larger , the value of ( cid:302 ) can also be larger . As long as the current memory usage MC of a CP tree becomes greater than the upper bound MU , the value of ( cid:303 ) is increased . As a result , more nodes can be merged and the size of the CP tree is reduced . On the other hand , when MC becomes less than the lower bound ML , the value of ( cid:303 ) is decreased to enhance the mining accuracy of the CP tree , so that the size of the CP tree is increased . By setting the lower bound ML high enough , the memory utilization of the estDec+ method is kept high . On the other hand , by setting the upper bound MU low enough , the estDec+ method can be executed without causing any memory overflow .
5 . Performance Evaluation
In this section , the performance of the estDec+ method is analyzed by two data sets : T10I4D1000K and WebLog . The data set T10I4D1000K is generated by the same method as described in [ 2 ] . The data set WebLog is a real web page access log data . The con
Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 )
1550 4786/05 $20.00 © 2005 IEEE
)
B M
( e z i s y r o m e M
100
80
60
40
20
200
150
100
50
)
B M
( e z i s y r o m e M
Smerge=0.003 Smerge=0.007 Smerge=0.03
Smerge=0.003 Smerge=0.007 Smerge=0.03
) 4 0 1 x (
E S A
120
100
80
60
40
20
0
) 4 0 1 x (
E S A
15
10
5
0
Smerge=0.003 Smerge=0.007 Smerge=0.03
100
)
B M
( e z i s y r o m e M
80
60
40
20
D10I4D1000K D10I4D1000K_R D10I4D1000K_C
) 4 0 1 (
E S A
15
10
5
0
D10I4D1000K D10I4D1000K_R D10I4D1000K_C
0.001 0.005 0.01 0.03 0.05 0.07 0.1
Merging gap threshold ( cid:303 )
0.001 0.005 0.01 0.03 0.05 0.07 0.1
0.001 0.005 0.01 0.03 0.05 0.07 0.1
Merge gap threshold ( cid:303 )
Merging gap threshold ( cid:303 )
0.001 0.005 0.01 0.03 0.05 0.07 0.1
Merging gap threshold ( cid:303 )
0
0.01 0.01 0.03 0.05 0.07 0.1 Mergin gap threshold ( cid:303 )
( a ) Memory Usage
( b ) Mining accuracy of frequent itemsets
( c ) Mining accuracy of maximal frequent itemsets
( d ) Memory Usage
( e ) Mining accuracy of maximal frequent itemsets
Figure 5 . Performance of the estDec+ method by varying ( cid:303 ) estDec ( cid:303 ) = 0.001 , Smerge = 0.03 ( cid:303 ) = 0.001 , Smerge = 0.01 ( cid:303 ) = 0.01 , Smerge = 0.01 estDec ( cid:303 ) = 0.001 , Smerge = 0.01
( cid:303 ) = 0.001 , Smerge = 0.03 ( cid:303 ) = 0.01 , Smerge = 0.01
10
)
% i
( e t a r g n s u y r o m e M
100
80
60
40
20
0
) 5 0 1 (
E S A
8
6
4
2
0 estDec ( cid:303 ) = 0.001 , Smerge = 0.03 ( cid:303 ) = 0.001 , Smerge = 0.01 ( cid:303 ) = 0.01 , Smerge = 0.01
) 5 0 1 (
E S A
5
4
3
2
1
0 estDec ( cid:303 ) = 0.001 , Smerge = 0.03 ( cid:303 ) = 0.001 , Smerge = 0.01 ( cid:303 ) = 0.01 , Smerge = 0.01 d n o c e s o r c M i
100
80
60
40
20
0 estDec ( cid:303 ) = 0.001 , Smerge = 0.03 ( cid:303 ) = 0.001 , Smerge = 0.01 ( cid:303 ) = 0.01 , Smerge = 0.01
0.3
0.5
0.7
S sig ( x S min )
0.9
0.1
0.5
0.3 S sig ( x S min )
0.7
0.9
0.1
0.3
0.5
0.7 S sig ( x S min )
0.9
0.1
0.3
0.5
0.7 S sig ( x S min )
0.9
0.1
0.5
0.3 S sig ( X S min )
0.7
0.9
0
0
0.1
( a ) Memory Usage
( b)Memory requirement
( c ) Mining accuracy of frequent itemsets
( d ) Mining accuracy of
( e ) Runtime maximal frequent(cid:71)(cid:144)(cid:155)(cid:140)(cid:148)(cid:154)(cid:140)(cid:155)(cid:154)(cid:71)(cid:71 )
Figure 6 . Performance comparison of the estDec+ method with the estDec method
0.06
0.05
0.04
( cid:303 )
0.03
0.02
0.01
0
0
( cid:302)=0.00005
( cid:302)=0.0001
)
B M
( e z i s y r o m e M
120
100
80
60
40
20
0 estDec+ ( (cid:302)=0.00005 ) estDec estDec+ ( (cid:302)=0.0001 )
)
5 0 1 x
(
E S A
40
35
30
25
20
15
10
5
0 estDec+ Frequent ( (cid:302)=0.00005 ) estDec+ Maximal ( (cid:302)=0.00005 ) estDec+ Frequent ( (cid:302)=0.0001 ) estDec+ Maximal ( (cid:302)=0.0001 )
1
2 TID ( x 10 5 )
3
4
5
0
1
2
3
TID ( x 10 5 )
4
5
0
1
3
2 TID ( x 10 5 )
4
5
Figure 7 . Performance of the estDec+ method with a dynamic adaptation technique of ( cid:303 )
( a ) Change of
( b ) Memory usage
( c ) Mining accuracy secutive web pages accessed by a user are considered as a semantically atomic unit of activities , ie , a transaction . The total number of items , ie , the number of web pages , is 545 . The minimum , maximum , and average lengths of a transaction in the data set WebLog are 2 , 30 , and 5 respectively . In addition , the total number of transactions is 500,000 . In all experiments , the transactions of a data set are looked up one by one in sequence to simulate the environment of an online data stream and a force pruning operation is performed in every 1000 transactions . In addition , the value of Smin is set to 0.001 and the count estimation function f(m,j ) is defined as follows : jmf , (
) c
( c
S
)
L
| e ji
|
| e
|
S e
|
L
|
| e
S
( cid:166)(cid:166 )
1 l l
1 l
1
|
1 l
All experiments are performed on a 1.8 GHz Pentium PC machine with 512MB main memory running on Linux 7.3 and all programs are implemented in C .
Figure 5 shows the performance of the estDec+ method on the data set T10I4D1000K by varying ( cid:303 ) . The value of Ssig is set to 0.1Smin in this experiment . The memory usage of the estDec+ method is illustrated in Figure 5 (a ) after the memory usage is stablized . To measure the accuracy of the estDec+ method , a term average support error ASE(R2|R1 ) [ 4 ] is employed . As
Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 )
1550 4786/05 $20.00 © 2005 IEEE the value of ASE ( R2|R1 ) gets smaller , the mining result R2 is more similar to R1 . In Figure 5 (a ) , the memory usage of the estDec+ method gets smaller as the value of ( cid:303 ) gets larger since more nodes are merged . The ASE(RestDec+|RApriori_MFI ) in Figure 5 (c ) is much smaller than the ASE(RestDec+|RApriori ) in Figure 5 (b ) since most of maximal frequent itemsets are more accurately monitored without merged count estimation . As the value of Smerge is set to be smaller for the same value of ( cid:303 ) , the ASE is increased but the memory usage is decreased . This is because more nodes are merged as the value of ( cid:303 ) is increased or the value of Smerge is decreased . Figure 5 (d ) and 5 (e ) shows that estDec+ method is order independent . For this experiment , T10I4D1000K_R is generated with the reversely ordered transactions of T10I4D1000K while T10I4 D1000K_C is generated with two consecutive datasets , ie , one with the transactions having odd number TID and the other with the transactions having even number TID . The value of Smerge is set to 0003
In Figure 6 , the performance of the estDec+ method is closely compared with that of the estDec method on the data set T10I4D1000K In this experiment , the value of ( cid:303 ) is fixed . For the same value of Ssig , the memory usage of the estDec+ method is always less than that of the estDec method . Figure 6 (b ) shows the memory requirement of the estDec+ method . The requirement is represented by the ratio of the size of memory space required by the estDec+ method over that required by the estDec method to execute the same dataset . By varying the value of Ssig , Figure 6 (c ) and Figure 6 (d ) illustrate the mining accuracy of finding frequent and maximal frequent itemsets respectively . When the value of Smerge gets higher , the ASE of the estDec+ method becomes closer to that of the estDec method since less nodes corresponding to maximal frequent itemsets are merged . In Figure 6 (e ) , the average processing time per transaction is compared . It is inversely proportional to the memory usage . This is mainly because the processing time to interpret the information of the itemsets in a node of a CP tree becomes longer as either the value of ( cid:303 ) is larger or the value of Smerge is smaller .
Knowledge embedded in a data stream is more likely to be changed over time [ 5 ] . Figure 7 shows how the estDec+ method can adaptively maximize the utilization of confined memory space . In this experiment , the data set WebLog is used . The values of Smin , Ssig , and Smerge are set to 0.003 , 0.1Smin , and 0.003 respectively . Furthermore , the values of MU , ML , and MA are set to 95MB , 85MB , and 100MB respectively . The initial value of ( cid:303 ) is set to 0 and two different values of a user defined increment ( cid:302 ) are used . The estDec method fails to be executed after the 1105th transaction . This is because the size of its prefix tree becomes larger than that of the confined memory space . On the other hand , there is no problem to execute the estDec+ method by adjusting the value of ( cid:303 ) adaptively for the same situation . Figure 7 (a ) illustrates the trace of the value of ( cid:303 ) in this experiment . As shown in Figure 7 (b ) , the memory usage of the estDec+ method is kept between MU and ML at all times . As expected , the value of ( cid:303 ) is more widely fluctuated for the larger value of ( cid:302 ) . Figure 7 (c ) shows the ASEs of the the estDec+ method in finding frequent and maximal itemsets . The ASE of finding frequent frequent itemsets is much higher than that of finding maximal frequent itemsets .
6 . Concluding Remarks
For a given value of Smin , the total number of frequent itemsets can be varied continuously over time without any upper bound . On the other hand , the up to date mining result of an on line data stream should be traced in real time and available at any moment . For this reason , the current counts of all the significant itemsets are kept in main memory by the estDec method . However , it is impossible to guarantee all of them to be maintained in confined memory space at all times . To cope with this problem , a CP tree is proposed in this paper . Although the proposed estDec+ method can be used to find either frequent itemsets or maximal frequent itemsets , it provides better accuracy for finding maximal frequent itemsets as illustrated in the experiments . By making the value of a merging threshold Smerge large enough , the estDec+ method can find the set of maximal frequent itemsets as accurately as the estDec method can do while the memory usage can be minimized . Although the average processing time of the estDec+ method is slightly increased , the proposed method successfully provides a way to accommodate the unpredictable number of significant itemsets generated in the future of a data stream not in a secondary storage but in confined memory space .
References
[ 1 ] RC Agarwal , CC Aggarwal , and VVV Prasad . Depth First Generation of Long Patterns . In Proc . of the 6th ACM SIGKDD , pp . 108 118 , 2000 .
[ 2 ] R . Agrawal and R . Srikant . Fast Algorithms for Mining Association Rules . In Proc . of the 20th VLDB , pp . 487499 , 1994 .
[ 3 ] S . Brin , R . Motwani , JD Ullman , and S . Tsur . Dynamic Itemset Counting and Implication Rules for Market Basket Data . In Proc . of the ACM SIGMOD , pp . 255 264 , 1997 . JH Chang and WS Lee . Finding recent frequent itemsets adaptively over online data streams . In Proc . of the 9th ACM SIGKDD , pp . 487 492 , 2003 .
[ 4 ]
[ 5 ] G . Dong , J . Han , LVS Lakshmanan , J . Pei , H . Wang , and PS Yu . Online Mining of Changes from Data Streams : Research Problems and Preliminary Results . In Proc . of the Workshop on Management and Processing of Data Streams , 2003 .
[ 6 ] M . Garofalakis , J . Gehrke , and R . Rastogi . Querying and Mining Data Streams : You Only Get One Look . In tutorial notes of the 28th VLDB , 2002 .
[ 7 ] S . Guha and N . Koudas . Approximating a Data Stream for Querying and Estimation : Algorithms and Performance Evaluation . In Proc . of the 18th ICDE , pp . 567576 , 2002 .
[ 8 ] A . Hafez , J . Deogun , and V . V . Raghavan . The Item Set Tree : A data Structure for Data Mining . In Proc . of the 1st International Conference on Datawarehousing and Knowledge Discovery , pages 183 192 , 1999 .
[ 9 ] G . Hulten , L . Spencer , and P . Domingos . Mining TimeChanging Data Streams . In Proc . of the 7th ACM SIGKDD , pp . 97 106 , 2001 .
[ 10 ] D . Lambert and JC Pinheiro . Mining a Stream of Transactions for Customer Patterns . In Proc . of the 7th ACM SIGKDD , pp . 305 310 , 2001 .
[ 11 ] GS Manku and R . Motwani . Approximate Frequency Counts over Data Streams . In Proc . of the 28th VLDB , pp . 346 357 , 2002 .
Proceedings of the Fifth IEEE International Conference on Data Mining ( ICDM’05 )
1550 4786/05 $20.00 © 2005 IEEE
