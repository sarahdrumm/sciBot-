Mining Generalized Association Rules and Sequential Patterns Using
SQL Queries
Shiby Thomas
Database Systems R & D Center
CISE Department
University of Florida , Gainesville FL 32611
Sunita Sarawagi
IBM Almaden Research Center
650 Harry Road , Sail Jose , CA 95120 sunita@almaden , ibm . corn sthomas@ciseufledu
Abstract
Database integration of mining is becoming ininstallation of larger creasingly important with tile and larger data warehouses built around relational database technology . Most of the commercially available mining systems integrate loosely ( typically , through an ODBC or SQL cursor interface ) with data stored in DBMSs . In cases where the mining algorithm makes nmltiple passes over the data , it is also possible to cache the data in fiat files rather than retrieve multiple times from the DBMS , to achieve better performance . Recent studies have found that for association rule mining , with carefully tuned SQL forinulations it is possible to achieve performance comparable to systems that cache the data in files outside the DBMS . The SQL implementation has potential for offering other qualitaUve advantages like automatic parallehzation , development ease , portability and inter operability with relational operators . In"this paper , we present several alternatives for formulating as SQL queries association rule generalized to handle items with hierarchies on them and sequential pattern mining . This work illustrates that it is possible to express computations that are significantly more complicated than simple boolean assom%tions , in SQL using essentially the same franmwork .
1 Introduction
Data mining on large data warehouses for nuggets of decision support knowledge is becoming crucial for Most of the commercial business organizations . "knowledge discovery" tools integrate loosely with data stored in DBMSs , typically through a cursor interface . The integration of mining with database querying will facilitate leveraging the query processing capabilities of the DBMS for mining . rule mining as SQL queries .
There have been a few research efforts to tightly integrate mining with databases ( Agrawal & Shim 1996 ) . Several language extensions have also been proposed to extend SQL with inining operators . Recently , researchers have addressed the issue of expressing boolean association ( Sarawagi , Thomas , & : Agrawal 1998 ) presents several architecfor integrating boolean association tural alternatives databases . They develop rule mining with relational several SQL formulations for association rule mining tuned SQL formulations and show that with carefully it is possible to achieve performance comparable to mining systems that cache the data in fiat files .
In this paper , we present various alternatives for formulating generalized association Agrawal 1995 ) and sequential pattern rule ( Srikant ( Srikant
Copyright @1998 , American Association for Artificial Intelligence ( wwwaaaiorg ) All rights reserved .
344 Thomas information as well as data to discover association
Agrawal 1996 ) mining as SQL queries . These mining techniques make use of additional about the application more useful knowledge . In generalized rules , application specific knowledge in the form of taxonomies ( is a hierarchies ) over items are used to disrules , where as sequential patcover more interesting tern mining utilizes the time associated with the transaction data to find frequently occurring patterns . One of the advantages of SQL based mining algorithms is fast and easy development since they are declaratively as a set of SQL queries . This work shows specified how the boolean association rule framework developed in ( Sarawagi , Thomas , & Agrawal 1998 ) can be easily augmented with non trivial to handle complex mining tasks . We develop SQL 92 formulations as well as those which utilizes the object relational extensions of SQL ( SQL OR ) . Although the SQL 92 formulations are slow compared to SQL OR , the use of just the standard SQL features makes them more portable across commercial DBMSs . The SQL OR approaches leverages the object relational performance . extensions to improve extensions
The rest of the paper is organized as follows . We present SQL fornmlations of generalized association rule mining in Section 2 . In Section 3 , we briefly introduce sequential pattern mining and develop several SQL based implementations . We report some of the resuits of our performance experiments in Section 4 and conclude in Section 5 .
2 Generalized Association
Rules applications taxonomies ( is a hierarIn most real life The taxonomy chies ) over the items are available . shown in Figure 1 says that Pepsi is a soft drink isa beverage etc . In general , a taxonomy can be represented as a directed acyclic graph ( DAG ) . Given a set of transactions T each of which is a set of items , and a taxonolny Tax , the problem of mining generalized association rules is to discover all rules of the form X + Y , with the user specified ininimum support and minimum confidence . X and Y can be sets of items at any level of the taxonomy , such that no item in Y is an ancestor of any item in X ( Srikant & Agrawal 1995 ) . For example , there might be a rule which says that "50 % of transactions that contain Soft drinks also contain Snacks ; 5 % of all transactions contain both these items" . Input format The taxonomy is represented as a table Tax with the schema , ( parent , child ) . Each record in Tax corresponds The transaction identifier ( tid ) and item identifier ( item ) . to an edge in the taxonomy DAG . table T has two attributes : transaction
Parent Beverages Beverages Soft drinks Soft drinks Alcoholic Snacks Snacks drinks
Child Soft drinks Alcoholic Pepsi Coke Beer Pretzels Chocolate drinks bar
Figure 1 : A sample taxonomy and the corresponding taxonomy table
( Srikant & Agrawal 1995 ) presents several algo and EstMerge . We rithms : Basic , Cumulate , Stratify picked Cumulate for our SQL formulations since it has the best performance . Stratify and EstMerge are sometimes marginally better but they are far too complicated to merit the additional development cost . Cumulate has the same basic structure as the Apriori algorithm ( Agrawal et al . 1996 ) for boolean associations . It makes multiple passes over the data where in the kth pass it finds frequent itemsets of size k . Each pass consists of two phases : In the candidate generation phase , the frequent ( k 1) itemsets , Fk 1 is used as the seed set to generate candidate k itemsets ( Ck ) that are poIn the support counting phase for tentially each itemset t E Ck , the number of extended transactions ( transactions augmented with all the ancestors of its items ) that contains t is counted . At the end of the pass , the frequent candidates are identified yielding Fk . The algorithm terminates when Fk or Ck+l becomes empty . frequent .
The above basic structure is augmented with a few optimizations . The important ones are pruning itemsets containing an item and its ancestor and pre computing for each item . We extend the SQL based boolean association rule framework in ( Sarawagi , Thomas , & Agrawal 1998 ) with these optimizations . the ancestors
Ancestors
Pre computing
In Section 2.1 , we present the SQL based ancestor pre computation . Candidate generation and support counting are presented in Sections 2.2 and 2.3 respectively . 2.1 We call ~ an ancestor of x if there is a directed path from to x in Tax . The Ancestor table is primarily used for ( i ) pruning candidates containing an item and its ancestor and ( ii ) extending the transactions by adding all the ancestors of its items . We use the transitive closure operation in SQL3 as shown in Figure 2 for the ancestor computation . The result of the query is stored in table Ancestor having the schema ( ancestor , descendant ) .
Candidate
Generation
2.2 The candidate generation and pruning to obtain Ck from Fk 1 is expressed as a k way join between the F~ l ’s use the same formulation except that we need to prune from Ck itemsets containing an item and its ancestor . ( Srikant & Agrawal 1995 ) proves that this pruning in ( Sarawagi , Thomas , & Agrawal 1998 ) . insert into Ancestor with R Tax ( ancestor , descendant ) as
( select parent , child from Tax union all select p.ancestor , c.child from R Tax p , Tax c where p.descendant = c.parent ) select ancestor : descendant from l~ Tax
R Tax
Tax tTax
Figure 2 : Pre computing Ancestors needs to be done only in the second pass ( for C2 ) . the SQL formulation as shown in Figure 3 , we prune all ( ancestor , descendant ) pairs from C2 which is generated by joining F1 with itself . insert into C2 ( select Iiiteml,I2iteml where Ii.iteml < I2.iteml ) except ( select ancestor , descendant from Ancestor union select descendant , ancestor from Ancestor ) from F1 I1 , F1 /2
EXCEPT
11.itcm I < I2.itemlmlj[~>~lancestor,d~
UNIO~ ~descendant ,
FI II Figure 3 : Generation of C2
FI 12 Ancestor
Ancestor
2.3
Support itemsets counting to find frequent two categories of SQL implementations We consider the SQL apbased on SQL 92 and SQL OR . All proaches developed for boolean associations ( Sarawagi , Thomas , & Agrawal 1998 ) can be extended to handle taxonomies . However , we present only a few representative approaches in this paper . In particular , we consider the KwayJoin approach from SQL 92 and llertical and GatherJo±n Support K way join the candidate itemsets Ck with k copies of an extended transaction table T* ( defined below ) , and follow it up with a group by on the itemsets . Query to generate T~
In each pass k , we join using SQL 92 from SQL OR . counting select item , tid from T union select distinct A.ancestor as item , T.tid from T , Ancestor A where A.descendant = T.item
T¯ t
UNION
’~ TAicL A.ancestor as item~
Figure 4 : Transaction extension subquery
T
AnCestor A table T* is obtained by The extended transaction augmenting T to include ( rid , item ) entries for all ancestors of items appearing in T . This can be formulated as a SQL query as shown in Figure 4 . The select distinct clause is used to eliminate duplicate records due to extension of items with a common ancestor . Note that for this approach we do not materialize T* . Instead we
KDD 98 845 use the SQL support for common subexpressions ( with construct ) to pipeline the generation of T* with tile join operations ( Figure 5 ) . Tile pipelining idea can also used for other queries involving "insert mate,’ialization . into" to avoid insert into Fa . with T’(tid , item ) as ( Query for select item ~ , itcmk , count(* ) from C~ , T" t~ , T" tk where t~.item = Ck.item~ and and t~.item Ca.itemk and t~.tid = t2.tid and and ta_~tid = tk.tid group by item~,item2 having count(* ) > :minsup item~ t ck ,,~ml ~,1 il=m
/
f ,i
¯ k l ,e
Figure 5 : Support Counting by K way join
Subquery optimization The basic KuayJo±n approach can he optimized to make use of common prefixes between the itemsets in Ck by splitting the support counting phase into a cascade of k subqueries . The subqueries in this case are exactly similar to those for boolean associations presented in ( Sarawagi , Thomas , & Agrawal 1998 ) except for the use of T* instead of T . Support counting section we present two approaches that make use of the object relational shown in Gatheraoin Figure 6 , which is based on the use of table functions ( Lohman et al . 1991 ) , generates all possible kitem combinations of extended transactions , joins them with the candidate table Ck and counts the support by grouping the join result . using SQL OR In this featm’es of SQL .
Join approach
The Gather insert into Fk select iteml,,itemk , count(* ) fl’om 6’k , ( select t2T itml , , t2.T itmk from T" tt , table ( GatherComb K(tl.tid , tt.item ) ) as where t2.T_itm , = Ck.iteml and and t,T_itm# = Ck.itemk group by Ck.iteml , , Ckitem , having count(* ) > :minsup counl(’ ) ~ ;nlLnstlp flroup b~," qrabt~ ¢~cu~a ~alhel~r’a~nb . N :
~}M~et by
Figure 6 : Support Counting by Gather Join fT
The extended transactions T" ( defined in 2.3 ) are passed to the table function GatherComb K in the ( tid , item ) order . A record output by the table function is a k item combination supported by a transaction and has k attributes T_itm~,,T_itm~ The special optimization for pass 2 and the variations of the GatherJo±n approach , and Horizontal ( Sarawagi , Thomas , & Agrawal 1998 ) ) are also applicable here . namely GatherCount , GatherPrune ( refer
346 Thomas transactions are first Vertical In this al/proach , tile format by creating for each converted into a vertical containing all tids that contain item a BLOB ( tid list ) that item . The support for each itemset is counted by intersecting the tid lists of all its items . The tid list of leaf uode items can be created using a table function which collects all the tid ’s for each item and outputs records which are stored in the table ( item , lid list ) TidTable . We present the tid list of the interior nodes in the taxonomy DAG . two approaches for creating
Tim first approach is based on doing a union of the of an interior node . For every descendant ’s tid lists of node x , table flmction TUniou collects leaf nodes reachable from x , union them and outall tile puts tile tid list for x . In this approach , lid lists have to be created and materialized for every leaf node item irrespective of its support . This could get expensive especially when the number of items is large . the lid lists
The second approach is to pass T" ( defined in 2.3 ) the Gather table puts lid lists function as shown below which out for all the items in the taxonomy . insert into TidTable select t>item , t>tid list from T" & , table(Oather(t~.item , t~.tid , The SQL queries for support counting are the same as ( Sarawagi , Thomas , & Agrawal
:minsup ) ) as for boolean associations 1998 ) .
3 Sequential
Patterns is is an ordered list
Given a set of data sequences each of which is a list of transactions ordered by the transaction time , the problem of mining sequential patterns is to discover all sequences with a user specified minimum support . contains a set of items . A sequenEach transaction tial pattern ( sequence ) of itemsets . The itemsets that are contained in the sequence are called elements of the sequence . For example , is a sequence with two ( (eomputer , modeuz)(printer)} elements ( computer , modem ) and ( printer ) . The support of a sequential pattern the number of datasequences that coutain the sequence . A sequential pattern can be further qualified by specifying maximum and/or minimum time gaps between adjacent elements and a sliding time window within which items are considered part of the same sequence element . These time constraints are specified by three parameters , max gap , rain gap and window size . Input format The input has three colunm attributes : transaction ( item ) . The data sequence table contains multiple rows corresponding to different items that belong to transactions in the data sequence . Output format The output of frequent sequences . A sequence which is represented as a tuple in a fixed width table consists of an ordered list of elements where each element is a set of items . The schema of the fl’equent sequences table is ( item~ , eno~,,item~ , eno~,len ) . The len attribute gives the length of the sequence , ie , the total nun> ber of items in all the elements of the sequence . Tile eno attributes stores the element number of the corresponding items . For sequences of smaller length , the extra colmnn values are set to NULL . For example , if k = 5 , tile sequence ( (computer , modem)(printer ) ) is rep table D of data sequences ( sid ) , time ( time ) and item identifier sequence identifier is a collection resented by the tuple ( computer , 1 , modem , I , printer , 2 , NULL , NULL , 3 ) .
In Section 3.1 , we briefly introduce the GSP algo
GSP Algorithm rithm for sequential pattern mining . In Section 3.2 , we present the SQL based GSP candidate generation and in Section 3.3 we present the support counting procedure . 3.1 The basic structure of the GSP algorithm ( Srikant Agrawal 1996 ) is similar to that of the Cumulate algorithm outlined in Section 2 , although the specific details are quite different which are described next . 3.2 Candidate In each pass k , the candidate k sequences Ck are generated from the frequent ( k 1 ) sequences Fk 1 . Ck has the same schema of frequent sequences explained above , except that we do not require the len attribute since all the tuples in Ck have the same length k .
Generation
Candidates are generated in two steps . The join step generates a superset of Ck by joining Fk 1 with itself . A sequence Sl joins with s2 if the subsequence obtained item of sl is the same as the one by dropping the first obtained by dropping the last item of s2 . This can be e.xpressed in SQL as follows : insert into Ck select I1 .iteml , I1 .enol , , I1 .itemk_ 1 , I~ .enok 1 , I2.itemk 1 , I1 .enok 1 + I2.enok 1 I2.enok 2 from Fk 1 I1,Fk 1 I2 where Ii.item2 = I2.iteml and and
Ii.itemk i = I2.itemk 2 and Ii.eno3 Ii.eno2 = I2.eno2 I2.enol and and Ii.enok 1 Ii.enok 2 = I2.enok 2 I2.enok 3
In the above query , subsequence matching is expressed as join predicates on the attributes of Fk 1 . Note the special join predicates on the eno fields that ensure that not only do the joined sequences contain the same set of items but that these items are grouped in the same is the manner into elements . The result of the join sequence obtained by extending Sl with the last item of s2 . The added item becomes a separate element if it was a separate element in s2 , and part of the last element of sl otherwise . In our representation of the candidate sequence , enok 1 and enok 2 determine if the added item is a separate element . all candidate that have a non frequent contiguous ( k 1) subsequence are deleted . We perform both the join and prune steps in the same SQL statement by writing it as a k way join , to the candidate generawhich is structurally tion query for association rules ( Sarawagi , Thomas , Agrawal 1998 ) . For any k sequence there are at most k contiguous subsequences of length ( k 1 ) for which Fk 1 needs to be checked for membership . Note that all ( k 1) subsequences may not be contiguous because the max gap constraint between consecutive elements .
In the prune step , sequences similar
While joining F1 with itself to get C2 , we need to generate sequences where both the items appear as a single element as well as two separate elements .
3.3
Support sequences counting to find frequent
In each pass k , we use the candidate table Ck and the input data sequences table D to count the support . We counting based on SQL 92 and consider SQL implementations SQL 0R . Support K way join This approach KwayJoin approach for association except for these two key differences : 1 . We use select distinct before the group by to ensure to the rules ( section 2.3 ) is very similar using SQL 92 that only distinct data sequences are counted .
2 . Second , we have additional predicates PRED(k ) between sequence numbers . The predicates PRED(k ) is a conjunct ( and ) of terms pij(k ) corresponding to each pair of items from Ck . Pij ( k ) is expressed as :
( Ckenoj=Ckenoi and abs(dj.time di.time ) < window size ) or ( Ck.enoj = Ck.enol + 1 and dj.time di.time <_ max gap and dj.time di.time > min gap ) or ( Ck.enoj > Ck.enoi + 1 ) Intuitively , these predicates check ( a ) if two items of candidate sequence belong to the same element , then the difference of their corresponding transaction times is at most window size and ( b ) if two items belong adjacent elements , then their transaction most max gap and at least rain gap apart . Subquery optimization tion for association rules can be applied for sequential patterns also by splitting the support counting query in pass k into a cascade of k subqueries . The predicates Pij can be applied either on the output of subquery Qk or sprinkled across the different subqueries .
The subquery optimiza times are at counting to the Vertical using SQL OR
Support Vertical This approach is similar approach in Section 23 insert into Fk select t.iteml , teno~ , ,t.itemk , t.enok , cnt from ( select item1 , enol,,itemk , CountIntersect K(Ckenol , . . , Ck.enok , dls list , dk.s list , window size,min gap,max gap ) as cnt from Ck , SlistTable dl , where dl.item = Ck.iteml and and
,SlistTable dk enok ,
. . dk.item = Ck.itemk ) as where count(* ) > :minsup ilemlitemk , enolenok , cnt cnl > :minsup lcnt
Counllnlerseel
K ( UDF )
Ck,ileml = d|.ilcm Ck ilemk ~ i em
I dls lisldk,~list
Ck
SlistTablc dl , , SlislTablo dk
Figure 7 : Support Counting by Vertical
For each item , we create a BLOB is list ) containing time ) pairs corresponding to that item . The all ( sid , sequence table D is scanned in the ( item , sid , time ) order and passed to the table function Gather , which collects the ( sid , time ) attribute values of all tuples D with the same item in memory and outputs a ( item , s list ) pair for all the items that meet the minimum support criterion . The s lists are maintained sorted using sid as the major key and time as the minor key , and is stored in a new SlistTable with the schema ( item , s list ) .
In the support counting phase , we collect of all the items of a candidate and intersect the s lists them using
KDD 98 347 a UDF CountIntersect K ( as shown ill Figure 7 ) t( , detm’mine the data sequences coutaining that sequence . For determining whet}mr a candidate is contained in tile data sequence , we use an algorithm similar to tim one described in ( Srikant & Agrawal 1996 ) . to the subquery optimization
Tile intersect operation can also be decomposed to share it across sequences having colnulon prefixes similar in the KwayJoin approach . Gather Join The Gather Join approach for association rules can be extended to mine sequential patterns also . We generate all possible h sequences using a Gather table function , them with Ck and group the join result to count the support of the candidate sequences . Tile time constraints are checked on the table function output using join predicates PIlED(k ) in the KwayJoin approach . join
4 Performance results
In this section , we report the results of some of our performance experiments on real life datasets . We present only one set of results of generalized association rule mining clue to space limitations .
Pedormance com~l],son
OPte~ IIPass I OPass 20Pass 3 IIPass 40Pass 5 IlPa~.s 6
LL+
I + g 7sco
=
[ . ,___
"1
.I~mlr+~,l
0
I
I
" ~
.,++5+++ .,,+ oS+j
Mail order data : Total nunlber of records = 2.5 million Number of transactions = 568000 Number of items = 85161 ( leaf nodes in taxenmny DAG ) Total number of items = 228428 ( including interior nodes ) Max . depth of the taxonmny = 7 Avg . number of children per node = 1.6 Max . number of parents = 3
Figure 8 : Comparison of different SQL approaches t)reprocessing
Our experiments were performed on Version 5 of IBM DB2 Universal Server installed on a IlS/6000 Model 140 with a 200MHz CPU , 256 MB main memory and a 9 GB disk witil a measured transfer rate of 8 MB/sec . Figure 8 shows the performance of three approaches Vertical , Gather Join and Stored procedure . The tinm and the time taken chart shows tile for tile different passes . For Vertical the preprocessing time includes ancestor pre colnputation and ridlist creation times , where as for Gather Join it is just In the stored the time for ancestor pre conlputation . procedure approach , the mining algorithln is encapsulated as a stored procedure ( Chamberlin 1996 ) which runs in tile same address space as the DBMS . For the Stored procedure experiment , we used the generalized association rule implementation provided with the IBM data mining product , Intelligent Miner ( Int 1996 ) . For all tile support values , the Vertical approach performs equally well as the Stored procedure approach and on some other datasets it performed better than the
348 Thomas function and hence the effective
Tile Gather Join apStored procedure al)l)roach , large number of item l)roach is worse mainly due to tile combinations generated . In the Gather Join approach , dm extended tra~mactions are passed ~o the GatherComb table number of items per transaction gets multiplied by the average depth of the taxonomy . In the Gather Join approach , we show the performance numbers for o/fly the second pass . Note that just the time for second pass is an order of magnitude more titan time for all the passes of Vertical . The gwayJoin approach was an order of magnitude slower than the other approaches . the total
5 Conclusion and future work relational
to achieve better perfor
We addressed the problem of mining generalized association rules and sequential patterns using SQL queries . We developed SQL forlnulations based on SQL 92 and SQL OR ( SQL enhanced with object extensions ) for the two mining problems . The SQL 92 approaches use just standard SQL and are readily portable across various DBMS platforms , where as SQL OII leverages the object relational features some of which are not yet standardized mance . We also report some results of our performance experiments . This work points out that it is possible to express complex mining computations in SQL . We augmented the basic association rule framework in ( Sarawagi , Thomas , & Agrawal 1998 ) to implement generalized association rule and sequential pattern ininint . The major addition for generalized association rule was to "extend" tile table ( transform T to T’ ) . For sequential patterns , join predicates for candidate generation and support counting were significantly different . We plan to do more experimentation on different datasets to consolidate the experiences from this work . Aeknowledgements thank Rakesh Agrawal and Ramakrishnan Srikant for useful discussions . input transaction tile
We wish to
References
Agrawal , R and Shim , K . 1996 . Developing tightlycoupled data" mining applications on a relational database systenl . In Proc . of , KDD , Agrawal , R . ; Mannila . H . ; Srikm~t , R . ; Toivonen , H . ; and Verkamo , A . I . 1996 . Fast Discoxery of Association Rules . In Advances in Knowledge Discovery and Data Minin9 . AAAI/MIT Press . chapter 12 , 307 a28 . Chaml)erlilhD . 1996 . Using the New DB2 : IBM ’s ObjectRelational Database System . Morgan Kaufinann . Internationl Business Machines . 1996 . IBM Intelligent Miner User ’s Guide , Version 1 Release 1 , SH12 6213 00 edition . Lohman , G4 Lindsay , B . ; Pirahesh , H . ; and Schiefer , K . B . 1991 . Extensions to starburst : Objects , types , functions , and rules . Communications of the ACM 34(10 ) . Sarawagi , S . ; Thomas , S . ; and Agrawal , R . 1998 . Integrating Association Rule Mining w~th Relational Database Systems : Alternatives and Implications . In Proc . of the ACM SIGMOD Conference on Management of Data . Srikant , R . , and Agrawal , R . 1995 . Mining Generalized Association Rules . In Proe . of the 21st Int’l Conference on Very Large Databases . Srikant , R . and Agrawal R . 1996 . Mining Sequential Patterns : Generalizatmns and Performance Improvements . In Proe . of the Fifth Int’l Conference on Eztendin9 Database TechnoTogy .
