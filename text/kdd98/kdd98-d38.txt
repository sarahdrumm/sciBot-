Methods for Linking and Mining Massive Heterogeneous
Databases
Josd c . Pinheiro and Don X . Sun
Statistics Research
Bell Laboratories , Lucent Technologies
600 Mountain Avenue , Murray Hill , NJ 07974
Email : j cp,dxsun@bell labs.eom
Abstract
Many real world KDD expeditions involve investigation of relationships between variables in different , heterogeneous databases . We present a dynamic programming technique for linking records in multiple heterogeneous databases using loosely defined fields that allow free style verbatim entries . We develop an interestingness measure based on non parametric randomization tests , which can be used for mining potentially useful relationships among variables . This measure uses distributional characteristics of historical events , hence accommodating variable length records in a natural way . As an illustration , we include a successful application of the proposed methodology to a real world data mining problem at Lucent Technologies .
1 Introduction temporal structures . in investigating
Many large scale data analysis problems involve the investigation of relationships between variables in heterogeneous databases with different For example , one may be interested relationships between customer satisfaction with products and services provided by a company and the company ’s in house maintenance and sales records . Satisfaction surveys are generally conducted on a periodic basis and only involve a relatively small sample from the universe of customers . Maintenance and sales records , on the other hand , are collected continuously , providing massive amounts of information on all customers .
We concentrate on applications where two databases are to be combined and mined , but the methods described here extend easily to more than two databases . The scenario we consider consists of one database with massive amounts of data collected over time , with multiple records per individual and another , smaller database with a single record per individual . In Section 2 , we describe a real life example with this type of data structure referring to customer satisfaction data and maintenance records collected over several years at
Copyright ( ~)1998 , American Association for Artificial Intelligence ( wwwaaaiorg ) All rights reserved .
Lucent Technologies . This example is used throughout the different methods we present . the paper to illustrate
To link records with incomplete or missing common identifiers , we present in Section 3 a method for linking records in multiple heterogeneous databases , using loosely defined fields that allow free style verbatim entries . A dynamic programming technique is applied to compute matching probabilities and the decision thresholds are estimated from some valid records known as training data . Section 4 briefly describes the strategies for collapsing and combining databases once record linkage has been established .
The combined database is used for mining interesting relationships among variables . Usually , a large number of variables is present in the data and it is desirable to employ automatic mining techniques to select a reasonable number of potentially interesting variables for further , more detailed investigation . We present , in Section 5 , an interestingness measure , based on a non parametric randomization test , which can be used for automatic data mining . We also describe graphical methods , based on Trellis displays ( Becket , Cleveland , & Shyu 1996 ) , for summarizing the results of the data mining search and for further exploring the relationships with largest interestingness values . These methods are model free , robust to the presence of outliers , and scale up to databases of arbitrary size . Our conclusions and suggestions for further research are included in Section 6 .
2 An example a real life example that
We introduce includes databases with different temporal structures which include a customer satisfaction database and a maintenance service database collected over the past several years at Lucent Technologies .
The customer satisfaction database contains records from a quarterly sample survey of Lucent Technologies’ customers . The survey includes over twenty questions measuring customer satisfaction with various aspects of equipment and maintenance service . All questions use a 1 4 ordinal scale , with 1 meaning very dissatisfied and 4 very satisfied .
KDD 98 309
The maintenance database contains records pertain ing to any maintenance service provided by Lucent over the past several years . Records are entered in this database whenever a new maintenance service is initiated or has its status modified , amounting to several gigabytes of data per month . Dozens of variables measuring different aspects of the maintenance service cycle are included in this database . Some examples are : service duration , severity of the problem , and type of equipment involved .
The objectives of the data mining investigation are , first , to verify if any relationships exist and , if so , to identify which customer satisfaction variables are more sensitive to maintenance service variables and which maintenance service variables most affect customer satisfaction . These can be used to determine potential areas of intervention for improving services to meet or exceed customer expectations .
3 Record linkage
Ill this section , we present a general method for matching verbatim text fields which is used to link records across different databases . First , we propose a text similarity measure between two sequences of characters based on a dynamic programming algorithm . The similarity measure ranges from 0 ( indicating that the fields are completely dissimilar ) to 1 ( exact match ) . Based the similarity measures for each corresponding pair of fields , we build a classification model using logistic regression to predict whether the two records are matched or not . measure
3.1 Text similarity To find tile best match of two text strings , we propose a text similarity measure . For a given text string , we use a vector to represent all the characters of the string with the consecutive space characters collapsed into one . For two given sequences ai , i = 1 , ¯ ¯ . , n and bi , i = 1 , ¯ ¯ . , m , our objective is to find a map
M(. ) : {1,,n} ~
{1, ,m,0} such that
E’,’= s(a , , bM(, ) )
( , + m)/2 is maximized . The map function satisfies that M(i ) > M(j ) for any pair of ( i , M(i ) ¢ O , and M(j ) ~ O . The character function s( . , . ) is defined the condition j ) with i > j , similarity s(ai , bj )
1 , if ai = bi,j :P O ;
O , otherwise .
3.2 Prediction Once the similarity measures are calculated for the corresponding fields of two records , they can be used as tile basis for predicting whether the match is true or false . Let xl,,x~ , be the variables representing the text similarity measures for all the verbatim fields that appear in both databases , and y be the binary variable indicating if the match is actually true or false . We use a simple logistic regression model for this purpose : Pr(y exp(Z0 + E 1 ,’*i ) 1 + exp(/30 + ~j=l flJXi ) k /3
= k
( 2 ) where/3i ,j = 0 , , k are model parameters to be estimated from a given training data set . Using this prediction model , we can link the records without common unique identifier in two databases A and B as follows . For each record in database B , we compute Xil,,xik , the similarity measures between its k text fields and the corresponding fields of the ith record in database A . Then , we find the record in database A with tile largest matching probability using ( 2 ) : i* argmaxiEa Pr(y l[xi~ , ,xi k ) . If
Pr(y = llzi,1 , , zi.k ) >_ Pr(y = 0[xi1 , , xi.k ) , the record in database B is linked to the i* th record in database A . Otherwise , no link is established for this record between databases A and B .
In our customer satisfaction example , there are 500,000 records in tile maintenance record database and 12,000 records in the customer survey database . Among these 12,000 records , only about 40 % of the records do not have the unique identifier field . Four fields are chosen as the basis for matching records in this task : Customer Business Name : ( Xl ) ; Street Address : ( x~ ) ; Name : ( x3 ) ; State Name : ( x4 ) . To evaluate the posed method of record linkage , we randomly split all the records with the common identifier field into two parts , one for training and the other for testing . We fit four different logistic regression models using various number of variables , and the result is shown in Table 1 . In this example , using just one text field ( business name ) gives a satisfactory matching accuracy of 98 % . An additional field of street address boosts tile accuracy to over 99 % .
Model .721 Xl+X2 xl+xz+xa xl+xg.+x3+x4
Accuracy ( Train )
98.5 % 99.0 % 99.3 % 99.3 %
Accuracy ( Test )
98.7 % 99.5 % 99.8 % 99.7 %
We define s( . , b ) = max bM. ) ) M( ) ( .+m)/2 as our text similarity measure .
The optimization problem in ( 1 ) can be solved using the well known dynamic time warping method . More details on the algorithm can be found in ( Pinheiro Sun 1998 ) .
( 1 )
Table 1 : Prediction results of record linkage based on text similarity measure of various text fields .
4 Combining temporal structures of the Because of the different databases , individual records in the smaller database databases
310 Pinheiro are generally linked to multiple records in the larger database . These multiple records need to be collapsed to generate a consolidated database with a single record per individual , which is used for mining potentially interesting relationships . Averages and medians are used to collapse numeric variables , while percentages and counts are used to replace categorical variables in the collapsed database . For example , in the customer satisfaction study introduced in Section 2 , customer ’s maintenance service durations are summarized by the median service duration and the reporting status ( whether or not a customer reported the problem ) of the multiple maintenance records are represented by the percentage of customer reported problems .
5 Mining interesting relationships
This section describes a methodology for screening potentially interesting relationships , based on a model free interestingness measure and Trellis graphical displays . 5.1 An interestingness measure We denote a generic variable in the collapsed massive database by X and assume that it takes numeric values . A generic variable in the smaller database with unique records per individual is denoted by Y and , without loss of generality , we assume that it takes values on a discrete set . We denote by ny the number of possible values of Y .
A way of characterizing how interesting is the rela tiouship between X and Y is by measuring how much the conditional distribution of X given Y differs from the marginal distribution of X , that is , how much knowing that Y = y affects the chances of X taking a value X .
A non parametric description of the distribution of
XIY = Y is provided by the quantiles of that distribution ( Conover 1980 , p . 29 ) . Similarly , the empirical conditional distribution of XIY = Y may be described by the sample quantiles of the values X that were observed with Y = y . Generally , only a small number of quantiles , nq , are required to give a good representation of the distribution . If X and Y are independent , the quantiles of XIY = y are independent of y . The amount by which the quantiles of XIY = y vary with y relates to the interestingness of the underlying relationship . Because the true quantiles are not known , the empirical quantiles are used to evaluate the differences in the conditional distributions .
Let Ep denote the set of equivalent empirical quantiles associated with the different values of y , corresponding to a probability p ( eg all 25 % quantiles ) . Under the assumption that X and Y are independent , all elements in Ep estimate the same theoretical quantile and any ordering of them is equally likely to be observed . Replacing the actual values of the empirical quantiles by their respective ranks within Ep , it follows that , under the assumption of independence , all ny! rank permutations are equally likely . By convention , ties are assigned the average rank of the elements involved . Intraclass ranks for the different Ep quantile classes can be independently permuted , resulting in N(X , Y ) = ( ny !)"~ equally likely permutations . These can be used to derive a reference distribution for measuring the distance between the conditional distributions and , hence , the interestingness .
Let P~j denote the rank of the jth empirical quantile corresponding the ith value of y within its Ep class . The following statistics can be used to measure the difference between the conditional distributions .
K(x , r )
7~y i=l
R)2 /
R~ . = ~ P~/nq , j=l ny
~q i=l j=l
/by
R i:1
= ~ ( 3 ) to a Kruskal Wallis non parametric test K is similar ( Conover 1980 , p . 229 ) for testing equality statistics of means . Intuitively , if the conditional distributions present some sort of stochastic ordering , there will be an association between the empirical ranks and y , leading to larger deviations between average ranks ( the numerator of K ) and smaller within class deviations ( the denominator of K ) , resulting in larger values of K . reference distribution for K can be constructed by considering permutations ~r of the ranks within each Ep class and applying ( 3 ) to the permuted ranks to obtain a new value K,~ ( Good 1995 ) . This reference distribution can be used to calculate a randomization test p value for the observed K ( Good 1995 ) , which constitute our interestingness measure for the pair ( X , Y )
~(X,Y ) = ~{~:K , > K(X,Y)}/lV(X,Y )
That is , ~(X , Y ) gives the percentage of K~ that are greater than or equal to K(X , Y ) . can beint erpreted as a p value for the null hypothesis that X and Y are independent and the smaller the value of 4 , the more the relationship between X and Y . Because interesting c~ is derived from a randomization test based on intrit is model free and robust aclass ranks of quantiles , to the presence of outliers . Note , in particular , that ~r is invariant to 1 1 transformations of X . Also , because the number of quantiles nq can be kept fixed , it scales up to arbitrarily large databases . When N(X , Y ) is too large for complete enumeration of the reference set , a large sample of random permutations is used to estimate a ( Good 1995 ) . interestingness
5.2 Exploring example of SecWe consider the customer satisfaction the use of the interestingness meation 2 to illustrate sure ~ described in Section 51 There are a total of 21 Y variables in the customer satisfaction database , all measured on an ordinal 1 4 scale ( ny = 4 ) , and 13 numeric X variables in the consolidated maintenance service database , corresponding to 273 ( X , Y ) pairs . The 10 % , 25 % , 50 % , 75 % , and 90 % quantiles are used to
KDD 98 311 represent the empirical conditional distributions of XJY
= 5 ) . As a first application of a , we consider the problem of determining a time window for collapsing the maintenance records . As described in Section 4 , because the two databases have different records in the larger database need to be collapsed over a time window . This window must include the quarter in which the associated record in the customer data was collected1 but its width may vary . Short windows may lead to a loss of relevant records , but long windows may include data no longer associated with the customer ’s responses . That may also vary with both X and Y . A total of 8 widths , ranging from 0 to 36 months are considered for the customer satisfaction example . temporal structures ,
0 3 0 9 12 18 24
32 o
:
!
,.00
0.6O
¯ O.3g
~o
E
1.00
060
0.30
0.10
¯ 0.01
0 °
0
\O oJ ?\ o 0f0 z i z i i 0 3 6 9 12 18 24 z J
32
~’/~d~h ( months )
Figure 1 : Interestingness of four customer satisfaction variables with respect to median duration of maintenance service , versus time window width ( in months ) .
Figure 1 gives a Trellis display of a versus window width for the Y variables Data ( appropriateness of data ) , TechTtieian ( technician ’s knowledge ) , Reliability , and Overall ( overall satisfaction ) , with respect to the median maintenance service duration . Each panel of corresponds to a different Y and the same the trellis scale is used in all panels , to facilitate their comparison . A square root scale is used for a to enhance visualization . Data does not seem to be related to service duration , as all its a values are above 030 The highest interestingness value for Technician occurs for a 3 month window , suggesting that this is a "short memory" variable . The optimal widths for Reliability and Overall are respectively 18 and 24 months , suggesting that these are "long memory" variables . All of these last three variables show potentially interesting relationships with service duration , which should be further investigated . Similar analyses are done for the other ( X , Y ) pairs .
The analysis objectives for the customer satisfaction project are to determine which maintenance servicc
312 Pinheiro variables have greater impact on customer satisfaction and which customer satisfaction variables are most sensitive to maintenance service performance . The interestingness measure a can be used to address both of these issues . Figure 2 gives a Trellis display of the minimum a over window widths for a subset of maintenance and customer satisfaction variables . The square root scale is used again .
0.01 O.OS 0.15 0.30 0.50
P , epcd~
3 s~aq
Frequency
R~oa
O;apeleh~
Otlat~m s.v,~
Frequency
J
[ ]
Ove~l,~
I
~ ~~ K ,I ~I
I i i
I
I
001 005
0.15 O~ 0.50
Interestingness Measure
Figure 2 : Interestingness measures for a subset of maintenance service and customer satisfaction variables , with different panels for the customer satisfaction variables .
It is clear that Data and Overall are less sensitive to maintenance service variables than Tech~icia~ and Reliability . Frequency of problems seems to be the less influential maintenance variable , but this becomes clearer in the Trellis display of Figure 3 , where the panels are now determined by the maintenance variables and the rows within the panels by the customer satisfaction variables .
Figure 3 also reveals that Reported ( percentagc of times a problem was reported by the customer ) has uniformly low a’ values , suggesting it is an influential variable on customer satisfaction .
Interestingness
5.3 Understanding The sample distribution of a variable is compactly represented by its boxplot ( Velleman & Hoaglin 1981 ) . Boxplots have good scalability properties , because they are based on a few quantiles of the data . distributions side by side ,
Comparison of the conditional of XIY = y is done by plotting , the boxplots corresponding to each y . Trellis displays provide a powerful graphical environment for combining several of these plots , facilitating their comparison and understanding . Figure 4 gives an example of such a Trellis display for the customer satisfaction data . The Y variables are Data , Overall , Reliability , and Technicia~ h
I
I
I ~ :~::::::::~
:~::~:: : : i :~i::~:~ :! : ::::::~:~ : ; : ~:::~: : : ;~ :~ : : r : : ~ .:~ i ~ ~ : . , ’ i ~ ~ ~ "
Good E~c~le~
I poor
I
Fair I
:~:::i~iz ] ]~:i:i::~ ~ : :~:~:~:~:~ : ~ rT~ i ."i"~ ~ ’:T"’ =’:iiii’ ii’
: : ~:~:~
~ ~ ¯ ] t:o n i~’iZ:i,!i!!’~ =
,, , , o , i , ! ; t
: ::k : : : :~ : : :: : : : ::T~:~ : : :: : : : r ~ . ! i ~i~ i i[~ ii~~ , Fi~ i ri~ i i~~
::::::::::::::::::: : :
:2::2 : ~:~:: : :
! i o i/~ i : , i_L
_~ i
_ij
: ~ ~ ! I ~ . o
~
~ k i ~
i oot o.o6 i i ors e 030 o.so i i i
,
Po~"
F~"
Good E,~celle~t i
’ i
" i
InterestJngness Moasure
RaUr~
Figure 3 : Interestingness measures for the same subset of variables as in Figure 2 , with different panels for the maintenance variables .
Figure 4 : Boxplots of the sample distributions of Reported conditional on satisfaction ratings for a subset of the customer satisfaction variables . each corresponding to a different panel , and the X variable is Reported .
It is clear from Figure 4 that customers with poor satisfaction levels have different Reported values than the rest of the customers . This is more evident for the variables Overall and Reliability , for which the dissatisfied customers present higher values of reported problems . This information is useful for identifying and prioritizing customer satisfaction problem areas .
Similar Trellis displays are used for all potentially interesting relationships flagged by the interestingness measure . Human intervention is required at this stage of the analysis to sort out the relevant relationships and to decide on their usefulness . The automatic screening of potentially interesting relationships prior to this step greatly reduces the need of human intervention , allowing the most valuable resources to be selectively allocated .
6 Discussion
We develop a methodology for linking , combining , and mining massive heterogeneous databases . We propose a method for linking records in multiple heterogeneous databases using loosely defined fields that allow freestyle verbatim entries . A dynamic programming technique is developed to compute matching probabilities , with the decision thresholds being estimated from training data . To screen potentially interesting relationships between variables in the massive databases , we present an interestingness measure based on a non parametric randomization test , which can be used for automatic data mining . We describe graphical methods , based on
Trellis displays , for summarizing the results of the data mining search and for further exploring the relationships with largest interestingness values . These methods are model free , robust to the presence of outliers , and scale up to databases of arbitrary size .
7 Acknowledgements
We would like to thank Lorraine Denby and James M . Landwehr from the Statistics l~esearch group at Bell Labs for their helpful comments and suggestions .
8 References
Becker , R . A . ; Cleveland , W . S . ; and Shyu , M J 1996 . The visual design and control of trellis graphics displays . J . of Computational and Graphical Statistics 5(2):123 156 . Conover , W . J . 1980 . Practical Nonparametric Statistics . New York : Wiley , 2nd edition . Good , P . 1995 . Permutation Tests : A Practical Guide to Resampling Methods for Testing Hypotheses . New York : Springer Verlag . Pinheiro , J . C . , and Sun , D . X . 1998 . Methods for linking and mining massive heterogeneous databases . Technical memorandum , Bell Laboratories , Lucent Technologies . Velleman , P . , and Hoaglin , D . 1981 . Applications , basics , and computing of exploratory data analysis . New York : Duxbury Press .
KDD 98 313
