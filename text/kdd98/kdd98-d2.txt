A Fast Computer Intrusion Detection Algorithm Based on Hypothesis
Testing of Command Transition Probabilities William DuMouchel
Matthias Schonlau ATgcT Labs Research and
AT&T Labs Research 180 Park Avenue
Florham Park , NJ 07932 dumouchel@researchattcom
National Institute of Statistical Sciences
PO Box 14006
Research Triangle Park , NC 27709 4006 schonlau@researchattcom
Abstract
This statistical method compares in real time the sequence of commands given by each user to a profile of that user ’s past behavior . We use the Fisher score statistic to test the null hypothesis that the observed command transition probabilities come from a profiled transition matrix . The alternative hypothesis is formed from a principal components analysis of historical differences between the transition probabilities of all other users and those of the user being tested . The calculations can be structured so that only a few dozen arithmetic operations are needed to update an online test statistic after each submitted command . The theoretical statistical properties of the test , such as false positive and false negative rates , are computable under the assumptions of the markov process model . Based on a population of 45 research users on a single computer , test data from each user are used to challenge the profile of every user . The test had sufficient statistical power to successfully discriminate between almost every pair of users based on a sample size equivalent to a single day ’s usage of an average user .
Description of Statistical Methodology Introduction . In computer intrusion detection one attempts to identify unauthorized accesses to computer accounts . There are two main approaches to intrusion detection : pattern recognition and anomaly detection . is the attempt to recognize genPattern recognition that stem from known attacks eral "attach signatures" a software bug . The approach has such as exploiting the disadvantage that it cannot defend against previously unknown software bugs , or any unauthorized user with the knowledge of the account password . Anomaly detection , on the other hand , attempts to identify an unauthorized user by identifying unusual usage of the computer . Usually , for each user a historical profile is built and large deviations from the profile indicate a possible intruder . Therefore it is also referred to as the profile based approach . Intrusion detection systems like
Copyright Q1998 , American Association for Artificial Intelligence ( wwwaaaiorg ) All rights reserved . to a statistical that each that could
IDES ( Lunt et al . 1992 ) , NIDES and Emerald ( Porras and Neumann 1997 ) use both approaches , presumably because neither one is uniformly superior to the other . In this paper we only consider the anomaly detection approach . This approach lends itself treatment . Ryan et . al . ( 1998 ) suggested user on a computer system leaves a "print" be captured by training a neural network with historical data . When for new data from any user the neural network predicts to stem from another user in the historical data , then an alarm for a possible intrusion is raised . Forrest et al . ( 1996 ) consider anomalies for unix processes ( such as ftp , or root ) rather than for users . In this paper we propose a test for anomaly detection based on hypothesis testing . Since users ( including the root user ) and system processes ( such as ftp ) both generate command level data , we are able to test anomalies for unix processes and users simultaneously . that the data is more likely
Probabilities .
Command Transition
Our method is based on comparing the sequence of each user ’s commands to a stored profile describing the probability distribution of that user ’s command sequences . Each command is one of a fixed number K of possible commands or command groupings . We represent each user ’s historical data in terms of a transition matrix of command probabilities :
Pjku = P(Next Com . = k]Prev . Com . = j , User = u )
( 1 ) The commands are arbitrarily numbered as j , k = 1 , , K and we assume that historical data are available for U+I users , arbitrarily numbered u = 0 , 1 , , U . We focus on User u = 0 as the user whose commands are being monitored and tested for unusual behavior at any given time , but the historical data from the other U users play a role in the test procedure for user 0 .
Transition
Smoothing Historical Probabilities The probabilities ( 1 ) must be reliably estimated , with all Pjk , , > 0 . Thus we smooth the observed proportions from the training period . Denote by Njk , , the raw count of transitions from command j to command k for user
KDD 98 189 u during the training period . This array will have many elements equal to 0 and many of its nonzero elements may be so small that they are statistically unreliable . For some small c > 0 ( we use ~ = 0.001 ) , let
N.ku
"
E Njku
J k
+ qk , = ( N.k , ,
The qku are tile marginal probabilities of command k for user u , modified using c so that they are all positive . The transition probabilities Pjk , , are weighted averages of qku and tire raw proportions h~ku/Nj.u , namely ( 2 ) Pjk , , = [ (Njk,+~l,ljuqku)/(Nj.u+Mju)+e]/(l+Ke ) where Nj.u = Ek Njk , , and Mju are weights chosen to be large if the raw transition frequencies are not significantly different from the marginal frequencies , but near 0 if the raw transition frequencies are very reliably different than the marginal ones . Specifically , let
Mju 1/max{.0001 , [ E(Njku Nj.,,qk,,)2/ k gj.,qku
I( + 1]/gj.u(K 1 ) }
( 3 ) The use of equations ( 2 ) and ( 3 ) is inspired by an empirical Bayes model in which it is assumed that each vector ( Pjl , , PjK , ) was generated from a Dirichlet prior distribution ( O’Hagan 1994 , Ch . 10 ) with mean vector ( qh , , , qKu ) and probability density proportional to YIk Pjku
5liu q~’" l"
Testing
Framework
Hypothesis Suppose that User 0 is logged on and has generated a sequence of T+ 1 commands Co , C1 , , CT . There is the possibility that these commands are being generated by someone other than User 0 , and let the unknown true transition probabilities of this sequence be lrjk = P(Ct = klCt_l = j )
( 4 ) The corresponding transition counts for this user ’s test data are njk , where ~j,k njk = T . Let nj . = ~k njk . By definition , E[njk]nj . ] = njzrjk We want to test the null hypothesis t = l,2,,T
Ho : 7rjk : Pjko j = 1 , , K ; k = 1 , , K ( 5 ) Statistical hypothesis testing is a procedure in which a decision maker prespecifies a computable test statistic whose distribution is supposed to be completely known assuming that a null hypothesis H0 is true . This allows the false alarm probability to be computable in advance for a decision rule that rejects H0 whenever the test statistic exceeds a fixed value .
The standard test statistic likelihood ratio statistic , for this situation is the log namely
The range of j in the above summation is over the J values of j for which nj . > 0 . If T is very large and tile assumptions ( 4 5 ) are true , then LR will have approximate chi squared distribution with J(K 1 ) degrees of freedom , so that LR could be compared to the percentiles of this distribution to assess H0 . Unfortunately , T will rarely be large enough for this distributional assumption to be even approximately true . The usual rule of thumb is that every value of nj.PjkO > 1 , and that most nj.pjko > 5 . This would imply that every nj . > 3K , yet many rarely occurring commands would have many fewer occurrences than that in the test data . Another problem with using the test statistic ( 6 ) is that this is an omnibus test with power against all possible alternatives to ( 5 ) , which is likely to waste statistical power testing against unlikely or nonsensical alternative sets of transition probabilities . Therefore we will construct an alternative hypothesis with fewer degrees of freedom , using tire historical data from all users as a guide to which alternative transition probabilities are plausible .
Alternative Hypothesis . Suppose that test data are being generated by the transition probabilities the u=l,U
,flKU ) Instead of considering all alwhere fl = ( fill , to Ho , ( 7 ) focuses on directions in the space ternatives that the historical data conof transition probabilities firm are occupied by one or more other users . The expression ( 7 ) becomes identical to H0 if all KU elements of/~ = O , so HI might also be stated as/~k , ¢ 0 for some ( k , u ) . However , ( 7 ) still has the disadvantage of too many degrees of freedom because many of the users may have similar historical probabilities so that the vectors ( Pjh , Pjlo , , PjK , PjKo ) may be highly collinear for many values of u .
Prlneipal
Components Regression .
The dimenhypothesis is reduced by from sionality of the alternative choosing linear combinations of user deviations pjko that have maximum variance and are uneorrelated . See DuMouchel and Schonlau ( 1998 ) for more details the statistical the matrices Xj : theory behind this approach . First define x k , = ( pjk , , Pjko)/,/g ko
Then let Zj be a K x U* matrix consisting of the first U* < rain(U , K ) principal uncentered principal components , so that tr(Z~Zj ) components of Xj . Take ~
Test Procedure After reducing the dimensionality in this way , the corresponding Fisher score statistics ( Stuart and Ord 1991 , Ch . 25 ) are defined as follows , where v = 1 , , U’ :
= &k /,/ Yjko
( 8 )
Lt{ = 2 E E n’ikl°g(njk/nj’p:ik° )
( 6 ) j k k
190 DuMouchel
2 ~ = ~pjkoY~jk k
The principal component scores Sjv have moments
E[Sjv ] 0
Var(Sj , )
= nj.I~v
( 9 )
( 10 )
= 0 for all combinations j ¢ j’ or ( 8 ) are then only U* additions are required to update
Cov(Sj,,,Sj,,, , ) v ¢ vI . Note that stored , the entire matrix Sju after each observed transition ( Ct 1 the U*K2 subscores
= j , Ct = k ) . if components chi squared .
The test
Principal statistic
S~ = ~,(S~v~/nj.V~ ) j,v
( 11 ) has an approximate X2 distribution with df = JU* under H0 , or , using the Wilson Hilferty ( 1931 ) transformation ,
S* = [ (S2/df )
1/3
1/ 2
1 + 2/9df](9df/2 )
In our example , U* = 5 principal components are used for each previous command j .
Data and Results
To evaluate the method presented in the previous section , we compare test data to training data ( profiles ) for pairs of users . Ideally , an alarm should always be raised except when a user is tested against his or her own profile . To establish user profiles , we use historical data from usage on our local unix machine . The data ( user names and commands ) are extracted from output of the unix acct auditing mechanism and consist of user names and commands only ( without their arguments ) . Some commands recorded by the system are implicitly generated and not explicitly typed by the user . For example , each execution of the .profile file or a make file generates commands contained in these files that are also recorded in the data stream . We use test data separated in time from training data according to the following cross validation scheme involving four separate time periods . the first 1000 command transitions
Experimental Design . Data were collected from our local population during four separate time periods approximately a month apart . During each time period , by each user are included in the study . There were 45 users with that amount of data available from all four time periods . We form four separate replications of our study by considering in turn each of the four time periods as the test period and the other three time periods as historical training periods for collecting user profiles . Within each replication , we test each user ’s test data against each of the profiles in the historical data and record the standardized test statistic S* . Within each set of 1000 test commands , we compute the test statistic for each of 10 sets of 100 commands , so the basic unit of study is observation of 100 commands from the user being validated . When the standardized test statistic S* exceeds a threshold value , an alarm is raised . Depending on the chosen value of the threshold , different rates for false positives ( false alarms ) and false negatives ( missing alarms ) can be obtained . In the following we investigate the tradeoff between false negatives and false positives by choosing different thresholds .
Results . Figure 1 focuses just on the false alarm problem ( comparing each test user to the same user ’s profile ) and looks at the test statistic as a function of the number of commands N . Each of the 45 curves in Figure 1 corresponds to one test data stream . The two horizontal in Figure 1 correspond to thresholds of S* = 10 and of S* 100 respectively . Out of 45 users , only 2 ever exceed the threshold of 100 . The vast majority of users maintain S* < 10 . Under the lines
2¢o
,too so0
Number of Commands a¢o
Figure 1 : Time plot of standardized score comparing each user ’s test data with their own training data profile . Training Periods = 1 3 . Test Period = 4 . Number of Principal Components U* = 5 .
Null hypothesis , S* should have a standard normal distribution which would suggest a small threshold ( eg 3 ) . Our data show higher false alarm rates than this theory predicts , which we attribute to the fact that our model does not accommodate users’ behavior changing over time , and some of our users changed significantly . that pair .
Figure 2 shows , for each of the 45 x 45 test data verthe median value of S* for blocks sus a profile pairs , of N = 100 commands within ( Note that actually 20 + S* is plotted to allow for the logarithmic scale on the vertical axis . A vertical at S* = 0 ) . Ideally , user ’s own historical profile ( denoted by "+" in Figure 2 ) should be lower than all of the test scores run against other people ’s profiles ( denoted by "" ) Another way of saying this is that a user should only be able to break into his/her own account without causing an alarm to be raised . As we can see in Figure 2 , the block medians the median test score against line is drawn
KDD 98 191
I i .
: il
,+ if! ,
, . : . ;
,+ i Ii ’i
I
!
I
’ I
, i
:
J!i i I ,+ i I l i
"1" ¯
,
, ,
. i , , i i , , .
0 0 L~
0 II Z
0 0
"oe
CO
I 0 0
I
++
0
I L+ + + +
+4"
+
+
:
÷
+
+
+
:
++
+
I ,
+ i i : ,
! +
+
++
+
+
+
+
+
4"
2o User Account
4" "
"1"
+
+
+
4
4’0
Figure 2 : Medians of standardized scores for blocks of 100 "+" denotes comparison to own training data , "." denotes Test Period = 4 . Number of Principal Components U* = 5 . test data commands , compared to each training data¯ comparison to other users . Training Periods = 1 3 . A horizontal line is drawn at S* = 0 . discriminate almost perfectly between a user ’s own and other profiles .
As the threshold where an alarm is raised changes , different rates of false alarms ( false positives ) and missing alarms ( false negatives ) can be obtained¯ Figure and Figure 4 show the tradeoff between these false positive and false negative rates for all four time periods based on blocks of 100 and 900 commands , respectively . Each time period is used as testing data with the remaining three time periods serving as training data . The lower left corner represents the ideal scenario : no false alarms and no missing alarms . Note that both axes are presented on a logarithmic scale . From Figure 3 we can tell , for example , based on 100 transitions , at a false positive rate of 5 % we get a corresponding false negative rates between about 15 % 60 % . Based on 900 transitions 5 % 31 % . These numbers are quite high and also indicate that there is a considerable variability from time in Figure 4 is in period to time period . The variablility part due to the relatively small sample size : an alarm for 2 out of 45 blocks of 900 commands amount to about 5 % false alarms .
( Figure 4 ) , the false negative rates drop
192 DuMouchel
Discussion
Ryan et . al . ( 1998 ) use a neural network approach and test classification errors based on 10 users¯ They have 11 successive days of data , 8 of which are used for training . One of the users only had little data . They report a false alarm rate of 7 % and 4 % missing alarms . Our test is more challenging in that we test with more users , and because there is a gap in time between historical and test data . Also , their decision criterion seems to assume that the intruder would be one of the other users in their training data . On the other hand , unlike them , we excluded users with very low account usage¯
In order for an intrusion detection tool to be useful , the false alarm rate needs to be low otherwise alarms tend to be ignored . To that extent a false alarm rate of 5 % still seems high . Perhaps extending the length of the training period will make the profiles more robust to changes in user behavior¯ One possible way to improve the markov model is by consolidating series of cascading commands ( generated , for example , by a makefile ) into single ( meta ) commands , or by conthe next command conditional on more than sidering one previous command . Note that our theoretical false ignore the problem of multiple testalarm probabilities o
0.5
1.0
5.0 10,0 False Positive ( % )
50.0
100.0
0.5
1.0
5.0 10.0 False Posigve ( % )
50.0
100.0
Figure 3 : Tradeoff between false positive and false negative rates for statistic ( 11 ) , treating every block of 100 commands as a separate experiment . Each of four periods is used as test data with the respective other three periods being used as training data . Number of PrincipM Components U* = 5 .
Figure 4 : Tradeoff between false positive and false negative rates for statistic ( 11 ) based on 900 commands for each user . Each of four periods is used as test data with the respective other three periods being used as training data . Number of Principal Components U* = 5 . ing , in which repeated testing of the same null hypothesis as time goes on increases the chance of a false alarm rate . This problem , common to most control chart like procedures , seems to be a less important cause of excessive false alarms than our failure to model how users tend to change their profiles over time .
A major strength of the approach presented is its speed . Only a few dozen operations are needed for updating the test statistic , and preliminary calculations indicate that it will be easily possible to implement this procedure in real time . The amount of storage required for the procedure is relatively large . Based on 5 principal components and 100 command categories , 50500 single precision numbers need to be stored for each user . Because of space constraints , we report here only on and defer comparisons the behavior of the S* statistic for varying numbers of principal components and differSee DuMouchel and Schonlau ( 1998 ) ent test statistics . for description of a comparative study of different test statistics and numbers of principal components to use with this method .
We need to perform further investigation of the optimal number of principal components to take . We will also investigate the effect of adding known intrusion signatures as profiles in the training data to make the principal components methodology more sensitive to such attacks . We also expect to be able to use this procedure to increase our understanding of local system usage .
References
DuMouchel , W . and Schonlau , M . ( 1998 ) . A Comparison of Test Statistics for Computer Intrusion Detection
Based on Principal Components Regression of Transition Probabilities . sium on the Interface : Computing Science and Statistics , ( to appear ) .
In Proceedings of the 30th Sympo
Forrest , S . , Hofmeyr , S . , Somayaji , A . , Longstaff , T . ( 1996 ) . In Proceedings of the 1996 IEEE Symposium on Security and Privacy . Los Alamitos , CA , pp . 120 128 .
IEEE Computer Society Press ,
Lunt , T . Tamaru , A . , Gilham , F . ,
Jagannathan ,
R . , Neumann , P . , Javitz , H . , Valdes , A . , Garvey , T . ( 1992 ) . A Real Time Intrusion Detection Expert System ( IDES ) final technical report . Computer Science Library , SRI International , Menlo Park , California .
O’Hagan , A . ( 1994 ) . Kendall ’s Advanced Theory
Statistics , Vol . 2B : Bayesian Inference , New York : John Wiley .
Porras ,
P . , and Neumann P . ( 1997 ) . EMERALD :
Event Monitoring Enabling Responses to Anomalous Live Disurbances . In Proceedings of the National Information Systems Security Conference . ( to appear ) .
Ryan , J .
, Lin,M . , and Miikkulainen , R . ( 1998 ) . Intrusion Detection with Neural Networks . In Jordan , M . I . , Kearns , M . J . , and Solla , S . A . ( editors ) , Advances in Neural Information Processing Systems 10 ( NIPS’97 , Denver , CO ) . Cambridge , MA : MIT Press .
Stuart , A . and Ord , JK ( 1991 ) . Kendall ’s Advanced Vol . 2 : Classical Inference and
Theory of Stististics , Relationship , New York , John Wiley .
Wilson EB , Hilferty MM ( 1931 ) . The distribution
In Proe . Nat . Acad . Sci . , Wash . DC , 17 , chi square , 684 688 .
KDD 98 193
