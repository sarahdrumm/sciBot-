Algorithms for Storytelling
Deept Kumar∗ , Naren Ramakrishnan∗ , Richard F . Helm# , and Malcolm Potts#
Contact : naren@csvtedu
∗Department of Computer Science , Virginia Tech , VA 24061
#Department of Biochemistry , Virginia Tech , VA 24061
ABSTRACT We formulate a new data mining problem called storytelling as a generalization of redescription mining . In traditional redescription mining , we are given a set of objects and a collection of subsets defined over these objects . The goal is to view the set system as a vocabulary and identify two expressions in this vocabulary that induce the same set of objects . Storytelling , on the other hand , aims to explicitly relate object sets that are disjoint ( and hence , maximally dissimilar ) by finding a chain of ( approximate ) redescriptions between the sets . This problem finds applications in bioinformatics , for instance , where the biologist is trying to relate a set of genes expressed in one experiment to another set , implicated in a different pathway . We outline an efficient storytelling implementation that embeds the CARTwheels redescription mining algorithm in an A* search procedure , using the former to supply next move operators on search branches to the latter . This approach is practical and effective for mining large datasets and , at the same time , exploits the structure of partitions imposed by the given vocabulary . Three application case studies are presented : a study of word overlaps in large English dictionaries , exploring connections between genesets in a bioinformatics dataset , and relating publications in the PubMed index of abstracts .
Categories and Subject Descriptors : H28 [ Database Management ] : Database Applications Data Mining ; I26 [ Artificial Intelligence ] : Learning
General Terms : Algorithms .
Keywords : redescription , data mining , storytelling .
1 .
INTRODUCTION
Redescription mining is a recently introduced data mining problem [ 9 , 10 ] that seeks to find subsets of data that afford multiple definitions . The input to redescription mining is a set of objects O ( eg , books , genes ) and a collection of subsets S defined over O . The goal is to view the set system as a vocabulary of descriptors and identify clusters of
Figure 1 : An example input to storytelling . objects that can be defined in at least two ways using this vocabulary .
For instance , consider the set system in Fig 1 where the six objects are books and the descriptors denote books about traveling in London ( Y ) , books containing information about places where popes are interred ( G ) , popular books about the history of codes and ciphers ( R ) , books about Mary Magdalene ( M ) , and books about the ancient Priory of Sion ( B ) . An example redescription for this dataset is : ‘books involving Priory of Sion as well as Mary Magdalene are the same as non travel books describing where popes are interred,’ or B ∩ M ⇔ G − Y . This is an exact redescription and gives two different ways of defining the singleton set {‘The Da Vinci Code’} . The basic premise of redescription mining is that object sets that can indeed be defined in at least two ways are likely to exhibit concerted behavior and are , hence , interesting .
While traditional redescription mining is focused on finding object sets that are similar , storytelling aims to explicitly relate object sets that are disjoint ( and hence , maximally dissimilar ) . Given start and end descriptors X , Y ∈ S , the goal here is to find a sequence of descriptors Z1,Z2,··· ,Zk where Z1 = X , Zk = Y , and every Zi is an approximate redescription of Zj , 1 ≤ i < k , j = i + 1 . A redescription Zi ⇔ Zj is approximate if its Jaccard ’s coeffi|Zi∩Zj| |Zi∪Zj| is strictly between zero and one . An example cient story in the above dataset results when we try to relate London travel books to books about codes and cipher history : Some London travel books ( Y ) overlap with books about places where popes are interred ( G ) , some of which are books about ancient codes ( R ) . This story is a sequence
LondonMap GuideChristianity ’s Hidden GoddessRick Steves’LondonHoly BloodHoly GrailDa Vinci CodeCodebreakersYGRMB S1 = { S2 = { S3 = { S4 = { S5 = { S6 = { o1 , o1 , o2 , o2 , o3 o3 , o4
} } } } } } o5 o5 o6
Figure 2 : Example data for illustrating operation of storytelling algorithm . of ( approximate ) redescriptions : Y ⇔ G ⇔ R . Each step of this story holds with Jaccard ’s coefficient 1/3 . A stronger story , that holds with Jaccard ’s coefficient 1/2 at each step , is : B ⇔ ( G ∩ M ) ⇔ R .
Why is this problem interesting and relevant ? Storytelling can be viewed as a carefully argued process of removing and adding participants , not unlike a real story . Knowing exactly which objects must be displaced , and in what order , helps expose the mechanics of complex relationships . Second , storytelling can be viewed as an abstraction of relationship navigation for propositional vocabularies and reveals insight into how the underlying Venn diagram of sets is organized , and how it can be harnessed for explaining disjoint connections . Finally , with the emergence of highthroughput data acquisition systems , domains such as bioinformatics are now suffering from ‘descriptor overload’ ; storytelling promises to be a valuable tool to attack this problem and reconcile disparate vocabularies .
Why is this problem difficult ? Storytelling is non trivial because the space of possible descriptor expressions is not enumerable beforehand and hence the network of overlap relationships cannot be materialized statically . In particular , observe that the intermediaries Zi are not constrained to be just elements of S but can be set theoretic expressions made up of the Si ’s , eg , S1 ∪S3,S2 −S4,S1 ∩ ( S2 ∪S5 ) . In a typical application , we have hundreds to thousands of objects and an order of magnitude greater descriptors , with an even larger number of possible set theoretic constructions made of the descriptors . Effective storytelling solutions must multiplex the task of constructive induction of descriptor expressions with focused search toward the end point of the story .
2 . DESIGNING A STORYTELLER
We embed CARTwheels inside an A* search procedure , using the former to supply next move operators on search branches to the latter . Each move is a possible redescription to be explored and a heuristic function evaluates these redescriptions for their potential to lead to the end descriptor of the story . In this paper , we focus on story length— number of redescriptions to reach the end descriptor—as the primary criterion of optimality although different criteria might be more suitable in other applications . Backtracking happens when a previously unexplored move ( redescription ) appears more attractive than the current descriptor . The search terminates when we reach a descriptor that is within the specified Jaccard ’s threshold from the ending descriptor or when there are no redescriptions left to explore . 2.1 Working Example For ease of illustration , consider the artificial example in Fig 2 with six descriptors {S1,S2,S3,S4,S5,S6} defined over the universal set O = {o1 , o2 , o3 , o4 , o5 , o6} ( in a re alistic application , the number of descriptors would greatly exceed the number of objects ) . Our goal is to find a story between descriptor S1 , corresponding to the set {o1} , and S5 , corresponding to the set {o5} , such that each step is a redescription that holds with Jaccard ’s coefficient at least θ = 05 In this example , we set the maximum depth of decision trees used to 2 .
To initialize the alternation , we prepare a traditional dataset for classification tree induction ( see Fig 3 , left ) , where the entries correspond to the objects , the class ( to be learnt ) corresponds to the starting descriptor , and the boolean features are comprised of the remaining descriptors . A classification tree can now be grown using these features and class assignments with the Jaccard ’s coefficient as the node evaluation criterion . Hence , at each level in the decision tree we construct , we look for a descriptor Si such that one of the blocks in its induced partition will provide the best overlap with the class we seek ( in this case , S1 ) . If the maximum Jaccard ’s coefficient value obtainable is lesser than θ , we choose the descriptor that provides the best value . Else , we consider all descriptors that satisfy the Jaccard ’s threshold and , among them , greedily choose the one with the highest Jaccard ’s coefficient with the end point of the story . The tree growth is continued until the maximum Jaccard ’s coefficient observed at a given depth is lesser than that observed at the parent level , or the depth limit of tree growth is reached . Once the tree has been constructed , class assignments at the leaves are made by majority and paths that lead to a given class are union ed to form redescriptions . For instance , Fig 4 ( a ) shows the decision tree we have constructed to match the partition {S1,S1} . This tree provides the first step in the story to be the redescription S1 ⇔ ( S2 − S3 ) . In this example , we show only one possible ‘next tree’ for our example but in our implementation , we maintain a number of such possible matching trees , to simulate a branching process and for potential backtracking . Note that while the current redescription holds with a Jaccard ’s value of 0.5 , the new descriptor does not have any overlap with S5 . For the next step in our story , we use the partition {(S2 − S3 ) , ( S2 − S3)} as the classes to match and consider the dataset as shown in Fig 3 ( right ) . In constructing the new dataset , observe that we ignore the descriptor that is the top most node ( here , S2 ) in the decision tree that defines the current partition . This ensures that we do not utilize the same features for matching a partition as those that define the partition! The one level tree we learn at this stage is shown in Fig 4 ( b ) . The redescription of interest here is ( S2 − S3 ) ⇔ S3 , which also holds with a Jaccard ’s coefficient of 05 Although it introduces the element we seek ( o5 ) , the redescription to the end point of the story , S3 ⇔ S5 , has only a Jaccard ’s coefficient of 025 We hence continue the search and obtain the redescription S3 ⇔ S4 which gives us the desired overlap with the target , and our final redescription , namely S4 ⇔ S5 . Our story is thus S1 ⇔ ( S2 − S3 ) ⇔ S3 ⇔ S4 ⇔ S5 . 2.2 The storytelling algorithmic framework follows the outline of the working example above for a given O , S , X and Y . The parameters that need to be specified are : a threshold θ ( 0 < θ < 1 ) denoting the minimum required Jaccard ’s coefficient for each connection in the story ; d ( depth of trees )
Implementation class
S6
S5
S4
S3 obj . S2 o1 o2 o3 o4 o5 o6
√ × × × × S1 √ √ × × × S1 √ × √ × × S1 × √ × × × S1 × × √ √ × S1 × × × × √ S1
S6
S5
S4
S3 obj . S1 o1 o2 o3 o4 o5 o6 class
√ × × × × ( S2 − S3 ) × √ × × × ( S2 − S3 ) × × √ × × ( S2 − S3 ) × √ × × × ( S2 − S3 ) × × √ √ × ( S2 − S3 ) × × × × √ ( S2 − S3 )
Figure 3 : ( left ) Dataset to initialize storytelling algorithm . ( right ) Dataset for the second iteration .
Figure 4 : Storytelling using CARTwheels alternation . Beginning with S1 , the starting descriptor exposed by the bottom tree in ( a ) , the alternation systematically moves toward S5 , the ending descriptor in ( d ) . At each step we alternately keep one of the trees fixed and grow a new tree to match it . The story mined here is the sequence of redescriptions : S1 ⇔ ( S2 − S3 ) ⇔ S3 ⇔ S4 ⇔ S5 . that imposes a bias B over set expressions defined on S ; and branching factor b that restricts the maximum number of possible next states from each state in the A* search .
Our implementation can be divided into an Initialization step and an Alternation step . In the Initialization step , an empty open list ( OL ) and closed list ( IL ) required for A* search are defined . Also , the decision tree induced by the starting class ( a 1 level tree with the node X ) is added to OL along with its heuristic score obtained from the function calculate heuristic score as explained later . This tree provides the classes for the first step of the Alternation process . The class of interest ( X ) is marked as the one we want to find the closest match for . At each alternation in the Alternation process , the first tree ( tN ) in OL provides the classification C . The candidate set of features F is made equal to all except the feature used at the root of the current tree providing the classes . b distinct trees of depth d are created using these definitions of C and F and Jaccard ’s coefficient as the metric . For each of the decision trees constructed , the Jaccard ’s coefficient between the current descriptor of interest and the union of the paths leading to it in the current tree is calculated . For each tree ( tj ) for which this value is higher than or equal to θ , the calculate heuristic score is used to compute the heuristic score hj .
If the heuristic evaluation hj for the currently picked tree tj is zero , we have arrived at a tree that has sufficient Jaccard ’s overlap with the end point of the story . We can then terminate by displaying the story by tracing back the sequence of mined redescriptions . If hj is not zero , tj is placed in OL and tN is moved to CL . For adding tj to OL , the heuristic score hj is combined with cost expended so far ( gj ) to arrive at the evaluation criterion sj . Nodes are placed in OL in ascending order of sj . This completes one step in the Alternation process . The whole alternation process outlined is repeated until there is no tree left in OL or a story has been found .
The heuristic function h is designed to systematically never over estimate the number of redescriptions remaining and takes the value of zero for a tree whose partition has an overlap of at least θ with the ending descriptor . We now present details of h that clearly indicate its admissibility .
Table 1 outlines the approach to estimate hj for tree tj . This algorithm can be understood as follows . Assume that the new descriptor Zj ( provided by tree tj ) has f elements in common with the target descriptor Y and e elements that do not participate in Y . This means that Zj must shed enough of the e elements and acquire enough of the |Y | − f elements in order to have a Jaccard ’s threshold of ≥ θ with Y . The goal of calculate heuristic score is to estimate the number of redescriptions required to shed the requisite number among e elements and acquire some of the necessary |Y |− f elements . The procedure first conservatively estimates if the current discrepancies already correspond to a Jaccard ’s threshold of ≥ θ with Y , in which case it returns zero . If this is not possible , the procedure estimates the shortest number of steps in which the deletions and additions can happen by a recursive computation . Two extremes are considered at each step – the case where we can acquire as many of the necessary new elements as dictated by θ without any
S1yesnoyesnoyesnoS2S3(a)S4noyesS5yesno(d)S4noyesS3noyes(c)S3noyesyesnoyesnoS2S3(b ) Table 1 : Heuristic for storytelling A* search . calculate heuristic score(tj , C , Y , θ ) : set Zj−i = target class from C set Zj = block from tj that redescribes to Zj−1 set f = |Zj ∩ Y | set e = |Zj − Y | set h = 0 calculate h = minpath(f , e , |Y | , h , θ ) return h minpath(f , e , |Y | , h , θ ) : calculate θY = f /(e + |Y | ) if ( θY ≥ θ ) else return h calculate δfmax = b ( 1−θ)(f +e ) calculate δemax = b(1 − θ)(f + e)c set hmin = ∞ for ( i = 0 ; i ≤ δfmax ; i = i + 1 ) c
θ set done = false for ( k = δemax ; k ≥ 0 and ! done ; k = k − 1 ) calculate θnew = f +e−k if ( θnew ≥ θ ) f +e+i set done = true set hcurr = minpath(f + i , e − k , |Y | , h + 1 , θ ) if ( hcurr < hmin ) set hmin = hcurr end if end if end for end for return hmin end if removals , and the case where we can shed as many of the unnecessary elements as dictated by θ without any additions . This step provides us the bounds δfmax and δemax in Table 1 . We then search combinatorially within these ranges for the maximal number of deletions , for every possible number of additions , such that θ holds , akin to dynamic programming . The minimum number of redescriptions over all possibilities is then returned . 2.3 Data structures
The efficient implementation of our storytelling algorithm hinges on data structures for fast estimation of overlaps ( eg , see [ 7 , 11] ) . In this paper , we combine an AD tree data structure [ 6 ] with the signature tables [ 1 ] approach for efficient similarity search in categorical data . The signature table is constructed before the Initialization step mentioned earlier . Here , objects in the universal set are divided into a predefined number of clusters ( c ) on the basis of their cooccurrence frequencies , forming their signature . All descriptors and their co occurrence frequencies ( used in constructing a decision tree of depth more than 1 ) are also built into an AD tree at this stage . The descriptors at the top level of the AD tree are additionally linked to their signatures . When a similarity search query is issued , only nodes that correspond to signatures of interest need to be investigated . At greater depths in the AD tree , we can either construct individual signature tables for each node in the AD tree or we can opt to use a traditional AD tree node that contains descriptor names and co occurrence frequencies . In our implementation , we used traditional AD tree nodes at depth greater than 1 .
Using these data structures , we can reduce the number of descriptors searched against at each step and improve the speed of computation of stories . For instance , in the first call to the function construct tree , where we are looking for the best match for the class X from among the descriptor set D , we can reduce X to a vector of size c ( X c ) . Also , we keep a count of the number of objects in X that belong to each of the c clusters in the form of a frequency vector f c . The optimistic Jaccard ’s coefficient ( OJ ) between X c and a signature vector V c i corresponding to a set of descriptors can then be calculated by the formula
Pc j=1(f c[j ] ∗ X c[j ] ∗ V c i [ j ] )
OJ ( X c , V c i ) =
Pc j=1 f c[j ]
We then compare X c to all the signature vectors and retain only those for which the optimistic Jaccard ’s coefficient is above θ . This narrows down our search to only those descriptors that have potential to provide the necessary overlap . 2.4 Assessing Significance of Stories
The significance of a story is assessed at the level of each redescription participating in the story . To assess the significance of redescription X ⇔ Y , we use the cumulative hypergeometric distribution to determine the probability of obtaining a rate of co occurrence of X and Y ( over the object domain ) , given their marginal occurrence probabilities , and comparing it to the observed rate of co occurrence by chance . To account for multiple hypothesis testing , the significance threshold is determined by first characterizing the distribution for all descriptors tested and determining if the given redescription has a rate of occurrence more than four standard deviations above the mean . 3 . EXPERIMENTAL RESULTS
Our three experimental studies are meant to illustrate different aspects of our storytelling algorithm and implementation . The first study characterizes word overlaps in large English dictionaries and illustrates scalability of the implementation and how the different parameter settings affect the quality of stories mined . The second study , involving gene sets in bioinformatics , showcases the constructive induction capabilities of CARTwheels when used for storytelling . This study and the third , which builds stories between PubMed abstracts , also illustrate interesting nuggets of discovered knowledge . 3.1 Word Overlaps
In our first study , we implement storytelling for the MorphWord puzzle wherein we are given two words , eg , PURE and WOOL , and we must morph one into the other by changing only one letter at a time ( meaningfully ) . One solution is : PURE → PORE → POLE → POLL → POOL → WOOL . Here we can think of a word as a set of ( letter , position ) tuples so that all meaningful English words constitute the descriptors . Each step of this story is an approximate redescription between two four element sets , having three elements in common . Note that words that are anagrams of each other ( eg , ‘ELVIS’ and ‘LIVES’ ) will not have a Jaccard ’s coefficient of 1 , since position is important .
We harvested words of length 3 to 13 words from the Wordox dictionary of English words ( http://wwwesclubgr/ games/wordox/ ) , yielding more than 160 , 000 words . Con
Figure 5 : Fraction of stories mined as a function of story length , for different values of lc ( Top left ) and different values of b ( Bottom left ) ; Average time required to mine stories as a function of story length , for different values of lc ( Top right ) and different value of b ( Bottom right ) ; for L10 . sistent with the MorphWord puzzle , we restrict all CARTs to be of depth d = 1 and study the effect of θ and b on the number of stories possible , length of stories mined , and time taken to mine stories . For ease of interpretation , we recast Jaccard ’s thresholds in terms of the number of letters in common ( lc ) between two words . Although MorphWord is traditionally formulated with lc = 1 , we explore higher lc values as well . Due to space restrictions , we present our results only on 10 letter words ( L10 ) . We selected 100 , 000 pairs of words at random and tried to find stories between them , with different lc and b settings .
Fig 5 ( top left ) depicts a plot of the fraction of stories ( out of 100 , 000 ) mined with various story lengths as a function of lc , for a branching factor b = 5 . In the plot , a story length of 0 , rather counter intuitively , implies that no story was found for the word pair considered . The critical story length where the majority of stories are mined steadily increases as lc is increased . This is because , as lc is increased , more overlap is required at each step of the story such that it takes longer for one word to morph into another . At the same time , the total number of stories mined decreases as lc is increased , due to the lack of viable redescriptions .
To study the effect of b on the length of stories mined , we focus our attention on lc value of 5 for L10 . Fig 5 ( bottom left ) shows a plot of the fraction of stories mined with various lengths as a function of b . As before , a path length of 0 in the plots implies that no story was found for the word pair considered . Here , the lc value chosen contributes to a high probability of longer stories . As a result the branching factor b plays a crucial role . This is evident in the case of b = 1 , where the excessively greedy strategy is often rendered futile . As b increases , the chances of going down toward the target word increases and more stories are mined .
To study the effect of these parameters on the time required to mine stories , we set b = 5 as before for understanding the role of lc . We computed the average time taken to mine a story , for various story lengths , across all pairs of words considered . Fig 5 ( top right ) shows the plot of this average time against story lengths , for different lc values . The plots indicate that there is a near linear increase in time required , with steeper increases for lower lc values . This is because the lower lc values cause an increase in the number of possibilities ( within the bound of b = 5 ) which must be explored before converging on the shortest path . Also observe the higher times for story lengths of 0 , indicating it takes longer to conclude that stories do not exist . Similar linear trends are observed in time versus the role of b ( Fig 5 , bottom right ) . Here , steeper profiles are witnessed for higher b values . Once again , this is due to the increase in the number of possibilities , although these increases appear to taper off quickly . These figures clearly indicate the underlying tradeoff in mining stories : time versus importance of optimal story lengths .
3.2 Gene Sets
In our second case study , we mine stories among descriptors defined over gene sets in the budding yeast S . cerevisiae . We draw our descriptors from various bioinformatics vocabularies ( eg , the Gene Ontology ( GO ) , microarray experiment clusters , experiment ranges ) as done in previous work [ 10 ] . An example significant story , between the GO categories protein modification and hexokinase , mined for θ = 0.5 , b = 5 , and d = 2 is shown in Fig 7 . Observe that the second descriptor in the story involves a set intersection performed by CARTwheels . A unifying feature that links the genes in this story is their common role
Early expression of yeast genes affected by chemical stress
( PMID:15713640 ; 2005–02–16 )
⇓
Glutathione , but not transcription factor
Yap1 , is required for carbon source dependent resistance to oxidative stress in
Saccharomyces cerevisiae
( PMID:10794174 ; 2000–06–22 )
⇓
The role of glutathione in yeast dehydration tolerance
( PMID:14697735 ; 2003–12–30 )
⇓
The adaptive response of Saccharomyces cerevisiae to mercury exposure
( PMID:11816031 ; 2002–01–29 )
⇓
Cloning , characterization , and expression of the CIP2 gene induced under cadmium stress in Candida sp .
( PMID:9627968 ; 1998–07–09 )
⇓
Mutations in the Schizosaccharomyces pombe heat shock factor that differentially affect responses to heat and cadmium stress
( PMID:10071222 ; 1999–04–07 )
⇓
Genome wide analysis of the biology of stress responses through heat shock transcription factor
( PMID:15169889 ; 2004–05–31 )
⇓
Isolation and characterization of
HsfA3 , a new heat stress transcription factor of Lycopersicon peruvianum
( PMID:10849352 ; 2000–10–10 )
⇓
Heat stress transcription factors from tomato can functionally replace
HSF1 in the yeast Saccharomyces cerevisiae
( PMID:9268023 ; 1997 09 18 )
Figure 6 : An example significant story among PubMed abstracts relating chemical stresses .
Figure 7 : A significant story among gene sets from protein modification to hexokinase . in nutrient control and carbohydrate metabolism , particularly metabolism of glucose phosphate . Considering the three genes in the first descriptor , YKL035W is involved in the reversible conversion of glucose 1 phosphate to UDPglucose via UTP ; YJL164C is a cAMP dependent kinase and binds both YFL033C ( glucose repressed , nutrient control ) and YIL033C ( glycogen accumulation ) ; and YGL158W is a kinase that binds YGL115W ( release from glucose repression ) . Two new genes enter the story with the first redescription , namely YCL040W ( involved in phosphorylation of glucose ) and YFR053C ( a hexokinase also involved in the phosphorylation of glucose in the glycolysis pathway ) . In traversing the second redescription , two additional genes appear : YDR516C is involved in phosphorylation of glucose and , most importantly , also binds YCL040W ( which is present in earlier redescriptions ) . YGR052W is a mitochondrial serine/threonine kinase of unknown function . Through the thread of the story we predict that YGR052W may also be involved in an aspect of glucose metabolism and/or nutrient control .
3.3 PubMed Abstracts
For our final case study , we consider the more than 140 , 000 publications about yeast in the PubMed index and focus on finding stories between publication abstracts . Each abstract is hence a descriptor over terms/keywords . We restrict our CARTs to be of depth 1 and also adopt a weighted Jaccard ’s measure that is more suited to measuring similarity between bags ( details omitted due to space constraints ) . To generate keywords , we focused on the 3756 abstracts containing the keywords ‘yeast AND stress’ and applied stop word removal and Porter ’s stemming as well as manual inspection to cluster similar words together . Over 95 % of the keywords were eliminated by significance testing over the values of T F · IDF ( corresponds to a threshold of about 7 ) , resulting in 6821 unique words .
For this application , it is important to note that the computation of the heuristic function would result in a combinatorial problem since each word does not uniformly have a weight of 1 in our Jaccard ’s calculation . For instance , elimination of different word subsets from a given descriptor , even if they are of the same size , will result in different Jaccard ’s coefficients ; hence we will have to exhaustively search all combinations for removal and addition of keywords to determine the theoretically shortest possible storylength . Thus , for the case of the weighted Jaccard ’s coefficient , we used a simpler heuristic function wherein we estimate the maximum weight we can gain/lose at each step and calculated the number of steps required to gain enough of the weight for the final document and lose enough weight from the current document , to reach a Jaccard ’s coefficient above the threshold for the final document . An example of a significant story we mined using this function is given in Figs 6 ( the PubMed IDs and publication dates are given alongside ) .
The story ( see Fig 6 ) , mined with θ = 0.2 , b = 5 , begins with a high throughput experiment that links chemical stress to gene expression in Saccharomyces cerevisiae , and ends with heat stress transcription factors in tomato . The ‘story line’ was initiated through comparisons between oxidative and heavy metal stresses . This led to a paper identifying a gene from Candida sp . that was expressed when the cells are exposed to cadmium but not copper , mercury , lead or manganese . Interestingly a BLAST search for the en
YGL158WYJL164CYKL035WkinasehexokinaseproteinmodificationYCL040WYFR053CYGL158WYJL164CYKL035WYCL040WYDR516CYFR053CYGL158WYGR052WYJL164CYCL040WYDR516CYFR053Ccell growthand/ormaintenancetransferase,transferringP containinggroups coded protein sequence indicates that the protein is novel . The link between tomato heat stress transcription factors and a cadmium specific gene with no known match in the current databases was through work with the fission yeast Schizosaccharomyces pombe where a study looked specifically at heat and cadmium stress responses . This story hence illustrates the key players in the systems biology of related chemical stresses .
4 . RELATED RESEARCH
We briefly survey related research in three categories : storytelling in information visualization , approaches for topic tracking in documents , and link mining .
In the first category , storytelling has been viewed , not in a data mining context , but as an information organization tool based on narrative structures from real life . Kuchinsky et al . [ 4 ] propose an interactive approach for biological information management using three constructs – items , collections ( of items ) , and stories . A ‘story editor’ is used to form an outline of the story using a template . The players ( items and itemsets ) are then used to fill in the template manually to complete the story .
Pertinent work in the topic tracking community , eg , [ 3 ] focuses on post processing search results into storylines by analyzing bipartite graphs of document term relationships . Here a story is a thread of related documents with temporal as well as semantic coherence . Although similar to our PubMed abstracts case study , these works are focused on unsupervised discovery of all threads whereas we focus on directed storylines between given start and end points . Furthermore , as shown in our GeneSets case study , we allow arbitrary set constructions for the purpose of positing overlaps by casting stories as a generalization of redescriptions . The definition of a ‘thread’ is also different in this work and relies on the notion of node disjoint directed paths .
Link mining [ 2 ] begins with data that can be modeled as a collection of links and , in this sense , storytelling can be approached as a problem of analyzing overlap relationships . However , the links used and sought by us are between sets of items rather than individual items , and these sets are not enumerated beforehand . The concept of stories is also inherently similar in spirit to relational knowledge discovery , eg , [ 8 ] , but observe that our vocabularies are primarily propositional in nature , and defined over a single domain of objects . In future work , we aim to generalize story telling into relational redescription mining where the stories can straddle different domains and employ relationships for navigating across domains .
Finally , the applications presented here suggest comparisons to classical discovery systems such as Swanson ’s Arrowsmith [ 13 ] which can be viewed as seeking stories of length two . Our stories can be of arbitrary lengths with differing complexities of the participating descriptors .
5 . DISCUSSION
By defining stories as chains of redescriptions , we have been able to design a storytelling algorithm as A* search around the outputs of a redescription mining algorithm . We have demonstrated the scalability of this approach using the Word overlaps case study and showcased its potential for knowledge discovery using the Gene sets and PubMed abstracts case studies .
In future work , we aim to investigate other metrics for evaluating stories besides story length , eg , based on the number of objects temporarily brought into the story , the story ’s conformance to prior background knowledge , or using overlap metrics that better mirror a domain scientist ’s conception of set similarity . We also aim to explore connections to works that characterize the structure of partitions [ 5 , 12 ] and investigate whether storylines can be designed around paths in such discrete structures . We also intend to generalize from propositional to predicate vocabularies and cast storytelling in the context of relational redescriptions . This will help provide structured stories that follow a template of connections . Our eventual goal is to establish storytelling as an important tool for reasoning with data and domain theories .
6 . REFERENCES [ 1 ] CC Aggarwal , JL Wolf , and PS Yu . A New
Method for Similarity Indexing of Market Basket Data . In Proc . SIGMOD’99 , pages 407–418 , 1999 .
[ 2 ] L . Getoor . Link Mining : A New Data Mining
Challenge . SIGKDD Explorations , Vol . 5(1):pages 84–89 , 2003 .
[ 3 ] R . Guha , R . Kumar , D . Sivakumar , and R . Sundaram .
Unweaving a Web of Documents . In Proc . KDD’05 , pages 574–579 , 2005 .
[ 4 ] A . Kuchinsky , K . Graham , D . Moh , A . Adler ,
K . Babaria , and ML Creech . Biological Storytelling : a Software Tool for Biological Information Organization based upon Narrative Structure . ACM SIGGROUP Bulletin , Vol . 23(2):pages 4–5 , Aug 2002 . [ 5 ] M . Meila . Comparing Clusterings by the Variation of Information . In Proc . COLT’03 , pages 173–187 , 2003 .
[ 6 ] AW Moore and MS Lee . Cached Sufficient
Statistics for Efficient Machine Learning with Large Datasets . JAIR , Vol . 8:pages 67–91 , 1998 .
[ 7 ] A . Nanopoulos and Y . Manolopoulos . Efficient
Similarity Search for Market Basket Data . VLDB Journal , Vol . 11(2):pages 138–152 , 2002 .
[ 8 ] J . Neville and D . Jensen . Supporting Relational
Knowledge Discovery : Lessons in Architecture and Algorithm Design . In Proc . Data Mining Lessons Learned Workshop , ICML’02 , 2002 .
[ 9 ] L . Parida and N . Ramakrishnan . Redescription
Mining : Structure Theory and Algorithms . In Proc . AAAI’05 , pages 837–844 , 2005 .
[ 10 ] N . Ramakrishnan , D . Kumar , B . Mishra , M . Potts , and RF Helm . Turning CARTwheels : An Alternating Algorithm for Mining Redescriptions . In Proc . KDD’04 , pages 266–275 , 2004 .
[ 11 ] S . Sarawagi and A . Kirpal . Efficient Set Joins on
Similarity Predicates . In Proc . SIGMOD’04 , pages 743–754 , June 2004 .
[ 12 ] DA Simovici and S . Jaroszewicz . An Axiomatization of Partition Entropy . IEEE Transactions on Information Theory , Vol . 48(7):pages 2138–2142 , 2002 .
[ 13 ] DR Swanson and NR Smalheiser . An Interactive System for Finding Complementary Literatures : A Stimulus to Scientific Discovery . Artificial Intelligence , Vol . 91(2):pages 183–203 , 1997 .
