A Local Scalable Distributed Expectation Maximization Algorithm for Large
Peer to Peer Networks
Kanishka Bhaduri
MCT Inc . , NASA Ames Research Center
MS 269 2 , Moffett Field , CA 94035
KanishkaBhaduri 1@nasagov
Ashok N . Srivastava
NASA Ames Research Center
MS 269 2 , Moffett Field , CA 94035
AshokNSrivastava@nasagov
Abstract—This paper describes a local and distributed expectation maximization algorithm for learning parameters of Gaussian mixture models ( GMM ) in large peer to peer ( P2P ) environments . The algorithm can be used for a variety of well known data mining tasks in distributed environments such as clustering , anomaly detection , target tracking , and density estimation to name a few , necessary for many emerging P2P applications in bioinformatics , webmining and sensor networks . Centralizing all or some of the data to build global models is impractical in such P2P environments because of the large number of data sources , the asynchronous nature of the P2P networks , and dynamic nature of the data/network . The proposed algorithm takes a two step approach . In the monitoring phase , the algorithm checks if the model ‘quality’ is acceptable by using an efficient local algorithm . This is then used as a feedback loop to sample data from the network and rebuild the GMM when it is outdated . We present thorough experimental results to verify our theoretical claims .
Keywords peer to peer ; local algorithms ; expectation maxi mization
I . INTRODUCTION
Expectation Maximization ( EM ) is a powerful statistical and data mining tool which can be used for a variety of tasks such as clustering , estimating parameters from the data in the presence of hidden variables , anomaly detection , target tracking and more . In 1977 , Dempster et al . [ 1 ] presented the seminal work on EM and its application for estimating the parameters of a Gaussian Mixture Model ( GMM ) . The authors showed that given a sample of data , there is a two step process which can estimate certain unknown parameters of the data by judiciously choosing hidden variables . The classical EM algorithm is well understood and produces satisfactory estimates of the parameters when the data is centralized .
However , there exist emerging technologies where the data is not located at a central location but rather distributed across a large network of nodes or machines connected by an underlying communication infrastructure . The next generation Peer to Peer ( P2P ) networks such as Gnutella , BitTorrents , and the sensor networks offer some examples . A scalable and distributed EM algorithm developed for such networks can be deployed for a variety of tasks such as collaborative target tracking , clustering , density estimation , data compaction , and surveillance in wireless sensor networks [ 2][3 ] .
To solve this problem , in this paper we develop an asynchronous P2P distributed ( PeDEM ) algorithm for monitoring and subsequent reactive updating of a GMM model . Our algorithm is provably correct ie given all the data , our algorithm will converge to the same result produced by a similar centralized algorithm . The algorithmic framework is local , in the sense that the computation and communication load at each node is independent of the size or the number of nodes of the network . This guarantees high scalability of the algorithm to possibly millions of nodes . The proposed methodology takes a two step approach for building and maintaining GMM parameters in P2P networks . The first step is the monitoring phase in which , given an arbitrary estimate of the GMM parameters , our algorithm checks if they are valid with respect to the current data within userspecified thresholds . If not , this algorithm raises a flag , whereby we employ a convergecast broadcast technique to rebuild the model parameters . This step is known as the computation phase . The specific contributions of this paper are as follows : ( 1 ) To the best of the authors’ knowledge this is one of the first attempts on developing a completely asynchronous and local algorithm for monitoring the GMM parameters in P2P networks . ( 2 ) Besides this direct contribution , this paper shows how second order statistics can be directly monitored in a P2P network .
In the next section we present the work related to this research .
II . RELATED WORK
Work related to this research can be subdivided into two major areas — distributed EM algorithms and computation in large distributed systems . Distributed EM Algorithms : In standard EM algorithm , the task is to estimate some unknown parameters from the given data in the presence of some unobserved or hidden variables . Dempster et al . [ 1 ] proposed an iterative technique alternating between the E step and M step that solves this estimation problem . Most of the effort has been focused on efficiently computing the updates in the M step ( which are essentially averages ) in a distributed fashion . Nowak [ 3 ] proposed a distributed EM ( DEM ) algorithm in which a ring topology is overlaid over the original network encompassing all the nodes and the updates are passed from one node to the next in sequence . Newscast EM [ 4 ] , proposed by Kowalczyk and Vlassis uses gossip style distributed computation to compute the parameters of the M step . Using deterministic averaging technique , Gu [ 2 ] proposed an EM algorithm for GMM which uses graph Laplacian for asymptotic convergence . Wolfe et al . [ 5 ] developed a fully distributed EM algorithm based on MapReduce and junction tree topology . Unlike these algorithms , the technique proposed in this paper is local and hence offers excellent scalability . Data Mining in Large Distributed ( P2P ) Systems : Several algorithms have been proposed for data mining in large P2P systems . Probabilistic algorithms such as the P2P kMeans algorithm by Bandyopadhyay et al . [ 6 ] , the newscast model by Kowalczyk et al . [ 7 ] , distributed inner product identification by Das et al . [ 8 ] compute the results within some error bounds . Deterministic algorithms produce exactly the same results compared to a centralized algorithm eg [ 9 ] and [ 10 ] . Local algorithms for P2P data mining include the majority voting and protocol developed by Wolff and Schuster [ 11 ] , outlier detection [ 12 ] , meta classification [ 13 ] , decision trees [ 14 ] and the generic local algorithms [ 15][16 ] .
III . PRELIMINARIES
In this section we present some background material necessary to understand our PeDEM algorithm that we have developed .
A . Expectation Maximization
EM [ 1 ] is an iterative optimization technique to estimate some unknown parameters Θ given some data U . It is also assumed that there are some hidden variables J . The EM algorithm iteratively alternates between two steps to maximize the posterior probability distribution of the parameters Θ given U : ( 1 ) E Step : estimate the Expected value of J given Θ , U . ( 2 ) M Step : re estimate Θ to Maximize the likelihood of U , given the estimates of J found in the previous E step .
−→ For GMM , a multidimensional Gaussian mixture for a x ∈ Rd is defined as the weighted combi random vector nation : k . p(−→x ) =
πsp(−→x |s ) s=1
' of k Gaussian densities where the s th density is given by −1(−→x − −→μs)/2 p(−→x |s ) = fi−(−→x − −→μs)T
Cs
1
( 2π)d/2|Cs|1/2 exp by parameterized
=
−→ each vector its [ μs1μs2 . . . μs.d]T and covariance matrix μs Cs=(x − μs)(x − μs)T . πs = p(s ) is the prior probability multi dimensional samples X = {−→ the s th density generates a data point . Given n that the task x1 , . . . ,
−→ xn} , mean is to estimate the set of parameters by maximizing the log likelihood of the parameters given the data : −→xa ;
L(Θ|X ) = log
−→xa|Θ ) =
−→μs , Cs ) n . k .
πsN ( nff log p( a=1 a=1 s=1
Using EM for GMM , the E step and the M step can be written as :
E step ( estimate the contribution of each point ) : qs,a =
( k −→xa ; πsN ( r=1 πrN (
−→μs , Cs ) −→xa ;
−→μr , Cr )
M step ( recompute the parameters ) :
πs = −→μs =
( n ( n ( n ( n a=1 qs,a n
−→xa a=1 qs,a ( n a=1 qs,a −→xa − −→μ s)( a=1 qs,a( a=1 qs,a
( 1 )
( 2 )
( 3 )
−→xa − −→μ s)T
−→ xa ;
Cs = −→ where N ( μs , Cs ) denotes the pdf of a normal distribu−→ μs and covariance Cs . Note that tion with input the above computation needs to be carried out for all the k Gaussian components .
−→ xa , mean
( 4 )
In the next few sections we shift our focus to distributed computation of these parameters and discuss some assumptions and necessary background material .
B . Notations and Assumptions Let V = {P1 , . . . , Pp} be a set of peers connected via an underlying communication infrastructure . The set of Pi ’s neighbors , Γi , is known to Pi . Each peer communicates with its immediate neighbors ( one hop neighbors ) only . At time t , let G denote a collection of data tuples which have been generated from k Gaussian densities having unknown parameters and unknown mixing probabilities . The tuples are horizontally distributed over a large ( undirected ) network of machines ( peers ) . The local data of peer Pi at time t is Si = −→ −→ xi,j = [ xi,j1xi,j2 . . . xi,j.d]T [ xi,1 , ∈ Rd . Here mi denotes the number of data tuples at Pi and d denotes the dimensionality of the data . The global input is denoted by G =
−−−→ xi,mi ] , where
−→ xi,2 , . . . ,
)
Si . i=1,,p
We assume that communication among neighboring peers is reliable and ordered . These assumptions can be imposed using heartbeat mechanisms or retransmissions proposed elsewhere [ 15 ] . Furthermore , it is assumed that data sent from Pi to Pj is never sent back to Pi . One way of ensuring this is to assume that communication takes place over a communication tree – an assumption we make here .
C . Problem Formulation in P2P Scenario
When all the data is available at a central location , the update equations for the iterative EM algorithm are given by Equations 1–4 . However , in the distributed setup , all the data is not available at a central location . Therefore , for any peer Pi , the log likelihood per data point and the update equations for the EM algorithm , can be written as : −→μs , Cs )
( p i=1 ff
L(Θ|G ) = qi,s,a = fl a=1 log
−→μs , Cs
( mi
( k ( p −−→xi,a ; s=1 πsN ( fl πsNfi−−→xi,a ; i=1 mi r=1 πrNfi−−→xi,a ; ( k −→μr , Cr ( mi ( p ( p ( mi ( p ( mi ( p ( p ( mi ( p
−−→xi,a ( mi a=1 qi,s,a −−→xi,a − −→μ s)( a=1 qi,s,a( a=1 qi,s,a a=1 qi,s,a a=1 qi,s,a i=1 mi i=1 i=1 i=1 i=1 i=1
−−→xi,a − −→μ s)T
( 5 )
( 6 )
( 7 )
( 8 )
( 9 )
D . Monitoring Functions
As a building block of PeDEM , we use an efficient , provably correct , and local algorithm for monitoring functions of average vectors in Rd , where the vectors are distributed in a P2P network .
Pj∈Γi
)
Peers communicate with one another by sending sets of points in Rd or statistics as defined later in this section . Let Xi,j denote the last set of points sent by peer Pi to Pj . Assuming reliable messaging , once a message is delivered both Pi and Pj know Xi,j and Xj,i . There are three sets of vectors which are crucial to the monitoring algorithm . The knowledge of Pi is Ki = Si Xj,i . Ki can also be initialized using combinations of vectors defined on Si ( instead of only Si ) as we will present in the next section . The agreement of Pi with any of its neighbors Pj is Ai,j = Xi,j ∪ Xj,i . The withheld knowledge of Pi with respect to a neighbor Pj is Wi,j = Ki \ Ai,j . In the next section we present a theorem which shows how we can convert this monitoring problem into a geometric problem for an efficient solution . For this we need to split the domain into convex regions since the stopping condition we describe later ( Theorem IV.1 ) relies on this . The following definition states the properties of these convex regions .
Finally , for any
Definition III1 A collection of non overlapping regions RF = {R1 , R2 , . . . , R . , T} is a cover of region Rd , invariant with respect to a function F : Rd → O ( where O is an arbitrary range ) , if ( 1 ) every Ri ∈ RF ( except T ) is convex ,
( 2 ) F is invariant in Ri ie , ∀(x , y ) ∈ Ri,F(x ) = F(y ) , and ( 3 ) T denotes the area of the domain , not encompassed by
. i=1 Ri , known as the tie region . −→ x ∈ Rd , let RF(
−→ x ) denote the first −→ region in RF which includes x . The precise specification of the convex regions will depend on the definition of F . Since these sets can be arbitrarily large , below we define sufficient statistics on each set which are far more efficient to communicate . Set Statistics : For each set , define two statistics : ( 1 ) the average which is the average of all the points in the respective sets ( eg Si , Ki , Ai,j , Wi,j , Xi,j , Xj,i and G ) , and ( 2 ) the weights of the sets denoted by ω(Si ) , ω(Xi,j ) , ω(Xj,i ) , ω(Ki ) , ω(Ai,j ) , ω(Wi,j ) , and ω(G ) . Each peer communicates these two statistics for each set . We can write the following expressions for the weights and the average vectors of each set : Knowledge — ω(Ki ) = ω(Si ) +
ω(Xj,i )
. .
Pj∈Γi
Si +
Pj∈Γi
ω(Si ) ω(Ki )
— Ki =
ω(Xj,i ) ω(Ki ) Agreement — ω(Ai,j ) = ω(Xi,j ) + ω(Xj,i ) — Ai,j = ω(Xj,i ) ω(Ai,j ) Withheld — ω(Wi,j ) = ω(Ki ) − ω(Ai,j )
ω(Xi,j ) ω(Ai,j )
Xi,j +
Xj,i
Xj,i
E step :
M step :
πs = −→μs =
Cs = where the sum is taken over all peers’ data . Note that computation in the E step is entirely local to a peer . However , for the log likelihood and the M step , a peer needs information from all the nodes in the network in order to recompute the parameters . In this paper , we consider a monitoring version of this problem : Given a time varying data set and pre computed initial values of these parameters ( built from a centralized or sampled data ) to all peers , do these parameters describe the union of all the data held by all the peers in terms of an appropriately low log likelihood function ?
Our goal is to develop a framework under which each peer ( 1 ) checks if the current parameters of the GMM are up to date with respect to G , and ( 2 ) recomputes the models whenever deemed unfit . For a centralized EM with static data , convergence occurs when the difference of the log likelihood in two subsequent iterations becomes a constant . However , for our distributed setup , since we are considering dynamic data , we relax this criteria and consider a solution to be admissible when it is within a user defined threshold of its true value . For the monitoring ffl−→ μs,fflCs , . . .} , denote the parameters problem , let ffiΘ = {ffiπs , to check ( 1 ) if L(ffiΘ|G ) < , or ( 2 ) if these parameters are that were calculated offline based on some past data , and disseminated to all the peers . The monitoring problem is valid with respect to the current data of all the peers . Below is a formal problem definition . problem is to check if :
Problem Definition : Given a time varying dataset Si , user defined thresholds , 1 , 2 , and 3 , and pre computed estimates ffiΘ , for each Gaussian distribution , the monitoring — either L(ffiΘ|G ) < , or
−→ < 3 μs −ffl−→ |πs − ffiπs| < 1 , — where '·' F denotes the Frobenius norm of a matrix . One needs to either threshold the log likelihood of the data or monitor each parameter separately . We discuss the tradeoff of these situations later .
'Cs'
−fflCs
2
< 2 ,
μs
F
∀s
Ai,j
ω(Ki ) ω(Wi,j )
Ki − ω(Ai,j ) ω(Wi,j )
— Wi,j = Note that these computations are local to a peer . The general methodology for computing F(G ) requires us to cover the domain of F using non overlapping convex regions . In the next section we present a stopping condition for the peers to converge to the correct result .
IV . GLOBALLY CORRECT TERMINATION CRITERIA The goal of the monitoring algorithm is to raise a flag whenever the estimates of the parameters are no longer valid with respect to G . The EM monitoring algorithm guarantees eventual correctness : once computation terminates , each peer computes the correct result compared to a centralized setting . The following theorem allows a peer to stop sending messages and achieve a correct termination state ie decide if F(G ) > or < solely based on Ki , Ai,j , and Wi,j . Theorem IV1 [ Termination Criteria ] Let P1 , . . . , Pn be a set of peers connected to each other via a spanning tree G ( V , E ) . Let G , Ki , Ai,j , and Wi,j be as defined in the previous section . Let R be any region in RF . If at time t no messages traverse the network , and for each Pi , Ki ∈ R and for every Pj ∈ Γi , Ai,j ∈ R and either Wi,j ∈ R or Wi,j = ∅ , then G ∈ R . Proof : Consider a network G(V , E ) . Let us select a leaf peer Pi for which Ki ∈ R and for every Pj ∈ Γi , Ai,j ∈ R and either Wi,j ∈ R or Wi,j = ∅ . Let us eliminate Pi by sending all of its withheld knowledge Wi,j to Pj ∈ Γi . Now , the new knowledge of Pj becomes K . j = Kj ∪ Wi,j . Since G is a tree , Kj ∩ Wi,j = ∅ . Therefore , for some η ∈ [ 0 , 1 ] , K . j = η · Kj + ( 1 − η ) · Wi,j . Since both Kj and Wi,j ∈ R , K . j in R too . Using a similar argument on the withheld knowledge of Pj , we can show that it also belongs to R as a result of this unification . Continuing , we will be left with one peer P1 whose K1 ∈ R . Also under the said unification , K1 = G since no data was lost . Thus , G ∈ R .
The above theorem allows a peer to stop the communication and output F(Ki ) which will eventually become equal to F(G ) . A peer can avoid communication even if its local data changes or the network changes as long as the result of the theorem is satisfied . Indeed , if the result of the theorem holds for every peer , and all messages have been delivered , then Theorem IV.1 guarantees this is the correct solution . Otherwise , if there exists one peer Pz for which the condition does not hold , then either of these two things will happen : ( 1 ) a message will eventually be received by Pz or , ( 2 ) Pz will send a message . In either of these two cases , Kz will change thereby guaranteeing globally correct convergence .
V . MONITORING GMM PARAMETERS
We present the monitoring of the log likelihood of the data and the three parameters given in Equations 7–9 in the next few sections . Note that in practice we need to monitor either the log likelihood of the data or the GMM parameters .
A . Monitoring log likelihood i=1 mi
: L(ffiΘ|G ) =
Monitoring the average log likelihood of the global data is equivalent to checking if the following quantity is less
< , where Li(ffiΘ|Si ) is the
( p i=1 Li(ffiΘ|Si ) ( p log likelihood of all the points available at peer Pi . Thus each peer has a number in R , and the goal is to check if the average of those numbers is greater than . This can be done using the framework presented in Section III D . Each peer checks if its knowledge is in [ 0 , ) or ( ,∞ ) . We discuss the details of how this is done in Section V . Therefore , for monitoring L(ffiΘ|G ) , the following initializations need to be
L log
.Si = carried out : ( 1 ) M ( 2 ) RF = {[0 , ) , ( ,∞)} . In this case T = { } . Since monitoring πs is the same as
L(ffiΘ|G ) , we do not present it here due to shortage of space .
−→ μs , Cs )
−→ xi,1 ;
, . . .
( s=1 πsN ( k ff
B . Monitoring μs
Following a similar argument , monitoring to thresholding the following quantity :
Err(−→
μs ) =
−→ μs −−→
μ s
=
( p
( mi ( p
( mi i=1 a=1 qi,s,a i=1 a=1 qi,s,a
−→ μs is equivalent −−→
< 2 xi,a −−→ −−→ xi,a − ffl−→
μ s mi
(
−→ μs ) < 2 , where the error vector is the average of qi,s,a μ s across all the peers . However the average in this case is not taken with respect to the number of tuples in the dataset Si , but rather over all the qi,s,a ’s . As a result , we set |Si| = a=1 qi,s,a . Moreover , for this problem in R2 , the geometric interpretation to the monitoring problem is −→ to check if the L2 norm of the vector difference between μ s lies inside a circle of radius 2 . Geometrically , the area in which Err( is inside the sphere and hence is already convex in Rd . However , outside of the sphere is not convex . Hence random tangent lines are drawn on the surface of the sphere by choosing points
μs − ffl−→ fflu1 , . . . ,fflur on the sphere ( the same points across all −→ peers ) . Each of these half spaces is convex . To check if z · ffiui > 2 . The following the first point ffiui such that checks if '−→ z is inside the sphere , a peer simply an arbitrary point z ' < 2 . To check if it is outside , a peer selects −−→ xi,a−−→ ( z · ffiui > 2} fl i=1 {−→ −→ denotes the initialization necessary for this instance of the problem M μs : M μs.Si =
M μs.ω(Si ) = RF = {−→ In this case T denotes the area between the polygon formed by the half spaces and the circle .
( mi z ∈ Rd : fl z ∈ Rd : ||−→ z || < 2} mi a=1 qi,s,a ,
( mi a=1 qi,s,mi a=1 qi,s,a
R1,,Rr
−→
Rin
μ s
, r
. s i
F i=1 i=1 i=1 k=1
2 y
2 i,a.d
− i=1 i=1 a=1 qi,s,a i=1 a=1 qi,s,a a=1 qi,s,a n s =
C
'Cs'2
( p
(
⎞⎠ 2 a=1 qi,s,axi,a.k
Err(C n
( mi s ) = C n
2 a=1 qi,s,ax i,a.k
F ≤ d .
−→ yi,a =
( mi s > 3 . 'Cs'
F is not a convex function , but C n
By taking the square root and re substituting
C . Monitoring Cs The last parameter that we need to monitor is the covariance matrix Cs . A natural extension of the L2 norm in this case is the Frobenius norm . Let μs . It can be shown that ,
−−→ xi,a − −→ i,a.1 + · · · + y a=1 qi,s,a −→ ( p ( mi yi,a , we get , ( mi ( p −fflCs < 3 ie 'Cs' F <fflCs+ 3 .
⎛⎝( p !( p ( mi ( mi ( p We need to check if 'Cs' Since 'Cs' s is , we monitor the latter one instead . Note that , C n F < 3 . C n s for thresholding is more conservative : in the worst case we will have more false alerts for building new models but no false dismissals . ( 2d Let Err(C n follows : ∀(s1 , . . . , s2d ) ∈ R , g ( s1 , . . . , s2d ) = ⎛⎝( p
−fflCs . Let g : R2d → R be defined as −fflCs − 3 . We have the following key result : i=1 si − i=d+1 s2 ⎞⎠ < 0 . ( mi s < 3 ⇒ 'Cs' F > 3 . Therefore , using C n s ) < 3 ⇔ ( mi
Each peer can locally compute the 2 d dimensional vector . Then the goal is qi,s,a zero thresholding g applied to the average of local vectors . Taking the Hessian of −g it can be easily shown that −g is convex . The outside of g can be decomposed into fflu1 , . . . ,ffluz on g . Checking if g(Ki ) < 3 is equivalent to convex regions using tangent lines placed at random points ffiui such that Ki · ffiui > 'ffiui' . We then apply the theorem for checking if Ki lies inside g . If not , we find the first point half space defined by ffiui . s ) can be both positive or negative , s )| < 3 . Therefore , we need we need to check if |Err(C n two monitoring instances denoted by M Cs 2 . The ( mi following denotes the datasets and convex regions for this ( monitoring problem . 1 .Si = M Cs 1 .ω(Si ) = M Cs 2 .Si = −M Cs M Cs RF = D . Algorithm
( z · ffiui > 'ffiui'$ mi a=1 qi,s,a , 1 .Si , M Cs z ∈ R2d : g(z ) < 0
( mi i,a.d , xi,a.1 , . . . , xi,a.d
Now , since Err(C n i,ad,xi,a1,,xi,a1 )
2 .ω(Si ) = −→
2 i,a.d , xi,a.1 , . . . , xi,a.d x2 i,a.1 , . . . , x2
#−→
( p mi a=1 qi,s,a a=1 qi,s,a(x
2 x i,a.1 , . . . , x and M Cs
2 i,a1,,x
2 i=1 a=1 qi,s,a i=1 a=1 qi,s,a a=1 qi,s,a ff z i=1
,
. d ff
1 g
Having discussed each of the monitoring problems , we are now in a position to present the algorithms for monitoring the parameters . Using log likelihood , we need to instantiate only one monitoring problem . However , using the parameters themselves , we need to monitor the prior , mean , and covariance for each Gaussian s ∈ {1 , . . . , k} .
In order to use Theorem IV.1 for developing a monitoring algorithm , the following steps must be followed : ( 1 ) specify the input to the algorithm ( ie Si ) , and ( 2 ) specify the cover ie RF . For each of the monitoring problems , these presents the pseudo code for monitoring L(ffiΘ|G ) . The other are already specified in the previous sections . Algorithm 1 Input : , RF , Si , Γi , L and ffiΘ computations can be performed in a similar fashion .
2"
!
Output : Set
L = f lag
L
.Ki >
1 if M 0 otherwise
L
Initialization : Initialize M On any Event : begin
L
L fi
.ω ( Xj,i ) ;
= T then if RF M M MLω(Ki)MLKi−MLω(Xj,i)MLXj,i fl forall Pj ∈ Γi do .Ki L M .ω ( Ki ) − M .ω ( Xi,j ) ← M L .Xi,j ← L flfl fi ML.ω(Xj,i ) flfl fi & .Ki .Ai,j '∈ RF L L M M .Ki .Wi,j '∈ RF L L M M .Ki .ω ( Wi,j ) = 0 .Ai,j '= M L L L then M M L L .ω ( Xj,i ) and M .Xj,i such Compute new M .Ki ) .Wj,i ∈ RF ( M .Aj,i , M L L that M end if CurrT ime − LastM sgSent > L then .ω(Xi,j ) ) to Pj fi %fi %fi
SendMsg(M end if
.Xi,j , M fl
L
L
L
; end else Wait ( L − ( CurrT ime − LastM sgSent ) ) time and check conditions again fl end fi end On MessageRecvd begin .Xj,i ← X ; M .ω ( Xj,i ) ← ω(X ) ; M .Ki , M L L Recompute M
L L
X , ω(X ) from Pj :
L end ff
.Wi,j ;
.Ai,j , M
’’ > 2 or g any peer Pi . For any peer Pi , the input to the algorithm are , RF ,
Algorithm 1 : Pseudo code for monitoring L(ffiΘ|G ) for Si , Γi , L and ffiΘ ( we describe L later ) . The output of ’’M μs .Ki each monitoring instance is a flag which is set if the corresponding Ki exceeds the threshold eg if M πs 1 .Ki > 1 > 0 . In the initialization or phase , it initializes its local statistics Ki , Ai,j and Wi,j according to the equations in Section III D . The algorithm is entirely event driven . Events can be one of the following : a change in local data Si , message received or a change in the set of neighbors Γi . If one of these things happen , a peer checks if the conditions of Theorem IV.1 are satisfied . First peer Pi finds the active region : the region R ∈ RF in which Ki lies ie R = RF(Ki ) . If , R = T , ie the knowledge lies in the tie region , the condition of the theorem does not guarantee a solution and hence the only correct solution is
1 .Ki M Cs flooding all of its data . On the contrary , if ∀ Pj ∈ Γi , both Ai,j,Wi,j ∈ R , Pi does nothing and can rely on the result of the theorem for correctness . If Ai,j /∈ R or Wi,j /∈ R , the result of the theorem dictates Pi to send a message to Pj . Other than these two cases , a peer need not send any message even if its local data has changed .
Message sending is performed by the SendMsg method . When R = T , the peer has to flood whatever knowledge it has . Thus it sets Xi,j and ω(Xi,j ) equals to its knowledge minus what it had received from Pj previously . It then sends this to Pj . However , when R fi= T , a peer can refrain from sending all data . This technique of sending all the data has adverse effects on the communication in a dynamic data scenario . This is because if a peer communicates all of its data , and the data changes again later , the change is far more noisy than the original data . So we always set Xi,j and ω(Xi,j ) such that some data is retained while still maintaining the conditions of the theorem . We do this by checking with an exponentially decreasing set of values of ω(Wi,j ) until either all Ki , Ai,j and Wi,j ∈ R , or ω(Wi,j)=0 . If the latter happens , it means that a peer cannot have any withheld knowledge and it has to send all of its knowledge in order to satisfy the conditions of the theorem . Lastly , when Pi receives a message ( X and ω(X ) ) from Pj , it sets Xj,i ← X and ω(Xj,i ) ← ω(X ) and checks the conditions of Theorem IV.1 again .
To prevent message explosion , in our event based system we employ a “ leaky bucket ” mechanism which ensures that no two messages are sent in a period shorter than a constant L . This technique is not new but has been used earlier [ 14 ] . Note that this mechanism does not enforce synchronization or affect correctness ; at most it might delay convergence . We explore its effect thoroughly in our experiments . Next we discuss the correctness of PeDEM . Correctness and Complexity Analysis : For PeDEM , computation will continue for each node unless one of the following happens : ( 1 ) for every node , Ki = G or , ( 2 ) for every Pi and every neighbor Pj , Ki , Ai,j,and Wi,j ∈ R . In the former case , obviously F(Ki ) = F(G ) . In the latter case , Theorem IV.1 dictates that G ∈ R . Therefore , in either of the cases F(Ki ) = F(G ) . Determining the communication complexity of local algorithms in dynamic environments is still an open research issue . Researches have proposed definitions of locality [ 15][8 ] . For PeDEM , the worst case communication complexity is bounded by O(|V |2 ) when G = . Since this does not happen often in practice , local algorithms exhibit good scalability ( in most cases independent of |V | ) as shown in our experiments . In the next section we describe how we can use this monitoring algorithm in closed loop .
VI . COMPUTING NEW MODELS
Input : , 1 , 2 , 3 , RF , Si , Γi , L , B , ffiΘ and τ Output : New model ffiΘ
Initialization : Initialize vectors ; Set LastDataAlert ← ∞;Datasent ← f alse ; On Receiving a message : begin
( MsgType , Recvd Pj ) ← MessageRecvdFrom(Pj ) if M sgT ype = M onitoring M sg then
Update Monitoring Algorithm ; end if M sgT ype = P attern M sg then
Update models;Forward new models to Γi ; Datasent = f alse;Restart PeDEM ; end if M sgT ype = Dataset M sg then
N umRecvd = Count num recvd( ) ; & Recvd Dataset = Recvd Dataset if N umRecvd=Γi − 1 then f lag=Output Monitoring Algorithm( ) ; if Datasent = f alse f lag = 1 then if CurrT ime − LastDataAlert > τ then
Recvd Pj ;
D=Sample(Si , Recvd Dataset , B ) ; Datasent = true ; Send D to remaining neighbor ; end else LastDataAlert=CurrTime;Check back in τ time ; end if f lag=0 then LastDataAlert ← ∞ end if N umRecvd=Γi then
D=Sample(Si , Recvd Dataset , B ) ; N ewM odel=EM(D ) ; Forward N ewM odel to all neighbors ; Datasent=f alse ; Restart Monitoring Algorithm ; end end end On an event : Run Monitoring Algorithm ; flag=Output Monitoring Algorithm( ) ; if flag=1 and Pj=IsLeaf( ) then
Execute the same conditions as MsgType=Dataset Msg ; end Algorithm 2 : Pseudo code for PeDEM Algorithm .
Once this happens , we need to build new models . Building global models in a distributed environment is communication intensive . Here we rely on the outcome of our correct and efficient local algorithm to generate a trigger dictating the need for re building the model . Given enough time to converge , the correctness of our monitoring algorithm ensures that even simple techniques such as best effort sampling from the network may be sufficient to produce good results . If the model is not satisfactory , the underlying monitoring algorithm would eventually indicate this and a new model building will be triggered .
The monitoring algorithm presented in the previous section generates an alert whenever F(Ki ) goes outside .
The idea of model computation in the network is very simple . Peers engage in a convergecast broadcast process .
)
|
G Θ ( L
50
40
30
20
10
0 0
0.5
1
1.5
2
Time
2.5
3
3.5
4 x 106
|
ε < ) G Θ ( L h t i w s r e e p f o %
100
50
0 0
0.5
1
1.5
2
Time
2.5
3
3.5
4 x 106 s e g a s s e M d e z i l a m r o N
2
1.5
1
0.5
0 0
0.5
1
1.5
2
Time
2.5
3
3.5
4 x 106
Figure 1 . Plot of typical experiments . Each experiment is run for several epochs . Quality is measured as the percentage of peers correctly detecting an alert . Cost is measured during the entire experiment and during stationary phases . Last 80 % of the time refers to stationary phase to ignore transitional effects . The dotted line in Figure 1(a ) refers to =70
The monitoring algorithm raises a flag whenever the model is a misfit with respect to the global data . If this happens for any peer , it first waits for a specific amount of time which we call the alert mitigation time τ to see if the alert is indeed due to a data change or random noise . If the alert exists even after τ units of time , the peer checks if it has received data from all its neighbors except one . If yes , it generates a sample of user defined size B from its own data and each of its children weighing each point inversely as the size of its subtree such that each point has an equal probability of being included in the sample . It then sends the sample to its parent and marks its state as convergecast . Whenever a peer receives data from all peers , it becomes the root of the convergecast tree and employs a centralized EM algorithm to build new model parameters . It then sends these models to itself and marks its state as broadcast . Whenever a peer Pj gets new models from Pi , it forwards those to all its neighbors in Γj except Pi . Pj then moves from the convergecast to the broadcast phase . Because we do not impose the root of the tree , it may so happen that two peers get all the data simultaneously . We break the tie in such scenarios using the id of the nodes . For the same convergecast round , assuming i > j , if both Pi and Pj build new models , Pi is allowed to propagate the models in the network . Algorithm 2 presents the pseudo code of PeDEM . As shown , there are three types of messages : M onitoring M sg , P attern M sg and Dataset M sg . The monitoring message is passed to the underlying monitoring algorithm . The pattern message is received as part of the broadcast round while the datasets are received when the peer engages in the convergecast round .
VII . EXPERIMENTAL RESULTS
We demonstrate the performance of PeDEM on a synthetic data generator and a real world dataset ( see Section VII C ) . Our implementation of the algorithm was done in Java using the DDMT1 toolkit developed at UMBC . For the topology , we used the BRITE topology generator2 . We experimented with the Barabasi Albert ( BA ) model since it generates edge delays ( in millisec ) simulating the
1http://wwwumbcedu/ddm/Software/DDMT/ 2http://wwwcsbuedu/brite/ internet . We convert the edge delays to simulator ticks for time measurement since wall time is meaningless when simulating thousands of peers on a single PC . For all our experiments the average edge delay is 1100 simulator ticks . On top of each network generated by BRITE , we overlay a communication tree .
For synthetic data experiments , the input data of a peer is a set of vectors in Rd generated according to multidimensional GMM . More specifically , for a given experiment , we fix the prior probabilities , the means and the covariance matrices . Whenever a peer needs an additional data point , it first selects a Gaussian s with corresponding −→ probability πs and then generates a Gaussian vector in Rd μs , Cs . The prior , means and the with mean and covariance covariances are changed randomly at controlled intervals to create an epoch change .
The two quantities of measurement are the quality of the results and the cost . When the monitoring algorithm is used merely as a detector ( open loop mode ) , quality refers to the percentage of the peers which correctly detect a change in the GMM model using ( i ) L(ffiΘ|G ) , ( ii ) mean , and ( iii ) covariance monitoring . When PeDEM is used for rebuilding the model ( closed loop ) , quality refers to the average loglikelihood over the entire experiment compared against a centralized execution . We plot both the mean and standard deviation for 10 independent trials ( two columns for each measurement in Table I ) . Due to the dynamic nature , the cost of our algorithm , referred to as normalized messages , denotes the number of messages exchanged per peer per unit of leaky bucket . For a broadcast based algorithm , its normalized message is 2 , assuming 2 neighbors per peer on average . We report both the stationary and overall messages . We also report , where appropriate , messages required for convergecast and broadcast of the model .
A . Results : EM Monitoring
Figure 1 and Table I demonstrate the dependence of the monitoring algorithm on the following algorithm and system parameters : size of local dataset |Si| ; error thresholds , 1 , 2 , and 3 ; size of leaky bucket L ; number of peers p ; dimension of the problem d ; and number of Gaussians k . In every experiment , we vary one of the parameters
9 1 0
.
2 1 0
.
9 0 0
.
1 2 1
.
3 9 0
.
6 8 0
.
6 1 0
.
1 1 0
.
8 0 0
.
8 7 0
.
2 6 0
.
6 5 0
.
9 0 0
.
1 1 0
.
1 0
.
7 6 1
.
9 8 0
.
4 3 0
.
9 0 0
.
9 0 0
.
9 0 0
.
4 1 1
.
3 9 0
.
3 8 0
.
2 1 0
.
1 1 0
.
1 0
.
1 7 0
.
2 6 0
.
6 5 0
.
9 0 0
.
8 0 0
.
1 0
.
4 8 0
.
4 7 0
.
1 6 0
.
6 1 0
.
3 1 0
.
7 0 0
.
1 6 0
.
1 4 0
.
5 3 0
.
1 0
.
9 0 0
.
6 0 0
.
8 6 0
.
5 4 0
.
1 2 0
.
9 0 0
.
2 1 0
.
1 1 0
.
3 2 1
.
7 5 0
.
1 2 0
.
8 1 9
.
6 7 8
.
4 1 6
.
.
2 3 7
.
7 9 8
3 6 4 9
.
.
1 0 1
6 7 8
.
5 3 5
.
8 0 0
.
1 0
.
1 1 0
.
7 4 0
.
1 4 0
.
8 3 0
.
2 1 0
.
9 0 0
.
9 0 0
.
6 5 0
.
5 4 0
.
5 3 0
.
0 1 0
.
8 0 0
.
9 0 0
.
3 4 0
.
2 3 0
.
9 2 0
.
4 5 6
.
6 7 6
.
7 6 5
.
.
6 0 9
.
7 9 8
.
2 9 8
2 3 7
.
6 7 7
.
1 2 7
.
.
4 6 7
.
6 5 7
.
7 2 7
4 3 6
.
4 5 5
.
2 3 5
.
1 0
.
1 1 0
.
2 0
.
3 1 0
.
9 0 0
.
9 0 0
.
2 1 1 0
.
1 1 0
.
8 0 0
.
3 9 0
.
2 9 0
.
2 9 0
.
1 0
.
1 1 0
.
1 1 0
.
2 6 0
.
1 6 0
.
2 6 0
.
1 1 0
.
8 0 0
.
9 0 0
.
4 7 0
.
3 7 0
.
4 7 0
.
1 0
.
1 0
.
9 0 0
.
1 4 0
.
1 4 0
.
1 4 0
.
1 1 0
.
9 0 0
.
9 0 0
.
5 4 0
.
4 4 0
.
3 4 0
.
1 1 0
.
1 1 0
.
1 1 0
.
2 3 0
.
2 3 0
.
1 3 0
.
6 7 8
.
1 3 6
.
3 3 6
.
.
7 9 8
.
3 9 8
.
4 9 8
6 7 8
.
5 4 6
.
5 4 6
.
8 7 0
.
1 1
.
7 5 1
.
3 1 0
.
9 0 0
.
9 0 0
.
2 5 0
.
2 7 0
.
5 4 1
.
2 1 0
.
9 0 0
.
1 0 0
.
7 6 0
.
9 8 0
.
3 2 1
.
1 1 0
.
9 0 0
.
1 0
.
4 0
.
1 5 0
.
9 0
.
2 1 0
.
9 0 0
.
9 0 0
.
1 4 0
.
8 6 0
.
3 2 1
.
2 1 0
.
9 0 0
.
8 9 0 0
.
9 2 0
.
3 4 0
.
3 9 0
.
2 3 7
.
7 9 6
.
8 9 6
.
.
3 4 9
.
3 2 8
.
2 1 6
1 2 7
.
2 3 7
.
2 3 6
.
3 9 0
.
4 9 0
.
3 0 1
.
1 0
.
9 0 0
.
8 0 0
.
2 6 0
.
3 6 0
.
1 7 0
.
1 0
.
9 0 0
.
9 0 0
.
7 0
.
7 7 0
.
3 8 0
.
1 0
.
9 0 0
.
8 0 0
.
1 4 0
.
2 4 0
.
5 4 0
.
1 0
.
2 1 0
.
1 0
.
5 4 0
.
7 4 0
.
1 5 0
.
1 0
.
9 0 0
.
9 0 0
.
2 3 0
.
3 3 0
.
8 3 0
.
1 3 7
.
9 5 7
.
9 1 6
.
.
7 9 8
1 7 6 8
.
7 1 2 8
.
6 7 7
.
1 5 6
.
1 3 6
.
.
6 5 7
.
4 5 7
.
2 5 7
4 3 1 8
.
3 2 1 7
.
8 7 0 6
.
.
6 5 7
7 1 2 7
.
8 7 0 7
.
4 5 5
.
1 7 6
.
6 4 4
.
2 1 5
.
7 6 5
.
8 9 5
.
4 5 5
.
1 3 6
.
1 5 5
.
2 1 0
.
9 0 0
.
7 8 0
.
3 9 0
.
1 6 0
.
8 3 0
.
1 1 0
.
1 0
.
9 0 0
.
2 6 0
.
3 5 0
.
2 2 0
.
9 0 0
.
8 0 0
.
7 0 0
.
4 7 0
.
6 4 0
.
1 2 0
.
3 1 0
.
9 0 0
.
9 0 0
.
1 4 0
.
4 3 0
.
1 2 0
.
9 0 0
.
6 0 0
.
5 0 0
.
5 4 0
.
8 1 0
.
8 1 0
.
1 0
.
9 0 0
.
9 0 0
.
2 3 0
.
6 2 0
.
1 1 0
.
6 7 8
.
9 9 8
.
6 9 7
.
.
7 9 8
.
7 3 9
.
7 9 9
6 7 8
.
1 7 8
.
7 6
. v o C n a e
M s e g a s s e
M l l a r e v O
|
) G ffiΘ ( L v o C n a e
M s e g a s s e
M y r a n o i t a t
S
|
) G ffiΘ ( L v o C n a e
M s r e e P t c e r r o C f o e g a t n e c r e P
|
) G ffiΘ ( L s e u l a V r e t e m a r a P
.
6 5 7
.
5 5 8
.
6 7 9
.
9 7 6
.
6 5 7
.
5 9 9
4 5 5
.
1 5
.
3 4
.
8 9 5
.
3 5
.
2 3 5
.
3 0 4 9
.
.
7 7 9
6 8 9 9
.
.
5 6 5
.
8 7 6
.
9 7 9
.
6 5 9
3 0 4 9
.
3 0 2 9
.
3 0 4 9
.
2 1 4 9
.
9 0 4 9
.
7 0 6 9
.
3 8 0 9
.
4 3 5 6
.
3 0 4 9
.
5 0 3 9
.
4 0 1 9
.
0 0 1
0 0 2
0 0 4
5
8
0 1
,
,
3 0
.
5 0
.
,
0 1
.
,
,
6
7
,
9
0 0 2
0 0 5
0 0 0 1
0 0 5
0 0 0 1
0 0 0 2
2
4
7
2
3
5
| i
S
|
L s r e e P
# n o i s n e m D # i s n a i s s u a G #
I e l b a T
. S R E T E M A R A P M H T I
R O G L A
T N E R E F F I
D
E H T
N O
T S O C
D N A
Y T I L A U Q
F O
Y C N E D N E P E D while keeping the others at their default values : |Si| = 100 , = 8.0 , 1 = 0.5 , 2 = 0.5 , 3 = 8.0 , L=500 , p = 500 , d=3 , k=2 . We choose based on a sample of data offline . the data is generated . For other epochs , we change the data
Figure 1 shows the data , quality and cost graph of a typical experiment . In all our experiments , we replace 10 % of the data of each peer after every 1000 simulator ticks . On top of this , after every 5×105 ticks , we induce an epoch change by changing the distribution . For epochs 1 , 3 , 5 , , each peer is given the same model parameters ffiΘ from which generator without changing ffiΘ given to each peer . Hence L(ffiΘ|G ) for these epochs are low while for the others it is Figure 1(b ) reports the number of peers detecting L(ffiΘ|G ) < threshold =7.0 passes through L(ffiΘ|G ) , approximately 95 % the detection is much simpler since the L(ffiΘ|G ) is far away quite high as shown in Figure 1(a ) . Corresponding to this , for each epoch . As is evident for the odd epochs , since of the peers report the correct result . For the even epochs , from . Figure 1(c ) shows the corresponding communication cost which temporarily increases on every epoch change . In order to calculate the stationary cost , we consider the later 80 % of each epoch .
The first row of the table depicts the quality and cost of PeDEM as size of the local dataset is increased from 100 to 400 . As shown , the quality improves as |Si| is increased for all the monitoring instances . Both the stationary and overall communication overhead of the algorithm decrease as |Si| increases . Next we demonstrate the variation of quality and cost as the different s vary . The three values at each row correspond to , 2 and 3 respectively . As expected , the quality improves as is increased for all the monitoring instances . Both the stationary and overall cost also decreases steadily with increasing . The reason is that smaller translates to a more difficult problem , thereby increasing the cost and deteriorating the quality . The variation with the size of the leaky bucket is shown next . The quality of the algorithm approximately remains constant as L is varied , but both the stationary and overall messages decrease with increasing L .
The last three parameters correspond to the scalability results . As shown , quality remains almost constant as the number of peers is increased . Also both the overall and stationary messages converge to a constant , independent of the number of nodes . This is because in a local algorithm , the resource consumption becomes independent of the size of the network with no change in quality . This results in excellent scalability of the algorithm . However , as shown , quality decreases linearly and cost increases linearly as the number of dimension is increased . This is can be attributed to an increase in variance in each dimension due to the covariance matrix .
Parameter
Values
Computed Model
Distributed
Centralized
τ
Sample size
1000 2000 3000 5000
6 7 8 9
2000 5000 7000 10000
8.4098 8.4796 8.5289 9.1538 7.456 8.124 8.479 8.7779 9.8744 8.4796 7.3898 6.7124
0.43 0.51 0.62 0.75 0.58 0.53 0.51 0.28 0.25 0.33 0.21 0.28
7.1098 7.1098 7.1098 7.1098 7.1098 7.1098 7.1098 7.1098 8.7098 7.1908 6.51 5.92
0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.21 0.46 0.21 0.19 0.15
Stationary Messages Avg Std . dev 0.009 0.015 0.007 0.024 0.004 0.029 0.003 0.0401 0.09 0.009 0.007 0.089 0.004 0.024 0.003 0.021 0.009 0.056 0.007 0.024 0.023 0.004 0.003 0.021
Table II
Overall Messages Avg Std . dev 0.0075 0.0453 0.0061 0.0512 0.0051 0.0526 0.0053 0.0647 0.123 0.0075 0.0061 0.101 0.0051 0.0512 0.0053 0.0432 0.0075 0.079 0.0061 0.0512 0.051 0.0051 0.0053 0.0512
PERFORMANCE OF PEDEM IN CLOSED LOOP EXPERIMENTS .
Data Rounds per epoch
3.5 2 1.5 1 5 3.5 2.5 2 3 2 1.2 1.2
60
40
20
)
|
G Θ ( L
0 0 0.5 1 1.5 2 2.5 3 3.5 4 x 106
Time
2
1
0 0 0.5 1 1.5 2 2.5 3 3.5 4 x 106
Time s e g a s s e M d e z i l a m r o N
Figure 2 . Typical run of PeDEM in closed loop .
B . Results : EM Models
In this section we demonstrate the results of PeDEM in closed loop mode . As shown in Figure 2 , whenever the distribution changes , L(ffiΘ|G ) exceeds ( dotted line ) , thereby triggering model rebuilding . This reduces L(ffiΘ|G ) to less than and subsequently only the efficient monitoring algorithm operates . The monitoring cost increases after every epoch change and then decreases after new models are rebuilt .
We explore the effect of three parameters in this section : alert constant τ , and sample size of convergecast . Their default values are : τ = 2000 ( twice the average edge delay ) , = 7.0 and sample size=5000 . We compare PeDEM to a centralized EM algorithm having access to all the data . The results are shown in Table II in which we show ( 1 ) average and standard deviation of the quality ( for both distributed and centralized scenarios ) , ( 2 ) same for both stationary and overall monitoring messages , and ( 3 ) finally the number of data rounds per epoch . From the table , we see that the average log likelihood increases with increasing τ . This is because the model remains inaccurate for a longer time before it is rebuilt . For the centralized algorithm , its loglikelihood is independent of τ . For the cost , as expected , the number of convergecast rounds decrease as τ increases . The second set of results show that the average log likelihood increases and cost decreases as is increased . Finally , increase in sample size improves quality and decreases cost due to more accurate models being built . Moreover , the loglikelihood of PeDEM and the centralized algorithm become closer as the sample size is increased . We can conclude that most of the error induced in PeDEM is as a result of the sample size and not due to the distributed computation .
Thus , in general PeDEM provides a moderate rate of false positives and an excellent rate of true positives . The models built are quite accurate with respect to centralization under moderately low communication overhead .
C . Application
Consider a sensor network deployed in a remote region of the forest to monitor changes in the forest cover over time . PeDEM can be efficiently used for this purpose by deploying it in the network . In the absence of real sensor network data , we have simulated the network in our simulator using the real world forest cover dataset3 . This dataset has 54 features — 44 binary and the rest categorical . The last column is the class label which can take values between 1 to 7 each representing a different type of forest cover . In order to use the dataset for detecting changes in forest cover using PeDEM , we performed the following preprocessing tasks : ( 1 ) We have only used tuples having categories 1 , 2 , 3 and 7 . ( 2 ) We have grouped them such that categories 1 and 3 belong to the same set and 2 and 7 belong to the other ; each set corresponds to one epoch . Each epoch denotes one forest cover type . ( 3 ) We removed the class information and all the binary attributes , leaving us with 10 attributes . ( 4 ) The dataset for each epoch consists of 240000 tuples . Initially the dataset was divided into 200 peers with each peer having 600 points . At 100,000 , 200,000 and 300,000
3http://kddicsuciedu/databases/covertype/covertypehtml
20
10
0
)
|
G θ ( L
−10 0
1
2
Time
3
4 x 105
10000
5000
0 0
1
2
Time
3
4 x 105 s e g a s s e M e v i t l a u m u C
Figure 3 . Quality and cost for forest covertype dataset . clock ticks we replaced 10 % of the peers points every 1000 clock ticks . Thus the entire dataset of each peer was replaced after 110,000 , 210,000 and 310,000 clock ticks . We have fitted a 10 dimensional GMM having two gaussian components since each epoch consists of data from two separate classes . Figure 3 shows the results . The left figure shows the variation in L(ffiΘ|G ) vs . time with the red line showing .
Whenever data changes , we see re computation of the model ( to reduce the log likelihood ) . The right figure shows the cumulative monitoring messages ( blue ) and data messages ( red ) . As seen , monitoring messages remain constant when the data do not change . We also directly compared the GMM model computed by PeDEM and that computed centrally and found that the models were very close . This result shows that PeDEM may allow scientists to track changes in the forest cover without centralizing all the data .
VIII . CONCLUSION
In this paper we have presented a local , asynchronous , distributed , and provably correct algorithm for monitoring the GMM parameters in a large P2P network . To the best of the authors’ knowledge , this is the first EM algorithm specifically developed for such environments . The algorithm can seamlessly adapt to data and network changes . Besides direct contribution to monitoring GMM parameters , this paper also developed a technique for monitoring the covariance of the data . Our extensive experimental results support the theoretical claims .
ACKNOWLEDGEMENTS
This work was supported by the NASA Aviation Safety
Program Intelligent Vehicle Health Management project .
REFERENCES
[ 1 ] A . Dempster , N . Laird , and D . Rubin , “ Maximum Likelihood from Incomplete Data via the EM Algorithm , ” J . R . Stat . Soc . , B , vol . 39 , no . 1 , pp . 1–38 , 1977 .
[ 2 ] D . Gu , “ Distributed EM Algorithm for Gaussian Mixtures in Sensor Networks , ” IEEE TNN , vol . 19 , no . 7 , pp . 1154–1166 , 2008 .
[ 3 ] R . D . Nowak , “ Distributed EM Algorithms for Density Estimation and Clustering in Sensor Networks , ” IEEE TSP , vol . 51 , no . 8 , pp . 2245–2253 , 2003 .
[ 4 ] W . Kowalczyk and N . A . Vlassis , “ Newscast EM , ” in Pro ceedings of NIPS’04 , 2004 , pp . 713–720 .
[ 5 ] J . Wolfe , A . Haghighi , and D . Klein , “ Fully Distributed EM for Very Large Datasets , ” in Proceedings of ICML’08 , 2008 , pp . 1184–1191 .
[ 6 ] S . Bandyopadhyay , C . Giannella , U . Maulik , H . Kargupta , K . Liu , and S . Datta , “ Clustering Distributed Data Streams in P2P Environments , ” Inf . Sci . , vol . 176 , no . 14 , pp . 1952–1985 , 2006 .
[ 7 ] W . Kowalczyk , M . Jelasity , and A . E . Eiben , “ Towards Data Mining in Large and Fully Distributed Peer to Peer Overlay Networks , ” in Proceedings of BNAIC , 2003 , pp . 203–210 .
[ 8 ] K . Das , K . Bhaduri , K . Liu , and H . Kargupta , “ Distributed Identification of Top l Inner Product Elements & its Application in a P2P Network , ” TKDE , vol . 20 , no . 4 , pp . 475–488 , 2008 .
[ 9 ] N . Linial , “ Locality in Distributed Graph Algorithms , ” SIAM
Journal of Computing , vol . 21 , pp . 193–201 , 1992 .
[ 10 ] Y . Afek , S . Kutten , and M . Yung , “ The Local Detection Paradigm and Its Application to Self Stabilization , ” In Theoretical Computer Science , vol . 186 , no . 1–2 , pp . 199–229 , 1997 .
[ 11 ] R . Wolff and A . Schuster , “ Association Rule Mining in P2P Systems , ” IEEE SMC B , vol . 34 , no . 6 , pp . 2426 – 2438 , 2004 .
[ 12 ] J . Branch , B . Szymanski , C . Giannella , R . Wolff , and H . Kargupta , “ In Network Outlier Detection in Wireless Sensor Networks , ” in Proceedings of ICDCS’06 , 2006 .
[ 13 ] P . Luo , H . Xiong , K . L¨u , and Z . Shi , “ Distributed Classification in P2P Networks , ” in Proceedings of SIGKDD’07 , 2007 , pp . 968–976 .
[ 14 ] K . Bhaduri , R . Wolff , C . Giannella , and H . Kargupta , “ Distributed Decision Tree Induction in P2P Systems , ” Stat . Anal . and Data M . , vol . 1 , no . 2 , pp . 85–103 , 2008 .
[ 15 ] R . Wolff , K . Bhaduri , and H . Kargupta , “ A Generic Local Algorithm for Mining Data Streams in Large Distributed Systems , ” TKDE , vol . 21 , no . 4 , pp . 465–478 , 2009 .
[ 16 ] I . Sharfman , A . Schuster , and D . Keren , “ A Geometric Approach to Monitoring Threshold Functions over Distributed Data Streams , ” in Proceedings of SIGMOD’06 , 2006 , pp . 301–312 .
