An Approach to Spacecraft Anomaly Detection Problem
Using Kernel Feature Space
∗
Ryohei FUJIMAKI
Univ . of Tokyo
Dept . of Aero . and
Astronautics fujimaki@spacercastu tokyoacjp
Takehisa YAIRI
Univ . of Tokyo .
Kazuo MACHIDA
Univ . of Tokyo .
Research Center for Advanced
Research Center for Advanced
Science and Technology yairi@spacercastu tokyoacjp
Science and Technology machida@spacercastu tokyoacjp
ABSTRACT Development of advanced anomaly detection and failure diagnosis technologies for spacecraft is a quite significant issue in the space industry , because the space environment is harsh , distant and uncertain . While several modern approaches based on qualitative reasoning , expert systems , and probabilistic reasoning have been developed recently for this purpose , any of them has a common difficulty in obtaining accurate and complete a priori knowledge on the space systems from human experts . A reasonable alternative to this conventional anomaly detection method is to reuse a vast amount of telemetry data which is multi dimensional time series continuously produced from a number of system components in the spacecraft .
This paper proposes a novel ” knowledge free ” anomaly detection method for spacecraft based on Kernel Feature Space and directional distribution , which constructs a system behavior model from the past normal telemetry data from a set of telemetry data in normal operation and monitors the current system status by checking incoming data with the model .
In this method , we regard anomaly phenomena as unexpected changes of causal associations in the spacecraft system , and hypothesize that the significant causal associations inside the system will appear in the form of principal component directions in a high dimensional non linear feature space which is constructed by a kernel function and a set of data .
We have confirmed the effectiveness of the proposed anomaly detection method by applying it to the telemetry data obtained from a simulator of an orbital transfer vehicle designed to make a rendezvous maneuver with the International Space Station .
∗Address :
Japan
4 6 1 , Komaba , Meguro ku , Tokyo 153 8904
Categories and Subject Descriptors I26 [ Artificial Intelligence ] : Learning ; H28 [ Database Management ] : Database applicationsData Mining
General Terms Algorithms
Keywords anomaly detection , time series data , kernel feature space , principal component analysis , von Mises Fisher distribution , spacecraft
1 .
INTRODUCTION
Anomaly detection is a key issue in the development of recent advanced complex spacecraft . The space environment is very harsh for spacecraft due to a variety of factors such as direct radiation , great temperature difference , risk of clash with space debris , and so on . It is practically impossible to completely eliminate the possibility of anomalies or faults , even if we increase the reliability of the system components to the limit . In addition , the space is so distant from the earth that it is extremely difficult to directly inspect and repair a damaged component . Therefore , early detection of anomalous symptoms in the system behavior is significantly important to avoid disastrous situations such as loss of control . Although several anomaly detection / diagnosis methods using modern reasoning techniques such as qualitative reasoning , expert systems and probabilistic reasoning have been developed , they have difficulties in acquiring accurate and complete models and knowledge of the spacecraft systems and in monitoring the system behavior exhaustively and efficiently .
One major reason for these difficulties is that conventional anomaly detection systems are heavily dependent on a priori knowledge on the system behavior for each spacecraft . For example , the model based method[5 , 9 , 12 , 17 ] requires a perfect dynamics model of the spacecraft , and the expert system[11 ] demands a set of production rules . In practice , however , preparing such complete and accurate a priori knowledge of the systems is very difficult and expensive , partly because of the so called ” bottle neck of knowledge acquisition ” , and partly because of the difference between theory , experiment and actual behavior of the system on the orbit . To make matters worse , the reuse of models and
401Industry/Government Track Paper knowledge of the past systems is also limited , because the spacecraft is one of the ultimate custom made productions in the world , unlike household appliances .
Another difficulty in the anomaly detection and diagnosis for the spacecraft lies in the complexity of the spacecraft systems . Although the spacecraft subsystems ( such as attitude control , power supply , and so on ) are designed to minimize mutual interference , actual anomalies often occur across several subsystems , which makes it difficult for human experts and model/knowledge based detection/diagnosis systems to investigate and understand the phenomena .
For the above reasons , the necessity for ” knowledge free ” anomaly detection methods which are not dependent on a priori expert knowledge such as dynamics models and production rules is being widely recognized . Fortunately , most modern spacecraft including artificial satellites and orbital transfer vehicles are transmitting multi dimensional time series called telemetry data containing a variety of low level system information to ground stations . While the telemetry data is originally for simplistic limit checking and manual analyses by engineers and experts , recent researches have shown that a variety of data mining techniques can be applicable to this data .
This paper proposes a novel method which detects anomalous behaviors of the spacecraft from the vast telemetry data by using the kernel feature space . In this method , telemetry data at each time point is implicitly transformed into a high dimensional nonlinear feature space by the polynomial kernel . Then the primary causal associations underlying the system behavior are extracted as principal component vectors . By detecting some significant changes of the direction of the vectors , it attempts to find unexpected changes in the causal associations of the system behavior , ie , anomalies . The remainder of this paper is organized as follows . First , we present a brief review of the conventional approaches to the anomaly detection problem in space systems in Section 2 . Then , we explain the basic concept of the proposed method in Section 3 . In Section 4 and 5 , we explain the center of the proposed method , the extraction of causal associations and its optimization . In section 6 , we show and discuss some results of an experiment . We made use of the telemetry data of a simulated unmanned orbital transfer vehicle during the process of rendezvous with the ISS ( International Space Station ) . Finally , we conclude this study in section 7 .
2 . CONVENTIONAL TECHNIQUES OF
ANOMALY DETECTION / DIAGNOSIS FOR SPACE SYSTEMS
Limit checking has been the most basic and common technique of detecting anomalies in spacecraft systems for a long time . It constantly monitors some important time series in the telemetry data and checks whether the value is within the pre defined upper and lower limits . Ref.[7 ] proposed a method of automatically computing limit values using autoregressive model . Though the limit checking has an advantage that it is simple enough to be applied to any types of spacecraft , it lacks flexibility and expressiveness and suffers from the problem of false alarms .
In contrast to the limit checking , the model based fault detection and diagnosis method will be the most sophisticated approach to the problem , in which system models are utilized to simulate the spacecraft behavior and examine the validity of the actual telemetry data . Some researchers use qualitative models[5 , 17 ] , while others use mathematical ( probabilistic ) models[9 ] . Ref.[12 ] does not directly detect anomalies but intelligently estimates the importance of each sensor information using Bayesian Networks and gives a higher priority to the more important one when it is displayed on a monitor . The model based approach would provide an ideal performance if a accurate and complete model and infinite computational power were available . In practice , however , both of them are not available , which limits the applicability of this method .
Expert systems ( knowledge based systems ) also have been developed for this purpose , in which knowledge for anomaly detection acquired from human experts is used . The knowledge is generally represented in the form of ” if then ” production rules[11 ] . Though the expert systems are powerful and flexible , it has a difficulty in preparing a set of accurate and complete knowledge on the spacecraft . This problem has been well known as the bottleneck of knowledge acquisition . In summary , the above methods of limit checking , modelbased and knowledge based approaches have a common problem that they are too dependent on the knowledge of human experts .
As mentioned in the previous section , a reasonable approach to this problem is the application of data mining and machine learning techniques to the spacecraft telemetry data . Actually , some researchers have developed anomaly detection methods for spacecraft using the DM/ML techniques such as regression tree learning[14 ] , temporal pattern clustering[18 ] , association rule mining[19 ] , support vector machine[6 ] and relevance vector regression[16 ] . Most of them are based on a common idea that they attempt to detect significant unexpected changes in the system behavior by automatically constructing some behavior models inductively from a set of training data and comparing them with newly arriving data .
In the subsequent section , we propose a novel anomaly detection method which belongs to this data mining approach . The proposed method regards anomalies as unexpected changes in the causal associations , and attempts to detect the change by using the kernel feature space .
In the meanwhile , the conventional methods including data mining approaches have other two problems . First , they have defined anomaly in a restricted way . For instance , limit checking is capable of defining only one type of anomaly , in other words , crossing limit values . We regard anomaly phenomena as unexpected changes of causal associations in a system . This makes it possible for the proposed method to detect various types of anomalies . Second , the conventional methods have difficulties to model the whole behavior of the spacecraft . Although the telemetry data of the spacecraft consists of the various heterogeneous time series data , they have not explicitly made consideration for them . In this paper , we give one consideration for this difficulty by using the kernel method .
402Industry/Government Track Paper Figure 1 : Image of anomaly phenomena . Some failures cause changes of causal associations in a system .
3 . BASIC CONCEPT OF THE PROPOSED
METHOD
3.1 Anomaly
It is difficult to define what anomalies are in a general sense because the type of anomaly depends on the problem . However , it is a reasonable assumption that some unexpected changes occur in the relationships among system parameters when the system becomes anomalous . Taking a space system for instance , we can see an unexpected change of inertia parameters as anomaly .
In this study , although the behaviors of system ( telemetry data ) are dynamic , we assume that the causal associations governing such dynamics of the system are almost static being slightly affected by sensor noise , disturbance , operation mode of the system and so on . Then , we define anomalies as following ,
Definition 1 . Anomalies are some unexpected changes of causal associations in the system such as unexpected disappearance , occurrence , or change of coherence degree(dotted arrow in Figure 1 ) of causal associations ( Figure 1 ) .
Note that our causal associations mean arbitrary relationships among the components , though Figure 1 shows only ones between two components for simplicity .
In this study , each series in the telemetry data is represented as a variable , and nonlinear causal associations among the variables are extracted from the data . We explain the extraction of feature which represents these associations conceptually in Section 3.2 and in 4 in detail . 3.2 Extraction of Causal Associations
As we define anomaly above , we must firstly consider how to extract the appropriate features which represent the causal associations among the variables . Unfortunately , linear relations are too simple to model the complex associations inside the spacecraft telemetry data .
In this study , we hypothesize that significant causal associations among the original variables are supposed to appear as a principal component vector in some appropriate feature space . More specifically , we noticed the product features ( so called ” monomials ” ) whose effectiveness have been confirmed in many fields such as pattern recognition research[3 ] . In Section 4 , we explain that the direction of the principal component vector with regard to the data mapped into a
Figure 2 : Image of training data . Telemetry data are divided into M data subsets . high dimensional feature space represented by product features can be interpreted as the causal associations inside the system . The anomaly we intend to detect is unexpected changes in this kind of nonlinear associations .
Although it is generally difficult to deal with the high dimensional feature space directly because of high computational cost , we can implicitly deal with it by using the kernel method which has been noticed because of the great success of the Support Vector Machine[2 ] . Since we are interested in direction of principal component vector with regard to data mapped into the feature space , we applied the kernel principal component analysis ( kernel PCA)[4 ] to extract the feature vector .
For the purpose of anomaly detection , it is more significant to estimate the directional distribution of the principal component vector in the normal operation than to predict the most likely principal component vector as a point estimate . We explain the optimal estimation of the directional vector which represents the normal data mapped into the feature space the best and the distribution of the principal component vectors in Section 5 . The von Mises Fisher distribution ( vMF distribution ) is the most natural distribution for directional data in that it can be derived using the maximum entropy principle[1 , 10 ] .
3.3 Problem Description
Here , we clearly describe the problem once more . Let us assume that we have telemetry data in normal operation . The telemetry data have thousands of time series and each element of data point xi is corresponding to each series of telemetry data . Then , we divide them into M data subsets , each of which includes N data points , using the sliding window[8 ] ( Figure 2 ) . These data subsets are denoted as Dj = {xj i}N i=1(j = 1 , . . . , M ) .
Then , the proposed method computes the principal component vector vj corresponding to the subset Dj mapped into the high dimensional feature space and learns the directional distribution model modeled as the vMF distribution around the optimal direction r computed from vj .
After learning the optimal distribution model , it computes the occurrence probability of the principal component vector with respect to the real time incoming telemetry data mapped into the feature space . If this probability is under the pre defined threshold , it detects anomaly ( Figure 3 ) .
( cid:58)(cid:58)(cid:58)(cid:58)(cid:67)(cid:75)(cid:78)(cid:87)(cid:84)(cid:71)(cid:58)(cid:58)(cid:58)(cid:58)(cid:67)(cid:75)(cid:78)(cid:87)(cid:84)(cid:71)(cid:84)(cid:79)(cid:67)(cid:78)(cid:79)(cid:67)(cid:78)1D3D2DM 1DMD403Industry/Government Track Paper Figure 3 : Image of the proposed anomaly detection method . In learning phase , it extracts principal axes from M data subsets . Then , it learns the distribution of the principal axes . In detection phase , it extract principal axis from online data subset and compare it with the learned distribution . If the probability is under the threshold , it detects anomaly .
4 . EXTRACTION OF CAUSAL
ASSOCIATIONS
4.1 Product Feature and Kernel Mapping
As mentioned above , we consider that significant causal relationships which characterize the spacecraft system behavior will become visible in the form of directions of principal components of the telemetry data , if it is mapped into some appropriate feature space .
Though it will be difficult to find such an appropriate nonlinear mapping in a general case , we focused on the product feature space which is implicitly constructed by the polynomial kernel in this work . Suppose we are given a vector x ∈ X = Rn where most information is contained in the dth order products ( so called monomials ) of elements xi of data x , xj1 · xj2 ··· xjd , where j1 , . . . , jd ∈ {1 , . . . , n} such as x2 2 , x1x2x3 and so on(third order products ) . These features are referred to as product features . The effectiveness of these features has been confirmed in the many fields such as pattern recognition research[3 ] .
1x2 , x3
( 1 )
Let us take a look at this feature in a simple example of the telemetry data consisting of two series , in other words , x ∈ X = R2 . By introducing the product features of degree two ( d = 2 ) , we obtain a nonlinear mapping as below .
Φ : X = R2 → H = R3 , ( x1 , x2 ) → ( x2
1 , x2
2 , x1x2 ) .
( 2 )
( 3 )
Now imagine that the system has a causal association ax2 1 + bx2 2 + cx1x2 = d in terms of x1 and x2 , which means that the data lies on a quadratic curve in the original space X ( Figure 4 left ) . This data is mapped through the mapping function Φ onto a ( hyper)plane in the three dimensional
Figure 4 : Example of nonlinear mapping on product feature space . This is the case , 8x2 2 = 25 . The data mapped into H are on the hyperplane , and the principal axis represents the data property well .
1 − 3x1x2 + 5x2 product feature space H , where the linear PCA can be applied for extracting principal axis . We can easily understand that the directions of principal components in the product feature space would change drastically if a non trivial change occurred in the causal relationships of this system or the system parameters a , b , c took some unexpected values . As this example indicates , we can interpret the direction of the data mapped into the feature space H represented by nth order product features as the nonlinear causal associations in the original space X .
A problem of this idea is that it is practically impossible to compute the feature space explicitly when the dimension of the original data ( n ; the number of telemetry data series in this study ) and the degree of product feature ( d ) become large . Fortunately , we can deal with the nonlinear mapping Φ implicitly by using a kernel function which is the dot product in the feature space ,
) = Φ(x ) , Φ(x
) , k(x , x
( 4 ) where k(·,· ) is a kernel function and the notation ·,· represents the dot product . Especially , it has been proved that the polynomial kernel , k(x , x
) = x , x d
( 5 ) constructs the high dimensional feature space represented by the dth order product features and computes the dot product in that space .
In the remainder of this section , we review briefly the kernel PCA in 4.2 and then define an anomaly metric based on the principal directions of the data in the product feature space in 43 4.2 Estimation of Data Direction in Feature
Space Using Kernel PCA
The kernel PCA proposed by Sch¨olkopf , Smola and Muller[4 ] is an algorithm for computing the principal component vectors in a high dimensional nonlinear feature space by applying the kernel method to the classical linear principal component analysis ( linear PCA ) . In this subsection , we explain how the ” direction ” of the telemetry data in the product feature space H is computed using the kernel PCA .
( cid:84)(cid:79)(cid:67)(cid:78)(cid:67)(cid:86)(cid:67)(cid:71)(cid:78)(cid:71)(cid:79)(cid:71)(cid:86)(cid:84)(cid:67)(cid:86)(cid:67)(cid:71)(cid:67)(cid:84)(cid:75)(cid:73)(cid:75)(cid:85)(cid:86)(cid:84)(cid:75)(cid:87)(cid:86)(cid:75)(cid:79)(cid:67)(cid:84)(cid:75)(cid:85)(cid:79)(cid:67)(cid:78)(cid:71)(cid:86)(cid:71)(cid:86)(cid:75)1D2D3DMD(cid:71)(cid:67)(cid:84)(cid:75)(cid:73)(cid:50)(cid:74)(cid:67)(cid:85)(cid:71)(cid:71)(cid:86)(cid:71)(cid:86)(cid:75)(cid:50)(cid:74)(cid:67)(cid:85)(cid:71)fflffl(cid:58)(cid:58)fflffl(cid:42)(cid:71)(cid:84)(cid:78)(cid:67)(cid:71)(cid:84)(cid:75)(cid:75)(cid:67)(cid:78)(cid:67)(cid:75)(cid:85)(cid:478)HX404Industry/Government Track Paper If k is a positive definite kernel function , Mercer ’s theorem assures that it can be expressed as a dot product in a high dimensional feature space . That is ,
Φ(x ) , Φ(x
) = k(x , x
)
Then , any algorithm depending only upon dot product can be transformed into another algorithm for the high dimensional feature space by replacing the dot product with the kernel function . This technique is called kernel trick .
Though we used the polynomial kernel in this work , the choice of suitable kernels depends on the types of systems and telemetry data . In other words , the proposed anomaly detection method can be applied to various systems other than spacecraft , if we can prepare some suitable kernels . {xj the dual eigen value problem ,
The mth principal component vector of the jth data set i}N i=1 in the feature space H can be computed by solving
NX i=1 vj m =
αj mi
˜Φ(xj i ) , where αj mi is the corresponding weight and
˜Φ(xj i ) = Φ(xj i ) − 1 N
Φ(xj k ) .
NX k=1
( 6 )
( 7 ) m is normalized[3 , 4 ] .
As described in Section 3 , we regard the direction of data i}N i=1 mapped into the feature space H as the feature .
We assume that vj {xj Therefore , we define
1vj vj = λj
1 + ··· + λj as the feature vector . Here , –j = ( λj m ) is the normalized eigen value vector . Please note that the features in ” feature space ” and ” feature vector ” have different meanings in this paper . mvj m 1 , . . . , λj
( 8 )
Computing the principal components in the high dimen sional feature space has a certain advantage as below ,
Property 1 . Using only first m principal eigen vectors , we can eliminate noise .
The usefulness of this property has also been confirmed in the field of image processing and so on . In this study , we can focus only on causal associations buried in noise because of this property .
In addition , the polynomial kernel of Eq
( 5 ) has the following property ,
Property 2 . The direction in the feature space H is invariant with respect to the scale transformation in the original space ,
„
« a x1 x2
→ a2
1A .
0@ x2
1 x2 2 x1x2
( 9 )
Thereby we can exclude the scale change of the whole system from analysis . It is considered to be very important because the causal associations may be invariant with respect to scale change .
Now , we have one question . Although it is a great advantage of the kernel method that it is capable of computing the dot product in the feature space implicitly , is it guaranteed that two different data sets are mapped into an identical
Figure 5 : Image of the proposed anomaly metric . The larger θ is , the larger anomaly metric is . feature space when we apply a kernel to them ? The answer is Yes . We will give only an intuitive explanation here . For more detail , please consult [ 3 ] .
Infinite dimensional feature space is constructed both by data and by Mercer kernel in theory . However , since finite data cannot construct infinite feature space , the map Φ into the feature space H is dependent on the data {xj i}N i=1 ( Data Dependent Kernel Map[3] ) . Hence , strictly speaking , i}N the feature space H1 constructed by the data set {x1 i=1 is different from the feature space H2 constructed by another data set {x2 i ∈ X and i ∈ X are in the same space X , the feature spaces H1 and x2 H2 is considered to be approximately identical . 4.3 Anomaly Metric i=1 . However , since the data sets x1 i}N
We defined the feature vector in 42 The proposed method detects anomaly by monitoring the change of direction of the feature vector . Therefore , we define anomaly metric as following .
Definition 2 . Suppose that we have a normal feature vector vj1 . Then , the anomaly metric of a test feature vector vj2 is defined as ,
θ = Acos|vj1 , vj2| ,
( 10 ) because the difference between directional vectors can be interpreted as the dot product .
The larger θ is , the greater the anomaly degree is ( Figure 5 ) .
For simplicity , we transform ( 10 ) using only the first prin cipal eigen vector ( m = 1 ) ,
NX vj1 , vj2 = NX NX NX NX NX k=1 i=1 i=1
=
=
αj1 1i
˜Φ(xj1 i ) ,
αj2 1k k ) ˜Φ(xj2 k=1
1i αj2 αj1
1k ˜Φ(xj1 k ) i ) , ˜Φ(xj2
1i αj2 αj1
1k
˜k(xj1 i , xj2 k ) .
Here , i=1 k=1
˜k(xj1 i , xj2 k ) = ˜Φ(xj1 i ) , ˜Φ(xj2 k ) .
( 11 )
( 12 )
χ(cid:464)χΦ1D2Dθ1v2v1v2v(cid:84)(cid:75)(cid:73)(cid:75)(cid:67)(cid:78)(cid:67)(cid:71)(cid:45)(cid:71)(cid:84)(cid:71)(cid:78)(cid:71)(cid:67)(cid:86)(cid:87)(cid:84)(cid:71)(cid:67)(cid:71)(cid:79)(cid:67)(cid:78)(cid:71)(cid:86)(cid:84)(cid:75)405Industry/Government Track Paper In general m principal eigen vectors case , we can compute anomaly metric in the same way .
5 . OPTIMAL DIRECTION AND
DISTRIBUTION
5.1 Optimal Direction in Feature Space After extracting the feature vectors vj from the M data i}N,M sets {xj i,j=1 of the spacecraft operating normally , we need to compute the optimal directional vector which represents these feature vectors the best . It is natural to suppose that the optimal directional vector is a linear combination of the feature vectors , r = c wjvj
( 13 )
MX j=1 where c is the normalization constant to satisfy rT r = 1 and w = ( w1 , . . . , wM )T is the weight vector which satisfies wT w = 1 . The optimal directional vector r should minimize the sum of anomaly metric between r and vj . Considering that anomaly metric θ becomes larger in inverse proportion to the dot product r , vj , the optimization problem is expressed as follows , ropt = arg max r r , vj2 .
( 14 )
Substituting ( 13 ) to ( 14 ) ,
MX j=1 r , vj2 = wkvk , vj2
= c2 wT VjVjT w
MX j=1
= c2wT Vw . j=1 j=1 k=1 c
MX MX MX 0B@ v1 , vj MX vM , vj
VjVjT .
1CA ,
( 15 )
( 16 )
( 17 )
Here , and
Vj =
V = j=1
After all , optimization problem for computing the optimal direction ropt becomes the optimization problem for computing the optimal weight wopt , wopt = arg max w
{wT Vw}
( 18 ) subject to wT w = 1 . By introducing a Lagrange multiplier γ , we can rewrite ( 18 ) as ,
`
´ d dw so that wT Vw − γwT w
Vw = γw .
= 0 ,
( 19 )
( 20 )
Therefore , the optimization problem becomes the eigen value problem . The optimal weight vector wopt is the first principal eigen vector .
The normalization constant c can be computed from he following equation , r , r = c2
MX wiwjvi , vj = 1 .
( 21 ) i,j
5.2 Directional Distribution
For the purpose of anomaly detection , it is more significant to estimate the directional distribution of the principal component vector around the optimal direction vector ropt than to predict the most likely principal component vector as a point estimate .
In this study , the feature vector is the directional vector . The most natural distribution for directional data will be von Mises Fisher distribution ( vMF distribution)[1 , 10 ] . Although [ 1 , 10 ] discuss the utility of a mixture model of the vMF distribution , we applied the single vMF model for simplicity . [ 20 ] proposes the anomaly detection method for network systems using vMF distribution .
A p dimensional unit random vector v is said to have pvariate von Mises Fisher distribution Mp(κ , — ) if its probability density function is given by ,
Mp(κ , — ) = cp(κ)eκ—T v x , — ∈ Sp−1 ,
( 22 ) where — = 1 , κ ≥ 0 . Sp−1 denotes the ( p− 1) dimensional sphere embedded in Rp . The normalizing constant cp(κ ) is given by ,
κp/2−1
, cp(κ ) =
( 2π)p/2Ip/2−1(κ )
( 23 ) where Ip(· ) represents the modified Bessel function of the first kind of order p . The vector— and κ correspond to the mean vector and the variance of the Gaussian distribution , respectively . Ref.[1 , 10 ] discuss the maximum likelihood estimation for this model . The logarithmic likelihood is
L(κ , — ) = M ln cp(κ ) + κ—T u . j vj is the resultant vector . Since we have where u = already computed the optimal direction from the data set {vj}M j=1 , we can assume
( 24 )
P
— = ropt .
Let us write ¯R as ,
—T u = c
MX i,j wjvj , vi = M ¯R .
( 25 )
( 26 )
According to Ref.[1 , 10 ] , the following equation gives a very reasonable approximation in most cases ,
ˆκ =
¯Rp − ¯R3 1 − ¯R2
.
( 27 )
Although the Newton Raphson iteration gives a more accurate approximation , we used ( 27 ) in this study . See [ 1 , 10 ] for more detail of this maximum likelihood estimation .
Let us consider the dimension of vMF distribution p . The dimension of the feature space constructed by N data and the kernel function is at most N . Therefore , the directional vector is supposed to have at most N dimension . Considering the kernel PCA performs basis transformation and we
406Industry/Government Track Paper apply only the first mth principal component vectors , it is reasonable to approximate p = m1 .
Once we compute Mp(κ , ropt ) , the proposed method monitors the system by extracting the feature vector v from an incoming data set {xi}N i=1 and computing anomaly metric θ = Acos|r , v| . If the following probability is smaller than some pre defined threshold , it detects anomaly , Mp(— , κ)dθ ≤ .
Z +∞
Mp(— , κ)dθ +
( 28 )
Z −η
−∞
+η where η is the threshold value .
In summary , the anomaly detection system based on the proposed method operates as follows ,
Learning Phase
Step 1 . Acquisition of training data : Acquiring the teleme try data from the spacecraft operating normally in the initial phase .
Step 2 . Extraction of feature vector : Extracting the principal component vectors vj in the kernel feature space .
Step 3 . Optimization of direction vector : Computing the optimal direction vector r using the training data {vj}M j=1 .
Step 4 . Predicting directional distribution : Predicting the directional distribution of the feature vectors by optimizing the parameter of vMF distribution . Here , the learning phase is over .
Monitoring Phase
Step 5 . Acquisition of incoming data : Acquiring the real time telemetry data and extracting feature vector v .
Step 6 . Detecting Anomaly : Computing anomaly metric If it is smaller than η , the proposed method of v . detects anomaly .
5.3 Computational Cost
We do not make a detailed discussion about computational cost in this paper because we intend to emphasize not on how to reduce it but on how to monitor the changes of causal associations . However since the computational cost is the quite significant issue for anomaly detection system , let us describe some considerations .
The proposed method acquires the model of causal associations from the normal telemetry data in an off line process . Therefore , the computational cost is not so critical . On the other hand , in the operation phase of the spacecraft , we must detect anomalies in real time process . In the detection phase , it is computationally the costliest to compute the anomaly metric r , v in ( 22 ) whose order is O(M N 2 ) . Therefore , we can say that it is important to reduce N .
1Although principal component vectors of M data subsets are not completely the same , this approximation can be said to be natural because the directional vectors of normal data are considered to strongly distribute around the optimal direction ropt .
The term N 2 derives from the dot product of the principal component vectors , vk1 , vk2 =
NX
αk1iαk2j ˜k(xk1 i
, xk2 j ) .
( 29 ) i,j=1
If many αk1iαk2j become zero , it is expected that we can reduce the computational cost in the second order .
This sparsity can be achieved by the Sparse kernel PCA proposed by Tipping[13 ] which makes use of the framework of the Bayesian learning . Ref.[13 ] has confirmed that the small subset of original data can construct the same principal component vector in the kernel feature space . This algorithm is supposed to greatly reduce the computational cost of the proposed method .
6 . EXPERIMENTS AND DISCUSSIONS
We have confirmed the effectiveness of the proposed method by applying it to the telemetry data of a simulated unmanned orbital transfer vehicle during the process of rendezvous maneuver with the ISS provided by Japan Aerospace Exploration Agency ( JAXA ) .
This telemetry consists of 27 time series variables in total , thirteen of which are from position and attitude control subsystem ( AOCS ) , and the rest are from propulsion subsystem ( PS ) . In more detail , the former group ( AOCS telemetry ) consists of twelve numerical observation timeseries variables regarding the position and attitude of the vehicle and one discrete valued variable representing a command sequence . The latter group ( PS telemetry ) consists of fourteen discrete valued time series variables , each of which indicates the command input to each of the fourteen thrusters installed in the vehicle .
The state of the spacecraft dynamically varies according to the command and the control low ( we did not obtain the knowledge of the control low from JAXA ) . In addition , the properties of the observation series and the command series are quite different . It is very difficult task to acquire the knowledge from this type of data .
6.1 Assumptions First , we have applied the polynomial kernel k(x , x ) = x , xd . We have empirically set d = 2 since the telemetry data obtained from the simulation are comparatively simpler than the real telemetry data .
Secondly , we have 7500 data points of the normal telemetry data ( 950 sec ) . We divided them into the 25 data sets ( M = 25 ) which means each subset contains 300 data points ( N = 300 ) .
We set m = 2 as the number of principal components as the result of the trade off between performance and computational cost .
It should be noted that we used the difference value between time t and t + 1 with regard to the position and attitude control subsystem instead of its original observation value . This is because the difference value generally has more information than the original observation value itself with regard to the position and attitude control subsystem . And finally , we have defined the threshold for anomaly detection at = 0.03 which corresponds to the three sigma range of the Gaussian distribution ( [µ − 3σ , µ + 3σ] ) .
407Industry/Government Track Paper Figure 6 : The von Mises Fisher distributions learned by the proposed method and the method using the linear PCA .
Figure 7 : Changes of anomaly metric of normal telemetry data over time .
6.2 Comparison of Kernel PCA with Linear
PCA
To confirm the validity of our hypothesis that the causal associations in the system appear in the principal component direction in the kernel feature space , we have applied the proposed method and the method using the linear PCA ( in other words , using linear kernel k(x , x ) = x , x ) to the normal telemetry data and have compared their performances . If the proposed anomaly metric ( 10 ) is effective , the proposed method is supposed not to detect anomaly against the threshold computed by ( 28 ) .
The telemetry data in normal operation was divided to training and test data sets . Using the training data , the proposed method and the method using the linear PCA respectively have learned the optimal directions r and the vMF distributions Mm(r , κ ) in each feature space ( the linear kernel constructs original linear space ) . Figure 6 shows the learned vMF distributions . The solid line and the dashed line represent the vMF distributions of the proposed method and the linear PCA method respectively . We can see that the latter is nearly uniformly distributed and obtains no knowledge . On the other hand , the former has the strong peak around the optimal direction r . This result implies that our hypothesis about the causal associations is reasonable . In this case , the threshold for detection is computed as η ∼ 0.304(radian ) from ( 28 ) . Then , we have monitored the anomaly metric θ ( cos θ = r , v ) of the test data over time and Figure 7 shows the results . The solid line , the chained line and the dashed line represent the result of the proposed method , the method using linear PCA and the limit value η for the proposed method respectively . From Figure 6 and Figure 7 , we can confirm that the linear model in the original space cannot model the causal associations . And the proposed feature vector and anomaly metric give few false alarms in the normal state .
Next , we confirm that the proposed method is capable of detecting anomalies in the following three anomaly cases . In each case , the ninth thruster which is used for the pitch control has some trouble at 250 [ sec ] . Figure 8 shows the changes of the thruster duty of each case . The lower the thruster duty is , the greater the anomaly is .
Figure 8 : Changes of the thruster duty over time in each scenario .
Scenario 1 The thruster periodically passes between the normal state and completely failure state . The time cycle is 60 seconds ( 480 data points ) .
Scenario 2 The thruster duty sinusoidally varies . The period of the sine function is 300 seconds ( 2400 data points ) .
Scenario 3 The thruster duty falls down to 30 percents .
6.3 Case Study
631 Scenario 1
In this scenario , The thruster engine periodically passes between the normal state and completely failure state as shown in the top of Figure 8 .
Figure 9 shows the result . The upper figure shows the change of anomaly metric . The proposed method succeeded in detecting the anomaly . It looks like the predicted anomaly period is longer than the real one . This is because of the window length of the data set ( N ) . In other words , the completely normal data set rarely appears as shown in Figure 10 .
3 2 101230051152253354Theta(radian)Probability Density FunctionProposed MethodLinear PCA100200300400500600700800005115Time ( sec)Theta ( radian)Proposed MethodLinear PCALimit for Proposed Method20030040050060070080010080 60 40 20 0 Thruster Duty ( %)Scenario 120030040050060070080010080 60 40 20 0 Thruster Duty ( %)Scenario 220030040050060070080010080 60 40 20 0 Time ( sec)Thruster Duty ( %)Scenario 3408Industry/Government Track Paper Figure 9 : Change of anomaly metric over time in the scenario 1 .
Figure 10 : Period of anomaly and data length .
632
Scenario 2
In this scenario , the thruster duty sinusoidally varies as shown in the Figure 8 .
Figure 11 shows the result . This result is more interesting than the result of scenario 1 . The form of the change of the predicted anomaly metric ( upper figure ) is quite similar with the one of real thruster anomaly ( lower figure ) . From this result , we could confirm that the proposed method put out quite high performance if the parameters such as N are adequate .
633
Scenario 3
This scenario is the most difficult among three . Even though the ninth thruster duty falls down to 30 percents , the behavior of the spacecraft hardly makes any change because other thrusters compensate for the lack of thruster power . The expert of JAXA said that even experts are supposed to miss this anomaly if they do not carefully monitor the telemetry data .
Figure 12 shows the result . The proposed method captured the slight change of the causal associations and detected anomaly .
7 . CONCLUSIONS
This paper proposed a novel anomaly detection method for spacecraft using kernel method . The system behavior of the spacecraft dynamically varies over time . This method successfully detects changes in the semi static causal associations underlying the system behavior by mapping the telemetry data into a nonlinear feature space and obtain
Figure 11 : Change of anomaly metric over time in the scenario 2 .
Figure 12 : Change of anomaly metric over time in the scenario 3 .
200300400500600700800005115Theta ( radian)Scenario 1Anomaly MetricLimit20030040050060070080010080 60 40 20 0 Time ( sec)Thruster Duty ( %)Thruster Duty ( %)(cid:84)(cid:79)(cid:67)(cid:78)(cid:79)(cid:67)(cid:78)(cid:79)(cid:67)(cid:78)(cid:75)(cid:79)(cid:71)200300400500600700800005115Theta ( radian)Scenario 2Anomaly MetricLimit20030040050060070080010090 80 70 60 50 40 30 20 10 0 Time ( sec)Thruster Duty ( %)Thruster Duty200300400500600700800005115Theta ( radian)Scenario 3Anomaly MetricLimit20030040050060070080010090 80 70 60 50 40 30 20 10 0 Time ( sec)Thruster Duty ( %)Thruster Duty409Industry/Government Track Paper ing the direction of its principal component vector .
The contributions of this paper are as follows . • The proposed method acquires the knowledge from telemetry data and requires little a priori knowledge . Thereby , it attained the low construction cost and the high generality of the method which are the main issues of conventional approaches requiring detailed a priori knowledge .
• We regarded anomaly as unexpected changes of the causal associations in the system . We made the hypothesis that the causal associations appear as the principal component vector in the kernel feature space and confirmed it experimentally . Our anomaly metric is considered to include the anomalies defined by the conventional detection systems for spacecraft .
While we used the simple polynomial kernel in this study , the proposed method can be applied to more heterogeneous multidimensional time series data if we can design an appropriate kernel .
Finally , let us describe our future works . The proposed method is incapable of reasoning the cause of anomaly because the kernel function implicitly computes the dot product in the high dimensional feature space2 . We will approach to this difficulty by some means . In addition , we have to consider the optimization problems with regard to the parameter such as the data length N or the number of the principal component vector m .
8 . ACKNOWLEDGEMENTS
The authors would like to thank Japan Aerospace Exploration Agency ( JAXA ) for providing the simulation telemetry data .
9 . REFERENCES [ 1 ] A . Banerjee , I . Dhillon , J . Ghosh , and S . Sra . Generative model based clustering of directional data . In Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 19 28 , 2003 .
[ 2 ] B . Sch¨olkopf , Support Vector Learning , R . Oldenbourg
Verlag , M¨unchen , 1997 , Doktorarbeit , Technische Universit¨at Berlin .
[ 3 ] Bernhard Sch¨olkopf and Alexander J . Smola , Learning with Kernel , The MIT Press , 2002 .
[ 4 ] B . Sch¨olkopf , A . Smola , and K R Muller . Nonlinear component analysis as a kernel eigenvalue problem . Neural Computation , 10:1299 1319 , 1998 .
[ 5 ] de Kleer Johann and Brian C . Williams , Diagnosing with behavioral modes , In : Proceedings of the 11th IJCAI , pp . 1324 1330 . 1989 .
[ 6 ] D . DeCoste : Automated Learning and Monitoring of Limit
Functions , In Proceedings of International Symposium on Artificial Intelligence and Robotics and Automation in Space , 1997 .
[ 7 ] Dennis DeCoste and Marie Levine . Automated Event Detection in Space Instruments : A Case Study Using IPEX 2 Data and Support Vector Machines . SPIE Conference Astronomical Telescopes and Instrumentation , March 2000 .
[ 8 ] Eamonn J . Keogh , Selina Chu , David Hart , and Michael J . Pazzani . An online algorithm for segmenting time series . In Proceedings of the IEEE International Conference on Data Mining , pages 289 296 , 2001 .
[ 9 ] F . Hutter and R . Dearden , The Gaussian Particle Filter for
Diagnosis of non linear Systems , Proceedings of the 5th IFAC . Symposium on Fault Detection , Supervision and Safety of Technical Processes , 2003 .
[ 10 ] IS Dhillon and S . Sra , Modeling data using directional distributions , Technical Report TR 06 03 , University of Texas , Dept . of Computer Sciences , February 2003 .
[ 11 ] J . Durkin , D . Tallo and E . Petrik , FIDEX : An Expert
System for Satellite Diagnostics , Space Communications Technology Conference , Onboard Processing and Switching , NASA Lewis Research Center , Cleveland , OH , Nov . 12 14 , 1991 .
[ 12 ] J . Horvitz , M . Barry : Display of information for Time
Critical Decision Making , In Proceedings of 11th Conference on Uncertainty in Artificial Intelligence , 1995 . [ 13 ] Michael E . Tipping . Sparse Kernel Principal Component Analysis . In Advances in Neural Information Processing Systems ( NIPS ) 13 , Vancouver , Dec . 2001 .
[ 14 ] Minoru Nakatsugawa , Takehisa Yairi , Naoki Ishihama ,
Koichi Hori and Shinichi Nakasuka ” Supporting Anomaly Detection from Satellite Telemetry Data by Regression Trees ” The 24th International Symposium on Space Technology and Science ( ISTS ) , 2004 .
[ 15 ] Richard Doyle , Steve Chien , U . Fayyad and E . J . Wyatt ,
” Focused Real Time Systems Monitoring Based on Multiple Anomaly Models , ” unpublished manuscript , Artificial Intelligence Group , Jet Propulsion Laboratory , 1992 .
[ 16 ] Ryohei Fujimaki , Takehisa Yairi , Kazuo Machida , An
Anomaly Detection Method for Spacecraft using Relevance Vector Learning , The Ninth Pacific Asia Conference on Knowledge Discovery and Data Mining ( PAKDD ) , 2005 , pp785 790 ( Springer , LNAI3518 ) .
[ 17 ] SH Chung , JM Van Eepoel , BC Williams : Improving
Model based Mode Estimation through Offline Compilation , In Proceedings of the 6th International Symposium on Artificial Intelligence and Robotics and Automation in Space , 2001 .
[ 18 ] Takehisa Yairi , Shiro Ogasawara , Koichi Hori , Shinichi
Nakasuka , and Naoki Ishihama ” Summarization of Spacecraft Telemetry Data By Extracting Significant Temporal Patterns ” The Eighth Pacific Asia Conference on Knowledge Discovery and Data Mining ( PAKDD2004 ) , pp.240 244 , 2004 .
[ 19 ] Takehisa Yairi , Yoshikiyo Kato and Koichi Hori , ” Fault
Detection by Mining Association Rules from House keeping Data ” , Proc . of International Symposium on Artificial Intelligence , Robotics and Automation in Space ( i SAIRAS 2001 ) , 2001 .
[ 20 ] Tsuyoshi Ide and Hisashi Kashima , ” Eigenspace based
Anomaly Detection in Computer Systems , ” Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ( KDD 2004 ) , 2004 .
2Though this is the great advantage of the kernel method , we would like to know what occurs in that space for the purpose of failure diagnosis .
410Industry/Government Track Paper
