SVM Selective Sampling for Ranking with Application to
Data Retrieval
Hwanjo Yu
Department of Computer Science
University of Iowa Iowa City , IA 52242 hwanjoyu@csuiowaedu
ABSTRACT Learning ranking ( or preference ) functions has been a major issue in the machine learning community and has produced many applications in information retrieval . SVMs ( Support Vector Machines ) a classification and regression methodology have also shown excellent performance in learning ranking functions . They effectively learn ranking functions of high generalization based on the “ large margin ” principle and also systematically support nonlinear ranking by the “ kernel trick ” . In this paper , we propose an SVM selective sampling technique for learning ranking functions . SVM selective sampling ( or active learning with SVM ) has been studied in the context of classification . Such techniques reduce the labeling effort in learning classification functions by selecting only the most informative samples to be labeled . However , they are not extendable to learning ranking functions , as the labeled data in ranking is relative ordering , or partial orders of data . Our proposed sampling technique effectively learns an accurate SVM ranking function with fewer partial orders . We apply our sampling technique to the data retrieval application , which enables fuzzy search on relational databases by interacting with users for learning their preferences . Experimental results show a significant reduction of the labeling effort in inducing accurate ranking functions .
Categories and Subject Descriptors I.m [ Computing Methodologies ] : Miscellaneous ; H.4 [ Information Systems Applications ] : Miscellaneous
General Terms Algorithms
Keywords Support vector machine , Ranking , Selective sampling , Active learning
1 .
INTRODUCTION
Learning ranking ( or preference ) functions has been a major issue in the machine learning community [ 9 , 7 , 8 ] and has produced many applications in information retrieval [ 11 , 4 ] . Targetting information retrieval applications , we distinguish the task of learning ranking functions from learning classification functions as follows :
1 . Unlike classification functions , which output a distinct class for a data object , ranking functions output a score for each data object , from which a global ordering of data is constructed .
2 . While a training set in classification is a set of data objects and their class labels , in ranking , a training set consists of partial orders of data . For instance , let “ A is preferred to B ” be specified as “ A > B ” . For a dataset D = {d1 , , d|D|} , an example of partial orders is {(d5 > d4 > d9 > d2 ) , ( d4 > d7 ) , } , and the target function F outputs a ranking score of a data object such that F ( di ) > F ( dj ) for any di > dj . Section 2 discusses this in detail .
There are other types of ranking models . However , this model has produced practical applications in information retrieval [ 9 , 11 , 15 ] . ( Section 6 discusses other related ranking models . )
SVMs ( Support Vector Machines ) have proven effective in learning classification or regression functions [ 14 , 3 , 5 ] . They have also shown excellent performance in learning ranking functions [ 9 , 11 , 15 ] . They effectively learn ranking functions of high generalization1 based on the “ large margin ” principle and also systematically support nonlinear ranking by the “ kernel trick ” [ 9 ] .
Typically , the SVM ranking ( or the large margin based preference learning ) machine learns a function in a supervised batch learning scenario , assuming a training set of samples ( ie , partial orders ) is given . In many applications , however , collecting training samples involves human labor which is time consuming and often expensive . While this has been a major issue in classification , it is an even more serious problem in ranking [ 1 ] ; Labeled data in ranking denotes partial ordering of data , and thus users must consider relative ordering of data in labeling while in classification users only consider the absolute class of data .
The concept of active learning or selective sampling refers to approaches that aim at reducing the labeling effort by selecting only the most informative samples to be labeled . SVM selective sampling techniques have been developed and proven effective in
1In the context of ranking , function F of high generalization means that a learned ranking function F not only is concordant with the ordering of the training set ( ie , partial orders ) but also generalize well beyond the training set . achieving a high accuracy with fewer examples in many applications [ 12 , 13 , 4 ] . However , they are restricted to classification problems and do not extend to ranking problems . ( Section 6 discusses this in detail . )
We propose an SVM selective sampling technique for learning ranking functions ( Section 3 ) . That is , using our selective sampling technique , an accurate SVM ranking function can be learned with fewer partial orders . Our method is “ optimal ” in the sense that it selects the most ambiguous set of samples at each round which is considered most informative in SVM ranking . Experimental results show a significant reduction of the labeling effort ( Section 5 ) .
We apply our sampling technique to the “ data retrieval ” application [ 15 ] , which enables fuzzy search on relational databases by interacting with a user for learning her preference ( Section 4 ) . Experiments on this application also show consistent results , ie , our selective sampling method induces ranking functions of high accuracy with fewer interaction with users .
This paper is organized as follows : We first overview the SVM rank learning in Section 2 , present the SVM selective sampling technique for ranking in Section 3 , and then present the data retrieval application in Section 4 . We experimentally evaluate our method in Section 5 . We discuss related work in Section 6 and conclude our study in Section 7 .
2 . SVM RANK LEARNING 2.1 Preliminaries
To establish the context of our discussion , we first discuss preliminaries . We represent data as a vector ~d , in which each element is a numerical value indicating an attribute value of the data . For instance , a vector ~d representing a for sale house from an online real estate company such as realtor.com can be represented by a vector ( age , price , size , beds , baths ) .
We say ~di >R ~dj or ( ~di , ~dj ) ∈ R if a vector ~di ranks higher than ~dj in an order R , otherwise , we say ( ~di , ~dj ) 6∈ R . If not stated , we assume for simplicity that R is strict ordering , which means that for all pairs ~di and ~dj in a set D , either ~di >R ~dj or ~dj >R ~di . However , it can be straightforwardly generalized to weak orderings .
Let R∗ be the optimal ranking of data in which the data is ordered perfectly according to user ’s preference . A ranking function F is evaluated by how closely its ordering RF approximates R∗ . Kendall ’s τ has been the most widely used measure for similarity between two orderings R∗ and RF [ 11 ] . For two strict orderings Ra and Rb , Kendall ’s τ is defined based on the number P of concordant pairs and the number Q of discordant pairs . If R∗ and RF agree in how they order a pair , ~di and ~dj , the pair is concordant , otherwise , it is discordant . For ordering R∗ and RF on a dataset D , we define the similarity function τ as the following :
τ ( R∗ , RF ) =
P
P + Q
= 1 −
Q
„ |D|
2 «
( 1 )
To illustrate , suppose R∗ and RF order five vectors ~d1 , . . . , ~d5 as follow :
~d1 >R∗ ~d2 >R∗ ~d3 >R∗ ~d4 >R∗ ~d5
~d3 >RF ~d2 >RF ~d1 >RF ~d4 >RF ~d5
( 2 )
( 3 )
In this example , τ ( R∗ , RF ) is computed as 0.7 , as the number of discordant pairs is 3 , ie,{ ~d1 , ~d2} , { ~d1 , ~d3} , { ~d2 , ~d3} while all remaining 7 pairs are concordant .
Using the τ measure , we evaluate the accuracy of F as the similarity of the ordering RF generated by F and the optimal ordering R∗ , ie , τ ( RF , R∗ ) . 2.2 SVM Rank Learning
Using the techniques of SVM , we can learn a global ranking function F from partial orders R′ ∈ R∗ . For now , assume F is a linear ranking function such that :
∀( ~di , ~dj ) ∈ R′ : F ( ~di ) > F ( ~dj ) ⇐⇒ ~w · ~di > ~w · ~dj
( 4 )
A weight vector ~w is adjusted by a learning algorithm . We say a set of partial orders R′ is linearly rankable if there exists a function F ( ie , a weight vector ~w ) that satisfies Eq ( 4 ) for all ( ~di , ~dj ) ∈ R′ . The goal is to learn F which is concordant with the given partial orders R′ ∈ R∗ and also generalize well beyond R′ . That is to find the weight vector ~w that satisfies Eq ( 4 ) for most data pairs ( ~di , ~dj ) ∈ R∗ , which maximizes τ ( RF , R∗ ) .
Though this problem is known to be NP hard [ 6 ] , Reference [ 9 ] approximates the solution using SVM techniques by introducing ( non negative ) slack variables ξij and minimizing the upper bound
P ξij [ 9 ] as follows .
QP 1 . minimize : subject to : ∀( ~di , ~dj ) ∈ R′ : ~w · ~di ≥ ~w · ~dj + 1 − ξij
2 ~w · ~w + C P ξij
W ( ~w , ξij ) = 1
∀(i , j ) : ξij ≥ 0
( 5 )
( 6 ) ( 7 )
By the constraint ( 6 ) and minimizing the upper bound P ξij in ( 5 ) , QP 1 satisfies orderings on the training set R′ with minimal error . By minimizing ~w· ~w or by maximizing the “ margin ” ( = 1 || ~w|| ) , it tries to maximize the generalization of the ranking function . We will discuss how maximizing the margin corresponds to increasing the generalization of ranking in Section 221 C is the soft margin parameter that controls the trade off between the margin size and training error .
By rearranging the constraint ( 6 ) as
~w( ~di − ~dj ) ≥ 1 − ξij
( 8 )
QP 1 becomes equivalent to that of SVM classification on pairwise difference vectors ( ~di − ~dj ) . Thus , we can extend an existing SVM implementation to solve the QP .
221 Maximizing Generalization of Ranking
The support vectors in QP 1 denote the data pairs ( ~di , ~dj ) such that ~w( ~di − ~dj ) = 1 . Assume that the training data is linearly rankable and thus ξij = 0 for all ( i , j ) . Then , from Eq ( 8 ) , the support vectors are the closest data pairs when projected to ~w : From Eq ( 4 ) , the linear ranking function F ~w projects data vectors onto a weight vector ~w . The geometrical distance of the two vectors ( ~di , ~dj ) projected onto ~w is formulated as ~w( ~di− ~dj ) . Thus , geometrically , the margin δ ( = 1 || ~w|| ) originally , in the classification problem , denoting the distance from the support vectors to the boundary denotes , in the ranking problem , the distance between the closest two projections . This is illustrated in Figure 1 : two different linear functions F ~w1 and F ~w2 project four data vectors { ~d1 , ~d2 , ~d3 , ~d4} onto ~w1 and ~w2 respectively in a two dimensional
|| ~w|| d2
1 w1 w2 d1 d3
2 racy . The basic idea of SVM selective sampling in classification is that at each round , the learning machine selects the samples that are the closest to the classification boundary so that they are the most difficult to classify . Since an SVM classification function is represented by support vectors that are the data closest to the boundary , this simple selective sampling technique effectively learns an accurate function with fewer labeled data [ 12 , 13 ] .
Figure 1 : Linear projection of four data points
• Output : a classification function F d4
• Input : a few positive and a few negative data , a set of unla beled data
1
|| ~w1|| and
1 space . Both ~w1 and ~w2 make the same ordering R for the four vectors , that is , ~d1 >R ~d2 >R ~d3 >R ~d4 . The distances between the closest two projections onto ~w1 and ~w2 are respectively δ1 and δ2 , which are formulated as
|| ~w2|| respectively .
QP 1 computes the weight vector ~w such that it is concordant with the given orders and generalizes beyond it by maximizing the distance of the closest data pairs in ranking . By minimizing ~w · ~w , QP 1 maximizes the margin , ie , the distance of the closest data vectors in ranking . For instance , in Figure 1 , although the two weight vectors ~w1 and ~w2 make the same ordering , intuitively ~w1 generalizes better than ~w2 because the distance of the closest vectors in ~w1 ( ie , δ1 ) is larger than that in ~w2 ( ie , δ2 ) . Refer to [ 9 , 11 ] for the detailed discussion on maximizing the margin in ranking .
It can be shown that the learned ranking function F can always be represented as dot products of data vectors , and thus it is possible to use nonlinear kernels to learn nonlinear ranking functions . Refer to [ 9 ] for the nonlinear kernel extension of the ranking function .
3 . SVM SELECTIVE SAMPLING FOR RANK
ING
In this section , we present our SVM selective sampling algorithm for ranking , which reduces the labeling effort by selecting only the most informative samples to be labeled .
While previous SVM selective sampling ( or active learning ) techniques have been studied for binary classification [ 12 , 13 , 4 ] , they are not extendable to learning ranking functions , as selective sampling for ranking is more complicated .
The key idea of our selective sampling technique is to select the most ambiguous samples for ranking at each round , so that the user ’s feedback on those samples will maximize the degree of learning . As discussed in Section 2.2 , the support vectors in ranking denote the data pairs that are the closest and thus most ambiguous in ranking . Thus , this principle effectively identifies the support vectors with fewer labeled data ( or partial orders ) . Our sampling algorithm is “ optimal ” in the sense that it selects the most ambiguous set of samples with respect to the learned ranking function at each round .
We first briefly overview the selective sampling for classification
( Section 3.1 ) and present our method ( Section 32 ) 3.1 Overview of selective sampling for classi fication
In a typical setting of selective sampling for binary classification , it is assumed that acquiring a large number of training data ( or labeled data ) is hard or expensive , so we want to minimize the total number of samples to label in order to achieve a high accu
1 . Put the positive and negative data into training set , and build a classification function F from it ( which will be very rough ) .
2 . Compute |F ( ~d)| – the relative distance from a data point ~d to the boundary – for all the unlabeled data , and select l number of data which are the closest to the boundary .
3 . User labels ( or classifies ) the selected data .
4 . Accumulate the newly labeled data into the training set .
5 . Repeat from 2 until the boundary function becomes accurate enough .
Figure 2 : Selective sampling framework for classification
Figure 2 shows the SVM selective sampling framework for classification which is introduced in [ 12 ] to deal with text classification problems . They assume that they have a few labeled data to start with . The relative distance from a vector ~d to the boundary is evaluated by |F ( ~d)| , where F is an SVM classification function . At each round , the system selects l unlabeled data that are closest to the boundary . The user labels the selected data , which will be included in the training set for the next round . The function F becomes more accurate as it iterates . It has been shown that using this selective sampling , the function F becomes accurate with fewer rounds than by using random sampling [ 12 , 13 ] . 3.2 SVM Selective Sampling for Ranking
Similar to the framework of Figure 2 , our framework in Figure 3 starts with l randomly selected samples ( Step 1 ) . Once a user orders the samples ( Step 2 ) , the learning machine puts the partial orders into the training set and builds an SVM ranking function F from the training set by solving the QP 1 ( Step 3 ) .
In Step 4 , the learning machine selects another l samples , S , that are most ambiguous for ranking such that |F ( ~di− ~dj )| is minimized for all ( ~di , ~dj ) ∈ S . Note that the relative ranking difference between ~di and ~dj is evaluated by |F ( ~di − ~dj)| .
As discussed in Section 2.2 , the support vectors in ranking are the data pairs that are the closest and thus most ambiguous for ranking . Thus , this sampling principle quickly identifies the support vectors and reduces the total number of labeled data to achieve a high accuracy .
To select the most ambiguous samples in Step 4 , we define the objective function : arg min Si+1
C(Si+1 )
( 9 ) fi fi d d fi fi fi fi • Input : a dataset D
• Output : a ranking function F
1 . Randomly select l number of samples .
2 . User orders the samples .
3 . Accumulate the orders into the training set and build a rank ing function F from it .
4 . Return F if F is accurate enough . Otherwise , choose another l number of samples using our selective sampling algorithm ( Figure 5 ) .
5 . Repeat from 2 .
Figure 3 : Selective sampling framework for ranking where C(Si+1 ) ( ie , the cost function of Si+1 ) is the sum of the ranking difference of every data pair in Si+1 , ie ,
C(Si+1 ) = X∀( ~dj , ~dk)∈Si+1
|Fi( ~dj − ~dk)|
( 10 ) i is the number of iterations . Fi is the ranking function learned at ith iteration . Si+1 is the target set that we want to select for the next iteration , and it is selected based on the ranking difference according to Fi .
The QP 1 in Section 2.2 uses every data pair ( ~dj , ~dk ) ∈ Si+1 as training data [ 9 , 11 ] . Thus , the objective function Eq ( 9 ) minimizes the sum of ranking differences of every data pairs within the samples such that their rankings are most ambiguous each other .
A naive way to select Si+1 that minimizes the cost function requires |D|Cl evaluations of the function F , as it needs to evaluate every combination of l data objects in the dataset . However , such a long selection time is often unacceptable in information retrieval applications , including the data retrieval application we will present in Section 4 , as most information retrieval applications require a fast response time .
We can reduce the response time by sacrificing the accuracy by approximating Eq ( 9 ) as follows .
1 . Compute |F ( ~dj − ~dk)| for every data pair ( ~dj , ~dk ) ∈ R .
2 . Sort the index pairs {(j , k ) , } in ascending order according to the value of |F ( ~dj − ~dk)| .
3 . Take the top l indices I from the index pair list .
4 . Select the data ~dj for j ∈ I .
This approximation reduces the number of the function evaluations to O(|D|C2 ) , as it evaluates only every data pair in the dataset . However , its results are not optimal because it does not minimize the cost function .
321 Optimal and Efficient Selective Sampling Algo rithm
Is it possible to design an “ optimal ” algorithm that minimizes the cost function C(Si+1 ) and is also efficient ? At the end of this section , we present an optimal algorithm that computes Si+1 minimizing C(Si+1 ) in linear time ( O(|D|) ) . The algorithm is designed based on Theorem 1 , which we will establish . To prove
Theorem 1 , or to prove the optimality of our algorithm in the sense that it minimizes the cost function , we first introduce lemmas 1 and 2 .
Let R = { ~d1 , ~d2 , , ~d|R|} be the ordering of data according to ranking function Fi – generated at the ith iteration – such that ~da >R ~db for a < b .
DEFINITION 1
( CONSECUTIVE SET ) . Let r = { ~da , , ~db} be a subset of R . r is consecutive if b − a = |r| + 1 .
LEMMA 1 . Let r = { ~da , , ~db} be a non consecutive subset of R having only one empty spot , ie , b − a = |r| , and let the empty spot be ~dx ( a < x < b ) . Suppose we construct two consecutive subsets r′ 2| = |r| ) by “ filling in ” ~dx and removing the last vector ~db and the first vector ~da respectively , as shown in Figure 4 . Then ,
2 from r such that ( |r′
1| = |r′
1 and r′
( 1 ) C(r′ ( 2 ) C(r′
1 ) < C(r ) if x ≥ a+b−1 2 ) < C(r ) if x ≤ a+b−1
2
2
, and da da d 1 d 1 d 1 x 1 da+1
… dx 1 dx x 1 da+1
… dx 1 dx x 1 x x x b 1 dx+1
… db 1 db b 1 dx+1
… db 1 db b 1 da da+1
… dx 1 dx dx+1
… db 1 db r r’
1 r’
2
Figure 4 : “ filling in ”
PROOF . Let C(rx ) denote the cost function of r involving only
~dx , ie ,
C(rx ) = Xa≤j<x
|F ( ~dj − ~dx)| + Xx<j≤b
|F ( ~dx − ~dj)|
( 11 )
Let C(rb ) and C(ra ) denote the cost function of r involving only ~db and ~da respectively , ie ,
C(rb ) = Xa≤j<b C(ra ) = Xa<j≤b
|F ( ~dj − ~db)|
|F ( ~da − ~dj )|
Then , we can denote
C(r′ C(r′
1 ) = C(r ) + C(rx ) − C(rb ) 2 ) = C(r ) + C(rx ) − C(ra )
( 12 )
( 13 )
( 14 ) ( 15 )
Let δx denote F ( ~dx − ~dx+1 ) as shown in Figure 4 . For instance , F ( ~dx − ~dx+2 ) = δx + δx+1 . Then , C(rx ) and C(rb ) can be d d d d d d d d d formulated as the following :
C(rx ) = 1δa + 2δa+1 + + ( x − a)δx−1 + ( b − x − 1)δx
+(b − x − 2)δx+1 + 1δb−2
C(rb ) = 1δa + 2δa+1 + + ( x − a)δx−1 + ( x − a)δx +
( x − a + 1)δx+1 + + ( b − a − 1)δb−1
• Input : a dataset D and function Fi
• Output : a subset Si+1
1 . Scan D to build R using Fi .
2 . Set Cmin := a large number ;
Thus ,
C(rx ) − C(rb ) < 0 if ( b − x − 1 ) ≤ ( x − a )
( 16 )
3 . Read the first l data from R , ie , { ~d1 , , ~dl} and compute the cost function of the data ; let C1 be the cost ;
In a similar way ,
4 . Set j := 1 ;
C(rx ) − C(ra ) < 0 if ( b − x − 1 ) ≥ ( x − a )
( 17 )
5 . Repeat until j + l − 1 > |R|
If we plug Eq ( 14 ) into Eq ( 16 ) ,
C(r′
1 ) < C(r ) if x ≥ and plug Eq ( 15 ) into Eq ( 17 )
C(r′
2 ) < C(r ) if x ≤ a + b − 1
2 a + b − 1
2
( a ) If Cmin > Cj , then Cmin := Cj ; Imin = j ; ( b ) Set Cj+1 := Cj − C ~dj
, where
+ C ~dj+l |F ( ~dj − ~dk)| and
|F ( ~dk − ~dj+l)|
C ~dj
C ~dj+l
= Pj<k<j+l = Pj<k<j+l
( c ) Set j := j + 1 ;
Lemma 1 implies that for a non consecutive subset r having one empty spot , we can always build a consecutive subset r′ such that the cost of the consecutive one ( ie , C(r′ ) ) is smaller than that of the non consecutive one ( ie , C(r) ) .
LEMMA 2 . Let r = { ~da , , ~db} be a non consecutive subset of R such that b − a + 1 > |r| , Then , there exists a consecutive subset r′ such that |r′| = |r| and C(r′ ) < C(r ) .
PROOF . We can build rnew such that C(rnew ) < C(r ) by fill ing in one empty spot ~dx and removing either ~da or ~db :
1 . re number the data in r with ~dx by its ordering ,
2 . fill in ~dx and remove either the first or the last data , and
3 . reinstate the data numbers . ( Either ~db or ~da is removed . )
From Lemma 1 , performing the above “ filling in ” procedure in Step 2 will generate a new subset C(rnew ) such that C(rnew ) < C(r ) . We repeat this “ filling in ” procedure for every empty spot until rnew becomes a consecutive set r′ . Thus , for any non consecutive set r , we can always build a consecutive set r′ such that C(r′ ) < C(r ) .
THEOREM 1 . A subset r of R that minimizes the cost function
C(r ) is consecutive .
PROOF . Suppose some r that minimizes the cost function is not consecutive . Then , from Lemma 2 , there exists another consecutive set r′ within r such that C(r′ ) < C(r ) , which contradicts the premise . Therefore , the subset minimizing the cost function must be consecutive .
From Theorem 1 , to find an Si+1 that minimizes the cost function , we can search over only consecutive sets in R . Thus , we can design a selective sampling algorithm that scans the dataset twice ( O(|D| ) ) to compute Si+1 – one for generating R and the other for computing Si+1 from R – as described in Figure 5 .
6 . Output Si+1 = { ~dImin , , ~dImin+l−1}
Figure 5 : The “ optimal ” selective sampling algorithm
4 . APPLICATION TO DATA RETRIEVAL :
ENABLING FUZZY SEARCH ON DATABASES
This section presents an application of our selective sampling algorithm data retrieval which enables fuzzy search on relational databases by , on a “ front end ” , interacting with users to formulate fuzzy queries , and , on a “ back end ” , leveraging a relational query system to process the queries .
Consider several example scenarios of data retrieval in Figure 6 . A user Amy is looking for a house in Chicago . She searches realtor.com with a few constraints on city , price , beds , baths , which returns 3,581 matching houses . Similarly , when Amy searches froogle.com for digital camera , she is again overwhelmed by a total of 746,000 matches . She will have to sift through and sort out all these matches according to her preference . Or , Amy may realize that she must “ narrow ” her query . However , if she narrows her search too far , she may well get no hits at all – an equally undesirable extreme . She will likely manually “ oscillate ” between these extremes before eventually managing to complete her data search task , if at all .
As another example , consider a biologist Bob , searching for genes related to tumor X from a human genome database like EnsEMBL2 . Bob knows that tumor X shares some features with cancers A , B , and C . He needs to formulate a query , from his domain knowledge , to express the features of A , B and C that are relevant to X . Formulating such a query is far from trivial for ordinary users like Bob . Furthermore , after retrieval , it will still take him a long time to investigate all candidate genes for possible involvement with X .
Relational databases support the processing of rank queries through
ORDER BY and LIMIT clauses in SQL . Amy ’s query “ searching for cheap and large houses in Chicago ” can be formulated in SQL as follows .
2http://wwwensemblorg
( a ) Search on realtor.com and froogle.com
( b ) A query interface in EnsEMBL
Figure 6 : Examples of on line search facilities .
Query Q : SELECT h.id , h.address FROM House h WHERE h.city = Chicago ORDER BY min(f1:cheap(h.price ) , f2:large(h.size ) ) LIMIT 10
Predicate cheap(h.price ) : IF ( h.price > 500 , 000 ) THEN RETURN 1.0 − ELSE RETURN 1.0 h.price
M AX P RICE
Predicate large(h.size ) : IF ( h.size > 5000 ) THEN RETURN 1.0 ELSE RETURN h.price 5000
SQL ranks the results based on the score returned in the ORDER BY clause . Users specify the soft predicates ( eg , cheap , large ) such that the returned scores are between zero and one .
While this score based ranking model supported in SQL is expressive and efficient , formulating such ranking functions is challenging to users . It is far from trivial for the user to articulate how she evaluates each and every object into an absolute numeric score , that is , to express her preference by defining the soft predicates and function . Note that , unlike typical relational queries usually formulated by application developers or DB administrator , common users for data retrieval tasks are ordinary people like Amy . Thus , to accommodate such users , the formulation of ranking must be essentially supported without which ranking is not usable .
A framework was proposed to provide users with an intuitive way for expressing their preferences into queries [ 15 ] : Preference often stems from relative ordering without explicit absolute scores . The framework allows users to specify only relative ordering or partial orders ; it is up to the system to infer the underlying ranking function from the few examples . In other words , it gets qualitative feedback from the user and generates a quantitative ranking function which is usable in the existing relational query model .
By learning a scoring function , the SVM ranking machine can be easily adopted in the relational query model . From Eq ( 4 ) , function F outputs the ranking score and thus is adoptable in the ORDER BY clause in SQL .
Our selective sampling framework ( Figure 3 ) can be used as a front end query formulator , as illustrated in Figure 7 :
The rank processing module ( Figure 7 , bottom ) carries out the learned function F for query processing over the database . ad hoc ranking R*
5
4
3
2
1 ranking R* over S sample S ( unordered ) results top ranked results
Rank Formulation Learning Machine
Over S : R F S
?*R no
Function Learning : learn new F
Sample Selection : generate new S ranking function
F yes database D
Rank Processing
Top k Query Processing
Figure 7 : Rank formulation and processing for data retrieval .
The rank formulation module ( Figure 7 , top ) iteratively interacts with the user to learn the desired ranking function . This process operates in rounds , as Figure 3 also presents . In each round , the learning machine selects a sample S of a small number of l objects ( for l << D ; eg , l = 4 or 5 in our study ) . The user orders these examples by her desired ranking R∗ ; thus she “ labels ” these examples as training data . The learning machine will thus learn a function F from the training data ; let RF S be the induced ranking over the latest sample S . At convergence , ie , when RF S is sufficiently close to R∗ ( ie , when F is accurate on S ) , the learner will halt and output F as the learned ranking function .
Note that , unlike typical document retrieval tasks , users in data retrieval tasks are often willing to perform many iterations to further refine the ranking functions . A document retrieval task usually ends as soon as the user finds a few satisfying documents . However , users in data retrieval tasks often want to retrieve every possible candidate before they make decisions . For instance , users searching for houses or digital camcorders do not easily end their tasks by retrieving a few good samples . Instead , they usually retrieve every possible candidate that fits their preferences before they make purchasing decisions . Spending more time on refining the ranking function is likely to reduce the total time for performing the data retrieval task .
5 . EXPERIMENT
This section reports our extensive experiments for studying the
» effectiveness of our selective sampling algorithm . Due to the lack of labeled real world datasets for ranking which are completely ordered , we mostly evaluate our method on artificially generated global orderings R∗ . We first evaluate our method on synthetic data with artificially generated ranking functions ( Section 51 ) Then we use real world data – realtor.com – to demonstrate the practicality of the method ( Section 52 ) We finally discuss some issues in extending the selective sampling technique for nonlinear ranking and further possible applications ( Section 53 )
We use Kendall ’s τ measure discussed in Section 2.1 for evaluation . We implemented the SVM ranking ( ie , QP 1 ) and the selective sampling algorithm using Matlab . Our experiments were conducted with a AMD Athlon 64 2800+ PC with 1GB RAM . 5.1 Experiment on Synthetic Data
We here evaluate the learning performance of our method against random sampling . We randomly created 1000 data points of 10 dimensions ( ie , 1000 by 10 matrix ) such that each element is a random number between zero and one . For evaluation , we artificially generated ranking functions : First , we generated arbitrary linear functions F ( ~d ) = ~w · ~d by randomly generating the weight vector ~w . The global ordering R∗ is constructed from the function . Second , we constructed a second degree polynomial function F ( ~d ) = ( ~w · ~d + 1)2 by also generating ~w randomly .
1
0.95
0.9
0.85
0.8
0.75
0.7
0.65
RAN SEL
2
4
6
8
10 12 14 16 18 20
Figure 8 : Accuracy convergence of random and selective sampling ( linear function ) . X axis : # of iterations ; Y axis : accuracy ; RAN : random sampling ; SEL : selective sampling .
1
0.95
0.9
0.85
0.8
0.75
0.7
RAN SEL random sampling on the orderings . The results are averaged over 20 runs .
Figure 8 and 9 show the accuracy convergence of random and selective sampling for linear and polynomial functions respectively . We use SVM linear and polynomial kernel for them respectively . The selective sampling method consistently outperforms random sampling on both types of functions : The accuracy at the first iteration is the same because they start with the same random samples . Selective sampling achieves higher accuracy at each iteration ( or each number of training samples ) . We selected four samples at each iteration ( ie , l = 4 ) . References [ 12 , 13 ] observe similar behaviors for classification problems . 5.2 Experiment on Real Data
This section performs experiments with a real life house dataset extracted from realtorcom We extracted all the for sale houses in Illinois from realtor.com , resulting in N = 20990 objects for relation house , each with attributes id , price , size ( in square feet ) , # of bedroom , # of bath , zip and city.3 We use SVM linear kernels in this experiment . We discuss using nonlinear kernels in practice in Section 53
521 Experiment with Synthetic Queries
We first synthetically generate queries simulating real situations and evaluate the accuracy and response time of each method . Query 1 shows a scenario of finding a house in a big city , Chicago , while Query 2 focuses on a small city , Champaign .
Query 1 :
SELECT id FROM house WHERE city= “ Chicago ” ORDER BY average(a,b,c,d ) : a = cheap(price ) , b = large(size ) , c = many1(beds ) , d = many2(baths )
Query 2 :
SELECT id FROM house WHERE city= “ Champaign ” ORDER BY average(a,b,c,d ) : a = cheap(price ) , b = large(size ) , c = many1(beds ) , d = many2(baths )
Predicates : cheap(price ) a : a = ( 100,000 price ) * 0.001 large(size ) b : b = size * 0.1 many1(beds ) c : c = beds * 20 many2(baths ) d : d = baths * 20
Figure 10 : Rank queries
2
4
6
8
10 12 14 16 18 20
Figure 9 : Accuracy convergence of random and selective sampling ( polynomial function ) . X axis : # of iterations ; Y axis : accuracy ; RAN : random sampling ; SEL : selective sampling .
We generated global orderings R∗ from the two types of ranking functions and tested the accuracy of our sampling method against
The queries in Figure 10 show that the user is interested in cheap and large houses having many beds and baths . The predicate definitions in the figure illustrate the user ’s preference in more detail . For instance , the user is willing to trade 200 square feet of size ( which decreases the score of b by 20 ) for one more bedroom ( which increases the score of c by the same amount ) . The ranking function
3The dataset is available in http://aimcsuiucedu/
R RAN 1 85.75 88.18 2 90.60 3 92.93 4 94.67 5 1 77.53 81.12 2 89.90 3 93.24 4 5 94.43
Q1
Q2
Accuracy ( % )
Time ( sec . )
SEL ASEL RAN 85.75 0.002 91.84 0.003 93.62 0.003 94.89 0.005 95.29 0.006 77.53 0.002 89.32 0.003 93.23 0.004 95.31 0.006 96.39 0.006
85.75 90.70 92.60 93.82 94.93 77.53 86.84 91.09 94.88 95.19
SEL ASEL 0.002 0.002 9.27 0.024 9.67 0.027 9.92 0.029 9.97 0.030 0.002 0.002 0.087 0.012 0.098 0.013 0.108 0.015 0.019 0.111
0.98
0.96
0.94
0.92
0.9
0.88
0.86
0.84
Query 1
SEL ASEL RAN
1
2
3
4
5
6
7
8
# of iteration
Table 1 : Performance results ( averaged over 20 runs ) . R : # of rounds ( l = 5 ) ; Time : average response time ; RAN : random sampling ; SEL : selective sampling ; ASEL : approximated selective sampling ;
Figure 11 : Performance convergence of three sampling methods on Query 1 . SEL : selective sampling ; ASEL : approximated selective sampling ; RAN : random sampling . can be formulated as the following linear ranking function :
F ( ~d ) = 100 − 0.001 ∗ price + 0.1 ∗ size + 20 ∗ beds + 20 ∗ baths ( 18 ) We generated user feedback , ie , partial orderings , based on the given query . We generated five samples at each iteration . We then measured the accuracy of the learned ranking function and response time at each round , with ( 1 ) random sampling ( RAN ) , ( 2 ) our selective sampling ( SEL ) , and ( 3 ) the approximate selective sampling ( ASEL ) which takes O(|D|C2 ) function evaluations ( introduced in Section 32 ) Table 1 summarizes the results . The results are averaged over 20 runs . We highlight our observations as follow :
0.95
0.9
0.85
0.8
0.75
Query 2
SEL ASEL RAN
1
2
3
4
5
6
7
8
# of iteration
• SEL outperforms RAN and ASEL from the second iteration , as Figure 11 and 12 show . The accuracy at the first iteration is the same because they start with the same random samples .
Figure 12 : Performance convergence of three sampling methods on Query 2 . SEL : selective sampling ; ASEL : approximated selective sampling ; RAN : random sampling .
• Observe that the response time of RAN is similar for Q1 and Q2 because it is independent of the size of the dataset . In contrast , the response time of ASEL is very sensitive to the size of dataset , as it requires O(|D|C2 ) function evaluations . ASEL ’s response time is much longer for Q1 than Q2 , as there are more houses in Chicago than in Champaign . SEL manages a shorter response time than ASEL for both datasets while its accuracy is the highest . ( SEL requires 2|D| times of function evaluations . )
• The accuracy is consistent regardless of the size of the dataset |D| . For instance , Table 1 shows that ordering on five samples generated higher accuracy for houses in Chicago than houses in Champaign , but they become comparable as they iterate .
522 Experiment on Real Queries
Due to the lack of real world datasets for evaluating ranking , it is difficult to evaluate selective sampling in real situations . Thus , this section focus on presenting the potential of the selective sampling method in the applications of data retrieval by demonstrating experiment results with real life users . We asked 10 ordinary users to test our system with their own house preferences and collected around 100 real queries .
Note that , in this user study setting , the perfect ordering R∗ the user intended remains unclear and thus it is hard to make fair evaluations ; It is infeasible for a user to provide a complete ordering on hundreds or thousands of houses . Thus , we evaluated the accuracy of the ranking function at this iteration against the partial ordering specified by the user in the next iteration . That is , the accuracy of the ranking function Fi learned at ith iteration is measured by comparing the similarity of the user ’s partial ordering on Si+1 at the next iteration and the ordering generated by Fi . We set l = |S| = 5 at each iteration . We call this measure expected accuracy , as it is an approximation evaluated over ten pairwise orderings . ( An ordering on five samples generates ten ( = 5C2 ) pairwise orderings . ) That is , “ 100 % expected accuracy ” means it correctly ranks five samples that are randomly chosen .
This measure approximates the generalization performance of ranking functions , as Si+1 is not a part of training data for learning Fi . Further , using this evaluation method , we can also acquire fair evaluations from users since the users are not aware of whether they are providing feedback or evaluating the functions at each round .
However , this measure severely disfavors selective sampling . Intuitively , selective sampling will be most effective for learning if the user ’s ordering on Si+1 is not what is expected from the previous iteration . We thus use random sampling for the user study reported in this section . However , note that selective sampling is expected to be more effective in practice , as demonstrated in our experiments on synthetic data ( Section 5.1 ) and on real data with synthetic queries ( Section 521 )
Figure 13 shows the distribution of user queries generating over 90 % and 100 % expected accuracy per each iteration . Observe from Figure 13 that most user preferences were captured with 90 % ex s e i r e u q f o
#
60
50
40
30
20
10
0
90 %
100 %
1
2
3
4
5
6
Iteration
Figure 13 : Distribution of user queries generating over 90 % and 100 % expected accuracy
Figure 14 : Screen shot of our running system . The candidate set : houses in Chicago pected accuracy within the second iteration , and 100 % within the third iteration .
Figure 13 implies that , for the real user preferences , the SVM ranking with random sampling learns an accurate ( ie , expected accuracy ≥ 90 % ) ranking function in a couple of communications with a user ( ie , iterations ≤ 2 ) . Our experiments in previous sections suggest the SVM with selective sampling will achieve higher accuracy with fewer interactions with users . Note that the accuracy here is based on the house dataset . The learning performance could vary depending on the type of data ( eg , the number of attributes . )
523 Illustration of a running system
To qualitatively demonstrate , Figure 14 shows a screen shot of our system that we used in our user study :
At Round 1 , the system showed five randomly selected samples of houses . Each house shows its price , number of beds and baths , size , and location ( ie , latitude and longitude extracted from the zipcode ) . We have not performed any normalizations of the attribute values . Assume that the user prefers cheap and large houses with many beds and baths . Based on this criteria , a user ordered the five houses such that 5 >R∗ 2 >R∗ 4 >R∗ 3 >R∗ 1 .
At Round 2 , the system showed another randomly selected five samples , and the user ordered them as 1 >R∗ 2 >R∗ 3 >R∗ 4 >R∗ 5 , which turned out to be the same as the orders generated by F1 . Thus , the expected accuracy after Round 1 is 100 % in the figure . Our system printed out the top ten results according to the ranking function as shown in the result in the figure . The top house ranked by the function ( ie , PRICE:59000 , BEDS:8 , BATHS:2 , SIZE : 1080 , ) is large and has many bedrooms , but is low in price .
The following is the ranking function generated by our system after the first round .
F 1 = −0.00040567886125586483 ∗ price
+0.0004819932549453127 ∗ beds +0 ∗ baths +0.041829246236619627 ∗ size −0.00025355851829348932 ∗ latitude +7.4244894504004128e − 05 ∗ longitude −1.17129e − 11
Observe that the ranking function F1 from the first iteration captures that the user prefers houses of low price , many beds , and large size . In contrast , the weights of baths and latitude are very low , which implies , from the first round , the machine learns that these two attributes do not contribute much in ranking the data objects . ( Note that attributes are not normalized , eg , the values of price and size are relatively large compared to the others . ) 5.3 Discussion
Nonlinear ranking : We used only SVM linear kernels in the experiments with real queries . Linear functions are simple , yet often expressive enough , and thus have been used as a popular model for rank ( or top k ) query processing [ 2 , 10 ] . However , deploying nonlinear functions might be necessary to deal with complex preferences that are not rankable by linear functions . Nonlinear ranking functions can be learned directly using SVM nonlinear kernels [ 9 ] . However , tuning the nonlinear kernel parameters online is not trivial , as it is hard to perform a validation online .
Further applications : Other than the data retrieval applications , our selective sampling techinque is applicable to any rank or preference learning tasks , as labeling is time consuming and often expensive in many applications . For instance , this technique can be used to infer a customer ’s preference by getting a small amount of feedback . Getting a large amount of feedback from customers increases accuracy , but is often cumbersome to the customers .
6 . RELATED WORK
References [ 12 , 13 ] present SVM selective sampling techniques for binary classification . Reference [ 4 ] applies the techniques proposed in [ 12 , 13 ] , to conduct effective binary relevance feedback for image retrieval . However , these techniques are proposed within the context of binary classification ( of whether the image is relevant or not ) and thus does not support learning ranking functions from partial orders .
There is an effort to extend the selective sampling to ranking [ 1 ] . It is based on pairwise decomposition [ 7 ] and constraint classification [ 8 ] . They extend multi class classification to ranking and thus are limited to a finite and a priori fixed set of data and the model is not scalable to the size of the dataset .
Our selective sampling is based on the large margin ranking which has proven effective in practice for learning global ranking func
Conf . Data Engineering ( ICDE’05 ) , 2005 . tions [ 9 , 11 ] . This ranking model orders new examplies with respect to their ranking scores , and thus is scalable and has produced many practical applications for information retrieval [ 9 , 11 , 15 ] .
7 . CONCLUSIONS
This paper proposes an SVM selective sampling technique for learning ranking functions . Our method selects the most ambiguous set of samples for ranking so that the ordering on the set maximizes the degree of learning . Thus , our sampling technique significantly reduces the labeling effort to learn an accurate SVM ranking function . We apply our method to the data retrieval application . Our experiments on synthetic and real datasets show that our sampling method learns an accurate ranking function with fewer samples than random sampling and a naive selective sampling method and also is more scalable to large datasets than the naive selective sampling method .
8 . REFERENCES [ 1 ] K . Brinker . Active learning of label ranking functions . In
Proc . Int . Conf . Machine Learning ( ICML’04 ) , 2004 .
[ 2 ] N . Bruno , L . Gravano , and A . Marian . Evaluating top k queries over web accessible databases . In Proc . Int . Conf . Data Engineering ( ICDE’02 ) , 2002 .
[ 3 ] C . J . C . Burges . A tutorial on support vector machines for pattern recognition . Data Mining and Knowledge Discovery , 2:121–167 , 1998 .
[ 4 ] E . Chang and S . Tong . Support vector machine active learning for image retrieval . In ACM Multimedia 2001 , 2001 .
[ 5 ] N . Christianini and J . Shawe Taylor . An Introduction to support vector machines and other kernel based learning methods . Cambridge University Press , 2000 .
[ 6 ] W . W . Cohen , R . E . Schapire , and Y . Singer . Learning to order things . In Proc . Advances in Neural Information Processing Systems ( NIPS’98 ) , 1998 .
[ 7 ] J . Furnkranz and E . Hullermeier . Pairwise preference learning and ranking . In Proc . European Conf . Machine Learning ( ECML’03 ) , 2003 .
[ 8 ] S . Har Peled , D . Roth , and D . Zimak . Constraint classification : A new approach to multiclass classification and ranking . In Proc . Advances in Neural Information Processing Systems ( NIPS’02 ) , 2002 .
[ 9 ] R . Herbrich , T . Graepel , and K . Obermayer , editors . Large margin rank boundaries for ordinal regression . MIT Press , 2000 .
[ 10 ] V . Hristidis , N . Koudas , and Y . Papakonstantinou . PREFER :
A system for the efficient execution of multi parametric ranked queries . Proceedings ACM SIGMOD International Conference on Management of Data , 2001 .
[ 11 ] T . Joachims . Optimizing search engines using clickthrough data . In Proc . ACM SIGKDD Int . Conf . Knowledge Discovery and Data Mining ( KDD’02 ) , 2002 .
[ 12 ] G . Schohn and D . Cohn . Less is more : Active learning with support vector machines . In Proc . Int . Conf . Machine Learning ( ICML’00 ) , pages 839–846 , 2000 .
[ 13 ] S . Tong and D . Koller . Support vector machine active learning with applications to text classification . In Proc . Int . Conf . Machine Learning ( ICML’00 ) , pages 999–1006 , 2000 .
[ 14 ] V . N . Vapnik . Statistical Learning Theory . John Wiley and
Sons , 1998 .
[ 15 ] H . Yu , S . Hwang , and K . C C Chang . Rankfp : A framework for supporting rank formulation and processing . In Proc . Int .
