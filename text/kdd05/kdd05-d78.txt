Modeling and Predicting
Personal Information Dissemination Behavior
Xiaodan Song ,
Dept of Electrical Engineering ,
Ching Yung Lin IBM Watson Research
University of Washington , Seattle , WA 98195 , USA
Center , 19 Skyline Drive ,
Hawthorne , NY 10532 song@eewashingtonedu cyl@usibmcom
Belle L . Tseng
Ming Ting Sun
NEC Labs America , 10080 N . Wolfe Road , SW3 350 , Cupertino , CA 95014 , USA belle@svnec labscom
Dept of Electrical Engr ,
University of Washington ,
Seattle , WA 98195 , USA sun@eewashingtonedu and time contact , content ,
ABSTRACT In this paper , we propose a new way to automatically model and predict human behavior of receiving and disseminating information by analyzing the contact and content of personal communications . A personal profile , called CommunityNet , is established for each individual based on a novel algorithm incorporating information simultaneously . It can be used for personal social capital management . Clusters of CommunityNets provide a view of informal networks for organization management . Our new algorithm is developed based on the combination of dynamic algorithms in the social network field and the semantic content classification methods in the natural language processing and machine learning literatures . We tested CommunityNets on the Enron Email corpus and report experimental results including filtering , prediction , and recommendation capabilities . We show that the personal behavior and intention are somewhat predictable based on these models . For instance , "to whom a person is going to send a specific email" can be predicted by one ’s personal social network and content analysis . Experimental results show the prediction accuracy of the proposed adaptive algorithm is 58 % better than the social network based predictions , and is 75 % better than an aggregated model based on Latent Dirichlet Allocation with social network enhancement . Two online demo systems we developed that allow interactive exploration of CommunityNet are also discussed .
Categories and Subject Descriptors I26 [ Artificial Intelligence ] : Learning General Terms algorithms , experimentation Keywords user behavior modeling , personal information management , information dissemination
1 . INTRODUCTION
Working in the information age , the most important is not what you know , but who you know [ 1 ] . A social network , the graph of relationships and interactions within a group of individuals , plays a fundamental role as a medium for the spread of information , ideas , and influence . At the organizational level , personal social networks are activated for recruitment , partnering , and information access . At the individual level , people exploit their networks to advance careers and gather information .
Informal network within formal organizations is a major , but hard to acquire , factor affecting companies' performance . Krackhardt [ 2 ] showed that companies with strong informal networks perform five or six times better than those with weak networks , especially on the long term performance . Friend and advice networks drive enterprise operations in a way that , if the real organization structure does not match the informal networks , then a company tends to fail [ 3 ] . Since Max Weber first studied modern bureaucracy structures in the 1920s , decades of related social scientific researches have been mainly relying on questionnaires and interviews to understand individuals' thoughts and behaviors for sensing informal networks . However , data collection is time consuming and seldom provides timely , continuous , and dynamic information . This is usually the biggest hurdle in social studies .
Personal Social Network ( PSN ) could provide an organizing principle for advanced user interfaces that offer information management and communication services in a single integrated system . One of the most pronounced examples is the networking study by Nardi et al . [ 4 ] , who coined the term intensional networks to describe personal social networks . They presented a visual model of user ’s PSN to organize personal communications in terms of a social network of contacts . From this perspective , many tools were built such as LinkedIn [ 5 ] , Orkut [ 6 ] , and Friendster [ 7 ] . However , all of them only provide tools for visually managing personal social networks . Users need to manually input , update , and manage these networks . This results in serious drawbacks . For instance , people may not be able to invest necessary efforts in creating rich information , or they may not keep interests , responsibilities , and network change . They need a way to organize the relationship and remember who have the resources to help them . We coin the terminology of managing these goals as personal social capital management1 . information up to date as their the
In this paper , we develop a user centric modeling technology , which can dynamically describe and update a person ’s personal social network with context dependent and temporal evolution information from personal communications . We refer to the model as a CommunityNet . Senders and receivers , time stamps , subject and content of emails contribute three key components – content semantics , temporal information , and social relationship . We propose a novel Content Time Relation ( CTR ) algorithm to capture dynamic and context dependent information in an unsupervised way . Based on the CommunityNet models , many questions can be addressed by inference , prediction and filtering . For instance , 1 ) Who are semantically related to each other ? 2 ) Who will be involved in a special topic ? Who are the important ( central ) people in this topic ? 3 ) How does the information flow ? and 4 ) If we want to publicize a message , whom should we inform ?
1 Social capital infers to the accumulated contacts’ human capital ( asset , power , resources ) that a person can explore through social network [ 8 ] .
Figure 1 shows the procedure of our proposed scheme . First , topic detection and clustering is conducted on training emails in order to define topic communities . Then , for each individual , CommunityNet is built based on the detected topics , the sender and receiver information , and the time stamps . Afterwards , these personal CommunityNets inferring organizational informal networks and predicting personal behaviors to help users manage their social capitals . We incorporate the following innovative steps : 1 )
Incorporate content analysis into social network in an unsupervised way can be applied for
2 ) Build a CommunityNet for each user to capture the contextdependent , temporal evolutionary personal social network based on email communication records
3 ) Analyze people ’s behaviors based on CommunityNet , information sending and including predicting people ’s receiving behaviors
4 ) Show the potential of using automatically acquired personal social network for organization and personal social capital management
Applications Applications
Recommendation system Recommendation system
Prediction , Prediction ,
Filtering Filtering
CommunityNet CommunityNet
Input : Emails Input : Emails
From : sallybeck@enroncom From : sallybeck@enroncom To : shonawilson@enroncom To : shonawilson@enroncom
Subject : Re : timing of submitting Subject : Re : timing of submitting information to Risk Controls information to Risk Controls
Good memo let me know if you see results . Good memo let me know if you see results .
…… ……
Topic Detection , Topic Detection , Content Analysis Content Analysis
Topics Topics
Meeting schedule Meeting schedule
Agreement Agreement
California Energy California Energy
Game Game
Holiday celebration Holiday celebration
CommunityNet CommunityNet
Modeling Modeling
Figure 1 . An Overview of CommunityNet
We tested the CommunityNet model on the Enron email corpus comprising the communication records of 154 Enron employees dating from Jan . 1999 to Aug . 2002 . The Enron email dataset was originally made available to public by the Federal Energy Regulatory Commission during the investigation [ 9 ] . It was later collected and prepared by Melinda Gervasio at SRI for the CALO ( A Cognitive Assistant that Learns and Organizes ) project . William Cohen from CMU has put up the dataset on the web for research purpose [ 9 ] . This version of the dataset contains around 517,432 emails within 150 folders . We clean the data and extract 154 users from those 150 folders with 166,653 unique messages from 1999 to 2002 . In the experiments , we use 16,873 intra organizational emails which connect these 154 people .
The primary contributions of this paper are three fold . First we develop an algorithm incorporating content time relation detection . Second , we generate an application model which describes personal dynamic community network . Third , we show how this model can be applied to organization and social capital management . To the best of our knowledge , this is among the first reported technologies on fusing research in the social network analysis field and the content analysis field for information management . We propose the CommunityNet based on the Latent Dirichlet Allocation algorithm . In our experiments , we observed clear benefit of the CTR algorithm and discovering knowledge based on multi modality information rather than using only single type of data .
The rest of the paper is organized as follows . In Section 2 , we present an overview of related work . In Section 3 , we present our model . We discuss how to use CommunityNet to analyze communities and individuals in section 4 and 5 , respectively . In Section 6 , we show two demo systems for query , visualization and contact recommendation . Finally , conclusions and future work are addressed in Section 7 .
2 . RELATED WORK 2.1 Social Network Analysis
To capture relationships between entities , social network has been a subject of study for more than 50 years . An early sign of the potential of social network was perhaps the classic paper by Milgram [ 10 ] estimating that on average , every person in the world is only six edges away from each other , if an edge between i and j means "i knows j" . Lately , introducing social network analysis into information mining is becoming an important research area . Schwartz and Wood [ 11 ] mined social relationships from email logs by using a set of heuristic graph algorithms . The Referral Web project [ 12 ] mined a social network from a wide variety of publicly available online information , and used it to help individuals find experts who could answer their questions based on geographical proximity . Flake et al . [ 13 ] used graph algorithms to mine communities from the Web ( defined as sets of sites that have more links to each other than to non members ) . Tyler et al . [ 14 ] use a betweenness centrality algorithm for the automatic identification of communities of practice from email logs within an organization . The Google search engine [ 15 ] and Kleinberg's HITS algorithm of finding hubs and authorities on the Web [ 16 ] are also based on social network concepts . The success of these approaches , and the discovery of widespread network topologies with nontrivial properties , have led to a recent flurry of research on applying link analysis for information mining .
A promising class of statistical models for expressing structural properties of social networks is the class of Exponential Random Graph Models ( ERGMs ) ( or p* model ) [ 17 ] . This statistical model can represent structural properties that define complicated dependence patterns that cannot be easily modeled by deterministic models . Let Y denote a random graph on a set of n nodes and let y denote a particular graph on those nodes . Then , the probability of Y equals to y is
( P Y θ
=
) y
= exp
)
)
( ( θ T s y ( ) θ c
( 1 ) is a known vector of graph statistics ( Density , where Reciprocity , Transitivity , etc ) on y , θis a vector of coefficients to model the influence of each statistics for the whole graph , T means to . The parameters θ are estimated based on
“ transpose ” , ) 1 = a normalization
( c θ is satisfy term
= y
)
( s y
)
∑
( P Y θ y the observed graph obsy by maximum likelihood estimation .
All the research discussed above has focused on using static properties in a network to represent the complex structure . However , social networks evolve over time . Evolution property has a great deal of influence ; eg , it affects the rate of information diffusion , the ability to acquire and use information , and the quality and accuracy of organizational decisions .
Dynamics of social networks have attracted many researchers’ attentions recently . Given a snapshot of a social network , [ 19 ] tries to infer which new interactions among its members are likely to occur in the near future . In [ 20 ] , Kubica et al . are interested in tracking changes in large scale data by periodically creating an agglomerative clustering and examining the evolution of clusters over time . Among the known dynamical social networks in literature , Snijder's dynamic actor oriented social network [ 18 ] is one of the most successful algorithms . Changes in the network are modeled as the stochastic result of network effects ( density , reciprocity , etc ) Evolution is modeled by continuous time Markov chains , whose parameters are estimated by the Markov chain Monte Carlo procedures . In [ 21 ] , Handcock et al . proposed a curved ERGM model and applied it to the new specifications of ERGMs This latest model uses nonlinear parameters to represent structural properties of networks .
The above mentioned dynamic analyses show some success in analyzing longitudinal stream data . However , most of them are only based on pure network properties , without knowing what people are talking about and why they have close relationships .
2.2 Content Analysis
In statistical Natural Language processing , one common way of modeling the contributions of different topics to a document is to treat each topic as a probability distribution over words , viewing a document as a probability distribution over words , and thus viewing a document as a probabilistic mixture over these topics . Given T topics , the probability of the ith word in a given document is formalized as : where
( P w i
)
=
T
∑
= 1 j
( P w z
| i
= i
( ) j P z i
=
) j
( 2 ) iz is a latent variable indicating the topic from which the is the probability of the word ith word was drawn and j=
)
|i
( P w z ( ) iP z j= i iw under the jth topic . a word from topics j in the current document , which varies across different documents . gives the probability of choosing
Hofmann [ 22 ] introduced the aspect model Probabilistic Latent Semantic Analysis ( PLSA ) , in which , topics are modeled as multinomial distributions over words , and documents are assumed to be generated by the activation of multiple topics . Blei et al . [ 23 ] proposed Latent Dirichlet Allocation ( LDA ) to address the problems of PLSA that parameterization was susceptible to overfitting and did not provide a straightforward way to infer testing documents . A distribution over topics is sampled from a Dirichlet distribution for each document . Each word is sampled from a multinomial distribution over words specific to the sampled topic . Following the notations in [ 24 ] , in LDA , D documents containing T topics expressed over W unique words , P w z with a set of T multinomial we can represent
)
(
| distributions φ over the W words , such that , and P(z ) with a set of D multinomial distribution θ over the T
P w z
=
( w
|
( j φ ) j
=
) topics , such that for a word in document d ,
P z
(
=
( j θ ) j
=
) d
.
Recently , the Author Topic ( AT ) model [ 25 ] extends LDA to include authorship information , trying to recognize which part of the document is contributed by which co author . In a recent unpublished work , McCallum et al . [ 26 ] further extend the AT model to the Author Recipient Topic model by regarding the sender receiver pair as an additional author variable for topic classification . Their goal is role discovery , which is similar to one of our goals as discussed in Sec 412 without taking the temporal nature of emails into consideration .
Using LDA , φ and θ are parameters that need to be estimated by using sophisticated approximation either with variational Bayes or expectation propagation . To solve this problem , Griffiths and Steyvers [ 24 ] extended LDA by considering the posterior distribution over the assignments of words to topics and showed how Gibbs sampling could be applied to build models . Specifically ,
( P z i
= j z w
,
|
− i
)
∝
( w n i − , i ( ) n − i , j i
) j
+ +
( d n − i ( d W n i − i ,
β β i i , )
) j
+ +
α α T
( 3 ) where
( ) i is a count that does not include the current assignment , in−
)w
( jn is the number of times word w has been assigned to topic j in the vector of assignments z ,
)d
( jn is the number of times a word from document d has been assigned to topic j ,
( ) jn i is a sum of
)w
( jn
( )dni
, is a sum of
)d
( jn
. Further , one can estimate
(
)w jφ , the probability of using word w in topic j , and topic j in document d as follows :
(
)d jθ , the probability of
) w
( ˆ φ j
=
) d
( ˆ θ j
=
β β n W
) w
( + n j ( ) +i j ) ( d j
+ n ( +i n
) d
α α T
( 4 )
( 5 )
In [ 24 ] , experiments show that topics can be recovered by their algorithm and show meaningful aspects of the structure and relationships between scientific papers .
Contextual , relational , and temporal information are three key factors for current data mining and knowledge management models . However , there are few papers addressing these three components simultaneously . .In our recent paper , we built user models to explicitly describe a person ’s expertise by a relational and evolutionary graph representation called ExpertisetNet [ 27 ] . In this paper , we continue exploring this thread , and build a CommunityNet model which incorporates these three components together for data mining and knowledge management .
3 . COMMUNITYNET
In this section , we first define terminologies . Then , we propose a Content Time Relation ( CTR ) algorithm to build the personal CommunityNet . We also specifically address the prediction of the user ’s behaviors as a classification problem and solve it based on the CommunityNet models .
3.1 Terminology Definition 1 . Topic Community : A topic community is a group of people who participate in one specific topic .
Definition 2 : Personal Topic Community Network ( PTCN ) : A personal topic community network is a group of people directly connected to one person about a specific topic .
Definition 3 . Evolutionary Personal Social Network : An evolutionary personal social network illustrates how a personal social network changes over time .
Definition 4 . Evolutionary Personal Topic Community Network : An evolutionary network illustrates how a person ’s personal topic community network changes over time .
LDA LDA LDA
AT AT AT u u u
ART ART ART u u u
CTR CTR u u z z w w t t
S S
N N r r
D D
: observations : observations
θ θ
φ φ
A A
T T
ϕ ϕ Tm Tm
α α
β β
γ γ
Figure 2 . The graphical model for the CTR model comparing to LDA , AT and ART models , where u : sender , z : latent topic , S : social network , D : number of emails in the corpus , r : receivers , w : words , N : number of documents , T : number of topics , t : time , Tm : size of the time sliding window , A : number of authors ,
,θφand ϕ are the parameters we want to estimate with the hyperparameters
,α βγ
,
Definition 5 . Personal Social Network Information Flow : A personal social network information flow illustrates how the information flows over a person ’s personal social network to other people ’s personal social networks
Definition 6 : Personal Topic Community Information Flow : A personal Topic CommunityNet information flow illustrates how the information about one topic flows over a person ’s personal social network to other people ’s personal social networks .
3.2 Personal Social Network
We build people ’s personal social networks by collecting their communication records . The nodes of a network represent whom this person contacts with . The weights of the links measure the probabilities of the emails he sends to the other people : A basic form of the probability that an user u sending email to a recipient r is :
( P r u
|
)
= number of times u sends emails to r total number of emails sent out by u
( 6 )
We build evolutionary personal social networks to explore the dynamics and the evolution . The ERGM in Eq ( 1 ) can be used to replace Eq ( 6 ) for probabilistic graph modeling . A big challenge of automatically building evolutionary personal social network is the evolutionary segmentation , which is to detect changes between personal social network cohesive sections . Here we apply the same algorithm as we proposed in [ 27 ] . For each personal social network in one time period t , we use the exponential random graph model [ 17 ] to estimate an underlying distribution to describe the social network . An ERGM is estimated from the data in each temporal sliding window . With these operations , we obtain a series of parameters which the graph configurations . indicates
3.3 Content Time Relation Algorithm We begin with email content , sender and receiver information , and time stamps , and use these sources of knowledge to create a joint probabilistic model . An observation is ( u , r , d , w , t ) corresponds to an event of a user u sending to receivers r an email d containing words w during a particular time period t . Conceptually , users choose latent topics z , which in turn generate receivers r , documents d , and their content words w during time period t . z t P z d t , ,
( , P u r d t
( P u r
( 7 )
)
)
(
)
,
,
|
|
|
= ∑ z where
,u r is a sender receiver pair during time period t .
,u r can be replaced by any variable to indicate the user ’s behavior , as long as it is also assumed to be dependent on latent topics of emails .
In order to model the PTCN , one challenge is how to detect latent topics dynamically and at the same time track the emails related to the old topics . This is a problem similar to topic detection tracking [ 28 ] . We propose an incremental LDA ( ILDA ) algorithm to solve it , in which the number of topics is dynamically updated based on the Bayesian model selection principle [ 24 ] . The procedures of the algorithm are illustrated as follows :
Incremental Latent Dirichlet Allocation ( ILDA ) algorithm :
Input : Email streams with timestamp t
(
) j tφ , w , j tθ for different time period t d ,
(
)
Output :
Steps :
1 ) Apply LDA on a data set with currently observed emails in a jz and estimate time period t to generate latent topics
( ( P w z t φ= w , j t 0
)
,
|
0 j
) and
( ( P z d t θ= d , j t 0
)
,
|
0
) j by equation ( 4 ) and ( 5 ) . The number of topics is determined by the Bayesian model selection principle .
2 ) When new emails arrive during time period k , use Bayesian model selection principle to determine the number of topics and apply
( P z i
= j z w t ,
,
|
− i
)
∝
( P w z
| i k
= j t ,
−
1 k
)
) j
( + d n i − , i ) ( +i d n i − , i
α α T to estimate
( , k P z d t
|
)
( , k P w z t
|
)
,
, and
( P z w t , k
|
)
.
3 ) Repeat step 2 ) until no data arrive .
Based on this ILDA algorithm , we propose a Content TimeRelation ( CTR ) algorithm . It consists of two phases , the training phase and the testing phase . In the training phase , emails as well as time stamps are available . ( P w z t the senders , receivers and )
( P u r
, old z t and
, old
)
,
|
| are learnt from the observed )
( P z d t
, new
.
| data . In the testing phase , we apply ILDA to learn
Based on
( P u r
,
|
, old z t
)
, which is learnt from the training phase ,
,u r can be inferred . Again ,
,u r represents a sender receiver pair or any variable to indicate the user ’s behavior , as long as it is dependent on the latent topics of emails .
Content Time Relation ( CTR ) algorithm :
1 ) Training phase
Input : Old emails with content , sender and receiver information , and time stamps oldt
Output :
( P w z t ,
| old
)
Steps :
( P z d t ,
|
,
) old
, and
( P u r
,
|
, z t old
) a ) Apply Gibbs Sampling on the data according to equation ( 3 ) . b ) Estimate
( , P w z t
) equation ( 4 ) , and ( 5 ) . old
| j c ) Estimate
)
( φ= w , j t old and
( P z j
|
, d t old
)
( θ= d , j t
) old by
,
( P u r ∑
∝ d
|
, z t old
)
=
( P u r
,
| d t ,
∑ ) d old
|
,
( P u r ( P z d t ,
| d t , old
)
( , P d z t
| old
)
) old
( 8 )
2 ) Testing phase
Input : New emails with content and time stamps newt
( P u r d t ,
,
|
)
( , P w z t
|
, new
) new
, and
( , P z d t
| new
)
Output :
Steps : a ) Apply incremental LDA by Gibbs Sampling based on
( P z i
= j z w t ,
,
|
− i
)
∝
( P w z i
,
= new j
| t old
) to
) j
+ i , ) +i
α α T
( d n − i ( d n i − i , ) by equation ( 4 ) and estimate
( ,j P w z t
| new
)
, and
( 5 ) .
( P z d t
, new
| b ) the
If ( ˆ P u r
, topics are within
|
, d t new
)
= ∑ z
( P u r
, the
|
, z t old training set , estimate )
( , P z d t
, else if the new
)
| sender and receivers are within the training set , estimate ( ˆ P u r d t ( P u r topic independent social network
, new )
) .
| old t by
,
,
| c )
If there are new topics detected , update the model by incorporating the new topics .
Inference , filtering , and prediction can be conducted based on this model . For the CTR algorithm , sender variable u or receiver variable r is fixed . For instance , if we are interested in ( , which is to answer a question of whom we should send the message d to during the time period t . The answer will be
, P r u d t
)
,
| argmax r argmax r
( ˆ , P r u d t
,
| new
)
=
P r u z t old
,
|
, t P z old t old
)
(
   
∑ z t old
(
|
, , u d t new
)
+
∑ z t new old z t
/
( P r u t P z t new
) old
,
|
(
|
, , u d t new
( 9 )
)
    where z
/ tz old t new represents the new topics emerging during the time period t . Another question is if we receive an email , who will be possibly the sender ? argmax u argmax u
( ˆ P u r d t ,
| , new
)
=
P u r z t old
,
|
, t P z old t old
)
(
   
∑ z t old
( r d t | , , new
)
+
∑ z t new
/ z t old
( P u r t P z t old
) old
,
|
( r d t | , , new
( 10 )
)
   
Eq ( 9 ) and Eq ( 10 ) integrate the PSN , content and temporal analysis . Social network models such as ERGM in Eq ( 1 ) or the model in Sec 3.2 can be applied to the
( P u r d t ,
,
|
) terms .
Figure 2 illustrates the CTR model and compares to the LDA , AT and ART models . In CTR , the observed variables not only include the words w in an email but also the sender u and the timestamp on each email d .
3.4 Predictive Algorithms
For the sake of easier evaluation , we focus on prediction schemes in details . Specifically , we address the problem of predicting receivers and senders of emails as a classification problem , in which we train classifiers to predict the senders or receivers and other behavior patterns given the observed people ’s communication records . The trained classifier represents a function in the form of : f Comm t (
:
− → Y i t , )
( 11 ) where
( Comm t
) , i t− is the observed communication record during the interval from time t i to t , Y is a set of receivers or senders or other user behavior patterns to be discriminated , and the value of
( ( f Comm t i t− ,
)
) is the classifier prediction regarding which user behavior patterns gave rise to the observed communication records . The classifier is trained by providing the history of the communication records with known user behaviors .
341 Using Personal Social Network Model
We aggregate all the communication records in the history of a given user , and build his/her personal social network . We choose those people with the highest communication frequency with this person as the prediction result .
342 Using LDA combined with PSN Model
We use the LDA model and combine it with PSN to do the prediction , which is referred as LDA PSN in the paper . Latent topics are detected by applying original LDA on the training set and LDA testing data without incorporating new topics when time passes by . The possible is used for inference in senders and receivers when new emails arrive , estimated as
( ˆ P u r
,
|
, d t new
)
= ∑ z
( P u r
,
|
, z t
|
( P u r d t )
, ( , P z d t old
|
, new new
) ) is
.
People are ranked by this probability as the prediction results .
343 Using CTR Model
People tend to send emails to different group of people under different topics during different time periods . This is the assumption we made for our predictive model based on CTR .
( P u r d t
,
|
, new
) is estimated by applying the CTR model discussed in section 33 The prediction results are people with highest scores calculated by equation ( 9 ) and ( 10 ) .
344 Using an Adaptive CTR Model
Both the personal social network and the CTR model ignore a key piece of information from communication records the dynamical nature of emails . Both personal social network and Topic Community dynamically change and evolve . Only based on the training data which are collected in history will not get the optimal performance for the prediction task . Adaptive prediction by updating the model with newest user behavior information is necessary . We apply several strategies for the adaptive prediction . The first strategy is aggregative updating the model by adding new user behavior information including the senders and receivers into the model . Then the model becomes :
( ˆ , P u r d t i
,
|
)
=
( P u r z t P z d t , i
, k old
)
(
,
|
| k
K
∑
= 1 k
)
+
∑ z t i
/ z t old
( P u r t P z d t , i
) old
,
|
| t i
(
)
( 12 ) where K is the number of old topics . Here , we always use the data from oldt to predict the user behavior during it .
, including 0t
1it − to
In the second strategy , we assume the correlation between current data and the previous data decays over time . The more recent data are more important . Thus , a sliding window of size n is used to choose the data for building the prediction model , in which the prediction is only dependent on the recent data , with the consists influence of old data ignored . Here in equation ( 12 ) , oldt of i n t − to
1it − .
3.5 CommunityNet Model
We then build a CommunityNet model based on the CTR algorithm . The CommunityNet model , which refers to the personal Topic Community Network , draws upon the strengths of the topic model and the social network as well as the dynamic model , using a topic based representation to model the content of the document , the interests of the users , the correlation of the users and the receivers and all these relationship changing over time . For prediction , CommunityNet incorporates the adaptive CTR model as described in Section 344
4 . COMMUNITY ANALYSIS
The first part of our analysis focuses on identifying clusters of topics , and the senders and receivers who participated in those topics . First , we analyze the topics detected from the Enron Corpus . Then , we study the topic community patterns .
4.1 Topic Analysis
In the experiment , we applied Bayesian model selection [ 24 ] to choose the number of topics . In the Enron intra organization emails , there are 26,178 word terms involved after we apply ( P w T for T stop words removal and stemming , We computed
)
| values of 30 , 50 , 70 , 100 , 110 , 150 topics and chose T = 100 with the maximum value of for the experiment . log
(
( P w T
|
)
)
411 Topic Distribution
After topic clustering based on words , for each document , we have P(z|d ) , which indicates how likely each document belongs to each topic . By summing up this probability for all the documents , we get the topic distribution of how likely each topic occurs in this corpus . We define this summed likelihood as “ Popularity ” of the topic in the dataset . From this topic distribution , we can see that some topics are hot people frequently communicate with each other about them , while some others are cold , with only few emails related to them . Table 1 illustrates the top 5 topics in Enron corpus . We can see that most of them are talking about regular issues in the company like meeting , deal , and document . Table 2 illustrates the bottom 5 topics in Enron corpus . Most of them are specific and sensitive topics , like “ Stock ” or “ Market ” . People may feel less comfortable to talk about them broadly . meeting meeting plan conference balance presentation discussion
Trade trade
London bank name Mexico conserve
Table 1 . Hot Topics deal deal desk book bill group explore
Petroleum Petroleum research dear photo Enron station
Texas Houston
Texas Enron north America street
Table 2 . Cold Topics stock Stock earn company share price new network network world user save secure system
Project Court state India server project govern document letter draft attach comment review mark
Market call market week trade description respond
412 Topic Trend Analysis
To sense the trend of the topics over time , we calculate the topic popularity for year 2000 and 2001 , and calculate the correlation coefficients of these two series . For some topics , the trends over years are similar . Figure 3(a ) illustrates the trends for two topics which have largest correlation coefficients between two years . Topic 45 , which is talking about a schedule issue , reaches a peak during June to September . For topic 19 , it is talking about a meeting issue . The trend repeats year to year .
Figure 3(b ) illustrates the trend of Topic “ California Power ” over 2000 to 2001 . We can see that it reaches a peak from the end of year 2000 to the beginning of year 2001 . From the timeline of Enron [ 29 ] , we found that “ California Energy Crisis ” occurred at exactly this time period . Among the key people related to this topic , Jeff Dasovich was an Enron government relations executive . His boss , James Steffes was Vice President of Government Affairs . Richard Schapiro was Vice President of Regulatory Affairs . Richard Sanders was Vice President and Assistant General Counsel . Steven Kean was Executive Vice President and Chief of Staff . Vincent Kaminski was a PhD economist and Head of Research for Enron Corp . Mary Han was a lawyer at Enron ’s West Coast trading hub . From the timeline , we found all these people except Vince were very active in this event . We will further analyze their roles in Section 5 .
Topic Trend Comparison
Topic45(y2000 )
Topic45(y2001 )
Topic19(y2000 )
Topic19(y2001 ) l y t i r a u p o P
0.03
0.025
0.02
0.015
0.01
0.005
0
Jan
Mar
May
Jul
Sep
Nov
( a ) Trends of two yearly repeating events .
Topic Analysis for Topic 61
0.018
0.016
0.014
0.012
0.01
0.008
0.006
0.004
0.002
0 Jan 00
Apr 00
Jul 00 Oct 00
Jan 01
Apr 01
Jul 01 Oct 01
Keywords with
) ( P w z
|
Key people ) ( |P u z with power 0.089361 California 0.088160 electrical 0.087345 price 0.055940 energy 0.048817 generator 0.035345 market 0.033314 until 0.030681 Jeff_Dasovich 0.249863 James_Steffes 0.139212 Richard_Shapiro 0.096179 Mary_Hain 0.078131 Richard_Sanders 0.052866 Steven_Kean 0.044745 Vince_Kaminski 0.035953
( b ) The trend of “ California Power ” and most related keywords and people .
Figure 3 . Topic trends
4.2 Predicting Community Patterns
We assume that , people communicate with certain people only under certain few topics . People in the same community under a topic would share the information . Thus , if there is something new about one topic , people in that topic community will most likely get the information and propagate it to others in the community . Finally , many people in the community will get the information .
To evaluate our assumption and answer the question of who will be possibly involved in an observed email , we collect the ground truth about who are the senders and receivers for the emails to ( infer . We partitioned the data into P u r use by ( algorithm
CTR and
P u r
, the
|
,j z t
|
,j z t old
)
,
) new training set and testing set . We tried two strategies for this experiment . First is to randomly partition the data into a training set with 8465 messages and a testing set with 8408 messages . Prediction accuracy is calculated by comparing the inference results and the ground truth ( ie , receiver sender pair of that email ) . We found that 96.8446 % people stick in the old topics they are familiar with . The second strategy is to partition data by time : emails before 1/31/2000 as the training data ( 8011 ) and after that as the testing data ( 8862 ) . We found 89.2757 % of the people keep their old topics . Both results are quite promising . It is found that people really stick in old topics they are familiar with .
5 . INDIVIDUAL ANALYSIS
In this section , we evaluate the performance of CommunityNet . First , we show how people ’s roles in an event can be inferred by CommunityNet . Then , we show the predicting capability of the proposed model in experiments .
5.1 Role Discovery
People with specific roles at company hierarchy behave specifically on specific topics . Here we show it is possible to infer people ’s roles by using CommunityNet .
In Section 412 , we show there are some key people involved in “ California Energy Crisis ” . In reality , Dasovich , Steffes , Schapiro , Sanders , and Kean , were in charge of government affairs . Their roles were to “ solve the problem ” . Mary
Hain was a lawyer during the worst of the crisis and attended meetings with key insiders . We calculated the correlation coefficients of the trends of these people and the overall trend of this topic . Jeff Dasovich got 0.7965 , James Steffes got 0.6501 , Mary Hain got 0.5994 , Richard Shapiro got 0.5604 , Steven Kean got 0.3585 ( all among the 10 highest correlation scores among 154 people ) , and Richard Sanders got 0.2745 ( ranked 19 ) , while Vince Kaminski had correlation coefficient of 0.4617 ( Figure 4 ) . We can see that all the key people except Vince Kaminski have strong correlation with the overall trend of “ California Energy Crisis ” . From their positions , we can see that all of them were sort of politicians while Vince Kaminski is a researcher . Thus , it is clear to see the difference of their roles in this topic .
Overall trend
Jeff_Dasovich
Vince_Kaminski
0.5
0.4
0.3
0.2
0.1 l y t i r a u p o P
0 Jan 00 May 00 Sep 00 Jan 01 May 01 Sep 01
Figure 4 . Personal topic trend comparison on “ California Power ”
5.2 Predicting Receivers
Here we want to address the problem of whether it is possible to infer who will possibly be the receivers by a person ’s own historic communication records and the content of the emailto send . One possible application is to help people organize personal social capital . For instance , if a user has some information to send or a question to ask , CommunityNet can recommend the right persons to send the info or get the answer .
We conduct experiments by partitioning the dataset into a training set with the emails from 1999 to 2000 , and a testing set with the emails from 2001 to 2002 . The testing set is further partitioned into sub sets with emails from one month as a subset . With this , we have 15 testing sets . ( We exclude the emails after March 2002 because the total number of emails after that is only 78 . ) One issue we want to mention is that the number of people from 1999 to 2000 is 138 , while from 2001 to 2002 is 154 . In this study , we test each email in the training set by using its content , sender , and time as prior information to predict the receiver , which is compared to the real receiver of that email .
In Figure 5 , we illustrate the prediction performance by comparing the CTR algorithm , PSN , and the aggregated LDAPSN model . The result shows that CTR beats PSN by 10 % on accuracy . The aggregated LDA PSN model performs even worse than PSN , because of the inaccurate clustering results . The performance gain is 21 % . Moreover , intuitively , personal contacts evolve over time . Models built at a specific time should have decreasing predicting capability over time . In this figure , we obtain strong evidence of this hypothesis by observing that the performance of these models monotonically decays . This also implies our models well match the practice . y c a r u c c A
1
0.8
0.6
0.4
0.2
0 by PSN by CTR by LDA PSN
Jan 01
Apr 01
Jul 01
Oct 01
Jan 02
( a ) Accuracy based on the top 5 most likely people y c a r u c c A
1
0.8
0.6
0.4
0.2
0 by PSN by CTR by LDA PSN
Jan 01
Apr 01
Jul 01
Oct 01
Jan 02
( b ) Accuracy based on the top 10 most likely people
Figure 5 . Prediction Accuracy comparisons . Accuracy is measured by testing whether the “ real ” receiver is among the prediction list of the top 5 or 10 most likely people
5.3 Inferring Senders
We test whether it is possible to infer who will possibly be the senders given a person ’s CommunityNet and the content of the email . One possible application is to exclude spam emails or detect identification forgery . Figure 6 illustrates the prediction result , which also shows the prediction accuracy decays over time . y c a r u c c A
1
0.8
0.6
0.4
0.2
0 top5 top3
Jan 01 Mar 01 May 01 Jul 01 Sep 01 Nov 01
Figure 6 . Predicting senders given receiver and content
5.4 Adaptive Prediction
We observed the prediction performance decays over time from the results of 5.2 and 5.3 , which reflects the changes of the nature of email streams . Here we apply adaptive prediction algorithms we mentioned in 343 , in which we incrementally and adaptively estimate statistical parameters of the model by gradually forgetting out of state statistics . y c a r u c c A
1
0.8
0.6
0.4
0.2
0
Adaptive CTR(Top 5 )
Adaptive CTR(Top 10 )
CTR(Top5 )
CTR(Top10 )
Jan 01 Mar 01 May 01 Jul 01 Sep 01 Nov 01
( a ) . Comparison between Adaptive CTR and CTR models
Adaptive CTR(aggregative )
Adaptive CTR(6 months )
CTR
LDA PSN
PSN
45
40
35
30
25
20
15
10
5
0
Jan 01 Mar 01 May 01 Jul 01 Sep 01 Nov 01
( b ) Comparison of algorithms using Breese evaluation metrics
Figure 7 . Performance evaluation for adaptive prediction algorithm and overall comparison
Figure 7 ( a ) illustrates the performance of the Adaptive CTR algorithm and compares it to the CTR algorithm . For the data far away from the training data , the improvement is more than 30 % . And , if we compare it to the PSN and LDA PSN algorithms , the performance gains are 58 % and 75 % , respectively . Evaluation by this accuracy metric tells us how related the top people ranked in the prediction results are . To understand the overall performance of the ranked prediction results , we apply the evaluation metric proposed by Breese [ 30 ] , and illustrate the overall comparison in Figure 7(b ) . This metric is an aggregation of the accuracy measurements in various top n retrievals in the ranked list . Among all predictive algorithms , adaptive CTR models perform best and PSN performs worst . In adaptive CTR models , estimating from recent data of six months beats aggregative updating the model from all the data from the history .
6 . COMMUNITYNET APPLICATIONS
In this section , we show two application systems we built based on the CommunityNet . The first one is a visualization and query tool to demonstrate informal networks incorporation . The second one is a receiver recommendation tool which can be used in popular email systems . These demos can be accessed from http://nanseneewashingtonedu/CommunityNet/
6.1 Sensing Informal Networks 611 Personal Social Network
Figure 8 illustrates the interface of a visualization and query system of CommunityNet . The distance of nodes represents the closeness ( measured by the communication frequencies ) of a person to the center person . Users can click on the node to link to the CommunityNet of another person . This system can show personal social networks , which includes all the people a user contacts with during a certain time period . For instance , Figure 8(a ) illustrates the personal social network of Vice President John Arnold from January 1999 to December 2000 . During this period , there were 22 people he sent emails to , regardless what they were talking about . An evolutionary personal social network is illustrated in Figure 8(b ) , in which we show people ’s personal social network changes over time . From Jan . 1999 to Dec . 2000 , no new contact was added to John ’s PSN . However , people ’s relationship changed in 2000 . A Personal Social Network Information Flow is illustrated in Figure 8(c ) , in which we show how the information flows through the network ( here we illustrate the information in two levels . )
( a ) Personal Social Network of John Arnold
( b1 ) Jan ‘99 to Dec ‘99 ( b2 ) Jan ‘00 to Jun ‘00 ( b3 ) Jul ‘00 to Dec ‘00
( b ) Evolutionary Personal Social Network
( c ) Personal Social Network Information Flow with two level personal social network of John Arnold
Figure 8 . Personal social networks of John Arnold
612 Personal Topic Community Network
Personal topic community network can show whom this user will contact with under a certain topic . On retrieval , keywords are required for inferring the related topics . Figure 9 illustrates several personal topic community networks for John Arnold . First , we type in “ Christmas ” as the keyword . CommunityNet infers it as “ holiday celebration ” and shows the four people John contacted with about this topic . About “ Stock ” , we find John talked with five people on “ Stock Market ” and “ Company Share ” from Jan . 1999 to Dec . 2000 . Personal Topic Community network can be depicted by the system , too .
Figure 9 . Personal Topic Community Networks when we type in
“ Christmas ” and “ Stock ”
6.2 Personal Social Capital Management Receiver Recommendation Demo
When a user has some questions , he/she may want to know whom to ask how to find an expert and who may tell him/her more details because of their close relationships . In our second demo , we show a CommunityNet application which addresses this problem . This tool can be incorporated with general email systems to help users organize their personal social capitals . First , after a user login a webmail system , he can type in content and/or subject then click on the "Show Content Topic Community" . This tool shall recommend appropriate people to send this email to , based on the learned personal social network or personal topiccommunity . The distances of nodes represent the closeness of the people to the user . Users can click on the node to select an appropriate person to send email to . If the center node is clicked , then a sphere grows to represent his ties to a group of experts . Click on “ Mail To ” , then the people in the sphere will be included in the sender list .
In the examples in Figure 10 , we log in as Jeff Dasovich . He can ask his closest friends whenever he has questions or wants to disseminate information . If he wants to inform or get informed on “ Government ” related topics , the system will suggest him to send emails to Steffes , Allen , Hain , or Scott . The topics are inferred by matching the terms from the Subject as well as the content of the email . He can also type in “ Can you tell me the current stock price ? ” as the email content . This system will detect “ Stock Market ” as the most relevant topic . Based on Dasovich ’s CommunityNet , it shows three possible contacts . He then chooses appropriate contact(s ) .
[ 3 ] D . Krackhardt and M . Kilduff , "Structure , culture and Simmelian ties in entrepreneurial firms," Social Networks , Vol . 24 , 2002 .
[ 4 ] B . Nardi , S . Whittaker , E . Isaacs , M . Creech , J . Johnson , and J . Hainsworth , and Information Through Visualizing Personal Social Networks , ” Com . of the Association for Computing Machinery . April , 2002 .
Integrating Communication
“ ContactMap :
[ 5 ] https://wwwlinkedincom/home?trk=logo [ 6 ] https://wwworkutcom/Loginaspx [ 7 ] http://wwwfriendstercom/ [ 8 ] N . Lin , “ Social Capital , ” Cambridge Univ . Press , 2001 . [ 9 ] W . Cohen . http://www 2cscmuedu/~enron/ [ 10 ] S . Milgram . “ The Small World Problem , ” Psychology Today , pp 60
67 , May 1967 .
[ 11 ] M . Schwartz and D . Wood , “ Discovering Shared Interests Among
( a ) Receiver recommendation for “ Government ”
( b ) Receiver recommendation for “ Can you tell me the current stock price ? ”
Figure 10.Receiver recommendation demo system
7 . CONCLUSIONS AND FUTURE WORK
In this paper , we propose a new way to automatically model and predict human behavior of receiving and disseminating information . We establish personal CommunityNet profiles based on a novel Content Time Relation algorithm , which incorporates contact , content , and time information simultaneously from personal communication . CommunityNet can model and predict the community behavior as well as personal behavior . Many interesting results are explored , such as finding the most important employees in events , predicting senders and receivers of emails , etc . Our experiments show that this multi modality algorithm performs better than both the social network based predictions and the content based predictions . Ongoing work includes studying the response time of each individual to emails from different people to further analyze user ’s behavior , and also incorporating nonparametric Bayesian methods as hierarchical LDA with contact and time information . such
8 . ACKNOWLEDGMENTS We would like to thank D . Blei , T . Griffiths , Yi Wu and anonymous for valuable discussions and comments . This work was supported by funds from NEC Labs America . reviewers
9 . REFERENCES [ 1 ] B . A . Nardi , S . Whittaker , and H . Schwarz . “ It ’s not what you know , it ’s who you know : work in the information age , ” First Mon . , 5 , 2000 .
[ 2 ] D . Krackhardt , “ Panel on Informal Networks within Formal
Organizations , ” XXV Intl . Social Network Conf . , Feb . 2005 .
People Using Graph Analysis ” , Comm . ACM , v . 36 , Aug . 1993 .
[ 12 ] H . Kautz , B . Selman , and M . Shah . “ Referral Web : Combining social networks and collaborative filtering , ” Comm . ACM , March 1997 .
[ 13 ] G . W . Flake , S . Lawrence , C . Lee Giles , and F . M . Coetzee . “ Selfidentification of Web communities , ” IEEE organization and Computer , 35(3):66–70 , March 2002 .
[ 14 ] J . Tyler , D . Wilkinson , and B . A . Huberman . “ Email as spectroscopy : Automated Discovery of Community Structure Within Organizations , ” Intl . Conf . on Communities and Technologies . , 2003 .
[ 15 ] L . Page , S . Brin , R . Motwani and T . Winograd . “ The PageRank Citation Ranking : Bringing Order to the Web , ” Stanford Digital Libraries Working Paper , 1998 .
[ 16 ] J . Kleinberg . “ Authoritative sources in a hyperlinked environment , ” In Proc . 9th ACM SIAM Symposium on Discrete Algorithms , 1998 . [ 17 ] S . Wasserman , and P . E . Pattison , “ Logit models and logistic regression for social networks : I . An introduction to Markov graphs and p* ” , Psychometrika , 61 : 401– 425 , 1996 .
[ 18 ] T . AB Snijders . “ Models for Longitudinal Network Data , ” Chapter 11 in Models and methods in social network analysis , New York : Cambridge University Press , 2004 .
[ 19 ] D . L. Nowell and J . Kleinberg , “ The Link Prediction Problem for Social Networks , ” In Proceedings of the 12th Intl . Conf . on Information and Knowledge Management , 2003 .
[ 20 ] J . Kubica , A . Moore , J . Schneider , and Y . Yang . “ Stochastic Link the 2002 AAAI and Group Detection , ” In Proceedings of Conference . Edmonton , Alberta , 798 804 , 2002 .
[ 21 ] M . Handcock and D . Hunter , “ Curved Exponential Family Models for Networks , ” XXV Intl . Social Network Conf . , Feb . 2005 .
[ 22 ] T . Hofmann ,
“ Probabilistic Latent
Semantic Analysis , ”
Proc . of the Conf . on Uncertainty in Artificial Intelligence , 1999 .
[ 23 ] D . Blei , A . Ng , and M . Jordan , “ Latent Dirichlet allocation , ” Journal of Machine Learning Research , 3:993 1022 , January 2003 .
[ 24 ] T . Griffiths and M . Steyvers , “ Finding Scientific Topics , ” Proc . of the National Academy of Sciences , 5228 5235 , 2004 .
[ 25 ] M . R. Zvi , T . Griffiths , M . Steyvers and P . Smyth , “ The AuthorTopic Documents ” , Proc . of the Conference on Uncertainty in Artificial Intelligence volume 21 , 2004 .
Authors and
Model for
[ 26 ] A . McCallum , A . Corrada Emmanuel , and X . Wang , “ The AuthorRecipient Topic Model for Topic and Role Discovery in Social Networks : Experiments with Enron and Academic Email , ” Technical Report UM CS 2004 096 , 2004 .
[ 27 ] X . Song , B . L . Tseng , C Y Lin , and M T Sun , "ExpertiseNet : Relational and Evolutionary Expert Modeling," 10th Intl . Conf . on User Modeling , Edinburgh , UK , July 24 30 , 2005 .
[ 28 ] J . Allan , R . Papka , and V . Lavrenko . “ On line New Event Detection and Tracking , ” Proc . of 21st ACM SIGIR , pp.37 45 , August 1998 .
[ 29 ] http://enwikipediaorg/wiki/Timeline_of_the_Enron_scandal [ 30 ] J . Breese , D . Heckerman , and C . Kadie . “ Empirical analysis of filtering , ” Conf . on predictive algorithms Uncertainty in Artificial Intelligence , Madison,WI , July 1998 . for collaborative
