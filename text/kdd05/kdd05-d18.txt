Anonymity Preserving Data Collectionfi
1Computer Science Department , Stevens Institute of Technology , Hoboken , NJ 07030
Zhiqiang Yang1 Sheng Zhong1;2 Rebecca N . Wright1
2DIMACS Center , Rutgers University , Piscataway , NJ 08854 fzyang , sz38 , rwrightg@csstevensedu
ABSTRACT Protection of privacy has become an important problem in data mining . In particular , individuals have become increasingly unwilling to share their data , frequently resulting in individuals either refusing to share their data or providing incorrect data . In turn , such problems in data collection can affect the success of data mining , which relies on sufficient amounts of accurate data in order to produce meaningful results . Random perturbation and randomized response techniques can provide some level of privacy in data collection , but they have an associated cost in accuracy . Cryptographic privacy preserving data mining methods provide good privacy and accuracy properties . However , in order to be efficient , those solutions must be tailored to specific mining tasks , thereby losing generality .
In this paper , we propose efficient cryptographic techniques for online data collection in which data from a large number of respondents is collected anonymously , without the help of a trusted third party . That is , our solution allows the miner to collect the original data from each respondent , but in such a way that the miner cannot link a respondent ’s data to the respondent . An advantage of such a solution is that , because it does not change the actual data , its success does not depend on the underlying data mining problem . We provide proofs of the correctness and privacy of our solution , as well as experimental data that demonstrates its efficiency . We also extend our solution to tolerate certain kinds of malicious behavior of the participants .
Categories and Subject Descriptors E.3 [ Data ] : Data Encryption
General Terms Algorithms ; Security . fiThis work was supported by the National Science Foundation under Grant No . CCR 0331584 .
Keywords Anonymity , Data Collection , Data Mining .
1 .
INTRODUCTION
With the rapid development of computer and networking technologies , huge amounts of data are collected and analyzed all over the world every day . Some of this data is privacy sensitive , and issues of privacy protection of sensitive data are receiving more and more attention from the public [ 19 , 25 , 26 ] . In particular , since data mining is a powerful tool for discovering knowledge from large amounts of data , protection of privacy in data mining has become one of the top priorities of study [ 5 ] .
Currently , a significant amount of data used in data mining is collected on networks . Consider a typical scenario of online data collection : the miner ( or data collector ) queries large sets of respondents ( or customers ) , and each respondent submits her data to the miner in response . Clearly , this can be an efficient and convenient procedure , assuming the respondents are willing to submit their data . However , the respondents’ willingness to submit data is affected by their privacy concerns [ 6 ] . For example , the miner may be a medical researcher who studies the relationship between dining habits and a certain disease . Since a respondent may not want to reveal what food she eats and/or whether she has that disease , she may give false information or decline to provide information . Therefore , protecting privacy of respondents is highly important to the success of data mining . In the example we mentioned above , one possible solution is that the miner collects data anonymously . That is , he collects records from the respondents containing each respondent ’s dining habits and health information related to that disease , but does not know which record came from which respondent . Since a respondent is \hidden" among many peers , she should feel comfortable to submit her data . We generalize this idea to propose an approach called anonymity preserving data collection . Specifically , we propose that the miner should collect data in such a way that he is unable to link any piece of data collected to the respondent who provided that piece of data . In this way , respondents do not need to worry about their privacy . Furthermore , the data collected is not modified in any way , and thus the miner will have the freedom to apply any suitable mining algorithms to the data . 1.1 Related Work
A variety of methods have been proposed to protect the privacy of each respondent by perturbing the respondents’
334Research Track Paper data . Warner proposed randomized response techniques , together with statistical techniques for reconstructing distributions from the perturbed responses [ 37 ] . Different random perturbation methods have been proposed and applied in different data mining algorithms [ 2 , 1 , 12 , 28 , 11 , 9 ] . Random perturbation is very efficient , but in general it can induce a tradeoff between privacy of respondents and accuracy of the data mining result : the more privacy each respondent has , the less accurate the result of mining is , and vice versa . Although some perturbation techniques lead to good accuracy plus good privacy in specific data mining problems , these perturbation techniques would produce inaccurate results when used in other data mining problems . The privacy preserving properties of the perturbation techniques are further explored in [ 21 ] .
Privacy preserving data mining solutions have also been proposed based on cryptographic techniques ( cf [ 23 , 34 , 38 , 39] ) . However , the design of the cryptographic protocol depends on the specific mining task , unless a prohibitively expensive general purpose secure multiparty computation is used [ 40 , 15 ] .
A class of closely related work studies how to measure privacy in data mining . This includes privacy definitions based on confidence intervals [ 2 ] , based on mutual information [ 1 ] , and based on priori and posterior knowledge [ 11 , 8 ] . Privacy definitions motivated by cryptographic notions of confidentiality are given by Gilburd et al . [ 13 ] and Dwork and Nissim [ 10 ] , respectively .
We note that our problem could be solved if an anonymous communication channel were available . However , building an anonymous channel is a nontrivial task . General purpose ways to build anonymous channels include mix networks [ 3 , 24 , 29 , 20 , 18 ] , dining cryptographer networks ( DC nets ) [ 4 , 36 , 17 ] and k anonymous message transmission [ 35 ] , all of which are still under active study . Compared with mix networks , our work can be viewed as a ( nontrivial ) application of certain techniques in their design to the scenario of distributed data collection , which eliminates the burden of introducing a set of mix servers while keeping analogous security guarantees . Compared with DC nets and k anonymous message transmission , our solution produces more efficient results for our setting . For example , the communication cost of k anonymous message transmission is cubic in the number of users ; in comparison , our solutions in this paper have linear communication costs .
Systems like Crowds [ 27 ] and Hordes [ 22 ] provide practical anonymity for web access without assuming an existing anonymous channel . Similarly , our work provides anonymity for data collection without assuming an existing anonymous channel . However , Crowds and Hordes assume eavesdroppers involved are local ( ie , can only eavesdrop communications within one hop ) . They do not guarantee anonymity when an adversary is able to eavesdrop communications in the entire system . In contrast , our solutions in this paper can work against global eavesdroppers .
In contrast to our setting , work on k anonymization [ 32 , 31 , 30 , 7 ] deals with the complementary problem of ensuring that data does not reveal the identity of the data subject , by processing a database table to de associate privacy sensitive attributes from the corresponding identifiers . We note that the goal of k anonymization is somewhat different : in kanonymization , making the data anonymous is the target , but how it is communicated to the data miner in the first place is not addressed ; in our work , we assume the data is inherently anonymous ( as in our example of dining habits and a disease ) , and address the problem of making the data submission procedure anonymous . ( See Section 2 for the precise definition of the type of anonymity we consider ) . 1.2 Our Contributions
In this paper , we propose an approach called anonymitypreserving data collection . Instead of making each respondent ’s data oblivious to the miner , our approach reveals all respondents’ data to the miner , but does not allow the miner to link any respondent ’s data to the corresponding respondent . As long as the data itself does not contain information that can be used for identification , this is usually sufficient to protect respondents’ privacy . A strong advantage of this approach is its generality : since the data collected is not encrypted or perturbed , the miner can then use the data freely for a variety of data mining algorithms . Our contributions can be summarized as follows : ffl We introduce the notion of anonymity preserving data collection . ffl We present a concrete protocol for anonymity preserving data collection under the assumption that all participants follow the protocol . Proofs are given for its correctness and anonymity property . ffl We extend our solutions to provide anonymity protection even if the miner or the miner plus some respondents are acting maliciously . ffl We provide experimental results to measure the prac tical efficiency of our solutions .
In Section 2 , we provide a formal definition of anonymity . In Section 3 , we give a basic solution in the model that the miner and all respondents follow the protocol . We also prove the correctness and anonymity properties of the protocol and present experimental results of the efficiency . In Section 4 , we describe an extended protocol to protect respondents privacy against a malicious data miner , again with experimental results of efficiency . We further extend our protocol to works against a malicious miner plus some malicious respondents in Section 5 .
2 . PRELIMINARIES
In this section , we give a specification of our data collection problem as well as a formal definition of our anonymity requirements . 2.1 The Data Collection Problem
We consider a scenario of data collection in which there is a data miner and a ( potentially large ) number of respondents . Each respondent owns a piece of data and the miner intends to mine the data so that he can find useful patterns . In our setting , the goal is to allow the miner to collect the data without being able to determine which piece of data came from whom . Specifically , let N be a small constant number , typically 20 , 50 , or 100 . We divide the respondents into groups , where each group has N members . In order to make the protocol practical , the miner collects the data from one group at a time , so that only N respondents need
335Research Track Paper to be simultaneously online.1 Our requirement is that each respondent should be \hidden" in the N respondents in her group . In other words , the miner should get N pieces of data from a group , but should not know which piece came from which group member .
In the sequel , we restrict our discussion to one group of respondents and denote the N respondents in this group by 1 , . . . , N . We assume that there is a private and authenticated communication channel between each respondent and the miner . ( Note that such communication channels can be implemented using standard protocols like SSL and IPSec We do not go into details of the implementation of channels in this paper . ) Although communication channels between respondents may exist in some practical situations , to make the problem as general as possible , we do not assume their existence in our problem . Figure 1 illustrates the resulting layered architecture of our solution . Our anonymitypreserving data collection solution runs over any private and authenticated channels between respondents and miner , and the miner can use any data mining tools thereafter .
We denote by di the piece of data owned by respondent i , whose length is bounded by a security parameter . There are two possible ways for the miner to violate respondent i ’s anonymity : either di contains some information about respondent i ( like respondent i ’s identifier , telephone number , or zip code ) and by looking at this information the miner is able to associate di with respondent i , or during the data collection process the miner observes that di comes from respondent i . As noted before , in this paper we focus on the second possibility . In particular , we assume that di does not contain information that can be used to associate it with respondent i;2 in this case , respondent i will remain anonymous as long as the data collection process preserves her anonymity .
Data Mining Tools
Anonymity Preserving Data Collection ( This paper ) Private and Authenticated Communication Channel
Database and Operating System
Figure 1 : System Components
2.2 Formal Definition of Anonymity
In this paper , we allow for the possibility that some of the respondents may be corrupted and colluding with the miner . Informally , the data collection process preserves each honest respondent ’s anonymity if , when we arbitrarily switch the data between honest respondents , the miner ( with the help of dishonest respondents ) cannot see any difference in the data collection process . Mathematically , let be an arbitrary permutation on f1 ; : : : ; N g ; then ( d(1 ) ; : : : ; d(N ) ) is the result of arbitrarily switching data between respondents . We further require that ( i ) = i for any corrupted respondent i , which means only the honest respondents’ data are switched . The anonymity requirement is that the miner can
1Even this requirement can be removed if certain members of the group ( called \leaders" in our solutions ) remain online until the data collection procedure in this group is completed . 2This can be achieved by having respondent i remove from her submitted data any information related to her identity . not distinguish the data collection procedure in which the respondents have data ( d1 ; : : : ; dN ) from the data collection procedure in which respondents have data ( d(1 ) ; : : : ; d(N ) ) .
More formally , we give the following definition of anonymity in a standard cryptographic model , the semi honest model [ 14 ] . In the semi honest model , the miner and the corrupted respondents follow the protocol but attempt to derive private information and violate the anonymity of the honest respondents .
Definition 1 . A protocol for the data collection problem preserves each honest respondent ’s anonymity against the miner and t , 1 corrupted respondents in the semi honest model if , for any I f1 ; : : : ; ng such that jIj = t , 1 , for any ( d1 ; : : : ; dN ) and any permutation on f1 ; : : : ; N g such that 8i 2 I ; ( i ) = i , fviewminer;I ( d1 ; : : : ; dN )g c fviewminer;I ( d(1 ) ; : : : ; d(N ))g : c
In the above , denotes computational indistinguishability and fviewminer;I ( d1 ; : : : ; dN )g is the joint view of the miner and the set I of t,1 corrupted respondents . ( See a standard book of cryptography , eg , [ 14 ] for the formal definitions of these concepts . ) Intuitively , Definition 1 states that the adversary ( ie , the miner and the corrupted respondents ) cannot notice any difference in his view if we arbitrarily switch data between the honest respondents . Therefore , the miner and the corrupted respondents jointly learn nothing about which piece of data corresponds to which honest respondent . Clearly , this is consistent with the intuitive understanding of anonymity .
In this paper , we not only develop a solution in the semihonest model , but also extend the solution to another standard cryptographic model , the malicious model [ 14 ] . Because defining anonymity in the malicious model is significantly more complicated and requires many details out of the scope of this paper , we do not formalize a definition of anonymity in the malicious model . Instead , we give an informal explanation of anonymity in this model as used in our setting : first , an anonymity preserving protocol in the malicious model needs to be anonymity preserving when all participants follow the protocol ; second , when any malicious participant deviates from the protocol , the honest participants must be able to detect this before the anonymity is violated , so that the honest participants can abort the protocol without their anonymity being compromised . In this way , the malicious participants are effectively \forced" to follow the protocol .
3 . THE BASIC SOLUTION
In this section , we give a solution to the problem of anonymity preserving data collection in the semi honest model . Extensions of this solution to the malicious model are presented in Sections 4 and 5 . 3.1 Overview of the solution
Our goal is that the miner should obtain a random permutation of the respondents’ data ( d1 ; : : : ; dN ) , without knowing which piece of data comes from which respondent . To achieve this goal , we use ElGamal encryption ( further described below ) together with a rerandomization technique and a joint decryption technique . Both of these techniques
336Research Track Paper have been used extensively in mix networks , eg , [ 24 , 29 , 20 , 18 ] .
Let G ( jGj = q , where q is a large prime ) be a cyclic group in which the discrete logarithm is hard3 , and let g be a generator of G . The ElGamal encryption scheme uses a key pair ( x ; y ) such that y = gx mod q , where x is a private key and y is a public key4 . In this scheme , to encrypt a message M using the public key y , one computes C = ( M yr ; gr ) , where the exponentiations are done modulo q and r is chosen uniformly at random from [ 0 ; q ,1 ] . ( Throughout the paper , all exponentiations are modulo q . ) To decrypt the ciphertext C using the private key x , one computes M = C ( 1)=(C ( 2))x , where C ( 1 ) and C ( 2 ) denote the first and the second components of C , respectively . It has been shown in [ 33 ] that ( under standard complexity theoretic assumptions , ) the ElGamal encryption scheme is secure in the sense of semantic security . ( See [ 16 ] for the definition of semantic security ) .
In the ElGamal encryption scheme , one cleartext has many possible encryptions , since the random number r can take on many different values . ElGamal supports rerandomization , which means computing a different encryption of M from a given encryption of M . A related operation is permutation of the order of items , which means randomly rearranging the order of items . If we rerandomize and permute a sequence of ciphertexts , then we get another sequence of ciphertexts with the same multiset of cleartexts but in a different order . Looking at these two sequences of ciphertexts , the adversary cannot determine any information about which new ciphertext corresponds to which old ciphertext .
In our solution , t of the N respondents act as \leaders" . Leaders have the special duty of anonymizing the data . At the beginning of the protocol , all respondents encrypt their data using a public key which is the product of all leaders’ public keys . Note that the private key corresponding to this public key is the sum of all leaders’ private keys ; without the help of all leaders , nobody can decrypt any of these encryptions . The leaders then rerandomize these encryptions and permute them . Finally , the leaders jointly help the miner to decrypt the new encryptions , which are in an order independent of the original encryptions .
For notational convenience , we assume in the sequel that the leaders are respondents 1 through t . In practice , the choice of leaders can be arbitrary or can be dependent on the application .
3.2 Respondent Keys
Each respondent i has a key pair ( xi ; yi ) ( xi 2 [ 0 ; q , 1 ] , yi 2 G ) such that yi = gxi in G . ( All computations throughout this paper take place in G ) . Here , the public key yi is known to all participants , while the private key xi is kept secret by respondent i . In the sequel , let t y = yi ; i=1
3The discrete logarithm problem is a standard computational problem used in cryptography . Many cryptographic tools are based on the assumed hardness of the discrete logarithm . 4Throughout this paper , by \key" we mean a cryptographic key rather than a database key . and t x = xi : i=1
In our protocol , we use this public value y as a public key to encrypt respondent data . Clearly , y = gx . So , decrypting these encryptions of respondent data needs this secret value x , which is not known to any individual respondent . 3.3 Protocol ffl Phase 1 : Data submission .
{ For i = 1 ; : : : ; N , each respondent i encrypts her data using public key y :
Ci def
= ( C ( 1 ) i
; C ( 2 ) i
) = ( yri di ; gri ) ; where ri is picked uniformly at random from [ 0 ; q , 1 ] . Then respondent i sends Ci to the miner . ffl Phase 2 : t round anonymization . For i = 1 ; : : : ; t , the miner and the respondents work as follows .
{ At the beginning of the ith round , the miner sends
( C1 ; : : : ; CN ) to leader i .
{ Leader i rerandomizes each piece of data and per mutes the pieces : for j = 1 ; : : : ; N ,
Rj
; R(2 ) j ) def
= ( R(1 ) = ( C ( 1 ) j i ( j ) yffii(j ) ; C ( 2 ) i ( j ) gffii(j ) ) ; where i is a random permutation on f1 ; : : : ; N g , and each ffij is picked independently and uniformly from [ 0 ; q , 1 ] .
{ For j = 1 ; : : : ; N , leader i sets Cj = Rj . Then leader i sends ( C1 ; : : : ; CN ) back to the miner . ffl Phase 3 : Decryption .
{ The miner sends ( C ( 2 )
1 ; : : : ; C ( 2 )
N ) to all leaders .
{ Each leader i computes partial decryptions : for j = 1 ; : : : ; N , pj;i = ( C ( 2 ) j
)xi :
{ Each leader i sends the miner the partial decryp tions ( p1;i ; : : : ; pN;i ) .
{ The miner computes the decryptions : for j =
1 ; : : : ; N , j = C ( 1 ) d0 j = t i=1 pj;i :
3.4 Correctness
Theorem 2 . If all participants follow the protocol , then the miner ’s result ( d0
1 ; : : : ; d0
N ) is a permutation of ( d1 ; : : : ; dN ) .
Proof . At the end of Phase 1 , the miner has received encryptions of ( d1 ; : : : ; dN ) . In Phase 2 , these ciphertexts are rerandomized and permuted ; therefore , at the end of Phase
337Research Track Paper 
  2 , ( C1 ; : : : ; CN ) represents the encryptions of a permutation of ( d1 ; : : : ; dN ) . Since j = C ( 1 ) d0 j = pj;i t i=1 t
= C ( 1 ) j =
( C ( 2 ) j
)xi i=1
= C ( 1 ) = C ( 1 ) j =(C ( 2 ) j =(C ( 2 ) j j t i=1 xi
)
)x ; the cleartexts of ( C1 ; : : : ; CN ) are ( d0 ( d0
1 ; : : : ; d0 N ) is a permutation of ( d1 ; : : : ; dN ) .
1 ; : : : ; d0
N ) . Therefore ,
3.5 Anonymity
Theorem 3 . The protocol of Section 3.3 preserves the anonymity of each honest respondent against the miner and t , 1 corrupted respondents in the semi honest model .
Proof . By contradiction . Assume that this protocol does not preserve the anonymity . Based on this protocol , we give a probabilistic polynomial time algorithm that distinguishes the ElGamal encryptions of two different cleartexts , which contradicts the well known result that ElGamal is semantically secure .
Clearly it suffices to consider the case in which all the t , 1 corrupted customers are leaders . The above assumption of not preserving anonymity means that there exist ( d1 ; : : : ; dN ) , a permutation on f1 ; : : : ; N g such that 8i 2 I ; ( i ) = i , a probabilistic polynomial algorithm D , and a polynomial f ( ) such that for infinitely many ,
Pr[D(viewminer;I ( d1 ; : : : ; dN ) ) = 1 ] , Pr[D(viewminer;I ( d(1 ) ; : : : ; d(N ) ) ) = 1 ]
>1=f ( ) :
( 3.1 )
Now we use a hybrid argument ( see [ 14] ) : since is a permutation on f1 ; : : : ; N g such that 8i 2 I ; ( i ) = i , we can decompose it to a number of simple permutations where each simple permutation only switches the order of two elements outside I ( that are not equal ) . Formally , there exist permutations 1 ; : : : ; m ( m < N , ( t , 1 ) ) on f1 ; : : : ; N g such that for j = 1 ; : : : ; m , 8i 2 I ; j ( i ) = i and that
= 1 : : : m :
Define view0 = viewminer;I ( d1 ; : : : ; dN ) ; and for j = 1 ; : : : ; m , viewj = viewminer;I ( d1:::j ( 1 ) ; : : : ; d1:::j ( N ) ) :
Then clearly , viewm = viewminer;I ( d(1 ) ; : : : ; d(N ) ) :
By Equation 3.1 , we know there exists j 2 [ 0 ; m ] such that
Pr[D(viewj ) = 1 ] , Pr[D(viewj+1 ) = 1 ] >
1 mf ( )
:
The above equation is equivalent to
Pr[D(viewminer;I ( d1:::j ( 1 ) ; : : : ; d1:::j ( N ) ) ) = 1 ] , Pr[D(viewminer;I ( d1:::j j+1(1 ) ; : : : ; d1:::j j+1 ( N ) ) ) = 1 ]
>
1 mf ( )
:
( 3.2 )
Note a subtle convention of compositions :
1 : : : j j+1(i ) = j+1(1( : : : j(i)) ) :
( If we do not use this convention , we can get the same result by a simple modification of the indices . ) Therefore , we can rewrite Equation 3.2 as
Pr[D(viewminer;I ( d‘1 ; : : : ; d‘N ) ) = 1 ] , Pr[D(viewminer;I ( dj+1(‘1 ) ; : : : ; dj+1 ( ‘N ) ) ) = 1 ]
>
1 mf ( )
;
( 3.3 ) where ‘i = 1 : : : j(i ) . Recall that j+1 only switches the order of two elements outside I that are not equal ; suppose that it switches the order of ‘ff and ‘fi ( d‘ff 6= d‘fi , ff < fi , ff ; fi 62 I ) . Formally , we have dj+1(‘ff ) = d‘fi ; dj+1(‘fi ) = d‘ff ; and that for any i 6= ff , i 6= fi , dj+1 ( ‘i ) = d‘i :
Below we give a probabilistic polynomial time algorithm A that distinguishes an ElGamal encryption of d‘ff from an ElGamal encryption of d‘fi .
On input ciphertext e , A first computes , using the homomorphic property of ElGamal , another ciphertext e0 such that the product of the cleartexts of e and e0 is equal to d‘ff d‘fi : A computes a random encryption of d‘ff d‘fi and then divides it by e . Then A rerandomizes e0 to get e00 . Next , A simulates two executions of our protocol ; A extracts the view of the adversary generated in each simulated execution and applies D to it . Specifically , during each simulated execution , A simulates the miner using a process that works exactly as described in the protocol . The simulation of other parties is detailed as follows .
In Phase 1 of the protocol , for any i except ff and fi , A simulates customer i using a process with input d‘i ; the process works exactly as described in the protocol . A simulates customers ff and fi with two processes with ciphertext inputs ; these two processes do not encrypt their inputs as described in the protocol but directly send out their inputs to the simulated miner . ( Note that this has no impact on the view of the adversary because ff ; fi 62 I ; thus , it has no impact on the output of D which we need . ) During the first simulated execution , the simulated customer ff starts with ciphertext e and the simulated customer fi starts with e00 ; during the second execution , the simulated customer ff starts with ciphertext e00 and the simulated customer fi starts with e . Now recall that t , 1 leaders are dishonest ; suppose that the only honest leader is .
In Phase 2 , the first , 1 rounds of anonymization are simulated exactly as described in the protocol . For i = ; : : : ; t , A chooses a random permutation fli on [ 1 ; : : : ; N ]
338Research Track Paper      and simulates the ciphertexts ( C1 ; : : : ; CN ) at the end of round i using random encryptions of ( dfli(‘1 ) ; : : : ; dfli(‘N ) ) . The corresponding simulated messages and coin flips can be easily computed from these simulated ciphertexts .
In Phase 3 , the simulated messages and coin flips can be easily computed from the simulated ciphertexts ( C1 ; : : : ; CN ) at the end of round t in Phase 2 together with their decryptions ( dflt ( ‘1 ) ; : : : ; dflt(‘N ) ) .
Applying D to the views of the adversary generated in the simulated executions , A can compute o1 =D(viewminer;I ( d‘1 ; : : : ; d‘ff,1 ; D(e ) ; d‘ff+1 ; : : : ; d‘fi,1 ; D(e00 ) ; d‘fi+1 ; : : : ; d‘N ) ) ; and o2 =D(viewminer;I ( d‘1 ; : : : ; d‘ff,1 ; D(e00 ) ; d‘ff+1 ; : : : ; d‘fi,1 ; D(e ) ; d‘fi+1 ; : : : ; d‘N ) ) ; where D(e ) denotes the decryption of e . If o1 = 1 and o2 = 0 , A outputs 1 ; if o1 = 0 and o2 = 1 , A outputs 0 ; otherwise A outputs a uniformly random bit .
Now we analyze the probabilities of outputing 1 with in put ciphertext of d‘ff or d‘fi . For convenience , let p1 = P r[D(viewminer;I ( d‘1 ; : : : ; d‘N ) ) = 1 ] ; and p2 = Pr[D(viewminer;I ( dj+1(‘1 ) ; : : : ; dj+1(‘N ) ) ) = 1 ] :
When the input ciphertext is an encryption of d‘ff , the probability that we have output equals 1 is
Pr[A(d‘ff ) = 1 ] = p1(1 , p2 ) + p1p2=2 + ( 1 , p1)(1 , p2)=2 :
When the input ciphertext is an encryption of d‘fi , the probability that we have output equals 1 is
Pr[A(d‘fi ) = 1 ] = p2(1 , p1 ) + p2p1=2 + ( 1 , p2)(1 , p1)=2 :
Combining the above two equations , we have
Pr[A(d‘ff ) = 1 ] , Pr[A(d‘fi ) = 1 ]
= p1(1 , p2 ) + p1p2=2 + ( 1 , p1)(1 , p2)=2
,(p2(1 , p1 ) + p2p1=2 + ( 1 , p2)(1 , p1)=2 )
= p1 , p2
>
1 mf ( )
:
The last inequality is due to Equation 33 However , this contradicts the semantic security of ElGamal .
3.6 Efficiency Analysis and Measurements
In our protocol , the computational overhead of a nonleader respondent is 2 modular exponentiations . The major computational overhead of a leader is 3N + 2 modular exponentiations . The major computational overhead of the miner is N t modular multiplications and N modular divisions . The overall communication is at most ( 6t + 2)N bits .
To measure the efficiency of our protocol in practice , we implemented it using the OpenSSL libraries5 and measured the computational overhead . Since the time spent on communication highly depends on the network bandwidth , we
5Available at http://wwwopensslorg
Regular Respondent ’s Computation Time
) s m
( e m T i
. p m o C
20
18
16
14
12
10 100
80
60
40 Num . of Respondents
20
5
20
15
10 Num . of Leaders
Figure 2 : Regular respondent ’s computation time with semi honest participants
Leader ’s Computation Time
) s c e S ( e m T i
. p m o C
2.5
2
1.5
1
0.5
0 100
80
60
40 Num . of Respondents
20
5
20
15
10 Num . of Leaders
Figure 3 : Leader ’s computation time with semihonest participants
Miner ’s Computation Time
) s m
( e m T i
. p m o C
250
200
150
100
50
0 100
80
60
40 Num . of Respondents
20
5
20
15
10 Num . of Leaders
Figure 4 : Miner ’s computation time with semihonest participants
339Research Track Paper did not measure the communication overhead in our experiments . In our experiments , the length of cryptographic keys is 1024 bits . The environment used is the NetBSD operating system running on an AMD Athlon 2GHz processor with 512M memory .
We measure the computation times of the three types of participants : regular ( ie , non leader ) respondents , leaders , and the miner . For each of these times , we measure how it varies with different N and t . All our experimental results are consistent with our theoretical analysis .
Figure 2 illustrates our measurements of a regular respondent ’s computation time : it is always about 15ms regardless of N and t . Figure 3 illustrates our measurements of a leader ’s computation time : it is linear in N and does not depend on t . For a typical scenario where N = 20 , the computation time of a leader is about 0:47 seconds . Figure 4 illustrates our measurements of the miner ’s computation time : it is linear in both N and t . For a typical scenario where N = 20 and t = 3 , the computation time of the miner is about 40ms .
4 . MALICIOUS MINER
In this section , we extend our solution to a model in which the miner is malicious and the corrupted respondents are still semi honest . In Section 5 , we study the case in which the corrupted respondents may behave maliciously .
Recall that a malicious participant can deviate from the protocol arbitrarily . It is more difficult to preserve anonymity when the miner is malicious . For example , the miner may choose two respondents i and j and replace the encryption of dj with the encryption of di . When the protocol finishes , there will be a piece of data with two copies . The miner can then easily link this piece of data to respondent i . To disallow such behavior and force the miner to follow the protocol , we use a well known cryptographic tool , digital signatures , as we now describe . 4.1 Digital Signatures
A digital signature scheme allows each participant to generate a signature on her message using her private key . Anybody can verify this signature using her public key , but it is infeasible for any other party to forge her signature . Formally , we denote by s = Sx(M ) a signature on message M using private key x . We denote by Vy(M ; s ) the verification function of digital signature using public key y . Thus , for any key pair ( x ; y ) and any message M we have described in Section 32 This new key pair is used for digital signatures . ffl Phase 1 : Data submission .
{ For i = 1 ; : : : ; N , each respondent i encrypts her data using public key y :
Ci def
= ( C ( 1 ) i
; C ( 2 ) i
) = ( yri di ; gri ) ; where ri is picked uniformly at random from [ 0 ; q , 1 ] . Respondent i signs Ci using private key x0 i : si = Sx0 i
( Ci ) :
Then respondent i sends ( Ci ; si ) to the miner . ffl Phase 2 : t round anonymization . For i = 1 ; : : : ; t , the miner and the respondents work as follows .
{ At the beginning of the ith round , the miner sends
( (C1 ; s1 ) : : : ; ( CN ; sN ) ) to leader i .
{ Leader i checks that she has received N signed messages ; if not , she aborts the protocol . Then leader i verifies the signatures : if i = 1 , for j = 1 ; : : : ; N , she verifies that
Vy0 j
( Cj ; sj ) = accept ; otherwise , for j = 1 ; : : : ; N , she verifies that
Vy0 i,1
( Cj ; sj ) = accept ;
If any of the above equations does not hold , leader i aborts the protocol .
{ Leader i rerandomizes each piece of data and per mutes the pieces : for j = 1 ; : : : ; N ,
Rj
; R(2 ) j ) def
= ( R(1 ) = ( C ( 1 ) j i ( j ) yffii(j ) ; C ( 2 ) i ( j ) gffii(j ) ) ; where i is a random permutation on f1 ; : : : ; N g , and each ffij is picked independently and uniformly from [ 0 ; q , 1 ] .
{ For j = 1 ; : : : ; N , leader i sets Cj = Rj and signs
Cj using private key x0 i : sj = Sx0 i
( Cj ) :
Then leader i sends ( (C1 ; s1 ) ; : : : ; ( CN ; sN ) ) back to the miner .
Vy(M ; Sx(M ) ) = accept : ffl Phase 3 : Decryption .
Furthermore , without knowing x it is infeasible to forge a digital signature s such that Vy(M ; s ) = accept .
Note that in our solution in the semi honest model , each message sent from the miner to any respondent originally came from a respondent|the miner only forwards the message . Therefore , if the original sender of the message signs it and the receiver of the message verifies the signature , then a cheating miner who deviates from the protocol can be detected . 4.2 Protocol with malicious miner
This protocol assumes that each respondent i has another i is a private key i is a public key ) , in addition to the key pair ( xi ; yi ) key pair ( x0 and y 0 i ) such that y 0 i ( where x0 i = gx0 i ; y 0
{ The miner sends ( (C1 ; s1 ) ; : : : ; ( CN ; sN ) ) to all leaders .
{ Each leader checks that she has received N signed messages ; if not , she aborts the protocol . Then she verifies the signatures : for j = 1 ; : : : ; N , she verifies that
Vy0 t
( Cj ; sj ) = accept :
If any of the above equations does not hold , the leader aborts the protocol .
{ Each leader i computes partial decryptions : for j = 1 ; : : : ; N , pj;i = ( C ( 2 ) j
)xi :
340Research Track Paper { Each leader i sends the miner the partial decryp tions ( p1;i ; : : : ; pN;i ) .
{ The miner computes the decryptions : for j = of a leader is about 0:52s , which has a 10 % increase over the corresponding overhead of the protocol in the semi honest model . Figure 7 illustrates our measurements of the miner ’s
1 ; : : : ; N , j = C ( 1 ) d0 j = t i=1 pj;i :
4.3 Correctness and Anonymity
The only difference between this protocol and the protocol in the semi honest model is that her , messages are signed and signatures are verified . Consequently , when all parties follow the protocol , the miner finally obtains a permutation of ( d1 ; : : : ; dN ) .
This protocol preserves the anonymity of each honest respondent against a malicious miner , because if the miner drops or tampers with any message to any respondent , the respondent will detect it ( by checking the number of messages and verifying the signatures ) . 4.4 Efficiency Analysis and Measurements
In this protocol , the computational overhead of a nonleader respondent is 2 modular exponentiations and 1 signing operation . The major computational overhead of a leader is 3N +2 modular exponentiations , N +1 signing operations and 2N + 1 verification operations . The major computational overhead of the miner is N t modular multiplications and N modular division . The overall communications are at most ( 6t + 2)N + ( 4t + 1)0N bits , where 0 is the length of a digital signature , typically 512 or 1024 bits .
We also implemented this protocol and measured the computation times in the environment described in Section 36 The digital signature scheme we use is DSA and the length of each signature is 512 bits .
Figure 5 illustrates our measurements of a regular respondent ’s computation time : it is always about 16ms regardless of the values of N and t . Compared with 15ms for the protocol in the semi honest model , the increase in computational overhead is minimal .
Regular Respondent ’s Computation Time
) s m
( e m T i
. p m o C
20
18
16
14
12
10 100
80
60
40 Num . of Respondents
20
5
20
15
10 Num . of Leaders
Figure 5 : Regular respondent ’s computation time with malicious miner
Figure 6 illustrates our measurements of a leader ’s computation time : it is linear in N and does not depend on t . For a typical scenario where N = 20 , the computation time
Leader ’s Computation Time
) s c e S ( e m T i
. p m o C
1.5
1
0.5
0 100
80
60
40 Num . of Respondents
20
5
20
15
10 Num . of Leaders
Figure 6 : Leader ’s computation time with malicious miner
Miner ’s Computation Time
) s m
( e m T i
. p m o C
250
200
150
100
50
0 100
80
60
40 Num . of Respondents
20
5
20
15
10 Num . of Leaders
Figure 7 : Miner computation time with malicious miner computation time : it is linear in both N and t . For a typical scenario where N = 20 and t = 3 , the computation time of the miner is about 30ms . For the miner , this protocol against a malicious miner adds no additional computational overhead over the protocol against a semi honest miner .
5 . MALICIOUS MINER & RESPONDENTS In this section , we consider the case in which some corrupted respondents may also deviate from the protocol . Using the cryptographic tool of zero knowledge proofs , we further extend our solution to work against t , 1 malicious correspondents in addition to the malicious miner . Before presenting the protocol , we first introduce several types of zero knowledge proofs it uses . 5.1 Zero knowledge Proofs
Zero knowledge proofs ( ZKP ) are a standard cryptographic tool by which a participant can convince other participants of various statements without leaking any secret information . In this paper , we use three types of ZKP , all of
341Research Track Paper  which can be carried out noninteractively ( ie , with only a single message flow ) : ffl PoK(C ) , where C is an ElGamal ciphertext . A participant can use this to prove that she knows the cleartext of C . ffl PoR((C1 ; : : : ; CN ) ; ( C 0
N ) ) , where each Ci and each C 0 i are ElGamal ciphertexts . A participant can use this to prove that ( C 0 N ) is a permuted rerandomization of ( C1 ; : : : ; CN ) , ie , that ( C 0 N ) has the same multiset of cleartext messages as ( C1 ; : : : ; CN ) .
1 ; : : : ; C 0
1 ; : : : ; C 0
1 ; : : : ; C 0 ffl PoD(p ; C ( 2 ) ; y ) , where C ( 2 ) is the second component of an ElGamal ciphertext and y is a public key . A participant can use this to prove that p is a partial decryption computed by raising C ( 2 ) to the private key corresponding to the public key y . Formally , this means p = ( C ( 2))x , where x = log y .
Methods to carry out these proofs can be found in , eg , [ 18 ] . 5.2 Protocol
This protocol extends the protocol in the semi honest model by adding a number of ZKPs . In the data submission phase , each respondent i computes a proof , zi = PoK(Ci ) , proving she knows the cleartext of Ci . Along with Ci , respondent i sends zi to the miner . The miner forwards ( Ci ; zi ) to all other respondents . Each respondent verifies the proofs sent by the other N , 1 respondents . If any proof is missing or invalid , the respondent aborts the protocol .
In the t round anonymization phase , during round i , leader i generates a proof wi = PoR((C1 ; : : : ; CN ) ; ( R1 ; : : : ; RN ) ) ; which means the new ciphertexts ( R1 ; ; RN ) are a permuted rerandomization of the old ciphertexts ( C1 ; ; CN ) . When leader i sends the new ciphertexts to the miner , she also sends wi . The miner forwards them to all other respondents , who verify the proof . If the proof is missing or invalid , then the respondents abort the protocol .
In the decryption phase , each leader i computes a proof vi = PoD(pj;i ; C ( 2 ) j
; yi ) ; j which means pj;i is a partial decryption computed by raising C ( 2 ) to the private key corresponding to the public key yi . Each leader i sends the proof vi along with the partial decryption to the miner , and the miner then forward vi with partial decryptions to all other respondents . Each respondent verifies the proofs . If any proof is missing or invalid , the protocol is aborted .
In summary , we use ZKP to force the miner and the malicious respondents to follow the protocol . If they do not follow the protocol , their malicious behavior will be detected and the protocol will be aborted .
6 . CONCLUSION
In this paper , we propose anonymity preserving data collection , a new approach to protect privacy in data mining . This approach allows a data miner to collect data from a potentially large number of respondents but prevents the miner from finding out which respondent has submitted which piece of data . We present three protocols with provable anonymity guarantees , one in the semi honest model , one that can tolerate a malicious miner , and one that can tolerate some malicious respondents in addition to a malicious miner . As confirmed by our experiments , the protocols are very efficient .
Our current implementation of the protocols focuses on efficiency measurements , but does not address user interface or architectural issues . In practice , we suggest that the respondent side be implemented as a browser plug in or a plug in feature of a web service . Acknowledgments We thank the anonymous referees for their helpful comments .
7 . REFERENCES [ 1 ] D . Agrawal and C . Aggarwal . On the design and quantification of privacy preserving data mining algorithms . In Proc . 20th ACM SIGMOD SIGACT SIGART Symposium on Principles of Database Systems , pages 247 255 , 2001 .
[ 2 ] R . Agrawal and R . Srikant . Privacy preserving data mining . In Proc . ACM SIGMOD Conference on Management of Data , pages 439 450 . ACM Press , May 2000 .
[ 3 ] D . Chaum . Untraceable electronic mail , return address and digital pseudonyms . Comm . ACM , 24(2):84 88 , 1981 .
[ 4 ] D . Chaum . The dining cryptographers problem : unconditional sender and recipient untraceability . J . Cryptology , 1(1):65 75 , 1988 .
[ 5 ] C . Clifton and D . Marks . Security and privacy implications of data mining . In Proc . ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery , pages 15 19 , May 1996 .
[ 6 ] L . Cranor , editor . Comm . ACM 42(2 ) , Special Issue on
Internet Privacy , 1999 .
[ 7 ] T . Dalenius . Finding a needle in a haystack or identifying anonymous census records . J . Official Statistics , 2(3):329 336 , 1986 .
[ 8 ] I . Dinur and K . Nissim . Revealing information while preserving privacy . In Proc . 22nd ACM SIGMOD SIGACT SIGART Symposium on Principles of Database Systems , pages 202 210 . ACM Press , 2003 .
[ 9 ] W . Du and Z . Zhan . Using randomized response techniques for privacy preserving data mining . In Proc . of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 505 510 . ACM Press , 2003 .
[ 10 ] C . Dwork and K . Nissim . Privacy preserving datamining on vertically partitioned databases . In Advances in Cryptology Proceedings of CRYPTO 2003 , volume 3152 of Lecture Notes in Computer Science , Santa Barbara , California , August 2004 .
[ 11 ] A . Evfimievski , J . Gehrke , and R . Srikant . Limiting privacy breaches in privacy preserving data mining . In Proc . 22nd ACM SIGMOD SIGACT SIGART Symposium on Principles of Database Systems , pages 211 222 . ACM Press , 2003 .
[ 12 ] A . Evfimievski , R . Srikant , R . Agrawal , and J .
Gehrke . Privacy preserving mining of association rules . In Proc . of the Eighth ACM SIGKDD International
342Research Track Paper Conference on Knowledge Discovery and Data Mining , pages 217 228 . ACM Press , 2002 .
[ 13 ] B . Gilburd , A . Schuster , and R . Wolff . k TTP : a new privacy model for large scale distributed environments . In Proc . of the 2004 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 563 568 . ACM Press , 2004 .
[ 14 ] O . Goldreich . Foundations of Cryptography , volume 1 .
Cambridge University Press , 2001 .
[ 15 ] O . Goldreich , S . Micali , and A . Wigderson . How to play any mental game . In Proc . of the 19th Annual ACM Conference on Theory of Computing , pages 218 229 . ACM Press , 1987 .
[ 16 ] S . Goldwasser and S . Micali . Probabilistic encryption .
J . Computer and System Sciences , 28:270 299 , 1984 .
[ 17 ] P . Golle and A . Juels . Dining cryptographers revisited . In Advances in Cryptology EUROCRYPT 2004 , volume 3027 of Lecture Notes in Computer Science , pages 456 473 , 2004 .
[ 18 ] P . Golle , S . Zhong , D . Boneh , M . Jakobsson , and A .
Juels . Optimistic mixing for exit polls . In Advances in Cryptology ASIACRYPT 2002 , volume 2501 of Lecture Notes in Computer Science , pages 451 465 . Springer Verlag , 2002 .
[ 19 ] HIPAA . The health insurance portability and accountability act of 1996 , October 1998 . Available at wwwcmshhsgov/hipaa
[ 20 ] Markus Jakobsson . Flash mixing . In Proceedings of the
Eighteenth Annual ACM Symposium on Principles of Distributed Computing , pages 83 89 . ACM , 1999 .
[ 21 ] H . Kargupta , S . Datta , Q . Wang , and K . Sivakumar . On the privacy preserving properties of random data perturbation techniques . In The Third IEEE International Conference on Data Mining , 2003 .
[ 22 ] B . N . Levine and C . Shields . Hordes a multicast based protocol for anonymity . J . Computer Security , 10(3):213 240 , 2002 .
[ 23 ] Y . Lindell and B . Pinkas . Privacy preserving data mining . J . Cryptology , 15(3):177 206 , 2002 .
[ 24 ] C . Park , K . Itoh , and K . Kurosawa . Efficient anonymous channel and all/nothing election scheme . In Advances in Cryptology Proceedings of EUROCRYPT 93 , volume 765 of LNCS , pages 248 259 . Springer Verlag , 1993 .
[ 25 ] European Parliament . Directive 95/46/EC of the
European Parliament and of the Council of 24 October 1995 on the protection of individuals with regard to the processing of personal data and on the free movement of such data . Official J . European Communities , page 31 , 1995 .
[ 26 ] European Parliament . Directive 97/66/EC of the
European Parliament and of the Council of 15 December 1997 concerning the processing of personal data and the protection of privacy in the telecommunications sector . Official J . European Communities , pages 1 8 , 1998 .
[ 27 ] Michael K . Reiter and Aviel D . Rubin . Crowds :
Anonymity for web transactions . ACM Transactions on Information and System Security , 1(1):66 92 , 1998 .
[ 28 ] S . Rizvi and J . Haritsa . Maintaining data privacy in association rule mining . In Proc . of the 28th VLDB Conference , 2002 .
[ 29 ] K . Sako and J . Kilian . Receipt free Mix type voting schemes | a practical solution to the implementation of a voting booth . In Advances in Cryptology Proceedings of EUROCRYPT 95 , volume 921 of Lecture Notes in Computer Science , pages 393 403 . Springer Verlag , 1995 .
[ 30 ] P . Samarati and L . Sweeney . Generalizing data to provide anonymity when disclosing information ( abstract ) . In Proc . of the 17th ACM SIGACT SIGMOD SIGART Symposium on Principles of Database Systems , page 188 . ACM Press , 1998 .
[ 31 ] L . Sweeney . Achieving k anonymity privacy protection using generalization and suppression . Int . J . Uncertain . Fuzziness Knowl. Based Syst . , 10(5):571 588 , 2002 .
[ 32 ] L . Sweeney . k anonymity : a model for protecting privacy . Int . J . Uncertain . Fuzziness Knowl. Based Syst . , 10(5):557 570 , 2002 .
[ 33 ] Y . Tsiounis and M . Yung . On the security of
ElGamal based encryption . In Public Key Cryptography’98 , volume 1431 of Lecture Notes in Computer Science , pages 117 134 , 1998 .
[ 34 ] J . Vaidya and C . Clifton . Privacy preserving k means clustering over vertically partitioned data . In Proc . of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 206 215 . ACM Press , 2003 .
[ 35 ] Luis von Ahn , Andrew Bortz , and Nicholas J . Hopper . k anonymous message transmission . In Proc . 2003 ACM Conference on Computer and Communications Security , pages 122 130 , Washington , DC , 2003 .
[ 36 ] Michael Waidner . Unconditional sender and recipient untraceability in spite of active attacks . In EUROCRYPT ’89 , pages 302 319 , 1989 .
[ 37 ] S . L . Warner . Randomized response : A survey technique for eliminating evasive answer bias . J . Amer . Stat . , 60(309):63 69 , 1965 .
[ 38 ] R . N . Wright and Z . Yang . Privacy preserving
Bayesian network structure computation on distributed heterogeneous data . In Proc . of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 713 718 . ACM Press , 2004 .
[ 39 ] Z . Yang , S . Zhong , and R . N . Wright .
Privacy preserving classification of customer data without loss of accuracy . In Proc . of the 2005 SIAM International Conference on Data Mining ( SDM ) , Newport Beach , California , April 2005 .
[ 40 ] A . Yao . How to generate and exchange secrets . In
Proc . of the 27th IEEE Symposium on Foundations of Computer Science , pages 162 167 , 1986 .
343Research Track Paper
