A Hit Miss Model for Duplicate Detection in the WHO Drug Safety Database
G . Niklas Norén
WHO Collaborating Centre for International Drug Monitoring
Uppsala , Sweden
Mathematical Statistics Stockholm University Stockholm , Sweden
Roland Orre
NeuroLogic Sweden AB
Stockholm , Sweden rolandorre@neurologicse
Andrew Bate
WHO Collaborating Centre for International Drug Monitoring
Uppsala , Sweden andrew.bate
@who umc.org niklas.noren
@who umc.org
ABSTRACT The WHO Collaborating Centre for International Drug Monitoring in Uppsala , Sweden , maintains and analyses the world ’s largest database of reports on suspected adverse drug reaction incidents that occur after drugs are introduced on the market . As in other post marketing drug safety data sets , the presence of duplicate records is an important data quality problem and the detection of duplicates in the WHO drug safety database remains a formidable challenge , especially since the reports are anonymised before submitted to the database . However , to our knowledge no work has been published on methods for duplicate detection in postmarketing drug safety data . In this paper , we propose a method for probabilistic duplicate detection based on the hit miss model for statistical record linkage described by Copas & Hilton . We present two new generalisations of the standard hit miss model : a hit miss mixture model for errors in numerical record fields and a new method to handle correlated record fields . We demonstrate the effectiveness of the hit miss model for duplicate detection in the WHO drug safety database both at identifying the most likely duplicate for a given record ( 94.7 % accuracy ) and at discriminating duplicates from random matches ( 63 % recall with 71 % precision ) . The proposed method allows for more efficient data cleaning in post marketing drug safety data sets , and perhaps other applications throughout the KDD community .
Categories and Subject Descriptors G.3 [ Probability and Statistics ] : Statistical computing ; H2m [ Database Management ] : Miscellaneous ; J.3 [ Life and medical sciences ] : Health
Copyright ACM , 2005 . This is the author ’s version of the work . It is posted here by permission of ACM for your personal use . Not for redistribution . The definitive version was published in Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ( 2005 ) http://doiacmorg/101145/10818701081923
General Terms Algorithms
Keywords Duplicate detection , hit miss model , mixture models
1 .
INTRODUCTION
The WHO Collaborating Centre for International Drug Monitoring in Uppsala , Sweden ( also known as the Uppsala Monitoring Centre ) holds the world ’s largest database of spontaneous reports on suspected adverse drug reaction ( ADR ) incidents . Spontaneous reports are provided to pharmaceutical companies and regulatory bodies by health professionals upon the observation of suspected ADR incidents in clinical practice . The 75 member countries of the WHO Programme for International Drug Monitoring routinely forward ADR case reports submitted to their medical products agencies to the Uppsala Monitoring Centre . The first case reports in the WHO drug safety database date back to 1967 and as of January 2005 there are over 3 million reports in total in the data set ; currently around 200,000 new reports are added to the database each year .
While the analysis of spontaneous reporting data is one of the most important methods for discovering previously unknown safety problems after drugs are introduced on the market [ 16 ] , it is sometimes impaired by poor data quality [ 11 ] , and in particular the presence of duplicate case reports . Quantitative methods are important in screening spontaneous reporting data for new drug safety problems [ 1 ] , and may highlight potential problems based on as few as 3 case reports on a particular event , so the presence of just 1 or 2 duplicates may severely affect their efficacy . While there is a general consensus that the presence of duplicates is a major problem in spontaneous reporting data , there is a lack of published research with respect to the extent of the problem . A study on vaccine ADR data quoted proportions of around 5 % confirmed duplicates [ 14 ] . However , at times the frequency may be much higher : in a recent review of suspected quinine induced thrombocytopenia , FDA researchers identified 28 of the 141 US case reports ( 20 % ) as duplicates [ 6 ] .
There are at least two common causes for duplication in post marketing drug safety data : different sources ( health professionals , national authorities , different companies ) may provide separate case reports related to the same event and there may be mistakes in linking follow up case reports to earlier records . ( Follow up reports are submitted for example when the outcome of an event is discovered . ) The risk of duplication is likely to have increased in recent years due to the advent of information technology that allows case reports to be sent back and forth more easily between different organisations [ 8 ] , and the transfer of case reports from national centres to the WHO might introduce extra sources of error , including the risk that more than one national centre provide case reports related to the same event .
Duplicate records are typically much more similar than random pairs of records . There are however important exceptions . For example , separate case reports are sometimes provided for the same patient recorded at the same doctor ’s appointment when the patient has suffered from unrelated ADRs . Such record pairs may match perfectly on date , age , gender , country and drug substances , but should not be considered as duplicates . The opposite problem is illustrated by so called mother child reports that relate to ADR incidents in small children from medication taken by the mother during pregnancy . Such record pairs differ greatly depending on whether the patient information relates to the mother or the child .
The need for algorithms to systematically screen for duplicate records in drug safety data sets is clear [ 5 ] . There are no published papers in this area , but general duplicate detection methods are available [ 3 , 10 , 12 , 17 ] . In addition , the fundamentally similar problem of record linkage ( matching records across data sets ) has been studied since the 1960s [ 9 , 13 ] . We have chosen to develop a duplicate detection method based on the hit miss model for statistical record linkage described by Copas & Hilton [ 7 ] . The hitmiss model has several important beneficial properties . It imposes no strict criteria that a pair of records must fulfil in order to be highlighted as suspected duplicates , which is useful for spontaneous reporting data where errors occur in all record fields . Rather than just classifying record pairs as likely duplicates or not , the hit miss model provides a prioritisation ( scoring ) with respect to the chance that a given pair of records are duplicates . This allows the number of record pairs highlighted to be adjusted depending on the resources available for manual review . While the hit miss model punishes discrepancies it rewards matching information , which ensures that identical record pairs with very little data listed are unlikely to be highlighted for follow up at the expense of more detailed record pairs with slight differences . Furthermore , the reward for matching information varies depending on how common the matching event is , so that for example a match on a rare adverse event is considered stronger evidence than a match on gender . The fact that most of the hit miss model parameters are determined by the properties of the entire data set reduces the risk of over fitting the algorithms to training data , which is very important for the WHO database , where the amount of labelled training data is limited .
The aim of this paper is to propose two new improvements to the standard hit miss model ( a model for errors in numerical record fields and a computationally efficient approach to handling correlated record fields ) and to show
10
Sjj
8
6
4
2
0
0 a=0 , b=0 a=0.2 , b=0.2 a=0.5 , b=0.2 a=0.2 , b=0.5 a=0.5 , b=0.5
0.2
0.4
0.6
0.8
1 j
Figure 1 : Wjj(fij ) based on ( 8 ) , for several values of a and b that the adapted hit miss model is very useful in real world duplicate detection . We fit the hit miss model to the WHO drug safety database , and evaluate its performance on a test set of real world database records that includes a certain proportion of known duplicates .
2 . METHODS
2.1 The hit miss model
211 The standard hit miss model
The hit miss model is a probability model for how discrepancies between database records that relate to the same underlying event occur . Let X = j and Y = k denote the observed values on two database records for a certain record field and let pj and pk denote the corresponding probabilities . The joint probability for this pair of values under the independence assumption is pj pk . The hit miss model provides an estimate pjk for the same probability under the assumption that the two records are duplicates . The contribution from each record field ( its weight ) to the total match score is equal to the log likelihood ratio for the two hypotheses ( high values correspond to likely duplicates ) :
Wjk = log2 pjk pj pk
( 1 ) and the total match score is found by adding together the weights for all different record fields .
Under the hit miss model , each observed record field value X is based on a true but unobserved event T . Observed values are assumed to be either misses , blanks or hits . Misses occur with probability a , blanks with probability b and hits with probability 1 , a , b . For a miss X is a random variable following the overall incidence of T , for a blank the value of X is missing and for a hit X = T .
Let P ( T = i ) = fii and let P ( X = j j T = i ) = ffji . The following holds generally under the assumption that X and Y are independent conditional on T : pjk = X i ffjiffkifii
( 2 ) b Outcomes
Probability
Distribution
H,H H,D D,D H,M M,M D,M
( 1 , a1 , a2 , b)2 2a1(1 , a1 , a2 , b ) a2 1
2a2(1 , a1 , a2 , b ) a2 2
2a1a2 ffi(d )
( cid:30)(d ; 0 ; 2 1 ) ( cid:30)(d ; 0 ; 22 1 ) f ( d ) f ( d ) approx f ( d )
1 . Make initial guesses for the parameters ^a1 , ^a2 and
^2 1
2 . Expectation step : Calculate ^ff1 ; : : : ; ^ff4 :
^ff1 = ( 1 , ^a1 , ^a2 , ^b)2 ^ff2 = ^a2(2 , 2^b , ^a2 ) ^ff3 = 2^a1(1 , ^a1 , ^a2 , ^b ) ^ff4 = ^a2 1
Table 1 : Outcomes of interest ( H=hit , D=deviation , M=miss ) in the hit miss mixture model , together with associated probabilities and distributions for d .
Under the hit miss model : ffji = 8< : afij
1 , b , a(1 , fij ) b j 6= i j = i j blank and it can be shown that if c = a(2 , a , 2b ) : pjk =
8>>< >> :
Based on ( 4 ) : cfij fik fij f(1 , b)2 , c(1 , fij )g b(1 , b)fik b2 j 6= k j = k j blank j ; k blank
P ( X = j ) = ( 1 , b ) fij
P ( X blank ) = b
P ( discordant pair ) = c ( 1 , X i fi2 i )
( 3 )
( 4 )
( 5 ) ( 6 )
( 7 )
Thus , for a given record field , we estimate b by its relative frequency of blanks in the entire database and fii by its relative frequency of value i among non blanks in the entire database . c is estimated by the relative frequency of discordant pairs for this record field among non blanks in the set of identified duplicate pairs , divided by 1 , Pi fi2 i . Wjk = 8< : log2f1 , c(1 , fij )(1 , b),2g , log2 fij log2 c , 2 log2(1 , b )
( 3 ) , ( 4 ) and ( 5 ) give : j 6= k j = k
0 j or k blank
( 8 )
Thus , all mismatches for a given record field receive the same weight and blanks receive weight 0 . It can be shown that matches on rare events receive greater weights than matches on more common events ( Wjj decreases when fij increases ) as would intuitively be expected . The detailed behaviour of Wjj as a function of fij is illustrated in Figure 1 for different values of a and b .
212 A hit miss mixture model for errors in numeri cal record fields
For numerical record fields such as date and age , many types of error are more likely to yield small differences between true and observed values . If , for example , two different sources send separate case reports related to the same incident , the dates may perhaps disagree , but it is more likely that they should differ by a few days than by several years . Similarly , the registered age for patient sometimes differs from the true value , but then a small difference is more likely than a large one . At the same time , there may
For each observed di in training data , compute the probability that it belongs to each mixture component ^fl1(di ) =
^ff1ffi(di )
^ff1ffi(di )+ ^ff2f ( di)+ ^ff3 ( cid:30)(di;0;^2
1 )+ ^ff4(cid:30)(di;0;2^2 1 )
^fl2(di ) =
^fl3(di ) =
^fl4(di ) =
^ff2f ( di )
1 )+ ^ff4(cid:30)(di;0;2^2 1 )
^ff1ffi(di )+ ^ff2f ( di)+ ^ff3 ( cid:30)(di;0;^2 ^ff3(cid:30)(di;0;^2 1 ) ^ff1ffi(di )+ ^ff2f ( di)+ ^ff3 ( cid:30)(di;0;^2 1 )+ ^ff4(cid:30)(di;0;2^2 1 ) ^ff4 ( cid:30)(di;0;2^2 1 ) 1 )+ ^ff4(cid:30)(di;0;2^2 ^ff1ffi(di )+ ^ff2f ( di)+ ^ff3 ( cid:30)(di;0;^2 1 )
3 . Maximisation step : Calculate the weighted vari ance ^2 1 :
1 = Pn ^2 i=1 ^fl3(di ) d2 i +^fl4(di ) d2 i =2
Pn i=1 ^fl3 ( di)+^fl4 ( di )
Update ^a1 and ^a2 by numerical maximisation of the total likelihood for the observed data over eligible value pairs ( such that ^a1 + ^a2 + ^b < 1 ) .
4 .
Iterate 2 3 until convergence
Table 2 : EM algorithm for the hit miss mixture model . be other types of errors ( eg typing errors ) where a large numerical difference is as likely as a small one . In order to handle both possibilities , we propose a hit miss mixture model which includes a new type of miss for which small deviations from the true value are more likely than large ones . To distinguish between the two types of misses in this model , we refer to the first type as ’misses’ and the second type as ’deviations’ . If T is the true , but unobserved value , then X is a random variable assumed to have been generated through a process that results in a deviation with probability a1 , a miss with probability a2 , a blank with probability b and a hit with probability 1 , a1 , a2 , b . For a deviation , X follows a N ( T ; 2 1 ) distribution and for a miss , X is a random variable independent of T but with the same distribution . For a blank , the value of X is missing and for a hit , X = T .
For two observed numerical values X = i and Y = j , we focus on the difference d = j , i . For duplicates we must distinguish between 6 possible outcomes for the hitmiss mixture model as listed in Table 1 where ( cid:30)(d ; ; 2 ) denotes a normal distribution with mean and variance 2 and ffi(d ) denotes Dirac ’s delta function , which has all its probability mass centred at 0 . f ( d ) denotes the probability density function for the difference between two independent random events that follow the same distribution as T , such as for example a hit and a miss . Under the assumption that var(T ) * 2 1 , the difference between a miss and a deviation approximately follows this distribution .
Thus , the hit miss mixture model for the difference d between the numerical values for two duplicates can be reduced to four components : pd(d ) = ( 1 , a1 , a2 , b)2 ffi(d ) + a2(2 , a2 , 2b ) f ( d)+ 1 ( cid:30)(d ; 0 ; 22 1 ) ( 9 )
+ 2a1(1 , a1 , a2 , b ) ( cid:30)(d ; 0 ; 2
1 ) + a2
For unrelated records , d follows the more simple distribu tion :
However , the amount of data required to reliably estimate P ( jm j j1 ; : : : ; jm,1 ) increases rapidly with m . As a compromise we propose the following approximation that accounts for pairwise associations only :
P ( j1 ; : : : ; jm ) = P ( j1 ) m
Y t=2 max s<t
P ( jt j js )
( 14 ) pu(d ) = ( 1 , b)2 f ( d )
( 10 )
For correlated record fields , ( 14 ) may be used instead of ( 11 ) to model the joint distribution . Let : and we can calculate log likelihood ratio based weights W ( d ) by integrating ( 9 ) and ( 10 ) over an interval corresponding to the precision of d ( for two observed ages , for example , over d1 years ) and taking the logarithm of the ratio of integrals . As in the standard hit miss model , single or double blanks receive weight 0 .
In practice , f ( d ) must be estimated from training data ( often a normal approximation is acceptable ) and the probability for a blank b is estimated by the relative frequency of blanks in the entire database . To estimate the other parameters , an EM mixture identifier can be used . The restriction that the four mixture proportions be determined by a1 and a2 complicates the maximisation step of the EM algorithm , but can be accounted for in numerical maximisation . For a detailed outline of EM hit miss mixture identification , see Table 2 .
213 A method to handle correlated record fields
The standard hit miss model assumes independence between record fields and this allows the total match score for a record pair to be calculated by simple summation of the weights for individual record fields . The independence assumption may , however , lead to over estimated evidence that two records that match on a set of strongly correlated fields are duplicates , and this may hinder effective duplicate detection .
To reduce the risk for high total match scores driven solely by a group of correlated record fields , we propose a model that accounts for pairwise associations between correlated events . Let j1 ; : : : ; jm denote a set of events related to different fields on the same database record . In the independence model , the probability that these events should co occur on a record is :
P ( j1 ; : : : ; jm ) =
= m
Y t=1 m
Y t=1
P ( Xt = jt ) =
( 1 , bt),1fijt
( 11 )
The corresponding total contribution to the match score is : m
X t=1
Wjt jt = m
X t=1 log2f1 , ct(1 , fijt )(1 , bt),2g , m
X t=1 log2 fijt
( 12 ) but this is based on the assumption that the information in the different record fields can be considered independently . If no assumption of independence can be made , the joint probability for the set of events j1 ; : : : ; jm can only be expressed as :
P ( j1 ; : : : ; jm ) = P ( j1 ) P ( j2 j j1 ) P ( j3 j j1 ; j2 )
: : : P ( jm j j1 ; : : : ; jm,1 )
( 13 ) j fi t = argmax js :s<t
P ( jt j js ) jt = ( 1 , bt),1 P ( jt j j fi fi fi t )
Then :
W fi jj = log2f1 , c(1 , fi fi j )(1 , b),2g , log2 fi fi j
( 15 )
( 16 )
( 17 ) and : m
W fi jtjt =
X t=1
= m
X t=1 m
X t=1 m
X t=1 log2f1 , ct(1 , fi fi jt )(1 , bt),2g , log2f1 , ct(1 , fijt )(1 , bt),2g ,
Wjtjt , m
X t=1 log2 fi fi jt fijt m
X t=1 m
X t=1 log2 fi fi jt log2 fi fi jt
( 18 )
Thus , the adjusted match score can be calculated by subtracting a sum of compensating terms from the original match score . Each compensating term can be written on the following form : log2 fi fi jt fijt
= log2
P ( jt j j fi t ) P ( jt )
( 19 ) and a shrinkage estimate for this log ratio has earlier proven useful , as robust strength of association measures to find interesting associations in the WHO drug safety database [ 1 , 15 ] . This strength of association measure is referred to as the IC and is defined as [ 1 , 15 ] :
ICij = log2
P ( j j i )
P ( j )
( 20 )
Shrinkage is achieved through Bayesian inference with a prior distribution designed to moderate the estimated IC values toward the baseline assumption of independence ( IC = 0 ) [ 1 , 15 ] . The advantage of using IC values rather than raw observed to expected ratios is that they provide less volatile estimates when little data is available . In order to provide more robust scoring of correlated record fields , we propose IC shrinkage estimates be used to estimate log2 in ( 18 ) . The ordering of events j1 ; : : : ; jm may affect the magnitude of the compensating term in ( 18 ) since conditioning is only allowed on preceding events in the sequence . As a less arbitrary choice of ordering , we propose the set be re arranged in decreasing order of maximal IC value with another event in the set of matched events . 2.2 Fitting a generalised hit miss model to WHO fifi jt fijt drug safety data
An adapted hit miss model was fitted to the WHO drug safety database based on the data available at the end of 2003 , including a set of 38 manually identified groups of duplicate records .
Record field
DATE
Interpretation Date of onset
Type String
OUTCOME
Patient outcome
Discrete ( 7 values )
AGE
GENDER DRUGS ADRS
Patient age
Patient gender
Drugs used
ADRs observed
COUNTRY Reporting country
Numerical ( years old )
Discrete ( 2 values ) 14,280 binary events 1953 binary events Discrete ( 75 values )
Missing data
23 % 22 % 19 % 8 %
0.08 % 0.001 %
0 %
Table 3 : Record fields used for duplicate detection in the WHO database .
80000
60000
40000
20000
50
Years
100
150 a . Ages
0
1920
1940
1960 Year b . Dates
1980
2000
−100
−50
0
Years
50
100
−10000
−5000
0 Days
5000
10000 c . Age differences d . Date differences
80000
60000
40000
20000
0
0
Figure 2 : Empirical distributions for ages and dates on records in the WHO database , as well as empirical f ( d ) functions together with fitted normal distributions .
221 Implementation
Although the WHO database allows for the transmission and storage of a large amount of data for each individual case report , there are few records that have even the majority of the fields filled in [ 1 ] . However , all records in the data set have at least one drug substance , one ADR term and the reporting country listed . For the identification of possible duplicate records , the following record fields were considered the most relevant : date of onset , patient age , patient gender , reporting country , patient outcome , drug substances used and ADR terms observed ( drug substances and ADR terms are in fact sets of binary events related to the presence or absence of each ) . Table 3 lists basic properties for these record fields .
Some data pre processing was required . Onset dates are related to individual ADR terms , and although there tends to be only one distinct onset date per record , there are 1184 records ( 0.04 % of the database ) that have different onset dates for different ADR terms ; for those records , the earliest listed onset date was used . For the gender and outcome fields \ " had sometimes been used to denote missing values , and was thus re encoded as such . Similarly , gender was sometimes listed as N/A which was also considered a missing value . For the age field , a variety of non standard values were interpreted as missing values and re encoded as such . Sometimes different age units had been used so in order to harmonise the ages , they were all re calculated and expressed in years . Observed drug substances are listed as either suspected , interactive or concomitant , but since this subjective judgement is likely to vary between reporters , this information was disregarded .
For large data sets , it is computationally intractable to score all possible record pairs . A common strategy is to group the records into different blocks based on their values for a subset of important record fields and to only score records that are within the same block [ 9 ] . For the WHO
10
5 e r o c 0 S
−5
−20
10
5
0 e r o c S
−5
−400
−200
0
Days
200
400 b . Date
−10
0
Years
10
20 a . Age
Figure 3 : Fitted hit miss mixture model weight functions for age and date , respectively . Note the discrete jump in the weight functions at d = 0 . database , we block records based on drug substances crossed with ADR types so that only record pairs that have at least one drug substance in common and share at least one ADR type ( as defined by the System Organ Class , which is a higher level grouping of ADR terms ) are scored . In addition to the improvement in computational efficiency , this also reduces the risk for false leads generated by almost identical non duplicate database records that refer to different reactions in the same patient ( see Section 1 ) . While blocking may in theory yield extra false negatives , duplicate records that don’t match on at least one drug substance and an ADR type are very unlikely to receive high enough match scores to exceed the threshold for manual review .
222 Model fitting
The majority of the hit miss model parameters are estimated based on the entire data set , but c , a1 and a2 rely on the characteristics of identified duplicate records . For the WHO drug safety database there were 38 groups of 2 4 suspected duplicate records available for this purpose . These had been identified earlier by manual review .
^a
Record field GENDER 0.051 COUNTRY 0.036 OUTCOME 0.101 0.107 0.387
DRUGS ADRS
^b
0.080 0.000 0.217 0.001 0.000
Wjk 3.22 3.80 2.05 2.30 0.68
Maximum Wjj value
Minimum Wjj value
1.22 ( Male )
18.45 ( Iceland )
0.68 ( Female ) 1.03 ( USA )
8.19 ( Died unrelated to reaction )
0.97 ( Recovered )
21.23 ( non unique ) 20.14 ( non unique )
4.77 ( acetylsalicylic acid )
2.77 ( rash )
Table 4 : Some parameters for the hit miss model fitted to the WHO database . The Wjk value is the weight for a mismatch in that particular record field . The listed Wjj values are the maximum and minimum weights for matches on events in that particular record field . i was replaced by the average P fi2
Standard hit miss models were fitted to the gender , country and outcome record fields . Separate hit miss models were fitted for individual drug substances and ADR terms , but b and c was estimated for drug substances as a group and for ADR terms as a group ( c was estimated based on ( 7 ) where P fi2 for the group ) . Some of the fitted hit miss model parameters are displayed in Table 4 . As expected , matches on common events such as female gender receive much lower weights than matches on more rare events such as originating in Iceland . The penalty for mismatching ADR terms is significantly lower than that for mismatching drug substances , because discrepancies are more common for ADR terms . This is natural since the categorisation of adverse reactions requires clinical judgement and is more prone to variation . i
For the numerical record fields age and date , hit miss mixture models as described in Section 212 were fitted . Figure 2 shows empirical distributions in the WHO database for age and date together with the corresponding f ( d ) functions ( note as an aside the digit preference on 0 and 5 for age ) . Since the empirical f ( d ) functions for both age and date are approximately normal and since they must be symmetrical by definition ( d = j , i and i and j follow the same distribution ) , we assume normal f ( d ) functions with mean 0 for both age and date . The variances were estimated by :
2 = Pn ^2 i=1 d2 n i when calculating the weight . For example , to compare dates 2002 10 ? and 2002 10 12 , we integrate ( 9 ) and ( 10 ) from 12 to 20 . In practice , this leads to weights around 4.5 for matches on year when information on day and month are missing on one of the records and to weights around 8.0 for matches on year and month when information on day is missing on one of the records .
There tend to be strong correlations between drug substances and ADR terms ( groups of drug substances are often co prescribed and certain drug substances cause certain reactions ) so IC based compensation according to Section 213 was introduced for drug substances and ADR terms as one group .
223 A match score threshold
Under the hit miss model , the match score correlates with the probability that two records are duplicates . In order to convert match scores to probabilities , we use a simple form of the mixture model discussed by Belin & Rubin [ 2 ] . The assumption is that the match scores for duplicate records follow one normal distribution and the match scores for nonduplicate records follow a different normal distribution . For the WHO database , the empirical match score distributions are approximately normal . We estimated the match score mean and variance for duplicates based on the scores for the 38 duplicates in training data ( see Section 222 ) :
( 21 )
^s2 = 42:96
^s2 = 15:73
( 24 ) where n is the number of record pairs on which the estimate is based . EM mixture identification as outlined in Table 2 with the estimated values for b and 2 2 and with starting values ^a1 = 0:1 and ^a2 = 0:1 yielded the following parameters for the hit miss mixture model for age :
^a1 = 0:036 ^1 = 2:1
^a2 = 0:010 ^2 = 32:9 and for date :
^a1 = 0:051 ^1 = 50:2
^a2 = 0:010 ^2 = 3655
^b = 0:186
^b = 0:229
( 22 )
( 23 )
Because of the limited amount of training data available , we enforced a lower limit of 0.01 for both ^a1 and ^a2 . Thus , even though no large deviations in age and date were observed in our training data , the possibility of large errors in these record fields is not ruled out .
A problem with onset date is that quite a large proportion of the records in the data set ( > 15 % ) have incomplete but not altogether missing information ( such as 2002 10 ? or 1999 ? ? ) . This is straightforwardly taken care of in the hit miss mixture model by integrating over a wider interval , and for non duplicates based on a random sample of 10,000 record pairs :
^s1 = ,18:50
^s1 = 8:55
( 25 )
The only relevant data available to estimate the overall proportion of duplicates in the data set was the study of duplicate records in vaccine spontaneous reporting data [ 14 ] , which found duplication rates around 005 Based on ^P ( dup ) = 0:05 and the estimated match score distributions , we used Bayes formula to compute the probability that a given match score s corresponds to a pair of duplicates :
P ( dup j s ) =
0:05 ( cid:30)(s ; ^s2 ; ^s2 )
0:05 ( cid:30)(s ; ^s2 ; ^s2 ) + 0:95 ( cid:30)(s ; ^s1 ; ^s1 )
( 26 )
In order to obtain an estimated false discovery rate of below 0.05 , the match score threshold for likely duplicates was set at 37.5 since P ( dup j 37:5 ) = 0:95 according to ( 26 ) .
224 Experimental setup
One experiment was carried out to evaluate the performance of the adapted hit miss model in identifying the most
Onset date Age Gender Country Outcome Drug substances ADR terms 6 in total 3 of 6 + 1 2 of 6 + 4 2 of 6 + 4 3 of 6 + 2 3 of 6 + 3
1997 08 ? ? 1999 06 09 1997 09 ? ? 1995 11 29 1997 08 25
USA USA USA USA USA USA
Died Died Died Died Died Died
2 of 3 + 1 3 of 3 + 3
62 ? 62 62 ? ?
3 in total
3 of 3
2 of 3 2 of 3
Score
25.19 23.66 22.92 22.82 22.74
*
Table 5 : The first difficult template record together with the top 5 records in its list of potential duplicates according to the hit miss model . The test record is marked with an asterisk .
?
?
M M M M M M
F F ? ? M F
Onset date Age Gender Country Outcome Drug substances ADR terms 1997 08 23 1997 08 23 1997 08 23 1997 08 23 1997 08 ? ?
Died Died Died
Unknown
5 in total
4 in total 1 of 4 + 4 2 of 4 + 3 0 of 4 + 4 3 of 4 + 1 3 of 4 + 3
USA USA USA USA USA USA
40 40 40 40 ? 40
5 of 5 4 of 5 5 of 5 3 of 5 3 of 5
Died Died
Score
47.28 45.75 37.78 28.52 27.09
*
Table 6 : The second difficult template record together with the top 5 records in its list of potential duplicates according to the hit miss model . The test record is marked with an asterisk . likely duplicates for a given database record . The test data set consisted of the 38 groups of identified duplicates described in Section 222 and to avoid dependence between training cases , we only used the two most recent records in each group . The most recent record was designated the template record and the second most recent record was designated the test record . In the experiment , each template record was scored against all other records within its block ( see Section 221 ) in the entire WHO database to see if any other record received a higher match score with the template record than the test record . While the same data set had been used in fitting the hit miss model , its only impact had been on the proportion of misses in different record fields , so the risk for bias in the performance estimates is slight .
Another experiment was carried out to evaluate the performance of the hit miss model in discriminating duplicates from random record pairs based on the threshold of 37.5 derived in Section 221 The test set used in the first experiment could not be used to evaluate the threshold since this data had been used to determine the threshold . However , Norway who is one of the few countries that label duplicate records on submission , had in their last batch in 2004 indicated 19 confirmed duplicates . This allowed for an independent evaluation of the duplicate detection method . Match scores were calculated for all record pairs within the same block ( see Section 221 ) and those with scores that exceeded the 37.5 threshold were highlighted as likely duplicates .
3 . RESULTS
3.1 Duplicate detection for a given database record
The performance at duplicate detection for a given database record was evaluated based on whether or not it was the test record that received the highest match score together with the template record . This was the case for 36 out of the 38 record pairs ( 94:7% ) . The two template records for which the test record was not top ranked are listed in Table 5 and
Table 6 together with the most likely duplicates as indicated by the hit miss model . For the first difficult template record , there are no strong matches , and based on a superficial examination , the two top ranked records which are not known duplicates seem as plausible as the test record which is a confirmed duplicate . Thus , while its performance was imperfect for this template record , the hit miss model ’s predictions are at least in line with intuition . For the second difficult template record , there are strong matches ( match scores ranging from 37.78 to 47.28 ) with 3 records that are not confirmed duplicates . While these may well be false positive , they could also be undetected duplicates : the records match on most of the fields and although some of the ADR terms differ , a more careful analysis shows that the listed ADR terms relate to liver and gastric problems . Thus , while the hit miss model failed to identify the known duplicate for this template record , it may have identified 3 that are currently unknown . 3.2 Discriminant duplicate detection
There was a total of 1559 case reports in the last batch from Norway in 2004 . The median match score for the 19 known pairs of duplicates was 41.8 and the median match score for all other record pairs ( after blocking ) was 48 Figure 4 displays the match score distributions for the two groups . All in all , 17 record pairs had match scores above 37.5 and out of these , 12 correspond to known duplicates and 5 to other record pairs . Thus , the recall of the algorithm in this experiment was 63 % ( 12 of the 19 confirmed duplicates were highlighted ) and the precision was 71 % ( 12 of the 17 highlighted record pairs are confirmed duplicates ) . However , the threshold of 37.5 was set based on the assumed 5 % rate of duplicates in the data set , and following the discussion of precision recall graphs by Bilenko & Mooney [ 4 ] Figure 5 indicates how the precision and the recall varies with different thresholds ( an estimated 20 % rate of duplicates would give a 35.2 threshold , an estimated 10 % rate of duplicates would give a 36.5 threshold and an estimated 1 % rate of duplicates would give a 39.6 threshold ) . To achieve
Known duplicates Other record pairs
0.06
0.04
0.02 y c n e u q e r F
0 −100
−50
0
Total score
50
100
Figure 4 : Match score distributions for known duplicates and other record pairs in the Norwegian batch , normalised in order to integrate to 1 .
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0 10
Precision Recall
20
30
Threshold
40
50
60
Figure 5 : Precision and recall as functions of the threshold , for the discriminant analysis experiment on Norwegian data . The dotted line indicates the selected threshold . the minimum total number of errors , 11 ( 2 false positives and 9 false negatives ) , a threshold between 40.7 and 41.7 must be used . Precision normally tends to 1 as the threshold is increased , but this is not the case in Figure 5 , because the highest match score actually corresponds to a pair of records that were not known duplicates . Table 7 lists the three record pairs with highest match scores among record pairs that were not confirmed duplicates and Table 8 lists the three record pairs with lowest match scores among confirmed duplicate record pairs .
3.3 Computational requirements
The experiments were run on a workstation equipped with a 2.2 GHz P4 processor and 1 GB of RAM . Efficient use of the available hardware and optimised data structures reduced computing time and memory requirements so that the initial data extraction and model fitting required a total of 50 minutes . To score a single pair of database records took 6 s , and to score a database record against the rest of the data set took about 1 second ( average block size in the order of 100,000 records ) . The scoring for all record pairs in the Norwegian data subset ( 1559 database records ) , after blocking , took 27 seconds .
4 . DISCUSSION
The hit miss model as implemented on WHO data produced very promising results . For records that are known to have a duplicate , the hit miss model reliably highlighted the corresponding record ( 94.7 % accuracy ) . However , only a small proportion of database records have duplicates , so high ranked records are not necessarily duplicates , and in order for the method to be truly effective at duplicate detection , it needed to provide an absolute estimate for the probability that two records are duplicates . The 63 % recall and 71 % precision in Section 3.2 indicate that the hit miss model identified the majority of known duplicates , while generating few false leads , which demonstrates its practical usefulness . The hit miss model did fail to highlight 7 known duplicates in the Norwegian batch , but from Table 8 it is clear that the amount of information on these records is very scarce : ages , outcomes and onset dates are missing on at least one of the records in each pair and while there are a few matching drug substances and ADR terms , there are at least as many unmatched ones . The lowering of the threshold required to highlight all these duplicates would yield an unmanageable proportion of false leads . We anticipate that any method would require non anonymised data to be able to identify such duplicates , since lack of data cannot be compensated for with advanced algorithms . This emphasises the need for improved quality of case reports .
Five of the record pairs highlighted in the Norwegian batch were not confirmed duplicates . One of these received the highest match score in the experiment ( the top one in Table 7 ) , but did not seem like an obvious pair of duplicates : outcomes are missing , onset dates and ages are close but don’t match and none of the registered ADR terms match . On the other hand , 6 out of the 7 drug substances on these two records are the same and this is what generated the unusually high match score . These drug substances are not particularly commonly co reported ( the pairwise associations between them are weak ) which further strengthens the evidence . In order to determine the true status of this record pair , we subsequently contacted the Norwegian national centre who confirmed that it was indeed a pair of duplicates : two different physicians at the same hospital had provided separate case reports for the same incident . This demonstrates that the hit miss model may account for probabilistic aspects of data that are not immediately clear from manual review and that the hit miss mixture model ’s treatment of small deviations in numerical record fields may be very useful in practice . The Norwegian centre also provided information on the 4 other record pairs of unknown status that had been highlighted in the study : the record pair with the second highest match score was reported to be a likely but yet unconfirmed duplicate whereas the other three highlighted record pairs were confirmed non duplicates . However , these case reports had all been provided by the same dentist and all referred to the same drug ADR combination . Such case reports submitted by the same individual will tend to be similar and difficult to distinguish from true duplicates . With respect to duplicate detection , these record pairs are certainly false leads , but in a different context the detection of such clusters of case reports may be very valuable ( since they would generally be considered less strong evidence of a true problem than case reports from independent sources ) . The Norwegian feedback indicates that the reported 71 % precision in Section 3.2 is an under estimate .
Onset date Age Gender Country Outcome 2004 04 30 2004 04 20 2003 02 02 2003 02 02 2003 12 16 2003 12 16
NOR NOR NOR NOR NOR NOR
? ? ? ? ? ?
51 50 57 55 8 18
F F M M F F
Drug substances
ADR terms
Score
6 matched , 1 unmatched
0 matched , 3 unmatched
76.97
3 matched , 1 unmatched
1 matched , 0 unmatched
42.88
1 matched , 0 unmatched
1 matched , 0 unmatched
40.69
Table 7 : The three record pairs with highest match scores among record pairs that are not confirmed duplicates in the Norwegian data .
Onset date Age Gender Country Outcome
Drug substances
ADR terms
Score
? ?
2003 01 07
? ? ?
79 ? 76 ? 43 ?
F F F F F F
NOR NOR NOR NOR NOR NOR
? ? ? ? ? ?
1 matched , 0 unmatched
1 matched , 2 unmatched
24.36
1 matched , 1 unmatched
1 matched , 3 unmatched
17.82
2 matched , 2 unmatched
0 matched , 8 unmatched
14.05
Table 8 : The three record pairs with lowest match scores among non highlighted confirmed duplicates in the Norwegian data .
The actual precision of the experiment was at least 76 % ( 13/17 ) and possibly even higher . The reported recall rate may be either under or over estimated depending on how many unidentified duplicates remain .
The hit miss mixture model is a new approach to handling discrepancies in numerical record fields . Like the standard hit miss model , it is based on a rigorous probability model and provides intuitive weights . For matches , the weights depend on the precision of the matching values : matches on full dates receive weights around 12.0 , matches on year and month when day is missing receive weights around 8.0 and matches on year when month and day are missing receive weights around 35 Both matches and near matches are rewarded , and the definition of a near match is data driven : for the WHO database , age differences within 1 year and date differences within 107 days receive positive weights and are thus favoured over missing information . There is a limit to how strongly negative the weight for a mismatch will get ( see Figure 3 ) , so any large enough deviation is considered equally unlikely . An alternative model for dates which would be useful if typing errors were very common is to model year , month and day of the date as separate discrete variables . The disadvantage of this approach is that absolute differences of just a few days could lead to very negative weights whereas differences of several years may yield positive weights if the two records match on month and day . In the hit miss model , on the other hand , a pair of dates such as 1999 12 30 and 2000 01 02 contributes +3.18 to the match score , despite the superficial dissimilarity .
The experiments in this article were retrospective in the sense that they evaluated the performance of the algorithms based on what duplicates had already been identified . In the future , we aim to do a prospective study where the hitmiss model is used to highlight suspected duplicates in an unlabelled data subset and follow up the results by manual review . Such a study should allow for more accurate precision estimates and more insight into how the algorithms may be best applied in practice .
The hit miss model will be used routinely for duplicate detection in in the WHO database . Database wide screens will be carried out regularly and , in addition , duplicate detection can be carried out at data entry and automatically when a case series is selected for clinical review . The rate limiting step in duplicate detection for post marketing drug safety data is the manual review required to confirm or refute findings , so further testing will be necessary to determine whether the selected threshold is practically useful .
The hit miss model fitted to the WHO drug safety database in Section 2.2 can be used for duplicate detection in other post marketing drug safety data sets as well , provided they contain similar information . An alternative approach would be to use the methods described in this paper to fit adapted hit miss models directly for the data sets of interest , since the properties of different data sets may vary and additional record fields may be available .
5 . CONCLUSIONS
In this paper we have introduced two generalisations of the standard hit miss model and demonstrated the usefulness of the adapted hit miss model for automated duplicate detection in WHO drug safety data . Our results indicate that the hit miss model can detect a significant proportion of the duplicates without generating many false leads . Its strong theoretical basis together with the excellent results presented here , should make it a strong candidate for other duplicate detection and record linkage applications .
6 . ACKNOWLEDGEMENTS
The authors are indebted to all the national centres who make up the WHO Programme for International Drug Monitoring and contribute case reports to the WHO drug safety database , and in particular to the Norwegian national centre for allowing the evaluation of their data to be used in this paper and for providing rapid assessment of the suspected duplicates . The opinions and conclusions , however , are not necessarily those of the various centres nor of the WHO .
7 . REFERENCES
[ 1 ] A . Bate , M . Lindquist , I . R . Edwards , S . Olsson ,
R . Orre , A . Lansner , and R . M . De Freitas . A Bayesian neural network method for adverse drug reaction signal generation . European Journal of Clinical Pharmacology , 54:315{321 , 1998 .
[ 2 ] T . Belin and D . Rubin . A method for calibrating false match rates in record linkage . Journal of the American Statistical Association , 90:694{707 , 1995 .
[ 3 ] M . Bilenko and R . J . Mooney . Adaptive duplicate detection using learnable string similarity measures . In KDD ’03 : Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining , 2003 .
[ 4 ] M . Bilenko and R . J . Mooney . On evaluation and training set construction for duplicate detection . In Proceedings of the KDD 2003 workshop on data cleaning , record linkage and object consolidation , pages 7{12 , 2003 .
[ 5 ] E . A . Bortnichak , R . P . Wise , M . E . Salive , and H . H .
Tilson . Proactive safety surveillance . Pharmacoepidemiology and Drug Safety , 10:191{196 , 2001 .
[ 6 ] A . D . Brinker and J . Beitz . Spontaneous reports of thrombocytopenia in association with quinine : clinical attributes and timing related to regulatory action . American Journal of Hematology , 70:313{317 , 2002 .
[ 7 ] J . Copas and F . Hilton . Record linkage : statistical models for matching computer records . Journal of the Royal Statistical Society : Series A , 153(3):287{320 , 1990 .
[ 8 ] I . R . Edwards . Adverse drug reactions : finding the needle in the haystack . British Medical Journal , 315(7107):500 , 1997 .
[ 9 ] I . P . Fellegi and A . B . Sunter . A theory for record linkage . Journal of the American Statistical Association , 64:1183{1210 , 1969 .
[ 10 ] M . A . Hernandez and S . J . Stolfo . The merge/purge problem for large databases . In SIGMOD ’95 : Proceedings of the 1995 ACM SIGMOD international conference on Management of data , pages 127{138 . ACM Press , 1995 .
[ 11 ] M . Lindquist . Data quality management in pharmacovigilance . Drug Safety , 27(12):857{870 , 2004 .
[ 12 ] A . E . Monge and C . Elkan . An efficient domain independent algorithm for detecting approximately duplicate database records . In Research Issues on Data Mining and Knowledge Discovery , 1997 .
[ 13 ] H . B . Newcombe . Record linkage : the design of efficient systems for linking records into individual family histories . American Journal of Human Genetics , 19:335{359 , 1967 .
[ 14 ] J . N . Nkanza and W . Walop . Vaccine associated adverse event surveillance ( VAEES ) and quality assurance . Drug Safety , 27:951{952 , 2004 .
[ 15 ] R . Orre , A . Lansner , A . Bate , and M . Lindquist .
Bayesian neural networks with confidence estimations applied to data mining . Computational Statistics & Data Analysis , 34:473{493 , 2000 .
[ 16 ] M . D . Rawlins . Spontaneous reporting of adverse drug reactions . II : Uses . British Journal of Clinical Pharmacology , 1(26):7{11 , 1988 .
[ 17 ] S . Sarawagi and A . Bhamidipaty . Interactive deduplication using active learning . In KDD ’02 : Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining , pages 269{278 . ACM Press , 2002 .
