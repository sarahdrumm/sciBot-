Pattern based Similarity Search for Microarray Data
Haixun Wang
IBM T . J . Watson Research
Hawthorne , NY 10532 haixun@usibmcom
Jian Pei
Canada jpei@cssfuca
Simon Fraser University
IBM T . J . Watson Research
Philip S . Yu
Hawthorne , NY 10532 psyu@usibmcom
ABSTRACT One fundamental task in near neighbor search as well as other similarity matching efforts is to find a distance function that can efficiently quantify the similarity between two objects in a meaningful way . In DNA microarray analysis , the expression levels of two closely related genes may rise and fall synchronously in response to a set of experimental stimuli . Although the magnitude of their expression levels may not be close , the patterns they exhibit can be very similar . Unfortunately , none of the conventional distance metrics such as the Lp norm can model this similarity effectively . In this paper , we study the near neighbor search problem based on this new type of similarity . We propose to measure the distance between two genes by subspace pattern similarity , ie , whether they exhibit a synchronous pattern of rise and fall on a subset of dimensions . We then present an efficient algorithm for subspace near neighbor search based on pattern similarity distance , and we perform tests on various data sets to show its effectiveness .
Categories and Subject Descriptors H28 [ Database Management ] : Database Applications—Data Mining ; I52 [ Pattern Recognition ] : Design Methodology—Pattern analysis
Keywords pattern recognition , near neighbor , distance function
1 .
INTRODUCTION
Given a distance function dist(·,· ) that measures the similarity between two objects , a query object q ’s near neighbors within a given tolerance radius r in a database D is defined as : NN ( q , r ) = {p| p ∈ D , dist(q , p ) ≤ r}
( 1 ) The distance function dist(·,· ) has a direct impact on the efficiency of the search of near neighbors [ 3 ] . More importantly , it also determines the meaning of similarity and the meaning of the nearneighbor search .
Figure 1 : Similarity between two yeast genes
Applications . In this paper , we address a new type of similarity that cannot be effectively captured by conventional distance metric such as the Lp norm . As a motivating example , in Figure 1 , we show the expression levels of two Yeast genes under 17 different external conditions . It is clear that the two genes manifest similarity under a subset of conditions ( linked in thick lines ) .
In many scientific experiments , we measure objects in different environments . Figure 2(a ) is a dataset that contain the measurements of 3 objects in 8 different environments . Now , given a new object X whose measurements are shown in Figure 2(b ) , we want to find X ’s near neighbors in the dataset . Figure 2(c ) and ( d ) show potential near neighbors of object X . In Figure 2(c ) , the values of object X and A rise and fall coherently under conditions {a , b , d , e , g} . Figure 2(d ) reveals , in much the same way , the similarity of X and C under {a , b , c , e , h} .
Finding near neighbors based on subspace pattern similarity is important to many applications including DNA microarray analysis [ 1 , 8 , 7 ] . A DNA microarray is a two dimensional matrix where entry dij represents the expression level of gene i in sample j . Investigations show that more often than not , several genes contribute to a disease , which motivates researchers to identify genes whose expression levels rise and fall synchronously under a subset of conditions , that is , whether they exhibit fluctuation of a similar shape when conditions change .
Problems . Assume we are given a new gene for which we do not know in which conditions it might manifest coherent patterns with other genes . This new gene might be related to any gene in the database as long as both of them exhibit a pattern in some subspace . The dimensionality of the subspace is often an indicator of the degree of their closeness , that is , the more columns the pattern spans , the closer the relationship between the two genes .
EXAMPLE 1
( NEAR NEIGHBOR SEARCH IN ANY SUBSPACES ) .
Given a gene q , and a dimensionality threshold r , find all genes whose expression levels manifest coherent patterns with those of q
2602803003203403600246810121416expression levelsconditionsYGL106WYAL046C where us = 1|S| nate values of u and v in subspace S , and ≥ 0 . i∈S ui , vs = 1|S| i∈S vi are average coordi
The above definition , although intuitive , may not be applicable or effective for near neighbor search in arbitrary subspaces . Nearneighbor search queries often rely on index structures to speed up the search process . The definition of the coherent pattern ( Eq 2 ) uses not only coordinate values ( ie , ui , vi ) but also average coordinate values in subspaces ( ie , us , vs ) . It is unrealistic , however , to index average values for each of the 2|A| subsets .
To avoid the curse of dimensionality , we relax Definition 1 by eliminating the need of computing average values in Eq 2 . Instead , we use the coordinate values of any column k ∈ S as the base for comparison . Given a subspace S and any column k ∈ S , we define : dk,S ( u , v ) = max i∈S |(ui − uk ) − ( vi − vk)|
( 3 )
However , the choice of column k may be questionable : does an arbitrary k affect our ability in capturing pattern similarity ? The following property relieves this concern .
THEOREM 1 . If there exists k ∈ S such that dk,S ( u , v ) ≤ , then we have :
∀i ∈ S di,S ( u , v ) ≤ 2 and dS ( u , v ) < 2
PROOF . ( sketch ) Note :
|(uj − ui ) − ( vj − vi)| ≤ |(uj − vj ) − ( uk − vk)| +
|(uk − vk ) − ( ui − vi)| , and |(ui − uS ) − ( vi − vS )| ≤ 1 |S| j∈S
|(ui − uj ) − ( vi − vj )| .
Not only the difference among base columns is limited , Theorem 1 also shows that , the difference between using Eq 2 and Eq 3 is bounded by a factor of 2 in terms of the pattern quality . In the same light , we can show that if u and v exhibit an coherent pattern in subspace S , then ∀k ∈ S , we have dk,S ( u , v ) ≤ 2 . Thus , in order to find all coherent pattern , we can use dk,S ( u , v ) ≤ 2 as the criteria and then prune the results , since Eq 3 is much less costly to compute . In order to find patterns defined by a consistent measure , we fix the base column k for any subspace S ⊆ A . We assume there is a total order among the dimensions in A . Given a subspace S , we use its least dimension in terms of the total order as the base column . Now we arrive at the definition of pattern that induces an efficient implementation .
DEFINITION 2 pattern in subspace S ⊆ A if
( PATTERN ) . Objects u , v ∈ D exhibit an dk,S ( u , v ) ≤ where k is the least dimension in S and ≥ 0 .
The pattern definition focuses on pattern similarity in a given subspace . How to measure similarity between two objects when no subspace is specified ? Usually , we do not care over which subspace two objects exhibit a similar pattern , but rather , how many dimensions the pattern spans . Thus , the dimensionality of the subspace can be used as an indicator of the degree of the similarity .
( a ) a dataset of 3 objects
( b ) a query object X
( c ) X and A
( d ) X and C
Figure 2 : What is a near neighbor ? in any subspace S , where |S| ≥ r .
Our Contributions . We introduce a new measure to capture pattern based similarity exhibited by objects in subspaces . With the new distance measure , we extend the concept of near neighbor to the realm of pattern based similarity , which often carries significant meanings . We also propose a novel method to perform nearneighbor search by pattern similarity . Experiments show that our method is effective and efficient , and it outperforms alternative algorithms ( based on an adaptation of the R Tree index ) by an order of magnitude .
2 . PATTERN DISTANCE Let u , v be two objects in dataset D . How can we measure their pattern based similarity in a given subspace , say S = {a , b , c , d , e} ?
Figure 3 : pattern in subspace S = {a , b , c , d , e}
A straightforward way is to normalize both objects in subspace S ( Figure 3 ) by shifting u and v by an amount of us and vs respectively , where us ( vs ) is the average coordinate value of u ( v ) in subspace S . After normalization , we can check whether u and v exhibit a pattern of good quality in subspace S :
DEFINITION 1 exhibit a coherent pattern in subspace S ⊆ A if
( COHERENT PATTERN ) . Objects u , v ∈ D dS ( u , v ) = max i∈S |(ui − us ) − ( vi − vs)| ≤
( 2 )
0246810121416abcdefghmeasuresenvironmentABC0246810121416abcdefghmeasuresenvironmentX0246810121416abcdefghmeasuresXAX ( subspace)A ( subspace)0246810121416abcdefghmeasuresXCX ( subspace)C ( subspace)abcdeabcde0object uobject v DEFINITION 3
( SUBSPACE PATTERN SIMILARITY ) .
Given two objects u , v ∈ D and some ≥ 0 , we say that the similarity between u and v is r , or s(u , v ) = r if r is the maximum dimensionality of all subspaces S ⊆ A where u and v exhibit an pattern .
Thus , two objects that exhibit an pattern in the entire space A will have the largest similarity of |A| . The distance between the two objects is reversely proportional to their similarity . For instance , we can define dist(u , v ) = 1/s(u , v ) . Note that the distance defined above is non metric in that it does not satisfy the triangular inequality . One object can share patterns with two other objects in different subspaces , and the sum of the distances to the two objects might be smaller than the distance between the two objects , which may not share synchronous patterns in any subspace .
Problem Statement . We define the following problem of near neighbor search . Given an object q , a tolerance radius r , find NN ( q , r ) in dataset D :
NN ( q , r ) = {u ∈ D | s(q , u ) ≥ r}
( 4 )
3 . NEAR NEIGHBOR SEARCH BY SUBSPACE
PATTERN SIMILARITY
In this section , we propose a new index structure called PS Index ( pattern similarity index ) to support near neighbor search in pattern distance space . 3.1 Building a Trie Given a dataset D in space A = {c1 , c2 , , cn} , where c1 ≺ c2 ≺ ··· ≺ cn is a total order on attributes , we represent each object u ∈ D as a sequence of ( column , value ) pairs , that is : u = ( c1 , u1 ) , ( c2 , u2 ) , , ( cn , un )
An aligned suffix of u is defined as : f ( u , i ) = ( ci , 0 ) , ( ci+1 , ui+1 − ui ) , , ( ck , uk − ui )
( 5 )
We use an example to demonstrate the data sequentializing pro cess .
EXAMPLE 2 . Let database D be composed of the following ob ject defined in space A = {c1 , c2 , c3 , c4 , c5} . obj #1 c1 3 c2 0 c3 4 c4 2 c5 0
We derive all aligned suffices of length ≥ 2 of the object , and insert them into a trie . Figure 4 demonstrates the insertion of the following sequence : f ( #1 , 1 ) = ( c1 , 0 ) , ( c2,−3 ) , ( c3 , 1 ) , ( c4,−1 ) , ( c5,−3 )
Each leaf node n in the trie maintains an object list , Ln . Assuming the insertion of f ( #1 , 1 ) leads to node x , which is under arc ( e,−3 ) , we append 1 ( object #1 ) , to object list Lx . 3.2 Building PS Index over a Trie
The trie enables us to find near neighbors of a query object q = ( c1 , v1 ) , , ( cn , vn ) in a given subspace S , provided S is defined by a set of consecutive columns , ie , S = {ci , ci+1 , , ci+k} . The PS index , described below , allows us to ’jump’ directly from a column cj to any column ck , where k > j .
Figure 4 : Insertion of sequence f ( # , 1 ) .
We use the following two steps to build the PS index on top of a trie . First , after all sequences are inserted , we assign to each node x a pair of labels , nx , sx , where nx is the prefix order of node x in the trie ( starting from 0 , which is assigned to the root node ) , and sx is the number of x ’s descendent nodes .
Next , we store nodes into buffers . For each unique edge ( col , dist ) in the trie1 , we create a buffer . Nodes are appended to the buffers during a depth first walk of the trie . When we encounter a node x under edge ( col , dist ) , we append x ’s label nx , sx to the buffer of ( col , dist ) . From the definition of base column aligned suffixes , it is clear that a buffer is composed of nodes that have the same distance from their base columns ( root node ) .
The labeling scheme and the node buffers have the following property .
( PS INDEX PROPERTY ) .
THEOREM 2 1 . If node x and y are labeled nx , sx and ny , sy respectively , and nx < ny ≤ nx + sx , then y is a descendent node of x ;
2 . nodes in any link are ordered by their prefix order number ; and
3 . if a link contains nodes u . . . v . . . w ( in that order ) , and u and w have a common ancestor x , then x is also v ’s ancestor .
PROOF . 1 ) and 2 ) are due to the labeling scheme which is based on depth first traversal . For 3 ) , note that if nodes u , , v , , w are in a link , and u , v are descendents of x , we have nx < nu < nv < nw ≤ nx + sx , which means v is also a descendent of x .
The above properties enable us to use range queries to find de scendents of a given node in a given link . Algorithm 1 summarizes the index construction procedure . The time complexity of building the PS index is O(|D||A| ) . The Ukkonen algorithm [ 6 ] builds suffix tree in linear time . The construction of the trie for pattern similarity indexing is less time consuming because the length of the indexed subsequences is constrained by |A| . Thus , it can be constructed by a brute force algorithm [ 4 ] in linear time . The space taken by the PS Index is linearly proportional to the data size . Since each node appears once and only once in the pattern distance links , the total number of entries equals the total number of nodes in the trie , or O(|D||A|2 ) in the worst case ( if none of the nodes are shared by any subsequences ) . On the other hand , there are exactly |D|(|A| − 1 ) object ids stored . Thus , the space is linearly proportional to the data size |D| . 1For each column col , there are at most 2ξ−1 unique edges , where ξ is the number of unique values of that column . c1,0c2, 3c3,1c4, 1c5, 3 31distance to base column1Lx:objectlist of node xxy Input : D : objects in multi dimensional space A Output : PS Index of D for each u ∈ D do insert f ( u , i ) , 1 ≤ i < |A| into a trie ;
( Eq 5 ) for each node x encountered in a depth first traversal of the trie do label node x by nx , sx ; let ( c , d ) be the arc that points to x ; append nx , sx to link ( c , d ) ;
Algorithm 1 : Index Construction
3.3 Near Neighbor Search
In this section , we provide an efficient solution to the 2nd prob lem defined in Section 2 .
EXAMPLE 3 . Given a query object , q = ( a , 1 ) , ( b , 1 ) , ( c , 2 ) , ( d , 0 ) , ( e , 3 ) find NN ( q , 3 ) in D ( Table 1 ) . By definition , ∀p ∈ NN ( q , 3 ) , p and q must share a pattern in 3or higher dimensional space . obj ( 1 ) ( 2 ) ( 3 ) ( 4 ) a 3 4 1 0 b 0 1 4 3 c 4 5 5 4 d 2 3 1 0 e 0 6 6 5
Table 1 : dataset D in Example 3
The Coverage Property . Each node x in the trie represents a coverage , which we denote as a range c(x ) = [ nx , nx+sx ] ( assuming x is labeled nx , sx ) . Finding near neighbors with similarity ≥ r boils down to finding leaf nodes whose preorder number is inside at least r ranges associated with the query object . Let q be a query object , and p ∈ D be a near neighbor of q ( with similarity above threshold r , or s(p , q ) ≥ r ) . Hence , there exists a subspace S , |S| = r , in which p and q share a pattern . Consider f ( q , i ) = ( ci , 0 ) , · · · , ( ck , qk − qi ) , · · · , ( c|A| , q|A| − qi ) . Each element ( ck , qk − qi ) of f ( q , i ) corresponds to a pattern distance link , which contains a set of nodes . Let P ( q , i ) denote the set of all nodes that appear in the pattern distance links of the elements in f ( q , i ) , and let P ( q ) =
P ( q , i ) . i∈A
THEOREM 3 . ( The Coverage Property ) For any object p that shares a pattern with query object q in subspace S , there exists a set of |S| nodes {x1 , , x|S|} ⊆ P ( q ) , and a leaf node y that contains p ( p ∈ Ly ) , such that ny ∈ c(x1 ) ⊆ ··· ⊆ c(x|S| ) , where ny is the prefix order of node y .
PROOF . ( Sketch ) Let ci be the first column of S ( that is , there does not exist any cj ∈ S such that j < i ) . Assume the insertion of f ( p , i ) follows the path consisting of nodes xi , xi+1,··· , x|A| , which leads to c(x|A| ) ⊆ ··· ⊆ c(xi+1 ) ⊆ c(xi ) . Assume node xj is in the list of ( cj , pj − pi ) . Since p and q share pattern in S , ( cj , pj−pi ) = ( cj , pj−qi ) holds for at least |S| different columns , which means |S| of the nodes in xi , xi+1,··· , x|A| also appear in P ( q , i ) ⊂ P ( q ) .
The proof also shows that , to find objects that share patterns with q in subspace S , of which ci is the first column , we only need to consider ranges of the objects in P ( q , i ) , instead of in the entire object set P ( q ) . The reverse of the coverage property is also true , and can be proved under the same spirit : for any {x1,··· , xn} ⊆ P ( q ) satisfying c(x1 ) ⊆ ··· ⊆ c(xn ) , any object ∈ Lx1 is a near neighbor of q with similarity r ≥ n . The Algorithm . Based on the coverage property , to find NN ( q , r ) , we need to find those leaf nodes whose preorder number is inside at least r nested ranges . We perform near neighbor search iteratively . At the ith step , we find objects that share patterns with q in subspace S , of which ci is the first column . During that step , we only need to consider ranges of objects in P ( q , i ) .
We demonstrate the search process with an example . node objs
6
10
14
5 24 {1} {2} {3,4} {1} {2} {3,4} {1} {2} {3,4}
15
21
18
22
Figure 5 : suffix trie and object lists of dataset D
In Figure 5 , we show a labeled trie built on D , and the object lists associated with each leaf node of the trie . For presentation simplicity , we did not include suffixes of length less than 3 in Figure 5 . It does not affect the result of Example 3 , which looks for patterns in 3 or higher dimensional space . that contain column a ( the 1st column of A ) .
We start with f ( q , 1 ) , that is , we look for patterns in subspaces f ( q , 1 ) = ( a , 0 ) , ( b , 0 ) , ( c , 1 ) , ( d,−1 ) , ( e , 2 )
For each element in f ( q , 1 ) , we consult the corresponding horizontal link and record the labels of the nodes in the horizontal link . For instance , ( a , 0 ) finds one node , which is labeled 1 , 9 . We record it in Figure 6 . For the remaining elements of f ( q , 1 ) , our search is confined within that range , since we are looking for subspaces where column a is present . We consult the horizontal link of elements in f ( q , 1 ) one by one . After we consult ( b , 0 ) , ( c , 1 ) , and ( d,−1 ) and record the results , we find region [ 4 , 6 ] inside three brackets ( Figure 6 ) . It means objects in the leaf nodes whose prefix order are in range [ 4 , 6 ] already match the query object in a 3 dimension space . To find what those objects are , we perform a range query [ 4 , 6 ] in the object list table shown in Figure 5 , which returns object 1 and 2 , and they belong to leaf node 5 and 6 respectively . The two objects share a pattern with q in 3dimension space {a , c , d} . We repeat this process for f ( q , 2 ) , and so on .
Optimization . In essence , the searching process maintains a set of embedded ranges represented by brackets ( Figure 6 ) , and the goal is to find regions within r brackets . The performance of the search can be greatly improved by immediately dropping those regions from further consideration if i ) all nodes inside the region c,1d, 3a1d,0a,0b,0c,0b, 3d, 10,2415,0b,3c,4e,5e, 3e,2c,4c,1e,2d,2e,5e,0d, 4e,1e,1e, 45,04,26,03,32,410,09,18,27,31,914,013,212,318,017,116,211,721,022,020,224,023,119,5 after checking result
( a,0 ) :
( b,0 ) :
( c,1 ) :
( d, 1 ) :
( e,2 ) :
Figure 6 : Embedded ranges during the search of f ( q , 1 ) already satisfy the query , or ii ) no node inside the region can possibly satisfy the query . More specifically ,
1 . A region inside less than r − |A| + i brackets after the ith dimension of A is checked is discarded . It is easy to see that such regions will not be inside r brackets after the remaining |A| − i dimensions are checked .
2 . If a region is already inside r brackets , we output the objects in the leaf nodes within that region , and discard the region ( unless the users want the output objects ordered by their distance to the query object . )
For instance , in Figure 6 , after the range of [ 4 , 6 ] is returned , only region [ 3 , 4 ] shall remain before ( e , 2 ) is checked .
Input : q = ( c1 , v1),··· , ( cn , vn ) : a query object r : distance threshold , : pattern tolerance F : index file for D
Output : NN ( q , r ) for i = 1 , , r + 1 do
R ← the range of the ( only ) node in link ( ci , 0 ) ; j ← i + 1 ; while R = φ and j ≤ |A| do search link ( cj , v ) for nodes inside any range of R , where v ∈ [ vj − vi − , vj − vi + ] ; update R by adding the ranges of those nodes ; if a region s of R is inside |A| − r brackets then output objects in Lx where x ∈ s ; eliminate s from R ; end if a region s of R is inside less than r − j brackets then eliminate the region from s ; end j ← j + 1 ; end end
Algorithm 2 : Near Neighbor Search
4 . EXPERIMENTS
We tested PS Index with both synthetic and real life data setson a Linux machine with a 700 MHz CPU and 256 MB main memory . The yeast micro array is a 2 , 884×17 matrix ( 2,884 genes under 17 conditions ) [ 5 ] . The mouse cDNA array is a 10 , 934 × 49 matrix ( 10,934 genes under 49 conditions ) [ 2 ] and it is pre processed in the same way . We also generate synthetic data , which are random integers from a uniform distribution in the range of 1 to ξ . Let
|D| be the number of objects in the dataset and |A| the number of dimensions . The total data size is 4|D||A| bytes .
( a ) s(·,· ) ≥ 13
( b ) s(·,· ) ≥ 12
Figure 7 : Near neighbors of YAL046C ( = 20 )
Near Neighbor Search Results . We show results of nearneighbor search over the yeast microarray data , where genes’ expression levels ( of range 0 to 600 [ 1 ] ) have been discretized into ξ = 30 bins . Assume we are interested in genes related to gene YAL046C . Let = 20 ( or 1 after discretization ) . We found one gene , YGL106W , within pattern distance 3 of gene YAL046C , ie , YAL046C and YGL106W exhibit an pattern in a subspace of dimensionality 14 . This is illustrated by Figure 7(a ) , where except under conditions 1 , 3 , and 9 ( CH1B , CH2I , and RAT2 ) , the expression levels of the two genes rise and fall in sync .
Figure 7(b ) shows 11 near neighbors of YAL046C found with distance radius of 4 . That is , except for 4 columns , each of the 11 genes shares an pattern with YAL046C . It turns out that none of any two genes share patterns with YAL046C in the same subspace . Naturally , these genes do not show up together in any subspace cluster discovered by algorithms such as bicluster [ 1 ] . Thus , subspace near neighbor search may provide insights to understanding their interrelationship overlooked by previous techniques .
Space Analysis . The space requirement of the pattern similarity index is linearly proportional to the data size ( Figure 8 ) . In Figure 8(a ) , we fix the dimensionality of the data at 20 and change ξ , the discretization granularity , from 5 to 80 . It shows that ξ has little impact on the index size when the data size is small . When the data size increases , the growth of the trie slows down as each trie node is shared by more objects ( this is more obvious for smaller ξ in Figure 8(a) ) .
In Figure 8(b ) and 8(c ) , the discretization granularity ξ is fixed at 20 , while the dimensionality of the dataset varies . The dimensionality affects the index size . With a dataset of dimensionality |A| , the lowest similarity between two objects is 2 , ie , they do not share patterns in any subspace of dimensionality 2 or larger . However , given a query object q , our interest is in finding near neighbors of q , that is , finding NN ( q , r ) where the similarity threshold r is high . Thus , instead of inserting each suffix of an object sequence into the trie , we insert only those suffixes of length larger than a threshold t . This enables us to find NN ( q , r ) where r ≥ t . For a 40 Mbytes dataset of dimensionality |A| =80 , restricting nearneighbor search within r ≥ 72 reduces the index size by 71 % .
Time Analysis . We compare the algorithms presented in this paper with two alternative approaches , i ) brute force linear scan , and ii ) R Tree family indices . The linear scan approach for nearneighbor search is straightforward to implement . The R Tree , how
11011011036110366411036642602803003203403600246810121416expression levelsconditionsYGL106WYAL046C2503003504000246810121416expression levelsconditionsYAL046C ( a ) |A| = 20 , ξ = 5 , , 80
( b ) varying total data size , ξ = 20
( c ) varying # of objects , ξ = 20
Figure 8 : Index Size .
( a ) Pattern matching in given subspaces
( b ) Near neighbor search in subspaces beyond given dimensionalities
( c ) Impact of ξ and |A| in near neighbor query NN ( q , 7 )
Figure 9 : Query Performance ( average of 1000 runs ) . ever , indexes values not patterns . To support queries based on pattern similarity , we create an extra dimension cij = ci−cj for every two dimensions ci and cj . Still , R Tree index supports only queries in given subspaces and does not support finding near neighbors that manifest patterns in any subspace of dimensionality above a given threshold .
The query time presented in Figure 9(a ) indicates that PS Index scales much better than the two alternative approaches for pattern matching in given subspaces . The comparisons are carried out on synthetic datasets of dimensionality |A| = 40 and discretization level ξ = 20 . Each time , a subspace is designated by randomly selecting 4 dimensions , and random query objects are generated in the subspace . We find that the R Tree approach is slower than brute force linear scan for two reasons : i ) the R Tree approach degrades to linear scan under high dimensionality , and ii ) the fact that it indexes on a much larger dataset ( with |A|2/2 extra dimensions ) means that it scans a much larger index file . In Figure 9(b ) , we show the results of near neighbor search with different tolerance radiuses . PS Index is much faster than linear scan2 . Still , the response time of PS Index increases rapidly when the radius expands , as a lot more branches have to be traversed in order to find all objects satisfying the criteria . Figure 9(c ) also confirms that dimensionality is a major concern in query performance .
5 . CONCLUSIONS
We identify the need of finding near neighbors under subspace pattern similarity , a new type of similarity not captured by Euclidean , Manhattan , etc . , but essential to a wide range of applications , including DNA microarray analysis and e commerce target marketing . Two objects are similar if they manifest a coherent
2The complexity of checking whether two objects manifest an pattern in a subspace of dimensionality beyond a given threshold is at least O(n log(n) ) , where n = |A| . pattern of rise and fall in an arbitrary subspace , and their degree of similarity is measured by the dimensionality of the subspace . A non metric distance function is defined to model near neighbor search in subspaces . We propose PS Index , which maps objects to sequences and index them using a tree structure . Experimental results show that PS Index achieves orders of magnitude speedup over alternative algorithms based on naive indexing and linear scan .
6 . REFERENCES [ 1 ] Y . Cheng and G . Church . Biclustering of expression data . In Proc . of 8th International Conference on Intelligent System for Molecular Biology , 2000 .
[ 2 ] R . Miki et al . Delineating developmental and metabolic pathways in vivo by expression profiling using the riken set of 18,816 full length enriched mouse cDNA arrays . In Proceedings of National Academy of Sciences , 98 , pages 2199–2204 , 2001 .
[ 3 ] Piotr Indyk . On approximate nearest neighbors in non euclidean spaces . In IEEE Symposium on Foundations of Computer Science , pages 148–155 , 1998 .
[ 4 ] E . M . McCreight . A space economical suffix tree construction algorithm . Journal of the ACM , 23(2):262–272 , April 1976 .
[ 5 ] S . Tavazoie , J . Hughes , M . Campbell , R . Cho , and G . Church .
Yeast micro data set . In http://arepmedharvardedu/biclustering/yeastmatrix , 2000 . [ 6 ] E . Ukkonen . Constructing suffix trees on line in linear time . Algorithms , Software , Architecture : Information Processing , pages 484–92 , 1992 .
[ 7 ] Haixun Wang , Chang Shing Perng , Wei Fan , Sanghyun Park , and Philip S . Yu . Indexing weighted sequences in large databases . In ICDE , 2003 .
[ 8 ] Haixun Wang , Wei Wang , Jiong Yang , and Philip S . Yu .
Clustering by pattern similarity in large data sets . In SIGMOD , 2002 .
0501001502002501020304050607080index size ( Mega bytes)dataset size ( Mega bytes)ξ=80ξ=60ξ=40ξ=20ξ=10ξ= 501002003004005006001020304050607080index size ( Mega bytes)dataset size ( Mega bytes)|A|=40|A|=20|A|=10|A|= 501002003004005006001002003004005006007008009001000index size ( Mega bytes)dataset size ( K objects)|A|=30|A|=20|A|=10|A|= 50.111010010005101520253035404550time ( sec.)dataset size ( Mega Bytes)R Tree indexlinear scanPD Index0.111010010005101520253035404550time ( sec.)dataset size ( Mega Bytes)linear scanPD Index NN(q,7)PD Index NN(q,5)PD Index NN(q,3)PD Index NN(q,1)0.11105101520253035404550time ( sec.)dataset size ( Mega Bytes)ξ=10 , |A|=40ξ=20 , |A|=40ξ=10 , |A|=30ξ=20 , |A|=30
