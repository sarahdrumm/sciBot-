Computing Minimum Cost Diagnoses to Repair Populated
DL based Ontologies
State Key Laboratory of Computer Science ,
Institute of Software , Chinese Academy of Sciences
State Key Laboratory of Computer Science ,
Institute of Software , Chinese Academy of Sciences
Yi Dong Shen
Beijing 100080 , China ydshen@iosaccn
Jianfeng Du
Graduate University of the
Chinese Academy of Sciences
Beijing 100080 , China jfdu@iosaccn
ABSTRACT Ontology population is prone to cause inconsistency because the populating process is imprecise or the populated data may conflict with the original data . By assuming that the intensional part of the populated DL based ontology is fixed and each removable ABox assertion is given a removal cost , we repair the ontology by deleting a subset of removable ABox assertions in which the sum of removal costs is minimum . We call such subset a minimum cost diagnosis . We show that , unless P=NP , the problem of finding a minimum cost diagnosis for a DL Lite ontology is insolvable in PTIME wrt data complexity . In spite of that , we present a feasible computational method for more general ( ie SHIQ ) ontologies . It transforms a SHIQ ontology to a set of disjoint propositional programs , thus reducing the original problem into a set of independent subproblems . Each such subproblem computes an optimal model and is solvable in logarithmic calls to a SAT solver . Experimental results show that the method can handle moderately complex ontologies with over thousands of ABox assertions , where all ABox assertions can be assumed removable .
Categories and Subject Descriptors I23 [ Artificial Intelligence ] : Deduction and Theorem Proving ; I24 [ Artificial Intelligence ] : Knowledge Representation Formalisms and Methods
General Terms Algorithms
Keywords Ontologies , Description Logics , Disjunctive Datalog , Diagnosis
1 .
INTRODUCTION
Nowadays OWL [ 22 ] has been established as a core standard in the Semantic Web . It comes in three layers in ascending expressivity , ie , OWL Lite , OWL DL and OWL
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . Distribution of these papers is limited to classroom use , and personal use by others . WWW 2008 , April 21–25 , 2008 , Beijing , China . ACM 978 1 60558 085 2/08/04 .
Full , where the former two coincide semantically with certain description logics ( DLs ) [ 1 ] . A DL based ontology consists of an intensional part and an extensional part . The intensional part consists of a TBox and an RBox , and contains knowledge about concepts and relations ( called roles ) between the elements of the domain . The extensional part consists of an ABox , and contains knowledge about individuals and how they relate to the concepts and roles from the intensional part . In this paper , the knowledge in intensional parts is called axioms , whilst the knowledge in extensional parts is called ABox assertions or simply assertions .
A crucial question in the vision of Semantic Web is how to support and ease the process of creating and maintaining DL based ontologies . An important task within this process is ontology population , which adds instances of concepts and relations to the ontology . In recent years , there has been a great surge of interest in methods for populating ontologies from textual resources . To name a few , Text2Onto [ 3 ] and KITE [ 30 ] are frameworks that integrate algorithms for populating ontologies from textual data . The algorithms include information extraction algorithms that assign annotations carrying some semantics to regions of the data , and co reference algorithms that identify annotated individuals in multiple places . As for populating DL based ontologies , the information extraction process behaves as adding concept/role assertions , whilst the co reference process behaves as adding equality/inequality assertions . The populated ontology , however , may become inconsistent because the information extraction/co reference process is imprecise or the populated data possibly conflict with the original data . In order to repair the populated ontology , we propose to delete a subset of assertions in which the sum of removal costs is minimum , based on the following considerations . First , the intensional part should not be changed , because in general it is well prepared and coherent ( ie , having no unsatisfiable concepts ) before the population . Second , for changing the extensional part , only the deletion of assertions is considered because there is generally no criteria for revising assertions . Third , for deleting assertions , some minimal criteria on removable assertions ( eg , the cost of losing information ) should be considered . Fourth , the certainty information on an assertion , given by the information extraction/coreference process , can be used as the cost of losing information ( called the removal cost ) , because deleting a more certain assertion generally loses more information . Fifth , the
565WWW 2008 / Refereed Track : Semantic / Data Web Semantic Web IApril 21 25 , 2008 · Beijing , China collective removal cost of a set of assertions can be approximated by the sum of removal costs in the set .
Therefore , we in this paper address computing a minimum cost diagnosis for an inconsistent ontology KB , ie a subset of removable assertions whose removal turns KB consistent and in which the sum of removal costs is minimum . We show that , unless P=NP , the problem of finding a minimum cost diagnosis for a DL Lite ontology is insolvable in polynomial time ( PTIME ) wrt data complexity , ie the complexity measured in the size of the ABox only . Note that DL Lite is a fairly inexpressive DL language such that the consistency checking problem for DL Lite ontologies is in PTIME in the size of the ontology [ 2 ] . This complexity result implies that the problem of finding minimum cost diagnoses is in general intractable . In spite of that , we develop a feasible computational method for more general ( ie SHIQ ) ontologies . It transforms a SHIQ ontology to a set of disjoint propositional programs by applying an existing transformation method ( from SHIQ to disjunctive datalog ) [ 12 , 21 ] and new grounding and partitioning techniques . Thus our method reduces the problem of finding a minimum cost diagnosis into a set of independent subproblems . Each such subproblem computes an optimal model and is solvable in O(log2 n ) calls to a satisfiability ( SAT ) solver , by assuming that removal costs have been scaled to positive integers polynomial in n the number of removable assertions .
We implement our method and experiment on several originally consistent , real/benchmark ontologies . Each test ontology has over thousands of assertions . We implement a tool to inject conflicts into a consistent ontology , where a conflict , caused by several inserted assertions , violates a functional restriction or a disjointness constraint . Experimental results show that , even when all assertions are assumed removable , our method can handle all the test ontologies with injected conflicts . Especially , our method scales well on the extended benchmark ontologies with increasing number ( from 1000 ) of conflicts .
2 . RELATED WORK
There are some works that address repairing DL based ontologies . Kalyanpur et al . [ 13 ] extended Reiter ’s Hitting Set Tree ( HST ) algorithm [ 24 ] to compute a minimum rank hitting set , which is a subset of axioms that need to be removed/fixed to correct an unsatisfiable concept , such that the sum of axiom ranks in the subset is minimum . The notion of minimum rank hitting set is similar to that of minimum cost diagnosis , except that the former is on axioms while the latter is on assertions . Schlobach [ 26 ] applied Reiter ’s HST algorithm to compute a minimal subset of axioms that need to be removed/fixed to correct an unsatisfiable concept or an incoherent TBox . The above methods require all minimal conflict sets be computed beforehand , where a minimal conflict set is a minimal subset of axioms responsible for the unwanted consequence . Though the above methods can work with ABoxes as well ( by viewing assertions as axioms ) , it is impractical to adapt them to computing minimum cost diagnoses . First , the problem of finding a minimum hitting set from minimal conflict sets is intrinsically intractable [ 15 ] . Second , though there exist efficient methods for computing a minimal conflict set ( eg , [ 27 , 14 , 20] ) , computing all minimal conflict sets is still hard because the number of minimal conflict sets can be exponential in the number of assertions , as shown in the following example .
Example 1 . Let the intensional part consist of two axioms A . ∀P¬A'∀Q¬A and ¬A . ∀PA'∀QA , and the ABox be {A(a1 ) , P ( an , a1 ) , Q(an , a1)} ∪ {P ( ai , ai+1 ) , Q(ai , ai+1 ) | 1 ≤ i ≤ n − 1} , where n is an odd number . Then the ontology is inconsistent , because ¬A(a1 ) is one of its consequences but conflicts with A(a1 ) . The minimal conflict sets over the ABox are of the form {A(a1 ) , U1(a1 , a2 ) , . . . , Un−1(an−1 , an ) , Un(an , a1)} , where Ui is either P or Q . So the number of minimal conflict sets is 2n .
Hence , a method that computes minimum cost diagnoses from minimal conflict sets may work in exponential time and exponential space wrt data complexity ( eg , when it handles an ontology that is the union of the ontology in the above example and the ontology given in the proof of Theorem 2 ) . In contrast , our method works in exponential time ( more precisely , in logarithmic calls to an NP oracle ) and polynomial space wrt data complexity .
There exist some heuristics based methods for repairing DL based ontologies . Schlobach [ 25 ] proposed an approximate approach to computing a subset of axioms whose removal corrects an unsatisfiable concept or an incoherent TBox . Dolby et al . [ 4 ] exploited summarization and refinement techniques to compute a subset of assertions whose removal turns an inconsistent ontology consistent . Their proposed methods , however , cannot guarantee minimality for the set of removed axioms/assertions .
There also exist some methods for revising problematic axioms ( eg , [ 19 , 13 , 16 , 23] ) . But they cannot be adapted to revising assertions , because assertions are assumed atomic in our work . We only consider the deletion of assertions .
As for dealing with inconsistency in DL based ontologies , there is another approach that simply avoids/tolerates the inconsistency and applies a non standard reasoning method to obtain meaningful answers ( eg , [ 11 , 17] ) . We can also adapt our method to this approach , by defining a consistent consequence of an inconsistent ontology as a consequence invariant under all minimum cost diagnoses . This is out of the scope of this paper and is not discussed here .
3 . PRELIMINARIES
3.1 SHIQ and DL Lite
−
The SHIQ description logic [ 10 ] is a syntactic variant of OWL DL [ 22 ] without nominals and concrete domain specifications , but allowing qualified number restrictions . A SHIQ RBox KBR is a finite set of transitivity axioms T rans(R ) and role inclusion axioms R . S , where R and S be the reflexive transitive closure of {R . are roles . Let .∗ S , Inv(R ) . Inv(S ) | R . S ∈ KBR} , where Inv(R ) = R − and Inv(R ) = R for a role R . A role S is simple if there is S and either T rans(R ) ∈ KBR or no role R such that R .∗ T rans(Inv(R ) ) ∈ KBR . The set of SHIQ concepts is the smallest set containing ( , ⊥ , A , ¬C , C ' D , C D , ∃R.C , ∀R.C , ≤n S.C and ≥n S.C , where A is a concept name ( ie an atomic concept ) , C and D SHIQ concepts , R a role , S a simple role , and n a positive integer . A SHIQ TBox KBT is a finite set of concept inclusion axioms C . D , where C and D are SHIQ concepts . A SHIQ ABox KBA is a set of concept assertions C(a ) , role assertions R(a , b ) , equality assertions a ≈ b and inequality assertions a ffi≈ b , where C is a SHIQ concept , R a role , and a and b individuals . A SHIQ ontology KB is a triple ( KBR , KBT , KBA ) , where
566WWW 2008 / Refereed Track : Semantic / Data Web Semantic Web IApril 21 25 , 2008 · Beijing , China −
KBR is an RBox , KBT a TBox , and KBA an ABox . In this paper , by KB we simply denote ( KBR , KBT , KBA ) if there is no confusion . DL Lite [ 2 ] is a sub language of SHIQ . The set of DL , ¬B Lite concepts is the smallest set containing A , ∃R , ∃R and C1 ' C2 , where A is a concept name , R a role name , B a basic concept ( ie a concept of the form A , ∃R or ∃R − ) , and C1 and C2 DL Lite concepts . ∃R is actually an unqualified existential restriction ∃R( A DL Lite ontology KB = ( KBT , KBA ) consists of a TBox KBT and an ABox KBA . KBT is a finite set of inclusion axioms B . C and functionality axioms ( func R ) and ( func R ) , where B is a basic concept , C a DL Lite concept and R a role . KBA is a set of concept assertions B(a ) and role assertions R(a , b ) , where B is a basic concept , R a role , and a and b individuals . The semantics of a SHIQ ontology KB is given by a mapping π that translates KB into first order logic . Due to space limitation , we refer readers to [ 12 ] for the definition of π . KB is said to be consistent/satisfiable if there exists a first order model of π(KB ) . The semantics of a DL Lite ontology KB can still be given by the same mapping π , because a functionality axiom ( func R ) is a syntactic variant of ( .≤1 R( Note that the unique name assumption ( UNA ) [ 1 ] on individuals is applied in DL Lite but not in SHIQ . UNA can be explicitly axiomatized by appending to the ABox all inequality assertions a ffi≈ b for any two individuals a and b that have different URIs .
−
In our work we assume that all concept assertions are attached to atomic concepts only , due to the following reasons . First , the representation of non atomic concept assertions is not supported by the RDF/XML syntax of OWL ( cf . http://wwww3org/TR/owl ref ) , which is the main syntax for representing DL based ontologies nowadays . Second , a non atomic concept assertion C(a ) can be reduced to an atomic one by replacing C(a ) with Q(a ) and appending C ≡ Q to the TBox , where Q is a new atomic concept .
3.2 Disjunctive Datalog A disjunctive datalog program with equality [ 6 ] P is a finite set of rules without function symbols of the form A1 ∨ . . . ∨ An ← B1 , . . . , Bm ( where Ai and Bi are atoms ) . Each rule must be safe , ie , each variable occurring in a head atom Ai must occur in some body atom Bj . For a rule r , the set of head atoms is denoted by head(r ) , whereas the set of body atoms is denoted by body(r ) . A rule r is called a constraint if |head(r)| = 0 ; a fact if |body(r)| = 0 . An atom is called negated if it leads with negation as failure . Typical definitions of a disjunctive datalog program , such as [ 6 ] , allow negated atoms in the body . In our work , negated atoms cannot occur in a transformed program that we consider , so we omit negation as failure from the definitions . Disjunctive datalog programs without negation as failure are often called positive programs .
The set of all ground instances of rules in P is denoted by ground(P ) . An interpretation M of P is a subset of ground atoms in the Herbrand base of P . An interpretation M is called a model of P if ( i ) body(r ) ⊆ M implies head(r ) ∩ M ffi= ∅ for each rule r ∈ ground(P ) , and ( ii ) all atoms from M with the equality predicate ≈ yield a congruence relation , ie a relation that is reflexive , symmetric , transitive , and T ( a1 , . . . , ai , . . . , an ) ∈ M and ai ≈ bi ∈ M imply T ( a1 , . . . , bi , . . . , an ) ∈ M for each predicate symbol T in P . P is said to be satisfiable if it has a model .
3.3 Reducing SHIQ to Disjunctive Datalog
Since SHIQ is a subset of first order logic , SHIQ axioms can first be translated into logical formulas , then into clausal form . The resulting clauses can be represented as disjunctive rules without negation as failure . However , due to possible skolemization steps in the clausal form translation , the resulting rules may contain function symbols . Standard logic program engines , however , may not terminate in the presence of function symbols . To cope with this problem , Hustadt et al . [ 12 , 21 ] developed the KAON2 transformation method to get rid of function symbols without losing ABox consequences . The method reduces a SHIQ ontology KB to a positive disjunctive datalog program DD(KB ) = Γ(KBR , KBT ) ∪ Ξ(KBA ) ∪ Δ(KB ) . Γ(KBR , KBT ) is a set of disjunctive datalog rules computed from the intensional part of KB by translating SHIQ axioms into clauses , adding logical consequences , and translating clauses into disjunctive datalog rules . Ξ(KBA ) is a set of facts translated from KBA , where each inequality assertion ( of the form a ffi≈ b ) is translated into a ground constraint ( of the from ← a ≈ b ) , and other assertions are directly translated into ground facts . Δ(KB ) is a set of facts of the form HU ( a ) , HU ( af ) and Sf ( a , af ) , which are introduced to remove function symbols and instantiated for each individual a occurring in KB and each function symbol f .
Theorem 1
( [21] ) . For KB a SHIQ ontology , KB is unsatisfiable if and only if DD(KB ) is unsatisfiable .
4 . MINIMUM COST DIAGNOSIS
Given a possibly inconsistent SHIQ ontology KB in which some assertions are removable and assigned removal costs , our goal is to find a subset of removable assertions whose removal turns KB consistent and in which the sum of removal costs is minimum . Such subset is called a minimum cost diagnosis , formally defined below .
Definition 1 . Let KB be a possibly inconsistent SHIQ ontology and RKB ⊆ KBA a set of removable assertions such that each assertion α ∈ RKB is given a removal cost c(α ) > 0 . Then , a subset of assertions R ⊆ RKB is called a diagnosis for KB wrt RKB if ( KBR , KBT , KBA \ R ) is consistent . A diagnosis R is called a minimum cost diagnosis for KB wrt RKB if there is no diagnosis R for KB wrt α∈R c(α ) . R is simply called RKB such that a diagnosis/minimum cost diagnosis if KB and RKB are clear from the context .
α∈R . c(α ) <
.
. fi
We consider the time complexity for finding a minimum cost diagnosis . Complexity results in this paper refer to data complexity , ie the complexity measured as a function of the number of assertions in the ontology . Theorem 2 shows that , unless P=NP , there is no polynomial time algorithm for finding a minimum cost diagnosis for a DL Lite ontology KB wrt KBA . It implies that the problem of finding minimum cost diagnoses for SHIQ ontologies is in general intractable .
Theorem 2 . Given a positive integer k and a possibly inconsistent DL Lite ontology KB = ( KBT , KBA ) where each assertion α ∈ KBA is given a removal cost c(α ) = 1 , deciding if there is a diagnosis R for KB wrt KBA such that
α∈R c(α ) ≤ k is NP hard wrt data complexity .
.
567WWW 2008 / Refereed Track : Semantic / Data Web Semantic Web IApril 21 25 , 2008 · Beijing , China fi
−
Proof . Given an arbitrary instance I of the SAT problem , we transform it into an instance I of the given decision problem . Let I be the formula f = C1 ∧ . . . ∧ Cm with m fi clauses and n boolean variables x1 , . . . , xn . We construct I as follows . ( 1 ) KBT consists of the following axioms : − ( func S
∃T . ¬∃S , ∃T
− . ¬∃S
( func T
( 2 ) For each boolean variable xi in f , KBA contains a corresponding constant ai . ( 3 ) For each clause Cj containing nj literals lj,1 , . . . , lj,nj whose corresponding constants in KBA , introduced in ( 2 ) , are aj,1 , . . . , aj,nj respectively , KBA contains a corresponding constant cj for Cj and nj assertions U ( aj,1 , cj ) , . . . , U ( aj,nj , cj ) , where U ( aj,k , cj ) is T ( aj,k , cj ) if lj,k is positive , or S(aj,k , cj ) otherwise . ( 4 ) Let k = j=1(nj − 1 ) .
.m
−
) ,
,
) .
Now we prove that f is satisfiable if and only if there is a diagnosis R for KB = ( KBT , KBA ) wrt KBA such that . a∈R c(a ) ≤ k , ie , |R| ≤ k . ( ⇒ ) Since f is satisfiable , for each clause Cj there is a literal lj,k assigned true . We append to R all assertions in KBA of the form U ( aj,p , cj ) ( p ffi= k ) , where U ( aj,p , cj ) is T ( aj,p , cj ) if lj,p is positive , or S(aj,p , cj ) otherwise . Clearly , R is a diagnosis for KB wrt KBA such that |R| ≤ k . ( ⇐ ) Suppose R is a diagnosis for KB wrt KBA such that |R| ≤ k . It is not hard to see that any set of assertions of the form U ( aj,k , cj ) ( U is either T or S ) must have exactly nj − 1 assertions in R and one in KBA \ R . To see that f is satisfiable , for each U ( aj,k , cj ) ∈ KBA \ R ( j = 1 , . . . , m ) , if U is T , we assign xj,k ( ie the corresponding variable of aj,k in f ) true ; otherwise we assign xj,k false . The above ( partial ) assignment on {x1 , . . . , xn} is consistent and ensures lj,k = true for all j = 1 , . . . , m . Thus f is satisfiable .
Since the construction of KB is accomplished in PTIME and the SAT problem is NP complete , and since KBT has a fixed size , this theorem follows .
5 . COMPUTING MINIMUM COST
DIAGNOSES
As analyzed in related work , a method that computes minimum cost diagnoses based on minimal conflict sets is impractical , because it may require both exponential time and exponential space . We thus consider methods that need not compute minimal conflict sets . A na¨ıve method is the black box method , which searches minimum cost diagnoses over all subsets of removal assertions by applying a DL reasoner to check diagnoses . However , the black box method cannot compute a minimum cost diagnosis for a DL Lite ontology in polynomial calls to a DL reasoner , otherwise a minimum cost diagnosis can be computed in PTIME wrt data complexity , contradicting Theorem 2 . In order to find a practical computational method , we consider transforming the input ontology KB into a positive program Π such that for any subset S of RKB the set of removable assertions , ) = 1 | KB \ S is consistent if and only if Π ∪ {assign(α − ) = 0 | α ∈ RKB \ S} is satisfiable , α ∈ S} ∪ {assign(α − where α is a fresh ground atom corresponding to ground atom α in Π , and assign(β ) denotes the 0 1 truth value of β . Then , a minimum cost diagnosis corresponds to a valuation of X such that ) is minimum and Π is satisfiable , where X = {α
α−∈X c(α ) · assign(α −
− | α ∈ RKB} .
.
−
To find such a valuation of X , we need to handle pseudoi cixi ≤ d boolean constraints ( PB constraints ) of the form with constants ci , d ∈ Z and variables xi ∈ {0 , 1} , or a linear
.
. i cixi with optimization function of the form minimize constants ci ∈ Z and variables xi ∈ {0 , 1} , where Z denotes the integer domain . The SAT problems with PB constraints and linear optimization functions are well studied in the SAT community ( cf . http://wwwcriluniv artoisfr/PB07/ ) A SAT problem with linear optimization functions can be translated into a set of SAT problems with PB constraints . A SAT problem with PB constraints can be either solved by standard SAT solvers after translating PB constraints to SAT clauses [ 5 ] , or solved by extended SAT solvers that support PB constraints natively ( eg , PUEBLO [ 28] ) . Now , the remaining problems are how to transform a SHIQ ontology to the intended positive program and how to efficiently compute minimum cost diagnoses . We address these problems in the following subsections . 5.1 Constructing a Repair Program
Given a possibly inconsistent SHIQ ontology KB , we first employ the KAON2 transformation method [ 12 , 21 ] , described in Preliminaries , to reduce KB to a disjunctive datalog program DD(KB ) = Γ(KBR , KBT ) ∪ Ξ(KBA ) ∪ Δ(KB ) , but introduce a special treatment . The original KAON2 transformation method allows equality atoms ( of the form X ≈ Y or a ≈ b , where X , Y denote variables and a , b denote constants ) to occur in rule bodies in DD(KB ) while disallows inequality atoms ( of the form X ffi≈ Y or a ffi≈ b ) to occur in DD(KB ) . To handle inequality assertions in a similar way as other assertions , we first move equality atoms ( X ≈ Y or a ≈ b ) in any rule body in DD(KB ) to the corresponding rule head and replace them with inequality atoms ( X ffi≈ Y or a ffi≈ b ) , then append to DD(KB ) a constraint ← X ≈ Y , X ffi≈ Y ( written Rff≈ ) , so that Ξ(KBA ) is simplified to a direct translation from assertions in KBA to ground facts in DD(KB ) . Having such treatment we simply denote Ξ(KBA ) as KBA . The modified rules in DD(KB ) are still safe due to the restricted form of the original rules that have equality atoms in the body . In essence , our treatment views an inequality atom as an ordinary one and does not impact the satisfiability of DD(KB ) . Then , we convert DD(KB ) to a repair program R(KB ) defined below . Intuitively , the decision atom α is introduced to weaken KB , so that α = false ) implies that α is re= true ( resp . α moved from ( resp . kept in ) KB . Note that decision atoms in R(KB ) are treated as nullary ground atoms .
− −
−
Definition 2 . For KB a possibly inconsistent SHIQ ontology and RKB ⊆ KBA a set of removable assertions such that each assertion α ∈ RKB is given a removal cost c(α ) > 0 , a repair program of KB wrt RKB , written R(KB ) , is a disjunctive datalog program converted from DD(KB ) as follows : for each assertion α ∈ RKB , we introduce a corresponding decision atom α ) = c(α ) , then replace the ground fact α in DD(KB ) with α∨α − . We simply call R(KB ) a repair program if RKB is clear from the context . and give it a cost c(α
−
−
Example 2 . Let A , E , H , P , S , T , me and pa abbreviate Artif icer , Engineer , Human , P rof essor , Student , T eacher , mentor and parent respectively . Given a SHIQ ontology KB = ( ∅ , KBT , KBA ) , where KBT = {S .≤1 me ' ∃me.P ' H , H . ∀pa.H , P . E , ∃me.E . ¬A , E . ¬T} and KBA = {S(s1 ) , S(s2 ) , me(s1 , t1 ) , me(s1 , t2 ) , A(s2 ) , T ( t1 ) , T ( t2 ) , T ( p1 ) , E(p2 ) , pa(s1 , p1 ) , pa(s2 , p1 ) , t1 ffi≈ t2 , p1 ≈ p2} , and a set of removable assertions RKB =
568WWW 2008 / Refereed Track : Semantic / Data Web Semantic Web IApril 21 25 , 2008 · Beijing , China {S(s2 ) , A(s2 ) , T ( t1 ) , T ( t2 ) , E(p2 ) , t1 ffi≈ t2 , p1 ≈ p2} such that c(α ) = 1 for each assertion α ∈ RKB , we construct the repair program R(KB ) as follows .
Y1 ≈ Y2 ← S(X ) , me(X , Y1 ) , me(X , Y2 ) . P ( Xf ) ← S(X ) , Sf ( X , Xf ) .
First , by applying the KAON2 transformation method with our special treatment , we reduce KB to DD(KB ) = Γ(KBR , KBT ) ∪ {Rff≈} ∪ KBA ∪ Δ(KB ) , where Δ(KB ) = {Sf ( s1 , s1f ) , Sf ( s2 , s2f ) , Sf ( t1 , t1f ) , Sf ( t2 , t2f ) , Sf ( p1 , p1f )} and Γ(KBR , KBT ) = {R1 , . . . , R9} as given below . R1 : R2 : R3 : me(X , Xf ) ← S(X ) , Sf ( X , Xf ) . R4 : H(X ) ← S(X ) . R5 : H(Y ) ← H(X ) , pa(X , Y ) . E(X ) ← P ( X ) . R6 : R7 : ← A(X ) , me(X , Y ) , E(Y ) . R8 : ← T ( X ) , E(X ) . R9 : ← A(X ) , S(X ) . Then , by introducing decision atoms and converting ground facts in DD(KB ) , we obtain R(KB ) = {R1 , . . . , R9 , Rff≈}∪ Δ(KB ) ∪ {S(s1 ) , me(s1 , t1 ) , me(s1 , t2 ) , T ( p1 ) , pa(s1 , p1 ) , pa(s2 , p1 ) , S(s2 ) ∨ S(s2 ) , T ( t1 ) ∨ T ( t1 ) − , T ( t2 ) ∨ T ( t2 ) , ( t1 ffi≈ t2 ) ∨ ( t1 ffi≈ t2 ) − , −} . ( p1 ≈ p2 ) ∨ ( p1 ≈ p2 )
, E(p2 ) ∨ E(p2 )
, A(s2 ) ∨ A(s2 )
−
−
−
−
There exists a correspondence between minimum cost diagnoses for KB wrt RKB and X MC models of R(KB ) , − | α ∈ RKB} ( see Theorem 3 ) . A model where X = {α M of a positive program P is called an X MC model of P β∈M.∩X c(β ) < if there is no model M . β∈M∩X c(β ) , where X is a set of ground atoms and c is a of P such that
. fi predefined cost function over X .
− | α ∈ RKB} .
Theorem 3 . Let KB be a SHIQ ontology , RKB ⊆ KBA a set of removable assertions such that each assertion α ∈ RKB is given a removal cost c(α ) > 0 , R(KB ) a repair program of KB wrt RKB , and X = {α ( Soundness ) For each X MC model M of R(KB ) , {α | − ∈ M} is a minimum cost diagnosis for KB wrt RKB ; α ( Completeness ) For each minimum cost diagnosis R for KB wrt RKB , there exists an X MC model M of R(KB ) such that R = {α | α Proof sketch . ( Soundness ) Let M be an X MC model −|α ∈ R} . − ∈ M} and M of R(KB ) , R = {α | α is a model of DD(KB)\R . By Thefi It can be shown that M orem 1 , R is diagnosis of KB wrt RKB . Further , R must be a minimum cost diagnoses , otherwise it can be shown that ) < there exists a model M . of R(KB ) st
= M \ {α
− ∈ M} .
α−∈M∩X c(α
α−∈M∩X c(α ( Completeness ) Let R be a minimum cost diagnosis for KB wrt RKB . By Theorem 1 , DD(KB ) \ R is satisfiable fi and thus has a model , say M . It can be shown that M = M ∪ {α − | α ∈ R} is a model of R(KB ) . Further , M fi must be an X MC model of R(KB ) , otherwise it can be for KB wrt RKB shown that there exists a diagnosis R st 5.2 Computing X MC Models
α∈R . c(α ) <
α∈R c(α ) .
.
.
.
−
−
) . fi fi fifi
By Theorem 3 , the problem of finding minimum cost diagnoses for KB wrt RKB is reduced to the problem of computing X MC models of R(KB ) , which can be realized by applying SAT solvers . However , SAT solvers take a positive propositional program as input and do not distinguish equality atoms from other atoms . To treat the equality predicate ≈ , which is interpreted as a congruence relation , as an ordinary predicate , we use a well known transformation from [ 8 ] . For a disjunctive datalog program P , let P≈ denote the program consisting of the rules stating that the equality predicate is reflexive , symmetric and transitive , and the replacement rules given below , instantiated for each predicate T in P ( excluding ≈ ) and each position i . Note that the reflexive rule is not safe and is instead represented as a set of ground facts of the form a ≈ a , instantiated for each constant a in P . Then , appending P≈ to P allows to treat ≈ as an ordinary predicate . T ( X1 , . . . , Yi , . . . , Xn ) ← Xi ≈ Yi , T ( X1 , . . . , Xi , . . . , Xn ) . For the input issue , we need to ground R(KB ) before applying SAT solvers . A well known grounding technique is intelligent grounding ( IG ) [ 7 ] , which only applies to equalityfree disjunctive datalog programs . That is , if the equality predicate ≈ is present in a disjunctive datalog program P , we must append P≈ to P before grounding P using the IG technique . The IG technique has been implemented in a disjunctive datalog engine DLV [ 18 ] , but the current implementation cannot handle large disjunctive datalog programs due to memory limitation1 , especially when the equality predicate is present . On the other hand , current implementations of SAT solvers lack scalability for large propositional programs . To address these problems , we develop two diskbased algorithms for grounding R(KB ) to Π(KB ) and for partitioning Π(KB ) to disjoint subprograms respectively , so that the computation of minimum cost diagnoses can be separately performed over each subprogram .
Algorithm 1 is our algorithm for grounding a repair program P . By Mdef we denote the unique minimal model of the definite fragment of P , ie {R ∈ P | |head(R)| = 1} . C is actually the set of congruence classes {C1 , . . . , Cm} occurring in P , where Ci = {b | a ≈ b ∈ Mdef} for an arbitrary constant a occurring in some equality atom in Mdef that is not of the form a ≈ a . fc(a,C ) denotes the congruence class in C that contains constant a . minc(C ) denotes the constant a ∈ C having the smallest value in {occ(a ) | a ∈ C} , where occ(a ) is the occurrence order of a in P . Ddef is actually a set of non equality atoms in Mdef such that for each non equality atom T ( a1 , . . . , ak ) ∈ Mdef , there exists a unique ground atom T ( b1 , . . . , bk ) ∈ Ddef such that for each i = 1 , . . . , k , ai and bi are either the same or together in some C ∈ C . D is the set of ground atoms occurring in the grounded program Π .
Let S and S be two sets of ground atoms . S≈ denotes the subset of S consisting of all equality atoms in S ; S\≈ denotes S \ S≈ . For a rule R , the function GetSubstitutes(R , S , fi S ) returns the set of all ground substitutes σ such that body(Rσ ) ⊆ S , head(Rσ)\≈ ∩ S = ∅ and head(Rσ)≈ does not contain equality atoms of the form a ≈ a . The function Rewrite(S , C ) rewrites all constants a in S such that fc(a,C ) exists to minc(fc(a,C) ) , and returns the modified S . fi fi
The algorithm consists of three steps . Step 1 ( lines 1–13 ) computes Mdef in a standard iterative manner , but represents Mdef as Ddef and C . Step 2 ( lines 14–16 ) rewrites the constants occurring in disjunctive ground facts ( of the form α ∨ α − ) in P , because some constants occurring in α 1The current implementation with DB support , DLVDB ( http://wwwmatunicalit/terracina/dlvdb/ ) , does not work with DBs if the input program has disjunctions .
569WWW 2008 / Refereed Track : Semantic / Data Web Semantic Web IApril 21 25 , 2008 · Beijing , China are represented by other constants in step 1 . At a word , in step 1 and step 2 , all constants in a congruence class are replaced with a same constant , so as to reduce the number of instantiated rules in step 3 . Step 3 ( lines 17–26 ) grounds P + , ie P ∪ P≈ excluding the definite ground facts , in a standard iterative manner based on Mdef . Each instantiated rule r such that head(r ) ∩ Mdef ffi= ∅ is ignored ( line 22 ) , because r has no impact on computing models of P . If a ffi≈ b ∈ Ddef , the equality atom a ≈ b in an instantiated rule head is not appended to D ( line 24 ) , because it cannot occur in any model of P . The ground atoms in Mdef are removed from the body of any instantiated rule ( lines 25– 26 ) , because they are in every model of P . Note that the function GetSubstitutes can be realized by applying a SQL engine and its results can be stored in disk , so the algorithm In what follows , by Π(KB ) we denote the is disk based . grounded repair program returned by Ground(R(KB) ) .
Algorithm 1 . Ground(P ) Input : A repair program P . Output : A set C of sets of constants and a positive propositional def def do program Π . C := ∅ ; Ddef := ∅ ; Dfi def := {⊥} ; // to enforce Ddef '= Dfi that are not together in some C ∈ C then
1 . 2 . while Ddef '= Dfi def := Ddef ; Dfi 3 . for each rule R ∈ P st |head(R)| = 1 do 4 . Θ := GetSubstitutes(R , Ddef , Ddef ) ; 5 . for each σ sequentially retrieved from Θ do 6 . 7 . 8 .
Ddef := Rewrite(Ddef , C ) ; // executed once for Θ
Ddef := Ddef ∪ head(Rσ)\≈ ; if head(Rσ)≈ = {a ≈ b} for some constants a and b if fc(a , C ) does not exist then Set fc(a , C ) as {a} ; if fc(b , C ) does not exist then Set fc(b , C ) as {b} ; C := fc(a , C ) ∪ fc(b , C ) ; C := ( C \ {fc(a , C ) , fc(b , C)} ) ∪ {C} ;
9 . 10 . 11 . 12 . 13 . 14 . for each disjunctive ground fact α ∨ α − ) st fc(a , C ) exists do 15 . ) to minc(fc(a , C) ) ; 16 . 17 . P + := {R ∈ P ∪ P≈ | |head(R)| > 1 or R is non ground} ; 18 . Π := ∅ ; D := Ddef ∪ {a ≈ a | a occurs in P} ; Dfi 19 . while D '= Dfi do 20 . 21 . 22 . 23 . 24 .
:= D ; Θ := GetSubstitutes(R , D , Ddef ) ; for each σ sequentially retrieved from Θ do
Dfi for each rule R ∈ P + do
D := D ∪ head(Rσ)\≈ ∪ {a ≈ b ∈ head(Rσ)≈ | a '≈ B := body(Rσ ) \ ( Ddef ∪ {a ≈ a | a occurs in Rσ} ) ; Π := Π ∪ {fi head(Rσ ) ← ' for each constant a in α ( or α
Rewrite a in α ( or α b '∈ Ddef} ; in P do
:= ∅ ;
B} ;
−
−
25 . 26 . 27 . return ( C , Π ) ;
Example 3 . Continue with Example 2 . We now demonstrate how Ground(R(KB ) ) works . In step 1 , we compute the unique minimal model Mdef of R(KB)def in an iterative manner , obtaining C = {{t1 , t2 , s1f}} and Ddef = {S(s1 ) , me(s1 , t1 ) , T ( p1 ) , pa(s1 , p1 ) , pa(s2 , p1 ) , Sf ( s1 , t1 ) , P ( t1 ) , H(s1 ) , H(p1 ) , E(t1 ) , Sf ( s2 , s2f ) , Sf ( t1 , t1f ) , Sf ( t1 , t2f ) , Sf ( p1 , p1f )} . In step 2 , according to C , we replace the set of disjunctive ground facts in R(KB ) with {S(s2 ) ∨ S(s2 ) − , A(s2 ) ∨ A(s2 ) , T ( t1 ) ∨ T ( t1 ) , ( t1 ffi≈ − t1 ) ∨ ( t1 ffi≈ t1 ) , ( p1 ≈ p2 ) ∨ ( p1 ≈ p2 ) − In step 3 , we ground R(KB ) ∪ R(KB)≈ ( excluding the definite ground
, E(p2 ) ∨ E(p2 )
−} .
−
−
.
− facts ) in an iterative manner , obtaining a propositional program Π(KB ) = {r1 , . . . , r22} , where r14 is instantiated from ← X ≈ Y , X ffi≈ Y ( ie Rff≈ ) , r15 , . . . , r20 are instantiated from R(KB)≈ . Note that for instantiating a rule that contains X ≈ Y in the body , we only consider all ground substitutes σ such that occ(Xσ ) ≤ occ(Y σ ) , where occ(a ) is the occurrence order of constant a in R(KB ) . r1 : S(s2 ) ∨ S(s2 ) r3 : ( t1 ffi≈ t1 ) ∨ ( t1 ffi≈ t1 ) − . r5 : ( p1 ≈ p2 ) ∨ ( P1 ffi≈ p2 ) − r7 : P ( s2f ) ← S(s2 ) . r9 : H(s2 ) ← S(s2 ) . r11 :← A(s2 ) , me(s2 , s2f ) , E(s2f ) . r13 :← A(s2 ) , S(s2 ) . r15 : p2 ≈ p1 ← p1 ≈ p2 . r17 : E(p2 ) ← p1 ≈ p2 , E(p1 ) . r19 : E(p1 ) ← p1 ≈ p2 , E(p2 ) . r21 :← E(p1 ) . r2 : A(s2 ) ∨ A(s2 ) − . r4 : T ( t1 ) ∨ T ( t1 ) − . r6 : E(p2 ) ∨ E(p2 ) − r8 : me(s2 , s2f ) ← S(s2 ) . r10 : E(s2f ) ← P ( s2f ) . r12 :← T ( t1 ) . r14 :← t1 ffi≈ t1 . r16 : T ( p2 ) ← p1 ≈ p2 . r18 : pa(s1 , p2 ) ← p1 ≈ p2 . r20 : pa(s2 , p2 ) ← p1 ≈ p2 . r22 :← T ( p2 ) , E(p2 ) .
.
.
Algorithm 2 . Partition(Π , X )
Input : A positive propositional program Π and a set X of ground atoms occurring in Π .
Set map(α ) as 0 for all ground atoms α occurring in Π ;
Output : A set of disjoint subprograms of Π . 1 . 2 . Move constraints in Π in front of other rules in Π ; k := 0 ; 3 . 4 . 5 . merged := false ; for each rule r sequentially retrieved from Π st head(r ) =
∅ or map(α ) > 0 for all α ∈ head(r ) \ X do repeat for each α ∈ head(r ) ∪ body(r ) st map(α ) = 0 do if |map(r)| > 1 then k := k + 1 ; map(α ) := k ; merged := true ; minid := min(map(r) ) ; for each α ∈ head(r ) ∪ body(r ) do map(α ) := minid ;
6 . 7 . 8 . 9 . 10 . 11 . until not merged ; 12 . for i = 1 , . . . , k do 13 . 14 . return {Πi '= ∅ | 1 ≤ i ≤ k} ;
Πi := {r ∈ Π | ∀α ∈ head(r ) ∪ body(r ) : map(α ) = i} ;
Algorithm 2 is our algorithm for partitioning a positive propositional program Π based on a set X of ground atoms occurring in Π . The basic idea is to filter out rules that have no impact on M ∩ X when constructing an X MC model M of Π and put together remaining rules that have common ground atoms to form disjoint subprograms . In the algorithm , each ground atom α occurring in Π is mapped to a partition identifier map(α ) . For a rule r , we use map(r ) to denote {map(α ) | α ∈ head(r ) ∪ body(r)} . To simplify explanation , we call a rule r ∈ Π ready if head(r ) = ∅ or map(α ) > 0 for all α ∈ head(r ) \ X . Before a ground atom is detected in some ready rule , it is mapped to 0 ( line 1 ) . To process ready rules as early as possible , constraints ( which are ready rules ) are moved in front of other rules in Π ( line 2 ) . Then , {map(α ) | α occurs in Π} is adjusted in an iterative manner until {map(r ) | r ∈ Π} reaches a fixpoint ( lines 3–11 ) . Each ground atom α first detected in ready rules is initially mapped to a unique partition identifer ( lines 6–7 ) . All ground atoms in a ready rule r are mapped to the same partition identifier ( lines 8–10 ) . After the loop is finished , all ready rules in Π mapped to the same partition identifier are put together , yielding a set of nonempty subprograms {Πi}1≤i≤n ( lines 12–13 ) .
570WWW 2008 / Refereed Track : Semantic / Data Web Semantic Web IApril 21 25 , 2008 · Beijing , China It can be seen that the number of iterations ( lines 3–11 ) is at most |Π| , because the mapping adjustment ( lines 9–10 ) ensures that in each iteration , a ready rule rm having the smallest value of min(map(r ) ) among {r ∈ Π | r is ready and |map(r)| > 1} must reach a state that |map(rm)| = 1 and that map(rm ) is unchanged in subsequent iterations . Furthermore , Π0 = Π\ffn i=1 Πi is the intended set of filtered rules ( see Lemma 1 ) ; Πi and Πj contain no common ground atoms for all 1 ≤ i < j ≤ n . Since Π is sequentially accessed in each iteration , the algorithm is also disk based . fi r∈Π0 ff P , M
= M ∪ ff fi ∩ X . Proof . Let M0 =
Lemma 1 . Let P be the set of subprograms returned by Partition(Π , X ) and Π0 = Π \ ff P . For any X MC {α ∈ head(r ) | α ffi∈ model M of X , map(α ) = 0} is an X MC model of Π such that M ∩ X = M {α ∈ head(r ) | α ffi∈ X , map(α ) = 0} . Since M0 ∩ head(r ) ffi= ∅ for every r ∈ Π0 , M = M ∪ M0 satisfies every rule in Π0 . Moreover , since map(α ) > 0 for ff P , M0 ∩ M = ∅ and every ground atom α occurring in ff P as M . It follows that thus M still satisfies every rule in is an X MC M model of Π such that M ∩ X = M fi ∩ X . is a model of Π . Since M0 ∩ X = ∅ , M r∈Π0 ff fi fi fi fi
−
− 10:1 .
Example 4 . Continue with Example 3 . Let X ' be the set in Π(KB ) . We now demonof ground atoms of the form α strate how Partition(Π(KB ) , X ' ) works . We first move r11 , . . . , r14 , r21 , r22 in front of other rules in Π(KB ) , then map each ground atom in Π to a partition identifier . In the first iteration for processing rules r ∈ Π , map(r ) is set as follows ( for every ground atom α , αj:k denotes map(α ) = j before processing r at line 8 in Algorithm 2 , and map(α ) = k after the first iteration ) . r11 :← A(s2)1:1 , me(s2 , s2f )2:1 , E(s2f )3:1 . r12 :← T ( t1)4:4 . r14 :← ( t1 ffi≈ t1)6:6 . r13 :← A(s2)1:1 , S(s2)5:1 . r22 :← T ( p2)8:7 , E(p2)9:7 . r21 :← E(p1)7:7 . r2 : A(s2)1:1 ∨ A(s2 ) r1 : S(s2)1:1 ∨ S(s2 ) − 11:1 . r3 : ( t1 ffi≈ t1)6:6 ∨ ( t1 ffi≈ t1 ) r4 : T ( t1)4:4 ∨ T ( t1 ) − − 12:6 . 13:4 . 15:7 . r6 : E(p2)8:7 ∨ E(p2 ) r5 : ( p1 ≈ p2)14:7 ∨ ( p1 ≈ p2 ) − − 16:7 . r7 : P ( s2f )0:1 ← S(s2)1:1 . r8 : me(s2 , s2f )1:1 ← S(s2)1:1 . r9 : H(s2)0:0 ← S(s2)1:1 . r10 : E(s2f )1:1 ← P ( s2f )17:1 . r15 : ( p2 ≈ p1)0:0 ← ( p1 ≈ p2)14:7 . r16 : T ( p2)8:7 ← ( p1 ≈ p2)14:7 . r17 : E(p2)8:7 ← ( p1 ≈ p2)8:7 , E(p1)7:7 . r18 : pa(s1 , p2)0:0 ← ( p1 ≈ p2)7:7 . r19 : E(p1)7:7 ← ( p1 ≈ p2)7:7 , E(p2)7:7 . r20 : pa(s2 , p2)0:0 ← ( p1 ≈ p2)7:7 . In the second iteration , it is detected that |map(r)| = 1 for all ready rules r ∈ Π , so the loop is finished . Finally we obtain four disjoint subprograms from the resulting mapping : Π1 = {r11 , r13 , r1 , r2 , r7 , r8 , r10} , Π2 = {r12 , r4} , Π3 = {r14 , r3} and Π4 = {r21 , r22 , r5 , r6 , r16 , r17 , r19} .
− In what follows , we call a ground atom of the form α a translated decision atom . Let C be the set of congruence classes returned by Ground(R(KB) ) , and {Πi}1≤i≤n the set of subprograms returned by Partition(Π(KB ) , X ' ) , where X ' is the set of translated decision atoms occurring in Π(KB ) . We intend to compute X MC models of R(KB ) over each of {Πi}1≤i≤n , where X is the set of decision atoms occurring in R(KB ) . However , some decision atoms are rei=1 Πi , because all constants in placed with other atoms in a congruence class in C are replaced with a same constant . ffn fi fi fi
−
−
.
) =
Let X ffn i=1 Πi . X
) , where bi
− ∈ X
( T ( a1 , . . . , ak )
T ( b1,,bk)−∈X,b1 .=C a1,,bk be the set of translated decision atoms occurring in is said to be soundly converted from X wrt C if each ground atom T ( a1 , . . . , ak ) has been given a fi .=C ak cost c . =C ai means that constants bi c(T ( b1 , . . . , bk ) and ai are the same or together in some C ∈ C . Such conver− sion is reasonable because all decision atoms T ( b1 , . . . , bk ) ∈ X such that b1 − . =C ak for some T ( a1 , . . . , ak ) ∈ X must be present or absent together in every model of R(KB ) . Moreover , given a subset S of X , we define a decoding of S wrt X and C , written d(S , X,C ) , as {T ( b1 , . . . , bk ) − ∈ X | T ( a1 , . . . , ak ) =C ak} . Then , . a minimum cost diagnosis of KB corresponds to a disjoint union of models in each subprogram ( see Theorem 4 ) .
. =C a1 , . . . , bk
. =C a1 , . . . , bk
− ∈ S , b1 fi fi fi fi
−
−
−
−
−
− ff4
( T ( t1 )
, A(s2 )
Example 5 . Continue with Example 4 . Let X be the set of decision atoms in R(KB ) . In i=1 Πi , the set of ground atoms soundly converted from X wrt C = {{t1 , t2 , s1f}} = {S(s2 ) , ( t1 ffi≈ t1 ) , ( p1 ≈ p2 ) − − is X , T ( t1 ) , −} , where each ground atom α − ∈ X fi E(p2 ) is given a cost fi − fi c ) = 2 . Let Xi ( i = 1 , . . . , 4 ) ) = 1 except that c ( α be the subsets of X that occur in Πi . It is easy to see that Π1 has two X1 MC models M1,1 = {S(s2 ) , A(s2)} and , P ( s2f ) , me(s2 , s2f ) , E(s2f )} ; Π2 M1,2 = {S(s2 ) , A(s2 ) −} ; Π3 has a unique has a unique X2 MC model M2 = {T ( t1 ) X3 MC model M3 = {(t1 ffi≈ t1 ) −} ; Π4 has two X4 MC models M4,1 = {(p1 ≈ p2 ) , E(p2)} and M4,2 = {E(p2 ) − , p1 ≈ p2 , T ( p2)} . Hence , d(M1,1 ∩ X1 , X,C ) = {S(s2 ) −} ; −} ; d(M2 ∩ X2 , X , C ) = {T ( t1 ) d(M1,2 ∩ X1 , X , C ) = {A(s2 ) − −} ; d(M4,1∩X4 , X,C ) T ( t2 ) = {(p1 ≈ p2 ) −} . By Theorem 4 , we obtain four minimum cost diagnoses for KB wrt RKB : {S(s2 ) , T ( t1 ) , T ( t2 ) , t1 ffi≈ t2 , p1 ≈ p2} , {A(s2 ) , T ( t1 ) , T ( t2 ) , t1 ffi≈ t2 , p1 ≈ p2} , {S(s2 ) , T ( t1 ) , T ( t2 ) , t1 ffi≈ t2 , E(p2)} and {A(s2 ) , T ( t1 ) , T ( t2 ) , t1 ffi≈ t2 , E(p2)} .
−} ; d(M4,2 ∩ X4 , X , C ) = {E(p2 )
−} ; d(M3∩X3 , X,C ) = {(t1 ffi≈ t2 )
− fi fi ffn that occur in Π1 , . . . , Πn respectively . i=1 d(Mi ∩ Xi , X,C)} is a minimum cost diag
Theorem 4 . For KB a SHIQ ontology and RKB ⊆ KBA a set of removable assertions such that each assertion α ∈ RKB is given a removal cost c(α ) > 0 , suppose Ground(R(KB ) ) returns ( C , Π(KB ) ) and Partition(Π(KB ) , X ' ) returns {Πi}1≤i≤n , where X ' is the set of translated decision atoms occurring in Π(KB ) . Let X be the set of transi=1 Πi which is soundly lated decision atoms occurring in − | α ∈ RKB} , and X1 , . . . , Xn be converted from X = {α the subsets of X ( Soundness ) For each Xi MC model Mi of Πi ( i = 1 , . . . , n ) , − ∈ ffn {α | α nosis for KB wrt RKB ; ( Completeness ) For each minimum cost diagnosis R for KB wrt RKB , there exists an Xi MC model Mi of Πi ( i = i=1 d(Mi ∩ Xi , X,C)} . 1 , . . . , n ) such that R = {α | α Proof sketch . ( Soundness ) For i = 1 , . . . , n , let Bi be the set of ground atoms occurring in Πi and Mi an XiMC model of Πi . Let Π0 = Π(KB ) \ ffn i=1 Πi and M = {α ∈ head(r ) | α ffi∈ X ' ∪ ffn ff i=1(Mi ∩ Bi ) . r∈Π0 fi Let M be the set of ground atoms derived by applying all rules in R(KB)≈ over M ∪ {a ≈ b | a and b are together in some C ∈ C} , and M + = M ∪ M . It can be seen that ffn i=1 d(Mi ∩ Xi , X,C ) = M + ∩ X . It can further be shown that M + is an X MC model of R(KB ) . By Theorem 3 , − ∈ M +} is a mini{α|α mum cost diagnosis for KB wrt RKB . i=1 d(Mi ∩ Xi , X , C)} = {α|α i=1 Bi} ∪ ffn
− ∈ ffn
− ∈ ffn fi
571WWW 2008 / Refereed Track : Semantic / Data Web Semantic Web IApril 21 25 , 2008 · Beijing , China ( Completeness ) Let R be a minimum cost diagnosis for KB wrt RKB . By Theorem 3 , there exists an X MC − ∈ M} . Let M model M of R(KB ) st R = {α|α be a set of ground atoms converted from M by rewriting each constant a in M st fc(a,C ) exists to minc(fc(a,C) ) . It fi ∩ Bi is an Xi MC model of Πi can be shown that Mi = M − ∈ ffn ( i = 1 , . . . , n ) st R = {α | α i=1 d(Mi∩Xi , X,C)} . fi
By Theorem 4 , the problem of finding minimum cost diagnoses for KB wrt RKB is reduced to n subproblems , each of which computes Xi MC models of Πi ( i = 1 , . . . , n ) . We consider computing Xi MC models of Πi by applying SAT solvers that support PB constraints . We assume that the cost of each atom in Xi has been scaled to a positive integer polynomial in |X| the total number of removable assertions . Then , the first Xi MC model of Πi can be computed by a bi . fi β∈Xi c nary search ( within range [ 0 , ( β) ] ) for the minimum value vmin such that Πi ∪ { . ( β ) · assign(β ) ≤ vmin} fi β∈Xi c . ( β ) ) = O(log2 |X| ) calls fi β∈Xi c is satisfiable , taking O(log2 to a SAT solver . Let M = {M ∩ Xi | M is a previously computed Xi MC model of Πi} . Then a next Xi MC model M of Πi , such that M ∩ Xi ffi= S for every S ∈ M , can be computed as a model of Πi ∪ { . ( β ) · assign(β ) ≤ vmin}∪{← ' β∈S β | S ∈ M} , by calling a SAT solver once . fi β∈Xi c
Consider the time complexity for computing minimum cost diagnoses . Under the data complexity assumption , the number of non ground rules in R(KB ) and the number of different variables in each rule in R(KB ) are bounded by constants . Thus the number of rules in Π(KB ) is polynomial in |KBA| . It follows that Ground(R(KB ) ) is executed in PTIME . Let X ' be the set of translated decision atoms occurring in Π(KB ) . Partition(Π(KB ) , X ' ) commits at most |Π(KB)| iterations over Π(KB ) , so it is executed in PTIME too . Let n be the number of removable assertions in KB and {Πi}1≤i≤m be the set of propositional programs returned by Partition(Π(KB ) , X ' ) . Note that the SAT problem with a PB constraint is NP complete . Since Πi and Πj have no common ground atoms for all 1 ≤ i < j ≤ m , m calls to a SAT solver over Π1 , . . . , Πm respectively amount to one call to an NP oracle over i=1 Πi . Under the assumption that each removal cost has been scaled to a positive integer polynomial in n , it follows from Theorem 4 that , the first minimum cost diagnosis is computed in O(log2 n ) calls to an NP oracle , and a next one , in one more call . ffm
6 . EXPERIMENTAL EVALUATION
We implemented the proposed method for computing minimum cost diagnoses in GNU C++ . In the implementation , MySQL is used as the back end SQL engine ; ABox assertions and new ground atoms derived in the grounding process are maintained in a SQL database ; All ground substitutes of rules , retrieved via SQL statements , are maintained in disk files ; The SAT solver MiniSat+ [ 5 ] , which supports PB constraints and linear optimization functions by internally translating them into SAT clauses , is applied to compute X MC models . All the experiments were conducted on a 3.2GHz Pentium 4 CPU 2GB RAM PC running Windows XP and Cygwin . 6.1 Test Ontologies and Preparations
Semintec2 is an ontology about financial services , created
2 http://wwwcsputpoznanpl/alawrynowicz/
Table 1 : The complexity of test ontologies
NC NR 16 59 49 27 34 86 86 34
NI 17,941 82,095 50,253 629,568
S H L1 L10
NA Nr
Features 221 EQ13,DS0 EQ7,DS7 159 EQ2,DS0 168 168 EQ2,DS0
65,291 154,110 120,274 1,293,286
−
Note : S stands for Semintec . H stands for HumanCyc . L1 stands for LUBM1+ . L10 stands for LUBM10+ . NC is the number of concept names . NR is the number of role names . NI is the number of individuals . NA is the number of ABox assertions stored in MySQL databases . Nr is the number of rules transformed from the intensional part . The features show how many special transformed rules : EQn means there are n equality rules ( ie rules containing equality atoms ) ; DSn means there are n disjunctive rules . in the SEMINTEC project at the University of Poznan . Its intensional part contains functional roles and disjointness constraints .
HumanCyc3 is an ontology on human metabolic pathways and human genome , created by the SRI International corporation . Since its intensional part contains nomimals and concrete domain specifications ( eg , a role range is of some datatype , a concrete role is functional , etc . ) that cannot be handled by our method , we converted nominals to new atomic concepts and deleted concrete domain specifications . The weakened intensional part still contains disjunctions , functional roles/restrictions and disjointness constraints .
LUBM4 is a benchmark ontology developed at the Lehigh University [ 9 ] . Since its intensional part has no functional roles , number restrictions or disjointness constraints , which implies that it cannot be inconsistent , we extended it by adding a functional role headOf and an inverse functional role isTaughtBy , where headOf ( resp . isTaughtBy ) is also defined as an inverse role of isHeadOf ( resp . teacherOf ) , and adding disjointness constraints X . ¬N onX for each existing concept name X , where N onX is a new concept name . LUBM comes with an ABox generator . Let LUBMn denote the ontology obtained from the generator by setting the number of universities to n .
Before testing the proposed method , the intensional parts of the above ontologies were offline transformed to datalog programs using the KAON2 DL reasoner5 . Each transformation was performed in less than one second . Moreover , ABox assertions of the above ontologies were stored into MySQL databases , where duplicated ABox assertions were removed . Table 1 summarizes the complexity of the test ontologies and the datalog programs transformed from their denotes the weakened intensional parts , where HumanCyc HumanCyc , and LUBMn+ denotes the extended LUBMn . We developed a tool , called Injector , to inject a given number of conflicts into an ontology . Given a consistent ontology KB and a number ncnf of conflicts to be injected , Injector first deduces into KB all atomic concept assertions that are consequences of KB , then injects ncnf conflicts one by one . Let SF R denote the set of functional/inverse func
− semintec.htm 3
4
5 http://humancyc.org/ http://swatcselehighedu/projects/lubm/ http://kaon2semanticweborg/
572WWW 2008 / Refereed Track : Semantic / Data Web Semantic Web IApril 21 25 , 2008 · Beijing , China tional roles , SDC denote the set of atomic concepts that have disjoint concepts . To inject a conflict , Injector randomly selects an entity in SF R∪SDC . In case an functional role R is selected , if there exist role assertions over R in KB , Injector randomly selects one , say R(a , b ) , and appends R(a , c ) and b ffi≈ c to KB , where c is a new individual ; otherwise , Injector appends R(a , b ) , R(a , c ) and b ffi≈ c to KB , where a , b , c are new individuals . In case an inverse functional role R is selected , Injector treats it as R . In case an atomic concept C is selected , if there exist concept assertions over C in KB , Injector randomly selects one , say C(a ) , and appends D(a ) to KB for a randomly selected disjoint concept D of C ; otherwise , Injector appends C(a ) and D(a ) to KB , where a is a new individual and D a randomly selected disjoint concept of C . Injector was implemented in JAVA , using the Pellet [ 29 ] API to deduce all atomic concept assertions that are consequences of a consistent ontology .
−
6.2 Experimental Results
We injected different number of conflicts to the four test ontologies using Injector , obtaining a set of inconsistent ontologies . We consider the hardest case where all assertions in an obtained ontology are assumed removable . We assume that each assertion is given a removal cost 1 . In order to make the implemented system terminate in an acceptable time , we set a time limit of 20 minutes for one call to MiniSat+ .
The test results are reported in Table 2 . In each block , the first row lists ncnf , ie the number of injected conflicts ; the second row lists the total execution time for computing the first minimum cost diagnosis , starting from transform , the ing the input ontology . For Semintec and HumanCyc implemented system cannot handle more injected conflicts in our test environment , because when ncnf = 140 for Sem ) , some call to MiniSat+ intec ( or ncnf = 60 for HumanCyc exceeds the time limit . In contrast , the implemented system scales well on LUBM1+/LUBM10+ ontologies with increasing number ( from 1000 ) of conflicts .
−
−
We also collected runtime statistics on the partitioning process . Let KB be an inconsistent ontology reported in Table 2 . As can be seen , the number of rules in each grounded repair program Π(KB ) is up to millions . In addition , the number of decision atoms in Π(KB ) is at least in thousands . We experimentally verified that any Π(KB ) , without being partitioned , cannot be handled by MiniSat+ because the execution exceeds the time or memory limit . This shows the importance of the partitioning process .
|Π0|
Other statistics show the effectiveness of the partition|Π(KB)| , is at ing process . The percentage of filtered rules , least 11 % for all reported ontologies ( esp . , at least 57 % for LUBM10+ ontologies ) . The number of disjoint subprograms of Π(KB ) ( ie the number of partitions ) , #{Πi} , increases when the number of conflicts increases . This shows that the partitioning process improves the scalability . Table 2 also reports the maximum number of ground rules in each partition , max(|{Πi}| ) , and the maximum number of translated decision atoms in each partition , max(|{Xi}| ) . It can be seen that the total execution time is roughly dominated by max(|{Πi}| ) and max(|{Xi}| ) . For Semintec and , since max(|{Xi}| ) is up to tens of thousands , HumanCyc the execution of MiniSat+ over the largest partition quickly exceeds the time limit when the number of conflicts increases ( as max(|{Πi}| ) increases too ) . In contrast , for LUBM1+
−
Table 2 : Test results against different number of conflicts ncnf
Semintec ncnf Time ( sec ) |Π(KB)| |Π0| |Π(KB)| #{Πi} max({|Πi|} ) max({|Xi|} ) ncnf Time ( sec ) |Π(KB)| |Π0| |Π(KB)| #{Πi} max({|Πi|} ) max({|Xi|} ) ncnf Time ( sec ) |Π(KB)| |Π0| |Π(KB)| #{Πi} max({|Πi|} ) max({|Xi|} )
60 191 241K
100 298 371K
80 155 230K
120 40 1144 53 159K 636K 73.8 % 45.1 % 53.1 % 35.8 % 24.9 % 57 393K 18794
31 66K 16114
49 152K 20241
25 11K 7054
40 76K 14687 −
HumanCyc
20 326 607K
40 412 604K
30 531 620K
50 10 867 428 598K 639K 26.0 % 25.6 % 25.1 % 25.7 % 24.4 % 21 483K 68197
10 465K 68175
5 443K 68155
19 449K 68181
7 451K 68159 LUBM1+
3000 554
2000 387
4000 814
5000 1000 1010 202 537K 978K 1490K 2306K 2877K 41.9 % 25.9 % 18.7 % 13.3 % 11.4 % 4606 540K 898
2696 120K 895
3645 244K 901
1766 146K 859
886 43K 808
LUBM10+
2000 851
|Π0|
4000 1250
3000 1070
1000 736 ncnf Time ( sec ) |Π(KB)| |Π0| |Π(KB)| #{Πi}
5000 1618 3893K 4111K 4165K 4338K 4753K 82.3 % 70.8 % 65.8 % 62.8 % 57.3 % 4423 max({|Πi|} ) 34K max({|Xi|} ) 1393 Note : |Π(KB)| is the number of rules in the grounded repair |Π(KB)| is the percentage of rules filtered program Π(KB ) . out in our partitioning algorithm . #{Πi} is the number of partitions . max({|Πi|} ) is the maximum number of ground rules in each partition . max({|Xi|} ) is the maximum number of translated decision atoms in each partition .
1860 24K 1571
2713 31K 1961
3605 43K 2610
963 26K 810 and LUBM10+ , since max(|{Πi}| ) or max(|{Xi}| ) is stable around a relatively small value , the total execution time increases smoothly when the number of conflicts increases .
We can conclude that the performance of our method depends on the effectiveness of the partitioning process . As for what influences such effectiveness when the number of assertions and the number of conflicts are fixed , we can see from Table 1 and Table 2 that , equality rules have a stronger impact than normal rules ; further , disjunctive rules have a stronger impact than equality rules . Hence , we believe that our method can handle any real ( populated ) ontology that has up to millions of assertions together with a moderately complex intensional part , which can be transformed to up to hundreds of datalog rules with a few disjunctive rules and equality rules .
573WWW 2008 / Refereed Track : Semantic / Data Web Semantic Web IApril 21 25 , 2008 · Beijing , China 7 . CONCLUSION AND FUTURE WORK
A DL based ontology may become inconsistent after it is populated . In this paper , we proposed a solution to repair the populated ontology by deleting assertions in a minimum cost diagnosis . We first showed the intractability of finding a minimum cost diagnosis , then presented an exact method for computing minimum cost diagnoses for SHIQ ontologies . The method transforms a SHIQ ontology to a set of disjoint propositional programs in PTIME wrt data complexity , thus reducing the original problem into a set of independent subproblems . Each such subproblem computes an X MC model and is solvable by applying SAT solvers . We experimentally showed that the method can handle moderately complex ontologies with over thousands of assertions , where all assertions can be assumed removable . Especially , the method scales well on the extended LUBM ontologies with increasing number ( from 1000 ) of conflicts .
For future work , we plan to enhance our method to cope with concrete domain specifications , seek feasible approaches to handling nomimals , and work on tractable approximate methods for computing minimum cost diagnoses .
8 . ACKNOWLEDGEMENTS
This work is supported in part by NSFC grants 60673103 ,
60721061 and 60373052 .
9 . REFERENCES [ 1 ] F . Baader , D . Calvanese , D . L . McGuinness , D . Nardi , and P . F . Patel Schneider , editors . The Description Logic Handbook : Theory , Implementation , and Applications . Cambridge University Press , 2003 .
[ 2 ] D . Calvanese , G . D . Giacomo , D . Lembo ,
M . Lenzerini , and R . Rosati . Dl lite : Tractable description logics for ontologies . In Proc . of AAAI’05 , pages 602–607 , 2005 .
[ 3 ] P . Cimiano and J . V¨olker . Text2onto a framework for ontology learning and data driven change discovery . In Proc . of NLDB’05 , pages 227–238 , 2005 .
[ 4 ] J . Dolby , J . Fan , A . Fokoue , A . Kalyanpur ,
A . Kershenbaum , L . Ma , J . W . Murdock , K . Srinivas , and C . A . Welty . Scalable cleanup of information extraction data using ontologies . In Proc . of ISWC’07 , pages 100–113 , 2007 .
[ 5 ] N . E´en and N . S¨orensson . Translating pseudo boolean constraints into sat . JSAT , 2:1–26 , 2006 .
[ 6 ] T . Eiter , G . Gottlob , and H . Mannila . Disjunctive datalog . ACM Trans . Database Systems , 22(3):364–418 , 1997 .
[ 7 ] T . Eiter , N . Leone , C . Mateis , G . Pfeifer , and
F . Scarcello . A deductive system for non monotonic reasoning . In Proc . of LPNMR’97 , pages 364–375 , 1997 .
[ 8 ] M . Fitting . First order Logic and Automated Theorem
Proving ( 2nd ed ) Springer Verlag New York , Inc . , Secaucus , NJ , USA , 1996 .
[ 9 ] Y . Guo , Z . Pan , and J . Heflin . Lubm : A benchmark for owl knowledge base systems . J . Web Sem . , 3(2–3):158–182 , 2005 .
[ 10 ] I . Horrocks , U . Sattler , and S . Tobies . Practical reasoning for very expressive description logics . Logic Journal of the IGPL , 8(3 ) , 2000 .
[ 11 ] Z . Huang , F . van Harmelen , and A . ten Teije .
[ 12 ] U . Hustadt , B . Motik , and U . Sattler . Reducing description logic to disjunctive datalog
Reasoning with inconsistent ontologies . In Proc . of IJCAI’05 , pages 454–459 , 2005 . SHIQ− programs . In Proc . of KR’04 , pages 152–162 , 2004 . [ 13 ] A . Kalyanpur , B . Parsia , E . Sirin , and B . C . Grau .
Repairing unsatisfiable concepts in owl ontologies . In Proc . of ESWC’06 , pages 170–184 , 2006 .
[ 14 ] A . Kalyanpur , B . Parsia , E . Sirin , and J . Hendler .
Debugging unsatisfiable classes in owl ontologies . J . Web Sem . , 3(4):268–293 , 2005 .
[ 15 ] R . M . Karp . Reducibility among combinatorial problems . In Proc . of a Symposium on the Complexity of Computer Computations , pages 85–103 , 1972 .
[ 16 ] S . C . Lam , J . Z . Pan , D . H . Sleeman , and W . W . Vasconcelos . A fine grained approach to resolving unsatisfiable ontologies . In Proc . of WI’06 , pages 428–434 , 2006 .
[ 17 ] D . Lembo and M . Ruzzi . Consistent query answering over description logic ontologies . In Proc . of RR’07 , pages 194–208 , 2007 .
[ 18 ] N . Leone , G . Pfeifer , W . Faber , T . Eiter , G . Gottlob ,
S . Perri , and F . Scarcello . The dlv system for knowledge representation and reasoning . ACM Trans . Comput . Log . , 7(3):499–562 , 2006 .
[ 19 ] T . Meyer , K . Lee , and R . Booth . Knowledge integration for description logics . In Proc . of AAAI’05 , pages 645–650 , 2005 .
[ 20 ] T . Meyer , K . Lee , R . Booth , and J . Z . Pan . Finding maximally satisfiable terminologies for the description logic ALC . In Proc . of AAAI’06 , pages 269–274 , 2006 .
[ 21 ] B . Motik . Reasoning in Description Logics using Resolution and Deductive Databases . PhD thesis , Univesit¨at karlsruhe , Germany , Jan . 2006 .
[ 22 ] P . F . Patel Schneider , P . Hayes , and I . Horrocks . OWL
Web Ontology Language Semantics and Abstract Syntax . W3C Recommendation , 2004 . http://wwww3org/TR/owl semantics/
[ 23 ] G . Qi , W . Liu , and D . A . Bell . Knowledge base revision in description logics . In Proc . of JELIA’06 , pages 386–398 , 2006 .
[ 24 ] R . Reiter . A theory of diagnosis from first principles .
Artif . Intell . , 32(1):57–95 , 1987 .
[ 25 ] S . Schlobach . Debugging and semantic clarification by pinpointing . In Proc . of ESWC’05 , pages 226–240 , 2005 .
[ 26 ] S . Schlobach . Diagnosing terminologies . In Proc . of
AAAI’05 , pages 670–675 , 2005 .
[ 27 ] S . Schlobach and R . Cornet . Non standard reasoning services for the debugging of description logic terminologies . In Proc . of IJCAI’03 , pages 355–362 , 2003 .
[ 28 ] H . M . Sheini and K . A . Sakallah . Pueblo : A hybrid pseudo boolean sat solver . JSAT , 2:157–181 , 2006 . [ 29 ] E . Sirin , B . Parsia , B . C . Grau , A . Kalyanpur , and
Y . Katz . Pellet : A practical owl dl reasoner . J . Web Sem . , 5(2):51–53 , 2007 .
[ 30 ] C . Welty and J . W . Murdock . Towards knowledge acquisition from information extraction . In Proc . of ISWC’06 , pages 152–162 , 2006 .
574WWW 2008 / Refereed Track : Semantic / Data Web Semantic Web IApril 21 25 , 2008 · Beijing , China
