Cross sell : A Fast Promotion Tunable Customer item
Recommendation Method Based on Conditionally
Independent Probabilities
Brendan Kitts
Vignette Corporation 19 Newcrossing Road
Reading , MA . 01867 . USA
Ph : +1 781 942 3600 bkitts@vignette.com
David Freed
Vignette Corporation 19 Newcrossing Road
Reading , MA . 01867 . USA
Ph : +1 781 942 3600 dfreed@vignette.com
Martin Vrieze
Vignette Corporation 19 Newcrossing Road
Reading , MA . 01867 . USA
Ph : +1 781 942 3600 mvrieze@vignette.com
ABSTRACT We develop a method for recommending products to customers with applications to both on line and surface mail promotional offers . Our method differs from previous work in collaborative filtering [ 8 ] and imputation [ 18 ] , in that we assume probabilities are conditionally independent . This assumption , which is also made in Naïve Bayes [ 5 ] , enables us to pre compute probabilities and store them in main memory , enabling very fast performance on millions of customers . The algorithm supports a variety of tunable parameters so that the method can address different promotional objectives . We tested the algorithm at an on line hardware retailer , with 17,400 customers divided randomly into control and experimental groups . In the experimental group , clickthrough increased by +40 % ( p<0.01 ) , revenue by +38 % ( p<0.07 ) , and units sold by +61 % ( p<001 ) By changing the algorithm ’s parameter settings we found that these results could be the considerable potential of automated data mining for dramatically increasing the profitability of on and off line retail promotions . Keywords Imputation , cross sell , collaborative filtering , recommendation further . This work demonstrates improved even
1 . INTRODUCTION Most customer recommendation algorithms can be understood as performing some kind of imputation [ 13 ] . Some of the customer ’s interests are known because they have entered “ star ratings ” or have bought a product , but most are not . The problem of deciding what product to recommend next involves finding out what the customer ’s attitudes would be toward the missing values , by analyzing the statistical patterns of the population . For example , say that Joe purchased science&nature and mystery . We can look for all other customers who bought the same two items , and possibly other purchases . Joe ’s probability of interest might now be calculated by taking the average of the interest of the donor customers in the new category , or in other words , what Joe ’s “ soul mates ” thought on average about the other category . This particular method of filling in missing values is known in the statistics literature as conditional mean imputation [ 18 ] .
Formally , let a customer profile x consist of a binary vector x = [ 0,1]∈ ℜN where a xsi=1 means that customer s purchased/clicked product/web page i , and a 0 means that the customer did not , and N is the number of variables in the profile1 . We are trying to predict the customer ’s interest in variable j . Let xsj=MV , which stands for “ missing value ” . Conditional mean imputation is defined as :
Given that :}{ d
( x si
=
D
=
MV =→= x ∑ xsj 1 1 # D x dj
∈ Dd di
+ = x sj
) i ∀ x si
Other typical imputation algorithms include regression imputation [ 17,19 ] , the EM algorithm , and hot deck imputation [ 7,14,4 ] . Regression imputation selects donor cases in exactly the same way , and then calculates a least squares estimate : x
[ =+ x sj [ = xw di
] w ⋅ 1 si ] #1
−1
D
⋅ x dj where
1 This is not the only choice for profile ; for instance , we could have used a profile of revenues , percentages of spending , or page hits . We will use binary profiles in this article because this is what we have used in our experiments reported later .
Collaborative filtering systems [ 8,9,16 ] implement a nearest neighbor variant of the above strategy . The donor set is restricted to the k closest matching customer profiles to a candidate .
D = lowest(k ) |xs1N,xd1N| x dj
+ = x sj
1 k
∑
∈ Dd
Various alterations to this procedure have been proposed including weighting users , products or star ratings , and adding significance of recommendations [ 16 ] . for measuring reliability tests the
2 . PROBLEMS WITH COLLABORATIVE FILTERING In all the above methods one needs to calculate a match between the candidate and every other customer in the population , before blending the donor data to arrive at a score . In practice one needs to perform this computation quickly . One option is to calculate it when a customer visits a site . The time complexity of this operation is O(CN ) where C are the number of customers and N is the size of the profile .
The alternative is to pre compute probabilities and store in memory or on disk for faster lookup using an index or hash table . Unfortunately , there are usually too many match patterns to store for this to be feasible . We need to store results for each
Pr(xci=Xi | xc1=X1,xc2=X2,xc3=X3,…,xcN=XN ) where Xi∈[0,1 ]
There are N possible items in the term before the bar variable in the profile that we are estimating a probability for . The term after the bar , or pattern of conditional purchases in the customer ’s profile contains a string of N variables which can take the value 0 or 1 . This means that there are 2N different condition patterns . The total number of combinations is N2N , which grows as an exponential function of N .
3 . CONDITIONALLY INDEPENDENT RECOMMENDATIONS The approach in this paper differs from previous work on collaborative filtering in the following respect . We do not calculate interest probabilities conditional upon meeting all of the criteria of a customer ’s profile , as is required in conditional mean imputation and collaborative filtering . Instead , we operate under the assumption of conditional independence of the past behavior of the customer in question . Formally :
Definition : Conditional independence
Pr(b|a ) = Pr(b|a,c,d,e,…,n ) ∀a,b,c,d,e,…,n
This is somewhat unrealistic . If a customer has bought five scifi books , we would expect their probability of being interested in a new scifi book to be higher than another customer with one scifi book with ten gardening . Never the less , we will adopt the constraint . This assumption is also made in some other prediction algorithms such as Naïve Bayes [ 5 ] .
The disadvantage of this constraint is that accuracy can be lower because we are ignoring interactions . The advantage is that storage requirements are tiny , and as a result algorithm speed can be greatly increased . The recommendation of interest will be some function of the customer ’s profile and single condition events , Pr(b|a ) . This means that the storage complexity for those probabilities is only N*N = O(N2 ) which is polynomial in N . Storage can be decreased further since only half of a cooccurrence counter matrix needs to be stored , and low frequency pairs can be ignored below a certain threshold [ 1 ] . With low memory requirements , lookup can be achieved using fast hash tables .
4 . THE CROSS SELL RECOMMENDATION ALGORITHM This section will describe how individual conditional probabilities are combined to create a customer recommendation . Let a driver be an item the customer has purchased before , xci=1 → driver(c,i ) . Let R be the number of recommendations the customer needs to be provided with . Our recommendation algorithm simply considers each driver , and then reads off the top R cross sell items with the highest promotion objective score described below , subject to various parameter settings also described below .
4.1 Promotion objective score Retail businesses rarely have a single promotional goal . After a web site is first opened discount offers might be presented with the aim of generating traffic/clickthrough . Later , maximizing profit might become important . For new users with little data it might be best to offer products with the highest response probabilities across the population , such as Whitney Houston or Britney Spears CDs . But loyal customers , understanding their exact needs might be crucial . For these reasons , the recommendation score of an item is customizable to the promotional objective . for veteran
We have developed four criteria to measure the value of an item recommendation : 1 . probability of customer responding to item , 2 . lift or degree of mutual attraction between item and customer , 3 . expected profit from item , 4 . incremental profit from item .
411 Response Probability Response probability is the probability of an item b being bought , given a customer ’s purchase of item a . Interestingly , using this method for scoring item desirability , the most probable item a customer will buy after a hammer , might not be nails! It could be a magazine . If there exist items in the store which have very high baseline rates of being purchased , these can be recommended frequently , and seemingly without regard to the drivers in the customer ’s purchase history . Figure 1 illustrates how the most frequently purchased items dominate the recommendation value . Lift described below “ fixes ” the problem of high probability items dominating response probability is : recommendations . The formula for
RecommendationValue(b ) = Pr(b|a )
Figure 1 : Graph of the highest conditional probabilities in a grocery store . If we take any item in the store and list the conditional probabilities from largest to smallest , the top three “ cross sell ” products are nearly always eggs , bread and milk . This is because eggs , milk and bread have a high probability of appearing in any basket . In a recommendation system , utilizing cross sell probabilities would result in these very high baseline probability items being recommended again and again , regardless of the drivers appearing in the customer ’s purchase profile .
Figure 2 : Graph of top lift affinities for the same grocery store . Lift is very effective in revealing which products have strong two way purchase relationships .
412 Lift or Mutual Affinity The idea of lift is to promote products which have high mutual attractions to each other . For instance , an “ air conditioning unit ” and “ air conditioning unit accessory ” might be very rarely bought with other items , but might be bought together frequently . Although lift does not necessarily maximize sales probability or profit , previous work has indicated that profit can be generated by cross selling products with high lift scores . In a past experiment we optimized shelf layout by moving high lift items together . This
This was implemented by considering drivers in time order from most recent purchase to oldest purchase , until the required number of recommendations was filled .
4.4 Other Parameters The level of analysis , level of recommendation , number of duplicate recommendations tolerated , and recommendation of products already in customer history are also customizable . For example , in almost every retailer an item hierarchy is available . If no recommendations can be made confidently at the item level , it is possible to switch to examining affinities at the sub category or category level , and reading off recommendations at that level . This strategy for walking the hierarchy was implemented , but not used in the experimental test that follows since the retailer was only interested in targeting specific items .
5 . EXPERIMENTAL TEST We tested our algorithm at an on line and catalogue hardware retailer based in California . This retailer had accumulated 11 years of data on customer transactions , with approximately 60 million rows . The company ran an opt in direct email list , and distributed email messages to around 65,000 customers each week . Revenues accrued from the direct email campaign average around $2.18 per customer emailing , with clickthrough probability equal to 178 %
We took 14,770 customers and divided them randomly into control and experimental groups , with 6,999 and 7,771 respectively . The experimental group customers received automated recommendations , while the control group customers received the weekly scheduled promotion , put together by this company ’s marketing department .
To test the various parameter settings for this algorithm , we allocated recommendations to the experimental group based on a variety of parameter settings . We did not allow a customer to be recommended with a product that they already owned , and did not allow duplicates to be recommended . resulted in a +40 % increase in profit for items that were moved together [ 11 ] . The formula for lift is
RecommendationValue(b ) = Pr(b|a)/Pr(b )
= Pr(a,b)/[Pr(a)*Pr(b ) ]
Lift is a symmetric measure , so Lift(a,b)=Lift(b,a ) . A number greater than one is interpreted as the number of times higher than random that two items occur together . A fractional number can be inverted and interpreted as the number of times lower than random that two items occur . Interestingly , lift is related to the Mutual Information Criterion ( MIC ) from information theory [ 3 ] . MIC is equal to log of lift . We favor the untransformed lift score because it is easier to interpret for the user .
413 Expected Profit If we assume mutual independence between products , then the expected profit after buying a product a is equal to the probability of buying b given a , Pr(b|a ) multiplied by the profit Π of b . As a result this is the formula :
RecommendationValue(b ) = Pr(b|a ) * Π(b )
414 Incremental Profit The idea behind incremental profit is to maximize the profit minus the profit you would expect to receive due to the natural course of a customer ’s purchasing . For example , say a customer comes into a store and buys a hammer ( product a ) . You have two choices : nails , or screwdrivers . Analysis of customer purchase patterns may indicate that nails are almost certainly going to be bought in the future , since these have a 20 % chance of being bought by any customer . Therefore , instead of promoting something that we know the customer will be buying anyway , we go for the purchase that has a higher incremental profit – the screwdriver . Incremental profit maximizes the profit of the item , minus the baseline profit associated with the item . Thus incremental profit is similar to lift , except it subtracts the base probability , rather than dividing by it .
RecommendationValue(b ) = [ Pr(b|a) Pr(b ) ] Π(b )
4.2 Driver Diversity This parameter directs the algorithm to recommend at least one item from each driver , or will pool all of the recommendations together , and will select those with the highest promotional objective scores2 .
4.3 Driver Recency Driver recency forces the recommendation algorithm to consider more recent purchases preferentially over purchases in the past .
2 Forcing the algorithm to make a recommendation based on each of the customer ’s historical purchases can be beneficial , because the largest RecommendationValue scores might come from just one product in the customer ’s profile ( eg . one which has a high baseline probability ) . Thus all recommendations would be based on a single purchase , when that customer ’s profile might contain much more information , for instance , 10 purchases of scifi books .
( b )
61 %
0.25
0.2
0.15
0.1
0.05
0 trans quantity
( c )
38 %
6 . RESULTS 6.1 Overall Figure 3 shows the overall effectiveness of the automated recommendations , compared to the control recommendations . These results show that in the experimental group revenue per customer increased by 38 % , clickthrough by 40 % , and quantity purchased by 61 % . A t test revealed that the clickthrough , quantity and improvements were statistically significant at the p<0.01 level , whilst the revenue increase was significant at the p<0.07 level . As a result , the improvements in the automated system were both large and have a very low chance of being caused by random . Figures 7 and 8 show some example customers and the products they were recommended . transactions r e m o t s u c r e p y t q r o s n a r t
( a )
40 %
Exp Control r e m o t s u c r e p $
3.5 3 2.5 2 1.5 1 0.5 0 r e m o t s u c r e p h g u o r h t k c i l c
3.00 % 2.50 % 2.00 % 1.50 % 1.00 % 0.50 % 0.00 % click rev
StdDev p trans Mean
StdDev p quantity Mean
StdDev p rev Mean StdDev p
0.02484 0.15564 <0.01 0.14786 1.20643 <0.01 0.19071 1.7400 <0.01 3.0009 28.863 0.0676 0.01772 0.13193
0.09244 0.97856
0.11830 1.2575
2.1776 25.537 click Group Count Mean Exp
7771 Control 6999
Figure 3 : Main results from experiment aggregated over all tested parameter settings ( charts a , b and c )
( d )
8.2 %
( e )
8.6 , 9.0 % n o i t a d n e m m o c e r r e p
$
3.4
3.3
3.2
3.1
3
2.9
Group best diversity best r e p y t q r o s n a r t n o i t a d n e m m o c e r
0.25
0.2
0.15
0.1
0.05
0
Revenue
Transactions
Quantity trans Count Mean 61639 0.15594 1.22594 p 0.0512 0.20453 1.83855 0.0755 3.05911 28.2182 0.1152 quantity Mean rev Mean
StdDev
StdDev
StdDev
P p p diversity 76801 0.16928 1.29586
0.22289 1.96555
3.30926 30.2522
Figure 4 : Effect of using driver diversity ( charts d and e )
Exp Control
Exp Control diversity best
( f )
( g ) n o i t a d n e m m o c e r r e p $
3.4 3.3 3.2 3.1 3 2.9 2.8 2.7 incprof lift salesprob prof
Revenue r e p y t q r o s n a r t n o i t a d n e m m o c e r
0.25
0.2
0.15
0.1
0.05
0 incprof lift salesprob prof
Transactions
Quantity
% Improvement over vanilla conditional probability
)
%
( t f i l
10.0 %
5.0 %
0.0 %
5.0 %
10.0 % incprof lift prof qty trans rev metric
Group incprof lift prof salesprob
StdDev rev trans StdDev Mean Count Mean 25500 0.166784 1.28724 0.3505 2.08233 0.1516 3.35024 34258 0.169245 1.28464 0.2023 0.223948 1.98448 0.1516 3.28502 38313 0.157257 1.24604 2.97227 40369 0.161931 1.25259 0.5999 0.209443 1.83902 0.6658 3.24182 quantity Mean 0.22698
0.203847
1.7922
NA p
NA p
StdDev 32.0955 29.6433 26.7753 29.6677 p
0.107 0.1354
NA
0.1817
Figure 5 : Performance of different objective scores ( charts f and g ) . The table shows that maximizing incprof and lift resulted in the best performance on most metrics , where as maximizing “ prof ” resulted in the lowest performance on all metrics . The significance test is the probability that a group ( eg . lift ) is significantly different from the lowest group ( prof ) . The bottom figure shows that incprof and lift generated 6 8 % more revenue than base response probability .
6.2 Parameter Selection Incremental profit and lift both outperformed conditional probability and profit maximization in all behavioral measurements including revenue , transactions , and quantity purchased ( figure 5 ) .
The fact that incremental profit and lift out performed the other methods is interesting . Lift is the conditional probability divided by the baseline probability . Now consider that incremental profit is the conditional probability minus the baseline probability . These two measures are similar in that both are discounting the baseline probability in some way .
[ 2 ] also found that discounting base rating frequencies increased accuracy in predicting interest in test data . Their “ inverse user weighting ” scheme increased accuracy in all 24 experiments they ran on test data . Further experiments will be needed to identify ( a ) if this principle holds true in general , ( b ) the best
$ per customer for different numbers of items featured in promotion way to account for base probabilities ( [2 ] divided by a log inverse probability score , where as we have proposed dividing / subtracting the base rate ) , and ( c ) under what conditions base interests should be favored over lifted interests ( the base probabilities might be effective on new users with little data , and lift affinities for veteran customers ; however , this experiment needs to be performed ) .
Driver diversity increased revenue , transactions and quantitypurchased by 8 % , 9 % respectively , per recommendation . The increase in transactions was significant at the p<0.06 level . ( figure 4 ) and 8.6 %
A histogram of revenue versus number of recommendations is shown in figure 6 . Although the distribution is noisy , it appears that an optimal number of recommendations is around 11 per email , which results in $5.99 revenue per customer . The company currently uses 15 recommendations per email message . r e m o t s u c r e p
$
7
6
5
4
3
2
1
0
1
4
Table 41 Complete Purchase history for Customer A
SKU 2776 2901 33684 36954
Date
6/18/99 6/18/99 6/18/99 6/18/99
Qty Price 19.99 1 9.99 1 1 329.99 9.99 1
Description
Lathe Bits AR 6 10 PK
O Ring Assortment 382 PC
Lathe 7" X 10" Mini Retaining rings 225PC
Table 42 Recommendations for Customer A Recommendation
Driver
Lathe bits AR 6 10 PK Lathe 7" X 10" Mini
O Ring assortment 382 PC
Retaining rings 225PC
Tool set indexable Carbide Lathe Toolkit Quick change Lock nut storehouse 150PC
Spring asst 200 PC
25
7
13
10
22 number of recommendations
16
19
Number of customers viewing this number of recommendations t i r e m o t s u c f o m e r e b m u n s n o i t a d n e m m o c e r
14000 12000 10000 8000 6000 4000 2000 0
1 5 9
3 1
7 1
1 2
5 2 number of recommendations
Figure 6 : Revenue resulting from different numbers of recommendations
Description
Table 43 Customer A purchases three days after offer sent SKU 3629 35140 39424 39931 Total
Price 8.99 72.99 18.99 40 PC . Tungsten alloy SAE tap & die set 14.99 115.96
5 PC . Indexable carbide Tool set
Qty 1 1 1 1 4
Quick change lathe toolkit
7 PC . Forstner bit set
All
Figure 7 : On June 18 , 1999 Customer A bought a $329.99 Mini Lathe , along with some replacement cutting bits , a toolkit of Orings and Retaining rings . In response the system recommended an additional set of carbide lathe cutting bits , a Lathe quickchange toolkit , and toolkits with locknuts and springs . After receiving these offers through email , the customer bought four products including the lathe parts .
Variable speed reciprocating saw
Drill Holster
14.4V Cordless Drill
18V Cordless Drill
14.4V Battery
Table 81 Historical purchases for Customer B
Customer Qty Rev Responses
First date
B
82 561.74
11
4/22/96
Return rev
0
Days active
1165
Table 83 Customer B purchases three days after offer sent
Qty Price Description Date
1
59.99 Drill 18V 2/19/00
Table 82 Recommendations for Customer B Recommendation Criterion
Driver
Drill 14.4V
Drill 14.4V
Drill 14.4V
Drill 14.4V
Battery 14.4V
Drill 14.4V
Battery 14.4V
Battery 14.4V
Recip saw
Recip saw
Incprof
Lift
Drill Holster
Incprof
Drill Holster
Lift
Drill 18V
Drill 18V
Drill 18V
Drill 18V
Salesprob
Prof
Incprof
Lift
Figure 8 : Customer B previously purchased a 14.4V Drill and replacement battery . The system recommended an 18V Drill and the customer purchased it .
6.3 Lifetime factors Because we had access to a long period of customer history , we were also able to analyze the effect of previous responses to promotions on the likelihood of responding to this promotion . We identified a 25 factors , listed in figure 9 . The best predictor for high revenue in the promotion is a high quantity purchased per catalogue received ( R=0.38 ) followed by other lifetime revenue and quantity variables . The response probability of items recommended was correlated with customer revenue ( R=013 )
Variables that indicated low revenue included quantity returned as a percent of total ordered ( R= 0.33 ) , and revenue returned as a percent of total ( R= 029 ) In other words , customers who returned large numbers of goods were poor responders to future promotions . Perhaps this was due to dissatisfaction , and this might have indicated that an alternative strategy should be used for these customers .
Figure 9 . Impact of lifetime factors on promotion performance
Factor
R
Description mean probability avg price qtty per catalogue
Log rev per catalogue
Resp return qtty response rate days active rev per catalogue prof per catalogue lifetime qty lifetime rev lifetime prof
0.384 0.326 0.260 0.232 0.224 0.142 0.131 0.130 0.121 0.106 0.098 0.089 0.080 0.073 0.058 0.053 0.014 0.001 0.009 0.028 0.032 0.060 0.091 0.096 rev returned as % of totalrev 0.293 qtty returned as % of totalqty 0.330
Nocatalogues mean profit return rev Meanrank rev per day qtty per day prof per day
NumberOfRecommendations
DistinctRecommendations response per day profit as % of revenue quantity ordered per catalogue received log of revenue per catalogue revenue generated per catalogue profit generated through orders per catalogue quantity ordered in lifetime revenue generated in lifetime profit generated in lifetime average response probability for recommendations this customer was given average price of products purchased by this customer number of orders divided by number of catalogues received days since customer made first purchase number of orders number of items returned number of catalogues received average profit for recommendations this customer viewed in the email promotion dollar amount of products returned average rank of recommendations this customer viewed revenue generated / days active quantity generated / days active profit generated / days active number of recommendations this customer viewed number of distinct recommendations this customer viewed orders / days active for each dollar this customer spends , how much of that is profit percentage of customer ’s spending that returns to the store percentage of products that the customer returns to the store
7 . RELATED WORK Other researchers have reported similar results to those in our experiment . [ 10 ] reported a lift in clickthrough from 8.3 % to 13.2 % for market basket analysis ( possibly similar to the method in this paper ) , and 13.96 % for nearest neighbor method , in direct email campaigns ( 59 % and 68 % respectively ) . [ 15 ] reported a lift in revenue of 60 % at a catalogue company in the United Kingdom using a nearest neighbor method . Because of these large improvements , we are confident that our results are intelligent typical of results achieved by implementing customer item recommendation methods at other on line retailers .
8 . CONCLUSION On line retailers face a difficult situation . Customer acquisition costs are high , and competitor stores are a mouse click away . As on line retailers struggle to survive in this environment , we believe this will lead to a burgeoning market for data mining techniques that can analyze large volumes of data , develop quality as recommendation , price optimization , and notification ; and individualized customer services such increase profitability of customers . We have shown in this paper that implementation of such a system can significantly increase profitability and re visit propensity by as much as 38 % and 40 % respectively at a low volume retailer , and without a finely tuned system . This kind of improvement cannot be ignored , and we predict that all web sites will install systems of a type like that in this paper to increase their customer satisfaction , re visit frequency , and most importantly , the bottom line profitability of their web business .
9 . ACKNOWLEDGMENTS Thanks to Vignette Corporation for making possible this research .
10 . REFERENCES [ 1 ] Agrawal , R . and Srikant , R , Fast algorithms for mining association rules , Proceedings of the 20th International Conference on Very Large Databases , Santiago , Chile . ( 1994 ) .
[ 2 ] Breese , J . , Heckerman , D . , Kadie , C . , Empirical Analysis of Predictive Algorithms for Collaborative Filtering , Proceedings of the Fourteenth Conference on Uncertainty in Artificial Intelligence , Madison , WI . Morgan Kaufmann , ( July , 1998 ) .
[ 3 ] Chan , P . , A non invasive learning approach to building web user profiles , Workshop on Web usage analysis and user profiling , Fifth International Conference on Knowledge Discovery and Data Mining , San Diego . ( August , 1999 ) .
[ 4 ] David , M . , Little , R . , et . al . , Alternative methods for CPS income imputation , Journal of the American Statistical Association , Vol . 81 , No . 393 , pp . 29 41 . ( 1986 ) .
[ 5 ] Elkan , C . , Boosting and Naïve Bayesian Learning , Technical Report No . CS97 557 , Department of Computer Science and Engineering , University of California , San Diego . ( 1997 ) .
[ 6 ] Ford , B . , An Overview of Hot Deck Procedures , in Madow , W . et . al . ( eds ) , Incomplete data in sample surveys , Vol 2 . , Academic Press , NY . pp . 185 206 . ( 1980 ) .
[ 7 ] Herlocker , J . , Konstan , J . , Borchers , A . , Riedl , J . , An Algorithmic Framework for Performing Collaborative Filtering , Department of Computer Science and Minnesota , Engineering , http://wwwcsumnedu/Research/GroupLens ( 2000 ) .
University of
[ 8 ] Hey , J . , System and method of predicting subjective reactions , Patent number 4,870,579 , US Patent and Trademark Office , http://16419510011 ( 1989 ) .
[ 9 ] Hey , J . , System and method for recommending items , Patent number 4,996,642 , US Patent and Trademark Office , http://16419510011 ( 1991 ) .
[ 10 ] Kaupp , R . , The New Science of eMarketing : Targeted Email Communications to keep customers Coming Back , Digital Impact Corporation , San Mateo , CA , Proceedings of the Personalization Summit 2000 , Boston . ( April , 2000 ) .
[ 11 ] Kitts , B . , The Ecology of the Retail Store , Working paper ,
Vignette Corporation . ( 2000a )
[ 12 ] Kitts , B . , Diamonds in the Rough , Working paper , Vignette
Corporation . ( 2000b )
[ 13 ] Little , R . and Rubin , D . , Statistical Analysis with Missing
Data , John Wiley and Sons , NY . ( 1987 ) .
[ 14 ] Oh , H . and Scheuren , F . , Estimating the Variance impact of Missing CPS Income Data , Proceedings of the Survey Statistical Research Methods Association , pp . 408 415 . ( 1980 ) .
Section , American
[ 15 ] Riedl ,
J . , Soul Mate Searches , Net Perceptions Corporation , Proceedings of the Personalization Summit 2000 , Boston . ( April , 2000 ) .
[ 16 ] Robinson , G . , Automated collaborative filtering system , US Patent and Trademark Office , http://16419510011 ( 1998 ) .
[ 17 ] Rubin , D . , Multiple imputation after 18+ years , Journal of the American Statistical Association , Vol . 91 , pp . 434 , 473 489 . ( 1996 ) .
[ 18 ] Schafer , J . , Analysis of Incomplete Multivariate Data ,
Chapman and Hall , London . ( 1997 ) .
[ 19 ] Schafer , J . and Olsen , M . , Multiple imputation for multivariate missing data problems : a data analyst ’s perspective , Multivariate Behavioural Research , Vol . 33 , pp . from http://wwwstatpsuedu/~jls ( 1997 ) .
545 571 . also available
[ 20 ] Schafer , J . , Multiple imputation : a primer , Statistical
Methods in Medical Research , Vol . 8 , pp . 3 15 . ( 1999 ) .
