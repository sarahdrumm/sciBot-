Efficient Query Subscription Processing for Prospective Search Engines
Utku Irmak ∗
Svilen Mihaylov †
Torsten Suel ‡
Samrat Ganguly §
Rauf Izmailov 4
Abstract
1 Introduction
Current web search engines are retrospective in that they limit users to searches against already existing pages . Prospective search engines , on the other hand , allow users to upload queries that will be applied to newly discovered pages in the future . Important examples of prospective search on the web are the subscription features in Google News and in RSS based blog search engines , which notify users about relevant new items through email or RSS readers . In this paper , we consider the problem of efficiently processing large numbers of query subscriptions against a stream of newly discovered documents . We focus on the case of keywork queries , as opposed to the more structured types of queries studied , eg , in the context of streaming databases . In this case , a standard approach builds an inverted index structure on the queries , rather than the documents , and then queries this structure for each newly arriving document . In our work , motivated by a scenario involving RSS feeds , we propose and evaluate several query processing optimizations for prospective search . Our experimental evaluation shows that these techniques provide significant performance benefits and allow us to match thousands of incoming documents per second against millions of subscription queries per node .
∗CIS Department , Polytechnic University , Brooklyn , NY 11201 . uirmak@cispolyedu Part of this work was performed during a summer internship at NEC Laboratories .
†CIS Department , University of Pennsylvania , Philadelphia , PA 19104 . svilen@seasupennedu Part of this work was performed during a summer internship at NEC Laboratories .
‡CIS Department , Polytechnic University , Brooklyn , NY 11201 . suel@polyedu Supported by NSF Awards IDM 0205647 and CCR 0093400 , and the New York State Center for Advanced Technology in Telecommunications ( CATT ) at Polytechnic University .
§NEC Laboratories America ,
Inc . , Princeton , NJ 08540 .
{samrat@nec labs.com , rauf@nec labscom}
The growth of the world wide web to a size of billions of pages , and the emergence of large scale search engines that allow real time keyword searches over a large fraction of these pages , has fundamentally changed the way we locate and access information on all kinds of topics . Such search engines work by downloading pages from the web and then building a full text index on the pages . Thus , they are retrospective in nature , as they allow us to only search for currently already existing pages – including many outdated pages . An alternative approach , sometimes called prospective search , allows a user to upload a query that will then be evaluated by the search engine against documents encountered in the future . In essence , the user subscribes to the results of the query . The user can be notified of new matches in one of several ways , eg , via email , or through a desktop based or web based RSS reader . Popular currently available implementations of prospective search include the News Alert feature in Google News , or the PubSub subscription service for finding matches in RSS feeds [ 1 ] . Current standard web search engines index the crawled collection of pages using a text index structure called an inverted index , which consists of many inverted lists . In particular , for every word w that occurs anywhere in the collection , there is a corresponding inverted list lw that stores the IDs of all documents that contain w , together with additional information such as the number of occurrences in the document and their precise locations and maybe contexts . A search request can be processed by computing the intersection of the inverted lists corresponding to the search terms , and then ranking the results based on the position and context information stored in the lists plus other data derived from link analysis or user behavior.1
1This is a simplified view , and for performance reasons large en gines do not actually compute the complete intersection of all terms .
A naive implementation of a prospective search engine might simply execute all the subscription queries periodically against any newly arrived documents . However , if the number of subscriptions is very large , this would result either in a significant delay in identifying new matches , if we only execute the queries very rarely , or a significant query processing load for the engine . A smarter approach , first studied in detail as part of the SIFT project in [ 30 ] , essentially reverses the roles of the documents and the queries . That is , we build an inverted index on the subscriptions instead of the documents , and then issue a number of queries into the index for each newly arriving document . We note , however , that the two cases are not completely symmetric , and that some new issues arise in the prospective search case . In this paper , we follow this approach , and study techniques for optimizing the performance of prospective search engines . In particular , we are looking at the case where there are millions of subscriptions , and documents are discovered at a rate of hundreds or thousands per second . Our perspective is somewhat “ keywordcentric ” : We assume that subscriptions are at least primarily keyword based , and thus an approach based on inverted index structures seems most appropriate . We note that there is also a significant amount of previous work on how to evaluate more structured types of subscriptions , eg , against relational or XML data . This scenario , often studied in the context of streaming databases or trigger processing , differs from ours in important ways , though there are also many relevant ideas ; we will discuss this relationship later on . trieved through RSS feeds , and users can then access these items through an RSS reader . Thus , a user can , eg , follow a topic across a large number of weblogs without visiting each weblog or subscribing to its feed .
• Subscriptions in Basic Search : Query subscriptions can also be very useful in general purpose web search , in particular when looking for information about very focused or emerging topics where only a limited amount of information is currently available . As we will see , this might result in substantial performance challenges for large search engines if such services are widely adopted by millions of users .
• Ad Placement : Techniques for high speed processing of subscriptions are also highly relevant in the context of ad placement systems such as Google AdWords or AdSense . An advertiser buying a set of keywords essentially subscribes to a query containing these words . In the simplest case , these subscriptions are only evaluated against incoming search requests ( ie , very short documents ) , but in more advanced scenarios subscriptions may also be evaluated against some of the returned search results ( or synopses of these ) , or against web pages participating in the AdSense program for possible display on those pages . ( Such pages might be crawled continuously during the day to adjust the ad placement to newly posted content , say on a popular weblog . )
1.1 Applications of Prospective Search
1.2 An Example Scenario
We now briefly describe the main applications of prospective search that motivate our work .
• Google News and Specialized Search : Google News extracts news articles from various online sources and organizes them for searching and browsing . It also allows users to subscribe to a keyword search , in which case they will be notified via email of any newly discovered results matching all the terms . Similar services are available for some other specialized search applications , for example when searching for jobs or real estate , though some of these scenarios involve queries that are more structured ( eg , with conditions such as price < 200000 ) .
• Subscriptions in RSS Feeds : This scenario was the primary motivation for our work , and is discussed in more detail in the next subsection . In a nutshell , services such as PubSub [ 1 ] allow users to subscribe to queries that are evaluated against new items re
Our work is primarily motivated by a scenario involving prospective search in RSS feeds that arises in an RSSbased system for content distribution currently under development at NEC Labs [ 28 ] . The system is based on a highly distributed architecture for aggregating RSS feeds that allows desktop and mobile users to subscribe to certain feeds through a client based RSS reader . Our goal is to augment this system with keyword search capabilities for both retrospective and prospective search . Thus , a user should be allowed to subscribe to a keyword search that is executed over some or all of the RSS sources , say , a search for “ niger AND uranium ” over all political webblogs , all blogs on blogspot ( a large blogging site ) , or all blogs on a list of 20 personal favorites . We note that the output of such a subscription can be seen as just another feed that could possibly be shared with or searched by other users . Before outlining this architecture , we briefly discuss RSS feeds . RSS ( RSS 2.0 : Really Simple Syndication ) is an XML based data format that allows web sites and we
2 blogs to syndicate their content by making all new content , or at least meta data about new content , available at a specified location . Thus , rather than repeatedly browsing or crawling the site for new items , we can find such content by periodically downloading the corresponding RSS file , also called an RSS feed or channel . The RSS feed itself consists of a sequence of XML records , one per newly added item on the site , where each record contains a few elements ( fields ) such as the title , author , and URL of the newly added item , and a description which might be a summary or possibly the complete new content . In many cases the current RSS file only contains the last few items that were added ; thus , for sites with a lot of new content the RSS file needs to be downloaded frequently enough in order to not miss any new items . There are a number of existing weblog and RSS search engines that are based on RSS feeds , including PubSub , Bloglines , Blogpulse , Technorati , and Feedster , as well as recent offerings by the major search engine companies . The Syndic8 Personal List System [ 2 ] provides a feed directory , and the study in [ 25 ] presents an analysis on RSS feed characteristics and client behavior . While RSS records are structured , and users may decide to utilize this structure in their queries ( eg , by restricting some keywords to matches in the title , or by limiting the query to some range of publications dates ) , we view the RSS search problem as primarily a keyword search problem . We note that many aspects of such structured queries can also be very efficiently addressed within an inverted index structure , and since the keywords provide for a large share of the selectivity in typical queries , we expect keyword search to be the main performance challenge ; we will discuss this issue in detail in Subsection 14
Figure 1.1 : Architecture of a distributed system for RSSbased content distribution .
The basic architecture of the envisioned system is
3 shown in Figure 11 In the system , clients ( at the bottom ) upload their subscriptions into one of a number of FPS ( Forward Proxy System ) nodes , which store the subscriptions and also temporarily store any results of the subscription . In addition , each FPS forwards its queries to one or more matching nodes ( MNs ) , which perform the actual matching with newly arriving RSS items and send any result back to the FPS . Thus , the FPS nodes are acting as proxies for the clients , which include mobile clients that may only periodically check with their FPS for new results . RSS feeds enter the system through a crawling node ( CN ) at the top , which periodically checks a large number of RSS sources for new items . New RSS items are then forwarded in two directions : First , they are sent to an RSS storage and indexing system ( on the left ) that permanently stores them and that also implements retroactive RSS search based on a fairly standard search engine architecture . Second , all new items are also routed to one or more matching nodes in order to be matched against the subscriptions . Matching nodes in the same subnetwork may be organized under a joint master for more efficient broadcast of the RSS items . Our focus in this paper is on the efficient implementation of the matching nodes . Our goal is to enable tens of millions of keyword subscription queries to be matched against thousands of incoming RSS items per second . There are a number of other design decisions and challenges in this architecture that we do not address . For example , queries could be matched against RSS items consisting of only titles and a summary , or the crawling node could fetch the complete new document for matching , by crawling the associated URL . For each match that it receives , an FPS might decide to prefetch the complete item from the storage system , and might rank and further analyze the matched content .
1.3 Problem Setup
We now formally introduce the problem we consider in this paper . We are given n queries q0 to qn−1 , where each query qi contains si terms ( keywords ) ti,0 , . . . , ti,si−1 . We define T as the union of all the qi , ie , the set of terms that occur in at least one query . The terms in a query may be arranged in some Boolean formula , though we will mainly focus on the case of the intersection of the terms . Given these queries , we are allowed to precompute appropriate data structures , say , an inverted index . After preprocessing the queries , we are presented with a sequence of documents d0 , d1 , . . . , where each document dj is a set of terms {wj,0 , . . . , wj,s′ −1} . We assume that dj ⊆ T for all j ; this can be enforced by pruning from dj any terms that do not occur in any query qi . We are required to process the documents one by one where for each dj we have to determine all qi such that dj matches j qi . ( We could also allow the documents dj to be processed in batches of some size , but we did not observe any performance improvements from this . ) Within our matching system , queries are assigned integer query IDs and documents are assigned integer document IDs , and all terms in the queries and documents are replaced by integer term IDs . The output of the matching process is a stream of ( query ID , document ID ) pairs indicating matches . While retrospective search engines typically store their index on disk , we assume that for prospective search , all the index structures fit into main memory . To justify this , we observe that with current memory sizes of a few GB , tens of millions of queries can be kept in memory on a single machine , at least for the types of queries we expect . Some applications may involve even more queries , but our results indicate that in this case , CPU cycles become a bottleneck before main memory . Thus , unless we have a fairly small number of incoming documents per second , we have to split large sets of queries over several machines anyway , for CPU performance reasons . Thus , the matching process may occur in parallel on several machines . There are two obvious approaches to parallelizing this process : We can partition the queries among machines and broadcast each incoming document to all machines , or we can replicate the queries on all machines and assign each incoming document to any one of the machines . We expect the former to be preferable in cases involving large numbers of queries since it leaves each machine with a smaller set of queries and thus often better cache performance , while the broadcasting of documents will usually not be a bottleneck , especially if the machines are in the same subnetwork . In our approach , we divide queries into independent partitions , with maybe a few hundred thousand or million queries each , such that a single machine can hold multiple partitions . Each partition can be independently assigned to one or several machines ( and migrated between machines ) , and documents are routed accordingly , as needed for best performance and load balancing .
1.4 Discussion of Query Semantics
We now discuss a few different possible semantics for queries involving keywords , and justify our assumptions . In particular , we discuss AND queries , ranked queries , Boolean queries , and finally queries allowing keywords and some structured elements . AND Queries : Most current search engines assume AND semantics , where a query matches any document containing all query terms , in combination with ranking . As we show , such queries can be executed very efficiently in an optimized system for prospective search ; moreover , several other interesting types of queries can
4 be efficiently reduced to AND queries . Thus , we focus on this case as we expect AND queries ( or slight generalizations of them ) to make up the bulk of the query load in many applications . Ranked Queries : Ranking is of course extremely important in search engines and also has a role to play in prospective search . Note however that top k queries , which return the k highest scoring documents , may not make a lot of sense during subscription processing . Should the system match the top 10 results in the last hour , or the last day , or since the last time a user checked for new results ? Concerning the latter , the matching process will typically be decoupled from the access pattern of the user ( which in our architecture uses the system via a proxy ) . Top k ranking can be a very useful feature in the user interface ( eg , an RSS reader ) for ordering recent matches , but is probably less useful during the matching process . Another possibility is to allow a user to specify a threshold value such that only matches with a score ( say , according to cosine or some other measure ) above the threshold are returned . However , such raw threshold values are not really meaningful to most users . ( Is a score of 0.8 on cosine good or bad ? ) This issue was addressed in the SIFT project [ 30 ] by allowing the user to select a good threshold based on examples . Another simpler type of query , “ k out of n ” , ignores term weights and simply matches all documents that contain at least k of the n query terms . Boolean Queries : Boolean queries involve a number of terms connected by AND , OR , and NOT operators . In our framework , they can be executed in two different ways : ( i ) by converting them to DNF , inserting each conjunction as a separate AND query , and then removing duplicate matches from the output stream , or ( ii ) directly without reduction to AND . Our results indicate that the first approach ( or a hybrid if there is at least one required term ) is highly preferable for performance reasons unless the DNF is large . Note that the above “ k out of n ” queries may of course result in large DNFs , but we expect that in practice most queries would fall into the first case . Keywords and Structure : In our RSS search scenario , queries are matched against items with some degree of structure . While queries that simply match keywords across all different fields of an item are often sufficient ( eg , a query such as “ broder AND hashing ” ) , in other cases it is preferable to restrict keywords to certain fields ( eg , “ broder in author AND hashing in title ” ) or to add equality or range selections ( eg , “ hashing AND author=broder AND year inrange 1988 to 2000 ” ) . It is well understood that inverted index structures with appropriate extensions can efficiently process many such queries for retrospective search , and tools such a Lucene already offer some of these features.2 Similar extensions are also possible for prospective search . We expect that for many scenarios involving keywords with additional simple conditions on structure , solutions based on an inverted index with suitable extensions are more promising in terms of performance than a relational approach with extensions for keyword search . A comparative study of this issue is beyond the scope of this paper .
2 Contributions of this Paper
In this paper , we study the efficient processing of query subscriptions in a prospective search engine that can match millions of subscriptions against thousands of incoming documents per second . We focus on the case of Boolean keyword queries , with particular emphasis on AND queries . Our main contributions are as follows :
• We describe the design of a high performance subscription matching processor based on an inverted index organization , with several optimizations based on term frequencies and a Bloom filter structure .
• We study preprocessing schemes that cluster subscriptions into superqueries that are then fed into the actual matching process .
• We evaluate our schemes on queries from a search engine trace , and show significant improvements over a baseline scheme .
There is a significant amount of previous work in this area , and we now briefly compare our results to the most closely related work . Note that a more detailed overview of related work is provided in Section 5 . The SIFT project at Stanford [ 30 ] also focused on keyword queries , and used and inverted index structure on the queries . However , the emphasis was on ranked queries in the vector space model ( eg , cosine measure ) using OR semantics , and the work did not explore optimizations in queries involving AND that are our focus here . Carzaniga et al . [ 15 ] propose a forwarding algorithm in a content based routing scheme . It also uses an inverted index for efficiently matching the subscriptions against the messages . However , in this context the messages are structured as a set of attribute/value pairs , while the subscriptions are in the form of disjunctions of conjunctions of elementary constraints defined over the attribute val
2For example , conditions such as “ broder in author ” can be handled by splitting inverted lists into several partitions for data from different fields , while an equality condition “ author=broder ” could be handled by indexing terms of the form <fieldname>:<value> for fields likely to be used in such conditions . Range queries are somewhat trickier , but can also be handled efficiently in many cases . ues . Work by Fabret et al . [ 22 ] studies how to cluster subscriptions for improved throughput ; the focus in [ 22 ] is on queries with a few categorical or numerical attributes rather than keywords , and they propose a cost based approach to compute an optimal clustering . The remainder of this paper is organized as follows . In the next section , we describe the internal architecture of our subscription matching engine and several performance optimizations that we included in our design , and then evaluate the resulting performance . Section 4 describes and evaluates additional optimizations based on query clustering that are largely orthogonal to the internal structure of the matching engine . Finally , Section 5 gives an overview of related work , and Section 6 provides some concluding remarks .
3 The Core Query Processor
We now describe the design of our core query processor for subscription matching . After introducing the basic internal structures , we present a baseline algorithm , called the primitive matching algorithm , known from previous work [ 22 , 30 , 15 ] . Subsection 3.2 describes three optimizations that significantly improve throughput , as shown in the experimental evaluation in Subection 34
3.1 Preliminaries
Recall that each query consists of a set of terms , where terms are connected via Boolean operators , with the default being AND . Each query has a unique integer query ID ( QID ) and each term has an integer term ID ( TID ) . Each incoming document has a unique document ID ( DID ) and consists of a set of TIDs , and the output of the matching algorithm consists of a stream of ( QID,DID ) pairs , one for each time a document satisfies a particular query . We assume that term IDs are assigned from 0 to |T |− 1 , the total number of different terms occurring in the queries . The terms in each query are ordered by TID ; thus we can refer to the first , second , etc . term in a query . Any incoming documents have already been preprocessed by parsing out all terms , translating them into TIDs , and discarding any duplicate terms or terms that do not occur in any query . It will also be convenient to assume that QIDs are assigned at random . Note that we expect additions and deletions of subscriptions to be handled in an amortized fashion , by periodic rebuilding of the structures ( including updating the assignments of TIDs and QIDs ) . The main data structure used in all our algorithms is an inverted index , which is also used by current retrospective search engines . However , in our case we index the
5 queries rather than the documents , as proposed in [ 30 ] . The inverted index consists of |T | inverted lists , one for each unique term that occurs in the queries . Each list contains one posting for each query in which the corresponding word occurs , where a posting consists of the QID and the position of the term in the query ( recall that terms are ordered within each query by TID ) . The QID and position can usually be stored together in a single 32bit integer,3 and thus each inverted list is a simple integer array .
3.2 A Primitive Matching Algorithm
We now describe the primitive matching algorithm , which ( with some variations ) has been studied in a number of previous works including [ 22 , 30 , 27 , 15 ] . The basic idea is as follows . We initially build the inverted index from the queries using standard index construction algorithms ; see , eg , [ 29 ] . We also reserve space for a hash table , indexed by QIDs , of some sufficient size . Given an incoming document consisting of a set of terms , we first clear the hash table , and then process the terms in the document in some sequential order . To process a term , we traverse the corresponding inverted list in the index . For each posting of the form ( QID , position ) in this list , we check if there is already an entry in the hash table for this QID . If not , we insert such an entry into the hash table , with an associated accumulator ( counter ) set to 1 . If an entry already exists , we increase its accumulator by 1 . This first phase is called the matching phase . After processing all the terms , we iterate over all created hash table entries . For every entry , we test if the final value of the accumulator is equal to the number of query terms ; if so then we output the match between this query and the document . This second phase is called the testing phase . Note that for Boolean queries other than AND , we could reserve one bit in the accumulator for each term in the query , and then instead of increasing a counter we set the corresponding bit ; in the testing phase we then check if the accumulator matches the query , usually through one or a small number of tests applying appropriate bit masks . Also , since QIDs are assigned at random , we can use the QID itself as our hash function for efficiency . We sketch the primitive matching algorithm in Figure 31 The algorithm performs an infinite loop over the incoming documents . It receives the next incoming document ( line 2 ) and clears the hash table and its accumulators ( line 3 ) . In the matching phase ( lines 4 11 ) , we traverse the inverted lists of all terms in the document and for each posting either create a new entry in the hash table , or update an existing one . During the testing
3Most queries are short and thus the position can be stored in a few bits of the integer . doc ⇐ incoming document initialize( ) for each T ID in doc do for each QID in the inverted list for T ID do accum ⇐ check hashT able(QID ) if ( accum = null ) then accum ⇐ create entry(QID , 1 ) insert hashT able(accum ) else update accum(QID )
1 : loop 2 : 3 : 4 : 5 : 6 : 7 : 8 : 9 : 10 : 11 : 12 : 13 : 14 : for each ( accum ) in the hash table do if ( accum.count = original query size ) then output(accum.QID , DID )
Figure 3.1 : The primitive matching algorithm phase ( lines 12 14 ) , we check the accumulators for any matches .
3.3 Optimizations for Primitive Algorithm
The primitive algorithm is simple and reasonably efficient , but far from optimal . We now describe three sets of optimizations to improve the performance of the algorithm . The resulting benefits are evaluated in the next subsection . Exploiting Position Information and Term Frequencies : One problem with the primitive algorithm is that it creates an entry in the hash table for any query that contains at least one of the terms . This results in a larger hash table that in turn slows down the algorithm , due to additional work that is performed but also due to resulting cache misses during hash lookups . To decrease the needed size of the hash table , we first exploit the fact that we are focusing on AND queries . Recall that each index posting contains a QID as well as the position of the term in the query . Thus , if we are processing a posting with a non zero position , then this means that the term is not the term with the lowest TID in the query . Suppose we process the terms in the incoming document in sorted order , from lowest to highest TID . This means that for a posting with non zero position , either there already exists a hash entry for the query , or the document does not contain any of the query terms with lower TID and thus the query does not match . In other words , rather than creating a new hash entry any time there is no existing hash entry , it suffices to create a hash entry whenever the position in the posting is zero , and to only update existing hash entries otherwise . As we will see , this results in significantly smaller hash table sizes . A further reduction is achieved by simply assigning TIDs to terms in order of frequency , that is , we assign TID 0 to the term that occurs the least frequent in the set of queries , and TID |T | − 1 to the most frequent term . This means that an accumulator is only created for
6 those queries where the incoming document contains the least frequent term in the query . To implement this efficiently , we split each inverted list into two parts , a smaller list containing only postings with positions equal to zero , and the rest of the list . We then perform two passes over the terms in the incoming document , a first pass over all terms where we traverse only the first part of each relevant inverted list to generate hash entries , and a second pass over all terms where we traverse the rest of each list to update existing entries . This simplifies the critical inner loop over the postings and also allows us to quickly determine the optimal hash table size for each incoming document , by summing up the lengths of the first parts of the inverted lists involved . Bloom Filters : As a result of the previous set of optimizations , hash entries are only created initially , and most of the time is spent afterwards on lookups to check for existing entries . Moreover , most of these checks are negative , ie , the corresponding entry does not exist . Our next idea is to use a Bloom filter to speed up these checks . A Bloom filter [ 8 ] is a probabilistic space efficient method for testing set membership . The main advantage of a Bloom filter is space efficiency and simplicity , which is achieved at the cost of a small number of false positives . We refer to [ 9 ] for more background on Bloom filters and their applications . In our context , integration of a Bloom filter into the algorithm is fairly straightforward . We use a Bloom filter in addition to the hash table . In the initial phase when hash entries are created , we also set the corresponding bits in the Bloom filter ; the overhead for this is fairly low . In the next phase , when we iterate only over postings with non zero position , we first perform a lookup into the Bloom filter to see if there might be a hash entry for the current QID . If the answer from the Bloom filter is negative , we immediately continue with the next posting ; otherwise , we perform a lookup into the hash table . Use of a Bloom filter has two advantages . The Bloom filter structure is small and thus gives better cache behavior , and the innermost loop of our matching algorithm is also further simplified . We experimented with different settings for the size of the Bloom filter and the number of hash functions ; in the end , we found a single hash function ( trivial Bloom filter ) to perform best . Partitioning the Queries : As discussed in the previous optimizations , a critical issue is the size of the required hash table and Bloom filter structures , and any cache misses while accessing these structures have a significant impact on performance . However , these structures increase linearly with the number of query subscriptions , and thus eventually grow beyond the L1 or L2 cache sizes . This leads to our next optimization . Instead of creating a single index , we partition the queries into a
7 number p of subsets and build an index on each subset . In other words , we partition the index into p smaller indexes . An incoming document is then processed by performing the matching sequentially with each of the index partitions . While this does not decrease the number of postings traversed , or the locality for index accesses , it means that the hash table and Bloom filter sizes that we need are decreased by a factor of p . initialize( ) for each T ID in doc do for each QID in 1st part of inv . list for T ID do for each TID in doc do for each ( accum ) in the hash table do if ( accum.count = original query size ) then output(accum.QID , DID ) for each QID in 2nd part of inv . list for T ID do if ( check bloom(QID ) = 1 ) then accum ⇐ create entry(QID , 1 ) insert hashT able(accum ) insert bloom(QID ) accum ⇐ check hashT able(QID ) if ( accum 6= null ) then update accum(QID ) doc ⇐ incoming document qSort(doc ) {sort terms by TIDs in increasing order} for i = 1 to p do
1 : loop 2 : 3 : 4 : 5 : 6 : 7 : 8 : 9 : 10 : 11 : 12 : 13 : 14 : 15 : 16 : 17 : 18 : 19 : Figure 3.2 : Final algorithm with Bloom filter and index partitioning . Figure 3.2 shows the resulting algorithm . The terms in the incoming document are sorted in line 3 . We now loop over all p partitions ( line 4 ) . For each partition , we first clear the hash table and Bloom filter structures ( line 5 ) , and then traverse the first parts of the relevant inverted lists in the current index partition to initialize the accumulators . In lines 11 16 , we traverse the second parts of the relevant inverted lists in the current index partition to update the accumulators . We then test for any matches in the current partition ( lines ( 17 19 ) before moving to the next index partition . While we initially considered this index partitioning approach for performance reasons only , there are other important advantages . In particular , we can treat each partition as a completely independent index , possibly with its own local QID and TID assignment , that can be freely moved between different matching nodes for load balancing purposes . ( Each machine may have a moderate number , say up to a few dozen , of partitions . ) When a user subscribes to a new query , this subscription is routed to one partition , either at random or according to some rules , and partitions may independently perform rebuilding under updates . For example , we could route all new subscriptions to one partition , similar to the way search engines often separately index very recently crawled pages to avoid costly rebuilds of the entire index .
3.4 Experimental Evaluation
We now evaluate the performance of our query processor and the impact of the different optimizations . We were unable to find any large publicly available query subscription logs , and did not feel that artificial data sets would provide a realistic benchmark . For this reason , we decided to use queries from available search engine query logs , in particular queries from a 2001 trace of the Excite search engine . We note that query subscriptions in a prospective engine , even a general one as opposed to specialized services such as Google News , would likely be different in certain ways from standard retrospective queries ; in particular , we would not expect as many extremely broad queries that result in many millions of matches on large engines . For this reason , we will also look at how performance changes with query selectivity , by looking at different subsets of the query logs . We preprocessed the traces by removing any duplicate queries . We also removed any queries that contained more than 32 terms ; there were only 43 such queries out of a total of 1077958 distinct queries . We also removed stop words from the queries , and converted all terms to lower case . We selected 10000 web pages at random from a large crawl of over 120 million pages from Fall 2001 , to be used as incoming documents . To experiment with numbers of queries beyond the size of the query log , we replicated the queries several times according to a multiplier between 1 and 14 , for a maximum size of about 15 million queries . We note that the core query processor does not exploit similarities between different queries , and thus we believe that this scaling approach is justified . Later , in Section 4 , we will incorporate clustering techniques into our system that exploit such similarities ; for this reason we will not use a multiplier in the later evaluation of the clustering schemes , which limits us to somewhat smaller input sizes .
# of queries in preprocessed Excite trace : # of unique terms in queries : # of postings in index : # of documents in test run : # of queries in test run : # of terms per incoming document : # of postings traversed per document : # of postings with position=0 traversed :
1077958 271167 3633970 10000 1077958 144.37 199262.33 6629.67
Table 3.1 : Query log and inverted index statistics , plus statistics on index lookups per incoming document .
Some statistics on the query logs , documents , and resulting inverted index lookups are shown in Table 31 As we see , there are 271167 unique terms in the query log , and each query contains about 3.4 terms on average . Each incoming document contains about 144 dis tinct terms that also occur in the queries . For each document , our algorithms will visit about 200000 postings , or about 1400 postings per inverted list that is traversed . Of those postings , only about 6630 have position zero if we assign TIDs according to term frequencies . In the experiments , we report the running times of the various optimizations when matching different numbers of queries against 10000 incoming documents . The experiments are performed on a machine with a 3.0 Ghz Pentium4 processor with 16 KB L1 and 2 MB L2 cache , under a Linux 2612 Gentoo r10 environment . We used the gcc compiler with Pentium4 optimizations , and also checked results against runs under Intel ’s icc compiler , with comparable results . We also used the vtune performance tools to analyze program behavior such as cache hit ratio etc . In the charts , we separately show the times spent on the matching and testing phases . Note that the matching phase includes all inverted index traversals and the creation and maintenance of the accumulators , while the testing phase merely iterates over the created accumulators to identify matches .
Figure 3.3 : Running times of the various algorithm optimizations for different numbers of queries . In Figure 3.3 , we show the time spent by four versions of our query processor : ( i ) the primitive one , ( ii ) the version with optimization for AND and assignment of TIDs by frequency , ( iii ) same with additional Bloom filter , and ( iv ) same with Bloom filter and index partitioning with optimal choice of the number of partitions . We show total running times in seconds for matching 10000 documents against the queries with multipliers of 1 , 2 , 4 , 8 , 10 , and 14 ( ie , between about 1.08 and 15 million queries ) . As we see , each optimization gives signifi
8 cant performance benefits . For example , the best method ( iv ) takes less than 20 seconds to match 1.08 million queries against 10000 documents , which according to Table 3.1 involves traversal of about 100 million index postings per second . fewest number of matches to the 20 % with the most . In the Figure 3.6 , we show how the running times of the algorithms change as we go from queries with very few results ( leftmost 4 bars ) to queries with very many results ( rightmost 4 bars ) . Not surprisingly , queries with many matches are more costly . We note that in Figure 3.6 we use a query multiplier of 1 , resulting in only about 215000 queries per set ; this explains why partitioning does not seem to give any benefits in the figure . ( Results for other multipliers are omitted due to space constraints . )
Figure 3.4 : Running times of the algorithms versus number of queries , for 10000 documents .
Figure 3.5 : Number of documents processed per second . In Figures 3.4 and 3.5 , we plot the total running times and throughput in documents per second , respectively , of the four algorithms versus the number of queries . At first glance , running times are roughly linear in the number of queries . More exactly , they are slightly more than linear for the first three algorithms , due to the increased sizes of the hash table and Bloom filter structures resulting in more cache misses , while the best algorithm ( iv ) remains linear by increasing the number of partitions as the number of queries increases . As discussed , many of the Excite queries may have much larger results sizes than typical subscription queries might have . To examine possible relationships between matching performance and query selectivities , we partitioned our queries into quintiles according to selectivity . To do so , we matched all queries against a larger collection of around 144000 documents ( disjoint from the set of 10000 we used for testing ) , and counted the number of matches of each query . We then partitioned queries into five subsets , from the 20 % with the
Figure 3.6 : Running times versus query selectivities for the various algorithms , with multiplier 1 . To illustrate the benefits of index partitioning , we performed additional runs on a machine with 512 KB instead of 2 MB of L2 cache . As shown in Figure 3.7 , index partitioning resulted in a gain by about a factor of 4 for the largest query set . On the 2 MB machine , a similar effect is expected as we further increase our query multiplier . ( We cannot present this here due to time constraints as we need to first modify our experimental setup to copy with more than 224 queries . )
Figure 3.7 : Benefit of best possible index partitioning on a machine with smaller L2 cache . Finally , a few remarks on supporting Boolean queries other than AND . As we have seen , AND semantics enable significant performance optimizations that outperform the primitive algorithm by a factor of 5 to 10 on large query sets . As mentioned , one way to deal with general Boolean queries is to convert them to DNF , index each conjunction as a separate query , and then remove duplicate matches in the output stream . Moreover , our optimizations do not require strict AND semantics
9 between all terms , but only an AND between the least frequent term and the rest of the query . As a result , we expect that most Boolean queries that arise in practice can be handled within our approach without reverting to the primitive algorithm . Proving this seems difficult though as it is unclear how to obtain realistic large data sets with “ typical ” Boolean queries .
4 Optimizations using Query Clustering
In the previous section , we focused on optimizing the core subscription processor using various techniques . In this section , we attempt to obtain additional performance benefits by performing clustering of subscriptions , thus exploiting similarities and relationships between different subscriptions . This is done in a preprocessing step that is largely independent of the core subscription processor , and thus the resulting improvements are orthogonal to the earlier techniques . We note that clustering of subscriptions has been previously studied , eg , in [ 22 ] , but in the context of more structured queries involving a small number of numerical and categorical attributes .
4.1 Analysis of Containment Relations
We started out with a naive approach . We noticed that there were a large number of queries that were properly contained in other queries , and that this fact could be exploited to improve the matching performance . Thus , in a primitive query processor , we could simply remove any query q that is completely contained in another query q′ from the inverted index and hash table , and later test for a match for q during testing for q′ . In an optimized AND query processor where hash table entries are only created for postings with position zero , we need to impose an additional condition on the relation between q and q′ : They need to share the same least frequent query term .
Contained in another query With same least freq term Total number of queries
# of Queries
272248 222713 1077958
Percent 25.26 % 20.66 % 100 %
Table 4.1 : Number of queries contained in other queries . Table 4.1 shows that about 25 % of all queries are contained in some other query , and that around 20 % satisfy the more stringent condition needed for the optimized subscription processor . While this might give a reasonable improvement in performance , we would like to do better by exploiting similarities between queries that are not properly contained but have a significant overlap . To evaluate the potential for this , we chose 1000 queries at random and looked at what percentage of the terms in each query was contained in the most similar query from the entire query log .
Figure 4.1 : Partial containment analysis .
The result is plotted in Figure 4.1 , which shows that only 5 % of all queries do not have any common term with any other query . Moreover , for around 65 % of all queries there exists at least one other query in the log that contains at least half of all the terms in the query . Finally , around 25 % of the queries are fully contained in at least one other query , as already shown in Table 41
4.2 A Clustering Approach
This lead us to the following simple approach for clustering subscription . In a preprocessing step , we cluster all queries into artificial superqueries of up to a certain size , such that every query is contained in a superquery and shares the same least frequent term with a superquery ( and thus with all other queries in the cluster ) . Then we present these superqueries to the query processor , which indexes them and performs matching exactly as before . The only changes to the core subscription processor are as follows : ( i ) During matching , we set appropriate bits in the accumulators for each update instead of counting ( as described in Subsection 3.2 ) , and ( ii ) in the testing phase we need to test each query that is contained in a superquery that has an accumulator . To do this test , we create a simple structure for each superquery during preprocessing that contains a list of the QIDs of the contained queries , plus for each QID a bit mask that can be used to test the superquery accumulator for this subquery . In order to be able to use our optimized subscription processor , we limit our clustering approach to queries sharing the same least frequent term . We now discuss briefly how clustering impacts the cost of matching . Consider any two queries ( or superqueries ) that share the same least frequent term . Note that by combining these two queries into one superquery , we are guaranteed to decrease the size of the index by at least one posting . Moreover , the number of hash entries that are created and the number of accumulator updates that are performed during matching , will never increase but may often decrease as a result of combining the two queries . This would in
10 dicate that we should simply combine all queries with the same least frequent term into one potentially very large superquery , but this misses an important issue : We need at least one bit per term in the superquery for the hash table accumulator , and thus a very large superquery would result in higher costs for both testing and hash table accesses . However , this effect is not easy to capture with a formal cost model for clustering . In particular , if we restrict superqueries to at most 32 terms ( in addition to the least frequent term ) , then the accumulator can be kept in a single word and testing of each subquery in the testing phase consists of a simple AND with a 32 bit mask . We might also find it beneficial to allow superqueries with up to 64 terms , particularly on 64 bit processors . For very large superqueries , things get more complicated as the cost of testing depends on how close to each other the bits corresponding to a particular subquery are in the accumulator of the superquery . We omit a more detailed discussion due to space constraints , but we see little benefit for our scenario in a general formal model similar to the cost model in [ 22 ] for small numbers of attributes . Instead , we will impose an upper bound b on the size of each superquery , where b = {32 , 64 , 96 , 128} , and try to minimize index size under this constraint . In general , this problem is still intractable , and we will focus on some heuristics .
4.3 Greedy Algorithms for Clustering
All the algorithms we present in this subsection follow the approach discussed in the previous subsection . They start out by initially grouping all queries into pools based on their least frequent terms , and then separately build superqueries within each pool . Note that if we use index partitioning , we should make sure to assign all queries in a pool to the same partition . Random Selection : The simplest approach starts with the empty superquery and then repeatedly picks an arbitrary query from the pool and merges it into the superquery , as long as the resulting superquery has at most b = 32 terms ( apart from the least frequent term ) . If the result has more than b terms , then we write out the old superquery and start a new one . This algorithm is obviously fast ( linear time ) but does not try to make any smart decisions at all . Alphabetical Ordering : This algorithm is almost as fast but a little smarter . We take all queries in the same pool and first sort them in reverse alphabetical order recall that the terms in each query are sorted by frequency and thus we sort according to most common , second most common , etc . terms . We then consider queries in sorted order as we construct superqueries , rather than in arbitrary order .
Overlap Ratio : The third greedy algorithm builds superqueries by checking all remaining queries in the pool to find the one with the best match , ie , a query that has a lot of terms in common with the current superquery . This takes time quadratic in the size of the query pool , at least if implemented naively without optimizations for quickly finding good candidates , but should result in a better clustering of queries into superqueries . Pseudocode for the resulting algorithm is shown in Figure 4.2 , where in each step we look for the query with the largest overlap with the current superqueries . Let c be the number of common terms between a candidate query and the current superquery . We considered two definitions of overlap , ( i ) the ratio of c to the size of the resulting superquery , and ( ii ) the ratio of c to the size of the candidate query . Results were quite similar , but with slight advantages for the former ( for reasons we still do not quite understand ) .
SQ ⇐ empty while ( pool 6= empty ) do
1 : queries ⇐ quick sort(queries.T ID[0 ] ) 2 : pool list ⇐ create pools(queries ) 3 : for each pool in pool list do 4 : 5 : 6 : 7 : 8 : 9 : 10 : 11 : 12 : 13 : 14 : 15 : 16 : 17 : Figure 4.2 : Greedy method based on maximizing query overlap .
SQ ⇐ ( SQ union q max ) remove f rom pool(pool , q max ) update query list(SQ , q max ) update f ilter mask(SQ , q max )
SQ list.append(SQ ) SQ ⇐ empty q max ⇐ null for each query in pool do o ⇐ overlap(SQ , query ) identify q max with largest o if ( q max 6= null ) then else
4.4 Experimental Evaluations
Recall that in Section 3.4 , we used simple replication based on a multiplier to increase the number of queries in our data set . Of course , this technique cannot be used for the clustering approach , since the proposed clustering algorithms exploit the similarities among the queries in the collection . In order to obtain at least a slightly larger collection of queries , we combined our Excite queries with another set of queries from the AltaVista search engine . We present some statistics about this combined query set in Table 42 We start our evaluation by first comparing the performance of the proposed clustering algorithms in Figure 43 On the left , we have the best algorithm from the previous section ( with Bloom filter and index partitioning ) . As we see , even the most naive clustering algo
11
Number of queries : Number of unique terms : Number of postings :
3069916 922699 9239690
Table 4.2 : Statistics of the combined data set with queries from both Excite and AltaVista rithm gives significant benefits , and the algorithm based on overlap outperforms all others . lators during matching on the bottom . As we see , there is a slight benefit in allowing up to 64 terms , but for 96 and 128 terms any further gains are lost to additional testing time .
Match 13.71 12.96 12.82 12.70
Super Queries
939779 900359 890258 886101
Test 1.34 1.63 1.79 1.98
Total 15.05 14.59 14.61 14.68 Postings Accums 6543883 5522510 5400181 3527224 2597491 5356174 5334635 2145484
SQ1 SQ2 SQ3 SQ4
SQ1 SQ2 SQ3 SQ4
Table 4.4 : Running times and statistics for superqueries using 1 , 2 , 3 , and 4 unsigned integers as accumulators .
Figure 4.3 : Comparison of clustering algorithms on the combined query set .
In Table 4.3 , we show the number of superqueries created by each clustering algorithm , the number of postings in the resulting inverting index , and the number of accumulators created during the matching process . As we see , clustering decreases the number of index postings by about 40 % , but the number of accumulators created during the matches is reduced by a factor of up to 20 . This is because clustering is most effective for large query pools that have a significant number of queries with the same least common query term that can be combined ; these are also the least frequent terms that are most common in the incoming documents and thus most likely to result in the creation of an accumulator .
( Super ) queries
Random Alphabetical Overlap Best
957366 948417 939779 3069916
Postings 6089165 5784684 5522510 9239690
Accums 8870966 7670446 6543883 130691462
Table 4.3 : Comparison of the clustering algorithms and the best algorithm .
In the above experiments , we limited superqueries to at most b = 32 terms in addition to the least frequent term . Next , we investigate if there are benefits in allowing larger superqueries with up to 64 , 96 , and 128 terms . Thus , these variants use two , three , and four unsigned integers for the accumulators and for the bit masks used during testing . Table 4.4 shows the resulting running times for 10000 documents on the top , and the number of superqueries , index postings , and generated accumu
Figure 4.4 : Running times observed on the different query selectivity quintiles .
We also tried to further improve the greedy approach based on overlap by looking further ahead at the next 2 and 3 sets that can be added , as opposed to a strictly greedy approach where we take one step at a time . However , we did not observe any measurable gains , indicating that maybe the overlap approach is already close to optimal . Finally , in Figure 4.4 , we report the performance of clustering algorithms on the different selectivity ranges introduced in Section 3.4 , showing that again queries with many results are more expensive to match . We summarize our results by showing the throughput rates in documents per second obtained by our various matching algorithms in Figure 4.5 , on the Excite set and the combined set of Excite and AltaVista queries . We see that overall , throughput increases by more than a factor of 20 when all techniques are combined .
5 Related Work
In the following , we give a brief summary of related work . Our work is most closely related to the SIFT
12 we follow a centralized approach . However , the forwarding algorithms used by routing nodes in content based networking are related , as they have to select neighbor routers that need the message . In [ 14 ] , a fast forwarding algorithm is described that uses an inverted index structure built from the subscriptions , and that is essentially a counting algorithm for AND queries . The implementation of triggers and continuous queries in database systems is also related ; see , eg , [ 19 , 24 ] . The stream processing engines , such as [ 4 , 6 , 18 , 3 ] , which are also known as continuous query processors , usually perform computations on sliding windows of tuples , and support operators such as Filter , Aggregate and Union . Finally , there are a number of approaches for XML filtering that are related ; see [ 23 , 5 , 16 , 20 ] . These approaches usually support a subset of XPath queries on XML documents , and their main goal is to support more expressive ways to specify interests , while our goal is to support larger numbers of ( less expressive ) subscriptions against high rates of incoming documents .
6 Conclusions
In this paper , we studied the problem of efficient subscription matching in prospective search engines . We described several techniques for optimizing the matching performance of keyword based queries , and evaluated their benefits experimentally . Our results show that an efficient implementation can match millions of subscriptions per node against hundreds or thousands of incoming documents . However , there are a number of open questions for future research . One issue we have not addressed is how to efficiently update the index and superquery structures . We think that the right approach would most likely utilize an amortized solution , similar to those often used with standard inverted indexes . Thus , newly added queries are temporarily kept separate from the existing queries , resulting in somewhat higher processing cost per query during this time . Periodically , an entire partition with a few hundred thousand queries is rebuilt , and new queries are integrated and outdated queries removed at this point . However , it might be interesting to evaluate such schemes experimentally . Additional performance improvements might be possible based on better clustering , or maybe by adapting cluster and index structure in an online fashion based on past results . Finally , it would also be of interest to study in more detail the performance of inverted index based approaches on queries that involve both keywords and structured query elements . How far can this be pushed , and when does a database type approach become more appropri
Figure 4.5 : Number of documents processed per second for Excite and for the combined query set . project in [ 30 ] , which considers the problem of selective dissemination of information : Users define their interests through profiles which are checked against new incoming documents to identify matches . SIFT also uses an inverted index structure to efficiently match documents to profiles , but profiles are represented in a vector space model . Thus , users can specify term weights and a relevance threshold that are then used in identifying matched documents . In our work we focus mainly on AND queries as we expect them to dominate many scenarios . We propose various optimizations for such queries , and introduce a new clustering technique to further improve throughput rates . A main memory algorithm for matching events against subscriptions is proposed in [ 22 ] , where an event is an attribute/value pair , and a subscription is a conjunction of ( attribute , comparison operator , constant ) predicates . The proposed algorithm also employs a clustering approach . The created clusters have access predicates , where an access predicate is defined as a conjunction of equality predicates . The performance of the matching algorithm varies significantly depending on the clustering instances chosen and the access predicates used . The scenario we consider here is rather different , as the terms specified in the queries as well as the content provided in the incoming document are textual in nature . Also , our clustering approach is different and creates clusters with new artificial superqueries . Another body of related work is in the area of contentbased networking and publish/subscribe communication systems [ 13 , 7 , 21 ] . In this model , subscribers specify their interests by means of conjunctive predicates , while sources simply publish their messages ( events ) , which are usually structured as a set of attribute/value pairs . The goal is to efficiently identify and route messages to subscribers whose interests match the messages . Such routing schemes include [ 12 , 10 , 26 , 11 , 17 ] . In our case ,
13
[ 16 ] C . Y . Chan , P . Felber , M . N . Garofalakis , and R . Rastogi . Efficient filtering of XML documents with XPath expressions . The VLDB Journal , 11:354–379 , 2002 .
[ 17 ] R . Chand and P . A . Felber . A scalable protocol for content based routing in overlay networks . In Proc . of the 2nd IEEE Int.Symposium on Network Computing and Applications , 2003 .
[ 18 ] S . Chandrasekaran , O . Cooper , A . Deshpande , M . J . Franklin , J . M . Hellerstein , W . Hong , S . Krishnamurthy , S . Madden , F . Reiss , and M . A . Shah . TelegraphCQ : Continuous Dataflow Processing . In Proc . of ACM SIGMOD Conf . , 2003 .
[ 19 ] J . Chen , D . J . DeWitt , F . Tian , and Y . Wang . NiagaraCQ : a scalable continuous query system for Internet databases . In Proc . of the ACM SIGMOD Conf . , 2000 .
[ 20 ] Y . Diao , S . Rizvi , and M . J . Franklin . Towards an internetscale xml dissemination service . In Proc . of the 30th Int . Conf . on Very Large Data Bases , 2004 .
[ 21 ] P . T . Eugster , P . Felber , R . Guerraoui , and A M Kermar rec . The many faces of publish/subscribe . 35(2 ) , 2003 .
[ 22 ] F . Fabret , H . A . Jacobsen , F . Llirbat , J . Pereira , K . A . Ross , and D . Shasha . Filtering algorithms and implementation for very fast publish/subscribe systems . SIGMOD Record , 30(2):115–126 , 2001 .
[ 23 ] A . K . Gupta and D . Suciu . Stream processing of xpath queries with predicates . In Proc . of ACM SIGMOD Conf . , 2003 .
[ 24 ] E . N . Hanson , C . Carnes , L . Huang , M . Konyala , L . Noronha , S . Parthasarathy , J . B . Park , and A . Vernon . Scalable Trigger Processing . In Proc . of the 15th Int . Conf . on Data Engineering , 1999 .
[ 25 ] H . Liu , V . Ramasubramanian , and E . G . Sirer . Client Behavior and Feed Characteristics of RSS , A PublishSubscribe System for Web Micronews . In Proc . of Internet Measurement Conf . , 2005 .
[ 26 ] O . Papaemmanouil and U . Cetintemel . Semcast : SemanIn tic multicast for content based data dissemination . Proc . of the 21st Int . Conf . on Data Engineering , 2005 .
[ 27 ] J . Pereira , F . Fabret , F . Llirbat , and D . Shasha . Efficient In matching for web based publish/subscribe systems . Conf . on Cooperative Information Systems , 2000 .
[ 28 ] A . Saxena , S . Dan , S . Ganguly , S . Bhatnagan , and R . Izmailov . Design and implementation of meta data syndication network and SONATA RSS aggregator . Technical Report 2004 L082 , NEC Laboratories America , Inc . , Sept . 2004 .
[ 29 ] I . H . Witten , A . Moffat , and T . C . Bell . Managing Gigabytes : Compressing and Indexing Documents and Images . Morgan Kaufmann , second edition , 1999 .
[ 30 ] T . W . Yan and H . Garcia Molina . The SIFT information dissemination system . ACM Transactions on Database Systems , 24(4):529–565 , 1999 . ate ? One problem here is the difficulty in obtaining large real data sets for this case , and thus we are not sure about the typical structure of such queries in real applications .
References
[ 1 ] Pubsub matching service . http://pubsubcom [ 2 ] Syndic8 personal list system . http://syndic8com [ 3 ] D . J . Abadi , Y . Ahmad , M . Balazinska , U . Cetintemel , M . Cherniack , J H Hwang , W . Lindner , A . S . Maskey , A . Rasin , E . Ryvkina , N . Tatbul , Y . Xing , and S . Zdonik . The Design of the Borealis Stream Processing Engine . In Proc . of CIDR , 2005 .
[ 4 ] D . J . Abadi , D . Carney , U . C . etintemel , M . Cherniack , C . Convey , C . Erwin , E . F . Galvez , M . Hatoun , J H Hwang , A . Maskey , A . Rasin , A . Singer , M . Stonebraker , N . Tatbul , Y . Xing , R . Yan , and S . B . Zdonik . Aurora : A Data Stream Management System . In Proc . of ACM SIGMOD Conf . , 2003 .
[ 5 ] M . Altinel and M . J . Franklin . Efficient filtering of XML documents for selective dissemination of information . In The VLDB Journal , pages 53–64 , 2000 .
[ 6 ] A . Arasu , B . Babcock , S . Babu , M . Datar , K . Ito , I . Nizhizawa , J . Rosenstein , and J . Widom . STREAM : The Stanford Stream Data . In Proc . of ACM SIGMOD Conf . , 2003 .
[ 7 ] R . Baldoni , M . Contenti , and A . Virgillito . The evolution of publish/subscribe communication systems . In Future Directions of Distributed Computing , volume 2584 of LNCS . Springer , 2003 .
[ 8 ] B . Bloom . Space/time trade offs in hash coding with allowable errors . Communications of the ACM , 13(7):422– 426 , 1970 .
[ 9 ] A . Broder and M . Mitzenmacher . Network applications of bloom filters : A survey . In Proc . of the 40th Annual Allerton Conf . on Communication , Control , and Computing , pages 636–646 , 2002 .
[ 10 ] F . Cao and J . P . Singh . Efficient event routing in contentbased publish subscribe service networks . In Proc . of the 23th International IEEE Infocom Conf . , 2004 .
[ 11 ] A . Carzaniga , D . S . Rosenblum , and A . L . Wolf . Design and evaluation of a wide area event notification service . ACM Trans . on Computer Systems , 19(3):332–383 , 2001 . [ 12 ] A . Carzaniga , M . J . Rutherford , and A . L . Wolf . A routing scheme for content based networking . In Proc . of IEEE Infocom Conf . , 2004 .
[ 13 ] A . Carzaniga and A . L . Wolf . Content based networking : A new communication infrastructure . In NSF Workshop on an Infrastructure for Mobile and Wireless Systems , number 2538 in LNCS , pages 59–68 , 2001 .
[ 14 ] A . Carzaniga and A . L . Wolf . Fast forwarding for contentTechnical Report CU CS 922 01 , based networking . DepT of Comp . Science , Univ . of Colorado , 2001 .
[ 15 ] A . Carzaniga and A . L . Wolf . Forwarding in a contentbased network . In Proceedings of ACM SIGCOMM 2003 , pages 163–174 , Karlsruhe , Germany , Aug . 2003 .
14
