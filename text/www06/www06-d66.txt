Compressing and Searching XML Data Via Two Zips∗
P . Ferragina , F . Luccio
Dip . Informatica
Univ . Pisa
{ferragina,luccio}@diunipiit
G . Manzini Dip . Informatica
Univ . Piemonte Orientale manzini@unipmn.it
S . Muthukrishnan Dept Computer Science
Rutgers Univ . muthu@csrutgersedu
ABSTRACT XML is fast becoming the standard format to store , exchange and publish over the web , and is getting embedded in applications . Two challenges in handling XML are its size ( the XML representation of a document is significantly larger than its native state ) and the complexity of its search ( XML search involves path and content searches on labeled tree structures ) . We address the basic problems of compression , navigation and searching of XML documents . In particular , we adopt recently proposed theoretical algorithms [ 11 ] for succinct tree representations to design and implement a compressed index for XML , called XBzipIndex , in which the XML document is maintained in a highly compressed format , and both navigation and searching can be done uncompressing only a tiny fraction of the data . This solution relies on compressing and indexing two arrays derived from the XML data . With detailed experiments we compare this with other compressed XML indexing and searching engines to show that XBzipIndex has compression ratio up to 35 % better than the ones achievable by those other tools , and its time performance on some path and content search operations is order of magnitudes faster : few milliseconds over hundreds of MBs of XML files versus tens of seconds , on standard XML data sources .
Categories and Subject Descriptors E.1 [ Data Structures ] : Arrays , Tables , Trees ; E.4 [ Coding and Information Theory ] : Data compaction and compression ; H.3 [ Information Storage and Retrieval ] : Content Analysis and Indexing , Information Storage , Information Search and Retrieval .
General Terms Algorithms , Experimentation .
Keywords Labeled trees , XML compression and indexing . ∗Partially supported by the Italian MIUR projects Algorithms for the Next Generation Internet and Web ( ALGONEXT ) , and Pattern Matching and Discovery Algorithms on Discrete Structures with Applications to Bioinformatics ( RBIN04BYZ7 ) .
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . Distribution of these papers is limited to classroom use , and personal use by others . WWW 2006 , May 23–26 , 2006 , Edinburgh , Scotland . ACM 1 59593 323 9/06/0005 .
1 .
INTRODUCTION
In 1996 the W3C started to work on XML as a way to enable data interoperability over the internet ; today , XML is the standard for information representation , exchange and publishing over the Web . In 2003 about 3 % of global network traffic was encoded in XML ; this is expected to rise to 24 % by 2006 , and to at least 40 % by 2008 [ 15 ] . XML is also seeping into many applications [ 1 ] .
XML is popular because it encodes a considerable amount of metadata in its plain text format ; as a result , applications can be more savvy about the semantics of the items in the data source . This comes at a cost . At the core , the challenge in XML processing is three fold . First , XML documents have a natural tree structure , and many of the basic tasks that are quite easy on arrays and lists—such as indexing , searching and navigation—become more involved . Second , by design , XML documents are wordy since they nearly repeat the entire schema description for each data item . Therefore , data collections become more massive in their XML representations , and present problems of scale . As a result , XML can be “ inefficient and can burden a company ’s network , processor , and storage infrastructures ” [ 15 ] . Finally , XML documents have mixed elements with both text and numerical or categorical attributes . As a result , XML queries are richer than commonly used SQL queries ; they , for example , include path queries on the tree structure and substring queries on contents .
In this paper we address these basic challenges . In particular , we address the problems of how to compress XML data , how to provide access to its contents , how to navigate up and down the XML tree structure ( cfr . DOM tree ) , and how to search for simple path expressions and substrings . The crux is , we focus on doing all of these tasks while keeping the data still in its compressed form and uncompressing only a tiny fraction of the data for each operation .
Problems and the Background . As the relationships between elements in an XML document are defined by nested structures , XML documents are often modeled as trees whose nodes are labeled with strings of arbitrary length drawn from a usually large alphabet Σ . These strings are called tag or attribute names for the internal nodes , and content data for the leaves ( shortly Pcdata ) . See Fig 1 for an example . Managing XML documents ( cfr . their DOM tree ) therefore needs efficient support of navigation and path expression search operations over their tree structure . With navigation operations we mean :
• find the parent of a given node u , find the ith child of u , or find the ith child of u with some label .
With path expressions , we mean two basic search operations that involve structure and content of the XML document tree :
• Given a labeled subpath Π and a string γ , find either the set of nodes N descending from Π ( Π may be anchored to any internal node , not necessarily tree ’s root ) , or the occurrences of string γ as a substring of the Pcdata contents of N ’s nodes .
The first search operation , called SubPathSearch , corresponds to an XPath query having the form //Π , where Π is a fullyspecified path consisting of tag/attribute names . The second search operation , called ContentSearch , corresponds to an XPath query of the form //Π[contains(.,γ) ] , where Π is a fully specified path and γ is an arbitrary string of characters .
The text book solution to represent the XML document tree for navigation—finding parents and children of nodes in the tree—uses a mixture of pointers and hash arrays . Unfortunately , this representation is space consuming and practical only for small XML documents . Furthermore , while tree navigation takes constant time per operation , SubPathSearch and ContentSearch need the whole scan of the document tree which is expensive . In theory , there are certain sophisticated solutions ( see [ 5 , 14 ] and references therein ) for tree navigation in succinct space but they do not support the search operations above . If SubPathSearch is a key concern , we may use any summary index data structure [ 6 ] that represents all paths of the tree document in an index ( two famous examples are Dataguide [ 16 ] and 1 or 2 indexes [ 22] ) . This significantly increases the space needed by the index , and yet , it does not support ContentSearch queries efficiently . If ContentSearch queries are the prime concern , we need to resort more sophisticated approaches— like XMLnative search engines , eg XQueC [ 4 ] , F&B index [ 29 ] , etc . ; all of these engines need space several times the size of the XML representation .
At the other extreme , XML conscious compressors such as [ 21 , 3 , 8]—do compress XML data into small space , but any navigation or search operation needs the decompression of the entire file . Even XML queryable compressors like [ 27 , 23 , 10 ] , that support more efficient path search operations , incur into the scan of the whole compressed XML file and need the decompression of large parts of it in the worst case . This is expensive at query time .
Recently , there has been some progress in resolving the dichotomy of time efficient vs space efficient solutions [ 11 ] . The contribution in [ 11 ] is the XBW transform that represents a labeled tree using two arrays : the first contains the tree labels arranged in an appropriate order , while the second is a binary array encoding the structure of the tree . The XBW transform can be computed and inverted in ( optimal ) linear time with respect to the number of tree nodes , and is as succinct as the information contained in the tree would allow . Also , [ 11 ] shows that navigation and search operations over the labeled tree can be implemented over the XBW transform by means of two standard query operations on arrays : rankα(A , k ) computes the number of occurrences of a symbol α in the array prefix A[1 , k ] ; selectα(A , h ) computes the position in A of the hth occurrence of α . Since the algorithmic literature offers several efficient solutions for rank and select queries ( see [ 5 , 17 ] and references therein ) , the XBW transform is a powerful tool for compressing and searching labeled trees .
Our Contribution . The result in [ 11 ] is theoretical and relies on a number of sophisticated data structures for supporting rank and select queries . In this paper , we show how to adapt XBW transform to derive a compressed searching tool for XML , and present a detailed experimental study comparing our tools with existing ones . More precisely , our contribution is as follows .
( 1 ) We present an implementation of the XBW transform as a compressor ( hereafter called XBzip ) . This is an attractively simple compressor , that relies on standard compression methods to handle the two arrays in the XBW transform . Our experimental studies show that this is comparable in its compression ratio to the state of the art XMLconscious compressors ( which tend to be significantly more sophisticated in employing a number of heuristics to mine some structure from the document in order to compress “ similar contexts ” ) . In contrast , the XBW transform automatically groups contexts together by a simple sorting step involved in constructing the two arrays . In addition , XBzip is a principled method with provably near optimal compression [ 11 ] .
( 2 ) We present an implementation of the XBW transform as a compressed index ( hereafter called XBzipIndex ) . This supports navigation and search queries very fast uncompressing only a tiny fraction of the document . Compared to similar tools like XGrind [ 27 ] , XPress [ 23 ] and Xqzip [ 10 ] , the compression ratio of XBzipIndex is up to 35 % better , and its time performance on SubPathSearch and ContentSearch search operations is order of magnitudes faster : few milliseconds over hundreds of MBs of XML files versus tens of seconds ( because of the scan of the compressed data inherent in these comparable tools ) . The implementation of XBzipIndex is more challenging since in addition to the XBW transform , like in [ 11 ] , we need data structures to support rank and select operations over the two arrays forming XBW . Departing from [ 11 ] which uses sophisticated methods for supporting these operations on compressed arrays , we introduce the new approach of treating the arrays as strings and employing a state of the art string indexing tool ( the FM index [ 13 ] ) to support structure+content search operations over the document tree . This new approach of XBzipIndex has many benefits since string indexing is a well understood area ; in addition , we retain the benefits of [ 11 ] in being principled , with concrete performance bounds on the compression ratio as well as time to support navigation and search operations .
Both the set of results above are obtained by suitably modifying the original definition of XBW given in [ 11 ] that works for labeled trees to better exploit the features of XML documents . The final result is a library of XML compression and indexing functions , consisting of about 4000 lines of C code and running under Linux and Windows . The library can be either included in another software , or it can be directly used at the command line with a full set of options for compressing , indexing and searching XML documents .
XBzipIndex has additional features and may find other applications besides compressed searching . For example , it supports tree navigation ( forward and backward ) in constant time , allows the random access of the tree structure in constant time , and can explore or traverse any subtree in time proportional to their size . This could be used within an
XML visualizer or within native XML search engines such as XQueC [ 4 ] and F&B index [ 29 ] . There are more general XML queries like twig or XPath or XQuery ; XBzipIndex can be used as a core to improve the performance of known solutions . Another such example is that of structural joins which are key in optimizing XML queries . Previous work involving summary indexes [ 7 , 19 ] , or node numbering such as Vist [ 28 ] or Pr¨ufer [ 25 ] might be improved using XBzipIndex .
2 . COMPACT REPRESENTATION OF DOM
TREES
Given an arbitrary XML document d , we now show how to build an ordered labeled tree T which is equivalent to the DOM representation of d . Tree T consists of four types of nodes defined as follows :
1 . Each occurrence of an opening tag <t> originates a tag node labeled with the string <t .
2 . Each occurrence of an attribute name a originates an attribute node labeled with the string @a .
3 . Each occurrence of an attribute value or textual content of a tag , say ρ , originates two nodes : a text skip node labeled with the character = , and a content node labeled with the string ∅ρ , where ∅ is a special character not occurring elsewhere in d .
The structure of the tree T is defined as follows ( see Figure 1 ) . An XML well formed substring of d , say σ = <t a1="ρ1" . . . ak="ρ1"> τ </t> , generates a subtree of T rooted at a node labeled <t . This node has k children ( subtrees ) originating from t ’s attribute names and values ( ie @ai → = → ρi ) , plus other children ( subtrees ) originating by the recursive parsing of the string τ . Note that attribute nodes and text skip nodes have only one child . Tag nodes may have an arbitrary number of children . Content nodes have no children and thus form the leaves of T .1 2.1 The XBW Transform
We show how to compactly represent the tree T by adapting the XBW transform introduced in [ 11 ] . The XBW transform uses path sorting and grouping to linearize the labeled tree T into two arrays . As shown in [ 11 ] , this “ linearized ” representation is usually highly compressible and efficiently supports navigation and search operations over T . Note that we can easily distinguish between internal node labels vs leaf labels because the former are prefixed by either < , or @ , or = , whereas the latter are prefixed by the special symbol ∅ .
Let n denote the number of internal nodes of T and let ℓ denote the number of its leaves , so that the total size of T is t = n + ℓ nodes . For each node u ∈ T , let α[u ] denote the label of u , last[u ] be a binary flag set to 1 if and only if u is the last ( rightmost ) child of its parent in T , and π[u ] denote the string obtained by concatenating the labels on the upward path from u ’s parent to the root of T .
To compute the XBW transform we build a sorted multiset S consisting of t triplets , one for each tree node ( see Fig 2 ) . Hereafter we will use Slast[i ] ( resp . Sα[i ] , Sπ[i ] ) to
1Document d may contain tags not including anything , the so called empty tags ( ie <t/> or <t></t> ) . These tags are managed by transforming them to <t>λ</t> , where λ is a special symbol not occurring elsewhere in d . refer to the last ( resp . α , π ) component of the i th triplet of S . To build S and compute the XBW transform we proceed as follows :
1 . Visit T in pre order ; for each visited node u insert the triplet s[u ] = hlast[u ] , α[u ] , π[u]i in S ;
2 . Stably sort S according to the π component of its triplets ;
3 . Form XBW(d ) = h bSlast , bSα , bSpcdatai , where bSlast = Slast[1 , n ] , bSα = Sα[1 , n ] , and bSpcdata = Sα[n + 1 , t ] .
Since sibling nodes may be labeled with the same symbol , several nodes in T may have the same π component ( see Fig 1 ) . The stability of sorting at Step 2 is thus needed to preserve the identity of triplets after the sorting . The sorted set S[1 , t ] has the following properties : ( i ) Slast has n bits set to 1 ( one for each internal node ) , the other t − n bits are set to 0 ; ( ii ) Sα contains all the labels of the nodes of T ; ( iii ) Sπ contains all the upward labeled paths of T ( and it will not be stored ) . Each path is repeated a number of times equal to the number of its offsprings . Thus , Sα is a lossless linearization of the labels of T , whereas Slast provides information on the grouping of the children of T ’s nodes .
We notice that the XBW transform defined in Step 3 is slightly different from the one introduced in [ 11 ] where XBW is defined as the pair hSlast , Sαi . The reason is that here the tree T is not arbitrary but derives from an XML document d . Indeed we have that Sα[1 , n ] contains the labels of the internal nodes , whereas Sα[n + 1 , t ] contains the labels of the leaves , that is , the Pcdata . This is because if u is a leaf the first character of its upward path π[u ] is = which we assume is lexicographically larger than the characters < and @ that prefix the upward path of internal nodes ( see again Fig 2 ) . Since leaves have no children , we have that Slast[i ] = 1 for i = n + 1 , . . . , t . Avoiding the wasteful representation of Slast[n + 1 , t ] is the reason for which in Step 3 we split Sα and Slast into h bSlast , bSα , bSpcdatai .
In [ 11 ] the authors describe a linear time algorithm for retrieving T given hSlast , Sαi . Since it is trivial to get the document d from XBW(d ) we have that XBW(d ) is a lossless encoding of the document d . It is easy to prove that XBW(d ) takes at most ( 17/8)n + ℓ bytes in excess to the document length ( details in the full version ) . However , this is an unlikely worst case scenario since many characters of d are implicitly encoded in the tree structure ( ie , spaces between the attribute names and values , closing tags , etc ) . In our experiments XBW(d ) was usually about 90 % the original document size . Moreover , the arrays bSlast , bSα , and bSpcdata are only an intermediate representation since we will work with a compressed image of these three arrays ( see below ) . Finally , we point out that it is possible to build the tree T without the text skip nodes ( the nodes with label = ) . However , if we omit these nodes Pcdata will appear in Sα intermixed with the labels of internal nodes . Separating the tree structure ( ie h bSlast , bSαi ) from the textual content of the document ( ie bSpcdata ) has a twofold advantage : ( i ) the two strings bSα and bSpcdata are strongly homogeneous hence highly compressible ( see Sect . 2.2 ) , ( ii ) search and navigation operations over T are greatly simplified ( see Sect . 23 ) 2.2 Why XBW(d ) compresses well
Suppose the XML fragment of Fig 1 is a part of a large bibliographic database for which we have computed the XBW
<biblio>
<book id=1>
<author>J . Austin</author> <title>Emma</title>
</book> <book id=2>
<author>C . Bronte</author> <title>Jane Eyre</title>
</article>
</biblio>
Figure 1 : An XML document d ( left ) and its corresponding ordered labeled tree T ( right ) .
Slast 1 0 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1
Sα <biblio <book @id = ∅1 <author = ∅J . Austin <title = ∅Emma <book @id = ∅2 <author = ∅C . Bronte <title = ∅Jane Eyre
Sπ empty string <biblio <book<biblio @id<book<biblio =@id<book<biblio <book<biblio <author<book<biblio =<author<book<biblio <book<biblio <title<book<biblio =<title<book<biblio <biblio <book<biblio @id<book<biblio =@id<book<biblio <book<biblio <author<book<biblio =<author<book<biblio <book<biblio <title<book<biblio =<title<book<biblio
Stable sort
Rk
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
Slast 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1
Sα <biblio = = <book <book @id <author <title @id <author <title = = = = ∅J . Austin ∅C . Bronte ∅Emma ∅Jane Eyre ∅1 ∅2
Sπ empty string <author<book<biblio <author<book<biblio <biblio <biblio <book<biblio <book<biblio <book<biblio <book<biblio <book<biblio <book<biblio <title<book<biblio <title<book<biblio @id<book<biblio @id<book<biblio =<author<book<biblio =<author<book<biblio =<title<book<biblio =<title<book<biblio =@id<book<biblio =@id<book<biblio bSlast = 111010010011111 bSα = <biblio==<book<book@id<author<title@id<author<title==== bSpcdata = ∅J . Austin∅C . Bronte∅Emma∅Jane Eyre∅1∅2
Figure 2 : The set S after the pre order visit of T ( left ) . The set S after the stable sort ( right ) . The three arrays bSlast , bSα , bSpcdata , output of the XBW transform ( bottom ) . transform . Consider the string =<author . The properties of the XBW transform ensure that the labels of the nodes whose upward path is prefixed by =<author are consecutive in Sα . In other words , there is a substring of Sα consisting of all the data ( immediately ) enclosed in an <author> tag . Similarly , another section of Sα contains the labels of all nodes whose upward path is prefixed by , say , =@id<book and will therefore likely consists of id numbers . This means that Sα , and therefore bSα and bSpcdata , will likely have a strong local homogeneity property.2
We point out that most XML conscious compressors are designed to “ compress together ” the data enclosed in the same tag since such data usually have similar statistics . The above discussion shows that the XBW transform provides a simple mechanism to take advantage of this kind of regularity . In addition , XML compressors ( eg Xmill , Scmppm , XmlPpm ) usually look at only the immediately enclosing tag since it would be too space consuming to maintain sep
2Readers familiar with the Burrows Wheeler transform will recognize the analogy : the BWT groups together the characters which are prefixed by the same substring whereas the XBW groups together data enclosed in the same set of tags . arate statistics for each possible group of enclosing tags . Using the XBW transform we can overcome this difficulty since the different groups of enclosing tags are considered sequentially rather than simultaneously . For example , for a bibliographic database , Sα would contain first the labels of nodes with upward path =<author<article , then the labels with upward path =<author<book , and finally the labels with upward path =<author<manuscript , and so on . Hence , we can either compress all the author names together , or we can decide to compress the three groups of author names separately , or adopt any other optimization scheme . 2.3 Navigation and search using XBW(d )
Recall that every node of T corresponds to an entry in the sorted multiset S ( see Fig 2 ) . We ( logically ) assign to each tree node a positive integer equal to its rank in S . This number helps in navigation and search because of the following two properties of the sorted multiset S .
1 . Let u1 , . . . , uc be the children of a node u . The triplets s[u1 ] , . . . , s[uc ] lie contiguously in S in this order . The last triplet s[uc ] has its last component set to 1 ; the other triplets have their last component set to 0 .
2 . Let v1 , v2 denote two nodes with the same label ( ie , α[v1 ] = α[v2] ) . If s[v1 ] precedes s[v2 ] in S , then the children of v1 precede the children of v2 in S .
Example 1 In Fig 2 we have two nodes labeled <book , whose upward path is <biblio . These nodes have rank 4 and 5 , and have a total of 6 children that are stored in the subarray S[6 , 11 ] . The children of S[4 ] are S[6 , 8 ] , and the children of S[5 ] are S[9 , 11 ] . Note that Slast[8 ] = Slast[11 ] = 1 since these are the last children of their parent .
For every internal node label β , we define F(β ) as the rank of the first row of S such that Sπ is prefixed by β . Thus , for the example of Fig 2 we have F(<author ) = 2 , F(<biblio ) = 4 , F(<book ) = 6 , and so on . Suppose that the tree contains m internal nodes with label β . We can rephrase Properties 1–2 above stating that starting from position F(β ) there are m groups of siblings which are the offsprings of the nodes with label β . The end of each group is marked by a value 1 in the array Slast , and the k th group of siblings gives the children of the node corresponding to the k th occurrence of the label β in Sα ( see Example 1 for the case β = <book ) .
To efficiently navigate and search T , in addition to XBW(d ) and the array F , we need auxiliary data structures for the rank and select operations over the arrays bSlast and bSα . Recall that given an array A[1 , n ] and a symbol c , rankc(A , i ) denotes the number of times the symbol c appears in A[1 , i ] , and selectc(A , k ) denotes the position in A of the k th occurrence of the symbol c .
The pseudocode of the procedure for computing the rank of the children of the node with rank i is shown in Fig 3 to highlight its simplicity . We first compute the label c of node i by setting c = bSα[i ] ( Step 1 ) . Then , we set k = rankc( bSα , i ) ( Step 2 ) and we have that S[i ] is the k th node with label c is bSα . Because of properties 1–2 the children of S[i ] are the k th group of siblings starting from position y = F(c ) . The rank of the children is therefore easily computed by way of rank/select operations over the array bSlast ( Steps 4–6 ) . For example , in Fig 2 for i = 5 we have c = <book and k = 2 so we are interested in the second group of siblings starting from F(<book ) = 6 .
The procedures for navigation and SubPathSearch have a similar simple structure and are straightforward adaptations of similar procedures introduced in [ 11].The only nontrivial operations are the rank and select queries mentioned above . Note that navigation operations require a constant number of rank/select queries , and the SubPathSearch procedure requires a number of rank/select queries proportional to the length of the searched path . In this paper we introduce the new procedure ContentSearch that combines the techniques of [ 11 ] with the FM index data structure of [ 12 , 13 ] and will be discussed in Sect . 33
3 .
IMPLEMENTATION
3.1 Computation of the XBW transform
To build the tree T we parse the input document d using the Expat library by James Clark.3 Expat is a stream oriented parser written in C . We set its handlers in order to create the tree nodes and their labels . The time required to
3http://expatsourceforgenet/
Algorithm GetChildren(i )
1 . c = bSα[i ] ; 2 . k = rankc( bSα , i ) ; 3 . y = F[c ] ; 4 . z = rank1( bSlast , y − 1 ) ; 5 . First = select1( bSlast , z+k− 1)+1 ; 6 . Last = select1( bSlast , z + k ) ; 7 . return ( First , Last ) .
Figure 3 : Algorithm for computing the range ( First , Last ) such that S[First ] , S[First + 1 ] , . . . , S[Last ] are the children of node S[i ] .
Algorithm XBzip
1 . Compute XBW(d ) = h bSlast , bSα , bSpcdatai ; 2 . Merge bSα and bSlast into bS ′ 3 . Compress separately bS ′
α
α and bSpcdata using Ppmdi .
Figure 4 : Pseudocode of XBzip . build the tree T from one hundred MBs of XML data is a few seconds . In [ 11 ] the authors show that given T we can compute XBW(d ) in time linear in the number of tree nodes . In our tests we followed a simpler approach : we represent Sπ as an array of pointers to T nodes and we sort S operating on this array of node pointers . Experimentally we found that the stable sorting of Sπ is the most time consuming part of XBW computation because of the many pointer indirections that generate cache misses . Future work will be devoted to implementing more efficient algorithms , by using insights from the optimal algorithm proposed in [ 11 ] .
3.2 Compression of XBW(d ) : the XBzip tool
If we are only interested in a compressed ( non searchable ) representation of the XML document d , we simply need to store the arrays bSlast , bSα and bSpcdata as compactly as possible . This is done by the XBzip tool whose pseudocode is given in Fig 4 . Experimentally , we found that instead of compressing bSlast and bSα separately it is more convenient to merge them in a unique array bS ′ α obtained from bSα adding a label </ in correspondence of bits equal to 1 in bSlast . For example , merging the arrays bSlast and bSα of Fig 2 yields bS ′
α = <biblio</=</=</<book<book</@id<author
<title</@id<author<title</=</=</=</=</
This strategy usually offers superior performance in compression because it is able to capture repetitiveness in the tree structure .
As we observed in Sect . 2.2 the arrays bS ′
α and bSpcdata are locally homogeneous since the data descending from a certain tree path is grouped together . Hence , we expect that bS ′ and bSpcdata are best compressed splitting them in chucks according to the structure of the tree T . For simplicity in our tests we compress bS ′ α and bSpcdata using the general purpose compressor Ppmdi [ 26 ] . Somewhat surprisingly this simple strategy already yields good experimental results ( see Sect . 41 )
α
Algorithm XBzipIndex
1 . Compute XBW(d ) = h bSlast , bSα , bSpcdatai ; 2 . Store bSlast using a compressed representation support ing rank/select queries ( see text ) ;
3 . Store bSα using a compressed representation supporting rank/select queries ( see text ) ;
4 . Split bSpcdata into buckets such that two elements are in the same bucket if they have the same upward path ;
5 . Compress each bucket using the FM index .
Figure 5 : Pseudocode of XBzipIndex .
3.3 Supporting navigation and search : the
XBzipIndex tool
In Sect . 2.3 we observed that for navigation and search operations , in addition to XBW(d ) , we need data structures that support rank and select operations over bSlast and bSα . In [ 11 ] the authors use rank/select data structures with theoretically efficient ( often optimal ) worst case asymptotic performance ; in this paper we depart from their approach and use practical methods . In particular , we will view the array as strings , and thus use string indexing techniques . The resulting tool is called XBzipIndex and its pseudocode is shown in Fig 5 . Some details follow .
The array bSlast . Observe that search and navigation procedures only need rank1 and select1 operations over bSlast . Thus , we use a simple one level bucketing storage scheme . We choose a constant L ( default is L = 1000 ) , and we partition bSlast into variable length blocks containing L bits set to 1 . For each block we store :
• The number of 1 preceding this block in bSlast ( called
1 blocked rank ) .
• A compressed image of the block obtained by Gzip . • A pointer to the compressed block and its 1 blocked rank .
It is easy to see that rank1 and select1 operations over bSlast can be implemented by decompressing and scanning a single block , plus a binary search over the table of 1 blocked ranks .
The array bSα . Recall that bSα contains the labels of internal nodes of T . We represent it using again a one level bucketing storage scheme : we partition bSα into fixed length blocks ( default is 8Kb ) and for each block we store :
• A compressed image of the block ( obtained using Gzip ) . Note that single blocks are usually highly compressible because of the local homogeneity of bSα .
• A table containing for each internal node label β the number of its occurrences in the preceding prefix of bSα ( called β blocked ranks ) .
• A pointer to the compressed block and its β blocked rank .
Since the number of distinct internal node labels is usually small with respect to the document size , β blocked ranks can be stored without adopting any sophisticated solution . The implementation of rankβ( bSα , i ) and selectβ( bSα , i ) derives easily from the information we have stored .
The array bSpcdata . This array is usually the largest component of XBW(d ) ( see the last column of Table 1 and Table 3 ) . Recall that bSpcdata consists of the Pcdata items of d , ordered according their upward paths . Note that the procedures for navigating and searching T do not require rank/select operations over bSpcdata ( see Sect . 2 ) . Hence , we use a representation of bSpcdata that efficiently supports XPath queries of the form //Π[contains(.,γ) ] , where Π is a fully specified path and γ is an arbitrary string of characters . To this end we use a bucketing scheme where buckets are induced by the upward paths . Formally , let Sπ[i , j ] be a maximal interval of equal strings in Sπ . We form one bucket of bSpcdata by concatenating the strings in bSpcdata[i , j ] . In other words , two elements of bSpcdata are in the same bucket if and only if the have the same upward path . Note that every block will likely be highly compressible since it will be formed by homogeneous strings having the same “ context ” .4 For each bucket we store the following information :
• An FM index [ 12 , 13 ] of the bucket.5 The FM index is a compressed representation of a string that supports efficient substring searches within the bucket . Substring searches are efficient since they only access a small portion of the compressed bucket ( proportional to the length of the searched string , and not to the length of the bucket itself ) .
• A counter of the number of Pcdata items preceding the current bucket in bSpcdata .
• A pointer to the FM indexed block and its counter .
Using this representation of bSpcdata , we can answer the query //Π[contains(.,γ ) ] as follows ( see procedure ContentSearch in Fig 6 ) . By the procedure SubPathSearch we identify the nodes whose upward path is prefixed by ΠR ( ie the reversal of Π ) . Then , we identify the substring bSpcdata[F , L ] containing the labels of the leaves whose upward path is prefixed by =ΠR . Note that bSpcdata[F , L ] consists of an integral number of buckets , say b . To answer the query , we then search for γ in these b buckets using their FM indexes , taking time proportional to |γ| for each bucket . Since the procedure SubPathSearch takes time proportional to |Π| , the overall cost of the query is proportional to |Π| + b|γ| .
In addition to the above data structures , we also need two auxiliary tables : the first one maps node labels to their lexicographic ranks , and the second associates to each label β the value F[β ] . Due to the small number of distinct internalnode labels in real XML files , these tables do not need any special storage method .
4 . EXPERIMENTAL RESULTS
We have developed a library of XML compression and indexing tools based on the XBW transform . The library , called XBzipLib , consists of about 4000 lines of C code and runs under Linux and Windows ( CygWin ) . This library can be either included in another software or it can be directly
4Notice that Xcq [ 20 ] uses a similar partitioning of the Pcdata into data streams , however queries are supported by fully scanning the tree structure properly compressed by exploiting a DTD . 5We used the following parameter settings for the FM index ( cfr [ 12] ) : b = 2Kb , B = 32Kb and f = 005 These parameters can be tuned to trade space usage for query time .
Algorithm ContentSearch(Π , γ )
1 . ( First , Last ) ← SubPathSearch(Π ) ; 2 . F ← rank=( bSα , First − 1 ) + 1 ; 3 . L ← rank=( bSα , Last ) ; 4 . Let B[i , j ] be the range of buckets covering bSpcdata[F , L ] . 5 . Search for γ in the FM indexes of the buckets B[i , j ] .
Figure 6 : Search for the string γ as a substring of the textual content of the nodes whose leading path is Π ( possibly anchored to an internal node ) . used at the command line with a full set of options for compressing , indexing and searching XML documents . We have tested our tools on a PC running Linux with two P4 CPUs at 2.6Ghz , 512Kb cache , and 1.5Gb internal memory .
In our experiments we used nine XML files which cover a wide range of XML data formats ( data centric or text centric ) and structures ( many/deeply nested tags , or few/almostflat nesting ) . Whenever possible we have tried to use files already used in other XML experimentations . Some characteristics of the documents are shown in Table 1 . The following is the complete list providing the source for each file .
• Pathways6 contains the graphical description of metabolic pathways by means of the KEGG Markup Language ( KGML ) . The XML structure contains many distinct attribute values consisting of long strings and many attributes per tag .
• XMark7 has been produced by xmlgen ( of the XML Benchmark Project ) and models an auction database with significantly nested elements .
• Dblp8 is the popular bibliography database of major Computer Science journals and conference proceedings . Its main feature is the highly structured format of the file .
• Shakespeare9 is a corpus of marked up Shakespeare ’s plays , which contains many long textual passages with few distinct tag and attribute names .
• Treebank10 is a collection of parsed ( and partially encrypted ) English sentences from The Wall Street Journal , tagged with parts of speech . It is deeply nested and with many distinct tag and attribute names .
• XBench has been produced by the homonymous software as a single text centric XML document , covering the case of an e commerce catalog data that is captured as XML . The structural features are similar to Shakespeare but for a larger file .
• SwissProt11 is a protein sequence database which strives to provide a high level of annotations , a minimal level of redundancy and high level of integration with other databases . It is the file having the largest tree size , with many distinct tag and attribute names .
6http://wwwgenomejp/kegg/xml/ 7http://monetdbcwinl/xml/ 8http://wwwcswashingtonedu/research/xmldatasets/ 9http://wwwibiblioorg/xml/examples/shakespeare/ 10http://wwwcisupennedu/~treebank/ 11http://wwwcswashingtonedu/research/xmldatasets/
• News12 is a large corpus of news articles gathered from more than 2000 news sources from July 2005 . The XML tree is small and flat , but the textual data is very large .
4.1 XML compression
To evaluate the real advantages of XML conscious tools we compare them with general purpose compressors . The literature offers various general purpose compressors ranging from dictionary based ( Gzip ) , to block sorting ( Bzip2 ) , and Ppm based compressors ( we used Ppmdi [ 26 ] which is the one with the best performance ) . In addition , we compare XBzip with the current state of the art XML conscious compressors :
• Xmill13 [ 21 ] is one of the earliest known XML conscious compressors . It is user configurable and separates structure , layout and data . Content data are distributed into separate data streams ( int , char , string , base64 , etc ) which can be compressed with either ad hoc algorithms or with the classical Gzip , Bzip2 or Ppmdi tools . We did not adopt any ad hoc compressor for the Xmill ’s streams because we test many different sources and they have different characteristics ; also , whatever ad hoc optimizer one chooses to use with Xmill , this can be used with XBzip ( see Sect . 3.2 ) or on the PPM based compressors .
• XmlPpm14 [ 8 ] compresses every token ( tag , attribute , value , content ) by means of one among several “ multiplexed ” PPM compressors . Recently [ 9 ] proposed a variant of XmlPpm which exploits DTDs or schemas to improve compression . We did not experiment with this variant because , according to the author ’s conclusions , on large documents it achieves compression ratios similar to XmlPpm .
• ScmPpm15 [ 3 ] combines the Ppm technique with the Structural Contexts Model ( SCM ) idea , which is to use a separate Ppm model to compress the text that lies inside each different structure type .
• Lzcs16 [ 2 ] is based on a Lempel Ziv approach which takes advantage of redundant information ( repeated subtrees ) that can appear in the tree structure of the XML document . Compressed documents generated by Lzcs are easy to display , access at random , and navigate . In a second stage , the Lzcs output can be further compressed using Ppmdi : this improves compression but loses random access and navigation features .
We comment on two interesting issues arising from our experiments ( see Fig 7 ) .
• XBzip and Scmppm are the best algorithms in terms of compression ratio . Surprisingly , Ppmdi is competitive with them , and it is much faster . With the exception of Gzip , all other ( XML conscious and unconscious ) compressors lie within a 5 % absolute difference in their compression ratios .
12http://wwwdiunipiit/~gulli/ 13http://sourceforge.net/projects/xmill ( vers 08 ) 14http://xmlppmsourceforgenet/ 15http://wwwinforuvaes/~jadiego/downloadhtml 16http://wwwinforuvaes/~jadiego/downloadhtml
Dataset
Pathways XMark Dblp Shakespeare TreeBank XBench SwissProt News
Size ( bytes ) Tree Size #Leaves Tree depth Max/Avg 10 / 3.6 13 / 6.2 7 / 3.4 8 / 6.1 37 / 8.1 9 / 7.2 6 / 3.9 3 / 2.8
79,054,143 119,504,522 133,856,133 7,646,413 86,082,516 108,672,761 114,820,211 244,404,983
9,338,092 5,762,702 10,804,342 537,225 7,313,000 7,725,246 13,310,810 8,446,199
5,044,682 3,714,508 7,067,935 357,605 4,875,332 4,970,866 8,143,919 4,471,517
#Tag/Attr ( distinct ) 4,293,410 ( 49 ) 2,048,194 ( 83 ) 3,736,407 ( 40 ) 179,620 ( 22 ) 2,437,668 ( 251 ) 2,754,380 ( 25 ) 5,166,891 ( 99 ) 3,974,682 ( 9 )
| bSα|
| bSpcdata|
24,249,238 15,361,789 24,576,759 1,083,478 9,301,193 7,562,511 30,172,233 28,319,613
36,415,927 85,873,039 75,258,733 4,940,623 60,167,538 85,306,618 51,511,521 176,220,422
Table 1 : XML documents used in our experiments . The first three files are data centric , the others text centric . Note that columns | bSα| and | bSpcdata| report the byte length of these two strings .
Figure 7 : Comparison of XML compressors . Compression ratio ( top ) and compression time ( bottom ) . Compression times are scaled with respect to Gzip compression time . Note that Xmill , XmlPpm , Scmppm , and XBzip all use Ppmdi as their base compressor .
• Xmill and XmlPpm are faster than Ppmdi over all files except Treebank ( which is a pathological case for structure and ciphered content ) , but they are significantly slower than Gzip ( which achieves by far the worst compression ) . XBzip is from 2 to 6 times slower than Xmill and XmlPpm . Profiling shows that 90 % of XBzip running time is spent for the computation of the XBW transform which is currently done using an algorithm requiring quadratic time complexity in the worst case ( see Sect . 31 ) This can be easily decreased to linear time by implementing the optimal algorithm described in [ 11 ] . The decompression time of XBzip is already comparable to the one of Xmill and XmlPpm .
In summary , the experimental results show that XMLconscious compressors are still far from being a clearly advantageous alternative to general purpose compressors . However , the experiments show also that our simple XBW based compressor provides the best compression for most of the files . We think that the new compression paradigm introduced with XBW ( ie first linearize the tree then compress ) is much interesting in the light of the fact that we are simply applying Ppmdi without fully taking advantage of the local homogeneity properties of the strings bS ′ α and bSpcdata ( see Sects . 2.2 and 32 ) This will be further investigated in a future work .
4.2 Searching XML compressed files
The literature offers various solutions to index XML files [ 6 ] .
Here we only refer to XML compression formats that support efficient query operations . In Table 2 we compare our XBzipIndex against the best known queriable compressors . We were not able to test XPress [ 23 ] , XGrind [ 27 ] and XQzip [ 10 ] , because either we could not find their software or we were unable to run it on our XML files . However , whenever possible we show in Table 2 the performance of these tools as reported in their reference papers .
• Huffword [ 24 ] is a variant of the classical Huffmancompressor in which the dictionary consists of the tokens ( usually words ) extracted from the document .
Dataset Pathways XMark Dblp Shakespeare TreeBank Xbench SwissProt News
Huffword XPress XQzip XBzipIndex XBzip 1.84 18.07 9.69 17.46 29.52 15.45 4.66 10.61
3.62 28.65 14.13 21.83 54.21 19.47 7.87 13.52
33.68 34.15 44.00 42.08 67.81 44.96 43.10 45.15
– – 48 47 – – 42 –
– 38 30 40 43 – 38 –
Table 2 : Compression ratio achieved by queriable compressors over the files in our dataset . For XPress and XQzip we report results taken from [ 23 , 10 ] ( the symbol – indicates a result not available in these papers ) . The comparison between the last two columns allows us to estimate the space overhead of adding navigation and search capabilities to XBzip . Note that we can trade space usage for query time by tuning the parameters of the FM index [ 12 ] .
This is the typical storage scheme of ( Web ) search engines and Information Retrieval tools . Therefore its compression performance can be seen as a lower bound to the storage complexity of these approaches ( see eg [ 18] ) .
• XPress and XGrind adopt an homomorphic transform to preserve the structure of the XML data . Their compression ratio is usually not competitive with XML compressors because of the fine granularity of the individually compressed data units . To answer a query , these tools need to scan the whole compressed file . As a result , for large files query time is of the order of tens of seconds . In Table 2 we refer only to XPress because [ 23 ] shows that it outperforms XGrind .
• XQzip removes duplicate subtrees , as in Lzcs , and groups the data into data streams according to the enclosing tag/attribute , as in Xmill . As a result XQzip achieves compression better than XPress and XGrind and close to Xmill ; and yet needs the whole scan of the compressed file for subpath and content seareches .
From the previous comments and Table 2 we observe that XBzipIndex significantly improves the compression ratio of the known queriable compressors by 20 % to 35 % of the original document size . Table 3 details the space required by the various indexing data structures present in XBzipIndex . As expected , the indexing of bSlast and bSα requires negligible space , thus proving again that these two strings are highly compressible and even a simple compressed indexing approach , as the one we adopted in this paper , pays off . Conversely , bSpcdata takes most of the space and we plan to improve compression by fine tuning the parameters of the FM indexes that we use for storing this array ( see Sec 33 ) As far as query and navigation operations are concerned , we refer to Table 4 . Subpath searches are pretty much insensitive to the document size , as theoretically predicted , and indeed require few milliseconds . Navigational operations ( eg parent , child , block of children ) require less than one millisecond in our tests . As mentioned before , all the others queryable compressors—like XPress , XGrind , Xqzip— need the whole scanning of the compressed file , thus requiring several seconds for a query , and use much more storage space .
5 . CONCLUDING REMARKS two tools : XBzip , a XML ( un)compressor competitive with known XML conscious compressors but simpler and with guarantees on its compression ratio ; XBzipIndex that introduces the approach of using full text compressed indexing for strings and improves known methods by up to 35 % while simultaneously improving the search operations by an order of magnitude .
6 . REFERENCES [ 1 ] http://xmlcoverpagesorg/xmlhtml [ 2 ] J . Adiego , P . de la Fuente , and G . Navarro .
Lempel Ziv compression of structured text . In IEEE Data Compression Conference , 2004 .
[ 3 ] J . Adiego , P . de la Fuente , and G . Navarro . Merging prediction by partial matching with structural contexts model . In IEEE Data Compression Conference , page 522 , 2004 .
[ 4 ] A . Arion , A . Bonifati , G . Costa , S . D’Aguanno , I . Manolescu , and A . Pugliese . XQueC : pushing queries to compressed XML data . In VLDB , 2003 .
[ 5 ] D . Benoit , E . Demaine , I . Munro , R . Raman ,
V . Raman , and S . Rao . Representing trees of higher degree . Algorithmica , 2005 .
[ 6 ] B . Catania , A . Maddalena , and A . Vakali . XML document indexes : a classification . In IEEE Internet Computing , pages 64–71 , September October 2005 .
[ 7 ] T . Chen , J . Lu , and T . W . Lin . On boosting holism in XML twig pattern matching using structural indexing techniques . In ACM Sigmod , pages 455–466 , 2005 .
[ 8 ] J . Cheney . Compressing XML with multiplexed hierarchical PPM models . In IEEE Data Compression Conference , pages 163–172 , 2001 .
[ 9 ] J . Cheney . An empirical evaluation of simple
DTD conscious compression techniques . In WebDB , 2005 .
[ 10 ] J . Cheng and W . Ng . XQzip : Querying compressed
XML using structural indexing . In International Conference on Extending Database Technology , pages 219–236 , 2004 .
[ 11 ] P . Ferragina , F . Luccio , G . Manzini , and
S . Muthukrishnan . Structuring labeled trees for optimal succinctness , and beyond . In IEEE Focs , pages 184–193 , 2005 .
[ 12 ] P . Ferragina and G . Manzini . An experimental study
We have adopted the methods in [ 11 ] for compressing and searching labelled trees to the XML case and produced of a compressed index . Information Sciences , 135:13–28 , 2001 .
Dataset Pathways XMark Dblp Shakespeare TreeBank Xbench SwissProt News
% Index bSlast % Index bSα 0.8 2.5 2.3 3.4 14.7 4.7 2.5 0.5
1.7 3.6 4.9 4.6 5.2 4.4 2.2 1.0
Index bSpcdata Auxiliary Bytes per node 0.31 5.94 1.75 3.11 6.38 2.74 0.68 3.91
6.0 29.5 32.3 32.3 68.5 23.8 14.0 18.5
9.7 7.8 8.1 9.7 0.2 0.6 8.0 0.6
Table 3 : Percentage of each index part with respect to the corresponding indexed string . Auxiliary info includes all the prefix counters mentioned in Section 3.3 , and it is expressed as a percentage of the total index size . The last column gives an estimate of the avg number of bytes spent for each tree node .
Dataset : Query
Pathways : //entry[@id="3" ] XMark //person/address/city[.contains="Orange" ] Dblp : //article/author[contains="Kurt" ] Dblp : //proceedings/booktitle[contains="Text" ] Dblp : //cite[@label="XML" ] Dblp : //article/author Shakespeare : //SCENE/STAGEDIR Shakespeare : //LINE/STAGEDIR[contains="Aside" ] TreeBank //S/NP/JJ[contains="59B" ] Xbench //et/cr[contains="E4992" ] SwissProt : //Entry/species[contains="Rattus" ] News : //description[contains="Italy" ] bSlast blocks ( # bytes ) 5 ( 5005 ) 8 ( 71324 ) 5 ( 47053 ) 5 ( 21719 ) 5 ( 5005 ) 5 ( 47053 ) 5 ( 14917 ) 5 ( 21525 ) 8 ( 18436 ) 2 ( 2774 ) 5 ( 11217 ) 2 ( 2002 ) bSα blocks ( # bytes ) 4 ( 498 ) 6 ( 1599 ) 4 ( 1509 ) 4 ( 875 ) 4 ( 473 ) 2 ( 967 ) 2 ( 1035 ) 4 ( 1128 ) 6 ( 5965 ) 2 ( 996 ) 4 ( 1540 ) 2 ( 66 ) bSpcdata blocks
Time # occ in secs 0.007 0.008 0.001 0.002 0.002 0.008 0.002 0.003 0.020 0.006 0.002 0.003
2 2 2 2 134 0 0 2 697 4 2 2
62,414 41 288 10 7 221,289 4259 302 2 11 2,154 1,851
Table 4 : Summary of the search results for XBzipIndex . These time figures do not include the mmapping of the index from disk to internal memory and the loading of the auxiliary infos , which take 0.01 secs on average . Columns 2 , 3 , and 4 report the number of blocks accessed during the query and their total size in bytes .
[ 13 ] P . Ferragina and G . Manzini . Indexing compressed
[ 22 ] T . Milo and D . Suciu . Index structures for path text . Journal of the ACM , 52(4):552–581 , 2005 . expressions . In ICDT , pages 277–295 , 1999 .
[ 14 ] R . F . Geary , R . Raman , and V . Raman . Succinct
[ 23 ] Jun Ki Min , Myung Jae Park , and Chin Wan Chung . ordinal trees with level ancestor queries . In ACM SIAM Soda , 2004 .
Xpress : A queriable compression for XML data . In ACM Sigmod , pages 122–133 , 2003 .
[ 15 ] D . Geer . Will binary XML speed network traffic ?
[ 24 ] E . Moura , G . Navarro , N . Ziviani , and
IEEE Computer , pages 16–18 , April 2005 .
[ 16 ] R . Goldman and J . Widom . Dataguides : enabling query formulation and optimization in semistructured databases . In VLDB , pages 436–445 , 1997 .
[ 17 ] A . Golinsky , I . Munro , and S . Rao . Rank/Select operations on large alphabets : a tool for text indexing . In ACM SIAM SODA , 2006 .
[ 18 ] R . Kaushik , R . Krishnamurthy , J . Naughton , and R . Ramakrishnan . On the integration of structure indexes and inverted lists . In ACM Sigmod , pages 779–790 , 2004 .
R . Baeza Yates . Fast and flexible word searching on compressed text . ACM Transactions on Information Systems , 18(2):113–139 , 2000 .
[ 25 ] P . R . Raw and B . Moon . PRIX : Indexing and querying XML using Pr¨ufer sequences . In ICDE , pages 288–300 , 2004 .
[ 26 ] D . Shkarin . PPM : One step to practicality . In IEEE Data Compression Conference , pages 202–211 , 2002 .
[ 27 ] P . M . Tolani and J . R . Haritsa . XGRIND : A query friendly XML compressor . In ICDE , pages 225–234 , 2002 .
[ 19 ] R . Kaushik , R . Krishnamurthy , J . F . Naughton , and
[ 28 ] H . Wang , S . Park , W . Fan , and P . S . Yu . ViST : a
R . Ramakrishnan . On the integration of structure indexes and inverted lists . In ACM Sigmod , 2004 . [ 20 ] W . Y . Lam , W . Ng , P . T . Wood , and M . Levene . XCQ : XML compression and querying system . In WWW , 2003 .
[ 21 ] H . Liefke and D . Suciu . XMILL : An efficient compressor for XML data . In ACM Sigmod , pages 153–164 , 2000 . dynamic index methd for querying XML data by tree structures . In ACM Sigmod , pages 110–121 , 2003 .
[ 29 ] W . Wang , H . Wang , H . Lu , H . Jang , X . Lin , and J . Li .
Efficient processing of XML path queries using the disk based F&B index . In VLDB , pages 145–156 , 2005 .
