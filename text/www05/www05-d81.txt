$ 90 897,.9 43 147 #,70 ,90 47 ,88 1 .,9 43 3 ,7 0
$ . , 0 0 70.947
% 0 ,3 & fl ,4  fl %,4 "  fl 03  fl 43 #  fl 0 3 
 .748419 #080,7 . 8 , fl $ 2 , 03907fl 4 fl . :3 #4,/
, / ,3 897 .9fl 0 3 fl fl ! # 3 ,
9 9 :fl 03 .fl 2,< 2 .748419 .42
059 0.9743 . 3 3007 3 fl
%8 3 : , &3 ;078 9
0 3 fl fl ! # 3 ,
,3 ,4fl 6 38 9,4 < 2 , 8 98 3 : , 0/ : .3
703 98 3 : , 0/ : .3
ABSTRACT Automatically classifying the Web directories is an effective way to manage Web information . However , our experiments showed that the state of the art text classification technologies could not lead to acceptable performance in this task . Due to our analysis , the main problem is the lack of effective training data in rare categories of Web directories . To tackle this problem , we proposed a novel technology named Site Abstraction to synthesize new training examples from the website of the existing training document . The main idea is to propagate features through parentchild relationship in the sitemap tree . Experiments showed that our method significantly improved the classification performance .
Categories and Subject Descriptors H4m [ Information System Applications ] : Miscellaneous ; I54 [ Pattern Recognition ] : Applications – Text processing . General Terms Performance , Design , Experimentation , Verification . Keywords Text Classification , Site abstraction , Web directory , Hierarchical Classification , Support Vector Machines ( SVM ) .
1 . INTRODUCTION With the explosive growth of the Web , it becomes more and more difficult to manage the Web information . In early stage , people manually categorized Web pages into Web directories such as Yahoo! Directory ( http://diryahoocom/ ) and Open Directory Project ( ODP , http://dmozorg/ ) However , manually labeling is time consuming and labor expensive , which makes it not scalable with respect to the high growing speed of the Web . Therefore , automated text categorization ( TC ) technologies were adopted in many previous works to categorize Web pages [ 1][2][6 ] . However , these works were more of demonstrations than solutions because the sampling strategies used in them ( only top few levels or selective common categories ) could not well reflect the characteristics of Web directories . To tackle this problem , in this paper , we propose to use a specific subset of Yahoo! Directory named MERG which has very similar statistics to the full set for the experimental study . MERG consists of five sub trees , namely “ Reference ” , “ News
Copyright is held by the author/owner(s ) . WWW 2005 , May 10 14 , 2005 , Chiba , Japan . ACM 1 59593 051 5/05/0005 . *The works of Hao WAN and Tao QIN were performed at Microsoft Research Asia
“ Entertainment ” , and Media ” ,
“ Government ” and “ Regional ” . It contains totally 22,803 categories and 54,542 documents which are organized into a 13level hierarchy . Some comparisons between MERG and Yahoo! Directory are shown as below .
7 0 2 : 
7 4
0 9 ,
7 0 2 : 
7 4
0 9 ,
07,7 . 059 > 0;0 ?
7 0 2 : 
7 4
0 9 ,
07,7 . 059 > 0;0 ?
( a ) Yahoo! Directory ( b ) MERG Figure 1 . Category distributions over levels .
7 0 2 : 
7 4
0 9 ,
4.:2039 :2 07
4.:2039 :2 07
( a ) Yahoo! Directory ( b ) MERG
Figure 2 . Power law distributions of the category size .
Over the MERG data set , we ran hierarchical SVM classification with similar settings to [ 2 ] and [ 3 ] . The corresponding results were shown in Figure 3(a ) . From this figure , we can see that the classification performance was disappointing : Macro F1 of 0.116 and Micro F1 of 0.237 ( see the performance for the lowest level , which corresponds to the classification of the full set of MERG ) are not acceptable for real world classification applications . To find out why hierarchical SVM performed so poor , we listed the classification performance with respect to category size ( the number of positive examples in the training set ) in Figure 3(b ) .
0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0
1
2
3
4
Micro F1
Macro F1
6
5 Hierarchy Depth ( level )
7
8
9 10 11 12 13
1 F o r c a M
0.3
0.25
0.2
0.15
0.1
0.05
0
1
4
3
2 10 Number of Positive Examples in Categories
5
8
6
7
9
>10
( a ) ( b )
Figure 3 . Performance of hierarchical SVM classification over
MERG .
From this figure we can see that the classification performance decreased with the decreasing category size . That is , the data sparseness problem in rare categories might be the major reason for the overall poor classification performance . This motivates us to investigate how to expand the training set in order to improve the classification performance . As a result , we propose a novel method named Site Abstraction which utilizes the structure of the website to synthesize new training examples . 2 . SITE ABSTRACTION Due to our observation , almost all the labeled documents in Web directories are entry pages ( denoted by e ) of websites ( denoted by S ) . In conventional Web directory classification works [ 1][2][6 ] , only the entry page e was used as training document . However , it is easy to understand that other pages in S {e} are also relevant to the category the information embedded in S {e} to synthesize some new training documents for training set expansion . As a demonstration of this idea , we develop a mechanism named Site Abstraction to propagate the features ( terms ) of those pages in the lower levels of the sitemap tree to their ancestors . label . Therefore , we propose to utilize
* pF ( k
=
)
          pF ( k
+
) p k
α
)
+ 1 k ) k
) k p k
α pF ( ) k ∑ pF ( ∈ CHILD p ( + 1 CHILD p ( ∑ pF ) ( + k 1 ∈ HILD C p ( ) CHILD p (
)
+ 1 k k
CHILD ( p
) k
Φ=
( 1 )
CHILD ( p
) k
Φ≠ k
>
1 k
=
1 where Φ represents the empty set , F is the original feature of page pk , F* is the refined feature after propagation , CHILD(pk ) denotes the set of child pages of pk , |.| is the number of pages in a set . The above propagation starts from the lowest level in the sitemap tree . When it eventually terminates at the first level , a new training document is synthesized . By including this new document into the training set , we can solve the data sparseness problem to some extent . Note that this new page is based on the pages in S{e} , but independent of the entry page e . Therefore , it can serve as a good complement to the existing training document e . As for the above propagation process , one may argue that there is possibly the risk of topic drift . We acknowledge this ; however since the influences of the lower level pages are restrained by the weighting factor α , this risk will not be so high . 3 . EXPERIMENTS In this section , we tested the effectiveness of our Site Abstraction technology . For simplicity , we selected those categories with only one positive training example in the original training set for experiments . We totally crawled 3 levels and no more than 100 pages from the website corresponding to the existing positive examples . After that , we used the URL information ( folder depth ) of each crawled page to construct the sitemap tree of a website according to [ 3 ] . Then we synthesized one more training documents for each category by Site Abstraction . For comparison , we also implemented some other works targeting training set expansion ( ie LiveClassifier [ 4 ] and Document self Expansion [ 7] ) , as well as the approach of using all downloaded pages directly as training examples without applying the propagation formula ( 1 ) ( denoted by “ Site Raw ” ) . Our experimental results were shown in Figure 4 .
0.142
0.0571
0.061
0.061
1 F o r c a M
0.16
0.14
0.12
0.1
0.08
0.06
0.04
0.02
0
0.035
Site Raw
Baseline
Site abstraction
LiveClassifier Document self
Expansion
Figure 4 . Classification results over the 1 doc categories .
From this figure , we can see that both LiveClassifier and Document self Extension did not perform as well as expected . They did improve the classification accuracy , but only marginally . An interesting observation is that Site Raw actually deteriorated the performance , indicating the existence of concept drift . Comparatively , Site Abstraction did improve the classification accuracy significantly . The relative improvement was over 149 % . This showed that Site Abstraction could inhibit the concept drift and construct informative training examples . If looking at the absolute value of the resulting classification performance of Site Abstraction , we found that although we only added one more training document , the performance over the categories with only one document had been almost as good as over those categories with five or six training documents ( See Figure 3(b) ) . This verified from another aspect the effectiveness of Site Abstraction : one synthesized page is much more than one real page . 4 . CONCLUSION In this paper , we first conducted experiments to show that the state of the art text classification methods could not well handle Web directory classification . Then we pointed out that the data sparseness problem in rare categories of Web directories is the major reason for the poor classification performance . To tackle this problem , we proposed a novel technology named Site Abstraction to synthesize new training examples based on the website of the existing training document . The main idea is to propagate features through parent child relationship in the site structure . Experiments showed that our method significantly ( relatively 149 % ) improved the classification performance . 5 . REFERENCES [ 1 ] Calvo R . A . , Lee J . M . and Li X . , Managing Content with Automatic Document Classification . Journal of Digital Information , Vol.5 , No.282 , 2004 .
[ 2 ] Dumais S . and Chen H . , Hierarchical classification of Web content .
SIGIR 2000 , 256 263 .
APWeb 2005 .
[ 3 ] Feng G . , Liu T . Y . , Ma W . Y . , et al , Level based Link Analysis ,
[ 4 ] Huang C . C . , et al . Liveclassifier : creating hierarchical text classifiers through web corpora . WWW 2004 , 184 192 .
[ 5 ] Lewis , D . D . , Yang , Y . , Rose , T . , Li , F . RCV1 : A new benchmark collection for text classification research . Journal of Machine Learning Research . 5 ( 2004 ) 361 397
[ 6 ] McCallum , A . , Rosenfeld , R . , Mitchell , T . and Ng , A . Improving text classification by shrinkage in a hierarchy of classes . ICML 1998 , 359 367 .
[ 7 ] Tseng Y . H . and Juang D . W . , Document Self Expansion for Text
Classification , SIGIR 2003 , 399 400 .
