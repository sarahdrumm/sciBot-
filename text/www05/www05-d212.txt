Finding The Search Engine That Works For You
1Department of Electrical & Computer Engineering
2Graduate School of Information Science & Technology
Kin F . Li1 , Wei Yu1 , Shojiro Nishio2 , and Yali Wang1
University of Victoria
Victoria , BC , Canada V8W 3P6
1 250 721 8683
{kinli,locarno,wangyl}@eceuvicca
Osaka University
Suita , Osaka , 565 0871 Japan
+81 6 6879 4500 nishio@istosaka uacjp
ABSTRACT A search engine evaluation model that considers over seventy performance and feature parameters is presented . The design of a web based system that allows the user to tailor the model to his/her own preference , and to evaluate search engines of interest , is introduced . The results presented to the user identify the most suitable search engine that suits his/her needs .
Categories and Subject Descriptors H33 [ Information Storage and Retrieval ] : Information Search and Retrieval – retrieval models , search process , selection process .
General Terms Measurement , Performance , Human Factors .
Keywords Search Engines , Performance Evaluation , Personalization .
1 . MOTIVATION The Internet provides a wealth of information , and together with search engines , has become an indispensable tool for many people . However , many experts argue that existing web search engines are inefficient , and are effective only for some types of queries in certain context and niche focus [ 1 ] [ 3 ] . To further complicate the matter of evaluating a search engine's efficiency and effectiveness , each user has his/her own preference and is highly subjective in judging the relevance of the search results .
We have proposed a formal evaluation model for search engines that considers over seventy parameters [ 2 ] . In order to validate our approach and solicit users' feedback , we are implementing a web based search engine evaluation system using the model . At the same time , this web based system provides users the ability to evaluate search engines and then to identify the most suitable ones for their respective needs and preference . As a side benefit , the system also serves as a meta search engine during the evaluation process . The search engine evaluation model is introduced next . Section 3 presents the on going design and the specification of the webbased user centric evaluation system . Discussion of work in progress concludes the paper .
Copyright is held by the author/owner(s ) . WWW 2005 , May 10 14 , 2005 , Chiba , Japan . ACM 1 59593 051 5/05/0005 .
2 . SEARCH ENGINE EVALUATION After reviewing an exhaustive list of possible evaluation parameters , two major groups have been identified : Feature and Performance . The Feature part consists of characteristics pertaining to the appeal aspects and capabilities that enhance the usability and user friendliness of the search engine . The Performance part utilizes various metrics to examine the efficiency and the effectiveness of the search .
Within each part , related parameters are further classified into subgroups and sub subgroups , forming a hierarchy of evaluation parameters . Individual nodes of the hierarchy represent the various aspects of interest or importance to the user of the model . A hierarchical structure allows the user to examine and rank a search engine at various levels of abstraction details , by using a weighted sum of the parameters under consideration . For example , the overall score of a search engine can be formulated as
Wfeature * Pfeature + Wperformance * Pperformance
While the P's are measured values , a user can assign preferred weights to Feature and Performance , such as 30 % and 70 % if the user feels that P e r f o r m a n c e is more important than Feature . A negative weight is used to indicate any undesirable impact on the overall score , for example , the number of dead links . A parameter can have either a binary value to indicate the presence of a feature , or a range from 0 to 1 to indicate the degree of quality . The sum of the weights assigned to the parameters within a group must be 100 % , to ensure the consistent weight distribution across all groups .
2.1 Evaluation Parameters Figure 1 shows the top three levels of the evaluation hierarchy . There are six categories within Feature , and one of them , the search options further consists of five categories . Performance of a search engine includes three aspects with the quality of results divided into two more sub subgroups . For many search engine users , these are probably the most important metrics to measure the effectiveness of a search engine : problems encountered while reviewing the returned results which indirectly indicate how up to date the search engine's database is , and the relevance of the returned items .
The parameters in the Feature part are more static in nature since they represent facts and do not change often , while Performance parameters are dynamically measured and they depend on the particular search words used and the subjective ratings of the user . Not shown in Figure 1 are the more specific and low level parameters within the subgroup and subsubgroups .
920 Figure 1 . A Hierarchy of Evaluation Parameters .
The capability to adjust the weights according to individual preference , and to allow a user to enter scores for subjective parameters such as the relevance of returned items , makes this customizable scoring system flexible to use and the model attractive to search engine users and providers . A user , therefore , can use this evaluation model to find the search engines that are best suited for his/her needs , by collecting search results using a set of keywords in the areas of interest . The scores of the search engines are tabulated according to the empirical data and their assigned weights . Identifying the best search engines for one ’s needs is extremely useful as we all know how tedious and time consuming the process is to sift through the returned hits of multiple search engines to discover the wanted information .
3 . A USER CENTRIC WEB BASED SYSTEM Once a user adjusts the weight percentage for each parameter considered in the model , enters the keywords , and selects the search engines to be evaluated , the system will collect and tabulate the results . Randomized results are presented to and rated by the user according to an item's relevance . The overall score of each engine will then be summarized as shown in Figure 2 . Of course , a user can also review the detail scores of a particular group such as the comparison of response time , number of hits , and quality of results within the Performance category . It is expected that most of the Internet users search information using keywords in similar categories . Therefore , after some experimentation , a user can identify the search engines that are best suited for the type of information that he/she is currently focusing on or seeking regularly . We have performed some experiments in assigning different weights to the various parameters . Indeed , the evaluation model is sensitive to the weights as well as the values of the parameters . Google is not always the clear winner as the specific experiment shown in Figure 2 .
4 . WORK IN PROGRESS This web based search engine evaluation system is being designed and implemented , and will be made available for public use . Experiments are being designed to study web searchers' behavior using the statistics obtained and users' feedback . Once the evaluation model is better understood and validated , we plan to study the visualization aspect of the search result presentation , especially those related to the judgment and subjectivity of the user . In addition , it is often difficult for users to express and enter the weights as precisely as they feel , with a text based interface . A well designed user interface with visualization aid will alleviate this problem .
Figure 2 . Comparison of Search Engines .
5 . ACKNOWLEDGMENTS This research was supported in part by the Ministry of Education , Culture , Sports , Science and Technology ( MEXT ) of Japan's Special Coordination Funds for promoting Science and Technology , under the project "Establishment of a Peer to Peer Information Sharing Platform for Mobile Computing Environment" , in part by "Priority Assistance for the Formation of Worldwide Renowned Centers of Research The 21st Century Center of Excellence Program" of the MEXT , and in part by the University of Victoria Wighton Engineering Product Development Fund .
6 . REFERENCES [ 1 ] Allan , J . , et al . , Challenges in Information Retrieval and
Language Modeling , Workshop Report , Center for Intelligent Information Retrieval , University of Massachusetts , Amherst , Sep . 2002 .
[ 2 ] Li , KF , et al . , A Formal Approach to Evaluate and
Compare Internet Search Engines : A Case Study on Searching the Chinese Web , The 7th Asia Pacific Web Conf . , Mar . 2005 , Springer Verlag LNCS 3399 , 195 206 .
[ 3 ] Pokorny , J . , Web Searching and Information
Retrieval , IEEE Computing in Science and Engineering , Jul/Aug 2004 , 43 48 .
921
