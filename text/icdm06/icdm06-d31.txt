Multi Tier Granule Mining for Representations of Multidimensional
Association Rules
Yuefeng Li , Wanzhong Yang , Yue Xu
School of Software Engineering and Data Communications
Queensland University of Technology , Brisbane , QLD 4001 , Australia y2li@quteduau , w3yang@studentquteduau , yuexu@quteduau
Abstract for solving
It is a big challenge to promise the quality of multidimensional association mining . The essential issue is how to represent meaningful multidimensional association rules efficiently . Currently we have not found satisfactory approaches this challenge because of the complicated correlation between attributes . Multi tier granule mining is an initiative for solving this challenging issue . It divides attributes into some tiers and then compresses the large multidimensional database into granules at each tier . It also builds association mappings to illustrate the correlation between the meaningful association justified according to these association mappings .
1 . Introduction
Multidimensional association mining discusses two or more data dimensions or predicates [ 3 ] . Usually multidimensional association mining is designed for searching frequent predicate sets and that can be classified into inter dimension and hybrid dimension association rule mining . tiers . In rules can be this way ,
We can obtain a huge amount of association rules using the existing data mining techniques . However , not all strong association rules are interesting to users [ 3 ] . Several approaches have been conducted in order to guarantee the quality of discovered knowledge : the concept of closed patterns [ 14 ] [ 15 ] , non redundant rules [ 17 ] [ 18 ] , and constraint based association rules [ 1 ] [ 4 ] [ 5 ] [ 10 ] [ 12 ] [ 16 ] .
These approaches have significant performance for decreasing the number of association rules for transaction databases . However , they are not very efficient for representation of associations in very large multidimensional databases because we have to transfer multidimensional rule mining into single dimensional mining when we use these approaches .
Different to these approaches , in this paper we present the concept of granule mining ( GM ) in multidimensional databases for directly representations of associations between attributes , where a granule is a group of objects ( transactions ) that have the same attributes’ values .
Basically attributes are divided by users into two groups : condition attributes and decision attributes , and decision tables can be used to represent the association between condition granules and decision granules [ 11 ] [ 8 ] . In cases of large number of attributes , however , decision tables become inefficient . Decision tables also cannot describe association rules with shorter premises ( we call such rules general rules in this paper ) . To solve these drawbacks , in this paper we present multi tier structures and association mappings to manage associations between attributes . It provides represent multidimensional association rules efficiently . alternative way an to
The remainder of the paper is structured as follows . We begin by introducing the concept of closed patterns and decision tables for granule mining in Section 2 . In section 3 , we discuss the relationship between granule mining and data mining . In Section 4 , we introduce the multi tier structure . In Section 5 , we formalize association mappings for GM . In Section 6 , we introduce the experiment results . The last section includes related work and conclusions .
2 . Basic Definitions
Formally , a transaction database can be described as an information table ( T , VT ) , where T is a set of objects in which each record is a sequences of items , and VT = {a1 , a2 , … , an} is a set of selected items ( or called attributes in decision tables ) for all objects in T . Each
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 item can be a tuple , eg , ( name , cost , price ) is a product item .
2.1 Closed Patterns
Definition 1 . A set of items X is referred to as an itemset if X ⊆ VT . Let X be a itemset , we use [ X ] to denote the covering set of X , which includes all objects t such that X ⊆ t , ie , [ X ] = {t | t∈ T , X ⊆ t} .
Given an itemset X , its occurrence frequency is the number of objects that contain the itemset , that is |[X]| ; and its support is |[X]|/|T| . An itemset X is called frequent pattern if its support ≥ min_sup , a minimum support .
Definition 2 . Given a set of objects Y , its itemset which satisfies itemset(Y ) = {a | a∈ VT , ∀t ∈Y => a∈t} .
Given a frequent pattern X , its closure
Closure(X ) = itemset([X] ) .
From the above definitions , we have the following theorem ( see [ 18] ) . Theorem 1 . Let X and Y be frequent patterns . We have
( 1 ) Closure(X ) ⊇ X for all frequent patterns X ; ( 2 ) X ⊆ Y => Closure(X ) ⊆ Closure(Y ) . and
Definition 3 . An frequent pattern X is closed if and only if X = Closure(X ) .
22 Decision Tables
Decision tables can be used for dealing with multiple dimensional databases in line with user constraints . Formally , users may use some attributes of a database ; and they can divide these attributes into two groups : condition attributes , respectively . We call the tuple ( T , VT , C , D ) a decision table of ( T , VT ) if C∩D=∅ and C∪D⊆ VT . attributes decision
We usually assume that there is a function for every attribute a∈ VT such that a : T → Va , where Va is the set of all values of a . We call Va the domain of a . C ( or D ) determines a binary relation I(C ) ( or I(D ) ) on T such that ( t1 , t2 ) ∈ I(C ) if and only if a(t1 ) = a(t2 ) for every a∈C , where a(t ) denotes the value of attribute a for object t∈ T . It is easy to prove that I(C ) is an equivalence relation , and the family of all equivalence classes of I(C ) , that is a partition determined by C , is denoted by T/C .
The classes in T/C ( or T/D ) are referred to Cgranules ( or D granule ) . The class which contains t is called C granule induced by t , and is denoted by C(t ) .
Object t1 t2 t3 t4 t5 t6 items a1 a2 a3 a4 a6 a3 a4 a5 a6 a3 a4 a5 a6 a1 a2 a6 a7 a1 a2 a6 a7
Table 1 lists a part of an transition database , where VT = {a1 , a2 , … , a7} , T = {t1 , t2 ,… , t6} . We also can represent Table 1 as a decision table . Let a1 , a2 , a3 , a4 and a5 be the condition attributes and a6 and a7 be the decision attributes . Table 2 shows a decision table of Table 1 , where T/C∪D = {g1 , g2 , g3 , g4} and Ng is the number of objects that are in the same granule .
Table 2 . A decision table
Granule g1 g2 g3 g4 a1 1 0 0 1 a2 a3 0 1 1 0 0 1 0 1 a4 0 1 1 0 a5 0 0 1 0 a6 0 1 1 1 a7 Ng 1 0 1 0 0 2 2 1
Every granule in the decision table can be mapped into a decision rule [ 11 ] , where we treat the presence and absence of items as the same position if we view the decision table as a multidimensional database . Therefore , we can obtain 4 decision rules in Table 2 , and the first one can be read as the following decision rule : a1 =1 ^ a2 = 1 ^ a3 = 0 ^ a4 = 0 ^ a5 = 0
→ a6 = 0 ^ a7 = 0 or in short C(g1)→ D(g1 ) ( or C(t1 )→ D(t1) ) , where ^ means “ and ” .
3 . Data Mining and Granule Mining
Decision tables provide an efficient way to represent discovered knowledge . However , currently we can only obtain decision rules , a kind of very special association rules , in decision tables . To interpret what kinds of association rules in the decision tables , we present the concept of decision patterns .
Given a C granule cg= C(t ) , its covering set [ cg ] = {t’ | t’∈ T , ( t’ , t)∈ I(C)} . Let cg be a C granule and dg be a D granule , we define [ cg∧dg ] = [ cg ] ∩ [ dg ] .
For example , in Table 2 g1 = ( a1 =1 ^ a2 = 1 ^ a3 = 0 ^ a4 = 0 ^ a5 = 0 ^ a6 = 0 ^ a7 = 0 ) = C(g1 ) ^ D(g1 ) = cg1 ^ dg1 ; therefore
[ g1 ] = [ cg1 ^ dg1 ] = [ cg1 ] ∩ [ dg1 ]
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 = {d1 , d5 , d6} ∩ {d1} = {d1} .
Table 3 illustrates the covering sets of granules , where ( a ) includes the covering sets of C granules , ( b ) includes the covering sets of D granules , and ( c ) includes the covering sets of C∪D granules .
Table 3 . Covering sets of granules
Granule cg1 cg2 cg3 a3 0 1 1 a1 a2 covering set {t1 , t5 , t6} 1 1 {t2} 0 0 {t3 , t4} 0 0 ( a ) Covering sets of C granules a4 a5 0 0 1 0 1 1
Granule dg1 dg2 dg3 a6 0 1 1 a7 0 0 1 covering set {t1} {t2 , t3 , t4} {t5 , t6}
( b ) Covering sets of D granules
Granule a1 a2 a3 a4 a5 g1 g2 g3 g4
1 0 0 1
1 0 0 1
0 1 1 0
0 1 1 0
0 0 1 0 a6 a7 covering set 0 0 {t1} 1 0 {t2} 1 0 {t3 , t4} 1 1 {t5 , t6}
( c ) Covering sets of C∪D granules
Definition 4 . Let X be a frequent pattern . We call it a decision pattern if ∃g ∈ T/C∪D such that X = {ai ∈ C∪D | ai(g ) = 1} . We call X the derived decision pattern of g .
Theorem 2 . Let ( T , VT , C , D ) be a decision table . We have ( 1 ) [ C(t ) ] ⊇ [ C∪D(t ) ] , for all t∈ T . ( 2 ) The derived decision pattern of every granule g∈T/C∪D is a closed pattern .
Proof : ( 1 ) is obvious in accordance with the definition of closure .
For ( 2 ) , Let X be the derived pattern of g , that is , X={ai ∈ C∪D | ai(g ) = 1} . From the definition of the granules , we know there is a object t0 ∈ [ g ] such that X = {ai ∈ C∪D | ai(t0 ) = 1} , that is t0 ∈[X ] .
Given an item a ∈ itemset([X] ) , according to Definition 2 we have a ∈ t for all t ∈ [ X ] , that is , a ∈ t0 and also a ∈ X . Therefore , Closure(X ) = itemset([X ] ) ⊆ X .
We also have X ⊆ Closure(X ) from Theorem 1 , and hence we have X = Closure(X ) . , rules tables ,
4 . Multi Tier Structures
In cases of large number of attributes , the decision tables become inefficient . Also , we cannot discover general for example , association rules with shorter premises . In addition , some decision rules may be meaningless . In this section , we present a multi tier structure to manage the correlation between attributes in order to overcome these disadvantages of decision tables . We also clarify the meaning of meaningless in this section . in decision
Let T /C be the set of condition granules and T /D be the set of decision granules . To describe the association between condition granules and decision granules , we can further divide the condition attributes into some groups in accordance with user constraints . We assume that Ci and Cj are two subsets of condition attributes ; and they satisfy :
Ci ∩ Cj =∅ and Ci ∪ Cj = C .
Figure 1 illustrates the structure of the multi tier granule mining , which describes the hierarchy of the possible associations between tiers , where T/Ci = {cgi,1 , cgi , 2 , … , cgi , k} , T /Cj ={ cgj , 1 , cgj , 2 , … , cgj , m} , and T /D ={ dg1 , dg2 , … , dgs} . cgi , 1 cgi,2
6 cgj,2 4 2
…
… cgi,k cgj,m dg2 dg3 dgs
4 cgj,1
3 1 dg1
Figure 1 . The hierarchy of the multi tiers
The decision rules in the structure of multiple tiers can be illustrated as follows : cgi , x ∧ cgj , y → dgz
( conf = |[cgi , x ∧ cgj , y ∧ dgz]| / |[cgi , x ∧ cgj , y]| ) Different to decision tables , we can obtain some general association rules with shorter premises as follows : cgi , x → dgz , ( conf = |[cgi , x ∧ dgz]| / |[cgi , x]| ) .
In Figure 1 , we assume that
|[cgi , 1 ∧ cgj , 1 ∧ dg1]| = 3 , |[cgi , 1 ∧ cgj , 1 ∧ dg2]| = 1 |[cgi , 1 ∧ cgj , 2 ∧ dg1]| = 4 , |[cgi , 1 ∧ cgj , 2 ∧ dg3]| = 2 |[cgi , 1 ∧ cgj , 1]| = 4 , |[cgi , 1 ∧ cgj , 2]| = 6 , |[cgi , 1]| = 10 . According the above assumption and the structure in Figure 1 , we have the following decision rules : cgi , 1 ∧ cgj , 1 → dg1 ( conf = ¾ = 0.75 ) cgi , 1 ∧ cgj , 1 → dg2 ( conf = ¼ = 0.25 ) cgi , 1 ∧ cgj , 2 → dg1 ( conf = 4/6 = 0.67 ) cgi , 1 ∧ cgj , 2 → dg3 ( conf = 2/6 = 0.33 )
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 We also can obtain a general association rule with the shorter premise : cgi , 1 → dg1 ( conf = 7/10 = 070 )
Definition 5 . A rule cgi , x ∧ cgj , y → dgz is called meaningless if its confidence is less than or equals to the confidence of its general rule : cgi , x → dgz .
Based on Definition 5 , rule cgi,1 ∧ cgj,2 → dg1 ( conf = 4/6 = 0.67 ) is a meaningless rule since its confidence ( 0.67 ) is less than the confidence ( 0.70 ) of its general rule cgi , 1 → dg1 ( conf = 7/10 = 070 )
The rationale of the above definition is analogous to the definition of interesting association rules . If add extra evidence to a premise and obtain a weak conclusion , we can say the piece of evidence is meaningless .
5 . Association Mappings
In the basic association in a decision table , and then we develop methods to derive other associations between granules in different tiers based on this basic association . this section , we firstly formalize
The basic association between condition granules and decision granules can be described as an association mapping Γi,j,d such that
) is a set of D granule integer pairs . For example , using the granules in Figure 1 , we have dg 1 Let N=|T| and dgz∈{dg|(dg , f)∈
} , we can obtain a decision rule : cgi , x ∧ cgj , y → dgz with the support and confidence : dg )}1 , 2 cg (
Γ dji , ,
Γ dji , ,
Γ dji , ,
( ),3 , cg cg cg cg cg
{(
. yj , yj ,
∧
∧
∧ xi , xi ,
=
1 ,
1 ,
)
(
(
) j i
( cg
∧ cg
→ xi , sup conf = |[cgi , x ∧ cgj , y ∧ dgz]| / |[cgi , x ∧ cgj , y]| ) yj , z yj , xi , z
,
)
= dg
( dg
, f
) Γ∈ i cg
∧ cg
) dj ,
( N f
∑
=
∑ ∑
( dg
, f
) Γ∈ i z
, dj ,
( cg xi ,
∧ cg yj ,
)
( dg
, f
) Γ∈ i
, dj ,
( cg xi ,
∧ cg yj ,
) f f
The association mapping Γi,j between T/Ci and T/Cj can be derived from association mapping Γi,j,d , where is a set of Cj granule integer pairs . The Γ ji , following is the equation that we can derive : Γ i cg cg xi ,
)
(
,
( j Γ i
) = xi , cg ( cg {( yj , cg ∧ xi , yj ,
∧ ) f |)1 ∅≠
, dj , f 1 ,
=
∑
( dg
, f
) Γ∈ i
, dj ,
( cg xi ,
∧ cg yj ,
) f
}
For example , using the granules in Figure 1 , we have :
Γ ji ,
( cg i
1 ,
)
=
{( cg j
1 ,
( ),4 , cg j
2 ,
)}6 ,
.
It is more complicated to derive the association Γi,d between T/Ci and T/D based on association Γi,j,d and f
P 1
Γi,j . To simplify this process , we first review the composition operation that defined in [ 9 ] .
Let P1 and P2 be sets of D granule integer pairs . We call P1 ⊕ P2 the composition of P1 and P2 which satisfies : P {( 2 dg | ) , gname ( f f dg f dg P ( | ) , ) , ( , , + ∈ 1 2 1 1 gname gname P P ) ) ) ( ( ( ∈ ∪ − 1 2 P P gname P dg ( ( ) ) ) , ∩ ∪∈ 2 2 1 where gname(Pi ) = {dg | ( dg , f ) ∈Pi} .
=⊕ f {( ( dg dg P ) 1
The operands of ⊕ are interchangeable , therefore we can use ⊕{P1 , P2 , P3} to be the short form of ( P1 ⊕ P2 ) ⊕ P3 . The result of the composition is still a set of D granule integer pairs .
P 2
} ,
∈
U
}
) f
,
2
Let Γi,d be the association mapping between T/Ci cg xi ,
)}
(
) cg
{ Γ⊕= and T/D , we have the following equation for it : ( Γ di ji dji , , , , for all cgi , x ∈ T/Ci . f )1 ,
Γ∈
( | ) cg cg cg
∧ yj , yj , xi , xi ,
(
Algorithm 5.1 ( Construction of Multi Tiers ) Input parameters : ( T , VT , C , D , Ci , Cj ) . Output : Association mappings . Method 1 : ( Evaluate Γi,j,d ) .
T/C = ∅ ; for ( each g∈ T/C∪D ) //start from a decision table if ( C(g)∈ T/C ) //notice g=C(g ) ∧ D(g ) Γi,j,d ( C(g ) ) = Γi,j,d ( C(g))∪{(D(g ) , Ng)} ; else { T/C = T/C ∪ {C(g)} ; Γi,j,d ( C(g ) ) = {(D(g ) , Ng)} ; }
Method 2 : ( Evaluate Γi,j )
T/Ci = ∅ ; for ( each cg∈ T/C ) { f 1= 0 ; //notice cg=Ci(cg ) ∧ Cj(cg ) for ( (dg , f)∈ Γi,j,d ( cg ) ) f1 = f1 + f ; if ( Ci(cg)∈ T/Ci ) Γi,j ( Ci(cg ) ) = Γi,j ( Ci(cg))∪{(Cj(cg ) , f1)} ; else { T/Ci = T/Ci ∪ {Ci(cg)} ; Γi,j ( Ci(cg ) ) = {(Cj(cg ) , f1)} } } ;
Method 3 : ( Evaluate Γi,d ) for ( each cgi,x∈ T/Ci ) {
Γi,d ( cgi,x ) = ∅ ; for ( (cgj,y , f1)∈Γi,j ( cgi,x ) ) Γi,d ( cgi,x ) = Γi,d ( cgi,x ) ⊕ Γi,j,d ( cgi,x∧cgj,y ) } ;
For example , using the information in Figure 1 we have : Γi,d(cgi,1 ) = {(dg1 , 3 ) , ( dg2 , 1)} ⊕ {(dg1 , 4 ) , ( dg3 , 2)}
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 = {(dg1 , 7 ) , ( dg2 , 1 ) , ( dg3 , 2)} . is by from
The
Algorithm 5.1 describes the main procedure of the construction of the multi tier structure . It includes three methods for calculating the three kinds of association mappings . time complexity of Algorithm 5.1 is determined by Method 1 because |T/Ci| ≤ |T/C| . In Method 1 , checking C(g ) ∈ T/C takes O(|T/C| ) , so the time complexity of the algorithm is O(n×|T/C| ) , where n is the number of granules in the decision table , and the basic operation the comparison between granules . Since |T/C| ≤ n , the time complexity of Algorithm 5.1 ≤ O(n2 ) . pairs removing the multi tier
After constructed the multi tier structure , we can easily obtain decision rules and general rules by traversal of structure . Pruning meaningless decision rules can also be simply implemented the corresponding association mapping . For example , given a condition granule cg , based on its general rule , we might remove pairs in Γi,j,d ( cg ) if they are the conclusions of meaningless rules .
6 . Experiments
We simulate in a real multiple store environment where a fact table of sales can be described using one star schema including multiple dimensions : customer dimension , time dimension , data dimension , store dimension and production dimension . In our current experiment , we use time and production dimensions only . A product includes name , cost and price attributes . the data transaction
The fact table of sales in a financial year includes 26,590 records and 5000 different products . We view each product as an item . We set one to an item for a transaction if it appears in the transaction ; otherwise we set up zero to it .
We first select 300 most frequent products as items ( attributes ) {a1 , a2 , … , a300} . We also choice 162 products C from the 300 products , which profits are more than 50 % ( price > 1.5 × cost ) as condition attributes ; and select 35 products D from the 300 products , which profits are less than or equal to 20 % ( 1.2 × cost > price ) as decision attributes .
After compressed the transaction records , we obtain a decision table which includes 2486 granules , and hence we can generate 2486 decision rules .
The condition attributes are further divided into two tiers : Ci tier the products that profits are more than 90 % ( price > 1.9 × cost ) ; and Cj tier the products that the profits are in [ 90 % , 50% ) , ( 1.9 × cost ≥ price > 1.5 × cost ) . The products are now classified into three tiers : high profit Ci tier , medium profit Cj tier , and low profit D tier . The association between high profit products and low profit produces can also be described as general rules .
Figure 2 illustrates the numbers of granules and attributes in the three tiers . To compare to decision table , the multi tier structure is extremely impressive since only very small amounts of granules are useful for generating rules .
Granules
Attributes
2500
2000
1500
1000
500
0
Decision table
C tier
Ci tier
Cj tier
D tier
General rules
Figure 2 . Granules and attributes in multi tiers .
Figure 3 depicts the percentages ( 57.9 % ) of meaningless decision rules that can be pruned . It is also shows the percentages ( 68.9 % ) of transactions that are covered by these meaningless decision rules .
The Percentage of Corresponding Granule and Transaction Numbers
Meaningful
Meaningless
100 % 90 % 80 % 70 % 60 % 50 % 40 % 30 % 20 % 10 % 0 %
Figure 3 . The percentage of meaningless decision rules .
Transactions
Granules
In summary , the results demonstrate that the multitier structure uses only a very small space to store meaningful multi dimensional association rules . It is a very efficient and promising alternative of decision tables representations of multidimensional association rules . for
7 . Related Work
As mentioned in the introduction , several approaches have been conducted for the quality of discovered knowledge . We also noticed another interesting research , which discussed the similarity between patterns to discover the real useful patterns [ 13 ] .
For multidimensional association mining , Han et al . in [ 3 ] [ 4 ] summarized the possible techniques in accordance with the corresponding treatments of
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 quantitative attributes . Habitually , most current researchers on multidimensional association mining endeavor to use the existing efficient algorithms for single dimensional mining . Lee et al . presented an approach for multidimensional constraints [ 6 ] . It checked constraint during FP tree constructions . The approach firstly grouped products at the same cost and price into an item , and view the product table as a set of transactions .
In this paper , we concentrate on inter dimension association mining . Different to other ideas , we want to describe in multidimensional databases based on some abstractions ( granules ) . the associations
In the beginning , rough set theory looked like an adequate tool for this question , and can be used to describes the knowledge in information tables [ 2 ] [ 7 ] . Further , rough set based decision tables [ 11 ] presented by Pawlak can be used to represented some sorts of association rules . Li and Zhong [ 8 ] also presented a structure to disconnect the condition granules and decision granules in order to improve the efficiency of generating associate rules from decision tables .
Rough set theory is elegant , and has a clear logical semantics . However , it lacks the accurateness when we use it to deal with the associations between granules in multiple tiers .
8 . Conclusions
In this research , we present a multi tier granule mining approach in order to provide a foundational framework for efficiently representations of multidimensional association rules . We demonstrate is a significant replacement of decision tables . We also prove that granules in decision tables are kinds of closed patterns . In addition , we present the definition of meaningless decision rules . The definition can also be justified in the multi tier structure .
Acknowledgments
This paper was partially supported by Grant DP0556455 from the Australian Research Council . The authors also wish to thank Professor Ning Zhong at Maebashi Institute of Technology , Japan for his valuable comments .
References
[ 1 ] C . Bucila , J . Gehrke , D . Kifer , W . White , “ DualMiner : a Dual Pruning algorithm for Itemsets with constraints , ” ACMSIGKDD , Alberta , Canada , 2002 , 42 51 . [ 2 ] J . W . Guan , D . A . Bell , D . Y . Liu , “ The rough set that it approach to association rules , ” ICDM , USA , 2003 , 529 532 . [ 3 ] J . Han and M . Kamber , “ Data Mining : Concepts and Techniques ” , Morgan Kaufmann Publishers , 2000 . [ 4 ] J . Han , Y . Fu , “ Mining multiple level association rules in large databases , ” IEEE Transaction on Knowledge and Data Engineering , 1999 , 11(5 ) : 798 805 [ 5 ] C . K S Leung , LVS Lakshmanan , R . T . Ng , “ Exploiting succinct constraints using FP trees , ” ACMSIGKDD Explorations , 2002 , 40 49 . [ 6 ] A . J . T . Lee , W . Lin , C . Wang , “ Mining association rules with multi dimensional constraints , ” The Journal of Systems and Software , 2006 , 79 92 . [ 7 ] Y . Li , “ Extended random sets for knowledge discovery in information systems ” , 9th International Conference on Rough Sets , Fuzzy Sets , Data Mining and Granular Computing , China , 2003 , 524 532 . [ 8 ] Y . Li and N . Zhong , “ Interpretations of association rules by granular computing , ” ICDM , USA , 2003 , 593 596 . [ 9 ] Y . Li and N . Zhong , “ Mining ontology for automatically acquiring Web user information needs , ” IEEE Transactions on Knowledge and Data Engineering , 2006 , 18(4 ) : 554 568 . [ 10 ] RTNg , LVS Lakshmanan , J . Han , A . Pang , “ Exploratory mining and pruning optimizations of constrained associations rules , ” ACM SIGMOD , Seattle , Washington , USA , 1998 , 13 24 . [ 11 ] Z . Pawlak , “ In pursuit of patterns in data reasoning from data , the rough set way , ” 3rd International Conference on Rough Sets and Current Trends in Computing , USA , 2002 , 1 9 . [ 12 ] J . Pei , J . Han , LVS Lakshmanan , “ Mining frequent itemsets with convertible constraints , ” 17th International Conference on Data Engineering , Heidelberg , Germany , 2001 , 433 442 . [ 13 ] S . Tsumoto and S . Hirano , “ Visualization of rule ’s ICDM , similarity Melbourne , Florida , USA , 2003 , 339 346 . [ 14 ] P . Tzvetkov , X . Yan and J . Han , “ TSP : Mining top K closed sequential patterns , ” ICDM , Melbourne , Florida , USA , 2003 , 347 354 . [ 15 ] S T Wu , Y . Li , Y . Xu , B . Pham and P . Chen , “ Automatic pattern taxonomy exatraction for Web mining , ” IEEE/WIC/ACM on Web Intelligence , Beijing , China , 2004 , 242 248 . [ 16 ] G . I . Webb and S . Zhang , “ K optimal rule discovery , ” Data Mining and Knowledge Discovery , 2004 , 10 : 39 79 . [ 17 ] Y . Xu , and Y . Li , “ Mining for useful association rules using the ATMS , ” CIMCA2005 , Vienna , Austria , Nov . 2005 , 271 276 . [ 18 ] M . J . Zaki , “ Mining non redundant association rules , ” Data Mining and Knowledge Discovery , 2004 , 9 : 223 248 .
International Conference using multidimensional scaling ” ,
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006
