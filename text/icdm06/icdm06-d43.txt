Identifying Follow Correlation Itemset Pairs1
Shichao Zhang1,2 , Jilian Zhang1 , Xiaofeng Zhu1 , Zifang Huang2 1Department of Computer Science , Guangxi Normal University , China
2School of Automation Science and Electrical Engineering , Beihang University , Beijing , China zhangsc@itutseduau ; zhangjilian@yeah.net ; zhu0011@21cn.com ; zifangh@gmail.com
1 This work is partially supported by Australian large ARC grants ( DP0449535 , DP0559536 and DP0667060 ) , a China NSF major research Program ( 60496327 ) , a China NSF grant ( 60463003 ) , a National Basic Research Program of China ( 2004CB318103 ) , an Overseas Outstanding Talent Research Program of Chinese Academy of Sciences ( 06S3011S01 ) , and Guangxi Postgraduate Educational Innovation Plan .
Abstract approach , itemset pairs in evaluate sequential our
An association rule A→B is useful to predict that B will likely occur when A occurs . This is a classical association rule . In real world applications , such as bioinformatics and medical research , there are many follow correlations between itemsets A and B : B likely occurs n times after A occurred m times , wrote to <Am , Bn> . We refer to this follow correlation as P3.1 itemset pairs because <A3 , B1> like that in Example 2 should be uninterested in association analysis . This paper designs an efficient algorithm for identifying P3.1 data . We experimentally and demonstrate that the proposed approach is efficient and promising .
1 . Introduction
The goal of mining association rules is to capture and model the useful associated correlations within data . By the definition in [ 1 ] , an association rule is an implication of the form A ( cid:198 ) B , where A and B are frequent itemsets in a transaction database . In practical applications , the rule A ( cid:198 ) B can be used to predict that ‘if A occurs in a transaction , then B will likely also occur in the same transaction’ , and we can apply this association rule to predict the behavior that the presence of A implies the presence of B in marketing . Such applications are expected to increase product sales and provide more convenience for supermarket customers . Therefore , mining association rules in databases has been an active research topic in data mining and rooted in market basket analysis [ 1 , 2 , 10 ] . While association rule mining techniques have advanced to a mature stage , in many real world applications there exists another type of interesting pattern between objects ( or itemset ) that is different from the association rules . It has the form of ‘itemset B likely occurs n times after itemset A occurred m times’ . We refer to this type of follow correlation between two the Follow Correlation Itemset Pairs itemsets as ( denoted as P3.1 Itemset Pairs or FCIP , which will be defined in detail in section 2 ) and use the form of an ordered pair to represent the P3.1 pattern , namely <Am , Bn> , where A is the Condition itemset and B is the Action itemset of the pattern ; m and n represent the occurring times of the antecedent and consequent respectively . This paper proposes this new kind of interesting patterns and aims to develop techniques for mining them .
From the previous work of researchers , the association rule mining tends to find out those patterns , whose elements appear simultaneously in a transaction . Different from association rule mining , the discovery of the P3.1 pattern is the identification of those interesting patterns , whose elements do not appear simultaneously . Instead , the elements occur in an asynchronous way .
Our P3.1 patterns are also different from the sequential patterns , which were first brought up by [ 3 ] . The difference is that the traditional sequential patterns do not consider the quantities of items bought in a transaction , which may lead to the loss of important interesting information .
A P3.1 pattern 〈Am , Bn〉 can be used to predict that ‘if A has occurred m times , then B will likely occur n times in the following transactions’ . Like association rules , we can also utilize this P3.1 pattern to predict customer behavior in marketing as well as many other domains .
We now illustrate some kinds of P3.1 patterns using several examples below .
Example 1 . Consider a given database D with randomly appended transactions . Let A and B be two items in D . After deleting other items and those transactions that do not contain item A or B , assume we have the following data
A B
1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 1 1
Where ‘1’ indicates that item A occurs in a transaction and ‘0’ indicates that item A does not occur in a transaction .
Using the support confidence framework , we can see that the support count of AB is 2 , which is very low , and itemset AB may be not interesting . However , the above data has shown an interesting followcorrelation : B occurs 1 time after A occurred 1 time and , in last two transactions B occurs 1 time when A occurred 1 time . Using our method ( will be built in this paper ) , we can followcorrelation : itemset pairs 〈A1 , B1〉 with frequency of 10 . identify an interesting
Example 2 . Consider the same database D in Example 1 . Assume we have the following data ,
A B
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1 0 0 1
Using support confidence framework , we can obtain the association rule A ( cid:198 ) B with confidence 0333 It should be not of interest . However , the above data has also shown another interesting follow correlation : B occurs 1 time after A occurred 3 times . Using our method ( will be built in this paper ) , we can discover an interesting follow correlation : itemset pairs 〈A3 , B1〉 with frequency of 6 . We can identify the same followcorrelation from , for example , the following data
A 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 B 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1
Certainly , the association rule A ( cid:198 ) B with support 1 is not of interest according to the support confidence framework .
Also , we can interesting followcorrelation : itemset pairs 〈A4 , B2〉 with frequency 4 from the following data identify an
A B
1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1 0 0 0 0 1 1
Generally , we can obtain a common form for follow correlation itemset pairs . We name this new kind of itemset pairs as P3.1 pattern . A P3.1 pattern is denoted as ( 〈Cn , Am〉 , s ) , where s is the frequency of the ordered pairs 〈Cn , Am〉 in database ; C is the Condition itemset that occurs at first , and A is the Action itemset that occurs successively ; m and n denote the occurring times of the itemsets C and A in the database respectively . As described in example 2 , the itemset pairs 〈A3 , B1〉 should be pruned away in the association rule mining settings . But from another point of view , it is an interesting P3.1 pattern that will be useful in real world application .
The P3.1 patterns are common and useful in many domains . Below are two examples of the P3.1 patterns . increasing
Example 3 . In a daily stock exchange database , assume there are three attributes : the stock name , the percentage change of its value in terms of its previous day ’s value , and the date . From this database , it is possible to discover patterns related to stock value increases and decreases . Instead of real percentage values , we use some notations , such as D ( representing more than 10 % of the daily value Decrease ) , I ( representing more than 20 % of the daily value Increase ) and O ( Other kinds of changes ) . We then use these notations to transform the original data of stock exchange database into a new form of data . Consider the transformed sequence “ IDIIIODDDIIIIODDD ” for stock A and “ IODDOIDODODDODODD ” for stock B . Suppose we only care about the increase of the stocks , if there is an increase in the sequence , set the value in the corresponding position to 1 , otherwise , set to 0 . So , is the 10111000011110000 is 10000100000000000 . We can find an interesting phenomenon that after the real percentage value of stock B increased one time , stock A will increase four times ( we omit those zero values that appear in the same position of stock A and B , after deletion , the sequences of A and B are 111101111 and 100010000 respectively ) . This observation can be utilized to predict the trend of stock A based on the trend of stock B . On the contrary , we can also infer the trend of stock B based on the analysis of A ’s sequences .
Example 4 . Suppose a patient is infected with a kind of disease ( denoted as A ) , he is taking medicine B for treatment . And each column in the table below denotes a period of treatment . In the 2nd and 3rd columns , he will receive as many as 5 times treatments , because the density of virus in his body is very high at first . While in the next two period of treatments , he is recovering , sequence and stock A stock of
B
A B
1 0 0 0 0 1 1 1 0 1
100000 011100 so he needs fewer and fewer treatments . Generally , he needs 4 or 5 treatments during the whole period .
1 1 1 0 0 0 0 1 1 1 1 1
1 1 0 0 0 0 0 1 1 1 1 1
From the above examples , we can see that the Follow Correlation Itemset Pairs ( P3.1 pattern or FCIP ) are interesting and widely hidden in many real world applications , which can reveal the underlying relationships between objects that occur one after another . We will give a formal definition of the P3.1 pattern in the next section , and propose an algorithm for efficiently mining these interesting patterns from sequential dataset .
Some studies , such as cyclic association rules [ 4 ] , serial and parallel episodes [ 9 ] , segment wise periodic patterns [ 6 ] , and cyclically repeated patterns [ 7,8 ] are different from classical association rules . These studies have extended the association rule to a general form or a sequential form , which can well model the underlying sequential relationship between objects . Some research efforts [ 4 ] assume that the transactional data to be analyzed is time stamped and that time intervals are specified by the user to divide the data into disjoint segments , to discover such regularities in the behavior of association rules over time . The work of [ 6 ] , which can mine the segmentwise or point wise periodicity in time related data sets , differs from the cyclic association rules which aims at finding full cycle periodicity for all the segments in the selected sequences of the data . Both cyclic association rules and segment wise periodic patterns are based on the work of mining sequential patterns [ 3 ] . The work of [ 9 ] discovers frequent episodes in sequences of events , such as the serial episode and parallel episode . Our proposed P3.1 patterns are similar to the above patterns , but also different significantly from them . One can distinguish the differences from the definition of the p3.1 pattern .
The rest of this paper is organized as follows . In Section 2 , a formal definition of the P3.1 pattern is presented ; and in Section 3 we describe an algorithm for mining P3.1 patterns ; experimental study is given in Section 4 ; finally we conclude this paper and present our future work in Section 5 .
2 . Problem Definition
We first use a market basket database as an example to introduce the concept of the follow correlation itemsetpairs ( P3.1 pattern or FCIP ) , and then give a formal description of this concept . then
Example 5 . Given a customer transactional database of a supermarket , see Figure 1 , which contains 9 transactions . Each transaction consists of different number of items , representing the corresponding commodities purchased simultaneously by a customer .
TID 1 2 3 4 5 6 7 8 9 Figure 1 . The transactional database and b,d,e,g d,e,f,g a,c,e,g a,b,c,e a,c,e,g b,d,e,f,g a,b,c,d,e b,c,f,g its transformed counterpart b 1 0 0 1 0 1 1 1 0 d 1 1 0 0 0 1 1 0 0 c 0 0 1 1 1 0 1 1 0 g 1 1 1 0 1 1 0 1 0 a 0 0 1 1 1 0 1 0 1 e 1 1 1 1 1 1 1 0 1 f 0 1 0 0 0 1 0 1 0
Items bought a,e
The left table of Figure 1 is the original transactional database , while the right one is a transformed database of the left table . We use 0 and 1 to indicate an item does or doesn’t occur in a transaction . From the transformed database , we can find some interesting patterns . For instance , item c is likely to appear two or more times after item d has occurred two times . We use ordered pairs <d2 , c3> and <d2 , c2> to represent this follow correlation . As mentioned in Section 1 , we refer this kind of pattern to the Follow Correlation Itemset Pairs ( P3.1 pattern , or FCIP ) . Note that for the fourth times of the occurring of item d , the item c is also occurring at the same time ( in transaction 7 ) and continues its appearance to transaction 8 . This kind of pattern , say <d2 , c2 > , we call it the Strong FollowCorrelation Itemset Pairs ( SFCIP ) , while for the pattern , say <d2 , c3> , we call it the Lag FollowCorrelation Itemset Pairs ( LFCIP ) . As for items d and f , they both do not occur in transaction 3,4,5 and 9 , so we omit these non occurring sequences , and the resulting sequence of item d is ‘11110’ , the sequence of f is ‘01101’ . Finally , we can get the FCIP patterns from the sequences of the two items as <d1 , f2> , <d2 , f2> and <d4 , f1> . Note that we omit the non occurring transactions only for ease of finding the FCIP patterns . From figure 1 , we also find that for items d , e and c , there exist two patterns , ie , <{d , e}2 , c3> and <{d , e}2 , c2> . This kind of P3.1 pattern contains more than one items in its Condition itemset . For ease of discussion , in this paper we consider the situation that there is only one item in the Action itemset of a P3.1 pattern . Some other Itemset pairs are listed here , <f1 , a1> , <f1 , a3> , <g3 , b1> , <b1 , g3> , <b1 , g2> , <b3 , g1> . The traditional association rules mining algorithms cannot capture this tries kind of patterns . For one thing , the P3.1 pattern usually has relatively low support count under the traditional association rules mining framework . Take the items c and d for example , the support for itemset cd is only 1/9= 0.11 , which is fairly low and is likely to be pruned away while generating interesting patterns . For the other thing , the traditional association rules to discover underlying mining correlations between that within a same transaction , which can’t be used to mine out those follow correlations between items that do not appear within the same transaction . While using our proposed algorithm , one can efficiently grasp such kind of interesting follow correlation patterns , providing the decision maker with more useful information . framework items
Our proposed patterns are different from the sequential patterns , which were first brought up by [ 3 ] . The difference is that the sequential patterns do not take the quantities of items with a pattern into account , which may lead to the loss of important interesting patterns such as our proposed P3.1 patterns . This is crucial for distinguishing the P3.1 difference patterns from the sequential patterns .
Definition 1 . Item occurring sequence Given a database D with size of T transactions , the occurring sequence of an item I in D is denoted as SI=<I1 , I2 , I3 , … , It , … , IT> , where It ∈ {0,1} and t ∈ [ 1,T ] , representing that item I occurs or doesn’t occur in transaction t respectively . And It is in front of It+1 in the sequence for all t=1 , 2 , … , T 1 . IS , of an item I is a 1 An appearance sequence , subsequence of SI , in which item I is appearing =< > , where It=1 , consecutively , that is , IS is 1 t=m,…,n , and 1 m n T n m= − + . Similarly , the non appearance Len S 1( I > , S I sequence of item I is defined as m ≤ ≤ ≤ . The length where It = 0 , t = m , … ,n , and 1 m n T n m= − + . Thus , the occurring 1 of sequence of item I in a database is decomposed into the appearance sequences and non appearance sequences that are interleaved by each other . The traditional transaction database D is transformed into a set of the item occurring sequences in order to the Follow Correlation facilitate Itemset Pairs , which will be discussed in Section 3 .
Definition 2 . Follow Correlation Itemset Pairs ( or P3.1 pattern , FCIP ) A Follow Correlation Itemset
≤ ≤ ≤ . The length of 1 finding of
Len S 0( I
IS is 0
, ,
, ,
=< the
S
0 I
I
I
1 I
)
)
I m n n n
− 1
+ 1
1
=
C n , ,
Pairs is an ordered pair <C , A> , where C and A , representing the Condition and the Action itemset respectively , are both appearance sequences , that is , =< > , where 1 m n T ≤ ≤ ≤ C S , , C= 1 ; and m C =< > , where + n n∈ A S A k 1} { , 1 A= , k A l = ≤ ≤ C k l T C− 0 if , and ; m 1 < ≤ < ; += < ≤ < = , if 1 k 1 m n T A l T A 1 0 . l k The pair <C , A> is called the Lag Follow Correlation k n= + ; and is called the Itemset Pairs ( LFCIP ) , if Strong Follow Correlation Itemset Pairs ( SFCIP ) , if k n= . We will use the term ‘P3.1’ and ‘FCIP’ interchangeable throughout this paper .
The Condition itemset C and Action itemset A of a P3.1 pattern may contains one or more items , but currently we only consider the situation that the Action itemset A only contains one item in this paper for ease of discussion .
For instance , for sequences C =’111011101110’ , D = ’000100010001’ and E=’001100110011’ , we can get LFCIP <C3 , D1> and SFCIP <C3 , E2> . Another P3.1 pattern can be obtained , that is <{D , E}1 , C3> from above sequences of items . Note that , for sequence A=’101010101010’ B = ’010101010101’ , Both <A1 , B1> and <B1 , A1> are different FCIPs because Fellow Correlation ItemsetPairs is an order pair , FCIP <A1 , B1> is LFCIP and its frequency is 6 and FCIP <B1 , A1> is also a LFCIP pattern , but its frequency is 5 . sequence and
'
'
'
=
Len C n m
Without loss of generality , we use the general form of the FCIP , which is <CL1 , AL2> , where L1 and L2 are the lengths of the Condition and the Action itemset sequences appearance is , that respectively , = − + . = − + and 2 = Len A l k L L 1 ( ) 1 1 ( ) =< > and C C C ' , , ' ' A FCIP p’=<C’ , A’> , where m n > , is a subpair of FCIP p=<C , A> , =< A A A , , ' ' l k ' ' > , if =< =< A C C C , , where m n ≤ = and < ≤ < . A subpair p’ is m m n n ' ' l ' = = − + , j Len C n m ' 1 called a ( j1 , j2) subpair of p if 1 = − + . l ' 1 and
Definition 3 . ( The frequency of a P3.1 pattern ) The frequency of a P3.1 pattern p=<CL1 , AL2> is the occurring times of p in a database D .
> and k k
Len A
A k l
( ' )
, ,
A l
We can get the frequency of a pattern p by scanning the whole database and count how many times that p occurs . The users can take advantage of those P3.1 patterns that have higher frequency counts , because j 2
=
=
' ) k
(
'
'
' frequently occurred P3.1 patterns may be more useful in decision making .
< m
C n
C
< A k < ≤ ≤ l T
Definition 4 . Longest P3.1 pattern Given two > , and , , appearance sequences of item C= ≤ ≤ ≤ , > , where 1 m n T A item A= l n≤ + , the longest FCIP m k k pattern of these two appearance sequences is a pair > , p=<C’ , A’> , where ≤ . l A
= < C , , ≤ ≤ , n k n ' k
' > and
, , and
, ,
C ≤
=< n ' k
C
1 m
'
A k
'
A l
'
'S
There are some interesting properties of the P3.1 pattern , which can be utilized to facilitate the mining process . We present some of them as follows .
Property 1 . If a P3.1 ( or FCIP ) pattern p has a frequency of s , then each of its subpairs has a frequency , say s’ , which is at least equal to or larger than the frequency of p . That is ,
S≥ .
This property is similar to that of frequent itemsets called anti monotone in association rules mining framework . Different from the association rules mining process [ 1 ] , we find out the longest P3.1 ( or FCIP ) pattern p at each time without counting all its subpairs . After checking the whole database , we output p to the user and all its subpairs as well . This can substantially reduce the search space .
The number of longest P3.1 patterns of the appearance sequences of two items is equal to the number of transactions that these two items both occur simultaneously . So we can get the second property for P3.1 pattern below .
Property 2 . The frequency of a strong followcorrelation itemset pairs ( SFCIP ) p=<C1 , A1> for two items , C and A , are approximately equal to the support count of the itemset CA in a database D .
This can be proven from the previous definitions of SFCIP . Because the support count , say f , of an itemset CA in database is the total number of transactions that contain the itemset , while for a SFCIP pattern p=<C1 , A1> with frequency s , itemsets C and A may appear simultaneously in about s transactions approximately . That is , we have f≈s . For example , for item occurring sequences A=’1011010011’ , B=’0110110010’ , and C=’1110101011’ , we can get some SFCIP patterns as , <A1 , B1> with frequency 3 , <A1 , C1> with frequency 4 , and <{A , B}1 , C1> with frequency 2 . From the perspective of traditional association rules mining framework , we know that the support counts for itemsets AB , AC , and ABC are 3 , 4 , and 2 respectively .
From property 2 , we can have a deep understanding of the relationship between the association rules mining framework and our proposed patterns , that is , the association rules try to find out those items that occur together in each transaction , which can be called synchronized occurring ; while in our model we want to search the items that appear one after another , which can be called asynchronous occurring .
Given a database D , our goal is to find out those P3.1 patterns , whose frequencies are larger than or equal to user defined minimal support count ( currently , we only address the mining problem of P3.1 patterns with a single item in the Action itemset ) . The task of mining such patterns is different from traditional association rules mining in that the association rules mining algorithm is to generate candidate itemsets and then check them against the database ; while our algorithm need not generate candidate P3.1 patterns . Instead , it searches the sequences of two items from end to end , counting each longest P3.1 patterns that it encountered . After the counting process , all the frequency of FCIPs and its subpairs are output to the user . The mining algorithm for FCIP will be discussed in Section 3 .
3 . Algorithm
31 The Mining Algorithm
Our algorithm for mining FCIP patterns from databases consists of two steps , the first step is to sequentialize the data , which converts the transactional forms of items into sequences ; the second step is to search the sequences in order to find out the longest FCIP patterns . The algorithm is presented in Figure 4 .
Sequentialize Phase : In this first step , we read in the data and build a list for each item , which stores the appearance and the non appearance sequences of the item . In practice , the databases are usually very large , which will hinder the construction of the sequences of items . We devise a technique called Lazy Counting , in order to save storage space and quicken the process of sequentialization for items . The main idea of Lazy Counting is that we needn’t count the information about an item when it does not occur in a transaction . This technique takes effect with the help of a tail pointer that points to the last node of the item occurring list , and a pointer that indicates the current number of transaction that is under processing . We adopt the same database in Example 1 to illustrate the the Lazy Counting sequentialize algorithm and technique .
In Figure 2 , a list table is maintained , in which the ‘name’ , ‘tail’ and ‘child’ denote the name of item , the pointer that points to the tail node of the list and the consecutive child list respectively . The ‘tail’ pointer is used for quickening the access of the list , because each time we need to add a new node to the end of the list . The fields ‘S’,’E’ and ‘P’ denote the Start position , End position and the successive Pointer to next node respectively . We use CurrTrans to denote current number of transaction that is being processed .
S E P name tail child
Figure 2 . Illustration of sequentialize process
1 1 1 1 1 1 1 a b c d e f g
…
3 1
1
5 1
1 3
^ ^
^
1
The ‘S’ and ‘E’ record the start number and the end number of transactions between which the item appears continuously . For instance , item a occurs from the 3rd transaction to the 5th transaction , so its ‘S’ and ‘E’ fields are set to 3 and 5 respectively . For example , if current transaction contains item a , we then access the last node of item a ’s list and see whether the value of field ‘E’ equals to CurrTrans 1 . If yes , we then set the field ‘E’ to E=E+1 ; otherwise , we can infer that since last occurring of item a , there are CurrTrans E 1 transactions in total that do not contain item a . So we have to generate a new node and link it to the last node of item a ’s list , setting the new node with filed ‘S’ and ‘E’ both to CurrTrans . Finally we modify the pointer tail of a to point to the new node . If current transaction does not contain item a , we need not to access a ’s list leaving the field of ‘E’ unchanged . When we access the first node of item a ’s list , for example , we find that a ’s field ‘S’ is 3 , as a consequence , we can infer that from 1st transaction to 2nd transaction item a does not occur . Above discussion is the main idea of the Lazy Counting technique . For each item , we do not need to count the information of its ‘0’ sequence ( does not appear in transactions ) , instead , only the information of its ‘1’ sequence ( appear in transactions ) will be recorded . We call this strategy the Lazy Counting , which is lazy for treating the ‘0’ sequences . When all the is presented in Figure 3 . transactions are processed , table the list
Because of the principle of Lazy Counting , after processing all the transactions , we get the final list table of items in Figure 3 . The last appearances of items b and g are both in the 8th transaction , while the total transactions of database D is 9 , so we can infer that items b and g do not occur in the remained transactions . After the sequentialize process , all the items of database D are transformed into a long sequence , which consists of consecutive appearance sequences . These appearance sequences can be expressed by mutually disjoint intervals , which are important for the next step of finding the longest FCIP patterns . name tail child
S E P a b c d e f g
3 3
1 5 1
3 1
…
1 31
2
7 4
7 4
2 5 6
3 ^9 ^8
9 6
3
8 8 ^ ^
Figure 3 . The final list table
SequentializeItemsWithLazyCounting( ) 1 . Initialize the item list for database D 2 . While EOF(D)=false do 3 . read in a transaction , count each item in the transaction to the item list using the Lazy Counting technique
4 . Enddo
FindingFCIPpatterns( ) 1 . C=∅ ; 2 . While not_finish_processing_the_list_table do 3 . for each two items , process the appearance nodes of two sequences by turn ; compare the endpoints and the overlapping regions ; count up the longest FCIP patterns to C
4 . Enddo 5 . Count all the subpairs of longest FCIP in C patterns and output the Top K % of FCIP patterns to user
Figure 4 . The Mining Algorithm
Finding FCIP Patterns Phase : After constructing the list table for all items , we then search the sequences of each two items in order to find out the FCIP patterns . The search process is relatively straightforward , because we have got all the appearance sequences of each item , the next thing we should do is to compare the endpoints and the overlapping region of these mutually disjoint intervals for two sequences and count up all the longest FCIP patterns .
Based on Property 1 in Section 2 , the subpairs of the FCIP patterns are also counted up , and finally , the results are presented to the user .
3.2 The Pruning Strategy
In this section , we present a pruning strategy in order to reduce the huge search space for item pairs in order to discover P3.1 patterns . This strategy is based on mutual information ( MI ) . The proposed algorithm aims to find out the P3.1 patterns between the Condition and Action itemsets sequences in database , which can lead to combination explosion . For example , if there are 1000 distinct items in a database D , then the algorithm needs to check as many as 1000*(1000 1)=999000 sequence pairs of items , resulting in a great inefficiency in performance . This problem will be getting worse when D contains many items . Actually , we need not to check all these item pairs . For instance , item A may have relations with item C , while item B may have weak or none relations with item C . Therefore , we only need to search the sequences of items A and C , and needn’t to check the sequences of items B and C .
In order to measure the relationship between items , we employ the mutual information ( MI ) to evaluate the relations between items instead of the chi squared test [ 5 ] . If two items are independent , then the MI between them is zero . If the two items are strongly dependent , as for the case if one is a function of the other , then the MI between them is large . In other words , the value of MI between two items indicates the strength between these two items . We adopt the MI because it can measure the general ( non linear ) dependence while a correlation function measures linear dependence . In most cases in real world application , we usually don’t know the exact relationship between items , so adopting MI is an appropriate choose . We give an example for illustrating the computation of MI between two items . For example , we want to compute the MI between item a and b in Figure 1 . We first generate the contingency table for a and b , which is presented in Table 1 .
Table 1 . The contingency table for item a , b b a
0 1 Pi .
0 1 3 4
1 3 2 5
P.j 4 5 9
The MI between items a and b is calculated as :
MI
=
∑ ∑ n = i 1 m = j 1 p ij log p i
. p ij ∗ p . j ijP ,
. jP and
.iP are corresponding values from where Table 1 . The MI between items a and b is 0.0488 based on the above equation . For the case of multi items in Condition itemset , we simply transfer the Condition itemset into a new item , and then compute the MI by using the new item . For example , there are sequences for three items , A=’1011010011’ , B=’0110110010’ , and C=’1110101011’ . We transfer itemset AB to a new item A’ with occurring sequence ‘0010010010’ , that is , we set the sequence to ‘1’ if items A and B are both occur in a same transaction . Otherwise , set the sequence to ‘0’ . Then , we compute the MI between items A’ and C . If the MI value is greater than the user specified threshold , that means we can mine the P3.1 pattern <{A , B}L1 , CL2> in the database .
After the MI for all item pairs are computed , we sort the MI values and only process the top K percentage of largest MI values of item pairs in database , where the parameter K is given by the user . This can diminish the search space substantially .
3.3 Output the interesting P3.1 patterns
Generally , the number of P3.1 that contained in a database is usually very large and is beyond the user ’s ability to process . Even we adopt some pruning strategies , such as the one described in section 3.2 , there are still large amount of P3.1 patterns derived from database . As mention in section 2 , a P3.1 pattern p can be represented as p=(<Cm , An> , s ) , where s is the frequency , or support count , of the ordered items pair < Cm , An > . We can use a support count threshold given by the user , in order to throw away the P3.1 patterns whose frequencies are below the threshold and interesting P3.1 patterns whose output frequencies are equal to or larger than the specified threshold . those
Another commonly used technique is the Top k method . We can output the top k percentage patterns from all the generated P3.1 patterns , which are sorted in descent order according to their frequencies . Here we assume that if a P3.1 pattern p has a larger frequency than that of pattern q , then we can say that pattern p is more interesting than q .
4 . Experimental Study
We have conducted extensive experiments in order to evaluate the performance of our proposed algorithm for finding P3.1 patterns in databases . The dataset in this paper is generated as the same in [ 2 ] , and we use the same notations to describe the features of dataset , ie , we use T to denote the average length of each transaction , I the average length of patterns and D the number of transactions in dataset . In this section , we will report our experimental results of mining P3.1 patterns from several aspects , ie , the number of P3.1 patterns generated , the relationship between frequent itemsets obtained by using the association rules mining algorithm , under various settings of dataset . Because the number of different length of P3.1 patterns is very huge , ie , there are many combinations of m and n . Due to the paper size restriction , we only report the experimental results of two kinds of P3.1 patterns , <C1 , A1> and <C3 , A1> . Throughout this section , we use ‘Pattern 1’ and ‘Pattern 2’ to denote the above P3.1 pattern <C1 , A1> and <C3 , A1> respectively . the execution time and
The experiments have been conducted on a PC with P4 2.1GHz CPU and 256M main memory , the operating system is WINDOWS XP .
4.1 Performances on various numbers of items
The P3.1 patterns describe the interesting follow correlations between items in databases . Generally , the items are hundreds or thousands as large in supermarket databases ; while in biological databases , the number of items ( commonly called attributes ) is simply too huge to be handled . So we aim to evaluate our algorithm for finding P3.1 patterns from databases that contains different number of items in this subsection . We adopt two kinds of databases with different size , T10I4D10K and T10I4D100K , each of which is generated with 50 , 100 , 200 , 500 and 1000 items respectively . Then we use our algorithm to extract two kinds of P3.1 patterns , <C1 , A1> and <C3 , A1> from above various databases . The K is set to 50 % , ie , we only output the top 1/2 of the total generated P3.1 patterns , which are sorted by their frequencies . The mining results are presented in Figures 5 and 6 .
16
14
12 10 8 6 4 2 0 i
) s ( e m T n o i t u c e x E
Pattern1 Pattern2
0
200 400
600 800 1000
Number of Items
Pattern1 Pattern2
50
0
0
200
400
600
800 1000
Number of Items
250
200
150
100 i i t
) s ( u c e x E e m T n o
1000 s n r e t t a P 1 3 P
. f o r e b m u N
Figure 5 . The execution time under different number of items . Left table is T10I4D10K , right one is
T10I4D100K .
16000 s n r e t t a P 1
14000
12000
10000
Pattern1 Pattern2
.
3 P f o r e b m u N
8000
6000
4000
2000
0
0
400
200 Number of Item
600
800
140000
120000
100000
Pattern1 Pattern2
80000
60000
40000
20000
0
0
200
600
400
800 Number of Items
1000
Figure 6 . The number of P3.1 patterns under different number of items . Left : T10I4D10K ; Right : T10I4D100K
From above figures , we can see that the execution time increases approximately linearly when the number of distinct items increases . While in Figure 6 , the number of generated P3.1 patterns increases greatly when the number of items is large . But clearly , the increase of the number of short P3.1 patterns ( <C , A> in Figure 6 ) is much faster than the long P3.1 patterns ( <C3 , A1> in Figure 6 ) do .
4.2 Performances on different sizes of database
In this subsection , we use databases with different size to test our algorithm , which contain 10000 , 20000 , 50000 , 100000 and 250000 transactions respectively .
150
250
250
0
50
200
50
0
150
100
100
) s (
200 i t u c e x E i e m T n o
Pattern1 Pattern2
Number of Transactions ( K )
Figure 7 . The execution time under
All of these databases have a fixed number of 400 distinct items , and the average length of transactions is set to 10 . The results are listed in Figures 7 and 8 .
Figure 8 . The number of P3.1 patterns under various size of databases various sizes of databases
80000 70000 60000 50000 40000 30000 20000 10000 0
Number of transactions ( K )
Pattern1 Pattern2
In Figures 7 and 8 , we can see a same trend as in Figures 5 and 6 . Our algorithm for finding P3.1 patterns can well scale up to large datasets , which is promising in real world applications . s n r e t t a P 1
.
3 P f o r e b m u N
150
200
250
0
50
100
4.3 Performances on different K
Generally , the number of items in database is very large , resulting in huge combinations of item pairs that need to be checked for P3.1 patterns . In order to reduce the search spaces , we adopt the pruning strategy in section 32 We give the mining results by using the MI based pruning strategy along with the Top k method . The settings of database are as follows . The number of different items is 1000 , the average length of transaction is 10 and the total number of transactions is 100000 . The execution time and number of generated P3.1 patterns are presented in Figures 9 and 10 under different K .
) s ( i e m T n o i t u c e x E
138 136 134 132 130 128 126 124 122 120 118 116 114 112 110 108
0.0
Pattern1 Pattern2
0.1
0.2
0.3
Top K
0.4
0.5
0.6
Figure 9 . The execution time under different K
Pattern1 Pattern2
120000
100000
80000
60000
40000
20000
0 s n r e t t a P 1
.
3 P f o r e b m u N
0.0
0.1
0.2
0.4
0.3 Top K
0.5
0.6
Figure 10 . The number of P3.1 patterns under different K
From Figure 10 , the number of P3.1 patterns will shrink significantly if one can select an appropriate K value .
4.4 Performances on different average length of transactions
Another factor that affects the mining process of the P3.1 patterns is the average length of transactions in databases . For this reason , we generated several databases with different average length of transactions , ie , T4 , T6 , T10 , T15 and T20 . We fix the number of distinct items to 400 , and the total number of transactions to 100000 . The experimental results of our algorithm under above settings are presented in Figures 11 and 12 . experiments have been conducted under various settings and the results show that our algorithm is efficient in finding the P3.1 patterns .
In our future work , we will extend the P3.1 pattern , in which the Action itemset of a P3.1 pattern is a collection of items instead of single item at present .
6 . References
[ 1 ] Agrawal , R . , and Swami , A . , Mining association rules between sets of items in large databases , In : Proceedings of ACM SIGMOD , 1993 , pages 207 216 .
[ 2 ] Agrawal , R . , and Srikant , R . , Fast Algorithms for Mining Association Rules in Large Database . In : Proceedings of the 20th Int’l Conf . on Very Large Databases , 1994 , pages 478 499 .
[ 3 ] Agrawal , R . , and Srikant , R.,Mining Sequential Patterns . In : Proceedings of the 11th International Conference on Data Engineering , ICDE95 , Taipei , 1995 , pages 3 14 .
[ 4 ] Özden , B . , Ramaswamy , S . , and Silberschatz , A . , Cyclic the 14th Association Rules . International Conference on Data Engineering , ICDE98 , Orlando , Florida , USA , 1998 , pages 412 421 .
In : Proceedings of
[ 5 ] Brin , S . , Motwani , R . , and Silverstein , C . , Beyond Market Baskets : Generalizing Association Rules to Correlations . In : Proceedings of ACM SIGMOD , 1997 , pages 265 276 . [ 6 ] Han , J . , Gong , W . , and Yin , Y . , Mining Segment Wise in Time Related Databases . In :
Periodic Patterns proceedings of the ACM KDD 1998 , pages 214 218 .
[ 7 ] Toroslu , IH , and Kantarcioglu , M . , Mining Cyclically [ DBLP :
Repeated Patterns . DaWaK 2001 : 83 92 conf/dawak/TorosluK01 ]
[ 8 ] Toroslu , IH , Repetition support and mining cyclic patterns . Expert Syst . Appl , 2003 , 25(3 ) : 303 311 . in
[ 9 ] Mannila , H . , Toivonen , H . , and Verkamo , AI , Discovering In : Proceedings of the First International Conference on Knowledge Discovery and Data Mining . Montreal , Quebec , 1995 , pages 144–155 . frequent episodes sequence .
[ 10 ] Zhang , S . C . , Lu J . L . and Zhang , C . Q , A fuzzy logic based method to acquire user threshold of minimumsupport for mining association rules . Information Sciences , 164(1 4 ) , 2004 : 1 16 .
500
400
300
100
2
Pattern1 Pattern2
6
8 i t
200
0
2 s n r e t t a P 1
.
3 P f o u c e x E r e b m u N i e m T n o
Pattern1 Pattern2
10 12 14 16 18 20 22
220000 200000 180000 160000 140000 120000 100000 80000 60000 40000 20000 0
Figure 11 . The execution time under
4 Average Length of Transactions different average length of Transactions
Figure 12 . The number of P3.1 patterns under
5 . Conclusion and Future Work
We have presented a model for identifying a new type of pattern called Follow Correlation Itemset Pairs ( P3.1 , or FCIP ) in sequential data . A P3.1 pattern is a pair of two items , in which the condition item likely occurs m times followed by the action item that likely appears n times in sequential data . The model consists of defining the P3.1 patterns , and finding those patterns from sequences of items . Our P3.1 pattern differs from traditional association rules mining , and also differs from the sequential patterns and cyclic patterns . In many real world applications , we can find that P3.1 is very useful in modeling the underlying relationship between objects , which is usually less considered by the existing models rules , sequential patterns and cyclic pattern etc . different average length of transactions
4 Average Length of Transactions
10 12 14 16 18 20 22 finding association the frequent itemsets of
We have developed an algorithm for mining the sequential data . Extensive
P3.1 patterns from for
6
8
