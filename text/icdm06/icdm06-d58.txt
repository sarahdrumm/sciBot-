Corrective Classification : Classifier Ensembling with Corrective and Diverse
Base Learners
Yan Zhang
Dept . of Computer Science
University of Vermont
Burlington VT 05405 , USA yzhang@cemsuvmedu
Xingquan Zhu
Dept . of Comp . Sci . & Eng . Florida Atlantic University Boca Raton FL 33431 , USA xqzhu@csefauedu
Xindong Wu
Dept . of Computer Science
University of Vermont
Burlington VT 05405 , USA xwu@cemsuvmedu
Abstract
Empirical studies on supervised learning have shown that ensembling methods lead to a model superior to the one built from a single learner under many circumstances [ 1 ] , especially when learning from imperfect , such as biased or noise infected , information sources . In this paper , we provide a novel corrective classification ( C2 ) design , which incorporates error detection , data cleansing and Bootstrap sampling to construct base learners that constitute the classifier ensemble . The essential goal is to reduce noise impacts and eventually enhance the learners built from noise corrupted data . We further analyze the importance of both the accuracy and diversity of base learners in ensembling , in order to shed some light on the mechanism under which C2 works . Experimental comparisons will demonstrate that C2 is not only superior to the learner built from the original noisy sources , but also more reliable than Bagging [ 2 ] or the Aggressive Classifier Ensemble ( ACE ) [ 3 ] , which are two degenerate components/variants of C2 .
1
Introduction
For years , learning from low quality information sources has been a major concern for the data mining community . When the underlying data bear a certain amount of errors , a common practice is to adopt data preprocessing techniques , such as noise cleansing [ 4 ] , error detection [ 5 , 6 ] , and data imputation [ 7 ] , to enhance the data quality , for the benefit of the succeeding mining procedures . For many real world applications , data preprocessing is a must to enhance the data quality before the actual mining process takes place , although the data cleaning or error correction process could possibly incur various negative impacts such as information loss or new errors . Extensive research studies have shown that if properly and carefully adopted , data processing may enhance the data quality and help to build a more robust classification model [ 5 , 8 , 3 ] .
To build a robust learning model on noisy data sources , another category of methods – classifier ensembling , has been widely adopted as an effective tool [ 1 ] . Examples include Bagging and Boosting [ 2 , 9 ] , which are two most representative mechanisms of the field . It has been shown both theoretically and empirically [ 1 , 10 ] that an effective classifier ensemble should consist of base learners with highaccuracy as well as high diversity in predictions . A common practice in building diverse base learners is to inject randomness into the learning algorithms or the training data , such that the underlying baser learners can have their own uniqueness ( diversity ) in classification [ 2 , 9 , 11 ] . Comparing to many mechanisms that help to construct diverse base learners , not much work has been done to improve the accuracy of each base learner [ 12 , 13 ] . Intuitively , there are two possibilities to improve the accuracy of base learners : selecting a learning algorithm that fits the proposed dataset well or obtaining a training dataset with enhanced data quality . The former can be solved by applying cross validation to each bootstrap dataset and then choosing a learner which outperforms others ; and the latter could be accomplished by applying appropriate data preprocessing techniques . For example , Zhang et al . proposed an Aggressive Classifier Ensemble ( ACE ) , which detects possible erroneous attribute values and recommends correction(s ) , with each base training set obtained by making a random data correction from all possible corrections [ 3 ] . Unfortunately , ACE merely aims at enhancing base learner accuracies but does not solve the diversity issue well , which essentially limits its algorithm performances .
The above observations motivate our research on Corrective Classification ( C2 ) , which unifies general data preprocessing ( error identification and correction ) and ensembling classification for effective learning from data imperfections . C2 incorporates data preprocessing and Bootstrap sampling to generate various copies of corrected data sources , and the learners trained from the data copies vote to generate the final result . Such a design ensures the underlying learning algorithms work on the original data sources , but can still produce performance improvement .
The rest of this paper is organized as follows . Section 2 presents the system framework of C2 , with an intensive
Table 1 . Pseudocode of Corrective Classification ( C2 )
Input :
D : the noisy data source , n : ensemble size K : the maximum number of simultaneous attribute value changes for each instance γ ∈ [ 0 , 1 ] : the threshhold of prediction confidence ∈ [ 0 , 1 ] : the weight of each individual leaner µ ∈ ( 0 , 1 ] : the fraction of the training data
For i ← 1 to n
Output : classifier ensemble ϕA 1 ϕA ← ∅ 2 i ← Bootstrap sampling µ × |D| instances from D3 i ← ErrorDetection&Correction(DD learn ϕ(D i )} ϕA ← ϕA∪ { i , ϕ(D i ) , and update weight i
D
4 5 6 7 End For return ϕA 8 i , K , γ )
. shown in Table 2 . Given a Bootstrap sample set from D , say D , C2 first tries to identify suspicious instances in Dand detect possible erroneous attribute values . Initially , a benchmark classifier ϕ(· , D ) is learned from DIn addition , a subset S , which aggregates the most suspicious instances from D , will be constructed . The accuracy enhancement process includes four components : ( 1 ) acquire S ; ( 2 ) locate the erroneous attribute values of instances in S ; ( 3 ) propose the error correcting solutions for these instances ; and ( 4 ) choose suitable solutions to correct the erroneous attribute values . We will briefly describe these four components and we suggest interested readers refer to [ 14 ] for the implementation details .
First of all , a set of suspicious instances S has to be determined . This decision is very important since S is the target set of instances we try to correct . We perform 10 fold cross validations on Dby iteratively using nine tenth instances of Dto build a learner and testing on the remaining one tenth instances . The wrongly predicted instances during this process will be forwarded to S . The logic behind this heuristic is that the instances not conforming to the model built from Dare more likely to be the minorities , or the problematic instances that are prone to have greater impact on the whole learning model than those not in S . The experiments have shown that the proportion of noise infected attribute in S is higher than that in the remaining instances . This evidence supports our heuristic acquisition of S .
After having acquired S , we will locate the possible erroneous attribute values on the instances in S . This is done by the following steps . First construct a predictor ϕ(· , D (i ) ) for each attribute Ai of D , as described in lines ( 4 ) ( 6 ) in Table 2 . Second , apply ϕ(· , D (i ) ) ( i = 1··· N ) to every instance in S , which results in the predicted attribute values
Figure 1 . The Framework of C2 analysis on the rationale of C2 . Section 3 reports and discusses experimental results with detailed comparisons with three methods : ACE , Bagging and C2 . We summarize and conclude in Section 4 .
2 The C2 Framework
Figure 1 presents the framework of C2 , which consists of three major steps : diversity enhancement , accuracy enhancement , and classifier ensembling . The three steps denoted in Figure 1 correspond to lines ( 3 ) , ( 4 ) and ( 5 ) , and ( 6 ) in the pseudocode described in Table 1 , respectively . C2 builds up a classifier ensemble that consists of n base learners , each of which is learned from an error corrected Bootstrap sample of the original noisy dataset D . By first sampling from D to get a Bootstrap sample Di , we enhance the diversity of each base dataset . Then we apply error detection and correction on Di to improve the data quality and get D i . This data correction process will be described in Section 22
2.1 Diversity Enhancement
The diversity enhancement of C2 is mainly achieved through Bootstrap sampling . Given data source D , with N0 = |D| instances , C2 adopts Bootstrap sampling to randomly sample µ× N0 instances from D ( with replacement ) to construct one bag of Bootstrap samples . This process repeats a certain number , say n , of times and results in n bags of Bootstrap samples , on which the error detection and correction process will perform , and eventually n base learners will be built .
2.2 Accuracy Enhancement
To enhance the accuracy of each base learner , an error i , as detection and correction process is performed on D
Table 2 . Error Detection and Correction
Input :
K : the maximum number of simultaneous attribute value changes for each instance γ : threshold of prediction confidence corrected dataset D
)
T ← learn ϕ(· , D ) S ← Suspicious Instances Subset Construction(DFor i ← 1 to N D (i ) ← Dlearn ϕ(· , D (i ) ) with ith attribute as the class label EAi ← Solution Set Construction(S , N , ϕ(· , D (i ) ) End For a ← |S| % number of instances in S S ← ∅ For k ← 1 to a
Output : 1 2 3 N ← number of attributes in D4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 End If 19 S ← S ⊕ {Ik} 20 21 End For 22 D ← D S ⊕ Sreturn D 23
If(CV > γ )
End If
Sol ← the solution with the highest conf . CV ← the prediction confidence of Sol mk ← number of solutions in EAk If(mk > 0 )
Ik ← Fix Ik with Sol for each instance in S . Third , compare the predicted and original attribute values for each instance in S , so that if the two values do not match we treat the original attribute value as a candidate erroneous value .
The basic idea to form up the correcting solutions is to try every possible way changing the original attribute values with the predicted ones and check whether the modified instances will fit ϕ(· , D ) , that is , whether the modified instances could be correctly classified after changing one or more attribute values . If the answer is “ yes ” , we regard this combination of changes as a candidate solution for this specific instance in S .
At last , we will make a correcting selection from the candidate solutions of each instance in S . In particular , we prefer a solution of less attributes involved so that we could make the number of attribute changes the smallest possible . If there are more than one solution available and they include the same number of attributes we pick the one with the highest prediction confidence . Under the condition that an instance in S does not has a possible solution , we keep it unchanged .
2.3 Analysis of the C2 Framework
The proposed error detection and correction process can not ensure a 100 % accuracy , thus new errors might be introduced to the dataset . This , however , does not necessar ily mean that C2 bears the same deficiency as most existing data cleansing or error correction approaches . First of all , it is shown from Section 3.3 and Table 3 of [ 6 ] that , the corrective attributes are more than the number of new noisy positions incurred . Meanwhile , the research efforts on ACE have shown that the prediction accuracy of each base learner will most likely increase after the error correction process [ 3 ] , where each base learner in the ensemble often outperforms the benchmark learner T that was built from the original noisy data . Second , the design of C2 ensures that although new errors might still be introduced to the training sets , the impact of these newly introduced errors will be smoothed out from the effect of randomly Bootstrap sampling and majority voting . With the above two pieces of evidence on ( 1 ) enhancing base learners through error correction and cleansing , and ( 2 ) reducing new errors through Bootstrap sampling and voting , we expect that C2 can perform effective learning from noisy information sources .
In addition to enhancing base learner accuracies , C2 , meanwhile , has certainly done more by enhancing the diversities of all underlying base learners . It is expected that such a process , improving base learners’ diversity and accuracy in the meantime , will bring enhanced classifier ensembling for learning from data imperfections . We now justify the rationale of this design .
2.4 The Rationale of Corrective Classifi cation
In order to make our presentation clear , we let pe be the error rate of an individual base learner , X be the number of base learners making wrong predictions , ∆ be the number of test instances , Y be the number of test instances being correctly predicted , and n be the number of base learners – the ensemble size of a classifier ensemble ϕA . We define the diversity , denoted by Div , as the fraction of instances that can be predicted independently by the base learners in the classifier ensemble . Div ∈ [ 0 , 1 ] with Div = 0 if all base learners predict exactly the same and Div = 1 if base learners’ predictions are totally independent .
Under the assumption of independent base learners ( Div = 1 ) , the probability for an instance to be falsely predicted by ϕA will be
Pf = P ( X ≥ fin/2' ) = n
κ=.n/2fi
Cκ npκ e ·(1− pe)n−κ . ( 1 )
Pcor = 1 − Pf .
So the probability for an instance to be correctly predicted by ϕA is
( 2 ) It is easy to derive that , only if pe < 0.5 the classifier ensemble could outperform each of the base learners . When n = 1 , the ϕA degenerates to a single learner . When pe < 0.5 , given a fixed number of ensemble size n , the accuracy of ϕA increases along with the increase of the accuracy of the base learners ( 1 − pe ) .
Div = 0 Div = 0.25 Div = 0.5 Div = 0.75 Div = 1
)
% 0 0 1 * ( y t i l i b a b o r p
.
8 0
.
6 0
.
4 0
.
2 0
.
0 0
40
50
60
70
80
90
100 prediction accuracy ( % ) with n = 50 , err = 0.3
Figure 2 . Simulation of a classifier ensemble with different diversities
In reality , base learners often cannot make independent predictions , which means that Div ∈ ( 0 , 1 ) in general . Let r = Div ∗ ∆ be the number of instances that can be independently predicted by all base learners , ∆ − r be the number of instances with exactly the same predictions , then the probability of correctly predicting k out of ∆ instances is
P ( Y = k ) = Ck
∆pk(1 − p)∆−k , where p = Div ∗ Pcor + ( 1 − Div ) ∗ ( 1 − pe ) .
( 3 )
( 4 )
The detailed procedure to derive Eq 4 from Eq 3 is described in [ 14 ] . Based on Eqs . ( 1 ) ( 4 ) with parameter settings pe = 0.3 and n = 50 , Figure 2 shows the probability distribution of ϕA with Div varying from 0 , 0.25 , 0.5 , 0.75 to 1 . As we can see , for a small proportion , say 25 % , of the test instances predicted independently , the accuracy can normally increase 7 9 percentage compared to the results from a single base learner .
Since the prediction accuracy of ϕA will significantly increase either by increasing its base learners’ accuracy or increasing its base learners’ diversity , we would know for sure that achieving both of these two aspects simultaneously will increase the accuracy of ϕA as well .
Existing efforts in enhancing the diversity usually sacrifice the base learner accuracies through randomization procedures . Take Bagging as an example . The learners built from the Bootstrap sample sets are usually less accurate than the one built from the original data set D . Therefore , if we can increase the diversity among base learners and maintain their accuracies in the meantime , or vice versa , it is very likely that this framework will produce promising results .
3 Experimental Results
3.1 Experiment Settings
We have used Weka 3 4 [ 15 ] , which provides extensive machine learning algorithms in Java , to implement our system . For all reported results , the learner ϕ is constructed by using C4.5 trees [ 16 ] , with n = 50 , K = 3 , µ = 1 , γ = 0.5 and i = 1 for all i , unless there are additional explanations otherwise ( refer to Table 1 for notations ) . We evaluate the system performances on datasets collected from the UCI data repository and report the results from ten benchmark datasets [ 17 ] .
In order to evaluate the performance of the proposed C2 algorithm under different noise levels , we obtain dataset D by corrupting a dataset E with artificially generated noise . We only inject attribute noise and leave the class attribute clean . Given a real world dataset E from the UCI data repository , we first separate E into two parts : a dataset Dbase and the corresponding testing set Dtest . Then we manually add attribute noise into Dbase , where erroneous attribute values are introduced into each attribute with a level of x*100 % , and the error corruption for each attribute is assumed to be independent . To corrupt an attribute Ai with a noise level x*100 % , the value of Ai has x*100 % probability of being randomly changed to any other possible attribute values . After noise corruption , we denote the noise corrupted dataset by D .
For every dataset E , the performances of ACE , Bagging and C2 are evaluated by using 10 times 10 fold crossvalidation . For each repetition , dataset E is randomly split into 10 equal sized subsets with the original class distribution preserved . Each of the 10 subsets is set aside for testing once , and the results are averaged over 10 trials .
3.2 Results
The comparisons among ACE , Bagging and C2 on 10 datasets are reported in Figure 3 . For each dataset , the comparative results under four noise levels ( 10 40 ) are reported . The number in each cell indicates the percentage drop on the prediction accuracy compared to the most accurate algorithm of the four under the same noise level . The algorithms corresponding to percentage 0 have the best prediction accuracy . The grey shaded “ 0 ” indicates the situation of a tie or loss for the C2 algorithm . The results in Figure 3 show that although ACE often outperforms the learners built from the original information sources ( T ) , which is consistent with the authors’ conclusions , it is normally inferior to Bagging . This concludes that Bagging is a very efficient mechanism in dealing with noisy data sources .
Without any noise correction and cleansing , the learner voted from Bootstrap sampled examples almost always produces better results than the classifier T trained from the
Noise level ( % )
Noise level ( % )
Car
Classifier T
ACE
Bagging
C2
Classifier T
Balance
ACE
Bagging
C2
Classifier T
Tictactoe ACE
Bagging
C2
Classifier T
Segmentation ACE
Bagging C2
10
3.1
2.8
2.2
0.0
10
6.8
9.6
1.1
0.0
10
8.5
6.1
0.0
0.1
10
2.3
1.4
0.0 0.1
20
4.1
3.8
2.2
0.0
30
3.8
4.2
1.5
0.0
Noise level ( % )
20
6.9
8.0
2.0
0.0
30
5.5
7.5
2.1
0.0
Noise level ( % )
20
6.7
5.0
0.7
0.0
30
6.5
5.7
0.5
0.0
Noise level ( % )
20
3.1
1.7
0.0 0.1
30
4.5
2.6
0.0 0.0
40
3.2 4.9 Monks3 ACE 1.0
Bagging
Classifier T
C2
Classifier T
Nursery ACE
Bagging
C2
Classifier T
Krvskp ACE
Bagging
C2
0.0
40
5.6
7.6
1.9
0.0
40
7.0
5.5
0.5
0.0
40
5.9
4.1
0.0 0.0
10
2.7
0.9
1.5
0.0
10
5.4
2.8
2.5
0.0
10
7.7
2.4
0.4
0.0
20
5.0
3.1
2.6
0.0
30
4.6
4.1
3.1
0.0
Noise level ( % )
20
8.8
6.1
4.2
0.0
30
9.3
7.5
4.3
0.0
40
6.0
4.3
2.1
0.0
40
8.6
7.2
3.6
0.0
Noise level ( % )
20
30
40
16.7
13.6
10.8
7.5
0.9
0.0
5.7
0.9
0.0
6.8
0.5
0.0
Noise level ( % )
10
20
30
40
Classifier T
11.4
13.6
16.7
11.8
0.1
0.0
18.5
12.4
0.5
0.0
30
40
12.3
17.1
11.0
14.3
0.1
0.0
9.0
0.7
0.0
20
9.6
6.6
0.9
0.0
Soybean ACE
Bagging
C2
Classifier T
Splice ACE
Bagging
C2
Classifier T
Audio
ACE
Bagging
C2
9.3
2.0
0.0
10
6.1
3.8
0.2
0.0
10
2.3
0.0
0.5
1.0
Noise level ( % )
0.1
0.0
40
6.8
5.7
0.1
0.0
Noise level ( % )
20
4.3
2.0
0.5
0.0
30
7.3
4.7
0.7
0.0
Figure 3 . Simulation of a Classifier Ensemble with Different Ensemble Sizes
The number in each cell indicates the percentage drop compared to the best prediction accuracy under the same noise level . The algorithm associated with 0 percentage performs the best in a certain trial . The grey shaded “ 0 ” indicates the situation of a tie or loss for the C2 algorithm . original dataset . With noise correction and data cleansing , ACE can achieve better performances than the original learner T , but the improvement from ACE is normally less significant than the results from Bagging . Note that ACE and Bagging represent two basic approaches to enhance the classifier ensemble : enhancing base learner accuracies ( ACE ) and diversities ( Bagging ) . It is convincing that either of them may lead to an improved classifier . By enhancing the base learner accuracies and diversities at the same time , it can be observed that C2 has won 34 , tied 2 , lost 4 out of a total of 40 experiments . When C2 loses its performance is still very close to the best .
Furthermore , in Figure 4 , we report the prediction accuracies of individual base learners , in comparison with the results of classifier ensembling . Two plots on each row of Figure 4 correspond to the algorithm performances at the noise levels 10 % , 20 % , 30 % and 40 % , respectively ( on the Monks 3 dataset ) . The box plot on the left column in Figure 4 shows the prediction accuracy of individual base learners of three ensembling methods with ensemble size n = 50 . This result is acquired by summarizing the prediction accuracy of all individual base learners in each of the three classifier ensembles . The right column shows the performance of three classifier ensembles , ACE , Bagging and C2 with the ensemble size of 10 , 25 and 50 , respectively . For a more comprehensive comparison , we also report the prediction accuracy of the benchmark learner T in Figure 4 . In the box plot , the average performance of base learners is centered in the middle of each box . The box represents the middle 50 % of the base learners in each ensemble . The lines in each box denote the performances of medians . The smaller the box is , the less variations of the base learners’ performances .
4 Conclusions
Learning from imperfect information sources often requires significant data preprocessing efforts to enhance the underlying data quality before the model is built . Such a preprocessing procedure often incurs a certain amount of information loss , and will eventually isolate the succeeding data mining algorithms from the original data sources . On the other hand , traditional classifier ensembles can achieve good performances on noisy data sources , but they often focus on the diversity of the base learners only . In this paper , we have proposed a Corrective Classification ( C2 ) algorithm , which nicely takes care of the diversity and accuracy among base learners for effective classifier ensembling . Our intensive analysis has also explained the rationale on why such a design can generate promising results . C2 uses Bootstrap sampling to build multiple copies of the source data , then adopts error detection and data correction to temporarily enhance the underlying data quality , and induces several base classifiers from the temporarily enhanced data . The final decision is made by majority voting from all constructed base learners . Experimental results have demonstrated that C2 outperforms Bagging and ACE consistently . Our study has concluded that systems that consider both accuracy and the diversity among base learners , will eventually lead to a classifier superior to other alternatives .
References
[ 1 ] T . G . Dietterich . Ensemble methods in machine learning . Lecture Notes in Computer Science , Proceedings of the First International Workshop on Multiple Classifier Systems , 1857:1–15 , 2000 .
Box Plot for Individual Base Learners of
Three Classifier Ensemble
Comparison of Four Methods y c a r u c c a n o i t c d e r p i
1
0.99
0.98
0.97
0.96
0.95
0.94
0.93
0.92
0.91
0.9
ACE
Bagging methods
C2
10
25
50 ensemble size ( n ) y c a r u c c a n o i t c d e r p i y c a r u c c a n o i t c d e r p i y c a r u c c a n o i t c d e r p i y c a r u c c a n o i t c d e r p i
1
0.99
0.98
0.97
0.96
0.95
0.94
0.93
0.92
0.91
0.9
0.94
0.92
0.9
0.88
0.86
0.84
0.82
0.8
0.87
0.85
0.83
0.81
0.79
0.77
0.75
0.73
0.8
0.78
0.76
0.74
0.72
0.7
0.68
0.66 y c a r u c c a n o i t c d e r p i y c a r u c c a n o i t c d e r p i
ACE
Bagging methods
C2
ACE
Bagging methods
C2 y c a r u c c a n o i t c d e r p i
0.94
0.92
0.9
0.88
0.86
0.84
0.82
0.8
0.87
0.85
0.83
0.81
0.79
0.77
0.75
0.73
0.8
0.78
0.76
0.74
0.72
0.7
0.68
0.66 beled training data . Journal of Artificial Intelligence Research , 11:131–167 , 1999 .
[ 5 ] C . M . Teng . Correcting noisy data . Proceedings of International Conference on Machine Learning , pages 239–248 , 1999 .
ACE Bagging C2 classifierT
[ 6 ] X . Zhu , X . Wu , and Y . Yang . Error detection and impact sensitive instance ranking in noisy datasets . Proceedings of the 19th National Conference on Artificial Intelligence , pages 378–384 , 2004 .
[ 7 ] I . Fellegi and D . Holt . A systematic approach to automatic edit and imputation . Journal of the American Statistical Association , 71:17–35 , 1976 .
ACE Bagging C2 classifierT
[ 8 ] C . M . Teng . Polishing blemishes : Issues in data correction . IEEE Intelligent Systems , pages 34–39 , 2004 .
[ 9 ] Y . Freund and R . E . Schapire . Experiments with a new boosting algorithm . Proceedings of the Thirteenth International Conference on Machine Learning ( ICML ) , pages 148–156 , 1996 .
[ 10 ] L . I . Kuncheva and C . J . Whitaker . Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy . Machine Learning , 51(2):181–207 , May 2003 .
[ 11 ] J . F . Kolen and J . B . Pollack . Back propagation is sensitive to initial conditions . Advances in Neural Information Processing Systems , 3:860–867 , 1991 .
[ 12 ] A . Tsymbal , M . Pechenizkiy , and P . Cunningham . Di versity in ensemble feature selection . 2003 .
[ 13 ] R . S . Michalski . A theory and methodology of inductive learning . Machine Learning : An Artificial Intelligence Approach , 1 , 1983 .
[ 14 ] Y . Zhang , X . Zhu , and X . Wu . Corrective classification : Learning from data imperfections with aggressive and diverse classifier ensembling . University of Vermont , Department of Computer Science , Technical Report CS 06 10 , April 2006 .
[ 15 ] I . H . Witten and E . Frank . Data Mining : Practical Machine Learning Tools with Java Implementations . Morgan Kaufmann , 2000 .
[ 16 ] J . R . Quinlan . C4.5 : Programs for Machine Learning : Book and Software Package . Morgan Kaufmann , 1993 .
[ 17 ] S . Hettich , C . L . Blake , and C . J . Merz . Uci repository of machine learning databases , 1998 .
10
25
50 ensemble size ( n )
10
25
50 ensemble size ( n )
ACE Bagging C2 classifierT
ACE Bagging C2 classifierT
ACE
Bagging methods
C2
10
25
50 ensemble size ( n )
Figure 4 . Comparison of four methods on dataset Monks 3 with noise levels 10 % , 20 % , 30 % , and 40 % . The box plots on the left column show the prediction accuracy of individual base learners of an classifier ensemble ( ACE , Bagging , or C2 ) with ensemble size n = 50 . The plots on the right column report the comparison result of ACE , Bagging , C2 and T .
[ 2 ] L . Breiman . Bagging predictors . Machine Learning ,
24(2):123–140 , 1996 .
[ 3 ] Y . Zhang , X . Zhu , X . Wu , and JP Bond . ACE : An aggressive classifier ensemble with error detection , correction and cleansing . Proceedings of 17th International Conference on Tools with Artificial Intelligence ( ICTAI 2005 ) , pages 310–317 , 2005 .
[ 4 ] C . E . Brodley and M . A . Friedl .
Identifying misla
