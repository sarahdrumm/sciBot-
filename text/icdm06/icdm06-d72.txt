Integrating Features from Different Sources for Music Information Retrieval
Tao Li
School of Computer Science
Florida International University
Miami , FL 33199 taoli@csfiuedu
Mitsunori Ogihara
Shenghuo Zhu
Department of Computer Science
NEC Laboratories America
University of Rochester Rochester , NY 14620 ogihara@csrochesteredu
Cupertino , CA 95014 zsh@svnec labscom
Abstract
Efficient and intelligent music information retrieval is a very important topic of the 21st century . With the ultimate goal of building personal music information retrieval systems , this paper studies the problem of identifying “ similar ” artists using both lyrics and acoustic data . In this paper , we present a clustering algorithm that integrates features from both sources to perform bimodal learning . The algorithm is tested on a data set consisting of 570 songs from 53 albums of 41 artists using artist similarity provided by All Music Guide . Experimental results show that the accuracy of artist similarity classifiers can be significantly improved and that artist similarity can be efficiently identified .
1
Introduction
In multimedia information retrieval the data are naturally multi modal , in the sense that they are represented by multiple sets of features . For example , the representation of a movie has three modes : ( i ) the personnel ( the producer , the director , the editor , the scenario writer , the music composer , the cast , etc. ) , ( ii ) the visual features ( which summarize the scenarios and the actions ) , and ( iii ) the acoustic features ( which summarize the voice and the background audio ) . The representation of popular music is also trimodal in some sense , where the second feature set is replaced by the lyrics . The personnel feature set of the representation of music , however , is significantly smaller than that of movies , since many music artists produce , compose , and perform themselves . This compels one to take the standpoint that the representation of popular music is bimodal , consisting of the acoustic features , which summarize the sound , and the text features , which summarize the words put into the music .
Two fundamental problems in dealing with multime dia data are classification and clustering . Classification is the problem of assigning predefined class labels to the data , while clustering is the problem of dividing the data into classes based on their similarity without predefined class labels . These concepts are interchangeably called supervised learning and unsupervised learning , respectively . Since the proportion of predefined class labels available as part of input is 0 % for clustering and 100 % for classification , one naturally wonders about the special cases of these two fundamental problems in which only a part of the data has predefined labels . This problem is called semi supervised learning . The main question in semisupervised learning is whether it is possible to use the unlabeled data to produce something better than the one produced using only the labeled data . In particular , for semisupervised learning of multi modal data , ie , data with heterogeneous sets of features , a natural question is whether multi modality can be effectively utilized in learning and , if so , whether such multi modal learning methods produce better results than unimodal methods .
The celebrated paper of Blum and Mitchell [ 6 ] is the first to address formally this question . In this paper , Blum and Mitchell study the problem of incorporating unlabeled data in building classifiers in the presence of two feature sets . In particular , they propose a strategy for constructing classifiers called co training for the purpose of making use of unlabeled data . The co training algorithm proceeds in rounds in the following way : In each round a classifier is built on each of the two feature sets using the current training set , which is initially set to the set of data whose labels are given as input . Then , for each feature set , the point among the unlabeled data for which the classifier with respect to the feature set provides the most confident assertion is selected and is added to the training set of the other feature set along with the assertion . ( Note that the two classifiers may select an identical point and disagree on its class label ) . Blum and Mitchell show that under a certain “ independence ” assumption about the joint distribution of
1
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 the feature sets their co training algorithm converges in the sense of PAC learning . Many research efforts have been done for the purpose of extending and generalizing the idea of co training [ 1 , 9 , 16 , 25 , 28 ] .
It is also possible to design an interactive ( or ensemble)1 learning algorithm ( that exploits interactions among classifiers to improve accuracy ) for supervised learning ( that is , all the data are already labeled ) . For example , the coboosting algorithm of Collins and Singer [ 8 ] uses the individual boosting of the feature sets with the weight adjustments influenced by the labeling of the other classifier(s ) . The approach can be used not only for supervised learning but for semi supervised learning ( indeed co boosting algorithm was originally conceived for semi supervised learning ) . Although such algorithms may fall into pitfalls due to the highly simple mutual boosting structure , Collins and Singer point out , such multi modal learning can be very powerful and thus is worth while .
The work of Blum and Mitchell and that of Collins and Singer study the design of effective algorithms multimodality through interaction for semi supervised learning and for supervised learning , respectively . This naturally leads to the question of whether multi modal interactive methods can be more powerful than unimodal methods in the case of unsupervised learning , namely , clustering . The purpose of this paper is to study this question on bimodal clustering ( we of course anticipate that bimodal clustering techniques can be naturally extended to general multimodal clustering ) . We present a clustering framework for integrating the features based on minimizing disagreement . It is known that in bimodal learning minimizing disagreement between two classifiers can improve the performance of learning [ 3 , 12 ] .
In this paper we present a formalization of the problem of minimizing disagreement in bimodal learning in the Bayesian framework . In the framework , minimizing disagreement can be thought as a simple common theme of multi modal information retrieval : individual feature sets interact to help each other by reducing disagreement among their outputs . We then present a bimodal clustering algorithm based on the common theme — initialize the cluster layout using the output of the counterpart and try to minimize the disagreement between two modes . We apply the bimodal clustering algorithm to the problem of clustering popular music songs .
The rest of the paper is organized as follows : Section 2 introduces the underlying principle of minimizing the disagreement , Section 3 presents the clustering algorithm of utilizing the general principle , Section 4 describes the two
1In the literature , the word “ interactive ” is used often in the case of bimodal learning and “ ensemble ” in the case of learning with more than two modes . Here we use “ interactive ” throughout , even to mean learning of data with more than two modes .
2 heterogeneous feature sets extracted from the lyrics and acoustics data , Section 5 presents the results of experiments . Finally Section 6 concludes .
2 Minimizing the Disagreement
2.1 Theoretical Underpinnings
In this section , we introduce the basic principle of minimizing disagreement , ie , minimizing the disagreement between two individual models could lead to the improvement of learning performance of individual models .
Our data are bimodal : let X1 and X2 be the space of the first mode and the space of the second mode , respectively . Let X = ( X1 , X2 ) be the product space of X1 and X2 . Let 0 and 1 be the class labels of these data , which we will often denote by Y . For each u ∈ {0 , 1} , we use ¯u to its opposite class label , that is , 1 − b . Suppose that the data in X is subject to a distribution D . Let f be our class label function and let f1 and f2 be our class label functions based on the first mode and on the second mode , respectively . The ( x ) in f and Y are often dropped — we will write f = u to mean f(x ) = u and Y = u to mean Y ( x ) = u , etc .
Definition 1 We say that f is a nontrivial classifier if for all u ∈ {0 , 1} , Pr(f(x ) = u|Y ( x ) = u ) > Pr(f(x ) = ¯u|Y ( x ) = u ) , where the probability is subject to D .
Remark 1 The above nontrivial condition can be restated as ( ∀u ∈ {0 , 1})[Pr(f = u|Y = u ) > 1/2 ] and as ( ∀u ∈ {0 , 1})[Pr(f 6= Y ) ≤ P r(f = u) ] .
In [ 6 ] , it is assumed that x1 and x2 are conditionally independent given the labels , ie , Pr(x1 = x0
1|x2 = x0
2 ) = Pr(x1 = x0
1|f2(x2 ) = f2(x0
2) ) .
1 on X1 and f0
The independence assumption is rather strong , but has been used by many successful applications . Suppose we build hypotheses f0 2 on X2 . Thus , if x1 and x2 are conditional independent given the labels , then f0 1 and f0 2 are also conditional independent . The conditional independence of f0 1(x1 ) = u|f0 Pr(f0 where u , v , y ∈ {0 , 1} . In other words , The conditional independence implies that ( i ) for all S1 ⊆ X1 such that the probability of ( S1 , X2 ) is non zero , the distribution of X2 in which the first mode is restricted to S1 is identical
1 and f0 2(x2 ) = v , Y = y ) = Pr(f0
2 can be interpreted as follows :
1(x1 ) = u|Y = y )
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 to the distribution of X2 with no restriction ; and that ( ii ) for all S2 ⊆ X2 such that the probability of ( X1 , S2 ) is non zero , the distribution of X1 in which the first mode is restricted to S2 is identical to the distribution of X1 with no restriction .
One can show the following ( proof omitted ) :
Theorem 1 Under conditional independence assumption , the disagreement upper bounds the misclassification error for the nontrivial classifiers .
In essence , this indicates that , under certain conditions , the disagreement upper bounds the misclassification error . Thus , minimizing disagreement will ideally decrease the upper bound on the misclassification error and could bootstrap the learning algorithm . It should be pointed out that although the principle was originally proved in the context of supervised learning [ 12 ] , it can be thought as a simple common theme of multi modal information retrieval : individual feature sets interact to help each other by reducing disagreement among their outputs .
2.2 A Bayesian Framework for Capturing Mini mizing Disagreement
Let x = ( x1 , x2 ) be an observation vector . Then the
Bayes decision rule for the first mode is :
Pr(Y = 1|x1 ) ≶0
1 Pr(Y = 0|x1 ) .
This implies that if the posteriori probability of class 1 ( respectively , class 0 ) given x1 is larger than the probability of class 0 ( respectively , class 1 ) , x1 is assigned to class 1 . Using the Bayes theorem and eliminating the common term Pr(x1 ) , we get Pr(Y = 1 ) Pr(x1|Y = 1 ) ≶0 Z
1 Pr(Y = 0 ) Pr(x1|Y = 0 ) .
The Bayes error can be computed as : 2 min{Pr(Y = 1 ) Pr(x1|1 ) , Pr(Y = 0 ) Pr(x1|0)}dx1
=
Z
Z
= Pr(Y = 1 )
Pr(x1|1)dx1 + Pr(Y = 0 )
L1 0
Pr(x1|0)dx1 .
L1 1
1 is the area in which
Here L1 Pr(Y = 1 ) Pr(x1|Y = 1 ) > Pr(Y = 0 ) Pr(x1|Y = 0 )
=
0 is the area in which and L1 Pr(Y = 1 ) Pr(x1|Y = 1 ) < Pr(Y = 0 ) Pr(x1|Y = 0 ) . 2We use Pr(xi|j ) to denote Pr(xi|Y = j ) where i = 1 , 2 and j = 0 , 1 .
L1 0
L2 0
3
In other words , if an observation x1 ∈ L1 sified as in class 1 and if x1 ∈ L1 class 0 .
1 , it will be clas0 , it will be classified as in
Under the conditional independence assumption , the disagreement between two components can be computed as
E(x1 , x2 )
= Pr{(Pr(Y = 1|x1 ) > Pr(Y = 0|x1))∧ ( Pr(Y = 1|x2 ) < Pr(Y = 0|x2))} + Pr{(Pr(Y = 1|x1 ) < Pr(Y = 0|x1))∧ ( Pr(Y = 1|x2 ) > Pr(Y = 0|x2))}
= p0(x1 , x2 ) + p1(x1 , x2)dx1dx2
Z
Z
+
Z
L1 1
L2 0
Z
L1 0
L2 1 p0(x1 , x2 ) + p1(x1 , x2)dx1dx2 ,
1 is the region where where p0(x1 , x2 ) = Pr(Y = 0 ) Pr(x1|Y = 0 ) Pr(x2|Y = 0 ) , and p1(x1 , x2 ) = Pr(Y = 1 ) Pr(x1|Y = 1 ) Pr(x2|Y = 1 ) . Here L2 Pr(Y = 1 ) Pr(x2|Y = 1 ) > Pr(Y = 0 ) Pr(x2|Y = 0 ) and L2 Pr(Y = 1 ) Pr(x2|Y = 1 ) < Pr(Y = 0 ) Pr(x2|Y = 0 ) . Similarly , if an observation x2 ∈ L2 1 , it will be classified as in class 1 and if x2 ∈ L2 0 , it will be classified as in class 0 .
0 is the region where
Observe that
= Pr(Y = 1 )
Pr(x1|Y = 1)dx1
Z
Z
Z
L1 0
Z
L1 0
+ Pr(Y = 0 )
= Pr(Y = 1 )
+ Pr(Y = 0 )
Z
Z
Z
L1 0
L2 0
Z
+
Z
Z
Pr(x2|Y = 1)dx2
Pr(x2|Y = 1)dx2
dx1 dx1
L1 1
Pr(x1|Y = 0)dx1
Pr(x1|Y = 1),Z Pr(x1|Y = 0),Z Z Z Z
L1 0
L1 1
Z
L2 1 p1(x1 , x2)dx1dx2 + p1(x1 , x2)dx1dx2 p0(x1 , x2)dx1dx2 + p0(x1 , x2)dx1dx2
L1 1
L2 0
L1 1
L2 1
Thus , to ensure that ≤ E(x1 , x2 ) , it is sufficient that p1(x1 , x2)dx1dx2 < p1(x1 , x2)dx1dx2 ,
Z
Z
L1 1
L2 0
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 andZ
Z
L1 1
L2 1 p0(x1 , x2)dx1dx2 <
Z
Z
L1 0
L2 1 p0(x1 , x2)dx1dx2 .
The above formula can be reduced to
P r(x1 ∈ L1 P r(x1 ∈ L1
0|Y = 1 ) < P r(x1 ∈ L1 1|Y = 0 ) < P r(x1 ∈ L1
1|Y = 1 ) 0|Y = 0 )
( 1 ) ( 2 )
The formulas in Eq ( 1 ) and ( 2 ) in the above are essentially the same as those in Definition 1 of Section 2 . Hence , the disagreement upper bounds can also be derived from the Bayes perspective .
Remark 2 When the conditional independence condition ( eg , equation 1 ) doesn’t hold , to guarantee that disagreement upper bounds the misclassification error , we need Pr(f0 Pr(f0
2 = 0 , Y = 1 ) ≤ Pr(f0 2 = 1 , Y = 0 ) ≤ Pr(f0
2 = 0 , Y = 1 ) 2 = 1 , Y = 0 )
1 = 1|f0 1 = 0|f0
1 = 0|f0 1 = 1|f0
In other words , if 1 6= Y |f0
Pr(f0
2 6= Y ) ≤ Pr(f0
1 = Y |f0
2 6= Y ) , then the disagreement still upper bounds the misclassification error without the conditional independence condition .
3 Bimodal Clustering
In this section , we present a clustering algorithm that integrates different features based on the principle of minimizing disagreements .
3.1 Measuring Agreements Between Clusterings Let D = {d1 , d2,··· , dn} be a set of n data points . Suppose we are given two clusterings P1 and P2 with each consists of a set of clusters :
Pi = {C 1 i , C 2 i ,··· , C ki i } , i = 1 , 2
D = Ski where ki is the number of clusters for clustering Pi , and i . The first question is how to measure the j=1 C j agreements between the two clusterings .
We use adjusted Rand index to compute the agreement between clusterings . Adjusted Rand Index is a statistic to assess the clustering quality compared against assigned known classes . The Rand Index is defined as the number of pairs of objects which are both located in the same cluster and the same class , or both in different clusters and different classes , divided by the total number of objects [ 36 ] .
4
Adjusted Rand Index which adjusts Rand Index is set between [ 0 , 1 ] [ 17 ] . The higher the Adjusted Rand Index , the more resemblance between the two clusterings .
Formally , the adjusted Rand index , ARI , is defined as
Pk1 Pk1 i=1 i=1 ( ni .
2 i=1 i=1
,nij Pk2 2 )+Pk2 j , ni . =Pk2
Pk2 ,ni . −Pk1 ,ni . Pk2 −Pk1 j=1 nij , and n.j =Pk1
2 ) j=1 ( n.j j=1 i=1
2
2
2 j=1
Here nij denotes the number of objects belonging to both C 1 i and C 2 i=1 nij .
2 ) ( n.j ( n 2 ) 2 ) ( n.j ( n 2 )
.
3.2 Clustering Procedure
We present a bimodal clustering approach based on the minimizing the disagreement principle . The algorithm is an extension of the EM method [ 13 ] . In each iteration of algorithm , an EM type procedure is employed to bootstrap the model obtained from one data source by starting with the cluster assignments obtained in the previous iteration using the other data source . Upon convergence , the two individual models are used to construct the final cluster assignment . Table 1 listed the notions used for the algorithm and the algorithm procedure is presented in Figure 1 . n si = ( s1 i ) i , s2
S = ( s1,··· , sn ) K 1,··· , λ1 Λ1 = ( λ1 1,··· , λ2 Λ2 = ( λ2 Y = ( y1 , ,··· , yn ) yn ∈ {1,··· , K} s ∈ S ys = k
Number of Songs
A song si has two modes : content s1 i and lyrics s2 i A collection of songs Number of clusters
K ) Modal 1 model parameters K ) Modal 2 model parameters Cluster assignment vector s represents a song from S Song s is in k th cluster
Table 1 . The list of notations
We assume parameterized models , one for each cluster . Typically , all the models are from the same family , eg , multivariate Gaussian . The algorithm described above is a variant of the EM algorithm . It performs an iterative optimization process for each data source by using the cluster assignments from the other sources . Note that in each iteration , one data source is picked and every data point is reassigned to one of the clusters based on information from that data source and on its previous assignment . At the end of each iteration , the algorithm explicitly checks whether the agreement between two clusterings ( one clustering from each data source ) has been improved . If it is improved , the algorithm then continues to iterate . Other
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 Algorithm 1 : Bimodal Clustering Input : S , K Output : Cluster assignment Y as well as the trained model structure 1 : Initialization : Initialize the model structure ( Λ1 , Λ2 ) as well as the cluster assignment Y
2 : while the stopping criterion does not meet do 3 :
Step I : Randomly pick a different data source i ∈ {1 , 2} Step II : Model Re estimation for source i : for each cluster k , the model parameters , λi k , are re estimated as
4 :
5 :
X k = argmax λi
λ s:s∈S,ys=k log P ( si|Λi )
Step III : Sample re assignment : for each data sample s ∈ S , set ys = argmax k log P ( si|λi k )
6 :
Step IV : Measure the agreement between two sources . If the agreement increases , goto Step I . Otherwise , goto Step II . 7 : end while 8 : Return Y as well as the trained models ( Λ1 , Λ2 ) wise , the algorithm will go back to the allocation step and hopefully get a new clustering .
4 Two Heterogeneous Feature Sets
We addresses the issue of identifying the artist style using both content and lyrics . Ellis et al . [ 26 ] point out that similarity between artists reflects personal tastes and suggest that different measures have to be combined together so as to achieve reasonable results in similar artist discovery . Recently , [ 35 ] shows the usefulness of multi modal learning for music artist style classification . In this section , we describe the feature sets extracted from the lyrics and the acoustic content .
4.1 Text Based Style Features
Recently , there has appeared some work that exploits the use of non sound information for music information retrieval . Whitman and Smaragdis [ 35 ] study the use of the descriptions ( obtained from All Music Guide ) and the sounds of artists together to improve classification . Whitman , Roy , and Vercoe [ 34 ] show that the meanings the artists associate with words can be learned from
5 the sound signals . A number of researchers also presented probabilistic approaches to model music and text jointly [ 5 , 7 , 22 , 29 ] . From these results , it can be hypothesized that by analyzing how words are used to generate lyrics , artists can be distinguished from others and similar artists can be identified .
Previous study on stylometric analysis has shown that statistical analysis on text properties could be used for text genre identification and authorship attribution [ 2 , 18 , 30 ] and over one though stylometric features ( style makers ) have been proposed in variety research disciplines [ 32 ] . To choose features for analyzing lyrics , one should be aware of the characteristics of popular song lyrics . For instance , song lyrics are usually brief and are often built from a very small vocabulary . In song lyrics , words are uttered with melody , so the sound they make plays an important in determination of words . The stemming technique , though useful in reducing the number of words to be examined , may have a negative effect . In song lyrics , word orders are often different from those in conversational sentences and song lyrics are often presented without punctuation .
To account for the characteristics of the lyrics , our textbased feature extraction consists of four components : bagof words features , Part of Speech statistics , lexical features and orthographic features .
• Bag of words : We compute the TF IDF measure for each words and select top 200 words as our features . We did not apply stemming operations .
• Part of Speech statistics : We also use the output of Brill ’s part of speech ( POS ) tagger [ 4 ] as the basis for feature extraction . POS statistics usually reflect the characteristics of writing . There are 36 POS features extracted for each document , one for each POS tag expressed as a percentage of the total number of words for the document .
• Lexical Features : By lexical features , we mean features of individual word tokens in the text . The most basic lexical features are lists of 303 generic function words taken from [ 23]3 , which generally serve as proxies for choice in syntactic ( eg , preposition phrase modifiers vs . adjectives or adverbs ) , semantic ( eg , usage of passive voice indicated by auxiliary verbs ) , and pragmatic ( eg , first person pronouns indicating personalization of a text ) planes . Function words have been shown to be effective style markers . • Orthographic features : We also use orthographic features of lexical items , such as capitalization , word
3Available on line at http://wwwcseunsweduau/∼min/ILLDATA/Functionwordhtm
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 placement , and word length distribution as our features . Word orders and lengths are very useful since the writing of lyrics usually follows certain melody .
4.2 Content Based Features
There has been a considerable amount of work in extracting descriptive features from music signals for music genre classification and artist identification [ 14 , 19 , 27 , 33 , 21 ] . In our study , we use timbral features along with wavelet coefficient histograms . The feature set consists of the following three parts and totals 35 features .
421 Mel Frequency Cepstral Coefficients ( MFCC )
MFCC is a feature set popular in speech processing and is designed to capture short term spectral based features . To obtain the feature , we first compute , for each frame , the logarithm of the amplitude spectrum based on shortterm Fourier transform , where the frequencies are divided into thirteen bins using the Mel frequency scaling . ( The “ cepstrum ” is the name coined for this logarithm . ) After taking the logarithm of the amplitude spectrum , the frequency bins are grouped and smoothed according to Melfrequency scaling , which is design to agree with perception . MFCC features are generated by decorrelating the Mel spectral vectors using discrete cosine transform . In this study , we use the first five bins , and compute the mean and variance of each over the frames .
422 Short Term Fourier Transform Features ( FFT )
This is a set of features related to timbral textures and is not captured using MFCC . It consists of the following five types . More detailed descriptions can be found in [ 33 ] .
Spectral Centroid is the centroid of the magnitude spectrum of short term Fourier transform and is a measure of spectral brightness . Spectral Rolloff is the frequency below which 85 % of the magnitude distribution is concentrated . It measures the spectral shape . Spectral Flux is the squared difference between the normalized magnitudes of successive spectral distributions . It measures the amount of local spectral change . Zero Crossings is the number of time domain zero crossings of the signal . It measures noisiness of the signal . Low Energy is the percentage of frames that have energy less than the average energy over the whole signal . It measures amplitude distribution of the signal .
We compute the mean for all five types and the variance for all but zero crossings .
423 Daubechies Wavelet Coefficient Histograms
( DWCH )
Daubechies wavelet filters are ones that are popular in image retrieval ( see [ 10] ) . To extract DWCH features , the db8 filter with seven levels of decomposition is applied to thirty seconds of sound signals . After the decomposition , the histogram of the wavelet coefficients is computed at each subband . Then the first three moments of a histogram , ie , the average , the variance , and the skewness , are used [ 11 , 21 ] to approximate the probability distribution at each subband . In addition , the subband energy , defined as the mean of the absolute value of the coefficients , is also computed at each subband . A few trials reveal that of the seven subbands of db8 ( 1 : 11025–22050 Hz , 2 : 5513–11025Hz , 3 : 2756–5513Hz , 4 : 1378–2756Hz , 5 : 689–1378Hz , 6 : 334–689Hz , 7 : 0–334Hz ) , subbands 1 , 2 , and 4 show little variation . We thus choose to use only the remaining four subbands , 3 , 5 , 6 , and 7 , for our experiments . In fact , The subbands match the models of sound octave division for perceptual scales [ 20 ] .
5 Experiments
In this section , we perform experiments to evaluate whether the clustering algorithms based on minimizing disagreement can be more powerful than unimodal methods .
5.1 Data Description
Our experiments are performed on the dataset consisting of 570 songs from 53 albums of a total of 41 artists . The sound recordings and the lyrics from them are obtained .
To obtain the ground truth of song styles , we choose to use similarity information between artists available at All Music Guide artist pages ( http://wwwallmusiccom ) , assuming that this information is the reflection of multiple individual users . By examining All Music Guide artist pages , if the name of an artist X appears on the list of artists similar to Y , it is considered that X is similar to Y . The clusters are listed in Table 2 . Our goal is to identify the song styles using both content and lyrics , ie , cluster the 570 songs into the four different clusters . We use the cluster information of the artists as the labels for their songs .
5.2 Evaluation Measures
As discussed above , we use the cluster structures obtained from All Music Guide as labels to evaluate the clustering performance . We use Purity , Entropy and Accuracy [ 38 ] as our performance measures . We expect these
6
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 Clusters No . 1
No . 2
No . 3
No . 4
Members
{ Fleetwood Mac , Yes , Utopia , Elton John , { Carly Simon , Joni Mitchell , James Taylor ,
Genesis , Steely Dan , Peter Gabriel }
Simon & Garfunkel }
Suzanne Vega , Ricky Lee Jones , { AC/DC , Black Sabbath , ZZ Top , Led Zeppelin , Grand Funk Railroad ,
Derek & The Dominos } All the remaining artists
Table 2 . Cluster Memberships . the maximum sum of T ( Ck , Lm ) for all pairs of clusters and classes , and these pairs have no overlaps . The larger accuracy usually means the better clustering performance .
5.3 Experimental Comparisons
We compare the results of the bimodal clustering algorithm with the results obtained when the clustering is applied on the two sources of data separately .
We also compare the bimodal clustering algorithm with the following clustering strategies on integrating different information sources : measures would provide us with good insights on how our algorithm works .
Purity measures the extent to which each cluster contained data points from primarily one class [ 38 ] . The purity of a clustering solution is obtained as a weighted sum of individual cluster purity values and is given by
Purity = ni n
P ( Si ) , P ( Si ) =
1 ni maxj(nj i ) ,
KX i=1 where Si is a particular cluster of size ni , nj i is the number of documents of the i th input class that were assigned to the j th cluster , K is the number of clusters and n is the total number of points 4 . In general , the larger the values of purity , the better the clustering solution is .
Entropy measures how classes distributed on various clusters [ 38 ] . The entropy of the entire clustering solution is computed as :
Entropy = −
1 n log2 m i log2 ni nj i ni
,
KX mX i=1 j=1 where m is the number of original labels , K is the number of clusters . Generally , the smaller the entropy value , the better the clustering quality is .
Accuracy discovers the one to one relationship between clusters and classes , therefore to measure the extent to which each cluster contained data points from the corresponding class . It sums up the whole matching degree between all pair class clusters . Accuracy of the clustering can be represented as : max(P
Accuracy =
T ( Ck , Lm ) )
,
Ck,Lm N where Ck denotes the k th cluster , and Lm is the m th class . T ( Ck , Lm ) is the number of entities which belong to class m are assigned to cluster k . Accuracy computes
4P ( Si ) is also called the individual cluster purity .
7
• Feature Level Integration : Feature level integration performs K means clustering after simply concatenating the features obtained from the two data sources . • Cluster Integration : Cluster integration refers to the procedure of obtaining a combined clustering from multiple clusterings of a dataset [ 31 , 24 , 15 ] . Fordenote the clusters obtained mally , let C 1 2 , , C k2 2 denote the clusters from source 1 , and C 1 obtained from source 2 . Each point di can be represented as a ( k1 + k2) dimensional vector
1 , , C k1 1
( di =(di11,··· , di1k1,··· , di21,··· , di2k2 ) dijl =
1 di ∈ C kj 0 otherwise j
, for 1 ≤ j ≤ 2 .
A combined clustering can be found by applying the K means algorithm on the new representation .
• Sequential Integration : Sequential integration is an intermediate approach of combining different information sources . It first performs clustering on one data source and obtains a clustering assignment , say , C 1 , , C k1 . We can represent each point di as a k1dimensional vector using the similar idea in cluster integration . Then we can combine the new representation with another data source using feature integration . Clustering can thus be performed on the new concatenated vectors . Depending on the order of the two sources , we have two sequential integration strategies :
1 . Sequential Integration I : first cluster based on content , then integrate with lyrics ;
2 . Sequential Integration II : first cluster based on lyrics , then integrate with content .
Figure 1 illustrates and summarizes various strategies for integrating different information sources .
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 Figure 1 . Various strategies for integrating different information sources .
5.4 Analysis of the Results
We compare the results of bimodal clustering with the results obtained when clustering is applied on content and lyrics separately , and with the results of other integration strategies . Table 3 presents the experimental results .
Feature Set(s ) Content only Lyrics only
Feature Level Integration
Cluster Integration
Sequential Integration I Sequential Integration II bimodal Clustering
Purity Entropy Accuracy 0.436 0.444 0.425 0.465 0.431 0.438 0.471
0.731 0.728 0.729 0.725 0.724 0.734 0.697
0.438 0.402 0.380 0.423 0.434 0.407 0.453
Table 3 . Performance Comparison . The numbers are obtained by averaging over ten trials .
From the table , we observe the following : • The performance of purity , entropy , and accuracy relative to the other is not always consistent in our comparison , ie , higher purity values do not necessarily correspond to lower entropy values , or to higher accuracy values . This is because different evaluation measures consider different aspects of the clustering results . For example , the entropy measure takes into
8 account the entire distribution of the data in a particular cluster and not just the largest class as in the computation of the purity . The accuracy considers the relationships among all pair class clusters . We compare these three different measures and hope they would provide enough insights for our experiments .
• The purity and accuracy of feature level integration are worse than those of content only and lyric only clustering methods , while their entropy values are fairly close . This shows that even though the joint feature space is often more informative than that available from individual sources , naive feature integration tends to generalize poorly [ 37 ] .
• Cluster Integration : The cluster integration performs better than content only and lyrics only : cluster integration have higher purity and accuracy values and lower entropy values than those of content only and lyrics only . This actually conforms to the results in [ 15 ] : cluster aggregation would usually provide better clustering results .
• Sequential Integration : the results of sequential integration are generally better than feature level integration , and they are comparable with those of contentonly and lyrics only .
• Our bimodal clustering outperforms all other methods in all three performance measures . The bimodal
Feature Level IntegrationflCluster IntegrationflSequential Integration IflSequential Integration IIflBi modal ClusteringflClusteringflMusic ClustersflMusic LyricsflMusic ContentflClusteringflMusic ClustersflMusic LyricsflMusic ContentflMusic LyricsflMusic ContentflMusic ContentflClusteringflMusic ContentflMusic ClustersflMusic ClustersflClusteringflClusteringflMusic LyricsflMusic ClustersflMusic ClustersflClusteringflMusic LyricsflMusic ContentflClusteringflMusic ContentflMusic ClustersflMusic ClustersflClusteringflClusteringflMusic LyricsflMusic ClustersflMusic ClustersflClusteringflMusic LyricsflClusteringflMusic ContentflMusic ClustersflClusteringflMusic LyricsflMusic ClustersflMusic ClustersflClustering CombinationflClusteringflMusic ContentflMusic ClustersflClusteringflMusic LyricsflMusic ClustersflMusic ClustersflClustering CombinationflClusteringflMusic ContentflClusteringflMusic LyricsflMusic ClustersflClusteringflMusic ContentflClusteringflMusic LyricsflMusic ClustersflProceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 clustering algorithm can be thought of as a kind of semantic integration of data from different information sources . The performance improvements show that bimodal clustering has advantages over cluster integration . The bimodal clustering aims to minimize the disagreements between different sources and it can implicitly learn the correlation structure between different sets of features .
Experimental comparisons show that our bimodal clustering can efficiently identify song styles . For example , in our experiments , two songs from the album Utopia / Anthology : Overture Mountain Top And Sunrise Communion With The Sun and The Very Last Time would be put into two different clusters based on their contents or lyrics only . However , using both the content and lyrics , our bimodal clustering algorithm identifies them to be in the same cluster with similar styles . Similarly , bimodal clustering identifies two songs from the album Peter Gabriel / Peter Gabriel : Excuse Me and Solsbury hill to be in the same cluster while other methods don’t . In our experiments , we have identified around 50 such pairs and they give good anecdotal evidence that our bi modal clustering algorithm can efficiently identify song styles .
To investigate the relationship between the clustering performance and the agreement with respect to the two sources , we take a closer look at our experiments . Figure 2 shows the cluster performance ( entropy and purity values ) and the ( dis )agreements between two sources in a trial . Each unit on the X axis represents five iterations of the algorithm and the Y axis shows the performance value . We can observe from Figure 2 that as the agreement between the two sources increases , the clustering quality also tends to increase ( ie , entropy is generally decreasing while purity is increasing ) .
6 Conclusion
In this paper , we study the problem on whether multimodal interactive methods can be more powerful than unimodal methods in the case of clustering . In particular , we present a clustering framework for integrating the features based on minimizing disagreement . Experimental results on a data set consisting of 570 songs from 41 artists of 53 albums show the effectiveness of our approach .
There are two natural avenues for future research . The first natural direction is on music annotation . How can we automatically and efficiently generate music style or similarity information ? Note we did not agree completely with the artist similarity obtained from All Music Guide , but nonetheless used it as the ground truth to evaluate our algorithms in the experiments . Can we incorporate the opinions
9
Figure 2 . Relationships Between Clustering Performance and Agreements . Each unit on the X axis represents 5 iterations of the algorithm and the Y axis shows the performance value . from music experts or take into account the views from individual users ? Second , it would also be interesting to extend the bimodal algorithm by using statistical inference techniques to adaptively weight different data sources during the clustering process .
7 Acknowledgements
This work is supported in part by NSF Career Award IIS 054680 , NSF grants EIA 0080124 , and EIA 0205061 .
References
[ 1 ] Steven Abeny . Bootstrapping . In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics , pages 360–367 . Morgan Kaufmann Publishers , 2002 .
[ 2 ] Shlomo Argamon , Marin Saric , and Sterling S . Stein . Style mining of electronic messages for multiple authorship discrimination : first results . In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining , pages 475–480 . ACM Press , 2003 .
[ 3 ] Suzanna Becker . Mutual information maximization : Models of cortical self organization . Network : Computation in Neural Systems , , 7(1):7–31 , February 1996 .
[ 4 ] Eric Bill . Some advances in transformation based parts of speech tagging . In Proceedings of the twelfth national conference on Artificial intelligence ( vol . 1 ) , pages 722–727 , 1994 .
[ 5 ] David M . Blei , Andrew Y . Ng , and Michael I . Jordan . Latent dirichlet allocation . J . Mach . Learn . Res . , 3:993–1022 , 2003 .
[ 6 ] Avrim Blum and Tom Mitchell . Combining labeled and In Proceedings of the unlabeled data with co training . Eleventh Annual Conference on Computational Learning Theory ( COLT’98 ) , pages 92–100 . ACM Press , 1998 .
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006 [ 7 ] Eric Brochu and Nando de Freitas . Name that song! : A probabilistic approach to querying on music and text . In Neural Information Processing Systems : Natural and Synthetic , 2002 .
[ 8 ] Michael Collins and Yoram Singer . Unsupervised models for named entity classification . In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora , 1999 .
[ 9 ] Sanjoy Dasgupta , Michael L . Littman , and David McAllester . PAC generalization bounds for co training . In T . G . Dietterich , S . Becker , and Z . Ghahramani , editors , Advances in Neural Information Processing Systems 14 , pages 375–382 , Cambridge , MA , 2002 .
[ 10 ] I . Daubechies . Ten lectures on wavelets . SIAM , Philadel phia , 1992 .
[ 11 ] Afshin David and Sethurman Panchanathan . Wavelethistogram method for face recognition . Journal of Electronic Imaging , 9(2):217–225 , 2000 .
[ 12 ] Virginia R . De Sa and Dana Ballard . Category learning through multi modality sensing . Neural Computation , 10(5):1097–1117 , 1998 .
[ 13 ] AP Dempster , NM Laird , and DB Rubin . Maximum likelihood from incomplete data via the EM algorithm . Journal of the Royal Statistical Society , 39(1):1 , 38 1977 . [ 14 ] Jonathan Foote and Shingo Uchihashi . The beat spectrum : a new approach to rhythm analysis . In IEEE International Conference on Multimedia & Expo 2001 , 2001 .
[ 15 ] Aristides Gionis , Heikki Mannila , and Panayiotis Tsaparas .
Clustering aggregation . In ICDE , pages 341–352 , 2005 .
[ 16 ] Sally Goldman and Yan Zhou . Enhancing supervised learning with unlabeled data . In Proceedings of the 17th International Conference on Machine Learning ( ICML’00 ) , pages 327–334 , 2000 .
[ 17 ] Milligan GW and Cooper MC . A study of the comparability of external criteria for hierarchical cluster analysis . Multivar Behav Res , 21:846–850 , 1986 .
[ 18 ] Brett Kessler , Geoffrey Nunberg , and Hinrich Sch¨utze . Automatic detection of text genre . In Philip R . Cohen and Wolfgang Wahlster , editors , Proceedings of the Thirty Fifth Annual Meeting of the Association for Computational Linguistics and Eighth Conference of the European Chapter of the Association for Computational Linguistics , pages 32– 38 , 1997 .
[ 19 ] Jean Laroche . Estimating tempo , swing and beat locations in audio recordings . In Workshop on Applications of Signal Processing to Audio and Acoustics ( WASPAA01 ) , 2001 .
[ 20 ] Guohui Li and Ashfaq A . Khokhar . Content based indexing and retrieval of audio data using wavelets . In IEEE International Conference on Multimedia and Expo ( II ) , pages 885–888 , 2000 .
[ 21 ] Tao Li , Mitsunori Ogihara , and Qi Li . A comparative study In Proceedon content based music genre classification . ings of 26th Annual ACM Conference on Research and Development in Information Retrieval ( SIGIR 2003 ) , pages 282–289 . ACM Press , 2003 .
[ 22 ] Beth Logan , Patrawadee Prasangsit , and Pedro Moreno . Fusion of semantic and acoustic approaches for spoken document retrieval . In Proceedings of ISCA Workshop on Multilingual Spoken Document R etrieval , 2003 .
10
[ 23 ] Roger Mitton . Spelling checkers , spelling correctors and the misspellings of poor spellers . Information Processing and Management , 23(5):103–209 , 1987 .
[ 24 ] Stefano Monti , Pablo Tamayo , Jill Mesirov , and Todd Gloub . Consensus clustering : A resampling based method for class discovery and visualization of gene expression microarray data . Machine Learning Journal , 52(1 2):91–118 , 2003 .
[ 25 ] Kamal Nigam and Rayid Ghani . Analyzing the effectiveness and applicability of co training . In Proceedings of the 2000 ACM CIKM International Conference on Information and Knowledge Management ( CIKM’00 ) , pages 86– 93 . ACM Press , 2000 .
[ 26 ] Daniel PWEllis , Brian Whitman , Adam Berenzweig , and Steve Lawrence . The quest for ground truth in musical artist similarity . In Proceedings of 3rd International Conference on Music Information Retrieval , pages 170–177 , 2002 .
[ 27 ] L . Rabiner and BH Juang . Fundamentals of Specch
Recognition . Prentice Hall , NJ , 1993 .
[ 28 ] Dan Roth and Dmitry Zelenko . Toward a theory of learning coherent concepts . In Proceedings of the Seventeenth National Conference on Artificial Intelligence and Twelfth Conference on on Innovative Applications of Artificial Intelligence ( AAAI/IAAAI’00 ) , pages 639–644 , 2000 .
[ 29 ] Malcolm Slaney . Semantic audio retrieval . In Proceedings of the IEEE International Conference on Acoustics , Speech and Signal Processing , 2002 .
[ 30 ] Efstathios Stamatatos , Nikos Fakotakis , and George Kokkinakis . Automatic text categorization in terms of genre and author . Computational Linguistics , 26(4):471–496 , 2000 . [ 31 ] Alexander Strehl and Joydeep Ghosh . Cluster ensembles a knowledge reuse framework for combining multiple partitions . The Journal of Machine Learning Research , 3:583– 617 , March 2003 .
[ 32 ] Fiona J . Tweedie and R . Harald Baayen . How variable may a constant be ? Measure of lexical richness in perspective . Computers and the Humanities , 32:323–352 , 1998 .
[ 33 ] George Tzanetakis and Perry Cook . Musical genre classification of audio signals . IEEE Transactions on Speech and Audio Processing , 10(5 ) , July 2002 .
[ 34 ] B . Whitman , D . Roy , and B . Vercoe . Learning word meanings and descriptive parameter spaces from music . In Proceedings of the HLT NAACL03 workshop on learning wording meaning from non linguistic data , 2003 .
[ 35 ] B . Whitman and P . Smaragdis . Combining musical and cultural features for intelligent style detection . In Proceedings of 3rd International Conference on Music Information Retrieval , pages 47–52 , 2002 .
[ 36 ] Rand WM . Objective criteria for the evaluation of cluster ing methods . J Am Stat Assoc , 66:846–850 , 1971 .
[ 37 ] Lizhong Wu , Sharon L . Oviatt , and Philip R . Cohen . Multimodal integration a statistical view . IEEE Transactions on Multimedia , 1(4):334–341 , 1999 .
[ 38 ] Ying Zhao and George Karypis . Empirical and theoretical comparisons of selected criterion functions for document clustering . Machine Learning , 55(3):311–331 , 2004 .
Proceedings of the Sixth International Conference on Data Mining ( ICDM'06)0 7695 2701 9/06 $20.00 © 2006
