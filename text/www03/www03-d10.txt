Fractal Summarization for Mobile Device to Access Large
Documents on the Web
Christopher C . Yang
Dep . of Systems Eng . and Eng . Management
The Chinese University of Hong Kong
Shatin , Hong Kong SAR , China yang@secuhkeduhk
ABSTRACT Wireless access with mobile ( or handheld ) devices is a promising addition to the WWW and traditional electronic business . Mobile devices provide convenience and portable access to the huge information space on the Internet without requiring users to be stationary with network connection . However , the limited screen size , narrow network bandwidth , small memory capacity and low computing power are the shortcomings of handheld devices . Loading and visualizing large documents on handheld devices become impossible . The limited resolution restricts the amount of information to be displayed . The download time is intolerably long . In this paper , we introduce the fractal summarization model for document summarization on handheld devices . Fractal summarization is developed based on the fractal theory . It generates a brief skeleton of summary at the first stage , and the details of the summary on different levels of the document are generated on demands of users . Such interactive summarization reduces the computation load in comparing with the generation of the entire summary in one batch by the traditional automatic summarization , which is ideal for wireless access . Three tier architecture with the major computation is also discussed . Visualization of summary on handheld devices is also investigated .
Categories and Subject Descriptors H31 [ Information Storage and Retrieval ] : Content Analysis and Indexing Abstracting methods ; H35 [ Information Storage and Retrieval ] : Online Information Services Web based services . Keywords Document summarization , mobile commerce , fisheye view , fractal view , handheld devices . the middle tier conducting
1 . INTRODUCTION Access to the Internet through mobile phones and other handheld devices is growing significantly in recent years . The Wireless Application Protocol ( WAP ) and Wireless Markup Language ( WML ) provide the universal open standard and markup language . In this age of information , many information centric applications have been developed for the handheld devices [ 3][4][5][6][24 ] . For example , users can now surf the web , check e mail , read news , quote stock price , etc . using handheld devices . The convenience of handheld devices allows information access without geometric limitation ; however there are other limitations of handheld devices that restrict its capability . Although the development of wireless handheld devices is fast in recent years , there are many shortcomings associated with these
Fu Lee Wang
Dep . of Systems Eng . and Eng . Management
The Chinese University of Hong Kong
Shatin , Hong Kong SAR , China flwang@secuhkeduhk devices , such as screen size , bandwidth , and memory capacity . There are two major categories of wireless handheld devices , namely WAP enabled mobile phones and wireless PDAs .
Table 1 . Screen Resolutions of Wireless Handheld Devices .
Popular Wireless Handheld Devices
Screen Resolution 84×48 96×60 96×65
Nokia 3320 , 3330 , 3360 , 5510 , 5210 , 8310 , 8390 , 8910 Nokia 6210 Nokia 3350 , 3410 , 3510 , 3590 , 3610 , 6310 , 6510 , 6590 , 7110
Palm i705
128×128 Nokia 6610 , 7210 176×208 Nokia 7650 640×200 Nokia 9110i , 9210 160×160
At present , the typical display size of popular WAP enabled handsets and PDAs are 96 × 65 pixels and 160 × 160 pixels , respectively , which is approximately 1/126 to 1/30 of the display area of a standard personal computer ( 1024×768 pixels ) . Table 1 shows the limitation of screen resolution of Nokia and Palm handheld devices . The memory capacity of a handheld device greatly limits the amount of information that can be stored . The maximum WML deck size is 64 kilobyte ( Nokia 9110i and Nokia 9210 ) , and the maximum WML deck size for most of popular handset is about 1.4 kilobytes to 2.8 kilobytes binary . The typical memory capacity of PDAs is 8MB . The current bandwidth available for WAP is 9.6Kbps and can be speedup to 40.2 kbps data speed with GPRS , however it is not comparable with the broadband internet connection for PC . Although handheld devices are convenient , they impose other constraints that do not exist on desktop computers . The low bandwidth and small resolution are major shortcomings of handheld devices . Information overloading is a critical problem ; advance searching techniques solve the problem by filtering most of the irrelevant information . However , the precision of most of the commercial search engines is not high . Users may only find a few relevant documents out of a large pool of searching result . Given large screen and high bandwidth for desktop computing , users may still be able to browse the searching result one by one and identify the relevant information using desktop computers . However , it is impossible to search and visualize the critical information on a small screen with an intolerable slow downloading speed using handheld devices . Automatic summarization summarizes a document for users to preview its major content . Users may determine if the information fits their needs by reading their summary instead of browsing the whole document one by one . The amount of information displayed and downloading time are significantly reduced . the
Traditional automatic summarization does not consider the structure of document but considers the document as a sequence of sentences . In this paper , we propose the fractal summarization model based on the statistical data and the structure of documents . Keyword feature , location feature , heading feature , and cue features are adopted . Summarization is generated interactively . Experiments have been conducted and the results show that the fractal summarization outperforms the traditional summarization . In addition , information visualization techniques are presented to reduce the visual loads . Three tier architecture which reduces the computing load of the handheld devices is also discussed .
2 . Three tier Architecture Two tier architecture is typically utilized for Internet access . The user ’s PC connects to the Internet directly , and the content loaded will be fed to the web browser and present to the user as illustrated in Figure 1 .
Web Server r e s w o r
User
B
User ’s PC
Figure 1 . Document Browsing on PC
Web Server
HTML
Document Server
XML
SQL r e z i r a m m u S r e s w o r
B
User
DB Server for Summarizer Figure 2 . Document Browsing with Summarizer on PC
User ’s PC
Due to the information overloading problem , a summarizer is introduced to summarizes a document for users to preview before presenting the whole document . As shown in Figure 2 , the content will be first fed to the summarizer after loading to the user ’s PC . The summarizer connects to database server when necessary and generates a summary to display on the browser . The two tier architecture cannot be applied on handheld devices since the computing power of handheld devices is insufficient to perform summarization and the network connection of mobile network does not provide sufficient bandwidth for navigation between the summarizer and other servers .
HTML
XML
SQL
Web Server
Document Server
DB Server for Summarizer
WML
Wireless Handhel
User
PDA
Local Synchronization r e z i r a m m u S r e s w o r
B
WAP Gateway
Figure 3 . Document Browsing with Summarizer on WAP
The three tier architecture as illustrated in Figure 3 is proposed . A WAP gateway is setup to process the summarization . The WAP gateway connects to Internet trough broadband network . The wireless handheld devices can conduct interactive navigation with the gateway through wireless network to retrieve the summary piece by piece . Alternatively , if the PDA is equipped with more memory , the complete summary can be downloaded to PDA through local synchronization .
3 . Automatic Summarization 3.1 Traditional Summarization Traditional automatic text summarization is the selection of sentences from the source document based on their significance to the document [ 7][21 ] . The selection of sentences is conducted based on the salient features of the document . The thematic , location , title , and cue features are the most widely used summarization features . The thematic feature is first identified by Luhn [ 21 ] . Edmundson proposed to assign the thematic weight to keyword based on term frequency , and the sentence weight as the sum of thematic weight of constituent keywords [ 7 ] . In information retrieval , absolute term frequency by itself is considered as less useful than term frequency normalized to the document length and term frequency in the collection [ 13 ] . As a result , the tfidf ( Term Frequency , Inverse Document Frequency ) method is proposed to calculate the thematic weight of keyword [ 25 ] . The significance of sentence is indicated by its location [ 2 ] based on the hypotheses that topic sentences tend to occur at the beginning or in the end of documents or paragraphs [ 7 ] . Edmondson proposed to assign positive weights to sentences according to their ordinal position in the document , ie , the sentences in the first and last paragraphs and the first and last sentences of the paragraphs . There are several functions proposed to calculate the location weight of sentence . Alternatively , the preference of sentence location can be stored in a list called Optimum Position Policy , and the sentence will be selected base on their order in the list [ 20 ] . The title feature is proposed based on the hypothesis that the author conceives the title as circumscribing the subject matter of the document . When the author partitions the document into major section , he summarizes it by choosing appropriate heading [ 7 ] . The weight of heading is very similar to the keyword approach . A title glossary is a list consisting of all the words in title , sub title and heading . Positive weights are assigned to the title glossary , where the title words will be assigned a weight relatively prime to the heading words . The heading weight of sentence is calculated by the sum of heading weight of its constituent words . The cue phrase feature is proposed by Edmundson [ 7 ] based on the hypothesis that the probable relevance of a sentence is affected by the presence of pragmatic words such as “ significant ” , “ impossible ” , and “ hardly ” . A stored cue dictionary is used to identify the cue phases , which comprise of three sub dictionaries : ( i ) bonus word , that are positively relevant ; ( ii ) stigma words , that are negatively relevant ; and ( iii ) null words , that are irrelevant . The cue weigh of sentence is calculated by the sum of cue weight of its constituent words
Typical summarization systems select a combination of summarization features [ 7][19][20 ] , the total weight a sentence is calculated as , Wsen(sn)=a1×wcue(sn)+a2×wkeyword(sn)+a3×wtitle(sn)+a4×wlocation(sn ) where a1 , a2 , a3 , and a4 are positive integers to adjust the weighting of four summarization features . The sentences with sentence weight higher than a threshold are selected as part of the summary . It has been proved that the weighting of different summarization features do not have any substantial effect on the average precision [ 19 ] . In our system , the maximum weight of each feature is normalized to one , and the total weight of sentence is calculated as the sum of scores of all summarization features without weighting .
3.2 Fractal Summarization Advance summarization techniques take the document structure into consideration to compute the probability of a sentence to be included in the summary . Many studies [ 8][11 ] of human abstraction process has shown that the human abstractors extract the topic sentences according to the document structure from the top level to the low level until they have extracted sufficient information . However , the traditional automatic summarization models consider the source document as a sequence of sentences but ignoring the structure of document . Fractal Summarization Model is proposed here to generate summary based on document structure . Fractal summarization generates a brief skeleton of summary at the first stage , and the details of the summary on different levels of the document are generated on demands of users . Such interactive summarization reduces the computation load in comparing with the generation of the entire summary in one batch by the traditional automatic summarization , which is ideal for m commerce . Fractal summarization is developed based on the fractal theory [ 22 ] . Fractals are mathematical objects that have high degree of redundancy . These objects are made of transformed copies of themselves or part of themselves . Mandelbrot [ 22 ] was the first who investigated the fractal theory and developed the fractal geometry . In his well known example , the length of the British coastline depends on measurement scale . The larger the scale is , the smaller value of the length of the coastline is and the higher the abstraction level is . The British coastline includes bays and peninsulas . Bays include sub bays and peninsulas include subpeninsulas . these structures , abstraction of the British coastline can be generated with different abstraction degrees . Fractal theory is grounded in geometry and dimension theory . Fractals are independent of scale and appear equally detailed at any level of magnification . Such property is known as self similarity . Any portion of a self similar fractal curve appears identical to the whole curve . If we shrink or enlarge a fractal pattern , its appearance remains unchanged . In our fractal summarization , the important information is captured from the source text by exploring the hierarchical structure and salient features of the document . A condensed version of the document that is informatively close to the original is produced iteratively using the contractive transformation in the fractal theory . Similar to the fractal geometry applying on the British coastline where the coastline includes bays , peninsulas , sub bays , and sub peninsulas , large document has a hierarchical structure with several levels , chapters , sections , subsections ,
Using fractals to represent paragraphs , sentences , and terms as shown on Figure 4 . These objects are considered as prefractal [ 9 ] . A document can be represented by a hierarchical structure as shown on Figure 4 . A document consists of chapters . A chapter consists of sections . A section may consist of subsections . A section or subsection consists of paragraphs . A paragraph consists of sentences . A sentence consists of terms . A term consists of words . A word consists of characters . A document structure can be considered as a Fractal [ 22 ] structure . At the lower abstraction level of a document , more specific information can be obtained . Although a document is not a true mathematical fractal object since a document cannot be viewed in an infinite abstraction level , we may consider a document as a Prefractal [ 9 ] . The smallest unit in a document is character ; however , neither a character nor a word will convey any meaningful information concerning the overall content of a document . The lowest abstraction level in our consideration is a term .
Document
Chapter
Chapter
Section
Section
Sub section
Sub section
Paragraph
Paragraph
Sentence
Sentence
Term
Term
Word
Word
Character
Character
Figure 4 . Prefractal Structure of Document
The Fractal Summarization Model applies a similar technique as fractal image compression [ 1][15 ] . An image is regularly segmented into sets of non overlapping square blocks , called range blocks , and then each range block is subdivided into sub range blocks , until a contractive mapping can be found to represent this sub range block . The Fractal Summarization Model generates the summary by a simple recursive deterministic algorithm based on the iterated representation of a document . The original document is partitioned by the document structure , and each block is iteratively partitioned to child blocks until each block can be transformed to some key sentences by traditional summarization methods ( Figure 5 ) .
Document Weight 1 Quota 40
Chapter 1 Weight 0.3 Quota 12
Chapter 2 Weight 500 Quota 20
Chpater 3 Weight 200 Quota 8
Section 1.1 Weight 0.1 Quota 4
Section 1.2 Weight 0.15
Quota 6
Section 1.3 Weight 0.05
Quota 2
Section 2.1 Weight 0.1 Quota 3
Section 2.2 Weight 0.25 Quota 10
Section 2.3 Weight 10.5
Quota 7
Section 3.1 Weight 0.12
Quota 5
Section 3.2 Weight 0.8 Quota 3
Paragraphs
Paragraphs
Paragraphs
Figure 5 . An Example of Fractal Summarization Model
Select the sentence in the range block by summarization
If the quota is less than threshold value
Divide the range block into sub range blocks Repeat Step 5.1 , 5.2 , 5.3
The detail of the Fractal Summarization Model is shown as the following algorithm :
Fractal Summarization Algorithm 1 . Choose a Compression Ratio . 2 . Choose a Threshold Value . 3 . Calculate the Sentence Number Quota of the Summary . 4 . Divide the document into range blocks 5 . Repeat 5.1 For each range block , Calculate the sum of sentence weight under the range block . 5.2 Allocate Quota to each range block in proportion to the sum . 5.3 For each range block ,
Else
6 . Until all the range blocks are processed
The compression ratio of summarization is defined as the ratio of number of sentences in the summary to the number of sentences in the source document . It was chosen as 25 % in most literatures because it has been proved that extraction of 20 % sentences can be as informative as the full text of the source document [ 23 ] , those summarization systems can achieve up to a 96 % precision [ 7][16][27 ] . However , Teufel pointed out the high compression ratio abstracting is more useful , and 49.6 % of precision is reported at 4 % compression ratio [ 26 ] . In order to minimize the bandwidth requirement and reduce the pressure on computing power of handheld devices , the default value of compression ratio is chosen as 4 % . By the definition of compression ratio , the sentence quota of the summary can be calculated by the number of sentences in the source document times the compression ratio . A threshold value is the maximum number of sentences can be selected from a range block , if the quota is larger than the threshold value , and the range block must be divided into subrange block . Document summarization is different from image compression , more than one attractor can be chosen in one range block . It is proven that the summarization by extraction of fixed number of sentences , the optimal length of summary is 3 to 5 sentences [ 12 ] . The default value of threshold is chosen as 5 in our system . The weights of sentences under a range block are calculated by the traditional summarization methods described in Section 31 However , the traditional summarization features cannot fully utilize traditional summarization mode , the sentence weight is static through the whole summarization process , but the sentence weight should depend on the abstract level at which the document is currently viewing at , and we will show how the summarization features can integrate with the fractal structure of document .
321 Keyword Feature in Fractal Summarization Among the keyword features proposed previously , the tfidf score of keyword is the most widely used approach ; however , in the traditional summarization , it does not take into account of the document structure , therefore modification of the tfidf formulation is derived to capture the document structure and reflect the significance of a term within a range block . the fractal model of a document .
In tfidf score of term ti is calculated as followed : wij = tfij log2 ( N/n |ti| ) where wij is the weights of term ti in document dj , tfij is the frequency of term ti in document dj , N is the number of documents in the corpus , n is the number of documents in the corpus in which term ti occurs , and |ti| is the length of the term ti . Many researchers assume that the weight of a term remains the same over the entire document . However , Hearst thinks that a term should carry different weight in different location of a fulllength document [ 14 ] . For example , a term appears in chapter A once and appears in chapter B a lot of times , the term is obviously more important in chapter B than in chapter A . This idea can be extend to other document levels , if you look at document level , a specific term inside a document should carry same weight , if you look at chapter level , a specific term inside a chapter should carry same weight but the a specific term inside two chapters may carry different weight , etc . As a result , the tfidf score should be modified to different document In fractal summarization model , the tfidf should be defined as term frequency within a range block inversely to frequency of range block containing the term , ie instead of whole document . wir = tfir log2 ( N’/n’ |ti| ) levels
Here , wir is the weights of term ti in range block r , tfir is the frequency of term ti in range block r , N’ is the number of range blocks in the corpus , n’ is the number of range block in the corpus in which term ti occurs , and |ti| is the length of the term ti .
Table 2 . tfidf of the term , ‘Hong Kong’ , at different document level
1 23 358 794 2580 8053
Text block No of Text tfidf 3528 1 222 23 247 256 66 405 10 787 1113 6
Term
1113 Document Level 70 Chapter Level 69 Section Level Subsection Level 16 2 Paragraph Level Sentence Level 1
Taking the ‘Hong Kong’ in the first chapter , first section , first subsection , first paragraph , first sentence of Hong Kong Annual Report 2000 as an example ( Table 2 ) , the ttfidf score at different document levels differ a lot , the maximum value is 3528 at document level , and minimum 6 at sentence level .
322 Location Feature in Fractal Summarization Traditional summarization systems assume that the location weight of a sentence is static , where the location weight of a sentence is fixed . However , the fractal summarization model will adopt a dynamic approach ; the location weight of sentence depends on which document level you are looking for . As it is known that the significance of a sentence is affected by the position of the sentence inside a document . For example , the sentences at the beginning and the ending of document are usually more important than the others . If we consider the first and second sentences on the same paragraph at the paragraph level , the first sentence has much more impact on the paragraph than the second sentence . However , the difference of importance of two consecutive sentences is insignificant at the document level without lost of generality . Therefore , the importance of the sentence due to its location should depend on the level we are considering .
Document Position 1 Quota 40
Chapter 1 Position 1/1 Quota 16
Chapter 2 Position 1/2 Quota 8
Chpater 3 Position 1/1 Quota 16
Section 1.1 Position 1/1 Quota 7
Section 1.2 Position 1/2 Quota 3
Section 1.3 Position 1/1 Quota 6
Section 2.1 Position 1/1
Quota 3
Section 2.2 Position 1/2 Quota 2
Section 2.3 Position 1/1 Quota 3
Section 3.1 Position 1/1 Quota 8
Section 3.2 Position 1/1 Quota 8
Paragraphs
Paragraphs
Paragraphs
Paragraphs
Figure 6 . The Fractal Summary with Position Feature Only In the fractal summarization model , we calculate the location weight for a range block instead of individual sentence , all the sentences within a range block will receive same position weight . The position weight of a range block is 1/p , where p is the shortest distance of the range block to the first or last range block under same parent range block . The weight of a range block will be calculated as product of the weights of sentence in the branch and the location factor . Consider the previous example of generic Fractal Summarization Model ( Figure 5 ) , the new quota system is changed to Figure 6 if only position feature is considered .
323 Heading Feature in Fractal Summarization The heading weight of sentence is dynamic and it depends on which level we are currently looking at the document . At different abstraction level , some headings should be hidden and some headings must be emphasized . Taking the first sentence from the first chapter , first section , first subsection , and first paragraph as an example , if we consider at the document level , only the document heading should be considered . However , if we consider at the chapter level , then we should consider the document heading as well as the chapter heading . Since the main topic of this chapter is represented by the chapter heading , therefore the terms appearing in the chapter heading should have a greater impact on the sentence . Most the internal nodes above the paragraph level in the document tree usually associate with a title heading and there are two types of heading , structural heading and informative heading . For the structural headings , they indicate the structure of the document only , but not any information about the content of the document ; for example , “ Introduction ” , “ Overview ” and “ Conclusion ” are structural headings . The informative headings can give us an abstract of the content of the branch , and they help us to understand the content of the document , and they are used for calculation of heading weight . On the other hand , the structural headings can be easily isolated by string matching with a dictionary of those structural headings , and they will be used for cue feature at Sub Section 324 The terms in the informative headings are very important in extracting the sentences for summarization . Given a sentence in a paragraph , the headings of its corresponding subsection , section , chapter , and document should be considered . The significance of a term in the heading is also affected by the distance between the sentence and the heading the hierarchical structure of the document . Propagation of fractal value [ 17 ] is a promising approach to calculate the heading weight for a sentence . The first sentence of Section 3.1 in this paper is taken as an example to illustrate the propagation of the heading weight . As shown in Figure 7 , the sentence , “ Traditional automatic text summarization is the selection of sentences from the source document based on their significance to the document ” , is located in Section 3.1 , where the heading of Section 3.1 is “ Traditional Summarization ” , the heading of Section 3 is “ Automatic Summarization ” , and the heading of the document is “ Fractal Summarization for Handheld Devices ” . To compute the heading weight of the sentence , we shall propagate the term weight of the terms that appearing in both the sentence and the headings based on the distance between the headings and the sentences and the degrees of the heading node . wheading = wheading in document + wheading in section+ wheading in subsection where wheading in document = w “ summarization ” in headingdocument /(8×2 ) wheading in section =(w “ automatic ” +w “ summarization ” ) in headingsection 3/2 wheading in subsection=(w “ traditional ” +w “ summarization ” ) in headingsubsection 3.1
Documentlevel
Sectionlevel
Subsectionlevel
Sentencelevel
Fractal Summarization for Handheld Device
Degree : 8
3 . Automatic Summarization
Degree : 2
3.1 Traditional Summarization
3.2 Fractal Summarization
First Sentence
"Traditional automatic text summarization is the selection of senetnces from the source document based on their significance to the document."
Figure 7 . Example of Heading Feature
324 Cue Feature in Fractal Summarization The abstracting process of human abstractors can help to understand the cue feature at different document levels . When human abstractors extract the sentences from a document , they will follow the document structure to search the topic sentences . During the searching of information , they will pay more attention to the range block with heading contains some bonus word such as “ Conclusion ” , since they consider it as a more important part in the document and they extract more information for those important parts . The cue feature of heading of sentence is usually classified as rhetorical feature [ 26 ] . As a result , we proposed to consider the cue feature not only in sentence level , but also in other document levels . Give a document tree , we will examine the heading of each range block by the method of cue feature and adjust their quota of entire range block accordingly . This procedure can be repeated to sub range blocks until sentence level .
4 . Experimental Result It is believed that a full length text document contains a set of subtopics [ 14 ] and a good quality summary should cover as many subtopics as possible , the fractal summarization model will produce a summary with a wider coverage of information subtopic than traditional summarization model . The traditional summarization model extracted most of sentences from few chapters , take the Hong Kong Annual Report 2000 as an example ( Table 3 ) , the traditional summarization model extracted 29 sentences from one chapter when the sentence quota is 80 sentences , and total 53 sentences extracted from top 3 chapters out of total 23 chapters , 8 chapters without sentence been extracted at all . However , the fractal summarization model extracts the sentences evenly from each chapter . In our example , it extracts maximum 8 sentences from one single chapter , and at least 1 sentences from each the chapter . The standard deviation of sentence number extracted from chapters is 2.11 sentences in fractal summarization against 6.55 sentences traditional summarization . Table 3 . Number of sentences extracted by two summarization in models from Hong Kong Annual Report 2000
Fractal Summarization
Traditional Summarization
8
29
1
2.11
0
6.55 of sentences Maximum No extracted from one single chapter Minimum No sentences extracted from one single chapter Standard deviation of No of sentences extracted from chapters of
Table 4 . Precision of two Summarization Models the
The traditional summarization .
71.25 % 67.50 % 56.25 % 63.75 % 77.50 %
81.25 % 85.00 % 80.00 % 85.00 % 88.75 %
User ID Fractal Summarization Traditional Summarization 1 2 3 4 5
A user evaluation is conducted . Five subjects were asked to evaluate the quality of summaries . Summaries generated by fractal summarization and traditional summarization are assigned to subjects randomly . The results show that all subjects consider the summary generated by fractal summarization method as a better summary against the summary generated by traditional summarization model . In order to compare the result in more great detail , we calculate the precision as number of relevant sentence in the summary divided by the number of sentences in the summary . The precision of the fractal summarization outperforms fractal summarization can achieve up to 88.75 % precision and 84 % on average , while the traditional summarization can achieve up to maximum 77.5 % precision and 67 % on average .
5 . Visualization of Fractal Summarization The summary generated by Fractal Summarization Model is represented in a tree structure . The tree structure of summary is suitable for visualization on handheld devices , and it can be further enhanced by two approaches , ( i ) Fisheye View to change the visual layout of summary , ( ii ) Fractal View to change the tree structure of summary . The display area of a handheld device is very small , Fisheye View is a tool to help user to focus on important information . The Fisheye View change the visual size of information content , but the information structure does not change , the users are still viewing the same set of object , but in different size . This idea can be further extended , since the object far away from the focus point is shown in small size , the system should not described it in same degree of detail as the focus point . Some detail information of the far away objects should be hidden , even the whole object sometimes should be removed as well . The Fractal View is another tool which will change the structure of information content , and it can help user to navigate the information contents .
5.1 Fisheye View WML is the markup language supported by wireless handheld devices . The basic unit of a WML file is a desk ; each desk must contain one or more cards . The card element defines the content display to users , and the card cannot be nested . Each card links to another card within or across decks . Nodes on the same level of the fractal summarization model are converted into card , and anchor links are utilized to implement the tree structure .
Figure 8 . Example of Fisheye View
Given a card of a summary node , there may be a lot of sentences or child nodes , a large number of sentences in a small display area makes it difficult to read . Fisheye view is a visualization technique to enlarge the focus of interest and diminish the information that is less important [ 10 ] ( Figure 9 ) . When a user look at an object , the objects nearby will be shown in a larger visual size , and the visual size of other objects will be decreased inversely proportional to its distance to the focus point .
( a ) Chapters of HKAR 2000 ( b ) Chapter 19 of HKAR 2000 Figure 9 . Screen Capture of WAP Summarization System
In our system , we modified the Fisheye View a little bit , the size of an object does not depend on the distance from the focus point , but depends on the significance of the object . We have implemented the fisheye view with 3 scale font mode available for WML . The prototype system using Nokia 6590 Handset Simulator is presented on Figure 9 . The document presenting is the Hong Kong Annual Report 2000 . There are totally 23 chapters in the annual report , 6 of them are in large font , which means that they are more important , and the rest are in normal font or small font according to their importance to the report ( Figure 9a ) . The Figure 9b shows the summary of Chapter 19 .
A handheld PDA is usually equipped with more memory , and the complete summary can downloaded as a single WML file to the PDA through local synchronization . To read the summary , the PDA is required to install a standard WML file reader , ie KWML as shown in Figure 10 [ 18 ] .
Document Weight 1 Fractal 1 Quota 40
Chapter 2 Weight 0.5 Fractal 1/3 Quota 20
Chapter 3 Weight 0.2 Fractal 1/3 Quota 8
Chapter 1 Weight 0.3 Fractal 1/3 Quota 12
Section 1.1 Weight 0.1 Fractal 1/9 Quota 4
Section 1.2 Weight 0.15 Fractal 1/9 Quota 6
Section 1.3 Weight 0.05 Fractal 1/9 Quota 2
Section 2.1 Weight 0.1 Fractal 1/9 Quota 3
Section 2.2* Weight 0.25 Fractal 1/9 Quota 10
Section 2.3 Weight 0.15 Fractal 1/9 Quota 7
Section 3.1 Weight 0.12 Fractal 1/6 Quota 5
Section 3.2 Weight 0.08 Fractal 1/6 Quota 3
Paragraphs
Paragraphs
Paragraphs
Section 1.1 Weight 0.1 Fractal 1/12 Quota 3
Section 1.1 Weight 0.1 Fractal 1/15 Quota 2
Chapter 1 Weight 0.3 Fractal 1/4 Quota 8
Section 1.2 Weight 0.15 Fractal 1/12 Quota 4
Chapter 1 Weight 0.3 Fractal 1/5 Quota 6
Section 1.2 Weight 0.15 Fractal 1/15 Quota 3
Chapter 1 Weight 0.3 Fractal 1/6 Quota 5
( a ) σ=0
Document Weight 1 Fractal 1 Quota 40
Section 1.3 Weight 0.05 Fractal 1/12 Quota 1
Section 2.1 Weight 0.1 Fractal 2/16 Quota 4
Chapter 2 Weight 0.5 Fractal 2/4 Quota 27
Section 2.2* Weight 0.25 Fractal 4/16 Quota 18
Paragraphs
( b ) σ=1
Document Weight 1 Fractal 1 Quota 40
Section 1.3 Weight 0.05 Fractal 1/15 Quota 1
Section 2.1 Weight 0.1 Fractal 3/25 Quota 3
Chapter 2 Weight 0.5 Fractal 3/5 Quota 30
Section 2.2* Weight 0.25 Fractal 9/25 Quota 23
Paragraphs
( c ) σ=2
Document Weight 1 Fractal 1 Quota 40
Chapter 2 Weight 0.5 Fractal 4/6 Quota 32
Section 2.2* Weight 0.25 Fractal 16/36 Quota 26
Paragraphs
Section 2.1 Weight 0.1 Fractal 4/36 Quota 2
( d ) σ=3
Section 2.3 Weight 0.15 Fractal 2/16 Quota 5
Section 2.3 Weight 0.15 Fractal 3/25 Quota 4
Section 2.3 Weight 0.15 Fractal 4/36 Quota 4
Chapter 3 Weight 0.2 Fractal 1/4 Quota 5
Chapter 3 Weight 0.2 Fractal 1/5 Quota 4
Chapter 3 Weight 0.2 Fractal 1/6 Quota 3
Figure 11 . Fractal Summary with Magnification Parameter
=0 , 1 , 2 , 3
6 . Conclusion Mobile commerce is a promising addition to the electronic commerce by the adoption of portable handheld devices . However , there are many shortcomings of the handheld devices , such as limited resolution and low bandwidth . In order to overcome and information visualization are proposed in this paper . The fractal summarization creates a summary in tree structure and presents the summary to the handheld devices through cards in WML . The summarization fractal the shortcomings ,
Figure 10 . KWML on Palm V
5.2 Fractal View In Fractal View [ 17 ] , the fractal value of root of a document tree is assigned to 1 , then the tree is re rooted by propagation of fractal value , which is the fractal value of a child node is assigned to be the fractal value of its parent node divided by the total number of child nodes of its parent node . The Fractal View considers only the fractal value base on the tree structure , but it didn’t consider the information value of each child nodes . On the other hand , the Fractal Summarizations consider the information value ( weight ) of each child nodes only , but it did not take into account of the propagation of fractal value . As a result , we suggested integrating both methods together , which is the quota of sentences allocated to a child branch equal to the total weight of the branch times the fractal value of the branch node base on the current user ’s view . The original fractal value cannot adjust the magnification parameter of the focus point , we suggest modifying the Fractal value ( Fv ) as :
Fvroot Fvchild node of x with focus Fvchild node of x without focus = Fvx × ( rx+σ )
= 1 = Fvx × ( 1+σ)/(rx+σ )
Where rx is the node of child node of node x , and σ is a nonegative real number to change magnification effect as Fisheye view . The larger the value is , the higher the magnification effect is . If the value is set of 0 , there is no magnification effect . Consider the above example In Figure 11 , if the user change his focus point to Section 2.2 , then the quota system will change a lot . Actually , since the quota of some node is greatly cut , therefore they will collapse into a single node . On the other hand , since a large value of quota is allocated to the node with focus , it may need to be extended to sub levels .
[ 15 ] Jacquin . A . E . 1993 . Fractal image coding : A review . In
Proceeding of the IEEE , 81(10 ) 1451 1465 .
[ 16 ] Kepiec J . , Pedersen J . , and Chen F . , 1995 . A Trainable Document Summarizer . In Proc . of the 18th Annual International ACM Conf . on Research and Development in Info . Retrieval ( SIGIR ) , 68 73 .
[ 17 ] Koike , H . , 1995 , Fractal Views : A Fractal Based Method for Controlling Information Display , ACM Transaction on Information Systems , ACM , 13(3 ) 305323 .
[ 18 ] KWML , 2002 . KWML KVM WML ( WAP ) Browser on
Palm . http://wwwjshapecom/kwml/indexhtml
[ 19 ] Lam Adesina M . , and Jones G J . F . , 2001 . Applying summarization Techniques for Term Selection in Relevance Feedback , In Proceeding of SIGIR 2001 , 1 9 .
[ 20 ] Lin , Y . , and Hovy EH , 1997 . Identifying Topics by Position . In Proc . of the Applied Natural Language Processing Conference ( ANLP 97 ) , Washington , DC , 283 290 .
[ 21 ] Luhn H . P . , 1958 . The Automatic Creation of Literature Abstracts . IBM Journal of Research and Development , 159165 .
[ 22 ] Mandelbrot B . , 1983 . The fractal geometry of nature , New
York : WH Freeman . of
Palm
Paper
[ 23 ] Morris G . , Kasper G . M . , and Adams D . A , 1992 . The effect and limitation of automated text condensing on reading comprehension performance . Information System Research , 17 35 .
[ 24 ] PALM , 2002 . PALM : Providing Fluid Connectivity in a Wireless World , White Inc . , http://wwwpalmcom/wireless/ProvidingFluidConnectivityp df .
[ 25 ] Salton G . , and Buckley C . , 1988 . Term Weighting Information in Automatic Text Retrieval ,
Approaches Processing and Management , 24 , 513 523 .
[ 26 ] Teufel S . , and Moens M . , 1998 . Sentence Extraction and rhetorical classification for flexible abstracts , AAAI Spring Symposium on Intelligent Text summarization , Stanford .
[ 27 ] Teufel S . , and Moens M . , 1997 . Sentence Extraction as a Classification Task , In Workshop ‘Intelligent and scalable .02Text summarization’ , ACL/EACL . adoption of keyword feature , location feature , heading feature , and cue feature are discussed . Users may browse the selected summary by clicking the anchor links from the highest abstraction level to the lowest abstraction level . Based on the sentence weight computed by the summarization technique , fisheye views are employed to enlarge the focus of interest and diminish the less significant sentences . Fractal views are utilized to filter the less important nodes in the document structure . Such visualization effect draws users’ attention on the important content . The threetier architecture is presented to reduce the computing load of the handheld devices . The proposed system creates an information visualization environment to avoid the existing shortcomings of handheld devices for mobile commerce .
7 . REFERENCES [ 1 ] Barnsley M . F . , and Jacquin , A . E . 1988 . Application of recurrent iterated function systems to images . In Proceedings SPIE Visual Communications and Image Processing '88 , 1001 , 122 131 .
[ 2 ] Baxendale P . , 1958 . Machine Made Index for Technical Literature An Experiment . IBM Journal ( October ) , 354 361 . [ 3 ] Buyukkokten O . , Garcia Molina H . , Paepcke A . , and Winograd T . , 2000 . Power Browser : Efficient Web Browsing for PDAs . Human Computer Interaction Conference 2000 . The Hague , The Netherlands .
[ 4 ] Buyukkokten O . , Garcia Molina H . , and Paepcke A . , 2001 . Seeing the Whole in Parts : Text Summarization for Web Browsing on Handheld Devices . In Proceedings of the 10th International WWW Conference . ( WWW10 ) . Hong Kong .
[ 5 ] Buyukkokten O . , Garcia Molina H . , and Paepcke A . , 2001 . Accordion Summarization for End Game Browsing on PDAs and Cellular Phones . Human Computer Interaction Conf . 2001 ( CHI 2001 ) . Washington .
[ 6 ] Buyukkokten O . , Garcia Molina H . , and Paepcke A . , 2001 . Text Summarization of Web pages on Handheld Devices . In Proc . of Workshop on Automatic Summarization 2001 in conj . with NAACL 2001 .
[ 7 ] Edmundson H . P . , 1968 . New Method in Automatic
Extraction . Journal of the ACM , 16(2 ) 264 285 .
[ 8 ] Endres Niggemeyer B . , Maier E . , and Sigel A . , 1995 . How to Implement a Naturalistic Model of Abstracting : Four Core Working Steps of an Expert Abstractor . Info . Processing & Manag . 31(5 ) 631 674 .
[ 9 ] Feder J . , 1988 . Fractals . Plenum , New York . [ 10 ] Furnas G . W . , 1986 . Generalized Fisheye Views . In Proceedings of the SIGCHI Conference on Human Factors in Computing System .
[ 11 ] Glaser B . G . , and Strauss A . L . , 1967 . The discovery of grounded theory ; strategies for qualitative research . Aldine de Gruyter , New York .
[ 12 ] Goldstein J . , Kantrowitz M . , Mittal V . , and Carbonell J . , 1999 . Summarizing text documents : Sentence selection and evaluation metrics . In Proceedings of SIGIR , 121 128 .
[ 13 ] Harman D . K . , 1992 . Ranking algorithms . In Information Retrieval : Data Structures and Algorithms , WB Frakes and R . Baeza Yates , Eds , chapter 14 , Prentice Hall , 363 392 .
[ 14 ] Hearst M . A . , 1993 . Subtopic Structuring for Full Length Document Access . In Proc . of the 16th Annual International ACM SIGIR Conf . on Research and Development in Information Retrieval,56 68 .
