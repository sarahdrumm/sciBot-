Privacy Preserving Bayesian Network Structure Computation on Distributed Heterogeneous Data∗
Rebecca Wright
Stevens Institute of Technology
Hoboken , NJ 07030 , USA
Zhiqiang Yang
Stevens Institute of Technology
Hoboken , NJ 07030 , USA rwright@csstevens techedu zyang@csstevens techedu
ABSTRACT As more and more activities are carried out using computers and computer networks , the amount of potentially sensitive data stored by business , governments , and other parties increases . Different parties may wish to benefit from cooperative use of their data , but privacy regulations and other privacy concerns may prevent the parties from sharing their data . Privacy preserving data mining provides a solution by creating distributed data mining algorithms in which the underlying data is not revealed .
In this paper , we present a privacy preserving protocol learning the Bayesian for a particular data mining task : network structure for distributed heterogeneous data . In this setting , two parties owning confidential databases wish to learn the structure of Bayesian network on the combination of their databases without revealing anything about their data to each other . We give an efficient and privacypreserving version of the K2 algorithm to construct the structure of a Bayesian network for the parties’ joint data . Categories & Subject Descriptors : H28 [ Database Applications ] : Data Mining General Terms : Security Keywords : Bayesian Network , Privacy Preserving Data Mining , Distributed Databases
1 .
INTRODUCTION
The rapid growth of the Internet makes it easy to collect data on a large scale . Data , including sensitive data , is generally stored by a number of entities , ranging from individuals to small businesses to government agencies . By sensitive data , we mean data that , if used improperly , can harm data subjects , data owners , data users , or other relevant parties . Concern about the ownership , control , privacy and accuracy of such data has become a top priority ∗
This work was partially supported by the National Science Foundation ( CCR 0331584 ) and by the Stevens Wireless Network Security Center ( WiNSeC ) . in technical , academic , business , and political circles . In some cases regulations and consumer backlash also prohibit different organizations from sharing their data with each other [ 3 ] . Imagine a setting where one research center has a DNA sequence database about a large set of persons and those persons’ medical histories are stored in databases of one hospital . The research center wants to determine correlations between DNA sequence and specific diseases . Due to privacy concerns and regulations such as HIPAA [ 14 ] , the hospital cannot provide any information about individuals’ medical histories to the research center .
Traditionally , data mining requires all data to be gathered into a central site where a specific algorithm can be run on the joint data . Clearly this is undesirable from a privacy perspective . Distributed data mining ( cf . [ 17 ] ) removes the requirement to bring all data to a central cite , but has usually been motivated by reasons of efficiency , and typically even these algorithms communicate some information about the data beyond the output of the desired computation , often including a sample of individual data elements . Privacy preserving data mining , introduced independently by Agrawal and Srikant [ 2 ] and Lindell and Pinkas [ 18 ] , provides data mining algorithms in which the goal is to compute or approximate the output of a particular algorithm applied to joint data , without revealing anything else , or anything else important , about the data .
Bayes networks , which we describe in more detail in Section 2 , are a powerful data mining tool . They can be used for tasks including classification , hypothesis testing , and automated scientific discovery . Bayes networks consist of a structure and associated probabilities . In this paper , we present a privacy preserving data mining algorithm for learning the structure of Bayes networks ; we do not address the computation of the associated probabilities . 1.1 Related Work
Privacy preserving data mining . Privacy preserving data mining , introduced by Agrawal and Srikant [ 2 ] and Lindell and Pinkas [ 18 ] , allows certain data mining computations to take place while providing some protection for the underlying data . There has been a large body of work on privacy preserving data mining algorithms , including as algorithms for association rules [ 20 , 15 ] , clustering [ 21 ] , naive Bayes classifiers [ 16 , 22 ] , statistical analysis [ 5 , 9 ] , and finding common elements [ 1 , 11 ] .
The privacy preserving naive Bayes classifiers are the most closely related to our work . However , naive Bayes classification makes the assumption that different attributes satisfy
713 certain independence properties ( and when this assumption holds , naive Bayes classifiers are very accurate ) . In the more common case that there are dependencies among subsets of attributes , Bayes networks yield more accurate models of the data they represent .
Cryptographic methods for privacy preserving data mining , as introduced by Lindell and Pinkas [ 18 ] for decision trees , use cryptography to provide strong privacy guarantees . Such solutions are also provided in principle by the very elegant and powerful paradigm of general secure multiparty computation ( cf . [ 12] ) , but specifically tailored can be much more efficient than applications of the general solution , particularly when the inputs to the computation are large such as in data mining algorithms . Randomized methods , introduced by Agrawal and Srikant [ 2 ] , typically are substantially more efficient than cryptographic techniques , but have less strong privacy guarantees . In general , allowing more information leakage can yield solutions that are more efficient .
In a privacy preserving protocol , one is attempting to mirror the privacy that parties would obtain by each sending their databases to a trusted third party , who is trusted not to share received data with anyone . The third party then applies the desired algorithm to the combination of two databases , and sends back only the result to the parties . However , since such a mutually trusted party often does not exist , the goal of secure distributed computation is to provide the same privacy properties in the absence of the trusted third party , using a distributed protocol . In the case where inputs are databases , which may be quite large , these distributed protocols can potentially provide an efficiency advantage over the straightforward trusted third party solution as well as a privacy advantage .
Distributed Bayes Network Learning Algorithms . Yamanishi [ 23 ] presented a distributed algorithm for cooperative Bayesian learning for homogeneous , or horizontally partitioned , data sets . In that solution , different Bayesian agents estimate the parameters of the target distribution , and a population learner combines the outputs of those Bayesian models .
Chen , Sivakumar , and Kargupta [ 6 ] showed a method for learning Bayesian networks from distributed heterogeneous data sets . In their approach , each distributed site learns their local Bayesian network . Then each site identifies some its own records and transmits those records to a central site ( or to the other parties ) . Note that while more efficient than our solution , this method is not privacy preserving .
1.2 Our Contribution
We consider the problem of learning Bayesian network structure from distributed heterogeneous binary data ( ie , vertically partitioned data ) in an efficient and privacy preserving manner . That is , we consider a setting , as in [ 6 ] , in which a dataset is distributed among two parties , with different features at each party . The parties are assumed to have a common primary key for the data set ( such as an ID ) . Attributes for each data record are binary , and can be thought of as reflecting the presence or absence of the attribute for that record . Each attribute is “ owned ” by a single site , meaning that the values for that attribute are known only by that party . In this scenario , the two parties wish to cooperate by learning the structure of Bayesian network on the combination of their two databases , without revealing the individual values in their databases to each other .
We give an efficient solution for privately computing an approximation of a typically used BN score function for heterogenous distributed data . We then use this private computation to compute a BN using a distributed version of the widely used K2 algorithm [ 8 ] . All intermediate values the parties compute are uniformly distributed random shares that sum together to the actual intermediate value . In our solution , which uses cryptography , the parties learn not only the final Bayes network structure , but also , in intermediate steps , the relative ordering ( though not the exact values , which are hidden by secret sharing ) of a score function applied to various intermediate networks . It remains open to understand the extent that this might breach the privacy of the data , as well as to find solutions that do not leak this information .
Our protocols are secure against passive adversaries ( also called semi honest adversaries ) . In this setting , corrupted parties try to infer as much as they can from the messages they receive , but they correctly follow their specified protocols . It remains open to extend our solutions efficiently to active adversaries ( also called malicious or Byzantine , in which corrupted parties can deviate arbitrarily from their specified protocols .
We discuss Bayesian networks , the K2 algorithm , and our modifications to the K2 scoring function in more detail in Section 2 . In Section 3 , we describe our privacy preserving distributed Bayesian network structure learning protocol . We conclude with additional discussion in Section 4 .
2 . BAYESIAN NETWORKS
A Bayesian network ( BN ) is a graphical model that encodes probabilistic relationships among variables of interest . This can then be used for data analysis , and is widely used in data mining applications [ 13 , 8 ] .
Formally , a Bayesian network for a set of variables V = ( x1 , , xm ) is a pair ( Bs , Bp ) , where Bs = ( V , E ) , called the network structure , is a directed acyclic graph ( DAG ) whose nodes are the set of variables , and Bp is a description of local probability distributions associated with each variable , described further below . The graph Bs describes conditional independence assertions about variables in V : an edge between two nodes denotes direct probabilistic relationships among the corresponding variables . Together , Bs and Bp define the joint probability distribution for V . We use xi to denote both the variable and its corresponding node , and πi to denote the parents of node xi in Bs . The absence of an arc between xi and xj denotes conditional independence between the two variables given the values of all other variables in the network . In particular , given structure Bs , the joint probability for any particular instantia tion is given by p(X ) =n distributions Bp are the distributions corresponding to the individual terms in this product . The set of conditional distributions Bp = {p(xi|πi ) , xi ∈ V } are called the parameters of Bayesian network . If variable xi has no parents , p(xi|πi ) is the marginal distribution of xi . i=1 p(xi|πi ) . The local probability
In the distributed two party database setting we consider , two parties Alice and Bob each hold confidential databases , DA and DB , respectively . Each database is organized as a relational table . The variable ( attribute ) sets in DA and DB are denoted by VA and VB , respectively . We assume the data is vertically partitioned : there exists a key K ( SSN , bank account , etc . ) that is common to both DA and DB , where K ∈ VA ∩ VB , such that K takes on the same set of values in DA and DB . We assume that each possible key value occurs exactly once in each database and hence the key can be used to join the two databases together.1 We further assume that Alice and Bob have each sorted their data by this attribute . Here we solve the problem for the case where each variable ( other than the key ) is binary , taking on only values 0 and 1 , reflecting presence or absence of the corresponding attribute . We assume the variables of interest are the set V = VA ∪ VB − {K} . That is , Alice and Bob wish to compute the Bayesian network structure of the variables in their combined database DA DB , except for the common key , without revealing any individual record and ideally not revealing any partial information about their own databases to each other except the information that can be derived from the final Bayesian network structure and their own database . However , our solution does reveal some partial information , in that it reveals the relative ordering of certain quantities .
2.1 The K2 Algorithm
Given a database , determining the BN structure that best represents the database is NP hard [ 7 ] , so heuristic algorithms are typically used in practice . One of the most widely used structure learning algorithm is the K2 algorithm [ 8 ] , which we use as the starting point of our distributed privacypreserving algorithm . The K2 algorithm is a greedy heuristic approach to efficiently determining a good Bayes network representation of probabilistic relationships between variables from a database of records containing observations of those variables .
The K2 algorithm begins with a graph consisting of just nodes representing the variables of interest , with no edges . For each node in turn , it then incrementally adds edges whose addition most increases the score of the node , according to a specified scoring function . When the addition of no single parent can increase the score , this algorithm stops adding parents to the node . In order to keep the DAG structure of the graph , nodes are assumed to be ordered , and only nodes earlier in the ordering can be considered as possible parents . In addition , the number of parents for any node is restricted to some maximum u . Given a node xi , Pred(xi ) denotes all the nodes less than xi in the node ordering .
Somewhat more formally , V is a set of m discrete variables , where a variable xi in V has ri possible value assignments : ( vi0 , , viri −1 ) . D is a database of n records , where each record contains a value assignment for each variable in V . In our case , D = DA DB , and the variable set V is all the variables of D except the common key K . The K2 algorithm produces a Bayesian network structure Bs whose nodes are the variables in V . Each node xi ∈ V has a set of parents πi .
1If Alice and Bob ’s databases have an overlapping but not identical set of keys , a private intersection protocol [ 1 , 11 ] could be used first to identify the common keys without revealing the keys held by only one party . This leaks the set of common key values , but this seems an acceptable or even desirable leakage in many settings , where one wants to know exactly which data was used in creating the resulting Bayesian network .
Some bookkeeping is needed for the algorithm to progress properly , and in particular for Alice and Bob to agree on the control flow in the distributed version . Specifically , given a set of variables , we assume there is a canonical ordering of the variables and their possible values . Given the set of parent variables πi of a node i , we denote the jth unique instantiation of πi by φij . We denote by qi the number of unique instantiations of πi . Then αijk is defined to be the number of records in D in which variable xi is instantiated as vik and πi is instantiated as φij . Finally , define Nij = k=0 αijk . In constructing the BN structure , the K2 algorithm uses the score function f ( i , πi ) to determine which edges to add to the partially completed structure : ( ri − 1)! ri−1
αijk!
( 1 ) f ( i , πi ) =
( Nij + ri − 1)! ri−1 k=0 qi j=1
The K2 algorithm [ 8 ] is as follows :
Input : an ordered set of m nodes , an upper bound u on the number of parents for a node , and a database D containing n records .
Output : Bayesian network structure Bs ( whose nodes are the m input nodes , and whose edges are as defined by the values of πi at the end of the computation )
For i = 1 to m {
πi = ∅ ; Pold = f ( i , πi ) ; KeepAdding = true ; While KeepAdding and |πi| < u { let z be the node in Pred(xi ) − πi that maximizes f ( i , πi ∪ {z} ) ; Pnew = f ( i , πi ∪ {z} ) ; If Pnew > Pold Pold = Pnew ; πi = πi ∪ {z} ; Else KeepAdding = false ;
}
}
2.2 Our Scoring Function
We make a number of changes to the scoring function that do not significantly affect the outcome of the K2 algorithm , but that work better for our privacy preserving computation . Denote the variables ( other than the common key K ) in DA by ( a1 , , ama ) and in DB by ( b1 , , bmb ) , where ma + mb = m . Since all the variables are binary , it follows that ri1 = 0 , ri2 = 1 , and ri = 2 .
Then , Equation 1 can be rewritten as follows : f ( i , π(i ) ) =
= qi qi j=1 j=1
1
( Nij + 1)!
αijk!
1 k=0
αij0αij1
( αij0 + αij1 + 1)!
( 2 )
( 3 )
We refer to the collection of αij0 and αij1 for all possible i and j as α parameters .
We make two changes to the scoring function f ( i , πi ) . Since it is only used for comparison purposes , we work instead with a different score function that has the same relative ordering . Finally , we then use an approximation to the simpler score function .
First , we applying the natural log to f ( i , πi ) , yielding ( i , πi ) = ln f ( i , πi ) without affecting the ordering of dif f ferent scores : ln(αij0αij1 ) − ln(αij0 + αij1 + 1)!
( 4 ) f
( i , πi ) = j=1 qi 2π , e ez , where qi
√
According to Stirling ’s approximation , for any ≥ 1 , 12 . Taking = ! = αij0 + αij1 + 1 and combining Equation 4 with Stirling ’s approximation , we have :
12+1 < z < 1
1
√ 2π
1 2 f
( i , πi ) = ln(αij0αij1)−ln ln − ln +−z ( 5 ) j=1
√ 2π does not affect the comparison Since the constant ln ( i , πi ) and z is a sufficiently small factor ( as of different f bounded by Stirling ’s approximation ) , we omit them to obtain a new score function g(i , πi ) that approximates the same relative ordering as f ( i , πi ) : g(i , πi ) = qi ( ln αij0 + ln αij1 ) − 1 2 j=1 ln − ln +
( 6 )
In our privacy preserving version of K2 , we use g(i , πi ) as the scoring function . Note that this approximation itself does not inherently leak information because it is a private approximation , in the sense of Feigenbaum et al . [ 10 ] .
3 . PRIVACY PRESERVING DISTRIBUTED ALGORITHM FOR LEARNING BAYES NETWORK STRUCTURE
Our distributed privacy preserving structure learning protocol is based on the K2 algorithm , using the variable set ( except the common key ) of the combined database DA DB , without revealing the individual data values of each party to the other .
In the original K2 algorithm , all the variables are in one central site , while in our setting the variables are distributed in two sites . Hence , we must compute score function across two sites . Remembering that = αij0 + αij1 + 1 , we can see from Equation 6 that the score relies on the α parameters . Other than the distributed computation of the scores and their comparison , our control flow is as given in the K2 algorithm . ( For efficiency reasons , it is preferable to combine the comparisons that determine which possible parent yields the highest score with the comparison to determine if this score is higher than the current score , but logically the two are equivalent . ) Note that this method leaks relative score values by revealing the order in which the edges were added , but it does not reveal the actual scores . Instead , we use privacy preserving protocols to the random shares of the scores .
Overall , our algorithm executes jointly between Alice and
Bob as follows :
Input : an ordered set of m nodes , an upper bound u on the number of parents for a node , both known to Alice and
Bob , and a database D containing n records , vertically partitioned between Alice and Bob .
Output : Bayesian network structure Bs ( whose nodes are the m input nodes , and whose edges are as defined by the values of πi at the end of the computation )
For i = 1 to m {
πi = ∅ ; KeepAdding = true ; While KeepAdding and |πi| < u {
Alice and Bob jointly determine which element of g(i , πi ) , g(i , πi ∪ {z} ) for z ∈ Pred(xi ) − πi is maximum ( with equalities resolved in favor of the current score g(i , πi ) )
As a result of the above computation , Alice and Bob learn random shares of g(i , πi ) if this was the maximum element , or g(i , πi ∪ {z} ) for the z yielding the maximum .
In the former case , KeepAdding = false ; In the latter case , πi = πi ∪ {z} ;
}
} Note that throughout the protocol execution , the current values of πi are always known to both Alice and Bob , while we use privacy preserving protocols so that the values g(i , πi ) are always shared between Alice and Bob . In the following subsections , we present a privacy preserving protocol to compute random shares of the α parameters ( Section 3.1)—which in turn uses a privacy preserving scalar product protocol ( Section 3.2)—and a privacy preserving protocol to compute random score shares from the α parameter shares ( Section 33 ) We also discuss in Section 3.4 how to use existing privacy preserving protocols to compare the shared scores . 3.1 Scalar Product Protocol
In this section , we describe the privacy preserving scalar product protocol that is used as an important subroutine to design the privacy preserving structure learning BN protocol on distributed heterogeneous data . Atallah and Du presented a secure two party scalar product protocol against semi honest adversaries [ 4 ] . However , that protocol leaks the sum of the elements of one party ’s vector to the other party . Here , we give a protocol specific to binary data ( which is all we require in our use of it ) that does not suffer this leakage , and is more efficient than that of [ 4 ] in the special case of binary data . Our protocol makes use of additive homomorphic public key encryption , such as Paillier ’s scheme [ 19 ] . A public key encryption scheme is additive homomorphic if , given encryptions e(x ) and e(y ) of two plaintexts x and y , one can efficiently compute an encryption e(x + y ) of their It also follows that given a constant c ∈ N and an sum . encryption e(x ) , one can compute e(c · x ) = e(x)c . In our protocol , there are two parties , Alice and Bob . Alice has one binary vector , ZA = ( a1 , , an ) and Bob has compute the scalar product ZA ∗ ZB = n one binary vector ZB = ( b1 , , bn ) . The goal is to privately i=1 aibi . At the end of this protocol , Alice and Bob have random shares of the result ZA ∗ ZB .
Input : Alice has a binary vector ZA = ( a1,··· , an ) and Output : Alice learns ZA∗ ZB + R and Bob learns R , where
Bob has a binary vector ZB = ( b1,··· , bn ) .
R is a random number determined by Bob .
1 . Alice generates a cryptographic key pair ( PK , SK ) of a homomorphic encryption scheme and sends the public key PK to Bob . We denote encryption with PK by e(· ) and decryption with SK by e(· ) .
2 . Alice encrypts her elements with PK and sends the vector ( e(a1),··· , e(an ) ) of encryptions to Bob .
3 . Bob generates a random number R , uniformly dis tributed in [ 0 , n ] , and encrypts it with PK .
4 . Bob computes P = e(R ) ·n 5 . Alice decrypts P to get d(P ) = R +n bi = 1 and yi = 1 if bi = 0 . Bob sends P to Alice . i=1 ai · bi . i=1 yi , where yi = e(ai ) if
Proposition 1 . Assuming both parties follow the proto col , the scalar product protocol is correct . d(e(R ) ·n follows that d(P ) = R+n i = 0 if bi = 0 . Hence , Alice gets R +n
Proof . At the end of the protocol , Alice has d(P ) = i=1 yi ) . By the homomorphic properties of e , it i = ai if bi = 1 and i=1 ai · bi and Bob a has R . We can see that Alice and Bob obtain random shares of the scalar product of the two vectors , as desired . i , where a i=1 a
Proposition 2 . Assuming both parties follow the protocol and the encryption scheme is semantically secure , the scalar product protocol protects the privacy of each party .
Proof . After executing the protocol , Bob has the encrypted vector of Alice and Alice ’s public key PK . Since the encryption scheme is semantically secure , Bob can not distinguish between e(0 ) and e(1 ) with probability better than 1/2 . Hence , Alice ’s privacy is protected . Bob ’s privacy is protected since Bob only sends the encrypted output value to Alice .
The communication complexity of this scalar product protocol is cn bits where c is the bit length of an encrypted item . Computation complexity of this protocol is n encryptions and at most n multiplications . In contrast , the protocol for the general case [ 4 ] has more than 2cκn bits communication overhead and κn encryptions and decryptions , where κ ≥ 2 is a security parameter . 3.2 Privacy Preserving Computation of
α Parameters
In this section , we describe how to compute shares of the α parameters defined in Section 2.1 in a privacy preserving manner . Recall that αijk is the number of records in DA DB where xi is instantiated as k ∈ {0 , 1} and πi is instantiated as φij ( as defined in Section 2.1 ) , and recall that qi is the number of possible sequences of values that the variables in πi can take on . The α parameters include all possible αij0 and αij1 that appear in Equation 6 in Section 22 Let 1 ≤ i ≤ m , 1 ≤ j ≤ qi , and k ∈ {0 , 1} . We say a transaction in DA ( respectively DB ) is compatible with i , j , k if within its variables , any of xi and πi that occur are instantiated as specified by xi = k and πi specified by φij . For example , suppose in a particular transaction Alice has attributes {t , a1 , a2 , a3 , a4} and Bob has
{t , b1 , b2 , b3 , b4 , b5} where t is the value of the common key variable shared by Alice and Bob . Further suppose input xi = a1 = 0 and πi = {a2 , a3 , b2 , b4 , b5} is instantiated as φij = {a2 = 0 , a3 = 1 , b2 = 1 , b4 = 1 , b5 = 1} . For Alice ’s database , if one transaction has {a1 = 0 , a2 = 0 , a3 = 1} , then this transaction is compatible with the i , j , 0 . In Bob ’s database , the transaction {b2 = 1 , b4 = 1 , b5 = 1} is compatible with i , j , 0 .
Note that in the degenerate case , all variables for xi and πi belong to one party , who can locally compute the corresponding parameter without any interaction with the other party . The following protocol computes αijk parameters for the general case in which attributes including xi and πi are distributed among two parties .
Input : DA and DB held by Alice and Bob , respectively , Values 1 ≤ i ≤ m , 1 ≤ j ≤ qi , and k ∈ {0 , 1} , plus the current value of πi and a particular instantiation φij of the variables in πi are commonly known to both parties .
Output : two random shares of αijk .
1 . Alice and Bob generate two all 0 binary vectors of length n , respectively IA and IB .
2 . For i = 1 to n , if the ith transaction in DA is compatible with i , j , k , then IA[i ] = 1 , otherwise IA[i ] = 0 . Bob executes the same operations as Alice , except using DB and IB .
3 . Alice and Bob execute the privacy preserving scalar product protocol of Section 3.1 to generate the random shares .
3.3 Privacy Preserving Approximate Score
Our goal in this subprotocol is to privately compute two random shares of g(i , πi ) , as defined by Equation 6 in Section 22 There are four kinds of sub formulas to compute : ( 1 ) ln αij0 and ln αij1 , ( 2 ) 1 2 ln , ( 3 ) ln , and ( 4 ) , where = αij0 + αij1 + 1 . Alice and Bob can compute random shares for αij0 and αij1 using the protocol of Section 32 We denote these shares by αij0 = aij0+bij0 and αij1 = aij1+bij1 where aij0 , aij1 and bij0 , bij1 are random shares held by Alice and Bob respectively . To get two random shares of g(i , πi ) , we can first generate two random shares of each sub formula for Alice and Bob , then Alice and Bob can add their random shares of sub formulas together to get the random shares of score function g(i , πi ) .
Sub formula ( 4 ) can be written as aij0 + bij0 + aij1 + bij1 + 1 . Hence , two random shares of ( 4 ) can be computed locally by Alice and Bob as aij0 + aij1 + 1 and bij0 + bij1 . Sub formula ( 1 ) can be written as ln ( aij0 + bij0 ) and ln ( aij1 + bij1 ) . Similarly , sub formula ( 2 ) can be written as 1 2 ln ( (aij0 + aij1 ) + ( bij0 + bij1 + 1) ) , where aij0 + aij1 and bij0 + bij1 + 1 can be regarded as two private inputs by Alice and Bob . Then the problem of computing random shares for sub formulas ( 1 ) and ( 2 ) can be reduced to the problem of computing two random shares for ln(v1 + v2 ) where v1 and v2 are private inputs of two parties . The ln(v1 + v2 ) problem can be solved by the privacy preserving ln x protocol of Lindell and Pinkas [ 18 ] . Similarly , the problem of generating two random shares for sub formula ( 3 ) can be reduced to the problem of computing random shares of x ln x in a privacy preserving manner , which again is solved by Lindell and Pinkas [ 18 ] .
After computing random shares for sub formulas ( 1)–(4 ) , Alice and Bob can locally add their respective random shares together to compute random shares of g(i , πi ) .
Proposition 3 . Assuming the parties are semi honest , this protocol correctly and privately computes two random shares of g(i , πi ) . 3.4 Privacy Preserving Score Comparison
In our privacy preserving protocol specified at the start of Section 3 , Alice and Bob need to determine which of a number of shared values is maximum . That is , we require the following privacy preserving computation :
Output : i and xi such that rai + rbi
Input : a vector ( ra1 , ra2 , . . . , rax ) held by Alice , and a vec≥ raj + rbj for 1 ≤ tor ( rb1 , rb2 , . . . , rbx ) held by Bob . j ≤ x . In this case , x is at most u + 1 , where u is the restriction on the number of possible parents for any node , and in any case no larger than m , the total number of attributes in the combined database . Given that generally m will be much smaller than n , this can be privately and efficiently computed using Yao ’s two party general secure multiparty computation solution [ 24 ] .
4 . DISCUSSION
We presented a privacy preserving protocol for learning Bayesian network structure on distributed heterogeneous data . The overall complexity of our solution depends on the number n of database records , the number m of attributes , and the limit u on the number of possible parents for any node . Like the original K2 algorithm , our algorithm requires computation that is exponential in u ( in order to compute the α parameters for all possible 2u instantiations of binary values to the set of parents of a given node ) . In the K2 algorithm , the inner loop runs O(mu ) times . Each time the inner loop is executed , there are O(u ) scores to compute , each requiring O(m2u ) α parameters to be computed . In our version , the computation of each α parameter , including the scalar product protocol , requires O(n ) communication and computation . This is the only place that n comes into the complexity . Everything else , including combining the α parameters into the score and the secure maximum protocol , can be done in computation and communication that is polynomial in m and 2u .
We view our work as an initial step . There are a number of remaining directions to explore . In particular , more understanding of the extent of the information leaked by our solution is needed , as well as experimental or analytical validation of our use of g as a score function instead of f . It also remains open to improve the efficiency : in particular , it would be desirable to have communication complexity sublinear , perhaps polylogarithmic , in n and m . Other directions for future work include how to privately learn the Bayesian network structure in the multiparty case , learning the probabilities Bp , and handling malicious adversaries .
5 . REFERENCES [ 1 ] R . Agrawal , A . Evfimievski , and R . Srikant . Information sharing across private databases . In Proc . 2003 ACM SIGMOD International Conference on Management of Data , pages 86–97 . ACM Press , 2003 .
[ 2 ] R . Agrawal and R . Srikant . Privacy preserving data mining . In
Proc . ACM SIGMOD Conference on Management of Data , pages 439–450 . ACM Press , 2000 .
[ 3 ] P . Ashley , C . Powers , and M . Schunter . From privacy promises to privacy management : a new approach for enforcing privacy throughout an enterprise . In Proc . 2002 Workshop on New Security Paradigms , pages 43–50 . ACM Press , 2002 .
[ 4 ] M . Atallah and W . Du . Secure multi party computational geometry . In Proc . 7th International Workshop on Algorithms and Data Structures , pages 165–179 . Springer Verlag , 2001 .
[ 5 ] R . Canetti , Y . Ishai , R . Kumar , M . Reiter , R . Rubinfeld , and
R . Wright . Selective private function evaluation with applications to private statistics . In Proc . 20th ACM Symposium on Principles of Distributed Computing , pages 293–304 . ACM Press , 2001 .
[ 6 ] R . Chen , K . Sivakumar , and H . Kargupta . Learning Bayesian network structure from distributed data . In Proc . SIAM International Conference on Data Mining , 2003 .
[ 7 ] David Maxwell Chickering . Learning Bayesian networks is
NP complete . In D . Fisher and HJ Lenz , editors , Learning from Data : Artificial Intelligence and Statistics V , pages 121–130 . Springer Verlag , 1996 .
[ 8 ] Gregory F . Cooper and Edward Herskovits . A Bayesian method for the induction of probabilistic networks from data . Mach . Learn . , 9(4):309–347 , 1992 .
[ 9 ] W . Du and M . Atallah . Privacy preserving cooperative statistical analysis . In Proc . 17th Annual Computer Security Applications Conference , pages 103–110 , 2001 .
[ 10 ] J . Feigenbaum , Y . Ishai , T . Malkin , K . Nissim , M . Strauss , and
R . Wright . Secure multiparty computation of approximations . In Proc . 28th International Colloquium on Automata , Languages and Programming , pages 927–938 . Springer Verlag , 2001 .
[ 11 ] M . Freedman , K . Nissim , and B . Pinkas . Efficient private matching and set intersection . In Advances in Cryptology — EUROCRYPT 2004 , LNCS 3027 , pages 1–19 . Springer Verlag , 2004 .
[ 12 ] O . Goldreich . Secure multi party computation . available at http://philbyucsdedu , 1998 . unpublished manuscript .
[ 13 ] D . Heckerman . A tutorial on learning with Bayesian networks . Technical report , Microsoft Research , Redmond , Washington , 1995 . Revised June 96 .
[ 14 ] HIPAA . The health insurance portability and accountability act of 1996 , October 1998 . Available at wwwcmshhsgov/hipaa/ [ 15 ] M . Kantarcioglu and C . Clifton . Privacy preserving distributed mining of association rules on horizontally partitioned data . In The ACM SIGMOD Workshop on Research Issues on Data Mining and Knowledge Discovery , pages 24–31 , June 2002 . [ 16 ] Murat Kantarcioglu and Jaideep Vaidya . Privacy preserving naive Bayes classifier for horizontally partitioned data . In IEEE Workshop on Privacy Preserving Data Mining , 2003 .
[ 17 ] Hillol Kargupta and Philip Chan . Advances in Distributed and
Parallel Knowledge Discovery . MIT/AAAI Press , 2000 .
[ 18 ] Yehuda Lindell and Benny Pinkas . Privacy preserving data mining . Journal of Cryptology , 15(3):177–206 , 2002 .
[ 19 ] P . Paillier . Public key cryptosystems based on composite degree residue classes . In Advances in Cryptography — EUROCRYPT 99 , pages 223–238 , 1999 .
[ 20 ] J . Vaidya and C . Clifton . Privacy preserving association rule mining in vertically partitioned data . In Proc . 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 639–644 . ACM Press , 2002 .
[ 21 ] Jaideep Vaidya and Chris Clifton . Privacy preserving k means clustering over vertically partitioned data . In Proc . 9th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 206–215 . ACM Press , 2003 .
[ 22 ] Jaideep Vaidya and Chris Clifton . Privacy preserving naive
Bayes classifier on vertically partitioned data . In 2004 SIAM International Conference on Data Mining , 2004 .
[ 23 ] K . Yamanishi . Distributed cooperative Bayesian learning strategies . Information and Computation , 150(1):22–56 , 1999 . [ 24 ] A . Yao . Protocols for secure computation . In Proc . 23rd IEEE
Symposium on Foundations of Computer Science , pages 160–164 , 1982 .
