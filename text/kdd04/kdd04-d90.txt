Optimal Randomization for Privacy Preserving Data Mining
Yu Zhu
Department of Statistics
Purdue University
W . Lafayette , IN 47907
Lei Liu
Department of Statistics
Purdue University
W . Lafayette , IN 47907 yuzhu@statpurdueedu liulei@statpurdueedu
ABSTRACT Randomization is an economical and efficient approach for privacy preserving data mining ( PPDM ) . In order to guarantee the performance of data mining and the protection of individual privacy , optimal randomization schemes need to be employed . This paper demonstrates the construction of optimal randomization schemes for privacy preserving density estimation . We propose a general framework for randomization using mixture models . The impact of randomization on data mining is quantified by performance degradation and mutual information loss , while privacy and privacy loss are quantified by interval based metrics . Two different types of problems are defined to identify optimal randomization for PPDM . Illustrative examples and simulation results are reported .
Categories and Subject Descriptors H28 [ Database Management ] : Database Applications— Data mining ; H20 [ Database Management ] : General— Security , integrity , and protection
General Terms Theory , Algorithms , Security
Keywords mixture model , randomization operator , individual privacy
1 .
INTRODUCTION
In today ’s world , huge amounts of data are frequently collected , processed and stored . In order to extract useful information from these data , various data mining tools have been developed and used . Meanwhile , there arise serious concerns over individual privacy in data collection , processing and mining [ 4 ] . [ 13 ] predicted the making of a conflict between data mining and privacy . [ 2 ] and [ 10 ] proposed the concept of privacy preserving ( PP ) data mining ( DM ) aimed at alleviating this conflict .
The setting of PPDM can be described by a sever client model [ 5 ] . It consists of a sever S and n clients C1 , C2 , . . . , Cn . S needs to collect data from the clients to conduct a certain data mining task . For simplicity , we assume that the data includes only one attribute X . Let xi be the value of X for Ci with 1 ≤ i ≤ n . When X is privacy sensitive , the clients may not want to reveal their individual data and thus create a dilemma between data mining and privacy . There exist two general approaches to solving this dilemma , which are the secure multi party computing approach and the randomization approach . The former relies on secure multi party computing protocols that can perform computation without revealing each party ’s private data [ 10 , 14 ] , while the latter perturbs each individual data and reveal the perturbed data for data mining . In this paper , we focus on the randomization approach .
The randomization approach was first introduced by [ 2 ] . Each client ( Ci ) adds noise ( zi ) generated from certain distribution to his/her true data ( xi ) and sends the sum ( yi = xi + zi ) to the server . Denote the randomized data by y = {yi}n i=1 . Empirical results showed that data mining can be conducted with satisfaction using y instead of x . [ 9 ] raised concerns over the capability of randomization to protect individual privacy . Clearly , on one hand , randomization protects individual data and allows data mining ; on the other hand , it also results in information loss as well as privacy loss due to the revelation of randomized data . Hence , the central question in randomization is to construct randomization schemes that can achieve a balance between sharing information and preserving privacy .
The proper quantification of privacy and privacy loss is crucial for PPDM . Several privacy metrics were proposed in the literature . Based on information theory , [ 1 ] used the differential entropy to measure the amount of privacy of a random variable X , and the mutual information between X and Y to measure the privacy loss for X caused by disclosing Y . [ 5 ] and [ 6 ] introduced a concept called privacy breach and proposed the amplification method to limit privacy breaches . However , most existing results are either ad hoc or empirical . The connections between information and privacy , especially individual privacy , are still not clear . Many questions remain open . For example , how randomizations exactly affect PPDM ? how to discriminate different randomization schemes , and how to construct optimal randomization for various PPDM tasks ? This paper is intended to build up a general framework to address these questions . We focus on privacy preserving density estimation only in the current paper , because it is one of the most fun
761 damental tasks in data mining . The rest of the paper is organized as follows . Section 2 introduces a general framework for randomization . Section 3 presents various density estimators . Section 4 includes several numeric methods for calculating the estimators . Section 5 formally discusses information loss due to randomization , develops metrics to quantify individual privacy and proposes two optimization problems to identify optimal randomization for PPDM . Section 6 presents experimental results . Section 7 summarizes the main contributions of this paper .
2 . A GENERAL FRAMEWORK
In the server client model , the attribute X can be considered as a random variable with distribution G(x ) and density function g(x ) . The original data x = {x1 , x2 , . . . , xn} is a random sample drawn from G , but the server only receives the randomized data y = {y1 , y2 , . . . , yn} . In Section 1 , y is derived from x by adding noise . In fact , more general randomization schemes exist . For Ci , randomizing xi can be regarded as randomly drawing an observation from a density f ( y|xi , θ ) that depends on xi and some other parameter θ . We call f ( y|x , θ ) the randomization operator following [ 5 ] . y can be viewed as a random sample of a random variable Y with the following distribution , h(y ; θ , G ) =Z f ( y|x , θ)dG(x ) =Z f ( y|x , θ)g(x)dν(x ) ,
( 1 ) where ν is either the Lebesgue measure or the counting measure . Then privacy preserving density estimation is to reconstruct G or g based on y and the randomization operator f . In statistics , ( 1 ) is known as the mixture model and g the mixing distribution . General mixture models have been well studied in statistics . The existing theory and methods for mixture models can be employed to facilitate the construction of optimal randomization for PPDM . Next , we discuss two randomization schemes proposed in the PPDM literature and show that they are special cases of ( 1 ) .
Example 1 . A discrete version of ( 1 ) was considered in [ 5 ] , where both x and y are discrete and f ( y|x , θ ) was written as p[x → y ] . [ 6 ] and [ 5 ] employed a scheme called select a size randomization to perturb itemsets for mining association rules . Let I is a set of n items and T = {xi}1≤i≤N be a collection of N transactions with each being a subset of items . For convenience , the transactions are assumed to have the same size . For given ρ ∈ [ 0 , 1 ] and a multinomial distribution π = {πj}m j=0 , f ( y|x , ρ , π1 , . . . , πm ) =
−j(1 − ρ)n−m−m
+j
ρm
πj m j where y is a transaction of m items and j is the number of items shared by x and y . Hence , the select a size randomization is equivalent to sampling an item subset from the space of all possible subsets according to f ( y|x , θ ) , where θ = ( ρ , π1 , . . . , πm ) . Readers are referred to [ 5 ] for a detailed description of the randomization procedure .
Example 2 . In [ 1 ] and [ 2 ] , yi are obtained by adding noise zi to the original data xi , that is , yi = xi + zi for 1 ≤ i ≤ n . Assume the noise follows a distribution with density f0(z|θ ) . Then f ( y|x , θ ) = f0(y − x|θ ) , and h(y ; θ , G ) =
2 exp{− z
R f0(y − x|θ)g(x)dν(x ) , which is called the convolution of f0 and g . To estimate g based on h is called deconvolution . If 2τ 2 } , then adding zi to xi is equivaf0(z|θ ) = 1√ lent to randomly drawing yi from a normal distribution with mean xi and variance τ 2 . If f0(z|θ ) = 1 2θ I(−θ,θ)(z ) , a uniform distribution over ( −θ , θ ) , then adding zi is equivalent to randomly drawing yi from a uniform distribution over ( xi − θ , xi + θ ) .
2πτ
Theoretically , ( 1 ) represents an extremely flexible framework for randomization . The variables x and y can be discrete or continuous , and do not have to be of the same type . We will focus on the case where both are continuous in this paper . f ( y|x , θ ) can be a general density function that depends on x and θ . In practice , however , one may want to restrict f to be in a family of distributions F . For example , in Example 2 , F is the family of normal distributions with variance τ 2 . In general , the exponential family can be considered . How to choose an optimal f ∈ F for randomization is crucial for the success of PPDM .
Mixture models naturally arise from a variety of applications and form an important type of model in statistics . Readers can consult [ 11 ] for a comprehensive account of this topic . As it will be shown later on , many existing theory and methods can be used for PPDM directly . An important difIn statistics , f is considered ference , however , does exist . to be fixed thought it may not be completely known ; while in PPDM , a central question is how to construct or identify an optimal f that can best facilitate both data mining and privacy preserving . In Sections 3 4 , we will focus on the reconstruction of G or g using existing theory and methods from mixture model .
3 . DISTRIBUTION RECONSTRUCTION
In this section , we present two main approaches to estimating G0 or g0 , which denotes the original distribution , and emphasize on the role played by f . When f is chosen , θ is known . So , it is suppressed in both h and f .
3.1 Nonparametric MLE
Let M be the class of all possible distributions over the range of X , denoted by Ω . Because y is a random sample from h(y|G ) , the likelihood function of G ∈ M is l(G ) = n i=1 log h(yi ; G ) The nonparametric maximum likelihood estimator ( NPMLE ) is defined as ˆGn = argmax G∈M l(G ) . Under fairly general regularity conditions on f , it is known that ˆGn exists and converges to G0 asymptotically [ 11 ] . There exists a nice geometric description of how ˆGn is determined by y and f ( y|x ) . For convenience , we assume that yi are different from each other . Define the likelihood vector to be L(x ) = ( f ( y1|x ) , . . . , f ( yn|x) ) . When x varies in Ω , L(x ) forms a likelihood curve Γ = {L(x ) , x ∈ Ω} in Rn . For a given G , define L(G ) = R L(x)dG(x ) . Let VM = {L(G ) , G ∈ M} . It is not difficult to see that VM is the convex hull of Γ . Consider the upper sets U(c ) = {p : p ∈ Rn such that n i=1 log pi ≥ c} . It can be shown that U(c ) is convex and there exists a unique ˆc such that VM ∩ U(ˆc ) = {L( ˆGn)} . In other words , the likelihood vector corresponding to the NPMLE ˆGn is on the boundaries of VM and U(ˆc ) . Furthermore , ˆGn is a discrete distribution with a finite number of support points , that is ,
ˆGn ∼ ˜x1
˜q1
˜x2 ˜q2
··· ···
˜xm
˜qm
( 2 ) where ˜x = ( ˜xi ) denotes the support set and ˜q1 , . . . , ˜qm are the corresponding probabilities
ˆGn can be further characterized by the gradient function of l(G ) . For any two distributions G1 and G2 , define Gt = ( 1 − t)G1 + tG2 . Clearly , Gt belongs to M if t ∈ [ 0 , 1 ] and l(Gt ) is a function over [ 0 , 1 ] . The derivative of l(Gt ) with respect to t at 0 is defined to be the gradient of l from G1 to i=1 Li(G2 )
− 1 . When G2 is a G2 , which is D(G1 ; G2 ) = n − 1 . i=1 Li(x ) point mass at x , it becomes D(G1 ; x ) = n Assume that f ( yi|x ) are nonnegative and bounded , we have G is a MLE estimator if and only if ( P1 ) D(G ; x ) ≤ 0 for x ∈ Ω ; ( P2 ) D( ˆGn ; ˜x ) = 0 for ˜x in ˜x . P1 and P2 can be used to derive algorithms for calculating ˆGn . 3.2 Kernel Estimators
Li(G1 )
Li(G1 )
The kernel method is popularly used to estimate nonparametric functions . A typical kernel estimator of g0 based on y has the following form
ˆgn(x ) = x − yi bn
) .
K(
1 nbn n
Xi=1
( 3 ) where K(x ) is the kernel and bn the bandwidth . The choices of K and bn are crucial for ˆgn . When f ( y|x ) = f ( y − x ) , the mixture model is called the convolution model . For the convolution model , the properties of ˆgn have been well understood [ 7 ] .
Let φx(t ) , φf ( t ) and φy(t ) be the characteristic functions of g , f and h respectively . Because h(y ; G ) = R f ( y − x)g(x)dx , we have φx(t ) = φy(t)/φf ( t ) . Using the inverse 2π R exp{−itx} φy(t ) Fourier transform , g(x ) = 1 φf ( t ) dt . Based on y , φy(t ) can be approximated by its empirical characteristic j=1 exp{−ityj} . Introduce another function ˆφyn(t ) = 1 kernel function m(x ) with characteristic function φm(t ) satisfying some necessary conditions [ 7 ] . Then the kernel estimator of g0 is ˜gn(x ) = n n
1
2π Z exp{−itx}φm(bnt )
ˆφyn(t ) φf ( t ) dt =
1 n n
Xj=1
1 bn x − yj bn
) .
Kn(
( 4 )
2π R exp{−itx}φm(bnt)/φe(t)dt . ˜gn is a where Kn(x ) = 1 continuous density function and it converges to g as n → ∞ .
4 . COMPUTING ALGORITHMS
The calculation of ˜gn is relatively straightforward , but the calculation of ˆGn is not trivial . There exist two types of algorithms for computing ˆGn . The first type is based on P1 , P2 and other properties of ˆGn discussed in Section 3.1 and is called the gradient method . Due to limited space , readers are referred to [ 3 ] for a comprehensive review . This section focuses on discussing the second type , that is , the EM algorithm .
The EM algorithm is often used to calculate parametric MLEs when explicit solutions are not available . Although ˆGn is a nonparametric MLE , the EM algorithm can still be used because ˆGn is discrete with finite support points . The only difficulty is that the exact number of support points is unknown . Momentarily , we assume that it is known to be m . This issue will be further discussed later . Since ˆGn has m support points , we only need to consider all the discrete distributions with m support points in M . Let zm
Mm = {G ∈ M : G ∼ z1 q1
··· ··· z2 q2 qm } .
If G is restricted to Mm , then ( 1 ) becomes a finite mixj=1 qj f ( y|zj ) , and the likelihood ture model , h(y|G ) = m j=1 qj f ( yi|zj ) ] . Then i=1 log[ m function becomes l(G ) = n ˆGn = argmaxG∈Mm l(G ) . The standard EM algorithm for finite mixture models was developed a long time ago . It starts with an initial distribution , then alternates between an expectation step and a maximization step to update the estimates of zi and qi so that they converge to ˜xi and ˜qi , respectively . In the following , a pseudo code of the algorithm is given . For the derivation , readers can consult [ 12 ] . o j=1 qo j = 1 i=1 τij , j and qn j with zn n n j}1≤j≤m ; j f ( yi|z o j ) q h(yi|Go ) , j}m j=1 and {qo j f ( yi|zo j ) ; i=1 τij log f ( yi|z )
EM Algorithm : ( 1 ) Initialize Go with {zo ( 2 ) For 1 ≤ i ≤ n and 1 ≤ j ≤ m , calculate τij = where h(yi|Go ) = m ( 3 ) For 1 ≤ j ≤ m , update zj and qj : qn j = argmax z  n zn ( 4 ) Replace zo j and qo 1 ≤ j ≤ m and go to ( 2 ) . ( 5 ) Stop when some stopping criterion is met . For given f ( y|z ) , the maximization in the third step usually has explicit solutions , so the EM algorithm is a highly automatic procedure . One approach to overcoming the difficulty caused by an unknown m is to start with a small m . When the algorithm converges , one step of any gradient method is employed to add more points to the support and the EM algorithm is run again until it converges to ˆGn . The algorithm in [ 1 ] is a special case of the EM algorithm described above . j , respectively , for
5 .
INFORMATION VERSUS PRIVACY
Randomization is an economical and efficient approach for PPDM . However , there are also concerns . First , randomization can result in information loss or performance degradation in data mining . Second , the randomized data contain information about the original data , thus they may compromise individual privacy . 5.1 Performance Degradation and
Information Loss
If f ( y|x ) does not depend on x , then y contains no information about g0 , that is , Y and X are independent . This immediately fails any attempts to conduct data mining based on y . Some f ( y|x ) can cause the so called nonidentifiability problem in estimating g0 [ 11 ] . Therefore , great caution should be exercised to avoid using those randomization operators . The major concern over randomization is that it may reduce the accuracy of data mining . This is evident by comparing the performance of the estimators based on y and based on x . We use the kernel estimator as an example . Let gn(x ) be a kernel estimator based on x . Using the integrated mean squared errors ( IMSE ) as metric , the
− α
− α
α+β+1 ) or even to O(( log n )
α+1 ) , distance between gn and g0 is usually of order O(n where α depends on the smoothness of g0 . The accuracy of ˜gn , which is the kernel estimator based on y , can be re−γ ) , where α , duced to O(n β and γ are parameters related to the types and degrees of smoothness of g0 and f0 [ 8 , 7 ] . Hence , based on some prior knowledge about g0 , we need carefully choose f to avoid severe deterioration in accuracy . Due to limited space , we refer interested readers to [ 8 , 7 ] for details . For a given g0 , suppose F is a family of proper randomization operators . Intuitively , in order to guarantee the performance of data mining based y , we need select f to make y and x , or Y and X , as dependent as possible . And the mutual information I(X , Y ) is a natural measure of the depen dence . Based on ( 1 ) , I(X , Y ) =R f ( y|x)g0(x)logf ( y|x)dν(x ) dν(y ) − R h(y|G0)logh(y|G0)dν(x ) . It is known that 0 ≤ I(X , Y ) < +∞ with I(X , Y ) = 0 , when X and Y are independent , and I(X , Y ) = +∞ , when X = Y . For a specific data mining task , direct performance measures can also be derived , which are usually complicated . I(X , Y ) can act as a simple surrogate for these performance measures . In the literature , I(X , Y ) was proposed to be a privacy loss measure [ 1 ] . The reason why we use it as an information measure will be discussed in Section 521 and Section 523
2πτ
Example 3 . Suppose g0 follows N ( µ , σ2 ) . The randomization is to add noise drawn from N ( 0 , τ 2 ) to the original data . Then f ( y|x ) = 1√ 2τ 2 } , and Y follows exp {− ( y−x)2 N ( µ , σ2 + τ 2 ) . So I(X , Y ) = log 1 + σ2 τ 2 . Clearly , when τ 2 changes from 0 to +∞ , I(X , Y ) decreases from +∞ to 0 , where τ = 0 corresponds to revealing the original data . This implies that if no privacy constraints are imposed , the original data is the best . In PPDM , however , privacy constraints must be considered and guaranteed . Then a tradeoff between information and privacy need be carried out . 5.2 Individual Privacy and Its Protection
Privacy is the most important concept in PPDM , but its quantification turns out to be difficult . In this section , we define different levels of privacy and examine their connections to information . We emphasize that it is the individual privacy that we need to preserve in PPDM . Based on several privacy measures proposed in literature , we further define or develop metrics to quantify individual privacy in the context of density estimation .
521 Individual Privacy , Aggregate Privacy and
Information
Recall that the primary goal of PPDM is to share population information ( or aggregate information ) while protecting individual privacy . The individuality aspect of privacy has not been well emphasized in the literature . For a given population , privacy can be defined at different levels or scales . Let ’s consider a hypothetical example . Suppose we are interested in estimating the salary distribution of professors in a private university . Let X denote the amount of annual salary made by a professor . There exist at least three hierarchical levels for the privacy of salary , which are the individual , the departmental and the university levels . Because the individual level is related to every possible values of X , while the other two levels are related to collections of possible values of X , we refer to the former as individual privacy and the latter two as aggregate privacy . In PPDM , generally one can specify the level of privacy one need protect . In this paper , we assume we want to preserve individual privacy .
A close connection exists between privacy and information . Similarly , information can also be defined at various levels . At the same level , privacy and information could be regarded as the two sides of the same coin , because both of them are directly related to randomness and uncertainty . If this is true , sharing information must result in privacy loss , even when secure computing is employed . Then , we must ask how can PPDM be possible ? A careful examination concludes that the properties ( information ) we want to mine and the privacy we want to protect are usually at different levels . This is exactly how PPDM was defined at the first place , which is mining aggregate properties while protecting individual privacy . This definition can be generalized to mining properties at level i while protecting privacy at level j , where the levels should be well defined and j is usually lower than i . Although mining aggregate properties can still cause the decrease in individual privacy , individuals are willing to participate a data mining process because ( 1 ) the decreased privacy is above certain tolerable level and ( 2 ) the potential benefits can be huge relative to the small loss in privacy .
In summary , PPDM is possible because one can trade aggregate privacy for aggregate information while the individual privacy is maintained to be above some tolerance level . Next , we consider possible measures to quantify individual privacy .
522 Interval based privacy metric
The idea of using intervals to measure privacy was originally suggested in [ 2 ] . However , [ 1 ] criticized this approach and suggested information based measures instead . The counterexample in [ 1 ] was in fact not against the idea itself , it rather showed that the original definition was not enough and information regarding posterior distributions needs also to be taken into consideration . We modify the original definition and show that it is indeed a quite legitimate approach . Suppose X is a random variable with density g over Ω where g(x ) > 0 . For x ∈ Ω , we define its individual privacy at level α , denoted by Πα(x ) , to be min{µ((a , b ) ∩ Ω ) : x ∈ ( a , b ) and P ( X ∈ ( a , b ) ) ≥ α} , ( 5 ) where α ∈ ( 0 , 1 ) and µ is the Lebesgue measure . If Ω is the whole real line , the privacy of x is the width of the narrowest interval that contains x and has probability α .
Example 4 . Suppose X follows a uniform distribution over ( −a , a ) , that is , g(x ) = 1 2a I(−a,a)(x ) . Then for every x in ( −a , a ) , Πα(x ) = 2aα . Note that every x in ( −a , a ) has the same amount of privacy . Πα(x ) increases from 0 to 2a as α increases from 0 to 1 .
Example 5 . Suppose X follows N ( µ , σ2 ) . Define ξα to be Φ
2 ) . It can be shown that
−1( 1+α
Πα(x ) =fl 2σξα
|x − µ| − σΦ−1(Φ(
|x−µ|
σ
) − α ) if |x − µ| < σξα ; if |x − µ| ≥ σξα . ( 6 )
We introduce a function to characterize individual ’s privacy tolerance . Let t(α ) : [ 0 , 1 ] → ( 0 , +∞ ) be an nonnegative
If an individual has X = x and and increasing function . Πα(x ) ≥ t(α ) , then he/she is comfortable with his/her individual privacy at level α , otherwise , the individual will consider his/her privacy being breached . Individuals in a population are willing to reveal their population distribution , when their individual privacy can be above their tolerance , that is , Πα(x ) ≥ t(α ) for all x ∈ Ω and a given α .
In randomization , because the randomized data are revealed in addition to the data mining results , individual privacy will be further affected . For a give data x , we assume its randomized data is y . From ( 1 ) , the posterior distribution of X given Y = y is p(x|y ) = f ( y|x)g(x ) . Let Ωy be the support of p(x|y ) . For x ∈ Ωy , the privacy of x after PPDM , called the posterior privacy , is defined to be Πα(x|y ) = min{µ((a , b ) ∩ Ωy ) : x ∈ ( a , b ) and P ( X ∈ ( a , b)|y ) ≥ α} . ( 7 ) If there is a pair of data x and y such that Πα(x ) ≥ t(α ) and Πα(x|y ) < t(α ) , we claim that a privacy breach occurs at x . For a fixed x , the difference between its privacy and posterior privacy is h(y )
∆(x ) = Πα(x ) − Πα(x|y ) ,
( 8 ) which measures the impact of randomization on the privacy of x . Note that ∆(x ) is not necessary to be positive , because individual privacy can increase or decrease due to randomization .
Examples 3&5 ( Continued ) . Suppose we use a normal distribution with mean 0 and variance τ 2 as the randomizaexp {−(y − x)2/2τ 2} . The tion operator . So f ( y|x ) = 1√ posterior distribution p(x|y ) is also a normal distribution with mean
2πτ
˜µ =
τ 2
σ2 + τ 2 µ +
σ2
σ2 + τ 2 y
( 9 ) and variance ˜σ2 = σ α is
2
2
τ
σ2+τ 2 . So the posterior privacy at level
σ2+τ 2 ξα
|x − ˜µ| − ˜σΦ−1(Φ(
Πα(x|y ) = 2 σ2τ 2 −1( 1+α
|x− ˜µ|
˜σ
− α ) if |x − ˜µ| < ˜σξα ; if |x − ˜µ| ≥ ˜σξα , ( 10 ) where ξα = Φ 2 ) . Note that the minimum posterior privacy is 2˜σξα , which is less than the minimum prior privacy 2σ2ξα . But ∆(x ) can be positive or negative depends on the randomized data y . When τ goes to zero , the posterior privacy will go to zero and result in serious privacy breach . On the other hand , when τ goes to infinity , the posterior privacy converges to the prior privacy , that is , Πα(x|y ) → Πα(x ) for any x , y and α . In PPDM , a proper τ should be chosen between 0 and +∞ . 523 Entropy based privacy metric
Another type of privacy measure proposed in the literature is based on information theory . Again , we assume X is a random variable with density g over Ω . [ 1 ] defined the privacy of X to be h(X ) = − the differential entropy of X . Entropy was originally used to measure the randomness as well as the information of a random variable and it represents an aggregate property of X . We can have two random variables that have the same
R g(x ) log g(x)dν(x ) , which is entropy but are entirely different . So , h(X ) is not directly related to the values of X , thus is not a proper measure of individual privacy . In an extended version of this paper , we explore the possibility to “ individualize ” entropy and propose entropy based privacy measures . Interested readers can request the paper from the authors . 5.3 Optimal Randomization
In the previous sections , we discussed the impacts of randomization on data mining , eg , density estimation , and privacy protection , and proposed several metrics to quantify them . We argued that the success of PPDM hinges on the proper choice of randomization operators . Next , we define two types of problems for constructing optimal randomization . Suppose T is a data mining task . Let LDM(T ; f , g ; x , y ) be a measure of the discrepancy between the results of T based on y and x . The average discrepancy is defined to be LDM(T ; f , g ) = Ex,y(LDM(T ; f , g ; x , y) ) . For density estimation , the distances between the NPMLE ˆGn and the ordinary empirical distribution Gn , or between ˜gn and gn , can be used as LDM . When f is already restricted to be in a family F of proper distributions , we advocate to use some surrogate measures such as the mutual information for choosing optimal randomization operators , that is , let LDM = −I(X , Y ) . Let LPP(x;T , f , g ) denote the privacy of x after randomization and data mining . In density estimation , the worst possible posterior privacy of x can be used , which is LPP(x;T , f , g ) = minyΠα(x|y ) .
There are two types of problems in PPDM one need solve in order to choose optimal randomization operators . The first one is to maximize data mining performance under the constraint that posterior privacy for all x is above certain specified tolerance level ( CPP ) . The second is to maximize privacy protection under the constraint that data mining performance is guaranteed to be above certain satisfaction level ( CDM ) . These two types of problems are summarized below .
Problem 1 :
Minf∈F LDM(T ; f , g ) subject to LPP(x , f , g ) ≥ CPP for all x .
Problem 2 :
Maxf∈F LPP(x , f , g ) Subject to LDM(T , f , g ) ≤ CDM .
6 . SIMULATIONS
In this section , an example is used to show how to identify optimal randomization from a family of operators . Assume g0(x ) = 0.5I(0,1)(x ) + 0.25I(2,4)(x ) , and the family of operators is F = {N ( 0 , τ 2)} ∪ { λ 2 exp{−λ|z|}} . The randomized value y is obtained by adding noise z to x , where z follows f chosen from F . We will use the definition of optimality in Problem 1 of Section 5.3 only . ( 1 ) PP ( f , g ) = minyminx PP ( f , g ) = EY ( minxΠ(x|Y ) ) , which are the Π(x|y ) and L minimum lowest possible privacy and the average lowest(1 ) possible privacy , respectively . We calculated LDM , L PP and ( 2 ) L PP for normal and double exponential randomization operators with different variances and plotted them in Figure
Let LDM(T ; f , g ) = −I(X , Y ) . Let L
( 2 )
1 . The left is the plot of −LDM ( ie I(X , Y ) ) versus variance , in which the solid curve is for normal operators while the dot dashed curve for double exponential operators . The dot dashed curve is above the solid one consistently . This indicates that the double exponential operators caused less information loss . The right plot contains two pairs of curves . ( 2 ) PP ( f , g ) , in which the long dashed The pair on top is for L curve represents normal operators while the dotted curve represents double exponential operators . The long dashed curve is slightly above the dotted curve . This indicates that , on average , normal operators preserve slightly more ( 1 ) individual privacy . The pair at bottom is for L PP ( f , g ) , in which the dashed curve corresponds to double exponential operators while the two dashed curve corresponds to normal operators . The two dashed curve is quite flat . In fact , for ( 1 ) normal operators , L PP is always zero . It is positive in the plot because we computed it with y in a fixed finite interval . ( 1 ) Small L PP implies that when normal distributions are used , there always exists possibility of privacy breaches due to low posterior privacy . But the double exponential operators do not have such a drawback . One can show that there exists a positive lower bound for the posterior privacy when double exponential distributions are used . Based on Figure 1 , we conclude that double exponential operators outperformed normal operators and should be employed for randomization . The particular choice of variance 2/λ2 depends on the tolerance threshold CPP . For example , if we set CPP = 1.0 , then the variance should be larger than or equal to 225 Since the mutual information monotonically decreases with the variance increases , we should choose 2.25 as the optimal variance , so the optimal λ = 2/2.25 ≈ 09428 Hence , the optimal operator for this example is a double exponential distribution with λ = 9428 n o i t a m r o f n I l a u t u M
0 . 3
5 . 2
0 . 2
5 . 1
0 . 1
5 0
.
0 0
.
0 . 2
5 . 1
0 . 1
5 0
. l i
) 0 9 . 0 = a h p a ( y c a v i r p e b s s o p − t s e w o L l
0
1
2
3
4
0
1
2
3
4
Variance of noise
Variance of noise
Figure 1 : Mutual Information and Privacy Measures
7 . CONCLUSIONS
In this paper , a general framework based on mixture models is proposed for randomization in PPDM . We advocate the use of mutual information between the randomized and original data as a surrogate measure of the performance of PPDM and redefine the interval based privacy measure . Furthermore , two types of optimization problems are intro duced for the identification of optimal randomization operators .
8 . ACKNOWLEDGEMENT
Our thanks go to Professor Chris Clifton for many valu able discussions , help and encouragement .
9 . REFERENCES [ 1 ] D . Agrawal and C . Aggarwal . On the design and quantification of privacy preserving data mining algorithms . In Proceedings of the 20th ACM SIGACT SIGMOD SIGART Symposium on Principles of Database Systems , Santa Barbara , California , USA , May 21 23 2001 .
[ 2 ] R . Agrawal and R . Srikant . Privacy preserving data mining . In Proceedings of the 2000 ACM SIGMOD on Management of Data , pages 439–450 , Dallas , TX USA , May 15 18 2000 .
[ 3 ] D . Bohning . A review of reliable maximum likelihood algorithms for semiparametric mixture models . J . Statist . Plann . Inference , 47:5–28 , 1995 .
[ 4 ] The Economist . The end of Privacy . May , 1999 . [ 5 ] A . Evfimievski , J . E . Gehrke , and R . Srikant . Limiting privacy breaches in privacy preserving data mining . In Proceedings of the 22nd ACM SIGACT SIGMOD SIGART Symposium on Principles of Database Systems ( PODS 2003 ) , San Diego , CA , June 2003 .
[ 6 ] A . Evfimievski , R . Srikant , R . Agrawal , and
J . Gehrke . Privacy preserving mining of association rules . In Proceedings of 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , Edmonton , Alberta , Canada , July 2002 .
[ 7 ] J . Fan . Global behavior of deconvolution kernel estimates . Statistica Sinica , 1:541–551 , 1991 .
[ 8 ] J . Fan . On the optimal rates of convergence for nonparametric deconvolution problem . Annals of Statistics , pages 1257–1272 , 1991 .
[ 9 ] H . Kargupta , S . Datta , Q . Wang , and K . Sivakumar . On the privacy preserving properties of random data perturbation techniques . In Proceedings of the 3rd IEEE International Conference on Data Mining , pages 99–106 , Melbourne , Florida , November 19 22 2003 . [ 10 ] Y . Lindell and B . Pinkas . Privacy preserving data mining . In Advances in Cryptology Crypto2000 , Lecture Notes in Computer Science , volume 1880 , 2000 .
[ 11 ] BG Lindsay . Mixture Models : Theory , Geometry and Applications , NSF CBMS Regional Conference Series in Probability and Statistics , Vol . 5 . Alexandria , Virginia : Institute of Mathematical Statistics and the American Statistical Association , 1995 .
[ 12 ] R . A . Redner and H . F . Walker . Mixture densities , maximum likelihood and the EM algorithm . SIAM Review , 26(2):195–239 , 1984 .
[ 13 ] K . Thearling . Data mining and privacy : a conflict in making . DS,November 1998 .
[ 14 ] J . Vaidya and C . Clifton . Privacy preserving association rule mining in vertically partitioned data . In Proceedings of the 8th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , July 23 26 2002 .
