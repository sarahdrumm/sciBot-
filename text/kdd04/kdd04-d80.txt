Mining the Space of Graph Properties
Glen Jeh glenj@dbstanfordedu
Stanford University
Jennifer Widom widom@dbstanfordedu
Stanford University
Abstract
Existing data mining algorithms on graphs look for nodes satisfying specific properties , such as specific notions of structural similarity or specific measures of link based importance . While such analyses for predetermined properties can be effective in well understood domains , sometimes identifying an appropriate property for analysis can be a challenge , and focusing on a single property may neglect other important aspects of the data . In this paper , we develop a foundation for mining the properties themselves . We present a theoretical framework defining the space of graph properties , a variety of mining queries enabled by the framework , techniques to handle the enormous size of the query space , and an experimental system called F Miner that demonstrates the utility and feasibility of property mining .
1 Introduction Graph analyses have been used for a variety of applications to analyze interrelationships among entities . Some of these analyses concern standard graph theoretic properties , such as the radius of the graph or embedded cliques . Other analyses yield high level , subjective information about the data . For example , the web graph has been analyzed using the PageRank [ 16 ] and HITS [ 14 ] algorithms to identify web pages likely to be deemed “ important ” by the user . The citation structure of scientific papers has been analyzed to find papers related to a given paper [ 11 , 13 , 17 ] .
These techniques have in common that they analyze graph structures for predetermined properties . Although such analyses can be very effective , coming up with a good property for analysis is often a challenge , especially when little is known about the data to begin with . Moreover , by fixing specific properties for analysis , other important aspects of the data may be ignored . Therefore the space of properties itself should be explored .
As a concrete example , consider the simple case of looking for intuitively “ similar ” nodes in the graph of Figure 1 .
This work was supported by the National Science Foundation under grant IIS 9817799 and by a Junglee Stanford Graduate Fellowship .
Figure 1 : Graph example .
One possibility is to conclude that Prof1 and Prof2 are similar because they are both pointed to by Univ , as in the commonly used co citation metric [ 17 ] . Analogously , we may conclude that StudentB and StudentC are similar because they are both pointed to by Prof2 . On the other hand , we may argue that StudentA , StudentB , and StudentC are all similar because they are pointedto by a node that is pointed to by Univ , as in the recursive SimRank metric introduced in [ 11 ] . Each or all of these inferences may be valid , depending on the domain and application . However , current methods require the user to fix one measure of similarity ( eg , co citation or SimRank ) and query for nodes found to be similar under this measure . Ideally , we would like to query simply for “ similar ” nodes and get as a result the sets {Prof1 , Prof2} , {StudentB , StudentC} , and {StudentA , StudentB , StudentC} along with explanations for why they are similar . This functionality is not supported by any current system we know of . It is supported by F Miner , an implementation of the framework to be presented .
In this paper , we develop a framework for mining “ interesting ” or “ important ” graph properties . Essentially , we treat the space of properties as a domain and perform data mining on this domain . Our goal is to develop an appropriate analysis for mining the space of properties , just as analyses have been developed for mining the graph data itself . An obvious challenge is in handling the enormous size of the space of properties , in which even the simplest data mining operations seem hopelessly infeasible . We develop techniques that allow computational resources to be focused on only the most important properties , allowing us
1
StudentCProf1Prof2UnivStudentAStudentB Figure 2 : A logical diagram of the property mining framework , as seen by the user . to implement a practical mining system based on the framework .
The main contributions of this paper are : • A theoretical framework that defines the space of graph properties to be queried .
• Several specific data mining query types enabled by this framework , offering new capabilities not supported by existing systems .
• Techniques for dramatically reducing the computational resources required to answer queries within the framework .
• A simple and intuitive metric for calculating the “ im portance ” of properties .
• The F Miner experimental system , an implementation of the framework presented , demonstrating its utility and feasibility .
2 Framework for Property Mining
Before we can pose queries on the space of graph properties , we first have to define precisely what this space is .
1 . We begin with a labeled directed graph representing the objects and relationships in the domain we want to mine . Each edge represents a basic relationship between two objects .
2 . We encode properties as formulas in the syntax and semantics of Datalog . Each property ( formula ) is composed of the basic relationships ( predicates ) in the domain .
3 . We consider the set F of all formulas and their extents , the objects which satisfy the formula . Queries on the space of properties can be stated as queries on F .
A logical diagram of the framework , as seen by the user , is shown in Figure 2 . The property mining framework itself is enclosed in the dashed box . The framework enables querying on properties of the input data ( in our case a graph ) , from which a set of predicates representing basic relationships are derived . It is possible to derive predicates from sources other than graphs , such as the less than relationship in a numeric data set , but for concreteness we limit ourselves in this paper to discussing predicates corresponding to graph edges . The predicates form the basis of formulas , and the user ’s queries posed are on the set of all formulas and their extents F . Of course , F is only an abstraction provided to the user ; in most cases F would never materialized by an implementation . We define F formally in the next section .
2.1 The Query Space
Let G = ( V , E ) be a labeled directed graph , where E = V × V × L , for an arbitrary set L of strings serving as edge labels . For simplicity , we do not consider edge weights , although they can be added to the framework with slight modification . The fundamental relationships encoded in the edges are building blocks for the properties we will consider . In many domains there is an obvious canonical representation of the data as a graph , although in some domains the representation may require some consideration . As an example , consider the data shown in Figure 3 , which is a small fragment of a survey of members of the Stanford Database Group . The obvious representation of the data as a labeled graph is also shown in the figure . Many data types can readily be modeled as a graph , including data in relational and XML format .
The next step is to represent properties of the domain as formulas . We use formulas in the language of Datalog [ 19 ] , although arbitrary logic formulas , say of first order logic , are also possible . Clearly , the more powerful the logic , the greater the semantic and computational complexity of the system . Datalog has expressive power far beyond
2
Data SourcesGraph G ( other sourcesfrom whichpredicatescan be derived)p(a , b ) , q(a , b ) , r(a,b ) , etc.……{x1 , x2 , …}f(A ) : p(A , B ) & p(B,C)……{w1 , w2 , …}f(A ) : p(A , v1){u1 , u2 , …}f(A ) : p(A , B)ExtentsFormulasQuery TypesPredicatesSimilarityFrequent itemsetsFrequent substructuresAssociation rulesExplanations(other queries)Property Mining Framework Figure 3 : Sample data and its graph representation . what we can hope to support in practice . As we shall see , even the very restricted subset of Datalog that we use allows functionality well beyond what existing systems can support . We will define the syntax and semantics of our formula language as we go along .
The constants ( or objects ) of the logic are the nodes in G ( ie , objects of the domain ) , while predicates correspond to edges ( ie , relationships of the domain ) . We consider Datalog formulas f of the form : f(A ) :– p1(α1 , β1 ) & ··· & pk(αk , βk ) for k ≥ 1 , where pi ∈ L , A is the head variable , and each αi , βi is either a variable or a constant ( object ) . We use capital letters to denote variables , lowercase letters to denote constants , and Greek letters to denote either . Each predicate p(α , β ) corresponds to the existence of an edge with label p between its two arguments : predicate p(u , v ) , for u , v ∈ V , is true if and only if the edge hu , v , pi In the example of Figure 3 , the predicate exists in G . Food(Sriram , Indian ) is true . A formula f is satisfied by the satisfying assignment a , a function that maps variables to constants , if all the predicates in f are true when all variables X in f have been replaced by a(X ) . In a formula , at least one of the arguments of each predicate must be a variable , for otherwise the predicate would have a constant truth value . Two formulas that are identical except for variables names and predicate ordering are considered identical .
The most important aspect of a formula f is its extent , denoted E(f ) . It is the set of all objects v for which there exists a satisfying assignment a such that a(A ) = v ( recall that A is always the head variable ) . Intuitively , each formula specifies a “ property ” of the domain , and the extent of the formula is the set of objects which satisfy the property . For example , the formula f(A ) :– Advisor(B , A ) & Food(B , Chinese ) encodes the property of “ being the advisor of someone who likes Chinese food ” , and its extent is {Hector} . We define the set F = {(f , E(f))| f is a formula} of all formulas and their extents as the space in the context of which we pose our queries . A fragment of F is shown in Figure 2 as a relation . Of course , F is infinite , and is not meant to be computed . It serves only as the logical relation over which queries are posed .
2.2 Sample Query Types
There are many interesting data mining operations one can perform over F , and many common notions in data mining , such as the frequent itemsets computation [ 3 ] , have analogues in the space of formulas . Here are some examples : • Object similarity . Two or more objects can be considered similar if they satisfy “ many ” formulas in common . In contrast to previous approaches , now similarity can be computed based on multiple aspects ( as in the example of Section 1 ) , with the system automatically identifying the more “ important ” aspects ( Section 4 ) . Furthermore , similarity can be explained . Rather than simply returning a score , the formula(s ) which contributed to the score can be returned as an explanation of the results . Finally , “ find more ” queries can be supported . Given a set of objects U presumed to be similar in some ways , we can query for objects similar to objects in U in the same ways that objects in U are similar to one another . The objects returned are those which occur frequently in the formulas satisfied by members of U . These features are supported in the F Miner system ( Section 5 ) .
• Frequent itemsets . We can run a frequent itemsets computation on the set of all extents , identifying those sets U ⊆ V for which U is a subset of “ many ” extents . Each subset U represents a group of objects having “ a lot ” in common . For example , in the survey data to be discussed in Section 5 , the set of all professors may be a frequent itemset because they all have advisees and have written many papers .
• Frequent substructures . Many graph structures correspond to formulas , and vice versa . We can find fre
3
HomeIndiaDigital LibrariesMexicoFacultyPhD StudentThaiChineseIndianFoodResearchFoodFoodAdvisorSriramHectorPositionHomePositionFood quent substructures in the graph by finding formulas which have large extents . For example , the formula f(A ) :– e(A , B ) & e(B , C ) & e(C , D ) corresponds to a path of length 3 ( with edge labels e ) . If the extent of f is large , the graph contains many paths of length 3 .
• Association rules . We can look for association rules of the form f =⇒ g , where f and g are formulas whose extents have “ a lot ” of overlap . The rule says that objects which satisfy f also satisfy g , or at least with a high probability .
• Explanations . Given a set of objects U , we can “ explain ” what the objects in U have in common with one another by considering the formulas they satisfy in common . This functionality is demonstrated in FMiner ( Section 5 ) .
These are but some examples of the kinds of queries that can be posed on F . We use the examples as motivation for some of the techniques we develop , but it is important to remember that these queries are end applications of the framework , which itself consists only of the logical relation F . Other queries are possible in the framework and some may be more application specific . In contrast to traditional data mining , the queries here generally focus on the properties themselves , rather than the objects which satisfy the properties .
As a reminder , it is not possible ( nor necessary ) to materialize F in order to query it . Rather , once a specific application has been determined ( eg , finding similar objects ) , we can solve the end to end problem without explicitly constructing F .
2.3 Challenges
There are two major technical challenges to answering queries within our framework . The first is in dealing with the enormous size of the query space . We develop techniques to handle this problem in Section 3 . The second challenge is in determining the “ importance ” of formulas . This is a major component of property mining : just as we look for important ( interesting ) objects in traditional data mining , here we look for important properties . Moreover , identifying important formulas is intertwined with reducing the space considered , since we would like as much as possible to restrict ourselves to considering only the most important formulas . Computing importance of formulas is discussed in Section 4 .
3 Building Blocks Approach The query space F is infinite , and it is impossible to consider all formulas in F . Instead , we want to focus as much
Figure 4 : Graph example . of our computational resources as possible on the most important formulas . This poses a dilemma , since one of the goals of our mining is to identify these important formulas! At a high level , our solution is to construct formulas from basic building blocks called pseudopredicates . We analyze these building blocks for importance instead of analyzing the actual formulas . This allows us to determine the importance of the formulas that can be constructed from the building blocks , so that only the most important formulas are ever created . Hence much of the mining actually takes place in the space of pseudopredicates . Our approach can be broken into 3 steps :
1 . A set of pseudopredicates is computed to serve as ba sic building blocks for formulas .
2 . Importance scores are computed for the pseudopredicates , identifying those from which important formulas can be constructed .
3 . Important formulas are constructed from the pseudo predicates .
In this section we present steps ( 1 ) and ( 3 ) . Step ( 2 ) is presented in Section 4 .
3.1 Example
We motivate our approach using an example . Consider the top half of the structure shown in Figure 4 , a hypothetical fragment of the web graph . The web pages u1 , . . . , uk all point to Yahoo Sports , so they satisfy the formula f(A ) :– e(A , Yahoo Sports )
( 1 ) where e is taken to be the label of every edge in the ( unlabeled ) graph . Yahoo Sports in turn points to baseball ’s MLB.com , so Yahoo Sports satisfies the formula g(A ) :– e(A , MLB.com )
Finally , u1 , . . . , uk all satisfy h(A ) :– e(A , B ) & e(B , MLB.com )
( 2 )
( 3 )
It seems redundant to record this fact , however , since it follows immediately from the facts that ui , for all 1 ≤ i ≤ k ,
4 uuvvYahoo SportsMLBcomESPNcom1mk1 satisfies formula ( 1 ) and that Yahoo Sports satisfies formula ( 2 ) . More generally , for any formula g satisfied by Yahoo Sports , each ui points to a node that satisfies g . That is , ui satisfies the formula h(A ) :– e(A , B ) & g(B ) where g(B ) is g with head variable A replaced by a variable B not appearing already in g.1
Now we consider the entire Figure 4 , where v1 , . . . , vm all point to the sports site ESPNcom Since ESPN.com points to MLB.com , u1 , . . . , uk and v1 , . . . , vm are all related by their common satisfaction of formula ( 3 ) , a consequence of the fact that the ui ’s and vj ’s all point to either Yahoo Sports or ESPNcom We record this by saying that ui ’s and vj ’s satisfy the pseudoformula f(A ) :– e(A,{Yahoo Sports , MLB.com} )
3.2 Pseudopredicates and Pseudoformulas
A pseudopredicate is a predicate that may have as an argument a nonempty set of objects , as well as variables . It is a generalization of a regular predicate , which can be thought of as the special case when the only set arguments of a pseudopredicate are singleton sets . We have already seen one example of a pseudopredicate in Section 3.1 , e(A,{Yahoo Sports , ESPN.com} ) , which represents the property of pointing to either Yahoo Sports or ESPNcom We define a pseudoformula as a formula consisting of pseudopredicates , and define the extent of a pseudoformula f as the set of objects v for which there exists a satisfying assignment a for f such that a(A ) = v , where a assigns each set argument to one of its members . For example , the extent of the pseudoformula f(A ) :– ( A,{Yahoo Sports , ESPN.com} ) is {u1 , . . . , uk , v1 , . . . , vm} .
Note that the set of formulas can be thought of as a subset of the set of pseudoformulas , since we can replace each constant argument v by {v} to get a pseudoformula having the same semantics . Conversely , some pseudoformulas can be converted to formulas : if all set arguments of a pseudoformula f are either singleton sets or the set of all objects V , then f has the same semantics as the formula f0 which is a copy of f except with singleton objects replaced by their sole members , and each set argument V replaced by a dangling variable not appearing anywhere else in f0 .
3.3 Chaining Pseudoformulas We take the set of basic building blocks to be ( P , E(P) ) , the set of all head pseudopredicates P and their extents E(P ) .
1Technically , we do not allow formulas within formulas , so g ’s predicates must be substituted explicitly into h with appropriate variable renaming .
A head pseudopredicate is a pseudopredicate whose two arguments are the head variable A and a set argument S ⊆ V . These pseudopredicates can be treated as 1 predicate pseudoformulas . In the coming sections , we will talk about extents of head pseudopredicates as though they were 1predicate pseudoformulas , and omit the “ head ” qualification when the meaning is clear .
From this base set of head pseudopredicates we can compose a large class of more complex pseudoformulas and thus formulas , which as noted before are a subset of pseudoformulas . The two composition steps are conjoining and chaining .
Conjoining two formulas f and g creates a new formula h whose predicates are a conjunction of the predicates in f and g , with appropriate renaming of non head variables to avoid conflict .
Chaining is a formalization of the process of deriving formula h from f and g in Section 31 Suppose we have a 1 predicate pseudoformula f(A ) :– p(A , S ) . Then for any pseudoformula g whose extent is a superset of S , any object satisfying f also satisfies the pseudoformula h(A ) :– p(A , B ) & g(B ) . We say that h is the result of chaining f and g . In the general case , if S appears as a set argument in f , and S ⊆ E(gi ) for some formulas g1 , . . . , gk , then we can derive a new formula h by chaining f with g1 , . . . , gk on S , as follows :
1 . Let h be f with S replaced by a new variable X not appearing in f .
2 . For i = 1 . . . k , append to h all predicates of gi , with non head variables in gi renamed so as not to conflict with those already appearing in h , and with head variable A in gi renamed to X .
The resulting h has an extent E(h ) which is a superset of E(f ) . If S = E(gi ) for all 1 ≤ i ≤ k , then E(h ) = E(f ) . A key concept here is that an object set S ⊆ V , when it occurs as a set argument in a pseudoformula , represents the set of pseudoformulas satisfied by all members of S . Pseudoformulas ( and formulas ) are thus partitioned into classes according to their extents . In computation , we deal with the set of object sets ( seen as both extents and setarguments ) , with each object set representing a class of formulas . There are 2n such sets , which although large is at least finite .
Through chaining and conjoining , the base set of pseudopredicates P can be used to construct more complex pseudoformulas and formulas . For a formula f , let G(f ) be the undirected , unlabeled graph corresponding to f :
• The nodes of G are the variables and constants appearing in f , except that all instances of a constant in f are treated as different nodes .
• For every predicate p(α , β ) in f there is a corresponding edge between α and β in G , so that p1(A , X ) and p2(A , X ) would yield two edges between A and X .
5
Then we can state the following theorem about the formulas that can be constructed .
Theorem . If G(f ) is a tree , then f can be constructed by chaining and conjoining pseudoformulas , starting from P .
The theorem says that we can construct all formulas corresponding to tree structures . A stronger version of this theorem is stated and proven in Section 34
3.4 Computing a Working Subset of P The set P has size O(2n|L| ) , which , although much smaller than that of the set of all formulas ( which is infinite ) , is still enormous . In practice , we have to restrict ourselves to using only a subset of P , at the cost of restricting the set of formulas that can be constructed . Ideally , we would use only the most important pseudopredicates as building blocks , from which the most important formulas can be constructed . But we cannot tell which pseudopredicates are important in advance , so we start with an initial set of pseudopredicates P1 as seed , then iteratively expand ( or refine ) the set of pseudopredicates included . We maintain a series of head pseudopredicates and their extents ( Pi , E(Pi) ) , for i ≥ 1 . Each Pi is the set of pseudopredicates created on iteration i . We compute ( Pi+1 , E(Pi+1 ) ) from ( Pi , E(Pi ) ) on each iteration i + 1 , and after k − 1 iterations take their unions :
Pk = [ E(Pk ) = [
1≤i≤k
Pi
E(Pi )
1≤i≤k as the working ( trimmed ) set of basic building blocks .
We take P1 to be the set of all head pseudopredicates whose set argument is a singleton set or the set of all objects . On each iteration , we consider the extents of the pseudopredicates already created , as well as the extents’ intersections , and create new pseudopredicates having these sets as set arguments . More precisely , given that we have ( Pi , E(Pi) ) , we perform the following steps on iteration i + 1 to get ( Pi+1 , E(Pi+1) ) :
• Compute I , the intersection closure of E(Pi ) ( ie , the smallest set such that E(Pi ) ⊆ I and S1 ∩ S2 ∈ I for all S1 , S2 ∈ I ) .
• Compute Pi+1 as :
Pi+1 = {p(A , S)| p ∈ L , S ∈ I}
∪ {p(S , A)| p ∈ L , S ∈ I}
Each successive iteration considers formulas corresponding to trees one level deeper . This idea is formalized by the following theorem .
Theorem . A formula f whose corresponding graph G(f ) is a tree of depth at most k from A can be constructed by chaining and conjoining pseudoformulas starting from Pk . Note that the sole formula with a G(f ) depth of 0 is the trivial formula f(A ) :– p(A , A ) , which we do not consider .
Proof . The proof is by induction on the depth of G(f ) . As the base case , the set of formulas with depth 1 is exactly the base set P1 = P1 . Now assume that the theorem is true for some k ≥ 1 , and suppose that G(f ) is a tree of depth k + 1 starting from A . Each child of A is the root of a subtree Ti having depth at most k . Consider those subtrees Ti that have depth at least 1 ( ie , not constants and dangling variables ) . By the inductive hypothesis , the formula gi corresponding to each subtree Ti can be constructed from Pk , after we rename the root variable of each subtree ( and other instances in the subtree ) to A ( note that A cannot appear in the subtree already since G(f ) is acyclic ) . Then for each head predicate p(A , α ) of gi ( and analogously for p(α , A) ) , there must be a predicate p(A , α0 ) in Pk , where either
• α is a constant , α0 argument ) , and α = α0 , or is a constant ( singleton set
• α is a variable and α0 is a variable or set argument i E(pi ) ⊆ T tion of their extents be S = T and in either case E(p(A , α0 ) ) ⊆ E(p(A , α ) ) ⊆ E(gi ) . Let these predicates in Pk be p1 , . . . , pm , and let the interseci E(gi ) . Since S ∈ I on iteration k + 1 , all head predicates with setargument S are in Pi+1 and thus Pi+1 . Let f0 be the formula which has , for each head predicate p(A , α ) in f ( and analogously for predicates p(α , A) ) , a head predicate of the form :
• p(A , α ) if α is a constant or dangling variable • p(A , S ) if α is a variable which is the root of some subtree Ti
Then f0 can be constructed by conjoining predicates in Pi+1 , and f is the chain of f0 and g1 , . . . , gk on setargument S .
It follows immediately from the theorem that in the limit where k = ∞ , all formulas corresponding to tree structures can be constructed from P∞ ( and hence P , a superset of P∞ ) , which proves the weaker version of the theorem stated in Section 33
The larger the k , the more formulas can be constructed , at the cost of using more computational resources . In the F Miner system , we found that k = 3 accounts for a wide range of interesting formulas while having very manageable resource requirements ( Section 5 ) .
There are many ways the set Pk can be further pruned or tailored for the class of formulas suitable for a specific
6 application . First , instead of taking I to be the intersectionclosure of E(Pi ) in the iterative step i + 1 , we can simply take I to be E(Pi ) , or take I to be the ( first level ) intersection of elements of E(Pi ) . Thus conjunctions of pseudoformulas are only formed when their extents are equal . Second , those pseudopredicates in Pk and those sets in E(Pk ) deemed unimportant ( Section 4 ) can be pruned away after each iteration . By keeping only the most important pseudopredicates and their extents , the size of ( Pk , E(Pk ) ) can be kept constant with k , while allowing important formulas corresponding to deep tree structures to be considered .
4 Computing Importance
In Section 3 we established a set of head pseudopredicates and their extents ( P , E(P ) ) as building blocks for formulas . Formulas can be constructed from P through conjoining and chaining . Because P is usually extremely large , we showed how to iteratively compute a manageable subset Pk of P .
The next step is to construct important formulas from Pk . We first analyze ( Pk , E(Pk ) ) as to the importance of the formulas that can be constructed . The problem of computing importance on formulas becomes that of computing importance on sets ( representing classes of formulas satisfied by these sets ) and pseudopredicates . Just as in traditional data mining we look for interesting objects satisfying some predefined property , we now mine the space of properties for interesting properties satisfying some predefined notion.2 Accordingly , the development of a good measure of importance for properties is fairly ad hoc , although we try as much as possible to develop upon known principles .
4.1 Ranking Head Pseudopredicates and Sets
We start with some fundamental notions of importance for head pseudopredicates ( simply “ predicates ” in the rest of this section ) , and then let the analysis compute importance based on these notions . We borrow a technique from the field of web search . The PageRank [ 16 ] and HITS [ 14 ] algorithms have been used to analyze web pages for importance to aid in web search . The idea behind PageRank is that a web page is important if it is pointed to by important web pages . Similarly , the HITS algorithm identifies good hub pages and good authority pages recursively : good hubs are those which point to good authorities , and good authorities are those pointed to by good hubs . Good authorities are regarded as important pages . Common to these two algorithms is their recursive , mutually reinforcing definition
2Now we might mine the space of notions on properties to identify the important notions , but obviously this just pushes the same problem up a level . Instead , we settle for mining the space of properties using some predefined notions . Note this does not mean that we are back to where we started , since we can now mine for ( first level ) properties instead of just atomic objects . Extension to mining higher level properties ( ie , properties of properties ) is a possible direction for future work . of importance , and the iterative computation method ( corresponding to an eigenvector computation ) .
In the same spirit , we develop an iterative algorithm for ranking the importance of sets and pseudopredicates . And analogous to the definition of hubs and authorities in HITS , we say that :
• A pseudopredicate is important if its set argument is important .
• A set is important if it satisfies important pseudopred icates .
Thus , the basic notions from which we derive importance are satisfaction of pseudopredicates ( for sets ) , and importance of the set argument ( for pseudopredicates ) .
To compute importance scores , this intuition must be formalized mathematically . We take importance scores to be in the interval [ 0 , 1 ] , with importance scores for all pseudopredicates summing to 1 , and importance scores for all extents of pseudopredicates summing to 1 . For S ⊆ Pk , we define Pk(S ) to be the set of predicates satisfied by S :
Pk(S ) = {p ∈ Pk | S ⊆ E(p)}
As a basis , we start with the core equations
I(p ) = I(arg(p ) ) for predicates , which says that the importance I(p ) of a predicate p is the importance of its set argument arg(p ) , and
|E(Pk)| + ( 1 − c ) X c
I(S ) =
I(p ) p∈Pk(S ) which says that the importance of a set S has two components : ( 1 ) a small inherent importance |E(Pk)| ( in our experiments we used c = 0.2 ) , and ( 2 ) the sum of the importances of the predicates p satisfied by S . This equation is analogous to that used for PageRank [ 16 ] . c
These two core equations provide a good starting point in capturing the recursive intuition presented , but more specific details of the analysis should be incorporated .
First , instead of summing over the set of all predicates p satisfied by S , we should sum only over those that are not subsumed by another predicate satisfied by S . We say that a pseudopredicate p(A , S ) subsumes another pseudopredicate p(A , S0 ) if S ⊆ S0 , in which case E(p(A , S ) ) ⊆ E(p(A , S0) ) . Intuitively , p(A , S ) specifies a property more specific than that specified by p(A , S0 ) . For example , in Figure 4 , if we already know that v1 satisfies e(A , ESPN.com ) , it is pointless to also record that v1 satisfies e(A,{Yahoo Sports , ESPNcom} ) Another aspect that can be improved is when S ⊆ E(p ) , but S is only a small fraction of the objects in E(p ) . Then p ’s contribution to I(S ) should be weighed lower than to
7
I(S0 ) , where S0 = E(p ) . For example , in Figure 4 , we have
E(e(A , ESPN.com ) ) = {v1 , . . . , vm} so e(A , ESPN.com ) ’s contribution to the importance of a set S = {v1 , v2} should be smaller than to that of S0 = {v1 , v2 , v3 , v4} . Thus we consider the term w1(|S|,|E(p)| )
P S0∈Pk(S0 ) w1(|S0|,|E(p)| )
δ(S , p ) = which assigns weights according to the relative sizes of S and E(p ) , as compared with other sets S0 satisfying p . For both data sets in our experiments we used w1(x , y ) = y ) 1 ( x 3 , which we found to work well empirically . We may also attribute more importance to those sets that satisfy many pseudopredicates independently of the importance of the pseudopredicates . Let
σ(S ) = w2(|Pk(S)| ) be the number of predicates satisfied by S , weighted by a function w2(x ) . In our experiments , we found w2(x ) = x
1 10 to work well empirically . The equations we used in our experiments for scoring predicates and sets are :
( 4 )
( 5 ) p∈Pk(S )
δ(S , p)I(p )
I(p ) = I(arg(p ) ) I(S ) = c
|E| + ( 1 − c)σ(S ) X tion , the scores are normalized so that P P
As with the HITS equations , equations ( 4 ) and ( 5 ) can be solved by iterating to a fixed point . On each iterap I(p ) = 1 and S I(S ) = 1 . For equation ( 5 ) , the set Pk(S ) must be precomputed for each S , which in general is an expensive operation . One way to alleviate the problem is to approximate w1(|S|,|E(p)| ) as 0 when it is below a certain threshold t , in which case we do not check whether S ⊆ E(p ) at all . In our experiments , we used t = 0.01 , which sped up the computation with no noticeable effect on quality of results .
Note that an appropriate choice of equations is in general dependent on the data set and query type . However , we have found the above equations to work well on the two data sets and two query types we tried . Also note that inherent importances can be assigned nonuniformly to bias the results when there are sets we know apriori to be important . This is analogous to biasing web pages nonuniformly in PageRank to enable a personalized web search [ 9 , 12 ] .
4.2 Selective Construction of Pseudopredicates
The importance rankings for the base set of pseudopredicates and their extents ( Pk , E(Pk ) ) tell us the importance of the formulas that can be constructed . Using the chaining procedure as described in Section 3.3 , it is straightforward
8 to construct formulas from Pk . However , many queries , such as those in Section 2.2 , are computed based on the importance scores of the extents , while the actual formulas serve only as an explanation to the user . Thus an exhaustive construction of all constructable formulas is usually not necessary ( nor feasible ) . Instead , we want to construct only the most appropriate formulas , taking into account not only the computed importance of the formulas but such human aspects as the formulas’ brevity , comprehensibility , and variety . Here we present the chaining operation from Section 3.3 as a procedure that allows us to take these factors into account . We define the function chain(f ) , which takes a pseudoformula f as argument and returns the result f0 of chaining f with some pseudopredicates . The result is a pseudoformula whose graph G(f0 ) is one level deeper than f : 1 . Start off with f0 set equal to f .
2 . For each pseudopredicate ( not just head pseudopredi cates ) p in f0 having a non singleton set argument : ( a ) Let S be the set argument of p , and let P ( S ) ⊆ Pk(S ) be a set of pseudopredicates satisfied by S .
( b ) Replace S in p by a new variable X not appear ing anywhere in f0 .
( c ) For each p0 ∈ P ( S ) , append p0 to f0 with head variable A of p0 replaced by X .
3 . Return f0 .
Each call to chain results in a more complex formula . In theory , we could chain some formulas indefinitely , since the same set may be chained over and over again in a cycle . In practice , users will want formulas to be simple , so a maximum depth or cycle detection stopping criterion will be used anyway .
As an example , consider the pseudoformula f(A ) :– Home({Glen , Beverly} , A ) which represents the property of “ being the home of Glen or Beverly ” . If Glen and Beverly both like either Chinese or Indian food , then the formula may be expanded ( through one call to chain ) to f(A ) :– Home(B , A )
& Food(B,{Chinese , Indian} ) which represents the property of “ being the home of someone who likes Chinese or Indian food ” . Finally , this formula may be expanded to f(A ) :– Home(B , A ) & Food(B , C )
& Food(Jennifer , C )
Formulas satisfied :
4.72 : f(A ) : Position(A , MS Student ) 2.08 : f(A ) : Advisor(A , Jennifer )
Most similar objects :
Formulas satisfied :
11.6 : f(A ) : Undergrad(A , Stanford ) 7.72 : f(A ) : Home(A , California )
Most similar objects :
[ input ] : 79.5 Jing : 20.2 Glen : 13.8 Chris : 13.5 Beverly : 13.4 Brian : 10.1
[ input ] : 107 John : 72.4 Brian : 66.2 Jing : 65.9 Glen : 60.5 Wang : 59.9
Figure 5 : Results for query “ Steve ” .
Figure 6 : Results for “ Steve , Beverly ” . if Jennifer likes Chinese and Indian food .
The function P ( S ) can be adjusted to suit the specific query types and end application . As a general rule , it should consist of the m most important pseudopredicates satisfied by S . Most of the variability is in choosing m properly so as to produce informative formulas while minimizing complexity for the sake of user intelligibility . Specific rules for choosing m in the F Miner system are discussed in Section 5 .
5 The F Miner Experimental System Based on the framework and algorithms presented in the previous sections , we have implemented an experimental system , F Miner , that supports some of the data mining queries discussed in Section 22 Specifically , F Miner supports the following two query types on arbitrary input graphs :
• Similarity . Given a set of input objects , return a ranked list of objects similar to members of that set in the same ways the objects in the set are similar to one another . For example , given two professors in the research group data described below , F Miner returns a third professor .
• Explanation . Given a set of input objects , return formulas “ explaining ” what the objects have in common . This function can be used to explain the answers returned in the similarity queries .
For efficiency , the user may assign types to each object to minimize redundant comparisons by the system . For example , a university would never be considered as an argument to an Advisor predicate between two people . Types help to speed up the implementation without having any effect on semantics .
The exact parameters used in F Miner are given in Sec tion 53
5.1 First Data Set : Database Group Survey
We ran F Miner on two data sets . The first is based on a survey of Stanford University ’s Database Group , along with publication data from the Database Group ’s publication server [ 1 ] . The data is modeled as a graph where nodes represent all entities that participate in relationships , such as people , food types , and publications . The edges represent relationships , including those that denote food preferences , advisors , undergraduate institution , home country , research interests , and authorship for publications . The graph consists of 1725 nodes and 3552 edges .
When the system is first run , the set of basic building blocks ( Pk , E(Pk ) ) is precomputed as described in Section 34 A prompt is then presented to the user where a list of objects can be entered as a query for both similarity and explanation . The precomputation takes less than a minute , and each query returns in milliseconds .
We begin with a simple single object query for “ Steve ” . The results of the query are shown in Figure 5 . Scores in the query results for this data set have been scaled by 106 for legibility . The top portion of the output shows the most important formulas ( as determined by the system ) satisfied by the input . We find that Steve is a Masters student , and that his advisor is Jennifer . We chose to list these as separate formulas , although they can be printed as a single conjunctive formula instead . Among the properties satisfied by Steve , including the foods he likes and where he went as an undergrad , these two are found to be the most important by the algorithm . The importance scores are listed next to the formulas . The bottom portion of the output lists the 5 objects most similar to Steve , along with their similarity scores . The similarity score s(x ) for an object x is the weighted sum of the importance scores of the extents satisfied by both x and Steve : w1(2,|E|)I(E ) s(x ) = X
E∈E(Pk ) Steve,x∈E where w1 is the same weighting function used in Section 41 The self similarity s(Steve ) is given as a reference ( listed as [ input ] ) for comparison . In effect , the program finds those people who have “ a lot ” in common with Steve , taking into account the numerous properties they may share . The top match is Jing , whom we know to be the only other Masters student in the group . The following are two of Jennifer ’s other students . The next match , Beverly , is neither a Masters student nor Jennifer ’s student .
To find out why Beverly is listed , we can type in “ Steve , Beverly ” as a new query . The results are
9
Formulas satisfied :
3.89 : f(A ) : Undergrad(A , B )
& Undergrad(C , B ) & Advisor(C , Jeff )
1.67 : f(A ) : Undergrad(A,B )
Formulas satisfied :
0.182 : f(A ) : Gender(A , Male ) 0.169 : f(A ) : Knows(A , B ) & Knows(B , user 178 )
& Knows(user 178 , B )
& Undergrad(C , B ) & Advisor(C , Hector )
0.152 : f(A ) : Knows(B , A ) & Knows(B , user 898 )
Most similar objects :
Most similar objects :
[ input ] : 34.0 Chris : 32.0 Taher : 29.1 John : 26.0 Wang : 26.0 Calvin : 25.4
Figure 7 : Results for “ Glen , Qi ” .
Formulas satisifed :
148 : f(A ) : Undergrad(B , A )
& Home(B , California )
Most similar objects :
[ input ] : 543 Cal Poly : 223 IIT Madras : 217 MIT : 153 IIT Bombay : 137 University of Colorado : 137
Figure 8 : Results for “ UC Berkeley , Stanford ” . shown in Figure 6 . We find that Beverly and Steve both went to Stanford as undergrads and are from California originally . Note that these attributes were not regarded by the program to be Steve ’s most important attributes , but they are the most important of those attributes he shares with Beverly . Appropriately , the top matches returned are other students who went to Stanford as undergrads , followed by other students from California .
The next example illustrates more complex formulas for the query “ Glen , Qi ” . The results are in Figure 7 . Comparing the absolute magnitudes of the formula scores with those for the query “ Steve , Beverly ” , we see that there is relatively little in common between Glen and Qi . The first formula says that the two people both went to schools that Jeff ’s students tend to go as undergrads . The second formula is analogous . The two students do not share advisors or other preferences , and these formulas are the best connection between them .
Of course , we can also query on objects other than people . The query results for “ UC Berkeley , Stanford ” are shown in Figure 8 . The formula identifies these as schools that tend to be attended by people from California . This is indeed the most intuitive result that can be inferred from the data.3 user 2244 : 21.8 user 500 : 21.8 user 297 : 21.7 user 1081 : 21.7 user 2353 : 21.7
Figure 9 : Results for “ user 8 , user 9 , user 10 ” .
Formulas satisifed :
0.102 : f(A ) : Academic(A , Undergrad ) 0.101 : f(A ) : Knows(B , A )
& Major(B , International Relations )
Most similar objects :
[ input ] : 6.45 user 1503 : 6.41 user 188 : 6.41 user 1854 : 6.41 user 304 : 6.40 user 1735 : 6.40
Figure 10 : user 178 ” .
Results for
“ user 7 , user 98 ,
5.2 Second Data Set : Club Nexus
To test F Miner on a larger data set , we used data from Club Nexus [ 2 ] , which contains extensive personal information about 2469 Stanford students . Attributes used include the student ’s academic standing , major , and a list of Club Nexus members he knows . The data is modeled in FMiner analogously to the Database Group survey data . The resulting graph has 2852 nodes and 74197 edges . The precomputation step , which needs to be done only once , takes about 3 hours , and each query at the prompt takes about 2 seconds . ( Note that our system has not yet been optimized or tuned for scalability . ) Sample results for the random queries “ user 8 , user 9 , user 10 ” and “ user 7 , user 98 , user 178 ” are shown in Figure 9 and Figure 10 , respectively . Scores in the query results for this data set have been scaled by 1010 for legibility .
The results in Figure 9 say that the input students are related because they are all males , they all know someone who knows and is known by user 178 , and they all know someone who knows user 898 . The results in Figure 10 say that the students are related because they are all undergraduates and are known by a person who majors in international relations . These kinds of connections are found by the system for most random groups of people .
3Note that the Undergrad , Home , and Advisor relationships tend to be favored over , say , Food because each person has a unique choice for these attributes , whereas he usually has multiple food preferences . This is an effect of the δ function ( Section 4.1 ) , which causes a preference for a particular food to be deemphasized when the person has other food preferences .
10
5.3
Implementation Details
Our experiments were run on a 2.4GHz Pentium with 1GB of RAM using Java SDK 141 The code is written entirely in Java , unoptimized and without native methods . The core of the F Miner system is implemented based on the techniques presented in the previous sections . The same parameter settings were used for both data sets . We used k = 3 when deriving the basic building blocks ( Pk , E(Pk) ) , and ranked pseudopredicates using 10 steps of the fixedIn computing E(Pk+1 ) , we used point iteration process . I = E(Pk ) , omitting the intersection step for speed , and found this to have little effect on the results ( conjunctions were already accounted for ) .
A proper setting of m for P ( S ) , as discussed in Section 4.2 , is largely a user interface issue . We have developed a heuristic to determine m . Let pi ( i = 1 , 2 , . . . ) be the ith ranked predicate in order of decreasing importance . We take m to be the minimum of 10 and :
• The smallest i such thatX
I(pj ) ≥ 10 ∗ pi
1≤j<i
( ie , when pseudopredicates are trivial compared to those already included ) .
• The smallest i such thatX
I(pj ) ≥ 0.9 ∗X
1≤j≤i
I(pj )
1≤j
( ie , when at least 90 % of the pseudopredicates have been accounted for ) .
We have found this heuristic to work well in most cases , providing the results illustrated in the previous figures .
6 Related Work Much of the existing work on mining graph data , eg [ 10 , 15 , 20 ] , extends the traditional data mining problem of finding frequent itemsets in market basket data [ 3 ] . The focus in graphs is on finding frequent substructures , the graph equivalent of frequent itemsets . The focus of our work is on finding interesting properties in graphs , of which a substructure ’s frequency of occurrence is but one example . In fact , one of the mining queries supported by our framework ( Section 2.2 ) is an instance of the frequent substructures problem .
Other instances of property mining have been studied in specific contexts . One is the problem of identifying “ patterns and relations ” in the unstructured text of web pages , eg , [ 5 , 18 ] . Patterns are essentially regular expressions and correspond to the formulas of this paper ; relations correspond to extents . The sets of patterns and relations are expanded iteratively starting from a small initial set of known
11 relations . The process can be seen roughly as an extension of the frequent itemsets problem in our framework : frequent itemsets are used to discover additional frequent itemsets .
In [ 6 , 7 ] , the traditional association rules of market basket analysis are generalized to association rules on Prolog formulas ( similar to our Datalog queries ) evaluated on a relational database . The goal is to find association rules of the form f =⇒ g where f and g are formulas . As discussed in Section 2.2 , this type of association rule mining can be formulated as a query type in our framework .
Other graph mining algorithms to compute similarity of nodes based on graph structure include co citation [ 17 ] and its generalization SimRank [ 11 ] . Again , similarity is but one application for our framework , and advantages of the similarity computation enabled by our framework over specific measures of similarity were noted in Section 22
A particular feature of F Miner is the ability to relate nodes in a graph through relationships beyond just a single edge , as in the query of Figure 7 . This feature was also exhibited in the proximity search of [ 8 ] , which finds nodes in a graph that are nearby in terms of graph distance . However , there is no mechanism in [ 8 ] for explaining query results , one of the strengths of our approach . A system was presented in [ 4 ] that , given keywords matching tuples across different tables in a relational database , returns a tree denoting the schema relating the matching tuples , where the edges of the tree are foreign key relationships . The tree serves to explain how the tuples are related . However , these tree structures lack the expressive power of our formulas , and there is no ranking of explanations .
As discussed in Section 4.1 , the recursive notion of importance of pseudopredicates is analogous to the notion of importance computed by the PageRank [ 16 ] and HITS [ 14 ] algorithms for web pages .
The syntax and semantics of the formulas used in our framework are borrowed from the logic programming language Datalog [ 19 ] .
7 Conclusion
The main contributions of this paper are summarized as follows :
• We presented a framework under which data mining queries can be posed on graph properties . We showed that many common notions in data mining have analogues in the space of formulas that can be formulated as query types in our framework .
• We developed techniques to deal with the enormous size of the query space . Our basic building blocks approach partitions properties into classes , bypassing the prohibitive process of analyzing each property individually .
• We defined a general measure of importance for properties by treating properties as first class objects and applying known techniques . The measure was a vital component of the experimental system .
• We implemented the F Miner experimental system supporting queries under the property mining framework that are not supported by existing systems .
Our experiments to date have been with relatively small data sets . Much work is yet to be done in algorithms , approximations , tuning , and optimizations if we wish to scale to data sets approaching the size of the web . Nonetheless , many modest sized data sets with acceptable precomputation and query response times pose interesting applications for our framework already , such as the examples in our experiments . With the proliferation of XML and other easy means of expressing and interlinking data , we expect in the near future to see numerous graph structured datasets amenable to property mining .
The intent of this paper is mainly to provide a foundation for the mining of ( graph ) properties . The emphasis has been on demonstrating the utility and feasibility of this new kind of data mining . We have only scratched the surface in terms of theory , algorithms , implementation , and applications ; many aspects are open for further research .
References [ 1 ] http://dbpubsstanfordedu
[ 2 ] http://clubnexusstanfordedu
[ 3 ] Rakesh Agrawal and Ramakrishnan Srikant . Fast algorithms for mining association rules . In Proceedings of the 20th International Conference on Very Large Databases ( VLDB ) , Santiago , Chile , September 1994 .
[ 4 ] Gaurav Bhalotia , Arvind Hulgeri , Charuta , Soumen Chakrabarti , and S . Sudarshan . Keyword searching and browsing in databases using BANKS . In Proceedings of the 18th International Conference on Data Engineering ( ICDE ) , San Jose , California , USA , February 2002 .
[ 5 ] Sergey Brin . Extracting patterns and relations from the world wide web . In Proceedings of the WebDB Workshop at the 6th International Conference on Extending Database Technology ( EDBT ) , Valencia , Spain , March 1998 .
[ 6 ] Luc Dehaspe and Hannu TT Toivonen . Discovery of Relational Association Rules , pages 189–212 . Springer Verlag Heidelberg , Germany , 2001 . http://citeseernj neccom/486120html
[ 7 ] Bart Goethals and Jan Van den Bussche . Relational association rules : getting WARMeR . In Proceedings of the ESF Exploratory Workshop on Pattern Detection and Discovery in Data Mining , volume 2447 of Lecture Notes in Computer Science , pages 125–139 , Germany , 2002 . Springer Verlag Heidelberg .
[ 8 ] Roy Goldman , Narayanan Shivakumar , Suresh Venkatasubramanian , and Hector Garcia Molina . Proximity search in databases . In Proceedings of the 24th International Conference on Very Large Databases ( VLDB ) , New York City , New York , USA , August 1998 .
[ 9 ] Taher H . Haveliwala . Topic sensitive PageRank .
In Proceedings of the Eleventh International World Wide Web Conference ( WWW ) , Honolulu , Hawaii , USA , May 2002 .
[ 10 ] Akihiro Inokuchi , Takashi Washio , and Hiroshi Motoda . An apriori based algorithm for mining frequent substructures from graph data . In Proceedings of the Principles of Data Mining and Knowledge Discovery , 4th European Conference ( PKDD ) , Lyon , France , September 2000 .
SimRank : A measure [ 11 ] Glen Jeh and Jennifer Widom . of structural context similarity . In Proceedings of the Eighth International Conference on Knowledge Discovery and Data Mining ( KDD ) , Edmonton , Alberta , Canada , July 2002 .
[ 12 ] Glen Jeh and Jennifer Widom . Scaling personalized web search . In Proceedings of the Twelfth International World Wide Web Conference ( WWW ) , Budapest , Hungary , May 2003 . To appear .
[ 13 ] M . M . Kessler . Bibliographic coupling between scientific papers . American Documentation , 14:10–25 , 1963 .
[ 14 ] Jon M . Kleinberg . Authoritative sources in a hyperlinked environment . In Proceedings of the Ninth Annual ACM SIAM Symposium on Discrete Algorithms ( SODA ) , San Francisco , California , USA , January 1998 .
[ 15 ] Michihiro Kuramochi and George Karypis . An efficient algorithm for discovering frequent subgraphs . Technical report , Department of Computer Science , University of Minnesota , 2002 . http://wwwcsumnedu/˜kuram/ papers/fsg longpdf
[ 16 ] Lawrence Page , Sergey Brin , Rajeev Motwani , and Terry Winograd . The PageRank citation ranking : Bringing order to the Web . Technical report , Stanford University Database Group , 1998 . http://citeseernjnec com/368196html
[ 17 ] Henry Small . Co citation in the scientific literature : A new measure of the relationship between two documents . Journal of the American Society for Information Science , 24:265–269 , 1973 .
[ 18 ] Neel Sundaresan and Jeonghee Yi . Mining the web for relations . In Proceedings of the Ninth International World Wide Web Conference ( WWW ) , Amsterdam , The Netherlands , May 2000 . http://www9.org/w9cdrom/363/ 363html
[ 19 ] Jeffrey D . Ullman . Principles of Database and KnowledgeBase Systems , Vol . 1 2 . W H Freeman & Co . , New York City , New York , USA , 1989 .
[ 20 ] Mohammed J . Zaki . Efficiently mining trees in a forest . In Proceedings of the Eighth International Conference on Knowledge Discovery and Data Mining ( KDD ) , Edmonton , Alberta , Canada , July 2002 .
12
