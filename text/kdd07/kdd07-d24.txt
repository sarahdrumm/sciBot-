Correlation Search in Graph Databases
Yiping Ke keyiping@cseusthk
James Cheng csjames@cseusthk
Wilfred Ng wilfred@cseusthk
Department of Computer Science and Engineering
The Hong Kong University of Science and Technology
Clear Water Bay , Kowloon , Hong Kong
ABSTRACT Correlation mining has gained great success in many application domains for its ability to capture the underlying dependency between objects . However , the research of correlation mining from graph databases is still lacking despite the fact that graph data , especially in various scientific domains , proliferate in recent years . In this paper , we propose a new problem of correlation mining from graph databases , called Correlated Graph Search ( CGS ) . CGS adopts Pearson ’s correlation coefficient as a correlation measure to take into consideration the occurrence distributions of graphs . However , the problem poses significant challenges , since every subgraph of a graph in the database is a candidate but the number of subgraphs is exponential . We derive two necessary conditions which set bounds on the occurrence probability of a candidate in the database . With this result , we design an efficient algorithm that operates on a much smaller projected database and thus we are able to obtain a significantly smaller set of candidates . To further improve the efficiency , we develop three heuristic rules and apply them on the candidate set to further reduce the search space . Our extensive experiments demonstrate the effectiveness of our method on candidate reduction . The results also justify the efficiency of our algorithm in mining correlations from large real and synthetic datasets .
Categories and Subject Descriptors : H28 [ Database Management ] : Database Applications Data Mining
General Terms : Algorithms
Keywords : Correlation , Graph Databases , Pearson ’s Correlation Coefficient
1 .
INTRODUCTION
Correlation mining is recognized as one of the most important data mining tasks for its capability of identifying the underlying dependency between objects . It has a wide range of application domains and has been studied extensively on market basket databases [ 5 , 13 , 15 , 24 , 23 , 29 ] , quantita tive databases [ 11 ] , multimedia databases [ 16 ] , data streams [ 20 ] , and many more . However , little attention has been paid to mining correlations from graph databases , in spite of the popularity of graph data model pertaining to various domains , such as biology [ 4 , 10 ] , chemistry [ 2 ] , social science [ 3 ] , the Web [ 17 ] and XML [ 1 ] .
In this paper , we study a new problem of mining correlations from graph databases . We propose to use Pearson ’s correlation coefficient [ 21 ] to measure the correlation between a query graph and an answer graph . We formulate this mining problem , named Correlated Graph Search ( CGS ) , as follows . Given a graph database D that consists of N graphs , a query graph q and a minimum correlation threshold θ , the problem of CGS is to find all graphs whose Pearson ’s correlation coefficient wrt q is no less than θ .
Pearson ’s correlation coefficient is shown to be one of the most desirable correlation measures in [ 21 ] for its ability to capture the departure of two variables from independence . It has been widely used to describe the strength of correlation among boolean variables in transaction databases [ 21 , 23 , 29 ] . This motivates us to apply the measure in the context of graph databases . However , graph mining is a much harder problem due to the high complexity of graph operations ( eg , subgraph isomorphism testing is NP complete [ 7] ) . The difficulty of the problem is further compounded by the fact that the search space of CGS is often large , since a graph consists of exponentially many subgraphs and each subgraph of a graph in D can be a candidate graph . Thus , it poses great challenges to tackle the problem of CGS . How can we reduce the large search space of CGS and avoid as many expensive graph operations as possible ? We investigate the property of Pearson ’s correlation coefficient and derive two necessary conditions for the correlation condition to be satisfied . More specifically , we derive the lower bound and upper bound of the occurrence probability ( also called support ) , supp(g ) , of a candidate graph g . This effectively reduces the search space to be the set of Frequent subGraphs ( FGs ) [ 12 ] in D with the support values between the lower and upper bounds of supp(g ) . However , mining FGs from D is still expensive when the lower bound of supp(g ) is low or D is large . Moreover , we still have a large number of candidates and the solution is not scalable . Thus , we need to further reduce the number of candidates as well as address the scalability problem . Our solution to this problem is as follows .
Let Dq be the projected database of D on q , which is the set of all graphs in D that are supergraphs of q . We prove that , the set of FGs mined from Dq using lowerbound(supp(g ) ) supp(q ) supp(q ) lowerbound(supp(g ) ) as the minimum support threshold is complete wrt the answer set . Since Dq is in general much smaller than D while is greater than lowerbound ( supp(g) ) , our finding not only saves the computational cost for generating the candidate set , but also significantly reduces the number of candidates . Furthermore , we develop three heuristic rules to be applied on the candidate set to identify the graphs that are guaranteed to be in the answer set , as well as to prune the graphs that are guaranteed to be false positives .
In addition to the formulation of the new CGS problem and its efficient solution , the significance of our work also lies in its close connection to graph similarity search , which is an important research area of graph querying . There are two types of similarity : structural similarity ( ie , two graphs are similar in structure ) and statistical similarity ( ie , the occurrence distributions of two graphs are similar ) .
Existing work [ 8 , 18 , 27 , 22 ] mainly focuses on structural similarity search . However , in many applications , two graphs that are structurally dissimilar but always appear together in a graph in D may be more interesting . For example , in chemistry , isomers refer to molecules with the same chemical formula and similar structures . The chemical properties of isomers can be quite different due to different positions of atoms and functional groups . Consider the case that the chemist needs to find some molecule that shares similar chemical properties of a given molecule . Structural similarity search is not relevant , since it mostly returns isomers of the given molecule that have similar structures but different chemical properties , which is undesirable . On the contrary , CGS is able to obtain the molecules that share similar chemical properties but may or may not have similar structures to the given molecule . Therefore , our proposed CGS solves an orthogonal problem of structural similarity search .
Our extensive experiments on both real and synthetic datasets show that our algorithm , called CGSearch , achieves short response time for various queries with relatively small memory consumption . Compared with the approach whose candidate set is generated from the whole database with a support range , CGSearch is orders of magnitude faster and consumes up to 41 times less memory . The effectiveness of the candidate generation from the projected database and three heuristic rules is also demonstrated .
Contributions . The specific contributions of the paper are stated as follows .
• We formulate the new problem of correlation search in graph databases , which takes into account the occurrence distributions of graphs using Pearson ’s correlation coefficient .
• We derive theoretical bounds for the support of a candidate graph , which reduces the search space considerably .
• We propose to generate the candidate set by mining FGs from the projected database of the query graph . Three heuristic rules are developed to further reduce the size of the candidate set .
• We present an efficient algorithm to solve the problem of CGS . We also prove the soundness and completeness of the query results returned by the algorithm .
• A comprehensive set of experiments is conducted to verify the efficiency of the algorithm , and the effec tiveness of the candidate generation and the heuristic rules .
Organization . We give preliminaries in Section 2 . We define the CGS problem in Section 3 . We propose the effective candidate generation from a projected database in Section 4 . We present the algorithm , as well as the three heuristic rules , in Section 5 . Then , we analyze the performance study in Section 6 . Finally , we discuss related work in Section 7 and conclude our paper in Section 8 .
2 . PRELIMINARIES
In this paper , we restrict our discussion on undirected , labelled connected graphs ( or simply graphs hereinafter ) , since most of the interesting graphs in practice are connected graphs ; while our method can be easily extended to process directed and unlabelled graphs .
A graph g is defined as a 4 tuple ( V , E , L , l ) , where V is the set of vertices , E is the set of edges , L is the set of labels and l is a labelling function that maps each vertex or edge to a label in L . We define the size of a graph g as size(g ) = |E(g)| . Given two graphs , g = ( V , E , L , l ) and g′ = ( V ′ , E′ , L′ , l′ ) , a subgraph isomorphism from g to g′ is an injective function f : V → V ′ , such that ∀(u , v ) ∈ E , ( f ( u ) , f ( v ) ) ∈ E′ , l(u ) = l′(f ( u) ) , l(v ) = l′(f ( v) ) , and l(u , v ) = l′(f ( u ) , f ( v) ) . The subgraph isomorphism testing is known to be an NPcomplete problem [ 7 ] .
A graph g is called a subgraph of another graph g′ ( or g′ is a supergraph of g ) , denoted as g ⊆ g′ ( or g′ ⊇ g ) , if there exists a subgraph isomorphism from g to g′ .
|D|
Let D = {g1 , g2 , . . . , gN } be a graph database that consists of N graphs . Given D and a graph g , we denote the set of all graphs in D that are supergraphs of g as Dg = {g′ : g′ ∈ D , g′ ⊇ g} . We call Dg the projected database of D on g . The frequency of g in D , denoted as freq(g ; D ) , is defined as |Dg| . The support of g in D , denoted as supp(g ; D ) , is defined as freq(g;D ) . A graph g is called a Frequent subGraph ( FG ) [ 9 , 12 , 25 ] in D if supp(g ; D ) ≥ σ , where σ ( 0 ≤ σ ≤ 1 ) is a userspecified minimum support threshold . For simplicity , we use freq(g ) and supp(g ) to denote the frequency and support of g in D when there is no confusion . Given two graphs , g1 and g2 , we define the joint frequency , denoted as freq(g1 , g2 ) , as the number of graphs in D that are supergraphs of both g1 and g2 , ie , freq(g1 , g2 ) = |Dg1 ∩ Dg2| . Similarly , we define the joint support of g1 and g2 as supp(g1 , g2 ) = freq(g1,g2 ) . The support measure is anti monotone , ie , if g1 ⊆ g2 , then supp(g1 ) ≥ supp(g2 ) . Moreover , by the definition of joint support , we have the following property : supp(g1 , g2 ) ≤ supp(g1 ) and supp(g1 , g2 ) ≤ supp(g2 ) .
|D|
Example 1 . Figure 1 shows a graph database , D , that consists of 10 graphs , g1 , . . . , g10 . For clarity of presentation , all the nodes are of the same label ( not shown in the figure ) ; while the characters a , b and c represent distinct edge labels . The graph g8 is a subgraph of g2 . The projected database of g8 , ie , Dg8 , is {g2 , g3 , g6 , g7 , g8} . The frequency of g8 is computed as freq(g8 ) = |Dg8| = 5 . The support of g8 is supp(g8 ) = freq(g8 ) = 05 As for g9 , we have Dg9 = {g6 , g7 , g9} . The joint frequency of g8 and g9 is computed as freq(g8 , g9 ) = |Dg8 ∩ Dg9| = |{g6 , g7}| = 2 . The joint support of g8 and g9 is supp(g8 , g9 ) = freq(g8,g9 ) = 02 '
|D|
|D| bfl cfl afl afl cfl bfl afl bfl cfl bfl afl cfl cfl
( gfl1fl)fl afl bfl afl
( gfl4fl)fl afl cfl afl
( gfl7fl)fl cfl
( gfl 2fl)fl bfl
( gfl5fl)fl bfl cfl
( gfl3fl)fl afl afl cfl cfl
( gfl6fl)fl afl afl afl
( gfl10fl)fl afl cfl
( gfl9fl)fl cfl cfl afl
( gfl8fl)fl
Figure 1 : A Graph Database , D
3 . PROBLEM DEFINITION
We first define Pearson ’s correlation coefficient [ 19 ] for two given graphs . Pearson ’s correlation coefficient for boolean variables is also known as “ φ correlation coefficient ” [ 28 ] .
Definition 1 . ( Pearson ’s Correlation Coefficient ) Given two graphs g1 and g2 , the Pearson ’s Correlation Coefficient of g1 and g2 , denoted as φ(g1 , g2 ) , is defined as follows :
φ(g1 , g2 ) = supp(g1 , g2 ) − supp(g1)supp(g2 )
. supp(g1)supp(g2)(1 − supp(g1))(1 − supp(g2 ) ) When supp(g1 ) or supp(g2 ) is equal to 0 or 1 , φ(g1 , g2 ) is defined to be 0 .
The range of φ(g1 , g2 ) falls within [ −1 , 1 ] . If φ(g1 , g2 ) is positive , then g1 and g2 are positively correlated ; otherwise , g1 and g2 are negatively correlated . In this paper , we focus on positively correlated graphs defined as follows .
Definition 2 . ( Correlated Graphs ) Two graphs g1 and g2 are correlated if and only if φ(g1 , g2 ) ≥ θ , where θ ( 0 < θ ≤ 1 ) is a user specified minimum correlation threshold .
We now define the correlation mining problem in graph databases as follows .
Definition 3 . ( Correlated Graph Search ) Given a graph database D , a correlation query graph q and a minimum correlation threshold θ , the problem of Correlated Graph Search ( CGS ) is to find the set of all graphs that are correlated with q . The answer set of the CGS problem is defined as Aq = {(g , Dg ) : φ(q , g ) ≥ θ} .
For each correlated graph g of q , we include Dg in the answer set in order to indicate the distribution of g in D . We also define the set of correlated graphs in the answer set as the base of the answer set , denoted as base(Aq ) = {g : ( g , Dg ) ∈ Aq} . In the subsequent discussions , a correlation query graph is simply called a query .
Table 1 gives the notations used throughout the paper .
Table 1 : Notations Used Throughout Notation
D q θ
φ(q , g ) Aq Dg base(Aq ) freq(g ) , supp(g ) freq(q , g ) , supp(q , g ) freq(g ; Dq ) , supp(g ; Dq ) freq(q , g ; Dq ) , supp(q , g ; Dq ) lower ( g ) , upper ( g ) lower ( q , g ) , upper ( q , g )
Description a graph database a query graph a minimum correlation threshold , 0 < θ ≤ 1 Pearson ’s correlation coefficient of q and g the answer set of q the base of the answer set the projected database of D on graph g the frequency/support of g in D the joint frequency/support of q and g in D the frequency/support of g in Dq the joint frequency/support of q and g in Dq the lower/upper bound of supp(g ) the lower/upper bound of supp(q , g )
4 . CANDIDATE GENERATION
A crucial step for solving the problem of CGS is to obtain the set of candidate graphs . Obviously , it is infeasible to test all subgraphs of the graphs in D because there are exponentially many subgraphs . In this section , we discuss how to effectively select a small set of candidates for a given query . 4.1 Support Bounds of Correlated Graphs
We begin by investigating the bounds on the support of a candidate graph , g , with respect to the support of a query q . We state and prove the bounds in Lemma 1 .
Lemma 1 . If q and g are correlated , then the following bounds of supp(g ) hold : supp(q )
θ−2(1−supp(q))+supp(q ) ≤ supp(g ) ≤ supp(q )
θ2(1−supp(q))+supp(q ) .
Proof . By the definition of the joint support , we have supp(q , g ) ≤ supp(g ) and supp(q , g ) ≤ supp(q ) . supp(q , g ) with supp(g ) in φ(q , g ) , we have :
Since q and g are correlated , φ(q , g ) ≥ θ . By replacing supp(g ) − supp(q)supp(g ) supp(q)supp(g)(1 − supp(q))(1 − supp(g ) ) ≥ θ
⇒ supp(g ) ≥ supp(q )
θ−2(1 − supp(q ) ) + supp(q )
.
Similarly , by replacing supp(q , g ) with supp(q ) in φ(q , g ) , we obtain the upper bound : supp(g ) ≤ supp(q )
θ2(1 − supp(q ) ) + supp(q )
.
For simplicity , we use lower ( g ) and upper ( g ) to denote the respective lower and upper bounds of supp(g ) with respect to q , as given in Lemma 1 . The above lemma states a necessary condition for a correlated answer graph . Thus , a candidate graph should have support within the range of [ lower ( g ) , upper ( g) ] .
With the result of Lemma 1 , we can obtain the candidate set by mining the set of FGs from D using lower ( g ) as the minimum support threshold and upper ( g ) as the maximum support threshold . However , according to the antimonotone property of the support measure , the graphs with higher support are always generated before those with lower support , no matter adopting a breadth first or a depth first strategy . As a result , the maximum threshold upper ( g ) is not able to speed up the mining process . Therefore , generating the candidates by mining the FGs from D with a support range is still not efficient enough , especially when lower ( g ) is small or D is large . This motivates us to devise a more efficient and effective approach to generate the candidates . 4.2 Candidate Generation From a Projected
Database
From Definition 1 , it follows that if φ > 0 , then supp(q , g ) > 0 . This means that q and g must appear together in at least one graph in D . This also implies that ∀g ∈ base(Aq ) , g appears in at least one graph in the projected database of q , Dq . Since Dq is in general much smaller than D , this gives rise to the following natural question : can we mine the candidate set more efficiently from Dq instead of D ? The challenge is that , however , we need to determine a minimum support threshold that can be used to mine the FGs from Dq , so that no correlated answer graph is missed . Obviously , we cannot use a trivial threshold since it is too expensive . In this subsection , we derive a minimum support threshold which enables us to efficiently compute the candidates from Dq . Our solution is inspired by the following important observation as stated in Lemma 2 .
Lemma 2 . Given a graph g , supp(g ; Dq ) = supp(q , g ; Dq ) = supp(q,g ) supp(q ) .
= supp(q , g ; Dq ) .
Proof . By the definition of the projected database , every graph in Dq must contain q . Therefore , every graph in Dq that contains g must also contain q . Thus , supp(g ; Dq ) = supp(q , g ; Dq ) holds . Since the number of graphs containing both q and g in D is the same as that in Dq , that is , freq(q , g ) = freq(q , g ; Dq ) , we have supp(q,g ) = freq(q,g;Dq ) supp(q ) = freq(q,g)/|D| freq(q)/|D|
|Dq| Lemma 2 states that the support of a graph g in Dq is the same as the joint support of q and g in Dq . This prompts us to derive the lower bound and upper bound for supp(q , g ; Dq ) , given that g is correlated with q . Then , we can use the bounds as the minimum and maximum support thresholds to compute the candidates from Dq .
Since supp(q , g ; Dq ) = supp(q,g ) derive the bounds for supp(q , g ) . First , by the definition of the joint support , we obtain the supp(q ) by Lemma 2 , we try to upper bound of supp(q , g ) as follows : supp(q , g ) ≤ supp(q ) .
( 1 )
Then , we construct a lower bound for supp(q , g ) from Definition 1 . Given φ(q , g ) ≥ θ , we have the following inequality : ( 2 ) supp(q , g ) ≥ f ( supp(g) ) , where f ( supp(g ) ) = θ supp(q)supp(g)(1 − supp(q))(1 − supp(g ) )
+ supp(q)supp(g ) .
The lower bound of supp(q , g ) stated in Inequality ( 2 ) cannot be directly used , since it is a function of supp(g ) , where g is exactly what we try to get using supp(q , g ) . However , since we have obtained the range of supp(g ) , ie , [ lower ( g ) , upper ( g ) ] as stated in Lemma 1 , we now show that this range can be used in Inequality ( 2 ) to obtain the lower bound of supp(q , g ) . By investigating the property of the function f , we find that , f is monotonically increasing with supp(g ) in the range of [ lower ( g ) , upper ( g) ] . Therefore , by substituting supp(g ) with lower ( g ) in Inequality ( 2 ) , we obtain the lower bound of supp(q , g ) . We state and prove the bounds of supp(q , g ) in the following lemma .
Lemma 3 . If q and g are correlated , then the following bounds of supp(q , g ) hold : supp(q )
θ−2(1 − supp(q ) ) + supp(q ) ≤ supp(q , g ) ≤ supp(q ) .
Proof . The upper bound follows by the definition of the joint support .
To show that the lower bound holds , we need to prove that the function f is monotonically increasing within the bounds of supp(g ) given in Lemma 1 . This can be done by applying differentiation to f with respect to supp(g ) as follows : f′(supp(g ) ) =
θ · supp(q)(1 − supp(q))(1 − 2 · supp(g ) ) supp(q)supp(g)(1 − supp(q))(1 − supp(g ) )
2 + supp(q ) .
Thus , we need to prove that within [ lower ( g ) , upper ( g) ] , f′(supp(g ) ) ≥ 0 or equivalently the following inequality :
1 − 2 · supp(g ) supp(g)(1 − supp(g ) ) ≥ −
2 θ supp(q )
1 − supp(q )
.
( 3 )
First , if supp(g ) ≤ upper ( g ) ≤ 0.5 , then ( 1− 2· supp(g ) ) ≥ 0 and hence f′(supp(g ) ) ≥ 0 . Now we consider the case when upper ( g ) ≥ supp(g ) > 05 Since the left hand side of Inequality ( 3 ) is less than 0 , we take square on both sides of Inequality ( 3 ) and obtain :
( 1 − 2 · supp(g))2 supp(g)(1 − supp(g ) ) ≤
4 · supp(q )
θ2(1 − supp(q ) )
⇔ a · ( supp(g))2 − a · supp(g ) + θ2(1 − supp(q ) ) ≤ 0 , where a = 4θ2(1 − supp(q ) ) + 4supp(q ) . The left hand side of Inequality ( 4 ) is a quadratic function , which is monotonically increasing within the range of [ 0.5 , ∞ ] . Since 0.5 < supp(g ) ≤ upper ( g ) , we replace supp(g ) with upper ( g ) in this quadratic function :
( 4 ) a · ( upper ( g))2 − a · upper ( g ) + θ2(1 − supp(q ) )
= θ2(1 − supp(q))(−4 · upper ( g ) + 1 ) < θ2(1 − supp(q))(−4 × 0.5 + 1 ) < 0 . Therefore , when 0.5 < supp(g ) ≤ upper ( g ) , Inequality ( 4 ) holds and hence f′(supp(g ) ) ≥ 0 . Thus , f is monotonically increasing within the range of [ lower ( g ) , upper ( g) ] . By substituting supp(g ) with lower ( g ) in Inequality ( 2 ) , the lower bound of supp(q , g ) thus follows :
( Since upper ( g ) > 0.5 ) supp(q , g ) ≥ f ( supp(g ) ) supp(q )
)
≥ f (
=
θ−2(1 − supp(q ) ) + supp(q ) . supp(q )
θ−2(1 − supp(q ) ) + supp(q )
We use lower ( q , g ) and upper ( q , g ) to denote the lower and upper bounds of supp(q , g ) with respect to q , as given in Lemma 3 .
With the results of Lemmas 2 and 3 , we propose to generate the candidates by mining FGs from Dq using lower ( q,g ) supp(q ) as the minimum support threshold . A generated candidate set , C , is said to be complete with respect to q , if ∀g ∈ base(Aq ) , g ∈ C . We establish the result of completeness by the following theorem .
Theorem 1 . Let C be the set of FGs mined from Dq with supp(q ) . Then , C is com the minimum support threshold of lower ( q,g ) plete with respect to q .
Proof . Let g ∈ base(Aq ) . Since φ(q , g ) ≥ θ , it follows that lower ( q , g ) ≤ supp(q , g ) ≤ upper ( q , g ) by Lemma 3 . By dividing the inequality by supp(q ) on all the expressions , we have lower ( q,g ) supp(q ) ≤ 1 . By Lemma 2 , we have lower ( q,g ) supp(q ) ≤ supp(g ; Dq ) ≤ 1 . The result g ∈ C follows , since C is the set of FGs mined from Dq using lower ( q,g ) as the minimum support threshold . supp(q ) ≤ supp(q,g ) supp(q )
The result of Theorem 1 is significant , since it implies that we are now able to mine the set of candidate graphs from a much smaller projected database Dq ( compared with D ) with a greater minimum support threshold lower ( q,g ) ( comsupp(q ) pared with lower ( g ) which is equal to lower ( q , g ) , as shown in Lemmas 1 and 3 ) .
5 . CORRELATED GRAPH SEARCH
In this section , we present our solution to the CGS problem . The framework of the solution consists of the following four steps .
1 . Obtain the projected database Dq of q . 2 . Mine the set of candidate graphs C from Dq , using lower ( q,g ) supp(q ) as the minimum support threshold .
3 . Refine C by three heuristic rules . 4 . For each candidate graph g ∈ C ,
( a ) Obtain Dg . ( b ) Add ( g , Dg ) to Aq if φ(q , g ) ≥ θ .
Step 1 obtains the projected database of q . This step can be efficiently performed using any existing graph indexing technique [ 26 , 6 ] that can be used to obtain the projected database of a given graph .
Step 2 mines the set of FGs from Dq using some existing FG mining algorithm [ 12 , 25 , 14 ] . The minimum support threshold is determined by Theorem 1 . The set of FGs forms the candidate set , C . For each graph g ∈ C , the set of graphs in Dq that contain g is also obtained by the FG mining process . In Step 3 , three heuristic rules are applied on C to further prune the graphs that are guaranteed to be false positives , as well as to identify the graphs that are guaranteed to be in the answer set .
Finally , for each remaining graph g in C , Step 4(a ) obtains Dg using the same indexing technique as in Step 1 . Then Step 4(b ) checks the correlation condition of g with respect to q to produce the answer set . Note that , the joint support of q and g , which is needed for computing φ(q , g ) , is computed as ( supp(g ; Dq ) · supp(q ) ) by Lemma 2 . In the remainder of this section , we present three heuristic rules and our algorithm , CGSearch , to solve the problem of CGS . 5.1 Heuristic Rules
To check whether each graph g in C is correlated with q , a query operation to obtain Dg is needed for each candidate ( Step 4(a) ) . The step can be expensive if the candidate set is large . Thus , we develop three heuristic rules to further refine the candidate set .
First , if we are able to identify the graphs that are guaranteed to be correlated with q before processing Step 4 , we can save the cost of verifying the result . We achieve this goal by Heuristic 1 .
Heuristic 1 . Given a graph g , if g ∈ C and g ⊇ q , then g ∈ base(Aq ) . over , since g ∈ C , we have supp(g , q;Dq ) ≥ lower ( q,g ) Lemma 2 , we further have supp(q , g ) ≥ lower ( q , g ) .
Proof . Since g ⊇ q , we have supp(q , g ) = supp(g ) . Moresupp(q ) . By
By replacing supp(q , g ) with supp(g ) in φ(q , g ) , we have
φ(q , g ) =
1 − supp(q ) supp(q )
· supp(g )
1 − supp(g )
Now , φ is monotonically increasing with supp(g ) , and supp(g ) = supp(q , g ) ≥ lower ( q , g ) . We replace supp(g ) with its lower bound of lower ( q , g ) = θ−2(1−supp(q))+supp(q ) in φ(q , g ) . Then , we have the following : supp(q )
φ(q , g ) ≥
1 − supp(q ) supp(q )
·
≥ θ .
θ2supp(q ) 1 − supp(q )
Therefore , g ∈ base(Aq ) . Based on Heuristic 1 , if we find that a graph g in the candidate set is a supergraph of q , we can add ( g , Dg ) into the answer set without checking the correlation condition . In addition , since g is a supergraph of q , Dg can be obtained when g is mined from the projected database Dq . We next seek to save the cost of unrewarding query operations by pruning those candidate graphs that are guaranteed to be uncorrelated with q . For this purpose , we develop the following two heuristic rules .
Before introducing Heuristic 2 , we establish the following lemma , which describes a useful property of the function φ .
Lemma 4 . If both supp(q ) and supp(q , g ) are fixed , then
φ(q , g ) is monotonically decreasing with supp(g ) .
Proof . Since both supp(q ) and supp(q , g ) are fixed , we first simplify φ for clarity of presentation . Let x = supp(g ) , a = supp(q , g ) , b = supp(q ) , and c = supp(q)(1 − supp(q) ) . Then we have
φ(x ) = a − b · x c · x(1 − x )
.
The derivative of φ at x is given as follows :
φ′(x ) =
1 √c ·
( 2a − b)x − a
.
2x(1 − x ) x(1 − x )
Since 0 ≤ x ≤ 1 , we have x(1 − x ) ≥ 0 . Thus , the sign of φ′(x ) depends on the sign of ( (2a − b)x − a ) . Since ( (2a − b)x− a ) is a linear function , we can derive its extreme values by replacing 0 and 1 of x into the function . The two extreme values of ( (2a− b)x− a ) are ( −a ) and ( a− b ) , both of which are non positive , since a ≥ 0 and a ≤ b . Therefore , we have ( (2a − b)x − a ) ≤ 0 and φ′(x ) ≤ 0 . It follows that φ(q , g ) is monotonically decreasing with supp(g ) .
Heuristic 2 . Given two graphs g1 and g2 , where g1 ⊇ g2 and supp(g1 , q ) = supp(g2 , q ) , if g1 /∈ base(Aq ) , then g2 /∈ base(Aq ) .
Proof . Since g1 ⊇ g2 , we have supp(g1 ) ≤ supp(g2 ) . Since supp(g1 , q ) = supp(g2 , q ) and supp(q ) is fixed , by Lemma 4 , we have φ(q , g1 ) ≥ φ(q , g2 ) . Since g1 /∈ base(Aq ) , we have φ(q , g1 ) ≤ θ . Therefore , φ(q , g2 ) ≤ φ(q , g1 ) ≤ θ . Thus , we have g2 /∈ base(Aq ) .
By Lemma 2 , if supp(g1 , q ) = supp(g2 , q ) , then we have supp(g1 ; Dq ) = supp(g2 ; Dq ) . Thus , Heuristic 2 can be applied as follows : if we find that a graph g is uncorrelated with q , we can prune all the subgraphs of g that have the same support as g in Dq . heuristic :
We now use the function f again to present the third f ( supp(g1 ) ) = θ supp(q)(1 − supp(q))supp(g1)(1 − supp(g1 ) )
+ supp(q)supp(g1 ) .
Heuristic 3 . Given two graphs g1 and g2 , where g1 ⊇ g2 , if supp(g2 , q ) < f ( supp(g1) ) , then g2 /∈ base(Aq ) .
Proof . Since g1 ⊇ g2 , we have supp(g1 ) ≤ supp(g2 ) . By Lemma 1 , the necessary condition for φ(q , g2 ) ≥ θ is that , supp(g2 ) should fall within the range [ lower ( g2 ) , upper ( g2) ] . As shown in the proof of Lemma 3 , the function f is monotonically increasing within the range [ lower ( g2 ) , upper ( g2) ] . Therefore , we have supp(g2 , q ) < f ( supp(g1 ) ) ≤ f ( supp(g2) ) . By replacing supp(g2 , q ) with f ( supp(g2 ) ) in φ(q , g2 ) , we have the following derivations :
θ
φ(q , g2 ) <
=
= θ . f ( supp(g2 ) ) − supp(q)supp(g2 ) supp(q)supp(g2)(1 − supp(q))(1 − supp(g2 ) ) supp(q)supp(g2)(1 − supp(q))(1 − supp(g2 ) ) supp(q)supp(g2)(1 − supp(q))(1 − supp(g2 ) )
Therefore , we have g2 /∈ base(Aq ) . Note that , supp(g2 , q ) < f ( supp(g1 ) ) also implies g1 /∈ base(Aq ) . This is because g1 ⊇ g2 implies supp(g1 , q ) ≤ supp(g2 , q ) . Therefore , we have supp(g1 , q ) < f ( supp(g1) ) . Similarly , by replacing supp(g1 , q ) with f ( supp(g1 ) ) in φ(q , g1 ) , we can have φ(q , g1 ) < θ and thus g1 /∈ base(Aq ) .
Thus , f ( supp(g1 ) )
By Lemma 2 , we have supp(g2 , q ) = supp(g2 ; Dq)·supp(q ) . if supp(g2 , q ) < f ( supp(g1) ) , then supp(g2 ; Dq ) < if we find that a graph g is uncorrelated with q , we can prune all the subgraphs of g that have support values less than f ( supp(g ) )
. Thus , Heuristic 3 can be applied as follows : supp(q ) supp(q ) in Dq .
5.2 CGSearch Algorithm
Now , we present the CGSearch algorithm . As shown in Algorithm 1 , after we obtain the candidate set C from the projected database Dq ( Lines 1 2 ) , we process each candidate graph in C according to the descending order of the graph sizes . Then , Lines 4 5 applies Heuristic 1 to include the supergraphs of q ∈ C directly into the answer set without performing the query operation ( as in Line 7 ) . For other graphs in C , if they are verified to be correlated with q , we include them in the answer set ( Lines 8 9 ) ; otherwise , Heuristic 2 ( Lines 11 12 ) and Heuristic 3 ( Lines 13 14 ) are applied to further reduce the search space so that the unrewarding query costs for false positives are saved . supp(q ) as the minimum for each graph g ∈ C in size descending order do support threshold and add the FGs to C ; if ( g ⊇ q ) else
Algorithm 1 CGSearch Input : A graph database D , a query graph q , and a correlation threshold θ . Output : The answer set Aq . 1 . Obtain Dq ; 2 . Mine FGs from Dq using lower ( q,g ) 3 . 4 . 5 . 6 . 7 . 8 . 9 . 10 . 11 . 12 . 13 . 14 .
Add ( g , Dg ) to Aq ; H2 ← {g′ ∈ C : g′ ⊆ g , supp(g′ ; Dq ) = supp(g ; Dq)} ; C ← C − H2 ; H3 ← {g′ ∈ C : g′ ⊆ g , supp(g′ ; Dq ) < f ( supp(g ) ) supp(q ) } ; C ← C − H3 ;
Add ( g , Dg ) to Aq ; Obtain Dg ; if ( φ(q , g ) ≥ θ ) else
We now prove the soundness and completeness of the result returned by CGSearch algorithm . In other words , we prove that CGSearch is able to precisely return Aq with respect to a given q .
Theorem 2 . The answer set , Aq , returned by Algorithm
1 , is sound and complete with respect to q .
Proof . We first prove the soundness . ∀(g , Dg ) ∈ Aq , ( g , Dg ) is added to Aq in either Line 5 or Line 9 . For the case of Line 5 , we have proved in Heuristic 1 that g is correlated with q ; while for the case of Line 9 , the soundness is guaranteed in Line 8 . Thus , the soundness of Aq follows . It remains to show the completeness . By Theorem 1 , the candidate set , C , produced in Line 2 of Algorithm 1 is complete . ∀g ∈ C , if g is not included in Aq , then φ(q , g ) is checked to be less than θ ( Line 10 ) or g is pruned by Heuristics 2 or 3 ( Lines 11 14 ) . For all cases , g is proved to be uncorrelated with q and thus is not in Aq . Therefore , the completeness of Aq follows .
Example 2 . Consider the graph database in Figure 1 and the query q in Figure 2(a ) . Let θ = 06 CGSearch ( Line 1 ) first obtains Dq = {g1 , g2 , g3 , g4} . Thus , we have supp(q ) = 0.4 and lower ( q , g ) = 019 Then , CGSearch ( Line 2 ) mines FGs from Dq using 0.19 0.4 = 0.475 as the minimum support threshold and obtains 9 candidates , which are shown in Figure 2(b ) . The number following “ : ” in the figure is the support of each candidate in Dq . Since the candidates are sorted in descending order of their size , CGSearch first processes c1 . Since c1 is a super graph of q , ( c1 , Dc1 ) is directly included into Aq by Heuristic 1 . Note that Dc1 = {g1 , g2} can be obtained in the process of mining the candidates from Dq , since c1 is a supergraph of q .
Then , CGSearch processes c2 to obtain Dc2 = {g2 , g3 , g6 , g7} .
Therefore , we have φ(q , c2 ) = 05×04−04×04 √04×06×04×06 = 0.17 < θ . Then , CGSearch computes H2 = {c6} since c6 ⊂ c2 and supp(c6 ; Dq ) = supp(c2 ; Dq ) = 05 CGSearch further computes H3 = {c4 , c9} since c4 ⊂ c2 , c9 ⊂ c2 , and supp(c4 ; Dq ) = supp(c9 ; Dq ) = 0.75 < 0.76 = f ( supp(c2 ) ) , as shown in Figure 2(b ) . Therefore , after processing c2 , C = {c3 , c5 , c7 , c8} . Similar to c1 , CGSearch finds that c3 is a supergraph of q and ( c3 , Dc3 ) is directly included into Aq by Heuristic 1 . For c5 , after obtaining Dc5 , CGSearch computes φ(c5 , q ) = 0.61 ≥ θ , so ( c5 , Dc5 ) is added into Aq . Finally , by querying c7 and c8 , since φ(c7 , q ) = 0.4 < θ and φ(c8 , q ) = 0.82 ≥ θ , CGSearch adds ( c8 , Dc8 ) into Aq . Therefore , Aq = {(c1 , Dc1 ) , ( c3 , Dc3 ) , ( c5 , Dc5 ) , ( c8 , Dc8 )} . Among the 9 candidates , 5 of them do not need to perform correlation verification by applying Heuristics 1 to 3 . supp(q )
When carrying out the exhaustive search , there are 40 subgraphs for such a small and simple graph database . If we generate the candidate set by mining FGs from D using lower ( g ) = 0.19 and upper ( g ) = 0.64 as support thresholds , there are still 16 graphs in the candidate set . This clearly illustrates that the candidate generation from the projected database indeed significantly reduces the search space . ' bfl afl
( a ) An Example Query q bfl cfl afl cfl cfl bfl cfl cfl afl afl bfl
( cfl1fl : 0.5fl)fl
( cfl2fl : 0.5fl)fl
( cfl3fl : 1fl)fl
( cfl4fl : 0.75fl)fl
( cfl5fl : 0.5fl)fl cfl
( cfl6fl : 0.5fl)fl afl bfl cfl
( cfl8fl : 1fl)fl
( cfl7fl : fl1)fl ( b ) Candidate Set , C , of q
( cfl9fl : 0.75fl)fl afl cfl
Figure 2 : An Example Query and Its Candidate Set
5.3 Discussions
To apply the three heuristic rules in our algorithm , we need to obtain supergraphs or subgraphs of a given graph ( Lines 4 , 11 and 13 of Algorithm 1 ) by testing subgraph isomorphism . However , subgraph isomorphism testing is an expensive operation and we want to avoid it as much as possible . We find that the number of subgraph isomorphism testings can be effectively reduced by using a depth first FG mining algorithm ( such as gSpan [ 25 ] ) for the candidate generation . For a depth first mining process , the FGs gen erated can be organized by a prefix tree , in which a child is a supergraph of its parent . Thus , by following the root toleaf paths ( simply called path ) in the prefix tree , we are able to determine the subgraph supergraph relationship without performing subgraph isomorphism testing .
If we only follow a path in the prefix tree and do not check the relationship of the graphs that appear in different paths , we are not able to identify all the graphs in H2 and H3 , as well as all the supergraphs of q . However , we note that there is a trade off here . On the one hand , if we fully apply the three heuristic rules by cross checking the graphs in different paths to find all the subgraph supergraph relationships , more subgraph isomorphism testings have to be performed but less candidates are needed for verification of correlation condition . On the other hand , if we only partially apply the three heuristic rules by simply following the paths in the prefix tree , no subgraph isomorphism testing is needed but more candidates are required for verification . We demonstrate further this trade off in our experiments .
6 . PERFORMANCE EVALUATION
We evaluate the performance of our solution to the CGS problem on both real and synthetic datasets . 6.1 Experimental Settings
The real dataset contains the compound structures of cancer and AIDS data from the NCI Open Database Compounds1 . The original dataset contains about 249K graphs . By preprocessing and removing the disconnected graphs , we randomly select 100K graphs for our experiments . On average , each graph in the dataset has 21 nodes and 23 edges . The number of distinct labels for nodes and edges is 88 .
To test the scalability of CGSearch on graph size , we design a synthetic graph generator ( see details in GraphGen2 ) . We generate four synthetic datasets by varying the average number of edges in a graph from 40 to 100 . Each synthetic dataset has 100K graphs . The number of distinct labels is 30 and the average graph density is 015
We use FG index [ 6 ] to obtain the projected database of a graph . In all experiments , we set the minimum support threshold and the frequency tolerance factor in FG index to be 0.03 and 0.05 , respectively . We use gSpan [ 25 ] to mine the FGs for generating the set of candidates . All experiments were run on a linux machine with an AMD Opteron 248 CPU and 1 GB RAM .
The efficiency of CGSearch is based on the effective candidate generation from the projected database and the three heuristic rules . Since there is no existing work on mining correlations from graph databases , we mainly assess the effects of the candidate generation method and the heuristic rules on the performance of our algorithm .
To justify the effect of the candidate generation from the projected database on speeding up the mining process and on reducing the search space , we implement the approach whose candidates are mined from the whole database with a support range . Furthermore , to show the effect of the heuristic rules on refining the candidate set , we make three variants of our algorithm : CGSearch P , CGSearch F and CGSearch N . Among them , CGSearch P and CGSearch F are implemented based on the different strategies of apply
1http://cactusncinihgov/ncidb2/downloadhtml 2http://wwwcseusthk/graphgen ing the heuristic rules as discussed in Section 53 Table 2 summarizes the algorithms tested in our experiments .
Name Range
Table 2 : Algorithms Tested
Description Generate the candidate set from D using [ lower ( g ) , upper ( g ) ] as a support range .
CGSearch P Partially apply the heuristic rules in CGSearch . CGSearch F Fully apply the heuristic rules in CGSearch . CGSearch N Do not apply the heuristic rules in CGSearch .
6.2 Performance on Real Dataset
Since the complexity of the CGS problem mainly depends on the support of the query , we randomly generate four sets of queries , F1 , F2 , F3 , and F4 , each of which contains 100 queries . The support ranges for the queries in F1 to F4 are [ 0.02 , 0.05 ] , ( 0.05 , 0.07 ] , ( 0.07 , 0.1 ] and ( 0.1 , 1 ) , respectively .
621 Effect of Candidate Generation
Figure 3 reports the performance of CGSearch P and Range on the real dataset when varying the support of the queries . Figures 3(a b ) show the running time and memory consumption per query . On average , CGSearch P is two orders of magnitude faster and consumes 10 times less memory than Range . For both CGSearch P and Range , the time taken by the candidate generation dominates . We observe that , CGSearch P is slightly slower for the query set F1 and F4 . This is because the time for generating the candidates not only depends on the size of the projected database ( ie , supp(q) ) , but also depends on the minimum support threshold ( ie , lower ( q,g ) supp(q ) ) . Although the minimum support threshold of F4 is the highest among all the query sets , its projected database is the largest , which increases the mining time slightly . While for F1 , its low minimum support threshold results in slightly longer processing time . Compared with Range , the running time of CGSearch P is much more stable . For all support ranges , CGSearch P takes 2 to 4 seconds for each query , while the running time of Range is largely influenced by the support of the query . With the decrease in the support of the query , the running time of Range increases rapidly from 100 seconds to 400 seconds .
We show the size of the candidate sets of CGSearch P and Range in Figure 3(c ) . The size of the answer set is also shown as a reference . It is obvious that the size of the candidate set produced by CGSearch P is much closer to that of the answer set . Compared with Range , the candidate set of CGSearch P is over an order of magnitude smaller .
622 Effect of θ
Figure 4 reports the performance of CGSearch P and Range when varying the minimum correlation threshold θ from 0.6 to 1 . We test all query sets on the real dataset for both CGSearch P and Range . For clarity of presentation , we only present F4 for Range . But we remark that Range performs the best on F4 among all the query sets , which means that the performance of Range on F4 is the lower bound .
As shown in Figure 4 , for all values of θ , CGSearch P is over an order of magnitude faster and consumes 6.5 times less memory than Range on F4 . Given a query , with the decrease in θ , the minimum support threshold used to generate the candidates also decreases for both CGSearch P and
103
) c e s ( e m T i
102
101
100 F1
100
80
60
40
20
)
B M
( y r o m e M
0 F1
Range CGSearch_P
F2
Query Sets
F3
F4
( a ) Running Time
Range CGSearch_P
F2
Query Sets
F3
F4
( b ) Memory Consumption
104
103
102
101 s h p a r G f o r e b m u N
100 F1
Range CGSearch_P Answer Set
F2
Query Sets
F3
F4
( c ) Size of Candidate Set
Figure 3 : Performance on Varying Query Support
103
102
101
) c e s ( e m T i
F4 ( Range ) F1 ( CGSearch_P ) F2 ( CGSearch_P ) F3 ( CGSearch_P ) F4 ( CGSearch_P )
0.8
0.9
0.7
Minimum Correlation Threshold θ ( a ) Running Time
F4 ( Range ) F1 ( CGSearch_P ) F2 ( CGSearch_P ) F3 ( CGSearch_P ) F4 ( CGSearch_P )
100
0.6
100
)
B M
( y r o m e M
80
60
40
20
0 0.6
0.7
Minimum Correlation Threshold θ ( b ) Memory Consumption
0.8
0.9
1
1
Figure 4 : Performance on Varying θ
Range . Hence , the processing time of both CGSearch P and Range increases with the decrease in θ . We find that , when varying θ , the running time of CGSearch P on F1 and F2 is less stable than that on F3 and F4 . We also observe similar phenomenon for Range on F1 and F2 ( not reported in the figure ) . This is because the small minimum support threshold results in a large number of candidates . In this case , the time taken by candidate generation no longer dominates the total processing time . Instead , much more time is spent on querying the candidates by FG index to verify the correlation condition . For example , for the query set F1 , when θ = 1 , only 3 % of the total time is spent on querying the candidates ; while when θ = 0.6 , more than 60 % of the total time is spent on querying the candidates . This explains the trend of the running time for queries of low support .
623 Effect of Heuristic Rules
In order to show the effect of the heuristic rules clearly , we get rid of the time taken by the candidate generation and only present the time for querying candidates and checking the correlation condition .
Figure 5 shows the time on F4 for the three variants of CGSearch at different values of θ . When θ = 0.6 , the number of candidates is large . Therefore , CGSearch F performs the best , since the cost for querying the candidates is much larger than the cost for fully applying the heuristic rules . In this case , CGSearch P is slower than CGSearch F since partially applying the heuristic rules is not able to further reduce the number of candidates as effectively as does CGSearch F . However , with the increase in θ , and hence the decrease in the size of candidate set , CGSearch P outperforms CGSearch F . This is because , given the smaller number of candidates , the full application of the heuristic rules which involves subgraph isomorphism testings is more costly than querying the candidates by FG index . This suggests a good strategy for applying the heuristic rules : when the number of candidates is large , we can use CGSearch F to reduce the search space as much as possible ; when the number of candidates is relatively small , we can simply use CGSearch P .
In most of the cases , CGSearch N is the worst , since all the candidates need to go through the verification of correlation condition . However , if the number of candidates is small , it is possible that CGSearch F is even slower than CGSearch N due to too many subgraph isomorphism testings performed when fully applying the heuristic rules . Therefore , it can be seen from Figure 5 that the time of CGSearch F is almost the same as that of CGSearch N for high values of θ . However , in general , CGSearch P outperforms CGSearch N , since the partial application of the heuristic rules requires no subgraph isomorphism testing due to the prefix tree , as discussed in Section 53
0.07
0.06
) c e s ( e m T i
0.05
0.04
0.03
0.02
0.6
CGSearch_P CGSearch_F CGSearch_N
0.8
0.9
0.7
Minimum Correlation Threshold θ Running Time on F4
1
Figure 5 : Effect of Heuristic Rules ranges , respectively . Figure 6 reports the performance of CGSearch P and Range . For F1 , CGSearch P is up to four orders of magnitude faster and consumes 41 times less memory than Range . While for F4 , CGSearch P is still over an order of magnitude faster and consumes 6 times less memory than Range . The smaller improvement on the performance of CGSearch P over Range for F4 is because the average number of candidates of Range for F4 is over three orders of magnitude smaller than that of Range for F1 ( 111 , 955 for F1 and 795 for F4 ) . Figure 6 also shows that , CGSearch P is much more stable on resource usage than Range when varying graph sizes .
105
104
F1 ( Range ) F4 ( Range ) F1 ( CGSearch_P ) F4 ( CGSearch_P )
) c e s ( e m T i
103
102
101
100 40
350
300
250
200
150
100
50
)
B M
( y r o m e M
0 40
60
Graph Size
80
100
( a ) Running Time
F1 ( Range ) F4 ( Range ) F1 ( CGSearch_P ) F4 ( CGSearch_P )
60
Graph Size
80
100
( b ) Memory Consumption
Figure 6 : Performance on Varying Graph Size
6.3 Performance on Synthetic Dataset
7 . RELATED WORK
Since the graphs in the real dataset are of small size ( averagely 23 edges per graph ) , we use the synthetic datasets to test the scalability of CGSearch and Range on different graph sizes .
Similar to the experiments on the real dataset , we generate four sets of queries , F1 to F4 , with the same setting of support ranges as in Section 62
For clarity of presentation , we only show the results of F1 and F4 , which are of the largest and the smallest support
There have been a number of studies on mining correlations from various types of databases . Pearson ’s correlation coefficient , as well as its computation form for binary variables , φ correlation coefficient , are prevalently used as a correlation measure . Sakurai et al . [ 20 ] use Pearson ’s correlation coefficient to define the lag correlation between two time sequences . Xiong et al . [ 23 ] apply φ correlation coefficient to define the strongly correlated pairs in transaction databases . An upper bound of φ , as well as monotone properties of the upper bound , are identified to facilitate the efficient mining process . Recently , Zhang and Feigenbaum [ 29 ] also adopt φ correlation coefficient to measure the correlated pairs in transaction databases . An efficient algorithm that uses min hash functions as the pruning method is developed . To the best of our knowledge , our work is the first application of φ correlation coefficient in the context of graph databases .
In literature , many other correlation measures are proposed for different applications . For market basket data , correlation measures include χ2 [ 5 ] , interest [ 5 ] , all confidence [ 13 , 15 ] , bond [ 15 ] , h confidence [ 24 ] , and so on . For multimedia data , Pan et al . [ 16 ] use random walk with restart to define the correlation between the nodes in the graph that is constructed from a multimedia database . For quantitative databases , Ke et al . [ 11 ] utilize mutual information and all confidence to define the correlated patterns .
For similarity searching techniques developed for general graph models , Holder et al . [ 8 ] use the minimum description length principle for inexact graph matching . Raymond et al . [ 18 ] propose an efficient algorithm , called MCES , to perform similarity search measured by maximum common subgraphs . Yan et al . [ 27 ] develop a structural filtering algorithm , called Grafil , to filter graphs without performing similarity computations . Recently , Williams et al . [ 22 ] propose an indexing technique that adopts graph decomposition methods to facilitate similarity search on graph databases . However , all of them focus on structural similarity search as indicated by their graph similarity measures , while our work captures statistical similarity defined by Pearson ’s correlation coefficient .
8 . CONCLUSIONS
We formulate the problem of correlated graph search , which takes into account the occurrence distributions of graphs using Pearson ’s correlation coefficient . By deriving the theoretic bounds for the support of a candidate graph , we propose to efficiently generate the candidate set by mining FGs from the projected database of the query graph . We develop three effective heuristic rules to further reduce the size of the candidate set . We propose an efficient algorithm , CGSearch , to solve the problem of CGS . The soundness and completeness of the query results returned by CGSearch are also formally proved . The experimental results justify the efficiency and effectiveness of the candidate generation and the heuristic rules . Compared with the approach that generates the candidates directly from the database by a support range , our solution is orders of magnitude faster and consumes much less memory . More importantly , CGSearch achieves very stable performance when varying the support of the queries , the minimum correlation threshold , as well as the graph size .
Acknowledgement . This work is partially supported by RGC CERG under grant number HKUST6185/03E . We thank Dr . Xifeng Yan and Prof . Jiawei Han for providing us the executable of gSpan . We also thank the anonymous reviewers for their valuable comments .
9 . REFERENCES [ 1 ] DBLP Dataset . http://dblpuni trierde/xml/ [ 2 ] National library of medicine . http://chemsisnlmnihgov/chemidplus
[ 3 ] The International Network for Social Network Analysis . http://wwwinsnaorg/
[ 4 ] H . Berman , J . Westbrook , Z . Feng , G . Gilliland , T . Bhat ,
H . Weissig , I . Shindyalov , and P . Bourne . The protein data bank . Nucleic Acids Research , 28:235–242 , 2000 .
[ 5 ] S . Brin , R . Motwani , and C . Silverstein . Beyond market baskets : generalizing association rules to correlations . In SIGMOD , pages 265–276 , 1997 .
[ 6 ] J . Cheng , Y . Ke , W . Ng and A . Lu . FG Index : Towards verification free query processing on graph databses . In SIGMOD , 2007 .
[ 7 ] S . A . Cook . The complexity of theorem proving procedures .
In STOC , pages 151–158 , 1971 .
[ 8 ] L . Holder , D . Cook , and S . Djoko . Substructure discovery in the subdue system . In KDD , pages 169–180 , 1994 .
[ 9 ] A . Inokuchi , T . Washio , and H . Motoda . An apriori based algorithm for mining frequent substructures from graph data . In PKDD , pages 13–23 , 2000 .
[ 10 ] M . Kanehisa and S . Goto . KEGG : Kyoto encyclopedia of genes and genomes . Nucleic Acids Research , 28:27–30 , 2000 .
[ 11 ] Y . Ke , J . Cheng , and W . Ng . Mining quantitative correlated patterns using an information theoretic approach . In KDD , pages 227–236 , 2006 .
[ 12 ] M . Kuramochi and G . Karypis . Frequent subgraph discovery . In ICDM , pages 313–320 , 2001 .
[ 13 ] S . Ma and J . L . Hellerstein . Mining mutually dependent patterns . In ICDM , pages 409–416 , 2001 .
[ 14 ] S . Nijssen and J . N . Kok . A quickstart in frequent structure mining can make a difference . In KDD , pages 647–652 , 2004 .
[ 15 ] E . R . Omiecinski . Alternative interest measures for mining associations in databases . IEEE TKDE , 15(1):57–69 , 2003 .
[ 16 ] J Y Pan , H J Yang , C . Faloutsos , and P . Duygulu .
Automatic multimedia cross modal correlation discovery . In KDD , pages 653–658 , 2004 .
[ 17 ] S . Raghavan and H . Garcia Molina . Representing Web graphs . In ICDE , pages 405–416 , 2003 .
[ 18 ] J . W . Raymond , E . J . Gardiner , and P . Willett . RASCAL : calculation of graph similarity using maximum common edge subgraphs . Comput . J . , 45(6):631–644 , 2002 .
[ 19 ] H . Reynolds . The analysis of cross classifications . The Free
Press , New York , 1977 .
[ 20 ] Y . Sakurai , S . Papadimitriou , and C . Faloutsos . AutoLag : Automatic discovery of lag correlations in stream data . In ICDE , pages 159–160 , 2005 .
[ 21 ] P N Tan , V . Kumar , and J . Srivastava . Selecting the right interestingness measure for association patterns . In KDD , pages 32–41 , 2002 .
[ 22 ] D . Williams , J . Huan , and W . Wang . Graph database indexing using structured graph decomposition . In ICDE , 2007 .
[ 23 ] H . Xiong , S . Shekhar , P N Tan , and V . Kumar . TAPER : A two step approach for all strong pairs correlation query in large databases . IEEE TKDE , 18(4):493–508 , 2006 .
[ 24 ] H . Xiong , P N Tan , and V . Kumar . Hyperclique pattern discovery . DMKD , 13(2):219–242 , 2006 .
[ 25 ] X . Yan and J . Han . gspan : Graph based substructure pattern mining . In ICDM , page 721 , 2002 .
[ 26 ] X . Yan , P . S . Yu , and J . Han . Graph indexing based on discriminative frequent structure analysis . ACM TODS , 30(4):960–993 , 2005 .
[ 27 ] X . Yan , F . Zhu , P . S . Yu , and J . Han . Feature based similarity search in graph structures . ACM TODS , 31(4):1418–1453 , 2006 .
[ 28 ] G . U . Yule . On the methods of measuring association between two attributes . Journal of the Royal Statistical Society , 75(6):579–652 , 1912 .
[ 29 ] J . Zhang and J . Feigenbaum . Finding highly correlated pairs efficiently with powerful pruning . In CIKM , pages 152–161 , 2006 .
