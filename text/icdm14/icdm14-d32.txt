Co clustering Structural Temporal Data with Applications to Semiconductor Manufacturing
Yada Zhu
IBM TJ Watson Research Center
Email : yzhu@usibmcom
Jingrui He
Arizona State University Email : jingruihe@asucom
Abstract— Recent years have witnessed data explosion in semiconductor manufacturing due to advances in instrumentation and storage techniques . In particular , following the same recipe for a certain IC device , multiple tools and chambers can be deployed for the production of this device , during which multiple time series can be collected , such as temperature , impedance , gas flow , electric bias , etc . These time series naturally fit into a two dimensional array ( matrix ) , ie , each element in this array corresponds to a time series for one process variable from one chamber . To leverage the rich structural information in such temporal data , in this paper , we propose a novel framework named C Struts to simultaneously cluster on the two dimensions of this array . In this framework , we interpret the structural information as a set of constraints on the cluster membership , introduce an auxiliary probability distribution accordingly , and design an iterative algorithm to assign each time series to a certain cluster on each dimension . To the best of our knowledge , we are the first to address this problem . Extensive experiments on benchmark and manufacturing data sets demonstrate the effectiveness of the proposed method .
Index Terms—Structural ; temporal ; co clustering ;
I . INTRODUCTION
Semiconductor manufacturing represents one of the most complex manufacturing processes in the world [ 13 ] . Here , one key challenge is how to exploit the large amount of data associated with process variables monitored over time ( eg , temperature , impedance , gas flow , electric bias ) for a variety of purposes such as anomaly detection , quality control , and fault diagnostics , which may lead to significant reduction in the manufacturing cost [ 9 , 8 ] . In particular , to produce a certain IC ( Integrated Circuit ) device , multiple tools will be deployed following the same recipe process , and each tool has multiple chambers to carry out the task . Therefore , the time series data associated with various process variables measured from all the chambers fit into a two dimensional array , or matrix . To be specific , each row of the array corresponds to one chamber , each column corresponds to one process variable , and each element in this array corresponds to the measurements of the process variable over time . Such structural temporal data contain rich information about the manufacturing process , and thus can be exploited to help domain experts gain more insights into the recipe of the IC device .
In particular , the simultaneous clustering of rows ( chambers ) and columns ( process variables ) helps identify chambers with similar behaviors and process variables with similar patterns over time . Such information can be further used to detect outlying chambers as well as process variables for the sake of quality control and fault diagnostics . Although very important , this problem cannot be readily solved using existing techniques on time series clustering or multi way clustering . For time series clustering , most existing methods are designed for unstructured time series data [ 3 , 22 , 15 ] , and thus cannot leverage the structural information from the underlying matrix . For multi way clustering , existing methods take as input one or more matrices of scalers [ 6 , 1 , 4 ] , and cannot be applied on matrices of time series .
In this paper , for the first time , we study the co clustering of such structural temporal data and propose the C Struts framework to address this problem . In this framework , we first interpret the structural information associated with the two dimensional array as a set of constraints on the cluster membership . Then we introduce an auxiliary probability distribution taking these constraints into consideration , analyze its properties , and build a prototype for each row/ column accordingly . Finally , we propose an iterative algorithm to repeatedly assign each row/column to the closest prototype .
The rest of the paper is organized as follows . In Section 2 , we briefly review the related work . Then we present the C Struts framework together with the iterative algorithm in Section 3 . Experiments results are provided in Section 4 . Finally , we conclude the paper in Section 5 .
II . RELATED WORK
In this section , we briefly review the related work . Time Series Analysis . For time series data , researchers have studied a variety of problems , such as classification [ 3 , 7 ] , clustering [ 22 , 10 ] , search and indexing [ 16 , 20 ] , forecasting [ 21 ] , outlier detection [ 14 ] , etc . The major difference between existing methods for time series clustering and our proposed work is as follows . For the former , the time series data are typically unstructured , and the clustering results are solely based on the distance between two time series ; whereas for the latter , the time series data are structured , ie , they naturally fit into a two dimensional array , and the structural information can be exploited to improve the clustering results . Multi way Clustering . Different from traditional clustering techniques , which are designed to group objects so as to maximize within cluster similarity and between cluster dissimilarity , for sparse relational data , co clustering or bi clustering methods [ 12 ] aim at simultaneously clustering objects of each type . It has been generalized to handle more than two object types , ie , multi way clustering [ 5 , 11 ] . The major difference between existing methods for multi way clustering and our proposed work is as follows . The input of multi way clustering is one or more matrices of scalers ; whereas the input of the proposed work is a matrix of time series .
Semiconductor Device Fabrication . For the purpose of process fault/anomaly detection , multivariate statistical methods have been applied successfully in semiconductor manufacturing , such as Principal component analysis ( PCA ) , Fisher linear analysis and partial the structural information embedded in the time series data cannot be naturally incorporated into these algorithms . To the best of our knowledge , our work is the first to leverage the structural temporal information for process fault detection in semiconductor manufacturing . least square [ 2 ] . However ,
III . PROPOSED WORK
In this section , we introduce our proposed framework on co clustering structural temporal data . In other words , given structural temporal data that fit into a two dimensional array , our goal is to simultaneously cluster the rows and the columns . Here we would like to point out that the analysis and the proposed algorithm can be naturally extended to multidimensional arrays , which will be discussed in Subsection 35 A . Notation
1 , . . . , zi,j
Let zi,j denote the time series in the ith row and the jth column , i = 1 , . . . , M , j = 1 , . . . , N , where M ( N ) is the total number of rows ( columns ) in the array . Each time T i,j} . series zi,j has T i,j observations , ie , zi,j = {zi,j Notice that the length of different time series is not necessarily the same . Let R denote the number of row clusters , and C denote the number of column clusters . For example , in device fabrication of semiconductor manufacturing , the R row clusters are associated with different tools , which contain various number of chambers ; whereas the C column clusters are associated with different types of process variables , eg , the variables subject to Advance Process Control ( APC ) , the dependent variables , etc .
Let ˆzr , : denote the rth row cluster for r = 1 , . . . , R ; ˆz:,c denote the cth column cluster for c = 1 , . . . , C ; Φ1 denote the mapping from {zi,j} to {ˆzr,:} ( row cluster ) ; and Φ2 denote the mapping from {zi,j} to {ˆz:,c} ( column cluster ) . B . Problem Definition Given the above structured time series data , our goal is to simultaneously cluster the M × N time series into R row clusters and C column clusters , resulting in R× C clusters in total . In particular , the cluster assignment should satisfy the following two constraints .
1 ) Row Constraint ( RC ) : the time series in the same row should be assigned to the same row cluster ;
2 ) Column Constraint ( CC ) : the time series in the same column should be assigned to the same column cluster . Based on these constraints , ∀i = 1 , . . . , R , j = 1 , . . . , C , Φ1(zi,j ) = Φ1(zi,: ) , where zi , : denotes the time series on the ith row , and Φ2(zi,j ) = Φ1(zi,: ) , where z:,j denotes the time series on the jth column .
Notice that these constraints originate from device fabrication in semiconductor manufacturing , where the time series traditional collected from chambers in the same tool exhibit similar patterns due to their physical proximity ( constraint ( 1) ) , and the time series associated with process variables of the same type are similar to each other due to their control pattern ( constraint ( 2) ) . Therefore , time series clustering methods dealing with unstructured temporal data are not best suited for such problems , since they do not take these constraints into consideration . The problem setting is also different from existing co clustering/multi way clustering methods [ 4 , 1 , 18 , 6 ] , where the input is one or more matrices , ie , the elements on the two dimensional array are scalers instead of time series . C . The Proposed C Struts Framework t = L are the parameters , and i,j t
For each time series zi,j , we assume its current value at time stamp t can be regressed on the past values up to a maximum lag L : zi,j , where βi,j are IID random variables l for i = 1 , . . . , M , j = 1 , . . . , N , and t = 1 , . . . T i,j . Let L ]T , where ( ·)T denotes vector transpose . βi,j = [ βi,j In the initialization step , the parameters βi,j can be estimated by solving the following optimization problem .
1 , . . . , βi,j t−l + i,j
· zi,j l=1 βi,j l t
βi,j l
· zi,j t−l)2 + αR(βi,j ) t − L
( zi,j
βi,j = arg min
( 1 ) t l=1 where R(· ) is a regularizer on the parameters , eg , p norm of βi,j , and α is a positive parameter that balances between the mean squared error and the regularizer . Such optimization problem can be solve using ridge regression if R(βi,j ) = βi,j2 , Lasso [ 19 ] if R(βi,j ) = |βi,j| , elastic net [ 23 ] if R(· ) is a linear combination of both the 2 norm and the 1norm of βi,j , etc .
Based on the two constraints RC and CC , we assume that the joint probability of : ( 1 ) the parameters β , ( 2 ) the time series on the ith row zi, : , and ( 3 ) the time series on the jth column z:,j , can be approximated by the following auxiliary probability distribution . p(β , zi, : , z:,j ) ≈ q(β , zi, : , z:,j ) = µi,jp(ˆzr, : , ˆz:,c)p(zi,:|ˆzr,:)p(z:,j|ˆz:,c)p(β|zi,:)p(β|z:,j ) . ( 2 ) where Φ1(zi, : ) = ˆzr, : , Φ2(z:,j ) = ˆz:,c , and the value of the coefficient µi,j guarantees that q(· ) is a valid probability distribution , ie , µi,j =
β p(β|zi,:)p(β|z:,j ) .
Based on the auxiliary probability distribution q(· ) , the parameters β can be generated as follows . We first draw the row cluster ˆzr , : and the column cluster ˆz:,c from p(ˆzr, : , ˆz:,c ) ; based on these clusters , we then draw each row zi , : according to p(zi,:|ˆzr,: ) , and each column z:,j according to p(z:,j|ˆz:,c ) ; finally , we draw the parameters β based on both zi , : and z:,j according to µi,jp(β|zi,:)p(β|z:,j ) . It can be proven that q(· ) has the following property . LEMMA 3.1 [ Properties of q(· ) ] 1 ) The marginal probability of ˆzr , : ( ˆz:,c ) is the same under p(· ) and q(· ) . To be specific ,
1 q(ˆzr, : ) = p(ˆzr,: ) , q(ˆz:,c ) = p(ˆz:,c )
( 3 )
2 ) The conditional probability of zi , : ( z:,j ) given ˆzr , : ( ˆz:,c ) is the same under p(· ) and q(· ) . To be specific , q(zi,:|ˆzr, : ) = p(zi,:|ˆzr,: ) , q(z:,j|ˆz:,c ) = p(z:,j|ˆz:,c ) ( 4 ) 3 ) zi , : is conditionally independent of the column cluster ˆz:,c given the row cluster ˆzr, : ; z:,j are conditionally independent of the row cluster ˆzr , : given the column cluster ˆz:,c . To be specific , q(zi,:|ˆzr, : , ˆz:,c ) = q(zi,:|ˆzr, : ) q(z:,j|ˆzr, : , ˆz:,c ) = q(z:,j|ˆz:,c )
( 5 )
Proof . Omitted for brevity . From the above properties , we can see that the approximation probability q(· ) keeps the marginal probability of the row/column clusters , as well as the conditional probability of each row/column given a row/column cluster . Furthermore , the conditional independence in Equation ( 5 ) is consistent with both RC and CC . Therefore , we propose to construct a prototype for each row/column cluster based on q(· ) . To this end , ∀r , we first compute the posterior distribution of β given ˆzr , : as follows . q(β|ˆzr, : ) = q(β , ˆzr, : ) q(ˆzr, : ) zi,::Φ1(zi,:)=ˆzr , : z:,j :Φ2(z:,j )=ˆz:,c p(ˆzr, : )
ˆz:,c
ˆz:,c
=
= zi,::Φ1(zi,:)=ˆzr , : z:,j :Φ2(z:,j )=ˆz:,c q(β , zi, : , z:,j )
µi,jp(ˆz:,c|ˆzr,:)p(zi,:|ˆzr,:)p(z:,j|ˆz:,c )
· p(β|zi,:)p(β|z:,j ) Then for the rth row cluster , we define its prototype as the expected value of β given the row cluster , ie , ˆβ = Eq(β|ˆzr,:)(β ) . If both p(β|zi, : ) and p(β|z:,j ) follow a Gaussian distribution such that p(β|zi, : ) ∝ exp(− 1 ( β − βi,:)T ( β − βi,:) ) , ( β − β:,j)T ( β − β:,j) ) , where and p(β|z:,j ) ∝ exp(− 1 βi , : denotes the column average of βi,j , β:,j denotes the row average , σR and σC are both positive parameters , ie ,
2σ2 R
2σ2 C r , :
βi , : =
βi,j , β:,j =
1 M
βi,j
( 6 )
M i=1
ˆz:,c
Then , the row cluster prototype can be derived as follows . p(ˆz:,c|ˆzr,:)p(zi,:|ˆzr,:)p(z:,j|ˆz:,c ) r , : ˆβ
= zi,::Φ1(zi,:)=ˆzr , : z:,j :Φ2(z:,j )=ˆz:,c
· Eµi,j p(β|zi,:)p(β|z:,j )(β ) = p(ˆz:,c|ˆzr,:)p(zi,:|ˆzr,:)p(z:,j|ˆz:,c )
ˆz:,c zi,::Φ1(zi,:)=ˆzr , : z:,j :Φ2(z:,j )=ˆz:,c
· σ2
Cβi , : + σ2 R + σ2 σ2 C
Rβ:,j
( 7 )
N j=1
1 N
Similarly the column cluster prototype ˆβ
:,c can be obtained from the following equation .
:,c
ˆβ
=
ˆzr , : zi,::Φ1(zi,:)=ˆzr , : z:,j :Φ2(z:,j )=ˆz:,c
· σ2
Cβi , : + σ2 σ2 R + σ2 C
Rβ:,j p(ˆzr,:|ˆz:,c)p(zi,:|ˆzr,:)p(z:,j|ˆz:,c )
( 8 )
Notice that the row and column cluster prototypes in Equations ( 7 ) and ( 8 ) are not centroids . Instead , they are weighted combination of the row and column average of the parameters , where the weights are obtained via the q(· ) .
For the conditional probability of each row/column given its row/ column cluster , we propose to estimate its value as follows . r , :
) )
( 9 ) p(zi,:|ˆzr, : ) ∝ exp(− 1 2σ2 R p(z:,j|ˆz:,c ) ∝ exp(− 1 2σ2 C r , :
( βi , : − ˆβ ( β:,j − ˆβ
)T ( βi , : − ˆβ )T ( β:,j − ˆβ
:,c
:,c
) )
Together with the fact that and
( 10 ) zi,::Φ1(zi,:)=ˆzr , : p(zi,:|ˆzr, : ) = 1 z:,j :Φ1(z:,j )=ˆz:,c p(z:,j|ˆz:,c ) = 1 , we can obtain the To estimate the joint probability of each row/column cluster pair , we use the empirical probability mass of the time series that have been mapped to the corresponding row/column cluster . To be specific , exact value of these conditional probabilities .
|zi,j|Φ1(zi,j ) = ˆzr, : , Φ2(zi,j ) = ˆz:,c| p(ˆzr, : , ˆz:,c ) =
( 11 ) where |zi,j|Φ1(zi,j ) = ˆzr, : , Φ2(zi,j ) = ˆz:,c| denotes the number of times series that have been mapped to the rth row cluster and the cth column cluster .
M × N
Based on the above discussion , the optimal mapping func tions Φ1 and Φ2 should maximize the following objective ,
βi , : − Eq(β|ˆzr,:)(β)2
R C r=1
+ min Φ1,Φ2
Ep(
Φ1(zi,:)=ˆzr , :
β:,j − Eq(β|ˆz:,c)(β)2 )
( 12 ) c=1
Φ2(z:,j )=ˆz:,c where the outermost expectation is with respect to the true joint probability p(· ) , and the prototypes for row/column clusters are with respect to the auxiliary probability q(· ) . D . The Proposed Algorithm
The proposed algorithm is summarized in Algorithm 1 . In Step 1 to 5 , we compute the parameters βi,j for each time series in the two dimensional array ; in Step 6 to 11 , we compute the row/column average of the parameters βi,:/β:,j ; in Step 12 , we randomly assign the rows to the R row clusters , and assign the columns to the C column clusters ; then we repeat Step 14 to 25 until convergence ( not to exceed niter times ) , where in Step 14 to 19 , we compute the row/column :,c , and in Step 20 to 25 , we re assign cluster prototype ˆβ each row/column to the closest row/column cluster prototype . r,:/ˆβ
E . Discussion
Finally , in this subsection , we discuss alternative features and extensions for the proposed C Struts algorithm . l=1 βi,j l
· zi,j t−l + i,j t +L is the expectation of zi,j , and γi,j l t = ci,j +L
1 ) Alternative Features for Time Series : In Algorithm 1 , we use the parameters βi,j , i = 1 , . . . , M , j = 1 , . . . , N , to represent the time series in the two dimensional array , which is obtained from the Auto Regressive ( AR ) model . Alternatively , we could use the Auto Regressive Moving Average ( ARMA ) · l=1 γi,j model , ie , zi,j l i,j t−l , where ci,j are additional parameters . The rest of the algorithm applies on the concatenation of βi,j . If all the time series in the two dimensional array are of the same length , we could also use PCA or DFT to extract the features , both of which have been used in time series clustering . Algorithm 1 C Struts Algorithm Input : zi,j , i = 1 , . . . , M , j = 1 , . . . , N , R , C , niter Output : Φ1 , Φ2 1 : for i = 1 to M , j = 1 to N do 2 :
Compute the parameters βi,j by solving Equation ( 1 ) using ridge regression , Lasso , etc ; and γi,j l l
Compute the row average βi , : using Equation ( 6 ) ;
Compute the column average β: , : using Equation ( 6 ) ;
3 : end for 4 : for i = 1 to M do 5 : 6 : end for 7 : for j = 1 to N do 8 : 9 : end for 10 : Randomly initialize Φ1 and Φ2 ; 11 : for k = 1 to niter do for r = 1 to R do 12 : 13 :
Compute the row cluster prototype ˆβ tion ( 7 ) ; r , : using Equa
Compute the column cluster prototype ˆβ Equation ( 8 ) ;
:,c using
Update Φ1(zi, : ) ← arg minˆzr , : βi , : − ˆβ r,:2 ;
Update Φ2(z:,j ) ← arg minˆz:,c β:,j − ˆβ
:,c2 ; end for for c = 1 to C do
14 : 15 : 16 : end for for i = 1 to M do end for for j = 1 to N do
17 : 18 : 19 : 20 : 21 : 22 : 23 : 24 : end for end for
2 ) Extension to Multi dimensional Arrays : The proposed C Struts framework can be naturally extended to multidimensional arrays . For example , if the underlying structure is a three dimensional array instead of a matrix , the auxiliary probability distribution can be defined as follows . q(β , zi,:, : , z:,j, : , z:,:,k ) = µi,j,kp(ˆzr,:, : , ˆz:,c, : , ˆz:,:,o)p(zi,:,:|zr,:,:)p(z:,j,:|z:,c, : ) · p(z:,:,k|z:,:,o)p(β|zi,:,:)p(β|z:,j,:)p(β|z:,:,k ) the joint probability of clusters It consists of three parts : the conditional probability of a on the three dimensions ; single element ( eg , a row ) given the cluster on a certain dimension ; and the conditional probability of the parameters given elements on different dimensions . Based on the auxiliary probability distribution , we could modify the prototypes on the 3 dimensions accordingly , based on which we could repeatedly updated the cluster membership using Algorithm 1 .
IV . EXPERIMENTAL RESULTS
In this section , we test the performance of the proposed CStruts algorithm on benchmark and manufacturing data sets . Since C Struts is the first algorithm for co clustering structural temporal data , we compare its performance with existing methods for time series clustering , including CLDS [ 10 ] , KMeans on the vectors βi,j , and Co clustering based on the pair wise similarity between the time series in each row and each column . Different from C Struts , neither CLDS nor KMeans take into consideration the structural information associated with the underlying two dimensional array ; although Co clustering leverages the structural information , it ignores the detailed information in each time series since it only uses the pair wise similarity . Notice that all the algorithms are given the same number of clusters as input , ie , for C Struts and Coclustering , the number of row/column clusters is R/C ; and for CLDS and K Means , the number of clusters is R × C . A . Manufacturing Data
In this subsection , we test the performance of C Struts on a data set collected from semiconductor manufacturing . The data set corresponds to an etching step with 19 process variables that forms 3 categories based on the process control practice : ‘gas and pressure’ , ‘power’ , and ‘others’ . It is concurrently running in 5 tools , each having 6 chambers . Here , the goal is to identify similar chamber and process variable behaviors . Figure 1 shows the results on this data set . In particular , Figure 1(a ) presents the co clustering results , where the various colors indicate the ground truth , and the rows/columns are re arranged so that rows/columns assigned to the same row/column cluster are grouped together . From this figure , we can see that the 30 chambers have been correctly assigned to the row cluster that corresponds to the tool that the chambers belong to . This is consistent with the assumption that chambers behave similarly in the same tool and differently across various tools . On the other hand , of the 3 column clusters generated by C Struts , the first cluster corresponds to the ‘other’ category , and it mistakenly includes process variables from the ‘gas and pressure’ category . This might be due to the nature of the ‘other’ category , which mixes process variables of different types and is less well defined as the ‘gas and pressure’ or the ‘power’ category . Figure 1(b ) shows the comparison results on 10 wafers , which clearly demonstrates the superiority of C Struts over the competitors . B . Benchmark Data
Although the proposed C Struts algorithm is designed for semiconductor manufacturing , it can also be used in other applications . In this subsection , we test its performance on
REFERENCES all data sets in the ‘data1’ category from UCR Time Series Classification/Clustering Page1 . To be specific , we use the known classes in these data sets to form the row clusters , and form the column clusters based on various sampling frequencies . We compare all the methods in terms of the Jaccard index values associated with both row and column clustering at various sampling frequencies , and present the results in Figure 2 . From these figures , we can see that the performance of C Struts is better than the others in most cases .
( a ) Clustering results using C Struts .
( b ) Comparison results Fig 1 : Clustering results on semiconductor data set .
Furthermore , we provide the collective comparison results of C Struts and CLDS in Figure 3 . From this figure , we can see that the proposed C Struts algorithm outperforms CLDS in the majority of the data sets . The results of K Means are omitted due to the similarity with Co clustering .
Fig 3 : Comparison of C Struts and CLDS on all data sets in the ‘data1’ category .
V . CONCLUSION
In this paper , motivated by semiconductor manufacturing , we study a novel problem of co clustering structural temporal data . In this problem , we are given as input a two dimensional array consisting of multiple time series , and the goal is to simultaneously cluster both the rows and the columns . This problem is different from traditional time series clustering , which targets unstructured time series data , and multi way clustering , which assumes the input matrix consists of scalers . To address this problem , we propose a general framework named C Struts . It information as constraints on the cluster membership , and uses an auxiliary probability distribution to obtain prototypes for each row/column cluster . We also present an iterative algorithm to assign each time series to the closest row/column cluster based on the distance to the prototypes . Experimental results on various data sets demonstrate the effectiveness of C Struts . interprets the structural
1http://wwwcsucredu/∼eamonn/time_series_data/
[ 1 ] D . Chakrabarti , S . Papadimitriou , D . S . Modha , and C . Faloutsos . Fully automatic cross associations . In KDD , pages 79–88 , 2004 .
[ 2 ] H . J . Chang , D . Sung , P . J . Kim , and J . Y . Choi . Spatiotemporal pattern modeling for fault detection and classification in semiconductor manufacturing . IEEE Trans . on Semiconductor Manufacturing , 25:72–82 , 2012 .
[ 3 ] Y . Chen , B . Hu , E . J . Keogh , and G . E . A . P . A . Batista . Dtw d : time series semi supervised learning from a single example . In KDD , pages 383–391 , 2013 .
[ 4 ] I . S . Dhillon , S . Mallela , and D . S . Modha .
Information theoretic co clustering . In KDD , pages 89–98 , 2003 .
[ 5 ] B . Gao , T Y Liu , X . Zheng , Q . Cheng , and W Y Ma . Consistent bipartite graph co partitioning for star structured high order heterogeneous data co clustering . In KDD , pages 41–50 , 2005 . [ 6 ] J . He , H . Tong , S . Papadimitriou , T . Eliassi Rad , C . Faloutsos , Pack : Scalable parameter free clustering In SDM Workshop on Link Analysis , and J . Carbonell . on k partite graphs . Counterterrorism and Security , 2009 .
[ 7 ] B . Hu , Y . Chen , and E . J . Keogh . Time series classification In SDM , pages 578–586 , under more realistic assumptions . 2013 .
[ 8 ] A . Johnson and S . McLoone . A dynamic sampling methodology In 29th International for within product virtual metrology . Manufacturing Conf . , 2012 .
[ 9 ] D . Kurz , C . D . Luca , and J . Pilz . Monitoring virtual metrology reliability in a sampling decision system . In Conf . on Automation Science and Engineering , 2013 .
[ 10 ] L . Li and B . A . Prakash . Time series clustering : Complex is simpler! In ICML , pages 185–192 , 2011 .
[ 11 ] B . Long , Z . M . Zhang , X . Wu , and P . S . Yu . Spectral clustering for multi type relational data . In ICML , pages 585–592 , 2006 . [ 12 ] S . C . Madeira and A . L . Oliveira . Biclustering algorithms for biological data analysis : A survey . IEEE/ACM Trans . Comput . Biology Bioinform . , 1(1):24–45 , 2004 .
[ 13 ] G . Newell , N . Bekhazi , and R . Morgan . Optimizing storage and i/o for distributed processing on enterprise and high performance compute ( hpc ) systems for mask data preparation software ( cats ) . Technical report , Synopsys , Inc . , 2007 .
[ 14 ] S . Papadimitriou , J . Sun , and C . Faloutsos . Streaming pattern In VLDB , pages 697–708 , discovery in multiple time series . 2005 .
[ 15 ] T . Rakthanmanon , B . J . L . Campana , A . Mueen , G . E . A . P . A . Batista , M . B . Westover , Q . Zhu , J . Zakaria , and E . J . Keogh . Searching and mining trillions of time series subsequences under dynamic time warping . In KDD , pages 262–270 , 2012 . [ 16 ] T . Rakthanmanon , B . J . L . Campana , A . Mueen , G . E . A . P . A . Batista , M . B . Westover , Q . Zhu , J . Zakaria , and E . J . Keogh . Searching and mining trillions of time series subsequences under dynamic time warping . In KDD , pages 262–270 , 2012 . [ 17 ] J . Sun , C . Faloutsos , S . Papadimitriou , and P . S . Yu . Graphscope : parameter free mining of large time evolving graphs . In KDD , pages 687–696 , 2007 .
[ 18 ] R . Tibshirani . Regression shrinkage and selection via the lasso . Journal of the Royal Statistical Society ( Series B ) , 58:267–288 , 1996 .
[ 19 ] L . Wei , E . J . Keogh , X . Xi , and M . Yoder . Efficiently finding unusual shapes in large image databases . Data Min . Knowl . Discov . , 17(3):343–376 , 2008 .
[ 20 ] B K Yi , N . Sidiropoulos , T . Johnson , H . V . Jagadish , C . Faloutsos , and A . Biliris . Online data mining for co evolving time sequences . In ICDE , pages 13–22 , 2000 .
[ 21 ] J . Zakaria , A . Mueen , and E . J . Keogh . Clustering time series using unsupervised shapelets . In ICDM , pages 785–794 , 2012 . [ 22 ] H . Zou and T . Hastie . Regularization and variable selection via the elastic net . Journal of the Royal Statistical Society : Series B ( Statistical Methodology ) , 67(2):301–320 , 2003 .
( a ) 50words
( b ) Two Patterns
( c ) Beef
( d ) MedicalImages
( e ) WordsSynonyms
( f ) CinC ECG torso
( g ) Symbols
( h ) Cricket X
( i ) Cricket Y
( j ) Cricket Z
( k ) DiatomSizeReduction
( l ) OSULeaf
( m ) SwedishLeaf
( n ) FISH
( o ) FaceAll
( p ) yoga
( q ) FacesUCR
( r ) Trace
( s ) Haptics
( t ) InlineSkate
Fig 2 : Comparison on a subset of benchmark data sets .
