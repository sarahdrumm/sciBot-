2014 IEEE International Conference on Data Mining
A Gaussian Process Model for Knowledge
Propagation in Web Ontologies
Pasquale Minervini , Claudia d’Amato , Nicola Fanizzi , Floriana Esposito
Department of Computer Science Universit`a degli Studi di Bari Aldo Moro , Italy
{firstnamelastname}@unibait
Abstract—We consider the problem of predicting missing class memberships and property values of individual resources in Web ontologies . We first identify which relations tend to link similar individuals by means of a finite set Gaussian Process regression model , and then efficiently propagate knowledge about individuals across their relations . Our experimental evaluation demonstrates the effectiveness of the proposed method .
I .
INTRODUCTION
Standard query answering and reasoning services for the Semantic Web [ 1 ] ( SW ) rely on deductive inference . However , purely deductive approaches may suffer from limitations , owing to : i ) the complexity of reasoning tasks on expressive representations , ii ) the inherent incompleteness of SW knowledge bases ( KBs ) , and iii ) the presence of logically conflicting knowledge fragments . Deciding on the truth of specific facts ( assertions ) in SW KBs requires to take into account the openworld semantics adopted when reasoning in this context : a failure on deciding the truth value of a given fact does not imply that such fact is false , but rather that its truth value cannot be deductively inferred from the KB ; this differs from the Negation As Failure , commonly used with databases . Other issues are related to the distributed nature of the data across the Web : mutually conflicting pieces of knowledge may lead to flawed inferences and contradictory answers . Estimating the truth value of an assertion can be cast as a statistical inference problem : individual resources in an ontology can be regarded as statistical units , and their properties can be statistically inferred , even when they cannot be deduced from the knowledge base . Several approaches have been proposed in the SW literature ( see [ 2 ] for a survey ) . A major issue with the methods proposed so far is that the induced statistical models are either difficult to interpret and understand by experts and to integrate in logic based SW infrastructures , or computationally impractical when used on real KBs .
Related Work : A variety of methods have been proposed for predicting the truth value of assertions in Web ontologies . They include generative models , kernel methods ( eg [ 3 ] and [ 4] ) , and matrix or tensor factorization methods ( eg [ 5 ] and [ 6] ) . An issue with existing methods is that they either rely on a possibly expensive search process , or induce statistical models that are often not easy to interpret by human experts . Kernel methods induce models in a high dimensional feature space implicitly defined by a kernel function . The underlying kernel function itself usually relies on purely syntactic features of the neighborhood graphs of two individual resources , such as their common subtrees [ 3 ] , or isomorphic subgraphs [ 4 ] : in both cases , there is not necessarily a direct interpretation of such features in terms of domain knowledge . Latent variable models and matrix or tensor factorization methods such as [ 5 ] and [ 6 ] try to explain the observations in terms of latent classes and attributes , which also may be non trivial to interpret in terms of the domain ’s vocabulary .
Contribution : We propose a transductive inference method for predicting the truth value of assertions , which is based on the following intuition : examples that are similar in some aspects tend to be linked by specific relations . Our method aims at identifying such relations , and permits the efficient propagation of information along chains of related entities . It is especially useful with real world shallow ontologies , ie those with a relatively simple fixed terminology and populated by very large amounts of data , where related individuals tend to influence each other , such as social or citation networks . In particular , this paper makes the following contributions :
• A method for efficiently propagating knowledge among similar examples : it leverages a similarity graph which plays a critical role in the knowledge propagation process . • A method for learning an optimal similarity graph for a given prediction task , by leveraging a set of semantically heterogeneous relations among examples .
This paper is organized as follows : in Sect . II we introduce the problem of transductive learning in the context of semantic knowledge bases ; in Sect . III we discuss the proposed method , which is based on the efficient propagation of knowledge among similar examples , and address the problem of identifying which relations are likely to link similar examples ; in Sect . IV we provide empirical evidence for the effectiveness of the proposed method ; in Sect . V we summarize this work .
II . TRANSDUCTIVE LEARNING WITH WEB ONTOLOGIES We assume the knowledge base is encoded in a syntactic variant of some Description Logic [ 7 ] ( DL ) . Basic elements are atomic concepts NC = {C , D , . . .} interpreted as subsets of a domain of objects ( eg Person or Article ) , and atomic roles NR = {R , S , . . .} interpreted as binary relations on such a domain ( eg friendOf or authorOf ) . Domain objects are represented by individuals NI = {a , b , . . .} , each associated to a domain entity . Specifically , we consider KBs in the OWL 2 language 1 , which has its theoretical foundations in DLs : concepts and roles are referred to as classes and properties , respectively . A DL knowledge base ( KB ) K = .T ,Afi is composed by two main components : a TBox T , which contains terminological axioms , and an ABox A , which contains ground axioms ( assertions ) about individuals . In the following , we
1OWL 2 W3C Recommendation : http://wwww3org/TR/owl overview/
1550 4786/14 $31.00 © 2014 IEEE DOI 101109/ICDM201483
929 denote the set of individuals occurring in A as Ind(A ) . Let Q be a query concept and a an individual in a KB K : Instance Checking consists in deciding whether K |= Q(a ) holds . SW inference services make the Open World Assumption ( OWA ) , ie it might happen that K '|= Q(a ) and K '|= ¬Q(a ) , where ¬Q is the complement of Q . Given a ( infinite ) set of variables NV , a Conjunctive Query ( CQ ) q is a conjunction of concept ) , with v , v . ∈ NV ∪ NI , built on or role atoms C(v ) or R(v , v . the signature of K . A binding of the variables wrt some model of K determines a result via the value of answer variables .
In this work we focus on a transductive learning problem : given a set of labeled and unlabeled examples , the problem consists in learning a labeling function for a given target class that can be used for predicting whether individuals belong to a class C ( positive class ) or to its complement ¬C ( negative class ) when this cannot be inferred deductively . Formally : Definition 2.1 ( Transductive Class Membership Learning ) : Given : a target class C in a KB K , and a set of examples X ⊆ Ind(A ) , partitioned into :
• positive examples : X+ . {a ∈ X | K |= C(a)} ; • negative examples : X− . {a ∈ X | K |= ¬C(a)} ; • neutral ( unlabeled ) examples :
X0 . {a ∈ X | a '∈ X+ ∧ a '∈ X−} .
: X )→ {−1 , +1} , where +1 Find : a labeling function f∗ ( resp . −1 ) corresponds to the positive ( resp . negative ) class . III . A GAUSSIAN PROCESS REGRESSION MODEL FOR
KNOWLEDGE PROPAGATION
In this section , we discuss a new method , named Gaussian Process Knowledge Propagation ( GPKP ) , for solving the prediction problem in Def . 2.1 in the context of Web ontologies . In Sect . III A we show that a similarity graph between examples can be used to define a finite set Gaussian Process over their labels , which allows to efficiently propagate class information . In Sect . III B we propose a solution to the problem of learning the similarity graph . In Sect . III C we discuss how to retrieve relations among examples expressed as conjunctive queries .
A . Transductive Learning as an Optimization Problem
We now propose a solution to the transductive learning problem in Def . 21 Following Sect . II , we aim at finding a labeling function f∗ defined over examples X , which is both consistent with the training labels , and varies smoothly among similar individuals ; we assume that a similarity graph over examples in X has already been provided . Such a graph is represented by its symmetric adjacency matrix W ∈ R n×n , with n . |X| , such that Wij ≥ 0 if xi , xj ∈ X are similar , and 0 otherwise ; for simplicity , we assume that Wii = 0 . Formally , each labeling function can be represented as a finite size vector f ∈ {−1 , +1}n , where fi is the label for the i th element in the set of examples X . According to [ 8 ] , labels can be enforced to vary smoothly among similar individuals by means of the following penalty function defined over f :
E(f ) . 1 2
Wij(fi − fj )
2
+ i=1 j=1 i=1 n . n . n . f 2 i ,
( 1 )
930 where the first term enforces the labeling function to vary smoothly among similar examples , and the second term is a fi2 regularizer ( with weight > 0 ) over f . Let L . X+ ∪ X− and U . X0 represent labeled and unlabeled examples , respectively . In [ 8 ] , authors propose a continuous relaxation of f , where f ∈ [ −1 , +1 ] n also encodes a measure of the classification confidence . This allows for a simple , closed form solution to the problem of minimizing E(· ) for a given value of fL , providing a solution to the problem in Def . 21 Note that the penalty function E(· ) in Eq 1 can be rewritten as : ( 2 )
E(f ) = f T
( L + I)f ,
' j=1 Wij and where D is a diagonal matrix such that Dii = L . D − W is the graph Laplacian of W . Reordering the matrix W , the graph Laplacian L and the vector f wrt the membership to L and U , they can be rewritten as : ff
'
LLL LLU LU L LU U
WLL WLU WU L WU U
, f =
, L =
W = The problem of finding a labeling f∗ U for unlabeled examples which minimizes the penalty function E(· ) for a given value for fL has the following closed form solution : −1WU LfL . f∗ U = ( LU U + I )
. ( 3 )
( 4 ) ff
' ff fL fU fi|X|
Efficiency : A solution for Eq 4 can be computed efficiently in nearly linear time . Indeed computing f∗ U can be reduced to solving a linear system in the form Ax = b , with A = ( LU U + I ) , b = WU LfL and x = f∗ U . A linear system Ax = b with A ∈ R n×n can be solved in nearly linear time if the coefficient matrix A is symmetric diagonally dominant2
( SDD ) . An algorithm for solving a SDD linear system is discussed in [ 9 ] : its time complexity is ≈ O m log , where m is the number of non zero entries in A . In Eq 4 , the matrix ( LU U + I ) is SDD , since LU U is a principal submatrix of the graph Laplacian L which is also SDD [ 10 ] .
2 n
1
B . A Relations based Similarity Graph
The method for propagating knowledge across similar examples discussed in Sect . III A relies on a similarity graph , represented by its adjacency matrix W . The underlying assumption in this work is that some relations among individuals in the KB might encode a similarity relation wrt a specific target property or class : identifying such relations allows to propagate information across similar individuals . In literature , this phenomenon is referred to as homophily : related entities tend to influence each other , and some relations ( eg friendship in a social network ) can encode some form of similarity wrt a set of properties ( such as hobbies or musical tastes ) . However , depending on the learning task , not all relations are equally effective at encoding similarities between examples ( eg quiet people tend to prefer talkative friends and vice versa ) .
In this work , we represent each relation type by means of a symmetric adjacency matrix ˜W , such that ˜Wij = ˜Wji = 1 iff either the relation rel(xi , xj ) or rel(xj , xi ) hold in the ontology , and 0 otherwise ; rel represents a type of relation between examples ( such as friendship or co authorship ) . For simplicity , we assume that ˜Wii = 0,∀i . Given a set of matrices 2A matrix A is SDD iff A is symmetric and ∀i : Aii ≥ . i.=j |Aij| .
W . { ˜W1 , . . . , ˜Wr} , one for each relation type , we can define W as a linear combination of matrices in W : using the property ∂(X−1 ) = −X−1(∂X)X−1 , where ˜Li is the Laplacian of the graph corresponding to the matrix ˜Wi .
W .
˜Wi , with μi ≥ 0,∀i
μi
( 5 )
C . Retrieving Meaningful Relations Between Examples r . i=1 where μi , is a parameter representing the weight of ˜Wi in the adjacency matrix of the similarity graph W . Learning as Inverse Covariance Estimation : Let us consider the continuous relaxation of the penalty function E(· ) in Eq 2 ( with f ∈ R n ) . It corresponds to the energy function of ( the following probability density p over f : − 1 ff 2
2|Σ|− 1 − 1
E(f )
)
( 6 ) p(f ) = ( 2π ) 0 , ( L + I )
= N
2 exp −1
.
The probability density function in Eq 6 defines a finite set Gaussian process [ 11 ] f ∼ N ( 0 , Σ ) , where Ω = ( L + I ) and Σ = Ω−1 are respectively its inverse covariance ( or precision ) and covariance matrix , and |Σ| indicates the determinant of Σ . The covariance matrix and its inverse fully determine the independence relations among variables in a multivariate Gaussian distribution [ 11 ] : if Ωij '= 0 , then there is an edge between variables fi and fj in the minimal I map Gaussian Markov Random Field ( GMRF ) of p . The parametric form of W is fully specified by the hyperparameters μ in Eq 5 , which may be unknown . Estimating the inverse precision matrix in a GMRF given a set of observations is referred to as inverse covariance estimation [ 12 ] : in this work , we estimate the hyperparameters by maximizing a regularized marginal likelihood [ 11 ] of fL induced by the probability density p in Eq 6 . Following [ 12 ] , we add a fi1 norm regularization term for controlling the sparsity of hyperparameters ( and dealing with the curse of dimensionality ) . To comply with noisy training labels , we also assume independent and identically distributed Gaussian noise [ 11 ] with variance σ2 ≥ 0 . The resulting set of hyperparameters Θ . {μ , , σ2} fully determines a probability density p , and we estimate Θ by maximizing the following fi1regularized log marginal likelihood of fL : log 2π− λ||Θ||1 , log |KL|− 1 L fL − 1 L(Θ | fL ) = − 1 L K−1 f T 2 2 −1 is the covariance matrix ( Σ has a block where Σ = ( L+ I ) structure analogue to the one in Eq 3 ) , KL . ( ΣLL + σ2I ) , |KL| indicates the determinant of KL , and λ ≥ 0 controls the sparsity ( ie the complexity ) of the solution . We propose using gradient based optimization methods for finding the parameters ΘM L maximizing the marginal log likelihood L(Θ | fL ) . The subgradient of L(Θ | fL ) wrt a hyperparameter θ ∈ Θ can be calculated as follows [ 11 ] :
2
' ααT − K−1 ff
∂KL
∂L(Θ | fL )
1 2
Tr
∂θ
= where α = K−1 L fL and we assume that 0/0 = 0 . The partial derivatives of KL wrt hyperparameters in Θ , according to the parametrization of W proposed in Eq 5 , are :
∂θ
L
' ff
− λ
θ√ θ2
, fi fl
Σ˜LiΣ
,
LL
=
∂Σ ∂μi
∂KL ∂μi ∂KL
= − ∂ = − [ ΣIΣ]LL and
LL
∂KL ∂σ2 = I ,
931
In this work , we consider the relations encoded by CQs for the construction of the similarity graph . However , the number of relations that can be expressed using CQs is very large : to overcome this problem , in empirical evaluations ( see Sect . IV ) , we considered two types of such relations holding between pairs of examples a , b ∈ X : • Simple relations , ie those corresponding to CQs in the • Composite relations , corresponding to CQs in the form : ∃z.(r(z , a ) ∧ r(z , b) ) , form r(a , b ) , where r ∈ NR is an atomic role ;
∃z.(r(a , z ) ∧ r(b , z ) ) where r ∈ NR is an atomic role and z ∈ NV is a variable . Several efficient query answering services can be used for retrieving complex relations holding among examples . In particular , CQs ( see Sect . II ) can be expressed in the SPARQLDL [ 13 ] query language . SPARQL DL seems particularly convenient for the task : it is a specialization of SPARQL , sharing its syntax and specific for OWL ’s Direct Model Theoretic Semantics3 ) . SPARQL DL queries generalize CQs , as they admit variables in place of property names , thus answering multiple CQs at once , and non distinguished variables , ie those that are bound to entities that need not be interpreted as specific individuals of the queried ontology . or
Using SPARQL DL queries for retrieving complex relations between examples is particularly convenient : a single SPARQL DL query can answer a set of CQs , thanks to the use of variables in place of role names . When describing the outcome of empirical evaluations , we will use the following short hand notations to concisely describe the relations retrieved during the learning process : rel1 ◦ rel
2 ( a , b ) ≡ ∃z.(rel1(a , z ) ∧ rel2(z , b) ) , −1 1 ◦ rel2(a , b ) ≡ ∃z.(rel1(z , a ) ∧ rel2(b , z) ) , −1 rel where rel1 , rel2 ∈ NR , a , b ∈ NI and z ∈ NV .
D . Summary of the Method
The proposed method , named Gaussian Process Knowl edge Propagation ( GPKP ) , can be summarized as follows :
1 ) Retrieve ( possibly complex ) relations among examples in X using SPARQL DL queries , and then use them to create a set of adjacency matrices W = { ˜W1 , . . . , ˜Wr} . 2 ) Learn the hyperparameters by maximizing the regularized marginal log likelihood of labeled examples in Eq III B : ( 7 ) 3 ) Use the learned parameters ΘM L = {μ , , σ2} to find the
ΘM L = arg max Θ
L(Θ | fL ) . most likely labels for unlabeled examples fU : U = E [ fU | fL,W , ΘM L ] = ΣU LΣ−1 f∗
LLfL ,
, and L is the graph where Σ = Laplacian of the learned similarity graph with adjacency matrix W =
−1 + σ2I ˜Wi .
( L + I ) i=1 μi ffi fir ffl
3http://wwww3org/TR/owl2 direct semantics
TABLE I : Ontologies considered in the experiments
Ontology
DL Lang . AIFB PORTAL [ 3 ] ALEHO(D ) ALCH ALI(D )
DBPEDIA 3.9 [ 14 ] Frag . BGS [ 4 ]
#Axioms 268540 78795 825133
#Inds . 44328 16606 87555
#Props .
285 132 154
IV . EMPIRICAL EVALUATION
The method discussed in Sect . III was experimentally evaluated in comparison with other approaches proposed in the literature on a variety of assertion prediction problems . Sources and datasets are available at https://codegooglecom/p/gpkp/ Ontologies : We considered three real , shallow ontologies : the AIFB PORTAL Ontology 4 , the DBPEDIA 3.9 Ontology [ 14 ] and the BRITISH GEOLOGICAL SURVEY ( BGS ) Ontology 5 . AIFB PORTAL models the key concepts ( and relations ) within a research community , BGS represents knowledge collected by the British Geological Survey , and DBPEDIA contains structured information extracted from Wikipedia . The characteristics of these ontologies are outlined in Tab . I .
Experimental Setting : GPKP is summarized in Sect . III D . for solving the opWe used Projected Gradient Ascent timization problem in Eq 7 , jointly with an intermediate line search to assess the step size . In each learning the L1 regularization parameter λ was selected via task , cross validation within the training set ( with λ ranging in −1 , . . . , 102} ) . Before each experiment , all λ ∈ {0.0 , 10 −2 , 10 knowledge inherent to the target class was removed from the ontology . Following the related evaluation procedures in [ 3 ] , [ 4 ] , members of the target concepts were considered as positive examples , while an equal number of negative examples was randomly sampled from unlabeled examples . Remaining instances ( ie neither positive nor negative ) were considered as neutral ( or unlabeled ) examples .
Results are reported in terms of Area Under the PrecisionRecall Curve ( AUC PR ) , a measure to evaluate rankings also used in eg [ 6 ] . In each experiment , we considered the problem of predicting the membership of examples to several classes ; for each of such classes , we performed a 10 fold cross validation ( CV ) , and report the average AUC PR obtained using each of the considered methods . We used the same 10folds partitioning across experiments related to each of the datasets ; for such a reason , we report statistical significance tests using a paired , non parametric difference test ( Wilcoxon T test ) . We also report diagrams showing how using a limited quantity of randomly sampled labeled training instances ( ie 10 % , 30 % , 50 % , . . . , a plausible scenario for real world settings with limited labeled training data ) , and using the remaining examples for testing , affects the resulting AUC PR values .
We compare GPKP with state of the art approaches proposed for learning from ontological KBs . We considered two kernel methods : Soft Margin SVM ( SM SVM ) and Kernel Logistic Regression ( KLR ) , jointly with different kernel functions suited for ontological KBs . We also considered two relational prediction models , namely SUNS [ 5 ] and RESCAL [ 6 ] . The RDF graph used by both kernels methods and relational
4http://wwwaifbkitedu/web/Wissensmanagement/Portal 5http://databgsacuk/ , as of March 2014 prediction models was materialized as follows : all .s , p , ofi triples were retrieved by means of SPARQL DL queries ( where p was either an object or a data type property ) together with all direct type and direct sub class relations . In our experiments , we used the Intersection SubTree [ 3 ] ( IST ) and the WeisfeilerLehman [ 4 ] ( WL ) kernels for ontological KBs . For each kernel/algorithm and each learning task , parameters have been selected via 10 fold CV . IST kernel parameters were ranging in d ∈ {1 , 2 , 3 , 4} and λist ∈ {0.1 , 0.3 , . . . , 0.9} , and WL kernel parameters in d , h ∈ {1 , 2 , 3 , 4} ( where d is the depth of the neighborhood graph ) . In SM SVM , in order to obtain a ranking among instances ( provided by continuous labels f in GPKP ) , we applied the logistic function s to the decision boundary f instead of the sign function , which is commonly used in the classification context ( thus obtaining s(f ( · ) ) : X → [ 0 , 1] ) . −4 , . . . , 104 , 106} , while in In SM SVM , C ∈ {0.0 , 10 KLR the weight λk associated to the L2 regularizer was found considering λk ∈ {10 −3 , . . . , 104} . The SUNS relational prediction model relies on a low rank approximation of the matrix representing the relational multigraph . Parameters were selected by means of a 10 fold CV within the training set by grid optimization , with t ∈ {2 , 4 , 6 , . . . , 24} and λs ∈ {0 , 10 −1 , . . . , 106} . In RESCAL , each evaluation for the regularization parameters t and λr requires a tensor factorization step , thus model selection may be unfeasible for large domains . Also , factorized tensor representations are dense , thus the proposed approach might become too memory demanding for large values of t . Each experiment with RESCAL used the ALS algorithm [ 6 ] .
−6 , 10 −4 , 10
−2 , 10
AIFB PORTAL Ontology : Similarly to other experiments conducted on this ontology ( such as [ 3 ] and [ 4] ) , the learning task consisted in predicting the affiliations of AIFB staff members to research groups . Specifically , in a set of 316 examples ( each representing a researcher in the ontology ) , the task consisted in predicting missing affiliations to 5 distinct research groups . Due to the computational cost of RESCAL , the number of iterations for the ALS algorithm was fixed to 8 and the graph was composed only by statistical units and their immediate neighborhoods ; parameter selection was performed via 10 fold CV using the training set , with t ∈ {12 , 16 , . . . , 32} and λr ∈ {10
−4 , 1} .
−8 , 10
Fig 1 summarizes the AUC PR results on the research group affiliation prediction task , obtained via 10 fold CV ( one per research group , in a one versus all setting ) . The plot shows average AUC PR values describes results obtained with an increasing number of training examples , and leaving the rest to the test : error bars ( pictured horizontally ) represent twice the standard deviation . In general , results slightly varied among research groups . The proposed method ( GPKP ) yields significantly higher AUC PR values than those observed with other methods , where statistical significance was assessed by a Wilcoxon T test with p < 005 We also compared GPKP with its variant which does not make use of a sparsity enforcing L1 regularizer , denoted GPKP ( λ = 0 ) . Results provided by GPKP were significantly higher than those observed with GPKP ( λ = 0 ) , showing how enforcing sparsity in the parameters vector μ can be beneficial to the learning task . GPKP can also be used to elicit new knowledge on a domain : Tab . II shows a sample of the relations considered for the affiliation prediction task , among a total of 77 retrieved ( all composite ) relations , together with a measure of their relevance ( given by their
932
1
0.8
R P C U A
0.6
0.4
0.2
10 %
AUC PR results – AIFB Portal
GPKP GPKP ( λ = 0 )
SVM ( IST )
SVM ( WL )
KLR ( IST )
KLR ( WL )
SUNS
RESCAL
30 %
50 %
70 %
Percentage of labeled examples used during training
1
0.8
R P C U A
0.6
0.4
0.2
10 %
90 %
AUC PR results – DBpedia 3.9 Fragment
GPKP ( S )
GPKP ( S+C )
SVM ( IST )
SVM ( WL )
KLR ( IST )
KLR ( WL )
SUNS
RESCAL
30 %
50 %
70 %
Percentage of labeled examples used during training
GPKP ( λ = 0 )
SUNS
RESCAL
Method GPKP
SM SVM ( IST ) SM SVM ( WL )
KLR ( IST ) KLR ( WL )
AUC PR ( mean ± var . )
0.913 ± 0.009 0.847 ± 0.032 0.734 ± 0.030 0.845 ± 0.025 0.825 ± 0.025 0.834 ± 0.025 0.817 ± 0.029 0.837 ± 0.025 fi fi fi fi fi fi fi
Method GPKPS GPKPS+C SUNS
RESCAL
SM SVM ( IST ) SM SVM ( WL )
KLR ( IST ) KLR ( WL )
S fi fi
AUC PR ( mean ± var . )
0.943 ± 0.012 0.921 ± 0.019 0.832 ± 0.019 0.804 ± 0.029 0.930 ± 0.011 0.930 ± 0.011 0.888 ± 0.029 0.927 ± 0.012
90 %
S+C fi fi
Fig 1 : AIFB PORTAL Ontology – Plot : AUC PR results ( mean , stddev ) estimated by 10 fold CV , obtained varying the percentage of labeled examples used for training – Table : AUC PR results estimated by 10 fold CV : fi/' ( resp . ff/ ) indicates that GPKP ’s mean is significantly higher ( resp . lower ) in a paired Wilcoxon T test with p < 0.05 / p < 0.10
Fig 2 : DBPEDIA 3.9 Ontology – Plot : AUC PR results ( mean , stddev ) estimated by 10 fold CV , obtained varying the percentage of labeled examples used for training – Table : AUC PR results estimated by 10 fold CV and the corresponding paired Wilcoxon T significance tests ( described as in Fig 1 )
TABLE II : Relations considered in the AIFB PORTAL and the DBPEDIA 3.9 Ontologies and their corresponding weight
AIFB PORTAL publications interest ◦ interest
High μi −1 ◦ publications −1 −1 ◦ lecturer lecturer
Low μi title ◦ title −1 mobile ◦ mobile −1 road ◦ road −1
High μi vicePresident president region ◦ region
−1
DBPEDIA 3.9
Low μi successor profession ◦ profession −1 religion ◦ religion
−1 associated weight μi , described as either Low if μi ≈ 0 , and High otherwise ) . GPKP successfully recognizes that authors sharing publications or interests , teaching the same courses or sharing the office space are likely to be affiliated to the same research group ( unlike eg sharing the same academic title ) . Evaluation on the DBPEDIA 3.9 Fragment : Similarly to [ 6 ] , we evaluated the proposed approach on two prediction tasks , namely predicting party affiliations to either the Democratic and the Republican party for 82 US presidents and vicepresidents from DBPEDIA 39 The experiment illustrated in [ 6 ] uses a small RDF fragment containing the president and vicePresident predicates only . In this experiment , we used a fragment of DBPEDIA 3.9 , obtained by means of a crawling process . Following the extraction procedure in [ 15 ] , the DBPEDIA 3.9 RDF graph was traversed starting from resources representing US Presidents and Vice Presidents : all immediate neighbors , ie those with a recursion depth of 1 , were retrieved , together with their related schema information
933
( direct classes and their super classes , together with their hierarchy ) . All extracted knowledge was used to create a KB whose characteristics are outlined in Tab . I . In RESCAL , the number of iterations of the ALS algorithm was fixed to 16 , −8 ( given by an analysis with parameters t = 32 and λr = 10 of the dataset ) , while for WL d = 1 and h = 1 . In this experiment , the total number of retrieved relations ( both simple and composite ) was higher than the number of instances itself : 82 US presidents and vice presidents were interlinked by 25 simple relations and 149 composite relations . This differs from other empirical evaluations discussed in this paper , in which instances are linked by a more limited number of , exclusively composite , relations . For such a reason , we evaluated two variants of the proposed method : GPKPS , which only uses simple relations , and GPKPS+C , which uses both simple and composite relations among examples .
Experimental results are summarized in Fig 2 . We observe that AUC PR values obtained with GPKPS are higher than results obtained by other methods considered in comparison . However the difference was not always statistically significant : only in two cases we observed that p < 005 AUC PR values were slightly lower in the case of GPKPS+C , which might be explained by the curse of dimensionality . GPKP was able to identify which relations are likely to link same party affiliates , some of which are summarized in Tab . II . It successfully identified that the vice president is likely to belong to the same party of the president ; that representatives covering a role under the same president are likely to belong to the same party ; or that representatives elected in the same region are likely to belong to the same party . On the other hand , sharing the same religion , profession , nationality or awards does not necessarily mean sharing the same party affiliation .
AUC PR results – British Geological Survey
V . SUMMARY
1
0.8
R P C U A
0.6
0.4
0.2
10 %
GPKP GPKP ( λ = 0 )
SVM ( IST )
SVM ( WL )
KLR ( IST )
KLR ( WL )
SUNS
RESCAL
30 %
50 %
70 %
Percentage of labeled examples used during training
90 %
Starting from the assumption that some relations among examples in a Web ontology might influence each other , we propose a method , named Gaussian Process Knowledge Propagation ( GPKP ) , for efficiently learning the importance of each relation in a knowledge propagation process . In the proposed method , the joint distribution over labels for a set of examples is modeled through a finite set Gaussian Process regression model , where the inverse covariance matrix is learned by exploiting relations holding between examples in the ontology . We experimentally show that GPKP is competitive with stateof the art methods in terms of AUC PR . It also provides an interpretable statistical model , proving to be an effective instrument for mining new knowledge from Web ontologies . Acknowledgments : This work fulfills the objectives of the PON 02 00563 3489339 project “ PUGLIA@SERVICE Internet based Service Engineering enabling Smart Territory structural development ” funded by the Italian Ministry of University and Research ( MIUR ) .
REFERENCES
[ 1 ] T . Berners Lee , J . Hendler , and O . Lassila , “ The Semantic Web , ”
Scientific American , vol . 284 , no . 5 , pp . 34–43 , May 2001 .
[ 2 ] A . Rettinger , U . L¨osch , V . Tresp , C . d’Amato , and N . Fanizzi , “ Mining the Semantic Web : Statistical learning for next generation knowledge bases , ” Data Min . Knowl . Discov . , vol . 24 , no . 3 , pp . 613–662 , 2012 . [ 3 ] U . L¨osch , S . Bloehdorn , and A . Rettinger , “ Graph kernels for RDF data , ” in Proceedings of ESWC’12 , ser . LNCS , E . Simperl et al . , Eds . , vol . 7295 . Springer , 2012 , pp . 134–148 .
[ 4 ] G . K . D . de Vries , “ A Fast Approximation of the Weisfeiler Lehman Graph Kernel for RDF Data , ” in ECML/PKDD ( 1 ) , ser . LNCS , H . Blockeel et al . , Eds . , vol . 8188 . Springer , 2013 , pp . 606–621 .
[ 5 ] V . Tresp , Y . Huang , M . Bundschus , and A . Rettinger , “ Materializing and querying learned knowledge , ” in Proceedings of IRMLeS’09 , 2009 . [ 6 ] M . Nickel , V . Tresp , and H P Kriegel , “ A Three Way Model for Collective Learning on Multi Relational Data , ” in Proceedings of ICML’11 , L . Getoor et al . , Eds . Omnipress , 2011 , pp . 809–816 .
[ 7 ] F . Baader , D . Calvanese , D . L . McGuinness , D . Nardi , and P . F . Patel Schneider , Eds . , The Description Logic Handbook . Cambridge University Press , 2007 .
[ 8 ] X . Zhu , Z . Ghahramani , and J . D . Lafferty , “ Semi Supervised Learning Using Gaussian Fields and Harmonic Functions , ” in Proceedings of ICML’03 , T . Fawcett et al . , Eds . AAAI Press , 2003 , pp . 912–919 .
[ 9 ] M . B . Cohen , R . Kyng , G . L . Miller , J . W . Pachocki , R . Peng , A . Rao , and S . C . Xu , “ Solving SDD linear systems in nearly mlog1/2n time , ” in Proceedings of STOC 2014 , D . B . Shmoys , Ed . ACM , 2014 , pp . 343–352 .
[ 10 ] D . A . Spielman , “ Algorithms , Graph Theory , and Linear Equations in Laplacian Matrices , ” in Proceedings of ICM’10 , 2010 , pp . 2698–2722 . [ 11 ] C . E . Rasmussen and C . K . I . Williams , Gaussian Processes for Machine Learning ( Adaptive Computation and Machine Learning ) . MIT Press , 2005 . J . Friedman , T . Hastie , and R . Tibshirani , “ Sparse inverse covariance estimation with the graphical lasso , ” Biostatistics , vol . 9 , no . 3 , pp . 432–441 , 2008 .
[ 12 ]
[ 13 ] E . Sirin and B . Parsia , “ SPARQL DL : SPARQL Query for OWL DL , ” in OWLED , ser . CEUR Workshop Proceedings , C . Golbreich et al . , Eds . , vol . 258 . CEUR WS.org , 2007 .
[ 14 ] C . Bizer , J . Lehmann , G . Kobilarov , S . Auer , C . Becker , R . Cyganiak , and S . Hellmann , “ DBpedia a crystallization point for the Web of Data , ” J . Web Sem . , vol . 7 , no . 3 , pp . 154–165 , 2009 .
[ 15 ] S . Hellmann , J . Lehmann , and S . Auer , “ Learning of OWL Class Descriptions on Very Large Knowledge Bases , ” Int . J . Semantic Web Inf . Syst . , vol . 5 , no . 2 , pp . 25–48 , 2009 .
GPKP ( λ = 0 )
SUNS
RESCAL
Method GPKP
SM SVM ( IST ) SM SVM ( WL )
KLR ( IST ) KLR ( WL )
AUC PR ( mean ± var . )
0.837 ± 0.023 0.835 ± 0.016 0.724 ± 0.022 0.716 ± 0.015 0.735 ± 0.026 0.887 ± 0.010 0.781 ± 0.020 0.900 ± 0.007 fi fi fi
Fig 3 : BGS Ontology – Plot : AUC PR results ( mean , stddev ) estimated by 10 fold CV , obtained varying the percentage of examples used for training – Table : AUC PR results estimated by 10 fold CV and the corresponding paired Wilcoxon T significance tests ( described as in Fig 1 )
Evaluation on the BRITISH GEOLOGICAL SURVEY Ontology : As in [ 4 ] , we focused on the Lithogenesis prediction problem in the BRITISH GEOLOGICAL SURVEY ( BGS ) Ontology . The problem consisted in predicting the value of the property hasLithogenesis in a set of 159 named rock units labeled with their corresponding lithogenetic type . As in [ 4 ] , we focus on two tasks , consisting in the prediction of two major lithogenetic types : “ Alluvial ” and “ Glacial ” . For efficiency reasons , in SUNS and RESCAL the relational graph was composed only by statistical units and their immediate neighborhoods . In RESCAL , the number of iterations for the ALS algorithm was fixed to 16 , while parameter selection was performed via 5 fold CV within the training set , with t ∈ {12 , 16 , . . . , 32} and λr ∈ {10
−4 , 1} .
−8 , 10
Results are summarized in Fig 3 : AUC PR values observed with GPKP are higher than those observed with kernel methods using the IST kernel , SUNS or RESCAL . Kernel methods relying on the WL kernel provided slightly higher AUC PR results than GPKP ( p < 0.10 for KLR ) , confirming the effectiveness of the WL kernel on this specific dataset [ 4 ] . However , it is not clear how to interpret statistical models induced by using the WL kernel in terms of domain knowledge . On the other hand , models learned by GPKP explicitly indicate the importance of each relation in the knowledge propagation process . Also in this case , GPKP was able to extract relations between rock units that encode a form of similarity wrt their lithogenetic type . For example , among a total of 23 relations ( all composite ) it emerged that rocks with similar geographical distributions , thickness and lithological components were likely to share their lithogenetic type , while their geological theme and oldest geological age were not considered informative .
934
