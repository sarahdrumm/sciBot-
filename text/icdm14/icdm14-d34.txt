A Transfer Probabilistic Collective Factorization Model to Handle Sparse Data in Collaborative
Filtering
How Jing
National Taiwan University
Taipei , Taiwan
An Chun Liang and Shou De Lin
National Taiwan University
Taipei , Taiwan
Yu Tsao
Academia Sinica Taipei , Taiwan kublaijing@gmailcom notmydiagnosis@gmail.com , sdlin@csientuedutw yutsao@citisinicaedutw
Abstract—Data Sparsity incurs serious concern in collaborative filtering ( CF ) . This issue is especially critical for newly launched CF applications where observed ratings are too scarce to learn a good model to predict missing values . There could be , however , information from other related domains which are with relatively denser data that can be utilized . This paper proposes a transfer learning based approach that exploits probabilistic matrix factorization model trained with variational expectation maximization ( VEM ) to resolve data sparsity by using information from multiple auxiliary domains . We conduct experiments on several data combination and report significant improvements over state of the art transfer based models for collaborative filtering . The results also show that our framework is the only solution that can achieve acceptable performance when each user has only one single rating . The code of our model is available at 1 .
I .
INTRODUCTION
Collaborative Filtering ( CF ) [ 8 ] is a popular technique used to design a recommendation engine where the goal is to predict missing values in an incomplete rating matrix . One major limitation of CF is that it cannot produce satisfactory results when the observed ratings are considerably fewer than the total entries of the matrix , which is generally regarded as data sparsity or cold start phenomenon . Such issue happens frequently for newly launched online services where users have just begun to visit the site with insufficient amount of data collected . Data sparsity seriously degrades the performance of prediction due to over fitting . It is a serious concern in practice as generally new services demand an reliable system more eagerly than mature ones .
Fortunately , in practice there are related data that one can take advantage of from other domains to enhance a coldstart CF model . They are usually called the auxiliary data , and many transfer learning algorithms have been proposed to leverage them from various perspectives [ 3 ] , [ 4 ] , [ 6 ] , [ 7 ] , [ 12 ] , [ 13 ] . For example , rating data from a movie recommendation system may be helpful to alleviate the sparsity problem in a book recommendation system if we assume certain , most likely latent , correspondences are shared between these two user item matrices . In [ 3 ] and [ 4 ] , authors assume that clusterlevel patterns of matrices are shared across domains , so they construct clusters of rating patterns as bridges to transfer the knowledge .
Another type of auxiliary data that exists frequently in real recommendation systems are users’ implicit feedbacks , usually encoded in binary ( ie click or unclick ) . It is almost always the case that users have clicked or browsed a lot more items than they have actually rated . Such click records show users’ preferences of items to some degree , and they are useful if we could extract and transfer the knowledge from such ’heterogeneous’ feedbacks to enhance the system . Likewise , item side auxiliary data existing in the form of implicit feedbacks are relatively easy to obtain in practice . For instance , favored/disfavored is provided in Movieplot 2 and love/ban is provided in Last.fm 3 for users to express their preferences in a way that would not degrade users’ browsing experiences and satisfaction . In [ 6 ] , the authors show how a trifactorization model that first learns latent factors from auxiliary domains with binary feedbacks , then transfers the latent factors to the target domain can boost the performance in the target domain .
We roughly categorize current state of the art transferbased methods for handling sparsity issue in CF into four categories by asking two questions . First , do we know explicitly the correspondences of users and/or items between the auxiliary and target domains ? Second , do auxiliary data come from a homogeneous source ( eg ratings ) or heterogeneous source ( eg binary like/dislike values ) ? Table 1 shows the stateof the art transferring methods that approach the problem from these two perspectives .
Unfortunately , methods proposed to handle one type of transfer scenario usually cannot handle the others . For example , to construct cluster level rating patterns as a knowledge bridge , the auxiliary data needs to be homogeneous , meaning that they should have the same rating scale as in the target domain . Heterogeneous values are not suitable for clustering rating values as described in [ 6 ] . On the other hand , methods that use binary heterogeneous implicit feedbacks require that either user or item variables share the same latent factors across domains . Therefore , without knowing explicitly the correspondences of users and/or items between target and auxiliary domains , those methods cannot be exploited .
1https://github.com/Kublai Jing/TPCF
2http://wwwmoviepilotde/ 3http://wwwlastfm/
U and/or I None homogeneous
CBT [ 3 ] RMGM [ 4 ] heterogeneous TCF [ 7],CST [ 6 ]
TABLE I : Current state of the art methods on transfer based models for sparsity reduction in collaborative filtering . U and/or I denotes whether the correspondences of users and/or items are given in the auxiliary domains . Homo/Heterogeneous represent auxiliary data type .
The question we ask throughout this paper is : can we simultaneously transfer data from multiple domains with different properties ( ie data that falls into different cells in Table 1 ) ? The goal of this paper is to design a more general model not only outperforming each existing work individually , but also enjoying further performance leap by allowing the transferring of multiple types of knowledge to the target domain .
We present a unified probabilistic framework named Transfer Probabilistic Collective Factorization ( TPCF ) aiming at bringing different information from multiple CF tasks into the target domain to alleviate the sparsity problem . Specifically , we focus on three auxiliary CF data . First type is data with aligned users but not aligned items that have heterogeneous implicit feedbacks , existing in binary form . Second type is data with aligned items but not aligned users , also existing in binary form . Third type is homogeneous data that have the same rating scale as the target domain , but without the knowledge of the correspondences of users and items between target and auxiliary domains . We note that our model is general and extendable to other cases that appear in each cell of Table 1 ( such as the situation considered in [ 7] ) . Without loss of generality , in this paper we will focus on the three cases for transferring , because these cases happen more frequently in practice .
The main contributions of this paper are as follows : • We present TPCF , a general probabilistic model for transfer learning in collaborative filtering by using data from multiple domains with different statistical properties . To our knowledge , this is the first unified transfer learning model for CF that considers all the above mentioned scenarios .
•
•
One technical challenge in the problem is how to simultaneously transfer data from multiple domains and tackle both binary and rating values well . We present a learning schema based on variational EM algorithm to solve this issue within the probabilistic framework .
The experiments show our model not only outperforms the state of the art CF based transfer learning models before unifying all the auxiliary sources together but also enjoys another level of performance boosting when bringing all information into the target domain . The results also show that our model can achieve reasonable outcome when there are as few as only one single rating for each user .
II . RELATED WORK
Transfer learning algorithms have been proved to be effective in solving CF problems . Knowledge transferring is carried out by assuming there is some shared latent structure present across different domains . This section briefly introduces some popular models .
Collective Matrix Factorization ( CMF ) uses common latent features to jointly factorize multiple matrices with correspondences between rows and columns Usually , CMF is trained by minimizing some pre specified Bregman divergence that does not have to be squared L2 loss , plus regularization terms to prevent over fitting [ 13 ] . However , it was shown that in such SVD style model , complexity control of regularization parameters is a challenging problem that needs to be carefully tuned . Probabilistic models , on the other hand , have the advantage of using an adaptive prior for automatic complexity control [ 9 ] . Rating Matrix Generative Model ( RMGM ) takes clusterlevel information to be transferred from auxiliary domains by assuming that different domains share the same cluster level rating patterns [ 4 ] . RMGM can be viewed as an extension of mixture model that simultaneously clusters users and items to model rating patterns across domains . The drawback of RMGM comes from its inability to handle binary source data for transferring . Also , RMGM maximizes a self defined likelihood objective which does not always penalize bad predictions . Coordinate System Transfer ( CST ) is a matrix trifactorization approach that assumes latent features are similar but not identical across domains and allows the user to control the closeness of the latent features between different domains [ 6 ] . It first learns users’ and items’ factors from the auxiliary domains , then adapts them to the target domain .
III . PROBLEM FORMULATION AND NOTATIONS
We now describe the scenario we consider in this paper formally . As mentioned before , our model is very flexible and can be applied to problems in any quadrant of Table 1 . However , for clarity purpose , from this point on we only focus on three transferring tasks with three types of auxiliary data . There are four different domains represented as matrices . One is the target matrix denoted as R which has sparse rating values and represents the domain we want to predict missing values in . There are two auxiliary matrices with heterogeneous binary feedback , denoted as RU and RI , representing domains with only aligned users ( RU ) and only aligned items ( RI ) respectively . We assume that the two auxiliary matrices have binary values 0/1 indicating users’ implicit feedback , though it would be clear later on that our framework can be easily adjusted to handle numerical values . Users in RU are aligned to users in R , and items in RI are aligned to items in R . Also , there is another auxiliary domain , denoted as RO , that represents another different but related CF task with neither users nor items aligned . To be more precise , we assume that rating values in RO have the same scale as R , but items and users in RO are different to those in R . An illustration of the scenario we consider is shown in Figure 1 .
For simplicity , the number of users and items in R , RU and RI is denoted as N and M respectively . The number of users and items in RO is denoted as L and S . Moreover , we define a mask function Yab(d ) which returns 1 if cell ( a,b )
Fig 1 : Illustration of the scenario considered in this paper : users in R are aligned to users in RU ; items in R are aligned to items in RI ; we have no prior knowledge about the correspondences of users and items in RO . is observed in domain d , or 0 otherwise . In our setting , there are four domains , hence d can take on values {T , U , I , O} where T denotes the target domain , and U , I , O denote the three auxiliary domains .
Fig 2 : The graphical representation of TPCF . Colored nodes refer to variables that are shared . ξ is an auxiliary variable for optimization that will be detailed in Section 42 Here we replicate prior to avoid interleaved edges to make the picture uncluttered . a be can then target problem given formulated rating matrix R
Our as ∈ follows : {1 , 2 , 3 , 4 , 5}N×M fi Y∗∗(T ) and three auxiliary matrices RU ∈ {0 , 1}N×M fi Y∗∗(U ) , RI ∈ {0 , 1}N×M fi Y∗∗(I ) and RO ∈ {1 , 2 , 3 , 4 , 5}L×S fi Y∗∗(O ) , is to boost missing rating to utilize prediction performance for R . Here fi means elementwise multiplication . Note that we do not assume all three matrices RU , RI and RO need to exist . Our model can be conducted even when only one type of data is available . auxiliary matrices the goal
IV . TRANSFER PROBABILISTIC COLLECTIVE
FACTORIZATION
We now present TPCF , which falls into the category of an extension of the PMF family [ 9 ] , in which we want to learn a joint probabilistic model using all four domains that can overcome the limitations of previous models mentioned in Section 2 .
A . The Model
The graphical illustration of TPCF is shown in Fig 2 . The intuition is that latent user factors and item factors should capture both rating and binary feedback distributions well . Moreover , no matter what domain we are in , we always assume that users are coming from the same distribution ; same assumption applies for items . This assumption may seem to be too strong at first glance , but since we are working in a lowdimensional latent space , high level shared concept such as genres of items could emerge .
The distribution of the homogeneous ratings R , RO are assumed to be Gaussian :
N L i=1
M S j=1 l=1 s=1
N ( Rij|uT i vj , σ2)Yij(T )
N ( RO ls|uT l vs , ω2)Yls(O )
N
M and the distribution of the heterogeneous binary values is modeled by Bernoulli distribution :
Bern(RU ij |σ(uT i vj))Yij(U)Bern(RI ij|σ(uT i vj))Yij(I ) i=1 j=1 where U = {ui,i=1:N , ul,l=1:L} is the set of parameters representing the preferences of the users , and V = {vj,j=1:M , vs,l=1:S} is the set of parameters representing the implicit attributes of the items . Note that from the figure , the parameters ui , vj in domain R , RU and RI are different from ul , vs in domain RO , yet we do not distinguish them by defining different notations in order to make the equation more succinct . The distinction is implicitly embedded in domain variables T , U , I and O . We then assume that there is a single prior distribution for all users’ parameters , and there is a single prior distribution for all items’ parameters that are both Gaussian . The whole generative process is as follows : For each user i , generate ui ∼ N ( mu , Σu ) For each item j , generate vj ∼ N ( mv , Σv ) For each cell ( i , j ) in R , generate Rij ∼ N ( uT ∼ For each cell ( i , j ) in RU , generate RU ij Bern(σ(uT
Domain R , RU , RI : i vj , σ2 ) a ) b ) c )
1 ) d ) i vj ) )
M j=1
N i=1
S
+ log
L
Yij(U ) Yij(I ) exp(uT i vjRU exp(uT i vjRI i vj ) i vj ) ij )σ(−uT ij)σ(−uT L u1:L v1:S l=1
N ( RO e )
For each cell ( i , j ) in RI , generate RI ij Bern(σ(uT i vj ) )
∼
2 )
Domain RO : a ) b ) c )
For each user l , generate ul ∼ N ( mu , Σu ) For each item s , generate vs ∼ N ( mv , Σv ) For each cell ( l , s ) in RO , generate RO ls
∼ N ( uT l vs , ω2 ) ,
1 where Bern(σ(x ) ) denotes the Bernoulli distribution with mean given by σ(x ) which is the sigmoid function : σ(x ) = 1+exp(−x ) . Note that the information of which user in RU corresponds to which user in R and which item in RI corresponds to which item in R are known . This makes the algorithms easier to perform knowledge transfer because the correspondence information tells us the preference of each individual user , even though this preference statistics are heterogeneous . For instance , in a movie rental application , user i has only a few ratings in R , but we observe that he/she has clicked on lots of action movies about in RU . Then we can make a good guess about this user ’s preference . Similarly , movie j has only received a few ratings in R , but we observe that this movie received a lot of clicks in RI . Then it might be reasonable to believe that this movie is a popular movie and will receive mostly positive ratings in R . This correspondence/alignment information allows us to identify user ’s behaviors more clearly , and is the key to the success of many algorithms .
However , in RO we do not have any correspondence information . In fact , we do not even assume that there is overlap of users/items between RO and the other three domains . Even though there may exist some overlap between RO and ( R , RU , RI ) , we do not assume such correspondence is available due to privacy or overhead concerns . For instance , RO and R might be vendors that sell different products , and both companies have the obligation not to disclose the identities of its customers . This makes it harder to transfer knowledge because we cannot identify and match individual user from different domains easily .
Our basic assumption is that , in latent space of lower dimension , users’ preferences and items’ attributes , are somewhat similar across domains and come from the same prior distribution . This is different from those methods that consider cluster level ratings as a bridge for knowledge transferring , as they assume the explicit rating patterns to be similar . We hypothesize that as rating patterns differ across domains , clustered patterns from domain A may not be beneficial to domain B . However , down to a lower dimensional latent space , we may have a better chance to capture the shared information to improve the model performance . log likelihood function of our probabilistic model as follows : log P ( R , RU , RI , RO ; Θ )
= log P ( R , RU , RI ; Θ ) + log P ( RO ; Θ ) N ( ui ; mu , Σu )
= log
N
M u1:N v1:M i=1 j=1
N ( Rij ; uT i vj , σ2)Yij(T )
N ( vj ; mv , Σv )
N ( ul ; mu , Σu )
S s=1
N ( vs ; mv , Σv ) l=1 s=1 ls ; uT l vs , ω2)Yls(O ) ,
( 1 ) where Θ = {mu , Σu , mv , Σv , σ2 , ω2} is a set of model parameters , and we use the equivalence : σ(x)t(1−σ(x))1−t = exp(xt)σ(−x ) for the sigmoid function . Recall that we have defined Yab(d ) = 1 if Yab is a non missing entry in domain d to indicate which domain we are referring to .
B . Learning log P ( RO , u1:L , v1:S ; Θ ) log P ( R , RU , RI , u1:N , v1:M ; Θ )
The parameters set Θ which contains the means and covariances of the Gaussian prior for users and items needs to be learned such that Equation 1 is maximized . This optimization problem is intractable due to the integration over all latent variables u and v , hence we exploit the concept of variational approximation to perform learning [ 5 ] . We first use Jensen ’s inequality to derive a lower bound on the log likelihood , log P ( R , RU , RI ; Θ ) + log P ( RO ; Θ ) ≥ EQ + EQO
+ H(Q(u1:N , v1:M ; ψ ) ) + H(QO(u1:L , v1:S ; ψO) ) , ( 2 ) where H is the entropy . We have separated out domains ( R , RU , RI ) and RO for notational convenience . Q , QO are the variational posterior distributions that are governed by a set of variational parameters ψ , ψO respectively . The gap of this bound to the true log likelihood is the KullbackLeibler divergence between the approximate posterior and the true posterior , and the bound is tight if and only if Q is equal to the true posterior [ 1 ] . However , it is intractable to do exact inference on true posterior ; hence we use meanfield variational distribution by assuming a fully factorized posterior ,
N L i=1
Q(u1:N , v1:M ; ψ ) =
Q(u1:L , v1:S ; ψO ) =
N ( ui ; λui , γui )
N ( ul ; λul , γul )
M S j=1
N ( vj ; λvj , γvj )
N ( vs ; λvs , γvs ) , ( 3 )
Back to the model itself , we write down the ( marginal ) l=1 s=1 where λ is a set of means for variational Gaussian , and γ is a set of covariances which are set to be diagonal . We now have two types of parameters . First , a set of model parameters that control the Gaussian prior ,
Θ = {mu , mv , Σu , Σv , σ2 , ω2} , and two sets of variational parameters ,
ψ = {λui=1:N , λvj=1:M , γui=1:N , γvj=1:M} , ψO = {λul=1:L , λvs=1:S , γul=1:L , γvs=1:S} .
The optimization can then be done using variational expectation maximization ( VEM ) [ 1 ] . In VE step , we fix model parameters and optimize the bound in Equation 2 wrt ψ and ψO to make the bound as tight as possible . In VM step , we fix variational parameters and optimize Equation 2 wrt model parameters Θ to raise the bound . One thing should be mentioned is that this procedure guarantees to raise the bound of the log likelihood , but not the log likelihood itself . However , VEM has shown to work well in practice . The details of VEM steps are described below .
Variational E step : First we start with the VE step of learning to obtain the mean and covariance for each variational Gaussian . Let qui be a single variational Gaussian for user i with mean λui and ( diagonal ) covariance γui , the optimal q∗ ui can be derived by using the general principle of mean field inference [ 14 ] : log q∗ ui
∝ EQ−qui log p(R , RU , RI , u1:N , v1:M ; Θ )
,
( 4 )
Making use of the independence relations in the graphical model and drop constants that are not dependent to qui , we obtain the following form for q∗ ui , log q∗ ui
Yij(T ) log N ( Rij ; uT i vj )
+
M = E−qui M M
αE−qui j=1 j=1
αE−qui
+
( 5 )
The second and the third terms in Equation 5 , however , require integration of a Gaussian and a log logistic function ,
N ( vj ; λvj , γvj ) log σ(−uT i vj)dvj vj that are not analytically tractable . We hence introduce another lower bound on the log logistic function by using first order Taylor ’s approximation for convex functions [ 2 ] , log σ(−uT i vj)≥ log(ξij)+ i vj − ξij
2
−uT
σ(x ) − 1
− φ(ξij)((uT i vj )
2 − ξij
2 )
, ( 6 )
2
. The cost of this approximation where φ(x ) = 1 2x is that we have introduced an additional set of variational parameters ξij for each ( user , item ) pair in domains RU and RI . With Equation 6 , the integration of a Gaussian and the bound wrt vj can be derived analytically , as shown below .
N ( vj ; λvj , γvj ) log σ(−uT i vj)dvj
= log(ξij ) +
−uT i λvj − ξij
2
− φ(ξij)(uT i ( λvj λT vj
+ γvj)ui − ξ2 ij ) vj
To proceed , we have specified how to compute all three terms in Equation 5 that are needed to derive optimal q∗ ui . The parameters for qui , ie mean λui and covariance γui , can then be determined by observing the first order and second order terms and ’complete the square’ for the Gaussian density . Also , the optimal variational parameters ξij can be determined by replacing log σ(−uT i vj ) in Equation 5 with the lower bound in Equation 6 and taking the derivative wrt ξij . The update rules for variational parameters are shown as follows :
λui =
Σ−1 u +
( λvj λT vj
+ γvj )
−1
M j=1
M j=1
M j=1
M j=1
Yij(U ) uT i vjRU ij + log σ(−uT i vj )
Yij(I ) uT i vjRI ij + log σ(−uT i vj )
Yij(T ) + αYij(U)ξij + αYij(I)ξij
Σ−1 u mu + j=1 where the expectation is taken wrt other variational Gaussians , −qui . We have introduced a parameter α which is a trade off parameter that controls the ’mixing’ weight between R and ( RU , RI ) . In general , the bigger the α , the more we rely on the information from RU and RI .
In Equation 5 , the first term involves the integration of a Gaussian and a bunch of independent ’log Gaussian’ over all items set , which can be done analytically ,
M j=1 v1:M
M
= j=1
N ( vj ; λvj , γvj )
Yij(T ) log N ( Rij ; uT i vj , σ2)dv1:M
1 2σ2 ( 2Rijui
Tλvj − uT i ( λvjλT vj
+ γvj)ui ) + const , where const denotes factors that are not dependent on ui .
)
) + αYij(I)(RI ij − 1 2 ij − 1 2
−1
λvj
Yij(T)Rij + αYij(U)(RU
γui,dd =
Σ−1 u,dd +
( λ2 vj,dd + γvj,dd )
Yij(T )
1 σ2 +αYij(U)2φ(ξij ) + αYij(I)2φ(ξij )
ξij = Yij(U)Tr
( λui λT ui
+ γui)(λvjλT vj
+ γvj )
+
Yij(I)Tr
( λuiλT ui
+ γui )(λvjλT vj
+ γvj )
, where γui,dd denotes the cell in dth row and dth column of γui . The update rules for λvj and γvj have the same form . The VE step then proceeds by alternately updating λ , γ and ξ until convergence . Note that the update rules for domain RO is exactly the same except that there is no ξ in RO because the ratings in RO are homogeneous to the ratings in R and hence are modeled by Gaussian distribution .
Variational M step : Next we move on to the VM step . In VM step we fix all three sets of variational parameters that we have obtained from VE step , and optimize the bound in Equation 2 wrt the model parameters Θ = {mu , Σu , mv , Σv , σ2 , ω2} . This is done by taking derivatives of Θ in Equation 2 where all expectations can be done in the same way as what we have described in VE step . Similar to VE step , we introduce the trade off parameters β that controls the mixing weights between ( R , RU , RI ) and RO to update the parameters for prior distributions .
The optimal mean and covariance for Gaussian prior in
VM step take the following forms ,
N M i=1
λui + β
λul
L S l=1
λvj + β
λvs j=1 s=1 mu =
1
N + βL mv =
1
M + βS
+
1
1 i=1
γui + ( λui − mu)(λui − mu)T γvj + ( λvj − mv)(λvj − mv)T
N γul + ( λul − mu)(λul − mu)T M γvs + ( λvs − mv)(λvs − mv)T
M N j=1 λvj + ( λT ui
λvj)2 + Tr(γuiγvj )
γvjλui + λT vj
γvs λul + λT
RO2 ls + λT ul
L
S
R2 ij + λT ui
Yls(O )
Yij(T )
γuiλvj j=1
λvs )2 + Tr(γul γvs ) vs γulλvs
Σu =
N + βL
L
Σv =
M + βS
β
β l=1
S s=1
σ2 =
1 A i=1
− 2RijλT ui
ω2 =
1 W
− 2RO l=1 ls λT ul s=1 λvs + ( λT ul where A and W are the total number of observed ratings in R and RO respectively .
The complete optimization algorithm then proceeds by first initializing variational parameters , and alternating between VE step and VM step until some stopping criterion is met . Usually the stopping criterion would be the relative improvement on the bound of the log likelihood . However , evaluating that bound requires non trivial computation ; hence in our experiments we set a fixed number for VE step as well as the whole VEM algorithm , but we stop when RMSE on the validation set starts to increase . More details about the experiments will be given in Section 5 .
C . Prediction
To predict missing ratings in R , we find the optimal Rij which maximizes the bound in Equation 2 by taking the derivatives wrt Rij for a given user i and item j . It turns out that the prediction has exactly the same form as in matrix factorization : ˆRT λvj , although the optimization objective is very different . ij = λT ui
D . Automatic Complexity Control
In standard matrix factorization model such as SVD , choosing regularization parameters is critical to prevent over fitting . The usual way is to choose a fixed regularization value by doing an exhaustive search in some pre specified range using a validation set . Such method is very time consuming as we need to train multiple models in order to select the best one . Also , past experiences showed that such parameters are quite sensitive that using a regularizer that is too strong prevents the model from learning meaningful things , while using a weak regularizer causes the model to overfit [ 9 ] .
In our model , the complexity is controlled automatically via the shared Gaussian prior . If we fix the prior and do not do any learning on that , we will go back to the same issue as how to choose the mean and covariance of the prior . However , because our prior is adaptive to the training data , we do not need to fix it beforehand , instead we can learn it through training . Moreover , since in many practical situations we have denser auxiliary data , the prior parameters will automatically balance between modeling the target data and auxiliary data that we do not need to worry about complexity control in our model . Also , update rules in variational EM are all closed forms with no need to tune the learning rate or perform line search .
There are in total of four datasets used in our experiments , namely , Netflix 4 , Movielens 5 , Book Crossing 6 and EachMovie 7 , that are all popular datasets for collaborative filtering . The Netflix dataset contains about 108 integer rating values in the range {1 , 2 , 3 , 4 , 5} given by about 7×104 users on around 1.7 × 104 movies . The Movielens dataset contains about 107 rating values 1 5 , rated by about 7 × 104 users on around 104 movies . Book Crossing is a dataset for book recommendation with about 2.8 × 105 users and 2.7 × 105 books . Finally , EachMovie contains approximately 2.8× 106 ratings given by 7.2 × 104 users on 1628 movies .
For EachMovie and Book Crossing , we first normalize their rating values to be in the range {1 , 2 , 3 , 4 , 5} . The evaluation metrics used in this paper is Root Mean Square Error ( RMSE ) ,
N i
M
RM SE = j ( Rtest ij − ˆRtest ij
)2 fi Yij(T )
,
W where W is the number of observed ratings in the testing set Rtest and ˆR is the predicted ratings given by the algorithms .
4http://wwwnetflixprizecom/ 5http://wwwgrouplensorg/node/73 6http://wwwinformatikuni freiburgde/ cziegler/BX/ 7http://wwwcscmuedu/ lebanon/IR lab/data.html
+
V . EXPERIMENTS
A . Data Sets and Evaluation Metrics
B . Implementation Details
For the implementation of TPCF , there are few tunable parameters : α , β and k which is the rank of matrix factors . Throughout our experiments , we keep k at 10 unless otherwise specified . For parameter α , we perform a grid search in {0.1 , 0.3 , 0.5 , 1} , and for parameter β , {0.1 , 0.5 , 1 , 3 , 5} are tried . More experiments on the effects of α and β will be presented later .
For VEM optimization algorithm , the number of VE steps is set to 20 , and the total number of iterations of VEM is set to 20 as well . For each iteration of VEM , we record the RMSE on the validation set and we stop when this number starts to increase . The final parameters for α and β were selected by choosing the one that performs the best on the validation set in terms of RMSE . Furthermore , we preprocessed the data on R and RO by subtracting each rating with the mean of all ratings . This step is necessary to achieve good results when using Gaussian distribution to model rating values .
C . Compared Algorithms
We compare our model with three transfer learning algorithms introduced in Section 2 : Collective Matrix Factorization with L2 regularization ( CMF L2 ) [ 13 ] , Coordinate System Transfer ( CST ) [ 6 ] , and Rating Matrix Generative Model ( RMGM ) [ 4 ] . We have implemented CMF L2 and CST in MATLAB . For RMGM , the authors have provided example code 8 and we modify it for the purpose of this paper . Note that CMF L2 and CST cannot use data in RO because they require knowing explicitly the correspondences for either users or items in order to transfer knowledge . Also , RMGM cannot use data in RU and RI as it requires the matrix to have homogeneous ratings . Nevertheless , we can still compare our model with these algorithms assuming our model only observes partial data used in the corresponding scenario .
In the following section , we will first show some analysis of TPCF alone , and comparisons of previous state of the art will be detailed later .
D . Results
1 ) Learning Netflix with MovieLens : First , we take Netflix and MovieLens datasets to conduct this part of the experiment . Here the goal is to predict missing values in Netflix ( target domain ) and MovieLens is only used to construct RO . In order to evaluate the effectiveness of using auxiliary data , we perform the following pre processing steps :
5 )
6 )
To simulate implicit user feedbacks , we pre process RU and RI by relabeling ratings in the range {1 , 2 , 3} as 0 and ratings in the range {4 , 5} as 1 [ 11 ] . Finally , we randomly select 2000 × 2000 dense submatrix from Movielens data as RO to simulate what happens when we have other CF task without making any assumption on the correspondence of users/items between ( R , RU , RI ) and RO .
We make our training data in target domain very scarce . The sparsity levels for each of the matrices are listed in Table 2 . For training set Rtrain , we start from an extremely sparse case with each user having only 1 rating , and gradually add observed ratings .
Data Rtrain Rval Rtest RU RI RO
Data Source Netflix Netflix Netflix Netflix Netflix MovieLens
Domain target target target aux aux aux
Form 1 5 1 5 1 5 0/1 0/1 1 5
Sparsity ≤ 1.00 % 1.00 % 3.48 % 6.00 % 6.00 % 6.00 %
TABLE II : Statistics of matrices considered in NetflixMovieLens task . The sparsity levels of RU , RI , RO are purposely set to be identical so that we can make fair observation about which type of auxiliary data is most useful .
For this part of the experiment , we focus on our method alone . In particular , we want to know which auxiliary domain contributes the most to the prediction improvement . Hence we start from the single task version of TPCF without using any data other than R ( ie VBMF [ 5 ] , [ 10] ) , and gradually add auxiliary information from RO , RU and RI to examine the performance gain .
We run the tests with a set of Rtrain having various levels of sparsity . We start with the case where each user in Rtrain has rated only one item . Then we gradually increase the number of ratings for each user . The result in terms of RMSE is shown in Fig 3 where we denote |R|u as the number of ratings that each user has provided in Rtrain . The trend is very clear
1 )
2 )
3 )
4 )
Randomly extract a 4000 × 4000 dense rating matrix X from Netflix data , and take a sub matrix X1:2000,1:2000 as the target matrix R . Take a sub matrix X1:2000,2001:4000 as the auxiliary matrix RU with shared users . Clearly , RU and R only share common users but not common items . Take a sub matrix X2001:4000,1:2000 as the auxiliary matrix RI with shared items . Clearly , RI and R only share common items but not common users . Split sets Rtrain , Rval , and Rtest as training set , validation set and testing set respectively . target matrix R into disjoint the
8https://sitesgooglecom/site/libin82cn/
Fig 3 : RMSE on Netflix dataset with different types of information from auxiliary domains and different |R|u , that is , the number of observed ratings for each user in Rtrain . The matrix RO is sampled from MovieLens dataset that at the beginning , when |R|u is small , VBMF does poorly because there is not enough information to learn the model . For method [ 6 ] , hence we consider CST as the state of the art benchmark model in the scenario where we have RU and RI at hand . RMGM , on the other hand is the state of the art crossdomain learning algorithm considering situation that there are no correspondence between users/items in the target domain and auxiliary domains . All parameters in these three models are also selected using the validation set .
We report the results with latent dimension k = {10 , 50} shown in Table 4 and 5 . Here the experiments are repeated five times with random initialization of the parameters . Comparing TPCF+O to RMGM , using exactly the same data for both models , our model outperforms RMGM with a big margin . Also , comparing TPCF+U+I to CMF L2 and CST with the same set of data , our model shows significant improvements over the other methods for all the chosen sparsity levels . Moreover , as mentioned before , our probabilistic model can effectively ensemble all three sources of auxiliary data , shown as TPCF+U+I+O , to achieve further improvement .
TPCF + O , ie using data from MovieLens to learn a better prior distribution for users and items , the improvements are significant when |R|u ≤ 5 , albeit the amount of improvement gradually decreases when |R|u ≥ 10 . When we use RU or RI alone , the RMSE reduces greatly as expected . When using both RU and RI , a huge reduction in RMSE is further obtained . Interestingly , even though much information from RU and RI has already been brought into the model , there is still some improvement when we include RO , which essentially just affects the prior distribution . This result shows that the parameters of prior are critical in having a good prediction results , and our model can automatically learn the priors even though users and items are not well aligned .
2 ) Learning EachMovie with MovieLens : Second , similar to the previous experiment , we take EachMovie and MovieLens datasets and the goal is to predict missing values in EachMovie ( target domain ) . All preprocessing steps for this experiment is the same as in Netflix MovieLens experiment . The dimensions of R , RU and RI are all 1000 × 800 ; and we sample MovieLens randomly to select 1000 users and 800 items to form RO . Statistics are shown in Table 3 :
Data Rtrain Rval Rtest RU RI RO
Data Source EachMovie EachMovie EachMovie EachMovie EachMovie MovieLens
Domain target target target aux aux aux
Form 1 5 1 5 1 5 0/1 0/1 1 5
Sparsity ≤ 2.50 % 1.25 % 4.73 % 5.00 % 5.00 % 5.00 %
TABLE III : Statistics of matrices considered in EachMovieMovieLens .
The experiment result is shown in Fig 4 , and we observe similar trends as in Netflix MovieLens experiment .
Fig 4 : RMSE on EachMovie dataset with different types of information from auxiliary domains and different |R|u . The matrix RO is sampled from MovieLens dataset .
3 ) Comparison with Related Algorithms : In this part of experiment , we compare TPCF with several algorithms to show its effectiveness on Netflix MovieLens and EachMovieMovieLens tasks with all preprocessing steps being the same as described in last two subsections . We compare against methods introduced in Section 5.3 , ie CMF L2 , CST , and RMGM . CST is proven to be more powerful than CMFL2 in the original paper because CST is a tri factorization
Fig 5 : RMSE on Netflix dataset with TPCF . Top : varying value of α ; Bottom : varying value of β .
4 ) The Effects of α and β : Here we test how changes in α and β affect the performance . α is the mixing weight that controls relative importance of domains R and ( RU , RI ) , whereas β is the trade off parameter between ( R , RU , RI ) and RO . To reveal the effect of choosing the right α and β , we fix the value of one of them and vary the other to see the change in performance . We show the plots for Netflix MovieLens and EachMovie MovieLens tasks in Fig 5 and 6 .
5 ) Learning Books from Movies : Previous experiments are conducted on domains with the same kind of items ( movies ) . It seems reasonable to assume that we can place the same prior distribution over the latent space for items because they indeed belong to the same class of items . In this part , we take BookCrossing as target matrix R and Netflix as auxiliary matrix RO k = 10 RMGM TPCF+O CMF L2 CST TPCF+U+I TPCF+U+I+O k = 50 RMGM TPCF+O CMF L2 CST TPCF+U+I TPCF+U+I+O
|R|u = 1
10435±00013 10263±00004 09894±00027 09352±00009 09126±00010 08823±00002 10443±00019 10265±00013 10427±00019 09610±00022 09338±00012 08919±00016
|R|u = 1
Netflix MovieLens
|R|u = 5
10097±00011 09695±00007 09514±00031 09057±00011 08965±00007 08763±00003 10104±00012 09705±00015 10015±00025 09453±00024 09044±00011 08860±00014
|R|u = 5
|R|u = 10 09638±00026 09356±00004 09264±00045 08975±00010 08824±00005 08723±00002 |R|u = 10 09613±00014 09360±00015 09719±00020 09274±00020 08929±00011 08829±00014
|R|u = 15 09389±00010 09182±00012 09107±00040 08925±00009 08750±00008 08689±00001 |R|u = 15 09394±00020 09182±00012 09545±00038 09016±00020 08843±00015 08737±00016
|R|u = 20 09269±00035 09070±00009 09023±00029 08792±00017 08703±00010 08643±00003 |R|u = 20 09284±00017 09059±00014 09442±00017 08987±00031 08766±00018 08671±00016
TABLE IV : RMSE on Netflix : auxiliary domains include RU , RI and RO as described in section 541 Each algorithm utilizes all applicable auxiliary data . k = 10 RMGM TPCF+O CMF MAP CST TPCF+U+I TPCF+U+I+O k = 50 RMGM TPCF+O CMF MAP CST TPCF+U+I TPCF+U+I+O
|R|u = 1
14554±00025 14004±00011 13424±00014 12621±00016 11936±00012 11807±00012 14418±00020 14016±00010 13735±00020 12838±00009 11705±00007 11660±00010
|R|u = 1
EachMovie MovieLens |R|u = 5
12963±00022 12310±00013 12361±00026 11707±00026 11079±00014 11067±00017 12812±00053 12526±00009 12655±00018 11912±00012 11113±00009 11080±00009
|R|u = 5
|R|u = 10 12210±00028 11716±00013 11696±00010 11483±00020 10877±00014 10862±00018 |R|u = 10 12175±00033 11759±00014 11962±00033 11557±00019 10863±00012 10847±00018
|R|u = 15 11984±00018 11408±00016 11406±00011 11371±00011 10706±00013 10720±00015 |R|u = 15 11901±00037 11439±00012 11568±00024 11408±00021 10688±00014 10686±00015
|R|u = 20 11827±00031 11140±00012 11180±00020 11159±00013 10609±00012 10599±00014 |R|u = 20 11750±00035 11195±00008 11302±00019 11299±00022 10594±00009 10548±00011
TABLE V : RMSE on EachMovie : auxiliary domains include RU , RI and RO as described in Section 542 Each algorithm utilizes all applicable auxiliary data . to see what will happen when item sets do not belong to the same kinds . RMGM was proposed to solve this specific kind of cross domain collaborative filtering problem by capturing similar cluster patterns . Our model , on the other hand , does not use cluster level patterns . Instead , we use auxiliary data to learn a better prior distribution for users and items in the target domain without knowing any correspondences of users and items from different domains . We believe that down to a lower dimensional space ( such as 10 D or 50 D ) , we can still capture the semantic relations between books and movies ( such as genre ) to perform predictions well in the target domain .
To see whether we can learn a better model for book recommendation using auxiliary data from a set of ratings on movies , we first randomly select 500 users and 500 books with the most ratings from Book Crossing dataset as target data . Then we normalize the ratings to be in the range {1 , 2 , 3 , 4 , 5} . Next , we sample a 2000×2000 sub matrix from Netflix dataset as auxiliary data with density 6 % .
In this part of experiment , we only compare with RMGM because CST and CMF L2 could not handle data without knowing correspondence information explicitly . The dimension of k is fixed at 10 . We report the RMSE with varying β for our model and the RMSE of RMGM in Fig 8 . We also compare to a non transfer version of RMGM that only uses target domain as training data . We see that a transfer version of RMGM learning with data from Netflix actually degrades the model performance 9 . To investigate the cause of this result , we study the rating patterns in these two datasets . We treat the observed ratings from Book Crossing and Netflix as two categorical distribution with values in the range {1 , 2 , 3 , 4 , 5} , then we compute the Kullback–Leibler divergence between the two datasets . The result is 03251 Computing the KL divergence between training and testing ratings from BookCrossing dataset gives us a value of 00016 This shows a clear distribution mismatch , indicating inconsistent rating behaviors between users in Book Crossing and Netflix datasets . We believe this is the core reason why a transfer version of RMGM performs poorly . Because rating patterns across domains are
9In the original implementation of RMGM provided by the authors , they use categorical distribution for generating data . We have therefore also implemented a real value version of RMGM using Gaussian distribution to generate data . However , we still could not get a better result than non transfer version of RMGM . method to alleviate such problem with TPCF to transfer knowledge from related domains in a unified sense . As shown in the experiments , our method is particularly useful when there are extremely scarce data in the target domain , as the improvements are significant compared to other benchmark algorithms .
VII . ACKNOWLEDGEMENT
We thank Chung Yi Li for the implementation of real value version of RMGM . This study is also under the ” Online and Offline integrated Smart Commerce Platform(1/4 ) ” project of the Institute for Information Industry which is subsidized by the Ministry of Economy Affairs of the Republic of China .
REFERENCES
[ 1 ]
J . M . Bernardo , M . J . Bayarri , J . O . Berger , A . P . Dawid , D . Heckerman , A . F . M . Smith , M . West ( eds , Matthew J . Beal , and Zoubin Ghahramani . The variational bayesian em algorithm for incomplete data : with application to scoring graphical model structures , 2003 .
[ 2 ] TS Jaakkola and MI Jordan . A variational approach to bayesian logistic regression models and their extensions , 1996 .
[ 3 ] B . Li , Q . Yang , and X . Xue . Can movies and books collaborate ? : Crossdomain collaborative filtering for sparsity reduction . In Proceedings of the 21st International Jont Conference on Artifical Intelligence , pages 2052–2057 , 2009 .
[ 4 ] B . Li , Q . Yang , and X . Xue . Transfer learning for collaborative filtering via a rating matrix generative model . In Proceedings of the 26th Annual International Conference on Machine Learning , pages 617–624 , 2009 . [ 5 ] Y . J . Lim and Y . W . Teh . Variational Bayesian approach to movie rating prediction . In Proceedings of KDD Cup and Workshop , 2007 .
[ 6 ] W . Pan , and N . Liu E . Xiang , and Q . Yang . Transfer learning in collaborative filtering for sparsity reduction . In Proceedings of the 24th Association for the Advancement of Artificial Intelligence , pages 617– 624 , 2010 .
[ 7 ] W . Pan , N . Liu , E . Xiang , and Q . Yang . Transfer learning to predict In Proceedings of missing ratings via heterogeneous user feedbacks . the 22nd International Joint Conference on Artificial Intelligence , pages 2318–2323 , 2011 .
[ 8 ] P . Resnick , N . Iacovou , M . Suchak , P . Bergstrom , and J . Riedl . Grouplens : An open architecture for collaborative filtering of netnews . In Proceedings of the 1994 ACM Conference on Computer Supported Cooperative Work , pages 175–186 , 1994 .
[ 9 ] R . Salakhutdinov and A . Mnih . Probabilistic matrix factorization . In Advances in Neural Information Processing Systems , volume 20 , 2008 . [ 10 ] H . Shan and A . Banerjee . Generalized probabilistic matrix factorizations for collaborative filtering . In Proceedings of the 2010 IEEE International Conference on Data Mining , pages 1025–1030 , 2010 .
[ 11 ] V . Sindhwani , S . S . Bucak , J . Hu , and A . Mojsilovic . A family of non negative matrix factorizations for one class collaborative filtering problems , 2009 .
[ 12 ] A . Singh and GJ Gordon . A bayesian matrix factorization model for relational data . In UAI , pages 556–563 , 2010 .
[ 13 ] AP Singh and GJ Gordon . Relational learning via collective matrix factorization . In Proceedings of the 14th ACM SIGKDD , pages 650– 658 , 2008 .
[ 14 ] EP Xing , MI Jordan , and S . Russell . A generalized mean field algorithm for variational inference in exponential families . In Proceedings of the Nineteenth Conference on Uncertainty in Artificial Intelligence , pages 583–591 , 2003 .
Fig 6 : RMSE on EachMovie dataset with TPCF . Top : varying value of α ; Bottom : varying value of β
Fig 7 : Testing RMSE on Book Crossing of TPCF with varying β and RMGM . RMGMN ON means learning RMGM model without using auxiliary data from Netflix . very different , cluster level patterns from Netflix do not help alleviate sparsity issue in Book Crossing at all . Our model , on the other hand , does not rely on explicit rating patterns . We instead use an adaptive shared prior to automatically leverage the data from the two domains . From the plot we see that it indeed helps a lot as the RMSE reduces from 0.8283 , with non transfer VBMF to 07861 For β greater than 2−6 , we get about the same performance , showing the insensitivity of choosing exact value of β .
VI . CONCLUSION
A newly launched CF application usually contains scarce rating values , and such cold start phenomenon prevents non transfer learning algorithm from accurately capturing users/items preferences . In this paper , we propose a robust
