Graded Multilabel Classification by Pairwise Comparisons
Christian Brinker
Eneldo Loza Mencía
Johannes Fürnkranz
Technische Universität Darmstadt christianbrinker@studtu darmstadtde
Technische Universität Darmstadt
Technische Universität Darmstadt eneldo@ketu darmstadtde juffi@ketu darmstadtde
Abstract—The task in multilabel classification is to predict for a given set of labels whether each individual label should be attached to an instance or not . Graded multilabel classification generalizes this setting by allowing to specify for each label a degree of membership on an ordinal scale . This setting can be frequently found in practice , for example when movies or books are assessed on a one to five star rating in multiple categories . In this paper , we propose to reformulate the problem in terms of preferences between the labels and their scales , which can then be tackled by learning from pairwise comparisons . We present three different approaches which make use of this decomposition and show on three datasets that we are able to outperform baseline approaches . In particular , we show that our solution , which is able to model pairwise preferences across multiple scales , outperforms a straight forward approach which considers the problem as a set of independent ordinal regression tasks .
Keywords—graded multilabel classification , ordinal classifica tion , learning by pairwise comparisons
I .
INTRODUCTION
Multilabel Classification ( MLC ) , the task of learning to assign multiple labels to a single data item , has received a lot of attention in the recent machine learning literature [ 1 ] because it has many real world applications such as tagging of messages in blogs , annotating images , or assigning keywords to scientific papers . However , often we need to predict a degree or grade of membership to a particular category or label , instead of only whether this label is present or not . Cheng , Dembczy´nski , and Hüllermeier [ 2 ] introduced this task as Graded Multilabel Classification ( GMLC ) . For example , TV guides often rate a movie on a scale from one to five stars in several different categories such as ‘fun’ , ‘action’ , ‘sex’ , or ‘suspense’ , as is shown in Table I . Users may find the additional information in the form of grades of memberships in contrast to simple binary assignments of genres very useful , and appreciate it for choosing their individual TV programs . Another application is the prediction of answers from questionnaires , where a common setting is to ask the probands to answer a series
This is the authors’ version of the paper , which appeared in 2014 IEEE International Conference on Data Mining ( ICDM 2014 ) , pp . 731–736 , DOI : 101109/ICDM2014102 A longer version is available as technical report at http://wwwketu darmstadtde/publications/reports/tud ke 2014 01pdf For the present version , the following applies : cfl2014 IEEE . Personal use of this material is permitted . Permission from IEEE must be obtained for all other uses , in any current or future media , including reprinting/republishing this material for advertising or promotional purposes , creating new collective works , for resale or redistribution to servers or lists , or reuse of any copyrighted component of this work in other works . of questions and to respond on a graded scale of agreement , frequency , importance , quality or likelihood .
Although superficially similar , this task differs from a classical recommendation task [ 3 ] . While in both cases one essentially needs to make ordinal predictions that correspond to ratings , in recommender systems the training information is a sparsely populated rating matrix and the task is to predict ( some of ) the missing values . In contrast , the training information for GMLC is a complete matrix where each of the objects in the lines is characterized with a set of features ( eg , features that characterize the respective movie ) , and the task is to predict the entries for a new line , given the features that correspond to this new entry .
In this paper , an extended version is available as [ 4 ] , we assume an inherent preference structure between the labels in combination with their grade of membership , and propose pairwise preference learning as a suitable technique to exploit this structure . To this end , we generalize calibrated label ranking , a technique for tackling multilabel classification in a pairwise fashion [ 5 ] , to the case where we have multipartite instead of bipartite preference information . In particular , we show how the use of a calibration label , which indicates the separation between relevant and irrelevant labels in the predicted ranking , can be generalized to multiple such labels . As a result , we investigate and experimentally compare three different variations of this principled approach .
II . PRELIMINARIES
We represent an instance or object as a vector x in a feature space X . Each instance can be associated with a point yx in the target space Y . A training set is a finite set of tuples ( x , yx ) ∈ X × Y drawn independently from an unknown probability distribution on X × Y . The goal is to learn a classifier H : X → Y which predicts yx for a given x . We will denote the prediction of H with a circumflex , ie ˆy = H(x ) . Depending on the form of Y we face different problems and assumptions . In the simplest case , binary classification , we have Y = {0 , 1} . Ordinal classification generalizes this problem by extending the value space to a discrete and ordered
TABLE I .
EXAMPLE OF RATINGS OF SOME MOVIES ACCORDING TO THE GERMAN TV GUIDE TVSPIELFILM.DE
Movie title The other guys A few good men Once upon a time in the west Dirty dancing
‘fun’ ( cid:63 ) ( cid:63 ) ( cid:63 )
‘action’
‘sex’
‘suspense’
( cid:63)(cid:63 ) ( cid:63 )
( cid:63 ) ( cid:63 ) ( cid:63 )
( cid:63 )
( cid:63 ) ( cid:63 )
( cid:63 ) ( cid:63 ) ( cid:63 ) ( cid:63 ) ( cid:63 ) ( cid:63 )
Fig 1 . Different decompositions of graded multilabel classification : vertical ( left ) , horizontal ( center ) , and complete ( right ) . The illustration shows the decompositions for a training instance for which label λi has grade µi . finite space Y = M = {µ1 , . . . , µm} that is structured with a total order ≺ , such that µ1 ≺ µ2 ≺ . . . ≺ µm . On the other hand , multilabel classification extends the label space to x ) ∈ Y = {0 , 1}n . n binary dimensions , ie yx = ( y1 Alternatively , we may view this as a mapping from x to a subset Px ⊆ L , where L is a finite set of predefined , nonmutually exclusive labels {λ1 , . . . , λn} . yi is 1 if λi ∈ Px and 0 otherwise . The labels in Px are usually said to be relevant or positive , whereas L . Nx = L\Px is called the set of irrelevant or negative labels for x . x , . . . , yn
III . GRADED MULTILABEL CLASSIFICATION
In graded multilabel classification [ 2 ] , each label λ in the set of relevant labels Px of instance x ∈ X is no longer only relevant or not ( M = {0 , 1} ) , but has output values M = {µ1 , . . . , µm} with an ordered scale µ1 ≺ µ2 ≺ . . . ≺ µm as in ordered classification . It is assumed that the same ordinal scale is used for all labels , ie Y = {µ1 , . . . , µm}n , µ1 denoting the lowest and µn the highest degree of relevance of a label . This is a strong restriction but is motivated on real applications such as those sketched in the introduction . On the other hand , this assumption induces a ( limited ) comparability between the grades of the different labels which cannot be assumed in the more general setting of multi target ordinal regression .
Following [ 2 ] , we define the auxiliary membership function Lx : L → M as Lx(λi ) = yi x which returns the grade of a x = {λ | µi = Lx(λ)} be the specific label and instance . Let P i x = {λ | µi Lx(λ)} the set of labels with grade µi , and P i labels that are at least as relevant as µi . The latter set allows to model the assumption that if a label has a membership degree of µi , it also has all grades µj ≺ µi associated to it . Thus , x = L . since µ1 is the lowest possible grade , it follows that P 1 Cheng et al . [ 2 ] introduce three straight forward reduction schemes in order to decompose the original problem into a set of well known and solvable subproblems . Figure 1 illustrates these reductions on an example where we have four possible labels L = {λ1 , λ2 , λ3 , λ4} on a scale µ1 ≺ µ2 ≺ µ3 ≺ µ4 . the original problem of learning H : X → Mn is reduced to n ordinal classification problems of learning [ H]λ1 , , . . . , [ H]λn : X → M , one for each label λ1 , . . . , λn ( cf . Fig[H]λi ure 1 ( left) ) . The aggregation of the individual predictions is trivially given by H(x ) = ( [H]λ1 ( x ) , . . . , [ H]λn(x) ) . A simple yet effective decomposition strategy for solving the individual resulting ordinal problems was proposed by Frank and Hall [ 6 ] : the original problem is decomposed into n − 1 independent binary subproblems , each of which contains all instances with a class value ≺ µi as positive examples and
Vertical Reduction : In the vertical reduction , all others as negative examples . The probabilistic estimations of the base classifiers are then combined into a distribution P r(µi ) = P r(≺ µi+i ) − P r(≺ µi ) over the possible class grades . Obviously , such independent classifiers can not model interdependencies and correlations between the different labels , which is the main disadvantage of this approach .
Horizontal Reduction : In contrast , the horizontal reduction transforms the original problem into m = |M| multilabel classification problems . For each grade µi , i = 1 . . . m we learn a classifier [ H]i : X → P ( L ) using ( x , P i x ) as training x = L , we can ignore grade µ1 . information . As P 1 x ⊆ [ H]i ( x ) = ˆP i
An additional challenge for this approach is that it cannot x , µj ≺ µi be guaranteed that [ H]j ( x ) = ˆP j x for holds , although by definition it holds that P j µj ≺ µi . Cheng et al . attempt to address this problem by weighting the evidence for a higher grade higher than the evidence for a lower grade , effectively proposing to resolve contradictions by taking for each label λi the maximum predicted grade max≺{µj ∈ M | λi ∈ ˆP j x} , where max is defined with respect to the total order relation ≺ . x ⊆ P i
Unlike the vertical scheme , the horizontal reduction scheme conserves dependencies between labels because each multilabel subproblem allows to model the label dependencies at a certain degree of membership . This information can be taken into account by algorithms like IBLR ML [ 2 ] .
Complete Reduction : The complete reduction learns a : X → {0 , 1} for each of the n · m single classifier [ H]λiµj possible label/grade combinations using training information ( x , I(µj yi x ) ) where I is the indicator function ( I(x ) = 1 if x is true , and 0 otherwise ) .
IV . GRADED MULTILABEL CLASSIFICATION BY
PAIRWISE COMPARISON
Learning by pairwise decompositions is based on the idea of modeling preferences between labels [ 7 ] . These preferences are either derived from the label structure ( eg a hierarchy ) or given for the training instances at hand , eg in the form of a total or partial , often multipartite ranking . Moreover , pairwise decomposition implicitly takes label dependencies into account to some extent , since it explicitly models the cases of pairwise exclusions . We hence believe that pairwise decomposition is well suited to the setting of graded multilabel classification . In particular , we build upon calibrated label ranking ( CLR ) , a pairwise approach to solving multilabel problems , which we describe in more detail in the following . Thereafter , we will introduce three different approaches for generalizing CLR to the graded case , which are all based on the idea of working with multiple calibration labels .
A . Calibrated Label Ranking
The pairwise decomposition of multilabel problems interprets the training information as bipartite rankings Nx ≺ Px , ie , we can deduce explicit preference statements λu ≺ λv for all λu ∈ Nx , λv ∈ Px . These preferences are learned by training classifiers Huv : x → {0 , 1} for each of the possible pairs of labels , 1 ≤ u < v ≤ n . Hence , the problem is decomposed into n(n−1 ) smaller binary sub problems . For each pair of labels ( λu , λv ) , only examples belonging to either
2
Fig 2 . Preferences in calibrated label ranking : on the left , we see all preferences between the relevant labels Px = {λ1 , λ2} and the irrelevant labels Nx = {λ3 , λ4 , λ5} , the center graph shows the position of the virtual label v = λ0 , and the right graph shows all generated preferences ( the union of the previous two graphs ) .
λu or λv are used to train the corresponding classifier Hu,v . More precisely , classifier Hu,v receives all x where λu is a relevant label and λv is irrelevant as positive training examples ( x , 1 ) , and those where λv ∈ Px and λu ∈ Nx as negative examples ( x , 0 ) . All other examples are ignored . For making a prediction , all n(n−1 ) base classifiers predict a vote for one of the two corresponding classes . Adding these votes results in a full ranking over the labels .
2
To convert the resulting ranking of labels into a multilabel prediction , we use the calibrated label ranking ( CLR ) approach [ 5 ] . This technique avoids the need for learning a threshold function for separating relevant from irrelevant labels , which is often performed as a post processing phase after computing a ranking of all possible classes . The key idea is to introduce an artificial calibration label v = λ0 , which represents the split point between relevant and irrelevant labels . Thus , v is assumed to be preferred over all irrelevant labels , but all relevant labels are preferred over v ( cf . Figure 2 ) . During prediction , the virtual label is treated like any other label . Its position in the predicted ranking then denotes a natural cutting point for dividing the label ranking into two sets.1
B . Multiple Calibration Labels
The key idea of the proposed pairwise approach to graded multilabel classification is to generalize calibrated label ranking to the case of multiple calibration labels V = {v1 , . . . , vm−1} , where each label represents an intermediate grade vi between the original grades µi and µi+1 . Hence , we obtain Mv = M ∪ V with the inner structure
µ1 ≺ v1 ≺ µ2 ≺ v2 ≺ µ3 ≺ . . . ≺ vm−1 ≺ µm
As a consequence , we obtain an extended set of labels L ∪ V . Note that we use V to denote both , labels and grades , which conveniently emphasizes the fixed mapping between grade and label vi , ie it generally holds L(vi ) = vi .
Furthermore , in order to cover the case that some training instances may be ignored by certain pairwise classifiers , we introduce the projection function [ p]rp : x → {0 , 1 , ∅} which indicates to use a training example x either as positive ( 1 ) , negative ( 0 ) example or not at all ( ∅ ) for the given decomposition rp . Let us further also assume that the pairwise base classifiers are symmetric , ie [ H]λu,λv = 1 − [ H]λv,λu 1We break ties in the final counting in favor of the virtual label .
Generated preferences λ1 ≺ v1 ≺ λ2 , λ3 , λ4 λ1 , λ2 ≺ v2 ≺ λ3 , λ4 λ1 , λ2 , λ3 ≺ v3 ≺ λ4 i
General case ( i = 1 . . . m − 1 ) j x x ≺ {vi} ≺ m j
P
P j=1 j=i+1
( a ) Horizontal CLR
Generated preferences
λ1 ≺ v1 ≺ λ2 ≺ v2 ≺ λ3 ≺ v3 ≺ λ4 General case ( i = 1 . . . m − 1 ) x ≺ {vi} ≺ P i+1 P i x
( b ) Full CLR
Generated preferences
λ1 ≺ v1 ≺ λ2 , λ3 , λ4 , v2 , v3 v1 , λ1 , λ2 ≺ v2 ≺ λ3 , λ4 , v3 v1 , v2 , λ1 , λ2 , λ3 ≺ v3 ≺ λ4 {v1 . . . vi−1} ∪ i General case ( i = 1 . . . m − 1 ) x ≺ {vi} P j {vi} ≺ m x ∪{vi+1 . . . vm−1} P j j=1
( c ) Joined CLR j=i+1
Fig 3 . The three different approaches for a pairwise decomposition of a graded multilabel problem , showing also exemplarily the generated preferences and the general case ( i = 1 . . . m − 1 ) .
C . Horizontal Calibrated Label Ranking
The first , simple approach to generalize calibrated label ranking to the graded case is to use the horizontal decomposition as described in Section III , and to solve each of the resulting multilabel problems with CLR . Thus , in order to learn each [ H]i , we choose grade vi as our cutting point , ie we only differentiate between grades greater or smaller than vi . Translated to CLR , vi becomes the calibrating label and ∪vi≺µj P j x our positive and negative set of labels , respectively , as is illustrated in Figure 3(a ) . x and ∪µi≺vj P j
More precisely , we train each [ H]i {vi} using training examples ( x , [ p]i
λu,λv
, λu = λv ∈ L ∪ ( x ) ) given by
λu,λv if [ L]i if [ L]i 0 ∅ if [ L]i x(λv ) ≺ [ L]i x(λu ) ≺ [ L]i x(λu ) = [ L]i x(λu ) x(λv ) x(λv )
 1 fl µi
( 1 )
( 2 )
[ p]i
λu,λv
( x ) = and
[ L]i(λu ) =
µi+1 if λu ≺ vu if vu ≺ λu hx(λu ) =
[ H]i
λu=λv
For making a prediction for a test instance x , the votes ( x ) are summed up for each label u ∈ L ∪ {vi} , and λu is predicted as relevant if hx(λu ) > hx(λvi ) . The final graded prediction is obtained by using the maximum predicted score for each label , as described in Section III .
λu,λv
    D . Full Calibrated Label Ranking
The idea of the full calibrated label ranking approach is to consider the targets in a GMLC problem as a multipartite ranking P 1 ( cf . Figure 3(b) ) . Enriched by the virtual labels we eventually obtain x x . . . ≺ {vm−1} ≺ P m x x ≺ P 2 x . . . ≺ P m x ≺ {v1} ≺ P 2 P 1 x and Nx = P 2 x .
Obviously , for m = 2 , this reduces to calibrated label ranking with Px = P 1
The projection function for base classifiers [ H]λu,λv , λu = λv , λu , λv ∈ L∪V only slightly changes in comparison to ( 1 ) , namely into
1 if L(λv ) ≺ L(λu ) if L(λu ) ≺ L(λv ) 0 ∅ if L(λu ) = L(λv )
[ p]λu,λv ( x ) =
Note that in contrast to the horizontal decomposition in Sec IV C we can sum up the votes across the grades , obtaining one global ranking over all labels and grades . After querying all ( n + m− 1)(n + m− 2)/2 base classifiers , we then predict ˆyj = arg maxµi hx(λj ) > hx(λvi ) for λj .
A possible disadvantage of this approach is that the algorithm is prone to producing many ties in the ranking since n+m−1 labels have to be ordered on a scale of 0 to n+m−2 obtainable votes . This can potentially be remedied using a different voting function like weighted voting . However , we observed that predicting accurate and comparable scores such as confidences or probabilities is not a trivial task . Hence , 0 1 voting is more robust and makes the fewest assumptions on the base classifiers , and we restrict ourselves to this approach in this paper . Another , related problem is that preference intensities are not considered , ie , the difference between the grades of two compared labels is ignored , for training as well as during prediction . The Joined CLR approach , described in the next section , provides a solution to this .
E . Joined Calibrated Label Ranking
λu,λv x − yv
On the one hand , Full CLR is not able to capture different degrees of preference intensities since the preference between two labels λu , λv is only obtained in a binary way . On the other hand , we recall that in the horizontal approach we learn each exactly m − 1 times , once discriminating classifier [ H]i for every grade transition . In fact , the number of classifiers λu vs . λv which use a training instance x depends on the difference between the grades of the labels , more precisely , it is exactly |yu x| . We can hence expect that the difference in the number of votes between both labels correlates with the difference in the true grades . A solution , which takes such predictions with varying intensity into account , would be to compute a common , joint ranking across degrees and for all λu , λv ∈ L∪ V . Although this would possibly produce a good ranking over the labels in L , it cannot be expected to provide a good ranking over the virtual labels because each of the virtual labels only appears in one horizontal sub problem and can therefore only obtain at most n votes . In contrast , each of the real labels can obtain up to n(m − 1 ) votes . labels , ie to compute s(λu ) =
λv=λu
[ H]i
λu,λv
µi
Joined CLR solves this problem by generalizing the horizontal decomposition introduced above , so that all virtual labels are always used in all horizontal sub problems . More precisely , it decomposes the initial problem into m−1 bipartite ( three partite if we count the virtual label ) ranking problems with one main calibrating label vi on each grade transition . In this regard , joined CLR is equivalent to horizontal calibrated label ranking and all pairwise base classifiers learned by horizontal CLR are also learned in exactly the same manner by joined CLR . On the other hand , as shown in Figure 3(c ) , joined CLR also adds all remaining virtual labels vj = vi into these bipartite ranking problems allowing them to accumulate the necessary voting mass . The resulting problem remains bipartite , since we map all grades to µi and µi + 1 as in horizontal CLR . Using a simplified informal representation , this basically means that in addition to the comparisons
( 3 )
µ1 , . . . , µi ≺ vi ≺ µi+1 , . . . , µm each horizontal subproblems is enriched with the following preferences :
µ1 , . . . , µi ≺ vi+1 , . . . , vm−1 v1 , . . . , vi−1 ≺ µi+1 , . . . , µm v1 , . . . , vi−1 ≺ vi ≺ vi+1 , . . . , vm−1
λu,λv
More formally , we learn classifiers [ H]i using [ p ] and [ L ] from Eq ( 1 ) and ( 2 ) , but in this case for each λu = λv , λu , λv ∈ L ∪ V . Note that the training signal between two virtual labels is always fixed . Hence , we can set [ H]i ( x ) = 0 if vu ≺ vv , 1 otherwise , for vu = vv , vu , vv ∈ V . During prediction , the votes for each label are aggregated across all grade transitions as proposed in the beginning of this subsection . vu,vv
Note that fixing the predictions between virtual labels can introduce a bias since these predictions are always perfect , whereas the remaining predictions depend on the classification performance of a classifier trained on potentially noisy data . This problem can be alleviated eg by allowing different fixed values than 0 and 1 or by removing some comparisons . We are currently developing such methods and leave the investigation for further work .
V . EXPERIMENTS
In this section , we describe the data and setup of the experiments , followed by the results .
A . Datasets
An overview over the used datasets is given in Table II . The BELA E benchmark was used in previous work , whereas MOVIES and MEDICAL are two new real world datasets.2
BeLa E : The BELA E dataset results from a questionnaire in which 1930 students rated the importance of certain properties of their future jobs from ‘1’ to ‘5’ . We replicated the setup of Cheng et al . [ 2 ] by choosing a random subset of the n questions as target labels and the remaining 50− n as instance attributes . The selection was done for n = 5 and n = 10 , and in each case repeated 50 times , resulting in 50 different dataset for each value of n .
2Datasets and details at wwwketu darmstadtde/resources/GMLC and [ 4 ] .
TABLE II . OVERVIEW OF DATASETS USED IN THE EXPERIMENTS . SHOWN ARE THE TOTAL NUMBER OF INSTANCES , ATTRIBUTES , UNIQUE LABELS n , DIFFERENT GRADES m , THE AVERAGE GRADE INDEX AND THE
FREQUENCY OF THE SPECIFIC GRADES µi APPEARING IN THE
LABEL–INSTANCE MAPPINGS .
Dataset
BELA E n=5 BELA E n=10
MOVIES MEDICAL
Avg . Distribution of grades µi , i = 5
1
2
3
4
Instances Attributes Labels Grades Grade 2.50 2.50 0.72 50.26 31.13 15.18 3.43 0.37 0.02 99.08 0.31
7.95 13.04 23.89 31.43 23.69 7.95 13.04 23.89 31.43 23.69
1930 1930 1967 1953
5 10 5 204
27002 1602
45 40
5 5 4 4
0.24
– –
One Error Rank Loss : This metric is the generalization of the one error loss for rankings in multilabel classification . It compares if the highest real grade corresponds to the highest predicted grade . Contrary to [ 2 ] , we use a version that can be zero :
ONEERR,ˆyi
= x , yi x
ˆyi x , max 1≤j≤n with AE : M × M → N , AE ( µi , µj ) = |i − j| . m − 1 max 1≤i≤n
AE yj x
1
Movies : We collected a dataset from the German TV program guide wwwTVSpielfilmde which rates movies by assigning grades from ‘0’ to ‘3’ to the categories ‘fun’ , ‘action’ , ‘sex’ , ‘suspense’ and ‘sophistication’ rather than giving an overall rating . For characterizing the 1967 movies , we extracted the titles , the associated summary texts and other information from wwwimdborg and applied stemming , stop word removal and TF IDF weighting .
Medical : The MEDICAL dataset consists of 1953 free text radiology reports . Three expert companies were asked to annotate them with a set of ICD 9 CM diagnosis codes . In contrast to the original multilabel dataset , we generated a GMLC dataset by considering the level of agreement as grade of assignment . Note that it lies in the nature of the problem that labels are very likely to be absent . The texts were processed as for MOVIES but we used the absolute term frequency in contrast to TF IDF .
B . Experimental setup
All proposed approaches were implemented as part of the LPCforSOS framework,which is an extension of Weka,3 except for IBLR ML , which we obtained from the authors . IBLRML , a combination of instance based learning with logistic regression taking into account label dependencies , is a stateof the art multilabel learner proposed by Cheng et al . [ 2 ] for solving the horizontal decomposition . We used J48/C4.5 of Weka as binary base classifier . The complete reduction approach was implemented by using horizontal reduction with binary relevance decomposition ( BR ) . For ordinal classification in the vertical decomposition ( F&H ) , we used Weka ’s implementation of the method of Frank and Hall [ 6 ] . All losses ( see below ) are computed individually on the instances , averaged first over all examples in a test fold , and then over all 10 test folds . In addition , on the BELA E datasets , we averaged the results over the 50 versions of each dataset . For calculating the rank losses for the complete reduction approaches ( BR and F&H ) , IBLR ML and horizontal calibrated label ranking ( H CLR ) , the predicted grade is used as the score .
C . Losses
For the GMLC problem , Cheng et al . [ 2 ] generalized several common losses for multilabel classification , including Hamming Loss ( avg . deviation from correct grades ) , Vertical 01 Loss ( percentage of labels with incorrectly assigned grades ) and the ranking measure C Index ( pairwise ranking error ) . We follow this setup , except for the following slight modification of the One Error . In addition , we propose optimistic Hamming loss as a new loss function .
3Cf . http://wwwlpcforsossfnet and http://wwwcswaikatoacnz/ml/weka/
Optimistic Hamming Loss : Under some circumstances , CLR tends to under or overestimate the correct position of the virtual label . In order to be independent of such an effect , we follow the idea of [ 5 ] and propose to evaluate the ranking performance by cheating on the correct positioning of the virtual labels : we place the cutting points in hindsight so that the distribution of grades corresponds to the real one . In a way , this allows us to compute the regret of using a specific cutting technique . More precisely , we find the partitioning x | = ˆP 1 x , ˆP 2 x , µi ≺ µj . |P i x | and sx(λu ) ≤ sx(λv ) if λu ∈ P i Given the corresponing prediction ˆy , we obtain the optimistic Hamming loss as OPTHAMMLOSS = HAMMLOSS ( ˆy x , yx ) . x , . . . over the predicted ranking such that | ˆP i x , λv ∈ P j
D . Results
The experimental results are summarized in Table III . The first observation is that BR , ie , the complete reduction using horizontal and vertical cuts , is usually outperformed by the pairwise approaches , even for Hamming loss . Moreover , BR is always outperformed by F&H , even though both classifiers are trained equally . The difference is due to the different aggregation strategies of the predictions of the binary classifiers ( see Sec III ) , and obviously , the more sophisticated approach by Frank and Hall pays off for these datasets .
The next observation is that the approach using IBLR ML shows even worse results than BR . This is surprising , since it does not correspond to the results reported by Cheng et al . [ 2 ] , where BR is beaten by IBLR ML , although we used the code provided by the authors . A reason might be that the 50 sub datasets are obviously not exactly equal due to the random initialization . Furthermore , we used a different base learner for BR which explains the differences for this algorithm , but not the ones for IBLR ML , which was used exactly the same way as in Cheng et al . [ 2 ] .
Still , our results for C Index and one error seem more reasonable to us since IBLR ML uses the same overestimating aggregation as BR . H CLR also uses this aggregation but pairwise classification is an ensemble method and thereby is more robust to noise predictions of single classifiers .
Interestingly , the approach using vertical reduction ( F&H ) seems to perform quite competitive wrt other approaches , especially for Hamming and vertical 0 1 loss . This may show that preserving and focusing on the information about the grades ( vertical ) is more important for GMLC than considering the relations between the labels at each grade ( horizontal ) . On the other hand , horizontal CLR outperforms F&H on exactly these both losses ( except for MEDICAL , where they perform equally ) . On the BELA E datasets , all approaches are pairwise statistically significantly different with α = 0.01 ( sign test ) .
TABLE III . RESULTS OF THE THREE PAIRWISE GRADED MULTILABEL ALGORITHMS IN COMPARISON TO IBLR ML AND TWO BENCHMARKS . IN ADDITION TO THE RESULTS OF THE FIVE DIFFERENT LOSS FUNCTIONS IN TERMS OF PERCENTAGE ( ×100 ) , WE SHOW THE STANDARD DEVIATION FOR
BELA E AND THE AVERAGE RANK OF EACH ALGORITHM ON THE PARTICULAR DATASET IN PARENTHESIS .
Dataset
BELA E n = 5
BELA E n = 10
MOVIES
MEDICAL
Evaluation Measure Hamming Loss Optimistic Hamming Loss Vertical 0 1 Loss C Index One Error Loss Hamming Loss Optimistic Hamming Loss Vertical 0 1 Loss C Index One Error Loss Hamming Loss Optimistic Hamming Loss Vertical 0 1 Loss C Index One Error Loss Hamming Loss Optimistic Hamming Loss Vertical 0 1 Loss C Index One Error Loss
IBLR ML
–
27.23 ( 4)± 4.51 69.39 ( 5)± 5.39 49.55 ( 6)± 8.44 27.80 ( 6)± 7.46 27.27 ( 4)± 3.83 69.95 ( 5)± 4.16 50.37 ( 6)± 6.98 34.47 ( 6)± 9.23
–
BR
–
28.07 ( 5)± 2.62 61.27 ( 3)± 4.19 32.63 ( 5)± 3.19 12.89 ( 5)± 3.20 27.77 ( 5)± 1.83 61.17 ( 3)± 2.69 32.85 ( 5)± 3.45 17.03 ( 5)± 4.38
–
F&H
–
16.08 ( 2)± 1.65 51.97 ( 2)± 3.68 24.34 ( 4)± 4.25 11.35 ( 4)± 2.45 16.04 ( 2)± 1.04 51.97 ( 2)± 2.23 24.14 ( 4)± 2.68 12.92 ( 4)± 2.53
–
32.33 ( 5 )
–
–
67.34 ( 5 ) 33.98 ( 6 ) 15.43 ( 5 ) 1.30 ( 3 )
2.07 ( 3 ) 49.96 ( 6 ) 90.89 ( 6 )
21.94 ( 3 )
–
–
50.85 ( 3 ) 30.86 ( 5 ) 18.43 ( 6 ) 0.31 ( 2 )
0.62 ( 2 ) 18.40 ( 5 ) 20.93 ( 5 )
18.95 ( 2 )
–
–
47.86 ( 2 ) 23.12 ( 4 ) 14.24 ( 4 ) 0.26 ( 1 )
0.60 ( 1 ) 10.73 ( 3 ) 11.76 ( 3 )
Full CLR
33.97 ( 6)± 5.79 11.00 ( 2)± 1.70 73.44 ( 6)± 7.58 20.38 ( 2)± 4.13 8.50 ( 2)± 2.25 35.44 ( 6)± 3.70 12.70 ( 2)± 0.94 75.11 ( 6)± 4.47 18.57 ( 2)± 2.27 8.19 ( 2)± 1.67
Joined CLR 17.96 ( 3)± 1.31 9.62 ( 1)± 1.45 61.82 ( 4)± 3.61 18.16 ( 1)± 3.68 7.19 ( 1)± 1.82 17.92 ( 3)± 0.87 12.03 ( 1)± 0.91 61.76 ( 4)± 0.87 17.58 ( 1)± 2.14 7.77 ( 1)± 1.28
76.51 ( 6 ) 9.58 ( 2 ) 96.50 ( 6 ) 15.43 ( 2 ) 9.30 ( 2 ) 3.00 ( 4 ) 0.23 ( 1 ) 3.81 ( 4 ) 3.27 ( 1 ) 10.44 ( 1 )
25.32 ( 4 ) 8.98 ( 1 ) 67.16 ( 4 ) 14.74 ( 1 ) 7.75 ( 1 ) 10.34 ( 5 ) 0.31 ( 2 ) 21.87 ( 5 ) 5.20 ( 2 ) 10.65 ( 2 )
–
Horizontal CLR 15.77 ( 1)± 1.53 51.90 ( 1)± 3.52 23.88 ( 3)± 4.11 11.06 ( 3)± 2.31 15.13 ( 1)± 0.95 50.45 ( 1)± 2.15 22.78 ( 3)± 2.53 11.56 ( 3)± 1.93
–
17.73 ( 1 )
44.70 ( 1 ) 21.40 ( 3 ) 12.21 ( 3 ) 0.26 ( 1 )
–
–
0.60 ( 1 ) 12.06 ( 4 ) 12.71 ( 4 )
The results of the different calibrated label ranking approaches show a high correspondence to their inner structure . Full CLR shows the highest Hamming and vertical 01 loss among the approaches . When looking at its optimistic Hamming loss and the quite good C Index and one error , this seems to be clearly just a problem of the correct positioning of the virtual labels due to the narrowness and thus ties in the rankings ( see IV D ) . Joined CLR shows a similar behavior . On all but one dataset , it has the best results among the approach for all three ranking losses . The somewhat worse results on the medical dataset suggest that Joined CLR has problems on datasets with many labels being assigned too extreme low or high grades ( see Tab . II ) .
As already mentioned , Horizontal CLR outperforms all other approaches wrt Hamming and vertical 0 1 loss . This is very likely due to the easier positioning of the single calibrating label , especially in comparison to full CLR but also to Joined CLR . On the other hand , Horizontal CLR reveals its disadvantages regarding the prediction of good rankings . It is the worst approach compared to the other pairwise methods wrt C Index and one error . It seems very obvious that the aggregation strategy of selecting the highest seen grade for each label , also used by BR and IBLR ML and proposed by Cheng et al . , is not advantageous wrt ranking quality .
In summary , the pairwise approaches generally outperform all other approaches on the used ranking losses . Especially the full and joined decompositions provide a clear advantage when good label rankings are important . On the other hand , if we desire good predictions for each label independently ( hence for each ordinal problem separately ) , then Horizontal CLR is the most appropriate method among all evaluated techniques in our experiments .
These two main results make us confident that learning by pairwise comparisons has a natural access to the inner structure of GMLC problems . Moreover , it was shown that pairwise learning provides a flexible adaptation to different objectives by adjusting decomposition and aggregation . The very low optimistic Hamming losses of the CLR approaches additionally promise an even better result through finding a better way of positioning the virtual labels into the global ranking .
VI . CONCLUSIONS
In this work , we introduced pairwise comparisons for representing and learning graded multilabel classification ( GMLC ) problems , which are a combination of ordinal and multilabel classification problems , where each instance is associated with several different grades of relevance to multiple categories . To be able to solve such problems by learning from pairwise comparisons we generalized Calibrated Label Ranking to the case of multiple calibration labels in three different ways , and experimentally compared these approaches to previous work by Cheng et al . [ 2 ] on three different datasets . In these experiments , our approaches achieved the best results in all measured losses .
Nevertheless , we believe that we have not yet fully exploited the information that is inherent in GMLC problems . In particular , we believe that pairwise comparisons have the capacity to achieve even better results by improving the way the predicted ranking is separated into grades . In future work , we plan to investigate alternative aggregation strategies to the horizontal reduction , the use of different voting strategies like weighted voting , as well as novel approaches for introducing the virtual labels into the label rankings . Acknowledgements : This research has been partially funded by the German Science Foundation ( DFG ) . We would like to thank Weiwei Cheng and Eyke Hüllermeier for fruitful discussions and making their data and algorithms available .
REFERENCES
[ 1 ] G . Tsoumakas , I . Katakis , and I . P . Vlahavas , “ Mining multilabel data , ” in Data Mining and Knowledge Discovery Handbook . Springer , 2010 , pp . 667–685 .
[ 2 ] W . Cheng , K . Dembczy´nski , and E . Hüllermeier , “ Graded multilabel classification : The ordinal case , ” in Proceedings of the 27th International Conference on Machine Learning , 2010 .
[ 3 ] D . Jannach , M . Zanker , A . Felfernig , and G . Friedrich , Recommender Systems : An Introduction . Cambridge Univ . Press , 2010 . [ 4 ] C . Brinker , E . Loza Mencía , and J . Fürnkranz , “ Graded multilabel classification by pairwise comparisons , ” TU Darmstadt , Tech .
[ 5 ] J . Fürnkranz , E . Hüllermeier , E . Loza Mencía , and K . Brinker , “ Multilabel classification via calibrated label ranking , ” Machine Learning , vol . 73 , no . 2 , pp . 133–153 , Jun . 2008 .
[ 6 ] E . Frank and M . Hall , “ A simple approach to ordinal classification , ” in Proceedings of the 12th European Conference on Machine Learning ( ECML 01 ) , 2001 , pp . 145–156 .
Rep . TUD KE 2014 01 , 2014 . [ Online ] . Available : http://www . ketu darmstadtde/publications/reports/tud ke 2014 01pdf
[ 7 ] E . Hüllermeier , J . Fürnkranz , W . Cheng , and K . Brinker , “ Label ranking by learning pairwise preferences , ” Artificial Intelligence , vol . 172 , no . 16 17 , pp . 1897–1916 , 2008 .
