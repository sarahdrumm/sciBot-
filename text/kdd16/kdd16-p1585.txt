Fast Component Pursuit for Large Scale Inverse
Covariance Estimation
‡Department of Computer Science and Engineering , Hong Kong University of Science and Technology lhan@statrutgersedu ; zhangyu@cseusthk ; tzhang@statrutgersedu
Lei Han† , Yu Zhang‡∗ , Tong Zhang†§ †Department of Statistics , Rutgers University
§Baidu Inc . Beijing , China
ABSTRACT The maximum likelihood estimation ( MLE ) for the Gaussian graphical model , which is also known as the inverse covariance estimation problem , has gained increasing interest recently . Most existing works assume that inverse covariance estimators contain sparse structure and then construct models with the 1 regularization . In this paper , different from existing works , we study the inverse covariance estimation problem from another perspective by efficiently modeling the low rank structure in the inverse covariance , which is assumed to be a combination of a low rank part and a diagonal matrix . One motivation for this assumption is that the lowrank structure is common in many applications including the climate and financial analysis , and another one is that such assumption can reduce the computational complexity when computing its inverse . Specifically , we propose an efficient COmponent Pursuit ( COP ) method to obtain the low rank part , where each component can be sparse . For optimization , the COP method greedily learns a rank one component in each iteration by maximizing the loglikelihood . Moreover , the COP algorithm enjoys several appealing properties including the existence of an efficient solution in each iteration and the theoretical guarantee on the convergence of this greedy approach . Experiments on large scale synthetic and realworld datasets including thousands of millions variables show that the COP method is faster than the state of the art techniques for the inverse covariance estimation problem when achieving comparable log likelihood on test data .
Keywords Inverse Covariance Estimation ; Component Pursuit ; Large Scale Data ; Greedy Algorithm
INTRODUCTION
1 . Suppose there are n instances {x1 , . . . , xn} sampled from a Gaussian distribution N ( µ , Σ ) , where each instance xi ∈ Rp ( 1 ≤ i ≤ n ) lies in a p dimensional space , µ ∈ Rp is the mean ,
∗The first two authors contributed equally . and Σ ∈ Rp×p is the covariance matrix . An important and challenging problem is to recover Σ or its inverse Σ−1 in a highdimensional setting where n p . Estimating the inverse covariance matrix has attracted a lot of interests in several fields including machine learning , signal processing , computational biology and so on , since it can reveal the dependence among the p attributes [ 28 , 11 , 3 ] . The inverse covariance matrix is estimated by maximizing the log likelihood as log |Θ| − S , Θ , max Θ0 or equivalently minimizing the negative log likelihood ( NLL ) :
− log |Θ| + S , Θ , min Θ0 n i=1 xi is the mean of the samples , and S = 1
( 1 ) where Θ is the inverse covariance estimator , Θ 0 indicates that n Θ is positive definite , | · | denotes the determinant of a square matrix , ·,· denotes the dot product between two matrices or vectors , i=1(xi− ˆµ = 1 ˆµ)(xi − ˆµ)T is the sample covariance matrix . n If directly solving problem ( 1 ) , we can obtain an analytical solution for Θ as Θ = S−1 . Under the high dimensional setting where n p , S is rank deficient and hence this analytical solution is ill posed . In order to make the problem well defined , some regularizers are used to constrain Θ and a widely used one is the 1 regularization [ 28 , 11 , 3 ] which assumes that Θ is sparse with the objective function formulated as n g(Θ ) = − log |Θ| + S , Θ + ρΘ1 ,
( 2 ) min Θ0 where ρ is a regularization parameter that controls the trade off between the sparseness of Θ and the fitness to the data .
A large body of works have been devoted to solving problem ( 2 ) recently [ 4 , 6 , 11 , 23 , 24 , 25 , 16 , 17 , 26 ] , among which the stateof the art methods including the QUIC [ 16 ] , Big QUIC [ 17 ] and BCDIC [ 26 ] methods can handle Θ with billions of entries under the assumption that Θ is sparse . Those methods commonly use Newton proximal approaches , where a quadratic approximation is made and one key step is to calculate the inverse of Θ , to minimize the NLL . Obviously , the computational bottleneck in those methods is that they need to compute the matrix inverse Θ−1 in each iteration , which is computationally heavy when p is very large . Although the Big QUIC and BCDIC methods alleviate this problem by splitting the huge matrix Θ into blocks and use some cheaper operations , eg , solving some linear systems , to update the corresponding blocks in Θ−1 , the matrix inverse operation , whose complexity is O(p3 ) , is still unavoidable . Actually , almost all the existing methods to solve problem ( 2 ) have this problem . Moreover , in the QUIC , Big QUIC and BCDIC methods , an operation used to
1585 largely improve the efficiency is to restrict the number of updated positions in Θ and this operation works well when the optimal Θ is very sparse , corresponding to a situation that the regularization parameter ρ in problem ( 2 ) has a large value . To see this , empirical studies in those works [ 16 , 17 , 26 ] choose ρ such that the optimal Θ has only 10p non zero entries out of a total number of p2 entries and so only a very small fraction ( ie , 10/p ) in the optimal Θ can have non zero values . Therefore , although those works claim that their methods can handle a covariance matrix with billions of entries , only a small number of non zero values are actually computed . Empirically we find that the QUIC , Big QUIC , and BCDIC methods are not very efficient when ρ has a smaller value . Moreover , an extremely sparse Θ learned in those works may fail to recover the true relations between attributes .
In this paper , we investigate the inverse covariance estimation problem from another perspective by modeling the low rank structure contained in Θ . One motivation for learning the low rank structure in Θ is that the low rank structure is common in many applications . For example , in climate research , spatially close locations usually exhibit strong dependencies in the climate attributes and such geographical consistency usually leads to low rank structure in the data [ 14 , 2 , 27 ] . Similarly , in traffic analysis , strong local correlations have been detected on large scale traffic networks and hence low rank structure exists [ 13 ] . Moreover , in computational finance , a large body of works have focused on estimating nearly low rank covariance or precision matrices for economy and stock analysis [ 9 , 10 , 7 , 8 ] . Moreover , in addition to the generality of the low rank structure in various applications , this assumption can bring the computational benefit since the matrix inverse Θ−1 required in each iteration can be computed in lower complexity .
Specifically , we propose a COmponent Pursuit ( COP ) method which assumes that the inverse covariance is a combination of a diagonal matrix and a low rank matrix which can be sparse . In order to obtain the low rank part in Θ , the COP method greedily learns a rank one component in each iteration by maximizing the log likelihood , where each rank one component can be sparse . The subproblem associated with each rank one component is shown to be non convex under the high dimensional setting but due to the special structure of the subproblem , we can prove that all its local optimums have the globally optimal objective value , making the optimization easier . We further show that the greedy COP algorithm inherently enjoys several appealing properties including the existence of an efficient solution for each subproblem and the theoretical guarantee on the convergence of this greedy approach . Compared with most existing methods whose complexity is O(p3 ) , the proposed COP method only takes O(p2 ) operations . Experiments on large scale synthetic and real world datasets show that the proposed COP method is faster than the state of the art methods for large scale inverse covariance estimation when achieving comparable log likelihood on test data . Notations : We use lower case letters for scalars , bold face and lower case letters for vectors , and bold face and upper case letters for matrices . tr(· ) denotes the trace of a square matrix . rank(· ) denotes the rank of a matrix . diag(· ) converts a vector to a diagonal matrix or extracts the diagonal entries in a square matrix to form a vector . · 2 denotes the 2 norm of a vector . · ( cid:63 ) denotes the 2 norm of a matrix , which equals the maximum eigenvalue of a square matrix .
2 . RELATED WORK
Most of the previous studies [ 4 , 6 , 11 , 23 , 24 , 25 , 16 , 17 , 26 ] assume that the inverse covariance matrix is sparse and propose different optimization algorithms to solve problem ( 2 ) . Different from those approaches , we aim to learn low rank structure in the inverse covariance matrix .
Similar to our work , some recent methods investigate other structures of the inverse covariance instead of learning with pure sparsity . For example , in [ 23 , 14 , 17 ] , the inverse covariance matrix is assumed to have diagonal block structure , where each diagonal block matrix is sparse , when the attributes can be divided into several groups with each one containing similar attributes . Moreover , the latent Gaussian graphical model ( LGGM ) proposed in [ 5 ] assumes that the inverse covariance is equal to the difference between a sparse matrix and a low rank matrix , and two algorithms [ 22 , 15 ] including the alternating direction method and Newton proximal method have been proposed for the LGGM method . However , these methods [ 23 , 14 , 17 ] still learn the sparse inverse covariance and the LGGM method treats the sparse part as a dominate part . Moreover , computing the matrix inverse with O(p3 ) complexity is unavoidable in the LGGM method and even worse , it has to recover the low rank part via the eigen decomposition in each iteration , which also costs O(p3 ) . Different from these algorithms , the proposed COP method focuses on learning the low rank part and greedily pursuits a rank one component in each iteration , whose complexity is O(p2 ) .
The proposed COP method seems related to the principal component analysis ( PCA ) [ 18 ] but they are different , since the PCA assumes the covariance matrix is a sum of a low rank part and a diagonal one but in the proposed COP method , the inverse covariance matrix is a combination of a low rank part and a diagonal one , implying that the covariance matrix equals the difference between a diagonal part and a low rank one .
3 . MOTIVATION AND PROBLEM SETUP In this section , we formally present the motivation and define the problem . In order to make the inverse covariance Θ positive definite to satisfy the constraint of problem ( 1 ) , we assume that Θ is combination of two matrices , ie , Θ = L + P , where L is a low rank positive semidefinite matrix and P is a positive definite diagonal matrix . Such assumption on the structure of L and P is motivated by the solution of problem ( 1 ) as revealed in the following corollary .
COROLLARY 1 . The optimal solution Θ∗ of problem ( 1 ) sat isfies the following condition :
Θ
∗ 1 S(cid:63 )
I , where I is an identity matrix with appropriate size and A B implies that A− B is positive semidefinite for two square matrices A and B .
I
1S(cid:63 )
I where
+ 1S(cid:63 )
Corollary 1 can be directly proved by theorems in [ 3 , 21 ] and thus its proof is omitted here . From Corollary 1 , Θ∗ can be rewritΘ∗ − 1S(cid:63 ) ten as Θ∗ = I is diagonal and Θ∗ − 1S(cid:63 ) I can be assumed to capture the low rank structure . Inspired by this decomposition , we just assume that L is a low rank positive definite matrix and P = diag(η ) is a diagonal matrix where η ∈ Rp with each entry , ie , ηi , positive . As we will see later , such assumption on the structure of Θ can bring computational benefit since the complexity to compute Θ−1 reduces from O(p3 ) to O(p2 ) . Then we are ready to present the problem formulation . Given the sample covariance matrix S ∈ Rp×p , we consider the inverse covariance estimation problem by assuming a low rank plus diagonal
1586 structure as
Θ
L(Θ ) = − log |Θ| + S , Θ
( 3 ) min st Θ = L + P , P = diag(η ) , ηi > 0 , L 0 , rank(L ) ≤ r , where r p is a pre defined rank . In the next section , we propose the efficient COP method to solve problem ( 3 ) .
4 . THE COP METHOD
In this section , we show how to solve problem ( 3 ) efficiently . Since there are two parts , L and P , in problem ( 3 ) , we use an alternating method to solve it . That is , in each iteration , we first optimize problem ( 3 ) with respect to ( wrt ) P by fixing L and then estimate L with P fixed , where L is learned by pursuing its rank one components greedily . 4.1 Learning Diagonal Part
When the low rank component L is fixed , the problem wrt the diagonal part P is h(P ) = − log |L + P| + S , P min
P st P = diag(η ) , ηi > 0 .
( 4 )
It is easy to prove that problem ( 4 ) is convex wrt P or η and we can use some gradient descent method to solve it directly , where the gradient of the objective function in problem ( 4 ) is −1 ) + diag(S ) ,
∇ηh(P ) = −diag((L + P ) where ( L + P)−1 = P−1− P−1U(I + UT P−1U)−1UT P−1 by utilizing the low rank structure of L that L equals UUT for some low rank U and hence it can be computed efficiently . Then , with a carefully chosen step size as [ 16 , 17 , 15 ] , the positiveness of ηi ’s can be guaranteed in each iteration .
Moreover , at the beginning of the COP algorithm , L is set to be a zero matrix and the problem for P is formulated as min
P
− log |P| + S , P = − p i=1 log ηi + diag(S ) , η
, for 1 ≤ i ≤ p , where sij which has an analytical solution ηi = 1 sii denotes the ( i , j)th element in S and sii is positive since S is a covariance matrix . We use this analytical solution as the initialization for P . 4.2 Component Pursuit for Low Rank Part
With a fixed P , we aim to learn the low rank part L efficiently . We propose to pursue its rank one components of L iteratively . When P is fixed , the problem wrt L can be formulated as min
L st
− log |L + P| + S , L L 0 , rank(L ) ≤ r .
( 5 )
In order to make the whole algorithm efficient , we aim to learn the rank one components in L greedily and hence in the ( k+1)th iteration we formulate the estimation Lk+1 as Lk+1 = Lk +uk+1uT k+1 where Lk is the low rank estimation obtained until the kth iteration and uk+1 is the rank one component to be learned in the ( k + 1)th iteration . By defining Mk = Lk + Pk , the subproblem wrt uk+1 in the ( k + 1)th iteration can be formulated as
F ( uuT ) − log |Mk + uuT| + S , uuT ,
( 6 ) min u which can be simplified by omitting some constant terms as + S , uuT . f ( u ) − log
1 + uT M min
−1 k u u
( 7 )
Based on problem ( 7 ) , we are also interested in learning structured components . For example , in many situations , the rank one component in the low rank structure can be sparse [ 29 ] . To obtain sparse components via the 1 regularization , a simple variant of problem ( 7 ) can be formulated as
− log min u
1 + uT M
−1 k u
+ S , uuT + γu1 ,
( 8 ) where γ > 0 is a regularization parameter controlling sparsity in the rank one component vector u .
Here we investigate both problems ( 7 ) and ( 8 ) . For the two problems , the following theorem with its proof in the appendix shows that they are non convex under the high dimensional setting .
THEOREM 1 . When n p , problems ( 7 ) and ( 8 ) are non convex wrt u .
According to Theorem 1 , we could only find a local optimum of uk+1 , making the greedy algorithm hard to learn a globally optimal rank one component of L in each iteration . Fortunately , we find that all the local optimums of problem ( 7 ) have the same globally optimal objective value of problem ( 6 ) according to the following theorem .
THEOREM 2 . For problem ( 7 ) , if u is a rank deficient local minimum of f ( u ) , then U = uuT is a global minimum of F ( U ) , ie , all the local optimums have the same globally optimal objective value in problem ( 6 ) .
Theorem 2 allows us to use any optimization method , which can find a local optimum , to solve problem ( 7 ) . Generally , we can use gradient descent algorithms since the objective function f ( · ) is differentiable and its gradient can be computed as
∇uf ( u ) = − 2M
−1 k u −1 1 + uT M k u
+ 2Su .
For problem ( 8 ) , there is no result similar to Theorem 2 . However , we can use general proximal gradient ( GPG ) methods [ 12 , 20 ] to solve it efficiently by using the optimal solution of problem ( 7 ) as the initialization to speedup the convergence . The entire greedy COP algorithm is depicted in Algorithm 1 .
Algorithm 1 The COP algorithm . Input : S , r ; Output : ˆΘ ; 1 : Initialize P0 and set M0 = P0 , k = 0 ; 2 : repeat 3 : Solve problem ( 7 ) or ( 8 ) with fixed Pk ; Lk+1 = Lk + u∗ 4 : 5 : Mk = Lk + Pk ; −1 6 : k+1 ; 7 : 8 : 9 : until k > r or some convergence criterion is satisfied 10 : ˆΘ = Mk ;
Compute M Update Pk with fixed Lk ; k := k + 1 ; k+1u∗T k+1 ;
1587 5 . THEORETICAL ANALYSIS
In this section , we theoretically analyze the COP method , where we derive an efficiently analytical solution for problem ( 7 ) and prove the convergence of the COP algorithm in Algorithm 1 .
We first present some interesting properties , which set the stage for the introduce of our main results , of the COP method .
PROPOSITION 1 . Assume Mk is the matrix obtained in the kth iteration of Algorithm 1 . If there exists a vector a ∈ Rp that then by defining
α = aT M
−1 k a > aT Sa > 0 ,
( 9 )
1 aT Sa
−
1 aT M
−1 k a and u = αa ,
( 10 ) we have L(Mk + uuT ) < L(Mk ) . Otherwise , adding any rankone component to Mk will not decrease the NLL , implying that Algorithm 1 will stop at the kth iteration .
Proposition 1 provides the necessary condition , ie , Eq ( 9 ) , for the convergence of the COP method . Note that Proposition 1 does not require that u should be a local optimum of problem ( 7 ) or ( 8 ) .
PROPOSITION 2 . Suppose a vector a satisfies Eq ( 9 ) and define c = aT M aT Sa > 1 . Then , using the definitions in Eq ( 10 ) , the decrease of the NLL in the two successive iterations , ie L(Mk)− L(Mk + uuT ) , is a monotone increasing function wrt c :
−1 k a
L(Mk ) − L(Mk + uuT ) q(c ) = log c +
− 1 ,
1 c
( 11 ) where c > 1 .
Proposition 2 implies that in order to achieve fast decrease in the NLL by adding a rank one component to Mk , we need to choose the maximum value of c . Until now , both the Propositions 1 and 2 hold for Algorithm 1 when solving either problem ( 7 ) or ( 8 ) , since those results are obtained by analyzing the difference of the NLL values in two successive iterations . When we solve problem ( 7 ) based on the COP algorithm , we can obtain an analytical solution for it with the detailed result shown in the following proposition .
PROPOSITION 3 . If there exists a vector a satisfying Eq ( 9 ) , then problem ( 7 ) is equivalent to the following Rayleigh quotient problem :
−1 k a c aT M aT Sa max a st aT Sa > 0 ,
( 12 ) which admits an analytical solution by solving the generalized eigen−1 k a∗ = λ∗Sa∗ with λ∗ and a∗ as the decomposition problem M largest eigenvalue and the corresponding eigenvector . Moreover , c(k+1 ) max , ie , the maximum value that c can reach in the ( k + 1)th iteration of Algorithm 1 , can be computed as ( a∗)T M ∗ ( a∗)T Sa∗ = λ c(k+1 ) max = max
−1 k a∗
−1 k a aT M aT Sa
( 13 )
= a
.
In Proposition 3 , the largest eigenvalue λ∗ and eigenvector a∗ of the generalized eigen decomposition problem can be computed efficiently by the power method [ 19 ] . Moreover , Proposition 3 implies that solving the Rayleigh quotient problem also provides a way to check whether Eq ( 9 ) can be satisfied in the ( k + 1)th itmax = λ∗ > 1 holds or not . When eration by testing whether c(k+1 ) solving problem ( 8 ) instead , we directly check Eq ( 9 ) based on the component obtained by the GPG method to determine whether the COP algorithm needs to be terminated .
In the following theorems , we present the analytical solution for problem ( 7 ) and prove the convergence of the COP algorithm in Algorithm 1 .
THEOREM 3
( ANALYTICAL SOLUTION ) . Let Mk be the matrix defined in step 5 of Algorithm 1 in the kth iteration and denote by λ∗ and a∗ the largest eigenvalue and the corresponding eigen−1 k a∗ = vector of the generalized eigen decomposition problem M λ∗Sa∗ . Then u∗ , which is defined as
1
( a∗)T Sa∗
0 ,
∗ u
=
,1 − 1
λ∗ · a∗ , if λ∗ > 1 , otherwise .
( 14 ) is a local optimum of problem ( 7 ) in the ( k + 1)th iteration .
THEOREM 4
( CONVERGENCE ) . In the COP algorithm shown in Algorithm 1 , which solves either problem ( 7 ) or ( 8 ) , the NLL decreases iteratively until convergence .
Theorems 3 and 4 provide important guarantees for the proposed
COP method .
6 . SPEEDUP IN HIGH DIMENSIONS
According to Proposition 3 and Theorem 3 , a key step in the COP method is solving the Rayleigh quotient problem ( 12 ) if we want to adopt the analytical solution for problem ( 7 ) or use it to initialize the estimator in problem ( 8 ) . Both Eq ( 9 ) and problem ( 12 ) require that ( a∗)T Sa∗ > 0 for the optimal a∗ or equivalently a∗ lies in the range space of S . We can rewrite S as S = XT X if we assume that the data samples are normalized to have zero sample mean and based on this reformulation , we can see that the range space of S is spanned by X , implying that a∗ lies in the row space of X . Hence we can represent a as a = XT b where b ∈ Rn contains the spanning coefficients . Accordingly problem ( 12 ) can be reformulated as bT,XM k XT b
−1 bT ( XSXT ) b
∗ b
= arg max b
.
( 15 )
Problem ( 15 ) is still a Rayleigh quotient problem which can be solved by the power method . One advantage to solve problem ( 15 ) instead of problem ( 12 ) is that the size of matrices in the generalized eigen decomposition problem ( 15 ) is n × n which is much smaller than that of problem ( 12 ) under the high dimensional setting where n p , leading to a much more efficient implementation and a significant speedup . Moreover , when solving problem ( 15 ) , we only need to store the data matrix X instead of the sample covariance matrix S as in problem ( 12 ) , which can largely reduce the storage requirement . For the case where n > p , we still solve problem ( 12 ) since in this situation the null space of S is empty with a large probability .
7 . COMPLEXITY ANALYSIS
In this section , we discuss the complexity of the proposed COP method in Algorithm 1 and compare with existing approaches . −1 k+1 is In each iteration of Algorithm 1 , the matrix inverse M k+1 where u∗ k+1 is needed in step 6 . Since Mk+1 = Mk + u∗T −1 a vector , we can efficiently compute M k+1 as −1 −1 k+1u∗T k u∗ k+1M k −1 1 + u∗T k u∗ k+1M
−1 k+1 = M k − M −1 k+1u∗
M k+1
,
1588 −1 which only needs O(p2 ) operations because M k has already been stored during the previous iteration . Step 3 in Algorithm 1 when we consider problem ( 7 ) needs to solve problem ( 12 ) or ( 15 ) , whose complexity is O(min(p2 , n2) ) . When solving problem ( 8 ) , the complexity of the GPG method is no more than O(p2 ) , and when we adopt the optimal solution of problem ( 7 ) as the initialization , the GPG method will converge fast in considerably few iterations . Moreover , updating the diagonal matrix Pk in each iteration costs O(p2 ) . In a word , the overall time complexity of the COP algorithm is O(rp2 ) where r is the pre defined rank satisfying r p . Moreover , the storage requirement for the the two matrices ( ie , L and P ) in the COP algorithm is a linear function wrt p , since we only need to keep the diagonal elements in Pk and the component vectors {u∗
1,··· , u∗ k} .
−1 k
All the sparse inverse covariance estimation methods including [ 4 , 6 , 11 , 24 , 25 , 16 ] use the first order or second order proximal methods to solve problem ( 2 ) where computing the inverse of a p × p matrix Θ is needed and costs O(p3 ) . So the computational complexity of the COP method is lower than those of the aforementioned approaches . For the LGGM methods [ 5 , 22 , 15 ] , which assume the inverse covariance has a sparse minus lowrank structure , they need to compute the inverse of p × p matrices with O(p3 ) cost and also need additional O(p3 ) operations for the eigen decomposition to update the low rank part , making it have higher complexity than the proposed COP method . Moreover , as discussed before , the storage complexity of the COP algorithm is O(p ) but those of the above approaches depend on the number of non zero entries in Θ , which could be O(p2 ) in the worst case .
8 . EXPERIMENTS
In this section , we conduct experiments on both synthetic and real world datasets to evaluate the proposed COP method and the 1 regularized COP method ( COP 1 ) . 8.1 Experimental Settings
We compare with a number of state of the art methods for the inverse covariance estimation problem , including the QUIC [ 16 ] , Big QUIC [ 17 ] , BCDIC [ 26 ] and QUIC&Dirty [ 15 ] methods.1 Among those methods , the QUIC , Big QUIC and BCDIC methods are the state of the art sparse inverse covariance estimation methods , while the QUIC&Dirty method is currently the most efficient algorithm for the LGGM problem . The implementations for the QUIC , Big QUIC , BCDIC and QUIC&Dirty methods adopt the recommended settings as provided in their works and the Big QUIC and BCDIC methods are parallelized with multiple cores . All the experiments are performed on a machine with dual 6 core Intel Xeon X5650 2.66GHz processor and 32GB RAM .
In the experiments , we split the data into a training set containing 90 % of the samples and a test set with the rest samples . We use Strain to denote the sample covariance matrix on the training set and Stest as the sample covariance matrix on the test set . All the data are normalized such that the diagonal elements in both Strain and Stest are all ones . By following [ 16 , 17 , 26 ] , we choose the regularization parameter ρ in problem ( 2 ) for the QUIC , BigQUIC and BCDIC methods such that the estimated ˆΘ contains approximately 10p non zero elements . For the QUIC&Dirty method , we set its regularization parameter ρ1 for the sparse part to be ρ in problem ( 2 ) and choose another regularization parameter ρ2 for
1The codes for the QUIC , Big QUIC and QUIC&Dirty methods can be downloaded from http://wwwstatucdavisedu/~chohsieh/ and that for the BCDIC method can be obtained at http://www . javierturekcom/software/ the low rank part from {0.1 , 1 , 10} . For the COP 1 method , we choose the best γ from the candidate set {10−5 , 10−4,··· , 10−1} . 8.2 Experiments on Synthetic Data
In this section , we conduct experiments on synthetic data to test the performance of the proposed COP and COP 1 methods . 821 Results on Small Scale Data We first generate a dataset of small scale to test the correctness of the theoretical results presented in Section 5 . In order to do this , we generate a matrix A ∈ Rr∗×p , where r∗ = 20 and p = 100 . Each entry in A is sampled from the standard normal distribution N ( 0 , 1 ) . Then we generate the sample covariance matrix S∗ as ( S∗)−1 = AT A + I . We estimate ˆΘ by solving problem ( 1 ) and compare the estimated ˆΘ and ( S∗)−1 to see whether they are exactly the same . In order to see the learned L , we suppose that the diagonal part P is known and set to be the ground truth , ie , the identity matrix I .
Fig 1 shows detailed results of the COP method . Fig 1(a ) depicts the change of the NLL values when increasing the the number of components or equivalently the iterations . Since we are aware of the ground truth of the inverse covariance , we can calculate the ground truth of the NLL value which is illustrated by the red dashed line . We see that the NLL of the COP algorithm decreases in almost a linear rate , and when the rank or equivalently the number of components reaches 20 , which is the ground truth for the rank , the COP method exactly recovers the ground truth of the inverse covariance and the corresponding NLL value is equal to the ground truth . Hence , the COP algorithm stops at the 21st iteration by perfectly recovering the ground truth of the inverse covariance . Fig 1(b ) plots change of the λ∗ against the rank . As expected , the value of λ∗ decreases when increasing the rank and when the number of iterations reaches 21 , λ∗ becomes 1 , which implies that Eq ( 9 ) is no longer satisfied , leading to the termination of the COP algorithm . These observed results well match the theoretical results in Section 5 . 822 Results on Large Scale Data Similar to the previous section , we generate a matrix A ∈ Rr∗×p , where r∗ = 100 and each entry in A is sampled from the standard normal distribution N ( 0 , 1 ) . The true covariance S∗ is generated in the same way as ( S∗)−1 = AT A + I . In this case , we generate n = 1000 samples , which are stored in the data matrix X ∈ Rn×p , from N ( 0 , S∗ ) . We vary p from 5 , 000 to 25 , 000 at an interval of 5 , 000 to evaluate the performance of all the methods . Since the sparse inverse covariance estimation methods including the QUIC , Big QUIC and BCDIC methods solve problem ( 2 ) and the QUIC&Dirty method solve the LGGM problem , the comparison among them is not straightforward . In order to make fair evaluations , we compare the running time of different methods when they achieve the same or comparable NLL on the test dataset and the method with the lowest running time is the most efficient one . Moreover , we compare the COP and COP 1 methods with the sparse inverse covariance estimation methods and the QUIC&Dirty method separately .
Table 1 shows the results by comparing the proposed COP and COP 1 methods with the sparse inverse covariance estimation methods . In Table 1 , there are seven groups of columns . The first group of columns denotes different settings for p . The second group shows the value of the regularization parameter ρ in problem ( 2 ) , the number of non zero ( NNZ ) entries in the estimated ˆΘ which is around 10p by following experimental settings in the original works , and the NLL on the test data denoted by NLLte for the
1589 ( a ) The NLL for training vs iteration .
( b ) λ∗ vs iteration .
Figure 1 : The detailed results of the COP method on a small scale synthetic data .
Table 1 : Comparison of the running time ( in seconds ) between the sparse inverse covariance estimation methods , ie , QUIC , BigQUIC , BCDIC , and the proposed methods , ie , COP and COP 1 , on synthetic data . The detailed settings for various methods are reported , including the setting of ρ , the number of non zeros ( NNZ ) , the rank r , the parameter γ , and the NLL on the test data denoted by NLLte . ρ
Big QUIC BCDIC
Data
COP 1 p = 5 , 000 p = 10 , 000 p = 15 , 000 p = 20 , 000 p = 25 , 000
0.218 0.231 0.239 0.244 0.248
NNZ 51,296 103,422 153,454 207,306 258,850
NLLte 4967.5 9959.3 14966.4 19970.1 24980.3
QUIC 79.8 271.8 798.0 1821.6 4709.2
64.9 234.8 622.7 1349.0 3828.2
50.7 191.4 404.3 696.3 1087.3 r 11 16 16 17 12
NLLte 4965.3 9959.2 14966.0 19969.2 24980.1
COP 15.0 87.9 200.9 376.8 401.0 r 14 21 20 22 15
γ 10−5 10−5 10−5 10−5 10−5
NLLte 4965.9 9959.4 14966.2 19968.9 24980.5
26.1 136.7 312.5 584.3 560.8
Table 2 : Comparison of the running time ( in seconds ) between the QUIC&Dirty method and the proposed methods , ie COP and COP 1 , on synthetic data . The detailed settings for various methods are reported , including the setting of ρ1 and ρ2 , the rank r , the parameter γ , and the NLL on the test data denoted by NLLte . ‘ ’ indicates that the QUIC&Dirty method does not return a result after running over 5 hours for all choices of ρ2 ∈ {0.1 , 1 , 10} . QUIC&Dirty
COP 1
Data
ρ1 p = 5 , 000 p = 10 , 000 p = 15 , 000 p = 20 , 000 p = 25 , 000
0.218 0.231 0.239 0.244 0.248
ρ2 1 1 1
NLLte 4953.8 9945.8 14941.3
881.9 2795.0 8527.9 r 16 24 33 50 50
NLLte 4951.9 9945.1 14940.9 19910.6 24918.0
COP 23.4 132.3 413.7 1121.1 1423.0 r 21 30 41 66 68
γ 10−5 10−5 10−5 10−5 10−5
NLLte 4942.3 9946.1 14941.5 19911.7 24917.6
40.3 197.5 645.6 1757.7 2202.9
QUIC , Big QUIC and BCDIC methods . Since all the three methods solve the same problem ( ie , problem ( 2) ) , their NNZ ’s and NLLte ’s are nearly the same and thus we only report the results obtained from the BCDIC method . The third group reports the running time for the QUIC , Big QUIC and BCDIC methods . The forth group of columns shows the learned rank r and the NLLte of the COP method , and the fifth group reports its running time . Similarly , the last two columns show the results for the COP 1 method . From the results , the COP and COP 1 methods usually needs 10 to 20 components to achieve comparable NLLte with those of the QUIC , Big QUIC and BCDIC methods on all the synthetic datasets and the COP and COP 1 methods are always faster than other methods under all the settings .
The comparison results among the QUIC&Dirty , COP and COP1 methods are recorded in Table 2 . Table 2 has a similar format to Table 1 and it shows all the detailed settings and the running time of the three methods . When p is lower than 20 , 000 , the COP and COP 1 methods are much more efficient than the QUIC&Dirty method when they achieve similar NLLte . When p becomes larger , the QUIC&Dirty method cannot provide the estimation in reasonable time ( ie , 5 hours ) and hence it can only handle medium scale datasets . For the COP and COP 1 methods , we try larger ranks , ie , 50 , and they still obtain lower NLLte in reasonable time .
By comparing Table 1 and Table 2 , we find that the QUIC&Dirty method has slightly better testing NLL values than the sparse inverse covariance estimation methods when their regularization pa
Rank ( Iteration)15101520Training NLL01020304050607080The NLL value in COPThe best NLLRank ( Iteration)151015206*1501001502002506* in COPHorizontal line at 6*=11590 ( a ) The NLL for training vs iteration .
( b ) λ∗ vs iteration .
Figure 2 : Detailed results on synthetic data when p = 5 , 000 . rameters , which control the sparsity , are set to the same value . This observation reveals that considering both the low rank and sparse structure can fit the data better than purely sparse inverse covariance in these synthetic datasets . However , training the QUIC&Dirty method is much more computational expensive and hence it can hardly process large scale data as shown in Table 2 .
In Tables 1 and 2 , the COP 1 method does not perform better than the non regularized one , and it generally needs more ranks and running time to obtain comparable NLLte with the COP method . This is probably because under the synthetic setting , the ground truth does not contain sparse components .
In addition , we provide more details for the COP method in Fig 2 which plots iterative results of the COP method on synthetic data with p = 5 , 000 . We set the total number of ranks to be 101 in this case . Fig 2(a ) plots the change of the NLL on the training data wrt the number of iterations . Again , we find that the NLL on the training set decreases in a linear rate against the number of iterations . Fig 2(b ) shows the value of λ∗ in each iteration and we see that λ∗ becomes smaller iteratively while it is always larger than 1 even at the 101st iteration , implying that the algorithm can further proceed . Note that in this situation , the ground truth of the rank is 100 but the COP algorithm does not terminate at the 101st iteration . This is reasonable since under this setting where n p , the sampling bias exists in the training data and hence the estimated components are not exactly the true components . 8.3 Experiments on Real World Datasets
In this section , we conduct experiments on large scale real world datasets . We use four datasets from the Gridded Climate Data2 and one stock dataset collected from the Yahoo finance3 , which are also studied in [ 14 ] . The four climate datasets are : ( 1 ) the Northern Hemisphere EASE Grid Weekly Snow Cover and Sea Ice Extent ( Snow ) , which records the weekly snow cover in northern hemisphere on 1.0 latitude × 1.0 longitude grids from January , 1971 to December , 1995 . Each grid is treated as an attribute . By re
2http://wwwesrlnoaagov/psd/data/gridded/ 3http://financeyahoocom/ moving invalid observations , the number of attributes p is 9 , 148 , and the number of samples n is 297 ; ( 2 ) the NCEP/NCAR Reanalysis air data ( Air ) , which contains daily air temperature on the earth with 2.5 latitude × 2.5 longitude global grids . The number of attributes p is 10 , 512 and by following [ 14 ] we use n = 1460 records in year 2001 ; ( 3 ) the CPC Unified Gauge Based Analysis of Daily Precipitation over CONUS ( Precip ) , which focuses on the daily precipitation in USA . The valid data contains p = 13 , 610 attributes and we use n = 3652 observations from year 1997 to year 2006 ; ( 4 ) the NOAA ’s Outgoing Longwave Radiation ( OLR ) Daily Climate Data Record , which provides the OLR records on the earth . In this dataset , p equals 21 , 720 and n is equal to 2903 . For the Stock dataset , we collect p = 21 , 602 stocks with daily closing price recorded in latest 300 days before Dec . 31 , 2015 .
Table 3 reports experimental results for the QUIC , Big QUIC , BCDIC and QUIC&Dirty methods on all the datasets , while Table 4 gives the results of the COP and COP 1 methods . In Table 3 , the QUIC , Big QUIC and BCDIC methods , whose Θ ’s have about 10p non zero entries , have much larger NLL ’s on the test data especially for the Snow , Air , and OLR datasets when comparing with the COP and COP 1 methods in Table 4 . The QUIC&Dirty method has better NLLte than the sparse inverse covariance estimation methods on the Snow and Air datasets , but it fails to learn the model on the larger Precip , OLR and Stock datasets in reasonable time . Under all the settings , we set the rank of the COP method to be 5 , which is good enough to obtain lower NLL ’s on all the test data , and we choose the model parameters for the COP 1 method to obtain similar testing NLL ’s to the COP method . According to Table 4 , in most settings , the COP method not only has better NLLte than the COP 1 method but also performs faster . The exceptions are that on the OLR dataset , the COP 1 method has better predictive performance and that it is slightly faster on the Stock dataset .
Moreover , we provide some additional results for the QUIC , BigQUIC and BCDIC methods on the Snow , Air , OLR and Stock datasets in Table 5 , where their regularization parameters ρ ’s are selected such that the resulting estimators can achieve comparable
Rank ( Iteration)020406080100Training NLL4700475048004850490049505000The NLL value in COPRank ( Iteration)0204060801006*3234363840424446486* in COP1591 Table 3 : Comparison of the running time ( in seconds ) for the QUIC , Big QUIC , BCDIC and QUIC&Dirty methods on real world data . The NNZ ’s for the QUIC , Big QUIC and BCDIC methods are around 10p by choosing their regularization parameter ρ . ‘ ’ indicates that the corresponding methods do not return a result after running over 5 hours for all choices of ρ2 ∈ {0.1 , 1 , 10} . QUIC&Dirty
Big QUIC BCDIC
ρ p
Data Snow Air
Precip OLR Stock
9 , 148 10 , 512 13 , 610 21 , 720 21 , 602
0.982 0.975 0.820 0.988 0.985
NNZ 108,246 105,636 132,200 223,936 221,053
NLLte 10639.1 12250.3 13992.1 25647.9 24814.7
QUIC 282.3 660.5 1680.9 3650.2 3990.6
243.5 539.4 1213.6 2989.0 3212.7
72.0 129.1 483.0 544.2 634.1
ρ1
0.982 0.975 0.820 0.988 0.985
ρ2 10 10
NLLte 10439.0 11965.7
3174.2 7060.8
Table 4 : Comparison of the running time ( in seconds ) for the COP and COP 1 methods on real world data .
Data Snow Air
Precip OLR Stock p
9 , 148 10 , 512 13 , 610 21 , 720 21 , 602 r 5 5 5 5 5
NLLte 9162.3 10635.2 13901.5 21754.0 21632.6
COP 20.7 28.2 50.6 125.1 122.8 r 6 6 6 5 4
γ 10−5 10−5 10−5 10−4 10−4
NLLte 9167.9 10651.6 13921.9 21753.9 21652.1
COP 1
30.2 41.5 65.7 148.5 120.3
Table 5 : Comparison of the running time ( in seconds ) for the QUIC , Big QUIC and BCDIC methods on the Snow , Air , OLR and Stock datasets when decreasing ρ to obtain more non zero elements .
ρ
Data Snow 0.950 Air 0.910 0.950 OLR Stock 0.950
NNZ
568,402 ( ≈ 50p ) 406,888 ( ≈ 40p ) 940,100 ( ≈ 45p ) 928,147 ( ≈ 45p )
NLLte 9404.0 10646.7 24180.9 23990.6
QUIC 1604.3 2117.0 15557.2 17209.1
Big QUIC BCDIC 429.8 594.9 3248.2 3785.5
1253.6 1542.3 13725.0 14632.4
NLL ’s on the test data with those of the COP and COP 1 methods.4 Table 5 does not include the Precip data , because the result reported in Table 3 is already comparable to those of the COP and COP 1 methods . Under this setting , the QUIC&Dirty method still can not return any result in 5 hours and so it is not included . From the results , we can see that in order to achieve lower NLL ’s on the test set of the four datasets , the numbers of the non zero entries in their estimators become larger and as a consequence , the running time of the three methods significantly increases , which again demonstrates the efficiency of the proposed COP and COP 1 methods .
9 . CONCLUSION
In this paper , we proposed an efficient component pursuit ( COP ) method and its 1 regularized variant for the large scale inverse covariance estimation problem by assuming that the inverse covariance is a combination of a low rank matrix and a diagonal matrix . Both theoretical analysis and empirical evaluations demonstrate the effectiveness and efficiency of the proposed methods when compared with the state of the art methods .
As a future direction , we are interested in applying the COP methods to more large scale applications , eg , the gene expression data , where there exists inherent low rank structure among the features . Another future direction is to extend the COP method to deal with more complex structure in the inverse covariance estimation problem , eg , the low rank plus block diagonal structure , since in many applications such as financial analysis , the group information among features is available as a priori information .
4ρ with a value smaller than 0.95 on the Snow , OLR and Stock datasets will lead to memory exceeded problem for the three methods and hence we just set ρ to be 095
Acknowledgments This research was partially supported by NSF IIS 1250985 , NSF IIS 1407939 , NIH R01AI116744 and NSFC 61305071 .
References [ 1 ] F . Bach , J . Mairal , and J . Ponce . Convex sparse matrix factor izations . arXiv preprint arXiv:0812.1869 , 2008 .
[ 2 ] M . T . Bahadori , Q . R . Yu , and Y . Liu . Fast multivariate spatiotemporal analysis via low rank tensor learning . In Advances in Neural Information Processing Systems , pages 3491–3499 , 2014 .
[ 3 ] O . Banerjee , L . El Ghaoui , and A . d’Aspremont . Model selection through sparse maximum likelihood estimation for multivariate Gaussian or binary data . Journal of Machine Learning Research , 9:485–516 , 2008 .
[ 4 ] O . Banerjee , L . E . Ghaoui , A . d’Aspremont , and G . Natsoulis . Convex optimization techniques for fitting sparse Gaussian graphical models . In Proceedings of the International Conference on Machine learning , pages 89–96 , 2006 .
[ 5 ] V . Chandrasekaran , P . A . Parrilo , and A . S . Willsky . Latent variable graphical model selection via convex optimization . The Annals of Statistics , 40(4):1935–1967 , 2012 .
[ 6 ] A . d’Aspremont , O . Banerjee , and L . El Ghaoui . First order methods for sparse covariance selection . SIAM Journal on Matrix Analysis and Applications , 30(1):56–66 , 2008 .
[ 7 ] J . Fan , F . Han , and H . Liu . Page : Robust pattern guided estimation of large covariance matrix . Technical report , Technical report , Princeton University , 2014 .
1592 [ 8 ] J . Fan , Y . Liao , and H . Liu . An overview on the estimation of large covariance and precision matrices . arXiv preprint arXiv:1504.02995 , 2015 .
[ 9 ] J . Fan , Y . Liao , and M . Mincheva . High dimensional covariance matrix estimation in approximate factor models . Annals of Statistics , 39(6):3320 , 2011 .
[ 10 ] J . Fan , Y . Liao , and M . Mincheva . Large covariance estimation by thresholding principal orthogonal complements . Journal of the Royal Statistical Society : Series B ( Statistical Methodology ) , 75(4):603–680 , 2013 .
[ 11 ] J . Friedman , T . Hastie , and R . Tibshirani . Sparse inverse covariance estimation with the graphical lasso . Biostatistics , 9(3):432–441 , 2008 .
[ 12 ] P . Gong , C . Zhang , Z . Lu , J . Z . Huang , and J . Ye . A general iterative shrinkage and thresholding algorithm for non convex regularized optimization problems . In Proceedings of the International Conference on Machine Learning , 2013 .
[ 13 ] L . Han , G . Song , G . Cong , and K . Xie . Overlapping decomposition for causal graphical modeling . In Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 114–122 , 2012 .
[ 14 ] C J Hsieh , I . S . Dhillon , P . Ravikumar , and A . Banerjee . A divide and conquer procedure for sparse inverse covariance In Advances in Neural Information Processing estimation . Systems , 2012 .
[ 15 ] C J Hsieh , I . S . Dhillon , P . K . Ravikumar , S . Becker , and P . A . Olsen . QUIC & DIRTY : A quadratic approximation approach for dirty statistical models . In Advances in Neural Information Processing Systems , pages 2006–2014 , 2014 .
[ 16 ] C J Hsieh , I . S . Dhillon , P . K . Ravikumar , and M . A . Sustik . Sparse inverse covariance matrix estimation using quadratic approximation . In Advances in Neural Information Processing Systems , pages 2330–2338 , 2011 .
[ 17 ] C J Hsieh , M . A . Sustik , I . S . Dhillon , P . K . Ravikumar , and R . Poldrack . BIG & QUIC : Sparse inverse covariance estimation for a million variables . In Advances in Neural Information Processing Systems , pages 3165–3173 , 2013 .
[ 18 ] I . Jolliffe . Principal Component Analysis . Wiley Online Li brary , 2002 .
[ 19 ] C . Lanczos . An iteration method for the solution of the eigenvalue problem of linear differential and integral operators . Journal of Research of the National Bureau of Standards , 45(4):255–282 , 1950 .
[ 20 ] H . Li and Z . Lin . Accelerated proximal gradient methods for nonconvex programming . In Advances in Neural Information Processing Systems , pages 379–387 , 2015 .
[ 21 ] Z . Lu . Smooth optimization approach for sparse covariance selection . SIAM Journal on Optimization , 19(4):1807–1827 , 2009 .
[ 22 ] S . Ma , L . Xue , and H . Zou . Alternating direction methods for latent variable gaussian graphical model selection . Neural Computation , 25(8):2172–2198 , 2013 .
[ 23 ] R . Mazumder and T . Hastie .
Exact covariance thresholding into connected components for large scale graphical lasso . Journal of Machine Learning Research , 13(1):781– 794 , 2012 .
[ 24 ] F . Oztoprak , J . Nocedal , S . Rennie , and P . A . Olsen . Newtonlike methods for sparse inverse covariance estimation . In Advances in Neural Information Processing Systems , pages 755– 763 , 2012 .
[ 25 ] B . Rolfs , B . Rajaratnam , D . Guillot , I . Wong , and A . Maleki . Iterative thresholding algorithm for sparse inverse covariance In Advances in Neural Information Processing estimation . Systems , pages 1574–1582 , 2012 .
[ 26 ] E . Treister and J . S . Turek . A block coordinate descent approach for large scale sparse inverse covariance estimation . In Advances in Neural Information Processing Systems , pages 927–935 , 2014 .
[ 27 ] R . Yu , D . Cheng , and Y . Liu . Accelerated online low rank tensor learning for multivariate spatiotemporal streams . In Proceedings of the 32nd International Conference on Machine Learning , pages 238–247 , 2015 .
[ 28 ] M . Yuan and Y . Lin . Model selection and estimation in the
Gaussian graphical model . Biometrika , 94(1):19–35 , 2007 .
[ 29 ] H . Zou , T . Hastie , and R . Tibshirani . Sparse principal component analysis . Journal of Computational and Graphical Statistics , 15(2):265–286 , 2006 .
APPENDIX A . PROOF OF THEOREM 1 Proof . For problem ( 7 ) , the derivative and the Hessian of f ( u ) can be calculated as ∇uf = − 2M
+ 2Su
( 16 )
−1 k u −1 1 + uT M k u −1 uf = − 2(1 + uT M ∇2 k u)M ( 1 + uT −1 k
4M ( 1 + uT M
−1 k uuT M −1 k u)2
= k − 4M −1 −1 k uk)2 k M + 2S −
2
2
1+uT M is positiveIt is easy to see that −1 k u k u > 0 for any vector u . If S M −1 −1 k , it definite and uT M uf 0 and f ( u ) is convex wrt is easy to see that the hessian ∇2 u . However , under the high dimensional case where S is positive semidefinite but not positive definite due to n p , 2S − is not positive semi definite and it contains at least p − n negative eigenvalues . Moreover , the first term in the right hand side of Eq ( 17 ) is only a rank one matrix . So ∇2 uf is not positive semidefinite and hence f ( u ) is a non convex function wrt u . 2
−1 k u
1+uT M
−1 k
M
2
−1 k uuT M
−1 k
+ 2S
−1 k .
M
( 17 )
1 + uT M
−1 k u −1 < 2 , since M k
B . PROOF OF THEOREM 2 Proof . The proof of Theorem 2 follows directly from the Proposition 4 in [ 1 ] . 2
1593 C . PROOF OF PROPOSITION 1 Proof . By considering the difference between L(Mk ) and L(Mk+ uuT ) , we have L(Mk ) − L(Mk + uuT ) = − log |Mk| + S , Mk + log |Mk + α2aaT| − S , Mk + α2aaT = log
− α2aT Sa . Define l(α , a ) = log,1 + α2aT M k a − α2aT Sa . We inves
1 + α2aT M
−1 k a
−1 tigate whether there exists some pair ( α , a ) such that max α,a l(α , a ) > 0 .
−1 k a and c2 = aT Sa , where When a is fixed , we define c1 = aT M obviously c1 > 0 and c2 ≥ 0 since M −1 is positive definite and k S is positive semidefinite . Then l(α , a ) can be formulated as a function wrt α as l(α ) = log,1 + c1α2 − c2α2 .
( 18 )
The convexity and the extreme value of l(α ) depends on the two scalars c1 and c2 . Fig 3(a ) plots some examples of the function l(α ) when adopting different values for c1 and c2 . By setting ∂l ∂α = 0 we obtain the maximizer of l(α ) as
1
α = c2
0 ,
− 1 c1
, if c1 > c2 , otherwise .
.
( 19 )
From Eq ( 19 ) , if c1 > c2 , plugging Eq ( 19 ) into l(α , a ) gives max u
= max a
L(Mk ) − L(Mk + uuT ) aT Sa −1 k a
−1 k a aT M aT Sa aT M log
+
− 1 .
By defining c = aT M aT Sa , we have
−1 k a c u max
( 20 ) log c +
− 1 ,
∂c = 1 c − 1
L(Mk ) − L(Mk + uuT ) = max c −1 . Then we get ∂q
1 c where q(c ) = log c+ 1 c2 . It is easy to see that the function q(c ) is monotonically increasing when c > 1 , ∂c > 0 . Moreover , since q(1 ) = 0 , we have q(c ) > 0 for because ∂q any c > 1 . Fig 3(b ) plots the curve of q(c ) for c > 1 . Therefore , we can get that L(Mk + uuT ) < L(Mk ) . When c1 ≤ c2 , based on Eq ( 19 ) , we have u = αa = 0 and hence L(Mk)−L(Mk + uuT ) = 0 , which implies that adding an additional rank one component is not helpful to decrease the NLL . If this happens , the greedy algorithm stops . 2
D . PROOF OF PROPOSITION 2 Proof . When condition ( 9 ) is satisfied , combing Eqs . ( 10 ) , ( 19 ) and ( 20 ) , we have
L(Mk ) − L(Mk + uuT ) = q(c ) = log c +
− 1 .
1 c
Based on the proof of Proposition 1 , q(c ) is a monotonically increasing function wrt c for c > 1 . 2
E . PROOF OF PROPOSITION 3 Proof . According to Eq ( 20 ) , the decrease in the NLL becomes faster if c is larger , since q(c ) is monotonically increasing when c > 1 . Therefore , based on the analysis on the Rayleigh quotient problem ( 12 ) , we reach the conclusion . 2
( a ) The curve of l(α )
( b ) The curve of q(c ) for c > 1
Figure 3 : Illustrations of two functions .
F . PROOF OF THEOREM 3 Proof . Based on propositions 1 3 , we only need to check whether u∗ = α∗a∗ is a local optimum of problem ( 7 ) . Since ∇f ( u∗ ) = 0 and ∇2 uf ( u∗ ) 0 , u∗ is a local optimum and we reach the conclusion .
2
G . PROOF OF THEOREM 4 Proof . Proposition 1 implies that adding a rank one component will lead to a lower NLL in the current iteration , if the component vector a satisfies Eq ( 9 ) . Moreover , after adding a rank one component , updating the diagonal part P solves a convex function wrt P , and therefore the NLL will not increase after the updating . So the NLL is guaranteed to decrease during iterations in Algorithm 1 until there is no vector satisfying Eq ( 9 ) and then the algorithm converges . 2
, 6 4 20246l(,) 35 30 25 20 15 10 505c1 = 10 , c2 = 1c1 = 1 , c2 = 1c1 = 0.1 , c2 = 1c012345678910q(c)0051151594
