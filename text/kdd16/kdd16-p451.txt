Domain Adaptation in the Absence of Source Domain Data
Boris Chidlovskii , Stéphane Clinchant and Gabriela Csurka
Xerox Research Centre Europe
6 chemin Maupertuis , Meylan , France
ABSTRACT The overwhelming majority of existing domain adaptation methods makes an assumption of freely available source domain data . An equal access to both source and target data makes it possible to measure the discrepancy between their distributions and to build representations common to both target and source domains . In reality , such a simplifying assumption rarely holds , since source data are routinely a subject of legal and contractual constraints between data owners and data customers . When source domain data can not be accessed , decision making procedures are often available for adaptation nevertheless . These procedures are often presented in the form of classification , identification , ranking etc . rules trained on source data and made ready for a direct deployment and later reuse . In other cases , the owner of a source data is allowed to share a few representative examples such as class means .
In this paper we address the domain adaptation problem in real world applications , where the reuse of source domain data is limited to classification rules or a few representative examples . We extend the recent techniques of feature corruption and their marginalization , both in supervised and unsupervised settings . We test and compare them on private and publicly available source datasets and show that significant performance gains can be achieved despite the absence of source data and shortage of labeled target data .
Keywords Domain adaptation ; classification ; machine learning ; marginalization ; emerging applications
1 .
INTRODUCTION
While huge volumes of unlabeled data are generated and made available in many domains , the cost of acquiring data labels remains high . Domain Adaptation ( DA ) problems arise each time when we need to leverage labeled data in one or more related source domains , to learn a classifier for unseen data in a target domain . The domains are assumed to be related , but not identical in which case it becomes a standard machine learning problem . Such a situation occurs in multiple real world applications . Examples include named entity recognition across different text corpora , object recognition in images acquired in different conditions ( like background scene , object location and pose , view angle changes ) , and many others ( see [ 25 , 34 , 39 ] for a survey on transfer learning and domain adaptation methods ) .
Domain adaptation is particularly critical for service companies operating customer business processes in customer care , human resource and finance . All machine learning components deployed in a given service solution should be customized to a new customer . This entails re annotating data or calibrating the models in order to achieve a contractual performance . For example , in vehicle classification , when an image classification algorithm is re deployed in a new location , better performance is obtained by annotating samples collected on the field . In the brand sentiment management , when a sentiment classifier is re deployed for a new customer , it is critical to tune the classifier to the manner how users talk about their experience with a particular product , etc .
Numerous approaches have been proposed in the last years to address the text and visual domain adaptation to cite just a few [ 3 , 6 , 18 , 19 , 20 , 22 , 23 , 24 , 30 , 32 , 36 ] . The majority of existing methods makes an assumption of freely available source domain data . An equal access to both source and target data allows to measure the discrepancy between their distributions and 1 ) either build representations common to both target and sources , or 2 ) directly reuse some source instances for a better target classification [ 43 ] .
In reality , such a simplifying assumption rarely holds . Source data are often a subject of legal , technical and contractual constraints between data owners and data customers . Beyond privacy and disclosure obligations , customers are often reluctant to share their data . When operating customer care , collected data may include information on recent technical problems which is a highly sensitive topic that companies are not willing to share .
It is more common that just decision making procedures but not source domain data are available for adaptation . These procedures are often presented in the form of classification , identification , ranking etc . rules trained on source data and made ready for a direct deployment and later reuse . In other cases , the owner of a source data is not allowed to share the entire dataset , but some representative source examples such as class means .
In this paper we address the domain adaptation problem in real world applications , where the reuse of source data is limited to classification rules or a few representative examples . We adopt the recent techniques of feature corruption and their marginalization , both in the supervised ( the Marginalized Corrupted Features [ 31 ] ) and unsupervised ( stacked Marginalized Denoising Autoencoder [ 7 ] ) frameworks . We propose several extensions to MCF ad sMDA methods in order to address the adaptation needs with no access to source domain data . We cope with three most typical cases of what is available for adaptation : 1 ) classifiers as a black box , 2 )
451 classifiers with known models and parameters , and 3 ) class representatives .
The remainder of the paper is organized as follows . In Section 2 we present several industrial applications on customer data with a critical need for domain adaptation . In Section 3 we revise the prior art and Section 4 presents how to extend MCF ad sMDA methods to address these adaptation needs , in both supervised and unsupervised settings . Publicly available datasets of Office and Amazon , as well on Xerox ’s Smart Document Management data are described in Section 51 In Section 5 , we describe the experimental setting and report the evaluation results of adapting the source classifiers and representatives on the selected datasets . Section 6 discusses the open questions and concludes the paper .
2 . TARGET APPLICATIONS
In this section , we present three real world applications with a strong domain adaptation need and no access to source domain instances . 2.1 Vehicle Passenger Detection System
Upon a strong demand for vehicle occupancy count ( VOC ) automation in the US tolling and European border crossing , Xerox has developed Vehicle Passenger Detection System ( VPDS)1
Figure 1 : VPDS annotation/classification interface at FrenchSwiss border .
The VPDS is a two camera system that takes one photograph through the front windscreen of the car , and another one on the side of the car , looking into the back seat . Using the two photos , the system calculates whether the car contains just the driver , the driver plus one passenger , or the driver plus two or more passengers . The project started with one week of "training" the system on the field . Compliance with data protection law is ensured by applying nonreversible blurring techniques to the photographs to prevent facial and number plate recognition ; and by retaining the photographs for no more than five days . The results proved the system to be 95 % accurate in counting occupants .
The technical solution consists of the car detection , car location in the image , and the VOC classifiers . When the front and side cameras take a photo , the object detectors first localize the information zones in these images . In particular , the visor breeze to the front image and the rear window to the side image . The front and side classifiers then estimate probability of passenger presence in the car . The last module aggregates these probabilities into a final estimate of the vehicle occupancy rate . 1http://wwwxeroxcom/downloads/usa/en/bpo/casestudies/bpo_ casestudy_jougne.pdf
Figure 2 : EMPATH Text Analytics GUI .
All classifiers are learned during the training period , when the image annotation tool ( see Figure 1 ) is used to screen the images and to associate each car image with one of the labels , 1 , 2 or "3 or more" . The training of the algorithm includes annotating the image pairs and estimating optimum parameters to classify the new images .
When a new VPDS installation is requested , the "training" period and annotation cost is expected to be reduced by emerging domain adaptation techniques . As all images are destroyed after five days , the VOC classifiers are the only components to be reused from one VPDS installation to another . 2.2 EMPATH
EMPATH is a product developed by Xerox for customer analytics2 It aims to understand customers’ experiences , needs , and opinions in order to improve operations , products and services offered to customers . EMPATH starts by gathering data from a range of text sources ( social media , news feeds , emails , chat and surveys ) . Collected data is then analyzed by an operator with the help of a text analytics engine . The operator tags one to two hundred posts , which are then used for training statistical models . This analysis helps operators better answer customer requests , to report upcoming issues and to provide valuable insights on product development . In the text analytics engine , topic models , categories and sentiment classifiers are treated as domain and customer dependent . For some domains ( such as IT and mobile phone ) , major concerns are similar and domain adaptation has been shown to reduce the annotation burden .
The main text analytics GUI is presented in Figure 2 . Using the interface , the operator extracts topics from the text , creates categories to detect coming issues and monitors customer satisfaction with the sentiment predictions . As customers disallow to share their data , operators face the problem of wasting their time and resource by starting the analytics processes from scratch . As certain components , topics , categories and sentiments are common to many brand customers , the adaptation of classifiers across domain and customers represents a strong opportunity for the EMPATH product . 2.3 Print and Document Usage Analytics
As a part of Print and Document Management Services , Xerox offers to their customers facilities to automate and simplify the management of paper and electronic documents . The dematerialization services and process automation offered by Xerox help
2http://wwwwdsco/product/contact center/social media/
452 streamline client ’s business processes to drive growth , and to reduce costs .
As documents vary a lot by their origin , layout and content , there exists a strong need to evolve a workflow for the same client , as well as to redeploy the workflow for new clients , under all legal obligations .
In Section 5 , document collections from three customers and evaluation results of domain adaptation are presented in more details .
3 . STATE OF THE ART
Domain adaptation for text data has been studied for more than a decade , with applications in statistical machine translation , opinion mining , part of speech tagging and document ranking [ 15 , 32 , 44 ] . Most effective techniques include feature replication [ 14 , 15 ] , pivot features [ 4 , 32 ] and finding topic models shared by source and target collections [ 9 , 10 ] . Domain adaptation has equally received a lot of attention in computer vision [ 3 , 6 , 17 , 18 , 19 , 20 , 22 , 23 , 24 , 30 , 32 , 36 , 38 ] where domain shift is a consequence of changing conditions , such as background , location and pose , etc . and , more generally , a strong bias between datasets .
A considerable effort to systematize different domain adaptation and transfer learning techniques has been undertaken in [ 25 , 34 , 39 ] . These studies distinguish three main categories of domain adaptation methods . The first category aims at correcting sampling bias and this family of models gives more weight in the classification loss to instances more similar to the target collection [ 43 ] . The second category is in the line with multi task learning where a common predictor is learned for all domains , which makes it robust to domain shift [ 6 ] . The third family seeks to find common representation between source and target examples so that the classification task is eased [ 33 ] . In a nutshell , models of this family aim at inferring domain invariant features . Finally , an important research direction deals with the theory of domain adaptation ; it studies conditions and assumptions for which the adaptation can be effective and generalization bounds can be provided [ 2 ] .
More recently , deep learning has been proposed as a generic solution to domain adaptation and transfer learning problems [ 11 , 22 , 29 ] . One successful method which aims to find common features between source and target collection relies on denoising autoencoders . In deep learning , a denoising autoencoder is a one layer neural network trained to reconstruct input data from partial random corruption [ 40 ] . The denoisers can be stacked into multilayered architectures where the weights are fine tuned with backpropagation . Alternatively , outputs of intermediate layers can be used as input features to other learning algorithms . This learned feature representation has been applied to domain adaptation [ 22 ] , where stacked denoising autoencoders ( SDA ) achieved top performance in sentiment analysis tasks . The main drawback of SDAs is the long training time and Chen et al . [ 7 ] proposed a variation of SDA where the random corruption is marginalized out . This crucial step yields a unique optimal solution which is computed in closed form and eliminates therefore the back propagation . In addition , features learned with such an approach lead to classification accuracy comparable with SDAs , with a remarkable reduction of the training time [ 7 , 42 ] .
Several deep learning approaches have demonstrated their ability to learn robust features and that good transfer performance could be obtained by just fine tuning the neural network on the target task [ 11 ] . While such solutions perform relatively well on some tasks , the refinement may require a significant amount of new labeled data . Recent works by Ganin et al . [ 20 , 21 ] have proposed better strategies than fine tuning : adding a domain prediction task while learning the deep neural network leads to better domaininvariant feature representation . Their approach obtained a significant performance gain which shows that transfer learning is not completely solved by fine tuning and that transfer tasks should be addressed by appropriate deep learning representations .
Nevertheless , the majority of domain adaptation methods makes an assumption of largely available source collections . Such assumption rarely holds in reality . The source instances may become unavailable for technical reasons , or are disallowed to store for legal and contractual reasons . When objects are to be removed from a database , it also makes privacy preserving machine learning methods inapplicable [ 1 , 5 ] .
The case of available source classifiers have been considered by Duan et al . in [ 17 ] , where their contribution is limited to regularizing the supervised target classifier . On the other hand , this case has been studied by domain adaptation theory [ 28 ] . Particularly , a theoretical analysis was conducted by considering the algorithmic stability of source classifiers . It was shown that the relatedness of source and target domains accelerates the convergence of the Leave One Out ( LOO ) error to the generalization error , thus enabling the use of the LOO error to stop the adaptation learning . In case of unrelated domains , it also suggests how to prevent negative transfer , so that in the limit it does not hurt the performance in the target domain .
4 . DOMAIN ADAPTATION WITH CLASSI
FIERS
We define a domain D as composed of a feature space X ⊂ RD and a label space Y . Any given task in domain D ( classification , regression , ranking , etc . ) is defined by a function h : X → Y . In the domain adaptation setting , we assume working with nS +1 domains , including nS source domains Ds , s = 1 , . . . , nS and a target domain Dt . In conventional setting the source data X s = [ X1 , . . . , XnS ] , with the corresponding labels Y s = [ Y1 , . . . YnS ] are available . In the absence of source data , we assume to have at our disposal either 1 ) a set F of classifiers fk , k = 1 , . . . , K , each being trained on source data where at least one classifier is available for source domain Ds , or 2 ) a set of representatives for each Ds , s = 1 , . . . , nS .
A close analysis of target applications ( see Section 2 ) reveals three important cases to consider ; they reflect different situations and complexity levels , as follows :
1 . Models and parameters θk of source classifiers fk ∈ F are known ; for example we might know they are linear and have access to their parameter vectors θk = wk ;
2 . Models of classifiers fk ∈ F are unknown ; they are used i , predict a class c as a black box and , for a target instance xt probabilities P ( yt i = c|xt i;F ) ;
3 . In the target domain , we may have access to both labeled and unlabeled instances , denoted X t l and X t u accordingly .
The domain adaptation problem then consists of leveraging the source labeled and target unlabeled data to derive a hypothesis performing well on the target domain . To achieve this goal , most DA methods compute covariance or correlation between features from source and target domains . With no or limited access to source data , we argue that the above principle can be extended to the correlation between target features and the source class decisions . We thus tune the adaptation trick by considering predicted class probabilities as augmented features for target data . Domain adaptation algorithms can then be used to find relations between features which
453 were related in the source with features which seem also related in the target collection . In other words , we use the source classifiers as a pivot to transfer knowledge from source to target .
In the following section , we propose solutions to address the three cases mentioned above :
1 . When source classifiers are known and they are linear , we extend the Marginalized Corrupted Features ( MCF ) method [ 31 ] to jointly marginalize the corrupted features and predictions ;
2 . When source classifiers are used as a black box , we can either a ) marginalize their predictions with labeled data or b ) denoise these predictions with unlabeled target data and Marginalized Denoising Autoencoders ;
3 . When class means are available as source representatives , we can use them as a Domain Specific Class Means classifier , and denoise their predictions jointly with unlabeled target data .
In the following we will discuss the unsupervised setting where l = ∅ , and the supervised setting no target instance is labeled , Xt where a few target examples ( for each class ) are labeled . To address these problems , we adapt on one hand the Marginalized Corrupted Features that allows to address the problem when target labels are available and , on the other hand , the stacked Marginalized Denoising Autoencoder ( sMDA ) [ 7 ] framework to address the case when no labeled target instances are available . 4.1 Supervised Adaptation with MCF
First , we assume that a set of target instances were manually labeled and we consider the Marginalized Corrupted Features framework to address our specific domain adaptation cases . ily , p(˜x|x ) =D
To marginalize the corrupted features in the MCF , a corrupting distribution is first defined to transform observations x into corrupted versions ˜x . The corrupting distribution is assumed to factorize over all feature dimensions and , each individual distribution is assumed to be a member of the natural exponential famd=1 P ( ˜xd|xd ; θd ) , where x = ( x1 , . . . , xD ) and θd , d = 1 , . . . , D is a parameter of the corrupting distribution on dimension d . The corrupting distribution can be unbiased ( E[˜x]p(˜x|x ) = x ) or biased . Known examples of distribution P are the blankout [ 40 ] , Gaussian , Laplace and Poisson noise [ 31 ] . For example , in the 1−q ) = 1 − q , unbiased blankout noise , p(˜x = 0 ) = q and p(˜x = x with expectation E[˜x ] = x and variance V ar[˜x ] = q 1−q x2 .
For the generalization of a classifier using corrupting distribution P , the direct approach is to corrupt each element of the target training set Dt = {(xn , yn)} , n = 1 , . . . , N . The extended data set ˜Dt can be used for training the model by minimizing
L( ˜Dt ; Θ ) =
L(˜xnm , yn ; Θ ) ,
( 1 ) where ˜xnm ∼ p(˜xnm|xn ) is the m th corrupted observation of xn and Θ is the set of model parameters . As explicit corruption comes at a high computational cost , the marginalization trick is to consider the limiting case M → ∞ , where the weak law of large numbers is applied to rewrite 1 m=1 L(˜xnm , yn ; Θ ) as M its expectation E[L(˜xnm , yn ; Θ) ] . It has been shown that dropout marginalization plays the role of regularization [ 41 ] . Classifiers can be trained efficiently with quadratic , exponential , logistic [ 31 ] and hinge loss [ 8 ] , they generalize better and are more robust to missing
M
M
N
1 M n=1 m=1
N
−1 N feature values at test time . In this paper we focus on the quadratic loss which allows a closed form solution3 . Driven by our target applications in Section 2 , we consider the multi class case where label space Y includes C classes . We denote by yn the vector of size C , where the component c corresponding to the class label of xn is set to 1 , and all others set to 0 . bution p(˜x|x ) is given by 4
The expected value of the quadratic loss under corrupting distri
L(D ; Ω ) = E[ = tr(
,Ω E[˜xn ˜x n Ω ˜xn − yn2 ] n ]Ω + E[yny n ] ) , n
−yn E[˜x n ]Ω − Ω E[˜xn]y n
( 2 ) where Ω is a D×C parameter matrix with column c seen as a linear classifier corresponding to the class c , and tr(· ) is the matrix trace . The optimal solution for Ω∗ can be given in a closed form [ 31 ]
∗
Ω
=
E[˜xn ˜x n ]
E[˜xn]y n
.
( 3 ) n=1 n=1
As the corruption distribution factorizes over all dimensions , Ω∗ depends only on the expectations E[˜xnd ] and variances V ar[˜xnd ] over individual dimensions d . Hence , for the unbiased distribution P we can write Ω∗ = Q−1P , where n , Q =N n=1
,xnx n + diag ( V ar[xn]) , ( 4 )
P = xny
N n=1 and diag(V ar[xn ] ) denotes the D×D diagonal matrix constructed with the variances V ar[xn ] . 4.2 Integrating source classifiers in MCF
In the case of available source classifiers , the explicit corruption ( 1 ) takes into account their predictions on corrupted instances , as L(˜xnm , yn,F ; Ω ) .
In the limiting case M → ∞ , we obtain the loss expectation
N n=1
L(Dt,F ; Ω ) =
E[L(˜xn , yn,F ; Ω) ] ,
( 5 ) where the corrupting distribution p(˜xn|xn ) factorizes over d dimensions .
Minimizing the expected loss value under the corruption model leads to learning with marginalized corrupted features and source predictors . The tractability of ( 5 ) depends on the choice of the loss function L and the corrupting distribution .
Let us denote the vector of all the predictions for a given corrupted target instance ˜xn by f ( ˜xn ) and let Γ be the corresponding parameter matrix to be learned . The quadratic loss can then be written as
L(D ; Ω , Γ ) = =
E,Ω ˜xn + Γf ( ˜xn ) − y Ω
˜xn n
2 2
− y n
,
Γ f ( ˜xn ) n n
E where source predictions f ( ˜xn ) can be seen as augmented corrupted features under the same distribution p(˜xn|xn ) . 3Other losses have been tested as well ; the minimization with the exponential loss requires a gradient descent technique , the logistic and hinge losses are approximated by the upper bounds ; they will be included in the extended version . 4For the notation simplicity , we omit subscript p(˜x|x ) in E[·]p(˜x|x ) .
454 The corresponding closed form solution can be written as :
E
E
Γ∗
Ω∗ n n
= Q
−1F PF ,
˜xn f ( ˜xn )
˜xn f ( ˜xn ) n . y
QF =
PF =
( 6 )
,
˜xn f ( ˜xn )
Linear source classifiers . If source classifiers are known to be linear functions ( Case 1 in Section 4 ) , we can marginalize them out jointly with the corrupted features . If we know that f ( x ) = Ax , then we can estimate their expectation on a corrupted instance x , E(f ( ˜x ) ) = E(A ˜x ) = A E(˜x ) = f ( E(˜x ) ) and variance
] = E[A˜xn ˜x n A
] = A E[˜xn ˜x n ]A
E[f ( ˜xn)f ( ˜xn )
Hence , we can derive that
E[˜xn ˜x ID
E n ] A E[˜xn ˜x n ]
A n n n
˜xn ˜x
QF =
=
.
E[˜xn ˜x A E[˜xn ˜x n ]A n ]A
ID
A
= BQBT
( 7 ) and PF = BP , where B denotes [
ID A
] . n ) for labeled xt
Estimate [ Ω∗ ; Γ∗
Algorithm 1 Marginalized corrupted features and source predictions ( MCFA ) . l ∈ RNl×D with labels Yt Require : Labeled target dataset X t u ∈ RNu×D Require : Unlabeled target dataset X t Require : Source classifiers fk ∈ RD → [ 01]C 1 : Generate class predictions f ( xt 2 : if fk are known linear functions then 3 : ] by using ( 7 ) 4 : else 5 : 6 : 7 : end if 8 : Generate class predictions f ( xt n ) for unlabeled xt 9 : Estimate class labels as yt = [ Ω∗ ; Γ∗][xt ; f ( xt ) ] 10 : Label each xt with c∗ = argmaxc{yt 11 : return Labels for X t u
Estimate . Ω∗ ; Γ∗ fi by using ( 4 ) with ut
Compose an augmented dataset with ut n ∈ X t n ∈ X t c|yt} n = [ xt n ; f ( xt n ) ] n . u l
Classifiers as a black box . If the classifier parameters are unknown or they are complex nonlinear functions , it is hard to directly estimate their expectation and variance . Used as black boxes , they can generate class prediction for target instances .
In such a case , we approximate ( 6 ) by considering any fk(xn ) as an additional feature for xn . We generate an augmented representation of the target instance as un = [ xn , f1(xn ) , . . . , fK ( xn) ] . Instead of corrupting features ˜xn and marginalizing over known classifiers fk , we assume that the corruption distribution P factorizes over augmented representation un as p(˜u|u ) =D+K
In this case , ( 4 ) can be directly applied , where ˜xn is replaced by ˜un . Algorithm 1 summarizes all steps of joint marginalization of corrupted features and source predictions ( MCFA ) . Figure 3 schematically shows the diagrams of training MCFA with known linear and black box classifiers . d=1 P ( ˜ud|ud ; θd ) .
Figure 3 : MCFA diagrams . Training with a ) known linear classifiers and b ) black box classifiers .
4.3 Unsupervised Adaptation
The main drawback of supervised setting presented in the previous section is that it requires target labels and does not exploit the unlabeled target instances X t u , which is generally much larger set than X t l . In this section we address the unsupervised domain adaptation case by marginalizing corrupted features in the denoising autoencoder framework .
The stacked Marginalized Denoising Autoencoder ( sMDA ) is a version of the multi layer neural network trained to reconstruct input data from partial random corruption [ 40 ] proposed by Chen et al . [ 7 ] where the random corruption is marginalized out yielding the optimal reconstruction weights in the closed form .
The basic building block of the method is a one layer linear denoising autoencoder where a set of sample inputs xn are corrupted M times by random feature dropout with the probability p and reconstructed with a linear mapping W : RD → RD by minimizing the squared reconstruction loss5 :
L(W ) =
||xn − W˜xnm||2 .
( 8 )
N
M n=1 m=1
By applying the marginalization trick described for MCF , the mapping W can be expressed in closed form as W = E[P ] E[Q]−1 , where i = j , i = j , if if and E[P]ij = Sijqj ,
( 9 )
Sijqiqj ,
Sijqi ,
E[Q]ij = where q = [ 1 − p , . . . , 1 − p , 1 ] ∈ RD+1 , p is the dropout probability , D is the feature dimension and S = XXT is the covariance matrix of the uncorrupted data X . Stacking together several MDA layers can create a deep architecture where we feed the representations of the ( l − 1)th denoising layer as the input to the lth layer and learn the transformation Wl to reconstruct the previous output from its corrupted equivalent . In order to extend the mapping beyond a linear transformation , between layers we apply on each output either a hyperbolic tangent function hl = tanh(Wlhl−1 ) or rectified linear units ( RELU ) hl = max(Wthl−1 , 0 ) . We will denote the final output hl corresponding to the input xn by ˆxn .
The main advantage of sMDA is that it does not require class labels ; hence we can take advantage of the unlabeled target data and apply it for unsupervised domain adaptation . Indeed , [ 7 ] applied sMDA to the union of target and source datasets in order to learn domain invariant features . In our case , X S is unavailable , we have either access to source classifiers F or a set of representative source examples . We are 5A constant is added to the input , xn = [ xn ; 1 ] , and an appropriate bias incorporated within W which is is never corrupted .
455 Algorithm 2 Adapting Domain Specific Class Means ( ACM ) . Require : A large set of unlabeled target dataset Xt u and optionally a small set of labeled Xt l
Require : A set of source class means µs 1 : Compute W using ( 9 ) with X = [ µs
1 , . . . µs C 1 , . . . µs C , xt
1 , . . . , xt
N ] and
2 : ( Optionally ) repeat l times , while alternating with hl = noise level p tanh(Wlhl−1 )
3 : Decompose hl into reconstructed class means ˆµs n . ( Optionally concatenate ˆxt c and reconn with the orig c)+e(−ˆxt c )
+e n− ˆµt c ) n− ˆµt
( −ˆxt c ) structed targets ˆxt inal features xt n ) = p(c|xt n− ˆµs n− ˆµs c , e(−ˆxt ( −ˆxt e n , and ˆµs c with µs c ) 4 : if Labeled target examples then 5 : 6 : else 7 : 8 : end if 9 : Label xt 10 : return Labels for X t u . n ) = e(−ˆxt ( −ˆxt c ) n− ˆµs p(c|xt n− ˆµs c ) c e n with c∗ = argmaxc p(c|xt n ) for us , and we propose a Transductive Domain Adaptation ( TDA ) method which also relies on sMDA but uses it in the way different from the ACM .
Like in Section 4.1 , we consider class predictions fk(xn ) as relevant but corrupted by the domain shift . Hence , we can exploit the correlation between the target data xn and source predictions n ) to reconstruct ( or denoise ) both the target data and the source f ( xt classifiers predictions of these target data . We apply the sMDA to the augmented dataset U t = [ u1 , . . . uN ] and compute W ; or stack several layers interleaved with nonlinear functions . We denote by ˆun the final output corresponding to the input un .
In this case , we can directly use the reconstructed class predicn ) to make the classification decisions . If the set F intions ˆf ( xt cludes a single source classifier f1 with one prediction per class , the class with the maximum reconstructed value , c∗ = argmaxc uD+c is assigned as label to xt n . In the case of multiple classifiers fk in F , the maximum of the averaged predictions should be considered . Algorithm 3 summarizes all the steps of this transductive version of domain adaptation . n
Algorithm 3 Transductive domain adaptation with mSDA ( TDA ) . Require : Target dataset Xt ∈ RN×D without labels Require : Source classifiers fk ∈ RD → [ 01]C n ∈ Xt 1 : Generate class predictions f ( xt n ) for all xt 2 : Compose an augmented dataset U with ut n = [ xt 3 : Use sMDA to estimate W = minW||U − W ˜U||2 4 : Get 5 : Label xt with c∗ = argmaxc{yt 6 : return Labels for X t u
W:,D+1:D+C f ( x ) predictions c|yt} . denoised for xt n ; f ( xt as yt class n ) ]
=
5 . EXPERIMENTAL RESULTS
In this section we present a series of experiments to cope with domain adaptation tasks , along several important dimensions :
1 . The amount of supervision in target domain ; we consider un supervised , supervised and semi supervised settings .
2 . Information available from the sources : source linear classi
Figure 4 : The DSCM class mean classifier . interested in one particular case , when the representative examples are the class means for each domain Xs . Below we propose two different extensions of sMDA to these two cases . 4.4 Adaptation with Class Means Class Means . If class means are available , they can be used both as classifiers and as data points . Used as classifiers , the class means can directly predict labels with a weighted softmax distance [ 13 ] . Used as representatives of source data , the class means can be concatenated with the target data and fed to sMDA for a joint denoising . The denoised class means can then classify the target test instances [ 12 ] . These two ways of using the class means are described in what follows .
The DSCM [ 13 ] classifier ( see Figure 4 ) generates the class means per domain as
µd c =
1 N c d xi∈Dd∩Cc xi ,
( 10 ) d is the number of instances from class Cc in the domain where N c Dd . Then it can predict the class label for an unlabeled target instance using a weighted softmax distance to these domain specific class means : c c ) d wde(−xi−µd d wde(−xi−µd
, c ) p(c|xi ) = where wd is the domain weight . In unsupervised domain adaptation , the DSCM make predictions with source class means µs c . If some target instances are labeled , the classifier can additionally use the target class means µt c .
The Adapted Class Means [ 12 ] classifier ( ACM ) is an extension of DSCM to unsupervised and semi supervised settings . First , a sMDA is used to denoise the source class means . Instead of full source data XS , the source class means [ µs C ] concatenated with the unlabeled target data Xt u are fed into the sMDA . The transformation matrix W obtained by ( 9 ) ( or the set of stacked transformation matrices Wl ) is then used to jointly denoise the source class means ˆµs n . The denoised class means ˆµs c are then used by the classifier to predict labels for denoised target data . c and the target examples ˆxt
1 , . . . , µs
Algorithm 2 reports all steps for the case of a single source ; the generalization to multiple sources is straightforward . 4.5 Transductive domain adaptation
In the previous section we addressed the case of source representatives , available in the form of class means . Now we address the case of source classifiers available as a black box . They can be solely used for predicting labels , including for target domain instances . Such an unsupervised domain adaptation is of high interest
456 fier , source classifier as a black box , and source representatives in the form of class means .
3 . When the classifier is a black box , we test different classification models , including common ones like SVM and Logistic Regression , and specific ones like MCF and DSCM .
We recall briefly all algorithms proposed in the previous sec tions : MCFA ( Section 4.2 ) is primarily supervised domain adaptation algorithm described in Algorithm 1 . It includes two versions , mcfal when the source classifiers fk(x ) are linear , and mcfab when fk(x ) are used as a black box to predict class labels for a target example .
ACM ( Section 4.4 ) assumes that class means are available from the source data . In the unsupervised setting , it uses the sMDA reconstructions of the class means to predict the class . In the semi supervised setting , the target class means ( µt c ) are learned from labeled target data ; then , together with the source class means ( µs c ) , they are used to predict the class labels for target data ( see Algorithm 2 ) .
TDA ( Section 4.5 ) is the transductive algorithm to denoise source class predictions with target data in unsupervised setting ( see Algorithm 3 ) .
The experiments are organized by the supervision type ( unsupervised , supervised and semi supervised ) ; they aim to test performance of all algorithms on different datasets . Below we describe two image and one text datasets used in the experiments . 5.1 Datasets and Experimental Framework
XS3 . This collection is a part of the Xerox ’s Smart Document Management data ; it contains printed/scanned documents from three Xerox customers denoted by C1 , C2 and C3 . The three datasets contain different types of documents such as invoices , contracts , IDs , filled forms , etc . All the documents have been grouped into 21 different classes , all well represented in each dataset ( see examples in the Figure 5 ) . Amongst these classes , some refer to generic concepts such as printed emails , computer programs , drawings , handwritten letters ; some others ( contracts and filled forms ) form a more fine grained class hierarchy , according to the customers’ requirements . We manually aligned between the fine grain classes have been manually aligned by their visual similarities as the correspondences is often not obvious .
The number of documents per class and per customer varies from 24 to 859 ; around 2.5K documents are available for each customer . As image representations we use deep convolutional activation features [ 16 ] . These features are obtained using publicly available Caffe CNN models6 [ 27 ] trained on the 1000 classes of ImageNet [ 35 ] and fine tuned for document images on the RVLCDIP document image dataset7 [ 26 ] . In our experiments we use the fully connected layer ( caffe_fc6 ) of dimensionality 4096 .
Due to the confidentiality clauses on X3S collection , we also run experiments on two publicly available benchmark datasets :
OFF31 . One of the most popular datasets for comparing visual domain adaptation methods is the Office31 collection [ 36 ] . It consists of four domains : Amazon ( A ) , Caltech ( C ) , dslr ( D ) and Webcam ( W ) with images of 31 products ( classes ) . Each domain is considered in its turn as a target , with the other domains considered as sources . For the target set we select 3 instances per class to 6https://github.com/BVLC/caffe/ 7http://scsryersonca/~aharley/rvl cdip/
Figure 5 : Examples from the XC3 datasets . Each line corresponds to one customer and each column refers to one document class ( documents are intentionally blurred for privacy reasons ) . form the training set , all other instances form the test set . We use the caffe_fc6 deep convolutional activation features [ 16 ] we obtain with the publicly available VGGNET ( 16 layer ) CNN model [ 37 ] with no fine tuning .
AMT . The Amazon text dataset consists of products reviews in four domains : Books ( b ) , Dvd ( d ) , Kitchen ( k ) and Electronics ( e ) . While a book review can be quite different from a kitchen item review , there are nevertheless some common features to assess whether the users were satisfied with their purchase . A part of this collection was preprocessed by Blitzer et al . [ 3 ] and used subsequently in several domain adaptation studies . The task is to predict whether a customer review is positive or negative , where a review with more than 3 stars is considered as positive and ( strictly ) less than 3 as negative . Documents are represented by a bag of unigrams and bigrams . In our experiments , we only considered the top 10,000 most frequent features for each domain . In all experiments , we use the whole source and target collections whereas other studies use a predefined split of 2000 documents per domain .
Finally , we list four classification models tested as source classi fiers : DSCM classifier [ 13 ] uses a softmax distance to the class specific means to classify a test example .
MCF [ 31 ] is a multi class linear classifier with dropout noise probability fixed to 0.5 for image datasets ( OFF31 and XC3 ) and 0.9 for text dataset ( Amazon ) . Need for a stronger dropout level on text data is explained by its sparsity [ 12 ] .
LR refers to a l2 regularized Logistic Regression , cross validated with the regularization parameter C , where C ∈ [ 0.0001 , 0.001 , 0.1 , 1 , 10 , 50 , 100 ] .
SVM is used with the RBF kernel , two main hyperparameters C and γ are fit by a random search , C ∼ Exp(scale = 100 ) and γ ∼ Exp(scale = 1 ) For both SVM and LR , the Scikit learn implementation is used 8 .
5.2 Unsupervised Setting
In this setting , the baseline consists in classifying target data without any domain adaptation . We compare the performance of the unsupervised ACM with available class means to the TDA with the black box classifier . 8http://scikit learnorg/stable/indexhtml
457 Table 1 : Unsupervised adaptation in XS3 and OFF31 datasets with DSCM and TDA methods . Underline indicates improvement over the baseline and bold indicates the best performance per task .
Table 2 : Unsupervised adaptation in AMT dataset with TDA method and MCF/LR source classifiers . Underline indicates improvement over the baseline and bold indicates the best performance per task . fs ft
S → T C2 → C1 C3 → C1 C1 → C2 C3 → C2 C1 → C3 C2 → C3 D → A W → A A → D W → D A → W D → W smda∗ dscm fs(X t ) acm tda mcf fs(X t )
37.18 37.58 53.92 62.16 36.11 38.64 60.18 60.07 69.88 95.56 65.95 93.16
30.75 39.24 47.59 57.92 31.31 30.09 56.91 55.74 71.36 97.04 64.1 93.59
41.11 41.18 53.32 66.07 47.34 41.74 60.62 61.88 67.65 95.31 67.24 92.88
33.36 37.14 51.91 61.29 36.53 36.03 59.71 60.74 70.12 95.56 68.8 93.02
33.65 46.18 52.5 58.88 38.02 35.07 56.4 55.07 72.84 99.75 67.95 96.87 tda
34.75 47.8 54.1 60.15 39.4 36.83 57.83 56.65 73.83 99.51 69.52 96.3 fs ft S → T d → b e → b k → b b → d e → d k → d b → e d → e k → e b → k d → k e → k smda∗ mcf fs(X t )
80.81 73.39 74.93 81.96 75.91 77.47 77.47 79.02 87.16 80.45 81.44 88.59
80.08 71.22 71.17 80.31 74.20 76.03 74.53 76.03 86.28 76.86 77.64 87.72 tda
81.66 73.25 74.27 82.07 76.18 78.39 76.75 78.62 87.39 79.31 80.47 88.87 smda∗ lr fs(X t )
84.59 78.07 78.75 85.07 79.99 80.76 80.32 83.70 89.05 84.00 86.08 90.76
81.36 73.87 73.50 82.54 76.46 77.58 76.44 78.65 87.55 79.46 80.83 89.97 tda
82.61 75.93 75.02 83.56 77.67 79.16 78.54 80.75 88.38 81.44 83.15 91.10
Table 1 reports results for 6 domain adaptation tasks in XS3 and 6 tasks in OFF31 dataset . Each line indicates an adaptation task S → T , from source S to target T . Column 1 , sMDA∗ , refers to the dream case of fully available source data ; it shows classification accuracy of sMDA on full source and target data . Columns 3 to 5 correspond to cases where the source classifier fs is a DSCM classifier . Column 3 reports the baseline accuracy when the source classifier is applied on the target test without adaptation , fs(X t ) . Columns 4 ( ACM ) and 5 ( TDA ) show the results of applying the respective domain adaptation . Both methods in general outperform the baseline and achieve the accuracy values comparable with the dream case with full access to source data , and in general ACM outperforms TDA , showing that it is more interesting to adapt the class means ( if available ) than the softmax scores we obtain with . Finally , columns 6 and 7 show the classification accuracy when the source classifier is the MCF classifier and the source class means are unavailable . The TDA method outperforms the baseline MCF in most cases except the adaptation between D and W , that can be explained by the fact we have almost no domain shift between these two domains .
Table 2 shows the performance of the TDA model on the 12 adaptation tasks of the AMT dataset . We include accuracy values for MCF and LR source classifiers , but exclude results for DSCM and ACM as the class means classifier performs poorly on text data . On average , the LR classifier performs better . Compared to the baseline fs(X t ) and the dream case sMDA∗ , TDA always improves over the baseline and is often close to the dream case .
To sum up , domain adaptation with TDA is successful when the classification predictions are obtained with DSCM , MCF or LR . When we have access to the class means , adapting them with ACM seems to be a better strategy for image datasets . For the text dataset , TDA combined with LR predictions performs the best . In all cases , the performance of TDA and ACM is close to the dream case .
5.3 Supervised Setting
We assume now that some of the target instances are labeled , but no unlabeled target instances are given at the training time . For each adaptation task , there are two baselines . The first one consists in training the classifier on the labeled target instances ; the second one relies on the logistic regression model9 trained on the concatenation of the raw target features and the source predictions . Both baselines are shown in italic in the tables . We run experiments with different source classifiers ( MCF , SVM , DSCM ) and evaluate the two proposed MCF extensions : MCFAl and MCFAb .
Table 3 presents evaluation results on XS3 and OFF31 datasets . Each column in the table shows the accuracy of the target classification using linear classifiers ( Column 1 ) and the black box classifiers ( Columns 2 to 4 ) . For all tasks , the first supervised baseline is denoted as T → T ( for ex . , C1 → C1 ) , it refers to learning from labeled target data only . The second baseline is reported in the last column , it uses LR as the target classifier ( ft ) that is trained on the target features concatenated with the source classifier predictions obtained with DSCM ( fs ) .
We can observe that both MCF extensions outperform the baseline LR trained on the concatenated features . Given the small amount of labeled data , the MCF is more appropriate to handle the noise and variability in data , which makes it better suited for domain adaptation and transfer tasks . We can see that MCFAb with SVM or DSCM predictions provide even better results and outperform both baselines ; this witnesses a successful adaptation independently of which classifier is used in the black box ( fs ) .
We have also conducted experiments on the AMT dataset where 10 target labels per class were used to compare several source classifiers . We do not include results here but report the main findings . MCF shows a better classification performance than LR when using the target features only ( similarly to the image datasets ) . However , when the target data get combined with the source predictions , the LR baseline obtains better results than MCFAb . Adding the source classifier ’s predictions to the original target features brings an improvement over the supervised T → T baseline , for both LR and MCFA . However , due to a small amount of target labels , the T → T baseline is worse than the S → T one , and none approach is able to outperform the results obtained with the source classifier ’s predictions ( fs ) .
On the other hand , as shown in Table 2 , combining the source predictions with the unlabeled target data outperforms significantly the results obtained with source predictions fs . It points out that using the source predictions and the unsupervised denoising with TDA is a much better option than using any supervised method
9Experiments with SVM give very similar results .
458 Table 3 : Supervised adaptation in XS3 and OFF31 datasets with MCFA , using 3 labels per class . Underline indicates improvement over both baselines and bold indicates the best performance per task . fs ft
XS3 Tasks C1 → C1 C1 , C2 → C1 C1 , C3 → C1 C2 → C2 C2 , C1 → C2 C2 , C3 → C2 C3 → C3 C3 , C1 → C3 C3 , C2 → C3 OFF31 Tasks A → A A , D → A A , W → A D → D D , A → D D , W → D W → W W , A → W W , D → W mcf dscm mcfal mcfab mcfab mcfab svm mcf
95.19 95.41 95.44 86.38 86.48 86.61 85.78 86.01 86.05
69.38 70.29 70.44 89.63 89.14 88.89 84.05 85.33 84.76
95.19 94.75 95.3 86.38 86.98 88.8 85.78 86.09 85.97
69.38 69.63 70.66 89.63 91.36 95.56 84.05 85.04 91.03
95.15 95.3 95.41 86.38 87.75 87.93 85.78 86.16 86.2
69.38 70.59 70.07 89.63 90.12 96.05 84.05 86.61 90.46
95.15
95 95.78 86.38 88.21 89.25 85.78 86.16 86.09
69.38 70.96 70
89.63 90.37 94.81 84.05 84.47 90.74 dscm lr
90.07 91.18 91.18 81.7 83.3 85.8 85.6 85.6 85.7
62.7 66 66.1 87.9 87.9 89.6 88.3 87.3 88.7 including the baselines . This clearly demonstrates the importance of having access to the unlabeled target data . It shows that the unsupervised domain adaptation can be highly beneficial for the accuracy gain and can considerably reduce the annotation cost . 5.4 Semi supervised Setting
Lastly , we consider here a transductive semi supervised setting . We assume that a large set of unlabeled target set Xt u is available at the training time . The supervised baseline which uses only target labeled data and our algorithm MCFAb are used as baselines . They are compared to the semi supervised version of ACM , which assumes available source class means . Despite this requirement , it is still interesting to compare these approaches to understand which classifiers can be more amenable to transfer .
Table 4 shows the evaluation results for 12 domain adaptation tasks in XS3 and OFF31 datasets . For each adaptation task , the supervised baseline is denoted T → T ; it trains a classifier on target labeled data only . Column 2 in the table reports the results of DSCM classifier in the supervised setting . Column 3 indicates the performance of sMDA with a DSCM classifier with full access to source data . The sMDA results help us measure the performance or adaptation methods under the limited or no access to the source data . Column 4 indicates the performance of the ACM model and Column 5 reports the supervised baseline MCFAB . The table reveals two important findings . First , the semi supervised ACM brings additional gains comparing to the baselines . But the most important finding is that methods without access to source data ( ACM , MFCAb ) achieve performances close to the methods with access to source data ( sMDA+DSCM , Column 2 ) . This indicates that the classifier contains enough information for adaptation and upholds the result in unsupervised adaptation .
6 . CONCLUSION
In this paper we address the problem of domain adaptation in real world applications , where the reuse of source data is limited ,
Table 4 : Semi Supervised adaptation in XS3 and OFF31 datasets . fs
X in smda ft
XS3 Task C1 → C1 C1 , C2 → C1 C1 , C3 → C1 C2 → C2 C2 , C1 → C2 C2 , C3 → C2 C3 → C3 C3 , C1 → C3 C3 , C2 → C3 OFF31 Task A → A A , D → A A , W → A D → D D , A → D D , W → D W → W W , A → W W , D → W dscm dscm
94.16 91.92 90.63 86.93 88.57 88.39 86.78 83.14 84.44
70.33 72.32 71.99 89.38 89.63 95.06 83.76 85.04 92.02
[ µs , Xt ] acm
96.51 96.47 96.66 92.26 93.58 94.54 88.31 86.62 88.46
69.49 71.95 72.21 89.88 90.37 94.57 84.33 85.61 91.45
[ Xs , xt ] dscm∗
96.51 95.52 96.36 92.26 92.99 94.08 88.31 87.39 86.81
69.49 71.84 71.91 89.88 89.14 95.06 84.33 84.33 91.03 dscm Xt fs ( Xt ) mcfab
96.51 95.66 96.14 92.26 84.06 85.29 88.31 86.16 86.09
69.49 70.96 70.0 89.88 90.37 94.81 84.33 84.47 90.74 svm Xt fs ( Xt ) mcfab
96.51 96.36 96.44 92.26 88.43 88.66 88.31 85.47 85.74
69.49 70.55 70.63 89.88 89.38 92.59 84.33 87.04 88.89 due to legal and contractual obligations , to classification rules or a few representative examples . We adapt the recent techniques of feature corruption and their marginalization developed for the supervised ( MCF ) and unsupervised ( sMDA ) settings . We propose several extensions to MCF and sMDA methods in order to address cases when the source classifiers are available either as a black box or with known parameters , or a few class representatives are from a source domain . We conduct a series of experiments on two public and one in house datasets in supervised and unsupervised settings . We present the evaluation results and show that significant performance gains can be achieved despite the absence of source data and shortage of labeled target data . This result is an highly encouraging for a range of applications with machine learning components , whose adaptation to new domains and customers is expected to be low and without sacrificing the stated performance .
7 . REFERENCES [ 1 ] R . Agrawal and R . Srikant . Privacy preserving data mining . In Proc . of SIGMOD/PODS , ( ACM ) , pages 439–450 , 2000 .
[ 2 ] S . Ben David , J . Blitzer , K . Crammer , and F . Pereira .
Analysis of representations for domain adaptation . In Proc . of NIPS , ( Curran Associates ) , pages 137–144 , 2007 .
[ 3 ] J . Blitzer , S . Kakade , and D . P . Foster . Domain adaptation with coupled subspaces . In Proc . of AISTATS , pages 173–181 , 2011 .
[ 4 ] J . Blitzer , R . McDonald , and F . Pereira . Domain adaptation with structural correspondence learning . In Proc of EMNLP , pages 120–128 , 2006 .
[ 5 ] K . Chaudhuri and C . Monteleoni . Privacy preserving logistic regression . In Proc . of NIPS , ( Curran Associates ) , pages 289–296 , 2008 .
[ 6 ] M . Chen , K . Q . Weinberger , and J . Blitzer . Co training for domain adaptation . In Proc . of NIPS , ( Curran Associates ) , pages 2456–2464 , 2011 .
459 [ 7 ] M . Chen , Z . Xu , K . Q . Weinberger , and F . Sha . Marginalized denoising autoencoders for domain adaptation . In Proc . of ICML , pages 767–774 , 2012 .
[ 8 ] N . Chen , J . Zhu , J . Chen , and B . Zhang . Dropout training for support vector machines . In Proc . of AAAI , pages 1752–1759 , 2014 .
[ 9 ] Z . Chen and B . Liu . Topic modeling using topics from many domains , lifelong learning and big data . In Proc . of ICML , pages 703–711 , 2014 .
[ 10 ] Z . Chen , A . Mukherjee , B . Liu , M . Hsu , M . Castellanos , and R . Ghosh . Leveraging multi domain prior knowledge in topic models . In Proc . of IJCAI , ( AAAI ) , pages 2071–2077 , 2013 .
[ 11 ] S . Chopra , S . Balakrishnan , and R . Gopalan . DLID : Deep learning for domain adaptation by interpolating between domains . In ICML Workshop on Challenges in Representation Learning ( WREPL ) , 2013 .
[ 12 ] G . Csurka , B . Chidlovskii , and S . Clinchant . Adapted domain specific class means . In TASK CV , ICCV workshop , 2015 .
[ 13 ] G . Csurka , B . Chidlovskii , and F . perronnin . Domain adaptation with a domain specific class means classifier . In TASK CV , ECCV workshop , 2014 .
[ 14 ] H . Daumé . Frustratingly easy domain adaptation . CoRR , arXiv:0907.1815 , 2009 .
[ 15 ] H . Daume III and D . Marcu . Domain adaptation for statistical classifiers . Journal of Artificial Intelligence Research , 26(1):101–126 , 2006 .
[ 16 ] J . Donahue , Y . Jia , O . Vinyals , J . Hoffman , N . Zhang , E . Tzeng , and T . Darrell . Decaf : A deep convolutional activation feature for generic visual recognition . CoRR , arXiv:1310.1531 , 2013 .
[ 17 ] L . Duan , I . W . Tsang , D . Xu , and T S Chua . Domain adaptation from multiple sources via auxiliary classifiers . In Proc . of ICML , pages 289–296 , 2009 .
[ 18 ] L . Duan , D . Xu , and S F Chang . Exploiting web images for event recognition in consumer videos : A multiple source domain adaptation approach . In Proc . of CVPR , ( IEEE ) , pages 1338–1345 , 2012 .
[ 19 ] B . Fernando , A . Habrard , M . Sebban , and T . Tuytelaars . Unsupervised visual domain adaptation using subspace alignment . In Proc . of ICCV , ( IEEE ) , pages 2960–2967 , 2013 .
[ 20 ] Y . Ganin and V . Lempitsky . Unsupervised domain adaptation by backpropagation . In Proc . of ICML , pages 1180–1189 , 2015 .
[ 21 ] Y . Ganin , E . Ustinova , H . Ajakan , P . Germain , H . Larochelle ,
F . Laviolette , M . Marchand , and V . S . Lempitsky . Domain adversarial training of neural networks . CoRR , arXiv:1505.07818 , 2015 .
[ 22 ] X . Glorot , A . Bordes , and Y . Bengio . Domain adaptation for large scale sentiment classification : A deep learning approach . In Proc . of ICML , pages 513–520 , 2011 .
[ 23 ] B . Gong , Y . Shi , F . Sha , and K . Grauman . Geodesic flow kernel for unsupervised domain adaptation . In Proc . of CVPR , ( IEEE ) , pages 2066–2073 , 2012 .
[ 24 ] R . Gopalan , R . Li , and R . Chellappa . Domain adaptation for object recognition : An unsupervised approach . In Proc . of ICCV , ( IEEE ) , pages 999–1006 , 2011 .
[ 25 ] R . Gopalan , R . Li , V . M . Patel , and R . Chellappa . Domain adaptation for visual recognition . Foundations and Trends in Computer Graphics and Vision , 8(4 ) , 2015 .
[ 26 ] A . W . Harley , A . Ufkes , and K . G . Derpanis . Evaluation of deep convolutional nets for document image classification and retrieval . In Proc . of ICDAR , pages 991–995 , 2015 .
[ 27 ] A . Krizhevsky , I . Sutskever , and G . Hinton . ImageNet classification with deep Convolutional Neural Networks . In Proc . of NIPS , ( Curran Associates ) , 2012 .
[ 28 ] I . Kuzborskij and F . Orabona . Stability and hypothesis transfer learning . In Proc . of ICML , pages 942–950 , 2013 .
[ 29 ] M . Long , Y . Cao , J . Wang , and M . I . Jordan . Learning transferable features with deep adaptation networks . In Proc . of ICML , 2015 .
[ 30 ] M . Long , J . Wang , G . Ding , J . Sun , and P . S . Yu . Transfer joint matching for unsupervised domain adaptation . In Proc . of CVPR , ( IEEE ) , 2014 .
[ 31 ] L . v . d . Maaten , M . Chen , S . Tyree , and K . Weinberger .
Learning with marginalized corrupted features . In Proc . of ICML , 2013 .
[ 32 ] S . J . Pan , X . Ni , J T Sun , Q . Yang , and Z . Chen .
Cross domain sentiment classification via spectral feature alignment . In Proc . of WWW , 2010 .
[ 33 ] S . J . Pan , J . T . Tsang , Ivor W.and Kwok , and Q . Yang .
Domain adaptation via transfer component analysis . Transactions on Neural Networks , 22(2):199 – 210 , 2011 .
[ 34 ] S . J . Pan and Q . Yang . A survey on transfer learning . Transactions on Knowledge and Data Engineering , 22(10):1345–1359 , 2010 .
[ 35 ] O . Russakovsky , J . Deng , H . Su , J . Krause , S . Satheesh , S . Ma , Z . Huang , A . Karpathy , A . Khosla , M . Bernstein , A . C . Berg , and L . Fei Fei . Imagenet large scale visual recognition challenge . International Journal of Computer Vision , 115(3):211–252 , 2015 .
[ 36 ] K . Saenko , B . Kulis , M . Fritz , and T . Darrell . Adapting visual category models to new domains . In Proc . of ECCV , ( Springer ) , pages 213–226 , 2010 .
[ 37 ] K . Simonyan and A . Zisserman . Very deep convolutional networks for large scale image recognition . CoRR , arXiv:1409.1556 , 2014 .
[ 38 ] B . Sun , J . Feng , and K . Saenko . Return of frustratingly easy domain adaptation . CoRR , arXiv:1511.05547 , 2015 .
[ 39 ] S . S . Sun , H . Shi , and Y . Wu . A survey of multi source domain adaptation . Information Fusion , 24:84–92 , 2015 . [ 40 ] P . Vincent , H . Larochelle , Y . Bengio , and P A Manzagol . Extracting and composing robust features with denoising autoencoders . In Proc . of ICML , 2008 .
[ 41 ] S . Wager , S . I . Wang , and P . Liang . Dropout training as adaptive regularization . In Proc . of NIPS , ( Curran Associates ) , pages 351–359 , 2013 .
[ 42 ] Z . Xu , M . Chen , K . Q . Weinberger , and F . Sha . From sBoW to dCoT marginalized encoders for text representation . In Proc . of CIKM , ( ACM ) , 2012 .
[ 43 ] Z . Xu and S . Sun . Multi source transfer learning with multi view adaboost . In Proc . of NIPS , ( Curran Associates ) , pages 332–339 , 2012 .
[ 44 ] M . Zhou and K . C . Chang . Unifying learning to rank and domain adaptation : Enabling cross task document scoring . In Proc . of SIGKDD ( ACM ) , pages 781–790 , 2014 .
460
