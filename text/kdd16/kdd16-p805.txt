Ranking Causal Anomalies via Temporal and Dynamical
Analysis on Vanishing Correlations
Wei Cheng1 , Kai Zhang1 , Haifeng Chen1 , Guofei Jiang1 , Zhengzhang Chen1 , Wei Wang2
1NEC Laboratories America
2Department of Computer Science , University of California , Los Angeles
1{weicheng , kzhang , haifeng , gfj , zchen}@nec labs.com , 2weiwang@csuclaedu
ABSTRACT Modern world has witnessed a dramatic increase in our ability to collect , transmit and distribute real time monitoring and surveillance data from large scale information systems and cyber physical systems . Detecting system anomalies thus attracts significant amount of interest in many fields such as security , fault management , and industrial optimization . Recently , invariant network has shown to be a powerful way in characterizing complex system behaviours . In the invariant network , a node represents a system component and an edge indicates a stable , significant interaction between two components . Structures and evolutions of the invariance network , in particular the vanishing correlations , can shed important light on locating causal anomalies and performing diagnosis . However , existing approaches to detect causal anomalies with the invariant network often use the percentage of vanishing correlations to rank possible casual components , which have several limitations : 1 ) fault propagation in the network is ignored ; 2 ) the root casual anomalies may not always be the nodes with a highpercentage of vanishing correlations ; 3 ) temporal patterns of vanishing correlations are not exploited for robust detection . To address these limitations , in this paper we propose a network diffusion based framework to identify significant causal anomalies and rank them . Our approach can effectively model fault propagation over the entire invariant network , and can perform joint inference on both the structural , and the time evolving broken invariance patterns . As a result , it can locate high confidence anomalies that are truly responsible for the vanishing correlations , and can compensate for unstructured measurement noise in the system . Extensive experiments on synthetic datasets , bank information system datasets , and coal plant cyber physical system datasets demonstrate the effectiveness of our approach .
Keywords causal anomalies ranking , label propagation , nonnegative matrix factorization
1 .
INTRODUCTION
With the rapid advances in networking , computers , and hardware , we are facing an explosive growth of complexity in networked applications and information services . These large scale , often distributed , information systems usually consist of a great variety of components that work together in a highly complex and coordinated manner . One example is the Cyber Physical System ( CPS ) which is typically equipped with a large number of networked sensors that keep recording the running status of the local components ; another example is the large scale Information Systems such as the cloud computing facilities in Google , Yahoo! and Amazon , whose composition includes thousands of components that vary from operating systems , application softwares , servers , to storage , networking devices , etc .
A central task in running these large scale distributed systems is to automatically monitor the system status , detect anomalies , and diagnose system fault , so as to guarantee stable and high quality services or outputs . Significant research efforts have been devoted to this topic in the literatures . For instance , Gertler et al . [ 9 ] proposed to detect anomalies by examining monitoring data of individual component with a thresholding scheme . However , it can be quite difficult to learn a universal and reliable threshold in practice , due to the dynamic and complex nature of information systems . More effective and recent approaches typically start with building system profiles , and then detect anomalies via analyzing patterns in these profiles [ 5 , 13 ] . The system profile is usually extracted from historical time series data collected by monitoring different system components , such as the flow intensity of software log files , the system audit events and the network traffic statistics , and sometimes sensory measurements in physical systems .
The invariant model is a successful example [ 13 , 14 ] for large scale system management . It focuses on discovering stable , significant dependencies between pairs of system components that are monitored through time series recordings , so as to profile the system status and perform subsequent reasoning . A strong dependency between a pair of components is called invariant ( correlation ) relationship . By combining the invariants learned from all monitoring components , a global system dependency profile can be obtained . The significant practical value of such an invariant profile is that it provides important clues on abnormal system behaviors and in particular the source of anomalies , by checking whether existing invariants are broken . Figure 1 illustrates one example of the invariant network and two snapshots of broken invariants at time t1 and t2 , respectively . Each
805 static broken network instead of multiple broken networks at successive time points together . While we believe that , jointly analyzing temporal broken networks can help resolve ambiguity and achieve a denoising effect . This is because , the root casual anomalies usually remain unchanged within a short time period , even though the fault may keep prorogating in the invariant network . As an example shown in Figure 1 , it would be easier to detect the causal anomaly if we jointly consider the broken networks at two successive time points together .
To address the limitations of existing methods , we propose several network diffusion based algorithms for ranking causal anomalies . Our contributions are summarized as follows .
1 . We employ the network diffusion process to model propagation of causal anomalies and use propagated anomaly scores to reconstruct the vanishing correlations . By minimizing the reconstruction error , the proposed methods simultaneously consider the whole invariant network structure and the potential fault propagation . We also provide rigid theoretical analysis on the properties of the proposed methods .
2 . We further develop efficient algorithms which reduce the time complexity from O(n3 ) to O(n2 ) , where n is the number of nodes in the invariant network . This makes it feasible to quickly localize root cause anomalies in large scale systems .
3 . We employ effective normalization strategy on the ranking scores , which can reduce the influence of extreme values or outliers without having to explicitly remove them from the data .
4 . We develop a smoothing algorithm that enables users to jointly consider dynamic and time evolving broken network , and thus obtain better ranking results .
5 . We evaluate the proposed methods on both synthetic datasets and two real datasets , including the bank information system and the coal plant cyber physical system datasets . Experimental results demonstrate the effectiveness of our methods .
2 . BACKGROUND AND PROBLEM DEFI
NITION
In this section , we first introduce the technique of the invariant model [ 13 ] and then define our problem . 2.1 System Invariant and Vanishing Correla tions
The invariant model is used to uncover significant pairwise relations among massive set of time series . It is based on the AutoRegressive eXogenous ( ARX ) model [ 10 ] with time delay . Let x(t ) and y(t ) be a pair of time series under consideration , where t is the time index , and let n and m be the degrees of the ARX model , with a delay factor k .
Let by(t ; θ ) be the prediction of y(t ) using the ARX model by(t ; θ ) = a1y(t − 1 ) + ··· + any(t − n ) parametarized by θ , which can then be written as
+ b0x(t − k ) + ··· + bmx(t − k − m ) + d ⊤
= φ(t )
θ ,
( 1 )
( 2 )
( a ) t1
( b ) t2
Figure 1 : Invariant network and vanishing correlations(red edges ) . node in the figure represents the observation from a monitoring component . The green line signifies an invariant link between two components , and a red line denotes broken invariant ( ie , vanishing correlation ) . The network including all the broken invariants at given time point is referred to as the broken network .
Although the broken invariants provide valuable information of the system status , how to locate true , causal anomalies can still be a challenging task due to the following reasons . First , system faults are seldom isolated . Instead , starting from the root location/component , anomalous behavior will propagate to neighboring components [ 13 ] , and different types of system faults can trigger diverse propagation patterns . Second , monitoring data often contains a lot of noises due to the fluctuation of complex operation environments . Recently , several ranking algorithms were developed to diagnose the system failure based on the percentage of broken invariant edges associated with the nodes , such as the egonet based method proposed by Ge et al . [ 8 ] , and the loopy belief propagation ( LBP ) based method proposed by Tao et al . [ 22 ] . Despite the success in practical applications , existing methods still have certain limitations . First , they do not take into account the global structure of the invariant network , neither how the root anomaly/fault propagates in such a network . Second , the ranking strategies rely heavily on the percentage of broken edges connected to a node . For example , the mRank algorithm [ 8 ] calculated the anomaly score of a given node using the ratio of broken edges within the egonet 1 of the node . The LBP based method [ 22 ] used the ratio of broken edges as the prior probability of abnormal state for each node . We argue that , the percentage of broken edges may not serve as a good evidence of the causal anomaly . This is because , although one broken edge can indicate that one ( or both ) of related nodes is abnormal , lack of a broken edge does not necessary indicate that related nodes are problem free . Instead , it is possible that the correlation is still there when two nodes become abnormal simultaneously [ 13 ] . Therefore the percentage of broken edges could give false evidences . For example , in Figure 1 , the causal anomaly is node i⃝ . The percentage of broken edges for node i⃝ is 2/3 , which is smaller than that of node h⃝ ( which is equal to 1 ) . Since there exists a clear evidence of fault propagation on node i⃝ , an ideal algorithm should rank i⃝ higher than h⃝ . Third , existing methods usually consider
1An egonet is the induced 1 step subgraph for each node .
806 Table 1 : Summary of notations
Symbol
Definition n c ; ; ( · ) Gl Gb
A ( ˜A ) ∈ Rn×n P ( ˜P ) ∈ Rn×n M ∈ Rn×n D ∈ Rn×n r ∈ Rn×1 e ∈ Rn×1 d(i )
RCA
R RCA
RCA SOFT
R RCA SOFT
T RCA
T R RCA the number of nodes in the invariant network the parameters 0 < c < 1 ; > 0 ; > 0 the softmax function the invariant network the broken network for Gl the ( normalized ) adjacency matrix of Gl the ( normalized ) adjacency matrix of Gb the degree of the ith node in network Gl the logical matrix of Gl the degree matrix : D = diag(d(i ) ; :: : ; d(n ) ) the prorogated anomaly score vector the ranking vector of causal anomalies the basic ranking causal anomalies algorithm the relaxed RCA algorithm the RCA with softmax normalization the relaxed RCA with softmax normalization the RCA with temporal smoothing the R RCA with temporal smoothing
T RCA SOFT the RCA SOFT with temporal smoothing
T R RCA SOFT the R RCA SOFT with temporal smoothing
⊤ ∈ Rn+m+2 , φ(t ) = where θ = [ a1 , . . . , an , b0 , . . . , bm , d ] [ y(t−1 ) , . . . , y(t−n ) , x(t−k ) , . . . , x(t−k−m ) , 1 ] ⊤ ∈ Rn+m+2 . For a given setting of ( n , m , k ) , the parameter θ can be estimated with observed time points t = 1 , . . . , N in the training data , via least square fitting . In real world applications such as anomaly detection in physical systems , 0 ≤ n , m , k ≤ 2 is a popular choice [ 6 , 13 ] . We can define the “ goodness of fit ” ( or fitness score ) of an ARX model as
√∑
∑
N t=1
|y(t ) −by(t ; )|2
|y(t ) − ¯y|2
N t=1
F ( ) = 1 −
;
( 3 ) where ¯y is the mean of the time series y(t ) . A higher value of F ( θ ) indicates a better fitting of the model . An invariant ( correlation ) is declared on a pair of time series x and y if the fitness score of the ARX model is larger than a pre defined threshold . A network including all the invariant links is referred to as the invariant network . Construction of the invariant network is referred to as the model training . The model θ will then be applied on the time series x and y in the testing phase to track vanishing correlations .
To track vanishing correlations , we can use the techniques developed in [ 6 , 15 ] . At each time point , we compute the ( normalized ) residual R(t ) between the measurement y(t ) and its estimate by(t ; θ ) by
|y(t ) −by(t ; θ)|
,
( 4 )
R(t ) =
|y(t ) −by(t ; θ)| . If the residual exceeds a prefixed threshold , where εmax is the maximum training error εmax = max1≤t≤N
εmax then we declare the invariant as “ broken ” , ie , the correlation between the two time series vanishes . The network including all broken edges at given time point and all nodes in the invariant network is referred to as the broken network . 2.2 Problem Definition Let Gl be the invariant network with n nodes . Let Gb be the broken network for Gl . We use two symmetric matrices A ∈ Rn×n , P ∈ Rn×n to denote the adjacency matrix of network Gl and Gb , respectively . These two matrices can be obtained as discussed in Section 21 The two matrices can be binary or continuous . For binary case of A , 1 is used to denote that the correlation exists between two time series , and 0 denotes the lack of correlation ; while for P , 1 is used to denote that the correlation is broken ( vanishing ) , and 0 otherwise . For the continuous case , the fitness score F ( θ ) ( 3 ) and the residual R(t ) ( 4 ) can be used to fill the two matrices , respectively . Our main goal is to detect the abnormal nodes in Gl that are most responsible for causing the broken edges in Gb . In this sense , we call such nodes “ causal anomalies ” . Accurate detection of causal anomalous nodes will be extremely useful for examination , debugging and repair of system failures .
3 . RANKING CAUSAL ANOMALIES
In this section , we present the algorithm of Ranking Causal Anomalies ( RCA ) , which takes into account both the fault propagation and fitting of broken invariants simultaneously . 3.1 Fault Propagation
We consider a very practical scenario of fault propagation , namely anomalous system status can always be traced back to a set of root cause anomaly nodes , or causal anomalies , as initial seeds . As the time passes , these root cause anomalies will then propagate along the invariant network , most probably towards their neighbors via paths identified by the invariant links in Gl . To explicitly model this spreading process on the network , we have employed the label propagation technique [ 16 , 24 , 26 ] . Suppose that the ( unknown ) root cause anomalies are denoted by the indicator vector e , whose entries ei ’s ( 1 ≤ i ≤ n ) indicate whether the ith node is the casual anomaly ( ei = 1 ) or not ( ei = 0 ) . At the end of propagation , the system status is represented by the anomaly score vector r , whose entries tell us how severe each node of the network has been impaired . The propagation from e to r can be modeled by the following optimization problem ||ri − ei||2 , min r≥0 where D ∈ Rn×n is the degree matrix of A , c ∈ ( 0 , 1 ) is the regularization parameter , r is the anomaly score vector after the propagation of the initial faults in e . We can re write the above problem as ri − 1√ Djj rj||2 + ( 1 − c )
1√ Dii n∑ n∑
Aij|| i;j=1 i=1 c
⊤ cr min r≥0
( In − ˜A)r + ( 1 − c)||r − e||2 F , −1=2AD
( 5 ) −1=2 is the where In is the identity matrix , ˜A = D degree normalized version of A . Similarly we will use ˜P as the degree normalized P in the sequel . The first term in Eq ( 5 ) is the smoothness constraint [ 26 ] , meaning that a good ranking function should assign similar values to nearby nodes in the network . The second term is the fitting constraint , which means that the final status should be close to the initial configuration . The trade off between these two competing constraints is controlled by a positive parameter c : a small c encourages a sufficient propagation , and a big c actually suppresses the propagation . The optimal solution of problem ( 5 ) is [ 26 ] r = ( 1 − c)(In − c ˜A )
−1e ,
( 6 ) which establishes an explicit and closed form solution between the initial configuration e and the final status r through fault propagation . To encode the information of the broken network , we propose to use r to reconstruct the broken network Gb . The intuition is illustrated in Figure 2 . If there exists a broken
807 Algorithm 1 : Ranking Causal Anomalies ( RCA ) Input : Network Gl denoting the invariant network with n nodes , and is represented by an adjacency matrix A , c is the network propagation parameter , is the parameter to control the sparsity of e , ˜P is the normalized adjacency matrix of the broken network , M is the logical matrix of Gl ( 1 with edge , 0 without edge )
Output : Ranking vector e
1 begin 2 for i ← 1to n do
Dii ←∑ n j=1 Aij ;
Figure 2 : Reconstruction of the broken invariant network using anomaly score vector r .
3
4
5
6
7
8
9
10
11 12 end end D ← diag(D11 ; :: : ; Dii ) ; ˜A ← D −1=2 ; Initialize e with random values between ( 0,1 ] ; B ← ( 1 − c)(In − c ˜A )
−1=2AD
−1 ; repeat
Update e by Eq ( 9 ) ; until convergence ; link in Gb , eg , ˜Pij is large , then ideally at least one of the nodes i and j should be abnormal , or equivalently , either ri or rj should be large . Thus , we can use the product of ri and rj to reconstruct the value of ˜Pij . In Section 5 , we’ll further discuss how to normalize them to avoid extreme values . Then , the loss of reconstructing the broken link ˜Pij can be calculated by ( ri · rj − ˜Pij)2 . The reconstruction error of the whole broken network is then ||(rr F . Here , ◦ is element wise operator , and M is the logical matrix of the invariant network Gl ( 1 with edge , 0 without edge ) . Let B = ( 1 − c)(In − c ˜A ) −1 , by substituting r we obtain the following objective function .
)◦ M− ˜P||2
⊤ min ei∈{0;1};1≤i≤n
||(Bee
⊤
⊤
B
) ◦ M − ˜P||2
F
( 7 )
Considering that the integer programming in problem ( 7 ) is NP hard , we relax it by using the ℓ1 penalty on e with parameter τ to control the number of non zero entries in e [ 23 ] . Then we reach the following objective function .
||(Bee
⊤
⊤
) ◦ M − ˜P||2
F + τ||e||1
B
( 8 ) min e≥0
3.2 Learning Algorithm
In this section , we present an iterative multiplicative updating algorithm to optimize the objective function in ( 8 ) . The objective function is invariant under these updates if and only if e are at a stationary point [ 17 ] . The solution is presented in the following theorem , which is derived from the Karush Kuhn Tucker ( KKT ) complementarity condition [ 3 ] . Detailed theoretical analysis of the optimization procedure will be presented in the next section .
Theorem 1 . Updating e according to Eq ( 9 ) will monotonically decrease the objective function in Eq ( 8 ) until convergence .
[
] ⊤ ˜P ) ◦ M e ← e ◦
4
( B
Be
4 [ (B⊤Bee⊤B⊤ ) ◦ M ] Be + τ 1n
,
( 9 ) where ◦ , [ · ]
[ · ] and ( · )
1 4 are element wise operators .
Based on Theorem 1 , we develop the iterative multiplicative updating algorithm for optimization and summarize it in Algorithm 1 . We refer to this ranking algorithm as RCA .
 1
4

3.3 Theoretical Analysis
331 Derivation We derive the solution to problem ( 9 ) following the constrained optimization theory [ 3 ] . Since the objective function is not jointly convex , we adopt an effective multiplicative updating algorithm to find a local optimal solution . We prove Theorem 1 in the following . ||(Bee are symmetric matrix . Let F = ( Bee
We formulate the Lagrange function for optimization L = ⊤ n e . Obviously , B , M and ˜P
) ◦ M − ˜P||2
) ◦ M , then
F + τ 1
B
B
⊤
⊤
⊤
⊤
( F − ˜P)2
∂
∂em ij = 2(Fij − ˜Pij ) ∂Fij em = 4(Fij − ˜Pij)Mij(B = 4B mi(Fij − ˜Pij)Mij(Be)j : ⊤
⊤ miBj:e ) ( by symmetry ) m:[(F − ˜P ) ◦ M](Be ) , ⊤
= 4B
( 10 )
( 11 )
⊤
[ (F − ˜P ) ◦ M](Be ) .
= 4B
( 12 )
It follows that
∂||F − ˜P||2
F
∂em and thereby
F
∂e
∂||F − ˜P||2 [
]
Thus , the partial derivative of Lagrange function with respect to e is :
∇eL = 4B
⊤
⊤
⊤ − ˜P ) ◦ M
B
( Bee
Be + τ 1n ,
( 13 ) where 1n is the n × 1 vector of all ones . Using the KarushKuhn Tucker ( KKT ) complementarity condition [ 3 ] for the non negative constraint on e , we have ∇eL ◦ e = 0
( 14 )
The above formula leads to the updating rule for e that is shown in Eq ( 9 ) .
332 Convergence We use the auxiliary function approach [ 17 ] to prove the convergence of Eq ( 9 ) in Theorem 1 . We first introduce the definition of auxiliary function as follows .
808 Definition 31 Z(h , ˆh ) is an auxiliary function for L(h ) if the conditions
Z(h , ˆh ) ≥ L(h ) and
Z(h , h ) = L(h ) ,
( 15 ) are satisfied for any given h , ˆh [ 17 ] .
Lemma 31 If Z is an auxiliary function for L , then L is non increasing under the update [ 17 ] . h(t+1 ) = argmin
Z(h , h(t ) )
( 16 ) h
Theorem 2 . Let L(e ) denote the sum of all terms in L
)
1 + log eiej ˆeiˆej
(
}
{[
] ⊤ ˜P ) ◦ M
∑ containing e . The following function Z(e , ˆe ) = −2 {[ ∑ ∑
] ) ◦ M
Bˆeˆe
( B
( B
ˆei
B
+
⊤
⊤
⊤ ij i
B
ˆej
} ij
Bˆe i e4 i ˆe3 i
+
τ 4 e4 i + 3ˆe4 i
ˆe3 i i
( 17 ) is an auxiliary function for L(e ) . Furthermore , it is a convex function in e and has a global minimum .
Theorem 2 can be proven in a similar way as in [ 7 ] by validating Z(e ; ^e ) ≥ L(e ) , Z(e ; e ) = L(e ) , and the Hessian matrix ∇∇eZ(e ; ^e ) ≽ 0 . Due to space limitation , the detail of the proof is omitted . Based on Theorem 2 , we can minimize Z(e ; ^e ) with respect to e with ^e fixed . We set ∇eZ(e ; ^e ) = 0 , and get the following updating formula
[
]
⊤ ˜P ) ◦ M
4
( B
Bˆe
4 [ (B⊤Bˆeˆe⊤B⊤ ) ◦ M ] Bˆe + τ 1n
,
( 18 )
 e ← ˆe ◦
 1
4 which is consistent with the updating formula derived from the KKT condition aforementioned . From Lemma 3.1 and Theorem 2 , for each subsequent iteration of updating e , we have L(e0 ) = Z(e0 ; e0 ) ≥ Z(e1 ; e0 ) ≥ Z(e1 ; e1 ) = L(e1 ) ≥ : : : ≥ L(eIter ) . Thus L(e ) monotonically decreases . Since the objective function Eq ( 8 ) is lower bounded by 0 , the correctness of Theorem 1 is proven . 333 Complexity Analysis In Algorithm 1 , we need to calculate the inverse of an n×n matrix , which takes O(n3 ) time . In each iteration , the multiplication between two n×n matrices is inevitable , thus the overall time complexity of Algorithm 1 is O(Iter·n3 ) , where Iter is the number of iterations needed for convergence . In the following section , we will propose an efficient algorithm that reduces the time complexity to O(Iter · n2 ) .
4 . COMPUTATIONAL SPEED UP
In this section , we will propose an efficient algorithm that avoids the matrix inverse calculations as well as the multiplication between two n × n matrices . The time complexity can be reduced to O(Iter · n2 ) .
We achieve the computational speed up by relaxing the objective function in ( 8 ) to jointly optimize r and e . The objective function is shown in the following . min e≥0;r≥0
⊤
( In − ˜A)r + ( 1 − c)||r − e||2 F + τ||e||1
) ◦ M − ˜P||2 cr + λ||(rr
⊤
F
( 19 )
To optimize this objective function , we can use an alternating scheme . That is , we optimize the objective with respect to r while fixing e , and vise versa . This procedure continues until convergence . The objective function is invariant under these updates if and only if r , e are at a stationary point [ 17 ] . Specifically , the solution to the optimization problem in Eq ( 19 ) is based on the following theorem , which is derived from the Karush Kuhn Tucker ( KKT ) complementarity condition [ 3 ] . The derivation of it and the proof of Theorem 3 is similar to that of Theorem 1 .
{
Theorem 3 . Alternatively updating e and r according to Eq ( 20 ) and Eq ( 21 ) will monotonically decrease the objective function in Eq ( 19 ) until convergence . ˜Ar + 2λ( ˜P ◦ M)r + ( 1 − c)e [ ] 1 r + 2λ [ (rr⊤ ) ◦ M ] r r ← r ◦
} 1
( 20 )
4 e ← e ◦
2(1 − c)r
τ 1n + 2(1 − c)e
2
( 21 )
Based on Theorem 3 , we can develop the iterative multiplicative updating algorithm for optimization similar to Algorithm 1 . Due to page limit we skip the details . We refer to this ranking algorithm as R RCA . From Eq ( 20 ) and Eq ( 21 ) , we observe that the calculation of the inverse of the n × n matrix and the multiplication between two n × n matrices in Algorithm 1 are not necessary . As we will see in Section 7.4 , the relaxed versions of our algorithm can greatly improve the computational efficiency .
5 . SOFTMAX NORMALIZATION
In Section 3 , we use the product ri · rj as the strength of evidence that the correlation between node i and j is vanishing ( broken ) . However , it suffers from the extreme values in the ranking values r . To reduce the influence of the extreme values or outliers , we employ the softmax normalization on the ranking values r . The ranking values are nonlinearly transformed using the sigmoidal function before the multiplication is performed . Thus , the reconstruction error is expressed by ||(σ(r)σ eri∑ the softmax function with :
F , where σ(· ) is
( r))◦ M− ˜P||2
⊤
, ( i = 1 , , n ) .
σ(r)i =
( 22 ) n k=1 erk
The corresponding objective function in Algorithm 1 is modified to the following ||(σ(Be)σ
( Be ) ) ◦ M − ˜P||2
F + τ||e||1 .
( 23 )
⊤ min e≥0
Similarly , the objective function for Eq ( 19 ) is modified to the following ⊤ min e≥0;r≥0 cr + λ||(σ(r)σ
( In − ˜A)r + ( 1 − c)||r − e||2
F
⊤
( r ) ) ◦ M − ˜P||2
F + τ||e||1 .
( 24 )
The optimization of these two objective functions are based on the following two theorems .
809 
[
]
Theorem 4 . Updating e according to Eq ( 25 ) will mono(23 ) until tonically decrease the objective function in Eq convergence . e ← e ◦ where Ψ =
⊤
Ψ ˜P ) ◦ M
4
( B
σ(Be )
4 [ (B⊤Ψσ(Be)σ⊤(Be ) ) ◦ M ] σ(Be ) + τ 1n { diag [ σ(Be ) ] − σ(Be)σ
}
( Be )
⊤
.
 1
4
,
( 25 )
Theorem 5 . Updating r according to Eq ( 26 ) will mono(24 ) until tonically decrease the objective function in Eq convergence .
) n ) ◦ ~P + flfi ⊤
[ (  ˜Ar + 2 [ ( ) ( (r ) ◦ ( r))⊤(r ) + ( r)(⊤(r ) ~P ) ⊤
◦ M
( (r)1 r + 2
]
⊤
] ( r ) + ( 1 − c)e
◦ M
( r ) r ← r ◦
 1
4
( 26 ) where Λ = σ(r)σ
( r ) and ρ = σ
( r)σ(r ) . min e(t)≥0;1≤t≤T
||(Be(t)(e(t ) ) ⊤ B + α||e(t ) − e(t−1)||2 t=1
2
⊤
) ◦ M − ˜P(t)||2
F + τ||e(t)||1
( 27 ) Here , ˜P(t ) is the degree normalized adjacency matrix of broken network at time point t . Similar to the discussion in Section 3.3 , we can derive the updating formula of Eq ( 27 ) in the following .

[
] [ ⊤ ~P(t ) ) ◦ M ( B⊤Be(t)(e(t))⊤B⊤ ) ◦ M
( B
4
4
] Be(t ) + 2ffe(t−1 )
Be(t ) + 1n + 2ffe(t ) e(t ) ← e(t ) ◦
 1
4
( 28 ) The updating formula for R RCA , RCA SOFT , and RRCA SOFT with temporal broken networks smoothing is similar . Due to space limit , we skip the details . We refer to the algorithms with temporal smoothing as T RCA , TR RCA , T RCA SOFT and T R RCA SOFT respectively .
7 . EMPIRICAL STUDY
In this section , we perform extensive experiments to evaluate the performance of the proposed methods ( summarized in Table 1 ) . We use both simulated data and realworld monitoring datasets for validation . For comparison ,
Theorem 4 and Theorem 5 can be proven with a similar strategy to that of Theorem 1 . We refer to the ranking algorithms with softmax normalization ( Eq ( 23 ) and Eq ( 24 ) ) as RCA SOFT and R RCA SOFT respectively .
6 . TEMPORAL SMOOTHING ON MULTI
PLE BROKEN NETWORKS
As discussed in Section 1 , although the number of anomaly nodes could increase due to fault propagation in the network , the root cause anomalies will be stable within a short time period T [ 14 ] . Based on this intuition , we further develop a smoothing strategy by jointly considering the temporal broken networks . Specifically , we add a smoothing term ||e(t ) − e(t−1)||2 2 to the objective functions . Here , e(t−1 ) and e(t ) are causal anomaly ranking vectors for two successive time points . For example , the objective function of algorithm RCA with temporal broken networks smoothing is shown in Eq ( 27 ) .
T∑
[ we select several state of the art methods , including mRank and gRank in [ 8 , 13 ] , and LBP [ 22 ] . For all the methods , the tuning parameters were tuned using cross validation . We use several evaluation metrics including precision , recall , and nDCG [ 12 ] to measure the performance . The precision and recall are computed on the top K ranking result , where K is typically chosen as twice the actual number of ground truth causal anomalies [ 12 , 22 ] . The nDCG of the top p ranking result is defined as nDCGp = DCGp , where IDCGp p i=1
2reli DCGp = log2(1+i ) . Here , IDCGp is the DCGp value on the ground truth , and p is smaller than or equal to the actual number of ground truth anomalies . The reli represents the anomaly score of the ith item in the ranking list of the ground truth . 7.1 Simulation Study
∑
−1
;
]
We first evaluate the performance of the proposed methods using simulations . We have followed [ 8 , 22 ] in generating the simulation data . 711 Data Generation We first generate 5000 synthetic time series data to simulate the monitoring records2 . Each time series contains 1,050 time points . Based on the invariant model introduced in Section 2.1 , we build the invariant network by using the first 1,000 time points in the time series . This generates an invariant network containing 1,551 nodes and 157,371 edges . To generate invariant network of different sizes , we randomly sample 200 , 500 , and 1000 nodes from the whole invariant network and evaluate the algorithms on these sub networks . To generate the root cause anomaly , we randomly select 10 nodes from the network , and assign each of them an anomaly score between 1 and 10 . The ranking of these scores is used as the ground truth . To simulate the anomaly prorogation , we further use these scores as the vector e in Eq ( 6 ) and calculate r ( c = 09 ) The values of the top 30 time series with largest values in r are then modified by changing their amplitude value with the ratio 1+ri . That is , if the observed values of one time series is y1 , after changing it from y1 to y2 , the manually injected degree of anomaly is equal to 1 + ri . We denote this anomaly generation scheme as amplitude based anomaly generation . 712 Performance Evaluation Using the simulated data , we compare the performance of different algorithms . In this example , we only consider the training time series as one snapshot ; multiple snapshot cases involving temporal smoothing will be examined in the real datasets . Due to the page limit , we report the precision , recall and nDCG for only the top 10 items considering that the ground truth contains 10 anomalies . Similar results can be observed with other settings of K and p . For each algorithm , reported result is averaged over 100 randomly selected subsets of the training data .
|y2−y1|
|y1|
From Figure 3 , we have several key observations . First , the proposed algorithms significantly outperform other competing methods , which demonstrates the advantage of taking into account fault prorogation in ranking casual anomalies . We also notice that performance of all ranking algorithms will decline on larger invariant networks with more nodes , indicating that anomaly ranking becomes more challenging on 2http://csuncedu/∼weicheng/synthetics5000csv
810 Categories
Samples of Measurements utilization , user usage time , IO wait time
CPU DISK # of write operations , write time , weighted IO time MEM NET SYS run queue , collision rate , UsageRate error rate , packet rate
UTIL , MODE UTIL
Figure 3 : Comparison on synthetic data(K , p = 10 ) .
Figure 4 : ratio(K , p = 10 ) .
Performance with different noise networks with more complex behaviour . However , the ranking result with softmax is less sensitive to the size of the invariant network , suggesting that the softmax normalization can effectively improve the robustness of the algorithm . This is quite beneficial in real life applications , especially when data are noisy . Finally , we observe that RCA and RCASOFT outperform R RCA and R RCA SOFT , respectively . This implies that the relaxed versions of the algorithms are less accurate . Nevertheless , their accuracies are still very comparable to those of the RCA and RCA SOFT methods . In addition , the efficiency of the relaxed algorithms is greatly improved , as discussed in Section 4 and Section 74 713 Robustness Evaluation Practical invariant network and broken edges can be quite noisy . In this section , we further examine the performance of the proposed algorithms wrt different noise levels . To do this , we randomly perturb a portion of non broken edges in the invariant network . Results are shown in Figure 4 . We observe that , even when the noise ratio approaches 50 % , the precision , recall and nDCG of the proposed approaches still attain 05 This indicates the robustness of the proposed algorithms . We also observe that , when the noise ratio is very large , RCA SOFT and R RCA SOFT work better than RCA and R RCA , respectively . This is similar to those observations made in Section 712 As has been discussed in Section 5 , the softmax normalization can greatly suppress the impact of extreme values and outliers in r , thus improves the robustness . 7.2 Ranking Causal Anomalies on Bank In formation System Data
In this section , we apply the proposed methods to detect causal abnormal components on a Bank Information System ( BIS ) data set [ 8 , 22 ] . The monitoring data are collected from a real world bank information system logs , which contain 11 categories . Each category has a varying number of
Table 2 : Examples of categories and monitors .
Figure 5 : Two example monitoring data of BIS .
Data Set #Monitors#invariant links#broken edges at given time point
BIS
Coal Plant
1273 1625
39116 9451
18052
56
Table 3 : Data set description .
Figure 6 : Comparison on BIS data . time series , and Table 2 gives five categories as examples . The data set contains the flow intensities collected every 6 seconds . In total , we have 1,273 flow intensity time series . The training data is collected at normal system states , where each time series has 168 time points . The invariant network is then generated on the training data as described in Section 21 The testing data of the 1,273 flow intensity time series are collected during abnormal system states , where each time series contain 169 time points . We track the changes of the invariant network with the testing data using the method described in Section 21 Once we obtain the broken networks at different time points , we perform causal anomaly ranking in these temporal slots jointly . Properties of the networks constructed are summarized in Table 3 .
Based on the knowledge from system experts , the root cause anomaly at t = 120 in the testing data is related to “ DB16 ” . An illustration of two “ DB16 ” related monitoring data are shown in Figure 5 . We highlight t : 120 with red square . Obviously , their behaviour looks anomalous from that time point on . Due to the complex dependency among different monitoring time series , it is impractical to obtain a full ranking of abnormal measurement . Fortunately , we have a unique semantic label associated with each measurement . For example , some semantic labels read “ DB16:DISK hdx Request ” and “ WEB26 PAGEOUT RATE ” . Thus , we can extract all measurements whose titles have the prefix “ DB16 ” as the ground truth anomalies . The ranking score is precisionrecallnDCG04050607#Time Series=1000 RCA−SOFTR−RCA−SOFTRCAR−RCAgRankmRankLBPprecisionrecallnDCG04050607#Time Series=200precisionrecallnDCG04050607#Time Series=5000204060802030405noise ratioprecisionprecision 0204060802030405noise rationDCGnDCG 0204060802030405noise ratiorecallrecall RCA−SOFTR−RCA−SOFTRCAR−RCAgRankmRankLBP1001201401600204060DB16:DISK hday Request1001201401600100200300DB16:DISK hday Blocktimeamplitude0801600010203040506KPrecision @Top−K 0801600010203040506KRecall @Top−K 040800010203040506pnDCGp RCA−SOFTR−RCA−SOFTRCAR−RCAgRankmRankLBP(c ) nDCG(a ) precision(b ) recall811 mRank gRank
LBP
RCA
RCA SOFT
R RCA
R RCA SOFT
HUB17:DISK hda Request HUB17:DISK hda Request DB15:DISK hdaz Block
WEB16:NET eth1 BYNETIF HUB18:MEM UsageRate WEB22:SYS MODE UTIL HUB17:DISK hda Request DB17:DISK hdm Block HUB17:DISK hda Request DB17:DISK hdm Block DB17:DISK hday Block DB17:DISK hdba Block DB15:PACKET Output DB17:DISK hdba Block AP12:DISK hd45 Block WEB12:NET eth1 BYNETIF HUB17:DISK hda Busy DB16:DISK hdm Block HUB17:DISK hda Busy DB16:DISK hdm Block DB18:DISK hdba Block DB18:DISK hdm Block AP12:DISK hd1 Block DB17:DISK hdm Block DB16:DISK hdj Request DB18:DISK hdm Block DB16:DISK hdj Request DB17:DISK hdba Block DB16:DISK hdax Request AP11:DISK hd45 Block DB16:DISK hdm Block DB18:DISK hdba Block DB18:DISK hdm Block DB18:DISK hdag Request AP11:DISK hd1 Block DB17:DISK hday Block DB17:DISK hdba Block DB16:DISK hdax Request DB16:DISK hdm Block DB17:DISK hdm Block DB18:DISK hdag Request DB18:DISK hdba Block DB18:DISK hdbu Request DB15:PACKET Input DB17:DISK hdm Block DB16:DISK hdba Block DB18:DISK hdbu Request DB17:DISK hday Block DB18:DISK hdx Request DB16:DISK hdm Block WEB25:PAGEOUT RATE DB16:DISK hdj Request DB16:DISK hdba Block DB16:DISK hdba Block DB18:DISK hdax Request DB17:DISK hdba Block DB18:DISK hdm Block
DB16:DISK hdy Block DB18:DISK hdag Request DB18:DISK hdx Request DB16:DISK hdj Request DB18:DISK hdba Block AP13:DISK hd30 Block DB16:DISK hdax Request DB18:DISK hdax Request DB18:DISK hdag Request DB16:DISK hdx Request
AP12:DISK hd45 Block AP12:DISK hd1 Block WEB19:DISK BYDSK AP11:DISK hd45 Block AP11:DISK hd1 Block DB16:DISK hdm Block DB17:DISK hdm Block DB18:DISK hdm Block DB17:DISK hdba Block DB18:DISK hdba Block
WEB17:DISK BYDSK DB18:DISK hdt Busy
DB15:DISK hdl Request
DB18:DISK hdm Block
WEB21:DISK BYDSK
WEB27:FREE UTIL
WEB19:NET eth0
Table 4 : Top 12 anomalies detected by different methods on BIS data(t:120 ) . mRankgRankLBPRCARCA SOFTR RCAR RCA SOFT
10
7
4
14
16
13
17
Table 5 : Number of “ DB16 ” related monitors in top 32 results on BIS data(t:120 ) . determined by the number of broken edges associated with each measurement . Here our goal is to demonstrate how the top ranked measurements selected by our method are related to the “ DB16 ” root cause . Altogether , there are 80 measurements related to “ DB16 ” in the invariant network , so we report the precision , recall with K ranging from 1 to 160 and the nDCG with p ranging from 1 to 80 , respectively . The results are shown in Figure 6 . The relative performance of different approaches is consistent with the observations in the simulation study . Again , the proposed algorithms outperform baseline methods by a large margin . To examine the top ranked items more clearly , we list the top12 results of different approaches in Table 4 and report the number of “ DB16 ” related monitors in Table 5 . From Table 4 , we observe that the three baseline methods only report one “ DB16 ” related measurement in the top 12 results , and the actual rank of the “ DB16 ” related measurement appear lower ( worse ) than that of the proposed methods . We also notice that the ranking algorithms with softmax normalization outperform others . From Tables 4 and 5 , we can see that top ranked items reported by RCA SOFT and R RCASOFT are more relevant than those reported by RCA and R RCA , respectively . This clearly illustrates the effectiveness of the softmax normalization in reducing the influence of extreme values or outliers in the data .
As discussed in Section 1 , the root anomalies could further propagate from one component to related ones over time , which may or may not necessarily relate to “ DB16 ” . Such anomaly propagation makes anomaly detection even harder . To study how the performance varies at different time points , we compare the performance at t = 120 and t = 122 , respectively in Figure 7 ( p,K=80 ) . Clearly , the performance declines for all methods . However , the proposed methods are less sensitive to anomaly propagation than others , suggesting that our approaches can better handle the fault propagation problem . We believe this is attributed to the network diffusion model that explicitly captures the fault propagation processes . We also list the top 12 abnormal at t = 122 in Table 6 . Due to page limit , we only show the results of mRank , gRank , RCA SOFT and R RCA SOFT . By comparing the results in Tables 4 and 6 , we can observe that RCA SOFT and R RCA SOFT significantly outperform mRank and gRank , the latter two methods which are based on the percentage of broken edges are more sensitive to the anomaly prorogation .
AP12:DISK hd45 Block AP12:DISK hd1 Block DB18:DISK hday Block DB18:DISK hdk Block mRank gRank
RCA SOFT
R RCA SOFT
WEB21:NET eth1 BYNETIF WEB21:NET eth0 BYNETIF DB17:DISK hdm Block DB17:DISK hdm Block WEB21:NET eth0 BYNETIF WEB21:NET eth1 BYNETIF DB17:DISK hdba Block DB17:DISK hdba Block DB16:DISK hdm Block DB16:DISK hdm Block DB18:DISK hdm Block DB16:DISK hdj Request WEB26:PAGEOUT RATE DB16:DISK hdj Request DB16:DISK hdax Request
HUB18:MEM UsageRate
WEB21:FREE UTIL
WEB21:FREE UTIL
DB18:DISK hday Request DB18:DISK hdk Request WEB26:PAGEOUT RATE DB18:DISK hday Request DB18:DISK hdbl Request DB18:DISK hdax Request
DB16:DISK hdax Request DB18:DISK hdx Request DB16:DISK hdba Block DB18:DISK hdba Block DB18:DISK hdx Request DB16:DISK hdba Block
AP12:DISK hd45 Block AP12:DISK hd1 Block DB18:DISK hday Block DB18:DISK hdk Block
DB18:DISK hdba Block DB18:DISK hdm Block
DB17:DISK hdm Block DB16:DISK hdm Block
DB18:DISK hdk Request AP11:DISK hd45 Block
DB16:DISK hdx Busy
DB16:PACKET Inputx
DB16:DISK hdx Request DB18:DISK hdbl Request
Table 6 : Top 12 anomalies on BIS data(t:122 ) .
T RCA
T RCA SOFT
T R RCA
T R RCA SOFT
WEB14:NET eth0 BYNETIF DB17:DISK hdm Block WEB14:NET eth0 BYNETIF DB17:DISK hdm Block DB17:DISK hdba Block WEB21:NET eth0 BYNETIF DB17:DISK hdba Block DB16:DISK hdm Block WEB16:DISK BYDSK PHYS DB16:DISK hdm Block DB18:DISK hdm Block DB18:DISK hdm Block DB16:DISK hdj Request DB16:DISK hdj Request DB18:DISK hdba Block DB18:DISK hdba Block
WEB16:DISK BYDSK DB18:DISK hdba Block DB18:DISK hdm Block DB17:DISK hdba Block DB16:DISK hdm Block DB17:DISK hdm Block DB16:DISK hdax Request DB17:DISK hdm Block DB16:DISK hdax Request DB18:DISK hdx Request DB16:DISK hdba Block DB16:DISK hdba Block DB16:DISK hdj Request DB18:DISK hdx Request DB16:DISK hdba Block DB16:DISK hdax Request DB18:DISK hdbl Request
DB16:DISK hdba Block DB17:DISK hday Block DB16:DISK hdm Block
DB15:PACKET Output DB16:DISK hdj Request
WEB21:FREE UTIL
DB18:DISK hdbl Request DB16:DISK hdax Request DB16:DISK hdx Request
DB16:DISK hdx Busy
DB16:DISK hdx Request
DB18:DISK hdba Block
DB16:DISK hdx Busy
DB16:DISK hdx Busy DB16:DISK hdbl Busy
Table 7 : Top 12 anomalies reported by methods with temporal smoothing on BIS data(t:120 121 ) .
Without temporal smoothing 4 6
With temporal smoothing
4 6
3 4
4 6
RCARCA SOFTR RCAR RCA SOFT
Table 8 : Comparison on the number of “ DB16 ” related anomalies in top 12 results on BIS data . mRank
Y0039 X0128 Y0256 H0021 X0146 X0149 H0022 F0454 H0020 X0184 X0166 J0164 gRank Y0256 Y0045 Y0028 X0146 X0057 X0061 X0068 X0143 X0158 X0164 J0164 H0021
LBP Y0256 X0146 F0454 X0128 Y0039 X0166 X0144 X0149 J0085 X0061 Y0030 J0079
RCA X0146 Y0045 X0128 Y0030 X0057 X0158 X0068 X0061 X0139 X0143 H0021 F0454
RCA SOFT
R RCA
R RCA SOFT
X0146 Y0256 F0454 J0079 Y0308 X0166 X0144 X0128 X0165 X0142 H0022 X0143
X0146 X0128 F0454 Y0256 Y0039 Y0246 Y0045 Y0028 X0056 J0079 X0149 X0145
X0146 X0166 X0144 X0165 X0142 J0079 X0164 X0145 X0143 X0163 J0164 X0149
Table 9 : Top anomalies on coal plant data .
We further validate the effectiveness of proposed methods with temporal smoothing . We report the top 12 results of different methods with smoothing at two successive time points t = 120 and t = 121 in Table 7 . The number of “ DB16 ” related monitors in the top 12 results is summarized in Table 8 . From Tables 7 and 8 , we observe a significant performance improvement of our methods with temporal broken networks smoothing compared with those without smoothing . As discussed in Section 6 , since causal anomalies of a system usually do not change within a short period of time , utilizing such smoothness can effectively suppress noise and thus give better ranking accuracy . 7.3 Fault Diagnosis on Coal Plant Data
In this section , we test the proposed methods in the application of fault diagnosis on a coal plant cyber physical
812 ( a ) precision
( b ) recall
( c ) nDCG
Figure 7 : Performance at t:120 vs t:122 on BIS data(p,K=80 ) .
( a ) Egonet “ X0146 ” of node
( b ) Egonet of node “ Y0256 ”
Figure 8 : Egonet of node “ X0146 ” and “ Y0256 ” in invariant network and vanishing correlations(red edges ) on coal plant data . system data . The data set contains time series collected through 1625 electric sensors installed on different components of the coal plant system . Using the invariant model described in Section 2.1 , we generate the invariant network that contains 9451 invariant links . For privacy reasons , we remove sensitive descriptions of the data .
Based on knowledge from domain experts , in the abnormal stage , the root cause is associated with component “ X0146 ” . We report the top 12 results of different ranking algorithms in Table 9 . We observe that our algorithms all rank component “ X0146 ” the highest , while the baseline methods could give higher ranks to other components . In Figure 8(a ) , we visualize the egonet of the node “ X0146 ” in the invariant network , which is defined as the 1 step neighborhood around node “ X0146 ” , including the node itself , direct neighbors , and all connections among these nodes in the invariant network . Here , green lines denote the invariant link , and red lines denote vanishing correlations ( broken links ) . Since the node “ Y0256 ” is top ranked by the baseline methods , we also visualize its egonet in Figure 8(b ) for a comparison . There are 80 links related to “ X0146 ” in the invariant network , and 14 of them are broken . Namely the percentage of broken edges is only 17.5 % for a truly anomalous component . In contrast , the percentage of broken edges for the node “ Y0256 ” is 100 % , namely a false positive node can have a very high percentage of broken edges in practice . This explains why baseline approaches using the percentage of broken edges could fail , because the percentage of broken edges does not serve as a reliable evidence of the degree of causal anomalies . In comparison , our approach takes into account the global structures of the invariant network via network propagation , thus the resultant ranking is more meaningful . 7.4 Time Performance Evaluation
In this section , we study the efficiency of proposed methods using the following metrics : 1 ) the number of iterations
Figure 9 : Number of iterations to converge and time cost comparison .
Figure 10 : Running time on real data sets . for convergence ; 2 ) the running time ( in seconds ) ; and 3 ) the scalability of the proposed algorithms . Figure 9(a ) shows the value of the objective function with respect to the number of iterations on different data sets . We can observe that , the objective value decreases steadily with the number of iterations . Typically less than 100 iterations are needed for convergence . We also observe that our method with softmax normalization takes fewer iterations to converge . This is because the normalization is able to reduce the influence of extreme values [ 21 ] . We also report the running time of each algorithm on the two real data sets in Figure 10 . We can see that the proposed methods can detect causal anomalies very efficiently , even with the temporal smoothing module . To evaluate the computational scalability , we randomly generate invariant networks with different number of nodes ( with network density=10 ) and examine the computational cost . Here 10 % edges are randomly selected as broken links . Using simulated data , we compare the running time of RCA , R RCA , RCA SOFT , and R RCA SOFT . Figure 9(b ) plots the running time of different algorithms wrt the number of nodes in the invariant network . We can see that the relaxed versions of our algorithm are computationally more efficient than the original RCA and RCA SOFT . These results are consistent with the complexity analysis in Section 4 . mRankgRankLBPRCARCA−SOFTR−RCAR−RCA−SOFT000501015020250303504algorithmprecision@80 t:120t:122mRankgRankLBPRCARCA−SOFTR−RCAR−RCA−SOFT000501015020250303504algorithmrecall@80 t:120t:122mRankgRankLBPRCARCA−SOFTR−RCAR−RCA−SOFT000501015020250303504algorithmnDCG80 t:120t:1221020304012345678x 104#iterationobjective function valueBIS Data 102030200300400500600700800#iterationobjective function valueCoal Plant Data 050001000010−2100102104#nodes in invariant networktime cost ( seconds ) RCARCA−SOFTR−RCAR−RCA−SOFT(b ) Time costs comparison(a ) Number of iterations to convergeCoal Plant DataBIS Data050100150200250data setrunning time(second ) mRankgRankLBPRCARCA−SOFTR−RCAR−RCA−SOFTT−RCAT−RCA−SOFTT−R−RCAT−R−RCA−SOFT813 8 . RELATED WORK
In this section , we review the related work on anomaly detection and system diagnosis . In particular , we focus on the following two categories : 1 ) fault detection in distributed systems ; and 2 ) graph based methods .
For the first category , Yemini et al . [ 25 ] proposed to model event correlation and locate system faults using known dependency relationships between faults and symptoms . In real applications , however , it is usually hard to obtain such relationships precisely . To alleviate this limitation , Jiang et al . [ 13 ] developed several model based approaches to detect the faults in complex distributed systems . They further proposed several Jaccard Coefficient based approaches to locate the faulty components [ 14 , 15 ] . These approaches generally focus on locating the faulty components , they are not capable of spotting or ranking the causal anomalies .
Recently , graph based methods have drawn a lot of interest in system anomaly detections [ 2 , 5 ] , either in static graphs or dynamic graphs [ 2 ] . In static graphs , the main task is to spot anomalous network entities given the graph structure [ 4 , 11 ] . For example , Akoglu et al . [ 1 ] proposed OddBall to detect anomalous nodes in weighted graphs . Liu et al . [ 18 ] proposed to use frequent subgraph mining to detect non crashing bugs in software flow graphs . However , these approaches only focus on a single graph ; in comparison , we take into account both the invariant graph and the broken correlations , which provides a more dynamic and complete picture for anomaly ranking . In dynamic graphs , anomaly detection aims at detecting abnormal events [ 19 ] . Most approaches along this direction are designed to detect anomaly time stamps in which suspicious events take place , but not to perform ranking on a large number of system components . Sun et al . proposed to use temporal graphs for anomaly detection [ 20 ] . In their approach , a set of initial suspects need to be provided ; then internal relationship among these initial suspects is characterized for better understanding of the root cause of these anomalies .
In using the invariant graph and the broken invariance graph for anomaly detection , Jiang et al . [ 14 ] used the ratio of broken edges in the invariant network as the anomaly score for ranking ; Ge et al . [ 8 ] proposed mRank and gRank to rank causal anomalies ; Tao et al . [ 22 ] used the loopy belief propagation method to rank anomalies . As has been discussed , these algorithms rely heavily on the percentage of broken edges in egonet of a node . Such local approaches do not take into account the global network structures , neither the global fault propagation spreading on the network . Therefore the resultant rankings can be sub optimal .
9 . CONCLUSIONS
Detecting causal anomalies on monitoring data of distributed systems is an important problem in data mining research . Robust and scalable approaches that can model the potential fault propagation are highly desirable . We develop a network diffusion based framework , which simultaneously takes into account fault propagation on the network as well as reconstructing anomaly signatures using propagated anomalies . Our approach can locate causal anomalies more accurately than existing approaches ; in the meantime , it is robust to noise and computationally efficient . Using both synthetic and real life data sets , we show that the proposed methods outperform other competitors by a large margin .
10 . ACKNOWLEDGMENTS
Wei Wang is supported by the National Science Foundation grants IIS 1313606 , DBI 1565137 , by National Institutes of Health under the grant number R01GM115833 01 .
11 . REFERENCES
[ 1 ] L . Akoglu , M . McGlohon , and C . Faloutsos . Oddball : Spotting anomalies in weighted graphs . PAKDD , pages 410–421 .
[ 2 ] L . Akoglu , H . Tong , and D . Koutra . Graph based anomaly detection and description : A survey . CoRR , 2014 .
[ 3 ] S . Boyd and L . Vandenberghe . Convex Optimization .
Cambridge University Press , 2004 .
[ 4 ] M . M . Breunig , H P Kriegel , R . T . Ng , and J . Sander . Lof :
Identifying density based local outliers . SIGMOD , pages 93–104 , 2000 .
[ 5 ] V . Chandola , A . Banerjee , and V . Kumar . Anomaly detection :
A survey . ACM Computing Surveys , 41(3):1–58 , 2009 . [ 6 ] H . Chen , H . Cheng , G . Jiang , and K . Yoshihira . Global invariants for the management of large scale information systems . In ICDM , 2008 .
[ 7 ] C . Ding , T . Li , W . Peng , and H . Park . Orthogonal nonnegative matrix t factorizations for clustering . In KDD , pages 126–135 , 2006 .
[ 8 ] Y . Ge , G . Jiang , M . Ding , and H . Xiong . Ranking metric anomaly in invariant networks . TKDD , 8(2 ) , Jun . 2014 .
[ 9 ] J . Gertler . Fault Detection and Diagnosis in Engineering
Systems . Marcel Dekker , 1998 .
[ 10 ] Gertler:1998 . System Identification ( 2nd Ed. ) : Theory for the
User . 1999 .
[ 11 ] K . Henderson , T . Eliassi Rad , C . Faloutsos , L . Akoglu , L . Li ,
K . Maruhashi , B . A . Prakash , and H . Tong . Metric forensics : a multi level approach for mining volatile graphs . In KDD , pages 163–172 , 2010 .
[ 12 ] Jarvelin , Kalervo and Kekalainen , Jaana . Cumulated gain based evaluation of IR techniques . TIS , 20(4):422–446 , 2002 .
[ 13 ] G . Jiang , H . Chen , and K . Yoshihira . Discovering likely invariants of distributed transaction systems for autonomic system management . Cluster Computing , 9(4):385–399 , 2006 .
[ 14 ] G . Jiang , H . Chen , and K . Yoshihira . Modeling and tracking of transaction flow dynamics for fault detection in complex systems . TDSC , 3(4):312–326 , 2006 .
[ 15 ] G . Jiang , H . Chen , and K . Yoshihira . Efficient and scalable algorithms for inferring invariants in distributed systems . TKDE , 19(11):1508–1523 , 2007 .
[ 16 ] T . H . Kim , K . M . Lee , and S . U . Lee . Generative image segmentation using random walks with restart . In ECCV , pages 264–275 , 2008 .
[ 17 ] D . D . Lee and H . S . Seung . Algorithms for non negative matrix factorization . In NIPS , pages 556–562 , 2000 .
[ 18 ] C . Liu , X . Yan , H . Yu , J . Han , and P . S . Yu . Mining behavior graphs for ” backtrace ” of noncrashing bugs . In SDM , pages 286–297 , 2005 .
[ 19 ] R . A . Rossi , B . Gallagher , J . Neville , and K . Henderson .
Modeling dynamic behavior in large evolving graphs . WSDM , pages 667–676 , 2013 .
[ 20 ] J . Sun , D . Tao , and C . Faloutsos . Beyond streams and graphs :
Dynamic tensor analysis . KDD ’06 , pages 374–383 , 2006 .
[ 21 ] R . S . Sutton and A . G . Barto . Reinforcement Learning : An
Introduction . The MIT Press , Cambridge , MA , 1998 .
[ 22 ] C . Tao , Y . Ge , Q . Song , Y . Ge , and F . Omitaomu . Metric ranking of invariant networks with belief propagation . In ICDM , 2014 .
[ 23 ] R . J . Tibshirani . Regression shrinkage and selection via the lasso . Journal of the Royal Statistical Society , Series B , 58(1):267–288 , 1996 .
[ 24 ] H . Tong , C . Faloutsos , and J Y Pan . Fast random walk with restart and its applications . In ICDM , pages 613–622 , 2006 . [ 25 ] S . A . Yemini , S . Kliger , E . Mozes , Y . Yemini , and D . Ohsie .
High speed and robust event correlation . IEEE Communications Magazine , 34:82–90 , 1996 .
[ 26 ] D . Zhou , O . Bousquet , T . N . Lal , J . Weston , and B . Sch¨olkopf .
Learning with local and global consistency . In NIPS , pages 321–328 , 2003 .
814
