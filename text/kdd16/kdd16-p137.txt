Ranking Universities Based on Career Outcomes of
Graduates
Navneet Kapur
GoFundMe
∗
Redwood City , CA , USA nkapur@gofundme.com
Nikita Lytkin
LinkedIn Corporation
Mountain View , CA , USA nlytkin@linkedin.com
Bee Chung Chen LinkedIn Corporation
Mountain View , CA , USA bchen@linkedin.com
Deepak Agarwal LinkedIn Corporation
Mountain View , CA , USA dagarwal@linkedin.com
Igor Perisic
LinkedIn Corporation
Mountain View , CA , USA iperisic@linkedin.com
ABSTRACT Every year , millions of new students enter higher educational programs . Publicly available rankings of academic programs play a key role in prospective students’ decisions regarding which universities to apply to and enroll in . While surveys indicate that majority of freshmen enter college to get good jobs after graduation , established methodologies for ranking universities rely on indirect indicators of career outcomes such as reputational assessments of the universities among academic peers , acceptance and graduation rates , learning environment , and availability of research funding . In addition , many of these methodologies rely on arbitrary choices of weighting factors for the different ranking indicators , and suffer from lack of analyses of statistical stability . In this paper , we addresses these challenges holistically by developing a novel methodology for ranking and recommending universities for different professions on the basis of career outcomes of professionals who graduated from those schools . Our methodology incorporates a number of techniques for achieving statistical stability , and represents a step towards personalized educational recommendations based on interests and ambitions of individuals . We have applied this methodology on LinkedIn ’s Economic Graph data of over 400 million professional from around the world . The resulting university rankings have been made available to the public and demonstrate that there are valuable insights to be gleaned from professional career data on LinkedIn .
Keywords Educational Recommendations ; University Rankings ; Company Rankings ; Statistics
∗Work done while at LinkedIn .
1 .
INTRODUCTION
Millions of high school students ( 3 million in the US alone in 2015 ) apply for higher education every year . For each aspiring college student , the application process starts with selecting schools to apply to based on the student ’s career interests and academic performance . A recent survey [ 16 ] conducted by Higher Education Research Institute on hundreds of thousands of entering freshman found that 88 % of freshman attend college to get a good job while 81 % state the desire to be very well off financially as one of their personal goals . Thus , the ability to recommend schools on the basis of careers and eventually in a personalized manner has potential to provide tremendous value .
On LinkedIn.com , millions of professionals across the world enter rich information about their careers . We propose to leverage this valuable data and convert it into actionable information for LinkedIn ’s youngest users and drive change through actionable insights at higher education institutions . In this paper , we for the first time present in full detail our novel approach to ranking and recommending universities given a choice of a profession , on the basis of career outcomes of professionals who graduated from those schools .
The notion of ranking universities in itself is not a new concept . Ranking agencies such as US News & World Report , Times Higher Education and QS produce university lists each year overall and by major . These rankings assess schools on the basis of indicators such as percentages of accepted students who go on to enroll , graduation rates , average SAT scores in addition to somewhat nebulous indicators like reputational assessments by peers at other universities . However , we believe that a more objective way to evaluate a degree program with respect to career outcomes is to measure performance of its graduates in industry . We achieve this by first developing an approach for identifying most desirable companies for different professions . We then present a methodology for ranking universities based on the rates at which their graduates are able to obtain jobs at these desirable companies in a given profession . Such data driven rankings are a complex data product which requires careful consideration for a number of statistical aspects including representation bias and statistical robustness of results . In following sections , we present our methodology and approaches used for correcting potential representation biases
137 and ensuring statistical robustness of the computed rankings with respect to potential noise in the underlying data .
2 . RELATED WORK
Commonly adopted approaches [ 5 , 6 , 2 , 1 ] to university rankings typically rely on a mixture of factors such as a university ’s reputation amongst peer academics ( eg , deans , provosts and faculty ) , learning environment ( eg , class size ) , research quality , volume and funding , and student acceptance and graduation rates . While some ranking methodologies focus on a single factor such as quality of research output [ 19 ] or reputation among academic peers [ 4 , 3 ] , other methodologies combine multiple factors into a single ranking statistic [ 5 , 6 , 2 , 1 , 12 , 18 ] . In the latter case , the ranking statistic is often based on a weighted combination of scores on each individual factor . For instance , US News 2016 undergraduate rankings [ 5 ] place a weight of 22.5 % on Undergraduate academic reputation ( as judged by surveyed academic peers and high school counselors ) , and 12.5 % on Student selectivity , which includes application acceptance rate as a sub factor . Another popular ranking of universities produced by Times Higher Education ( THE ) [ 2 ] follows a similar approach to US News .
Both US News and THE methodologies are examples of approaches in which individual factor weights are assigned arbitrarily at the ranking agency ’s discretion a point of criticism which has also been raised by other researchers [ 19 , 14 ] . Furthermore , no assessment by the ranking agencies is provided on ( a ) statistical confidence of the rankings ( eg , due to limited sample sizes , reporting errors , etc. ) , and ( b ) the degree of sensitivity of the rankings with respect to changes in the weights assigned to the individual factors1 . The use of ad hoc factor weightings coupled with a lack of analyses of statistical stability of the rankings and of their sensitivity to changes in the factor weightings comes at the cost of interpretability of the rankings and makes their reliability ( in some sense , trustworthiness ) unclear . At the same time , research suggests that university rankings wield significant influence over prospective students’ educational choices with the strength of the influence increasing with increasing rank of a university [ 13 ] . Researchers have also begun to question the strength of the link between quality of education and the quantitative factors used in common university rankings ( see [ 11 ] for a methodological critique of the major quality assessments in US higher education ) .
In order to make university rankings robust to potential noise in the underlying data , in the current work , we integrate statistical stability mechanisms directly into the rankings methodology by making use of confidence intervals and resampling techniques as discussed in subsequent sections . Moreover , instead of attempting to combine multiple different ranking dimensions into one ranking statistic , we focus exclusively on a single ranking criterion based on career outcomes of university graduates , as will be explained in the following sections .
It is worth noting that factors such as academic reputation are prone to manipulation and feedback effects , with the effects getting stronger with increasing influence of the rankings publisher on the general audience . Interestingly and
1Unfortunately , the underlying data is not publicly available , which precludes such sensitivity analyses from being conducted by independent researchers . perhaps not surprisingly , broad publicity and the potential for attracting prospective students are cited by ranking and data collection agencies as the key reasons for universities to provide the necessary data2 . To see the potential for a feedback loop , consider that a better ranking of a university by a prominent ranking agency may lead to increases in the number of applications to that university in subsequent years . This in turn could further increase the university ’s reputational assessment and acceptance indicators ( eg , lower admission rates ) . As a result , this university ’s competitiveness in the rankings could increase over time . In fact , [ 9 ] found evidence of strong effects on university acceptance indicators due to ranking by US News . There is also evidence suggesting that the sheer act of publishing a ranking can influence peer assessments of reputability of a university in subsequent surveys [ 8 , 10 ] . For example , [ 10 ] found anchoring effects in peer assessments of university reputation due to the first publication of Times Higher Education Supplement world university rankings . In addition , another study [ 8 ] found evidence of significant influence of US News rankings on future peer assessments , independent of changes in organizational quality and performance . We therefore refrain from using reputational assessment factors in our ranking methodology .
A major limitation faced by the above ranking methodologies is due to the lack of comprehensive data on career outcomes of university graduates . In contrast , LinkedIn Economic Graph3 data comprised of over 400 million professional profiles is a unique dataset that provides a view of educational and career paths of individuals across the world at an unprecedented scale and granularity . Not only does this data allow us to rank universities with respect to the overall career outcomes of their graduates , the data also provides the necessary information for ranking universities with respect to career outcomes in specific professions such as Software Developers , Designers , Finance Professionals , etc . This is in stark contrast to rankings focused on academic areas of study . For example , US News engineering rankings , which are based solely on reputational peer assessments [ 4 ] , may not be as relevant to specific professional outcomes since according to [ 7 ] only an estimated 27 % of US college graduates end up working in roles related to their undergraduate majors .
There are certainly multiple facets to high quality education , with some researchers proposing multidimensional rankings for higher education [ 18 ] . Learning environment , teaching and research excellence , as well as financial returns on investment in education are important factors to consider when evaluating educational opportunities . Compared to university rankings based on the more traditional criteria discussed earlier in this section , the methodology presented in this work brings to light a complementary tool for informing educational decisions on the basis of career outcomes of university graduates . The resulting LinkedIn university rankings based on career outcomes are available to the general public4 . Next , we present the underlying methodology . Note that we use the terms ” profession ” and ” career ” interchangeably .
2See a link to a PDF at the bottom of the page at http://wwwcommondatasetorg/ 3https://wwwlinkedincom/company/linkedin economicgraph 4https://wwwlinkedincom/edu/
138 3 . METHODOLOGY 3.1 Overview
Our methodology for ranking universities based on career outcomes consists of two main components shown in Figure 1 . First , the most desirable companies for a given profession are identified by CompanyRanker based on employee transition dynamics reflected in LinkedIn member data . Universities are then ranked by SchoolRanker based on how successful their graduates are at landing jobs at the most desirable companies in the given profession . There is a number of methodological challenges such as representation bias and robustness to potential noise in the data that are addressed in order to produce statistically sound results . We discuss these in the following subsections where we present CompanyRanker and SchoolRanker in detail .
Figure 1 : Algorithm architecture overview
3.2 CompanyRanker : Determining companies desirable to a career
We define companies desirable for a profession as those which are the best at attracting and retaining talent in that profession . We let the career choices of hundreds of millions of LinkedIn members tell us how desirable it is to work at a company .
To illustrate this , imagine there are two companies , A and B . If more finance professionals are choosing to leave company A to work at company B , the data indicates that getting a finance job at B is more desirable . This is based on the hypothesis that when a professional moves from one company to another , she gives the company she moves to a strong vote of confidence .
Extending the hypothesis further , we posit that attracting employees from other desirable companies makes a company more desirable . Similarly , the ability of a company to retain its employees is a strong indicator of that employer ’s attractiveness . So , hypothetically , if A and B are both attracting external employees at similar rates , but A has much higher churn than B , A would be deemed to be less desirable than B .
The above model can be conveniently represented using a graph structure . Given a profession and a set of LinkedIn members with their career histories , we define a Talent Flow Graph ( TFG ) to be a directed graph whose nodes correspond to companies and edges are weighted by the numbers of employment transitions between companies . We restrict the set of eligible employment transitions to those taken by members in the profession of interest . For example , when ranking companies by desirability for software engineers ( SWEs ) , we limit the relevant population of members to those who held a SWE role . The corresponding TFG is then formed on
Figure 2 : An illustration of a Talent Flow Graph for a given profession . Nodes correspond to companies . Edges are weighted based on numbers of employees transitioning between companies . Variability in edge weights is depicted with different line widths . Weights on self loops are normalized by the median tenure in the profession . Self loops typically have higher weights than other edges leaving a node except in cases of significant lay offs or poor retention . the basis of companies these members have worked at while in SWE roles . Companies with very few professionals contributing to their edges are removed from the graph in order to reduce noise . In order to make company desirability estimates reflective of contemporary labor market conditions , only transitions during the past five years are considered . a company A in a TFG is defined as
We capture employee retention dynamics by introducing one self loop edge for each company in a TFG . Weights on self loop edges are normalized for median retention within the profession . This normalization allows us to effectively control for variations in tenure length across different professions . For a given profession P , the self loop weight for x∈RP ( A ) tP ( x , A ) , where RP ( A ) is the set of professionals with tenure at company A longer than median tenure for profession P , and tP ( x , A ) equals professional x ’s tenure at A divided by the median tenure for P .
A schematic illustration of a TFG is shown in Figure 2 . Once a TFG is constructed , company desirability scores are determined by applying PageRank [ 15 ] on this graph . Note that besides modeling employee transition dynamics more richly , factoring in retention helps mitigate company size reinforcement caused by the lack of inbound edge normalization in PageRank .
To see this , consider a hypothetical profession with one big company A , two medium sized companies B and C , and three small companies D , E and F . Figure 3 shows the corresponding TFG in the form of an employee transition probability matrix and in the absence of self loops . The transition probability matrix is obtained by representing the TFG by a weighted adjacency matrix with ( i , j) th element encoding the talent flow from company i to company j as discussed above , and with each row normalized to sum to one . For illustrative purposes , the individual probabilities are generated following the observation that bigger companies , besides having more open positions available , have
139 higher brand awareness and generally attract more job applications from aspirants . ( Some small companies are acquired by large ones as well . ) In row 2 of the transition probability matrix for example , we see that A has higher than three times the rate of attracting talent when compared to small companies ( D , E and F ) 0.4 as opposed to 0.13 and about two times the rate when compared to medium sized companies ( B and C ) 0.4 as opposed to ˜02
The computed page rank scores show that company A scores highest with 0.297 while the medium sized and small companies score 0.165 and 0.124 respectively .
Figure 3 : Transition probability matrix representing a Talent Flow Graph without retention ( self loop edges ) , for a hypothetical profession . Sizes and colors of the circles encode company sizes from large ( A ) to medium ( B , C ) , and small ( D , E , F ) . Bottom row shows the corresponding PageRank score for each company from A ( left ) through F ( right ) .
Now , what if the large company A was experiencing a high employee churn of , say , 20 % a year as compared to 5 % for the other companies ? This would indicate that A may not be such a desirable company to work at and we would like our methodology to reflect this . After representing retention in the form of self loops , the transition probability matrix and the resulting PageRank scores are shown in Figure 4 . With retention factored in , company A now comes in last wrt desirability with a score of 0.13 while the mediumsized companies score the highest with 0.184 due to stronger employee retention . The score for small companies is 0167 Note that since we construct different TFGs for different professions , given two companies A and B and professions P1 and P2 , it is possible for company A to score better than B for desirability for profession P1 and score worse than B for profession P2 .
In order to account for varying labor market dynamics and professional preferences across countries and educational degree levels ( eg , Bachelors , Masters , etc. ) , we construct a separate TFG for each ( profession , country , degree level ) combination . For example , the list of desirable companies for software engineers who studied in the UK will likely differ from the one for those who attended academic programs in the US . Also , the top companies for graduates of Bachelor ’s programs might differ from those for MBA graduates .
Figure 4 : Transition probability matrix with retention factored in for the hypothetical profession example . Bottom row shows the corresponding PageRank score for each company from A ( left ) through F ( right ) .
3.3 SchoolRanker : Ranking universities based on career outcomes
The foundational assumption underlying our approach to university rankings is that obtaining employment at some of the most desirable companies for a given profession indicates a favorable career outcome for a university graduate . We therefore derive a university success score based on the proportion of graduates who obtained employment in a given profession at some of the most desirable companies for that profession . However , not all graduates may be interested in pursuing the same profession . Hence , when computing a success score for a university with respect to a profession , we only consider the subpopulation of graduates who went on to obtain a position in that profession . For example , for the profession of software engineering , we consider every graduate who went on to hold a software engineering role at any company post graduation .
Note that since some university graduates may not be members of LinkedIn professional network , there may be a representation bias in the data . We correct for potential representation bias using the method of post stratification weighting [ 17 ] . In particular , we apply externally reported university graduation data , such as published by the US Department of Education5 , to adjust the sufficient statistics for university success scores by stratifying on gender , graduation year , degree level and university . Let X denote the domain of a categorical variable encoding all possible combinations of values of the attributes used for post stratification weighting . For a given university , let p(x ) denote the proportion of graduates who have the particular combination of attributes represented by x ∈ X , according to data on LinkedIn . Let q(x ) denote an externally reported proportion of graduates from the same university and with the same combination of attributes x . Then , the total bias corrected number of graduates from this university and relevant to the profession is x∈X r = m(x)w(x ) ,
5https://ncesedgov/ipeds/datacenter/
140 where m(x ) denotes the number of the university ’s graduates with attributes x on LinkedIn who entered the profession at any of the relevant companies , and w(x ) = q(x)/p(x ) is the corresponding post stratification weight . Similarly , the biascorrected number of graduates who obtained employment at any of the top companies is x∈X s = n(x)w(x ) ,
( 1 ) where n(x ) ≤ m(x),∀x ∈ X , denotes the size of the subset of the university ’s graduates with attributes x on LinkedIn who obtained employment at some of the top ( ie , most desirable ) companies for the profession .
Finally , we define the university success score to be the lower end of the 95 % Binomial confidence interval around the bias corrected ratio
θ = s r
( 2 ) of graduates who obtained employment at top companies out of all graduates who entered the profession from the university . The lower end of the confidence interval is used in order to stabilize the ranking statistic wrt limited sample sizes and ground it in sustained trends in career outcomes of university graduates . Note that given the scale of LinkedIn ’s professional member base of over 400 million members and because we consider all graduates from the last eight years when ranking universities , sample sizes for most universities ranked are large enough for the lower ends of the confidence intervals to be close to the point estimates in Eqn . 2 .
The lists of top ( ie , most desirable ) companies are based on the career wise desirability scores provided by the CompanyRanker . University success score computation by virtue of Eqn . 1 , however , requires another parameter to be specified the number of companies to be considered most desirable out of all companies ranked by CompanyRanker for the profession . We discuss the selection of the number of top companies later in this section . For now , let us assume that this number has been given , and consider the following . The representation bias alluded to earlier may also affect company desirability estimation . Unfortunately , at the present time there is no comprehensive publicly available company data that would allow to correct for possible representation bias during company desirability estimation . Reporting errors in LinkedIn member data may also affect the results . In order to make our methodology robust to potential inaccuracies in member data and company desirability estimates , we ( a ) only use data from member profiles that have successfully passed stringent spam detection checks , and ( b ) develop a Monte Carlo resampling technique discussed next . Given a ranking of companies by desirability and the number K of most desirable companies to be used for computing university success scores , a large number ( thousands ) of perturbed sets of most desirable companies are generated by repeatedly substituting a randomly chosen subset ( eg , 5 10 % ) of companies from the original set of K most desirable ones with the same number of companies selected from outside that set ( ie , from those companies which didn’t make it into the top K by desirability ) . Companies from outside the most desirable set are sampled with probabilities proportional to their estimated desirability , so the more desirable companies have a higher chance of being placed into a perturbed set .
For each perturbed set of most desirable companies , university success scores are computed and the universities are ranked based on those scores . Thus , for each university , this procedure results in a distribution over ranks the university attained across perturbed sets of most desirable companies . The 95th percentile rank from this distribution is then taken as the ranking statistic for the university . If two or more universities attain the same 95th percentile rank , the 75th percentile rank is used to resolve the tie . Universities that tie on both 95th and 75th percentile ranks are declared tied and are assigned the same final rank . As a result , universities with larger proportions of graduates obtaining jobs in the more desirable companies for a given profession , rank higher . At the same time , rankings of universities are made robust to potential noise in company desirability estimates . What remains to discuss is the determination of the number K of most desirable companies to use for ranking universities .
Selection of the number of desirable companies : As we vary the number K of the most desirable companies , the resulting university rankings may change . The degree of sensitivity of university rankings to the choice of K is a function of the distributions of university graduates across companies for a given profession . Figure 5 shows an example of the cumulative distributions of graduates from five universities over companies ranked by desirability .
Figure 5 : Cumulative distributions of numbers of graduates from five universities across companies ordered by desirability . Large steps in the curves indicate cases where a school feeds strongly into a single company . For example , school plotted in red would rank 4th among presented schools if top 10 companies are chosen and would rank 1st if top 25 companies are chosen .
The jumps in the distributions in Figure 5 indicate that there are cases where a school “ feeds ” strongly to a single company . Hence , the selection of K is important in determining the final university rankings . We would like to choose a K around which the changes in university ranks due to “ single company effects ” are minimized and the rankings are more stable . This is achieved by a grid search over a set of values of K . For each K , we quantify and measure the average pairwise agreement between all pairs of school rankings produced as a result of Monte Carlo resampling of
141 company rankings described above . The agreement between a pair of school rankings is defined as a weighted average of sizes of set intersections between the top N schools in the two rankings and normalized by N , for N=3 , 5 , 10 and 25 . The value of K corresponding to the highest average pairwise agreement is then chosen for defining the set of most desirable companies .
Figure 6 : Average pairwise agreement between university rankings across perturbed sets of most desirable companies , as a function of the number of most desirable companies used for determining university success scores .
Figure 6 shows an example of the average pairwise agreement as a function of the number of most desirable companies . In this example , average pairwise agreement is maximized at fifty most desirable companies . In other words , moderate perturbations to the set of most desirable companies affect the resulting university rankings the least at K=50 compared to other values of K . Therefore , in this example , K=50 most desirable companies would subsequently be used for ranking universities .
4 . RESULTS AND OBSERVATIONS
Below , we present some of the results obtained by applying our methodology . We discuss company desirability and university rankings for two professions in the US : the Investment Bankers and Software Developers at Startups . For illustrative purposes , Table 1 shows an alphabetically ordered list of the 20 most desirable companies generated by CompanyRanker for Investment Bankers .
It is worth noting that these companies are indeed wellrecognized leaders in the investment banking industry . Additionally , we present an alphabetically ordered list of top startups for Software Developers , as of September 2014 , in Table 2 . Only non public companies with less than 5,000 employees and less than 10 years in age are considered for this category . Similar to the list of most desirable companies for the Investment Bankers category , the list of top startups is comprised of highly regarded private companies . Note that the above lists of most desirable companies have been identified automatically by our methodology based on the transitions of employees across companies . This further highlights the great potential of LinkedIn ’s Economic Graph that can be realized through applications of data analytic approaches .
Table 1 : Top 20 companies for Investment Bankers ( in alphabetical order ) .
Company American Express Bank of America Citi Credit Suisse AG Deutsche Bank Goldman Sachs Jefferies JPMorgan Chase & Co KPMG Morgan Stanley New York Life Insurance Company Nomura Piper Jaffray Raymond James Financial , Inc . RBC Capital Markets TIAA CREF UBS AG USAA Wells Fargo William Blair
Table 2 : Top 20 startups for Software Developers ( in alphabetical order )
Type Hospitality Payments Education Operating Systems Database Systems Healthcare Cloud Storage Fitness
Company Airbnb Braintree Clever CoreOS Couchbase Counsyl Dropbox Fitbit Flatiron Health Healthcare Github Lyft Oscar Health PlanGrid PlanSource Riot Games Sovrn Holdings Online Advertising Square Tapad Uber Zen Payroll
Software Development Tools Transportation and Delivery Healthcare Industrial Design Software HR Management Systems Entertainment
Payments Online Advertising Transportation and Delivery Payroll Management
University rankings obtained by the SchoolRanker for Investment Bankers and Software Developers at Startups are shown in Tables 3 and 4 , resp . As was mentioned in the Methodology section , universities are ranked on the basis of their 95th percentile ranks across perturbed company sets . Ties on the 95th percentile ranks are resolved using the 75th percentile ranks . This can be seen in Table 3 , where Columbia University and Duke University both have equal 95th and 75th percentile ranks and are thus considered a tie , both ranking fourth for Investment Bankers . In contrast ,
142 Table 3 : Top ranking undergraduate programs for Investment Bankers
School Georgetown University University of Pennsylvania Yale University Columbia University in the City of New York Duke University Princeton University New York University Wellesley College Cornell University Dartmouth College
75th Percentile 1 3 4 7 7 9 11 4 10 10
95th Percentile Final Rank 1 2 3 4 4 6 7 8 9 10
2 4 7 9 9 11 11 12 12 13
Table 4 : Top ranking undergraduate programs for Software Developers at Startups
School Stanford University Massachusetts Institute of Technology University of California , Berkeley Carnegie Mellon University Brown University Cornell University The University of Texas at Austin Rochester Institute of Technology University of Illinois at Urbana Champaign University of Maryland College Park
75th Percentile 1 2 3 4 6 6 13 14 15 7
95th Percentile Final Rank 1 2 3 4 5 6 7 8 9 10
1 2 4 5 7 10 15 18 18 19
Table 4 shows Rochester Institute of Technology ( RIT ) and University of Illinois at Urbana Champaign ( UIUC ) achieving the same 95th percentile rank , but different 75th percentile ranks . As a result , RIT ’s final ranking comes out one step above UIUC ’s for Software Developers at Startups . The top universities for Investment Bankers have larger numbers of graduates joining some of the top investment institutions such as Goldman Sachs , JPMorgan Chase & Co and Morgan Stanley . Similarly , for Software Developers at Startups , larger numbers of graduates are helping build some of the top startups such as Airbnb , Dropbox , Uber and others . The complete set of university rankings together with insights about each university and career paths of their graduates can be found via LinkedIn University Rankings , University Finder , and Field of Study Explorer products , which are all part of LinkedIn ’s suite of educational decision making products6 .
LinkedIn university rankings developed using the methodology presented here based on career outcomes of professionals around the world were first made publicly available in October of 2014 for undergraduate programs with a subsequent expansion into graduate ( Masters ) programs in March of 2015 . The published rankings cover nine professions and three countries United States , United Kingdom and Canada . The results were viewed by millions of unique users in the first week alone and received broad media coverage including The New York Times , The Wall Street Journal , Inside HigherEd and numerous other publishers .
5 . CONCLUSION
We have presented a novel methodology for ranking the world ’s educational institutions on the basis of career out6https://wwwlinkedincom/edu/ comes of their graduates . By leveraging LinkedIn ’s Economic Graph data on career paths of hundreds of millions of professionals around the world , we are able to rank universities with respect to individual professions something that the leading ranking agencies such as US News and Times Higher Education are unable to achieve at a comparable scale and granularity . In contrast , these ranking agencies often fall back on reputational assessments instead of directly measuring career outcomes . Our methodology addresses some of the key limitations of the existing approaches such as their heavy reliance on reputational assessments and scarcity of statistical robustness mechanisms , which make the resulting rankings difficult to interpret .
We believe that the methodology we have developed reflects more accurately the impact that universities have on industries and their graduates’ careers . Using global career data as a ground truth for assessing career outcomes makes the resulting university rankings more interpretable and , eventually , more actionable for schools and students alike . Schools can use these rankings as a tool to fine tune their educational and career development programs while prospective students can choose universities based on professions that excite them . In addition , current students can use the tool in combination with the Alumni Explorer7 on LinkedIn to connect with alumni and inform the students’ career choices and job search .
Even though our methodology improves on the university ranking methodologies used in the industry , the methodology could be enhanced further by incorporating more granular data on job transitions . For example , when considering the flow of employees between companies when ranking companies by desirability , it is sometimes important to know
7https://wwwlinkedincom/edu/alumni
143 the circumstances around which the employee leaves an employer . While highly desirable companies have highly competitive hiring processes , in some cases such companies also have stringent employee reevaluation processes . Factoring in information on job application and acceptance rates and reasons for employees’ departures would increase the precision of company desirability estimates . Such data would also help further guide selection of subpopulations of graduates interested in a profession when ranking universities . In addition , comprehensive salary data would be a great way to enrich our definition of career outcomes . Finally , additional data from industry experts may help enrich the definition of career outcomes and increase precision of the rankings when coupled with appropriate data analytic methods such as semi supervised versions of PageRank .
There are multiple facets to high quality education . Learning environment , teaching and research excellence , as well as financial returns on investment in education are important factors to consider when evaluating educational opportunities . The methodology presented in this work brings to light a complementary tool for informing educational decisions on the basis of career outcomes of university graduates .
6 . REFERENCES [ 1 ] QS World University Rankings : Methodology . QS ,
2015 .
[ 2 ] World University Rankings 2015 2016 methodology .
Times Higher Education , 2015 .
[ 3 ] Best Undergraduate Business Programs Methodology .
US News & World Report , 2016 .
[ 4 ] Best Undergraduate Engineering Programs
Methodology . US News & World Report , 2016 .
[ 5 ] How US News Calculated the 2016 Best Colleges
Rankings . US News & World Report , 2016 .
[ 6 ] Methodology : 2016 Best Business Schools Rankings .
US News & World Report , 2016 .
[ 7 ] J . R . Abel and R . Deitz . Agglomeration and job matching among college graduates . Staff Report 587 , Federal Reserve Bank of New York , December 2012 .
[ 8 ] M . N . Bastedo and N . A . Bowman . The US News and World Report college rankings : Modeling institutional effects on organizational reputation . American Journal of Education , ( 116):163–184 , 2010 .
[ 9 ] N . A . Bowman and M . N . Bastedo . Getting on the front page : Organizational reputation , status signals , and the impact of us news and world report on student decisions . Research in Higher Education , 50(5):415–436 , 2009 .
[ 10 ] N . A . Bowman and M . N . Bastedo . Anchoring effects in world university rankings : exploring biases in reputation scores . Higher Education , 61(4):431–444 , 2010 .
[ 11 ] R . Brooks . Measuring university quality . The Review of Higher Education , 29(1 ) , Fall 2005 .
[ 12 ] C . Claassen . Measuring university quality .
Scientometrics , 104(3):793–807 , September 2015 .
[ 13 ] A . Griffith and K . Rask . The influence of the US News and World Report collegiate rankings on the matriculation decision of high ability students : 1995 2004 . Economics of Education Review , ( 26):244–255 , 2007 .
[ 14 ] S . Lee . Reputation without rigor . https://wwwinsidehigheredcom/news/2009/08/19/rankings , September 2009 .
[ 15 ] L . Page , S . Brin , R . Motwani , and T . Winograd . The pagerank citation ranking : Bringing order to the web . Technical Report 1999 66 , Stanford InfoLab , November 1999 . Previous number = SIDL WP 1999 0120 .
[ 16 ] J . H . Pryor , K . Eagan , L . Palucki Blake , S . Hurtado , J . Berdan , and M . H . Case . The American freshman : National norms fall 2012 . Higher Education Research Institute , UCLA , January 2013 .
[ 17 ] R . Valliant and J . A . Dever . Estimating propensity adjustments for volunteer web surveys . Sociological Methods & Research , 40(1):105–137 , 2011 .
[ 18 ] F . A . van Vught and F . Ziegele , editors .
Multidimensional Ranking : The Design and Development of U Multirank , volume 37 of Higher Education Dynamics . Springer Netherlands , 2012 . [ 19 ] L . Waltman , C . Calero Medina , J . Kosten , E . C .
Noyons , R . J . Tijssen , N . J . van Eck , T . N . van Leeuwen , A . F . van Raan , M . S . Visser , and P . Wouters . The leiden ranking 2011/2012 : Data collection , indicators , and interpretation . J . Am . Soc . Inf . Sci . Technol . , 63(12):2419–2432 , Dec . 2012 .
144
