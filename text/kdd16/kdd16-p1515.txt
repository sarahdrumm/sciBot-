Efficient Processing of Network Proximity Queries via Chebyshev Acceleration
Mustafa Co¸skun
Department of Electrical
Engineering and Computer Science
Case Western Reserve
University
Cleveland , OH 44106 , USA . mustafacoskun@caseedu
Ananth Grama Department of
Computer Science Purdue University
West Lafayette , IN 47906 , ayg@cspurdueedu
USA .
Mehmet Koyutürk Department of Electrical
Engineering and Computer Science
Case Western Reserve
University
Cleveland , OH 44106 , USA . mehmetkoyuturk@caseedu
ABSTRACT Network proximity is at the heart of a large class of network analytics and information retrieval techniques , including node/ edge rankings , network alignment , and randomwalk based proximity queries , among many others . Owing to its importance , significant effort has been devoted to accelerating iterative processes underlying network proximity computations . These techniques rely on numerical properties of power iterations , as well as structural properties of the networks to reduce the runtime of iterative algorithms . In this paper , we present an alternate approach to acceleration of network proximity queries using Chebyshev polynomials . We show that our approach , called Chopper , yields asymptotically faster convergence in theory , and significantly reduced convergence times in practice . We also show that other existing acceleration techniques can be used in conjunction with Chopper to further reduce runtime . Using a number of large real world networks , and top k proximity queries as the benchmark problem , we show that Chopper outperforms existing methods for wide ranges of parameter values . Chopper is implemented in Matlab and is freely available at http://compbiocaseedu/chopper/
Keywords Network proximity , Random walk with restarts , Chebyshev polynomials
1 .
INTRODUCTION
Proximity measures on networks are at the core of a large number of analytics and information retrieval techniques . In information retrieval , nodes/ edges are ranked based on their random walk distance from other nodes [ 18,25 ] . In network alignment , high scoring node alignments ( node pairs – one drawn from each network ) can be identified by their random walk distance from other high scoring alignments in the product graph of the two input networks [ 10 ] . In diseasegene prioritization , genes are ranked according to their network proximity to genes that are previously identified as associated with clinically similar diseases [ 13 ] .
The general setting for network proximity queries is as follows : For a given query node , we are interested in computing a score for each node that indicates the proximity of that node to the query node . For example , shortest path queries ask for the minimum number of hops ( or minimum total weight of edges ) connecting two nodes . Random walk based proximity measures , on the other hand , simulate random walks that make frequent restarts on the query node , and estimate proximity to the query node in terms of the probability of being at each node at steady state . In top k proximity queries , the k closest nodes to a specified source node are returned .
In many applications , random walk based proximity is preferred over shortest path distance because of its robustness to the inherent noise in the network . This noise may be due to inaccuracies in modeling ( not all interactions in the underlying system are modeled in the graph ) or noise in data ( missing or spurious edges ) . In such cases , random walk based proximity measures provide a more robust estimate of network proximity .
Random walk based proximity measures have been used in a wide variety of applications , including web search [ 14 ] , link prediction [ 6 , 11 ] , clustering [ 2 ] , disease gene prioritization [ 7 , 13 ] , and integration of disparate “ omic ” data in systems biology [ 9 ] . Some of the well known random walk based proximity measures include discounted hitting time [ 17 ] , personalized hitting probability [ 24 ] , network propagation [ 20 ] , diffusion state distance [ 5 ] , and random walk with restarts ( RWR ) [ 1 , 19 ] .
Motivated by widespread use of random walk proximity , significant effort has been devoted to reducing operation counts associated with computation of proximity . These efforts exploit numerical and structural characteristics of the problem to reduce operation counts . For instance , in the context of the top k proximity queries , during the iterative procedure , if it can be guaranteed that some nodes cannot enter into the top k set any further , the associated computations can be eliminated [ 23 ] . Likewise , owing to the structure of the network , the proximity of each node to the query node can be bounded systematically by considering nodes in a breadth first like order [ 21 ] . These techniques have been
1515 Table 1 : Notation used in the description of methods .
Meaning
Symbols G = ( V , E , w ) Undirected weighted graph G with node set V , edge setE , and weight function w P α W q ∗ x q rq y(t ) q e(t ) πt Pt Tt pt μ ρ(W ) σ(W )
Stochastic matrix derived from the adjacency matrix of G Restart probability ( damping factor ) Transpose of Stochastic matrix adjusted by the damping factor as W = ( 1 − α)P The query node Vector of proximities to q computed by random walk with restarts Restart vector used to compute proximity to q Linear combination of xq Residual between y(t ) Polynomial of order t Family of polynomials of order t Chebyshev polynomial of first kind Polynomial that minimizes the norm of residual for iterative computation of random walk with restart Variable that characterizes the convergence rate of Chebyshev acceleration Largest eigenvalue of matrix W All eigenvalues of matrix W
( t ) used for Chebyshev iterations
∗ q and x q demonstrated to yield significant improvement in runtime in the context of diverse applications .
In this paper , we take an alternate approach , based on accelerating the convergence of the underlying iterative process . To achieve this , we adapt a result from classical linear algebra , based on Chebyshev polynomials . Traditional iterative procedures use the result from one iteration to compute the next iterate . The iterations are terminated when convergence is detected , ie , when the proximity vector does not change significantly between two iterations . We can , however , define the next iterate as a linear combination of a predefined set of previous iterates . The coefficients of this linear combination can be optimally computed using Chebyshev polynomials . We demonstrate this process and show that the resulting the iterate converges much faster than the iterate in the original formulation . This results in significant speed up in the computation of random walk based proximity scores . Furthermore , we show that our method can be combined with existing methods to further improve the processing of top k proximity queries .
We provide detailed theoretical justification for our results , and experimentally demonstrate the superior performance of our method on a number of real world benchmark problems . Specifically , we show that ( i ) our method yields significant performance improvements over state of the art methods ( reducing the number of iterations required to compute network proximity to all nodes many fold on networks with hundreds of thousands of edges ) ; and ( ii ) for top K proximity queries , our method yields two fold improvement in runtime on graphs with millions of nodes and edges . The asymptotic acceleration of our scheme implies that this performance improvement increases as problem sizes are scaled up .
The rest of the paper is organized as follows : in the next section , we provide an overview of the literature on efficient computation of network proximity . In Section 3 , we describe the terminology , establish background on random walk proximity and top k proximity queries , and describe our method . In Section 4 , we provide detailed experimental evaluation of our method . We draw conclusions and summarize avenues for further research in Section 5 .
2 . RELATED WORK
Network proximity querying has received significant attention over the past years . In particular , top k proximity queries in networks involve identifying the k nodes that are in close ( random walk ) proximity to a query node ( or a set of query nodes ) . One of the basic approaches to computing random walk based proximity is the power iteration [ 16 ] . An alternate approach to power iterations is offline computation through LU decomposition and storing the factors for proximity estimation during online query processng [ 8 , 19 , 22 ] . However , LU decomposition is expensive and usually not feasible for very large networks . Furthermore , since the underlying networks are often dynamic , even small perturbations to the network require repetition of this costly procedure .
Recently , a number of approaches have been proposed to scale top k proximity queries to very large and sparse networks . These methods take advantage of the numerical properties of the iterative methods to bound the proximity of nodes in the network in early iterations , thereby stopping the computation early when only k contenders are left [ 23 ] . Other methods utilize the structure of the network to perform a local search around the query node(s ) , based on the notion that nodes with high random walk based proximity to the query node are also in close neighborhood of the query node in terms of the number of hops [ 3 , 4 , 12 , 24 ] . However , most of these local search based methods are approximate , in the sense that they do not provide guarantees for identifying the exact set of of k nodes that are most proximate to the query node . Recently , two local search based methods , FLoS [ 21 ] and Ripple [ 23 ] have been shown to enable exact computation of top k proximity queries without compromising efficiency .
In this paper , we also focus on exact computation of network proximity . Our method is fundamentally different from existing approaches in that it exploits the numerical properties of the iterative procedure to speed up its computation . This method can be used to efficiently compute the random walk with restarts based proximity of all nodes in the network to a given node , or to speed up the processing of top k proximity queries .
1516 3 . METHODS
In this section , we first define random walk with restarts ( RWR ) and and top K network proximity queries based on RWR . We then present insights from numerical linear algebra to motivate the use of polynomials for accelerating convergence of iterative procedures used to compute RWR based proximity . Subsequently , we show that Chebyshev polynomials can be used to optimize the convergence of iterative computation of RWR , and bound the relative error in each iteration . Finally , we discuss how these bounds can be used to efficiently process top K network proximity queries . We conclude this section by showing that our method generalizes to any proximity measure that can be iteratively computed , for which error in each iteration is bounded . 3.1 RWR Based Proximity
Let G = ( V , E , w ) represent a given network , directed or undirected , where V denotes the set of nodes , E denotes the set of edges , and w : E → R denotes the weight function assigned to the edges . Given a node q ∈ V , the random walk with restart based proximity to q is defined as follows : q = ( 1 − α)Px ∗ ∗ q + αrq . x
( 1 )
Here , P denotes the column normalized stochastic matrix derived from the adjacency matrix of G by dividing each entry by the corresponding column sum , rq denotes the restart vector that contains a 1 at its qth entry and a 0 in all other entries , and 0 < α < 1 denotes the damping factor . This parameter determines the probability of restarting at q in a random walk of the network . Defined this way , xq(u ) represents the probability of being at node u at a random step of a sufficiently long random walk that starts at q and either moves to an adjacent node ( with probability 1 − α ) or restarts at node q ( with probability α ) at each step .
While we focus on random walk with restarts here for clarity of discussion , the method described in this paper directly applies to any proximity measure that can be written in the form x = Ax + c , where A is a matrix with largest eigenvalue ρ(A ) < 1 and c is constant vector . Such proximity measures include penalized hitting probability [ 24 ] , effective importance [ 4 ] , and discounted hitting time [ 17 ] .
In practice , xq is computed iteratively , by setting xq
0 and performing the following computation : ( t ) + αrq
( t+1 ) = ( 1 − α)Pxq xq
( 0 ) =
( 2 )
( t+1 ) − xq in the tth iteration . This iterative procedure terminates when ||xq ( t)||2 is below a prescribed threshold , implying convergence . As we discuss below , the residual in this iterative procedure is proportional to the tth power of the largest eigenvalue of the matrix ( 1 − α)P . Therefore the iterative procedure is guaranteed to converge since the largest eigenvalue of P is equal to 1 and ( 1 − α ) < 1 . Throughout this paper , we refer to this procedure as the standard power iteration . 3.2 Top k Proximity Queries Given undirected network G = ( V , E , w ) , a query node q ∈ V , and a positive number k , the top k proximity query for RWR proximity returns the k nodes in V correspond∗ ing to the largest values in x q [ 23 ] . Note that the largest values correspond to the highest proximity ( smallest RWR distance ) . The current state of the art in efficiently processing top k proximity queries is based on two approaches .
The first approach uses the bound on the residual in the ∗ iterative computation of x q to eliminate nodes whose proximity values cannot exceed that of the notes that are already among the k . This process terminates when all but the top k nodes are eliminated . This approach improves efficiency by reducing the number of iterations , and is implemented by the Squeeze algorithm developed by Zhang et al . [ 23 ] . The second approach uses network structure , in combination with the residual , to bound the proximity of each node to the query node and avoids computing proximity scores for nodes that are sufficiently distant from the query node in terms of the number of hops . This approach improves efficiency by further reducing the number iterations , as well as the number of operations in each iteration . It was proposed by Wu et al . [ 21 ] and is also implemented in the Ripple algorithm developed by Zhang et al . [ 23 ] .
All of these methods are based on the standard power iterations , ie , the computation of the current vector iterate only uses its value from the previous iteration . Here , we show that the convergence rate of the iterative procedure can be significantly improved by utilizing the information gathered from all previous iterations . Specifically , we use Chebyshev polynomials to aggregate the values of xq across iterations , obtaining a better approximation to the steady state vector in each iteration . This results in faster convergence , which in turn also yields more effective pruning of nodes . The number of iterations required for such a procedure to process top k proximity queries is consequently much lower .
3.3 The Chopper Algorithm
The core idea behind the proposed Chebyshev Polynomial Based Efficient Proximity Retrieval ( Chopper ) algorithm ( t ) vectors in Equais to utilize the previously computed xq ∗ tion ( 2 ) to obtain a better approximation to x q in the next iteration . To describe this idea , for a given query node q , we first define W = ( 1− α)P and rewrite the ( 2 ) as follows :
( t+1 ) = Wxq
( t ) + αrq . xq
( 3 ) Observe that , since P is a stochastic matrix , we have |ρ(W)| ≤ ( 1 − α ) < 1 , hence the iterative procedure described by ( 3 ) ∗ converges to the solution of ( 1 ) , x q .
The idea behind Chebyshev acceleration is as follows : For the tth iteration of the iterative procedure , and a given series γt(m ) for 0 ≤ m ≤ t , we define vector y(t ) q : y(t ) q = t . m=0
γt(m)xq
( m )
( 4 )
Our objective is to choose a sequence γt such that the sequence y(t ) ( t ) , and as rapidly q ∗ as possible . Observe that , if we use y(t ) to approximate x q , q the residual in the tth iteration is given by :
∗ q faster than xq converges to x e(t ) = y(t ) q − x ∗ q .
( 5 ) Thus , for each t , the chosen γt should minimize ||e(t)||2 , m=0 γt(m ) = 1 . This constraint subject to the constraint : ensures that the linear combination also converges to x fit
∗ q .
We can reformulate the residual at the tth iteration as a
1517 As stated in the following theorem , the solution to minimax optimization problems of the form of ( 9 ) is provided by the well known Chebyshev polynomial of first kind , given by the following recurrence : T0(z ) = 1 , T1(z ) =z , T t+1(z ) = 2zTt(z ) − Tt−1(z ) .
Theorem 1 . Let [ a , b ] ⊆ R be non empty interval and ξ be a real number such that a < b < ξ . Then , argmin pt∈Pt,pt(ξ)=1
F ( pt ) =
Tt(1 + 2
Tt(1 + 2
= πt(λ )
λ − b b − a ) ξ − b b − a ) μt
1 +μ 2t ff
− ζt−1 ζt+1 y(t−1 ) q and F ( πt ) = where κ =
1
ξ − a b − a ) Tt(1 + 2 ξ − a ξ − b and μ =
= 2 √ κ − 1 √ κ + 1
.
Algorithm 1 : The Chopper Algorithm Input : G = ( V , E ) , q , k , α , andr q Output : a set R ⊆ V that contains the top K most proximate nodes to q
1 Construct matrix W q ← 0 2 R ← V , t ← 1,y(0 ) q ← Axq √ 3 y(1 ) ( 0 ) + αrq 4 κ ← 2 − α κ − 1 √ α , μ ← κ + 1 5 ζ0 ← 1 , ζ1 ← 1 1 − α 6 while |R| > k do ζt+1 ← 2 1 − α 7 q ← y(t+1 ) ( 1 − α)ζt+1 τ ←k−th largest score in y(t+1 ) foreach u ∈ R do
ζt − ζt−1 ' 2ζt
Wy(t )
8 q q + αrq
( u ) ; if ( y(t+1 )
( u ) + 4μt ) < τ then q Remove u from R ; end
9 10 11 12 13 14 15 end end polynomial as follows :
Detailed proof of this theorem can be found in [ 16 ] . We can immediately apply this result to our problem . From the construction of W , we know that ρ(W ) = 1 − α , where ρ( . ) denotes the largest eigenvalue of a matrix . Then , letting a = α − 1 , b = 1 − α , and ξ = 1 , we have pt(λ ) =
Tt(
Tt(
λ 1 − α ) 1 1 − α )
( 10 )
( 11 ) q − x ∗ e(t ) = y(t ) q t .
γt(m)(xq
( m ) − x ∗ q )
=
= m=0 t .
γt(m)Wm(xq
( 0 ) − x ∗ q )
( 6 )
Therefore , using Theorem 1 and ( 6 ) , we obtain ||e(t)|| ||e(0)|| ≤ ||pt(W)|| ≤ ρ(pt(W ) ) = max λ∈σ(W ) ≤ 2μt
|pt(λ)| = 2
μt
|pt(λ)|
1 +μ 2t m=0
= pt(W)e(0 ) . where κ =
≤ max λ∈[a,b ] 2 − α α √ √ and κ − 1 κ + 1
μ =
This observation suggests that , if we can find a sequence of polynomials pt such that ( pt(W)( ) ( Wt( , the error in each iteration is much smaller than that in the standard power iteration . 331 Chebyshev Polynomials It is an established result in linear algebra that for any matrix W and polynomial pt , we can write σ(pt(W ) ) = pt(σ(W) ) , where σ( . ) denotes the set of eigenvalues of the matrix [ 15 ] . Therefore , as described by Saad [ 15 ] , ||e(t)|| can be minimized by solving the following minimization problem : min pt∈Pt,pt(1)=1 max
λ∈σ(W )
|pt(λ)|
( 7 )
Here , Pt denotes the family of all polynomials of order t .
Clearly , computing the eigenvalues of W would defeat our purpose , since this computation is at least as expensive as solving ( 1 ) . However , since P is column normalized , we know that ( W( ≤ρ( W ) ≤ ( 1 − α ) [ 23 ] . Hence , we can relax ( 7 ) , and rewrite it as : min pt∈Pt,pt(λ)=1
F ( pt ) where
F ( pt ) = max
λ∈[−1+α,1−α ]
|pt(λ)| .
( 8 )
( 9 )
2(1 − α ) √
2α − α2
2 +
=
< ( 1 − α ) .
( 12 )
This result demonstrates the power of Chebyshev polynomials in accelerating the computation of random walk with restart based proximity scores . Specifically , for standard power iteration , we have q( q − x ∗ q − x q( ∗
≤ ( Wt( ≤ρ t = ( 1 − α)t .
( x(t ) ( x(0 )
( 13 )
In contrast , if we use Chebyshev acceleration , we have
( y(t ) ( y(0 ) q( q − x ∗ q − x q( ∗
≤ ( pt(W)( = ρ(pt(W ) ) ≤ 2μt .
( 14 )
Since μ <1 − α , the sequence y(t ) than x(t ) to x
∗ q . q q converges much faster
Implementation of Chebyshev Acceleration
332 fit We now describe an efficient technique for computing y(t ) q = m=0 γmxq suggests that its computation requires the addition of t vectors in the tth itera(t ) vectors computed tion , and that we need to store all xq throughout the power iteration . However , exploiting the
( m ) . The definition of y(t ) q
1518 Table 2 : Network data sets used in the experiments
Network
Enron E mail
Brightkite
Number of Nodes Number of Edges
Average Node Degree
36,692 183,831
10.02
58,228 214,078
7.35
Gowalla 196,591 950,327
9.67
Skitter 1,696,415 11,095,298
13.08 observation that Chebyshev polynomials are defined as a recurrence , we can show that y(t+1 ) can be computed from y(t−1 ) and y(t ) q . q q For this purpose , let ζt = Tt(
1 1 − α ) . Observing that ζt − ζt−1 and by the definition of pt , it sat
2 1 − α
ζt+1 = isfies three term recurrence . Therefore , we can write ζtWpt(W ) − ζt−1pt−1(W ) .
ζt+1pt+1(W ) =
2
( 15 )
( 1 − α )
Finally , we can use above last equation and basic algebraic manipulations to obtain [ 16 ] : y(t+1 ) q
2ζt
∗ q + e(t+1 ) = x ∗ q + pt+1(W)e(0 ) = x ∗ ( 1 − α)ζt+1 = x q + − ζt−1 pt−1(W)e(0 ) ζt+1 ( 1 − α)ζt+1
2ζt
'
=
Wpt(W)e(0 )
( 16 ) ff
Wy(t ) q + αrq
− ζt−1 ζt+1 q
. y(t−1 ) q and y(t−1 ) q q
, from y(t )
In other words , we can compute y(t+1 ) without requiring storage of the previous iterates . 333 Processing Top k Proximity Queries While Chebyshev acceleration can be used to efficiently compute the proximity of all nodes in V to a query node q , it often suffices to identify the k nodes that are most proximate to q , where k ) |V| . As discussed above , existing algorithms for efficiently processing top k proximity queries use the convergence properties of power iteration and the topology of the network to quickly identify nodes that are not sufficiently proximate to k , so that such nodes can be pruned out [ 21 , 23 ] . In Squeeze , Zhang et al . [ 23 ] use the bound on the norm of the residual for standard power iteration ( (1 − α)t ) to obtain a bound on the proximity score of a node . Subsequently , for “ in bound proximity queries ” ( ie , the proximity is quantified in terms of the probability of being at the query node for a random walk that makes frequent restarts at each other node ) , they show that the proximity score of each node forms a monotonically nondecreasing sequence throughout the power iterations . They utilize this monotonicity , along with the bound on the norm of the residual , to identify the nodes that can be pruned .
When Chebyshev acceleration is used to compute proximity scores , y(t ) q ( u ) does not produce a monotonically nondecreasing sequence for all nodes u ∈ V . However , as we show by the following theorem , this is not required , and that the error bound provided by Chebyshev acceleration can indeed be used to quickly identify nodes that are not sufficiently proximate to q . More importantly , this theorem shows that the idea is not limited to “ in bound proximity queries ” ; rather , it can be applied to any proximity measure that can be computed via power iterations , for which the error in each iteration can be bounded .
Theorem 2 . Let Sq denote the set of the k nodes in V that are most proximate to q . Let ut be the node such that y(t ) q ( ut ) is the kth largest value in y(t ) q . Then , for every node u in y(t ) q ( u ) , we must have y(t ) q ( ut ) − 4μt . q ( u ) ≥ y(t ) q ( u ) ≥ y(t ) q ( ut)− 4μt , since y(t ) q ( u ) is among the topk values in y(t )
Proof . There are two possible cases to consider . In the q . In this q ( u ) ≥ first case , y(t ) case , it is clear that y(t ) y(t ) q ( ut ) by definition of ut . In the second case , y(t ) q ( u ) is not among the top k values in q . In this case , there must be at least one node v ∈ V such y(t ) q , but v /∈ Sq that y(t ) q ( v ) is among the topk values in y(t ) ( at least one node must drop out of the top k list to make space for u in the top k list ) . Now , using ( y(t ) q − x q( ≤2 μt , ∗ we obtain the following inequalities : q ( v ) ≤ x q ( v ) + 2μt ⇒ x ∗ y(t ) q ( v ) ≥ y(t ) ∗ q ( v ) − 2μt and q ( u ) − 2μt ⇒ x q ( u ) ≥ x ∗ y(t ) q ( u ) ≤ y(t ) ∗
Since u ∈ Sk but v /∈ Sk , we have x follows that q ( u ) + 2μt q ( u ) ≥ x ∗ ∗ q ( v ) , so it q ( u ) ≥ x q ( u ) + 2μt ≥ x ∗ y(t ) q ( v ) ≥ y(t ) ∗ q ( v ) − 2μt .
Since v is in the top k at the tth iteration , we have y(t ) y(t ) q ( ut ) , so we obtain q ( u ) + 2μt ≥ y(t ) y(t ) q ( ut ) − 2μt ⇒ y(t ) q ( u ) ≥ y(t ) q ( ut ) − 4μt . q ( v ) ≥
Using this result , at any step of the Chebyshev iteration , we can identify nodes that are not sufficiently proximate to q to make it to the top k list . Specifically , at iteration t , if q ( ut)−4μt for a node u , then u can san safely be y(t ) q ( u ) < y(t ) pruned out from the list of candidates for the top k list . The resulting algorithm for computing the top k most proximate nodes to q is given in Algorithm 1 . Since μ <(1 − α ) , we have 4μt ) ( 1 − α)t for the values of t that are of interest ( ie , the number of iterations is large enough for very large networks ) . Therefore , Chebyshev acceleration provides a more efficient method for processing top K queries than algorithms that utilize the convergence characteristics of standard power iteration , eg , Squeeze [ 23 ] . Furthermore , as we demonstrate in the next section via comprehensive experimental results , although Chopper does not directly utilize information on network structures to speed up computation , it also outperforms algorithms that utilize the network structure .
1519 α = 0.01
100
10 5 l
100
10 5 l
α = 0.05 i a u d s e r f o m r o N
10 10
10 15
10 20
0
200
Standard power iteration Chebyshev acceleration
400
600
800
1000
Number of Iterations ( a ) α = 0.01 i a u d s e r f o m r o N
10 10
10 15
1200
1400
10 20
0
50
Standard power iteration Chebyshev acceleration
100
150
200
250
Number of Iterations ( b ) α = 0.05
α = 0.1
100
10 5 l
100
10 5 l
α = 0.9 i a u d s e r f o m r o N
10 10
10 15
10 20
0
20
40 i a u d s e r f o m r o N
10 10
10 15
10 20
0
2
Standard power iteration Chebyshev acceleration
60
80
100
120
140
160
Number of Iterations ( c ) α = 0.1
Standard power iteration Chebyshev acceleration
4
6
Number of Iterations ( d ) α = 0.9
300
350
8
10
Figure 1 : Comparison of the convergence rates of standard power iteration ( RWR ) and Chebyshev acceleration on the Enron Email dataset . The plots show the norm of the difference between successive values of the proximity vector as function of the number of iterations , for damping factor α = 0.01 , 0.05 , 0.1 , 09
4 . EXPERIMENTAL RESULTS
In this section , we systematically evaluate the performance of the proposed algorithm , Chopper , in accelerating the computation of network proximity scores and processing of top k proximity queries . As shown in the previous section , the proposed algorithm is “ exact ” in the sense that it is guaranteed to correctly identify the set K nodes that are most proximate to the query node . For this reason , we here focus on computational cost ( measured in terms of number of iterations and runtime ) here , and compare Chopper against other exact algorithms .
We start our discussion by describing the datasets and the experimental setup . We then assess the performance of Chebyshev acceleration in the computation of random walk based proximity globally , ie , for all nodes in the network . Subsequently , we compare the performance of Chopper in processing top k proximity queries with two state of the art algorithms , Squeeze and Ripple [ 23 ] , using both number of iterations and runtime as performance criteria .
4.1 Datasets and Experimental Setup
We use four real world network datasets from the Stanford Network Analysis Project1 for our experiments . Details of these four networks are given on Table 2 . The Enron Email dataset represents the undirected e mail communication network at Enron . Brightkite and Gowalla datasets represent the Brightkite and Gowalla location based online social networks . The Skitter dataset represents the undirected internet topology graph , constructed from traceroutes run daily in 2005 . These datasets are selected as representative samples for network sizes in terms of the number of nodes and of edges . Furthermore , network proximity queries are meaningful on all of these networks .
For Squeeze and Ripple algorithms , we use the Java implementation provided by Zhang et al [ 23 ] . We implement Chopper in both Matlab and Java , and the results reported for runtime reflect that of the implementation in Java . We assess the performance of the algorithms for different values
1https://snapstanfordedu/data/
1520 100
90
80
70
60
50
40
30
20 s n o i t a r e t I f o r e b m u N
10 22
90
80
70
60
50
40
30
20 s n o i t a r e t I f o r e b m u N
10 22
Squeeze
Ripple
Chopper
Squeeze
Ripple
Chopper
100
90
80
70
60
50
40
30
20 s n o i t a r e t I f o r e b m u N
24
26 k
28
210
212
10 22
( a ) Enron Email
24
26 k
28
210
212
( b ) Brightkite
Squeeze
Ripple
Chopper
Squeeze
Ripple
Chopper
100
80
60
40
20 s n o i t a r e t I f o r e b m u N
24
26 k
28
210
212
0 22
( c ) Gowalla
24
26 k
28
210
212
( d ) Skitter
Figure 2 : The number of iterations required for Chopper , Squeeze , and Ripple in computing the top k nodes that are most proximate to a query node , as a function of k ranging from 4 to 4096 . In these experiments , damping factor α = 0.2 and the reported numbers are the averages across 1000 randomly chosen query nodes . of damping factor ( restart probability ) , as well as the parameter k for top k proximity queries . For all experiments involving top k proximity queries , we randomly select 1000 query nodes and report the average of the performance figures for these 1000 queries . In all experiments , rq is set to the identity vector for node q . All of the experiments are performed on a Dell PowerEdge T5100 server with two 2.4 GHz Intel Xeon E5530 processors and 32 GB of memory .
4.2 Global Network Proximity Computation We assess the performance of Chebyshev polynomials in accelerating the computation of network proximity scores for all nodes in the network . The purpose of this analysis is to quantify the improvement using Chebyshev acceleration beyond specific applications such as top k proximity queries , and to demonstrate its applicability to a broader range of problems that involve iterative computation of network proximity scores .
Figure 1 shows the convergence rate for Chebyshev acceleration in comparison to the standard power iteration for computing random walk based restart based proximity . We limit this analysis to the Enron Email dataset , since global proximity computation is expensive ( and often unnecessary ) for larger networks . In the figure , for the restart probability α ranging from 0.01 to 0.9 , we report the norm of the difference between two successive values of the proximity vector at each iteration . In all cases , the threshold for convergence −10 . As seen in the figure , Chebyshev accelerais set to 10 tion significantly reduces the number of iterations required to compute RWR based proximity .
It is important to note that Chebyshev acceleration provides larger performance gains for smaller values of α . This observation is consistent with the theoretical analysis of the convergence of Chebyshev acceleration , reflected in the relationship between the variable μ , which characterizes the convergence of Chebyshev acceleration and the parameter α . Intuitively , for large values of α , the random walk is largely localized – thus acceleration of convergence is of limited benefit . However , queries that involve large α are of limited practical interest , since they do not fully utilize the information provided by the network ( eg , for α >0 .5 the random walk is expected to move away from the query node
1521 s n o i t a r e t I f o r e b m u N s n o i t a r e t I f o r e b m u N
350
300
200
100
50
10
250
200
100
50
10
100 80 60 40 20
0
0.1
0.2
60 50 40 30 20 10
0
0.1
0.2
Squeeze
Ripple
Chopper
0.5
0.5
α
1
0.9
( a ) Enron Email
Squeeze
Ripple
Chopper
0.5
0.5
α
1
0.9 s n o i t a r e t I f o r e b m u N s n o i t a r e t I f o r e b m u N
250
200
100
50
10
350
300
200
100
50
10
60 50 40 30 20 10
0
0.1
0.2
100 80 60 40 20
0
0.1
0.2
Squeeze
Ripple
Chopper
0.5
0.5
α
1
0.9
( b ) Brightkite
Squeeze
Ripple
Chopper
0.5
0.5
α
1
0.9
( c ) Gowalla
( d ) Skitter
Figure 3 : The number of iterations required for Chopper , Squeeze , and Ripple in computing the top k = 20 nodes as a function of α ranging from 0.05 to 09 In these experiments , top k = 20 and the reported numbers are the averages across 1000 randomly chosen query nodes for each α . by two hops on the average ) . For this reason , larger performance gains for smaller values of α are valuable for practical applications . 4.3 Top k Proximity Queries
In top k proximity queries , the two major parameters are the damping factor , α , and the number of nodes to be identified as most proximate to the query node , k . We evaluate the performance of Chopper as a function of both parameters , using four large real world networks .
The performance of Chopper in comparison to two algorithms , Squeeze and Ripple as a function of k is shown in Figure 2 . For this analysis , we fix the damping factor α to 02 Recall that Squeeze uses the convergence characteristics of the standard power iteration to terminate the power iterations early . Ripple , on the other hand , also uses network structure to bound the proximity of the nodes in the network to the query node , thereby reducing the number of iterations further . As seen in the figure , Chopper consistently outperforms both algorithms for all four networks . The favorable performance of Chopper as compared to Ripple , is particularly notable , since Ripple also uses information on network structure to speed up computation , whereas Chopper only utilizes the convergence properties of the numerical scheme .
The only case in whichRipple requires fewer iterations than Chopper is for k = 4 on the Skitter data set . When the network diameter is large and the query results are localized around the seed node , utilization of network structure is particularly beneficial . However , even for such networks , if the query seeks a larger number of proximate nodes ( ≥ 8 ) , leveraging network structure does not reduce the number of iterations for standard power iterations as much as Chebyshev acceleration does .
We also compare the performance of Chopper with Squeeze and Ripple as a function of the damping factor α . For this purpose , we fix k = 20 and process top k proximity queries for 1000 randomly chosen queries for α ranging from 0.01 to 09 The results of this analysis for all four data sets is shown in the Figure 3 . In each panel , close ups of the curves for Chopper and Ripple are also shown for smaller values of α to facilitate better comparison . As seen in the figure , the number of iterations required for processing top k queries is similar for all algorithms on all datasets for α ≥ 05 This
1522 Squeeze
Ripple
Chopper
0.6
0.5
) c e S
(
0.4
) c e S
( i e m T g n n n u R i i e m T g n n n u R i
0.3
0.2
0.1
0 22
3.5
3
24
26 k
28
210
212
( a ) Enron Email
Squeeze
Ripple
Chopper
) c e S
(
2.5
) c e S
(
Squeeze
Ripple
Chopper
24
26 k
28
210
212
( b ) Brightkite
Squeeze
Ripple
Chopper
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0 22
25
20
15
10
5 i e m T g n n n u R i i e m T g n n n u R i
2
1.5
1
0.5
22
28
210
212
0 22
24
26 k
( c ) Gowalla
24
26 k
28
210
212
( d ) Skitter
Figure 4 : The runtime in seconds required by Chopper , Squeeze , and Ripple to process queries for top k nodes that are most proximate to a query node , as a function of k ranging from 4 to 4096 . In these experiments , the damping factor α is set to 0.2 and the reported numbers are the averages across 1000 randomly chosen query nodes . is expected since the search is “ easier ” , ie , it is limited to nodes that are very close to the query node in this case . However , for smaller ( and more relevant ) values of α , Chopper consistently achieves best performance . 4.4 Runtime Performance
Finally , we compare the performance of Chopper with Squeeze and Ripple in terms of running time as a function of k . For this purpose , we fix α = 0.2 and process top k proximity queries for 1000 randomly chosen queries for k ranging from 4 to 4096 . The results of this analysis for all four data sets is shown in the Figure 4 . As expected , the time required to process top k queries increases with k for all methods . However , across all datasets and for all values of α , Chopper consistently delivers best performance , with two fold improvement over the runtime of Ripple for the largest dataset Skitter .
5 . CONCLUSION
In this paper , we propose an alternate approach to accelerating network proximity queries . The proposed approach is based on Chebyshev polynomials , an established acceleration technique for iterative methods in numerical linear algebra . We show that our approach , Chopper , produces asymptotically faster convergence in theory , and significantly decreased convergence times in practice on realworld problems . Using a number of large real world networks , and top k proximity queries as the benchmark problem , we show that Chopper outperforms existing methods significantly for wide ranges of parameter values . When integrated with existing methods , Chopper yields further improvement in performance over state of the art techniques . Future efforts in this direction would include incorporation of other acceleration techniques into our framework , extensions to other iterative proximity measures , and their applications . Furthermore , while Chopper is an “ exact ” algorithm and our experiments focus on runtime performance for this reason , there also exist approximate methods that compromise accuracy for improved runtime . Comparison of Chopper against such approximate algorithms can provide further insights into the trade off between runtime and accuracy in the context of network proximity problems .
1523 [ 14 ] L . Page , S . Brin , R . Motwani , and T . Winograd . The pagerank citation ranking : Bringing order to the web . Technical Report 1999 66 , Stanford University , November 1999 . Previous number = SIDL WP 1999 0120 .
[ 15 ] Y . Saad . Chebyshev acceleration techniques for solving nonsymmetric eigenvalue problems . M athematics of Computation , 42(166):567–588 , 1984 . [ 16 ] Y . Saad . I terative Methods for Sparse Linear Systems .
Society for Industrial and Applied Mathematics , Philadelphia , PA , USA , 2nd edition , 2003 .
[ 17 ] P . Sarkar and A . W . Moore . Fast nearest neighbor search in disk resident graphs . In P roceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 513–522 . ACM , 2010 .
[ 18 ] T . Tao and C . Zhai . An exploration of proximity measures in information retrieval . In P roceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval , pages 295–302 . ACM , 2007 .
[ 19 ] H . Tong , C . Faloutsos , and J Y Pan . Fast random walk with restart and its applications . In P roceedings of the Sixth International Conference on Data Mining , ICDM ’06 , pages 613–622 , Washington , DC , USA , 2006 . IEEE Computer Society .
[ 20 ] O . Vanunu , O . Magger , E . Ruppin , T . Shlomi , and
R . Sharan . Associating genes and protein complexes with disease via network propagation . P LoS Comput . Biol . , 6(1):e1000641 , Jan 2010 .
[ 21 ] Y . Wu , R . Jin , and X . Zhang . Fast and unified local search for random walk based k nearest neighbor query in large graphs . In P roceedings of the 2014 ACM SIGMOD international conference on Management of data , pages 1139–1150 . ACM , 2014 . [ 22 ] W . Yu and X . Lin . Irwr : incremental random walk with restart . In P roceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval , pages 1017–1020 . ACM , 2013 . [ 23 ] C . Zhang , S . Jiang , Y . Chen , Y . Sun , and J . Han . Fast inbound top k query for random walk with restart . In M achine Learning and Knowledge Discovery in Databases , pages 608–624 . Springer , 2015 .
[ 24 ] C . Zhang , L . Shou , K . Chen , G . Chen , and Y . Bei .
Evaluating geo social influence in location based social networks . In P roceedings of the 21st ACM international conference on Information and knowledge management , pages 1442–1451 . ACM , 2012 .
[ 25 ] J . Zhao and Y . Yun . A proximity language model for information retrieval . In P roceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval , pages 291–298 . ACM , 2009 .
Acknowledgements We would like to thank Xiang Zhang , Yubao Wu , and Sean Maxwell for many useful discussions , and anonymous reviewers for their valuable comments . This work was supported in part by US National Science Foundation ( NSF ) grants CCF 1533795 , CCF 0953195 , and CNS 1422338 , and US National Institutes of Health ( NIH ) grant U01 CA198941 . 6 . REFERENCES [ 1 ] D . Aldous and J . A . Fill . Reversible markov chains and random walks on graphs , 2002 . Unfinished monograph , recompiled 2014 , available at http : //wwwstatberkeleyedu/˜aldous/RWG/bookhtml
[ 2 ] R . Andersen , F . Chung , and K . Lang . Local graph partitioning using pagerank vectors . In F oundations of Computer Science , 2006 . FOCS’06 . 47th Annual IEEE Symposium on , pages 475–486 . IEEE , 2006 .
[ 3 ] R . Andersen , F . Chung , and K . Lang . Using pagerank to locally partition a graph . I nternet Math . , 4(1):35–64 , 2007 .
[ 4 ] P . Bogdanov and A . Singh . Accurate and scalable nearest neighbors in large networks based on effective importance . In P roceedings of the 22nd ACM international conference on Conference on information & knowledge management , pages 1009–1018 . ACM , 2013 .
[ 5 ] M . Cao , H . Zhang , J . Park , N . M . Daniels , M . E . Crovella , L . J . Cowen , and B . Hescott . Going the distance for protein function prediction : a new distance metric for protein interaction networks . P loS one , 8(10):e76339 , 2013 .
[ 6 ] M . Co¸skun and M . Koyut¨urk . Link prediction in large networks by comparing the global view of nodes in the network . In 2 015 IEEE International Conference on Data Mining Workshop ( ICDMW ) , pages 485–492 . IEEE , 2015 .
[ 7 ] S . Erten , G . Bebek , R . M . Ewing , and M . Koyut¨urk .
Dada : Degree aware algorithms for network based disease gene prioritization . B ioData mining , 4(1):1–20 , 2011 .
[ 8 ] Y . Fujiwara , M . Nakatsuji , M . Onizuka , and
M . Kitsuregawa . Fast and exact top k search for random walk with restart . P roceedings of the VLDB Endowment , 5(5):442–453 , 2012 .
[ 9 ] M . Hofree , J . P . Shen , H . Carter , A . Gross , and T . Ideker . Network based stratification of tumor mutations . N ature Methods , 10(11):1108–1115 , Sept . 2013 .
[ 10 ] H . Jeong and B . Yoon . Accurate multiple network alignment through context sensitive random walk . BMC Systems Biology , 9(S 1):S7 , 2015 .
[ 11 ] D . Liben Nowell and J . Kleinberg . The link prediction problem for social networks . J ournal of the American society for information science and technology , 58(7):1019–1031 , 2007 .
[ 12 ] Q . Mei , D . Zhou , and K . Church . Query suggestion using hitting time . In P roceedings of the 17th ACM conference on Information and knowledge management , pages 469–478 . ACM , 2008 .
[ 13 ] S . Navlakha and C . Kingsford . The power of protein interaction networks for associating genes with diseases . B ioinformatics , 26(8):1057–1063 , 2010 .
1524
