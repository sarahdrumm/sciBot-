Dynamic and Robust Wildfire Risk Prediction System : An
Unsupervised Approach
Mahsa Salehi
IBM Research Australia 60 City Road , Southbank Victoria , 3006 , Australia mahsalehi@au1ibmcom
Laura Irina Rusu
IBM Research Australia 60 City Road , Southbank Victoria , 3006 , Australia laurusu@au1ibmcom
Timothy Lynar
IBM Research Australia 60 City Road , Southbank Victoria , 3006 , Australia timlynar@au1ibmcom
Anna Phan
IBM Research Australia 60 City Road , Southbank Victoria , 3006 , Australia annaphan@au1ibmcom
ABSTRACT Ability to predict the risk of damaging events ( eg wildfires ) is crucial in helping emergency services in their decisionmaking processes , to mitigate and reduce the impact of such events . Today , wildfire rating systems have been in operation extensively in many countries around the world to estimate the danger of wildfires . In this paper we propose a data driven approach to predict wildfire risk using weather data . We show how we address the inherent challenge arising due to the temporal dynamicity of weather data . Weather observations naturally change in time , with finer scale variation ( eg stationary day or night ) or large variations ( nonstationary day or night ) , and this determines a temporal variation of the predicted wildfire danger .
We show how our dynamic wildfire danger prediction model addresses the aforementioned challenge using context based anomaly detection techniques . We call our predictive model a Context Based Fire Risk ( CBFR ) model . The advantage of our model is that it maintains multiple historical models for different temporal variations ( eg day versus night ) , and uses ensemble learning techniques to predict wildfire risk with high accuracy . In addition , it is completely unsupervised and does not rely on expert knowledge , which makes it flexible and easily applied to any region of interest . Our CBFR model is also scalable and can potentially be parallelised to speed up computation . We have considered multiple wildfire locations in the Blue Mountains , Australia as a case study , and compared the results of our system with the existing well established Australian wildfire rating system . The experimental results show that our predictive model has a substantially higher accuracy in predicting wildfire risk , which makes it an effective model to supplement the operational Australian wildfire rating system .
CCS Concepts •Information systems → Data streaming ; Data analytics ; Data stream mining ; •Computing methodologies → Anomaly detection ;
Keywords Wildfires , Bushfires , Risk Prediction , Data Stream Mining , Unsupervised Learning , Context Based Anomaly Detection
1 .
INTRODUCTION
Natural disasters are a prevalent reality around the world . Roughly 102 million people worldwide were affected by natural disasters in 2014 alone [ 8 ] , with a global annual economic loss estimated at over $300B [ 10 ] . Researchers link natural disasters with climate change and statistics show that in 2014 , 87 % of worldwide natural disasters were climaterelated [ 8 ] . Some countries , including Australia , experience wildfires , locally known as bushfires , as the most damaging disasters . In the Australian state of Victoria , wildfires pose the largest annual risk to the safety of residents [ 6 ] . For example , in the recent ‘Black Saturday’ Victorian wildfire event of February 2009 , over 1.1 million acres burnt , 173 people lost their lives and over 400 people were injured [ 5 ] . Another notable impactful event was ‘Ash Wednesday’ in February 1983 , with 75 fatalities and over 1 million acres burnt in the states of Victoria and South Australia . The impact of these disasters is multi dimensional , from social and psychological to economic and environmental .
The reality described above makes a strong case for wildfire research , not only in Australia but also around the world . One of the most pressing problems in this context is the ability to predict the risk of a wildfire event . By knowing the risk , government agencies , communities and individuals can be better informed so they can take the most appropriate measures to mitigate and prepare for of wildfire events , if and when they eventuate ( eg evacuate people , predeploy firefighting assets etc )
The McArthur Forest Fire Danger Index ( FFDI ) [ 17 ] is used in Australia by the national Bureau of Meteorology to
245 draw Fire Danger Index maps [ 2 ] , which in turn are used by state wildfire authorities to determine Fire Danger Ratings ( FDR ) by taking into account not only the contribution of weather but also other relevant information such as fuel load . The daily FDR are then publicly available and broadcasted to all interested stakeholders .
Along with FFDI , other approaches to predict wildfire danger also exist around the world ( summarised later in Section 2 , Related Works ) . However their main drawback , which we address in this paper , is that they generally calculated by feeding the current weather observations into an existing static model , therefore not catering for spatial or temporal variations between observations ( eg between weather stations due to elevation , or between summer and autumn days ) . With existing approaches , the danger index on any given day or at any given point in space is calculated using the same models , with static parameters that do not change to reflect the actual context of the danger index calculation . This determines a coarse variation between the danger indices of consecutive days and is not indicative of the temporal development of the wildfire danger , which is actually the case for most wildfire events .
As an exemplar , consider two weeks of weather observations where the current operational mathematical model or other learned/regression models in the literature is used to compute the risk values . Additionally , suppose that in the middle of this period an actual wildfire is happening . Figure 1 depicts an example of risk values computed using the FFDI model for this example time period . In this graph the vertical axis represents the risk values , horizontal axis shows the time in minutes , and the horizontal line in the middle bottom of the graph represents the actual wildfire period . Now suppose there is bad weather conditions one night before the actual wildfire in comparison to other normal nights . The rectangle in this figure shows the described night . Although the night weather information can be used to infer a high risk period in the next few hours , the FFDI model fails to use such information until the actual wildfire is happening . The risk values at night time in this figure ( values in the rectangle ) are low . Using online learning models which use the whole history of observations cannot be beneficial either , for such models do not differentiate ‘night time’ from ‘day time’ . This differentiation is extremely significant , as the decision makers and firefighters need to be able to predict the high risk days beforehand , to enable them to plan strategically in advance .
Since wildfire danger is mainly dependent on the weather and fuel load , and their variability can be observed both spatially and temporally [ 24 , 22 ] , we claim that wildfire risk models should not be static and generic , but dynamic and representative of the spatial and temporal context . That is , we propose a wildfire danger model that considers finer scale variations in day or night weather observations ( stationary observations ) or larger variations during day or night ( nonstationary observations ) and readjusts itself ( ie its parameters ) to the context . In this paper , we consider both the temporal variability and spatial variability of weather observations .
Based on the above , we summarise the novel contributions of this paper as follows :
• We propose a dynamic wildfire risk prediction model to augment the current static operational models ;
Figure 1 : Wildfire risk values over 20 days of weather observations using FFDI
• The solution captures the temporal contextual changes in meteorological observations in determining the applicable risk model ;
• The solution is completely unsupervised and it does not rely on expert knowledge or statistics , which makes it flexible and applicable to other areas of interest ;
• Since the solution is based on an ensemble learning approach , it is robust and scalable so that it can potentially be parallelised to speed up computation .
This work follows from the project with Fire & Rescue NSW , the largest emergency management agency in Australia and one of the largest in the world , where we looked at the spatiotemporal dynamics of wildfire danger . One challenge we found was the inability of the current wildfire danger models ( eg FFDI ) to incorporate the spatiotemporal context in the modelling , and that issue is addressed in this proposal .
2 . RELATED WORKS
There is a vast body of work modelling the risk of wildfires ( aka bushfires ) with diverse focus . Some investigate the likelihood of wildfires ( that is , probability of ignition or probability of burning ) , while others study the intensity or effects of wildfires ( based on ecological , social or economic values ) [ 18 ] . This section reviews a few methods currently used for wildfire danger assessment and that are most relevant to the topic of current paper , that is real time assessment of changes in wildfire danger due to weather changes . We then present the McArthur Forest Fire Danger Index ( FFDI ) , which is currently widely used by authorities in Australia and is the starting point for our proposal . Lastly , we highlight why a context based real time assessment of wildfire danger is required to supplement FFDI , and show the real world applicability of the proposed method .
Most of the wildfire danger prediction methods use meteorological observations sourced from weather stations ( eg temperature , wind speed , wind gust , wind direction relative humidity , precipitations ) together with other variables such as topography , vegetation type and vegetation density to predict the wildfire danger/risk for the given conditions based on empirical methods . For example :
005115225Time(min)×104050100150Risk ValueDaysFire PeriodNight246 • In USA , the National Fire Danger Rating System [ 11 ] uses current and historical weather data , fuel type as well as live and dead fuel moisture to come up with a danger rating . The model is 30 years old ( 1977 1978 ) and does not capture temporal or spatial dynamics of the meteorological information to fine tune the model . • The Canadian Forest Fire Weather Index ( FWI ) [ 9 ] is a numeric rating of wildfire intensity . It uses only four weather variables ( temperature , relative humidity , wind speed and 24 hour rainfall ) to determine a ‘wildfire spread’ index and a ‘build up’ index . These are based on consecutive daily observations of the four above mentioned variables , and together they give the Fire Weather Index ( FWI ) , used currently as the general index of wildfire danger in the Canadian forests .
In [ 12 ] , the authors show that there is a correlation between wildfire occurrence and the effect of fuel moisture and thus the rating of wildfire danger . Where wildfire occurrence is given by the frequency of wildfires recorded in a historical period of time , with data often summarised for different time periods , often by daily , weekly , or monthly intervals to help depict variation in wildfire activity through out the season . To counter the issue of spatially limited data ( eg received from sparse weather stations ) , a number of studies look at wildfire danger detection using sensor networks . For example , [ 26 ] propose a wireless sensor network where sensor nodes are used to collect the data ( eg temperature , relative humidity ) and submit the information to specific cluster nodes . The cluster nodes will then construct neural networks to produce a weather index showing the likelihood for the weather to cause a wildfire . The paper does not describe the actual model hence the spatiotemporal customisation of the model cannot be assessed . In [ 16 ] , it is claimed that wildfire risk needs to consider both wildfire behaviour probability and effect . The former depends on the spatial and temporal factors controlling wildfire spread , including fuel and weather . Moreover , the authors investigate the burn probability based on historic wildfire data , and highlight the need to move beyond assumptions of spatial and temporal uniformity while modelling that probability . Their approach is in line with [ 15 ] that argues that localised spatial properties ( topography , fuel , weather ) produce local differences in the wildfire behaviour , hence local differences in wildfire risk . This is also in line with our argument towards a customisable model that can cater for local spatial and temporal differences in wildfire danger due to weather . A scientist from the Commonwealth Scientific and Indus trial Research Organisation ( CSIRO ) developed the McArthur Forest Fire Danger index in the 1960s to measure wildfire danger in Australian forests . The index is currently used by the authorities in Australia to calculate and broadcast wildfire danger ratings during summer . It is based on temperature , humidity , wind speed , dryness and fuel weight as shown in Equations 1 and 2 [ 21 ] :
F F DIγ = 2e
−045+0987∗ln(DFγ )−0.0345Hγ +0.0338Tγ +0.0234Vγ ( 1 )
DFγ =
0.191(Iγ + 104)(Nγ + 1)1.5 3.52(Nγ + 1)1.5 + P reγ − 1
( 2 )
Figure 2 : Wildfire Danger Categories in Australia ( Figure reproduced from [ 4 ] ) where Hγ is relative humidity , Tγ is air temperature , Vγ is average wind velocity in the open at the height of 10 m , F F DIγ is forest fire danger index and DFγ is drought factor which uses precipitation observations P reγ , Nγ is time since rain and Iγ is soil ’s moisture content all at time γ .
The output FFDI values are further interpreted based on a defined categorisation . Figure 2 depicts the six different categories . Using the above equations and these categories , the Australian emergency management agencies find the relevant category and broadcast it daily .
As mentioned in the introduction , the main drawback of operational wildfire rating systems including FFDI is that the danger index is calculated based on the most current weather observations available , using a static model , and not customised to the particular location where the danger index is used . This determines a coarse variation between the danger indices of consecutive days and is not indicative of the temporal development of the wildfire danger conditions , which can be observed prior to wildfire events . To the best of our knowledge there are no current wildfire danger prediction frameworks that consider context based spatiotemporal variations to fine tune the models’ parameters . Our results , from an Australian case study , show that our proposal does not contradict but rather augment FFDI , giving the decision makers more fine grained information about the increasing wildfire danger and allowing them to take even better informed decision to protect communities and the environment .
3 . OUR PROPOSED CONTEXT BASED
FIRE RISK ( CBFR ) MODEL
In this section we first formally define the problem , then explain the steps of our context based fire risk prediction solution ( CBFR ) in detail . 3.1 Problem Definition
We consider the problem of wildfire risk prediction in dynamically changing environments based on meteorological observations . Specifically , let H be the relative humidity in % , T be the air temperature of the region in oC , V be the average wind velocity in the open at the height of 10 m in km hr−1 and DF be the drought factor which uses precipitation observations P re . DF is an indicator of amount of the soil moisture and covering layer of duff moisture in the region of interest R .
Assume that a set of streams of meteorological observations P R 1:Γ is collected over time period [ 1Γ ] for a region R . Hence , at time γ a vector P R γ = ( Hγ , Tγ , Vγ , P reγ ) is observed at region R . Our aim is to compute the wildfire risk of observation CBF RP R for all of the given observations in a given region R . Note that to make the assumptions
1Γ
247 Input : Meteorological data observations P1:Γ Context size W Decaying parameter α Output : Context based fire risk CBF R C(1 ) ←− Cluster(P1:W );// set of clusters C t ←− 1 ; while t < Γ W do
1:Γ models
// cluster observations is current context C(t + 1 ) ←− Cluster(PtW +1:(t+1)W ) ; // compute relevancy of historical context w1:t+1 ←− Relevancy(C(t + 1 ) , C(1 : t + 1) ) ; foreach γ ∈ {tW + 1 : ( t + 1)W} do // decay function g(x ) = 1/xα CBF R t+1 t+1 h=1 g(t + 1 − h)whP r(Pγ|C(h ) ) h=1 g(t + 1 − h)wh
Pγ = end F F DIf ilter(PtW +1:(t+1)W ) Smooth(PtW +1:(t+1)W ) t ←− t + 1 ; end return CBF R Algorithm 1 : Context Based Fire Risk ( CBFR ) Algorithm
1:Γ ; more realistic , we consider that the meteorological observations are dynamically changing both temporally and spatially . In other words , first the stream of observations are changing during time , ie time changing behaviour can occur in finer scale variation ( eg , daytime versus nigh time ) , or even variations during daytime . Second , the stream of observations can change spatially in different regions . 3.2 Analytical components of our proposed risk model
To develop a predictive risk model , one of the big challenges is lack of label information for building supervised predictive models . In fact , we noticed that in case of wildfire risk , it is really not reasonable to identify which periods of time are risky and which of them are not . One might argue that using wildfire histories can be beneficial . However , we can still have high wildfire risk periods of time where there is no wildfire due to the lack of ignition in the area .
To deal with this challenge an unsupervised algorithm is needed for wildfire risk prediction , where high risk periods are identified without any statistics or expert knowledge . Since wildfire onset is a rare event in comparison to the entire history in time , we believe an anomaly detection algorithm can be a very good candidate solution , where the high risk days can be seen as anomalies and detected in an unsupervised manner . Moreover , to capture the temporal dynamicity of input data streams , our solution would benefit from a stream mining technique . Figure 3 depicts overall schema of the proposed risk model including the analytical components . Algorithm 1 shows the pseudocode of our CBFR model . In the following , we discuss different components of our model in detail . sources can be any weather company which measures the variables mentioned in problem definition section . In the case study of this paper , weather data was provided by Fire & Rescue NSW from the Bureau of Meteorology ( BoM ) in Australia [ 1 ] . Although we evaluate our model using weather data , our model is not restricted to weather observations and we can incorporate other types of data eg vegetation type , fuel load and topographical data into the model to achieve more accurate results .
Reanalysis for high resolution :
In addition to the above data sources we conduct a high resolution meteorological reanalysis , running local atmospheric models to resolve smaller phenomena and provide more detailed data than would otherwise be possible from observations . The simulation was conducted with the Weather and Research Forecasting model ( WRF ARW ) [ 14 ] . The model outputs include temperature , precipitation , pressure , relative humidity and wind speed . 322 As mentioned earlier , the temporal dynamics in input data streams is not considered by current operational wildfire risk systems . To deal with this challenge , we propose exploiting an online anomaly detection algorithm . In addition , we need to deal with the non stationarity of temporal weather observations in the input data as well . Hence , the proposed online algorithm in this paper should be able to adapt to the non stationarity behaviour of data .
Identify context
This can be solved by modelling different contexts in the underlying behaviour of input data stream separately and maintain multiple models over time .
Definition 1 . Context is a specific period of time in which weather observations remain roughly stationary .
Thus in this step , we identify the defined context based on available resolution of input data . For instance , we may consider day context versus night context in weather observations . If we have finer granularity input data , we can further decompose the temporal context into morning , noon , afternoon , evening and etc . The number of weather observations in a context is denoted by parameter W . 323 Contextual Based Anomaly Detection After identifying the required context and parameter W , we need an anomaly detection algorithm that captures the temporal dynamicity in weather data streams to detect the anomalous patterns ( high risk ) periods . Our solution is to use an ensemble based anomaly detection algorithm which is proposed for dynamically changing data streams [ 23 ] . Figure 3 shows the schematic of this unsupervised learning algorithm in the bottom left of the figure . By dividing data streams into different data chunks based on their contexts , we are able to build anomaly detectors for each context ( day and night in Figure 3 ) separately . Each of these anomaly detectors is a risk predictor . In the current temporal context ( last ‘night’ in the bottom of Figure 3 ) , all relevant historical predictors are considered and a decision on the risk value of current observations are made by participating only the relevant models . We further discuss the subcomponents of this algorithm :
321 Data sources We developed our system based on weather data . Data
• Clustering : A clustering based anomaly detection tech nique is used to profile the weather observations for
248 Figure 3 : The analytical components of our proposed risk model each temporal context with size W ( called a data chunk ) . Using a density based clustering algorithm such as [ 20 ] enables on one hand to detect the number of clusters dynamically and on the other hand to speed up the algorithm to near linear . The output of this clustering algorithm is a set of hyper ellipsoidal boundaries for the current data context . Let C(t ) be the tth ( current ) set of hyper ellipsoidal boundaries or data clusters . Hence for the tth historical data chunk we only store the clusters centers ct and covariance matrices Σt . ing the mahalanobis distance of Pγ and all clusters in C(t ) . The mahalanobis distance of an observation Pγ to ith cluster in C(t ) with center ct i and covariance Σt i is computed as following :
( Pγ − ct
−1(Pγ − ct i)T ( Σt i ) i )
( 3 )
Using the above formula , if an observation Pγ falls into the .95 percent covered by at least one of the clusters ( hyperellipses ) in C(t ) we do not consider the observation as anomaly , ie , P r(Pγ|C(t ) ) = 0 . Otherwise it is equal to 1 .
• Identify relevancy : To select relevant historical contexts with the current context , at this step we compare the similarity of hyperellipsoidal boundaries of the current model with historical models . The similarity between two hyperellipsoids is computed using a distance measure called focal distance . Interested readers can refer to [ 19 ] for more details on this distance measure . The bottom left of Figure 3 depicts this step . In this figure the similarities between the current clustering model and all historical clustering models are computed and weights of similarity are computed ( ie wh , 0 < h < t ) . Let dish be the distance between a past clustering model C(h ) and a current clustering model
1
C(t ) , then wh = dish 1 if disth = 0 if disth = 0
.
• Ensemble based anomaly detection : In this step we incorporate the most relevant historical clustering models and use their weights to compute an anomalous value for all of the weather observations in the current context . Selecting relevant historical models leads to a more effective risk prediction model . Given a set of clusters C(t ) and a weather observation Pγ at time γ , an anomalous value of Pγ is computed us
Finally , an ensemble of relevant ( weighted ) historical models is used in assigning final anomalous values to the current observations . Given a weather observation Pγ at time γ , the final context based wildfire risk ( or anomalous ) value CBF RPγ is computed using all t clustering models C(h ) ( 0 < h ≤ t ) . More specifically : t t h=1 whP r(Pγ|C(h ) ) h=1 wh
CBF RPγ =
( 4 )
• Identify decaying factor : We are running our risk model on each weather station and the available memory is limited per station . By modelling the incoming weather data streams , we produce an infinite number of clustering models or profiles over time . This can be problematic both in terms of required memory and time . To deal with this problem , we define a decaying factor [ 13 ] which limits the number of clustering models to be stored in memory . We define a polynomial decay function g(x ) = 1/xα for a parameter α and x ≥ 0 . Other than relevancy weights which are identified in the above paragraphs , the temporal importance of each clustering model can be calculated as well . At tth step of the clustering model , the importance of historical models h ( 0 < h ≤ t ) is computed
249 as g(t − h ) . Hence the final risk value by integrating the decaying factor is computed using the following : t t h=1 g(t − h)whP r(Pγ|C(h ) ) h=1 g(t − h)wh
CBF R
Pγ =
( 5 )
324 FFDI filter In order to avoid the false positive rates of our anomaly detection solution in very rare cold days , we suggest using the current operational FFDI system as a filter to our model . This can be simply done by computing the FFDI values for incoming weather observations . If these values fall in one of the top five categories ( ie high , very high , severe , extreme or catastrophic ) according to Figure 2 , we keep the wildfire risk values ( CBF R Pγ ) intact . Otherwise , we set the values to zero . 325 Linear regression smoothing In this step of the algorithm , while we have the risk values for the current window observations , we smooth the output in order to find a pattern . By smoothing , we can better identify the temporal sequence of risk values . We use ‘locally weighted’ linear regression smoothing method in this component and a stream of risk values is produced as output . 326 Scalability of CBFR The computational complexity of analytical components in CBFR is near linear with respect to the number of weather observations . This matches the real time requirement of our risk prediction problem . Also CBFR is scalable and we can further speedup the algorithm by parallelising the computation of ‘relevancy identification’ and ‘incorporation of historical data profiles’ steps of the algorithm .
4 . EVALUATION OF OUR PROPOSED
MODEL IN BLUE MOUNTAINS NATIONAL PARK AUSTRALIA
In this section , we compare our proposed model with the operational McArthur FFDI method described in Section 2 . 4.1 Blue Mountains National Park Dataset
The dataset we used in this case study is the meteorological data provided by Fire & Rescue NSW from the Blue Mountains region . The reason why we chose this area for study is that a severe wildfires occurred in this area in 2013 from October 17 until October 21 . These days are considered as anomalies and the proportion of anomalies and normal observations in this dataset is 7 % . The dataset consists of temperature , relative humidity , wind speed and precipitation measurements from three different BoM weather stations located in this area ( Mt Victoria , Richmond Raaf and Penrith Lake ) . Figure 4 shows the mentioned locations in Blue Mountains of these weather stations . The meteorological measurements are taken every 1 minute and there are 300K observations in total from all stations .
Moreover , we created a higher spatial resolution dataset using our reanalysis model . The model consisted of 3 domains nested at 3:1 grid size ratio , the inner domain had a grid spacing of 5 km and covers an area of 275 km × 275 km centered on the town of Blackheath ( 34.80 , 138.90 ) in the Blue Mountains region .
The reanalysis simulated 96 hours from the start of October 13 , 2013 UTC to the end of October 17 , 2013 UTC . The model was initialised and forced with boundary conditions provided by ERA Interim reanalysis , this analysis is a global atmospheric reanalysis produced by the European Center for Medium Range Weather Forecasts ( ECMWF ) , it uses a 30 minutes time step and has a spectral T255 horizontal resolution which is about a 79km and a vertical resolution of 60 layers [ 14 ] . The simulation output is provided at frequency of 1 minute . 4.2 Performance measures
In order to compare our model with the operational FFDI , we have used different performance measures : ( 1 ) Since our proposed model ’s output is a fuzzy value between 0 and 1 , we used the Area Under ROC curve ( AUC ) to find the accuracy of our model . The output value of FFDI on the other hand , is a value between 0 to 100+ . To compare our model with FFDI , we consider the trend of both FFDI and CBFR values . ( 2 ) The second performance measure is accuracy ( T P os+T N eg P os+N eg ) , where T P os is the number of true positives ( the number of episodes that the high risk of wildfire is predicted correctly ) , T N eg is the number of true negatives ( the number of episodes that the low risk of wildfire is predicted correctly ) , P os is the number of total episodes where risk of wildfire is high and N eg is the number of total episodes where risk of wildfire is not high . ( 3 ) The third performance measure is sensitivity ( T P os P os ) , which is the ratio of predicting the high risk of wildfire correctly . And finally , ( 4 ) Youden Index , which is an optimal point on AUC . This is the farthest point from diagonal line and is computed as following [ 25 ] :
Sensitivity + Specif icity − 1 max(
√
2
)
( 6 ) where sensitivity is computed from above , and specificity is T N eg N eg . 4.3 Effectiveness of our CBFR Approach
We apply our proposed CBFR approach on the Blue Mountains dataset . In other words , all of the analytical components and subcomponents of our CBFR model ( including , decaying factor , FFDI filter and linear regression smoothing ) are applied on the Blue Mountains dataset and the final risk values are calculated for each episode of time in this dataset ( every minute ) . Hence the effectiveness and predictability measures which will be shown in this section , indicate how well the combination of all of these components perform .
According to granularity of the observations ( measurements are taken every 1 minute ) , we decided to set the window size equal to the number of observations which are measured over daytime and nighttime . A total number of 720 observations are measured during each day/night . The reason in selecting such window size is that we want to distinguish between the clustering models of nighttime and daytime . So if the weather is bad in the nighttime context , our model outputs high values which predicts a high wildfire risk in the next day . Whereas in the current FFDI model , the index is computed based on the weather data and independent of the temporal occurrence of historical observations .
While in this case study , we have used nighttime and daytime length as a window size , there might be some important and valuable variations in the daytime as well . Hence , if given higher frequency observations ( eg every 30 or 10
250 Figure 4 : The temporal changes in wildfire onset , Blue mountains region ( Figure reproduced from [ 1 , 7 ] ) seconds ) , multiple models can also be considered for a day that represent different variations in various times . The parameter α in decaying function is set to 2 and we delete the historical data profiles with very low decaying function values to constraint memory and time complexity .
Note that in order to evaluate our model we need to have the ground truth . However , in this specific application , it is very difficult to find the ground truth . One alternative that is used in the literature of disaster management is to label the onset of disasters as high risk episodes . While the episodes of disasters ( wildfire in this paper ) represent high risk episodes , there might be some other days that have high risk of onset of wildfire , but because no ignition occurs , no wildfire starts . In these situations it is difficult to evaluate whether the proposed model is able to find them as high risk episodes or not . In order to find a more accurate ground truth to evaluate our model with , we decided to further investigate the area of interest .
Figure 4 shows the wildfire onset in different days based on the information provided in the governmental website [ 3 ] . On October 16 , a wildfire was accidentally sparked in Marrangaroo ( top left of the figure ) which continued to travel to the northern regions of Blue Mountains national park . The next day , two major wildfires were reported in the south east ( Mount Victoria ) and south west ( Springwood ) . These areas are depicted with flames and labeled as ‘17th Oct’ in Figure 4 . The sparked wildfires were reported to continue burning until October 21 .
Given the wildfire history of the region , we consider two different scenarios for the evaluation purposes :
• Scenario I : In this scenario , we follow the evaluation method that is used in literature . This means we use the exact wildfire onset ( ie October 17 to October 21 ) to determine which temporal periods of time have high risk .
• Scenario II : As mentioned above , a wildfire had already started in the vicinity of the area of interest one day before the wildfire onset ( October 16 ) . Hence , in this second scenario we consider October 16 as a high risk day as well . We believe this can be a more realistic assumption .
In both above scenarios , the episodes are labeled based on the presence of wildfire , weather temperature , relative humidity and wind speed . Considering these two scenarios , we want to see how our proposed model is performing in comparison to FFDI model .
For the evaluation purposes , first we applied both our model and FFDI to all observations and compared the output risk of both models . The aim here is to find which model can reflect the high wildfire risk days more accurately . Considering the Scenario I , Figure 5a c depict the AUC results for three different stations in our area of interest . Each point on the ROC Curve is relevant to sensitivity and 1 specificity of both models considering a certain threshold . The three solid graphs in Figure 5a c show the results of our model and the three dashed graphs show the results of FFDI method . It is shown that in all three stations , the detection accuracy of wildfire risk by our CBFR model is substantially higher than using the current operational FFDI .
431 Predictability Considering Scenario II , the aim is to evaluate the predictability of our CBFR model . Figure 6a c depict the AUC results for three different weather stations in the area of interest . The three solid graphs in Figure 6a c correspond to the results of our model and the dashed graphs show the results of FFDI method . While the AUC of detecting risk of wildfire by our model is higher than using the current operational FFDI , we noticed that the AUC of our model is either roughly the same as previous scenario for Mt Victoria , or increased by 7 % and 8 % in Richmond Raaf ( Figure 6b ) and Penrith Lake ( Figure 6c ) receptively . Nevertheless , for the FFDI model , the AUC in Mount Victoria increased by 7 % but in Richmond Raaf and Penrith Lake , the AUC has
251 ( a ) Mount Victoria
( b ) Penrith Lakes
( c ) Richmond Raaf
Figure 5 : Scenario I Results : Comparing AUC of our CBFR model with FFDI model for all three weather stations . The solid lines represent CBFR while the dashed graphs represent FFDI .
( a ) Mount Victoria
( b ) Penrith Lakes
( c ) Richmond Raaf
Figure 6 : Scenario II Results : Comparing AUC of our CBFR model with FFDI model for all three weather stations . The solid lines represent CBFR while the dashed graphs represent FFDI .
( a ) Mount Victoria
( b ) Penrith Lakes
( c ) Richmond Raaf
Figure 7 : Scenario I Results : Comparing accuracy and sensitivity of CBFR model with FFDI model . Since the fires are rare events , the accuracy is biased towards not wildfire events and that is why the accuracy comparisons are close even though the CBFR model is more sensitive that the FFDI model .
( a ) Mount Victoria
( b ) Penrith Lakes
( c ) Richmond Raaf
Figure 8 : Scenario II Results : Comparing accuracy and sensitivity of CBFR model with FFDI model
00204060811 Specificity0020406081SensitivityCBFRFFDI00204060811 Specificity0020406081SensitivityCBFRFFDI00204060811 Specificity0020406081SensitivityCBFRFFDI00204060811 Specificity0020406081SensitivityCBFRFFDI00204060811 Specificity0020406081SensitivityCBFRFFDI00204060811 Specificity0020406081SensitivityCBFRFFDIAccuracySensitivity020406080100AccuracySensitivity020406080100AccuracySensitivity020406080100CBFR OptimalFFDI OptimalFFDI SevereFFDI ExtremeAccuracySensitivity020406080100AccuracySensitivity020406080100AccuracySensitivity020406080100CBFR OptimalFFDI OptimalFFDI SevereFFDI Extreme252 even decreased by 2 % ( Figure 6b ) and 1 % ( Figure 6c ) respectively .
Lastly , by comparing the results of both scenarios ( Figure 5 and Figure 6 ) it is clear that the AUC of FFDI drops in Scenario II , which shows that it fails to predict the wildfire risk patterns in advance . The AUC of CBFR on the other hand increases and hence it is more effective in predicting the wildfire risk . 4.4 Considering Risk Threshold
In this section we show how incorporating the FFDI categorisation could help in predicting the wildfire risk . As mentioned earlier , Figure 2 depicts the categorisation and interpretation of different values of the FFDI model . Currently the last two categories , namely extreme ( FFDI values between 75 and 99 ) and catastrophic ( FFDI values above 100 ) are introduced as very hot , dry and windy conditions for a wildfire in Australia and hence the periods with such characteristics are declared as total fire ban periods . This interpretation however can vary in different states of Australia and sometimes the fourth category ie , severe is also considered as a very bad wildfire condition . Hence , to set a threshold and further evaluate the FFDI ’s output , we consider both severe ( above 50 ) and extreme ( above 75 ) as thresholds and further compute the measures introduced in Section 42
In addition we compute the optimal point of ROC curves for both CBFR and FFDI to see how the performance measures change by setting a fixed threshold . Figure 7a c show the results of setting thresholds for both methods in all three different regions for Scenario I . Similarly , Figure 8a c depicts the same graphs for scenario II . Our method ’s optimal point has a very high accuracy and sensitivity in both scenarios and in all regions . FFDI on the other hand , has lower accuracy in all scenarios and regions . Moreover , it has a very low sensitivity , which suggests that it is not able to predict the high risk periods of time . The results comply with the design of the FFDI model . As mentioned in Section 2 , this model originally designed for a specific episode in a day without considering spatiotemporal variations .
While all the above results correspond to the dataset provided from Bureau of Meteorology ( BoM ) in Australia , Figure 9 shows the visualisation of the risk results by CBFR model for the dataset reproduced by high resolution meteorological reanalysis described in Section 321 As an example , we depict the results at a specific time ( 12:00:00pm on 16th October 2013 ) , which is related to 12 hours before the actual wildfire in the Blue Mountains . Three arrows in this figure point to the three weather stations depicted in Figure 4 . Note that here while building the model , only temporal context is considered .
This visualisation helps in identifying the whole central , northern and western areas on the figure as being at high risk , with a greater level of detail , while FFDI failed to identity all of these areas at risk and only flagged some increased risk in the areas that were already on fire at the time , north of Blue Mountains .
5 . DISCUSSION
In this paper we discussed the problem of wildfire risk prediction using meteorological observations . The first and most significant challenge in this problem is lack of data labels . This is difficult both in terms of designing effective analytical models on one hand , and evaluating the models on
Figure 9 : Fire risk values of CBFR model at 12:00:00pm on 16th October 2013 Blue Mountains National Park is located in the center the other hand . Even using the past wildfire histories cannot be completely sufficient as there might be some periods of time without a wildfire history but with high wildfire risk . In this paper we propose using an unsupervised learning algorithm ( anomaly detection ) as a candidate solution to this problem . Our solution does not rely on label information or expert knowledge .
The next challenge is temporal and contextual changes in meteorological observations . The existing operational models or the state of the art methods in wildfire risk literature either focus on the current weather observations and use a mathematical model to estimate the wildfire risk or use the whole historical observations to model risk . However , due to the temporal changes in the context of weather observations , in this paper we proposed to maintain multiple model of historical observations for different contexts . As a result , our context based fire risk ( CBFR ) model can predict a high risk day just in advance with 85 90 % accuracy and 99 % sensitivity in average . Figure 10 shows an example of a situation where our CBFR model estimates high risk values before the actual wildfire period , whereas the operational wildfire danger rating system in Australia postpones it to the actual wildfire day .
One lesson learned from this work was that old models that are used in various contexts and industries can benefit from applying modern analytics techniques ( in this case a context based anomaly detection algorithm ) to augment the type of knowledge they can produce and positively impact the final outcome for the benefit of the user ( in this case community as a final user of the danger risk prediction techniques ) . Potential clients of our proposed CBFR model are decision makers in emergency management agencies . Using the CBFR model can significantly help them predict high risk days beforehand and enable them to plan strategically in advance . Wildfire risk values can be also produced in variety of spatial resolutions , which gives decision makers a better understanding of wildfire risk at a high spatial as well as temporal resolution in real time .
While the proposed CBFR model has a linear time complexity and considers the memory constraints in meteorological stations , we intend to develop the parallelised version of this model using Spark to further speedup the algo
253 [ 13 ] E . Cohen and M . Strauss . Maintaining time decaying stream aggregates . In ACM SIGMOD symposium on Principles of database systems , pages 223–233 , 2003 .
[ 14 ] D . Dee , S . Uppala , A . Simmons , P . Berrisford , P . Poli , S . Kobayashi , U . Andrae , M . Balmaseda , G . Balsamo , P . Bauer , et al . The era interim reanalysis : Configuration and performance of the data assimilation system . Quarterly Journal of the Royal Meteorological Society , 137(656):553–597 , 2011 .
[ 15 ] C . A . Farris , C . Pezeshki , and L . F . Neuenschwander . A comparison of fire probability maps derived from gis modeling and direct simulation techniques . In Joint Fire Science Conference and Workshop , pages 131–138 , 1999 .
[ 16 ] M . A . Finney . The challenge of quantitative risk analysis for wildland fire . Forest Ecology and Management , 211(1):97–108 , 2005 .
[ 17 ] A . G . McArthur . Fire behaviour in eucalypt forests .
1967 .
[ 18 ] C . Miller and A . A . Ager . A review of recent advances in risk analysis for wildfire management . International journal of wildland fire , 22(1):1–14 , 2013 .
[ 19 ] M . Moshtaghi , T . C . Havens , J . C . Bezdek , L . Park ,
C . Leckie , S . Rajasegarar , J . M . Keller , and M . Palaniswami . Clustering ellipses for anomaly detection . Pattern Recognition , 44(1):55–69 , 2011 .
[ 20 ] M . Moshtaghi , S . Rajasegarar , C . Leckie , and S . Karunasekera . An efficient hyperellipsoidal clustering algorithm for resource constrained environments . Pattern Recognition , 44(9):2197–2209 , 2011 .
[ 21 ] I . Noble , A . Gill , and G . Bary . Mcarthur ’s fire danger meters expressed as equations . Australian Journal of Ecology , 5(2):201–203 , 1980 .
[ 22 ] B . Saglam , E . Bilgili , B . Dincdurmaz , A . I .
Kadiogulari , and ¨O . K¨u¸c¨uk . Spatio temporal analysis of forest fire risk and danger using landsat imagery . Sensors , 8(6):3970–3987 , 2008 .
[ 23 ] M . Salehi , C . A . Leckie , M . Moshtaghi , and
T . Vaithianathan . A relevance weighted ensemble model for anomaly detection in switching data streams . In Advances in Knowledge Discovery and Data Mining , pages 461–473 . 2014 .
[ 24 ] C . Vasilakos , K . Kalabokidis , J . Hatzopoulos , and
I . Matsinos . Identifying wildland fire ignition factors through sensitivity analysis of a neural network . Natural hazards , 50(1):125–143 , 2009 .
[ 25 ] B . Vidakovic . Statistics for bioengineering sciences : with MATLAB and WinBUGS support . Springer Science & Business Media , 2011 .
[ 26 ] L . Yu , N . Wang , and X . Meng . Real time forest fire detection with wireless sensor networks . In International Conference on Wireless Communications , Networking and Mobile Computing , volume 2 , pages 1214–1217 , 2005 .
Figure 10 : Fire risk values over 20 days of weather observations : FFDI versus CBFR models rithm . Moreover , spatially specific features ( such as vegetation type , fuel load and elevation ) can be included as an input to the CBFR algorithm to produce more sophisticated and accurate wildfire risk values in the property levels . We also intend to test our CBFR model on other areas and apply contemporary anomaly detection approaches in comparison to our proposed model .
6 . REFERENCES [ 1 ] Australian bureau of meteorology weather stations . http://wwwbomgovau/climate/cdo/about/sitesshtml
[ 2 ] Australian bureau of meteorology weather stations . http://wwwbomgovau/vic/forecasts/fire mapshtml
[ 3 ] Australian emergency management knowledge hub . https://wwwemknowledgegovau/resource/4781/2013/ bushfire new south wales 2013 . [ 4 ] Australian fire danger ratings . http://wwwesaactgovau/wp content/uploads/firedanger ratingspdf
[ 5 ] Black saturday bushfires . https://enwikipediaorg/wiki/black saturday bushfires .
[ 6 ] Emergency management victoria strategic action plan . https://wwwemvvicgovau/plans/strategic actionplan/
[ 7 ] Google maps . https://wwwgooglecomau/maps [ 8 ] The human cost of natural disasters 2015 : a global perspective , http://reliefwebint/report/world/humancost natural disasters 2015 global perspective
[ 9 ] Natural resources canada . http://cwfiscfsnrcangcca/background/summary/fwi
[ 10 ] The united nations office for disaster risk reduction , http://wwwunisdrorg/archive/42814
[ 11 ] Wildland fire assessment system . fire danger rating . http://wwwwfasnet/indexphp/fire danger ratingfire potential–danger 32
[ 12 ] P . L . Andrews , D . O . Loftsgaarden , and L . S .
Bradshaw . Evaluation of fire danger rating indexes using logistic regression and percentile analysis . International Journal of Wildland Fire , 12(2):213–226 , 2003 .
005115225Time(min)×1040020406081Risk ValueFFDICBFRFire PeriodDaysNight254
