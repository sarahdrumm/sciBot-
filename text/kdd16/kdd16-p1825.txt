Label Noise Reduction in Entity Typing by Heterogeneous Partial Label Embedding
Xiang Ren†∗ Wenqi He†∗ Meng Qu† Clare R . Voss‡ Heng Ji
Jiawei Han†
† Computer Science Department , University of Illinois at Urbana Champaign , Urbana , IL , USA
‡ Computational & Information Sciences Directorate , Army Research Laboratory , Adelphi , MD , USA
Computer Science Department , Rensselaer Polytechnic Institute , Troy , NY , USA
†{xren7 , wenqihe3 , mengqu2 , hanj}@illinois.edu ‡clarervossciv@mailmil jih@rpi.edu
ABSTRACT Current systems of fine grained entity typing use distant supervision in conjunction with existing knowledge bases to assign categories ( type labels ) to entity mentions . However , the type labels so obtained from knowledge bases are often noisy ( ie , incorrect for the entity mention ’s local context ) . We define a new task , Label Noise Reduction in Entity Typing ( LNR ) , to be the automatic identification of correct type labels ( type paths ) for training examples , given the set of candidate type labels obtained by distant supervision with a given type hierarchy . The unknown type labels for individual entity mentions and the semantic similarity between entity types pose unique challenges for solving the LNR task . We propose a general framework , called PLE , to jointly embed entity mentions , text features and entity types into the same low dimensional space where , in that space , objects whose types are semantically close have similar representations . Then we estimate the type path for each training example in a top down manner using the learned embeddings . We formulate a global objective for learning the embeddings from text corpora and knowledge bases , which adopts a novel margin based loss that is robust to noisy labels and faithfully models type correlation derived from knowledge bases . Our experiments on three public typing datasets demonstrate the effectiveness and robustness of PLE , with an average of 25 % improvement in accuracy compared to next best method . 1 .
INTRODUCTION
Entity typing is an important task in text analysis . Assigning types ( eg , person , location , organization ) to mentions of entities in documents enables effective structured analysis of unstructured text corpora . The extracted type information can be used in a wide range of ways ( eg , serving as primitives for information extraction [ 23 ] and knowledge base ( KB ) completion [ 4 ] , and assisting question answering [ 6] ) . Traditional entity typing systems [ 22 , 18 ] focus on a small set of coarse types ( typically fewer than 10 ) . Recent studies [ 34 , 14 , 35 ] work on a much larger set of fine grained ∗Equal contribution .
Figure 1 : Current systems may find Donald Trump mentioned in sentences S1 S3 and assign the same types to all ( listed within braces ) , when only some types are correct for context ( blue ) . types which form a tree structured hierarchy ( eg , actor as a subtype of artist , and artist is a subtype of person , as in blue region of Fig 1 ) . While types are usually defined to be mutually exclusive within a coarse type set ( eg , by assuming a mention cannot be both person and location ) , finegrained typing allows one mention to have multiple types , which together constitute one type path ( not necessarily ending in a leaf node ) in the given type hierarchy , depending on the local context ( eg , sentence ) . Consider the example in Fig 1 , “ Trump ” could be labeled as {person , artist , actor} in S3 ( TV show ) . But he could also be labeled as {person , politician} in S1 or {person , businessman} in S2 .
A major challenge in fine grained typing is the absence of human annotated data . The process of manually labeling a training set with large numbers of fine grained types ( usually over 100 ) is too expensive and error prone ( hard for annotators to distinguish over 100 types consistently ) . Current systems annotate training corpora automatically using knowledge bases ( ie , distant supervision ) [ 22 , 34 , 14 , 35 ] . A typical workflow of distant supervision is as follows ( see Fig 1 ) : ( 1 ) identify entity mentions in the documents ; ( 2 ) link mentions to entities in KB ; and ( 3 ) assign , to the candidate type set of each mention , all KB types of its KB linked entity . However , this approach introduces label noise to the mentions since it fails to take the semantics of the mentions’ local contexts into account when assigning type labels . For example , in Fig 1 , the types assigned to entity Trump include person , artist , actor , politician , businessman , while only {person , politician} are correct types for Trump in S1 . Many previous studies ignore the label noise in automatically labeled training corpora—all candidate types obtained
IDSentence S1S2S3 Republican presidential candidate Donald Trump spoke during a campaign event in Rock Hill . Donald Trump's company has threatened to withhold up to $1 billion of investment if the UK government decides to ban his entry into the country . In Trump ’s TV reality show , “ The Apprentice ” , 16 people competed for a jobText CorpusEntity : Donald TrumpKnowledge BasesNoisy Training ExamplesDistantSupervisionCandidate Type Set ( Sub tree)rootproductpersonlocationorganizationpoliticianartistbusinessmanauthoractorsingerTarget Type HierarchyMention : “ Donald Trump ” ; Context : S1;Candidate Types : {person , politician , businessman , artist , actor}Mention : “ Donald Trump ” ; Context : S2;Candidate Types : {person , politician , businessman , artist , actor}Mention : “ Trump ” ; Context : S3;Candidate Types : {person , politician , businessman , artist , actor}1231825 Dataset # of target types ( 1 ) noisy mentions ( % ) ( 2a ) sibling pruning ( % ) ( 2b ) min . pruning ( % ) ( 2c ) all pruning ( % )
89
47
Wiki OntoNotes BBN NYT 113 27.99 23.92 28.22 45.99
446 51.81 39.26 32.75 61.12
22.32 22.32 3.27 25.33
25.94 16.09 8.09 23.45
Table 1 : A study of type label noise . ( 1 ) : %mentions with multiple sibling types ( eg , actor , singer ) ; ( 2a) (2c ) : %mentions deleted by the three pruning heuristics [ 7 ] ( see Sec 4.1 ) , for three experiment datasets and New York Times annotation corpus [ 5 ] . by distant supervision are treated as “ true ” types in training multi label ( hierarchical ) classifiers [ 34 , 14 , 35 ] . This has become an impediment to improving the performance of current fine grained typing systems as a majority of mentions in training sets have noisy types ( see Table . 1 , row ( 1) ) . A few systems try to denoise automatically labeled training corpora by simple pruning heuristics such as deleting mentions with conflicting types [ 7 ] . However , such strategies significantly reduce the size of training set ( Table 1 , rows ( 2a c ) ) and lead to performance degradation ( later shown in our experiments ) . The larger the target type set , the more severe the loss . So far there is no effective way to automatically create high quality training data for fine grained typing .
This motivated us to define a new task : Label Noise Reduction in Entity Typing ( LNR ) , that is , identifying the correct type labels for each training example from its noisy candidate type set ( generated by distant supervision with a given type hierarchy ) . While the typical entity typing systems assume that type labels in training data are all valid and focus on designing models to predict types for unlabeled mentions , LNR focuses on identifying the correct types for automatically labeled mentions , which is related to partial label learning [ 20 , 2 ] . LNR is a fundamental task in building entity typing systems with distant supervision because it reduces the level of type label noise in the training data that , in turn , yields a better entity type classifier .
The presence of incorrect type labels in a mention ’s candidate type set poses a unique challenge to estimating the relatedness between entity mentions and types using fully/semisupervised learning methods [ 34 , 3 , 33]—co occurrence patterns alone between mentions and their candidate types in the corpus may be unreliable , as shown in our example above . We approach the LNR task as follows : ( 1 ) Model the true type labels in a candidate type set as latent variables and require only the “ best ” type ( measured under the proposed metric ) to be relevant to the mention—this requirement is less limiting compared with other multi label learning methods that assume every candidate type is relevant to the mention . ( 2 ) Extract a variety of text features from entity mentions and their local contexts , and leverage corpuslevel co occurrences between mentions and features to model mentions’ types . ( 3 ) Model type correlation ( semantic similarity ) jointly with mention candidate type associations and mention feature co occurrences , to assist type path inference , by exploiting two signals : ( i ) the given type hierarchy , and ( ii ) the shared entities between two types in KB .
To integrate these elements of our approach , a principled framework , Heterogeneous Partial Label Embedding ( PLE ) , is proposed . First , PLE constructs a heterogeneous graph to represent three kinds of objects : entity mentions , text features and entity types , and their relationships in a unified form ( see Fig 2 ) . Associations between mentions and their true types are kept as latent structures in the graph to be estimated ( Sec 31 ) We formulate a global objective to jointly embed the graph into a low dimensional space where , in that space , objects whose types are semantically close also have similar representations ( see Sec 32 ) Specifically , we design a novel margin based rank loss to model mention type as sociations , which enforces only the best candidate type to be embedded close to the mention ( thus is robust to the false candidate types ) . We further integrate the marginbased rank loss with the skip gram model [ 17 ] to jointly capture the corpus level mention feature co occurrences and the KB based type correlation in the embedding process . With the learned embeddings , we can efficiently estimate the correct type path for each entity mention in the training set in a top down manner . An efficient alternative minimization algorithm is developed to solve the optimization problem based on block wise coordinate descent [ 30 ] ( see Sec 33 ) The major contributions of this paper are as follows :
1 . This is the first systematic study of noisy type labels in distant supervision . It defines a new task , Label Noise Reduction in Entity Typing , to identify the correct typepath for each mention from its noisy candidate type set . It models and measures semantic similarity between entity mentions and type labels , and is robust to label noise .
2 . An embedding based framework , PLE , is proposed .
3 . A joint optimization problem is formulated that integrates mention type association , corpus level mention feature co occurrence , and KB based type correlation . schema YΨ ) as TΨ =((e , y ) ) ⊂ EΨ×YΨ . A target type hierar
4 . Experiments with three public fine grained typing datasets demonstrate that PLE reduces their label noise substantially and , when PLE denoised corpora are used as training sets , they also improve the performance of state ofthe art fine grained typing systems significantly . 2 . BACKGROUND AND PROBLEM The input to LNR is a knowledge base Ψ with type schema YΨ , a target type hierarchy Y which covers a subset of types in Ψ , ie , Y ⊆ YΨ , and an automatically labeled training corpus D ( obtained by distant supervision with Y ) . Knowledge Base and Target Type Hierarchy . A KB with a set of entities EΨ contains human curated facts on both entity entity facts of various relationship types and entitytype facts . We denote entity type facts in a KB Ψ ( with type chy is a tree where nodes represent types of interests from YΨ ( or types which can be uniquely mapped to those in YΨ ) . In existing entity typing studies , several fine grained type hierarchies are manually/semi automatically constructed using WordNet [ 35 ] or Freebase [ 7 , 14 ] . Automatically Labeled Training Corpora . Formally , a labeled corpus for entity typing consists of a set of extracted entity mentions M = {mi}N i=1 ( ie , token spans representing entities in text ) , the context ( eg , sentence , paragraph ) of each mention {ci}N i=1 , and the candidate type sets {Yi}N i=1 automatically generated for each mention . We represent the training corpus using a set of mention based triples D = i=1 . There exist publicly available automaticallylabeled corpora such as the Wikilinks dataset [ 26 ] where entity mentions have already been extracted and mapped to KB entities using anchor links in the corpus . In specific domains ( eg , customer reviews , tweets ) where such public datasets are unavailable , one can utilize distant supervision [ 22 , 3 , 14 ] to automatically label the corpus , where an entity linking system [ 25 ] will detect mentions mi ( in set M ) and map them to one or more entity ei in EΨ . Types of ei in KB Ψ are then associated with mi to form its candidate type set Yi , ie , Yi =(y | ( ei , y ) ∈ TΨ , y ∈ Y ) .
( (mi , ci , Yi))N
Problem Description . Since Yi is annotated for entity ei , it includes all possible types of ei and thus may contain types that are irrelevant to mi ’s specific context ci . Ideally , the
1826 Figure 2 : Framework Overview and Examples of Graph Construction .
Definition 1 with type schema YΨ and entity type facts TΨ = ( (e , y) ) , a training corpus D =((mi , ci , Yi))N type labels for mi ∈ M should form a type path ( not required to end at a leaf ) in Yi [ 34 , 7 , 35 ] , which serves as a contextdependent type annotation for mi . However , as discussed in [ 7 ] and shown in Fig 1 , Yi may contain type paths that are irrelevant to mi in ci . Even though in some cases Yi is already a type path , it may be overly specific for ci and so insufficient to infer the whole type path using ci . We denote the true type path for mention mi as Y∗ i . This work focuses on estimating Y∗ i from Yi based on mention mi as well as its context ci , where the candidate type set Yi may contain ( 1 ) types that are irrelevant to ci , and ( 2 ) types that are overly specific to ci . Formally , we define the LNR task as follows . ( Problem Definition ) . Given a KB Ψ target type hierarchy Y ⊆ YΨ , and an automatically labeled i=1 , the LNR task aims to estimate a single type path Y∗ i ⊆ Yi for each entity mention mi ∈ M , based on mi itself as well as its context ci . Non goals . Label noise may also come from incorrect mention boundaries and wrong mapping of mentions to KB entities . This work relies on existing entity linking tools [ 25 ] to provide decent entity mention detection and resolution results ( eg , leftmost column of Fig 2 ) , but we do not address their limits here . We also assume human curated target type hierarchies are given for the task ( It is out of the scope of this study to generate the type hierarchy Y ) . 3 . LABEL NOISE REDUCTION
This section lays out the framework . As the candidate type sets in the training corpus contain “ false ” types , supervised learning techniques ( eg , multi label learning [ 14 ] , hierarchical classification [ 35 ] ) may generate predictions biased to the incorrect type labels [ 7 ] . Our solution casts the problem as a weakly supervised learning task , which aims to derive the relatedness between mentions and their candidate types using both corpus level statistics and KB facts .
Specifically , each entity type is treated as an individual object to be modeled . As type assignment on each mention is noisy , we adopt ideas from partial label learning [ 2 ] to carefully model mention type associations , and extract a set of text features for each mention to assist in modeling its true types . In order to capture the semantic similarity between types , we further derive type correlation from two different sources , ie , KB and the given type hierarchy . Framework Overview . We propose a graph based partiallabel embedding framework ( see also Fig 2 ) as follows : 1 . Generate text features for each entity mention mi ∈ M , and construct a heterogeneous graph using three kinds of objects in the corpus , namely entity mentions M , target types Y and text features ( denoted as F ) , to encode aforementioned signals in a unified form ( Sec 31 )
2 . Perform joint embedding of the constructed graph G into the same low dimensional space where , in that space , close objects ( ie , whose embedding vectors have high similarity score ) tend to also share the same types ( Sec 32 )
3 . For each mention mi ( in set M ) , search its candidate type sub tree Yi in a top down manner and estimate the true type path Y∗ i from learned embeddings ( Sec 33 )
3.1 Construction of Graphs To capture the shallow syntax and distributional semantics of a mention mi ∈ M , we extract various features from both mi itself ( eg , head token ) and its context ci ( eg , bigram ) . Table 2 lists the set of text features used in this work , which is similar to those used in [ 34 , 14 ] . We denote the set of M unique features of M extracted from D as F = {fj}M j=1 . Details of feature generation are introduced in Sec 41 With entity mentions M , text features F and target types Y , we build a heterogeneous graph G to unify three kinds of links : mention type link represents each mention ’s candidate type assignment ; mention feature link captures corpuslevel co occurrences between mentions and text features ; and type type link encodes the type correlation derived from KB or target type hierarchy . This leads to three subgraphs GM Y , GM F , and GY Y , respectively . Mention Type Association Subgraph . In the automatically is assigned a set of candidate types Yi from the target type set Y . This naturally forms a bipartite graph between entity mentions M and target types Y , where each mention mi ∈ M is linked to its candidate types Yi with binary weight , ie , labeled training corpus D =((mi , ci , Yi) ) , each mention mi GM Y = ( (mi , yk ) | yk ∈ Yi , mi ∈ M ) ; wik = 1 if ( mi , yk ) ∈
GM Y and wik = 0 otherwise .
Existing embedding methods rely on either the local consistency assumption [ 9 ] ( ie , objects strongly connected tend to be similar ) , or the distributional assumption [ 17 ] ( ie , objects sharing similar neighbors tend to be similar ) to model graph structures . However , some links are “ false ” links in the constructed mention type subgraph—adopting the above assumptions may incorrectly yield mentions of different types having similar embeddings . For example , in Fig 2 , “ Hillary Clinton ” in S1 and “ Trump ” in S3 have several candidate types in common ( thus high distributional similarity ) , but their true types are different ( ie , politician versus businessman ) . Instead of defining a binary variable to indicate whether a mention type link is true or not , we specify the
State of the art Typing SystemsIDSentenceS1S2S3S4 New York City Mayor Bill de Blasio is heading to Iowa on Friday for four days to campaign for Democratic presidential candidate Hillary Clinton Republican presidential candidate Donald Trump spoke during a campaign event in Rock Hill . Trump's company has threatened to withhold up to $1 billion of investment if the UK government decides to ban his entry into the country . … , Trump announced the leaders of his presidential campaign in Louisiana on TuesdayMention : “ S1_Hillary Clinton ” ; Context : S1;Candidate Types : {person , politician , artist , author}Mention : “ S2_Donald Trump ” ; Context : S2;Candidate Types : {person , politician , businessman , artist , actor}Mention : “ S3_Trump ” ; Context : S3;Candidate Types : {person , politician , businessman , artist , actor}Mention : “ S4_Trump ” ; Context : S4;Candidate Types : {person , politician , businessman , artist , actor}Automatically Labeled Training ExamplesConstruction of GraphText CorpusMention : “ S1_Hillary Clinton ” ; Context : S1;Clean Types : {person , politician}Mention : “ S2_Donald Trump ” ; Context : S2;Clean Types : {person , politician}Mention : “ S3_Trump ” ; Context : S3;Clean Types : {person , businessman}Mention : “ S4_Trump ” ; Context : S4;Clean Types : {person , politician}Heterogeneous Partial label EmbeddingType InferenceDenoised Training ExamplesTestExamplesMulti label Perceptron;Hierarchical SVM;ClassifiersTrainingpredictionrootproductpersonlocationorganizationpoliticianartistbusinessmanauthoractorsingerMentionFeatureTypeS1_Hillary ClintonS2_Donald TrumpS3_TrumpS4_TrumppersonpoliticianartistactorbusinessmanauthorsingerHEAD_DonaldCONTEXT_candidateCONTEXT_campaignTOKEN_trumpCONTEXT_presidentialCONTEXT_republicanCONTEXT_democraticS3_TrumpS2_Donald TrumpS1_Hillary ClintonS4_TrumpbusinessmanpoliticianS2_Donald TrumppersonS3_TrumpS2_Donald TrumpEmbedding SpaceCONTEXT_campaignHEAD_donald1827 Feature Head Token POS Character Word Shape Length Context Brown Cluster Dependency
Description Syntactic head token of the mention Tokens in the mention Part of Speech tag of tokens in the mention All character trigrams in the head of the mention Word shape of the tokens in the mention Number of tokens in the mention Unigrams/bigrams before and after the mention Brown cluster ID for the head token ( learned using D ) Stanford syntactic dependency [ 16 ] associated with the head token
Example “ HEAD Turing ” “ Turing ” , “ Machine ” “ NN ” “ :tu ” , “ tur ” , , “ ng : ” “ Aa ” for “ Turing ” “ 2 ” “ CXT B:Maserati , ” , “ CXT A:and the ” “ 4 1100 ” , “ 8 1101111 ” , “ 12 111011111111 ” “ GOV:nn ” , “ GOV:turing ”
Table 2 : Text features used in this paper . “ Turing Machine ” is used as an example mention from “ The band ’s former drummer Jerry Fuchs—who was also a member of Maserati , Turing Machine and The Juan MacLean—died after falling down an elevator shaft . ” . likelihood of a mention type link being true as the relevance between the corresponding mention and type , and progressively estimate the relevance by incorporating other side signals ( eg , text features , type correlation ) . We propose to model mention type links based on the following hypothesis .
Hypothesis 1
( Partial Label Association ) . A men tion should be embedded closer to its most relevant candidate type than to any other non candidate type , yielding higher similarity between the corresponding embedding vectors .
During model learning , relevance between an entity mention and its candidate type is measured by the similarity between their current estimated embeddings . Text features , as complements to mention candidate type links , also participate in modeling the mention embeddings , and help identify a mention ’s most relevant type . In sentence S1 of Fig 2 , context words democratic and presidential infer that type politician is more relevant than type actor for mention “ Hillary Clinton ” . This hypothesis assumes that the embeddings of two mentions will be close if and only if their most relevant candidate types are similar . Mention Feature Co occurrence Subgraph . Intuitively , entity mentions sharing many text features ( ie , with similar distributions over F ) tend to have close type semantics ; and text features which co occur with many entity mentions in the corpus ( ie , with similar distributions over M ) likely represent similar entity types . The following hypothesis guides our modeling of mention text feature co occurrences .
Hypothesis 2
( Mention Feature Co occurrences ) .
If two entity mentions share similar features , they should be close to each other in the embedding space ( ie , high similarity score ) . If two features co occur with a similar set of mentions , their embedding vectors tend to be similar .
In Fig 2 , for example , mentions “ Donald Trump ” in S2 and “ Trump ” in S4 share multiple features ( eg , Trump , presidential and campaign ) , and thus are likely of the same type politician . Conversely , features campaign and presidential likely represent the same type politician since they co occur with similar sets of mentions in the corpus .
( (mi , fj ) | wij = 1 , mi ∈ M , fj ∈ F ) to denote the subgraph .
Formally , we form binary links between mentions and their text features to construct a mention feature co occurrence subgraph , ie , wij = 1 if feature fj ∈ F is extracted for mention mi ∈ M ; and wij = 0 otherwise . We use GM F = In target type hierarchy Y , Type Correlation Subgraphs . types closer to each other ( ie , shorter path ) tend to be more related ( eg , actor is more related to artist than to person in the left column of Fig 3 ) . In KB Ψ , types assigned to similar sets of entities should be more related to each other than those assigned to quite different entities [ 12 ] ( eg , actor is more related to director than to author in the right column of Fig 3 ) . We propose to model type correlation based on the following hypothesis .
Hypothesis 3
( Type Correlation ) . If high correlation exists between two target types based on either type hierarchy or KB , they should be embedded close to each other .
Figure 3 : Example of constructing type correlation graph .
We build a homogeneous graph GY Y to represent the correlation between types . A simple way to measure correlation between two types is to use their distance in the target type hierarchy ( tree ) . Specifically , a link ( yk , yk ) is formed if there exists a path between types yk and yk in Y ( paths passing root node are excluded ) . We define the weight of link
( yk , yk ) ∈ GY Y as wkk = 1/,1 + ρ(yk , yk ) , where ρ(yk , yk ) denotes the length of the shortest path between types yk and yk in Y . Although using shortest path to compute type correlation is efficient , its accuracy is limited—It is not always true that a type ( eg , athlete ) is more related to its parent type ( ie , person ) than to its sibling types ( eg , coach ) , or that all sibling types are equally related to each other ( eg , actor is more related to director than to author ) . An alternative approach to avoid this accuracy issue is to exploit entity type facts TΨ in KB to measure type correlation . Given two target types yk , yk ∈ Y , the correlation between them is proportional to the number of entities they share in the KB . Let Ek denote the set of entities assigned wkk of link ( yk , yk ) ∈ GY Y is defined as follows . with type yk in KB , ie , Ek =(e | ( e , yk ) ∈ TΨ fifi +fifiEk ∩ Ekfifi/fifiEkfifi
( 1 ) where |Ek| denotes the size of set Ek . We compare these two methods for measuring type correlation in our experiments . Entity entity facts of various relationships in the KB can also be utilized to model type correlation , as discussed in KB embedding [ 10 , 1 ] . We leave this as future work . 3.2 Heterogeneous Partial Label Embedding This section follows notations in Table 3 to formulate a joint optimization problem for embedding the constructed heterogeneous graph G into a d dimensional vector space .
) . The weight fifiEk ∩ Ekfifi/fifiEk wkk =
/2 ,
A straightforward solution is to model the whole graph with the local consistency objective [ 9 ] . Such a solution encounters several problems : False candidate types negatively impact the ability of the model to determine mention ’s true types , and the mention feature links are too sparse to model mention ’s types . As such , the learned embeddings may not accurately capture relatedness between mentions and types . In our solution , we formulate a novel optimization objective , by extending a margin based rank loss to model noisy rootproductpersonlocationorganizationcoachartistathleteauthoractordirectorExample Type Type Correlation GraphTarget Type Hierarchy ( Tree)Entity Type Facts in KBcorr(actor , person ) = 1/(1+2 ) = 1/3corr(actor , director ) = 1/(1+2 ) = 1/3corr(actor , author ) = 1/(1+2 ) = 1/3NO PATH  corr(person , location ) = 0(Ben Affleck , actor)(Ben Affleck , director)(Woody Allen , actor)(Woody Allen , director)(J . K . Rowling , author)(Kobe Bryant , athlete)Entity type factsBen AffleckWoody AllenJ . K . RowlingKobe BryantpersondirectoractorauthorathleteCorr = ( 1+1)/2=1Corr = ( 025+1)/2=0625personpoliticianartistactorbusinessmanauthorsingerdirectorathletecoach1828 i=1 k=1
D M = {mi}N Y = {yk}K Yi Y i F = {fj}M ui ∈ Rd cj ∈ Rd vk , v k ∈ Rd j=1
Automatically generated training corpus Entity mentions in D ( size N ) Target entity types ( size K ) Candidate types of mi Non candidate types of mi , ie , Y i = Y \ Yi Text features in D ( size M ) Embedding of mention mi ( dim . d ) Embedding of feature fj ( dim . d ) Embeddings of type yk on two views ( dim . d )
Table 3 : Notations . mention type links ( ie , GM Y ) and leveraging the distributional assumption [ 17 ] to model subgraphs GM F and GY Y . Modeling Mention Type Association . To effectively model the noisy mention type links in subgraph GM Y , we extend the margin based loss in [ 20 ] ( used to learn linear classifiers ) to enforce Hypothesis 1 . The intuition of the loss is simple : for mention mi , the maximum score associated with its candidate types Yi is greater than the maximum score associated with any other non candidate types Y i = Y \ Yi , where the scores are measured using current embedding vectors . Specifically , we use vectors ui , vk ∈ Rd to represent mention mi ∈ M and type yk ∈ Y in the d dimensional embedding space , respectively . The score of ( mi , yk ) is defined as the dot product of their embeddings , ie , s(mi , yk ) = vT k ui . We define the partial label loss i for mi ∈ M as follows .
0 , 1 − i = max max y∈Yi s(mi , y ) − max y∈Y i s(mi , y
)
.
( 2 )
Minimizing i encourages a large margin between the maxs(mi , y ) . This imum scores maxy∈Yi s(mi , y ) and maxy∈Y i forces mi to be embedded closer to the most “ relevant ” type in the noisy candidate type set , ie , y∗ = argmaxy∈Yi s(mi , y ) , than to any other non candidate types ( ie , Hypothesis 1 ) . This constrasts sharply with multi label learning [ 35 ] , where a large margin is enforced between all candidate types and non candidate types without considering noisy types . Modeling Mention Feature Co occurrences . Hypothesis 2 models mention feature links based on the idea that nodes with similar distributions over neighbors are similar to each other . This idea is similar to those in the second order proximity model [ 29 ] and skip gram models [ 17]—it models text corpora following the distributional hypothesis [ 8 ] which says that you should know a word by the company it keeps . Formally , we introduce vector cj ∈ Rd to represent feature fj ∈ F in the embedding space . Following second order proximity [ 29 ] , we define the probability of feature fj generated by mention mi for each link ( mi , fj ) ∈ GM F as follows . p(fj|mi ) = exp(cT exp(cT j ui ) .
( 3 ) j ui)ffi fj∈F
High conditional probability p(fj|mi ) indicates that embeddings of mi and fj are similar . Following Hypothesis 2 , we enforce the conditional distribution specified by embeddings , ie , p(·|mi ) to be close to the empirical distribution ( ie , link distribution of mi to F in subgraph GM F ) , which can be achieved by minimizing the following objective [ 29 ] .
OM F = −
( mi,fj )∈GM F wij · log p(fj|mi ) .
( 4 )
Optimizing OM F with p(fj|mi ) defined by Eq ( 3 ) is computationally expensive since it involves summation over all the features . We adopt the negative sampling method [ 17 ] to sample multiple negative features for each link ( mi , fj ) , according to some noise distribution . The method replaces log p(fj|mi ) in Eq ( 4 ) with the following function .
Similar types organization stock_exchange CXT A:Trans World organization government organization education
CXT A:Automobile Insurance CXT A:dual trading
Similar features
Table 4 : Example similar types and features for feature “ CXT B:Deutsche Bank ” based on the learned PLE embeddings .
Z
.log σ(−cT l ui)fi ,
( 5 ) log σ(cT j ui ) +
Efl∼Pn(f ) where σ(x ) = 1/,1 + exp(−x) is the sigmoid function . The z=1 f first term in Eq ( 5 ) models the observed links in GM F , and the second term models the Z negative features sampled from the noise distribution Pn(f ) ∝ D3/4 over all features F [ 17 ] . Here Df denotes the degree of feature f in GM F . Modeling Type Correlation . Type correlation links can be modeled with a method similar to that used in modeling the mention feature subgraph—two types are similar to each other if they are correlated to the same set of types ( ie , Hypothesis 3 ) . As link ( mi , fj ) in bipartite graph GM F is directed , we treat each undirected link ( yk , yk ) in the homogeneous graph GY Y as two directed links [ 28 ] . Hypothesis 3 can be modeled by minimizing the following objective .
OY Y = −
( yk,yk )∈GY Y wkk log p(yk|yk ) + log p(yk|yk )
.
This enforces the conditional distributions specified by embeddings to be close to its empirical distributions in terms of both directions of the link ( yk , yk ) . We use two vectors k ∈ Rd to represent each type yk ∈ Y in the embedvk , v ding space , where v k serves as the “ context ” view of yk [ 29 ] . Following a similar negative sampling procedure as that in Eq ( 5 ) , we define log p(yk|yk ) as follows .
Z
.log σ(−v
T vk)fi . l
( 6 ) log σ(v k
T vk ) +
Eyl∼Pn(y ) z=1
Similar to the derivation of log p(yk|yk ) in Eq ( 6 ) , we can define the log probability log p(yk|yk ) .
The Joint Optimization Problem . Our goal is to embed the heterogeneous graph G into a d dimensional vector space , following the three proposed hypotheses in Sec 31 Intuitively , one can collectively minimize the objectives of the three subgraphs GM Y , GM F and GY Y , as mentions M and types Y are shared across them . To achieve the goal , we formulate a joint optimization problem as follows .
O = OM Y + OM F + OY Y ,
( 7 )
{ui}N i=1,{cj}M min j=1,{vk,v k}K k=1 where objective OM Y of the subgraph GM Y is specified by aggregating the partial label loss defined in Eq ( 2 ) across all the mentions M , along with 2 regularizations on {ui}N and {vk}K k=1 to control the scale of the embeddings [ 20 ] . i=1
OM Y = i +
λ 2 ui2
2 +
λ 2 vk2 2 .
( 8 )
N i=1
N i=1
K k=1
Tuning parameter λ > 0 is used to control the amount of regularization on the embeddings . In Eq ( 7 ) , one can also minimize the weighted combination of the three subgraph objectives to model the importance of different signals , where weights could be manually determined or automatically learned from data . We leave this as future work . By solving the optimization problem in Eq ( 7 ) , we are able to represent every node in G with a d dimensional vector .
1829 Algorithm 1 : Model Learning of PLE Input : G = {GM Y , GM F , GY Y } , regularization parameter λ , Output : entity mention embeddings {ui}N learning rate α , number of negative samples Z i=1 , feature j=1 , type embeddings {vk}K embeddings {cj}M k=1
1 Initialize : {ui} , {cj} , and {vk} as random vectors 2 while O in Eq ( 7 ) does not converge do for each link in GM F and GY Y do
Draw Z negative links from noise distribution Pn(· ) ui ← ui − α · ∂O/∂ui with ∂O/∂ui defined in Eq ( 9 ) cj ← cj − α · ∂O/∂cj using ∂O/∂cj defined in Eq ( 10 ) vk ← vk − α · ∂O/∂vk based on ∂O/∂vk in Eq ( 11 ) k ← v v k using ∂O/∂v k − α · ∂O/∂v k in Eq ( 12 ) end for mi ∈ M do end for fj ∈ F do end for yk ∈ Y do
3
4
5
6
7
8
9
10
11
12
13
14 end
15 16 end
3.3 Model Learning and Inference
We propose an alternative minimization algorithm based on the block wise coordinate descent method [ 30 ] to jointly optimize the objective O in Eq ( 7 ) . In each iteration , the algorithm goes through links in G to sample negative links , and update each embedding based on the derivatives . We first take the derivative of O with respect to {ui} while fixing other variables . A similar procedure to that in [ 20 ] is followed to calculate the derivative for partial label loss . i − v− i ) i vk − max uT yk∈Y i uT i vk < 1
=λui + 1
∂O ∂ui max yk∈Yi
( v+ j ui)cj − Z
−
Efl∼Pn(f )[σ(cT
σ(−cT l ui)cl ]
, ( 9 ) fj∈Fi z=1 where 1(· ) denotes the indicator function , and Fi = {f | ( mi , f ) ∈ GM F } denotes features linked to mi in GM Y . We use v+ uT i vl to dei = argmaxyl∈Yi note the embeddings of the most relevant types in mi ’s candidate type set Yi and non candidate set Y i , respectively . i vl and v− uT i = argmaxyl∈Y i
The first two terms in Eq ( 9 ) adjust ui to ensure sufficient difference ( margin ) exists between its similarity to the most relevant candidate type and that to any non candidate type . The last part requires ui to be close to ( different from ) its linked ( unlinked ) features in GM F , respectively . Second , we fix {ui} and {vk} to compute the derivative of O with respect to {cj} . Let Mj = {m | ( m , fj ) ∈ GM F } denote the mentions linked to feature fj in graph GM F . ∂O ∂cj
= −
Z·|GM F |
E l=j fl∼Pn(f ) j ui)ui +
σ(−cT j u)u
σ(cT
. z=1 mi∈Mj
( 10 )
Finally , we compute the derivatives for {vk , v
The first part in Eq ( 10 ) models the observed links between feature fj and other mentions in graph GM F . The second part models negative samples drawn from links in GM F ( ie , with size Z|GM F | ) which involve feature fj . We use El=j k} by fixing other variables . We use Nk = {y | ( y , yk ) ∈ GY Y } to denote the set of types linked to type yk in graph GY Y . fl∼Pn(f )[· ] to denote the negative sampling process . · uk .σ(vT i vl − max uT yl∈Y i
−
N k − Z
Eyl∼Pn(y ) k vk)v uT i vl < 1 l vk)v
σ(−vT
∂O ∂vk
= λvk + max yl∈Yi wkk
( 11 ) i=1
1 i l fi yk∈Nk z=1
Algorithm 2 : Type Inference Input : candidate type sub tree {Yi} , mention embeddings {ui} , Output : estimated type path {Y∗ type embeddings {vk} , threshold η i } for mi ∈ M
1 for mi ∈ M do Initialize : Y∗ while Ci(r ) = ∅ do
2
3 i as ∅ , r as the root of Y if s(ui , vr ) > η then r ← argmaxyk∈Ci ( r ) s(ui , vk ) Update the type path : Y∗ return Y∗ else
{r} i ← Y∗ i i as the estimated type path for mi
4
5
6
7
8
9 end
10 11 end end where for each k the vector uk
1,yk = argmax yl∈Y i uk i =
− 1,yk = argmax i is defined as follow . uT i vl ui . uT i vl yl∈Yi
The derivative with respect to {v k} can be computed in a way similar to Eq ( 10 ) , which models both the observed links in GY Y and the negative samples of the observed links . Z·|GY Y |
= −
σ(−vT
σ(vT k vk )vk +
E l=k yl∼Pn(y ) k v)v
.
∂O ∂v k z=1 yk∈Nk
( 12 )
Algorithm 1 summarizes our algorithm . Eq ( 7 ) can also be solved by a mini batch extension of the Pegasos algorithm [ 24 ] , which is a stochastic sub gradient descent method and thus can efficiently handle massive text corpora . Due to lack of space , we do not include derivation details here . Type Inference . With the learned mention embeddings {ui} and type embeddings {vk} , we perform top down search in the candidate type sub tree Yi to estimate the correct typepath Y∗ i . Starting from the tree ’s root ( denoted as r ) , we recursively find the best type among the children types ( denoted as Ci(r ) ) by measuring the dot product of the corresponding mention and type embeddings , ie , s(ui , vk ) . The search process stops when we reach to leaf type , or the similarity score is below a pre defined threshold η > 0 . Algorithm 2 summarizes the proposed type inference process . Computational Complexity Analysis . In graph construction , the cost of building subgraph GY Y is O(K2I ) , where I is the average number of entities associated with a type in the KB . Building GM Y and GM F takes O(N ) time .
Let E be the total number of links in G . By alias table method [ 29 ] , sampling a negative link takes constant time and setting up alias tables takes O(N +M +K ) time for all the nodes in G . In each iteration of Algorithm 1 , optimization with negative sampling and partial labels takes O,d(Z+K)Eis O,dT ( Z + K)E , which is linear to the number of links E time . Supposing the algorithm stops after T iterations ( T < 50 in our experiments ) , the overall time complexity of PLE and does not depend on the number of nodes in G .
4 . EXPERIMENTS 4.1 Data Preparation and Experiment Setting Our experiments use three public datasets1 . ( 1 ) Wiki [ 14 ] : The training corpus consists of 1.5M sentences sampled from ∼780k Wikipedia articles . 434 news report sentences are 1Codes and datasets used in this paper can be downloaded at : https://githubcom/shanzhenren/PLE
,
1830 Data sets #Types #Documents #Sentences #Training mentions #Ground truth mentions #Features #Edges in graph
Wiki 113 780,549 1.51M 2.69M 563 644,860 87M
OntoNotes BBN 89 13,109 143,709 223,342 9,604 215,642 5.9M
47 2,311 48,899 109,090 121,001 125,637 2.9M
Table 5 : Statistics of the datasets . manually annotated using 113 types ( 2 level hierarchy ) to form the test data ; ( 2 ) OntoNotes [ 32 ] : It has 13,109 news documents where 77 test documents are manually annotated using 89 types ( 3 level hierarchy ) [ 7 ] ; ( 3 ) BBN [ 31 ] : It consists of 2,311 Wall Street Journal articles ( ∼48k sentences ) which are manually annotated using 93 types ( 2 level hierarchy ) . Statistics of the datasets are shown in Table 5 . Automatically Labeled Training Corpora . We followed the process introduced in [ 14 ] to generate training data for Wiki dataset . For BBN and OntoNotes datasets , we utilized DBpedia Spotlight2 , a state of the art entity linking tool , to identify entity mentions from text and map them to Freebase entries . We then applied the types induced from Freebase to each entity mention and map them to the target types . For experiment purpose , we discarded types which cannot be mapped to Freebase types in BBN dataset ( 46 out of 93 ) . Feature Generation . Table 2 lists the set of features used in our experiments , which are similar to those used in [ 34 , 14 ] except for topics and ReVerb patterns . We used a 6 word window to extract context unigrams and bigrams for each mention ( 3 words on the left and the right ) . We applied the Stanford CoreNLP tool [ 16 ] to get POS tags and dependency structures . The word clusters were derived for each corpus using the Brown clustering algorithm3 . We discarded features which occur only once in the corpus . The same kinds of features were used in both label noise reduction ( Sec 4.2 ) and fine grained entity typing ( Sec 4.3 ) experiments . Type Correlation Graphs . We used 2015 06 30 Freebase dump4 ( 1.9B triples , 115M entities , 16,701 types ) and collected 266M entity type facts ( triples with “ type.instance ” as predicate ) . Given two target types , we mapped them to Freebase types and followed the procedure introduced in Sec 3.1 to compute their KB based correlation score . Evaluation Sets . For Wiki and OntoNotes datasets , we used the provided training/test set partitions of the corpora . Since the BBN corpus is fully annotated , we followed a 80/20 ratio to partition it into training/test sets . Test sets for label noise reduction ( Sec 4.2 ) consist of mentions in the original test set which can also be linked to KB entities ( 241 , 1,190 and 32,353 mentions for Wiki , OntoNotes and BBN datasets , resp ) We further created a validation set by randomly sampling 10 % mentions from the test set and used the remaining mentions to form the evaluation set . Compared Methods . We compared the proposed method ( PLE ) with its variants which model parts of the hypotheses , and three pruning heuristics [ 7 ] . Several state of the art embedding methods and partial label learning methods were also implemented ( or tested using their published codes ) : ( 1 ) Sib [ 7 ] : removes siblings types associated with a mention . A mention is discarded if all its types are pruned ; ( 2 ) Min [ 7 ] : removes types that appear only once in the document ; ( 3 ) All [ 7 ] : first performs Sib pruning then Min pruning ; ( 4 ) DeepWalk [ 21 ] : DeepWalk is an approach for embedding a
2http://spotlightdbpediaorg/ 3https://github.com/percyliang/brown cluster 4https://developersgooglecom/freebase/data
Acc Method 0.513 Raw Sib 0.516 0.509 Min All 0.509 DeepWalk Raw 0.545 LINE Raw 0.703 0.713 WSABIE Raw PTE Raw 0.703 0.755 PLE NoCo PLE CoH 0.788 0.812 PLE
Macro R
F1
P 0.735 0.844 0.785 0.707 0.703 0.705 0.735 0.833 0.781 0.709 0.699 0.704 0.676 0.631 0.652 0.766 0.753 0.759 0.776 0.766 0.771 0.824 0.775 0.799 0.829 0.814 0.821 0.851 0.837 0.844 0.888 0.840 0.863
Micro R
F1
P 0.687 0.850 0.760 0.689 0.690 0.690 0.688 0.838 0.756 0.690 0.686 0.688 0.663 0.647 0.655 0.771 0.768 0.770 0.802 0.783 0.766 0.833 0.773 0.802 0.836 0.822 0.829 0.846 0.840 0.843 0.883 0.850 0.867
Table 6 : Performance comparisons on LNR on BBN dataset . homogeneous graph with binary edges . We applied it to the heterogeneous graph G by treating all nodes as if they had the same type ; ( 4 ) LINE [ 29 ] : We used second order LINE model and edge sampling algorithm on feature type bipartite graph ( edge weight wjk is the number of mentions having feature fj and type yk ) ; ( 5 ) WSABIE [ 34 ] : adopts WARP loss with kernel extension to learn embeddings of features and types ; ( 6 ) PTE [ 28 ] : We applied PTE joint training algorithm on subgraphs GM F and GM Y . ( 7 ) PL SVM [ 20 ] : Partial label SVM uses a margin based loss to handle label noise . ( 8 ) CLPL [ 2 ] : uses a linear model to encourage large average scores for candidate types . We adopted the suggested setting ( SVM with square hinge loss ) .
For PLE , besides the proposed model , PLE , which adopts KB based type correlation subgraph , we compare ( 1 ) PLENoCo : This variant does not consider type correlation subgraph GY Y in the objective in Eq ( 7 ) ; and ( 2 ) PLE CoH : It adopts the type hierarchy based correlation subgraph . Parameter Settings . In our testing of PLE and its variants , we set α = 0.25 , η = 0.1 and λ = 10−4 ( see Fig 4(b ) ) by default , based on the analysis on validation sets . For convergence criterion , we stopped the loop in Algorithm 1 if the relative change of O in Eq ( 7 ) is smaller than 10−4 . For fair comparison , the dimensionality of embeddings d was set to 50 and the number of negative samples ( Z in PLE ) was set to 5 for PLE , PTE and LINE , as used in [ 29 ] . For DeepWalk , we set window size as 10 , walk length as 40 , walks per vertex as 40 , as used in [ 21 ] . Learning rates of LINE and PTE were set to ρt = ρ0(1 − t/T ) with ρ0 = 0.025 where T is total number of edge samples ( set to 10 times of the number of edges ) , as used in [ 28 ] and [ 29 ] . After tuning on validation sets , we set learning rate as 0.001 for WSABIE , and set the regularization parameters in PL SVM and CLPL as 01 Evaluation Metrics . We use F1 score computed from Precision and Recall scores in 3 different granualities [ 14 , 34 ] . Let P denote evaluation set . For mention m ∈ P , we denote its ground truth types as tm and the predicted types astm . tm =tm : Accuracy ( Acc ) = m∈P 1(tm =tm)/|P| .
• Strict : The prediction is considered correct if and only if • Loose Macro : The Macro Precision ( Ma P ) and Macro|tm ∩tm|/|tm| . Recall ( Ma R ) are computed for each mention : Ma P = 1|P| • Loose Micro : The Micro Precision ( Mi P ) and MicroRecall ( Mi R ) scores are averages over all mentions , ie ,
|tm ∩tm|/|tm| and Ma R = 1|P| m∈P |tm∩tm| m∈P |tm∩tm| m∈P |tm| m∈P |tm| and Mi R =
Mi P = m∈P m∈P
.
4.2 Label Noise Reduction
We first conduct intrinsic evaluation on how accurately PLE and the other methods can estimate the true types of mentions ( ie , {Y∗ i } ) from its noisy candidate type set ( ie , {Yi} ) . Let PL denote the test mentions which can be linked to KB . We evaluate the quality of the candidate type set
1831 Wiki
Method Raw Sib [ 7 ] Min [ 7 ] All [ 7 ] DeepWalk Raw [ 21 ] LINE Raw [ 29 ] WSABIE Raw [ 34 ] PTE Raw [ 28 ] PLE NoCo PLE CoH PLE
Acc 0.373 0.373 0.373 0.373 0.328 0.349 0.332 0.419 0.556 0.568 0.589
Ma P Ma R Ma F1 Mi P Mi R Mi F1 0.681 0.614 0.719 0.605 0.558 0.521 0.636 0.653 0.583 0.578 0.608 0.613 0.679 0.717 0.561 0.524 0.615 0.606 0.634 0.585 0.651 0.581 0.608 0.614 0.459 0.367 0.598 0.595 0.519 0.454 0.596 0.610 0.600 0.590 0.598 0.600 0.609 0.633 0.554 0.557 0.580 0.592 0.597 0.607 0.678 0.686 0.635 0.644 0.668 0.678 0.795 0.804 0.730 0.732 0.808 0.805 0.671 0.704 0.752 0.732 0.840 0.675 0.833 0.705 0.749 0.763
Acc 0.480 0.487 0.481 0.487 0.441 0.549 0.482 0.529 0.593 0.620 0.639
OntoNotes
Ma P Ma R Ma F1 Mi P Mi R Mi F1 0.793 0.727 0.786 0.665 0.671 0.576 0.732 0.702 0.710 0.675 0.721 0.688 0.777 0.763 0.680 0.592 0.725 0.667 0.724 0.716 0.691 0.686 0.720 0.689 0.708 0.683 0.625 0.598 0.664 0.638 0.770 0.754 0.699 0.677 0.733 0.714 0.743 0.721 0.686 0.667 0.713 0.693 0.754 0.733 0.687 0.657 0.719 0.693 0.762 0.773 0.768 0.751 0.756 0.770 0.778 0.789 0.785 0.769 0.773 0.787 0.814 0.782 0.791 0.766 0.798 0.778
Table 7 : Performance comparisons on LNR on Wiki and OntoNotes datasets .
( ie , Raw ) , and three pruning methods on PL . For PLE and other embedding methods , we learn models on D ∪PL using the candidate types , and evaluate the estimation results on the ground truth types of PL . To test pruning methods , we further apply them on D ∪PL ( the pruned corpus is denoted as DP ) , and learn the compared embedding models on DP . 1 . Comparing PLE with the other methods . Tables 6 and 7 summarize the comparison results on the three datasets . For embedding models learned on different pruned corpora , we only show the combination that yields the best result . Overall , PLE and its variants outperform others on Accuracy , Precision and F1 scores , and achieve Recall close to that of Raw—Raw ’s Recall is the upper bound since type inference is conducted within the candidate type set . In particular , PLE obtains a 40.57 % improvement in Accuracy and 23.89 % improvement in Macro Precision compared to the best baseline PTE Raw on Wiki dataset , and improves Accuracy by 16.39 % compared to the best baseline LINE Raw , on the OntoNotes dataset . All three pruning methods suffer from low Recall because they filter conflicting subtypes ( eg , Sib ) and/or infrequent types ( eg , Min ) aggressively . Superior performance of PLE demonstrates the needs of LNR to identify true types from the candidate type sets ( versus aggressive type deletion ) . PTE utilizes heterogeneous graph structure but suffers from low Precision and Recall , since it does not handle the noisy mention candidate type links and does not model type correlation . PLE ’s performance improvement validates Hypotheses 1 and 3 . Both WSABIE and LINE aggregate feature mention type associations into feature type associations to reduce the effect of noisy types , but statistics of infrequent features may be biased due to noisy mention type links . PLE obtains superior performance because it effectively models the noisy type labels .
2 . Comparing PLE with its variants . Comparing with PLENoCo , PLE gains performance from capturing type semantic similarity with the type correlation subgraph GY Y , which assists in embedding rare types in the corpus . PLE always outperforms PLE CoH on all metrics on the three datasets . The enhancement mainly comes from modeling type correlation with entity type facts in KB , which yields more accurate and complete type correlation statistics compared to the type hierarchy based approach ( see Sec 31 )
Text
Wiki Page
Cand . type set by
NASA says it may decide tomorrow whether another space walk will be needed https://enwikipedia org/wiki/NASA person , artist , location , structure , organization , company , news_company company ,
WSABIE person , artist organization , news_company organization , company
PTE
PLE
the board of directors which are composed of twelve members directly appointed by the Queen . https://enwikipedia org/wiki/Elizabeth II person , author , politician person , artist actor , person_title , artist , person , artist person , person_title
Table 8 : Example output of PLE and the compared methods on two news sentences from the OntoNotes dataset .
3 . Example output on news articles . Table 8 shows the types estimated by PLE , PTE and WSABIE on three news sentences from OntoNotes dataset : PLE predicts fine grained types with better accuracy ( eg , person_title ) and avoids from overly specific predictions ( eg , news_company ) . 4 . Testing the effect of training set size . Experimenting with the same settings for graph construction and model learning , Fig 4(a ) shows the performance trend on Wiki dataset when varying the sampling ratio ( subset of mentions randomly sampled from the training set D ) . Performance of all methods improves as the ratio increases , and becomes insensitive as the ratio > 70 % . PLE always outperforms its variant and the best baseline PTE . In particular , PLE model trained at 10 % sampling rate outperforms the best PTE model ( obtained at 70 % sampling rate ) . 5 . Testing sensitivity of the tuning parameter . Fig 4(b ) analyzes the performance sensitivity of PLE with respect to λ—the only tuning parameter in the proposed model— on BBN dataset . Performance of PLE becomes insensitive as λ becomes small enough ( ie , 001 ) We set λ = 10−4 throughout our experiments for PLE and its variants .
( a ) Effect of training set size
( b ) Performance change wrt λ
Figure 4 : Performance change with respect to ( a ) sampling ratio of mentions from the training set on the Wiki dataset ; and ( b ) regularization parameter λ on the BBN dataset . 4.3 Fine Grained Entity Typing
We further conduct extrinsic evaluation on fine grained typing to study the performance gain from denoising the automatically generated training corpus D . Two state of theart fine grained type classifiers , HYENA [ 35 ] and FIGER [ 14 ] , are trained using the same set of features on the denoised corpus ( denoted as Dd ) , which is generated using PLE or the other compared methods . Trained classifiers are then tested on the evaluation set P . Similar to the process in Sec 4.2 , embedding models trained on pruned corpora are compared as well ( only the best performing ones ) . We also compare with partial label learning methods PL SVM [ 20 ] and CLPL [ 2 ] , which are trained on D and evaluated on P . 1 . Comparing with the other noise reduction methods . Table 9 reports the comparison results of the two best performing pruning methods and embedding methods on the three datasets . Both typing systems achieve superior performance on all metrics when using PLE and its variant to denoise the training corpus . In particular , PLE improves FIGER ’s Accuracy ( ie , Raw ) by 33.53 % and HYENA ’s Accuracy by
0505405806206607074078102030405060708090100Sample ratio ( %)Micro F1 wrt % of sampled mentionsPTEPLE NoCoPLE 00102030405060708090000001000010011100Micro F1LambdaSensitivity of PLE wrt LambdaPLE1832 Typing System N/A N/A
Noise Reduction Method PL SVM [ 20 ] CLPL [ 2 ] Raw Min [ 7 ] All [ 7 ]
HYENA [ 35 ] WSABIE Min [ 34 ]
PTE Min [ 28 ] PLE NoCo PLE Raw Min All
FIGER [ 14 ] WSABIE Min
PTE Min PLE NoCo PLE
Acc 0.428 0.162 0.288 0.325 0.417 0.199 0.238 0.517 0.543 0.474 0.453 0.453 0.455 0.476 0.543 0.599
Wiki Ma F1 0.613 0.431 0.528 0.566 0.591 0.462 0.542 0.672 0.695 0.692 0.691 0.648 0.646 0.670 0.726 0.763
Mi F1 0.571 0.411 0.506 0.536 0.545 0.459 0.522 0.634 0.681 0.655 0.631 0.582 0.601 0.635 0.705 0.749
Acc 0.465 0.438 0.249 0.295 0.305 0.400 0.452 0.496 0.546 0.369 0.373 0.400 0.425 0.494 0.547 0.572
OntoNotes
Ma F1 0.648 0.603 0.497 0.523 0.552 0.565 0.626 0.658 0.692 0.578 0.570 0.618 0.603 0.675 0.699 0.715
Mi F1 0.582 0.536 0.446 0.470 0.495 0.521 0.572 0.603 0.625 0.516 0.509 0.548 0.546 0.618 0.639 0.661
Acc 0.497 0.486 0.523 0.524 0.495 0.524 0.545 0.650 0.692 0.467 0.444 0.461 0.481 0.513 0.643 0.685
BBN
Ma F1 0.679 0.561 0.576 0.582 0.563 0.610 0.639 0.709 0.731 0.672 0.671 0.636 0.671 0.674 0.753 0.777
Mi F1 0.677 0.582 0.587 0.595 0.568 0.621 0.650 0.703 0.732 0.612 0.613 0.583 0.618 0.657 0.721 0.750
Table 9 : Study of performance improvement on fine grained typing systems FIGER [ 14 ] and HYENA [ 35 ] on the three datasets .
26.97 % on the BBN dataset . Compared to the best baseline PTE Min , PLE obtains over 28 % improvement in HYENA ’s F1 scores and over 13 % enhancement in FIGER ’s F1 scores on the Wiki dataset . Superior performance of PLE demonstrates the effectiveness of the proposed margin based loss in modeling noisy candidate types . PLE always outperforms PLE NoCo on all metrics on both typing systems . It gains performance from capturing type correlation , by jointly modeling the type type links in the embedding process . In particular , we observe that pruning methods do not always improve the performance ( eg , “ All ” pruning results in a 11.15 % drop in Macro F1 score on FIGER on the Wiki dataset ) , since they aggressively filter out subtypes and/or rare types in the corpus , which may lead to low Recall . 2 . Comparing with partial label learning methods . Comparing with PL SVM and CLPL , both typing systems obtain superior performance when PLE is applied to denoise the training corpora . PL SVM adopts a modified margin based objective to fit linear models on features using the noisy candidate types , but it assume that only one candidate type is correct and does not consider semantic similarity between the types . CLPL simply averages the model output for all candidate types , and thus may generate results biased to frequent false types . Superior performance of PLE mainly comes from jointly modeling of type correlation derived from KB and feature mention co occurrences in the corpus . 3 . Testing on unseen mentions . Fig 5 compares PLE with the other methods for predicting types of unseen mentions in the three datasets . We used the learned feature embeddings and type embeddings to estimate the type path for each mention in P . PLE outperforms both FIGER and HYENA systems ( eg , over 21 % improvement in Micro F1 on the OntoNotes dataset)—demonstrating the predictive power of the learned embeddings , and the effectiveness of modeling noisy candidate types . Although FIGER trained on PLE denoised corpus obtains superior F1 scores , PLE can achieve competitive performance without training an additional classifier ( ie , more efficiently ) .
Figure 5 : Performance comparison in terms of Micro F1 for predicting types of unseen entity mentions in the three datasets .
4.4 Case Analyses 1 . Testing at different type levels . Fig 6(a ) reports the Accuracy of PLE , PTE and WSABIE on recovering groundtruth types at different levels of the target type hierarchy Y . The results shows that it is more difficult to distinguish among deeper ( more fine grained ) types . PLE always outperforms the other two method , and achieves a 153 % improvement in Accuracy , compared to the best baseline PTE on level 3 types . The gain mainly comes from explicitly modeling the noisy candidate types , since most mentiontype links on fine grained types are false positives . 2 . Iterative re training of PLE . We re train PLE model and its variants using the corpus Dd which has been denoised by PLE , to analyze the effect of boostrapping PLE . To avoid overly low Recall , in each iteration we conduct type inference in the original candidate type set {Yi} . Fig 6(b ) shows that the performance gain becomes marginal after 3 iterations of re training . This may be because the learned embeddings in the first round of training already capture all the signals encoded in the heterogeneous graph—the updated mention type subgraph from the denoised corpus does not cause significant changes to the embeddings .
( a ) Test at different type levels
( b ) Iterative Re training
Figure 6 : Performance change of PLE ( a ) at different levels of the type hierarchy on the OntoNotes dataset ; and ( b ) with respect to the number of re training iterations on the BBN dataset . 5 . RELATED WORK Fine Grained Entity Typing . There have been extensive studies on entity recognition and typing . In terms of the dependence on context information , existing work can be categorized into context dependent [ 18 , 14 ] and context independent approaches [ 19 , 13 ] . Work along both lines can be further categorized in terms of the type granularity that is considered . Traditional named entity recognition systems [ 16 ] focus on coarse types ( eg , person , location ) and cast the problem as multi class classification following the type mutual exclusion assumption ( ie , one type per mention ) [ 18 ] . Recent work has focused on a much larger set of fine grained types [ 35 , 14 ] . As type mutual exclusion assumption no longer holds , they cast the problem as multi label multi class
050606550617069907490446051605280626066105870612068107120750010203040506070809HYENAFIGERWSABIEPLEFIGER+PLEMicro F1 on Typing Unseen Entity MentionsWikiOntoNotesBBN 0704500507904901407805101908106204800102030405060708091Level 1Level 2Level 3Accuracy on different type levelsRawWSABIEPTEPLE 0808108208308408508608708808909012345Re training IterationMicro F1 wrt Re training IterationPLE NoCoPLE1833 ( hierarchical ) classification problems [ 7 , 35 , 14 ] , or make use of various supervised embedding techniques [ 34 , 3 ] to jointly derive feature representations in classification tasks .
Most existing fine grained typing systems use distant supervision to generate training examples and assume that all candidate types so generated are correct . By contrast , our framework instead seeks to remove false positives , denoising the data and leaving only the correct ones for each mention based on its local context . Output of our task , ie , denoised training data , helps train more effective classifiers for entity typing . Gillick et al . [ 7 ] discuss the label noise issue in finegrained typing and propose three type pruning heuristics . However , these pruning methods aggressively filter training examples and may suffer from low recall ( see Table . 9 ) .
In the context of distant supervision , the label noise issue has been studied for other information extraction tasks such as relation extraction [ 27 ] and slot filling [ 11 ] . However , the form of supervision is different from that in entity typing .
Partial Label Learning . Partial label learning ( PLL ) [ 36 , 20 , 2 ] deals with the problem where each training example is associated with a set of candidate labels , where only one is correct . Unlike this PLL formulation , our problem can be seen as hierarchical classification with partial labels . Existing PLL methods model a single true label for each training example and do not consider label correlation information . We compare with simple extensions of PL SVM [ 20 ] and CLPL [ 2 ] by applying the learned partial label classifiers to predicted type paths in a top down manner ( see Table . 9 ) .
Text and Network Embedding . The proposed PLE framework incorporate embedding techniques used in modeling text data [ 34 , 3 , 17 ] , and networks/graphs [ 28 , 21 , 9 ] . However , existing methods assume links are all correct ( unsupervised ) or labels are all true ( supervised)—our approach seeks to delete noisy links and lables in the embedding process . We compare with several embedding methods like PTE [ 29 ] to validate Hypothesis 1 on noisy labels ( see Sec 42 )
6 . CONCLUSION AND FUTURE WORK
We study a new task on reducing label noise in distant supervision for fine grained entity typing , and propose a heterogeneous partial label embedding framework ( PLE ) to denoise candidate types in automatically labeled training corpora . Experiment results demonstrate that the proposed method can recover true type labels effectively and robustly , and the denoised training data can significantly enhance performance of state of the art typing systems . Interesting future work includes extending PLE ’s similarity function to model hierarchical type dependency [ 10 ] , deploying multisense embedding to model topics of contexts [ 34 ] , and exploiting relation facts in KB jointly [ 1 ] . Embeddings learned by PLE can be directly used to predict types for unseen mentions , which saves time otherwise needed to build additional classifiers . PLE is general and can be used to denoise training data in other domains ( eg , image annotation [ 33] ) .
7 . ACKNOWLEDGMENTS
Research was sponsored in part by the US Army Research Lab . under Cooperative Agreement No . W911NF09 2 0053 ( NSCTA ) , National Science Foundation IIS 1017362 , IIS 1320617 , and IIS 1354329 , HDTRA1 10 1 0120 , and grant 1U54GM114838 awarded by NIGMS through funds provided by the trans NIH Big Data to Knowledge ( BD2K ) initiative ( wwwbd2knihgov ) The views and conclusions contained in this paper are those of the authors and should not be interpreted as representing any funding agencies .
8 . REFERENCES
[ 1 ] A . Bordes , N . Usunier , A . Garcia Duran , J . Weston , and
O . Yakhnenko . Translating embeddings for modeling multi relational data . In NIPS , 2013 .
[ 2 ] T . Cour , B . Sapp , and B . Taskar . Learning from partial labels .
JMLR , 12:1501–1536 , 2011 .
[ 3 ] L . Dong , F . Wei , H . Sun , M . Zhou , and K . Xu . A hybrid neural model for type classification of entity mentions . In IJCAI , 2015 .
[ 4 ] X . L . Dong , T . Strohmann , S . Sun , and W . Zhang . Knowledge vault : A web scale approach to probabilistic knowledge fusion . In KDD , 2014 .
[ 5 ] J . Dunietz and D . Gillick . A new entity salience task with millions of training examples . EACL , 2014 .
[ 6 ] A . Fader , L . Zettlemoyer , and O . Etzioni . Open question answering over curated and extracted knowledge bases . KDD , 2014 .
[ 7 ] D . Gillick , N . Lazic , K . Ganchev , J . Kirchner , and D . Huynh .
Context dependent fine grained entity type tagging . arXiv preprint arXiv:1412.1820 , 2014 .
[ 8 ] Z . S . Harris . Distributional structure . Word , 10:146–162 , 1954 . [ 9 ] X . He and P . Niyogi . Locality preserving projections . In NIPS ,
2004 .
[ 10 ] Z . Hu , P . Huang , Y . Deng , Y . Gao , and E . P . Xing . Entity hierarchy embedding . In ACL , 2015 .
[ 11 ] H . Ji , T . Cassidy , Q . Li , and S . Tamang . Tackling representation , annotation and classification challenges for temporal knowledge base population . KIS , 41(3):611–646 , 2014 .
[ 12 ] J Y Jiang , C Y Lin , and P J Cheng . Entity driven type hierarchy construction for freebase . In WWW , 2015 .
[ 13 ] T . Lin , O . Etzioni , et al . No noun phrase left behind : detecting and typing unlinkable entities . In EMNLP , 2012 .
[ 14 ] X . Ling and D . S . Weld . Fine grained entity recognition . In
AAAI , 2012 .
[ 15 ] L . Liu and T . G . Dietterich . A conditional multinomial mixture model for superset label learning . In NIPS , 2012 .
[ 16 ] C . D . Manning , M . Surdeanu , J . Bauer , J . Finkel , S . J .
Bethard , and D . McClosky . The stanford corenlp natural language processing toolkit . ACL , 2014 .
[ 17 ] T . Mikolov , I . Sutskever , K . Chen , G . S . Corrado , and J . Dean .
Distributed representations of words and phrases and their compositionality . In NIPS , 2013 .
[ 18 ] D . Nadeau and S . Sekine . A survey of named entity recognition and classification . Lingvisticae Investigationes , 30:3–26 , 2007 .
[ 19 ] N . Nakashole , T . Tylenda , and G . Weikum . Fine grained semantic typing of emerging entities . In ACL , 2013 .
[ 20 ] N . Nguyen and R . Caruana . Classification with partial labels .
In KDD , 2008 .
[ 21 ] B . Perozzi , R . Al Rfou , and S . Skiena . Deepwalk : Online learning of social representations . In KDD , 2014 .
[ 22 ] X . Ren , A . El Kishky , C . Wang , F . Tao , C . R . Voss , and
J . Han . Clustype : Effective entity recognition and typing by relation phrase based clustering . In KDD , 2015 .
[ 23 ] M . Schmitz , R . Bart , S . Soderland , O . Etzioni , et al . Open language learning for information extraction . In EMNLP , 2012 .
[ 24 ] S . Shalev Shwartz , Y . Singer , N . Srebro , and A . Cotter . Pegasos : Primal estimated sub gradient solver for svm . Mathematical programming , 127(1):3–30 , 2011 .
[ 25 ] W . Shen , J . Wang , and J . Han . Entity linking with a knowledge base : Issues , techniques , and solutions . TKDE , ( 99):1–20 , 2014 .
[ 26 ] S . Singh , A . Subramanya , F . Pereira , and A . McCallum .
Wikilinks : A large scale cross document coreference corpus labeled via links to wikipedia . UM CS 2012 015 , 2012 .
[ 27 ] S . Takamatsu , I . Sato , and H . Nakagawa . Reducing wrong labels in distant supervision for relation extraction . In ACL , 2012 . [ 28 ] J . Tang , M . Qu , and Q . Mei . Pte : Predictive text embedding through large scale heterogeneous text networks . In KDD , 2015 . [ 29 ] J . Tang , M . Qu , M . Wang , M . Zhang , J . Yan , and Q . Mei . Line :
Large scale information network embedding . In WWW , 2015 .
[ 30 ] P . Tseng . Convergence of a block coordinate descent method for nondifferentiable minimization . JOTA , 109(3):475–494 , 2001 .
[ 31 ] R . Weischedel and A . Brunstein . Bbn pronoun coreference and entity type corpus . Linguistic Data Consortium , 112 , 2005 .
[ 32 ] R . Weischedel , E . Hovy , M . Marcus , M . Palmer , R . Belvin , S . Pradhan , L . Ramshaw , and N . Xue . Ontonotes : A large training corpus for enhanced processing . 2011 .
[ 33 ] J . Weston , S . Bengio , and N . Usunier . Wsabie : Scaling up to large vocabulary image annotation . In IJCAI , 2011 .
[ 34 ] D . Yogatama , D . Gillick , and N . Lazic . Embedding methods for fine grained entity type classification . In ACL , 2015 .
[ 35 ] M . A . Yosef , S . Bauer , J . Hoffart , M . Spaniol , and G . Weikum .
Hyena : Hierarchical type classification for entity names . In COLING , 2012 .
[ 36 ] M L Zhang . Disambiguation free partial label learning . In
SDM , 2014 .
1834
