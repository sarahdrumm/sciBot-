Smart Broadcasting : Do You Want to be Seen ?
Mohammad Reza Karimi∗ mkarimi@cesharifedu
Sharif University
Erfan Tavakoli∗ Sharif University erfantavakoli71@gmailcom
Mehrdad Farajtabar
Georgia Tech mehrdad@gatech.edu
Le Song Georgia Tech lsong@ccgatechedu
Manuel Gomez Rodriguez
MPI for Software Systems manuelgr@mpi sws.org
ABSTRACT Many users in online social networks are constantly trying to gain attention from their followers by broadcasting posts to them . These broadcasters are likely to gain greater attention if their posts can remain visible for a longer period of time among their followers’ most recent feeds . Then when to post ? In this paper , we study the problem of smart broadcasting using the framework of temporal point processes , where we model users feeds and posts as discrete events occurring in continuous time . Based on such continuoustime model , then choosing a broadcasting strategy for a user becomes a problem of designing the conditional intensity of her posting events . We derive a novel formula which links this conditional intensity with the “ visibility ” of the user in her followers’ feeds . Furthermore , by exploiting this formula , we develop an efficient convex optimization framework for the “ when to post ” problem . Our method can find broadcasting strategies that reach a desired “ visibility ” level with provable guarantees . We experimented with data gathered from Twitter , and show that our framework can consistently make broadcasters’ post more visible than alternatives .
1 .
INTRODUCTION
The popularization of social media and online social networking has empowered political parties , small and large corporations , celebrities , as well as ordinary people , with a platform to build , reach and broadcast information to their own audience . For example , political leaders use social media to present their character and personalize their message in hopes of tapping younger voters1 ; corporations increasingly rely on social media for a variety of tasks , from brand awareness to marketing and customer service [ 7 ] ; celebrities leverage social media to bring awareness to themselves and
Authors contributed equally
∗ 1http://wwwnytimescom/2012/10/08/technology/campaigns use socialmedia to lure younger votershtml strengthen their fans’ loyalty2 ; and , ordinary people post about their lives and express their opinions to gain recognition from a mix of close friends and acquaintances3 . However , social media users often follow hundreds of broadcasters , and they often receive information at a rate far higher than their cognitive abilities to process it [ 13 ] . This also means that many broadcasters actually share quite a portion of their followers , and they are constantly competing for attention from these followers .
In this context , these followers’ attention becomes a scarce commodity of great value [ 8 ] , and broadcasters would like to consume a good share of it so that their posted contents are noticed and possibly liked or shared . As a consequence , there are myriads of articles and blog entries about the best times to broadcast information in social media and social networking , as well as data analytics tools to find these times4 . However , the best time to post on social media depends on a variety of factors , often specific to the broadcaster in question , such as their followers’ daily and weekly behavior patterns , their location or timezone , and the number of broadcasters and volume of information competing for their attention in these followers’ feeds ( be it in the form of a Twitter user ’s timeline , a Facebook user ’s wall or an Instagram user ’s feed ) . Therefore , the problem of finding the best times to broadcast messages and elicit attention ( be it views , likes or shares ) , in short , the when to post problem , requires careful reasoning and smart algorithms , which have been largely inexistent until very recently [ 19 ] .
In this paper , we develop a novel framework for the whento post problem , where we measure the gained attention or visibility of a broadcaster as the time that at least one post from her is among the most recent k received stories in her followers’ feed . A desirable property of this time based visibility measure is that it is easy to estimate from real data . In order to measure the achieved visibility for a particular deployed broadcasting strategy , one only need to use a separate held out set of the followers’ feeds , independently of the broadcasted content . This is in contrast to other measures based on , eg , the number of likes or shares caused by a broadcasting strategy . These latter measures are difficult to estimate from real data and often require actual interventions , since they depend on other confounding factors such
2http://wwwwsjcom/articles/what celebrities can teach companies aboutsocial media 1444788220 3http://wwwpewinternetorg/topics/social networking/ 4http://wwwhuffingtonpostcom/catriona pollard/the best times to poston b 6990376.html , time to post on social/ and http://blogkloutcom/2015/07/whens the best
1635 as the follower ’s reaction to the post content [ 6 ] , whose effect is difficult to model accurately [ 5 ] .
More specifically , we will model users’ feeds and posts as discrete events occurring in continuous time using the framework of temporal point processes . Our model explicitly characterize the continuous time interval between posts by means of conditional intensity functions [ 1 ] . Based on such continuous time model , then choosing a strategy for a broadcaster becomes a problem of designing the conditional intensity of her posting events . We derive a novel formula which can link the conditional intensity of an arbitrary broadcaster with her visibility in her followers’ feeds . Interestingly , we can show that the average visibility is concave in the space of ( piece wise ) smooth intensity functions . Based on this result , we propose a convex optimization framework to address a diverse range of visibility shaping tasks given budget constraints . Our framework allows us to conduct fine grained control of a broadcaster ’s visibility across her followers . For instance , our framework can steer the visibility in such a way that some time intervals are favored over others , eg , times when the broadcasters’ followers are online . In addition to the novel framework , we develop an efficient gradient based optimization algorithm , which allows us to find optimal broadcast intensities for a variety of visibility shaping tasks in a matter of milliseconds . Finally , we experimented on a large real world dataset gathered from Twitter dataset , and show that our framework can consistently make broadcasters’ posts more visible than alternatives .
Related work . The work most closely related to ours is by Spasojevic et al . [ 19 ] , who introduced the when to post problem . In their work , they first perform an empirical study on the best times to post in Twitter and Facebook by analyzing more than a billion messages and responses . Then , they design several heuristics to ( independently ) pinpoint at the times that elicited the greatest number of responses in a training set and then show that these times also lead to more responses in a held out set . In our work , we measure attention by means of visibility , a measure that is not confounded with the message content and can be accurately evaluated on a held out set , and then develop a convex optimization framework to design complete broadcasting strategies that are provably optimal .
There have been an increasing number of empirical studies on understanding attention and information overload on social and information networks [ 2 , 14 , 16 , 13 ] . The common theme is to investigate whether there is a limit on the amount of ties ( eg , friends , followees or phone contacts ) people can maintain , how people distribute attention across them , and how attention influences the propagation of information . In contrast , in this work , we focus on optimizing a social media user ’s broadcasting strategy to capture the greatest attention from their followers .
Our work also relates to the influence maximization problem , extensively studied in recent years [ 18 , 15 , 4 , 10 ] , which aims to find a set of nodes in a social network whose initial adoptions of certain idea or product can trigger the largest expected number of follow ups . In this line of work , the goal is finding these influential users but not to find the best times for these users to broadcast their messages , which is our goal here . Only very recently , Farajtabar et al . [ 11 ] have developed a convex optimization framework to find broadcasting strategies , however , their focus is on steering the overall activity in the network to a certain state by incentivizing a few influential users , in contrast , we focus on maximizing visibility as measured on a broadcaster ’s audience ’s feeds .
Finally , the framework of temporal point processes , which our work builds upon , has been increasingly used to model a wide range of phenomena in social media and social networking sites , eg , from social influence [ 11 ] , network evolution [ 12 ] , opinion dynamics [ 9 ] or product competition [ 20 ] .
2 . BACKGROUND ON POINT PROCESSES A temporal point process is a stochastic process whose realization consists of a list of discrete events localized in time , {ti} with ti ∈ R+ and i ∈ Z+ . Many different types of data produced in online social networks can be represented as temporal point processes , such as the times of tweets , retweets or likes in Twitter . A temporal point process can be equivalently represented as a counting process , N ( t ) , which records the number of events before time t . Then , in a infinitesimally small time window dt around time t , the number of observed event is
δ(t − ti ) dt ,
( 1 ) ti∈H(t ) dN ( t ) = and hence N ( t ) = t
0 dN ( s ) , where δ(t ) is a Dirac delta function . It is often assumed that only one event can happen in a small window of size dt , and hence dN ( t ) ∈ {0 , 1} .
An important way to characterize temporal point processes is via the intensity function — the stochastic model for the time of the next event given all the times of previous events . The intensity function λ(t ) ( intensity , for short ) is the probability of observing an event in a small window [ t , t + dt ) , ie ,
λ(t)dt = P{event in [ t , t + dt)} .
( 2 )
Based on the intensity , one can obtain the expectation of the number of events in the windows [ t , t + dt ) and [ 0 , t ) respectively as t
E[dN ( t ) ] = λ(t ) dt , and E[N ( t ) ] =
λ(τ ) dτ
( 3 )
( 4 )
0
There is a wide variety of functional forms for the intensity λ(t ) in the growing literature on social activity modeling using point processes , which are often designed to capture the phenomena of interests . For example , retweets have been modeled using multidimensional Hawkes processes [ 11 , 22 ] , new network links have been predicted using survival processes [ 21 , 12 ] , and daily and weekly variations on message broadcasting intensities have been captured using inhomogeneous Poisson processes [ 17 ] .
In this work , since we are interested on optimizing message broadcasting intensities , we use inhomogeneous Poisson processes , whose intensity is a time varying function λ(t ) = g(t ) 0 .
3 . FROM INTENSITIES TO VISIBILITY
In this section , we will present our model for the posting times of broadcasters and the feed story arrival times of followers using point processes parameterized by intensity functions . Based on these models , we will then define our
1636 feed . For simplicity , we assume that the queue is always full at the time of modeling . In the list Hv(t ) , we keep track of the rank ruv(t ) of the most recent story posted by the broadcaster u among all the stories received by user v by time t , ie , ruv(t ) = min(i : u(i ) = u ) .
( 10 )
T
Then , given an observation time window [ 0 , T ] , and a deterministic sequence of broadcasting events , we can define the deterministic visibility of broadcaster u at k with respect to follower v as
Tuv(k ) :=
I[ruv(t ) k ] dt ,
( 11 )
0 which is the amount of times that at least one story from broadcaster u is among the most recent k stories in user v ’s feed .
Since the sequence of broadcasting events are generated from stochastic processes , we will consider the expected value of Tuv(k ) instead . If we first denote the probability that at least one story from broadcaster u is among the k most recent stories in follower v ’s feed as fuv(t , k ) = P{ruv(t ) k} ,
( 12 ) then the expected ( or average ) visibility V(k ) can be defined as
T visibility measure , and derive a novel link between the visibility measure and the intensity functions of a broadcaster and her followers .
Representation of broadcast and feed . Given a directed social network G = ( V,E ) with m = |V| users , we assume that each user can be both broadcaster and follower . Then , we will use two sets of counting processes to modeling each user ’s activity , the first set for the user ’s broadcasting activity , and the second set for the user ’s feed activity .
More specifically , we represent the broadcasting times of the users as a set of counting processes denoted by a vector N ( t ) , in which the u th dimension , Nu(t ) ∈ {0}∪Z+ , counts the number of messages user u broadcasted up to but not including time t . Then , we can characterize the message rate of these users using their corresponding intensities
E[dN ( t ) ] = λ(t ) dt .
( 5 ) Furthermore , given the adjacency matrix A ∈ {0 , 1}m×m corresponding to the social network G , where Auv = 1 indicates that v follows u , and Auv = 0 otherwise , we can represent the feed story arrival times of the users as a sum of the set of broadcasting counting processes . That is
M ( t ) = AT N ( t ) ,
( 6 ) which essentially aggregates for each user the counting processes of the broadcasters followed by this user . Then , we can characterize the feed rates using intensity functions
E[dM ( t ) ] = γ(t ) dt , where γ(t ) := AT λ(t ) = ( γ1 , . . . , γm)T .
Finally , from the perspective of a pair of broadcaster ( or user ) u and her follower v , it is useful to define the feed rate of v due to other broadcasters ( or users ) followed by v as
γv\u(t ) := γv(t ) − λu(t ) ,
( 8 ) where we assume γv\u(t ) := 0 if v does not follow u , Auv = 0 .
Definition of Visibility . Consider a broadcaster u and her follower v , and we note that v may follow many other broadcasters other than u . Thus , at any time t , user v may see stories originated from multiple broadcasters . We can model the times and origins of all these stories present in v ’s current feed as a first in first out ( FIFO ) queue5 of pairs
Hv(t ) :=((t(i ) , u(i ) ) : t t(1 ) . . . t(I−1 ) t(I ) , u(i ) ∈ N −
( v ) ) ,
( 9 ) where ·(i ) denotes the i th element in the queue , t(i ) is the time when v receives a story from broadcaster u(i ) , N −(v ) denotes the set of broadcasters followed by v , and I is the length of the queue . The length I accounts for the fact that online social platforms typically set a maximum number of stories that can be displayed in the feed , eg , currently Twitter has I = 20 . The FIFO queue is to model the fact that when a new story arrives , the oldest story , ( t(I ) , u(I) ) , at the bottom of the feed will be removed , and the ordering of the remaining stories will be shifted down by one slot , ie , i + 1 ← i ,
∀i = 1 , . . . , I − 1 and the newly arrived story will be appended to the beginning of the queue as t(1 ) and appear at the top of the 5
In this work , we assume the social network sorts stories in each user ’s feed in inverse chronological order .
Vuv(k ) := E [ Tuv(k ) ] = fuv(t , k ) dt ,
( 13 )
( 7 )
0 given the integral is well defined . In some scenarios , one may like to favor some periods of times ( eg , times in which the follower is online ) , encode such preference by means of a time significance function s(t ) 0 and consider fuv(t , k)s(t ) instead of just fuv(t , k ) . Note that the visibility Vuv(k ) is defined for a pair of broadcaster u and her follower v given k . We will focus our later exposition on a particular of u and v , and omit the subscript ·uv and simply use notation such as fk(t ) , V(k ) . However , we note that the computation of the visibility for a pair of users u and v may depend on the broadcast and feed intensities of all users in the network .
Computation of Visibility . In this section , we derive an expression for the average visibility , given by Eq 13 , using the broadcaster posting and follower feed representation , given by Eqs . 5 8 . This link is crucial for the convex visibility shaping framework in Section 5 .
Given a broadcaster u with λu(t ) = λ(t ) and her follower v with γv(t ) = γ(t ) and γv\u(t ) = µ(t ) , we first compute the probability f1(t ) that at least one message from the broadcaster is among the k = 1 most recent ones received by v at time t . By definition , one can easily realize that f1(t ) satisfies the following equation : f1(t ) ( 1 − µ(t)dt )
+ ( 1 − f1(t ) ) λ(t)dt , f1(t+dt ) =
1 . Remains the most recent
2 . Becomes the most recent ( 14 ) where each term models one of the two possible situations : 1 . The most recent message received by follower v by time t was posted by broadcaster u ( wp f1(t ) ) and none of the other broadcasters that v follows posts a message in [ t , t + dt ] ( wp 1 − µ(t)dt ) . 2 . The most recent message received by follower v by time t was posted by a different broadcaster ( wp 1 −
1637 f1(t ) ) and broadcaster u posts a message in [ t , t + dt ] ( wp λ(t)dt ) which becomes the most recent one . Then , by rearranging terms and letting dt → 0 , one finds that the probability satisfies the following differential equation :
1(t ) = −(µ(t ) + λ(t))f1(t ) + λ(t ) . f
( 15 ) fk(t + dt ) =
We can proceed with the induction step for fk(t ) with k > 1 . In particular , by definition , fk(t ) satisfies the following equation : fk−1(t )
1 . Was among k−1
+ ( 1 − fk(t))λ(t)dt ,
3 . Becomes the most recent
+ ( fk(t ) − fk−1(t))(1 − µ(t)dt )
2 . Remains on the k th position
( 16 ) where each term models one of the three possible situations : 1 . The last message posted by broadcaster u by time t is among the most recent k−1 ones received by follower v ( wp fk−1(t ) ) and , independent of whether a message is posted by any other broadcaster or not , this message will remain among the most recent k at t + dt . 2 . The last message posted by broadcaster u by time t is the k th one ( wp ( fk(t ) − fk−1(t) ) ) and none of the other broadcasters followed by v posts a message in [ t , t + dt ] ( wp 1 − µ(t)dt ) 3 . The last k messages received by follower v by time t were posted by other broadcasters ( wp 1− fk(t ) ) and broadcaster u posts a message in [ t , t+dt ] ( wp λ(t)dt ) , becoming the most recent one . By rearranging terms and letting dt → 0 , we uncover a recursive relationship between fk(t ) and fk−1(t ) , by means of the following differential equation :
( t ) = −(µ(t ) + λ(t))fk(t ) + µ(t)fk−1(t ) + λ(t ) , fk
( 17 )
Perhaps surprisingly , we can find a closed form expression for fk(t ) , given by the following Lemma ( proven in the Appendix A ) :
Lemma 1 . Given a broadcaster with message intensity λ(t ) and one of her followers with feed message intensity due to other broadcasters µ(t ) . The probability fk(t ) that at least one message from the broadcaster is among the k most recent ones received by the follower at time t can be uniquely computed as t 0 λ(τ )e− t
τ λ(x)dx Γ[k , t
( k − 1)! fk(t ) =
τ µ(x)dx ] dτ
,
( 18 )
∞ given the boundary conditions f1(0 ) = . . . = fk(0 ) = 0 and the incomplete Gamma function defined as Γ[k , x ] = x τ k−1e−τ dτ .
4 . ON THE CONCAVITY OF VISIBILITY
Once we have a formula that allows us to compute the average visibility given any arbitrary intensities for the broadcasters , we will now show that , remarkably , the average visibility is concave in the space of smooth intensity functions . Moreover , we will also show that the average visibility is concave with respect to the parameters of piecewise constant functions , which we will use in our experiments .
Smooth intensity functions . In this section , we assume that the message intensity of the broadcaster belongs to the
Figure 1 : The visibility shaping problem . A social media user u broadcast Nu(t ) messages at a rate λu(t ) . Her messages accumulate in each of her followers’ feeds , which receives Mv(t ) messages at a rate γv(t ) = λu(t ) + γv\u(t ) , where γv\u(t ) denotes the message rate due to other broadcasters v follows . For each follower , the average visibility of a user u ’s messages is defined as the time that a post from user u is among the last k stories the follower received . In the visibility shaping problem , the goal is to optimize λu(t ) to steer visibility . space H of all smooth functions . Before we proceed , we need the following definition :
Definition 2 . Given the space H of all smooth functions , a functional J : H → R is concave if for every g1 , g2 ∈ H and 0 < α < 1 :
J[αg1 + ( 1 − α)g2 ] ≥ αJ[g1 ] + ( 1 − α)J[g2 ] .
( 19 )
A functional J is convex if −J is concave .
It readily follows that the probability fk(t ) , given by Eq 18 , is a functional with λ(· ) as input . Moreover , the following two theorems , proven in Appendices B and C , establish the concavity of fk(t ) and V(k ) with respect to λ(· ) .
Theorem 3 . Given a broadcaster with message intensity λ(t ) and one of her followers with feed message intensity due to other broadcasters µ(t ) . The probability fk(t ) that at least one message from the broadcaster is among the k most recent ones received by the follower at time t , given by Eq 18 , is concave with respect to λ(· ) .
Theorem 4 . Given a broadcaster with message intensity λ(t ) and one of her followers with feed message intensity due to other broadcasters µ(t ) . The visibility V(k ) , given by Eq 13 , is concave with respect to λ(· ) .
Given the above results , one could think of finding the optimal ( general ) message intensity λ(t ) that maximize ( a function of ) the average visibilities across a broadcaster ’s followers . However , in practical applications , this may be inefficient and undesirable , instead , one may focus on a simpler parametrized family of intensities , such as piecewise constant intensity functions , which will be easier to optimize and fit using real data . To this aim , next , we prove
𝑤1𝑤2𝑢𝑣𝑤𝑚𝑀1(𝑡)𝑀2(𝑡)𝑀𝑚(𝑡)𝑀(𝑡)𝑁(𝑡)Visibility1638 that the average visibility is also concave on the parameters defining piecewise constant intensity functions .
Algorithm 1 : Projected Gradient Descent for Visibility Shaping
Piecewise constant intensity functions . In this section , we assume that the message intensity λ(t ) of the broadcaster belongs to the space of piecewise constant functions λ : [ 0 , T ] → R , denoted by G , which we parametrized as follows :
Initialize c ; repeat
1 Project c into the polytope c 0 , c1 C ; 2 Find the gradient g(c ) ; 3 Update c using the gradient g(c ) ;
λ(t ) = amI(τm−1 ≤ t < τm ) ,
( 20 ) until convergence ;
M
|J[λ ] − J[ˆλ]| <
( 21 ) maximizeλu(t )
Vuv(k )
( 24 ) where V u(k ) = ( Vuv(k))v∈N ( u)+ , N ( u)+ denotes the broadcaster u ’s followers , Vuv(k ) denotes the average visibility in m=1
Then , each piece m in the above intensities satisfies the re m=1 where am ≥ 0 , M is the number of pieces , τi−τi−1 = T /M = ∆ and τ0 = 0 .
As the reader may have noticed , the results from the previous section are not readily usable since Lemma 1 requires the intensity functions to be smooth . However , we will now show that , for every function λ(t ) ∈ G , there is a sequence of smooth functions λn(t ) ∈ H such that limn→∞ λn(t ) = λ(t ) and , this will sufficient to prove concavity . Before we proceed , we need the following definition :
Definition 5 . A functional J : G → H is said to be continuous at λ(· ) ∈ H if for every > 0 , there is a δ > 0 such that provided that ||λ − ˆλ|| < δ , where || · || is a norm in H .
It readily follows that the probability fk is a continuous functional on H . Moreover , we need the following lemma ( proven in Appendix D ) to prove the concavity :
Lemma 6 . For every λ(t ) ∈ G , there is a sequence of smooth functions λn(t ) ∈ H where limn→∞ λn(t ) = λ(t ) .
Using Lemma 6 , for any λ(t ) ∈ G , it follows that fk(λ(· ) ) = lim n→∞ fk(λn(t ) )
( 22 ) where λn(t ) is a sequence of smooth functions such that limn→∞ λn(t ) = λ(t ) . As a consequence , we can establish the concavity of fk(t ) and V(k ) with respect to a1 , . . . , aM with the following Theorem ( proven in Appendix E ) :
Theorem 7 . fk and V(k ) are concave functionals in the space of piecewise constant functions G .
Corollary 8 . If we represent λ ∈ G using Eq 20 , fk(t ) and V(k ) are concave with respect to a1 , . . . , am .
5 . CONVEX VISIBILITY SHAPING FRAME
WORK
Given the concavity of the average visibility , we now propose a convex optimization framework for a variety of visibility shaping tasks . In all these tasks , our goal is to find the optimal message intensity λu(t ) for broadcaster u that maximizes a particular nondecreasing concave utility function U ( V u(k ) ) of the average visibility of broadcaster u in all her followers within a time window [ 0 , T ] , ie , maximizeλu(t ) U ( V u(k ) ) subject to
T λu(t ) ≥ 0 t ∈ [ 0 , T ] 0 λ(t ) dt ≤ C ,
( 23 ) follower v , the first constraint asserts the intensity function remains positive , and the second limits the average number of messages broadcasted within [ 0 , T ] to be no more than C . We next discuss two instances of the general framework , which achieve different goals ( their constraints remain the same and hence omitted ) . More generally , the flexibility of our framework allows to use any nondecreasing concave utility function .
Average Visibility Maximization ( AVM ) . The goal here is to maximize the sum of the visibility for all the broadcaster ’s followers , ie , v∈N ( u)+ n
Minimax Visibility Maximization ( MVM ) . Suppose our goal is instead to keep the visibility in the n followers with the smallest visibility value above a certain minimum level , or , alternatively make the average visibility across the n followers with the smallest visibility as high as possible . Then , we can perform the following minimax visibility maximization task maximizeλu(t )
Vuv[i ] ( k ) ,
( 25 ) i=1 where Vuv[i ] ( k ) denotes the average visibility in the follower with the i th smallest visibility among all the broadcaster ’s followers .
6 . SCALABLE ALGORITHM
To solve the visibility shaping problems defined above , we need to be able to ( efficiently ) evaluate the probability function fk and visibility V(k ) . However , a direct evaluation by means of Eqs . 18 and 13 seem difficult . Here , we present an alternative representation of the probability function fk and the visibility V(k ) for piece wise constant intensity functions , which allow us to compute these quantities very efficiently . Based on this result , we present an efficient gradient based algorithm to find the optimum intensity .
Assume the broadcaster ’s message intensity λ(t ) and the follower ’s feed message intensity due to other broadcasters µ(t ) adopt the following form :
M M m=1
λ(t ) =
µ(t ) = cmI(τm−1 ≤ t < τm ) bmI(τm−1 ≤ t < τm ) .
1639 currence relation given by Eq 17 , which we rewrite as k(t ) + ( bm + cm)fk(t ) = cm + bmfk−1(t ) , f and one can easily prove by induction that , in general , the solution of the above differential equation for each time interval τm−1 ≤ t < τm is given by
( 26 ) fk(t ) = e
−(bm+cm)t(αk−1,ktk−1 + ··· + α0,k ) + βk i! ( hk−i − βk−i ) , βi = 1 − bm i bm+cm where αi,k = bi , and hi is the probability fi(τi−1 ) at the beginning of time interval . Such representation allows for an efficient evaluation of fk(t ) . Next , we also need to compute the integral of fk(t ) to efficiently compute the visibility V(k ) . Without loss of generality , we represent the time for each piece in a normalized time window [ 0 , 1 ] . Then , the integral of fk(t ) can be written as follows : V(k ) = fk(t ) dt
= βk +
αi,k
−(bm+cm)tti dt e
= βk +
0
αi,k
( bm + cm)i+1 [ i! − Γ(i + 1 , bm + cm ) ]
( 27 ) where note that the last term is efficiently computable since , for integer values of n , the incomplete Gamma function
Γ(n , x ) = ( n − 1)! e−xn−1 xi i! . i=0
Given Eq 27 , we can now easily compute the gradient of the visibility V(k ) , which we can then use to design an efficient gradient based algorithm . For brevity , we just show the gradient for k = 1 . Let c = ( c1 , . . . , cM ) , and y = ( y0 , . . . , yM−1 , yM ) be the values of fk(t ) at the beginning of each time interval , then , − ∂yi ∂ci
( bi + ci ) + ( yi − yi−1 ) + bi
∂V(1 ) ∂ci
( bi + ci)2
=
1
∂ym−1
.
− ∂ym ∂ci
1
+ bm + cm
∂ci m=i+1
0
1 k−1 k−1 i=0 i=0 where we can easily compute ∂yj/∂cm recursively as
−(bm+cm ) , e
∂cm bm bm cm
−
, if j > m .
( bm + cm )
( bm + cm)2 ym−1 −
( bm + cm)2 − if j = m , and e−(bj +cj ) ∂yj−1 Once we have an efficient way to compute the visibility V(k ) and its gradient , we can readily design a projected gradient descent algorithm to find the optimal message intensity λu(t ) in the visibility shaping problems described in Section 5 . Note that , since our optimization problems are convex , there is a unique optimum and convergence is guaranteed . Moreover , for the projection step , we solve a quadratic program , minimizing the distance to the feasible polytope . Algorithm 1 summarizes the overall algorithm . 7 . EXPERIMENTS
Dataset description and experimental setup . We use data gathered from Twitter as reported in previous work [ 3 ] , which comprises the following three types of information :
1
M profiles of 52 million users , 1.9 billion directed follow links among these users , and 1.7 billion public tweets posted by the collected users . The follow link information is based on a snapshot taken at the time of data collection , in September 2009 . Here , we focus on the tweets published during a six and a half month period , from February 2 , 2009 to August 13 , 2009 . In particular , we sample 10,000 users uniformly at random as broadcasters and record all the tweets they posted . Moreover , for each of these broadcasters , we track down all their followers and record all the tweets they posted as well as reconstruct their timelines by collecting all the tweets published by the people they follow .
In our experiments , we use the first three and a half month period , from February 2 to May 13 to fit the piecewise constant intensities of the followers’ timelines and the followers’ significance , which we use in our convex visibility shaping framework . Here , the follower ’s significance is the probability that she is on line , estimated as a piecewise ( hourly ) constant probability from the tweets retweets the follower posted – if a follower tweeted or retweeted in an hour , we assume it was on line during that hour . Then , we use the last three month period , from May 14 to August 13 , to evaluate our framework . We refer to the former period as the training set and the latter as the test set . We experiment both with T =24 hours ( M =24 , ∆=1 hour ) and T =7 days ( M =24× 7 , ∆=1 hour ) , and set the budget C to be equal to the average number of tweets per T the broadcaster posted in the training period .
Evaluation schemes . Throughout this section , we use three different evaluation schemes , with an increasing resemblance to a real world scenario :
Theoretical objective : We compute the theoretical value of the utility using the broadcaster intensity under study , be it the ( optimal ) intensity given by our convex visibility shaping framework , the intensity given by an alternative baseline , or the the broadcaster ’s ( true ) fitted intensity .
Simulated objective : We simulate events both from the broadcaster intensity under study and each of the followers’ timeline fitted intensities . Then , we estimate empirically the overall utility based on the simulated events . We perform 100 independent simulation runs and report the average and standard error ( or standard deviation ) of the utility .
Held out data : We simulate events from the broadcaster intensity under study , interleave these generated events on the true followers’ timelines recorded as test set , and compute the corresponding utility . We perform 10 independent simulation runs and report the average and standard error ( or standard deviation ) of the utility .
Intensities , top k probabilities and visibilities . We pay attention to four broadcasters , picked at random , and solve the average visibility maximization task for one of their followers , also picked at random . Our goal here is to shed light on the influence that the follower ’s timeline intensity and significance have on the optimized broadcaster ’s intensity as well as its corresponding visibility and top k probability for different values of k . Figure 2 summarizes the results , which show that ( i ) including the significance in the visibility definition shifts the optimized intensities away from the times in which the followers are not online ( first row ) ; ( ii ) the optimized intensities typically achieve a higher average visibility than the one achieved by the broadcaster ’s true posting activity on a held out set ( third row ) ; and ( iii )
1640 Figure 2 : Intensities and top k probabilities and visibilities . We focus on four broadcasters ( one per column ) and solve the AVM problem for one of their followers , picked at random . The first row shows the follower ’s timeline intensity ( µ(t ) , in brown ) fitted using events from the training set , and the optimized intensities , as given by our framework , that maximize visibility for k=1 , 20 on the training set with and without significance ( λ∗(t ) , in solid and dashed yellow and blue , respectively ) . The second row shows the top k probability for the optimized intensities with and without significance for k=1 , 20 ( f∗ k ( t ) , in solid and dashed yellow and blue ) as well as the follower ’s significance ( s(t ) , in brown ) . The third row compares the average visibility achieved by the optimized intensities without significance for k=1 , 20 ( V∗(k ) , in yellow and blue ) to the average visibility achieved by the broadcaster ’s posting activity ( V(k ) , in green and purple ) on a held out set . the optimized intensities are more concentrated in time for k = 1 ( first row ) and achieve a higher average visibility and top k probability for k = 20 ( second and third row ) .
Solution quality . In this section , we perform a large scale evaluation of our framework across all 10,000 broadcasters in terms of the three evaluation schemes described above and compare its performance against several baselines . Here , we consider the definition of visibility that incorporates significance since , as argued previously , may lead to more effective broadcasting strategies6 .
In the average visibility maximization task , we compare our framework with three heuristics , in which the broadcaster distributes the available budget uniformly at rani=1 µi(t ) ( IAVM ) and i=1 si(t)µi(t ) ( PAVM ) , respectively . In the minimax visibility maximization task , we also compare with three heuristics . The first two heuristics are similar to two of the ones just mentioned for AVM , ie , the broadcaster distributes the available budget uniformly at rani=1 µi(t ) ( IMVM ) . dom ( RAVM ) , proportionally to n proportionally to n dom ( RMVM ) and proportionally to n
6We obtain qualitatively similar results if we omit the significance in the definition of visibility . Actually , in such case , our framework beats the baselines by a greater margin . sity λ(t ) =n
In the third heuristic , the broadcaster distributes its budget following a greedy procedure : at each iteration k , it first finds the user with the least visibility given λ(k−1)(t ) and then solves the average visibility maximization for that user given a budget of C/n . Finally , it outputs the intenk=1 λ(k)(t ) . The greedy procedure starts with λ(0)(t ) = C/M . Additionally , for the held out comparison , we also compute the actual average intensity that the broadcaster achieved in reality .
Figure 3 summarizes the results by means of a box plot , which shows the utilities achieved by our framework and the heuristics normalized with respect to the utility achieved by the broadcasters’ fitted true intensity ( by the posts during the test set for the third evaluation scheme ) . That means , if y = 1 , the optimized intensity achieves the same utility as the broadcaster ’s recorded posts . For the average visibility maximization task , the intensities provided by our method achieve 1.5× higher theoretical objective and 1.3× higher utility on a held out set , in average ( black dashed line ) , than the broadcaster ’s fitted intensities . In contrast , alternatives fail at providing any gain , ie , y ≤ 1 for a half of the broadcasters . Finally , for the minimax visibility maximization task , which is significantly harder , the intensities provided by our method achieve 1.6× higher theoretical ob
06121824time00030609intensitytop 1 nosigtop 20 nosigwalltop 1 sigtop 20 sig06121824time0123intensitytop 1 nosigtop 20 nosigwalltop 1 sigtop 20 sig06121824time0123intensitytop 1 nosigtop 20 nosigwalltop 1 sigtop 20 sig06121824time00030609intensitytop 1 nosigtop 20 nosigwalltop 1 sigtop 20 sig06121824time0000000600120018f1significancetop 1 nosigtop 1 sigtop 20 nosigtop 20 sig000007014021f2006121824time00010203f1significancetop 1 nosigtop 1 sigtop 20 nosigtop 20 sig00030609f2006121824time00000000150003000045f1significancetop 1 nosigtop 1 sigtop 20 nosigtop 20 sig000004008012f2006121824time0000000200040006f1significancetop 1 nosigtop 1 sigtop 20 nosigtop 20 sig000004008012f2005101520day000006012018visibility(1)top 1 actualtop 1 nosigtop 20 actualtop 20 nosig00030609visibility(20)05101520day00020406visibility(1)top 1 actualtop 1 nosigtop 20 actualtop 20 nosig00153045visibility(20)05101520day000002004006visibility(1)top 1 actualtop 1 nosigtop 20 actualtop 20 nosig000025050075visibility(20)05101520day000007014021visibility(1)top 1 actualtop 1 nosigtop 20 actualtop 20 nosig00061218visibility(20)1641 l a c i t e r o e h T d e t a l u m S i t u o d l e H l a e R
Average Visibility
Minimax Visibility
Figure 3 : Visibility shaping for 10,000 broadcasters . The left ( right ) column corresponds to AVM ( MVM ) , evaluated using the theoretical objective ( first row ) , the simulated objective ( second row ) and the held out data ( third row ) . The red ( blue ) dashed line shows the median ( mean ) objective popularity and the box limits correspond to the 25%–75 % percentiles . a ) Followers b ) k c ) Running time
Figure 4 : The average visibility against ( a ) # of followers and ( b ) k . Panel ( c ) plots running time . jective and 1.4× higher average utility on a held out set , in average ( black dashed line ) , than the broadcaster ’s fitted intensities . In this case , although our method outperforms the baselines by large margins in terms of theoretical and simulated objectives , the baselines achieved almost the same average utility on the held out set . The theoretical and simulated objective are almost equal in all cases , as one may have expected .
Solution quality vs . # of followers . Figure 4(a ) shows the average visibilities achieved by our optimized intensities for the AVM task , normalized by the average visibility that the corresponding broadcasters’ fitted intensities achieve , against number of followers for the same 10,000 broadcasters as above . Independently of the number of followers , we find that the intensities provided by our method consistently outperform the broadcaster ’s fitted intensities . ity achieved by our optimized intensities for the AVM task against k for the four broadcasters from Figure 2 .
Scalability . Figure 4(c ) shows that our convex optimization framework easily scale to broadcasters with thousands of followers . For example , given a broadcaster with ∼2000 followers , our algorithm takes 250 milliseconds to find the optimal intensity for the average visibility maximization using a single machine with 64 cores and 1.5 TB RAM . 8 . CONCLUSIONS
In this paper , we developed a novel framework to solve the when to post problem , in which we model users’ feeds and posts as discrete events occurring in continuous time . Under such continuous time model , then choosing a strategy for a broadcaster becomes a problem of designing the conditional intensity of her posting events . The key technical idea that enables our framework is a novel formula which can link the conditional intensity of an arbitrary broadcaster with her visibility in her followers’ feeds , defined as the time that at least one post from her is among the most recent k received stories in her followers’ feed . In addition to the framework , we develop an efficient gradient based optimization algorithm , which allows us to find optimal broadcast intensities for a variety of visibility shaping tasks in a matter of seconds . Experiments on large real world data gathered from Twitter revealed that our framework can consistently make broadcasters’ posts more visible than alternatives .
Our work also opens many interesting venus for future work . For example , we assume that the social network sorts stories in each user ’s feed in inverse chronological order . While this is a realistic assumption for some social networks ( eg , Twitter ) , there are other social networks ( eg , Facebook ) where the feed is curated algorithmically . It would be very interesting to augment our framework to such cases . In this work , we model users’ intensities using inhomogeneous Poisson processes , whose intensities are history independent and deterministic . Extending our framework to point processes with stochastic and history dependent intensity functions , such as Hawkes processes , would most likely provide more effective broadcasting strategies . Finally , in this work , we validate our framework on two visibility shaping tasks , average visibility maximization and minimax visibility maximization , however , there are many other useful tasks one may think of , such as visibility homogenization .
Acknowledgements . This project was supported in part by NSF/NIH BIGDATA 1R01GM108341 , ONR N00014 151 2340 , NSF IIS 1218749 , and NSF CAREER IIS 1350983 .
9 . REFERENCES [ 1 ] O . Aalen , O . Borgan , and H . K . Gjessing . Survival and event history analysis : a process point of view . Springer , 2008 .
[ 2 ] L . Backstrom , E . Bakshy , J . M . Kleinberg , T . M .
Lento , and I . Rosenn . Center of attention : How facebook users allocate attention across friends . ICWSM , 2011 .
[ 3 ] M . Cha , H . Haddadi , F . Benevenuto , and P . K .
Gummadi . Measuring User Influence in Twitter : The Million Follower Fallacy . ICWSM , 2010 .
[ 4 ] W . Chen , C . Wang , and Y . Wang . Scalable influence
Visibility vs . k . Figure 4(b ) shows the average visibil maximization for prevalent viral marketing in
RAVMAVMPAVMIAVM051015RMVMMVMPMVMIMVM051015RAVMAVMPAVMIAVM051015RMVMMVMPMVMIMVM051015RAVMAVMPAVMIAVM051015RMVMMVMPMVMIMVM051015190018002700followers13161922VisibilityGain(Theory)05101520k144146148150VisibilityGain(Theory)0600120018002400followers050100150200250300Time(milisec)1642 large scale social networks . In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining , 2010 .
[ 20 ] I . Valera and M . Gomez Rodriguez . Modeling adoption and usage of competing products . In IEEE International Conference on Data Mining , 2015 .
[ 5 ] J . Cheng , L . Adamic , P . Dow , J . Kleinberg , and
[ 21 ] D . Vu , D . Hunter , P . Smyth , and A . Asuncion .
J . Leskovec . Can cascades be predicted ? In Proceedings of the 23rd international conference on World wide web , 2014 .
[ 6 ] T . Chenhao , L . Lee , and B . Pang . The effect of wording on message propagation : Topic and author controlled natural experiments on twitter . In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics , 2014 .
[ 7 ] E . Constantinides . Foundations of social media marketing . Procedia Social and behavioral sciences , 148:40–57 , 2014 .
[ 8 ] M . B . Crawford . The world beyond your head : On becoming an individual in an age of distraction . Macmillan , 2015 .
[ 9 ] A . De , I . Valera , N . Ganguly , S . Bhattacharya , and
M . Gomez Rodriguez . Modeling opinion dynamics in diffusion networks . arXiv preprint arXiv:1506.05474 , 2015 .
[ 10 ] N . Du , L . Song , M . Gomez Rodriguez , and H . Zha .
Scalable influence estimation in continuous time diffusion networks . In Advances in Neural Information Processing Systems , 2013 .
[ 11 ] M . Farajtabar , N . Du , M . Gomez Rodriguez , I . Valera ,
H . Zha , and L . Song . Shaping social activity by incentivizing users . In NIPS , 2014 .
[ 12 ] M . Farajtabar , Y . Wang , M . Gomez Rodriguez , S . Li , H . Zha , and L . Song . Coevolve : A joint point process model for information diffusion and network co evolution . In Advances in Neural Information Processing Systems , 2015 .
[ 13 ] M . Gomez Rodriguez , K . Gummadi , and B . Sch¨olkopf .
Quantifying information overload in social media and its impact on social contagions . In 8th International AAAI Conference on Weblogs and Social Media , 2014 .
[ 14 ] N . Hodas and K . Lerman . How visibility and divided attention constrain social contagion . SocialCom , 2012 .
[ 15 ] D . Kempe , J . Kleinberg , and ´E . Tardos . Maximizing the spread of influence through a social network . In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining , 2003 .
[ 16 ] G . Miritello , R . Lara , M . Cebrian , and E . Moro .
Limited communication capacity unveils strategies for human interaction . Scientific reports , 3 , 2013 .
[ 17 ] N . Navaroli and P . Smyth . Modeling response time in digital human communication . In Ninth International AAAI Conference on Web and Social Media , 2015 .
[ 18 ] M . Richardson and P . Domingos . Mining knowledge sharing sites for viral marketing . In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining , 2002 .
[ 19 ] N . Spasojevic , Z . Li , A . Rao , and P . Bhattacharyya .
When to post on social networks . In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 2127–2136 . ACM , 2015 .
( 28 )
( 29 )
τ µ(x)dx ] =
Continuous time regression models for longitudinal networks . In Advances in Neural Information Processing Systems , 2011 .
[ 22 ] Q . Zhao , M . Erdogdu , H . He , A . Rajaraman , and J . Leskovec . Seismic : A self exciting point process model for predicting tweet popularity . In 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , 2015 .
APPENDIX A . PROOF OF LEMMA 1
We will prove this lemma by induction on k . For the case k = 1 , f1(t ) satisfies a first order linear differential equation ,
1(t ) = −(µ(t ) + λ(t))f1(t ) + λ(t ) , f whose unique solution is t
− t
λ(τ )e f1(t ) = as long as assuming f1(t ) = 0 . Then , using that Γ[1 , t e− t
τ µ(x)dx , we can rewrite the solution as
τ ( λ+µ)(x)dx .
0 t
− t t f1(t ) =
λ(τ )e
τ λ(x)dxΓ[1 ,
µ(x)dx]dτ ,
0
τ which proves the theorem for k = 1 . Now , in the inductive step we assume the hypothesis is true for 1 , 2 , . . . k − 1 and we prove it for k . We start by rewriting the differential given by Equation 17 as fk
( t ) + ( µ(t ) + λ(t))fk(t ) = λ(t ) + µ(t)fk−1(t ) ,
( 30 ) where , by assumption , fk−1(t ) is unique and known . Then , as long as fk(0 ) = 0 , the above differential equation has a unique solution and thus we only need to find fk(t ) that satisfies it . To do so , we rewrite the right hand side of the differential equation using the inductive hypothesis as t 0 λ(τ )e− t
τ λ(x)dxΓ[k − 1 , t
( k − 2)!
τ µ(x)dx]dτ
,
λ(t ) + µ(t ) which , using Γ[k − 1 , x ] = 1 expressed as t
λ(τ )e− t
τ λ(x)dxΓ[k , t k−1 ( Γ[k , x ] + ∂Γ[k,x ] τ µ(x)dx ] + ∂Γ[k , t ∂ t
∂x
λ(t)+µ(t )
0
( k − 1)! dτ
) , can be
τ µ(x)dx
τ µ(x)dx
( 31 )
,
( 32 )
Next , we hypothesize that fk(t ) = and rewrite Eq 31 as
τ λ(x)dx Γ[k , t t 0 λ(τ )e− t µ(t ) t
0 λ(τ )e− t
( k − 1)!
λ(t ) + µ(t)fk(t ) +
τ µ(x)dx ] dτ )
τ λ(x)dx ∂Γ[k , t ∂ t ( k − 1)!
τ µ(x)dx ]
τ µ(x)dx dτ
.
( 33 )
1643 Then , by the fundamental theorem of calculus ,
Proof . We simply verify that J[λ ] satisfies the definition
− t of convexity , as given by Eq 19 : J[αλ1 + ( 1 − α)λ2 ] = e a αλ1(x)+(1−α)λ2(x ) dx − t a λ1(x ) dx + ( 1 − α)e ≤ αe = αJ[λ1 ] + ( 1 − α)J[λ2 ]
− t a λ2(x ) dx where the inequality follows from the arithmetic geometric mean inequality , ie , θx + ( 1 − θ)y ≥ xθy1−θ for all positive x , y , and 0 < θ < 1 .
Lemma 10 . If the functional Jt[λ(· ) ] is convex with respect to λ(· ) . Then , given any arbitrary function g(x ) ≥ 0 , 0 Jτ [ λ(.)]g(τ )dτ is also convex with respect to λ(· ) . the functional L[λ ] = t Proof . We verify that the functional L[λ ] = t verifies the definition of convexity , as given by Eq 19 : Jτ [ αλ1 + ( 1 − α)λ2]g(τ )dτ
L[αλ1 + ( 1 − α)λ2 ] =
0 Jτ [ λ(.)]g(τ )dτ t t
0
0
≤ α
Jτ [ λ1]g(τ )dτ t
+ ( 1 − α ) Jτ [ λ2]g(τ )dτ = αL[λ1 ] + ( 1 − α)L[λ2 ]
0 for all x ∈ D , then where the inequality holds using that , given any two arbitrary functions h1 and h2 such that h1(x ) ≥ h2(x ) ≥ 0 D h2(x)g(x)dx given g(x ) ≥ 0 for all x ∈ D .
D h1(x)g(x)dx ≥
C . PROOF OF THEOREM 4 Theorem 3 proves the concavity of fk(t ) with respect to λ(· ) . Therefore , 1− fk(t ) is convex and , using Lemma 10 , it 0 fk(t)s(t)dt is 0 fk(t)s(t)dt holds that T also convex . Then , since T
0 s(t)dt− T 0 s(t)dt is constant , T
0 ( 1−fk(t))s(t)dt = T is concave with respect to λ(· ) and the proof is complete .
D . PROOF OF LEMMA 6
Each piecewise continues function can be represented as summation of a number of heaviside step functions . The count is equal to the number of discontinuity points . However , each heaviside function itself is the limit of smooth tanh functions . Therefore , the piecewise continues function will be the limit of a finite summation of smooth tanh functions .
E . PROOF OF THEOREM 7
Consider two piecewise constant functions λ(· ) , µ(· ) ∈ G . According to Lemma 6 there exist sequence of smooth funcn = λ . Betions such that limn→∞ λn = λ and limn→∞ λ cause of the concavity of fk in H we know for 0 < α < 1 : fk[αλn(· ) + ( 1 − α)λ n(·) ] . n(· ) ] ≥ αfk[λn(· ) ] + ( 1 − α)fk[λ
Taking the limit and using the continuity of fk we get : fk[αλ(· ) + ( 1 − α)λ ( ·) ] . ( 35 ) Accompanied with convexity of space G the theorem is proved .
( · ) ] ≥ αfk[λ(· ) ] + ( 1 − α)fk[λ
∂Γ[k , t ∂ t
τ µ(x)dx ]
τ µ(x)dx and thus
λ(t ) + µ(t)fk(t ) +
∂Γ[k , t ∂Γ[k , t
=
= t 0 λ(τ )e− t
τ µ(x)dx ] ∂t
×
∂ t
∂t
τ µ(x)dx
τ µ(x)dx ] ∂t
× 1 µ(t ) τ λ(x)dx ∂Γ[k , t ( k − 1)!
τ µ(x)dx ] ∂t dτ
. ( 34 )
Finally , using that for differentiable functions g and h , gh = ( gh ) − gh , we have that
0 t t t
−
=
0
0
(
( λ(τ )e
τ λ(x)dx)(
− t ∂(λ(τ )e− t
( k−1)!(f
∂λ(τ )e− t
∂t
∂Γ[k , t τ λ(x)dxΓ[k , t t
∂t k(t)−λ(t ) )
( k−1)!λ(t)fk(t )
)(Γ[k ,
τ
τ λ(x)dx
τ µ(x)dx ] ∂t
)dτ
τ µ(x)dx ] ) dτ
µ(x)dx])dτ and then we can rewrite Eq 34 as
( k − 1)!(f k(t ) − λ(t ) ) + ( k − 1)!λ(t)fk(t )
( k − 1)!
,
λ(t ) + µ(t)fk(t ) + which simplifies to fk
( t ) + ( µ(t ) + λ(t))fk(t ) .
This asserts that hypothesized solution for fk(t ) in Eq 32 satisfies Eq 30 , hence , it is the unique solution for fk(t ) .
B . PROOF OF THEOREM 3
From Lemma 1 , we know that t 0 ( λ(τ )e− t
τ λ(x)dx)Γ[k , t
( k − 1)! fk(t ) =
τ µ(x)dx]dτ
. dτ
−
τ µ(x)dx ] ∂τ
0 µ(x)dx ]
Using integration by parts , we can rewrite the above expression as
0 λ(x)dxΓ[k , t fk(t ) = 1 − e− t t ( k − 1)! τ λ(x)dx ) ∂Γ[k , t 0 ( e− t ( k − 1)! 0 λ(x)dx and e− t Lemma 9 tells us that e− t τ λ(x)dx are conthe fact that ∂Γ[k , t vex with respect to λ(· ) . Moreover , using Lemma 10 and t τ λ(x)dx ) ∂Γ[k , t 0 ( e− t Γ[k , t > 0 , it follows that the function spect to λ(· ) . Lemma 9 . Functional J[λ ] = e− t respect to λ(· ) for any constant a ≤ t . dτ is convex . Finally , given that 0 0 ] > 0 , we can conclude that fk(t ) is concave with re a λ(x)dx is convex with
τ µ(x)dx ] ∂τ
τ µ(x)dx ] ∂τ
1644
