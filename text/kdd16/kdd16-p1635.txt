Smart Broadcasting : Do You Want to be Seen ?
Mohammad Reza Karimiâˆ— mkarimi@cesharifedu
Sharif University
Erfan Tavakoliâˆ— Sharif University erfantavakoli71@gmailcom
Mehrdad Farajtabar
Georgia Tech mehrdad@gatech.edu
Le Song Georgia Tech lsong@ccgatechedu
Manuel Gomez Rodriguez
MPI for Software Systems manuelgr@mpi sws.org
ABSTRACT Many users in online social networks are constantly trying to gain attention from their followers by broadcasting posts to them . These broadcasters are likely to gain greater attention if their posts can remain visible for a longer period of time among their followersâ€™ most recent feeds . Then when to post ? In this paper , we study the problem of smart broadcasting using the framework of temporal point processes , where we model users feeds and posts as discrete events occurring in continuous time . Based on such continuoustime model , then choosing a broadcasting strategy for a user becomes a problem of designing the conditional intensity of her posting events . We derive a novel formula which links this conditional intensity with the â€œ visibility â€ of the user in her followersâ€™ feeds . Furthermore , by exploiting this formula , we develop an efficient convex optimization framework for the â€œ when to post â€ problem . Our method can find broadcasting strategies that reach a desired â€œ visibility â€ level with provable guarantees . We experimented with data gathered from Twitter , and show that our framework can consistently make broadcastersâ€™ post more visible than alternatives .
1 .
INTRODUCTION
The popularization of social media and online social networking has empowered political parties , small and large corporations , celebrities , as well as ordinary people , with a platform to build , reach and broadcast information to their own audience . For example , political leaders use social media to present their character and personalize their message in hopes of tapping younger voters1 ; corporations increasingly rely on social media for a variety of tasks , from brand awareness to marketing and customer service [ 7 ] ; celebrities leverage social media to bring awareness to themselves and
Authors contributed equally
âˆ— 1http://wwwnytimescom/2012/10/08/technology/campaigns use socialmedia to lure younger votershtml strengthen their fansâ€™ loyalty2 ; and , ordinary people post about their lives and express their opinions to gain recognition from a mix of close friends and acquaintances3 . However , social media users often follow hundreds of broadcasters , and they often receive information at a rate far higher than their cognitive abilities to process it [ 13 ] . This also means that many broadcasters actually share quite a portion of their followers , and they are constantly competing for attention from these followers .
In this context , these followersâ€™ attention becomes a scarce commodity of great value [ 8 ] , and broadcasters would like to consume a good share of it so that their posted contents are noticed and possibly liked or shared . As a consequence , there are myriads of articles and blog entries about the best times to broadcast information in social media and social networking , as well as data analytics tools to find these times4 . However , the best time to post on social media depends on a variety of factors , often specific to the broadcaster in question , such as their followersâ€™ daily and weekly behavior patterns , their location or timezone , and the number of broadcasters and volume of information competing for their attention in these followersâ€™ feeds ( be it in the form of a Twitter user â€™s timeline , a Facebook user â€™s wall or an Instagram user â€™s feed ) . Therefore , the problem of finding the best times to broadcast messages and elicit attention ( be it views , likes or shares ) , in short , the when to post problem , requires careful reasoning and smart algorithms , which have been largely inexistent until very recently [ 19 ] .
In this paper , we develop a novel framework for the whento post problem , where we measure the gained attention or visibility of a broadcaster as the time that at least one post from her is among the most recent k received stories in her followersâ€™ feed . A desirable property of this time based visibility measure is that it is easy to estimate from real data . In order to measure the achieved visibility for a particular deployed broadcasting strategy , one only need to use a separate held out set of the followersâ€™ feeds , independently of the broadcasted content . This is in contrast to other measures based on , eg , the number of likes or shares caused by a broadcasting strategy . These latter measures are difficult to estimate from real data and often require actual interventions , since they depend on other confounding factors such
2http://wwwwsjcom/articles/what celebrities can teach companies aboutsocial media 1444788220 3http://wwwpewinternetorg/topics/social networking/ 4http://wwwhuffingtonpostcom/catriona pollard/the best times to poston b 6990376.html , time to post on social/ and http://blogkloutcom/2015/07/whens the best
1635 as the follower â€™s reaction to the post content [ 6 ] , whose effect is difficult to model accurately [ 5 ] .
More specifically , we will model usersâ€™ feeds and posts as discrete events occurring in continuous time using the framework of temporal point processes . Our model explicitly characterize the continuous time interval between posts by means of conditional intensity functions [ 1 ] . Based on such continuous time model , then choosing a strategy for a broadcaster becomes a problem of designing the conditional intensity of her posting events . We derive a novel formula which can link the conditional intensity of an arbitrary broadcaster with her visibility in her followersâ€™ feeds . Interestingly , we can show that the average visibility is concave in the space of ( piece wise ) smooth intensity functions . Based on this result , we propose a convex optimization framework to address a diverse range of visibility shaping tasks given budget constraints . Our framework allows us to conduct fine grained control of a broadcaster â€™s visibility across her followers . For instance , our framework can steer the visibility in such a way that some time intervals are favored over others , eg , times when the broadcastersâ€™ followers are online . In addition to the novel framework , we develop an efficient gradient based optimization algorithm , which allows us to find optimal broadcast intensities for a variety of visibility shaping tasks in a matter of milliseconds . Finally , we experimented on a large real world dataset gathered from Twitter dataset , and show that our framework can consistently make broadcastersâ€™ posts more visible than alternatives .
Related work . The work most closely related to ours is by Spasojevic et al . [ 19 ] , who introduced the when to post problem . In their work , they first perform an empirical study on the best times to post in Twitter and Facebook by analyzing more than a billion messages and responses . Then , they design several heuristics to ( independently ) pinpoint at the times that elicited the greatest number of responses in a training set and then show that these times also lead to more responses in a held out set . In our work , we measure attention by means of visibility , a measure that is not confounded with the message content and can be accurately evaluated on a held out set , and then develop a convex optimization framework to design complete broadcasting strategies that are provably optimal .
There have been an increasing number of empirical studies on understanding attention and information overload on social and information networks [ 2 , 14 , 16 , 13 ] . The common theme is to investigate whether there is a limit on the amount of ties ( eg , friends , followees or phone contacts ) people can maintain , how people distribute attention across them , and how attention influences the propagation of information . In contrast , in this work , we focus on optimizing a social media user â€™s broadcasting strategy to capture the greatest attention from their followers .
Our work also relates to the influence maximization problem , extensively studied in recent years [ 18 , 15 , 4 , 10 ] , which aims to find a set of nodes in a social network whose initial adoptions of certain idea or product can trigger the largest expected number of follow ups . In this line of work , the goal is finding these influential users but not to find the best times for these users to broadcast their messages , which is our goal here . Only very recently , Farajtabar et al . [ 11 ] have developed a convex optimization framework to find broadcasting strategies , however , their focus is on steering the overall activity in the network to a certain state by incentivizing a few influential users , in contrast , we focus on maximizing visibility as measured on a broadcaster â€™s audience â€™s feeds .
Finally , the framework of temporal point processes , which our work builds upon , has been increasingly used to model a wide range of phenomena in social media and social networking sites , eg , from social influence [ 11 ] , network evolution [ 12 ] , opinion dynamics [ 9 ] or product competition [ 20 ] .
2 . BACKGROUND ON POINT PROCESSES A temporal point process is a stochastic process whose realization consists of a list of discrete events localized in time , {ti} with ti âˆˆ R+ and i âˆˆ Z+ . Many different types of data produced in online social networks can be represented as temporal point processes , such as the times of tweets , retweets or likes in Twitter . A temporal point process can be equivalently represented as a counting process , N ( t ) , which records the number of events before time t . Then , in a infinitesimally small time window dt around time t , the number of observed event is
Î´(t âˆ’ ti ) dt ,
( 1 ) tiâˆˆH(t ) dN ( t ) = and hence N ( t ) = t
0 dN ( s ) , where Î´(t ) is a Dirac delta function . It is often assumed that only one event can happen in a small window of size dt , and hence dN ( t ) âˆˆ {0 , 1} .
An important way to characterize temporal point processes is via the intensity function â€” the stochastic model for the time of the next event given all the times of previous events . The intensity function Î»(t ) ( intensity , for short ) is the probability of observing an event in a small window [ t , t + dt ) , ie ,
Î»(t)dt = P{event in [ t , t + dt)} .
( 2 )
Based on the intensity , one can obtain the expectation of the number of events in the windows [ t , t + dt ) and [ 0 , t ) respectively as t
E[dN ( t ) ] = Î»(t ) dt , and E[N ( t ) ] =
Î»(Ï„ ) dÏ„
( 3 )
( 4 )
0
There is a wide variety of functional forms for the intensity Î»(t ) in the growing literature on social activity modeling using point processes , which are often designed to capture the phenomena of interests . For example , retweets have been modeled using multidimensional Hawkes processes [ 11 , 22 ] , new network links have been predicted using survival processes [ 21 , 12 ] , and daily and weekly variations on message broadcasting intensities have been captured using inhomogeneous Poisson processes [ 17 ] .
In this work , since we are interested on optimizing message broadcasting intensities , we use inhomogeneous Poisson processes , whose intensity is a time varying function Î»(t ) = g(t ) 0 .
3 . FROM INTENSITIES TO VISIBILITY
In this section , we will present our model for the posting times of broadcasters and the feed story arrival times of followers using point processes parameterized by intensity functions . Based on these models , we will then define our
1636 feed . For simplicity , we assume that the queue is always full at the time of modeling . In the list Hv(t ) , we keep track of the rank ruv(t ) of the most recent story posted by the broadcaster u among all the stories received by user v by time t , ie , ruv(t ) = min(i : u(i ) = u ) .
( 10 )
T
Then , given an observation time window [ 0 , T ] , and a deterministic sequence of broadcasting events , we can define the deterministic visibility of broadcaster u at k with respect to follower v as
Tuv(k ) :=
I[ruv(t ) k ] dt ,
( 11 )
0 which is the amount of times that at least one story from broadcaster u is among the most recent k stories in user v â€™s feed .
Since the sequence of broadcasting events are generated from stochastic processes , we will consider the expected value of Tuv(k ) instead . If we first denote the probability that at least one story from broadcaster u is among the k most recent stories in follower v â€™s feed as fuv(t , k ) = P{ruv(t ) k} ,
( 12 ) then the expected ( or average ) visibility V(k ) can be defined as
T visibility measure , and derive a novel link between the visibility measure and the intensity functions of a broadcaster and her followers .
Representation of broadcast and feed . Given a directed social network G = ( V,E ) with m = |V| users , we assume that each user can be both broadcaster and follower . Then , we will use two sets of counting processes to modeling each user â€™s activity , the first set for the user â€™s broadcasting activity , and the second set for the user â€™s feed activity .
More specifically , we represent the broadcasting times of the users as a set of counting processes denoted by a vector N ( t ) , in which the u th dimension , Nu(t ) âˆˆ {0}âˆªZ+ , counts the number of messages user u broadcasted up to but not including time t . Then , we can characterize the message rate of these users using their corresponding intensities
E[dN ( t ) ] = Î»(t ) dt .
( 5 ) Furthermore , given the adjacency matrix A âˆˆ {0 , 1}mÃ—m corresponding to the social network G , where Auv = 1 indicates that v follows u , and Auv = 0 otherwise , we can represent the feed story arrival times of the users as a sum of the set of broadcasting counting processes . That is
M ( t ) = AT N ( t ) ,
( 6 ) which essentially aggregates for each user the counting processes of the broadcasters followed by this user . Then , we can characterize the feed rates using intensity functions
E[dM ( t ) ] = Î³(t ) dt , where Î³(t ) := AT Î»(t ) = ( Î³1 , . . . , Î³m)T .
Finally , from the perspective of a pair of broadcaster ( or user ) u and her follower v , it is useful to define the feed rate of v due to other broadcasters ( or users ) followed by v as
Î³v\u(t ) := Î³v(t ) âˆ’ Î»u(t ) ,
( 8 ) where we assume Î³v\u(t ) := 0 if v does not follow u , Auv = 0 .
Definition of Visibility . Consider a broadcaster u and her follower v , and we note that v may follow many other broadcasters other than u . Thus , at any time t , user v may see stories originated from multiple broadcasters . We can model the times and origins of all these stories present in v â€™s current feed as a first in first out ( FIFO ) queue5 of pairs
Hv(t ) :=((t(i ) , u(i ) ) : t t(1 ) . . . t(Iâˆ’1 ) t(I ) , u(i ) âˆˆ N âˆ’
( v ) ) ,
( 9 ) where Â·(i ) denotes the i th element in the queue , t(i ) is the time when v receives a story from broadcaster u(i ) , N âˆ’(v ) denotes the set of broadcasters followed by v , and I is the length of the queue . The length I accounts for the fact that online social platforms typically set a maximum number of stories that can be displayed in the feed , eg , currently Twitter has I = 20 . The FIFO queue is to model the fact that when a new story arrives , the oldest story , ( t(I ) , u(I) ) , at the bottom of the feed will be removed , and the ordering of the remaining stories will be shifted down by one slot , ie , i + 1 â† i ,
âˆ€i = 1 , . . . , I âˆ’ 1 and the newly arrived story will be appended to the beginning of the queue as t(1 ) and appear at the top of the 5
In this work , we assume the social network sorts stories in each user â€™s feed in inverse chronological order .
Vuv(k ) := E [ Tuv(k ) ] = fuv(t , k ) dt ,
( 13 )
( 7 )
0 given the integral is well defined . In some scenarios , one may like to favor some periods of times ( eg , times in which the follower is online ) , encode such preference by means of a time significance function s(t ) 0 and consider fuv(t , k)s(t ) instead of just fuv(t , k ) . Note that the visibility Vuv(k ) is defined for a pair of broadcaster u and her follower v given k . We will focus our later exposition on a particular of u and v , and omit the subscript Â·uv and simply use notation such as fk(t ) , V(k ) . However , we note that the computation of the visibility for a pair of users u and v may depend on the broadcast and feed intensities of all users in the network .
Computation of Visibility . In this section , we derive an expression for the average visibility , given by Eq 13 , using the broadcaster posting and follower feed representation , given by Eqs . 5 8 . This link is crucial for the convex visibility shaping framework in Section 5 .
Given a broadcaster u with Î»u(t ) = Î»(t ) and her follower v with Î³v(t ) = Î³(t ) and Î³v\u(t ) = Âµ(t ) , we first compute the probability f1(t ) that at least one message from the broadcaster is among the k = 1 most recent ones received by v at time t . By definition , one can easily realize that f1(t ) satisfies the following equation : f1(t ) ( 1 âˆ’ Âµ(t)dt )
+ ( 1 âˆ’ f1(t ) ) Î»(t)dt , f1(t+dt ) =
1 . Remains the most recent
2 . Becomes the most recent ( 14 ) where each term models one of the two possible situations : 1 . The most recent message received by follower v by time t was posted by broadcaster u ( wp f1(t ) ) and none of the other broadcasters that v follows posts a message in [ t , t + dt ] ( wp 1 âˆ’ Âµ(t)dt ) . 2 . The most recent message received by follower v by time t was posted by a different broadcaster ( wp 1 âˆ’
1637 f1(t ) ) and broadcaster u posts a message in [ t , t + dt ] ( wp Î»(t)dt ) which becomes the most recent one . Then , by rearranging terms and letting dt â†’ 0 , one finds that the probability satisfies the following differential equation :
1(t ) = âˆ’(Âµ(t ) + Î»(t))f1(t ) + Î»(t ) . f
( 15 ) fk(t + dt ) =
We can proceed with the induction step for fk(t ) with k > 1 . In particular , by definition , fk(t ) satisfies the following equation : fkâˆ’1(t )
1 . Was among kâˆ’1
+ ( 1 âˆ’ fk(t))Î»(t)dt ,
3 . Becomes the most recent
+ ( fk(t ) âˆ’ fkâˆ’1(t))(1 âˆ’ Âµ(t)dt )
2 . Remains on the k th position
( 16 ) where each term models one of the three possible situations : 1 . The last message posted by broadcaster u by time t is among the most recent kâˆ’1 ones received by follower v ( wp fkâˆ’1(t ) ) and , independent of whether a message is posted by any other broadcaster or not , this message will remain among the most recent k at t + dt . 2 . The last message posted by broadcaster u by time t is the k th one ( wp ( fk(t ) âˆ’ fkâˆ’1(t) ) ) and none of the other broadcasters followed by v posts a message in [ t , t + dt ] ( wp 1 âˆ’ Âµ(t)dt ) 3 . The last k messages received by follower v by time t were posted by other broadcasters ( wp 1âˆ’ fk(t ) ) and broadcaster u posts a message in [ t , t+dt ] ( wp Î»(t)dt ) , becoming the most recent one . By rearranging terms and letting dt â†’ 0 , we uncover a recursive relationship between fk(t ) and fkâˆ’1(t ) , by means of the following differential equation :
( t ) = âˆ’(Âµ(t ) + Î»(t))fk(t ) + Âµ(t)fkâˆ’1(t ) + Î»(t ) , fk
( 17 )
Perhaps surprisingly , we can find a closed form expression for fk(t ) , given by the following Lemma ( proven in the Appendix A ) :
Lemma 1 . Given a broadcaster with message intensity Î»(t ) and one of her followers with feed message intensity due to other broadcasters Âµ(t ) . The probability fk(t ) that at least one message from the broadcaster is among the k most recent ones received by the follower at time t can be uniquely computed as t 0 Î»(Ï„ )eâˆ’ t
Ï„ Î»(x)dx Î“[k , t
( k âˆ’ 1)! fk(t ) =
Ï„ Âµ(x)dx ] dÏ„
,
( 18 )
âˆž given the boundary conditions f1(0 ) = . . . = fk(0 ) = 0 and the incomplete Gamma function defined as Î“[k , x ] = x Ï„ kâˆ’1eâˆ’Ï„ dÏ„ .
4 . ON THE CONCAVITY OF VISIBILITY
Once we have a formula that allows us to compute the average visibility given any arbitrary intensities for the broadcasters , we will now show that , remarkably , the average visibility is concave in the space of smooth intensity functions . Moreover , we will also show that the average visibility is concave with respect to the parameters of piecewise constant functions , which we will use in our experiments .
Smooth intensity functions . In this section , we assume that the message intensity of the broadcaster belongs to the
Figure 1 : The visibility shaping problem . A social media user u broadcast Nu(t ) messages at a rate Î»u(t ) . Her messages accumulate in each of her followersâ€™ feeds , which receives Mv(t ) messages at a rate Î³v(t ) = Î»u(t ) + Î³v\u(t ) , where Î³v\u(t ) denotes the message rate due to other broadcasters v follows . For each follower , the average visibility of a user u â€™s messages is defined as the time that a post from user u is among the last k stories the follower received . In the visibility shaping problem , the goal is to optimize Î»u(t ) to steer visibility . space H of all smooth functions . Before we proceed , we need the following definition :
Definition 2 . Given the space H of all smooth functions , a functional J : H â†’ R is concave if for every g1 , g2 âˆˆ H and 0 < Î± < 1 :
J[Î±g1 + ( 1 âˆ’ Î±)g2 ] â‰¥ Î±J[g1 ] + ( 1 âˆ’ Î±)J[g2 ] .
( 19 )
A functional J is convex if âˆ’J is concave .
It readily follows that the probability fk(t ) , given by Eq 18 , is a functional with Î»(Â· ) as input . Moreover , the following two theorems , proven in Appendices B and C , establish the concavity of fk(t ) and V(k ) with respect to Î»(Â· ) .
Theorem 3 . Given a broadcaster with message intensity Î»(t ) and one of her followers with feed message intensity due to other broadcasters Âµ(t ) . The probability fk(t ) that at least one message from the broadcaster is among the k most recent ones received by the follower at time t , given by Eq 18 , is concave with respect to Î»(Â· ) .
Theorem 4 . Given a broadcaster with message intensity Î»(t ) and one of her followers with feed message intensity due to other broadcasters Âµ(t ) . The visibility V(k ) , given by Eq 13 , is concave with respect to Î»(Â· ) .
Given the above results , one could think of finding the optimal ( general ) message intensity Î»(t ) that maximize ( a function of ) the average visibilities across a broadcaster â€™s followers . However , in practical applications , this may be inefficient and undesirable , instead , one may focus on a simpler parametrized family of intensities , such as piecewise constant intensity functions , which will be easier to optimize and fit using real data . To this aim , next , we prove
ð‘¤1ð‘¤2ð‘¢ð‘£ð‘¤ð‘šð‘€1(ð‘¡)ð‘€2(ð‘¡)ð‘€ð‘š(ð‘¡)ð‘€(ð‘¡)ð‘(ð‘¡)Visibility1638 that the average visibility is also concave on the parameters defining piecewise constant intensity functions .
Algorithm 1 : Projected Gradient Descent for Visibility Shaping
Piecewise constant intensity functions . In this section , we assume that the message intensity Î»(t ) of the broadcaster belongs to the space of piecewise constant functions Î» : [ 0 , T ] â†’ R , denoted by G , which we parametrized as follows :
Initialize c ; repeat
1 Project c into the polytope c 0 , c1 C ; 2 Find the gradient g(c ) ; 3 Update c using the gradient g(c ) ;
Î»(t ) = amI(Ï„mâˆ’1 â‰¤ t < Ï„m ) ,
( 20 ) until convergence ;
M
|J[Î» ] âˆ’ J[Ë†Î»]| <
( 21 ) maximizeÎ»u(t )
Vuv(k )
( 24 ) where V u(k ) = ( Vuv(k))vâˆˆN ( u)+ , N ( u)+ denotes the broadcaster u â€™s followers , Vuv(k ) denotes the average visibility in m=1
Then , each piece m in the above intensities satisfies the re m=1 where am â‰¥ 0 , M is the number of pieces , Ï„iâˆ’Ï„iâˆ’1 = T /M = âˆ† and Ï„0 = 0 .
As the reader may have noticed , the results from the previous section are not readily usable since Lemma 1 requires the intensity functions to be smooth . However , we will now show that , for every function Î»(t ) âˆˆ G , there is a sequence of smooth functions Î»n(t ) âˆˆ H such that limnâ†’âˆž Î»n(t ) = Î»(t ) and , this will sufficient to prove concavity . Before we proceed , we need the following definition :
Definition 5 . A functional J : G â†’ H is said to be continuous at Î»(Â· ) âˆˆ H if for every > 0 , there is a Î´ > 0 such that provided that ||Î» âˆ’ Ë†Î»|| < Î´ , where || Â· || is a norm in H .
It readily follows that the probability fk is a continuous functional on H . Moreover , we need the following lemma ( proven in Appendix D ) to prove the concavity :
Lemma 6 . For every Î»(t ) âˆˆ G , there is a sequence of smooth functions Î»n(t ) âˆˆ H where limnâ†’âˆž Î»n(t ) = Î»(t ) .
Using Lemma 6 , for any Î»(t ) âˆˆ G , it follows that fk(Î»(Â· ) ) = lim nâ†’âˆž fk(Î»n(t ) )
( 22 ) where Î»n(t ) is a sequence of smooth functions such that limnâ†’âˆž Î»n(t ) = Î»(t ) . As a consequence , we can establish the concavity of fk(t ) and V(k ) with respect to a1 , . . . , aM with the following Theorem ( proven in Appendix E ) :
Theorem 7 . fk and V(k ) are concave functionals in the space of piecewise constant functions G .
Corollary 8 . If we represent Î» âˆˆ G using Eq 20 , fk(t ) and V(k ) are concave with respect to a1 , . . . , am .
5 . CONVEX VISIBILITY SHAPING FRAME
WORK
Given the concavity of the average visibility , we now propose a convex optimization framework for a variety of visibility shaping tasks . In all these tasks , our goal is to find the optimal message intensity Î»u(t ) for broadcaster u that maximizes a particular nondecreasing concave utility function U ( V u(k ) ) of the average visibility of broadcaster u in all her followers within a time window [ 0 , T ] , ie , maximizeÎ»u(t ) U ( V u(k ) ) subject to
T Î»u(t ) â‰¥ 0 t âˆˆ [ 0 , T ] 0 Î»(t ) dt â‰¤ C ,
( 23 ) follower v , the first constraint asserts the intensity function remains positive , and the second limits the average number of messages broadcasted within [ 0 , T ] to be no more than C . We next discuss two instances of the general framework , which achieve different goals ( their constraints remain the same and hence omitted ) . More generally , the flexibility of our framework allows to use any nondecreasing concave utility function .
Average Visibility Maximization ( AVM ) . The goal here is to maximize the sum of the visibility for all the broadcaster â€™s followers , ie , vâˆˆN ( u)+ n
Minimax Visibility Maximization ( MVM ) . Suppose our goal is instead to keep the visibility in the n followers with the smallest visibility value above a certain minimum level , or , alternatively make the average visibility across the n followers with the smallest visibility as high as possible . Then , we can perform the following minimax visibility maximization task maximizeÎ»u(t )
Vuv[i ] ( k ) ,
( 25 ) i=1 where Vuv[i ] ( k ) denotes the average visibility in the follower with the i th smallest visibility among all the broadcaster â€™s followers .
6 . SCALABLE ALGORITHM
To solve the visibility shaping problems defined above , we need to be able to ( efficiently ) evaluate the probability function fk and visibility V(k ) . However , a direct evaluation by means of Eqs . 18 and 13 seem difficult . Here , we present an alternative representation of the probability function fk and the visibility V(k ) for piece wise constant intensity functions , which allow us to compute these quantities very efficiently . Based on this result , we present an efficient gradient based algorithm to find the optimum intensity .
Assume the broadcaster â€™s message intensity Î»(t ) and the follower â€™s feed message intensity due to other broadcasters Âµ(t ) adopt the following form :
M M m=1
Î»(t ) =
Âµ(t ) = cmI(Ï„mâˆ’1 â‰¤ t < Ï„m ) bmI(Ï„mâˆ’1 â‰¤ t < Ï„m ) .
1639 currence relation given by Eq 17 , which we rewrite as k(t ) + ( bm + cm)fk(t ) = cm + bmfkâˆ’1(t ) , f and one can easily prove by induction that , in general , the solution of the above differential equation for each time interval Ï„mâˆ’1 â‰¤ t < Ï„m is given by
( 26 ) fk(t ) = e
âˆ’(bm+cm)t(Î±kâˆ’1,ktkâˆ’1 + Â·Â·Â· + Î±0,k ) + Î²k i! ( hkâˆ’i âˆ’ Î²kâˆ’i ) , Î²i = 1 âˆ’ bm i bm+cm where Î±i,k = bi , and hi is the probability fi(Ï„iâˆ’1 ) at the beginning of time interval . Such representation allows for an efficient evaluation of fk(t ) . Next , we also need to compute the integral of fk(t ) to efficiently compute the visibility V(k ) . Without loss of generality , we represent the time for each piece in a normalized time window [ 0 , 1 ] . Then , the integral of fk(t ) can be written as follows : V(k ) = fk(t ) dt
= Î²k +
Î±i,k
âˆ’(bm+cm)tti dt e
= Î²k +
0
Î±i,k
( bm + cm)i+1 [ i! âˆ’ Î“(i + 1 , bm + cm ) ]
( 27 ) where note that the last term is efficiently computable since , for integer values of n , the incomplete Gamma function
Î“(n , x ) = ( n âˆ’ 1)! eâˆ’xnâˆ’1 xi i! . i=0
Given Eq 27 , we can now easily compute the gradient of the visibility V(k ) , which we can then use to design an efficient gradient based algorithm . For brevity , we just show the gradient for k = 1 . Let c = ( c1 , . . . , cM ) , and y = ( y0 , . . . , yMâˆ’1 , yM ) be the values of fk(t ) at the beginning of each time interval , then , âˆ’ âˆ‚yi âˆ‚ci
( bi + ci ) + ( yi âˆ’ yiâˆ’1 ) + bi
âˆ‚V(1 ) âˆ‚ci
( bi + ci)2
=
1
âˆ‚ymâˆ’1
.
âˆ’ âˆ‚ym âˆ‚ci
1
+ bm + cm
âˆ‚ci m=i+1
0
1 kâˆ’1 kâˆ’1 i=0 i=0 where we can easily compute âˆ‚yj/âˆ‚cm recursively as
âˆ’(bm+cm ) , e
âˆ‚cm bm bm cm
âˆ’
, if j > m .
( bm + cm )
( bm + cm)2 ymâˆ’1 âˆ’
( bm + cm)2 âˆ’ if j = m , and eâˆ’(bj +cj ) âˆ‚yjâˆ’1 Once we have an efficient way to compute the visibility V(k ) and its gradient , we can readily design a projected gradient descent algorithm to find the optimal message intensity Î»u(t ) in the visibility shaping problems described in Section 5 . Note that , since our optimization problems are convex , there is a unique optimum and convergence is guaranteed . Moreover , for the projection step , we solve a quadratic program , minimizing the distance to the feasible polytope . Algorithm 1 summarizes the overall algorithm . 7 . EXPERIMENTS
Dataset description and experimental setup . We use data gathered from Twitter as reported in previous work [ 3 ] , which comprises the following three types of information :
1
M profiles of 52 million users , 1.9 billion directed follow links among these users , and 1.7 billion public tweets posted by the collected users . The follow link information is based on a snapshot taken at the time of data collection , in September 2009 . Here , we focus on the tweets published during a six and a half month period , from February 2 , 2009 to August 13 , 2009 . In particular , we sample 10,000 users uniformly at random as broadcasters and record all the tweets they posted . Moreover , for each of these broadcasters , we track down all their followers and record all the tweets they posted as well as reconstruct their timelines by collecting all the tweets published by the people they follow .
In our experiments , we use the first three and a half month period , from February 2 to May 13 to fit the piecewise constant intensities of the followersâ€™ timelines and the followersâ€™ significance , which we use in our convex visibility shaping framework . Here , the follower â€™s significance is the probability that she is on line , estimated as a piecewise ( hourly ) constant probability from the tweets retweets the follower posted â€“ if a follower tweeted or retweeted in an hour , we assume it was on line during that hour . Then , we use the last three month period , from May 14 to August 13 , to evaluate our framework . We refer to the former period as the training set and the latter as the test set . We experiment both with T =24 hours ( M =24 , âˆ†=1 hour ) and T =7 days ( M =24Ã— 7 , âˆ†=1 hour ) , and set the budget C to be equal to the average number of tweets per T the broadcaster posted in the training period .
Evaluation schemes . Throughout this section , we use three different evaluation schemes , with an increasing resemblance to a real world scenario :
Theoretical objective : We compute the theoretical value of the utility using the broadcaster intensity under study , be it the ( optimal ) intensity given by our convex visibility shaping framework , the intensity given by an alternative baseline , or the the broadcaster â€™s ( true ) fitted intensity .
Simulated objective : We simulate events both from the broadcaster intensity under study and each of the followersâ€™ timeline fitted intensities . Then , we estimate empirically the overall utility based on the simulated events . We perform 100 independent simulation runs and report the average and standard error ( or standard deviation ) of the utility .
Held out data : We simulate events from the broadcaster intensity under study , interleave these generated events on the true followersâ€™ timelines recorded as test set , and compute the corresponding utility . We perform 10 independent simulation runs and report the average and standard error ( or standard deviation ) of the utility .
Intensities , top k probabilities and visibilities . We pay attention to four broadcasters , picked at random , and solve the average visibility maximization task for one of their followers , also picked at random . Our goal here is to shed light on the influence that the follower â€™s timeline intensity and significance have on the optimized broadcaster â€™s intensity as well as its corresponding visibility and top k probability for different values of k . Figure 2 summarizes the results , which show that ( i ) including the significance in the visibility definition shifts the optimized intensities away from the times in which the followers are not online ( first row ) ; ( ii ) the optimized intensities typically achieve a higher average visibility than the one achieved by the broadcaster â€™s true posting activity on a held out set ( third row ) ; and ( iii )
1640 Figure 2 : Intensities and top k probabilities and visibilities . We focus on four broadcasters ( one per column ) and solve the AVM problem for one of their followers , picked at random . The first row shows the follower â€™s timeline intensity ( Âµ(t ) , in brown ) fitted using events from the training set , and the optimized intensities , as given by our framework , that maximize visibility for k=1 , 20 on the training set with and without significance ( Î»âˆ—(t ) , in solid and dashed yellow and blue , respectively ) . The second row shows the top k probability for the optimized intensities with and without significance for k=1 , 20 ( fâˆ— k ( t ) , in solid and dashed yellow and blue ) as well as the follower â€™s significance ( s(t ) , in brown ) . The third row compares the average visibility achieved by the optimized intensities without significance for k=1 , 20 ( Vâˆ—(k ) , in yellow and blue ) to the average visibility achieved by the broadcaster â€™s posting activity ( V(k ) , in green and purple ) on a held out set . the optimized intensities are more concentrated in time for k = 1 ( first row ) and achieve a higher average visibility and top k probability for k = 20 ( second and third row ) .
Solution quality . In this section , we perform a large scale evaluation of our framework across all 10,000 broadcasters in terms of the three evaluation schemes described above and compare its performance against several baselines . Here , we consider the definition of visibility that incorporates significance since , as argued previously , may lead to more effective broadcasting strategies6 .
In the average visibility maximization task , we compare our framework with three heuristics , in which the broadcaster distributes the available budget uniformly at rani=1 Âµi(t ) ( IAVM ) and i=1 si(t)Âµi(t ) ( PAVM ) , respectively . In the minimax visibility maximization task , we also compare with three heuristics . The first two heuristics are similar to two of the ones just mentioned for AVM , ie , the broadcaster distributes the available budget uniformly at rani=1 Âµi(t ) ( IMVM ) . dom ( RAVM ) , proportionally to n proportionally to n dom ( RMVM ) and proportionally to n
6We obtain qualitatively similar results if we omit the significance in the definition of visibility . Actually , in such case , our framework beats the baselines by a greater margin . sity Î»(t ) =n
In the third heuristic , the broadcaster distributes its budget following a greedy procedure : at each iteration k , it first finds the user with the least visibility given Î»(kâˆ’1)(t ) and then solves the average visibility maximization for that user given a budget of C/n . Finally , it outputs the intenk=1 Î»(k)(t ) . The greedy procedure starts with Î»(0)(t ) = C/M . Additionally , for the held out comparison , we also compute the actual average intensity that the broadcaster achieved in reality .
Figure 3 summarizes the results by means of a box plot , which shows the utilities achieved by our framework and the heuristics normalized with respect to the utility achieved by the broadcastersâ€™ fitted true intensity ( by the posts during the test set for the third evaluation scheme ) . That means , if y = 1 , the optimized intensity achieves the same utility as the broadcaster â€™s recorded posts . For the average visibility maximization task , the intensities provided by our method achieve 1.5Ã— higher theoretical objective and 1.3Ã— higher utility on a held out set , in average ( black dashed line ) , than the broadcaster â€™s fitted intensities . In contrast , alternatives fail at providing any gain , ie , y â‰¤ 1 for a half of the broadcasters . Finally , for the minimax visibility maximization task , which is significantly harder , the intensities provided by our method achieve 1.6Ã— higher theoretical ob
06121824time00030609intensitytop 1 nosigtop 20 nosigwalltop 1 sigtop 20 sig06121824time0123intensitytop 1 nosigtop 20 nosigwalltop 1 sigtop 20 sig06121824time0123intensitytop 1 nosigtop 20 nosigwalltop 1 sigtop 20 sig06121824time00030609intensitytop 1 nosigtop 20 nosigwalltop 1 sigtop 20 sig06121824time0000000600120018f1significancetop 1 nosigtop 1 sigtop 20 nosigtop 20 sig000007014021f2006121824time00010203f1significancetop 1 nosigtop 1 sigtop 20 nosigtop 20 sig00030609f2006121824time00000000150003000045f1significancetop 1 nosigtop 1 sigtop 20 nosigtop 20 sig000004008012f2006121824time0000000200040006f1significancetop 1 nosigtop 1 sigtop 20 nosigtop 20 sig000004008012f2005101520day000006012018visibility(1)top 1 actualtop 1 nosigtop 20 actualtop 20 nosig00030609visibility(20)05101520day00020406visibility(1)top 1 actualtop 1 nosigtop 20 actualtop 20 nosig00153045visibility(20)05101520day000002004006visibility(1)top 1 actualtop 1 nosigtop 20 actualtop 20 nosig000025050075visibility(20)05101520day000007014021visibility(1)top 1 actualtop 1 nosigtop 20 actualtop 20 nosig00061218visibility(20)1641 l a c i t e r o e h T d e t a l u m S i t u o d l e H l a e R
Average Visibility
Minimax Visibility
Figure 3 : Visibility shaping for 10,000 broadcasters . The left ( right ) column corresponds to AVM ( MVM ) , evaluated using the theoretical objective ( first row ) , the simulated objective ( second row ) and the held out data ( third row ) . The red ( blue ) dashed line shows the median ( mean ) objective popularity and the box limits correspond to the 25%â€“75 % percentiles . a ) Followers b ) k c ) Running time
Figure 4 : The average visibility against ( a ) # of followers and ( b ) k . Panel ( c ) plots running time . jective and 1.4Ã— higher average utility on a held out set , in average ( black dashed line ) , than the broadcaster â€™s fitted intensities . In this case , although our method outperforms the baselines by large margins in terms of theoretical and simulated objectives , the baselines achieved almost the same average utility on the held out set . The theoretical and simulated objective are almost equal in all cases , as one may have expected .
Solution quality vs . # of followers . Figure 4(a ) shows the average visibilities achieved by our optimized intensities for the AVM task , normalized by the average visibility that the corresponding broadcastersâ€™ fitted intensities achieve , against number of followers for the same 10,000 broadcasters as above . Independently of the number of followers , we find that the intensities provided by our method consistently outperform the broadcaster â€™s fitted intensities . ity achieved by our optimized intensities for the AVM task against k for the four broadcasters from Figure 2 .
Scalability . Figure 4(c ) shows that our convex optimization framework easily scale to broadcasters with thousands of followers . For example , given a broadcaster with âˆ¼2000 followers , our algorithm takes 250 milliseconds to find the optimal intensity for the average visibility maximization using a single machine with 64 cores and 1.5 TB RAM . 8 . CONCLUSIONS
In this paper , we developed a novel framework to solve the when to post problem , in which we model usersâ€™ feeds and posts as discrete events occurring in continuous time . Under such continuous time model , then choosing a strategy for a broadcaster becomes a problem of designing the conditional intensity of her posting events . The key technical idea that enables our framework is a novel formula which can link the conditional intensity of an arbitrary broadcaster with her visibility in her followersâ€™ feeds , defined as the time that at least one post from her is among the most recent k received stories in her followersâ€™ feed . In addition to the framework , we develop an efficient gradient based optimization algorithm , which allows us to find optimal broadcast intensities for a variety of visibility shaping tasks in a matter of seconds . Experiments on large real world data gathered from Twitter revealed that our framework can consistently make broadcastersâ€™ posts more visible than alternatives .
Our work also opens many interesting venus for future work . For example , we assume that the social network sorts stories in each user â€™s feed in inverse chronological order . While this is a realistic assumption for some social networks ( eg , Twitter ) , there are other social networks ( eg , Facebook ) where the feed is curated algorithmically . It would be very interesting to augment our framework to such cases . In this work , we model usersâ€™ intensities using inhomogeneous Poisson processes , whose intensities are history independent and deterministic . Extending our framework to point processes with stochastic and history dependent intensity functions , such as Hawkes processes , would most likely provide more effective broadcasting strategies . Finally , in this work , we validate our framework on two visibility shaping tasks , average visibility maximization and minimax visibility maximization , however , there are many other useful tasks one may think of , such as visibility homogenization .
Acknowledgements . This project was supported in part by NSF/NIH BIGDATA 1R01GM108341 , ONR N00014 151 2340 , NSF IIS 1218749 , and NSF CAREER IIS 1350983 .
9 . REFERENCES [ 1 ] O . Aalen , O . Borgan , and H . K . Gjessing . Survival and event history analysis : a process point of view . Springer , 2008 .
[ 2 ] L . Backstrom , E . Bakshy , J . M . Kleinberg , T . M .
Lento , and I . Rosenn . Center of attention : How facebook users allocate attention across friends . ICWSM , 2011 .
[ 3 ] M . Cha , H . Haddadi , F . Benevenuto , and P . K .
Gummadi . Measuring User Influence in Twitter : The Million Follower Fallacy . ICWSM , 2010 .
[ 4 ] W . Chen , C . Wang , and Y . Wang . Scalable influence
Visibility vs . k . Figure 4(b ) shows the average visibil maximization for prevalent viral marketing in
RAVMAVMPAVMIAVM051015RMVMMVMPMVMIMVM051015RAVMAVMPAVMIAVM051015RMVMMVMPMVMIMVM051015RAVMAVMPAVMIAVM051015RMVMMVMPMVMIMVM051015190018002700followers13161922VisibilityGain(Theory)05101520k144146148150VisibilityGain(Theory)0600120018002400followers050100150200250300Time(milisec)1642 large scale social networks . In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining , 2010 .
[ 20 ] I . Valera and M . Gomez Rodriguez . Modeling adoption and usage of competing products . In IEEE International Conference on Data Mining , 2015 .
[ 5 ] J . Cheng , L . Adamic , P . Dow , J . Kleinberg , and
[ 21 ] D . Vu , D . Hunter , P . Smyth , and A . Asuncion .
J . Leskovec . Can cascades be predicted ? In Proceedings of the 23rd international conference on World wide web , 2014 .
[ 6 ] T . Chenhao , L . Lee , and B . Pang . The effect of wording on message propagation : Topic and author controlled natural experiments on twitter . In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics , 2014 .
[ 7 ] E . Constantinides . Foundations of social media marketing . Procedia Social and behavioral sciences , 148:40â€“57 , 2014 .
[ 8 ] M . B . Crawford . The world beyond your head : On becoming an individual in an age of distraction . Macmillan , 2015 .
[ 9 ] A . De , I . Valera , N . Ganguly , S . Bhattacharya , and
M . Gomez Rodriguez . Modeling opinion dynamics in diffusion networks . arXiv preprint arXiv:1506.05474 , 2015 .
[ 10 ] N . Du , L . Song , M . Gomez Rodriguez , and H . Zha .
Scalable influence estimation in continuous time diffusion networks . In Advances in Neural Information Processing Systems , 2013 .
[ 11 ] M . Farajtabar , N . Du , M . Gomez Rodriguez , I . Valera ,
H . Zha , and L . Song . Shaping social activity by incentivizing users . In NIPS , 2014 .
[ 12 ] M . Farajtabar , Y . Wang , M . Gomez Rodriguez , S . Li , H . Zha , and L . Song . Coevolve : A joint point process model for information diffusion and network co evolution . In Advances in Neural Information Processing Systems , 2015 .
[ 13 ] M . Gomez Rodriguez , K . Gummadi , and B . SchÂ¨olkopf .
Quantifying information overload in social media and its impact on social contagions . In 8th International AAAI Conference on Weblogs and Social Media , 2014 .
[ 14 ] N . Hodas and K . Lerman . How visibility and divided attention constrain social contagion . SocialCom , 2012 .
[ 15 ] D . Kempe , J . Kleinberg , and Â´E . Tardos . Maximizing the spread of influence through a social network . In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining , 2003 .
[ 16 ] G . Miritello , R . Lara , M . Cebrian , and E . Moro .
Limited communication capacity unveils strategies for human interaction . Scientific reports , 3 , 2013 .
[ 17 ] N . Navaroli and P . Smyth . Modeling response time in digital human communication . In Ninth International AAAI Conference on Web and Social Media , 2015 .
[ 18 ] M . Richardson and P . Domingos . Mining knowledge sharing sites for viral marketing . In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining , 2002 .
[ 19 ] N . Spasojevic , Z . Li , A . Rao , and P . Bhattacharyya .
When to post on social networks . In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 2127â€“2136 . ACM , 2015 .
( 28 )
( 29 )
Ï„ Âµ(x)dx ] =
Continuous time regression models for longitudinal networks . In Advances in Neural Information Processing Systems , 2011 .
[ 22 ] Q . Zhao , M . Erdogdu , H . He , A . Rajaraman , and J . Leskovec . Seismic : A self exciting point process model for predicting tweet popularity . In 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , 2015 .
APPENDIX A . PROOF OF LEMMA 1
We will prove this lemma by induction on k . For the case k = 1 , f1(t ) satisfies a first order linear differential equation ,
1(t ) = âˆ’(Âµ(t ) + Î»(t))f1(t ) + Î»(t ) , f whose unique solution is t
âˆ’ t
Î»(Ï„ )e f1(t ) = as long as assuming f1(t ) = 0 . Then , using that Î“[1 , t eâˆ’ t
Ï„ Âµ(x)dx , we can rewrite the solution as
Ï„ ( Î»+Âµ)(x)dx .
0 t
âˆ’ t t f1(t ) =
Î»(Ï„ )e
Ï„ Î»(x)dxÎ“[1 ,
Âµ(x)dx]dÏ„ ,
0
Ï„ which proves the theorem for k = 1 . Now , in the inductive step we assume the hypothesis is true for 1 , 2 , . . . k âˆ’ 1 and we prove it for k . We start by rewriting the differential given by Equation 17 as fk
( t ) + ( Âµ(t ) + Î»(t))fk(t ) = Î»(t ) + Âµ(t)fkâˆ’1(t ) ,
( 30 ) where , by assumption , fkâˆ’1(t ) is unique and known . Then , as long as fk(0 ) = 0 , the above differential equation has a unique solution and thus we only need to find fk(t ) that satisfies it . To do so , we rewrite the right hand side of the differential equation using the inductive hypothesis as t 0 Î»(Ï„ )eâˆ’ t
Ï„ Î»(x)dxÎ“[k âˆ’ 1 , t
( k âˆ’ 2)!
Ï„ Âµ(x)dx]dÏ„
,
Î»(t ) + Âµ(t ) which , using Î“[k âˆ’ 1 , x ] = 1 expressed as t
Î»(Ï„ )eâˆ’ t
Ï„ Î»(x)dxÎ“[k , t kâˆ’1 ( Î“[k , x ] + âˆ‚Î“[k,x ] Ï„ Âµ(x)dx ] + âˆ‚Î“[k , t âˆ‚ t
âˆ‚x
Î»(t)+Âµ(t )
0
( k âˆ’ 1)! dÏ„
) , can be
Ï„ Âµ(x)dx
Ï„ Âµ(x)dx
( 31 )
,
( 32 )
Next , we hypothesize that fk(t ) = and rewrite Eq 31 as
Ï„ Î»(x)dx Î“[k , t t 0 Î»(Ï„ )eâˆ’ t Âµ(t ) t
0 Î»(Ï„ )eâˆ’ t
( k âˆ’ 1)!
Î»(t ) + Âµ(t)fk(t ) +
Ï„ Âµ(x)dx ] dÏ„ )
Ï„ Î»(x)dx âˆ‚Î“[k , t âˆ‚ t ( k âˆ’ 1)!
Ï„ Âµ(x)dx ]
Ï„ Âµ(x)dx dÏ„
.
( 33 )
1643 Then , by the fundamental theorem of calculus ,
Proof . We simply verify that J[Î» ] satisfies the definition
âˆ’ t of convexity , as given by Eq 19 : J[Î±Î»1 + ( 1 âˆ’ Î±)Î»2 ] = e a Î±Î»1(x)+(1âˆ’Î±)Î»2(x ) dx âˆ’ t a Î»1(x ) dx + ( 1 âˆ’ Î±)e â‰¤ Î±e = Î±J[Î»1 ] + ( 1 âˆ’ Î±)J[Î»2 ]
âˆ’ t a Î»2(x ) dx where the inequality follows from the arithmetic geometric mean inequality , ie , Î¸x + ( 1 âˆ’ Î¸)y â‰¥ xÎ¸y1âˆ’Î¸ for all positive x , y , and 0 < Î¸ < 1 .
Lemma 10 . If the functional Jt[Î»(Â· ) ] is convex with respect to Î»(Â· ) . Then , given any arbitrary function g(x ) â‰¥ 0 , 0 JÏ„ [ Î»(.)]g(Ï„ )dÏ„ is also convex with respect to Î»(Â· ) . the functional L[Î» ] = t Proof . We verify that the functional L[Î» ] = t verifies the definition of convexity , as given by Eq 19 : JÏ„ [ Î±Î»1 + ( 1 âˆ’ Î±)Î»2]g(Ï„ )dÏ„
L[Î±Î»1 + ( 1 âˆ’ Î±)Î»2 ] =
0 JÏ„ [ Î»(.)]g(Ï„ )dÏ„ t t
0
0
â‰¤ Î±
JÏ„ [ Î»1]g(Ï„ )dÏ„ t
+ ( 1 âˆ’ Î± ) JÏ„ [ Î»2]g(Ï„ )dÏ„ = Î±L[Î»1 ] + ( 1 âˆ’ Î±)L[Î»2 ]
0 for all x âˆˆ D , then where the inequality holds using that , given any two arbitrary functions h1 and h2 such that h1(x ) â‰¥ h2(x ) â‰¥ 0 D h2(x)g(x)dx given g(x ) â‰¥ 0 for all x âˆˆ D .
D h1(x)g(x)dx â‰¥
C . PROOF OF THEOREM 4 Theorem 3 proves the concavity of fk(t ) with respect to Î»(Â· ) . Therefore , 1âˆ’ fk(t ) is convex and , using Lemma 10 , it 0 fk(t)s(t)dt is 0 fk(t)s(t)dt holds that T also convex . Then , since T
0 s(t)dtâˆ’ T 0 s(t)dt is constant , T
0 ( 1âˆ’fk(t))s(t)dt = T is concave with respect to Î»(Â· ) and the proof is complete .
D . PROOF OF LEMMA 6
Each piecewise continues function can be represented as summation of a number of heaviside step functions . The count is equal to the number of discontinuity points . However , each heaviside function itself is the limit of smooth tanh functions . Therefore , the piecewise continues function will be the limit of a finite summation of smooth tanh functions .
E . PROOF OF THEOREM 7
Consider two piecewise constant functions Î»(Â· ) , Âµ(Â· ) âˆˆ G . According to Lemma 6 there exist sequence of smooth funcn = Î» . Betions such that limnâ†’âˆž Î»n = Î» and limnâ†’âˆž Î» cause of the concavity of fk in H we know for 0 < Î± < 1 : fk[Î±Î»n(Â· ) + ( 1 âˆ’ Î±)Î» n(Â·) ] . n(Â· ) ] â‰¥ Î±fk[Î»n(Â· ) ] + ( 1 âˆ’ Î±)fk[Î»
Taking the limit and using the continuity of fk we get : fk[Î±Î»(Â· ) + ( 1 âˆ’ Î±)Î» ( Â·) ] . ( 35 ) Accompanied with convexity of space G the theorem is proved .
( Â· ) ] â‰¥ Î±fk[Î»(Â· ) ] + ( 1 âˆ’ Î±)fk[Î»
âˆ‚Î“[k , t âˆ‚ t
Ï„ Âµ(x)dx ]
Ï„ Âµ(x)dx and thus
Î»(t ) + Âµ(t)fk(t ) +
âˆ‚Î“[k , t âˆ‚Î“[k , t
=
= t 0 Î»(Ï„ )eâˆ’ t
Ï„ Âµ(x)dx ] âˆ‚t
Ã—
âˆ‚ t
âˆ‚t
Ï„ Âµ(x)dx
Ï„ Âµ(x)dx ] âˆ‚t
Ã— 1 Âµ(t ) Ï„ Î»(x)dx âˆ‚Î“[k , t ( k âˆ’ 1)!
Ï„ Âµ(x)dx ] âˆ‚t dÏ„
. ( 34 )
Finally , using that for differentiable functions g and h , gh = ( gh ) âˆ’ gh , we have that
0 t t t
âˆ’
=
0
0
(
( Î»(Ï„ )e
Ï„ Î»(x)dx)(
âˆ’ t âˆ‚(Î»(Ï„ )eâˆ’ t
( kâˆ’1)!(f
âˆ‚Î»(Ï„ )eâˆ’ t
âˆ‚t
âˆ‚Î“[k , t Ï„ Î»(x)dxÎ“[k , t t
âˆ‚t k(t)âˆ’Î»(t ) )
( kâˆ’1)!Î»(t)fk(t )
)(Î“[k ,
Ï„
Ï„ Î»(x)dx
Ï„ Âµ(x)dx ] âˆ‚t
)dÏ„
Ï„ Âµ(x)dx ] ) dÏ„
Âµ(x)dx])dÏ„ and then we can rewrite Eq 34 as
( k âˆ’ 1)!(f k(t ) âˆ’ Î»(t ) ) + ( k âˆ’ 1)!Î»(t)fk(t )
( k âˆ’ 1)!
,
Î»(t ) + Âµ(t)fk(t ) + which simplifies to fk
( t ) + ( Âµ(t ) + Î»(t))fk(t ) .
This asserts that hypothesized solution for fk(t ) in Eq 32 satisfies Eq 30 , hence , it is the unique solution for fk(t ) .
B . PROOF OF THEOREM 3
From Lemma 1 , we know that t 0 ( Î»(Ï„ )eâˆ’ t
Ï„ Î»(x)dx)Î“[k , t
( k âˆ’ 1)! fk(t ) =
Ï„ Âµ(x)dx]dÏ„
. dÏ„
âˆ’
Ï„ Âµ(x)dx ] âˆ‚Ï„
0 Âµ(x)dx ]
Using integration by parts , we can rewrite the above expression as
0 Î»(x)dxÎ“[k , t fk(t ) = 1 âˆ’ eâˆ’ t t ( k âˆ’ 1)! Ï„ Î»(x)dx ) âˆ‚Î“[k , t 0 ( eâˆ’ t ( k âˆ’ 1)! 0 Î»(x)dx and eâˆ’ t Lemma 9 tells us that eâˆ’ t Ï„ Î»(x)dx are conthe fact that âˆ‚Î“[k , t vex with respect to Î»(Â· ) . Moreover , using Lemma 10 and t Ï„ Î»(x)dx ) âˆ‚Î“[k , t 0 ( eâˆ’ t Î“[k , t > 0 , it follows that the function spect to Î»(Â· ) . Lemma 9 . Functional J[Î» ] = eâˆ’ t respect to Î»(Â· ) for any constant a â‰¤ t . dÏ„ is convex . Finally , given that 0 0 ] > 0 , we can conclude that fk(t ) is concave with re a Î»(x)dx is convex with
Ï„ Âµ(x)dx ] âˆ‚Ï„
Ï„ Âµ(x)dx ] âˆ‚Ï„
1644
