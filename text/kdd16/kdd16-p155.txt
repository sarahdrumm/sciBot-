Repeat Buyer Prediction for E Commerce
Guimei Liu⋆ , Tam T . Nguyen⋆ , Gang Zhao# , Wei Zha⋆ , Jianbo Yang§
Jianneng Cao⋆ , Min Wu⋆ , Peilin Zhao⋆ , Wei Chen#
⋆Data Analytics Department , Institute for Infocomm Research , Singapore 138632 ,
{liug,nguyentt,zhaw,caojn,wumin,zhaop}@i2ra staredusg
#Development Bank of Singapore , {georgegzhao , nuswaltchan}@gmailcom
§General Electric , jianboyang@gecom
ABSTRACT A large number of new buyers are often acquired by merchants during promotions . However , many of the attracted buyers are one time deal hunters , and the promotions may have little long lasting impact on sales . It is important for merchants to identify who can be converted to regular loyal buyers and then target them to reduce promotion cost and increase the return on investment ( ROI ) . At International Joint Conferences on Artificial Intelligence ( IJCAI ) 2015 , Alibaba hosted an international competition for repeat buyer prediction based on the sales data of the “ Double 11 ” shopping event in 2014 at Tmallcom We won the first place at stage 1 of the competition out of 753 teams . In this paper , we present our winning solution , which consists of comprehensive feature engineering and model training . We created profiles for users , merchants , brands , categories , items and their interactions via extensive feature engineering . These profiles are not only useful for this particular prediction task , but can also be used for other important tasks in e commerce , such as customer segmentation , product recommendation , and customer base augmentation for brands . Feature engineering is often the most important factor for the success of a prediction task , but not much work can be found in the literature on feature engineering for prediction tasks in e commerce . Our work provides some useful hints and insights for data science practitioners in e commerce .
Keywords Repeat Buyer Prediction ; Feature Engineering ; E commerce
1 .
INTRODUCTION
Large business to consumer ( B2C ) e commerce websites , such as Amazon and Alibaba , often run nationwide sales promotions on special days like Black Friday and Double 11 ( Singles’ Day ) . Merchants acquire new customers during these events . However , most new customers are one time
KDD ’16 , August 13 17 , 2016 , San Francisco , CA , USA cfl 2016 ACM . ISBN 978 1 4503 4232 2/16/08 . . . $15.00 DOI : http://dxdoiorg/101145/29396722939674 deal hunters , and promotions to them usually do not generate return on investment ( ROI ) as expected by merchants . Therefore , merchants need to identify potential loyal ones from these new customers , so as to conduct targeted advertisements ( and promotions ) towards them to lower the promotion cost . It is difficult for any individual merchant to identify its potential loyal customers as it has little information on its new customers . B2C e commerce websites instead have the click stream data and purchase history of all the customers at all the merchants on their platforms . Thus , they can learn the preferences and habits of the new customers from their historical data , and then predict how likely a new customer will buy again from a same merchant . At IJCAI 2015 , Alibaba hosted an international competition1 for repeat buyer prediction based on the sales data of the “ Double 11 ” day of 2014 at Tmall.com—the largest B2C platform in China . Double 11 is the biggest online shopping event in China with sales ( in Tmall and Taobao ) at US$5.8 billion in 2013 , US$9.3 billion in 2014 , and over US$14.3 billion in 20152 . Data provided to the competition include a number of merchants and their new buyers acquired during the event , and six months of user activity log data before the event . The task is to predict which new customers of a given merchant would buy items from the same merchant again within six months . These new buyers are called repeat buyers of the respective merchants .
We won the first place at stage 1 of the competition . Our winning solution consists of comprehensive feature engineering and model training . In particular , we generated various types of features to describe users , merchants , brands , categories , items and their interactions from different aspects . We have trained various classification models , including Factorization Machine [ 14 , 11 ] , Logistic Regression [ 1 , 2 ] , Random Forest [ 5 ] , GBM [ 10 ] , and XGBoost [ 6 ] . We have also used ensemble techniques to blend multiple classifiers together to further improve the performance .
The repeat buyer prediction problem can be formulated as a typical classification problem , as most of the competition participants did . Model training of this task is not much different from that of other classification tasks . Instead , feature engineering is the main component that distinguishes this task from others . Feature engineering , an integral part of data science , is often the key to the success of a machine learning project . It can be more difficult than learning
1http://ijcai 15org/indexphp/ repeat buyers prediction competition 2https://enwikipediaorg/wiki/Singles Day
155 Table 1 : Statistics of training and testing data
Table 2 : Statistics of log activity data data #users #merchants #pairs #positive pairs positive % train 212,062 test 212,108
260,864 261,477
1,993 1,993
15,952 16,037
6.12 % 6.13 % because it is domain specific , while machine learning algorithms are largely general purpose . Much trial and error can go into feature design , and it is typically where most of the effort in a machine learning project goes [ 8 ] . While thousands of classification algorithms have been proposed and studied in the research community , not much work has been reported on feature engineering for prediction tasks in e commerce . Therefore , in this paper we focus on feature engineering . We will describe how to generate various types of features from user activity log data and study the importance of these features via extensive experiments . The features we generated can be used in all kinds of e commerce applications , such as customer segmentation , product recommendation , and customer base augmentation for brands . We hope that our work can be valuable for data science practitioners , who need to develop solutions for prediction tasks in e commerce .
The rest of the paper is organized as follows . Section 2 gives the problem description . Section 3 describes the features we have generated . Model ensemble is briefly described in Section 4 . In Section 5 , the importance of features is studied and top features are listed . Finally , Section 6 concludes the paper .
#rows
#users #merchants #items #categories #brands
54,925,330 424,170
4,995
1,090,390
1,658
8,444
Table 3 : Statistics of action types click add to cart purchase add to favourite
48,550,713 ( 88.39 % ) 76,750 ( 0.14 % ) 3,292,144 ( 5.99 % ) 3,005,723 ( 5.47 % ) and time stamp . Action type takes four values : 0 for click , 1 for add to cart , 2 for purchase and 3 for add to favourite . Products sold in different merchants are assigned different item ids even if the products are exactly the same . Table 2 shows the statistics of the user activity log data . Many merchants in the log data do not have new buyers in the training or testing data . They are included in the log data because some new buyers visited them . The activities of the new buyers at these merchants are valuable information for inferring the preferences and habits of the new buyers .
Table 3 shows the number of the four types of actions . The majority of actions are clicks . The number of addto cart actions is very small , so we merge the add to cart actions with click actions .
The user activity log data provided in this competition are very typical in e commerce prediction tasks . However , the log data are not in a form that is amenable to learning . We need to construct new features from them and then join the new features with the training and testing data . In the next section , we describe how we do this .
2 . PROBLEM DESCRIPTION
3 . FEATURE ENGINEERING
For the repeat buyer prediction competition , the following data are provided as shown on the top of Figure 1 : demographic information of users , six months of user activity log data prior to the “ Double 11 ” promotion , and training and testing hnew buyer , merchanti pairs , where the first purchase of the new buyer from the merchant is on the “ Double 11 ” promotion . User demographic data contains the age and gender of users . The age values are divided into seven ranges . The class label of a training hnew buyer , merchanti pair is known , and it indicates whether the new buyer bought items from the merchant again within six months after the “ Double 11 ” promotion . The class labels of testing hnew buyer , merchanti pairs are hidden . The task is to predict the class labels of the testing pairs . The competition was carried out in two stages . In stage 1 , all the data were released to the contestants except for class labels of testing pairs , which were released after stage 1 . Stage 2 ran on the cloud platform of Alibaba for bigger data , and the data were not released . Therefore , in this paper , we focus on the data of stage 1 .
Table 1 shows the statistics of the training and testing data . The set of merchants in training data and that in testing data are the same except for a single merchant . Users in the training and testing data have no overlap . The second last column is the number of positive hnew buyer , merchanti pairs such that the new buyer bought items from the merchant again within six months . The last column is the percentage of such positive pairs . The percentage of positive pairs is around 6 % , which indicates that most of the new buyers are indeed one time deal hunters .
The user activity log data contains the following fields : user id , merchant id , item id , cat id , brand id , action type
The user activity log data contain five entities : users , merchants , brands , categories and items . The characteristics of these entities and their interactions can be predictive of the class labels . For example , users are more likely to buy again from a merchant selling snacks than from a merchant selling electronic products within six months , since snacks are cheaper and are consumed much faster than electronic products . We generated a large number of features to describe the characteristics of the five types of entities and their pairwise interactions . In the rest of this section , we first give an overview of all the generated features , and then describe the features in details .
3.1 Overview of features and profiles
The features we generated range from basic counts to complex features like similarity scores , trends , PCA ( Principal Component Analysis ) and LDA ( Latent Dirichlet allocation ) features . All the features of an entity form the profile of the entity . We have five entity profiles and five interaction profiles as shown at the bottom of Figure 1 . Table 4 gives a summary of the types of features contained in these profiles . User merchant interaction is the most important interaction among the five pairwise interaction profiles as the task is to predict whether a user will return to a merchant to buy again . Therefore , user merchant profile contains more features than the other interaction profiles .
The original training/testing data contain only user ids and merchant ids as shown on the top of Figure 1 . We expanded the training/testing data by adding age range and gender of users , item id , brand id , and category id as shown in the middle of Figure 1 , where item id is the id of the item bought by the user from the merchant on the Double 11 day ,
156 Raw data training data user_id merchant_id 34176 34176
3906 121 …
… label
0 0 … user demographic data user_id 376517 234512
… age_range gender
6 5 …
1 0 … user activity log data ( 6 months ) user_id merchant_id Item_id cat_id brand_id action_type 328862 328862
323294 844400
833 1271
2661 2661
2882 2882
…
…
…
…
…
0 0 … time_stamp
0829 0829
… testing data user_id merchant_id 163968 360576
4605 1581
…
… prob
? ? … expanded training data expanded testing data user_id age_range gender merchant_id Item_id cat_id brand_id label 34176 34176
821 757713 800752 1028
6268 2337
6 6 …
0 0 …
3906 121 …
…
…
…
…
0 0 …
Feature Engineering user_id age_range gender merchant_id Item_id cat_id brand_id prob 163968 360576
7622 4066
4605 1581
772645 1368 614 948181 …
…
…
? ? …
0 2 …
…
…
0 2 …
Generated features user_id brand_id fea_1 … fea_n
1 1 …
3 16 …
3 10 …
… 2.4 … 4.7 … … user brand ( UB ) profile brand_id fea_1 … fea_n
1 2 …
1.2 … 3.9 … … …
23 4 … brand profile merchant_id brand_id fea_1 … fea_n
1 1 …
2 5 …
2 9 …
… 0.3 … 0.1 … … merchant brand ( MB ) profile user profile user_id fea_1 … fea_n
1 2 …
2.4 … 0.2 … 0.1 3 … … … user merchant ( UM ) profile user_id merchant_id fea_1 … fea_n 34176 34176
0.9 0.2
3906 121 …
2 5 …
… … … user category ( UC ) profile
… user_id cat_id fea_1 … fea_n
1 1 …
1 5 …
7 3 …
… … …
45 68 …
. merchant category ( MC ) profile merchant_id cat_id fea_1 … fea_n
1 1 …
1 3 …
10 14 …
… … …
3 5 … category profile cat_id fea_1 … fea_n
1 2 …
0.1 … 0.5 … … …
23 59 … merchant_id fea_1 … fea_n
1 2 …
3 20 …
… … …
0.6 1.5 … merchant profile item profile item_id fea_1 … fea_n
1 2 …
8 5 … …
… 0.5 … 0.7 …
Figure 1 : Feature engineering on raw data feature types profile profile profile profile profile
( UM ) profile
( UB ) profile ( UC ) profile
( MB ) profile
( MC ) profile user merchant category brand item user merchant user brand user category merchant brand merchant category
Table 4 : Summary of features and profiles . count/ratio aggregation recent activity complex features overall action count/ratio
X overall day count
X monthly action count/ratio X X product diversity penetration monthly aggregation merchant aggregation user aggregation
Double 11 features latest one week latest one month trend repeat buyer features market share similarity
LDA features PCA features
X
X
X
X
X
X age/gender related age related features gender related features
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X
X and brand id and category id are the brand and category of the item . If a user bought multiple items from a merchant on the Double 11 day , then the most frequent one is used . The features are joined with the expanded training/testing data as follows : entity features are joined based on their respective ids ; age related features are joined by the respective entity id and age range ; gender related features are joined by the respective entity id and gender ; interaction features are joined by the two entity ids involved .
12 May
Double 11 day
May
June
July
Aug
Sep
Oct
Nov click/add to cart purchase add to favourite
Figure 2 : Action history of an example entity
3.2 Count/ratio features
Each entity has three types of actions—click , purchase and add to favourites—over the six month period from 12 May , 2014 to 11 Nov , 2014 . Figure 2 shows the action history of an example entity . The three types of actions are represented by green circles . Action count , action ratio and day count . Action counts are number of clicks , purchases , add to favourite actions in each month ( monthly counts ) or over the whole data period ( overall count ) . Count features are the basis for gen erating more complex features . For the entity shown in Figure 2 , the monthly click counts are ( 1 , 1 , 1 , 2 , 1 , 3 , 3 ) , the monthly purchase counts are ( 0 , 1 , 0 , 0 , 0 , 0 , 1 ) , and the monthly add to favourite counts are ( 0 , 0 , 0 , 0 , 1 , 1 , 0 ) . The overall counts of click , purchase , and add to favorite are 12 , 2 , and 2 , respectively . Action ratio is the proportion of a particular action type over all action types , and it can be calculated in each month or over the whole data period . For the entity in Figure 2 , the overall click ratio is 12/(12+2+2)= 0.75 , and June click ratio is 1/(1+1+0)=05
157 Day counts are the number of days with a particular action type in each month or over the whole data period . Day count features are mainly used to differentiate regular buyers from occasional buyers . For example , a user with 10 purchase actions in one single day is different from another user with the same number of purchase actions that spread over 10 different days . The latter user is considered a more regular buyer than the former .
Action count , action ratio , and day count features can be generated for pairs of entities as well . For example , for each huser , merchanti pair , monthly click counts are the number of times the user clicked some items of the merchant in each month . For a hmerchant , brandi pair , overall purchase counts are the number of times products of the brand were purchased from the merchant over the whole data period .
Not all the monthly features are directly used , otherwise there will be too many features . Instead , we use these features to generate more complex features , like monthly aggregation features and trend features as described later . Product diversity features . For a user , product diversity features are the number of unique items , brands and categories that the user clicked , purchased or added to favourites in each month or over the whole data period . For a merchant , product diversity features are defined in a similar way . For a huser , merchanti pair , product diversity features are the number of unique items , brands and categories of the merchant that were clicked , purchased or added to favourites by the user in each month or over the whole data period . The intuition behind product diversity features is that if a user is interested in more items of a merchant , then the user is more likely to buy again from the merchant ( see Figures 6(a ) , 7(d ) and 7(i) ) . Penetration features . Penetration feature of an item is defined as the number of users , who have purchased the item in a given time interval . We have also computed penetration features for merchants , brands and categories . A large customer base usually indicates that the entity has a good reputation , so users are more likely to come back .
3.3 Aggregation features Monthly aggregation features are mean , standard deviation , max and median of monthly action counts , monthly day counts , monthly product diversity counts and monthly penetration counts . User aggregation features are calculated for merchants , brands , categories , hmerchant , brandi pairs and hmerchant , categoryi pairs . The user purchase day aggregation features of a merchant are calculated by first counting the number of days that each individual user bought items from the merchant , and then calculating the mean , standard deviation , max and median over all the users of the merchant . User purchase item aggregation features of a merchant are defined in a similar way over the number of unique items that each user purchased from the merchant . For click and addto favourite actions , user action day aggregation and useraction item aggregation features are calculated in the same way for merchants . For other entities , only the purchase action is considered . User aggregation features are also generated by considering only users of a specific gender or age range .
The intuition behind user aggregation features is — given a merchant , if users visited it or bought items from it more than once on average , then new buyers of the merchant on
“ Double 11 ” day are more likely to come back as well ( see Figures 5(c ) , 5(d ) , 6(e ) , 6(f ) , 7(c ) , 7(e ) , and 7(f) ) . Merchant aggregation features are generated for users . Given a user , his/her merchant purchase day aggregation features are calculated by first counting the number of days that the user bought items from each individual merchant , and then calculating the mean , standard deviation , max and median over all the merchants , from which the user had made at least one purchase . Merchant purchase item aggregation features are calculated over the number of unique items that the user purchased from each merchant in a similar way . For click and add to favourite actions , merchant action dayaggregation and merchant action item aggregation features are calculated in the same way .
Merchant aggregation features reflect users’ habit .
If a user tends to buy from or visit merchants multiple times on average , then he/she is likely to buy from new merchants again ( see Figures 5(a ) , 5(b ) and 7(l ) )
3.4 Recent activity features Double 11 features are counts of clicks , purchases , addto favourites on the Double 11 day . The ratio of the double 11 counts to the overall counts are also calculated . For the entity in Figure 2 , its Double 11 click count is 1 , its Double 11 click ratio is 1/12=0.083 and its Double 11 buy ratio is 1/2=05 If a user has a high Double 11 buy ratio , then the user is more likely to be a one time deal hunter . Latest one week features and latest one month features are counts/ratio of clicks , add to favourites , and purchases in the last one week and in the last one month before Double 11 , respectively .
3.5 Complex features Trend features are calculated based on monthly features . Given monthly counts or monthly ratios y=(y1 , y2 , · · · , y7 ) over seven months from May to November , the slope of the trend line is calculated as α = n Pn i=1(yi ) , where n=7 and xi = i . i=1(xiyi)−Pn Pn i=1(xi ) Pn i=1(xi))2 i=1(x2 i )−(Pn
µ
We also calculated the deviation of the latest month from the previous months and normalized it using either mean or standard deviation as follows : d1 = y7−µ and d2 = y7−µ σ , where y7 is the feature value in November , µ and σ are the mean and standard deviation of the feature values over the previous six months . Repeat buyer features . Repeat buyer number of a merchant is defined as the number of users , who bought on at least two different days from the merchant . For items , brands and categories , repeat buyer number is defined as the number of users , who bought the item/brand/category on at least two different days . Repeat buyer ratio of a merchant/item/brand/category is defined as the ratio of repeat buyers to all buyers ( including non repeating buyers ) of the merchant/item/brand/category .
A repeat buy day of a user at a merchant is defined as a day , such that the user bought items from the merchant both before and on the day . Repeat day number of a merchant is the sum of the repeat buy day of all its users . Repeat buy day ratio is the ratio of the repeat day number of a merchant to the sum of the buy days of all the users of the merchants . Repeat buyer features are also calculated for pairs of entities . For example , for a hmerchant , brandi pair , repeat buyer number is the number of users , who bought items of the brand on at least two different days from the merchant .
158 A high number or a high proportion of repeat buyers indicates that the entity is widely liked , so the customers are more likely to come back again . Our experiment results confirmed this ( see Figures 7(a ) , 7(g ) and 7(j) ) . Market share features measure how important a brand/ category is to a merchant , or how important a merchant is to a brand/category . Take a hmerchant , brandi pair as an example . Let NM B be the number of purchases of the brand from the merchant , NM be the total number of purchases from the merchant , and NB be the number of purchases of the brand from all the merchants . Similarly , we define UM B as the number of users buying the brand from the merchant , UM the total number of buyers of the merchant , and UB the number of buyers of the brand from all the merchants . The following four features are then generated : 1 ) merchant ’s market share on the brand = NM B /NB 2 ) merchant ’s user share on the brand = UM B/UB 3 ) brand ’s market share within the merchant = NM B /NM 4 ) brand ’s user share within the merchant = UM B/UM The first two features measure how important a merchant is to a brand , and the last two features measure how important a brand is to a merchant . Similarly , we can calculate market share features for hmerchant , categoryi pairs . User merchant similarity features measure how similar a user and a merchant are based on brands or categories . They are calculated based on the four market share features defined above and the preferences of users on brands/ categories . The preferences are measured by the times or the number of days the user clicked , purchased , or added to favorites the brand/category . Suppose that a merchant has five brands with respective market shares ( 0.1 , 0.2 , 0.05 , 0.3 , 0.01 ) , and that the number of times of a user buying the five brands are ( 0 , 1 , 2 , 0 , 2 ) . We can compute the inner product of the two vectors , and take it as the similarity score between the user and the merchant , that is , 0.1 × 0 + 0.2 × 1 + 0.05 × 2 + 0.3 × 0 + 0.01 × 2 = 032 We can also take the max , instead of sum , over all brands , then the similarity score is 0.2 × 1 = 02
Intuitively , the more similar a user and a merchant are , the more likely the user will buy from the merchant again ( see Figure 7(h) ) . PCA features are generated based on the similarity between merchants . Give a pair of merchants , we use the number of users who bought items from both of them as their similarity score . The total number of merchants is 4,995 . Therefore , a matrix of 4,995×4,995 is built . This matrix is highly sparse with most elements equal to 0 . Simply adding it into the feature list does not obviously improve the accuracy of classification models , but dramatically increases the model training time . As such , we have applied PCA ( principal component analysis ) [ 3 , 12 ] on the similarity matrix . Then for each merchant , the top 10 principal coordinates are used as merchant features . LDA features . Latent Dirichlet Allocation ( LDA ) [ 4 ] is often used in text mining to retrieve topics from a corpus of documents . It views each document as a mixture of various topics , where each topic is characterized by a distribution over words . The retrieved distribution of the topics can be taken as a feature of the document . We first model users as documents and merchants as words . Given a user , we extract from log activity data all the merchants , from which the user purchased items , and treat these merchants as the words of the user ’s document . By applying LDA on these created documents , we generate features ( ie , distributions of topics over merchants ) for users . Similarly , we model merchants as documents and users as words , and generate features ( ie , distributions of topics over users ) for merchants . We set the number of topics to 40 based on the performance of predictive models .
3.6 Age/gender related features
Different user groups may favor different types of products . For example , clothes and cosmetics are more attractive to women while electric products are more appealing to men . As such , we generated features to describe the popularity of merchants , brands , categories , and items within different user groups , where users are grouped based on their gender or age range . These features include overall buy counts , monthly aggregation on monthly buy counts , penetration features and repeat buyer features . Only users of a particular age range or a particular gender are used to calculate these features .
3.7 Feature ranking
We have generated 1364 features in total . It is crucial to identify important ones and remove those that are of little use to reduce the training cost [ 13 , 7 ] . During the competition , we tested both the wrapper method described in [ 15 , 16 ] and the feature ranking function provided by XGBoost , and we found that all the methods yield very similar feature rankings . In this paper , we report the results by the feature ranking function of XGBoost . Besides ranking all the features together , we also group features based on their types or the profiles they belong to . We rank the features within each group separately , and output the top features . We have also evaluated the importance of each feature group by leaving it out .
4 . MODEL TRAINING
In the competition , we have trained various classification models , including Factorization Machine [ 14 ] , Logistic Regression [ 1 ] , Random Forest , GBM [ 10 ] , and XGBoost [ 6 ] , where grid search was used to select the optimal parameters . XGBoost performed the best .
To further improve the performance , we used ensemble techniques to blend together the predictions made by the above single classifiers . The blending model is basically a weighted sum as defined below . p(u , m ) = k
X i=1 wi × pi(u , m ) ,
( 1 ) where p(u , m ) is the final probability that a user u will make a repeated purchase from a merchant m , pi(u , m ) is the probability predicted by the i th single model , wi is the weight assigned to the i th single model , and k is the number of single models .
We tested two methods to assign the weight wi to the ith single model . For the first method , we manually assign weights to single models , such that single models with higher AUC ( the area under the ROC curve ) scores receive bigger weights . For the second method , we built a classifier to learn the weights . In particular , we generated a k dimensional feature vector for each user merchant pair ( u , m ) , where the i th dimension is the probability pi(u , m ) by the i th
159 Ğ ƌ Ž Đ ^ h
Ϭ͘ϳϬϬϬϬ
Ϭ͘ϲϱϬϬϬ
Ϭ͘ϲϬϬϬϬ
Ϭ͘ϱϱϬϬϬ
Ϭ͘ϱϬϬϬϬ
&ĂĐƚŽƌŝǌĂƚŝŽŶ
>ŽŐŝƐƚŝĐ
DĂĐŚŝŶĞ
ZĞŐƌĞƐƐŝŽŶ
ZĂŶĚŽŵ &ŽƌĞƐƚ
ĂŐŐŝŶŐ ŽĨ ZĂŶĚŽŵ &ŽƌĞƐƚ
' D y' ŽŽƐƚ
ůĞŶĚŝŶŐ
DŽĚĞů h
Ϭ͘ϲϳϵϴϮ
Ϭ͘ϲϴϬϵϳ
Ϭ͘ϲϳϰϲϬ
Ϭ͘ϲϴϵϬϯ
Ϭ͘ϲϵϱϬϵ
Ϭ͘ϳϬϮϴϮ
Ϭ͘ϳϬϰϵϰ
Figure 3 : AUC of single models and the blending model single model . We trained a linear model on these feature vectors to learn the weights .
Our experiments showed that manually assigned weights are often as good as and sometimes even better than the learned weights in this application . Therefore , in the competition , we mainly manually assigned weights to blend the predictions of different models together . We did it in an incremental manner – in each round we kept the best prediction thus far , and blended it with the prediction of a single model . If the resultant AUC score did not improve , we discarded both the blended model and the single model , otherwise , we updated the best prediction using the blended model .
Figure 3 shows the AUC scores of the single models on the testing data . The two linear models , Factorization Machine and Logistic Regression , performed closely . Although their scores are not really high , they contribute to the overall AUC score in the blending model . In ensemble algorithm family , Random Forest has the worst AUC score . However , we found that bagging of Random Forest models can improve the score significantly . XGBoost has the best AUC score of 070282 Comparing with the runner up Gradient Boosting Machine , its improvement is more than 07 % We have blended around 20 single models with various parameter settings and feature settings , and achieved an AUC score of 0.70494 , which is an improvement of 0.21 % over the best single model ( ie , XGBoost ) .
5 . A PERFORMANCE STUDY
In this section we evaluate the importance of features in groups . We first conduct the experiments on training data by five fold cross validation to measure the importance of each group of features ( Section 5.1 ) , and to find the top features locally in each group as well as globally in the full feature set ( Section 52 ) Extensive experimental results show that some features are less important – removing them has only marginal effect on the performance of the predictive models . Such a finding can help a user to determine the subset of features to be applied in real applications for a good balance between model accuracy and training time . Then , we carry out the experiments on testing data ( Section 53 ) We study how the prediction accuracy increases as we incrementally use more features to train models .
5.1 Importance of feature groups
We have generated 1364 features in total . They are organized in groups either by type or by profile as summarized in Table 4 and discussed in Section 3 . Features in a same group are generated based on the same hypothesis , and their importance are evaluated together . If one group
Table 5 : Feature groups and their AUC scores Feature groups #features AUC leave out AUC all features user profile merchant profile brand profile category profile item profile user merchant profile UB and UC profile MB and MC profile monthly action count monthly action ratio product diversity penetration monthly aggregation user aggregation merchant aggregation all aggregation double 11 latest one week latest one month trend repeat buyer UM similarity score PCA LDA age related gender related entity profiles interaction profiles count/ratio aggregation features recent activity complex features age/gender related
1364 201 221 90 90 70 107 26 58 161 163 61 43 164 88 24 276 79 24 10 109 72 192 10 80 30 40
0.70036 0.60442 0.6601 0.65818 0.62087 0.60915 0.62952 0.59148 0.6569 0.68227 0.6791 0.67829 0.66095 0.68729 0.66289 0.58637 0.6946 0.67713 0.66516 0.57935 0.68234 0.67099 0.64762 0.64546 0.64639 0.63794 0.65397
0.69886 0.70096 0.70071 0.69944 0.70002 0.69991 0.70088 0.69954 0.70034 0.70026 0.70029 0.70001 0.70058 0.70031 0.70039 0.69973 0.69996 0.69988 0.70037 0.69989 0.70014 0.70043 0.70023 0.69877 0.70044 0.70017
C U A
C U A
0.75
0.7
0.65
0.6
0.55
0.5
0.75
0.7
0.65
0.6
0.55
0.5
AUC leave out AUC
U
B U
M
B M
C profile
C profile user profile m erch a bra n cate g d profile nt profile ite m profile
U
M profile ory profile
( a ) entity and interaction profiles profiles
AUC leave out AUC m o m o nthly actio nthly actio pro d p e n m o etratio uct diversity n ratio u nt nthly a n d m all a nt a user a erch g gre g g gre atio g atio n n a u o ble 1 g gre g atio g gre n g atio n
1 n co latest o latest o tre n re p e n e w e d n e m o nth ek at b
U
P
L
D
C
A
A
M similarity score uyer a g g e n e relate d d er relate d feature types
( b ) feature types
Figure 4 : AUC scores of feature groups of features turns out to be not important , we can remove the whole group to save the cost of both feature engineering and model training . Table 5 lists the feature groups together with their sizes . The second row shows the AUC score of the full feature set . We study merchant brand ( MB ) profile and merchant category ( MC ) profile together , since they are of small sizes . Likewise , user brand ( UB ) profile and user category ( UC ) profile are investigated together .
We use five fold cross validation to evaluate the importance of each group of features . The predictive model in the experiments is XGBoost with the parameter setting : eta=0.04 , nrounds=400 , max.depth=7 , min child weight= 200 , and subsample=08 The five folds are the same for all the experiments , and the reported results are the averages over the five folds . We first train XGBoost by each group of features alone . The “ AUC ” column in Table 5 and the “ AUC ” bars in Figure 4 are the averaged AUC scores of XGBoost over the five folds . Clearly , the higher the score , the more important the group of features is . We also evaluate
160 frequency proportion of positives frequency proportion of positives frequency proportion of positives
( inf;1.0
( 1.0
9
( 1.3
4
( 1.6
7
( 2.5
4
5;1.3
2;1.6
9;2.5
9
5 ]
4
2 ]
7
9 ]
4
5 ]
5;+inf )
U_merchant_buy_item_num_avg
( a ) user , rank 96 frequency proportion of positives
( inf;1.3
( 1.3
6
( 1.7
8
( 2.6
7
( 4.5
0
1;1.7
2;2.6
4;4.5
6
1 ]
8
2 ]
7
4 ]
0
0 ]
0;+inf )
U_merchant_click_item_num_avg
( b ) user , rank 18 frequency proportion of positives
( inf;0.1
( 0.1
4
4
8 ]
( 0.1 8;0.1
9
7
( 0.2 0;0.2 0 ]
( 0.3 9;0.3 9 ]
( 0.5 9;0.5 9 ]
( 0.7 9;0.7 9 ]
7
7
7
6
6
5
9
5
4 ]
4;+inf )
MG_user_buy_day_num_std
( c ) merchant , rank 1
( inf;1.0 ( 1.0
1
1
8 ]
( 1.0 8;1.0
3
3
5
( 1.0 3;1.0 3 ]
( 1.0 0;1.0 0 ]
5
1
( 1.1 6;1.1 6 ]
( 1.1 8;1.1 8 ]
1
( 1.1 7;1.1 7 ]
3
3
9
9
7
3;+inf )
3 ]
7
M_user_buy_day_num_avg
( d ) merchant , rank 82 frequency proportion of positives frequency proportion of positives frequency proportion of positives
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0 y c n e u q e r f y c n e u q e r f y c n e u q e r f y c n e u q e r f y c n e u q e r f
0.2
0.15
0.1
0.05
0
0.2
0.15
0.1
0.05
0
0.2
0.15
0.1
0.05
0
0.2
0.15
0.1
0.05
0
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0 s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f y c n e u q e r f y c n e u q e r f y c n e u q e r f y c n e u q e r f
0.2
0.15
0.1
0.05
0
0.2
0.15
0.1
0.05
0
0.2
0.15
0.1
0.05
0
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 y c n e u q e r f y c n e u q e r f
1
0.8
0.6
0.4
0.2
0
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;1.0
( 1.0
0
( 2.0
0
( 3.0
0
0;2.0
0;3.0
0
0 ]
0
0 ]
0;+inf )
0
0 ]
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p
( inf;0.0
( 0.0
0
0
0 ]
( 1.0 0;1.0
0
0
( 3.0 0;3.0 0 ]
( 5.0 0;5.0 0 ]
( 8.0 0;8.0 0 ]
( 1 0 0;1 0 ]
9.0 0 9.0 0
0
0
0
0
0
0;+inf )
0 ]
UM_click_item_num
UM_total_buy_action_num
( a ) user merchant , rank 2
( b ) user merchant , rank 7
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;1.0
0
0 ]
( 1.0
0
( 2.0
0
0;2.0
0
0 ]
0;+inf )
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;0.0
4
7 ]
( 0.0
4
( 0.1
4
( 0.8
8
7;0.1
0;0.8
4
0 ]
8
9 ]
9;+inf )
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p
UB_total_buy_action_num
UC_user_buy_action_num_ratio
( c ) user brand , rank 151
( d ) user category , rank 582
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;0.1
( 0.1
7
( 0.2
4
( 0.4
5
9;0.2
3;0.4
4
3 ]
5
8 ]
8;+inf )
7
9 ]
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p
( inf;0.1
( 0.1
8
8
4 ]
( 0.2 4;0.2
8
8
( 0.5 1;0.5 1 ]
( 0.5 1;0.5 1 ]
( 0.7 1;0.7 1 ]
7
0
2
2
7
1 ]
0
1;+inf )
MB_user_buy_day_num_std
MC_user_buy_day_num_std
( e ) merchant brand , rank 3
( f ) merchant category , rank 12
Figure 6 : Top features in interaction profiles interaction profiles , MB and MC profiles together have the highest AUC score , and the AUC score drops the most if they are excluded .
Among all the feature types , monthly aggregation has the highest AUC score—068729 When all the 276 aggregation features ( 164 monthly aggregation features , 88 user aggregation features and 24 merchant aggregation features ) are used to build XGBoost , the AUC score is 0.6945 , which is just 0.82 % lower than the AUC score when all the features are used . LDA has the lowest leave out AUC score ( ie , AUC score drops most if LDA features are excluded ) , which is still just 0.23 % lower than the AUC score of the full feature set . The results above suggest that any feature group can be removed without decreasing the AUC score much .
The “ leave out AUC ” column in Table 5 indicates some feature groups may be redundant given all other features , including merchant profile , brand profile , UB and UC profiles , monthly aggregation features , merchant aggregation features , latest one month features , user merchant similarity features and age related features . The leave out AUC scores of these feature groups are even slightly higher than that of the full feature set . For example , if we exclude merchant profile from the full feature set , then the leaveout AUC score is 0.70096 , which is slightly higher than 070036 If we remove all the above seemingly redundant feature groups , the number of remaining features is 691 ( 50.7 % of total features ) and the AUC score becomes 0.69936 , which is lower than the AUC score of the full feature set .
5.2 Top features
XGBoost calculates a gain score for each feature , which measures how important a feature is to the model . We rank
( inf;0.2
( 0.2
0
0
0 ]
( 0.2 0;0.2
9
9
( 0.5 4;0.5 4 ]
( 0.6 8;0.6 8 ]
( 0.7 2;0.7 2 ]
5
2
2
5
5
1 ]
5
1;+inf )
BG_user_buy_day_num_std
( e ) brand , rank 245
( inf;0.0
( 0.0
2
2
1 ]
( 0.0 1;0.0
3
5
( 0.0 3;0.0 3 ]
( 0.0 7;0.0 7 ]
( 0.1 4;0.1 4 ]
( 0.1 3;0.1 3 ]
8
5
5
8
5
8
3
8
4 ]
4;+inf )
BG_repeat_buy_user_day_ratio
( f ) brand , rank 468 frequency proportion of positives frequency proportion of positives
( inf;1.0 ( 1.0
2
2
( 1.0 9;1.0 9 ]
9
6
( 1.1 1;1.1 1 ]
( 1.2 4;1.2 4 ]
( 1.2 1;1.2 1 ]
( 1.2 6;1.2 6 ]
( 1.5 9;1.5 9 ]
( 1.5 7;1.5 7 ]
( 1.5 3;1.5 3 ]
2
2
6
1
8
8
0
0
9
1
1
1
5
2;+inf )
5
2 ]
C_user_buy_item_num_avg
( g ) category , rank 404
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;1
9
2 2.0 0
0 ]
( 1
9
2 2.0 0
0;+inf )
0.2
0.15
0.1
0.05
0
( inf;0.0 ( 0.0
0
0
( 0.0 6;0.0 6 ]
5
8
( 0.0 7;0.0 7 ]
( 0.0 6;0.0 6 ]
( 0.0 9;0.0 9 ]
( 0.1 8;0.1 8 ]
( 0.1 4;0.1 4 ]
( 0.1 8;0.1 8 ]
( 0.2 9;0.2 9 ]
8
9
1
1
7
7
5
8
8
9
1
1
1
7;+inf )
1
7 ]
CG_repeat_buy_user_ratio
( h ) category , rank 392
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;1
0
8 5.0 0
0 ]
( 1
0
8 5.0 0
0;+inf )
0.2
0.15
0.1
0.05
0
X10__item_0
X9__item_0
( i ) item , rank 74
( j ) item , rank 178
Figure 5 : Top features in entity profiles the importance of a group of features by considering the full feature set but excluding the group . In this way , if the AUC score drops more , then the group is more important . The “ leave out AUC ” column in Table 5 and the “ leave out AUC ” bars in Figure 4 give the results .
Among the 5 entity profiles in Table 5 , merchant profile and brand profile have the highest AUC scores : 0.6601 and 0.65818 , respectively . However , if one of them is removed , the leave out AUC score is even a bit higher than 0.70036—the AUC score of the full feature set . This indicates the redundancy of the two profiles . User profile has the lowest AUC score , but the AUC score drops the most if it is removed . This implies that user profile has important information that does not exist in other profiles . For
161 global rank type
Table 6 : Features with high profile ranking
Feature name U merchant buy item num avg U merchant click item num avg average number of unique items clicked in merchants by the user MG user buy day num std
Description average number of unique items bought from merchants by the user profile user merchant user merchant brand category item user brand usercategory merchantbrand merchantcategory
96 18 1
82 2 7
245
468
404 392
74 178 151 582
3
12 aggregation & aggregation & merchant aggregation merchant aggregation user gender related user aggregation product diversity overall action count user gender related repeat buyer & gender related user aggregation repeat buyer & gender related monthly action count monthly action count overall action count overall action ratio
M user buy day num avg UM click item num UM total buy action num BG user buy day num std
BG repeat buy user day ratio
C user buy item num avg CG repeat buy user ratio
X10 item 0 X9 item 0 UB total buy action num UC user buy action num ratio user aggregation
MB user buy day num std user aggregation
MC user buy day num std standard deviation of the number of days that users made a purchase from the merchant , only users of a particular gender are considered . average number of days that users made a purchase from the merchant number of unique items clicked by the user in the merchant total number of purchases made by the user from the merchant standard deviation of the number of days that users purchased the brand , only users of a particular gender are considered proportion of repeat buy days of the brand , only users of a particular gender are considered . average number of items in the category that were bought by users proportion of repeat buyers of the category , only users of a particular gender are considered . times that the item was clicked in October times that the item was clicked in September total times that the user bought the brand ratio of the times that the user purchased the category to the total actions taken by the user on the category standard deviation of the number of days that users bought the brand from the merchant , only users of a particular gender are considered . standard deviation of the number of days that users bought the category from the merchant , only users of a particular gender are considered . global rank profile type merchant brand repeat buyer user merchant trend merchant brand user aggregation user merchant product diversity user aggregation & merchant gender related user aggregation
Table 7 : Features with high global ranking
Feature name MB repeat buy day ratio user seller store visit day count MDP MB user buy day num avg UM click cat num MG user buy day num avg
MC user buy day num avg
Description proportion of repeat buy days of the brand in the merchant deviation of the number of times the user clicked the merchant in the latest month from the mean of the previous months normalized using mean average number of days users bought the brand from the merchant number of unique categories clicked by the user in the merchant average number of days users bought some item from the merchant , only users of a particular gender are considered average number of days that users bought the category from the merchant .
4 5
6 8 9
10
11
13
14
15 16
17 19
20 merchantcategory merchant user user merchant merchantcategory category user user repeat buyer & age related monthly aggregation U monthly click merchant num std standard deviation of the number of merchants clicked by the user every proportion of repeat buy days of the merchant , only users of a particular age group are considered .
MA repeat buy user day ratio user merchant similarity score
UM buy action num brand merchant user share simscore sum product diversity repeat buyer
UM buy item num MC repeat buy day ratio month similarity score between the user and the merchant , and the score is obtained by first calculating the product of the times that the user bought a brand and the brand ’s user share within the merchant , and then taking sum over all brands in the merchant . number of unique items purchased by the user in the merchant proportion of repeat buy days of the category in the merchant user aggregation merchant tion product diversity aggrega
C user buy day num avg U merchant click day num std average number of days that users bought the category . standard deviation of the number of days that the user clicked merchants .
U buy merchant ratio ratio of the number of merchants that the user made a purchase from to the total number of merchants that the user took some actions features based on their average gain scores over the five folds . Each feature has two rankings : 1 ) profile ranking is the ranking of a feature when only features in the corresponding profile are used to build XGBoost models , and 2 ) global ranking is the ranking of a feature when all of the 1364 features are used to build XGBoost models . Table 6 shows the top one or two features in each profile based on profile ranking . The global rankings of these features are in column “ global rank ” . All the features we generated are numeric . To visualize their correlations with the class labels , we discretize their values using the method in [ 9 ] . To avoid generating too many small bins , we set the minimum number of instances in a bin to 5000 . Figure 5 reports the relative frequency of each bin ( blue bar with the frequency given by the left yaxis ) and the proportion of positive instances therein ( green bar with proportion value given by the right y axis ) for top features in entity profiles . Figure 6 reports the top features in interaction profiles . The x axis in Figures 5 and 6 gives the value ranges of the discretized bins . The proportion of positive instances increases with the feature values in most cases . None of the features is a strong indicator of class labels . The maximal information gain of all features is only 0.00868 after discretization .
Among features in user profile , the average number of items clicked in or purchased from merchants are the top2 features . For merchant profile , the average and standard deviation of the number of days that users made a purchase in the merchant are the top 2 features in the profile , with the latter being the top feature globally . In profiles of usermerchant , merchant brand , and merchant category , top features locally in the profiles also have high global rankings .
Table 7 lists the top 20 features based on global ranking . Those already reported in Table 6 are not repeated in Table 7 . Top features are mainly from user aggregation ( 7 features ) , repeat buyer ( 3 ) , and product diversity ( 3 ) , which account for almost 2/3 of the top 20 features . Figure 7 shows the statistics of the top features , including discretized bins , the frequency , and proportion of positive instances in the bins . Features U monthly click merchant num std ( rank 13 ) and U buy merchant ratio ( rank 20 ) are not shown in the figure , because they have only one bin after discretization . Feature user seller store visit day count MDP is set to 999 , if a user did not visit the merchant from May to October . This feature is discretized into two bins : ( inf , 999 ] and ( 999 , +inf ) , and the second bin has a higher proportion of positive classes . It indicates that if a user visited a merchant before November , then the user is more likely to buy from the merchant again after Double 11 .
Some user aggregation features and repeat buyer features capture like characteristics of entities or interactions from different aspects , and they are highly correlated . For example , feature MB repeat buy day ratio ( Figure 7(a ) ) and feature MB user buy day num avg ( Figure 7(c ) ) are merchantbrand features , and they show similar patterns . The former
162 y c n e u q e r f y c n e u q e r f
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0 y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 y c n e u q e r f
1
0.8
0.6
0.4
0.2
0
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0
( inf;1.0 ( 1.0
1
1
8 ]
( 1.0 8;1.0
3
3
5
( 1.0 3;1.0 3 ]
( 1.1 0;1.1 0 ]
5
1
( 1.1 0;1.1 0 ]
( 1.1 8;1.1 8 ]
1
( 1.1 6;1.1 6 ]
3
3
0
0
8
6;+inf )
6 ]
8
( inf;1.0
( 1.0
0
( 2.0
0
( 3.0
0
( 6.0
0
0;2.0
0;3.0
0;6.0
0
0 ]
0
0 ]
0
0 ]
0
0 ]
0;+inf )
MB_user_buy_day_num_avg
UM_click_cat_num
( c ) user aggregation , rank 6
( d ) product diversity , rank 8 frequency proportion of positives frequency proportion of positives
( inf;1.0
( 1.0
2
2
4 ]
( 1.0 4;1.0
3
3
( 1.0 9;1.0 9 ]
( 1.1 5;1.1 5 ]
( 1.1 6;1.1 6 ]
7
0
0
5
5
8 ]
7
8;+inf )
( inf;1.0
( 1.0
2
( 1.0
3
( 1.0
7
( 1.1
3
3;1.0
8;1.0
2;1.1
2
3 ]
3
8 ]
7
2 ]
3
0 ]
0;+inf )
MG_user_buy_day_num_avg
MC_user_buy_day_num_avg
( e ) user aggregation , rank 9
( f ) user aggregation , rank 10 frequency proportion of positives
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;1.2
0
2 ]
( 1.2
0
( 2.2
5
2;2.2
5
0 ]
0;+inf )
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p
( inf;0.0
( 0.0
2
2
6 ]
( 0.0 6;0.0
4
5
( 0.0 2;0.0 2 ]
( 0.0 2;0.0 2 ]
( 0.1 7;0.1 7 ]
( 0.1 1;0.1 1 ]
2
8
2
5
8
7
4
7
9 ]
9;+inf )
MA_repeat_buy_user_day_ratio
UM_buy_action_num_brand_merchant_user_share_simscore_sum y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;1.0
0
0 ]
( 1.0
0
( 2.0
0
( 3.0
0
0;2.0
0;3.0
0
0 ]
0
0 ]
0;+inf )
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;0.0
( 0.0
3
3
7 ]
( 0.0
6
( 0.1
2
( 0.1
9
7;0.0
4;0.1
1;0.1
6
4 ]
2
1 ]
9
0 ]
0;+inf )
UM_buy_item_num
MC_repeat_buy_day_ratio
( i ) product diversity , rank 15
( j ) repeat buyer , rank 16 frequency proportion of positives frequency proportion of positives
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0
( inf;1.0 ( 1.0
7
7
1 ]
( 1.0 1;1.0
8
8
0
( 1.1 6;1.1 6 ]
( 1.1 3;1.1 3 ]
0
3
( 1.1 8;1.1 8 ]
( 1.1 1;1.1 1 ]
3
( 1.3 4;1.3 4 ]
3
3
1
1
3
3;+inf )
3 ]
3
( inf;0.3
( 0.3
7
7
6 ]
( 0.8
2
( 1.2
4
( 2.1
3
6;0.8
5;1.2
9;2.1
2
5 ]
4
9 ]
3
0 ]
0;+inf )
C_user_buy_day_num_avg
U_merchant_click_day_num_std
( k ) user aggregation , rank 17
( l ) merchant aggregation , rank 19
Figure 7 : Features with high global ranking is the proportion of buyers , who bought the brand from the merchant on at least two different days , among the users who bought the brand from the merchant at least once . The latter is the average number of days that users bought the brand from the merchant . A larger MB repeat buy day ratio value often implies a larger MB user buy day num avg value
( g ) repeat buyer , rank 11
( h ) UM similarity score , rank 14
LDA_user_7
LDA_merchant_8 frequency proportion of positives
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf; 9
9 9.0 0
0 ]
( 9 9 9.0 0
0;+inf )
0.2
0.15
0.1
0.05
0
( inf;0.0 ( 0.0
4
4
1 ]
( 0.0 1;0.0
6
6
8
( 0.0 0;0.0 0 ]
( 0.1 3;0.1 3 ]
8
7
( 0.1 7;0.1 7 ]
( 0.2 4;0.2 4 ]
7
( 0.2 8;0.2 8 ]
0
0
3
3
5
5;+inf )
5 ]
5
MB_repeat_buy_day_ratio user_seller_store_visit_day_count_MDP
( a ) repeat buyer , rank 4
( b ) trend , rank 5 frequency proportion of positives frequency proportion of positives s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;0.0
0
2 ]
( 0.0
0
( 0.1
9
2;0.1
9
7 ]
7;+inf )
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;0.4
8
1 ]
( 0.4
8
( 0.6
8
1;0.6
8
8 ]
8;+inf )
0.2
0.15
0.1
0.05
0 m_10user_action_type_2_rate
U_buy_1111_merchant_ratio
( a ) action ratio , rank 25
( b ) double 11 , rank 40
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;5
9.0 0
0 ]
( 5
9.0 0
0;+inf )
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives last_1week__user_action_0
UM_click_item_num_1mth
( c ) latest one week , rank 38
( d ) latest one month , rank 50
( inf;0.0
( 0.0
0
0
0 ]
( 1.0 0;1.0
0
0
( 3.0 0;3.0 0 ]
( 5.0 0;5.0 0 ]
( 8.0 0;8.0 0 ]
( 1 0 0;1 0 ]
7.0 0 7.0 0
0
0
0
0
0
0;+inf )
0 ]
0.2
0.15
0.1
0.05
0
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p s e v i t i s o p f o n o i t r o p o r p
0.2
0.15
0.1
0.05
0
0.2
0.15
0.1
0.05
0
0.2
0.15
0.1
0.05
0
1
0.8
0.6
0.4
0.2
0 y c n e u q e r f y c n e u q e r f frequency proportion of positives frequency proportion of positives
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0
( inf;6
0 0.0 0
( 6
( 6
( 1
3
0 0.0 0 0;6 9 5.0 0
9 5.0 0 0;1 3
0 ]
( 2
2
( 2
3
7 4.0 0 0;2 2
2 7.0 0 0;2 3
2 4.0 0
7 4.0 0
0 ]
2 7.0 0
0 ]
0;+inf ) 2 4.0 0
0 ]
0 ]
( inf; 1
( 1
0.6 0
0.6 0
8 ]
( 4.8 8; 4.8
9
( 3.7 2; 3.7 2 ]
9
3
( 2.1 6; 2.1 6 ]
( 0.7 7;0.7 7 ]
3
( 8.3 6;8.3 6 ]
4
1
1
4
6 ]
6
6
6;+inf ) penetration_cat_month11_colMax merchant_similairty_PCA10
( e ) penetration , rank 65
( f ) PCA , rank 68
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf;0.0
1
4 ]
( 0.0
1
4;+inf )
0.2
0.15
0.1
0.05
0 s e v i t i s o p f o n o i t r o p o r p y c n e u q e r f
1
0.8
0.6
0.4
0.2
0 frequency proportion of positives
( inf; 0.0 ( 0.0
0
1
( 0.0 0; 0.0 0 ]
( 0.0 9; 0.0 9 ]
( 0.0 6; 0.0 6 ]
( 0.0 5; 0.0 5 ]
( 0.0 3; 0.0 3 ]
( 0.0 ( 0.0 ( 0.0 0;0.0 2; 0.0 1;0.0 0 ] 1 ] 2 ]
( 0.0 2;0.0 2 ]
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
3;+inf )
0
3 ]
( g ) LDA user , rank 42
( h ) LDA merchant , rank 122
Figure 8 : Top features in other feature type groups and vice versa . The same correlation is observed for feature MC user buy day num avg ( Figure 7(f ) ) and feature MC repeat buy day ratio ( Figure 7(j) ) . Both features are merchant category features .
Several feature types , including monthly action ratio , double 11 , latest one week , latest one month , penetration , PCA and LDA , do not occur in the global top 20 feature list ( Table 7 ) . Table 8 reports the top features in these feature groups based on global ranking . Figure 8 shows the statistics of these features .
5.3 Performance on testing data
Section 5.1 and 5.2 evaluate the feature importance on training data by five fold cross validation . In this subsection , we evaluate the importance of features on the testing data . We set the parameters of XGBoost as follows : eta=0.01 , nrounds=2000 , max.depth=7 , min child weight= 200 , and subsample=08 When all the features are used , the testing AUC score is 0.702508 3 as shown in the second row of Table 9 . The last column of the table is the percentage of AUC
3In the competition , we used smaller learning rate and more rounds to achieve the slightly better AUC score of 070282
163 Table 8 : Features with the highest global ranking among features in the remaining feature groups global rank profile user user type monthly action ratio Double 11
Feature name m 10user action type 2 rate
U buy 1111 merchant ratio
Description ratio of the number of purchases made by the user in October to the total number of actions taken by the user in October ratio of the number of merchants that the user made a purchase from on Double 11 to the total number of merchants that the user took some actions on Double 11 the number of clicks made by the user in the last week before Double 11 the number of unique items clicked by the user in the merchant in the latest one month latest one week last 1week user action 0 UM click item num 1mth user user merchant latest month penetration PCA LDA user LDA merchant LDA merchant 8 category merchant user merchant one penetration cat month11 colMax number of users who purchased some item of the category in November merchant similairty PCA10 LDA user 7 the 10 th component of PCA the value of the 7 th topic when users are regarded as documents the value of the 8 th topic when merchants are regarded as documents
25
40
38 50
65 68 42 122
Table 9 : AUC on testing data AUC
#features
% of drop feature types
1 all feature types 2 overall action counts/ratio , overall day counts , product diversity , monthly aggregation , user aggregation , merchant aggregation , repeat buyer , 11 , latest one month double profiles all profiles user merchant profile , merchant profile profile , user
3 feature set 2 plus
LDA features same as feature set 2
4 same as feature set 3 feature set 2 plus MB and MC profiles
5 same as feature set 3 feature set 4 plus brand profiles and category profiles all profiles
6 feature set 3 plus simi user merchant larity features
7 feature set 6 plus action monthly counts , penetration features and PCA features
1364 354
0.702508 0.694927
1.08 %
434
492
0.696812
0.81 %
0.699226
0.47 %
616
0.701392
0.16 %
866
0.701913
0.08 % all profiles
1053
0.702250
0.04 % score drop , when only subsets of features ( as specified in the second and third columns of the table ) are used .
Feature set 2 contains 354 features from nine feature types and three profiles . Its AUC score is only 1.08 % lower than the AUC score when all the 1364 features ( ie , feature set 1 ) are used . When more feature types and/or profiles are added ( top down in Table 9 ) , the AUC score increases marginally . The results again imply that we can use a smaller number of features to train predictive models without decreasing the AUC score significantly .
6 . CONCLUSION
In this paper , we presented our winning solution for the repeat buyer prediction competition hosted at IJCAI 2015 conference . We generated a large number of features to capture the preferences and behaviors of users , characteristics of merchants , brands , categories and items and the interactions among them . Our study shows that none of the features generated is a strong indicator of class labels , so we need hundreds of features to achieve a relatively high AUC score . We hope our winning solution , along with concrete analysis on feature engineering , would serve as a solid stepping stone for practitioners to solving future e commerce problems . It is a tedious task to generate and manage a large number of features . As our next step , we will explore how to automate the feature generation and selection process for e commerce prediction tasks .
7 . REFERENCES [ 1 ] Fitting generalized linear models . Available on https://statethzch/R manual/R devel/library/stats/ html/glmhtml
[ 2 ] Generalized linear models . Available on http :
//scikit learn.org/stable/modules/linear modelhtml
[ 3 ] H . Abdi and L . J . Williams . Principal component analysis . Wiley Interdisciplinary Reviews : Computational Statistics , 2(4):433–459 , 2010 .
[ 4 ] D . M . Blei , A . Y . Ng , and M . I . Jordan . Latent dirichlet allocation . Journal of Machine Learning Research , 3(4 5):993–1022 , 2003 .
[ 5 ] L . Breiman . Random forests . Mach . Learn . ,
45(1):5–32 , 2001 .
[ 6 ] T . Chen and T . He . Xgboost : extreme gradient boosting . Available on https://githubcom/dmlc/xgboost
[ 7 ] M . Dash and H . Liu . Feature selection for classification . Intelligent data analysis , 1(1):131–156 , 1997 .
[ 8 ] P . Domingos . A few useful things to know about machine learning . Communications of the ACM , 55(10):78–87 , 2012 .
[ 9 ] U . M . Fayyad and K . B . Irani . Multi interval discretization of continuous valued attributes for classification learning . In Proc . of the International Joint Conference on Uncertainty in AI , pages 1022–1027 , 1993 .
[ 10 ] J . H . Friedman . Greedy function approximation : A gradient boosting machine . Annals of Statistics , 29:1189–1232 , 2000 .
[ 11 ] Y C Juan , W S Chin , and Y . Zhuang . Field aware factorization machines . Available on https://githubcom/guestwalk/libffm
[ 12 ] S . Lˆe and F . H . Julie Josse . FactoMineR : an R package for multivariate analysis . Journal of statistical software , 25(1):1–18 , 2008 .
[ 13 ] L . C . Molina , L . Belanche , and `Angela Nebot . Feature selection algorithms : A survey and experimental evaluation . In ICDM , pages 306–313 , 2002 .
[ 14 ] S . Rendle . Factorization machines with libfm . ACM Transactions on Intelligent Systems and Technology , 3(3 ) , 2012 .
[ 15 ] K Q Shen , C J Ong , X P Li , and E . Wilder Smith .
Feature selection via sensitivity analysis of svm probabilistic outputs . Machine Learning , 70(1):1–20 , 2008 .
[ 16 ] J B Yang and C J Ong . An effective feature selection method via mutual information estimation . IEEE Transactions on Systems , Man and Cybernetics ( Part B ) , 42(6):1550 – 1559 , 2012 .
164
