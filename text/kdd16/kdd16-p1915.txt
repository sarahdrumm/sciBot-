Probabilistic Robust Route Recovery with Spatio Temporal
Dynamics
Hao Wu† Jiangyun Mao† Weiwei Sun† Baihua Zheng‡ Hanyuan Zhang†
Ziyang Chen† Wei Wang†
†School of Computer Science , Fudan University , Shanghai , China
†Shanghai Key Laboratory of Data Science , Fudan University , Shanghai , China
‡Singapore Management University , Singapore
{wuhao5688 , jymao14 , wwsun , zhanghy12 , ziyangchen13 , weiwang1}@fudaneducn , bhzheng@smuedusg
ABSTRACT Vehicle trajectories are one of the most important data in locationbased services . The quality of trajectories directly affects the services . However , in the real applications , trajectory data are not always sampled densely . In this paper , we study the problem of recovering the entire route between two distant consecutive locations in a trajectory . Most existing works solve the problem without using those informative historical data or solve it in an empirical way . We claim that a data driven and probabilistic approach is actually more suitable as long as data sparsity can be well handled . We propose a novel route recovery system in a fully probabilistic way which incorporates both temporal and spatial dynamics and addresses all the data sparsity problem introduced by the probabilistic method . It outperforms the existing works with a high accuracy ( over 80 % ) and shows a strong robustness even when the length of routes to be recovered is very long ( about 30 road segments ) or the data is very sparse .
Keywords Trajectory ; route recovery ; spatio temporal ; location based services
1 .
INTRODUCTION
With the development of GPS devices , more and more trajectory data are generated every day which brings the bloom of LocationBased Services ( LBSs ) [ 21 ] . To improve the quality of service , most , if not all , applications prefer a large volume of data with zero uncertainty . However , most of the data in the real world have uncertainty . Consequently , recovering the routes of uncertain trajectory data can help enhance the utility of data and reduce the uncertainty which can improve the performance and service quality of those trajectory data driven applications .
Route recovery is an important building block for many reallife applications , and we list two scenarios where route recovery could make an impact . i ) According to a statistical analysis on the GPS data collected from 10,000+ taxis by [ 19 ] , more than 60 % taxi trajectories are in low sampling rate ( eg , a GPS point every 2+ minutes ) and reducing the uncertainty of those low sampling rate trajectories is an urgent issue . ii ) Digital cameras and sensors installed in the roads are able to capture certain information of vehicles with high accuracy but those devices are still not universal . Route recovery can help to recover the trajectories passing by roads without devices installed .
In the literature , there are several works related to route recovery and they can be categorized into two groups , non data driven approaches without relying on historical data [ 5 , 9 , 12 , 13 , 19 ] , and data driven approaches that are based on historical data [ 3 , 16 , 20 ] . Non data driven approaches recover the routes according to geometric properties of digital map . They utilize certain external properties of road networks ( eg , the turning count , length and number of lanes ) as the cost and return the optimal route having the minimum cost . These approaches model the cost empirically without any guarantee on the effectiveness as they have no historical data to infer from . Data driven approaches recover the routes by leveraging historical data . A typical approach of finding the most popular route is introduced in [ 3 ] , which is applicable to the route recovery problem , under the assumption that people tend to use the route that most people prefer . [ 16 ] tries to calibrate trajectories to some anchor points . If we use turning points as the anchor points , we can also apply the complementary component of this approach to solve route recovery problem . Another example is presented in [ 20 ] , which finds the candidate routes through dynamic programming based on route popularity . To the best of our knowledge , this approach , as the state of the art solution directly designed for route recovery problem , makes a comprehensive usage of historical data and outperforms many existing approaches .
We also adopt a data driven approach to tackling route recovery problem , because data drive approaches can draw more informative inference than geometric based approaches , as stated in [ 20 ] . In addition , we propose to solve the problem from a probabilistic view instead of an empirical view . Empirical approaches solve the problem by intuition while probabilistic approaches can guarantee the effectiveness of solutions via sound theoretical models .
However , building a probabilistic model based on historical trajectory data will definitely suffer from data sparsity . It is wellknown that more than 80 % of the traffic in a typical city runs on only 10 % to 20 % of the roads hence the trajectory data are expected to be sparse . Besides , as mentioned before , given a set of trajectories , the volume of high sampling rate data based on which a probability model will be built is often much smaller than that of low sampling rate data . Inferring the probability distribution ( eg , the transition probability between roads ) is essential for ev
1915 ery probability model , which can be addressed by traditional statistical frequency based approaches . However , when the data are sparse and the volume of data is insufficient , directly counting the road frequency will result in a poor estimation according to the theory of probability . Moreover , as it is guaranteed that some roads are less frequent with insufficient trajectories passing by , missing value problem is also expected . Thus , how to address data sparsity issue will be the main challenge that our approach needs to address . Note that we will explain different types of data sparsity that route recovery has to address in details in Section 4 when we present our solution .
We summarize the key points to the route recovery problem in the following . 1 ) The approach should be data driven . 2 ) The approach should be fully based on probability . 3 ) The approach should take care of the data sparsity problem . To our best knowledge , none of the existing works fulfills these three conditions simultaneously .
Motivated by this , we propose a novel route recovery system fully based on probabilistic models . Our system incorporates both temporal dynamics and spatial dynamics according to the theoretical probabilistic derivation and addresses all the challenges introduced by the data sparsity mentioned above . We include in our system a temporal model and a spatial model as the key components . The temporal model aims to estimate the travel time of a candidate route to quantify the likelihood of the candidate route being the answer . Our spatial model estimates how reasonable a candidate route is via inverse reinforcement learning that can learn the latent cost ( reward ) of a road through historical data . To summarize , we make three main contributions in this paper .
Non Empirical Approach : We study the problem in a probabilistic view and incorporate both spatial and temporal dynamic with the theoretical probabilistic derivation .
Data Sparsity Solution : We propose multiple strategies to address the data sparsity problem . Our temporal model includes a new regression model to estimate the travel time of temporal sparse trajectories , and also proposes a static temporal separation matrix factorization approach to deal with data sparsity ; the spatial model adopts inverse reinforcement learning to solve the data sparsity problem against traditional statistical frequency based approach .
Large Improvement : We conduct extensive experiments using real taxi trajectories to demonstrate both the effectiveness and the robustness of our system when facing data sparsity issue . The results show that our system largely outperforms existing approaches . It achieves a high accuracy consistently ( over 80% ) , even when the pair of GPS locations are far away from each other ( eg , about 30 road segments apart ) while other approaches can only achieve an accuracy about 40 % . 2 . RELATED WORK
Many existing works [ 12 , 13 , 22 ] adopt shortest path to return a route with minimum weight . [ 22 ] is based on geometric and topological information of the road network ; [ 12 ] defines the cost as a heuristic cost function which is related with the delay of traffic lights and left turns ; [ 13 ] , as an extension of [ 12 ] , uses the same cost function to build a candidate graph and finds the path with as many straight lines as possible . These approaches fail to capture the preference of drivers when choosing a route , as many drivers select roads not based on whether roads are straight or not but based on the traffic condition . Differently , our system can capture the spatial dynamics by learning from historical trajectories . Map matching algorithms for low sampling rate trajectories are proposed in [ 8 , 19 ] . Although these approaches have also used the concept of transition probability , they only use this probability as a factor in a score function but the real frameworks are still empirical based . In brief , they are all non data driven approaches , and the probabilities are empirically set .
On the other hand , some existing works including [ 5 , 7 , 16 , 20 ] adopt model based approaches to solve the route recovery . [ 5 ] infers the route between two GPS samples by a binary logit model utilizing hidden Markov model . However , the performance of this model deteriorates when there are more than two candidate routes . [ 7 ] uses absorbing Markov chain model to synthesize routes for low sampling trajectories . Although it is a probabilistic approach , it suffers from the problem of data sparsity , as it counts the frequency in historical data to estimate the transition probability between two states . [ 16 ] constructs the transition matrix without considering the destination information which is fatal in the route recovery problem . Besides , it needs to enumerate all the possible paths which makes the computation cost extremely high when the route to be recovered is long . [ 20 ] constructs the traverse graph from historical trajectories and finds the optimal route in the graph via dynamic programming . This approach deals with data sparsity but the whole framework is empirically designed . As an contrast , each component of our system is designed with the guarantee of probability while taking great care of data sparsity . Besides , the query process of our system is optimized to support online search .
3 . PRELIMINARY
We first present the formal definitions of road network , route and trajectory as following .
DEFINITION 1
DEFINITION 2
( ROAD NETWORK ) . A road network is modeled as a directed graph G(V , E ) , where V refers to the set of vertices ( ie , crossroads ) and E refers to the set of edges ( ie , road segments ) . We assume each edge r ∈ E is from a vertex v ∈ V to another vertex v . ∈ V , where r.s = v and r.e = v . represent the source and the end of the edge respectively , r.s → r.e refers to the direction , and r.len is the length of the edge r . ( ROUTE ) . A route R is a list of adjacent road segments , r1 → r2 → ··· rm , where each two consecutive road segments are connected in G , ie , ri.e = ri+1s We use R[i ] to denote the i th road segment in R . ( TRAJECTORY ) . A trajectory T r is a sequence of GPS positions with timestamps , i.e , T r = {(p1 , t1 ) , ( p2 , t2 ) , ··· , ( pn , tn)} , where pi in the form of ( xi , yi ) captures the latitude and longitude of the i th GPS position and ti is the timestamp . ( MAP MATCHING ) . Map matching is a procedure to match the trajectory T r to a route R . R(pi ) returns the road segment to which point pi is mapped .
DEFINITION 3
DEFINITION 4
When the sampling rate is low , two continuous GPS sample points p1 , p2 might be mapped to two road segments r1 , r2 that are not adjacent ( ie , r1.e '= r2s ) In other words , the moving object must pass certain unknown road segment(s ) after r1 but before r2 . Take Figure 1 as an example . Given a trajectory T r = {(ps , ts ) , ( pe , te)} , both routes R1 and R2 are possible . In this paper , we study the problem of route recovery defined in Problem 1 , which locates the route R∗ that has the highest possibility of being taken by a given trajectory T r . Note that although we focus on the recovery of the route between two consecutive locations , the techniques developed can be easily extended to recover the route passed by several consecutive locations in a sparse sampled trajectory . ( ROUTE RECOVERY ) . Given a set of ( high sampling rate ) historical trajectories T and a road network G , the route recovery query takes two GPS positions with timestamps ( ie , ( ps , ts ) and ( pe , te ) ) as input , and tries to recover the real route R from ps to pe that is passed by T r as accurate as possible . Note that there is no restriction that ps/pe can only be the source/destination of a trajectory , any two consecutive positions in a trajectory are legal to be the input .
PROBLEM 1
1916 1(cid:42 ) fi fi
( sp t , s
)
2(cid:42 ) fi
( ep t , e
)
Figure 1 : Example route recovery problem
4 . SPATIO TEMPORAL BASED ROUTE RE
COVERY SYSTEM
In this section , we introduce a novel system as our solution to perform Route Recovery , namely Spatio Temporal based Route Recovery System ( STRS ) . STRS consists of three main components , preprocessor , spatio temporal model and route search engine , as shown in Figure 2 .
Historical Trajecories
Road Network
Map Matching
Trajectories & Routes
Temporal Partitioning
Temporal Model Time Estimation
Matrix Factorization
Spatial Model
Inverse Reinforcement
Learning
Trajectories In Time Slots
Candidate Route Posterior Probability
Route Search Greedy Search
Exact Search
Preprocessor
Spatio Temporal Model
Route Search Engine
Figure 2 : System architecture
Preprocessor performs preprocessing of trajectories , including map matching and trajectory temporal partitioning . Spatio temporal Model , as the essential part of STRS , tries to learn and model properties of routes from historical data via a probability approach . This component contains two separate models , ie , the spatial model and the temporal model . Route Search Engine computes the posterior probability of a candidate route which can be regarded as the score of a route and returns a route with the highest score .
The main objective of system STRS is to solve the route recovery problem via a pure probabilistic approach . To facilitate following discussion , we summarize the main notations used in this paper in Table 1 . Given a start GPS position ps with its timestamp ts and an end GPS position pe with its timestamp te , the route recovery problem is equivalent to find the route R∗ with the highest posterior probability wrt the input information , ie ,
R∗
= arg maxR P ( R|ps , pe , ts , te,T ) = arg maxR P ( R|ps , pe , te , Δt,T ) where T is the set of historical trajectories and Δt = te−ts . Based on Bayes’ theorem ,
P ( R|ps , pe , te , Δt,T ) = P ( R , ps , pe , te , Δt,T )/P ( ps , pe , te , Δt,T ) ∝ P ( R , ps , pe , te , Δt,T ) = P ( Δt|R , ps , pe , te,T ) · P ( R|ps , pe , te,T ) · P ( ps , pe , te,T ) ∝ P ( Δt|R , ps , pe , te,T ) · P ( R|ps , pe , te,T ) ( 1 ) Since P ( ps , pe , te , Δt,T ) and P ( ps , pe , te,T ) are the probabilities of input information , they can be regarded as constants . In the following , we omit the notation T in all the representations of probabilities for presentation clarity . Based on Equation ( 1 ) , we understand that the posterior consists of two probabilities , the time interval likelihood part P ( Δt|R , ps , pe , te ) and the time interval invariant posterior part P ( R|ps , pe , te ) . The former describes how likely the time interval will be if R is the route and te is the end time ; the latter quantifies the existence probability of R if the route starts from ps and ends in pe at time te .
Table 1 : Major notations
Notation Description r R , R[i ] R(p ) ps/pe ts/te Δt T τ ( t ) road segment or road element ( in Section 421 ) route , i th road segment in route R road segment to which position p is matched start/end position in a route recovery query start/end timestamp in a route recovery query time interval of a route recovery query , ie , Δt = te − ts entire historical trajectory set time slot in which time t falls interval of a time slot
ν
4.1 Preprocessor
The preprocessor of STRS performs two processes , map matching and temporal partitioning . We first adopt map matching algorithm to get the ground truth of historical data , ie , the actual route . We consider all the trajectories that can be mapped to routes without uncertainty as useful historical samples . Eg , according to [ 10 ] , when the sampling rate is 1 ∼ 30s per point , map matching can achieve an accuracy about 99 % , indicating that these trajectories can obtain the ground truth route without uncertainty .
It is known that the properties of historical trajectory data may vary over time [ 1 ] . This observation motivates us to partition the trajectories based on the temporal dimension . We then introduce a parameter ν which determines the temporal duration within when the trajectories shall be gathered into one class . By default , we set ν to 60 minutes in our experiments . Accordingly , there are 48 partitions T1,T2,··· ,T48 with T1,T2,··· ,T24 corresponding to working day and T25,T26,··· ,T48 corresponding to weekends . For those trajectories crossing multiple time slots , we distribute them according to the time slot which te is in . The effects of different time slot granularity will be studied in Section 531 4.2 Spatio Temporal Model
As introduced previously , spatio temporal model is the essential component of STRS . Recall that Equation ( 1 ) consists of two probabilities , ie , P ( Δt|R , ps , pe , te ) , and P ( R|ps , pe , te ) . The former is to model the likelihood of the time interval that is taken care by the temporal model and the latter is the posterior of a route regardless of time information Δt which accounts for a spatial model to model existence of the route . 421 Temporal Model In the following , we introduce our temporal model to model the likelihood P ( Δt|R , ps , pe , te ) . The key is to model the distribution of the observed time interval Δt , conditioned by a candidate route R , given ps and pe under time slot τ ( te ) , where τ ( te ) refers to the time slot that end time stamp te falls in . Intuitively , the distribution will be strongly correlated with the expected time of R in τ ( te ) , ie , the closer Δt and the expected time of R are , the higher the likelihood will be . The connection between the expected time and the distribution will be further demonstrated in Section 43 To be more comprehensive , we call the expected time as estimated time ( denoted as ΔtE ) to emphasize that we want to perform estimation on the time cost of a candidate route R , which is achieved by two steps , including Regression Estimation Model and Staticdynamic separation Matrix Factorization , as detailed below . Regression Estimation Model . This step is to estimate the time taken by a given R in time slot τ ( te ) through historical trajectories . There are several existing works on solving the travel time estimation . Most of them can be categorized into road segment based and route based . However , both categories face some problems in supporting route recovery . Road segment based approaches , eg , [ 4 , 15 ] , first estimate the average speed and then get the time cost of individual road segment . The travel time of a route is the summation of the time cost of road segments passed by the route . These
1917 approaches face issues when the speed is not available or the sampling rate is not high enough . Take p1 and p2 in Figure 3 as an example . The ratio of the total travel distance between p1 and p2 to the time interval does not provide a good estimation of the travel speed as the route passes two junctions and it is very likely that the speed varies . However , this sample is a useful historical trajectory . Although the corresponding road segment of p1 and p2 , ie,r1 and r3 , are not adjacent , it is still easy to infer that r2 should be included in the route . On the other hand , route based approaches , eg , [ 1 , 11 ] , collect the same routes in the historical dataset and return their mean time cost as the answer . This kind of approaches can avoid estimating the speed thus they can address the problem faced by road segment based approaches . However , they face significant data sparsity problem . Note that data sparsity is severe in route recovery as the number of historical routes that are same as R presented in τ ( te ) could be very small or even zero . In other words , although route based approaches have better performance , they are not applicable in route recovery due to the small number of historical routes that are same as R presented in τ ( te ) . A hybrid approach that combines both road segment based and routebased approaches is proposed in [ 18 ] . It estimates the time cost of individual driver which is over grained and will deteriorate the data sparsity problem . Hence , we propose an approach to combine these two types of approaches by a regression model to solve the data sparsity problem .
.
. fi .
.fi' ffflfi( fffffi ffffffi) ff fflff ()fl(ffi
Figure 3 : Example showing the sampling rate problem
In detail , we first construct a matrix H ∈ R
The main idea of our solution is that we adopt a road segmentbased approach to estimate the total time cost of a route and employ a route based approach to train the time cost of each road segment by minimizing the error of the estimation in historical data . As we intend to consider the time spent on the crossroads , notation r denotes not only road segments but also crossroads , which is different from its original meaning used in Definition 2 . For simplicity , we name rs asroad elements . |Tτ |×(m+n ) , where m and n refer to the total number of road segments and crossroads m+n denotes the ith row of H and Hi∗ represpectively . Hi∗ ∈ R resents each historical training sample . For each historical route R(i ) processed from Tτ ( for simplicity , in this section we use τ to indicate τ ( te) ) , we construct each training sample based on following criteria . We use superscript with parentheses , eg , ( i ) , to index the training sample . Note that R(i)[1 ] and R(i)[k(i ) ] represent the first and the last road segment of R(i ) with corresponding length k(i ) = |R(i)| . if rj ∈ R(i ) & rj '= R(i)[1 ] & rj '= R(i)[k(i ) ] . 1 s ,R(i)[1 ] if rj = R(i)[1 ] p(i ) distG R(i)[1].len if rj = R(i)[k(i ) ] otherwise ( 2 )
R(i)[k(i)].s,proj(p(i ) R(i)[k(i)].len
⎧⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎩ e ,R(i)[k(i) ] )
Hij =
,R(i)[1].e
. . distG proj fi fi fi
0
Here , distG(a , b ) refers to the network distance from a to b via road network G , and proj(p , r ) refers to the projection position of a point p on the road segment r . We represent a historical route R(i ) by setting the element of Hi∗ to 1 corresponding to the road segments passed by R(i ) . Note that although a route is represented by a set of complete road segments , the training input representa tion Hi∗ is different . As the start position p(i ) s and the end position e may lay on the middle of the road segment , elements in Hi∗ p(i ) corresponding to R(i)[1 ] and R(i)[k(i ) ] are set to the ratio in terms of length within the road segment passed by the trajectory . Equation ( 2 ) gives out the criteria for road segments and for crossroads we set corresponding elements in H to 1 if the crossroad is passed by R(i ) .
For all of the training data , we set the cost function as the squared error between the estimated travel time and the observed time interval as Equation ( 3 ) . The first component represents the error in a matrix form , where ΔT = ( Δt(1 ) , Δt(2),··· , Δt(|Tτ | ) ) and φτ ∈ R m+n . Note that φτ ( j ) is the estimated time cost spent on rj in time slot τ . Because the value of φτ may be odd in some road segments as it can be set to any value to fit the training data , we add the second component to restrict the solution so it can only vary around a given value , ie , φ . τ denotes a rough estimation of the time cost , which is estimated by the road segment based approach . Although this estimation is not accurate , we can infer that the actual time cost of each road segment shall be not too far from this estimation . Moreover , we also exert a regularization on φτ to further avoid over fitting .
τ . φ .
'
C(φτ ) =
1 2
Hφτ − ΔT2
2 +
φτ − φ .
τ2
2 +
λ1 2
φτ2
2 ( 3 )
λ2 2
We use stochastic gradient decent ( SGD ) [ 2 ] to train the model and the gradient can be computed by :
∇C =
Hi∗φτ − Δt(i )
Hi∗ + λ1
φτ − φ .
τ
(
)
+ λ2φτ
After training φτ for each individual time slot , we combine them together in column wise , ie , Φ = ( φ1 φ2 ··· φ48 ) ∈ R ( m+n)×48 . Note that in order to achieve low variance , we train the road elements with the number of historical trajectories passing by larger than certain support count ( 5 in our experiment ) . Besides , as the dataset will further be partitioned into 48 time slots and we understand that 80 % of the traffic in a typical city runs on only 10 % to 20 % of the roads , a new data sparsity problem emerges . Actually , after the training , an incomplete time cost matrix ˜Φ with some elements being null is generated and we will visualize the missing elements in Section 532 Static dynamic separation Matrix Factorization . This step is to infer the value of missing elements in the cost matrix ˜Φ according to other elements . We assume the time cost of a road element consists of two costs , including a static cost and a temporal dynamic cost , as presented in Equation ( 4 ) . Static cost models the time cost that is influenced by the explicit features of the road element , such as the length of the road , the degree of a crossroad and so on . This cost is invariant over time . The temporal dynamic cost captures the dynamic cost which varies over time . ( 4 ) where Φs , Φt ∈ R ( m+n)×48 . Φs is the static time cost matrix and ( Φs)ij denotes the static time cost of road element i in time slot j . As the static time cost matrix is temporal invariant , ( Φs)i1 = ( Φs)i2 = ··· ( Φs)i48 . We factorize it into F W where F ∈ R ( m+n)×η is the feature matrix of all road elements and η denotes the number of explicit features . The ith row Fi∗ represents the features of ri . The road segment features used in our system include i ) the length of a road segment ; ii ) the level of the road segment ( eg , highways , parkways ) ; and iii ) the number of POIs near the road segment ; while the features of crossroads used in our system are i ) the degree of the crossroad ; ii ) the number of POIs near the crossroad ; and iii ) the average level of the road segments that are connected to the crossroad . W ∈ R η×48 is the weight matrix which is to be trained , with stacking 48 equivalent weight vectors ws in the column wise , ie , W = ( w , w,··· , w ) .
Φ = Φs + Φt = F W + RΓ
'
1918 Φt ∈ R
( m+n)×48 is the temporal dynamic cost matrix and ( Φt)ij denotes the temporal dynamic cost of ri in time slot j . We factorize Φt into two low rank matrices , ie,Φt = RΓ . We propose a latent road element factor matrix R ∈ R ( m+n)×' , where each row of R , ie , Ri∗ ∈ R '×1 , represents the latent factors of road segment ri and denotes the dimension of latent factors . Similarly , we introduce a latent temporal factor matrix Γ ∈ R 48×' with each row Γj∗ ∈ R '×1 representing the latent factors wrt time slot j . Figure 4 illustrates the factorization .
'
.
.
(
.
)
( cid:73 ) .
.
( cid:65 ) . fi fi fi
. ff
. '
( cid:73 )
( cid:65 )
Figure 4 : Illustration of matrix factorization
By approximating the incomplete matrix ˜Φ based on Equation ( 4 ) and reconstructing the cost matrix according to learned W , R and Γ , we can fill in the missing elements in ˜Φ . The cost function is the square error between the reconstructed elements and the elements .
J(W , R , Γ ) =
F W + RΓ
( W2
1 2 λ3 2
+
' − ˜Φ
2 ◦ M ) F + Γ2
F
F
F + R2
∂J
Here , M indicates not null elements in ˜Φ and it is a 0 1 matrix satisfying that Mij = 0 if ˜Φij is null and 1 otherwise . The gradient is computed as follows : ∂w = Fi∗F ' ∂J ∂Ri∗ = ( Γ ∂J ∂Γj∗ = ( R' j∗Γj∗ + λ3)Ri∗ + ( w'Fi∗ − ˜Φij + λ3)Γj∗ ' i∗Ri∗ + λ3)Γj∗ + ( w'Fi∗ − ˜Φij + λ3)Ri∗ i∗Γj∗ − ˜Φij)Fi∗ + λ3w i∗ w + ( R'
We can optimize the cost function by gradient based optimization methods [ 2 ] . After learning the weight matrix W and two latent factor matrices R and Γ , we can reconstruct the complete time cost matrix according to Equation ( 4 ) and estimate the travel time of a route by constructing Hi∗ according to Equation ( 2 ) and perform inner product to the τ th column of Φ , ie , ΔtE = Hi∗Φ∗τ . The detail of how to use the estimated time to model the probability P ( Δt|R , ps , pe , te ) will be introduced in Section 43 Why data sparsity can be solved . i ) For those sparse sampled historical trajectories , although the route segment based estimation is inaccurate , our regression model can leverage the time information of the entire path to adjust the cost of road elements to minimize the estimation error of routes . ii ) For the sparsity of identical routes , we perform the final estimation through a road segment based view to avoid the sparsity of historical routes . iii ) For the sparsity of missing values in the matrix , matrix factorization enables the inferring of the missing value based on other values , and we separate the static cost which can even work for the roads without any car passed by in any time slot . 422 Spatial Model The spatial model is to model P ( R|ps , pe , te ) without considering the time interval Δt . Since this probability is only relevant to the start position ps and the end position pe with respect to the time slot τ ( te ) , we can observe that it only depends on the spatial influence under the dataset of Tτ ( te ) . For clarity of formulas , we omit the conditional variable te or Tτ ( te ) in the following discussion . Recall that in Section 421 notation r denotes both road segments and crossroads , here we just change back the notation , ie , r refers to only road segments now . Suppose R consists of k road segments , P ( R|ps , pe ) can be equally represented as
P ( R|ps , pe ) = P ( R[1]|ps , pe ) k . i=2
P ( R[i]|R[i − 1 ] , ps , pe )
( 5 )
N . N
Markov assumption is often adopted on the driving behavior to facilitate the modeling [ 7 , 10 , 21 ] . A straightforward approach to model the transition probability is to perform the statistic .
P ( R[i]|R[i − 1 ] , ps , pe ) =
( 6 ) is the count of historical trajectories starting from R(ps ) where N . and ending in R(pe ) while passing R[i−1 ] → R[i ] . N is the count of trajectories starting from R(ps ) and ending in R(pe ) while passing R[i− 1 ] . However , this naive method suffers from a data sparsity problem . To be more specific , for some R(pe ) , we might not be able to find many trips that pass R[i−1 ] and are ended in R(pe ) . If N is not large enough , the estimation of the transition probability can be largely affected by randomness . The effects of data sparsity when using this frequency based approach to compute the transition probability will be illustrated in Section 533 Markov Decision Process and Reinforcement Learning . In our system , we adopt a better model to address the data sparsity problem . The decision process that makes each decision based on Markov property can be modeled as a Markov Decision Process ( MDP ) [ 17 ] . An ( deterministic ) MDP is a tuple ( S , A , γ, ) , where S is state set of the system , A is the action set , γ ∈ [ 0 , 1 ] is a discount factor , and is the reward function where ( s ) denotes the reward at state s . An MDP works as following . It starts at some state s0 with reward ( s0 ) and performs an action and the state of system transits to s1 with collecting reward ( s1 ) . It continues until it reaches the goal . Making decision at certain state is irrelevant to all of the previous states , ie , Markov property . Reinforcement learning is a learning algorithm in AI to make an optimal decision with maximized expected rewards in the future [ 17 ] in an MDP . This model is similar to making decision in the crossroads when driving . We can regard each road segment r as a state and the transition ri → rj between two adjacent road segments as action . The reward of each state is the negative latent cost of each road as the larger the cost is , the smaller the reward will be . Specifically , given an MDP , reinforcement learning can be performed to figure out the best policy of each state . Optimal Value function V ∗ ( s ) defines the maximum reward the agent can get in the future if the current state ( s)+γ(s1)+γ2(s2)+··· . is s , ie , V ∗ Note that the reward of each state is often set to a negative value and the reward of the destination/goal is set to 0 to avoid performing MDP infinitely through a ring . Besides , γ is often empirically set between 0.95 to 1.0 ( 0.95 in our experiments ) to exert an discount on the future . Q function is a function S × S ff→ R with the definition that Q(firi → rjfl| ) = ( ri ) + γV ∗ ( rj ) . It is not hard to find that Q(firi → rjfl| ) means that the reward can be received in the future if the agent makes the decision by transferring from current state ri to another state rj . According to [ 14 ] , the transition probability from ri to rj can be modeled as :
( s ) = arg max s→s1→s2···
1 Zi
P ( firi → rjfl| ) = eQ(ri→rj|( )
( 7 ) The larger the future reward is if the agent decides to drive from ri to rj , the larger the probability to make a decision from ri to rj will be . Zi is the normalization coefficient to ensure it is a probability . As the reward ( negative latent cost ) is unavailable , if we can learn through historical routes by maximizing the likelihood or posterior using Equation ( 7 ) , we can derive all the transition probabilities between any two adjacent road segments . This draws our attention to inverse reinforcement learning ( IRL ) . Therefore , we
1919 adopt Bayesian inverse reinforcement learning ( BIRL ) [ 14 ] to handle this task , because BIRL has fewer hyper parameters , easy implementation , and quick convergence . The main idea of BIRL is to compute the mean of the posterior distribution of the reward as the answer , given observations O which is the set of historical routes .
P ( |O ) ∝ P ( O|)P ( ) = P ( )
P ( R(i)| )
( 8 ) ff
R(i)∈O fl fi
1 , P ( (.|O ) P ( (|O )
The likelihood part P ( R(i)| ) is the simple production of Equation ( 7 ) wrt each two adjacent road segments in a historical route R(i ) . We choose uniform distribution to be the prior of . [ 14 ] proposes PolicyWalk to get , which is a Markov Chain Monte Carlo method designed for high dimension parameters . Briefly speaking , the sampler first starts from a random initial value of and then samples a new . drawn uniformly at random from the neighbors of current with distance no more than the step δ , ie , . ∼ U nif orm( −δ , + δ ) . The new . will be accepted with probability min . The mean of last few samples drawn from the Markov chain will be returned as the answer when the Markov chain converges . Please refer to [ 14 ] for the details of PolicyWalk and BIRL . Why Data Sparsity Can Be Solved : Unlike frequency based approaches , IRL aims to fit the whole historical routes by assigning rewards of each state ( road segments ) . The likelihood of each observation is not only based on the reward of the next status but also considers the whole rewards towards the destination , ie , the Q function . Consequently , the entire preference towards the destination will be taken into consideration which is different from the edge centric approaches that only count the ratio of transition between two consecutive edges . Thus , for those roads that are passed by a very small number of historical trajectories , IRL will assign the feasible rewards to those roads so the model can generate the historical data as likely as possible . 4.3 Route Search Engine
The last component accounts for locating the result of a route recovery query . It searches the routes that start from ps and end in pe in the road network . For each candidate route R , it computes the posterior probability of R according to Equation ( 1 ) . The route with the highest posterior is returned as the answer . In the following , we first explain how to compute the temporal and spatial probability in Equation ( 1 ) by our novel spatio temporal model proposed in Section 4.2 , and then present how to perform the search . Compute P ( Δt|R , ps , pe , te ) . At the first glance , one may tend to assume the distribution of the time interval of a route P ( Δt| R , ps , pe , te ) follows a Gaussian . However , [ 6 ] claims that the distribution of the time does not follow a Gaussian . Instead , the distribution of the speed does follow a Gaussian . ie , v ∼ N ( μv , 1/λv ) , where λv = 1/σ2 v is the precision of the Gaussian . Thus , according to [ 2 ] , given the distribution of v , the distribution of Δt = R.len/v can be derived by PΔt(Δt ) =P v(v ) · ( 9 ) For better representation , we denote R.len as ξ . Equation ( 9 ) √ λv and implies that the distribution of Δt has two parameters ξ λv and these two parameters vary when the route is different μv as ξ is the length of the route and μv is the average speed of the route . Note that till now , we only have obtained the expected time √ ΔtE of a route according to our temporal model . Thus , we next √ λv . study the correlation between ΔtE and ξ λv λv estimated from the historical routes which are
Figure 5 plots the relation between ΔtE and the parameter ξ
λv as well as μv as well as μv
√ √ λv fifififi dv fifififi =
−μv dΔt ff2
Δt2
√
√
√
2π
− 1
2
'
ξ
λv
Δt
√
√
λv e
ξ
' . )
( cid:77 ) fi fi . )
. .
'
. ff .
' . fi .
. .
( cid:77 ) fi fi
(
'
.
√
√
(
λv )
( a ) Scatters of ( ΔtE , ξ
( b ) Scatters of ( ΔtE , μv Figure 5 : Statistics for parameter estimation
λv )
√
√
√ √
λv and ξ
λv and ΔtE thus ξ frequently passed to ensure that the estimation is accurate enough . √ From Figure 5(a ) we can find a strong linear correlation between ξ λv can be represented by aΔtE + b . As μv is the mean of the distribution of v of a certain route R , we can approximate μv by the division of the length of R and the corresponding expected time cost ΔtE , ie , μv ≈ ξ/ΔtE and λv = a + b/ΔtE . Parameters a , b can be estimated by linμv ear regression . In summary , for a candidate route R , we can get λv and further get the distribution of Δt by Equaμv tion ( 9 ) , using the corresponding ΔtE computed in our temporal model and parameters a and b . Compute P ( R|ps , pe , te ) . We construct the MDP with the reward τ ( te ) learned by our spatial model in time slot τ ( te ) . We set the reward of destination to zero . Then we perform value iteration [ 17 ] on the MDP to get the optimal value function and Q function of each state . According to Equation ( 5 ) and Equation ( 7 ) , the probability of R given ps and pe can be derived as P ( R|ps , pe , te ) = P ( R[1]|ps , pe ) i Q(R[i]→R[i+1]|(τ ( te ) ) e
1 Z
Z
Route Search . After explaining how to compute the posterior of a candidate route R , we now discuss how to find a route as the answer , including a simple greedy search algorithm and an exact search algorithm . Recall that we have computed the Q function of each state by value iteration before . Accordingly , the greedy algorithm starts from the start state R[1 ] and then selects an transition action fiR[1 ] → rfl among the road segments adjacent to R[1 ] with the highest transition probability , ie , r = arg maxr . P ( fiR[1 ] → r.fl| ) = 1 eQ(R[1]→r|( ) It then transits to state r , selects the next road segment with the highest transition probability and so on . It performs state transition based on the transition probability until the destination state re is reached . The state sequence traversed is returned as the answer of greedy search . Note that the greedy search algorithm , in short GreedyIRL , is simple and fast , but the returned route might not be the optimal one as it does not consider the temporal dynamics . Alternatively , we also propose an exact search algorithm to return the route with the highest posterior probability P ( R|ps , pe , Δt , te ) based on dynamic programming . We first discretize the domain of time which is real number into integer . Assuming Tmax is the maximum time duration of route , we construct the status matrix used in dynamic programming which is denoted as S ∈ R m×Tmax . The status S[ri , tj ] refers to the log maximum route probability with constraint that the route should start from R[1 ] and end in ri with expected time cost tj , ie , S[ri , tj ] = maxR . log P ( R.|Ω ) , where Rf irst = R[1 ] , Rlast = ri and tj ≤ Δt(R . ) < tj +1 . Here , for simplicity , we denote the notation Ω to the input observations {ps , pe , te} . Thus , the optimal substructure can be derived as :
⎧⎪⎪⎪⎨ ⎪⎪⎪⎩ log(1 ) inf max ri∈adj(rk ) =tj & tl+Φiτ ( te )
S[ri , tj ] = if ri = R[1 ] & tj = Φ(ri ) if ri = R[1 ] & tj '= Φ(ri )
{S[rk , tl]+log P ( ri|rk , ps , pe)} ow where adj(r ) ={ r|re = rs} We use a Dijkstra like algo
1920 rithm to find the route with the highest posterior probability which is detailed in Algorithm 1 .
Directly performing the above algorithm will suffer from great computation cost as the algorithm will not stop until all the statuses have been updated . To address this problem we maintain a lower bound SLB of the result to prune the states which are impossible to have the final probability higher than SLB . Notice that the probability value is always smaller than 1 , which implies that the logprobability value is negative . Thus , for the status popped from the priority queue , the final log probability of this status is definitely smaller than current status value as it will be added several logprobabilities that decrease the value . According to this property , if the value of the top status in the priority queue is already smaller than SLB , we can safely confirm that all the statuses in the priority queue are impossible to be extended as the answer , as listed in Line 6 7 in Algorithm 1 . We first perform the greedy route search algorithm GreedyIRL( ) to return an approximate optimal route as the lower bound ( Line 1 ) and update the lower bound when the states are extended to re ( Lines 12 14 ) . Note that the complexity of the algorithm without pruning is O(CmTmax × log(mTmax) ) .
Algorithm 1 Exact Route Search 1 : Rans ← GreedyIRL( ) , SLB ← log P ( Rans|Ω ) ; 2 : S[ , ] ← −inf , S[R[1 ] , Φ(R[1] ) ] ← 0 , R[ , ] ← empty array ; 3 : pq.push(S[R[1 ] , Φ(R[1])] ) ; 4 : while !pq.empty do 5 : 6 : 7 : 8 : 9 : 10 : 11 : 12 : pq.pop(S[rk , tl] ) ; if S[rk , tl ] < SLB then break ; for each ri ∈ adjrk do tj ← tl + Φiτ ( te ) S[ri , tj ] ← max{S[ri , tj ] , S[ri , tl ] + log P ( ri|rk , pe)} ; R[ri , tj ] ← [ rk , tl ] ; if ri = re & SLB < S[ri , tj ] + log P ( Δt(R[ri , tj ])|Ω ) then
SLB ← S[ri , tj ] + log P ( Δt(R[ri , tj ])|Ω ) ; Rans ← getRoute(ri , tj )
13 : 14 : 15 : else 16 : 17 : return Rans ; 5 . EVALUATION pq.push(S[ri , tj ] )
In order to evaluate the performance of our STRS system , we conduct a comprehensive evaluation study and report the results and our findings in this section . Dataset Description . We employ the real dataset generated by taxis from Porto as the main dataset , and select the central of the city which contains 2 , 412 edges and 1 , 410 crossroads where historical trajectories are densely distributed . The road network data is processed from OpenStreetMap . The whole dataset contains 785 , 705 trajectories . As mentioned in Section 4.1 , we set ν to 60 minutes in our experiments and there are accordingly 48 time units T1,T2,··· ,T48 . In average , there are 16 , 368 trajectories in each time unit Ti . The average sampling rate of the original dataset is 15s per point . We split the dataset into two equal subsets , one for training and the other for testing ; while we do study the impact of the size of training set in our experimental study . Ground Truth . For the ground truth of a trajectory , we use the map matching algorithm of [ 10 ] to get the route in the form of a sequence of edges . For the sampling rate of 15s , it is enough to accurately ( ≈ 99 % ) map a series of GPS positions to a road network . Thus , we use the result of map matching as the ground truth route . Test Cases . For a complete trip generated by a taxi , we subsample it by different scales ( 1 ∼ 30 segments ) between two consecutive
GPS positions in the subsampled trajectory . We use consecutive points in a subsampled trajectory as the input of the query . For each scale , we randomly generate 1,000 test samples . We conduct our experiments to see how the performance changes over different scales of route recovery queries , while the scale of a query is set to the total number of road segments passed by the route . Accordingly , we partition the test data based on different scales and evaluate all the approaches under different scales . Evaluation Criteria . We adopt accuracy of route recovery as the main performance metric . It is defined as the ratio of the length of correctly inferred road segments to the length of the ground truth route RG or the inferred route RI whichever is longer , ie , max{RG.len,RI .len} . We use max{RG.len , RI .len} accuracy = to penalize a long inferred route as the longer the route , the higher the chance that it contains the correct road segments . 5.1 Overall Evaluation
( RG∩RI ).len
First , we compare the performance of STRS with its competitors . To have a better demonstration of the effectiveness of STRS , we implement five approaches as competitors , including HRIS , MPR , calibration , SP , FP and GreedyIRL .
History based Route Inference System ( HRIS ) is a typical dataIt first locates k candidate driven route recovery approach [ 20 ] . routes between two consecutive GPS samples and then uses dynamic programming to find out the global route by picking up one route from top k routes wrt each two consecutive GPS samples . As HRIS is designed to return a series of candidate routes , we conduct the evaluation on HRIS by returning different top k candidate routes , denoted as HRIS@k with k set to 1 , 5 and 10 . Most Popular Route ( MPR ) [ 3 ] is a data driven approach which returns the route between two locations by observing the traveling behavior of many previous users . Trajectory calibration [ 16 ] is also a datadriven approach which matches the trajectory points to the anchor points and complements the missing anchor points which are very likely to be passed by the trajectory . By selecting crossroads as the anchor points , the approach can be trivially modified to solve the route recovery problem . Shortest Path ( SP ) uses the shortest path to recover the route between two locations which is commonly adopted by many applications because of its simplicity . Similar as SP , Fastest Path ( FP ) returns the route with the minimum time cost . Last but not the least , we include greedy search algorithm ( GreedyIRL ) , introduced in Section 4.3 , as our final competitor . Note that GreedyIRL is a simplified version of STRS which does not take temporal dynamics into consideration .
We evaluate the accuracy of different algorithms under various query scales from 1 to 30 segments . It is observed from Figure 6 that with the increase of the length ( scale ) of the query route , the accuracy of all the approaches drops . This is because , as query scale increases , the number of the possible routes between two locations increases which makes route recovery more difficult . However , among all approaches , STRS demonstrates the most robust accuracy , especially when the scale of query route is large . To be specific , when scale is 30 , STRS still achieves an accuracy over 80 % while others ( except GreedyIRL ) have their accuracy below 50 % . This justifies the fact that a full probabilistic approach that can deal with data sparsity is essential . In addition , GreedyIRL , a simplified version of STRS , also demonstrates a stable performance . As the query scale becomes larger , the performance gap between GreedyIRL and STRS shrinks . This is because when the query route is short , the relative difference of time interval of different routes is large . Hence , the temporal probability P ( Δt|R , ps , pe , te ) has influence on route selection . Accordingly , the advantage of STRS over GreedyIRL by considering the temporal dynamics be
1921 )
%
( y c a r u c c A
100 90 80 70 60 50 40 30
SP
FP
MPR
HRIS@1
HRIS@5
HRIS@10
Calibration
GreedyIRL
STRS
1~3
4~6
7~9
10~12
13~15
16~18 Query Scale ( # road segments ) Figure 6 : Overall evaluation
19~21
22~24
25~27
28~30
100 90 80 70 60 50 40 30 comes more significant . When the query route contains more segments , the relative difference of time interval of different routes is shorter . Accordingly , the temporal probability of different routes becomes more similar . In other words , the temporal influence is weakened which explains the reason that the performance gap shrinks . road of the route recovered by STRS is quite wide while the road is extremely narrow in the route of SP/HRIS . STRS can capture the fact that people are reluctant to drive the route generated by SP/HRIS as it is more dangerous and unpleasant . This is because IRL can capture the reward of the road through the tendency of historical data and the reward of road segment in the dashed blue route will be assigned a relatively low value as most of drivers tend to drive the red solid route . Note that although calibration can recover the route , it takes about half an hour to return the answer .
In the second case shown in Figure 7(b ) , FP and MPR recover a route which seems to be reasonable and the street view also shows that the road condition of the route returned by FP/MPR is also better than STRS . However , only STRS returns a route that is the same as the ground truth . The reason is that the duration ( ie , Δt ) of this query is actually much longer than the estimated time of the route recovered by FP/MPR since FP always returns the route with minimum time cost . As analyzed in Section 5.1 , MPR performs similar to FP in most of time thus MPR also returns the same route as FP . From the ground truth , we intend to infer that this test sample may be generated by a driver who is unfamiliar with the road network . This case shows that the temporal model of STRS can correct the route according to the information of time duration even though the route is not efficient and natural .
SP,fiHRIS
STRS ,
Calibration
( a ) Real case 1
STRS
FP,fiMPR
( b ) Real case 2
Figure 7 : Case study
5.3 Component Study 531 Experiments of Preprocessor Experiments of Time Slot Granularity First , we study the impact of time slot granularity in the preprocessor component . As explained in Section 4.1 , parameter ν determines the temporal duration . In our study , we set ν to half an hour , 1 hour , 2 hours , 8 hours , 12 hours , and 24 hours . Accordingly , there are in total of × 2 time slots , half of them wrt weekdays and the other half 24h ν wrt weekends . We also test a special case where there is only one time slot , denoted as ν = 48h . The results are shown in Figure 8(a ) . We can find that with the decrease of ν , the performance of STRS improves . As mentioned previously , information of historical data with regard to different time slots is very different . When ν becomes larger , the time span of each time slot is enlarged and
Calibration performs the worst among all approaches . The main reason is that it constructs the transition matrix , ie , the matrix denoting the transition probability from one anchor point to another one , without considering the destination . It is intuitive that the decision of turning left or right is largely depended on where the destination is . Consequently , we can utilize MDP to model the driving decision process as we also consider the destination . Besides , as calibration will enumerate all the possible routes from ps to pe , the computation cost scales up exponentially . Thus , when the missing route is longer than 22 road segments , we can not even get the result as the estimation of the time cost of each test sample will exceed 104 seconds .
When a query route contains less than 9 segments , all the ap proaches except GreedyIRL and calibration can achieve almost 100 % accuracy . This is because when the query route is not too long , the ground truth of the missing route is often a direct connection of several road segments . For GreedyIRL , when the route is short , the Q values of states for each action near the terminal do not differ much , which results in the similar transition probabilities . This explains why GreedyIRL does not achieve 100 % accuracy .
HRIS recoveries the route by constructing traverse graph and finding the shortest path in the traverse graph . Most of roads in the dense area are passed by historical trajectories which makes the traverse graph almost equivalent to the original road network . Thus , HRIS@1 will be reduced to SP . Our experimental results also prove this , as the accuracy difference between SP and HRIS@1 is bounded by 3 % . When the route is not too long ( <18 ) , HRIS@10 performs best among all the competitors as it leverages the information of historical data . When the length of the route becomes longer , HRIS becomes inferior to MPR . This is because HRIS is designed to recover the whole low sampling rate trajectory with GPS positions in the middle of the trajectory given ; while MPR is designed to return the most popular route between two positions . Therefore , when the length of route increases , the advantage of MPR gradually emerges and finally outperforms HRIS .
MPR performs similar to FP in most of cases which indicates that popular routes are mostly fastest which is consistent with intuition . When the query route contains not too many segments ( eg < 18 ) , SP has a higher accuracy , as compared with FP and MPR . The reason is that when the trip is not too long , the time cost of different routes could be similar . When the query route is long , FP and MPR outperform SP since the difference of time cost of different routes becomes innegligible which affects the route selection . 5.2 Case Study
We next present two cases of route recovery to show how and why STRS performs better . In the first case shown in Figure 7(a ) , the route recovered by SP or HRIS is greatly different from that of STRS and calibration while the route recovered by STRS is the same as the ground truth . We also present the street view of some places in each route . From the photos we can figure out that the
1922 92 91 90 89 88 87 86 85
)
%
( y c a r u c c A
120
%
( r o r r
E t s o C e m T e v i t i
Speed Averaging approach Our Temporal Model
90
60
30 more data are distributed into the same slot . This causes a high variance of data , which has a negative impact on STRS . When ν is small enough , the performance starts to converge as the variance of data does not decrease any longer .
)
48 24 12
8 4 ( h ) ( a ) vs ν
2
1 0.5 l a e R
0 10 20 30 40 50 60 70 80 90
Sampling Interval ( s )
( b ) vs sampling interval i
|
E
Δt(i ) ffi
|Δt(i)−Δt(i )
Figure 8 : Results of different time spans and sampling intervals 532 Experiments of Temporal Model Recall that STRS proposes a temporal model to approximate the likelihood of time duration Δt . In this set of experiments , we first study the effectiveness of our temporal model . Robustness of Time Estimation approach . First , we conduct the experiments to show the performance of our time cost estimation approach . As route based approaches will inevitably face the data sparsity problem in route recovery and sometimes they even cannot find any answer , we compare our approach only with road segmentbased approaches and the speed of a GPS sample is estimated by the ratio of the network distance between this GPS sample and the previous one to the sampling rate . We employ the relative time cost error of a given testing route as the main metric . To be more specific , for a set of testing routes R(i ) having time interval Δt(i ) , the relative time cost error is = . Figure 8(b ) depicts the results . Our temporal model has its error rate around 20 % and it consistently outperforms its competitor . This is because we adopt a regression model to adjust the cost of each road element through minimizing the error for the whole route which is invariant to the sampling rate . The road segment based approach has a large error rate as the sampling interval becomes longer . Accordingly , the quality of the speed estimation drops significantly which affects the accuracy of road segment based approach . Visualization of Time Cost Matrix . Recall that to avoid high variance , STRS tries to avoid training those road segments with no or very few historical trajectories passing by . Figure 9(a ) visualizes the missing value in ˜Φ . Elements in black are the missing values , ie , those road segments in corresponding time slots have very few or even zero historical trajectories passing by . We can observe that data sparsity problems do exist . For example , people travel more frequently during the daytime ( 9:00 to 20:00 ) of weekdays . Accordingly , there are less missing values between 9:00 to 20:00 , as compared with other time slots . In weekends , many people may stay at home which leads to the increase of missing values . Note that road segment IDs in the range of [ 0 , 2412 ] represent road segments , and the IDs larger than 2,412 represent the crossroads .
After filling the missing elements in ˜Φ using static dynamic separation matrix factorization , we have the entire time cost matrix Φ . Here , we visualize the elements of Φ via heatmap . For each row Φi· ∈ R 1×48 of Φ , which represents the time cost of road element i in different time slots , we normalize the elements of Φi· , ie , Φij−min Φi· . max Φi·−min Φi· , in order to visualize the relative trend of ij = Φ time cost of the same road element in different time slots , with the shown in Figure 9(b ) . The intenser normalized time cost matrix Φ the color , the smaller the time cost and vise versa . For example , we can observe that between 0:00 to 8:00 of a weekday , the color remains dark ; when it reaches 9 a.m , the rush hour , the time cost increases until 20:00 , which further demonstrates that our time model works and the influence of time slots can not be ignored .
.
( a ) Elements with null value
Figure 9 : Visualizations of time cost matrix
.
( b ) Φ
533 Experiments of Spatial Model Effects of Data Sparsity . We have pointed out in Section 422 that the key problem of spatial model is how to model the transition probability P ( R[i]|R[i− 1 ] , ps , pe ) . Simply using frequencybased estimation ( ie , Equation ( 6 ) ) does not work , as it inevitably suffers from data sparsity problem . In the following , we conduct experiments under different degrees of data sparsity to show that our spatial model can handle the data sparsity while traditional frequency based estimation will have problems . In detail , we use the subset of the training dataset as the sparse training dataset , with the size set to 1/2 , 1/5 and 1/10 of the original training dataset .
Figure 10(a ) shows when training data become sparser , the accuracy of frequency based estimation drops drastically which justifies our analysis on data sparsity problem . On the other hand , STRS maintains a high accuracy regardless of data sparsity , which demonstrates its robustness under various quality of historical data . As explained in Section 422 , performing IRL on MDP model can avoid the data sparsity problem as it is based on fitting the historical data by assigning rewards to each road and it will assign the feasible reward to those roads with no/few trajectories passed by . Convergence of IRL . Next , we conduct experiments to demonstrate how an IRL model can be trained . Recall that when using PolicyWalk sampling algorithm , the step δ is involved . We vary the parameter δ to see how fast the Markov chain converges . We compute the posterior probability according to Equation ( 8 ) over training data to observe how IRL model fits the data . We vary the update step δ from 0.05 to 51.2 , as shown in Figure 10(b ) . With the increase of the number of training iterations , the posteriors P ( |O ) on the training data also increases wrt all the settings of δ which means the model increasingly fits the training data . When δ = 0.8 , the Markov chain converges fastest and when δ becomes smaller , the convergence slows down . This is consistent with our expectation . When δ is very small , is moved slightly in each iteration , which makes it slower to reach the position near the maximum posterior . When δ becomes larger , it also increases the hardness of convergence . This is because t+1 is drawn uniformly from the neighbours of previous reward t and most of the samples t+1 drawn may be very far away from the optimal which results in a very low acceptance ratio . Thus , many samples are rejected which directly results in the poor convergency .
100
Frequency based
STRS
1
)
%
( y c a r u c c A
80
60
40
1
1/2 1/5 Data Size
1/10
( a ) vs data sparsity
) 5 0 1 × (
R f o r o i r e t s o P g o L
2
3
4
0
( cid:71)fifi0.05 ( cid:71)fifi0.2 ( cid:71)fifi0.8 ( cid:71)fifi3.2 ( cid:71)fifi12.8 ( cid:71)fifi51.2
200k
100k
50k # Sampling Iterations
150k
( b ) Convergence v.s
Figure 10 : Evaluation on spatial model 534 Experiment of Route Search Engine Effects of Pruning Strategy Note that we have adopted pruning strategies in the exact route search algorithm . Here , we study the
1923 efficiency of our exact route search algorithm . To have a better illustration of the pruning strategy , we plot the query time using the exact route searching without pruning , in short ERSN oP rune . Recall that the result of GreedyIRL serves as the initial value of the lower bound SLB . We also plot the execution time of IRL by initializing SLB to the result of shortest path . We set Tmax to 2000 in our experiment . In Figure 11(a ) , both search algorithms with pruning take less time , in average about 10 times faster than ERSN oP rune . The significant improvement on search time justifies the effectiveness of the pruning strategies . As ERSN oP rune updates the whole status matrix S[ , ] , query scale has a less significant impact on the computation time . For ERSGreedyIRL and ERSSP , their search time changes wrt the query scale . The reason is that when the query route contains many segments , it is very likely that the start road and the end road are far away from each other . Accordingly , the number of status that need extension or update will also increase . From the observation that ERSGreedyIRL performs faster than ERSSP , we can further conclude that the result of GreedyIRL does provide a better lower bound than SP and our MDP model trained by IRL is more effective . Efficiency Comparison We conduct the experiment to show the time cost of online part of STRS ( the route search engine ) in order to see whether it can be applied in the real scenarios . The competitors are three data driven approaches mentioned above , ie , HRIS , MPR and calibration . As non data driven approaches do not require data processing and can be transfered to a shortest path algorithm , they have very small time cost ( in several milliseconds ) and hence are skipped in this set of experiments . Figure 11(b ) depicts the result . We can see when the query scale is small , calibration is the fastest as the number of possible routes is small . However , with the query scale increases , the number of possible routes drastically increases . Thus , the cost increases exponentially , as stated in Section 51 MPR stays consistent with the query scale . The reason is that MPR needs a data preprocessing step for each query which costs much more than the query phase . STRS performs similar as HRIS . When scale is too large the scalability of STRS reduces for the reason that the sizes of discretized time and the states both increase . For the sake of the high accuracy STRS brings , we claim that the additional cost is worth to spend .
8
6
4
2
0 i
) s ( e m T y r e u Q
1~3 no_pruning SP_pruning GreedyIRL_pruning
3.4
59.1
860.9
N/A
N/A
N/A
STRS MPR HRIS Calibration
1.0
0.8
0.6
0.4
0.2 i
) s ( e m T y r e u Q
0.0
7~9 10~12 13~15 16~18 19~21 22~24 25~27 28~30
4~6 Query Scale ( # road segments ) ( a ) Query time Figure 11 : Evaluation on route search engine
4~6 Query Scale ( # road segments ) ( b ) Efficiency comparison
1~3
7~9 10~12 13~15 16~18 19~21 22~24 25~27 28~30
6 . CONCLUSION
In this paper , we study the problem of recovering the missing route of a trajectory using historical data in a probabilistic way . We propose a system based on fully probabilistic derivation showing that what kind of temporal and spatial dynamics should be taken into consideration theoretically . We have addressed all the data sparsity problems brought by the probabilistic view and thus we can take full advantages of probabilistic methods . Evaluation results show that our system outperforms all of the competitors and maintains the accuracy over 80 % even when the route contains 28 ∼ 30 road segments . The results also show that our system is robust for the data sparsity . In the future work , we plan to extend the route recovery to not only vehicles but also other transportations such as buses , bikes and walking to make route recovery more general .
7 . ACKNOWLEDGEMENTS
This research is supported in part by National Natural Science Foundation of China ( NSFC ) under grant 61073001 , Shanghai Natural Science Foundation under grant 14ZR1403100 . Weiwei Sun is the corresponding author . 8 . REFERENCES [ 1 ] R . K . Balan , N . X . Khoa , and L . Jiang . Real time trip information service for a large taxi fleet . In MobiSys 2011 . [ 2 ] C . M . Bishop . Pattern recognition and machine learning .
Springer , 2006 .
[ 3 ] Z . Chen , H . T . Shen , and X . Zhou . Discovering popular routes from trajectories . In ICDE 2011 .
[ 4 ] C . D . Fabritiis , R . Ragona , and G . Valenti . Traffic estimation and prediction based on real time floating car data . In ITSC 2008 .
[ 5 ] G . R . Jagadeesh and T . Srikanthan . Robust real time route inference from sparse vehicle position data . In ITSC 2014 .
[ 6 ] M . Li , A . Ahmed , and A . J . Smola . Inferring movement trajectories from GPS snippets . In WSDM 2015 .
[ 7 ] C . Liao , J . Lu , and H . Chen . Synthesizing routes for low sampling trajectories with absorbing Markov chains . In WAIM 2011 .
[ 8 ] Y . Lou , C . Zhang , Y . Zheng , X . Xie , W . Wang , and Y . Huang .
Map matching for low sampling rate GPS trajectories . In SIGSPATIAL GIS 2009 .
[ 9 ] T . Miwa , D . Kiuchi , T . Yamamoto , and T . Morikawa .
Development of map matching algorithm for low frequency probe data . Transportation Research Part C , 22 , 2012 .
[ 10 ] P . Newson and J . Krumm . Hidden Markov map matching through noise and sparseness . In SIGSPATIAL GIS 2009 . [ 11 ] M . Rahmani , E . Jenelius , and H . N . Koutsopoulos . Route travel time estimation using low frequency floating car data . In ITSC 2013 .
[ 12 ] M . Rahmani and H . N . Koutsopoulos . Path inference of low frequency GPS probes for urban networks . In ITSC 2012 .
[ 13 ] M . Rahmani and H . N . Koutsopoulos . Path inference from sparse floating car data for urban networks . Transportation Research Part C , 30 , 2013 .
[ 14 ] D . Ramachandran and E . Amir . Bayesian inverse reinforcement learning . In IJCAI 2007 .
[ 15 ] J . Rice and E . V . Zwet . A simple and effective method for predicting travel times on freeways . IEEE ITS , 5(3 ) , 2004 .
[ 16 ] H . Su , K . Zheng , J . Huang , H . Wang , and X . Zhou .
Calibrating trajectory data for spatio temporal similarity analysis . The VLDB Journal , 24(1 ) , 2015 .
[ 17 ] R . S . Sutton and A . G . Barto . Reinforcement learning : an introduction . MIT press Cambridge , 1998 .
[ 18 ] Y . Wang , Y . Zheng , and Y . Xue . Travel time estimation of a path using sparse trajectories . In SIGKDD 2014 .
[ 19 ] J . Yuan , Y . Zheng , C . Zhang , X . Xie , and G . Sun . An interactive voting based map matching algorithm . In MDM 2010 .
[ 20 ] K . Zheng , Y . Zheng , X . Xie , and X . Zhou . Reducing uncertainty of low sampling rate trajectories . In ICDE 2012 . [ 21 ] Y . Zheng . Trajectory data mining : An overview . ACM TIST ,
6(3 ) , 2015 .
[ 22 ] Y . Zheng and M . A . Quddus . Weight based shortest path aided map matching algorithm for low frequency positioning data . In TRB 2011 .
1924
