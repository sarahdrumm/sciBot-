Point of Interest Recommendations : Learning Potential
Check ins from Friends
Huayu Li∗ , Yong Ge+ , Richang Hong− and Hengshu Zhu× ∗The University of North Carolina at Charlotte , + University of Arizona ,
− Hefei University of Technology , ×Baidu Research Big Data Lab hli38@uncc.edu , ygestrive@gmail.com , hongrc@hfuteducn , zhuhengshu@baidu.com
ABSTRACT The emergence of Location based Social Network ( LBSN ) services provides a wonderful opportunity to build personalized Point of Interest ( POI ) recommender systems . Although a personalized POI recommender system can significantly facilitate users’ outdoor activities , it faces many challenging problems , such as the hardness to model user ’s POI decision making process and the difficulty to address data sparsity and user/location cold start problem . To cope with these challenges , we define three types of friends ( ie , social friends , location friends , and neighboring friends ) in LBSN , and develop a two step framework to leverage the information of friends to improve POI recommendation accuracy and address cold start problem . Specifically , we first propose to learn a set of potential locations that each individual ’s friends have checked in before and this individual is most interested in . Then we incorporate three types of check ins ( ie , observed check ins , potential check ins and other unobserved check ins ) into matrix factorization model using two different loss functions ( ie , the square error based loss and the ranking error based loss ) . To evaluate the proposed model , we conduct extensive experiments with many state of the art baseline methods and evaluation metrics on two real world data sets . The experimental results demonstrate the effectiveness of our methods . Keywords Point of Interest ; Recommendation ; Matrix Factorization
1 .
INTRODUCTION
Recent years have witnessed the prevalence of smart mobile devices and the convenience of accessing wireless network , which makes people much easier to acquire their realtime location information . This development stimulates the emergence of location based social network ( LBSN ) services such as Foursquare , Jiepang , and Facebook Places . These LBSNs allow users to build connections with each other , and share their experience and check in information associ ated with a Point of Interest ( POI ) . A variety of such user interaction data with LBSNs provide a good opportunity for developing personalized POI recommender systems . Indeed , the accurate and personalized POI recommendation is a crucial demand in LBSN services . It not only helps users to explore new locations , but also facilitates users to find relevant POIs without spending too much time on searching , particularly when they are in a new region .
Although developing a personalized POI recommender system is a crucial task and could benefit users’ outdoor activities , it is still a very challenging problem due to three reasons . First , a user ’s check in decision making process is very complex and could be influenced by many different kinds of factors . For example , it is difficult to model the influence of social friends on user ’s check in behaviours . We do not know which friend will actually influence user ’s POI decision , not mention to know how she affects user ’s choice . Also , the geographical distance might affect user ’s POI decision . A user often prefers a nearby POI to another one far away . Second , POI recommender system usually suffers a severe challenge caused by extreme sparse check in data . In real system , there are over millions of POIs . However , a single user usually checks in a limited number of POIs , which significantly increases the difficulty of recommendation . Third , when a new POI or a new user enters the system and we do not have its visitor information or her historical check in information , it is very difficult to recommend new POI to users or recommend POIs to new user .
In the literature , some related works have been proposed to incorporate social network into POI recommendations . For example , [ 16 ] placed a social regularization term to constrain the estimation of user feature vectors with the assumption that friends will share the similar interests . Meanwhile , some researchers also proposed to take the geographical influence into account to assist POI recommendation . For instance , [ 28 ] leveraged a linear model to combine user interest , social network and geographical distance for POI prediction . On the other hand , [ 15 ] modeled the geographical neighborhood influence in both instance and region level . In instance level , one user ’s preference for a location is predicted as a combination of her special preference on this location and the nearest neighborhoods of this location . In region level , it places a group lasso penalty to learn locationspecific latent vectors . However , few of these models incorporate the influence of geographically close users on each other ’s check in activities into matrix factorization . The geographically close users may share similar interests and should have potential influence on check in behaviors [ 23 ] .
975 Moreover , few of these models could address user cold start problem in location recommendation . Motivated by these , we first formally define three types of friends for each user : social friends , location friends and neighboring friends . The social friends of a user refer to the set of users who are socially connected with this user in LBSNs . The location friends of a user denote the set of users who check in the same locations as this user does . The neighboring friends of a user are those users who are geographically close to this user . Then we novelly incorporate their historical check ins into matrix factorization model with different loss functions . Through our analysis on two real world data sets , we find that users share the similar interests with their three types of friends . Consequently , we propose a two step framework to elaborate friends’ check ins . In the first step , we design two approaches ( ie , a linear aggregation based and a random walk based ) to learn a set of friends’ locations that each user most potentially prefers and she never visited . Thus , a user ’s check ins are divided into observed check ins , potential check ins and other unobserved check ins . In the second step , we develop two loss functions to model these three kinds of check ins : the square error based loss function and the ranking error based loss function . Specifically , the square error based loss treats user ’s check ins as an indication of positive , potential and negative preference with varying confidence . The ranking error based loss assumes that the user prefers an observed location over any potential locations , and also prefers a potential location over any unobserved locations . We extensively evaluate our models with many state of the art baseline models and different validation metrics on two real world data sets . The experimental results not only demonstrate the improvements of our models on POI recommendation , but also show the effectiveness for cold start problem .
To summarize , the major contributions of this paper are : • empirically analyzes the correlations between users and their three type of friends using two check in datasets ; • designs two approaches to learn a set of locations for each individual user that her friends have checked in before and she is most interested in ; • develops matrix factorization based models via different error loss functions with the learned potential check ins , and correspondingly proposes two scalable optimization methods ; • designs three different recommendation strategies for standard recommendation , new location recommendation , and new user recommendation .
2 . PRELIMINARIES
In this section , we first introduce some mathematical notions , and then provide the definition of friends . At last , we introduce the recommendation framework . 2.1 Notation
Suppose there are N users and M locations . For convenience we will henceforth refer to i as user , f as friend and j as the location unless stated otherwise . Suppose there are C kinds of categories and the category of location j is denoted as cj . For user i , Fi denotes a set of friends which will be further defined and explained in Section 2.2 , Mo i is a set of locations checked in by her , Mp i is a set of potential locations learned in Section 3 , and Mu i is the remaining unvisisted locations . rij is the check in frequency of user i on
Figure 1 : The user ui ’s social network and check ins . location j . In addition , all column vectors are represented by bold lower case letters , all matrices are represented by bold upper case letters , and a numeric value is denoted by lower case letter . A predicted value is denoted with aˆ(hat ) over it . The terms location and POI are used interchangeably . 2.2 Definition
To better understand users’ check in behaviours , we examine the check in data collected from Gowalla and Foursquare ( Details can be found in Section 5 ) . To clarify the relation between the similarity of pairwise users and their physical distance , we plot their relations in Figure 2(a ) and Figure 2(b ) . The physical distance of two users refers to the distance between their home locations , and the similarity of user i and user f is measured by cosine similarity , given by :
Simu(i , f ) = ( r2 ij
− 1 2 r2 f j ) j∈Mo i j∈Mo f j∈Mo i
∩Mo f rij rf j .
( 1 )
Based on the observation , we find that the physically closer two users live , the more similar their POI interests are . It motivates us to leverage neighboring friends , who are physically neighbors , to learn user ’s interest in POIs . In addition , social friends who build connections online share the similar interests in POI decisions [ 16 , 1 , 5 , 22 ] . Users who check in similar locations are treated as location friends , and also might have similar tastes . Thus , three types of friends of user i , ie , neighboring friends , social friends and location friends , might affect her check in activity , defined as :
Definition 1
( Social Friends ) . The social friends of user i are the set of users who have socially connected with her in LBSNs , which is denoted as F s i .
Definition 2
( Location Friends ) . Given a set of loi , which have been checked in by user i , her locai , are the set of users who have Ψj , where cations Mo tion friends , denoted as F l also checked in these locations , ie , F l Ψj is the set of users who also have checked in location j . i = j∈Mo i
Definition 3
( Neighboring Friends ) . Given the home location of user i , the neighboring friends are the set of users who live physically closest to her and denoted as F n i .
In the example of Figure 1 , the target user ui has checkedin locations {l1 , l2 , l3} . {f1 , f2} are her social friends who socially connect with her online . User f3 has check ins at locations l2 and l5 , and user f4 has check ins at locations l3 and l4 . f4 and f5 have common POIs with user ui , ie , l2 and l3 , respectively . Thus , both of them are the location friends of user ui . In addition , f5 and f6 are the target user ’s neighboring friends due to their physically short distance to her . Thus , {f1,··· , f6} are regarded as the friends of user i . In this paper , the friends of user i are defined as :
Fi = F s i ∪ S(F l i ) ∪ S(F n i ) ,
( 2 ) where S(F l i ) is the set of S most similar friends with the highest cosine similarities and S(F n i ) is the set of S physically nearest friends with the shortest distance among their
SocialNetworkLocationsuif6f1f3l1l2l3l4l5f2f4f5976 ( c ) Gowalla Data
( d ) Foursquare Data
( a ) Gowalla Data
( b ) Foursquare Data
Figure 2 : ( a ) ∼ ( b ) Cosine similarity as a function of distance between users’ home locations . ( c ) ∼ ( d ) Complementary Cumulative Distribution Function ( CCDF ) of cosine similarity between friends . homes1 . To examine the correlation between friends , we report the complementary cumulative distributions of their similarities in Figure 2(c ) and Figure 2(d ) on Gowalla and Foursquare , respectively . There are over 5 % , 20 % and 40 % pairs of social , neighboring and location friends which have similarities larger than 02 Particularly , the friends’ correlation is much stronger in Gowalla than Foursquare . The observation shows the importance of friends in LBSNs and motivates us to use friends’ historical check ins to improve recommendation accuracy . 2.3 The Recommendation Framework
To obtain the potential locations of each user i , we propose two methods , ie , Linear Aggregation and Random Walk , to estimate the probability ppot ij of this user on each location j that her friends have checked in . Then we rank them by the estimated probabilities and select S locations with the highest probabilities2 . The learned potential locations will assist to make accurate recommendation in Section 4 . 3.1 Linear Aggregation
In this section , we propose Linear Aggregation method , denoted as LA , to predict the probability ppot that user i ij prefers location j which has been visited by her friends . Suppose Sim(i , f ; j ) is the similarity between user i and friend f on the preference for location j . A location is possibly checked in by more than one friends , so we define ppot ij as : ij ∝ max ppot f∈F j i
{Sim(i , f ; j)} ,
The recommendation task in this paper is defined as : given users’ historical checked in locations , we aim at recommending each user with top K locations that she might be interested in but has not visited before . In this paper , we propose a two step recommendation framework . Specifically , in the first step , we learn a set of potential locations from three types of friends , which will be introduced in Section 3 . In the second step , we incorporate the learned potential locations of each individual into matrix factorization model with different error loss functions , which will be presented in Section 4 . At last , we introduce different recommendation strategies for standard recommendation , location cold start recommendation and user cold start recommendation . 3 . LEARNING POTENTIAL LOCATIONS Social network plays an important role in recommendations [ 16 , 28 , 5 , 22 ] . However , only leveraging the historical locations of social friends cannot successfully model user ’s preference for locations due to that it is difficult to appropriately model the preference of users who have no social friends , not mention to handle user cold start problem ( ie , a user has never checked in any location before ) . To address these problems , we will exploit the characteristics of three types of friends : social friends , location friends and neighboring friends . The earlier section has shown their significance in LBSNs , ie , friends would share the similar preferences for POIs . In other words , users might be interested in those locations which have been checked in by their friends , and have a high probability to check in them next time . However , the extremely large number of these locations will lead to the inefficiency of computation with the increase of locations , and the inaccuracy of prediction with the increase of noise . Hence , the problem in this section is to find the most potential locations for the target user , defined as :
Definition 4
( Problem of Potential Locations ) . Given the set of locations Mf i , that the friends of target user i have checked in before but she never visits , the problem is to find top S most potential locations that she might be interested , denoted as Mp i . 1In the experiment , we set S as 10 . f∈Fi
Mo f\Mo i = where F j i is the set of user i ’s friends who have checked in location j . The similarity Sim(i , f ; j ) incorporates two parts : ( 1 ) the similarity of user interest , and ( 2 ) the similarity of geographical location . The similarity of user interest can be measured by cosine similarity in Eq ( 1 ) . Since a user ’s check in probability and the distance from her home to the corresponding location follow a power law distribution [ 9 ] , we exploit this characteristic to model geographical similarity . Hence , we define the probability that a user checks in a location d km far away as the following :
P rG(d ) = a · db ,
( 3 ) where a and b are the parameters of power law distribution and could be learned by maximum likelihood estimation . Then the probability of user i to check in a POI j due to the geographical influence is normalized as : pG ij =
P rG(d(hi , j ) )
P rG(dmin )
,
( 4 ) where hi is the home location of user i , and d(hi , j ) indicates the distance between the home location of user i and the POI j , and dmin is the minimum distance . The distance could be computed by Haversine formula with latitude and longitude . Thus , Sim(i , f ; j ) is the linear aggregation of similarities on both user interest and geographical location , given by
Sim(i , f ; j ) = ζ Simu(i , f ) + ( 1 − ζ ) pG ij , where ζ ∈ [ 0 , 1 ] is a tuning parameter to control the importance of the similarity of user interest . 3.2 Random Walk
Random walk with restart has successfully measured the correlation between two nodes in a graph [ 7 , 24 ] . In this section , we propose a Random Walk method , denoted as RW , to learn the probability ppot ij of user i on location j which has been visited by her friends . We construct a directed
2In the experiments , we set S as 500 .
100102104Distance between users ( km ) ( log scale)000200400600801Cosine Similarity100102104Distance between users ( km ) ( log scale)00005001001500200250030035Cosine Similarity0020406081Cosine Similarity0020406081CCDFSocial FriendsNeighboring FriendsLocation Friends0020406081Cosine Similarity0020406081CCDFSocial FriendsNeighboring FriendsLocation Friends977 parameter to indicate that user has a small probability to prefer one location with another category .
Many of the recent works suppose to only model the observed rating , which is adapted to explicit feedback datasets . However , the check in dataset is implicit feedback dataset , where we do not have explicit feedback for user ’s preference to locations . In other words , we lack substantial evidence on which location the user dislikes . To address user cold start problem and data sparseness problem , we propose to model the observed preference , potential preference and unobserved preference of users for location , simultaneously . Let j , k , h denote the observed location , potential location and unobserved location , respectively . The loss function of general form is given as follows :
Ei(pij , pik , pih , ˆpij , ˆpik , ˆpih ) + Θ(U , V , Q ) ,
( 8 ) i argmin U,V,Q
∀j ∈ Mo i , ∀k ∈ Mp i , ∀h ∈ Mu i , where Ei(· ) is the loss function for the observed , potential and unobserved preference of user i for locations , and Θ(· ) is a regularization term with 2 norm which is defined as :
Θ(U , V , Q ) =
||U||2
2 +
λu 2
λv 2
||V||2
2 +
||Q||2 2 ,
λq 2
( 9 ) where λu , λv and λq are the regularization constants . We develop two different types of models which use different loss function for Ei(· ) , ie , the square error based and the ranking error based loss functions , and will be described in the next two sections , respectively . 4.1 The Square Error based Model
In this section , we present the Augmented Square error based Matrix Factorization ( ASMF ) model constrained with the square error loss function and its optimization method . 411 The ASMF Model Due to the similar interests between friends , one user might have opportunity to visit those potential locations that her friends have visited before but she never checksin . We treat each individual user ’s check ins as an indication of positive , potential and negative preference associated with different confidence . One user has a high confidence for the positive preference to their checked in POIs . However , she will have a low confidence for the potential preference to those potential locations and the negative preference to other unvisited locations . Correspondingly , we augment the binary preference variable pij to a ternary value as follows :
1 if j ∈ Mo α if j ∈ Mp i otherwise , 0 i pij = graph with two kinds of nodes : the users ( ie , the target user and her friends ) , and the locations checked in by her and her friends . Let y be a column vector where yi refers to the probability that the random walk is at node i . Also let A be the column normalized transition matrix where aij denotes the probability that node i jumps to node j . Here we consider three types of transition probabilities : ( 1 ) the probability between users measured by the cosine similarity in Eq ( 1 ) ; ( 2 ) the probability from each user to each location which is one if the user checks in the corresponding location and otherwise is zero ; ( 3 ) the similarity between a pair of locations ( j and k ) measured by the normalized power law function which is defined as the following : P rG(d(j , k ) ) P rG(dmin )
SimG(j , k ) =
( 5 )
, where d(j , k ) is the distance between these two locations and the power law parameters are learned with the check in probabilities and corresponding distances of pairwise locations . Hence , the iteration equation for updating the steadystate probability of each node is given as follows : y = ( 1 − β)Ay +
β
|Mo i ∩ Mf i | + |Fi| + 1 x ,
( 6 ) where x is the column vector of zeros with the elements corresponding to the target user and her checked in locations as one , and β ∈ [ 0 , 1 ] is the restart probability to return to the target user and her checked in locations . The steady state probability is achieved by recursively performing Eq ( 6 ) until convergence . Thus , the probability ppot is the steadyij state probability corresponding to the location j . 4 . RECOMMENDATION MODELS
In Section 3 , for each individual user , we have learned the potential locations from her friends’ information . In this section , the learned potential locations are utilized to make accurate recommendation and address user cold start problem . Overall , for each user i , we have her three kinds i , potential locations Mp of locations : observed locations Mo and other unobserved locations Mu i . i
In this paper , we build our recommendation models by leveraging the widely used matrix factorization techniques [ 20 , 19 , 8 , 6 , 11 ] , where both user and location are mapped into latent low dimension spaces . Let U ∈ RK×N and V ∈ RK×M be the latent user and location feature matrices , with column vectors ui and vj representing the K dimensional user specific and location specific feature vectors of user i and location j , respectively . A typical prediction for the preference of user i to location j is taken by an inner prodi vj , where P ∈ RN×M is uct of latent vectors , ie , ˆpij = uT the preference matrix .
However , in LBSNs the category information of POIs affects user ’s check in decision making process . Users are often used to visiting those POIs which belong to the same category due to their specific hobbies . For example , users who like eating would have a much higher probability to choose a new POI relevant to food next time , but they have much less chance to check in a POI about sight . Thus , the preference of category is another important factor to affect user ’s decision on a new POI . Here , we introduce the category feature matrix Q ∈ RN×C , where each entry qic indicates the preference of user i to category c . Hence , the preference of user i for location j is refined as follows :
( 10 ) where α ∈ [ 0 , 1 ] is a potential preference constant , indicating user i has a probability α to choose an unvisited location j that her friends have visited before .
Therefore , we propose the augmented square error based matrix factorization model ( ASMF ) to compute the loss Ei(· ) by using the squared error loss function with the ternary variable defined in Eq ( 10 ) , given by :
Ei(· ) = wij ( pij − ˆpij )2 ,
( 11 ) where W is the confidential matrix with element wij as the confidential weight for user i to location j , given by :
1 + γ × rij 1 if j ∈ Mo i otherwise ,
( 12 )
M j=1
ˆpij = ( qicj + ε)uT i vj ,
( 7 ) wij = where cj is the category of location j and ε is a tuning where γ is the tuning parameter .
978 412 The Parameter Estimation In ASMF model , based on the Eq ( 7 ) , Eq ( 8 ) and Eq ( 11 ) , the matrices U , V , and Q are learned by minimizing the following regularized optimization problem :
N
M i=1 j=1 pij − ( qicj + ε)uT i vj
2 wij
L = min
U,V,Q
+ Θ(U , V , Q ) ,
( 13 )
To solve the above optimization problem , we adopt Alternating Least Squares ( ALS ) [ 8 ] optimization method due to the accurate parameter estimation and fast convergence rate . We perform ALS method to compute each latent variable by fixing the other variables when minimizing the objective function . The updating formulas with respect to U , V and Q are given as follows : ui = ( λuIK + wij ˜q2 icj vj vT j ) vj = ( λvIK + wij ˜q2 icj uiuT i ) qic = ( wij ( pij − ε)uT i vj )/(λq + j∈Nc wij ˜qicj pij vj ,
( 14 ) wij ˜qicj pij ui ,
( 15 ) wij ( uT i vj )2 ) ,
( 16 ) where IK is the K dimension unit matrix , Nc is the set of locations with category c , and ˜qicj is equal to qicj + ε . The detailed algorithm is reported in Algorithm 1 . Specifically , we place the non negative constraints on Q and project the negative variables to 0 in each iteration .
−1 −1 j i j∈Nc j i
Algorithm 1 : ASMF Optimization
Input : W , P , λu , λv , λq , α , ε , τ , maxIter Output : U(t ) , V(t ) , Q(t )
4
1 Randomly initialize U(0 ) and V(0 ) , t ← 1 , ω ← ∞ 2 Initialize Q(0 ) by using Eq ( 16 ) 3 while t maxIter && ω τ do Update U(t ) by using Eq ( 14 ) Update V(t ) by using Eq ( 15 ) Update Q(t ) by using Eq ( 16 ) ω ← |L(U(t),V(t),Q(t))−L(U(t−1 ) ,V(t−1 ) ,Q(t−1 ) )| t ← t + 1
|L(U(t−1 ) ,V(t−1 ) ,Q(t−1 ) )|
5
6
7
8 9 end 10 return U(t ) , V(t ) , Q(t ) ic icj icj j ˜q2 vj vT vj vT vj vT j ˜q2 icj j∈Nc j∈Nc j wij ˜q2 j γrij ˜q2 icj vj vT j vj vT c ˜q2 j + j = j = term can be written as For each category c ,
Complexity Analysis . The complexity of direct computation is O(N M K 2 ) which is extremely inefficient particularly with the increase of locations and users . To improve the efficiency , we design the following updating strategies . For updating ui , we employ the similar trick in [ 6 ] , ie , j . The first j . vj vT is independent of i and already pre computed , so the time complexity of this term is O(CK2 ) and C is usually very small . The cost time of the second term is O(niK2 ) , where the potential part can be pre computed and ni is the number of observed locations for which rij > 0 . In addition , the inverse of a K×K matrix costs O(K3 ) . Consequently , the re computation of ui is performed in time O(CK2 + niK2 + K3 ) . This procedure is performed over each user , so the total time is O(N CK2 + nK2 + N K3 ) , where n is defined as n = Similarly , when updating vj , we have i = i . For each category c , the first term is independent of j and was already pre computed . Thus , the total cost time over M locations is O(nK2 + M K3 ) . To update qic , we can rewrite the crucial expression as i vj )2 . The j∈Nc j∈Nc first term can be written as i + i vj )2 = i vj )2 + i ( i vj )2 = uT i γrij ˜q2 i wij ˜q2
γrij ( uT wij ( uT j∈Nc j∈Nc i ˜q2 icj j∈Nc i ni . uiuT uiuT icj uiuT
( uT
( uT icj vj vT j )ui , where vj vT j∈Nc j was already pre computed , so it costs O(K2 ) . The second term costs O(Knic ) , where nic is the number of locations for which rij > 0 and belongs to category c . The total complexity of updating Q is O(N CK2+Kn ) . In a summary , for each iteration of optimization , the total time is O(nK 2 ) , where n > max{M , N}K , and n > CN are usually satisfied . In other words , the time complexity of one optimization iteration is in linear proportion to the number of observed check ins . 4.2 The Ranking Error based Model
In this section , we present the Augmented Ranking error based Matrix Factorization ( ARMF ) model constrained with the ranking error loss and its optimization method .
421 The ARMF Model In check in dataset , we only have a user ’s check in record and do not know how much she dislikes a location . In other words , an unvisited location does not necessarily indicate the user dislikes it . The unobserved data actually is a mixture of negative preference for locations and missing values . It motivates us to consider a ranking error based loss function for modeling the ranking order of user ’s preference for observed locations , potential locations and unobserved locations . We assume that the user prefers an observed location over all potential locations , and at the same time she prefers a potential location over all other unobserved locations . Thus , for user i , the ranking order of her preference over an observed location j ∈ Mo i and an unobserved location h ∈ Mu ( qicj + ε)uT ( qick + ε)uT i is given as the following : i vj > ( qick + ε)uT i vk > ( qich + ε)uT i , a potential location k ∈ Mp fl ˆpij > ˆpik i vk i vh
ˆpik > ˆpih
( 17 )
⇒
.
To this end , we propose the augmented ranking error based matrix factorization ( ARMF ) to compute the loss Ei(· ) by using the ranking error loss function , given by ,
Ei(· ) = − − j∈Mo i k∈Mp i k∈Mp i h∈Mu i ln σ( ˆpij − ˆpik ) ln σ( ˆpik − ˆpih ) ,
( 18 ) where σ(x ) = 1 1+e−x is the logistic sigmoid function which is introduced to penalize the violated constraints in Eq ( 17 ) . As we can see in Eq ( 18 ) , the error function does not focus on predicting the right value , but on the ordering of the preference for observed , potential and unobserved locations .
422 The Parameter Estimation In ARMF model , based on the Eq ( 7 ) , Eq ( 8 ) and Eq ( 18 ) , the matrices U , V , and Q are learned by minimizing the following regularized optimization problem : argmin U,V,Q k∈Mp i
 j∈Mo i
− i k∈Mp i h∈Mu i ln σ( ˆpij − ˆpik ) +
 + Θ(U , V , Q ) . ln σ( ˆpik − ˆpih )
( 19 )
As there is no close form for each variable with ALS approach , a Stochastic Gradient Descent ( SGD ) using the boostrap sampling with replacement algorithm is employed to solve the optimization problem in Eq ( 19 ) . The optimization algorithm is iteratively performed by sampling a tuple
979 ( i , j , k , h ) and updating the corresponding variables , where i is a user , j ∈ Mo i is her potential location , and h ∈ Mu i is other unobserved location . More details of optimization are provided in Algorithm 2 . Specifically , we define g(x ) = σ(x ) − 1 . i is her observed location , k ∈ Mp
Complexity Analysis . The run time of sampling a tuple ( i , j , k , h ) is quite small in each update and can be neglected . Hence , the complexity of the optimization algorithm is O(mK ) , where m is the total iteration number . In the experiments , m is proportional to the number of observed check ins .
Algorithm 2 : ARMF Optimization
Input : λu , λv , λq , η , maxIter Output : U , V , Q
1 Randomly initialize U and V , Q , t ← 1 2 while t maxIter do
Randomly sample a ( i , j , k , h ) , where i is a user , and j , k , h are her one observed , potential , and unobserved location
3
4
5
6
7
8
9
10
11
12
13
14 j ← ( qicj + ε)vj ˜vi i ← ( qicj + ε)ui ˜uj ˜pijk ← g( ˆpij − ˆpik ) ˜pikh ← g( ˆpik − ˆpih ) j − ˜vi ui ← ui − η( ˜pijk(˜vi vj ← vj − η( ˜pijk ˜uj i + λvvj ) vk ← vk − η(( ˜pikh − ˜pijk)˜uk vh ← vh − η(− ˜pikh ˜uh i + λvvh ) qicj ← qicj − η( ˜pijkuT i vj + λqqicj ) qick ← qick − η(( ˜pikh − ˜pijk)uT qich ← qich − η(− ˜pikhuT t ← t + 1 k ) + ˜pikh(˜vi i + λvvk ) i vh + λqqich ) i vk + λqqick ) k − ˜vi h ) + λuui )
15 16 end 17 return U , V , Q
4.3 Incorporating Geographical Influence
Different from online product consuming , a POI ’s geographical distance significantly affects the user ’s check in decision making process . One user would have a small probability to check in a location far away , even though she is interested in it . In the example shown in Figure 1 , user ui has more chance to check in the locations in the left side than those in the right side . It motivates us to incorporate the geographical influence into user ’s decision on POIs . Thus , the probability that user i prefers a POI j is :
ˆpij ∝ pG ij × σ( ˆpij ) ⇒ ˆpij ∝ pG ij × σ((qicj + ε)uT i vj ) ,
( 20 ) ij is the geographical influence shown in Eq ( 4 ) . where pG 4.4 Recommendation Strategies
Our goal is to recommend unvisited locations for users which they might be interested in . For each individual user , we first predict the probability that this user would check in each unvisited location and then recommend the top K locations with the highest probabilities for her . In particular , we adopt the following strategies for recommendation . • Standard Recommendation . Similar to traditional recommendation , we consider to recommend the existing users with the existing locations . After learning the model from training data , we exploit Eq ( 20 ) to predict the probability that one user prefers each unvisited location . • New User Recommendation . When new users enter the system , we consider to recommend them with the existing locations . First , we need to re train the models with these new users by leveraging the historical check ins of their social friends and neighboring friends . As new users do not have check ins , they do not have location friends but they have neighboring friends . After the latent factors are learned , Eq ( 20 ) is employed for recommendations . • New Location Recommendation . When new locations enter the system , we consider to recommend existed users for them . By utilizing the neighboring location characteristics , the probability that user i checks in a new location j is defined as follows :
 l∈ ˆψj l∈ ˆψj
SimG(j , l ) ˆpil
SimG(j , l )
 ,
ˆpij ∝ pG ij × σ where ˆψj is the set of S nearest neighboring locations of location j in the training data and in the experiments S is set as 10 . The advantage to exploit the similarity of neighboring locations is that we can handle new locations as soon as they are generated in the system , without needing to re train the model and estimate new parameters .
5 . EXPERIMENTS
In this section , we evaluate the proposed models with baseline methods on two real world data sets . 5.1 Experimental Setup
Datasets . In this paper , we use Gowalla and Foursquare datasets to evaluate the performance of the proposed models . Gowalla contains check in data ranging from January 2009 to August 2010 , and Foursquare includes the check in data of users who live in California , ranging from December 2009 to June 2013 . Each check in record in the datasets includes a user ID , a location ID and a timestamp , where each location has latitude , longitude and category information . Totally , there are 262 and 10 categories in Gowalla and Foursquare , respectively . Also , data sets have undirected friendship information and user ’s home information3 .
To evaluate model ’s cold start recommendation performance , for each data set , we divide it in three steps . First , we remove those users who have visited less than 10 locations and those locations which are visited by less than 10 users . These check ins are used to evaluate our model ’s performance for standard POI recommendation . In recommendation system , we aim to recommend those unvisited locations for users . Therefore , we split the training and testing data as follows : for each individual user , ( 1 ) aggregating the check ins for each location ; ( 2 ) sorting the location according to the first time that the user checked in ; ( 3 ) selecting the earliest 80 % to train the model and using the next 20 % as testing . Second , in the rest of check ins ( ie , locations that are visited by less than 10 users and not included in the training ) , we use those check ins whose locations are visited by users in the training data to evaluate the model ’s performance for new location recommendation . Third , in the rest of check ins ( ie , users who have visited less than 10 locations ) , we use those check ins where users are not in training data to evaluate user cold start recommendation performance . The data statistics are shown in Table 1 .
Experimental Settings .
In the experiments , the parameters β , λu , λv , ζ , η and ε are set to 0.15 , 0.015 , 0.015 , 0.5 , 0.001 , and 0.1 , respectively . In Gowalla dataset , α , and λq are set to 0.3 and 500 . In Foursquare dataset , α and λq are set to 0.1 and 300 . We will discuss the influence of α in the Section 544 The latent feature number is set as 10 . 3Our model can be applied in the general check in datasets . The home location can be estimated by using the existing approach in [ 2 , 3 ]
980 Data Set Gowalla
Foursquare
#User #Location #Checkin 2,577,336 52,216 2,551 124,933
98,351 13,474
#Train 2,049,630 100,033
#Test 527,706 24,900
Sparsity #New Location 0.0399 % 0.2910 %
78,881 93,311
#Test 568,937 119,876
#New User #Test 79,153 17,964
9,326 1,221
Table 1 : The statistics of data sets .
New Location Rec
New User Rec
Data Set Gowalla
Foursquare
Table 2 : The performance comparison of standard recommendation in terms of MAP . RegPMF 0.01388 0.02325
ARMF RW ARMF LA 0.05705 0.03907
ASMF RW ASMF LA 0.05713 0.05700 0.04167 0.04064
0.05715 0.03857
0.05205 0.03464
BPR
USG
PMF
0.03652 0.01923
WRMF 0.02470 0.03626
LOCABAL 0.01446 0.02344
IRenMF 0.02554 0.01357 0.03683 0.02288 541 Performance of Standard Recommendation The performance comparison of our models and baseline models in terms of Precision@K , Recall@K , and Map are shown in Figure 3 , Figure 4 and Table 2 .
Modeling observed check ins vs modeling all check ins . From the results , we can see that WRMF and BPR almost outperform LOCABAL , RegPMF and PMF . Even though LOCABAL and RegPMF incorporate social network into matrix factorization , the sparseness of data due to only modeling the observed check ins results in their poor performance . Both LOCABAL and RegPMF are slightly superior to PMF . One possible explanation is that social network assists to make more accurate recommendation . Different from them , WRMF not only utilizes the observed check ins , but also models negative preference for all unvisited locations with a low confidence . But BPR easily leads to bias by only sampling some unvisited locations , which explains why it performs not good in Foursquare data set .
Our models vs baseline models . Our models achieve the best performance in both data sets with all evaluation metrics , illustrating the superiority of our approaches . Although USG exploits social influence , geographical effect and user interest , its simple linear combination results in the poor performance . As Gowalla covers a much larger area than Foursquare , the clustering result is not good , leading to the worse performance of IRenMF in Gowalla than in Foursquare . ARMF and ASMF have different performance in two datasets which is consistent with performance of WRMF and BPR . Their similar performance in Gowalla is due to the much more evident spatial clustering phenomenon . Two approaches to learn potential locations perform similarly . But LA is more efficient than RW because it does not require any matrix operation . In addition , the better performance of our models in Gowalla than in Foursquare is for the sake of ( 1 ) the stronger correlation in Gowalla which is reflected in Figure 2(c ) and Figure 2(d ) , and ( 2 ) the more detailed category in Gowalla than in Foursquare , where Gowalla has 262 kinds of categories while Foursquare only has 10 different categories .
542 Performance of New POI Recommendation In this section , we evaluate the model performance of addressing location cold start problem . To recommend new locations , we predict the check in probability for each new location and then recommend the top K locations with the highest probabilities . Note that , among all the baseline methods , only USG and IRenMF can be applied here . Since new locations are never checked in by any users , USG is reduced to only model the geographical influence . In addition , the latent location vectors for new locations are not learned in the training , so one user ’s preference for a new location in IRenMF model is actually dependent on her preferences for this location ’s neighborhoods . The model performance in terms of precision , recall and MAP is shown in Table 3 .
5.2 Evaluation Metrics
As POI recommender system only recommends the limited locations for users , we quantitatively evaluate our models versus other models in terms of ranking performance , ie , Precision@K and Recall@K metrics . MAP metric , the mean of the average precision ( AP ) over all locations in the testing , is also adopted in the experiments to evaluate models’ performance . They are formally defined as follows :
N i=1
Si(K ) ∩ Ti
K
N i=1
M AP =
1 N
, Recall@K =
ˆmi j=1 p(j ) × rel(j )
1 N
,
|Ti|
N i=1
Si(K ) ∩ Ti
|Ti|
,
P recision@K =
1 N where Si(K ) is a set of top K unvisited locations recommended to user i excluding those locations in the training , and Ti is a set of locations that are visited by user i in the testing . ˆmi is the number of the returned locations in the list for user i , p(j ) is the precision of a cut off rank list from 1 to j , and rel(j ) is an indicator function that equals to 1 if the location is visited in the testing , otherwise equals to 0 . 5.3 Baseline Methods
To comparatively demonstrate the effectiveness of our mod network and user interest with collaborative filtering ; els , we compare them with the following seven models : • USG [ 28 ] , which combines geographical influence , social • IRenMF [ 15 ] , which models geographical influence by incorporating neighboring characteristics into weighted matrix factorization in both instance level and region level ; • LOCABAL [ 22 ] , which models two types of social relations : social friends and the users with high global reputations , in the framework of matrix factorization ; • RegPMF [ 16 ] , which models the influence of social network by placing a social regularization constraint on learning user specific feature vectors between friends ; • PMF [ 20 ] , which minimizes the square error loss only using the observed check ins based on matrix factorization . • WRMF [ 6 ] , which minimizes the square error loss by assigning both observed and unobserved check ins with different confidential values based on matrix factorization ; • BRP [ 18 ] , which optimizes the ordering of the preference for the observed location and the unobserved location .
In this paper , we develop two methods to learn the potential locations for each user ( ie , LA , RW ) and then design two loss functions : ASMF and ARMF . Thus we consider the following combinations : ASMF + LA , ASMF + RW , ARMF + LA , ARMF + RW , which are denoted as ASMFLA , ASMF RW , ARMF LA , ARMF RW , respectively . 5.4 Performance Comparison
In this section , we evaluate the proposed models for standard recommendation , new location and new user recommendation in terms of Precision@K , Recall@K and MAP . In addition , we discuss the influence of α in ASMF LA model .
981 ( a ) Precision@K on Gowalla
( b ) Recall@K on Gowalla
( c ) Precision@K on Foursquare ( d ) Recall@K on Foursquare
Figure 3 : The performance comparison of standard recommendation of basic methods for precision and recall .
( a ) Precision@K on Gowalla
( b ) Recall@K on Gowalla
( c ) Precision@K on Foursquare ( d ) Recall@K on Foursquare
Figure 4 : The performance comparison of standard recommendation of our models and other models .
( a ) Precision@K
( b ) Recall@K
( c ) Precision@K
( d ) Recall@K
Figure 5 : The performance comparison of new user recommendation on Gowalla data set ( top ) and Fousquare data set(bottom ) .
Based on the results , we can observe that IRenMF performs the worst among all methods on both datasets . Although taking advantage of the similarities of neighboring locations , IRenMF fails to appropriately model user ’s checkin behaviours . It happens likely due to that it does not well exploit the inherent characteristics of geographical distance . On the other hand , our models and USG utilize the power law distribution to capture the spatial clustering phenomenon for user ’s check in activities , which is based on the observation over data . Therefore , they have much better performance than IRrenMF model in location cold start recommendation . Also , our models gain superior performance over USG . A possible reason is that a user ’s preference latent vector has been learned in the training so that her preference on the target location ’s neighborhoods can be accurately predicted . However , USG only leverages the geographical similarity between a new location and her historical POIs as prediction . In addition , the performance of ASMF and ARMF is consistent with earlier experimental results . 543 Performance of New User Recommendation In this section , we evaluate model ’s recommendation performance for user cold start problem . When a new user enters the system , we do not have her historical check in information . As a result , her latent vector cannot be learned and all of these baseline methods could not address this problem . The proposed models elaborate the historical check ins of a user ’s neighboring friends ( and social friends if she has ) to learn her preference vector . Thus , they can be adopted to cope with user cold start problem . As the proposed augmenting framework could be adapted to WRMF and BPR based models , we construct the following baseline methods with the similar loss functions in Eq ( 18 ) and Eq ( 11 ) : ( 1 ) WRMF+LA , denoted as AWRMF LA ; ( 2 ) WRMF+RW , denoted as AWRMF RW ; ( 3 ) BPR+LA , denoted as ABPRLA ; ( 4 ) BPR+RW , denoted as ABPR RW . The precision , recall and MAP of these models over two datasets are shown in Figure 5 and Table 4 .
From the results , we find that all models have good performance to address user cold start problem . The augmenting approach with friends’ historical check ins significantly benefits the location recommendation , in particular user coldstart recommendation . Meanwhile , the successful application of the augmenting strategy in WRMF and BPR demonstrates that the proposed augmenting strategy can be easily applied in any square error and ranking error based matrix factorization models . Moreover , our models perform much better than the baseline approaches for the sake of exploiting geographical influence and category information . ARMF and ASMF perform consistently as above results . Overall , we can see that our models can handle user cold start problem very well . 544 The ASMF model treats user ’s check in as an indication of positive , potential and negative preference with difference confidence . The parameter α shown in Eq ( 10 ) indicates the probability that users will check in an unvisited location
Study of Influence of Parameter α
5810121520K001002003004005PMFRegPMFLOCABALBPRWRMF5810121520K001002003004005006007008PMFRegPMFLOCABALBPRWRMF5810121520K002003004005006PMFRegPMFLOCABALBPRWRMF5810121520K002003004005006007PMFRegPMFLOCABALBPRWRMF5810121520K002003004005006007IRenMFUSGARMF LAARMF RWASMF LAASMF RW5810121520K00200400600801IRenMFUSGARMF LAARMF RWASMF LAASMF RW5810121520K0030035004004500500550060065IRenMFUSGARMF LAARMF RWASMF LAASMF RW5810121520K003004005006007008IRenMFUSGARMF LAARMF RWASMF LAASMF RW5810121520K0025003003500400450050055006ABPR LAABPR RWAWRMF LAAWRMF RWARMF LAARMF RWASMF LAASMF RW5810121520K00300400500600700800901ABPR LAABPR RWAWRMF LAAWRMF RWARMF LAARMF RWASMF LAASMF RW5810121520K0010015002002500300350040045ABPR LAABPR RWAWRMF LAAWRMF RWARMF LAARMF RWASMF LAASMF RW5810121520K00200400600801012ABPR LAABPR RWAWRMF LAAWRMF RWARMF LAARMF RWASMF LAASMF RW982 ASMF RW 0.08956 ASMF LA 0.08967 ARMF RW 0.09463 0.09456 ARMF LA 0.08632 0.00073
IRenMF
USG
ASMF RW 0.04195 ASMF LA 0.04171 ARMF RW 0.04061 0.04022 ARMF LA 0.03551 0.00401
IRenMF
USG
0.08543 0.08549 0.08946 0.08927 0.07826 0.00094
0.04276 0.04257 0.04085 0.04000 0.03594 0.00339
0.08320 0.08323 0.08666 0.08643 0.07407 0.00104
0.04171 0.04230 0.04057 0.04002 0.03452 0.00314
P@15
R@5 Gowalla Data Set
0.07807 0.07807 0.08038 0.08022 0.06587 0.00120
0.06032 0.06020 0.06457 0.06449 0.05448 0.00033 Foursquare Data Set 0.00419 0.00411 0.00382 0.00457 0.00268 0.00038
0.04121 0.04116 0.04048 0.03949 0.03301 0.00317
0.08095 0.08100 0.08401 0.08375 0.07044 0.00113
0.04144 0.04111 0.04052 0.03951 0.03375 0.00304
Table 3 : The performance comparison of new location recommendation . P@5
R@10
P@12
P@10
P@12
R@15
R@8
P@8
0.08029 0.08035 0.08576 0.08564 0.07645 0.00057
0.00697 0.00680 0.00664 0.00701 0.00561 0.00050
0.09259 0.09268 0.09822 0.09794 0.08885 0.00079
0.00843 0.00860 0.00823 0.00856 0.00714 0.00055
0.10344 0.10353 0.10914 0.10901 0.10007 0.00105
0.01006 0.00992 0.00993 0.01017 0.00886 0.00068
0.11883 0.11887 0.12437 0.12440 0.11515 0.00140
0.01247 0.01257 0.01296 0.01258 0.01126 0.00108
MAP
0.08424 0.08430 0.08768 0.08766 0.07578 0.00271
0.02036 0.02040 0.02010 0.02051 0.01592 0.00346
Table 4 : The performance comparison of new user recommendation in terms of MAP .
Data Set Gowalla
Foursquare
ASMF RW ASMF LA ARMF RW ARMF LA AWRMF RW AWRMF LA ABPR RW ABPR LA
0.05442 0.04831
0.05427 0.04836
0.05589 0.03770
0.05562 0.03718
0.03021 0.03242
0.02921 0.03683
0.02423 0.02971
0.02396 0.02813 which her friends have checked in before . In this section , we study the influence of variable α . Due to limited space , we only show the performance of ASMF model with Linear Aggregation . The precision , recall and MAP of ASMF LA with different α value over two datasets are reported in Figure 6 . Based on the results , we can observe that the performance in all evaluation metrics has similar behaviour with the varying value of α . It is observed that ASMF LA achieves the best performance when α is 0.3 and 0.1 on Gowalla and Foursquare , respectively . The performance then drops dramatically when α goes far away from the maximum point . If the α is set as a very small value , it will have no major difference to optimize those potential check ins and other unobserved check ins , which makes ASMF LA difficult to obtain more accuracy prediction . If the α is set with a very large value , it will easily generate noise when optimizing both her own and friends’ historical check ins . It occurs possibly due to some other locations that a user ’s friends have checked in but she might be in fact not interested in . As a result , α with a large value would probably affect the entire optimization process . Furthermore , the maximum point of α on Gowalla is larger than the one on Foursqaure , which indicates that users would have a larger chance to check in their friends’ POIs on Gowalla . This result is consistent with the observation that the correlation between users in Gowalla is much stronger than that in Foursquare . At last , we find that the performance with different α value on Gowalla changes much smaller than that on Foursquare . The more evident spatial clustering phenomenon on Gowalla than that on Foursquare is a reasonable explanation why ASMF LA has such small change . On Gowalla dataset , geographical distance plays an extremely important role on affecting user ’s POI decision so that it compromises the prediction result even though user interest has a big change . 6 . RELATED WORK
Related works about POI recommendation can be grouped into two categories . The first category focuses on modeling geographical influence [ 28 , 3 , 1 , 30 , 13 , 14 , 12 , 15 , 17 ] . Specifically , there are several approaches to model geographical distance . For example , some approaches leveraged Gaussian mixture model to characterize user ’s check in activities [ 3 , 1 ] ; While some approaches utilized the kernel density estimation ( KDE ) to study user ’s check in behavior and avoid employing a specific distribution[30 , 13 ] . [ 28 ] pro posed to use a power law distribution to estimate the checkin probability with the distance of any pair of visited POIs due to the spatial clustering phenomenon exhibited in LBSNs . The user ’s preference for one location is predicted by a linear model with combining users’ interest , social friends’ interests and geographical influence . Later , [ 15 ] considered two types of geographical neighborhood characteristics : instance level and region level . Specifically , in instance level , a user ’s preference for one location is modeled by a combination of her preference for this location and the nearest neighborhoods of this location . In region level , it places a group lasso penalty to learn location specific latent vectors and capture the region effect .
The second category throws light on elaborating social network information [ 16 , 5 , 22 , 28 , 25 , 4 , 27 , 7 , 21 , 9 ] . For example , [ 27 , 28 ] proposed user based collaborative filtering to estimate the unobserved rating by directly using the check in information of friends . [ 16 ] assumed friends would share similar interests and then placed a social regularization term to constrain the objective functions for learning accurate user feature vectors . [ 5 ] proposed to model four types of social correlations ( ie , local friends , distant friends , local non friends and distant non friends ) by using a geo social correlation model with users’ check in activities , where the check in probability was measured as a linear combination of these four geo social correlations and the corresponding coefficients were learned by a group of features in a logistic regression like fashion . [ 22 ] modeled local and global social relations for all users . Specifically , in local context , it models the correlation between users and their friends ; while in global context , it uses the reputation of a user in the whole social network as weight to fit observed ratings .
In addition , there are some recommendation works based on content , sentiments and temporal effect [ 10 , 14 , 26 , 17 , 29 , 31 ] . However , our work is different from these existing works . To be specific , we first learn user ’s potential locations with the check in information of social friends , location friends and neighboring friends , and then incorporate them into matrix factorization model using different error loss functions . 7 . CONCLUSION
In this paper , we proposed a two step framework for POI recommendation problem , which considers the check in information of three types of friends , ie , social friends , loca
983 ( a ) Precision@5
( b ) Precision@5
( c ) Precision@10
( d ) Precision@10
( e ) Recall@5
( f ) Recall@5
( g ) Recall@10
( h ) Recall@10
( i ) MAP
( j ) MAP
Figure 6 : The influence of α on Gowalla data set ( left ) and Foursquare data set ( right ) . tion friends and neighboring friends . Specifically , in the first step , we designed two approaches to learn the locations that a user ’s friends had checked in before and she was most interested in . In the second step , we developed matrix factorization based models with two different error loss functions using the learned potential locations . Specifically , the square error based loss extended a binary preference to a ternary variable for the observed check ins , potential check ins and other unobserved check ins , and the ranking error based loss modeled the ranking of user ’s preference for her visited locations , potential locations , and unvisited locations . Finally , experimental results on two real world data sets clearly validated the improvement of our models over many baseline methods based on different validation metrics .
Acknowledgments This work is partially supported by NIH ( 1R21AA02397501 ) and NSFC ( 71571093 , 71372188 , 61572032 ) . 8 . REFERENCES
[ 1 ] C . Cheng , H . Yang , I . King , and M . R . Lyu . Fused matrix factorization with geographical and social influence in location based social networks . In AAAI , 2012 .
[ 2 ] Z . Cheng , J . Caverlee , K . Lee , and D . Z . Sui . Exploring millions of footprints in location sharing services . In ICWSM , 2011 .
[ 3 ] E . Cho , S . A . Myers , and J . Leskovec . Friendship and mobility :
User movement in location based social networks . In KDD , pages 1082–1090 , 2011 .
[ 4 ] H . Gao , J . Tang , and H . Liu . Exploring social historical ties on location based social networks . In ICWSM , 2012 .
[ 5 ] H . Gao , J . Tang , and H . Liu . gscorr : Modeling geo social correlations for new check ins on location based social networks . In CIKM , pages 1582–1586 , 2012 .
[ 6 ] Y . Hu , Y . Koren , and C . Volinsky . Collaborative filtering for implicit feedback datasets . In ICDM , pages 263–272 , 2008 .
[ 7 ] I . Konstas , V . Stathopoulos , and J . M . Jose . On social networks and collaborative recommendation . In SIGIR , 2009 .
[ 8 ] Y . Koren , R . Bell , and C . Volinsky . Matrix factorization techniques for recommender systems , 2009 .
[ 9 ] H . Li , R . Hong , S . Zhu , and Y . Ge . Point of interest recommender systems : A separate space perspective . In ICDM , pages 231–240 , 2015 .
[ 10 ] H . Li , Z . W . Richang Hong , and Y . Ge . A spatial temporal probabilistic matrix factorization model for point of interest recommendation . In SDM , pages 117–125 , 2016 .
[ 11 ] H . Li , H . Zhu , Y . Ge , Y . Fu , and Y . Ge . Personalized TV recommendation with mixture probabilistic matrix factorization . In SDM , pages 352–360 , 2015 .
[ 12 ] D . Lian , C . Zhao , X . Xie , G . Sun , E . Chen , and Y . Rui . Geomf :
Joint geographical modeling and matrix factorization for point of interest recommendation . In KDD , 2014 .
[ 13 ] M . Lichman and P . Smyth . Modeling human location data with mixture of kernel densities . In KDD , 2014 .
[ 14 ] B . Liu , Y . Fu , Z . Yao , and H . Xiong . Learning geographical preferences for point of interest recommendation . In KDD , pages 1043–1051 , 2013 .
[ 15 ] Y . Liu , W . Wei , A . Sun , and C . Miao . Exploiting geographical neighborhood characteristics for location recommendation . In CIKM , pages 739–748 , 2014 .
[ 16 ] H . Ma , D . Zhou , C . Liu , M . R . Lyu , and I . King . Recommender systems with social regularization . In WSDM , 2011 .
[ 17 ] QuanYuan , G . Cong , and A . Sun . Graph based point of interest recommendation with geographical and temporal influences . In CIKM , pages 659–668 , 2014 .
[ 18 ] S . Rendle , C . Freudenthaler , Z . Gantner , and
L . Schmidt Thieme . Bpr : Bayesian personalized ranking from implicit feedback . In UAI , pages 452–461 , 2009 .
[ 19 ] S . Ruslan and M . Andriy . Bayesian probabilistic matrix factorization using markov chain monte carlo . In ICML , 2008 .
[ 20 ] R . Salakhutdinov and A . Mnih . Probabilistic matrix factorization . In NIPS , pages 1257–1264 , 2007 .
[ 21 ] S . Scellato , A . Noulas , and C . Mascolo . Exploiting place features in link prediction on location based social networks . In KDD , pages 1046–1054 , 2011 .
[ 22 ] J . Tang , X . Hu , H . Gao , and H . Liu . Exploiting local and global social context for recommendation . In IJCAI , 2013 .
[ 23 ] W . Tobler . A computer movie simulating urban growth in the detroit region . Economic Geography , pages 234–240 , 1970 .
[ 24 ] H . Tong , C . Faloutsos , and J Y Pan . Fast random walk with restart and its applications . In ICDM , pages 613–622 , 2006 .
[ 25 ] H . Wang , M . Terrovitis , and N . Mamoulis . Location recommendation in location based social networks using user check in data . In SIGSPATIAL , pages 374–383 , 2013 .
[ 26 ] D . Yang , D . Zhang , Z . Yu , and Z . Wang . A sentiment enhanced personalized location recommendation system . In HT , 2013 . [ 27 ] M . Ye , P . Yin , and W C Lee . Location recommendation for location based social networks . In GIS , pages 458–461 , 2010 .
[ 28 ] M . Ye , P . Yin , W C Lee , and D L Lee . Exploiting geographical influence for collaborative point of interest recommendation . In SIGIR , pages 325–334 , 2011 .
[ 29 ] Z . Yu , H . Xu , Z . Yang , and B . Guo . Personalized travel package with multi point of interest recommendation based on crowdsourced user footprints . IEEE Trans . Human Machine Systems , 46(1):151–158 , 2016 .
[ 30 ] J . Zhang and C . Chow . igslr : Personalized geo social location recommendation a kernel density estimation approach . In SIGSPATIAL , pages 334–343 , 2013 .
[ 31 ] H . Zhu , E . Chen , H . Xiong , K . Yu , H . Cao , and J . Tian . Mining mobile user preferences for personalized context aware recommendation . ACM ( TIST ) , 5(4):58:1–58:27 , 2014 .
0102030405060708091006600665006700675006800685α0102030405060708091004500500550060065α0102030405060708091005250053005350054α010203040506070809100350040045005α0102030405060708091004900495005α01020304050607080910030035004α01020304050607080910074007450075007550076α010203040506070809100450050055006α01020304050607080910056005620056400566005680057α0102030405060708091003200340036003800400420044α984
