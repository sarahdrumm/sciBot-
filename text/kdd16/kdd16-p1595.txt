Meta Structure : Computing Relevance in
Large Heterogeneous Information Networks
Zhipeng Huang , Yudian Zheng , Reynold Cheng , Yizhou Sun † , Nikos Mamoulis , Xiang Li
{zphuang , ydzheng2 , ckcheng , nikos , xli2}@cshkuhk , †yzsun@ccsneuedu
The University of Hong Kong ,
†Northeastern University
ABSTRACT A heterogeneous information network ( HIN ) is a graph model in which objects and edges are annotated with types . Large and complex databases , such as YAGO and DBLP , can be modeled as HINs . A fundamental problem in HINs is the computation of closeness , or relevance , between two HIN objects . Relevance measures can be used in various applications , including entity resolution , recommendation , and information retrieval . Several studies have investigated the use of HIN information for relevance computation , however , most of them only utilize simple structure , such as path , to measure the similarity between objects . In this paper , we propose to use meta structure , which is a directed acyclic graph of object types with edge types connecting in between , to measure the proximity between objects . The strength of meta structure is that it can describe complex relationship between two HIN objects ( eg , two papers in DBLP share the same authors and topics ) . We develop three relevance measures based on meta structure . Due to the computational complexity of these measures , we further design an algorithm with data structures proposed to support their evaluation . Our extensive experiments on YAGO and DBLP show that meta structure based relevance is more effective than state of the art approaches , and can be efficiently computed .
1 .
INTRODUCTION
Heterogeneous information networks ( HINs ) , such as DBLP [ 8 ] , YAGO [ 15 ] , DBpedia [ 1 ] and Freebase [ 2 ] , have recently received a lot of attention . These graph data sources contain a vast number of inter related facts , and they are used to facilitate the discovery of interesting knowledge [ 5 , 7 , 12 , 13 ] . Figure 1 illustrates an HIN , which describes the relationship among entities of different types ( eg , author , paper , venue and topic ) . For example , Jiawei Han ( a2 ) has written a VLDB paper ( p2,2 ) , which mentions the topic “ efficient ” ( t3 ) .
Given two HIN objects a and b , the evaluation of their relevance is of fundamental importance . This quantifies the degree of closeness between a and b . In Figure 1 , Jian Pei ( a1 ) and Jiawei Han ( a2 ) have a high relevance score , since they have both published papers with keyword “ mining ” in the same venue ( KDD ) . Relevance
Figure 1 : Illustrating an HIN . finds its applications in information retrieval , recommendation , and clustering [ 18 , 22 ] : a researcher can retrieve papers that have high relevance in terms of topics and venues in DBLP ; in YAGO , relevance facilitates the extraction of actors who are close to a given director . As another example , in entity resolution applications , duplicated HIN object pairs having high relevance scores ( eg , two different objects in an HIN referring to the same real world person ) can be identified and removed from the HIN .
Prior works . To measure the relevance between two graph objects , neighborhood based measures such as common neighbors and Jaccard ’s coefficient were proposed [ 9 ] . Other graph theoretic measures that are based on random walks between objects include Personalized PageRank [ 3 ] and SimRank [ 6 ] . These measures do not consider object and edge type information in an HIN . To handle this information , the concept of meta paths has been recently proposed [ 7 , 18 ] . A meta path is a sequence of object types with edge types in between . Figure 2(b ) illustrates a meta path P1 , which states that two authors ( A1 and A2 ) are related by their publications in the same venue ( V ) . Another meta path P2 says that two authors have written papers containing the same topic ( T ) . Based on a meta path , several relevance measures , such as PathCount , PathSim , and Path Constrained Random Walk ( PCRW ) [ 7,18 ] have been proposed . These measures have been shown to be better than those that do not consider object and edge type information .
Meta structures . We propose a novel concept , named meta structure , to depict the relationship of two graph objects . This is essentially a directed acyclic graph of object and edge types . Figure 2(b ) illustrates a meta structure S , which depicts that two authors are relevant if they have published papers in the same venue , and have also mentioned the same topic . A meta path ( eg , P1 or a1a2a3p1,2p1,1p2,1p2,2p3,2p3,1v1v2v3v4t1t2t3t4KDD “ mining ” AAAIVLDB “ efficient ” “ privacy ” AAAI’15VLDB’15KDD’15KDD’07ICDM “ social ” ICDM’12writepublishmentionVLDB’06authorpapervenuetopicobject types:edge types:1595 P2 ) is a special case of a meta structure . However , a meta path fails to capture such complex relationship that can be conveniently expressed by a meta structure ( eg , S ) . Our experiments also show that meta structures are more effective than meta paths .
We provide a sound definition for meta structure . This is not straightforward , since a meta structure can be complex . We then present three relevance measures based on meta structures . These measures vary in the way that the relevance is computed . Given a meta structure S , the StructCount evaluates the number of subgraphs that matches S ; the Structure Constrained Subgraph Expansion ( SCSE ) simulates the process of subgraph expansion restricted on S ; the Biased Structure Constrained Subgraph Expansion ( BSCSE ) is a generalization of StructCount and SCSE .
A challenge of these new measures is their high computational cost . In general , evaluating these measures requires a subgraph matching operation over an HIN . In a typical HIN ( eg , YAGO ) that contains millions of objects and edges , this can be very expensive . Moreover , an application ( eg , clustering ) may require computing relevance for many object pairs . Hence , it is important to ensure that these relevance measures can be efficiently evaluated . To tackle this challenge , we design a recursive traversal algorithm with two data structures ( called Compressed ETree and i LTable ) to improve the efficiency of relevance computation .
To validate our approaches , we have performed extensive experiments on YAGO and DBLP . The results show that our three meta structure measures are more effective in expressing relevance than meta path based approaches . Our algorithms also enable meta structure relevance to be computed efficiently on large graphs , yielding similar runtime cost to meta path measures .
The rest of this paper is as follows . We describe the HIN model and summarize existing meta path based approaches in Section 2 . We introduce the meta structure in Section 3 . We then define relevance measures based on meta structures in Section 4 . We develop a recursive algorithm and two data structures to facilitate computing relevance measures in Section 5 . Section 6 presents our experiment results . We conclude our study in Section 7 .
2 . HIN AND META PATHS
Let us now review the HIN model in Section 21 We then sum marize existing meta path approaches in Section 22 2.1 The HIN model
A Heterogeneous Information Network ( HIN ) , proposed in [ 18 ] , is a directed graph G = ( V , E ) with an object type mapping function φ : V → L and a link type mapping function ψ : E → R , where each object v ∈ V belongs to an object type φ(v ) ∈ L , and each link e ∈ E belongs to a link type ψ(e ) ∈ R .
Figure 1 illustrates an HIN , which is also a bibliography network . A paper object can link ( or be linked ) to its authors , a venue and its related topics . Note that multiple edges of distinct types between two objects may exist .
DEFINITION 1 . HIN Schema [ 18 ] . Given an HIN G = ( V , E ) with mappings φ : V → L and ψ : E → R , its schema TG is a directed graph defined over object types L and link types R , ie , TG = ( L,R ) .
The HIN schema expresses all allowable link types between object types . Figure 2(a ) shows the schema of the HIN defined in Figure 1 , where the nodes A , P , T and V correspond to author , paper , topic , and venue , respectively . There are also different edge types in the schema , such as ‘publish’ and ‘write’ .
( a ) Schema
( b ) Meta Path , Meta Structure
Figure 2 : Schema , Meta Path , and Meta Structure .
Table 1 : Relevance of Author Pairs . Meta Path Measures
Meta Structure Measures
PathCount
PathSim PCRW StructCount
2 2
0.5 0.5
0.25 0.25
1 0
SCSE 0.25
0
BSCSE
0.5 0
Pair a2 , a1 a2 , a3
2.2 Meta Paths
A meta path [ 18 ] , denoted by P , is essentially a path defined on an HIN schema TG , with the types of source object and target object on both ends of the path . For example , based on the schema in Figure 2(a ) , a meta path AP V P A ( P1 in Figure 2(b ) ) describes the relationship of two authors ( source and target objects ) who have published papers at the same venue . An instance of the meta path in the HIN of Figure 1 is a1 → p1,2 → t2 → p2,1 → a2 . Here we use lower case letters ( eg , v1 ) to denote objects in an HIN and upper case letters ( eg , V ) to denote object types . Given a source object os ∈ V , a target object ot ∈ V and a meta path P , meta path relevance measures have been proposed to evaluate the relevance between os and ot : • PathCount [ 18 ] : the number of meta path instances of P connecting os and ot . • PathSim [ 18 ] : a normalized version of PathCount , whose value is between 0 and 1 . • PCRW [ 7 ] : the probability that a random walk restricted on P starting from os would arrive at ot .
Researchers have recently studied the use of meta paths in search and mining tasks , including top k search [ 18 ] , link prediction [ 16 , 17 , 20 ] , clustering [ 4 , 19 ] , and recommendation [ 10 , 11 , 21 ] . As pointed out in [ 18 ] , meta paths can be provided by experts who are familiar with the HIN schema . More recently , a meta path discovery algorithm has been proposed [ 12 ] , where users provide example instances of source and target objects , based on which meta paths are derived automatically .
Drawbacks of meta paths . Although meta paths have been shown to be useful in different applications , they can only express simple relationship between source and target objects . As illustrated in Figure 2(b ) , a complex relationship ( S ) between two authors cannot be captured by a path between them . To solve this problem , a straightforward way is to decompose S into two meta paths ( ie , P1 and P2 ) . The relevance functions of two given author objects are computed for P1 and P2 separately , then the relevance based on S is a linear combination of the relevances based on P1 and P2 [ 7 , 10 , 12 ] . However , this simple approach overlooks the problem that some nodes in S ( eg , P1 ) are shared by two or more edges ; decomposing S into two separate meta paths results in a loss of this information . In this example , the node P1 in S refers to a single paper . However , when S is decomposed , the corresponding P1 nodes in meta paths P1 and P2 can mean different papers . This can yield inaccurate relevance results . As shown in Table 1 , using
APVTwritementionpublishcitemention−1publishVpublish−1writewrite 1P1P2A2A1Twritewrite 1P1P2A2A1mentionpublishVpublish−1writewrite 1P1P2A2A1Tmentionmention−1P1P2S:::1596
07 and KDD the linear combination approach , existing meta path measures regard pairs ( a2 , a1 ) and ( a2 , a3 ) to have the same relevance score . In fact , ( 1 ) a1 and a2 have papers ( KDD 15 ) both mentioning “ mining ” and published in the KDD venue ; and ( 2 ) none of the papers of a2 and a3 are published in the same venue and have the same topic . Hence , ( a2 , a1 ) should have a higher relevance score than ( a2 , a3 ) . The linear combination approach fails to recognize these differences , and mistakenly gives the same relevance for ( a2 , a1 ) and ( a2 , a3 ) . This calls for a better measure to handle such complex relationship , as discussed next .
3 . META STRUCTURES
The meta structure , designed to capture complex relationship be tween two HIN objects , is defined as follows .
DEFINITION 2 . Meta Structure . A meta structure S is a directed acyclic graph ( DAG ) with a single source node ns ( ie , with in degree 0 ) and a single sink ( target ) node nt ( ie , with outdegree 0 ) , defined on an HIN schema TG = ( L,R ) . Formally , S = ( N , M , ns , nt ) , where N is a set of nodes and M is a set of edges . For any node x ∈ N , x ∈ L ; for any link ( x , y ) ∈ M , ( x , y ) ∈ R .
An example meta structure S is shown in Figure 2(b ) . We can see that S is a DAG , with source node ns = A1 ( in degree 0 ) and target node nt = A2 ( out degree 0 ) .
In Definition 2 , a meta structure has a single source node and a single target node . Otherwise , there exists at least one node v such that there is no path from ns to nt that goes through v . Since v does not affect the relationship between ns and nt , v can be removed from S .
DEFINITION 3 . Instance of Meta Structure . Given an HIN G and meta structure S = ( N , M , ns , nt ) , an instance s of meta structure S on G is a subgraph of G , denoted by s = ( Ns , Ms ) , such that there exists a mapping for s , hs : Ns → N satisfying the following constraints : • Object Correspondence : for any object v ∈ Ns , its object type φ(v ) = hs(v ) ; • Link Correspondence : for any link ( u , v ) ∈ ( /∈)Ms , we have ( hs(u ) , hs(v ) ) ∈ ( /∈)M .
( a ) Instance s1
( b ) Instance s2
Figure 3 : Instances of Meta Structure for Figure 2(b ) .
Figure 3 illustrates two instances of meta structure S in Fig ure 2(b ) , where os = a2 for both cases .
Constructing a meta structure . In this paper , we assume that the meta structure is given . We outline several possible solutions that can be used to define a meta structure ; their details are left for future work . • Develop a Graphical User Interface ( GUI ) that provides drawing tools to allow meta structures to be conveniently specified . • Use an existing graph query . For example , SPAQRL [ 14 ] is a RDF language that allows query graphs to be expressed . Since a meta structure can also be specified as a query graph , SPAQRL can be used to represent a meta structure . Meta structure relevance computation operations can also be defined on SPARQL .
• Synthesize meta paths . A meta structure can also be constructed by synthesizing existing meta paths . For example , from two meta paths P1 and P2 in Figure 2(b ) , we can form meta structure S by combining the common nodes A1 , P1 , P2 , A2 in P1 and P2 .
The above solutions assume that the user has some knowledge about the HIN schema and meta structures . Once these meta structures are defined , they can be stored in the system for non expert users to choose . Recently , an example based algorithm has been recently developed in [ 12 ] , where a user first provides some example pairs of relevant source and target objects . The algorithm then discovers possible meta paths that best explain the relationship between the example pairs . It would be interesting to investigate how this method can be extended to support automatic discovery of meta structures . 3.1 Meta Structure Based Relevance Given an HIN G = ( V , E ) and a meta structure S , we define the relevance function for a source object os ∈ V and a target object ot ∈ V as follows : s(os , ot | S ) = s∈S f ( os , ot | s ) ,
( 1 ) where f ( os , ot | s ) is a relevance measure defined on some instance s of meta structure that conforms to S . Here , we use s ∈ S to denote the set of all instances of S on G . For example , given HIN G in Figure 1 , and meta structure S in Figure 2(b ) , two possible instances of S are shown in Figure 3 . Let us define f ( os , ot | s ) = 1 if and only if hs(os ) = ns and hs(ot ) = nt . Then , s(a2 , a1 | S ) = 1 and s(a2 , a3 | S ) = 0 .
We can now define the Relevance Search Problem that we intend to study in this paper .
DEFINITION 4 . Relevance Search Problem . Given an HIN G = ( V , E ) , a meta structure S = {N , M , ns , nt} , a relevance measure f ( · ) , and a source object os ∈ V , return a ranked list of target objects in decreasing order of s(os , ot | S ) , such that for any ot in the list , s(os , ot | S ) > 0 .
The relevance search problem is prevalent in many applications , such as information retrieval and recommendation . For example , an author can use meta structure S in Figure 2(b ) to find out a list of potential co authors . In our experiments , we also study this problem in the context of entity resolution , ranking , and clustering . We remark that a useful variant of this problem is to return the topk target objects ( ie , those whose relevance scores are among the k highest ) , where k is specified by the user . 4 . MEASURES ON META STRUCTURE
In this section , we show how the relevance measures f ( os , ot | s ) based on a meta structure instance s can be defined . Specifically , we first define two meta structure based relevance measures , StructCount and Structure Constrained Subgraph Expansion ( SCSE ) . Then , we propose a variant of SCSE named Biased Structure Constrained Subgraph Expansion ( BSCSE ) , which is a generalization of StructCount and SCSE . Finally we analyze the recursive tree of BSCSE in detail and give an explicit definition of f ( os , ot | s ) for BSCSE . 4.1 StructCount
A straightforward relevance measure is to count the number of meta structure instances in the graph that have os ( ot ) as source ( target ) node :
DEFINITION 5 . StructCount . Given an HIN G = ( V , E ) , a meta structure S = ( N , M , ns , nt ) , a source object os and a target object ot , the value of StructCount is defined as the number of a1p1,2v2t2p2,1a2v2t2a2a2p2,1p2,11597 instances of s ∈ S , such that os and ot are mapped to ns and nt in S , respectively . Recall the mapping function hs(· ) defined in Definition 3 . Formally , for the relevance measure f of StructCount , f ( os , ot | s ) = 1 if there exists a mapping function hs for s , such that hs(os ) = ns and hs(ot ) = nt .
Take the HIN G in Figure 1 and the meta structure S in Figure 2(b ) as an example . If we set os = a2 and ot = a1 , then the StructCount of S on G is 1 , ie , StructCount(a2 , a1 | S ) = 1 . The reason is that there is only one instance , ie , s1 in Figure 3 that correctly maps a2 to A1 and a1 to A2 .
We can directly use StructCount to measure relevance on HINs . However , just as PathCount in meta path based framework , the value of StructCount is not bounded . This biases highly visible objects ( ie , objects with higher degrees tend to have larger StructCount values ) . This could be useful when we favor popular objects , but in some applications where we favor highly relevant objects instead of popular ones , such as co author recommendation , StructCount is not suitable . 4.2 SCSE
The fact that StructCount is a biased measure motivates us to define another relevance measure , named Structure Constrained Subgraph Expansion ( SCSE ) . Intuitively , SCSE models the probability that the source object os would expand to an instance of S that covers the target object ot . As the value of SCSE is between 0 and 1 , it removes the bias of highly visible nodes .
Before defining SCSE , we first need to define a concept of layer for meta structure .
DEFINITION 6 . Layer of Meta Structure . Given a meta structure S = ( N , M , ns , nt ) , we can partition its nodes wrt their topological order in S . Specifically , we denote by S[i ] ⊆ N as the nodes of the i th layer , and by S[i : j ] ( 1 ≤ i ≤ j ) as the nodes from the i th to the j th layer . We denote by dS the number of layers , thus S[1 : dS ] = N . Note that S[· ] is a partition of nodes in N , thus for any i = j , S[i ] ∩ S[j ] = ∅ .
For example , the meta structure S in Figure 2(b ) has dS = 5 layers . That is , S[i ] for 1 ≤ i ≤ 5 are {A1} , {P1} , {V , T} , {P2} and {A2} , respectively . Given an HIN G and a meta structure S , starting from a source object os ∈ V , we can generate all possible instances s ∈ S following the layers of S . For example , given an HIN G ( Figure 1 ) and a meta structure S ( Figure 2(b) ) , starting from an instance os = a2 , we can generate all the instances of s ∈ S on G by recursively expanding subgraph of G as shown in Figure 4 . In order to define the process of subgraph expansion , we denote by σ(g , i | S , G ) the ( i + 1) th layer ’s instances expanded from g ∈ S[1 : i ] on G . For example , if g is the graph 3(a ) in Figure 4 , then σ(g , 3 | S , G ) is a set containing the graphs 4(a ) and 4(b ) because they are instances of S[1 : 4 ] expanded from g .
Based on these notations , we now turn to a more unbiased mea sure , defined below .
DEFINITION 7 . Structure Constrained Subgraph Expansion ( SCSE ) . Given an HIN G = ( V , E ) , a meta structure S , a source object os ∈ V and a target object ot ∈ V , the SCSE of a i th layer subgraph g ⊆ G is defined recursively as follows :
SCSE(g , i + 1 | S , ot ) g∈σ(g,i | S,G )
SCSE(g , i | S , ot ) = where the base case is the instance at layer dS . SCSE(g , dS | S , ot ) = 1 if and only if there exists a mapping function hg for g such that hg(ot ) = nt . We are interested in SCSE(os , 1 | S , ot ) .
| σ(g , i | S , G ) |
,
Figure 4 : An Example ETree .
For example , given the HIN G of Figure 1 , meta structure S in Figure 2(b ) , and os = a2 , ot = a1 , starting from os , we show the process of subgraph expansion in Figure 4 . In the last layer , ie , the base case , only 5(b ) correctly maps a1 to A2 ( 5(a ) and 5(c ) do not have a1 ) . In the first layer , we derive the value of our interest SCSE(s2 , 1 | S , a1 ) = 1/2+0 We can see that SCSE models the probability that an initial subgraph of G ( ie , os ) would expand to an instance of S covering ot . Obviously , the value of SCSE is between 0 and 1 , so it can remove the bias to highly visible objects . 4.3 BSCSE : A Unified Measure
4 . 2 = 1
From the definitions above , we observe that both StructCount and SCSE restrict search to subgraphs that can strictly match the meta structure . For example , StructCount measures the absolute number of such subgraphs , while SCSE applies graph expansion from source object os to an instance covering the target object ot . Each measure has its own pros and cons . To make the best of both measures and combine them in a unified framework , we propose a variant of SCSE , named Biased Structure Constrained Subgraph Expansion ( BSCSE ) , defined as follows .
DEFINITION 8 . Biased Structure Constrained Subgraph Expansion(BSCSE ) . Given an HIN G = ( V , E ) , a meta structure S , a source object os ∈ V and a target object ot ∈ V , the BSCSE of a i th layer subgraph g ⊆ G is defined recursively as follows :
BSCSE(g , i + 1 | S , ot ) g∈σ(g,i | S,G )
BSCSE(g , i | S , ot ) = , where for the base case , ie , i = dS , we have BSCSE(g , dS | S , ot ) = 1 if and only if there exists a mapping function hg for g such that hg(ot ) = nt . We are interested in BSCSE(os , 1 | S , ot ) .
| σ(g , i | S , G ) |α
Note that α ∈ [ 0 , 1 ] is a bias factor to balance the weight between StructCount and SCSE : ( 1 ) a smaller α cares more about the number of subgraphs that match the meta structure ( if α = 0 , BSCSE reduces to StructCount ) ; ( 2 ) a larger α focuses more on the possibility that a random expansion can cover the target object ( if α = 1 , BSCSE reduces to SCSE ) . On the other hand , as we have combined StructCount and SCSE into a unified BSCSE framework , we can focus on the computation of BSCSE only . 4.4 ETree In this subsection , we analyze the expanding process of BSCSE , and give an explicit expression of the relevance measure f ( os , ot | s ) for BSCSE .
As we can see in Definition 8 , the computation of BSCSE simulates the process of subgraph expansion . If we track the expansion a2a2p2,1a2p2,2a2p2,1v2t2a2v3t3a2p2,1v2t2p2,1p1,2a2p2,1v2t2a2p2,2p2,2v3t3a2p2,1v2t2p2,1a2p1,2a2p2,1v2t2a1a2p2,2p2,2v3t3a21(a)2(a)2(b)3(a)3(b)4(a)4(b)4(c)5(a)5(b)5(c)p2,21598 path from the original source object os to an instance s ∈ S , we can get a recursive tree of subgraph expansion . We define this recursive tree ETree , as follows :
DEFINITION 9 . ETree . Given an HIN G , a meta structure S and a source object os , the structure ETree is denoted as ET ree = ( T , L , w ) , where • T : the tree node set , where each node is a subgraph of G ; • L : the edge set ; • w : a function w(· ) that maps a tree node v ∈ T to its weight w(v ) . The weight is defined based on v ’s parent u , ie , ( u , v ) ∈ L . It considers ( 1 ) u ’s weight w(u ) , and ( 2 ) the #children of u , ie , |{v|(u , v ) ∈ T}| . Specifically , we have w(v ) =
1 |{v|(u,v)∈T}|α w(u ) if v = os , otherwise .
For example , given G in Figure 1 and S in Figure 2(b ) , the ETree that starts from a2 is shown in Figure 4 . We can see that the root is a2 , and each edge links a subgraph to one of its one layer expansion wrt S . For example , a2 can either expand to {a2 , p2,1} or {a2 , p2,2} wrt S , and their weights are both 1/2α . The leaf nodes ( with depth dS ) contain all instances of S starting from a2 .
Next , we analyze two properties of ETree , related to its height ( Property 1 ) and node ( Property 2 ) , which help to express our value of interest , ie , BSCSE(os , 1 | S , ot ) ( Theorem 1 ) .
PROPERTY 1 . The height of ETree is at most dS − 1 . PROOF . The root of ETree is the source object os at the first layer of S . Suppose g1 = os , g2,··· , gS−1 , gk = v is a path from os to a leave nodes v , each step means a one layer expansion of subgraph . We have at most dS − 1 one layer expansions from os to v . Thus , the height of ETree is at most dS − 1 .
PROPERTY 2 . Each node of ETree at depth d is an instance of S[1 : d + 1 ] and each instance s of S[1 : d + 1 ] with hs(os ) = ns must be a node of ETree at depth d . PROOF BY INDUCTION . When d = 0 , the root os is only an instance of S[1 : 1 ] with h(os ) = ns . Suppose Property 2 holds for d = k . Assume that u is a node of ETree at depth k + 1 and its parent node is v . Then , u ∈ σ(v , k + 1 | S , G ) as ( v , u ) ∈ L , so u must be an instance of S[1 : k + 2 ] . On the other hand , ∀s ∈ S[1 : k + 2 ] , s = s − {v ∈ s | hs(v ) ∈ S[k + 2]} must be an instance of S[k + 1 ] , which means s is a one layer expansion of s . So s is a node of ETree at depth k + 1 .
THEOREM 1 . Given a meta structure S = ( N , M , ns , nt ) , a souce object os ∈ V and a target object ot ∈ V ,
BSCSE(os , 1 | S , ot ) =
( 2 ) PROOF . Suppose s is an instance of S and g1 = os , g2 , . . . , gdS = s is the path of ETree from os to s . According to the recursive definition of BSCSE , s∈S , hs(ot)=nt w(s ) . f ( os , ot | s ) =
1
| σ(gi , i | S , G ) |α , if hs(ot ) = nt . to the definition of w , w(s ) = dS−1
According to Properties 1 and 2 , s must be a leaf node at depth dS −1 , and P must be a path of ETree from root os to s . According | σ(gi,i | S,G ) |α , then we i=1
1 dS−1 i=1 can finally derive
BSCSE(os , 1 | S , ot ) =
Based on the proof of Theorem 1 , we know that the relevance measure f ( os , ot | s ) for BSCSE is : f ( os , ot | s ) = w(s ) 0 if hs(ot ) = nt , otherwise .
Take the HIN in Figure 1 for example , we show the relevance values for two pairs of authors with our three measures in Table 1 . We can see that our three meta structure relevance measures can better handle complex relationship , ie , the relevance score of ( a2 , a1 ) is larger than ( a2 , a3 ) . This is because the meta structure can make use of the information of common nodes in different meta paths .
5 . COMPUTING BSCSE
As we know , BSCSE is a generalization of StructCount and SCSE . Thus in this section , we study how to efficiently perform relevance search with BSCSE ( also works for StructCount and SCSE ) wrt a source object os , based on a given S . We first propose a traversal algorithm on ETree ( Section 5.1 ) , and then further improve its efficiency by proposing two optimizations ( Section 52 ) 5.1 Traversal Algorithm
In order to calculate BSCSE(os , 1 S , G ) , an initial idea is to visit all the leaf nodes of ETree and accumulate the weights of all s ∈ S for which hs(ot ) = nt . Based on this , we develop a recursive algorithm , called Traversal ( Algorithm 1 ) to compute BSCSE . It first checks whether the base case is caught , ie , if g is already an instance of S . In this case , the instance g with its weight w are returned ( steps 1 2 ) . The rest of the algorithm consists of two phases . The first phase ( steps 3 11 ) calculates the set σ(g , layer | S , G ) and the second phase ( steps 12 17 ) recursively calls the algorithm for each g ∈ σ(g , layer | S , G ) and accumulates the results . In the first phase , for each node n at the ( i + 1) th layer of S , we consider all nodes n such that ( n , n ) ∈ M , check its instance object g[n ] and calculate possible instance objects wrt node n ( steps 6 8 ) . Then , we calculate the instance objects wrt n that satisfy all the dependency constrains ( step 9 ) . Finally , we compute the Cartesian product over the possible instances of each node at layer ( i + 1 ) , and derive the set of possible expansions σ ( step 11 ) . In the second phase , we first record the weight w for layer ( i + 1 ) according to Definition 9 ( step 12 ) . Then , for each possible expansion , we expand the subgraph g to g ( step 15 ) and recursively call the algorithm on the expanded subgraph g to get all instances of S and their corresponding weights ( step 16 ) . For example , suppose we are traversing the ETree in Figure 4 based on the meta structure S in Figure 2(b ) . We set layer as 3 and g as the graph in 3(b ) . In the first phase , there is only one meta node n at the 4th layer , ie , n = P2 , and n depends on two nodes , ie , V and T . Then , we can see that g[V ] = v3 , and it has two neighbors p2,2 and p3,2 ; g[T ] = t3 , and it has two neighbors p2,2 and p3,1 . {p2,2} , which means that there is only one possible instance object for P2 . At the second phase , we have w = w because there is only one possible expansion . We then compute the expanded subgraph g = g ∪ {p2,2} , and recursive call T raversal(G,S , g , w , 4 ) . 5.2 Optimizations
We get C = {{p2,2 , p3,2},{p2,2 , p3,1}} , and Ins[P2 ] = ( cid:84 ) C = s∈S , hs(ot)=nt w(s ) .
We propose two optimizations on the traversal algorithm to boost the efficiency . First , we devise a compressed representation of ETree to reduce the redundancy . Then , we propose an index structure to further accelerate the process of online query .
1599 Algorithm 1 : Traversal Algorithm Input : HIN G , meta structure S , subgraph g , weight w and layer id . Output : all possible instances of S and their weights . return {< g , w >} ;
1 if layer == dS then 2 3 Initialize Ins[· ] ; 4 for n ∈ S[layer + 1 ] do C ← ∅ ; 5 for ( n , n ) ∈ M do 6 F ← {v | ψ(g[n ] , v ) = ( n , n)} ; 7 C ← C ∪ {F} ; 8
E ←(cid:84 ) C ;
9 10 n∈Ins Ins[n ] ;
Ins[n ] ← E ;
11 σ ← 12 w = w|σ|α ; 13 rtn ← ∅ ; 14 for combination ∈ σ do 15 16 17 18 return rtn ; g ← g ∪ combination ; I ← T raversal(G , S , g , w , layer + 1 ) ; rtn ← rtn ∪ I ;
Table 2 : 3 LTable . key
<v1 , t1> <v2 , t2> <v3 , t3> <v3 , t4> <v4 , t3> value
<a1 , 1.0> <a1 , 0.5> <a2 , 0.5> <a2 , 1.0> <a3 , 1.0> <a3 , 1.0>
Figure 5 : A Compressed ETree .
Compressed ETree According to Property 2 , at an internal node v of ETree with depth d , we need to maintain an instance of S[1 : d + 1 ] . However , to further expand v , we do not necessarily need the information of the whole instance . Instead , we just need to maintain a subset of v on which the layers of S after d have dependencies . For example , in graph 2(a ) ( Figure 4 ) , we do not need to maintain the whole graph ; instead , {p2,1} is enough to represent it as the rest of meta structure only depends on node P1 .
Based on this idea , we develop a compressed structure , called Compressed ETree , which is shown in Figure 5 . We can see that it is more concise compared to ETree ( Figure 4 ) . Thus by traversing Compressed ETree instead of ETree , we can reduce the computation cost and required space for each tree node .
To derive the Compressed ETree , intuitively we have to precompute and maintain the necessary nodes for each layer of meta structure , which we call the dependency set . We use a map structure to store the nodes that need to be maintained at each layer . The details are shown in Algorithm 2 . Specially , for each node n in S , we first get the maximal layer that the node can reach , ie , depending on n ( step 3 ) . Then we add n to the corresponding layers of D ( steps 4 5 ) . After all nodes have been added to D , we can get the set of nodes we need to maintain at layer i in D[i ] . Take S in Figure 2(b ) as an example ; the dependency set D[i ] for i = 1 to 5 is {A1} , {P1} , {V , T} , {P2} and {A2} , respectively.1 By considering the dependency set D[∗ ] , we can improve the performance by traversing Compressed ETree instead of ETree . The algorithm is slightly different from Algorithm 1 . At step 16 , instead 1Note that D[i ] is not necessarily equal to S[i ] , as we do not require that each edge must point to the node in the next layer . maintain in Compressed ETree at layer i .
Algorithm 2 : Pre compute Dependencies Input : meta structure S . Output : D[∗ ] , where D[i ] is a set of nodes we need to 1 Initialize D[i ] = ∅ for i = 1 , 2 , . . . , dS ; 2 for n ∈ N do 3 4 5 d ← max(n,n)∈M layer(n ) ; for i = layer(n ) to d do D[i ] = D[i ] ∪ {n} ;
6 return D ; of calling it recursively on a whole subgraph g , we can just maintain a subset of g which is in the dependency set D[layer + 1 ] . i LTable Compressed ETree can reduce the computation for each node of ETree , but it still has the same number of tree nodes . Especially there is much redundancy in the computation if we have a batch of queries to answer . For example , when computing BSCSE for two source objects a2 and a1 in Figure 1 , we have to traverse two Compressed ETrees for a2 and a1 , respectively . When traversing one for a2 ( Figure 5 ) , we visit a sub tree with 3(a ) as root ; meanwhile , we would visit the same sub tree while traversing the other Compressed ETree for a1 . This is because the last two layers of the meta structure S[4 , 5 ] only depend on S[3 ] ( instead of S[1 , 3] ) . By considering this idea , we propose a novel data structure called i LTable , which stores all leaf nodes for a sub tree of the CompressedETree in advance . Once we traverse to the i th layer , we can get the information of leaf nodes directly from the i LTable , which saves the search time from the ( i + 1) th to the last layer . Given an S , the i LTable wrt layer i is a data structure that maps each node instance v of Compressed ETree at layer i to all the node instances in the last layer ( with v as an ancestor ) . To be specific , the keys of i LTable are the instances of the stored nodes in D[i ] , and the values are the distributions of weights over all possible target objects . Given S in Figure 2(b ) , consider the Compressed ETree in Figure 5 , the corresponding 3 LTable is shown in Table 2 . For example , as D[3 ] = {V , T} , and the target node nt = A2 , the keys of 3 LTable are pairs of venues and topics and the values are distributions of weights on authors . Next we study how to build an i LTable for a given meta structure S offline . First , we address the selection of i , ie , which layer the i LTable should be built on , and then we deal with how to build indexes offline and conduct queries online . Choosing An Appropriate i . If we have built i LTable on the ith layer , then we only need to search the Compressed ETree for the top i layers . Intuitively the choice of i is a trade off between time and space . For a smaller i , the number of nodes that needs to be visited is smaller , resulting in efficient processing . However , the number of reachable target objects is large , resulting in larger space requirement . We next list three heuristic methods on how to select i : ( 1 ) MinKey : choose i with minimal number of possible 2 · dS ; ( 3 ) Min : choose a minimal key values ; ( 2 ) Half : choose i = 1 i with space budget constraint . Building Indexes Offline . After choosing an i , we can start to build the i LTable , and the details are shown in Algorithm 3 . After retrieving the nodes in D[i ] , we can construct i LTable by traversing the sub trees of Compressed ETree for each possible key . Online Query Processing . Once we have built i LTable , we can speed up the process of online query . The algorithm is similar to a2p2,1p2,2v2t2v3t3p2,1p1,2p2,21(a)2(a)2(b)3(a)4(a)3(b)4(b)4(c)a2a2a15(a)5(b)5(c)1600 Algorithm 3 : Building i LTable Input : HIN G , meta structure S , dependency set D , layer i . Output : i LTable for S . 1 initialize i LTable ;
2 for key ∈ n∈D[i]{v ∈ V | φ(v ) = n} do i LTable[ key ] ← Traversal(G,S , key , 1.0 , i ) ;
3 4 return i LTable ;
( a ) YAGO
( b ) DBLP
Figure 6 : Meta Paths and Meta Structures Used in Experiments .
Algorithm 1 , except that it only needs to traverse the CompressedETree for the top i layers . Then the results can be retrieved directly from i LTable instead of recursively searching the sub trees .
6 . EXPERIMENTS
We now discuss the experiment results . Section 6.1 describes the experiment setup . We then examine the effectiveness ( Section 6.2 ) and efficiency ( Section 6.3 ) of different relevance measures . 6.1 Setup
We examine two HIN datasets , namely YAGO and DBLP .
YAGO [ 15 ] is a large scale knowledge graph derived from Wikipedia , WordNet and GeoNames . We use its “ CORE Facts ” , ie , YAGOCore [ 12 ] , which consists of 4 million facts ( edges ) of 125 types , made from 2.1 million objects . These entities have 365,000 types . DBLP is a bibliographic network . It contains four types of objects , ie , paper , author , venue and topic . We use a subset of DBLP , ie , DBLP 4 Area [ 12 ] , containing 5,237 papers , 5,915 authors , 18 venues , and 4,479 topics from 4 areas : database , data mining , machine learning and information retrieval . These objects are connected by 51,377 edges .
We compare our relevance metrics ( ie , StructCount , SCSE , and BSCSE ) with three representative meta path measures ( ie , PathCount [ 18 ] , PCRW [ 7 ] , and PathSim [ 18] ) . These measures employ the meta paths and structures shown in Figure 6 . We implement the experiments in C++ on an 8GB memory Mac OS X machine . 6.2 Effectiveness
We compare the quality of relevance measures in three applications : entity resolution ( Section 621 ) , ranking ( Section 622 ) and clustering ( Section 623 ) We then study the properties of meta structures in Section 624 and Section 625
621 Entity Resolution We first perform an entity resolution ( ER ) task to find pairs of objects in YAGO that refer to the same entity . For example , the two objects Barack_Obama and Presidency_Of_Barack_Obama refer to the same person . Identifying such pairs helps to “ clean ” an HIN by deduplicating its entries .
We manually label a small subset of data . We look for ( human ) object pairs that both have marriage relationship to an object . In total , we get 3020 such pairs , containing 4518 different persons . We consider these as our test data , and manually label their ground truth . We got 44 positive samples ( ie , each object pair refers to the same person ) , while the remaining 2976 ones are negative . We use the meta structure S and two meta paths ( P1 , P2 ) in Figure 6(a ) to compute the relevance . For each person ( out of 4518 ones ) , we set it as the source object in S , P1 , P2 , and use them to find target objects , which can be duplicates . Then , we get all the ( target ) persons such that the relevance value with respect to the source object is larger than zero . The larger the relevance , the more likely the object pairs refer to the same person . For each relevance measure , we vary the threshold for the relevance values of all returned pairs and plot the Precision Recall Curve . We then compute the the area under the curve , ie , AUC .
The AUC values for different metrics are shown in Table 3 . Observe that meta structure based measures are more effective than the meta path ones . This is because S is more expressive than a single meta path ( ie , ( P1 or P2 ) . Here , S limits the results to those persons who are married to the same person and affiliated to the same organization , which cannot be represented by P1 or P2 alone . We then study the effectiveness of the linear combination of the two meta paths . The relevance is computed as s = β · s1 + ( 1 − β ) · s2 , where s1 and s2 is the relevance derived by P1 and P2 respectively . As shown in Figure 7(a ) , a linear combination of two meta paths is better than using P1 or P2 alone . However , as it does not consider the common nodes in the meta paths ( ie , nodes P1 and P2 ) , its AUC value , based on the the optimal β , is just 0.2920 , and is still worse than SCSE ( ie , 0.5640 ) ( Table 3 ) .
We also examine how parameter α influences the effectiveness of BSCSE . As shown in Figure 7(b ) , its AUC is stable for a wide range of α values . When α = 1 , BSCSE has the best result . This is consistent with our expectation , because entity resolution favors highly relevant objects , instead of popular ones .
We next show the top 10 relevant pairs for PCRW and SCSE in Table 4 ( for PCRW , we use a linear combination with optimal β , achieving the best AUC value ) . The pairs in bold are negative samples . We see that PCRW has three negative samples in the top10 pairs . For example , the reason that Sally Hayfron and Grace Mugabe appear in the result is that they have been married to the same person , and as the weight for the meta path P1 dominates the other ( P2 ) , this pair has a high score even though these two persons do not satisfy P2 . This explains why meta path based measures have lower AUC values than meta structure based ones .
622 Ranking Quality In our second effectiveness experiment , we perform a task of relevance ranking as follows . We first label the relevance of each pair of venues in DBLP using three levels : 0 for ‘non relevant’ , 1 for ‘somewhat relevant’ and 2 for ‘very relevant’ . We consider both the level and the scope of the venues while labeling . For example , the relevance score for SIGMOD and VLDB is 2 as they are highly relevant . We use the meta structure S and the two meta paths P1 , P2 shown in Figure 6(b ) . Then , we evaluate the quality of the returned ranked list wrt different measures using Normalized Discounted Cumulative Gain ( nDCG ) , which is a commonly used measure in ranking quality , and the larger , the better . The results are shown in Table 3 . We can observe that the first meta path P1 = V P AP V yields better results than the second meta path P2 = V P T P V on all the three meta path based measures . However , meta structure based measures perform better than meta path based measures on the whole .
PP1P2OP1P2PP1P2OP1P2S:::marrymarrymarry−1marry−1AffliatedToAffliatedToAffliatedTo−1AffliatedTo−1mention−1publishApublish−1write 1P1P2TP1P2mentionAP1P2Tmentionmention−1P1P2S:::V1V1V1V2V2V2writepublish−1publishpublishwrite 1writepublish−11601 Table 3 : Qualities on Three Experiments : Entity Resolution ER ( Section 621 ) , Ranking ( Section 622 ) , and Clustering ( Section 623 )
Experiment Metric
ER
Ranking
Clustering
AUC nDCG NMI Purity
PathCount
0.1324 0.9004 0.4932 2.75
P1 PCRW PathSim PathCount 0.0120 0.9047 0.6866 3.50
0.0003 0.8224 0.3595 2.50
0.0097 0.9083 0.6780 3.00
P2 PCRW PathSim PathCount 0.0014 0.8901 0.6866 3.50
0.2898 0.9004 0.4932 2.75
0.0002 0.8834 0.5157 2.75
Linear Combination ( Optimal β )
S ( BSCSE∗ : Optimal α )
PCRW PathSim StructCount 0.2606 0.9100 0.6866
0.2920 0.9083 0.6780
0.5556 0.9056 0.3202 2.25
3.5
3.5
SCSE 0.5640 0.9104 0.8065 3.50
BSCSE∗ 0.5640 0.9130 0.8065 3.50
( a ) Varying β ( Meta Path Measures )
( b ) Varying α ( BSCSE )
( a ) Varying β ( Meta Path Measures )
( b ) Varying α ( BSCSE )
Figure 7 : Varying Parameters on Different Measures ( Entity Resolution ) .
Figure 8 : Varying Parameters on Different Measures ( Ranking ) .
( a ) Varying β ( Meta Path Measures )
( b ) Varying α ( BSCSE )
( c ) Varying β ( Meta Path Measures )
( d ) Varying α ( BSCSE )
Figure 9 : Varying Parameters on Different Measures ( Clustering ) , with Metrics NMI ( a)(b ) and Purity ( c)(d ) .
Table 4 : Top 10 Relevant Pairs in YAGO .
Rank
1 2 3 4 5 6 7 8 9 10
PCRW
Presidency of Corazon Aquino , Corazon Aquino Corazon Aquino , Presidency of Corazon Aquino
Sally Ponce Enrile , Salvacion Sally Santiago Ponce Enril
Presidency of Cristina Fernandez de Kirchner , Cristina Fernandez de Kirchner
Sally Hayfron , Grace Mugabe Edu Manzano , Ralph Recto
Gloria Macapagal Arroyo , Presidency of Gloria Macapagal Arroyo
Presidency of Fidel V . Ramos , Fidel V . Ramos
Presidency of Gloria Macapagal Arroyo , Gloria Macapagal Arroyo
Marguerite of Lorraine , Marie de Bourbon
SCSE
Ronald Reagan , Presidency of Ronald Reagan
Rudy Giuliani , Political positions of Rudy Giuliani Political positions of Rudy Giuliani , Rudy Giuliani Presidency of Corazon Aquino , Corazon Aquino Presidency of Nestor Kirchner , Nestor Kirchner Presidency of C . F . de Kirchner , C . F . de Kirchner
Presidency of Ronald Reagan , Ronald Reagan
Rise of Neville Chamberlain , Neville Chamberlain Outerbridge Horsey ( senator ) , Outerbridge Horsey
Vice Presidency of Al Gore , Al Gore
We also compare with a linear combination of the two meta paths . We vary the weight β ∈ [ 0 , 1 ] to trade off P1 , P2 , and record the nDCG values of the ranking results . The results are shown in Figure 8(a ) . Among meta path based measures , PCRW performs better than PathCount and PathSim . We can see that the quality gets better as β increases . This means that the linear combination of two meta paths cannot get better results than P1 itself . We further study how parameter α influences the ranking quality of BSCSE . We vary α ∈ [ 0 , 1 ] and observe the quality of returned ranked list . As shown in Figure 8(b ) , BSCSE achieves the best nDVG value when α = 08 In Table 3 we see BSCSE with optimal α ( 0.8 ) outperforms the linear combination of meta paths . 623 Clustering Quality Similar to the experiment above , given the same meta structure and meta paths in Figure 6(b ) , in order to further evaluate the qual ity of relevance values between venues , we perform a task of clustering the venues in DBLP . To be specific , we apply K means on the derived relevance matrixes wrt different measures . We use two evaluation metrics , Normalized Mutual Information ( NMI ) and Purity ( both the larger , the better ) . The results are shown in Table 3 . We can see that SCSE has the best performance over all measures . We further compare with a linear combination of these two meta paths . We vary the weight β ∈ [ 0 , 1 ] to trade off P1 , P2 , and record the clustering accuracy . The results are shown in Figures 9(a)(c ) . It can be seen that PCRW performs better than PathCount and PathSim , and its performance does not vary much with β . Again , from Table 3 we observe that a linear combination of two meta paths cannot get better results than P1 itself . No matter what weight we give , the clustering accuracy of meta path based measures is no better than SCSE .
000204060810 0 0.2 0.4 0.6 0.8 1AUCβPathCountPCRWPathSim050052054056058060 0 0.2 0.4 0.6 0.8 1AUCαBSCSE075080085090095100 0 0.2 0.4 0.6 0.8 1nDCGβPathCountPCRWPathSim09000905091009150920 0 0.2 0.4 0.6 0.8 1nDCGαBSCSE000204060810 0 0.2 0.4 0.6 0.8 1NMIβPathCountPCRWPathSim000204060810 0 0.2 0.4 0.6 0.8 1NMIαBSCSE0010203040 0 0.2 0.4 0.6 0.8 1PurityβPathCountPCRWPathSim0010203040 0 0.2 0.4 0.6 0.8 1PurityαBSCSE1602 Figure 10 : Meta Structures with Different Semantic Meaning .
Table 5 : Top 5 Relevant Actors to Clint Eastwood with Different S .
S1
Clint Eastwood Sondra Locke Gene Hackman Laura Linney
Marcia Gay Harden
S2
Clint Eastwood Sondra Locke Meryl Streep Jessica Walter John Larch
S3
Clint Eastwood Matt Damon
Chief Dan George Cecile de France Sondra Locke
S4
Clint Eastwood Shirley MacLaine
Robert Duvall Richard Burton
Fred Ward
We also study how α influences BSCSE in the task of clustering . The results are shown in Figures 9(b)(d ) . We can see that the clustering accuracy gets better with a larger α . When α = 1 , we have the best clustering accuracy .
We observe that in different tasks ( eg , ranking and clustering ) , BSCSE achieves the best performance at different values of α . This leads to the question of how to set α . We can set α = 1 for simplicity as SCSE ( ie , α = 1 ) has pretty good performances over all the tasks we perform . On the other hand , α can be set as a user input , or can be tuned with training data in the experiments . 624 Semantics of Meta Structures Different meta structures imply different meanings . We perform a case study on YAGO to show that , with different meta structures , we can find totally different top k results wrt different relations . Specifically , we query a famous actor and director Clint Eastwood in YAGO with four different meta structures in Figure 10 to find top 5 relevant actors to him .
We make some analysis based on the observations of the top 5 results in Table 5 : ( 1 ) Sondra Locke ranks very high in the results of S1 and S2 , but has low relevance in the results of S3 and S4 . This is because S1 and S2 are shorter , and they tend to find out actors who directly collaborated with Eastwood , eg , Sondra Locke . On the other hand , S3 and S4 are longer , so they tend to find out famous actors like Matt Damon and Shirley MacLaine . ( 2 ) Matt Damon ranks high with S3 because he collaborated a lot with the actors and creators who had participated in the films directed by Eastwood . ( 3 ) Similarly , Shirley MacLaine ranks high with S4 because he collaborated a lot with the directors and creators who had participated in the films Eastwood acted in . We can conclude that , with different meta structure , the top 5 results are different . Although S1 and S2 have the same length , S1 and S2 are different as S2 only consider those films with Eastwood being the director and actor at the same time , while S1 has looser constraint . Although S3 and S4 both have dS = 5 , S3 only considers those films he directs and S4 only considers those films that he acts in . We want to show that , as meta structure is more complex than meta path , a user can use meta structures with subtle differences to express different relevances . 625 Effect of Meta Structure Sizes We study the impact of different sizes of a meta structure . Especially , we study whether the following hold : does larger size ( ie , dS ) leads to better quality for a meta structure ?
To test the effectiveness of different sizes , we use concatena
Table 6 : Influence of dS on Ranking Quality .
Measure
S nDCG
0.9055
StructCount
S2 0.7767
S4 0.7332
S
0.9104
SCSE
S2 0.8026
S4 0.7933 tions of the meta structure S in Figure 6(b ) , ie , S , S 2 and S 4 . Intuitively , with S , two venues are relevant if they share the same authors and the same topics . However , with S 2 and S 4 , the relevance becomes more subtle as the meta structures involve remote objects . When the size tends to infinity ( ∞ ) , the top k results tend to be the global result . We also compare the ranking quality ( ie , nDCG ) similar to Section 622 It is shown in Table 6 that a meta structure with larger size gives worse ranking result . 6.3 Efficiency
We perform two experiments to study the efficiency of the algorithm and two optimization techniques proposed in Section 5 . For ease of presentation , we denote as follows : • Traversal+ : the Traversal algorithm with Compressed ETree optimization ( without index ) ; • Traversal++ : the Traversal+ with index built on it .
In this section , we first compare the executing time of Traversal , and Traversal+ with meta path measures . Then , we study the impact of different indexes ( ie , i ) in Traversal++ .
631 Comparison with Meta Path Measures We start by comparing the runtime of BSCSE with that of meta path measures . On DBLP , we ran 18 queries using the meta structure and meta paths in Figure 6(b ) , setting source objects as different venues . In addition , we ran 1000 queries starting from randomly selected authors using the meta structure and meta paths in Figure 2(b ) . On YAGO , we ran queries over 1000 randomly selected persons based on the meta structure and meta paths in Figure 6(a ) . We record the average executing time of each bundle of queries as shown in Table 7 . We can see that meta path based measures have different runtime performances for different meta paths . For example , a P2 query for venues takes 20 times more than a P1 query for all the three meta path based measures . Observe that BSCSE is not worse than meta path based measures in terms of efficiency . In addition , the Compressed ETree optimization can slightly boost the efficiency as it can reduce the redundancy in the representation .
To further explain this phenomenon , we analyze the average number of instances by the different meta structures and meta paths . As shown in Table 8 , the number of instances is proportional to the executing time . We can also see that the number of instances of meta structures are small because they are more restrictive compared to meta paths .
632 Effect of i LTable We show the time for building the i LTable offline for different values of i in Figure 11(a ) . We can see that , as i increases , the time for building the i LTable decreases . Particularly , if we select i = 1
2 dS = 3 , we need 10s for building i LTable .
Figure 11(b ) shows the time for online queries using the i LTable for different values of i ( i = 5 means we do not use i LTable as dS = 5 ) . We can see that an i LTable greatly reduces the cost of online queries . Particularly , if we select i = 1 2 dS = 3 , the Traversal++ algorithm needs only 0.5ms compared to 2.45ms required by Traversal+ .
SSSS1234directdirectdirectdirectcreatecreateactInactInactInactIn−1actIn−1actIn−1actIn−1actIn−1actInactIn−1create−1create−1MMMMMP1P1P1P1P2P2P2P2P3P3P4P4M1M2direct−11603 S ( time unit ) venue ( s ) author ( 10−2s ) person ( 10−3s )
PathCount
0.055 3.06 2.533
Table 7 : Execution Time for Different Measures . P1 PCRW PathSim PathCount 0.065 2.88 2.454
P2 PCRW PathSim Traversal 1.181 1.70 7086
0.528 2.54 3.629
1.188 1.71 7426
0.054 2.95 2.163
1.187 1.80 7106
S
Traversal+
0.516 2.45 3.629
Table 8 : Number of Instances . S
P2
118893.2 3602.3 3610.3
7254.8 766.6 1.259
P1 5150.7 5949.0 1.615 venue author person
[ 5 ] N . Jayaram , M . Gupta , A . Khan , C . Li , X . Yan , and
R . Elmasri . Gqbe : Querying knowledge graphs by example entity tuples . In ICDE , pages 1250–1253 . IEEE , 2014 .
[ 6 ] G . Jeh and J . Widom . SimRank : a measure of structural context similarity . In KDD , pages 538–543 , 2002 .
[ 7 ] N . Lao and W . W . Cohen . Relational retrieval using a combination of path constrained random walks . Machine learning , 81(1):53–67 , 2010 .
[ 8 ] M . Ley . Dblp computer science bibliography . 2005 . [ 9 ] D . Liben Nowell and J . Kleinberg . The link prediction problem for social networks . J . Assoc . Inf . Sci . Technol . , 58(7 ) , 2007 .
[ 10 ] X . Liu , Y . Yu , C . Guo , and Y . Sun . Meta path based ranking with pseudo relevance feedback on heterogeneous graph for citation recommendation . In CIKM , pages 121–130 , 2014 . [ 11 ] X . Liu , Y . Yu , C . Guo , Y . Sun , and L . Gao . Full text based context rich heterogeneous network mining approach for citation recommendation . In JCDL , pages 361–370 , 2014 . [ 12 ] C . Meng , R . Cheng , S . Maniu , P . Senellart , and W . Zhang . Discovering meta paths in large heterogeneous information networks . In WWW , pages 754–764 , 2015 .
[ 13 ] D . Mottin , M . Lissandrini , Y . Velegrakis , and T . Palpanas . Exemplar queries : Give me an example of what you need . PVLDB , 7(5):365–376 , 2014 .
[ 14 ] E . Prud’Hommeaux , A . Seaborne , et al . Sparql query language for rdf . W3C recommendation , 15 , 2008 .
[ 15 ] F . M . Suchanek , G . Kasneci , and G . Weikum . Yago : a core of semantic knowledge . In WWW , pages 697–706 , 2007 . [ 16 ] Y . Sun , R . Barber , M . Gupta , C . C . Aggarwal , and J . Han .
Co author relationship prediction in heterogeneous bibliographic networks . In ASONAM , pages 121–128 , 2011 .
[ 17 ] Y . Sun , J . Han , C . C . Aggarwal , and N . V . Chawla . When will it happen ? : relationship prediction in heterogeneous information networks . In WSDM , pages 663–672 , 2012 .
[ 18 ] Y . Sun , J . Han , X . Yan , P . S . Yu , and T . Wu . Pathsim : Meta path based top k similarity search in heterogeneous information networks . In PVLDB , pages 992–1003 , 2011 .
[ 19 ] Y . Sun , B . Norick , J . Han , X . Yan , P . S . Yu , and X . Yu .
Pathselclus : Integrating meta path selection with user guided object clustering in heterogeneous information networks . TKDD , 7(3):11 , 2013 .
[ 20 ] Y . Yang , N . Chawla , Y . Sun , and J . Hani . Predicting links in multi relational and heterogeneous networks . In ICDM , pages 755–764 , 2012 .
[ 21 ] X . Yu , X . Ren , Y . Sun , Q . Gu , B . Sturt , U . Khandelwal ,
B . Norick , and J . Han . Personalized entity recommendation : A heterogeneous information network approach . In WSDM , pages 283–292 , 2014 .
[ 22 ] X . Yu , X . Ren , Y . Sun , B . Sturt , U . Khandelwal , Q . Gu ,
B . Norick , and J . Han . Recommendation in heterogeneous information networks with implicit user feedback . In RecSys , pages 347–350 , 2013 .
( a ) Build Time with i
( b ) Execution Time with i
Figure 11 : Influence of i on Build and Execution Time .
7 . CONCLUSIONS AND FUTURE WORK In this paper , we introduce a notion of meta structure , which is a powerful extension of meta path . Based on meta structure , we introduce a relevance framework on heterogeneous information networks , which can express complex relevance of two objects . In particular , we define two relevance measures under this framework , ie , StructCount and SCSE . SCSE simulates the process of subgraph expansion , and it can reduce the bias to highly visible objects . Moreover , we define a unified measure named BSCSE , which combines StructCount and SCSE into the same framework . For efficiently computing BSCSE , we propose a recursive algorithm along with two optimizations ( Compressed ETree and i LTable ) to boost the efficiency . Experiments on real datasets demonstrate the effectiveness and efficiency of our methods .
In the future , we will examine methods for automatically learning meta structures from the knowledge base . We will also study the use of meta structure in different applications , such as citation recommendation and paper reviewer assignment .
Acknowledgments We would like to thank the reviewers for their invaluable comments . Reynold Cheng , Zhipeng Huang , and Yudian Zheng were supported by the Research Grant Council of Hong Kong ( RGC GRF project 17205115 ) , Nikos Mamoulis was supported by RGC GRF project 715413E , and Yizhou Sun was supported by NSF CAREER 1453800 , Northeastern TIER 1 , and Yahoo! ACE Award .
8 . REFERENCES [ 1 ] S . Auer , C . Bizer , G . Kobilarov , J . Lehmann , R . Cyganiak , and Z . Ives . Dbpedia : a nucleus for a web of open data . In ISWC , pages 722–735 . Springer Verlag , 2007 .
[ 2 ] K . Bollacker , C . Evans , P . Paritosh , T . Sturge , and J . Taylor .
Freebase : a collaboratively created graph database for structuring human knowledge . In SIGMOD , pages 1247–1250 , 2008 .
[ 3 ] S . Chakrabarti . Dynamic personalized pagerank in entity relation graphs . In WWW , pages 571–580 , 2007 .
[ 4 ] J . Chen , W . Dai , Y . Sun , and J . Dy . Clustering and ranking in heterogeneous information networks via gamma poisson model . NTm , 1000:1 .
00100200300400 1 2 3 4 5Build Time ( s)i00102030 1 2 3 4 5Execution Time ( ms)i1604
