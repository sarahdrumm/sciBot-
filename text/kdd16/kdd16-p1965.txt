Diversified Temporal Subgraph Pattern Mining
Yi Yang1,2 , Da Yan2 , Huanhuan Wu2 , James Cheng2 , Shuigeng Zhou1 , John CS Lui2
1School of Computer Science and Shanghai Key Lab of Intelligent Information Processing
1Fudan University
1{yyang1,sgzhou}@fudaneducn
2Department of Computer Science and Engineering , The Chinese University of Hong Kong
2{yyang,yanda,hhwu,jcheng,cslui}@csecuhkeduhk
ABSTRACT Many graphs in real world applications , such as telecommunications networks , social interaction graphs and co authorship graphs , contain temporal information . However , existing graph mining algorithms fail to exploit these temporal information and the resulting subgraph patterns do not contain any temporal attribute . In this paper , we study the problem of mining a set of diversified temporal subgraph patterns from a temporal graph , where each subgraph is associated with the time interval that the pattern spans . This problem motivates important applications such as finding social trends in social networks , or detecting temporal hotspots in telecommunications networks . We propose a divide and conquer algorithm along with effective pruning techniques , and our approach runs 2 to 3 orders of magnitude faster than a baseline algorithm and obtains high quality temporal subgraph patterns in real temporal graphs .
1 .
INTRODUCTION
Many graphs in real world applications contain temporal information . For example , telecommunication companies record huge amounts of phone call and SMS records every day , where each phone call or SMS record contains attributes about the sender , the recipient , and the time when the phone call was made or the SMS was transmitted . As another example , online social networking companies keep logs about the interactions between users and the time when each interaction occurred . However , most existing graph mining algorithms do not consider temporal information in a graph , and thus fail to exploit those temporal attributes for detecting important temporal patterns such as social trends , temporal communication hotspots , and evolving social structures .
In this paper , we study the mining of subgraph structures with temporal information . Specifically , we define the concept of temporal subgraph pattern , which consists of a set of vertices S and a time interval I = [ ts , te ] , indicating that all the vertices in S closely interact with each other during the period of time from ts to te . Mining diversified temporal subgraph patterns motivates numerous new applications , two of which are introduced below . Evolving Social Groups . In an online social network , people join and leave social groups from time to time . For example , during the period of FIFA World Cup , soccer fans will actively discuss events on FIFA World Cup in an online forum . When the World Cup competition ends , they may interact more actively with other groups of people , eg , to discuss projects with classmates towards the end of a semester . Such interesting social groups can be detected by mining temporal subgraph patterns from a temporal graph constructed from the interaction records of an online forum . Moreover , the detected social activities contain temporal information , which may help social media companies to recommend new apps and products to their users before a similar event happens in the future . Temporal Hotspots . In a telecommunication company , each connection between two users is recorded along with the time of the connection . By mining temporal subgraph patterns from a temporal graph extracted from user connections , the telecommunication company can detect communication hotspots in different time periods , and allocate more resources to hotspot regions in their peak time periods to improve services . The company may also use the information of hotspot for marketing or promotion activities .
In fact , temporal clustering has been extensively studied in the spatial setting [ 5 , 11 , 13 , 18 ] , which detects clusters of people or animals that move together for a reasonably long period of time . This work studies the problem in the context of a temporal graph , where the distance between two vertices are evaluated on a graph rather than in a geo spatial setting .
Since it is important to find social groups ( or subgraph patterns ) where people closely interact with each other , many definitions of dense subgraph patterns have been proposed , such as k core [ 3 ] , ktruss [ 31 ] , γ dense subgraph [ 9 , 14 ] and γ quasi clique [ 1 ] . Among them , k core and k truss can be efficiently computed , but for a specific value of k , there is only one k core and k truss subgraph for a graph . Thus , they only provide us a global view of the dense parts of a graph , rather than individual dense groups . A better definition is γ dense subgraph or γ quasi clique , which qualifies a subset of vertices to form a social group if each vertex interacts with most of the other vertices in the subset .
This paper follows the definition of γ quasi clique . Since computing γ quasi clique is NP hard [ 25 ] , existing solutions are either fast approximation algorithms [ 35 ] , or exact algorithms with heuristic pruning rules [ 20 ] . Moreover , computing γ quasi cliques becomes much harder in the context of a temporal graph , as the time information makes the problem much more challenging .
The main contributions of this paper are summarized as follows : • To our knowledge , this is the first work that studies the problem of mining dense subgraph patterns in a temporal graph . We formally define the problem of mining top k diversi
1965 fied temporal subgraph patterns , and propose efficient algorithms for the mining task .
• We design several effective pruning rules to remove vertices and time periods that do not belong to any temporal subgraph patterns , which allow us to terminate a useless search earlier . • We propose a heuristic search strategy . Based on the search strategy , a quick search algorithm and a complete search algorithm are proposed . We then compare them with a baseline approach on several real datasets . The experimental results demonstrate that our algorithms obtain high quality mining results , while the quick search algorithm is 2 to 3 orders of magnitude faster than the baseline algorithm .
The rest of this paper is organized as follows . Section 2 defines some notations and the problem . Section 3 introduces the baseline algorithm . Section 4 proposes the framework of our solution , including the mining algorithms . Section 5 proposes some pruning rules for mining dense subgraph patterns in temporal graphs . Section 6 proposes some optimization techniques for our mining algorithms . Section 7 studies the performance of our mining algorithms on real datasets . Section 8 introduces the related works . Finally , Section 9 concludes the paper .
2 . PROBLEM DEFINITION Temporal Graph . In this paper , we consider an undirected temporal graph without self loops . A temporal graph G = ( V , E ) consists of a vertex set V and a temporal edge set E . Each temporal edge e ∈ E has the form ( u , v , I ) , indicating that there is an undirected edge between vertices u and v during the time interval I . Here , I = [ ts , te ] indicates that e appears in G during the time period [ ts , te ] , and we denote the length of I by |I| = te − ts .
A time interval I consists of a set of discrete time points or time snapshots ( eg , I can be a minute consisting of 60 seconds ) . Given a time snapshot t , we define the edge set of G at time t as E(t ) = {(u , v ) | ∃(u , v , I ) ∈ E : t ∈ I} , and define the snapshot graph of G at time t as G(t ) = ( V , E(t) ) . Since the degree of a vertex v in a temporal graph G changes from time to time , we denote the degree of v at time t by dv(t ) . We can view G(t ) , E(t ) and dv(t ) as functions of t , which show how they change over time . Given G = ( V , E ) , a vertex subset V ⊆ V , and a time interval I , we define the temporal subgraph of G induced by V and I as a temporal graph G = ( V , E , I ) , such that for any time snapshot t ∈ I , G(t ) is the subgraph of G(t ) induced by V . Dense Temporal Graph . We define dense temporal graphs based on the definition of γ quasi clique in a non temporal graph [ 1 ] , where 0 ≤ γ ≤ 1 is a user defined density parameter : given a non temporal graph G = ( V , E ) , if dv ≥ γ · ( |V | − 1 ) for all v ∈ V , then G is a γ quasi clique . When γ = 1 , G is a clique .
Now we need to incorporate temporal information into the above Given a temporal graph G = ( V , E ) and a parameter γ , we say definition to define dense temporal graphs as follows . that G is a γ quasi clique during the time interval I iff dv(t ) ≥ γ · ( |V | − 1 )
A temporal subgraph G = ( V , E , I ) is considered γ dense iff holds for all v ∈ V and t ∈ I . G is a γ quasi clique during the time interval I . Temporal Coverage . Given a temporal graph G and its temporal subgraph G = ( V , E , I ) , we define the coverage set of G on G as C(G ) = {(v , t ) | v ∈ V , t ∈ I} , whose size is |C(G)| = |V | · |I| . Consider a set of temporal subgraphs of G , denoted by G = {G1 , G2 , . . . , Gk} , where Gi is induced by a vertex set Vi and a time interval Ii from G . The coverage set of G is the union of the coverage sets of individual subgraphs : k
C(G ) =
C(Gi ) = {(v , t)|∃i , st v ∈ Vi , t ∈ Ii} , i=1 and its size is denoted by |C(G)| . Although a pair ( v , t ) may appear in different coverage sets , ie , ( v , t ) ∈ C(Gi ) , C(Gj ) with i = j , it is counted only once when calculating |C(G)| . Apparently , |C(G)| is larger if ( 1 ) |Vi| , |Ii| are larger , and ( 2 ) Vi , Ii are different from each other for i = 1 , 2 , , k . The Problem . In this paper , we study how to find k dense temporal subgraphs in a temporal graph , such that the k subgraphs are large and diversified ( ie , maximizing the coverage ) . Formally , given a temporal graph G and four parameters γ , k , σ and τ , we want to find a set of γ dense subgraphs G = {G1 , , Gk} induced by Vi and Ii ( i = 1 , 2 , , k ) from G , such that ( 1)|Vi| ≥ σ , ( 2 ) |Ii| ≥ τ , and ( 3 ) |C(G)| is maximized . We call G = {G1 , , Gk} the top k diversified temporal subgraph patterns in G .
EXAMPLE 1 . Assume γ = 0.6 , k = 2 , σ = 4 , τ = 4 , and a temporal graph G shown in Figure 1 . There are two diversified temporal subgraph patterns , G1 = ( V1 , E1 , I1 ) and G2 = ( V2 , E2 , I2 ) , of G , where V1 = {a , b , c , d} , I1 = [ 0 , 4 ] and V2 = {c , d , e , f} , I2 = [ 2 , 6 ] . Since for every vertex v and time snapshot t in G1 , G2 , we have dv(t ) = 2 ≥ 0.6 · ( |4| − 1 ) , G1 , G2 are γ dense , and we have ( 1 ) |V1| = |V2| = 4 ≥ σ , ( 2 ) |I1| = |I2| = 4 ≥ τ , and ( 3 ) |C(G)| is maximized with G = {G1 , G2} . Since C(G1 ) , C(G2 ) overlap on vertices c , d at time t ∈ [ 2 , 4 ] , we have |C(G)| = 2 × ( 4 × 4 ) − 2 × 2 = 28 as Figure 2 illustrates .
Figure 1 : A temporal graph
Figure 2 : The coverage set
3 . THE BASELINE ALGORITHM
A straightforward solution to our problem is to list all qualified subgraph patterns , and find k of them that maximize the coverage . Search Space . Given a temporal graph G and a parameter γ , a naive solution is to check every subgraph induced by any V ⊆ V and any I ⊆ I from G . To do so , we consider the set of discrete time points T = {t1 , t2 , . . .} , where t1 , t2 , . . . are the time points when an edge appears or disappears . If the subgraph induced by V is γ quasi clique at ti , ti+1 , . . . , tj , then it is γ dense throughout time interval [ ti , tj ] . Thus , it suffices to examine every nontemporal subgraph G(t ) induced by any V ⊆ V and any t ∈ T . Therefore , the search space for pattern listing is 2|V | · |T| . Pruning during Subgraph Listing . Some pruning rules have been proposed to reduce the cost of listing quasi cliques in a nontemporal graph [ 20 ] . These pruning rules check whether a subgraph can be further grown to form a larger qualified pattern . In the algorithm of [ 20 ] , a mining task consists of a set S of selected vertices and a set C of candidate vertices . It then selects a vertex v1 ∈ C , and generates two mining tasks : ( 1 ) moving v1 from C to S , and ( 2 ) simply removing v1 from C . These two tasks refer to two cases , ie , a candidate vertex v1 is selected into ( resp . excluded from ) a pattern . Each task can be further expanded by checking another vertex v2 ∈ C in a similar manner . In this way , a mining task is
1966 recursively processed , and meanwhile , the pruning rules may terminate a task from further expansion . Maximizing the Coverage . Selecting k subgraph patterns from all the qualified patterns can be regarded as a maximum set cover problem , which is NP hard . Using the greedy algorithm of [ 23 ] , we can obtain a solution with ( 1 − 1/e ) approximation ratio . This algorithm picks k patterns greedily one by one , where each pattern is selected as the one that maximizes the current coverage . The Baseline Algorithm . The algorithm maintains a set V of vertex sets , where for each vertex set V ∈ V , there exists a time point t ∈ T such that the subgraph of G(t ) induced by V is a γ quasi clique . Initially , V is empty . We first use the algorithm in [ 20 ] to list all γ quasi cliques with at least σ vertices in every graph snapshot G(ti ) ( ∀ti ∈ T ) . For the γ quasi cliques of G(ti ) , let the set of their vertex sets be Vi . We then check Vi one by one from i = 1 to i = |T| , and for each Vi , we use it to update V in two cases . ( 1 ) If a vertex set V ∈ Vi is not in V , then we attach V with a starting time ts = ti and add V to V . ( 2 ) If a vertex set V ∈ V is not in Vi , then we attach V with an ending time te = ti , output the subgraph pattern induced by V and I = [ ts , te ] to the result set R if |I| ≥ τ , and then remove V from V . After all qualified temporal subgraph patterns have been collected to R , we call the greedy set cover algorithm over R , and output the top k subgraph patterns . Drawbacks of the Baseline Algorithm . The baseline algorithm simply calls an existing algorithm for each graph snapshot G(ti ) , where i = 1 , 2 , . . . ,|T| , which is inefficient since it incurs a lot of redundant computation when there are not many changes between consecutive graph snapshots . Moreover , we need to keep all the quasi cliques of each snapshot graph ( even if they may not last for τ time steps ) , which consumes a large amount of memory .
4 . OUR SOLUTION
In this section , we introduce the main framework of our algorithm for finding the top k diversified temporal subgraph patterns . 4.1 Overview The high level idea is to find qualified patterns by divide andconquer . We define a mining task as T = ( G , S , I ) . Here G = ( V , E ) is a temporal graph , S is a subset of V that we have already selected as a subgraph pattern , and I is a time interval . The mining task aims to find all maximal dense subgraphs induced by V ⊆ V and I ⊆ I from G , such that V ⊇ S , |V | ≥ σ and |I| ≥ τ . We start with the task T = ( G,∅ , T ) , where we abuse T ( wrt G ) to also denote the minimal time interval that contains all the time snapshots in T . We process the task T recursively as follows . We first remove some vertices and time snapshots of G by the pruning rules to be introduced in Section 5 , as they cannot be included in any qualified subgraph patterns . If all the vertices and time snapshots are removed , then G does not contain any qualified subgraph patterns , and the task is done . Otherwise , let the remaining graph be G = ( V , E ) , if G is dense throughout I , then we add G to the result set R , and the task is also done . If G is neither empty nor dense , we divide the task T recursively into subtasks . Let I be the set of unpruned time snapshots in I , then we continue with two cases : ( Case 1 ) If I is a consecutive interval , then we select a vertex v from V \ S according to a total order on vertices ( the ordering will be discussed in Section 6.1 ) , and divide T into two subtasks . One subtask examines the subgraphs that contain v and the other examines the subgraphs that do not contain v . More specifically , T is divided into T1 = ( G , S ∪ {v},I ) and T2 = ( G \ {v} , S,I ) , where G \ {v} is the remaining graph after removing vertex v and all edges incident on v from G . ( Case 2 ) Otherwise , I is disjoint , ie , I = [ s1 , e1]∪[s2 , e2]∪ . . .∪[s , e ] , then let Ii = [ si , ei ] and we divide T into subtasks Ti = ( G ∩ Ii , S , Ii ) , where i = 1 , 2 , . . . , and G ∩ Ii is a subgraph of G induced by V and Ii . We then process the subtasks recursively . 4.2 Updating the Result Set
We keep at most k subgraph patterns in the result set R throughout the whole mining process . To do so , we simply add the new qualified subgraphs to R when |R| < k ; otherwise , we maintain R greedily to increase the coverage |C(R)| . More specifically , we first select a subgraph G from the result set R , where
G = arg maxG∈R
|C(R \ {G})| is the subgraph in R such that after removing it from R , the remaining coverage is maximized . Let R− = R \ {G} be the result set after excluding G from R . To decide whether a new qualified subgraph Gnew should be included into R , we replace G with Gnew , and check whether the new coverage |C(R− ∪ {Gnew})| becomes larger than the current coverage |C(R)| . To allow effective pruning ( to be discussed in Section 5 ) , we only replace G with Gnew if
|C(R− ∪ {Gnew})| > ( 1 + 1/k ) · |C(R)| ,
( 1 )
In other words , we only update the result set if the coverage increases by more than 1/k times after updating . According to [ 2 ] , this updating rule has a guarantee of a 1/4 approximation ratio wrt the maximum value of |C(R)| . 4.3 The Algorithm Our mining algorithm is sketched in Algorithms 1 and 2 . Algorithm 1 first initializes the result set R ( Line 1 ) and then calls the “ Search ” procedure detailed in Algorithm 2 with the given temporal graph G , an empty set ( of selected vertices ) and G ’s time interval T ( Line 2 ) . Finally , it outputs the computed result set R ( Line 3 ) . Algorithm 2 shows the recursive procedure of a mining task . It first applies the pruning rules ( see Section 5 ) to prune some vertices and time snapshots from G ( Line 1 ) . Then , we continue to process the pruned graph ( denoted as Gnew ) in three cases . ( 1 ) If the set of the remaining time points I is empty , then there is no qualified subgraph and the mining task is done ( Lines 2 3 ) ; otherwise , ( 2 ) if I contains only one consecutive time interval and Gnew is a γ quasi clique through out I , then Gnew is a new qualified subgraph , and the result set R will be updated as described in Section 4.2 before finishing the mining task ( Lines 4 6 ) ; otherwise , ( 3 ) we continue with two subcases : if I is a consecutive time interval , the task is divided into two subtasks according to a selected vertex v ∈ V \ S ( Lines 7 10 ) ; otherwise , the task is divided into subtasks according to the disjoint time intervals of I ( Lines 11 13 ) . In both subcases , the subtasks are then processed recursively .
Compared with the baseline algorithm , we now examine the subgraph patterns in the unit of time intervals rather than time points . We also terminate the mining task immediately once we find that no dense subgraph patterns can last for a period of length at least τ . This pruning opportunity , however , is not utilized by the baseline algorithm . Also , we keep at most k subgraph patterns in the result set throughout our mining procedures , which is more space efficient than the baseline algorithm .
5 . PRUNING RULES
In this section , we present our five pruning rules for temporal subgraph mining , which are used in Line 1 of Algorithm 2 . In the pruning procedure , we repeat the first four pruning rules to prune
1967 Algorithm 1 : Top k Diversified Temporal Subgraph Mining Input : G = ( V , E ) , γ , σ , τ , k Output : R 1 . R ← ∅ 2 . Search(G,∅ , T ) 3 . return R
Algorithm 2 : Search(G = ( V , E ) , S , I ) 1 . Apply the pruning rules to shrink G ( see Section 5 )
{Let Gnew be the remaining graph and I = I1 ∪ ∪ I be the remaining time snapshots after pruning , where I1 , , I are the disjoint time intervals of I} if I = ∅ return if = 1 and Gnew is a γ quasi clique throughout I Update R with Gnew ( see Section 4.2 ) return if = 1 select a vertex v ∈ V \ S Search(Gnew , S ∪ {v},I ) Search(Gnew \ {v} , S,I )
2 . 3 . 4 . 5 . 6 . 7 . 8 . 9 . 10 . 11 . 12 . 13 . else for i = 1 , 2 , . . . ,
Search(Gnew ∩ Ii , S , Ii ) the given temporal graph until it cannot be further pruned , and then use the last pruning rule to further prune the remaining graph . Summary of Pruning Rules . For temporal graph G of a mining task , the first rule prunes the vertices with low degrees and short durations , such that the degree of any vertex in the remaining graph remains at least γ · ( σ − 1 ) for a period with length at least τ .
The second rule prunes the vertices that are far away from a newly selected vertex v , such that the distances from v to the remaining vertices are within a valid range .
After calculating the bounds on the sizes of the qualified subgraph patterns , the third ( resp . fourth ) rule removes the snapshot graphs ( resp . vertices ) that cannot be included in a qualified subgraph pattern according to the bounds .
The last rule is applied only if the time points of the remaining snapshot graphs still form a consecutive interval after the previous pruning . In this case , the task is terminated if no qualified subgraph can increase the coverage by more than 1/k times as the updating rule requires . The Pruning Operations . Before presenting the details of our pruning rules , we first introduce three pruning operations that are commonly used to shrink a temporal graph G .
Operation 1 : Edge Removal . Recall that a temporal edge e = ( u , v , I ) connects vertices u and v within time interval I . After removing this edge , du(t ) and dv(t ) decrease by 1 for all t ∈ I . Sometimes we may only remove an edge within a given time interval I , and then this edge becomes ( u , v , I \ I ) , which will be broken into two edges if I \ I is disjoint after removal . For example , let a temporal edge be ( u , v , [ 0 , 60] ) , and if we remove this edge within time interval [ 20 , 50 ] , then this edge is broken into two edges ( u , v , [ 0 , 20 ] ) and ( u , v , [ 50 , 60] ) . Operation 2 : Vertex Removal . If a vertex v is removed from G , then all its adjacent temporal edges are removed . Sometimes we may only remove a vertex within a given time interval I , and thus only its adjacent edges within the time interval I are removed . Moreover , given a set of disjoint time intervals , I = {[s1 , e1 ] , . . . , [ si , ei ] , . . . , [ s , e]} , if we only remove v wrt I , then v is only removed within time intervals [ si , ei ] for all i = 1 , 2 , , . Operation 3 : Snapshot Graph Removal . Given a set of disjoint time intervals , I , if we remove the snapshot graphs in I , then all the vertices of G are only removed wrt I , and hence , the snapshot graphs will be empty at any time t ∈ I . 5.1 The List of Pruning Rules
Now we present our five pruning rules . Let T = ( G , S , I ) be a mining task , where G = ( V , E ) . For an induced subgraph G = ( V , E , I ) of G , if V ⊇ S , |V | ≥ σ , |I| ≥ τ and G is γ dense throughout I , then we say G is a qualified subgraph pattern . Rule 1 : Degree and Duration Based Pruning . We first prune the vertices with low degrees or short durations , since they cannot be included in a qualified subgraph pattern . More specifically , let v ∈ V be a vertex of G . If dv(t ) < γ · ( |S|−1 ) , then dv(t ) < γ·(|V |−1 ) for any superset V ⊇ S . Thus , dv(t ) is too low for v to be included in a γ dense subgraph at time t . Moreover , if dv(t ) < γ · ( σ − 1 ) , then we also cannot include v in a γ dense subgraph with size at least σ at time t . Based on these v = {t | t ∈ I , dv(t ) < γ · ( max{|S| , σ} − facts , let us define I− 1)} , then we can prune v within any time interval in I− v . Let us define I + v = {t | t ∈ I , dv(t ) ≥ γ · ( max{|S| , σ}− 1)} , and let [ s1 , e1 ] , [ s2 , e2 ] , , [ s , e ] be the disjoint time intervals of I + v . If ei − si < τ for some i , where 1 ≤ i ≤ , then time interval [ si , ei ] is too short and v cannot be included in a qualified subgraph pattern at any time t ∈ [ si , ei ] . Based on this fact , we can prune v within [ si , ei ] for any i = 1 , 2 , , such that ei − si < τ . We repeat the above operations for all vertices in G until no more vertex can be removed within any time interval . Rule 2 : Distance Based Pruning . According to [ 26 ] , if a vertex is too far away from any selected vertex , it cannot be in a γ quasiclique . Thus , after a new vertex is selected , we remove vertices that are farther away than a distance threshold computed based on γ . Specifically , if a non temporal graph G = ( V , E ) is a γ quasiclique , then according to Theorem 1 in [ 26 ] , we have δu,v ≤ f ( γ ) for all u , v ∈ V , where δu,v is the distance between vertices u and v , and f is a function of γ . In particular , f ( 1 ) = 1 and f ( γ ) = 2 for 0.5 ≤ γ < 1 . According to this property , vertices whose distance are larger than f ( γ ) from any selected vertex can be removed . To do so , we define δu,v(t ) as the distance between vertices u and v in G at time t , and define I∗ v ( u ) = {t | δu,v(t ) > f ( γ)} as the set of time points when the distance between u , v ∈ V is larger than a given threshold f ( γ ) . Then , after adding a new vertex v to S , for every u ∈ V \ S , we prune u within any time interval in I∗ Rule 3 : Pattern Size Based Pruning . Consider the current task T = ( G , S , I ) again . For a time point t ∈ I , if there does not exist any qualified subgraph pattern G = ( V , E , I ) such that t ∈ I , we call t as a break point . To find break points for any t ∈ I , we first calculate an upper bound ub(t ) and a lower bound lb(t ) for the size of any qualified subgraph pattern at time t ( see Section 5.2 for the calculation ) . Obviously , if ub(t ) < σ or ub(t ) < lb(t ) , then t is a break point . Based on this property , we define Tb = {t|t ∈ I , ub(t ) < σ or ub(t ) < lb(t)} as the set of break points . v ( u ) .
Then , we can use Tb to find more break points by checking the length of the time interval between any two break points in Tb , which is detailed as follows . If t1 , t2 ∈ Tb satisfies |t2 − t1| < τ , then for any t ∈ [ t1 , t2 ] , the time span of any γ dense subgraph that spans across time t is broken at t1 and t2 , and hence , these subgraph patterns cannot last for a period with length τ . As a result , all time points t ∈ [ t1 , t2 ] are also break points . We denote this expanded set of break points as follows : b = {t|t ∈ I,∃t1 , t2 ∈ Tb , st t1 ≤ t ≤ t2 , t2 − t1 < τ} . T +
1968 Then , we can prune the snapshot graphs in T + b . Rule 4 : Vertex Based Pruning . Recall that V is the vertex set of G . For a vertex v ∈ V and a time point t ∈ I , if there does not exist any qualified subgraph pattern G = ( V , E , I ) such that v ∈ V and t ∈ I , then we say that v is disqualified at time t . We will show how to find disqualified vertices in Section 53 Moreover , if a vertex v is disqualified at both t1 and t2 such that |t2 − t1| < τ , then v is also disqualified at any time t ∈ [ t1 , t2 ] . Let Tv be the set of time points when v is disqualified . If v ∈ S , then all the time points in Tv are break points and we prune the snapshot graphs in Tv ; otherwise , we prune v at any time t ∈ Tv . Rule 5 : Diversity Based Pruning . This pruning rule is only called when the set of time intervals ( denoted as I ) of the remaining snapshot graphs ( after repeatedly applying Rules 1 4 ) consists of only one consecutive time interval . Recall from Section 4.2 that if Inequality ( 1 ) does not hold , we do not update the result set R , and thus can terminate the task earlier . For this purpose , we derive an upper bound on the coverage score after we update R with any subgraph pattern G mined from the current task T . Let ∆(G ) = |C(R− ∪ {G})| − |C(R−)| be the increment of the coverage after adding G to R− . Since we have selected a set S of vertices , we can first calculate ∆(G ∩ S ) , where G ∩ S refers to the subgraph of G induced by S and I . Let m = maxt∈I ub(t ) be the maximum allowed number of vertices in a qualified subgraph , and let ∆1 , ∆2 , . . . , ∆m−|S| be the ( m − |S| ) largest values of ∆(G ∩ {v} ) among all v ∈ V \ S . Then the upper bound of the i=1 ∆i ( ie , the coverage after we add into R− a pattern G , which contains S and up to ( m−|S| ) other vertices ) . If C ub < ( 1 + 1/k)·|C(R)| , then Inequality ( 1 ) cannot hold , and we thus terminate task T directly . 5.2 Bounds on Pattern Sizes coverage is C ub = |C(R−)| + ∆(G ∩ S ) +m−|S|
Recall that Rule 3 requires the bounds ub(t ) and lb(t ) on the size ( ie , the number of vertices ) of any qualified subgraph pattern at time t . We now derive these bounds . 521 Degree Based Bounds The degree of a vertex provides an upper bound on the size of any quasi clique that contains this vertex . We discuss how to derive the upper bound u(t ) for a mining task . Given a mining task T = ( G , S , I ) , for any t ∈ I , let dmin(t ) = min{dv(t ) | v ∈ S} . Then , u(t ) is given by the following lemma . LEMMA 1 . Let G = ( V , E ) be a subgraph of G(t ) . If V ⊇ S and G is a γ quasi clique , then |V | ≤ u(t ) , where u(t ) = dmin(t)/γ + 1 .
PROOF . According to the definition of γ quasi clique , we have dv(t ) ≥ γ · ( |V | − 1 ) for all v ∈ V . Since V ⊇ S , we have dmin(t ) ≥ γ · ( |V | − 1 ) , that is , |V | ≤ dmin(t)/γ + 1 = u(t ) .
We now derive the lower bound l(t ) . Let Nv(t ) be the set of v ’s neighbors at time t . Given a set of vertices , S , we first define the restricted degree of v wrt S at time t as dS v ( t ) = |Nv(t ) ∩ S| , which refers to the number of neighbors of v that are in S at time v ( t ) | v ∈ S} . Then , l(t ) is given by the t . Let dS following lemma . min(t ) = min{dS
LEMMA 2 . Let G = ( V , E ) be a subgraph of G(t ) . If V ⊇ S and G is a γ quasi clique , then |V | ≥ l(t ) , where l(t ) = ( cid:100)(|S| − dS min(t ) − γ)/(1 − γ ) . v ( t ) ≥ dS
Sum of Degree Based Bounds v ( t ) , and thus , |V | − |S| + dS
PROOF . According to the definition of γ quasi clique , we have dV v ( t ) ≥ γ · ( |V | − 1 ) for all v ∈ V . Since V ⊇ S , we have dV v ( t ) ≤ ( |V | − |S| ) + dS v ( t ) ≥ γ · ( |V | − 1 ) for all v ∈ V . Since dS min(t ) , we have |V | − |S| + dS min(t ) ≥ γ · ( |V | − 1 ) , and thus , |V | ≥ ( cid:100)(|S| − min(t ) − γ)/(1 − γ ) = l(t ) . dS 522 We now make u(t ) and l(t ) tighter by considering the sum of the restricted degree of individual vertices . Note that if a non temporal graph G = ( V , E ) is a γ quasi clique , then for any m vertices in V , the sum of their degrees must be at least m·(cid:100)γ · ( |V |− 1 ) . Since S ⊆ V , for any subset of S with m vertices , denoted by S , the sum of all degrees of vertices in S should be at least m · ( cid:100)γ · ( |V | − 1 ) . Currently , V = S but the degree sum may be less than m · ( cid:100)γ · ( |S| − 1 ) , and we need to include more vertices into V to make the requirement satisfied for the subset S . We present how to derive bounds on the number of vertices that needs to be included , using restricted vertex degrees wrt S . For vertices in S , we compute their sum of restricted degree wrt S v ( t ) . For vertices in V \ S ( which are candidates to be included into V ) , we sort them in non increasing order of their restricted degree dS v ( t ) , and denote the sorted vertices by v1 , v2 , . . . , v|V \S| . Then , we have the following lemma . at time t as v∈S dS i=1 v∈S
| − 1 ) dS v ( t ) +
| · ( cid:100)γ · ( |V
LEMMA 3 . Let G = ( V , E ) be a subgraph of G(t ) , and S be a subset of S , if V ⊇ S and G is a γ quasi clique , then we dS vi ( t ) ≥ |S have |V \S| to prove that LHS ≥ PROOF . According to the definition of γ quasi clique , we have v∈S dV v ( t ) ≥ |S|·(cid:100)γ· ( |V |− 1 ) = RHS , then we just need Note that and V , and thus equals v∈S dV prove that LHS ≥ v∈V dS v∈V dS v ( t ) . v ( t ) equals the number of edges between S v ( t ) . Thus , we only need to
We divide V into two sets S and V \ S , then we get v∈S dV v ( t ) .
( 2 ) dS v ( t ) = dS v ( t ) + dS v ( t ) . v∈V v∈S v∈V \S
Since we have sorted the vertices v ∈ V \ S in descending order of their restricted degrees , we have
|V \S| LHS ≥ i=1 dS vi ( t ) ≥ v∈V \S dS v ( t ) + v∈S v∈V \S
Thus , according to Inequality ( 2 ) , we have dS v ( t ) . v∈V dS v ( t ) , dS v ( t ) = which completes the proof .
Let uS
( t ) ( resp . lS
( t ) ) be the maximum ( resp . minimum ) |V |
( computed from S ) , such that ( t ) ≤ |V l(t ) ≤ lS
| ≤ uS
( t ) ≤ u(t ) ,
( 3 )
( 4 ) v∈S
|V \S| i=1 dS v ( t ) + dS vi ( t ) ≥ |S
| · ( cid:100)γ · ( |V
| − 1 ) .
1969 ( t ) , we first compute
( t ) . v∈S dS
( t ) and lS
According to Inequality ( 3 ) , uS
To compute uS ( t ) and lS v ( t ) . Then , we sort the vertices in V \ S in non increasing order of their restricted degree dS v ( t ) for every t ∈ I , and hence we obtain the LHS of Inequality ( 4 ) for |V | = |S|,|S| + 1 , , u(t ) by summing up the restricted degree dS vi ( t ) one by one from the sorted list for i = 1 , 2 , . . . , u(t ) − |S| . Finally , we compare the sum with RHS to get uS ( t ) are tighter than u(t ) and l(t ) . If there is no valid value of |V | that satisfies Inequalities ( 3 ) and ( 4 ) , then we set uS ( t ) = |V | + 1 . Since any subset S ⊆ S can be selected to compute the bounds uS ( t ) and lS ( t ) and lm(t ) = maxS⊆S lS ( t ) and lS
( t ) = −1 and lS ( t ) , we define um(t ) = minS⊆S uS ( t ) , then um(t ) and lm(t ) are tighter than uS ( t ) for any S ⊆ S , and we have the following corollary . COROLLARY 1 . Let G = ( V , E ) be a subgraph of G(t ) , if V ⊇ S , |V | ≥ σ and G is a γ quasi clique , then we have lm(t ) ≤ |V | ≤ um(t ) .
( t ) and lS
For efficiency reasons , we only enumerate some subsets S ⊆ S to compute the bounds , as we will discuss in Section 61 523 Duration Based Bounds Note that um(t ) and lm(t ) are functions of t for t ∈ I , we can further make them tighter using the minimum duration τ .
LEMMA 4 . If there exists t , t1 , t2 ∈ I , such that t1 < t < t2 , t2 − t1 < τ and
( 5 ) ( 6 ) ( 7 ) then no dense subgraph pattern with size um(t ) at time t can last for a duration with length τ . um(t ) > max{um(t1 ) , um(t2)} ,
PROOF . According to Corollary 1 , there does not exist a dense subgraph pattern with size larger than um(t1 ) at time t1 or um(t2 ) at time t2 . That is , there does not exist a dense subgraph pattern with size larger than max{um(t1 ) , um(t2)} at time t1 or t2 . Then , any dense subgraph pattern with size um(t ) > max{um(t1 ) , um(t2)} at time t must start after t1 and end before t2 , and hence , cannot last for a duration with length t2 − t1 < τ .
According to Lemma 4 , we can make um tighter if there exists t , t1 , t2 ∈ I satisfying Inequalities ( 5) (7 ) . In this case , we say um is tighten able at time t , and we tighten um by setting um(t ) to max{um(t1 ) , um(t2)} . We repeat this operation until um is not tighten able at any time t ∈ I . Then , the upper bound ub(t ) used by Rule 3 equals the tightened um(t ) , which can be computed in linear time as follows . where s is the number of changes of the value of um(t ) for t ∈ I , ti is the time of the i th change , and ∆i is the difference of the value of um(t ) after and before time t = ti . As a special case , t1 is the starting time of I and ∆1 equals um(t1 ) . For example , the upper bound um(t ) shown in Figure 3(a ) can be represented in 3 pairs ( 0 , 8 ) , ( 20 , 6 ) , ( 40,−4 ) . Before explaining how to compute ub(t ) in linear time , we need to prove the following lemma .
We first represent um(t ) in s pairs ( t1 , ∆1 ) , ( t2 , ∆2 ) , . . . , ( ts , ∆s ) ,
LEMMA 5 . Let ( ta , ∆a ) and ( tb , ∆b ) be two consecutive pairs in the representation of um(t ) . If
∆a > 0 , ∆b < 0 and tb − ta < τ , then um(t ) is tighten able at any time t ∈ ( ta , tb ) .
( 8 )
( a ) The original upper bound
( b ) The improved upper bound
Figure 3 : An example of um before and after improvement .
PROOF . Since ∆a > 0 , we have um(t ) > um(ta ) for t > ta ; also , since ∆b < 0 , we have um(t ) > um(tb ) for t < tb . Then , let t1 = ta , t2 = tb and t ∈ ( t1 , t2 ) , we have t1 < t < t2 , t2−t1 < τ and um(t ) > max{um(t1 ) , um(t2)} , and thus , um is tighten able at any time t ∈ ( ta , tb ) .
To compute ub(t ) , we maintain a stack S of pairs , which is empty initially . Recall that um(t ) has been represented in s pairs ( t1 , ∆1 ) , ( t2 , ∆2 ) , . . . , ( ts , ∆s ) , we push the pairs ( ti , ∆i ) into S one by one for i = 1 , 2 , , s . After we have pushed a pair into S , let the top 2 pairs of S be ( ta , ∆a ) and ( tb , ∆b ) , we then check Inequalities ( 8 ) in Lemma 5 . If they all hold , then um(t ) is tightenable at any t ∈ ( ta , tb ) , and hence , we want to tighten um(t ) by setting um(t ) to max{um(ta ) , um(tb)} for all t ∈ ( ta , tb ) . To handle this operation , we first pop ( ta , ∆a ) and ( tb , ∆b ) out from S . We then define ∆ = ∆a + ∆b , and update S as follows , if ∆ > 0 , we push ( ta , ∆ ) into S ; otherwise , if ∆ < 0 , we push ( tb , ∆ ) into S . We repeat the previous operations , until Inequalities ( 8 ) do not hold for the top 2 pairs of S . Finally , ub(t ) is derived as the pairs in S represent . Apparently , the computation time of ub(t ) is linear to s .
To illustrate the computation of ub(t ) , let I = [ 0 , 70 ] , τ = 30 , and um(t ) be shown in Figure 3(a ) . To compute ub(t ) , we first push the pairs ( 0 , 8 ) , ( 20 , 6 ) , ( 40,−4 ) into S one by one . After we have pushed ( 40,−4 ) into S , the top 2 pairs are ( 20 , 6 ) and ( 40,−4 ) , which satisfy 6 > 0 , −4 < 0 and 40 − 20 < τ , and thus , um is tighten able at t ∈ ( 20 , 40 ) . To tighten um , we pop ( 20 , 6 ) and ( 40,−4 ) out from S , and we have ∆ = 6 + ( −4 ) = 2 > 0 , and hence , we push ( 20 , 2 ) into S . Finally , we get S = {(0 , 8 ) , ( 20 , 2)} , and ub(t ) is derived as the 2 pairs ( 0 , 8 ) , ( 20 , 2 ) represent , which is shown in Figure 3(b ) .
Similarly , we have the following lemma on the lower bounds . LEMMA 6 . If there exists t , t1 , t2 ∈ I , such that t1 < t < t2 , t2 − t1 < τ and lm(t ) < min{lm(t1 ) , lm(t2)} , then all the dense subgraph patterns with size lm(t ) at time t cannot last for a duration with length τ .
According to Lemma 6 , we can make lm tighter by a similar procedure , such that t1 < t < t2 , t2 − t1 < τ and lm(t ) < min{lm(t1 ) , lm(t2)} cannot hold simultaneously for any t , t1 , t2 ∈ I . Finally , the lower bound lb(t ) used by Rule 3 equals the tightened lm(t ) . 5.3 Computation of Disqualified Vertices
After deriving the bounds lb(t ) and ub(t ) on the size of qualified subgraph patterns of G , we can use these bounds to check whether we can include a vertex v in a qualified subgraph pattern at time t . If we cannot include v in a qualified subgraph pattern at time t , then v is disqualified at time t , which will be pruned by Rule 4 . To check whether a vertex v is disqualified at time t , we first prove the following lemma .
LEMMA 7 . Let G = ( V , E ) be a subgraph of G(t ) , if V ⊇ S and G is a γ quasi clique , then we have dv(t ) ≥ γ · ( lb(t ) − 1 ) for all v ∈ V .
1970 PROOF . According to the definition of γ quasi clique , we have dv(t ) ≥ γ · ( |V | − 1 ) for all v ∈ V . Since we have |V | ≥ lb(t ) , we obtain dv(t ) ≥ γ · ( lb(t ) − 1 ) .
According to Lemma 7 , if we find that there exists v ∈ V , t ∈ I , such that dv(t ) < γ · ( lb(t ) − 1 ) , then we cannot include v in a qualified quasi clique at time t , and hence , v is disqualified at time t . More disqualified vertices can be found by the following lemma . LEMMA 8 . Let G = ( V , E ) be a subgraph of G(t ) , if V ⊇ v ( t ) ≥ v ( t ) ≥
S and G is a γ quasi clique , then we have ub(t ) − |S| + dS γ · ( lb(t)− 1 ) for all v ∈ S and we have ub(t)−|S|− 1 + dS γ · ( lb(t ) − 1 ) for all v ∈ V \ S .
PROOF . Since G is a γ quasi clique , we have dV v ( t ) ≥ γ · ( lb(t ) − 1 ) . Since we have |V | ≤ ub(t ) , V contains at most ( ub(t)−|S| ) vertices that are not in S , and thus , we have dV v ( t ) ≤ v ( t ) for v ∈ S and dV ub(t)−|S|+dS v ( t ) for v ∈ V \S . Thus , we obtain ub(t)−|S|+dS v ( t ) ≥ γ·(lb(t)−1 ) v ( t ) ≥ γ · ( lb(t ) − 1 ) for all for all v ∈ S and ub(t ) − |S| − 1 + dS v ∈ V \ S . v ( t ) ≤ ub(t)−|S|−1+dS
According to Lemma 8 , if we find that there exists v ∈ S , t ∈ I , such that ub(t ) − |S| + dS v ( t ) < γ · ( lb(t ) − 1 ) , then we cannot include v in a qualified quasi clique at time t , and hence , v is disqualified at time t . Also , if we find there exists v ∈ V \ S , t ∈ I , such that ub(t ) − |S| − 1 + dS v ( t ) < γ · ( lb(t ) − 1 ) , then v is disqualified at time t . We can further check whether a vertex w ∈ V \S can be included in a qualified subgraph pattern at time t by considering the sum of degrees as follows . If we include vertex w in the set of selected vertices , then the set of selected vertices will be S ∪ {w} . Let S be a subset of S , and v1 , v2 , . . . , v|V \(S∪{w})| be the vertices in V \(S∪{w} ) that are sorted by descending order of their restricted degrees dS v ( t ) wrt S at time t . Let
Σ = v∈S∪{w} m−|S|−1 i=1 dS v ( t ) + dS vi ( t ) ,
If there does where m refers to the size of a subgraph pattern . not exists m , such that ( 1 ) lb(t ) ≤ m ≤ ub(t ) , and ( 2 ) Σ ≥ |S|·(cid:100)γ · ( m− 1 ) , then vertex w cannot be included in a qualified subgraph pattern at time t , and hence , w is disqualified at time t .
6 . OPTIMIZATIONS
In this section , we provide some optimization techniques that are used to further improve our algorithm . 6.1 Ordering Techniques
Consider a task T = ( G , S , I ) , let I be the set of time intervals of the remaining snapshot graphs after pruning . Recall that when I is a single consecutive time interval , we will divide T into two subtasks , T1 = ( G , S ∪ {v1},I ) and T2 = ( G \ {v1} , S,I ) , where v1 is a selected vertex . Since T2 may be further divided into T2,1 = ( G \ {v1} , S ∪ {v2},I ) and T2,2 = ( G \ {v1 , v2} , S,I ) , and T2,2 may be further divided into T2,2,1 = ( G \ {v1 , v2} , S ∪ {v3},I ) and T2,2,2 = ( G \ {v1 , v2 , v3} , S,I ) , and so on , we can divide the task T into |V \ S| subtasks T1 , T2 , . . . , T|V \S| directly , where Ti = ( G\{v1 , v2 , . . . , vi−1} , S∪{vi},I ) . Therefore , when I is a consecutive time interval , we need to arrange the |V \ S| vertices in order so that we can divide the task T into |V \ S| subtasks directly .
Vertex Ordering . We order the vertices in ascending order of their degrees . That is , the vertices with smaller degrees will be selected first . Since we have selected a set S of vertices , their degrees are more important than the degrees of the vertices we have not selected . According to this intuition , we define a score function of a vertex as the weighted sum of its restricted degree wrt S and its original degree . Formally , the score function of a vertex v in a temporal graph G at time t is defined as v ( t ) = |S| · dS G sc t∈I sc t∈I sc v ( t ) + dv(t ) .
G\{v1} v is the vertex with the smallest
Then , the first selected vertex v1 is the vertex with the smallest v ( t ) among all v ∈ V \ S , the second selected vertex v2 G ( t ) among all v ∈
V \ ( S ∪ {v1} ) , and so on . Subtasks Ordering . Since the degrees of v1 , v2 , are smaller than the remaining vertices , the remaining graph G \ {v1 , v2 , } is probably denser than the original graph G , and hence , it is easier to find qualified subgraph patterns in the remaining graph . In other words , it is easier to mine dense subgraphs from subtask Ti with larger i intuitively . According to this intuition , we process the subtask Ti in descending order of i ( ie i = |V \ S|,|V \ S| − 1 , , 2 , 1 ) , so that we can find some qualified subgraph patterns more quickly . The previous discussions are based on the case that I is a consecutive time interval . When I is disjoint , we will divide T into subtasks according to the disjoint time intervals in I . Then , we order the subtasks according to the density of their graphs , where the density is measured by the weighted sum of the degrees of the ( t)/|Ii| , then a subtask will be processed earlier if its graph has a larger Σ value . Vertex Subsets Ordering . Recall that any subset S ⊆ S can be used to derive a bound of pattern size ( see Section 522 ) , we only take |S| subsets into consideration to achieve higher efficiency . We next specify which |S| subsets will be considered . vertices . Specifically , let Σ =
G∩Ii v sc v∈V t∈Ii t∈I sc weighted degrees
The first subset is S itself , then the next subset is the previous subset after excluding a vertex with the largest weighted degree . The reason is that the vertices with smaller degrees are harder to satisfy the degree threshold , and hence , they are more likely to affect the bounds of pattern sizes . Formally , let v1 , v2 , . . . , v|S| be the list of vertices in S sorted by non increasing order of their G v ( t ) , then the first subset is S itself , the second subset is S \ {v1} , and so on . 6.2 Search Strategy Recall that we continue processing a task only when C ub ≥ ( 1 + 1/k ) · |C(R)| holds ( see Rule 5 in Section 5.1 ) , a good result set R may help us to terminate many tasks earlier since the larger |C(R)| is , the less likelihood this condition holds . According to this intuition , we want to collect the first k qualified subgraph patterns ( 1 ) as quick as possible , and ( 2 ) with the size of the coverage set as large as possible . However , our current search strategy only achieves the first goal , but has not achieved the second goal yet . The reason is that our search is depth first , ie , we do not proceed to the next subtask until the current subtask is done . Note that all the subgraphs mined from T = ( G , S , I ) contain the set S of vertices , they overlap with each other on any vertex v ∈ S , and hence , our current search strategy cannot get a large initial coverage .
To achieve both goals , we propose a quick search algorithm , which runs with a user defined parameter . This search strategy proceeds to the next subtask earlier according to the value of . To specify how the algorithm works , we first define the hardness of a task T , denoted as h(T ) . If T can be done without dividing into
1971 subtasks , ie , the graph is totally pruned , or is dense throughout its time interval , then h(T ) = 0 . Otherwise , h(T ) is defined in a recursive way as follows . Let h(Ti ) be the hardness of the i th subtask of T , i = 1 , 2 , . . . , s , where s is the number of subtasks of T . Let hm(T ) = max{h(Ti ) | 1 ≤ i ≤ s} be the maximum hardness of the subtasks of T , and let hc(T ) = |{i | h(Ti ) = hm(T ) , 1 ≤ i ≤ s}| be the number of subtasks of T with the maximum hardness . Then we define h(T ) = hm(T ) if hc(T ) = 1 , and h(T ) = hm(T ) + 1 otherwise .
The quick search algorithm only goes into the first subtask that has a large enough hardness , then passes through the remaining subtasks quickly . More specifically , the quick search algorithm with parameter works as follows . If T is divided into subtasks , it recursively calls the quick search algorithm with parameter to handle the subtasks T1 , T2 , . . . , one by one . Once a subtask Ti is finished , it checks whether h(Ti ) ≥ or not . Once h(Ti ) ≥ holds , it passes through the remaining subtasks quickly as follows . It first checks whether > 0 or not . If = 0 , it terminates immediately without handling the remaining subtasks Ti+1 , Ti+2 , . . . ; otherwise ( ie > 0 ) , it handles the remaining subtasks Ti+1 , Ti+2 , . . . by recursively calling the quick search algorithm with parameter − 1 only . We have the following theorem on the efficiency of the quick search algorithm .
THEOREM 1 . The quick search algorithm with parameter handles at most r+1 max tasks , where rmax is the maximum depth of recursions handling a task , and smax is the maximum number of subtasks that a task is divided into . max · s max·s max
PROOF . We first prove that there are at most R( ) = r+1 tasks that need to be handled in a task T with hardness . We prove this proposition by induction . The base case is = 0 . According to the definition of hardness , if T needs to be divided , it must be divided into at most one subtask T1 , and T1 has at most one subtask T1,1 , and T1,1 has at most one subtask T1,1,1 , and so on . Then the total number of tasks needs to be handled in T is at most rmax , which proves the base case of the proposition . For the induction case , suppose the proposition holds for the tasks with hardness − 1 , and the hardness of a task T is . Then there are at most one subtask of T with hardness . Without losing generality , let h(T1 ) = , then we have h(Ti ) ≤ − 1 for i = 2 , 3 , . . Then there are at most one subtask of T1 with hardness , and without loss of generality , let h(T1,1 ) = , then we have h(T1,i ) ≤ − 1 for i = 2 , 3 , . . Then the same argument can be applied to T1,1 , then T1,1,1 , and so on . Hence , the total number of tasks that need to be handled in T is at most rmax · smax · R( − 1 ) = R( ) , which proves the induction case and the proposition holds for all . max · s
We then prove , by induction , that the quick search algorithm with parameter handles at most R( ) = r+1 max tasks . The base case is = 0 . According to the quick search algorithm , if T needs to be divided , it only handles the first subtask T1 . If T1 needs to be divided , it only handles the first subtask T1,1 , and so on . Then the total number of tasks that need to be handled in T is at most rmax , which proves the base case of the theorem . For the induction case , suppose the theorem holds for parameter − 1 , then the algorithm with parameter first handles some tasks with hardness at most − 1 , then handles a task with parameter , and then handles the remaining tasks with parameter − 1 . By similar arguments in the previous proof , the algorithm handles at most rmax · smax · R( − 1 ) = R( ) tasks , which proves the induction case and the theorem holds for all .
Apparently , both rmax and smax cannot exceed |V | + |T| . So according to Theorem 1 , given a constant value , the running time of the quick search algorithm is a polynomial of |V | and |T| . However , the quick search algorithm may miss some qualified subgraph patterns . To avoid missing any qualified subgraph pattern , we also propose a complete search algorithm , which works as follows . It calls the quick search algorithm with parameter = 0 , 1 , 2 , . . . for the initial task T , until = h(T ) holds . Then we have the following theorem on the performance of the complete search algorithm .
THEOREM 2 . The complete search algorithm achieves the 1/4 approximation ratio on maximizing |C(R)| .
PROOF . We first show that a task with hardness will be completely handled by the quick search algorithm with parameter . We prove the proposition by induction . Apparently , this proposition holds for the base case = 0 . For the induction case , suppose the tasks with hardness − 1 will be completely handled by the quick search algorithm with parameter − 1 , and h(T ) = . Recall that the algorithm with parameter handles the subtasks of T by three steps : ( 1 ) first handles some subtasks whose hardness is at most −1 with parameter , ( 2 ) then handles a subtask whose hardness is with parameter , ( 3 ) then handles the remaining subtasks whose hardness is at most − 1 with parameter − 1 . Apparently , the subtasks in step ( 1 ) and ( 3 ) will be completely handled , it remains to show that the subtask in step ( 2 ) will be completely handled . Since the same argument can be recursively applied to the smaller subtasks of the subtask in step ( 2 ) , they will be completely handled . Thus the proposition holds for all cases . Since the complete search algorithm finally calls the quick search algorithm with parameter = h(T ) for the initial task T , this task will be completely handled . Then according to the updating rule described in Section 4.2 and the theoretical results in [ 2 ] , the complete search algorithm achieves the 1/4 approximation ratio on maximizing |C(R)| , which completes the proof .
7 . EXPERIMENTAL RESULTS
This section studies the performance of our algorithms . The experiments were conducted on a PC with Intel Core i5 3570 CPU at 3.40GHz and 32GB RAM . The operation system is Linux . Our algorithms are implemented using C++ and compiled by g++ . Datasets . We used six real datasets in our experiments . Five datasets are social networks and one is hyperlinks , which are all downloaded from KONECT ( http://konectuni koblenzde/ ) In which , “ DBLP coauthor ” dataset is the co authorship between authors in DBLP , “ Enron employees ” dataset is the communication between employees in Enron , “ Facebook wall posts ” dataset is the wall posts between users in Facebook , “ Linux kernel mails ” dataset is the emails between email addresses in Linux kernel , “ Slashdot ” dataset is the communication between users in Slashdot , and “ Wikipedia simple En ” dataset is the hyperlinks between Wikipedia articles in simple English . The sizes of these datasets are shown in Table 1 .
|V |
|E|
Table 1 : Dataset size and duration
Dataset
1,314,050
DBLP coauthor Enron employees Facebook wall posts Linux kernel mails Slashdot threads
Duration 35 years 4 years 4 years 8 years 3 years 9 years 7.1 Experiments on Algorithm Efficiency
18,986,618 1,148,072 876,993 1,096,440 140,778 1,627,472
87,273 46,952 63,399 51,083 100,312
Wikipedia simple En
We first report the efficiency of our algorithms . We report the running time of both the complete search algorithm ( denoted as “ Complete ” ) and the quick search algorithm ( denoted as “ Quick ” ) ,
1972 Figure 4 : Effect of γ
Figure 5 : Effect of k
Figure 6 : Effect of τ compared with the baseline algorithm ( denoted as “ Baseline ” ) described in Section 3 . We set γ = 0.8 and k = 10 as the default values , while the default values of σ and τ for each dataset are shown in Table 2 . Note that if σ and/or τ are too large , there will be no qualified patterns ; while if σ and/or τ are too small , then the coverage of the top k patterns will be too small . We study the effects of different values of the parameters in Section 73 We also set = 2 as the default value for the quick search algorithm .
Table 2 : Default values of σ and τ
Dataset
DBLP coauthor Enron employees Facebook wall posts Linux kernel mails Slashdot threads
Wikipedia simple En
σ 20 32 8 32 6 18
τ
1 year
4 months 4 months 4 months 4 months 8 months
Table 3 reports the running time of the three algorithms on each dataset . Note that we terminated an algorithm when it ran for more than 10 days ( ie , 864,000 seconds ) . The result shows that Quick is 2 to 3 orders of magnitude faster than Baseline . Baseline could not complete the process in 10 days for 5 out of the 6 datasets , showing the hardness of the problem studied in this paper . Complete also achieves good performance for 4 out of the 6 datasets . In fact , for 3 of the 4 datasets , Complete achieves the same performance as Quick , which is because the search space of Complete is already small ( as reflected by the running time ) and the strategy used in Quick cannot further reduce the search space . However , for the other 3 datasets that take much longer time to process , the optimization of Quick becomes vital and significant reduction in the running time is observed compared with Complete .
Table 3 : Running time ( in sec )
Dataset
DBLP coauthor Enron employees Facebook wall posts Linux kernel mails Slashdot threads
Wikipedia simple En
Baseline >864,000 >864,000 >864,000 >864,000 >864,000
1,656
198
>864,000
Complete Quick 198 2,417 560 958 2,438
560 7,293 3,697
1
1
7.2 Experiments on Quality of Results
Theorem 2 shows that theoretically Complete has a 1/4 approximation ratio , while Quick is heuristic . Thus , we also show practically how good the results obtained by Complete and Quick are . To do this , we compare the results obtained by Complete and Quick with that obtained by an “ Enumerate all ” algorithm , which lists all the qualified subgraph patterns and then computes the top k result by the greedy algorithm for the maximum set cover problem . The result set obtained by Enumerate all is guaranteed to have a ( 1 − 1/e ) approximation ratio of the optimal result . We used the default values of the parameters as in Section 7.1 for the algorithms .
Table 4 reports the coverage ( ie , |C(G)| ) of the top k patterns obtained by each of the three algorithms on each dataset . The result shows that the top k patterns obtained by Complete achieves a coverage far better than the theoretical 1/4 approximation ratio , and practically the approximation ratio is over 0.8 in all the datasets and over 0.9 in 4 datasets . In fact , for 2 datasets the results of Complete are exactly the same as Enumerate all and for another one the approximation ratio is 0997
Table 4 : Coverage of top k results
Dataset
DBLP coauthor Enron employees Facebook wall posts Linux kernel mails Slashdot threads
Enumerate all 34,401,846,400 2,307,833,012 1,297,815,288 2,258,325,198 615,257,760 1,043,388,109
Complete
Quick
34,306,345,600 2,093,446,876 1,297,815,288 1,789,498,564 530,798,960 1,043,388,109
34,306,345,600 2,093,446,876 1,297,815,288 1,361,365,217 530,798,960 1,043,388,109
Wikipedia simple En The results obtained by Quick are exactly the same as those obtained by Complete for 5 out of the 6 datasets , but Quick is much faster than Complete for processing 3 datasets as shown in Table 3 . Thus , the results of this experiment demonstrate that Quick is not only fast but also computes high quality results . 7.3 Effects of Different Parameters
In this set of experiments , we show the performance of our algorithm , Quick , by varying the different parameters . We first vary γ = 0.75 , 0.8 , 0.85 , 0.9 , while keeping the other parameters as their default values as in Section 71
Figure 4 shows that the running time of Quick can vary considerably with varying values of γ . For some datasets , the running time increases when γ increases , because it is easier to collect the first k qualified subgraph patterns into the result set with a smaller γ , and once we have collected k patterns , we can apply Pruning Rule 5 to terminate a task earlier . However , there are also a few datasets for which the running time remains rather stable or even decreases when γ increases , which can be explained as follows . From Lemma 1 we have u(t ) = dmin(t)/γ + 1 , which decreases if γ increases . Since ub(t ) is tightened from u(t ) , and the snapshot graphs at time t will be pruned by Pruning Rule 3 if ub(t ) < σ , more snapshot graphs will be pruned when γ increases . Thus , the result shows that the effect of γ on the performance of the algorithm varies for different datasets , but overall , even if the running time increases , it only increases linearly in terms of γ .
Next we vary k = 5 , 10 , 15 , 20 . Figure 5 shows that the running time of Quick remains quite stable for different values of k for all the datasets . Note that we could set larger values of k , but the quality of the patterns degrades significantly when k is larger than 20 ( ie , they do not increase the coverage much ) . We also vary τ to be 0.6 , 0.8 , 1 , 1.2 times of the default value , ie , τ0 in Figure 6 . The result shows that the running time of Quick decreases when τ increases , which is because we can prune more short duration patterns by Rule 1 and obtain a tighter bound by duration based bounds ( see Section 523 )
1973 8 . RELATED WORK
Existing work on temporal graphs is mostly related to temporal paths and their applications [ 8 , 15 , 16 , 24 , 27 , 28 , 29 , 34 , 32 ] . More applications of temporal graphs and the sources of temporal graph data can be found in surveys on temporal graphs [ 8 , 12 , 22 ] . None of these works study mining dense subgraph patterns in a temporal graph , and the algorithms of mining dense temporal subgraph patterns are also totally different from any of the existing works .
Many different types of subgraph structures that have high density have been proposed and studied for real world network analysis , including maximal cliques [ 7 ] , quasi clique [ 1 ] , densest subgraphs [ 9 , 14 ] , k core [ 3 ] , k truss [ 31 ] , and so on . The well known definition of quasi clique was introduced by Abello et al . in [ 1 ] . Similar with exact maximal cliques , the problem of enumerating quasi cliques is NP hard . In [ 20 ] , Liu et al . proposed several effective pruning rules for mining quasi cliques . In [ 30 ] , Tsourakakis et al . showed that quasi cliques are high quality subgraphs . Readers can refer to the survey [ 17 ] on dense subgraphs for more comprehensive understanding . All the above discussed works are studied in non temporal graphs .
There has been work on temporal community detection over dynamic networks [ 10 , 33 , 19 , 21 ] and multi layer networks [ 4 , 6 ] . These work first identify communities in a static network , then identify the evolution of the communities from the changes of the network . To our knowledge , our work is the first one for mining quasi cliques in a temporal graph , which can be seen as a multilayer network or the whole history of a dynamic network .
9 . CONCLUSIONS
We proposed the problem of mining the top k diversified temporal subgraph patterns in a temporal graph , and presented a complete search algorithm and a quick search algorithm with effective pruning techniques and search strategies . Our experimental results show that our algorithms are orders of magnitude faster than a baseline algorithm and obtain high quality results . Acknowledgments . We thank the reviewers for their valuable comments . The authors are supported by the Hong Kong GRF 2150851 and 415013 , and the Key Projects of Fundamental Research Program of Shanghai Municipal Commission of Science and Technology under grant No . 14JC1400300 . The project is funded by Research Committee of CUHK .
10 . REFERENCES [ 1 ] J . Abello , M . G . C . Resende , and S . Sudarsky . Massive quasi clique detection . In LATIN , pages 598–612 , 2002 .
[ 2 ] G . Ausiello , N . Boria , A . Giannakos , G . Lucarelli , and V . T . Paschos .
Online maximum k coverage . In Fundamentals of Computation Theory , pages 181–192 . Springer , 2011 .
[ 3 ] V . Batagelj and M . Zaversnik . An O(m ) algorithm for cores decomposition of networks . CoRR , cs.DS/0310049 , 2003 .
[ 4 ] M . Bazzi , M . A . Porter , S . Williams , M . McDonald , D . J . Fenn , and
S . D . Howison . Community detection in temporal multilayer networks , with an application to correlation networks . Multiscale Modeling & Simulation , 14(1):1–41 , 2016 .
[ 5 ] M . Benkert , J . Gudmundsson , F . Hübner , and T . Wolle . Reporting flock patterns . In ESA , pages 660–671 , 2006 .
[ 6 ] B . Boden , S . Günnemann , H . Hoffmann , and T . Seidl . Mining coherent subgraphs in multi layer graphs with edge labels . In KDD , pages 1258–1266 . ACM , 2012 .
[ 7 ] C . Bron and J . Kerbosch . Finding all cliques of an undirected graph
( algorithm 457 ) . Commun . ACM , 16(9):575–576 , 1973 .
[ 8 ] A . Casteigts , P . Flocchini , W . Quattrociocchi , and N . Santoro .
Time varying graphs and dynamic networks . International Journal of Parallel , Emergent and Distributed Systems , 27(5):387–408 , 2012 .
[ 9 ] G . Gallo , M . D . Grigoriadis , and R . E . Tarjan . A fast parametric maximum flow algorithm and applications . SIAM J . Comput . , 18(1):30–55 , 1989 .
[ 10 ] M G Gong , L J Zhang , J J Ma , and L C Jiao . Community detection in dynamic social networks based on multiobjective immune algorithm . Journal of Computer Science and Technology , 27(3):455–467 , 2012 .
[ 11 ] J . Gudmundsson and M . J . van Kreveld . Computing longest duration flocks in trajectory data . In GIS , pages 35–42 , 2006 .
[ 12 ] P . Holme and J . Saramäki . Temporal networks . CoRR , abs/1108.1780 , 2011 .
[ 13 ] H . Jeung , H . T . Shen , and X . Zhou . Convoy queries in spatio temporal databases . In ICDE , pages 1457–1459 , 2008 .
[ 14 ] S . Khuller and B . Saha . On finding dense subgraphs . In ICALP , pages 597–608 , 2009 .
[ 15 ] G . Kossinets , J . M . Kleinberg , and D . J . Watts . The structure of information pathways in a social communication network . In KDD , pages 435–443 , 2008 .
[ 16 ] V . Kostakos . Temporal graphs . Physica A : Statistical Mechanics and its Applications , 388(6):1007–1023 , 2009 .
[ 17 ] V . E . Lee , N . Ruan , R . Jin , and C . C . Aggarwal . A survey of algorithms for dense subgraph discovery . In Managing and Mining Graph Data , pages 303–336 . 2010 .
[ 18 ] Z . Li , B . Ding , J . Han , and R . Kays . Swarm : Mining relaxed temporal moving object clusters . PVLDB , 3(1):723–734 , 2010 .
[ 19 ] Y R Lin , Y . Chi , S . Zhu , H . Sundaram , and B . L . Tseng . Facetnet : a framework for analyzing communities and their evolutions in dynamic networks . In WWW , pages 685–694 . ACM , 2008 .
[ 20 ] G . Liu and L . Wong . Effective pruning techniques for mining quasi cliques . In PKDD , pages 33–49 , 2008 .
[ 21 ] J . Mugan , E . McDermid , A . McGrew , and L . Hitt . Identifying groups of interest through temporal analysis and event response monitoring . In Intelligence and Security Informatics ( ISI ) , 2013 IEEE International Conference on , pages 185–190 . IEEE , 2013 .
[ 22 ] M . Müller Hannemann , F . Schulz , D . Wagner , and C . D . Zaroliagis .
Timetable information : Models and algorithms . In ATMOS , pages 67–90 , 2004 .
[ 23 ] G . L . Nemhauser , L . A . Wolsey , and M . L . Fisher . An analysis of approximations for maximizing submodular set functions i . Mathematical Programming , 14(1):265–294 , 1978 .
[ 24 ] R . K . Pan and J . Saramäki . Path lengths , correlations , and centrality in temporal networks . Phys . Rev . E , 84:016105 , 2011 .
[ 25 ] P . M . Pardalos and S . Rebennack . Computational challenges with cliques , quasi cliques and clique partitions in graphs . In Experimental Algorithms , pages 13–22 . Springer , 2010 .
[ 26 ] J . Pei , D . Jiang , and A . Zhang . On mining cross graph quasi cliques .
In KDD , pages 228–238 , 2005 .
[ 27 ] N . Santoro , W . Quattrociocchi , P . Flocchini , A . Casteigts , and F . Amblard . Time varying graphs and social network analysis : Temporal indicators and metrics . CoRR , abs/1102.0629 , 2011 .
[ 28 ] J . Tang , M . Musolesi , C . Mascolo , and V . Latora . Temporal distance metrics for social network analysis . In WOSN , pages 31–36 , 2009 .
[ 29 ] J . Tang , M . Musolesi , C . Mascolo , and V . Latora . Characterising temporal distance and reachability in mobile and online social networks . Computer Communication Review , 40(1):118–124 , 2010 . [ 30 ] C . E . Tsourakakis , F . Bonchi , A . Gionis , F . Gullo , and M . A . Tsiarli . Denser than the densest subgraph : extracting optimal quasi cliques with quality guarantees . In KDD , pages 104–112 , 2013 .
[ 31 ] J . Wang and J . Cheng . Truss decomposition in massive networks .
PVLDB , 5(9):812–823 , 2012 .
[ 32 ] H . Wu , J . Cheng , S . Huang , Y . Ke , Y . Lu , and Y . Xu . Path problems in temporal graphs . PVLDB , 7(9):721–732 , 2014 .
[ 33 ] J . Xie , M . Chen , and B . K . Szymanski . Labelrankt : Incremental community detection in dynamic networks via label propagation . In Proceedings of the Workshop on Dynamic Networks Management and Mining , pages 25–32 . ACM , 2013 .
[ 34 ] B M B . Xuan , A . Ferreira , and A . Jarry . Computing shortest , fastest , and foremost journeys in dynamic networks . Int . J . Found . Comput . Sci . , 14(2):267–285 , 2003 .
[ 35 ] L . Yuan , L . Qin , X . Lin , L . Chang , and W . Zhang . Diversified top k clique search . In ICDE , pages 387–398 , 2015 .
1974
