Finding Gangs in War from Signed Networks ∗
Lingyang Chu† , Zhefeng Wang‡ , Jian Pei† , Jiannan Wang† ,
Zijin Zhao† and Enhong Chen‡
†Simon Fraser University , Burnaby , Canada
‡University of Science and Technology of China,Hefei , China lca117@sfu.ca , zhefwang@mailustceducn , jpei@cssfuca , jnwang@sfu.ca , zijinz@sfu.ca , cheneh@ustceducn
ABSTRACT Given a signed network where edges are weighted in real number , and positive weights indicate cohesion between vertices and negative weights indicate opposition , we are interested in finding k Oppositive Cohesive Groups ( k OCG ) . Each k OCG is a group of k subgraphs such that ( 1 ) the edges within each subgraph are dense and cohesive ; and ( 2 ) the edges crossing different subgraphs are dense and oppositive . Finding k OCGs is challenging since the subgraphs are often small , there are multiple k OCGs in a large signed network , and many existing dense subgraph extraction methods cannot handle edges of two signs . We model k OCG finding task as a quadratic optimization problem . However , the classical Proximal Gradient method is very costly since it has to use the entire adjacency matrix , which is huge on large networks . Thus , we develop FOCG , an algorithm that is two orders of magnitudes faster than the Proximal Gradient method . The main idea is to only search in small subgraphs and thus avoids using a major portion of the adjacency matrix . Our experimental results on synthetic and real data sets as well as a case study clearly demonstrate the effectiveness and efficiency of our method .
1 .
INTRODUCTION
The US presidential primaries and then the US presidential election of 2016 are foreordained a hot topic in social media this year . In the process of social media analysis , to zoom in , it is interesting to find several groups of individuals in an active social network , such as Facebook and Twitter , so that within each group the individuals are of the same mind while different groups have very different opinions . We call such a data mining problem finding gangs in war .
∗This research is supported in part by an NSERC Discovery grant , the Canada Research Chair program , and a sponsored research grant from Huawei Technologies Co . Ltd . All opinions , findings , conclusions and recommendations in this paper are those of the authors and do not necessarily reflect the views of the funding agencies .
KDD ’16 , August 13 17 , 2016 , San Francisco , CA , USA cfl 2016 ACM . ISBN 978 1 4503 4232 2/16/08 . . . $15.00 DOI : http://dxdoiorg/101145/29396722939855
Technically , we assume a signed network where edges between vertices are either cohesive or oppositive . A real number as the weight can be associated with each edge to model the strength of the cohesion ( a positive weight ) or opposition ( a negative weight ) [ 23 ] . Given a signed network , finding gangs in war tries to find a set of subgraphs such that within each subgraph edges are dense and cohesive , and the edges crossing different subgraphs are dense and oppositive . Finding gangs in war is a useful exercise that enjoys many interesting application scenarios . For example , the international relationships between countries can be modeled as a signed network [ 1 ] , where each vertex represents a country . Friendly countries are connected by cohesive edges and hostile countries are connected by oppositive edges . Finding gangs in war in this network reveals hostile groups of allied forces , such as the Allied and Axis power during World War II . Social opinion networks with cohesive and oppositive relationships are well studied [ 9 ] , where each vertex represents a user , a cohesive edge indicates a cohesive relationship and an oppositive edge represents an oppositive relationship . Finding gangs in war from such signed networks discovers multiple groups of friends with strong inter group enmity , such as the rival groups of voters that support different political leaders . Interestingly , finding gangs in war can be used in applications well beyond social networks . For example , the network of adjectives in the WordNet database [ 16 ] is also a signed network , where each vertex represents an adjective , the synonyms are connected by cohesive edges and the antonyms are connected by oppositive edges . From this signed network , finding gangs in war can identify groups of synonyms that are antonymous with each other , which will be further demonstrated in Section 56
As to be reviewed in Section 2 , there are established methods for signed network partitioning , antagonistic community mining and dense subgraph finding . Can we adapt the existing methods to tackle the problem of finding gangs in war from signed networks ? Unfortunately , the answer is no due to the following unique challenges .
First , the “ gangs in war ” are typically small groups and are hard to be located . Most vertices and edges in a network may not even participate in a “ gang in war ” . Although there are many existing methods on partitioning signed networks so that each partition is relatively cohesive [ 3 , 11 ] , those methods cannot find needles from a haystack – they cannot find small groups of dense cohesive subgraphs effectively .
Second , there often exist multiple groups of “ gangs ” in war , such as multiple groups of synonym adjectives that are antonymous group wise . Existing signed network partitioning methods are not able to find alternative partitionings .
1505 Third , there may be more than two “ gangs in war ” , such as the multiple groups of voters supporting different presidential candidates . The existing antagonistic community mining methods are not able to detect the community containing more than two “ gangs ” .
Last but not least , the signed edge weights create a huge challenge for the existing dense subgraph detection methods . To the best of our knowledge , the existing dense subgraph extraction methods only consider edges of the same sign and cannot distinguish edges of two signs . The well defined concepts and algorithms for dense subgraph detection on unsigned networks [ 23 ] no longer hold in signed networks .
In this paper , we tackle the novel problem of finding gangs in war from signed networks . We make several contributions . First , we formulate the problem of finding gangs in war as finding k Oppositive Cohesive Groups ( k OCG ) . A k OCG is a set of k subgraphs such that each subgraph is cohesive , that is , having high intra subgraph cohesion , and the subgraphs are oppositive to each other , that is , among the subgraphs there is a high inter subgraph opposition . We model the problem as a constrained quadratic optimization problem .
Second , we show that the classical Proximal Gradient method ( PG ) [ 18 ] is very costly in finding k OCGs on large signed networks , since it has to use the entire adjacency matrix . We develop a two phase iterative method FOCG that is experimentally two orders of magnitudes faster than PG on average . The key idea is that FOCG confines the search in small subgraphs instead of the whole graph so that it only uses small sub matrices of the adjacency matrix . Specifically , FOCG iteratively conducts a locate phase and an update phase . The locate phase increases the intra subgraph cohesion and inter subgraph opposition of a subgraph by removing weak vertices that contribute little to the cohesion and opposition . The update phase further increases the cohesion and opposition of the small subgraph by adding new vertices that contribute more to the objective .
Third , we report an extensive experimental study on both synthetic and real world data sets . The results clearly show that our method is accurate , efficient and scalable in finding k OCGs . We also conduct a case study on the adjective network sampled from the WordNet database [ 16 ] , where the detected k OCGs accurately identify significant groups of synonyms that are antonymous with each other .
2 . RELATED WORK
To the best of our knowledge , finding k OCGs in general is a new problem that has not been touched in literature . It is related to the problems of signed network partitioning , antagonistic community mining , and dense subgraph extraction on unsigned networks .
2.1 Signed Network Partition
The signed network partitioning methods partition a signed network into several cohesive subgraphs . The partitioning problem is often transformed into a traditional data clustering problem and solved with classic techniques .
Spectral clustering is one of the most widely adopted techniques . Kunegis et al . [ 10 ] proposed the signed Laplacian matrix for signed networks . Performing classic spectral clustering algorithms [ 26 ] with such signed Laplacian matrix results in subgraphs with only cohesive edges . However , Kunegis ’s Laplacian matrix [ 10 ] tends to separate vertices connected by oppositive edges rather than group vertices connected by cohesive edges . To solve this problem ,
Zheng et al . [ 31 ] proposed the balanced normalized signed Laplacian matrix .
As an alternative approach , Doreian et al . [ 6 ] first defined the objective function for signed network partitioning as E = αNn + ( 1 − α)Np , where Np is the number of cohesive edges between subgraphs and Nn is the number of oppositive edges within subgraphs . Many methods attempt to partition a signed network by minimizing Doreian ’s objective function E . For example , Traag et al . [ 24 ] used simulated annealing , and Liu et al . [ 11 ] applied the k balanced social theory to solve a similar optimization problem .
All the signed network partitioning methods partition the entire signed network . However , in real applications , significant k OCGs always exist in small local regions of a large and sparse signed network . Such local regions are not known beforehand . Thus , partitioning the entire signed network cannot effectively find significant k OCGs .
2.2 Antagonistic Community Mining
The antagonistic community mining methods [ 29 , 15 , 14 , 30 , 7 ] aim to find two cohesive communities that are antagonistic against each other . This can be regarded as a special case where there are two “ gangs ” in war .
There are generally two categories of such methods . The direct methods [ 15 , 14 , 7 ] mine antagonistic communities directly from signed networks . The indirect methods [ 29 , 30 ] take a transaction database of user ratings as the input and detect antagonistic communities using frequent patterns . Both the direct and indirect methods cannot be straightforwardly extended to find more than two communities that are antagonistic against each other .
2.3 Dense Subgraph Extraction
The dense subgraph finding problem on unsigned network has been well investigated [ 25 , 5 ] . Motzkin et al . [ 17 ] formulated the dense subgraph seeking problem on an un weighted graph as a quadratic optimization problem on the simplex . Pavan et al . [ 19 ] extended the method by Motzkin et al . to weighted graphs by reformulating the dense subgraph detection problem as a standard quadratic optimization ( StQP ) problem and solved it using the Dominant Set ( DS ) method [ 19 ] . According to Bul`o et al . [ 2 ] , the time complexity of DS is O(n2 ) for a graph of n vertices . Bul`o et al . [ 2 ] also proposed a more efficient method , Infection Immunization Dynamics ( IID ) , to solve the StQP problem [ 19 ] .
Both DS and IID search an entire weighted graph . Liu et al . [ 13 , 12 ] discovered that most dense subgraphs exist in local regions . By leveraging such locality property of dense subgraphs , Liu et al . [ 13 , 12 ] efficiently solved the StQP problem by searching only small subgraphs .
All these methods find dense subgraphs on unsigned graphs by seeking the local maximums of the StQP problem [ 19 ] . However , due to the existence of oppositive edges , the StQP problem [ 19 ] becomes undefined on signed networks . As a result , existing dense subgraph detection methods cannot be straightforwardly extended to solve the kOCG detection problem on signed networks .
3 . PROBLEM FORMULATION
In this paper , we use bold lower case characters ( eg , x , y , e ) and upper case characters with subscript ( eg , Xj , Xh , Xl ) to represent column vectors . Upper case characters ( eg , X , M , E ) are used to represent matrices , sets or graphs . Some frequently used notations are summarized in Table 1 .
1506 Table 1 : Frequently used notations .
Notation
Description
U S
S
X
X ∗ X ∗ j ˆXj ˆSj
1 , S∗
2 , , S∗
The universal index set of all vertices . A k subgraph set . S = {S1 , S2 , , Sk} , Si is the i th subgraph . A set of k OCGs . S = {S∗ i th k OCG . An n by k dimensional matrix that represents a k subgraph set . A KKT point of F ( X ) on graph G . A KKT point of f ( Xj ) on graph G . A KKT point of f ( Xj ) on subgraph Sj . The subgraph induced from ˆXj . i is the p } , S∗
A signed graph is a triple G = ( V , E , A ) , where V = {v1 , . . . , vn} is a set of n vertices , E = {(vi , vj ) | i , j ∈ [ 1 , n]} is a set of edges , and A is an n by n signed adjacency matrix that describes the relationship between vertices . The entry Ai,j at the i th row and the j th column of A is positive if ( vi , vj ) is a cohesive edge , negative if ( vi , vj ) is an oppositive edge , and 0 otherwise . The absolute value |Ai,j| measures the strength of the cohesion or opposition .
The signed network adjacency matrix A can be rewritten into A = A+ − A− . A+ is the cohesion network and is composed of all cohesive edges in A , that is , A+ i,j = max ( Ai,j , 0 ) . A− is the opposition network , where A− i,j = | min ( Ai,j , 0)| . Let U = {1 , . . . , n} be the universal index set of all vertices in the set of vertices V . From any index subset S ⊂ U , we can induce a subgraph GS = {VS , ES , AS} , where VS = {vi | i ∈ S} , ES = {(vi , vj ) | i , j ∈ S} , and AS = [ Ai,j | i , j ∈ S ] is the signed adjacency matrix that describes the relationship between each pair of vertices in VS .
A common way to represent a subgraph GS is to associate it with a non negatively valued n dimensional column vector x = [ x1 , x2 , . . . , xn ] in the standard simplex △n , where the i th dimension xi indicates the participation of vertex vi in GS , that is , the weight of vertex vi in GS , and simplex i=1 xi = 1 , xi ≥ 0} . Particularly , if xi = 0 , vertex vi does not belong to GS . If xi > 0 , vi participates in GS . Given GS and its vector representation x , we can immediately have the set of indexes of the vertices in GS as S = {i ∈ U | xi > 0} . In the rest of the paper , we refer to a subgraph by the vector representation x and the set of indexes of vertices S interchangeably .
△n = {x | Pn
We are interested in finding k oppositive cohesive groups ( k OCG ) , where each cohesive group is a dense subgraph dominated by cohesive edges and thus has high intrasubgraph cohesion . At the same time , among the groups there are dense oppositive edges and thus the k OCG as a set has high inter subgraph opposition .
To model a k OCG , we introduce the notion of k subgraph set , denoted by S = {S1 , S2 , , Sk} , which is a set of k subgraphs . We represent each subgraph Sj ∈ S ( 1 ≤ j ≤ k ) by an n dimensional column vector Xj ∈ △n . Consequently , we represent S by an n by k dimensional matrix X where the j th column Xj ∈ △n represents subgraph Sj . Obviously , we have Sj = {i ∈ U | Xi,j > 0} , where Xi,j is the entry at the i th row and the j th column of matrix X .
Pavan et al . [ 19 ] proposed a widely used measure for intra subgraph cohesion . For subgraph x ∈ △n , define g+(x ) = x⊤A+x = n n
Xi=1
Xj=1 xixj A+ i,j
( 1 ) i=1 xi = 1 as x ∈ △n , Equation 1 is the weighted average of cohesive edge weights in subgraph x .
Since Pn
Similarly , we can measure the weighted average of oppos itive edge weights between two subgraphs x and y by g−(x , y ) = x⊤A−y = n n
Xi=1
Xj=1 xiyj A− i,j
We can further define the intra subgraph cohesion of a kOCG S as the sum of all intra subgraph cohesion of each Sj ∈ S , that is , g+(S ) = k
Xj=1 g+(Xj ) = tr(X ⊤A+X ) where tr(· ) is the trace operator .
We can further define the inter subgraph opposition of S as the sum of the inter subgraph opposition for each pair of subgraphs in S , that is , g−(S ) =Xh6=j g−(Xh , Xj ) = tr(X ⊤A−X ) where tr(M ) is the complementary trace that sums up all non diagonal entries of matrix M , that is , tr(M ) = It can be verified that tr(M1 ) ± tr(M2 ) =
Pi6=j Mi,j . tr(M1 ± M2 ) .
A k oppositive cohesive groups ( k OCG ) is a k subgraph set that has a large intra subgraph cohesion g+(S ) and a large inter subgraph opposition g−(S ) . Accordingly , we define the k OCG detection problem as max
F ( X )
X∈△n×k F ( X ) = g+(S ) + αg−(S ) − βtr(X ⊤X )
( 2 )
= tr(X ⊤A+X ) + tr(X ⊤HX ) where H = ( αA− − βI ) , I is the identify matrix , parameter α > 0 controls the tradeoff between intra subgraph cohesion and inter subgraph opposition , and the term βtr(X ⊤X ) penalizes the overlap between different cohesive subgraphs .
Every local maximum of F ( X ) corresponds to a k OCG in graph G . However , not all local maximums are of the same significance . More often than not , in real applications we want to find the significant k OCGs of large intra subgraph cohesion and inter subgraph opposition . Such significant kOCGs are induced by the local maximums with large values of F ( X ) . Since every local maximum of F ( X ) satisfies the Karush Kuhn Tucker ( KKT ) conditions [ 8 ] , every KKT point X ∗ of F ( X ) is a potential local maximum of F ( X ) . In the rest of the paper , we focus on detecting significant kOCGs by seeking the KKT points with large F ( X ∗ ) values . The problem in Equation 2 is a constrained optimization problem that can be solved by classic numerical optimization methods , such as Proximal Gradient method ( PG ) [ 18 ] . However , the classic numerical optimization methods generally operate with the entire adjacency matrix A and often involves the computationally expensive gradient calculation . Therefore , when graph G is large , A is large . The classic numerical optimization methods are not efficient in solving the problem in Equation 2 on large graphs .
Since k OCGs usually exist in small local regions of a signed network , a lot of information carried by A is redundant and we can accurately and efficiently find a k OCG using only small submatrices of A without calculating the
1507 gradient . Next , we propose the FOCG algorithm that solves the problem in Equation 2 by iteratively seeking the KKT points [ 8 ] of F ( X ) , and achieves high efficiency by confining all iterations on small subgraphs .
4 . THE FOCG ALGORITHM
We first re organize Equation 2 . For any j ∈ [ 1 , k ] ,
F ( X ) = f ( Xj ) +Xh6=j
X ⊤ h A+Xh +Xl6=j Xh6=j h6=l
X ⊤ l HXh
( 3 ) j HXh consists of all where f ( Xj ) = X ⊤ the terms in F ( X ) that are related with Xj . j A+Xj + 2Ph6=j X ⊤
According to Equation 3 , when the other columns of X ( ie , {Xh | h 6= j , h ∈ [ 1 , k]} ) are fixed , we can monotonically increase the value of F ( X ) by maximizing f ( Xj ) on variable Xj . Thus , we can find the KKT points of F ( X ) by optimizing f ( Xj ) on each column of X ( ie , {Xj ∈ △n | j ∈ [ 1 , k]} ) . The corresponding optimization problem is max Xj ∈△n f ( Xj )
( 4 ) where f ( Xj ) = X ⊤ is an n dimensional column vector . j A+Xj + 2X ⊤ j Mj and Mj = Ph6=j HXh
The first term X ⊤ j A+Xj of f ( Xj ) in Equation 4 is the intra subgraph cohesion of subgraph Sj . This term is exactly the objective function of the dense subgraph seeking methods [ 19 , 13 , 12 ] . To understand the second term in Equation 4 , we notice the following . First , since H = ( αA− −βI ) , we have Hi,l = αA− i,l when i 6= l . Thus , Hi,l ( i 6= l ) represents the opposition between vertices vi and vl . Second , we Hi,lXl,h . Since Xl,h is the weight of vertex vl in subgraph Sh , ( HXh)i represents the average opposition between vertex vi and all rewrite the i th entry of HXh to ( HXh)i =Pl∈Sh the vertices in subgraph Sh . Then , since Mj =Ph6=j HXh , the i th entry of Mj can be written as Mi,j =Ph6=j(HXh)i , which is the sum of the average opposition between vertex vi and all the ( k − 1 ) subgraphs in S \ Sj = {Sh ∈ S | h 6= j} . By expanding the second term of f ( Xj ) 2X ⊤ j Mj is the weighted average opposition between all the vertices of subgraph Sj and all the other subgraphs in S \ Sj . j Mj = 2Pi∈Sj
Xi,jMi,j , we can see that 2X ⊤
Next , we illustrate how to efficiently find a k OCG by seeking a KKT point X ∗ of F ( X ) . In Section 4.1 , we prove that we can find X ∗ by seeking the KKT points X ∗ for j all j ∈ [ 1 , k ] . Section 4.2 introduces the LUA method that efficiently finds X ∗ j of f ( Xj ) by searches in small subgraphs . Section 4.3 summarizes the FOCG method , which finds a KKT point X ∗ of F ( X ) by seeking X ∗ j for all j ∈ [ 1 , k ] with LUA . We also introduce the initialization method IOCG and illustrate how to select significant k OCGs .
4.1 KKT Points
The following result establishes the relation between a KKT point of F ( X ) and the KKT points of f ( Xj ) , j ∈ [ 1 , k ] . Therefore , finding the KKT points of f ( Xj ) for all j ∈ [ 1 , k ] can be used to find KKT points of F ( X ) .
Theorem 1 . X ∗ ∈ △n×k is a KKT point of F ( X ) if and only if ∀j ∈ [ 1 , k ] , X ∗ j is a KKT point of f ( Xj ) .
Proof sketch . We prove here only the biconditional logical connectivity with respect to the stationarity condition of KKT conditions . The proof on the biconditional logical connectivity with respect to the primal feasibility , dural feasibility and complementary slackness is straightforward and thus is omitted for the interest of space .
For X and Xj , since X ∈ △n×k = {X | Xj ∈ △n , j ∈ i=1 Xi,j = 1 , Xi,j ≥ 0} , the Lagrange functions of F ( X ) and f ( Xj ) can be written to Equations 5 and 6 , respectively . k n
R(X ) =
LF ( X , µ , λ ) = F ( X ) + R(X )
[ 1 , k]} and Xj ∈ △n = {Xj | Pn    
µi,j Xi,j − λj(
µi,j Xi,j −
Xj=1
Xi=1
Xi=1 r(Xj ) =
Xi=1
Xj=1 n n k
Lf ( Xj , µj , λj ) = f ( Xj ) + r(Xj )
λj( n
Xi=1
Xi,j − 1 )
Xi,j − 1 )
( 5 )
( 6 ) where µ , λ , µj and λj are Lagrangian multipliers , µj is the j th column of the n by k dimensional matrix µ , and λj is the j th element of the k dimensional vector λ . Apparently ,
R(X ) =Pk j=1 r(Xj ) .
Denote by ∇X LF the gradient of LF ( X , µ , λ ) , which is an n by k dimensional matrix . ( ∇X LF )j is the j th column of ∇X LF . We have
( ∇X LF )j = ∇Xj F ( X ) + ∇Xj R(X )
( 7 ) where ∇Xj is the gradient operator over variable Xj .
According to Equation 3 , we have ∇Xj F ( X ) = ∇Xj f ( Xj ) . j=1 r(Xj ) , we have ∇Xj R(X ) = ∇Xj r(Xj ) . By substituting the above two equations into Equation 7 , we have
Since R(X ) = Pk
( ∇X LF )j = ∇Xj f ( Xj ) + ∇Xj r(Xj ) = ∇Xj Lf
( 8 ) where ∇Xj Lf is the gradient of Lf ( Xj , µj , λj ) .
Sufficiency . If X ∗ is a KKT point , then ∇X ∗ LF = 0 . Lf = 0 , ∀j ∈ [ 1 , k ] ,
According to Equation 8 , we have ∇X ∗ thus the stationarity condition holds for each f ( X ∗
Necessity . If ∀j ∈ [ 1 , k ] , X ∗ then we have ∇X ∗ 0 . Therefore , the stationarity condition holds for F ( X ∗ ) . j is a KKT point of f ( Xj ) , Lf = 0 for all j ∈ [ 1 , k ] . Thus , ∇X ∗ LF = j ) . j j
Theorem 2 . X ∗ j ∈ △n is a KKT point of f ( Xj ) if and only if
Ri(X ∗ j )(= Q(X ∗ j ) ≤ Q(X ∗ j ) if i ∈ S∗ j if i ∈ U \ S∗ j
( 9 ) where S∗ X ∗ j , Ri(X ∗ and ( A+X ∗ j = {i ∈ U | X ∗ i,j > 0} is the subgraph induced from j )i + Mi,j , Q(X ∗ j ) = ( A+X ∗ j ) = ( X ∗ j ) , j )i is the i th entry of A+X ∗ j . j )⊤R(X ∗
Proof . A KKT point X ∗ conditions : ( 1 ) Stationarity : 2(A+X ∗ j of f ( Xj ) must satisfy the KKT j )i +2Mi,j + µi,j − λj =
0 , ∀i ∈ [ 1 , n ] ; ( 2 ) Complementary slackness :
µi,j X ∗ i,j = 0 ;
( 3 ) Dual feasibility : µi,j ≥ 0 , ∀i ∈ [ 1 , n ] ; and ( 4 ) Primal feasibility : X ∗ i,j ≥ 0 , ∀i ∈ [ 1 , n ] and i,j = 1 . Note that ,
X ∗ n the primal feasibility trivially holds , since X ∗ j ∈ △n .
Sufficiency . If X ∗ j is a KKT point , then X ∗ j satisfies all the above KKT conditions . Considering Xi,j and µi,j are non negative for all i ∈ [ 1 , n ] , the complementary slackness condition can be rewritten as ∀i ∈ [ 1 , n ] , if X ∗ i,j > 0 , then µi,j = 0
( 10 )
Pi=1 n
Pi=1
1508 Since X ∗ i,j > 0 means i ∈ S∗ j , we transform Equation 10 into
∀i ∈ [ 1 , n ] , if i ∈ S∗ j , then µi,j = 0
( 11 )
By doing simple calculations on both Equation 11 and the stationary condition , we can rewrite the KKT conditions as
Ri(X ∗ j )( = λj
2 ≤ λj 2 if if i ∈ S∗ j i ∈ U \ S∗ j
( 12 ) which indicates Ri(X ∗ j ) = λj
2 , for all i ∈ S∗ j . j
Since Pi∈S∗ Pi∈S∗
X ∗ j i,j Ri(X ∗ we have Equation 9 .
X ∗ i,j = 1 , we have Q(X ∗ j ) = λj
2 . Plugging this into Equation 12 , j ) = ( X ∗ j )⊤R(X ∗ j ) =
Necessity . If Eqnation 9 holds , then there always exists a set of Lagrangian multipliers µi,j , i ∈ [ 1 , n ] and λj as follows that make the KKT conditions hold .
µi,j =(0
λj − 2Ri(X ∗ j ) if i ∈ S∗ j if i ∈ U \ S∗ j where λj = 2Q(X ∗ conditions and thus is a KTT point of f ( Xj ) . j ) . This means that X ∗ j satisfies the KKT
For Ri(X ∗ j ) in Equation 9 , the first term ( A+X ∗ j )i is the average cohesion between vertex vi and all vertices in subgraph S∗ j , and captures the contribution from vertex vi to the intra subgraph cohesion of S∗ j . The second term Mi,j is the average opposition between vi and the vertices of the other ( k − 1 ) subgraphs in S \ S∗ j , and captures the contribution from vi to the inter subgraph opposition between S∗ j ) measures the contribution from vi to both the intra subgraph j . For Q(X ∗ cohesion and inter subgraph opposition of S∗ j ) in the same equation , since Q(X ∗ j ) = ( X ∗ j )⊤R(X ∗ j ) = j ) is the weighted j and the other subgraphs in S \ S∗ j ) , we know that Q(X ∗ j . Thus , Ri(X ∗ i,j Ri(X ∗
X ∗ average contribution from all vertices in S∗ j .
Theorem 2 indicates that , for a KKT point X ∗ j ) by each vertex vi inside subgraph S∗ tribution Ri(X ∗ equal to the average contribution Q(X ∗ the contribution Ri(X ∗ S∗ j , the conj is j . Moreover , j ) by each vertex vi outside subgraph j ) by S∗ j . j satisfying the KKT conditions in Equation 9 is a KKT point of f ( Xj ) in graph G . Thus , any ˆXj ∈ △n is a KKT point in subgraph Sj if j is not larger than the average contribution Q(X ∗ According to Theorem 2 , any point X ∗ j ) by S∗
Pi∈S∗ j
Ri( ˆXj)(= Q( ˆXj )
≤ Q( ˆXj ) if i ∈ ˆSj if i ∈ Sj \ ˆSj
( 13 ) where ˆSj = {i ∈ U | ˆXi,j > 0} is a subset of Sj .
Apparently , a KKT point ˆXj on Sj induces a subgraph ˆSj ⊂ Sj , where no vertex vi in Sj \ ˆSj has a larger contribution Ri( ˆXj ) than the average contribution Q( ˆXj ) . However , since Sj \ ˆSj is not equal to U \ S∗ j , a KKT point in subgraph Sj is not necessarily a KKT point in graph G . Therefore , we further explore the relationship between a KKT point in subgraph Sj and a KKT point in graph G as follows .
Corollary 21 If ˆXj is a KKT point of f ( Xj ) in subgraph Sj , then ˆXj is a KKT point of f ( Xj ) in graph G if and only if Ωj = {i ∈ U \ ˆSj | Ri( ˆXj ) > Q( ˆXj)} = ∅ .
Proof . ( Sufficiency . ) If Ωj = ∅ , then ˆXj also satisfies the KKT conditions in graph G ( ie , Equation 9 ) , thus ˆXj is also a KKT point in graph G .
( Necessity . ) Ωj 6= ∅ indicates the KKT conditions in graph G do not hold for ˆXj , which means ˆXj is not a KKT point in graph G .
Ωj contains all the vertices that are outside subgraph ˆSj and contribute more cohesion and opposition to ˆSj than the average contribution Q( ˆXj ) . Adding the vertices in Ωj into subgraph ˆSj can further increase the average cohesion and opposition of ˆSj , thus can increase the value of f ( ˆXj ) .
In summary , a KKT point of f ( Xj ) corresponds to a potential dense subgraph S∗ j that possesses both large intrasubgraph cohesion within itself and large inter subgraph opposition with the other subgraphs in S \ S∗ j . Since a dense subgraph usually consists of small subsets of vertices [ 13 ] , the size of S∗ j is a KKT point of G . Based on this insight , we propose the Locate and Update Algorithm next , which finds KKT points of graph G by constraining searches in small subgraphs . j is usually small if X ∗
4.2 The Locate and Update Algorithm ( LUA ) In this section , we introduce the Locate and Update Algorithm ( LUA ) that efficiently finds a KKT point of f ( Xj ) in graph G . The key to the efficiency of LUA is that it always works on a small subgraph Sj and iteratively updates Sj until a KKT point in graph G is found .
We first transform the problem in Equation 4 into the following standard form of dense subgraph seeking problem max Xj ∈△n f ( Xj )
( 14 ) j + Mje⊤ is where f ( Xj ) = X ⊤ an n by n dimensional matrix . e is a column vector with all entries equal to 1 . j Bj Xj and Bj = A+ + eM ⊤
When matrix Bj is given , there are many existing dense subgraph seeking algorithms [ 19 , 2 , 13 ] that can be used to solve the problem in Equation 14 . However , since matrix Bj is not sparse , it is hard to calculate and store Bj when graph G is large . Without materializing Bj , we cannot solve the problem in Equation 14 by a simple extension of the existing dense subgraph seeking algorithms [ 19 , 2 , 13 ] .
To tackle this problem , we design the LUA algorithm , which effectively avoids computing the entire matrix Bj by confining computation in small subgraphs . LUA iteratively conducts a locate phase and an update phase . The locate phase locates a KKT point ˆXj in subgraph Sj and reduces Sj into its subgraph ˆSj . The update phase updates subgraph ˆSj by taking more vertices in Ωj whose contribution Ri( ˆXj ) to the intra subgraph cohesion and inter subgraph opposition of subgraph ˆSj is larger than the average contribution Q( ˆXj ) . The iteration continues until Ωj = ∅ . According to Corollary 2.1 , ˆXj is also a KKT point in graph G . Next , we discuss the details of LUA .
421 The Locate Phase
The locate phase locates a KKT point ˆXj in subgraph Sj and reduces Sj into its subgraph ˆSj = {i ∈ U | ˆXi,j > 0} .
Given an initialization of Xj(0 ) that is obtained by a heuristic method to be discussed in Algorithm 3 , the locate phase finds a KKT point ˆXj in subgraph Sj by the Replicator Dynamics ( RD ) iteration [ 27 ] . At the t th iteration ,
Xi,j(t + 1 ) = Xi,j(t )
( Bj Xj(t))i
Xj(t)⊤Bj Xj(t )
( 15 )
1509 where ( Bj Xj(t))i is the i th entry of the n dimensional vector Bj Xj(t ) . According to [ 27 ] , the iterations converge to ˆXj . The resulting subgraph is ˆSj .
A nice property of Equation 15 is that , if Xi,j(t ) = 0 , then Xi,j(t + 1 ) = 0 . Thus , we can confine all computation of Equation 15 within subgraph Sj by initializing Xj(0 ) as Xj(0 ) = {Xi,j >0 | i ∈ Sj} . Since ∀i 6∈ Sj , Xi,j(t ) = 0 , we only need to calculate and store a sub matrix BSj of Bj that corresponds to the edge set ESj of subgraph Sj .
The locate phase efficiently finds a KKT point ˆXj of subgraph Sj and reduces Sj into its subgraph ˆSj . However , according to Corollary 2.1 , ˆXj may not necessarily be a KKT point in graph G . Thus , we use an update phase to further increase the value of f ( ˆXj ) and make sure that LUA converges to a KKT point in graph G .
422 The Update Phase
According to Corollary 2.1 , if Ωj = ∅ , then ˆXj is already a KKT point in graph G , thus the LUA iteration converges . However , if Ωj 6= ∅ , then ˆXj is not a KKT point in graph G . In this case , we update ˆXj with a carefully designed ndimensional vector b and a step size σ , such that f ( ˆXj + tb ) > f ( ˆXj ) under the constraint ( ˆXj + σb ) ∈ △n .
The i th entry of b = [ b1 , . . . , bn ] is defined as
Ri( ˆXj ) − Q( ˆXj ) −s ˆXi,j 0 i ∈ Ωj if i ∈ ˆSj if otherwise
( 16 ) bi =  where s=Pi∈Ωj bi . We know s>0 from the definition of Ωj . According to Corollary 2.1 , if i ∈ Ωj , then the contribution Ri( ˆXj ) of vertex vi is larger than the average contribution Q( ˆXj ) of all vertices in subgraph ˆSj . Adding vi into subgraph ˆSj further increases the intra subgraph cohesion and inter subgraph opposition of ˆSj , thus increases the value of f ( ˆXj ) . Therefore , we set bi = Ri( ˆXj ) − Q( ˆXi ) . In this case , bi assigns a positive weight to the i th entry of ( ˆXj + σb ) , which is equivalent to adding vi into the updated subgraph . is that the constraint s ] due ˆXi,j = 1 , we have ( −s ˆXi,j ) = s − s = 0 , thus s ] and s > 0 , we have ˆXi,j + σbi ≥ 0 , ∀i ∈ [ 1 , n ] . Then , we can derive the optimal step size by maximizing f ( ˆXj + σb ) − f ( ˆXj ) as to the following . First , since Pi∈ ˆSj Pn i=1 bi = Pi∈Ωj Pi( ˆXi,j + σbi ) = 1 . Second , since σ ∈ [ 0 , 1
( ˆXj + σb ) ∈ △n always holds for all σ ∈ [ 0 , 1 bi + Pi∈ ˆSj
Another useful property of bi f ( ˆXj + σb ) − f ( ˆXj ) = b⊤A+bσ2 + 2b⊤(A+ ˆXj + Mj)σ
= b⊤A+bσ2 + 2(Xi∈Ωj b2 i )σ
( 17 ) b2 i > 0 . Thus , the optimal step size σ∗ is
When Ωj 6= ∅ , we have Pi∈Ωj σ∗ =  min 1
Pi∈Ωj s , −
1 s if b⊤A+b ≥ 0 b2 i b⊤A+ b if b⊤A+b < 0 j of f ( Xj ) in graph G .
Algorithm 1 : The Locate and Update Iteration Input : Xj(0 ) ∈ △n . Output : A KKT point X ∗ 1 : Set ˆXj = Xj(0 ) and update Ωj . 2 : repeat 3 : 4 : 5 : 6 :
Update phase : Xj ← ( ˆXj + σ∗b ) . if Ωj 6= ∅ then end if Locate phase : Start from Xj and find a KKT point ˆXj in subgraph Sj using Equation 15 . Update Ωj = {i ∈ U \ ˆSj | Ri( ˆXj ) > Q( ˆXj)} .
7 : 8 : until Ωj = ∅ . 9 : X ∗ 10 : return A KKT point X ∗ j ← ˆXj . j of f ( Xj ) in graph G .
Algorithm 2 : The FOCG Algorithm Input : X(0 ) ∈ △n×k . Output : A KKT point X ∗ of F ( X ) in graph G . 1 : Set X = X(0 ) . 2 : repeat 3 : 4 :
Find a KKT point X ∗ Algorithm 1 . Update the j th column of X by Xj ← X ∗ j .
5 : 6 : 7 : until ∀j ∈ [ 1 , k ] , a KKT point X ∗ 8 : return a KKT point X ∗ of F ( X ) in graph G . for all j ∈ [ 1 , k ] do end for j of f ( Xj ) in graph G by j of f ( Xj ) is found .
423 The Locate and Update Iteration
Algorithm 1 gives the pseudocode of the LUA algorithm . The main computational cost of LUA lies in the locate phase , whose efficiency is largely affected by the size of subgraph Sj . In real world applications , the graph G is usually very sparse , thus the size of both Ωj and Sj are usually small , which leads to the high efficiency of locate phase . As a result , LUA converges pretty fast on sparse graphs .
We prove the convergence of LUA as follows .
Theorem 3 . The LUA iteration in Algorithm 1 con verges to a KKT point X ∗ j in graph G .
Proof . By setting all entries of Bj to the maximum value in Bj , we can easily obtain a trivial upper bound of f ( Xj ) . In both the locate phase and the update phase , f ( Xj ) monotonously increases , therefore , the LUA iteration converges in the perspective of numeric optimization .
Algorithm 1 converges only when Ωj = ∅ . According to Corollary 2.1 , when LUA converges ( ie , Ωj = ∅ ) , the KKT point ˆXj found in subgraph Sj is a KKT point X ∗ j in G .
4.3 The Complete Algorithm
( 18 )
Algorithm 2 gives the pseudocode of the FOCG algorithm , which finds a KKT point of F ( X ) ( Equation 3 ) by alternatively optimizing f ( Xj ) over each column Xj of X . which guarantees f ( ˆXj + σ∗b ) − f ( ˆXj ) > 0 .
To sum up , when Ωj 6= ∅ , the update phase updates subgraph ˆSj by taking some vertices in Ωj and further increases the value of f ( ˆXj ) .
Theorem 4 . The FOCG algorithm converges to a KKT point X ∗ of graph G .
Proof . We first prove that FOCG converges . According to Equation 3 , increasing f ( Xj ) equivalently increases
1510 Algorithm 3 : The IOCG Algorithm Input : Adjacency matrices of A+ and A− . Output : An initialization X(0 ) for FOCG algorithm .
1 : Initialize the seed index set η = ∅ . 2 : Calculate the vertex degree vector on positive network as d+ = [ d+
1 , d+
2 , , d+ n ] , where d+ j=1 A+ i,j . i =Pn
3 : Select the first seed h1 = Roul(d+ ) by roulette wheel selection [ 20 ] and update η ← η ∪ h1 .
4 : for l ∈ [ 2 , k ] do 5 : i,j . i = 1
1 , , o− i , , o− n ] ,
|η| Pj∈η A−
Calculate opposition vector o− = [ o− where o− Select seed by hl = Roul(o− ) and update η ← η ∪ hl .
6 : 7 : end for 8 : Initialize X as a n by k dimensional all zero matrix . 9 : for j ∈ [ 1 , k ] do 10 : 11 : end for 12 : return X(0 ) ← X .
Set Xηj ,j = 1 , where ηj is the j th seed index in η .
F ( X ) . Since for each iteration in FOCG , the LUA algorithm monotonously increases f ( Xj ) , the value of F ( X ) is monotonously increased as well . Due to the fact that F ( X ) has an upper bound , the FOCG algorithm converges . The FOCG algorithm does not terminate until X ∗ j is a KKT point of f ( Xj ) for all j ∈ [ 1 , k ] . The reason is that , if there exist an X ∗ j that is not a KKT point of f ( Xj ) , then F ( X ) can be further increased by LUA . Since FOCG converges when all X ∗ j ( j ∈ [ 1 , k ] ) are KKT points of f ( Xj ) , according to Theorem 1 , X ∗ is a KKT point of graph G .
For Algorithm 2 , a proper initialization of X(0 ) usually improves the possibility of getting a KKT point X ∗ with large value of F ( X ∗ ) . Here , we propose an initialization method IOCG ( Algorithm 3 ) for the initialization of X(0 ) . IOCG randomly selects k seed vertices as the initializations for the k subgraphs Si ( 1 ≤ i ≤ k ) in S . The first seed is selected according to the degree of each vertex on network A+ . The roulette wheel selection method [ 20 ] h = Roul(d+ ) randomly selects a vertex vh with probability , thus the vertices with larger degrees are more likely to be selected . Heuristically , a vertex with a large degree in network A+ is more likely to be a member of a dense subgraph . The other ( k − 1 ) seed vertices are selected under the criterion that the opposition between seed vertices should be large . Such seed vertices are more likely to belong to different dense subgraphs such that the group of subgraphs in whole possesses a large inter subgraph opposition . As a result , IOCG provides a good start point for FOCG to detect a KKT point X ∗ with large value of F ( X ∗ ) . Such a KKT point often corresponds to a significant k OCG S ∗ = {S∗ j | j ∈ [ 1 , k]} , where S∗ j is the subgraph induced by X ∗ j . dh i=1 di
Pn
Let ψ be the set of all KKT points of F ( X ) . The size of ψ is often very large and it is impractical to compute the entire set . However , in real applications , more often than not we are interested in only the significant k OCGs of large value of F ( X ) . Similar to most dense subgraph detection methods , we adopt the “ peeling off ” method [ 19 , 13 , 5 ] . Due to its simplicity and robustness , such a “ peeling off ” method is widely used in the task of dense subgraph detection to enumerate the set of KKT points .
Specifically in our case , when a KKT point X ∗ is obtained , it is first added into the answer set . Then , we remove the vertices and edges that belong to the corresponding k subgraph set S ∗ from graph G and find another KKT point using a new initialization of X(0 ) . Such a process iterates until all vertices in graph G are removed and a set of KKT points ˆψ is obtained . Then , we can search ˆψ for the significant k OCGs of large value of F ( X ∗ ) .
5 . EXPERIMENTS
[ 31 ] ,
In this section , we evaluate the performance of the proposed FOCG algorithm and compare it with the state ofthe art related signed network partitioning methods including ( 1 ) Simple Normalized Signed Graph Laplacian method ( SNS ) ( 2 ) Signed Normalized Laplacian method ( SNL ) [ 10 ] , ( 3 ) Balance Normalized Cut method ( BNC ) [ 4 ] , and ( 4 ) Ratio Associate method ( RA ) [ 4 ] . Both the SNS and SNL methods are incorporated in the standard spectral clustering framework [ 26 ] to perform the partitioning task on signed network . The codes for BNC and RA were provided by Chiang et al . [ 4 ] . We also compare the scalability of FOCG and the Proximal Gradient method ( PG ) [ 18 ] . We use the default parameters for all compared methods . For FOCG and PG , we set α = 0.9 , β = 50 and k = 10 by default . All experiments are performed using MATLAB . We use a PC with Core i7 3370 CPU ( 3.40GHz ) , 16GB memory , and a 5400 rpm hard drive running Ubuntu 1504 The source code of FOCG is available on GitHub [ 21 ] .
The following five data sets are used . For the directed networks , we symmetrize the adjacency matrix by A = A+A⊤ . Synthetic Data Set . The synthetic data set is generated by the data generation method proposed by Chiang et al . [ 4 ] . We generate four networks with different sparsity . Each network contains 10,000 vertices that form 20 subgraphs .
2
Slashdot Data Set . The public Slashdot data set is from SNAP [ 22 ] . We use the version “ soc sign Slashdot081106 ” , which contains 77,357 vertices and 516,575 edges .
Epinions Data Set . The Epinions data set is a public data set on SNAP [ 22 ] . It is a directed signed network containing 131,828 vertices and 841,372 edges .
Douban Data set . The Douban data set [ 28 ] contains a social network of users and the movie ratings of each user . We build the signed network in three steps . First , we induce a cohesive network G+ = {V , E+} by treating each user as a vertex in vertex set V and their friendships as cohesive edges in edge set E+ . Second , we build an oppositive network G− = {V , E−} by calculating the average movie rating difference between each pair of users . If the difference is greater than 1 , we build an oppositive edge between them . Last , we obtain the signed network G = {V , E} by merging G+ and G− . Since the set of vertices V in G+ and G− are the same , we only merge the set of edges E = E+ ∪ E− . If there are both cohesive edge and oppositive edge between a pair of users , we keep the oppositive edge in G . The network contains 1.59 million vertices and 19.67 million edges .
WordNetAdj Data Set . The WordNetAdj data set is a subset of adjectives sampled from the adjective network of the WordNet database [ 16 ] . It contains 12,883 vertices and 39,460 edges , where each vertex represents an adjective . The edge between a pair of synonyms is cohesive and the edge between a pair of antonyms is oppositive .
5.1 Performance Measures
Let S = {S ∗
1 , S ∗
2 , . . . , S ∗ p } be a set of p detected k OCGs ,
1511 i = {S∗ i,j | j = 1 , . . . , k} is a k OCG and S∗ where S ∗ i,j is a cohesive subgraph in S ∗ i . Let np be the total number of vertices contained by the set of k OCGs S . Apparently , we have np ≤ n , where n is the number of vertices in G .
The intra subgraph cohesion of a single subgraph S∗ i,j is
Cohe(S∗ i,j ) =
1 i,j| ( |S∗
|S∗ i,j| − 1 ) Xh∈S∗ i,j Xl∈S∗ i,j l6=h
A+ h,l is the number of vertices in subgraph S∗ where |S∗ Cohe(S∗ is widely used to measure intra subgraph cohesion [ 25 ] . i,j| i,j ) is the average cohesive edge weight of S∗ i,j . i,j , which
The inter subgraph opposition between two subgraphs i,j and S∗ i,h can be measured by
S∗
M A H
0.6
0.5
0.4
0.3
0.2
0.1
0
Slashdot
Epinions
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 np/n
Figure 1 : Ranked HAM performances on real world data sets . n is the number of vertices in G .
0.25
0.2
0.15
0.1
0.05
M A H
\
O A M
\
C A M
MAC MAO HAM
0.25
0.2
0.15
0.1
0.05
M A H
\
O A M
\
C A M
MAC MAO HAM
Oppo(S∗ i,j , S∗ i,h ) =
1
|S∗ i,j| |S∗ i,h| Xr∈S∗ i,j Xl∈S∗ i,h
A− r,l
0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0
0.2 0.4 0.6 0.8 1.0 1.2 1.4 1.6 1.8 2.0
α
( a ) Slashdot
α
( b ) Epinions
We define the Mean Average Cohesion ( MAC ) as the mean of the average intra subgraph cohesion for all k OCGs in S , that is ,
Figure 2 : The effect of parameter α .
MAC =
1 p p
Xi=1 1 k
Cohe(S∗ i,j)! k
Xj=1
Moreover , the Mean Average Opposition ( MAO ) is the mean of the average inter subgraph opposition for all k OCGs in S , that is ,
  i,h) 
MAO =
1 p p
Xi=1
1 k(k − 1 ) Xj∈[1,k ] Xh∈[1,k ] h6=j
Oppo(S∗ i,j , S∗
Finally , we define Harmonic Mean ( HAM ) as
HAM =
2 × ( MAC · MAO )
MAC + MAO
Mean Average Precision ( MAP ) is only used on the synthetic data set , where the vertex index set for each of the 20 subgraphs is known and used as ground truth . Denote such vertex index set of the j th subgraph as Sgt j , j ∈ [ 1 , 20 ] , we measure the average precision of a single k OCG S ∗ i by
Prec(S ∗ i ) =
1 20
20
Xj=1 and further evaluate MAP by
|S∗ i,j ∩ Sgt j | |S∗ i,j|
MAP =
1 p p
Xi=1
Prec(S ∗ i )
Since all the signed network partitioning methods ( ie , SNS , SNL , BNC and RA ) partition the entire graph G into a single k OCG , the size of S is p = 1 for those methods . For FOCG , the k OCGs in S are obtained by selecting the top p KKT points with large value of F ( X ∗ ) from the set of KKT points ˆψ . Thus , the size of S for FOCG is p > 1 .
Using a small value of p ( eg , p = 10 ) FOCG returns an answer S that contains the top ten k OCGs , which usually achieve very high MAC , MAO and HAM performance . However , for the fairness of the comparison , we set p to a large value so that np = 0.5 × n , which forces FOCG to produce k OCGs covering 50 % of the vertices in graph G .
5.2 Effect of Parameters
We analyze the effect of parameters np and α ( Equation 2 ) of FOCG . To analyze the effect of np , we sort all the KKT points X ∗ in ˆψ in descending order of F ( X ∗ ) , then evaluate the HAM value for each KKT point X ∗ by regarding it as the only k OCG in S . Figure 1 shows the results on the two real data sets with respect to the percentage of vertices in G that are covered by the top p KKT points .
The KKT points ranked on the top ( ie , np n < 0.01 ) achieve very high HAM on both data sets . The HAM decreases and approaches zero when np n ≈ 045 This indicates that about 45 % of the vertices in graph G can form significant k OCGs . Therefore , for the fairness of experiment , we evaluate the performance of FOCG by the average performance of all k OCGs that cover 50 % of the vertices of G , that is , setting np = 0.5 × n .
Figure 2 shows the effect of parameter α on the performances of FOCG . In Equation 2 , α controls the tradeoff between intra subgraph cohesion and inter subgraph opposition . A larger α results in a smaller intra subgraph cohesion thus a lower MAC , and a larger inter subgraph opposition thus a higher MAO . As shown in Figure 2 , the larger α , the smaller MAC and larger MAO . However , when α > 1 , MAC , MAO and HAM all become stable . This indicates that the second term αg−(S ) of Equation 2 dominates F ( X ) when α > 1 , thus the detected k OCGs favor MAO most and do not change much when α increases further . HAM on both data sets becomes stable when α = 0.9 , thus we set α = 0.9 as default in our experiments .
5.3 Effect of Network Sparsity
We analyze the effect of network sparsity using the synthetic data set . The sparsity of the signed network is defined as the percentage of zero entries in the adjacency matrix A . A higher sparsity weakens both the cohesive and oppositive connections between graph vertices , thus decreases both the intra subgraph cohesion and inter subgraph opposition . Thus , in Figure 3(a) (c ) , MAC , MAO and HAM all decrease when the sparsity increases . However , in Figure 3(d ) , MAP of all graph partitioning methods is not sensitive to sparsity . This is because the connectivity of the cohesive network and oppositive network is not affected too much by the sparsity .
1512 C A M
1
0.8
0.6
0.4
0.2
0
O A M
1
0.8
0.6
0.4
0.2
0
0.8
FOCG ( k=20 ) RA , BNC , SNS , SNL . ( k=20 )
0.2
0.4
0.6
Sparsity
FOCG
RA
BNC
SNS
SNL
C A M
0.2
0.1
0 k=2 k=3 k=5 k=7 k=10 k=50
0.4
0.3
0.2
C A M
0.1
0
FOCG
RA
BNC
SNS
SNL k=2 k=3 k=5 k=7 k=10 k=50
0.8
( a ) MAC on Slashdot
( b ) MAC on Epinions
FOCG ( k=20 ) RA , BNC , SNS , SNL . ( k=20 )
0.2
0.4
0.6
Sparsity
( a ) MAC performances
( b ) MAO performances
M A H
1
0.8
0.6
0.4
0.2
0
P A M
1
0.8
0.6
0.4
0.2
0
0.8
FOCG ( k=20 ) RA , BNC , SNS , SNL . ( k=20 )
0.2
0.4
0.6
Sparsity
FOCG ( k=20 ) RA , BNC , SNS , SNL . ( k=20 )
0.2
0.4
0.6
Sparsity
O A M
0.2
0.15
0.1
0.05
0
FOCG
RA
BNC
SNS
SNL k=2 k=3 k=5 k=7 k=10 k=50
O A M
0.2
0.15
0.1
0.05
0
FOCG
RA
BNC
SNS
SNL k=2 k=3 k=5 k=7 k=10 k=50
0.8
( c ) MAO on Slashdot
( d ) MAO on Epinions
( c ) HAM performances
( d ) MAP performances
Figure 3 : The effect of network sparsity .
Thus , the partitioning methods can still accurately find the 20 subgraphs in the ground truth . FOCG achieves the same good performance in MAP as the graph partitioning methods , which means the k OCGs detected by FOCG are also consistent with the ground truth .
In Figure 3(a) (c ) , when the sparsity is 0.2 , SNS , SNL , BNC and RA achieve equivalently good performance as FOCG . This is because when the sparsity is small , the 20 subgraphs of the synthetic data set form a single 20 OCG . Thus , partitioning the entire graph into 20 subgraphs leads to the perfect result . However , when the sparsity increases , the original single k OCG will be scattered into many small k OCGs . In this case , partitioning the entire graph does not effectively obtain such small significant k OCGs , thus the performance of the graph partitioning methods degrades quickly . Nevertheless , FOCG is able to accurately detect such small k OCGs , thus achieves better performance under high sparsity . It is worth noting that real word signed network are often sparse . For example , the network sparsity of Slashdot and Epinions are both larger than 099
5.4 Results on Real Data
We compare the performance of all methods on Slashdot and Epinions . In such real world networks , a k OCG represents k groups of people with strong intra group cohesion and strong inter group opposition . Apparently , the chance of finding k = 50 groups of people with strong intergroup opposition is much smaller than finding k = 2 groups of such people . Thus , it is more difficult to achieve good performance in MAO when k is large . As a result , in Figure 4(c) (d ) , the MAO of FOCG decreases when k increases . Since the real world networks are highly sparse , the entire network cannot form a single significant k OCG . Instead , there are many small sized k OCGs in different local regions . Since FOCG is designed to detect such small significant kOCGs , it achieves much better HAM in Figure 4(e) (f ) .
In Figure 4(a) (b ) , FOCG is not always the best in MAC . In Figure 4(c) (d ) , BNC outperforms FOCG in MAO when k = 7 and k = 5 , respectively . The reason is that the kOCGs in S of FOCG are selected according to the value of F ( X ∗ ) , which leads to a high HAM and a balanced performance of MAC and MAO . Since we are most interested in finding the significant k OCG with both strong intrasubgraph cohesion and strong inter subgraph opposition ,
M A H
0.2
0.15
0.1
0.05
0
FOCG
RA
BNC
SNS
SNL k=2 k=3 k=5 k=7 k=10 k=50
M A H
0.2
0.15
0.1
0.05
0
FOCG
RA
BNC
SNS
SNL k=2 k=3 k=5 k=7 k=10 k=50
( e ) HAM on Slashdot
( f ) HAM on Epinions
Figure 4 : Performances on Slashdot and Epinions . l e u a V e v i t c e b O j
200
150
100
50
0 0
FOCG ( k=10 ) PG ( k=10 )
0.5
1.5 Number of edges
1
4 10
3 10
2 10
1 10
) s d n o c e s ( e m T i
0 10 0
2
7 x 10
FOCG ( k=10 ) PG ( k=10 )
0.5
1.5 Number of edges
1
2
7 x 10
( a ) Objective value
( b ) Running time
Figure 5 : Scalability analysis on Douban data set . a good HAM performance with balanced MAC and MAO guides the objective . Although FOCG may not achieve the best in MAC or MAO , its advantage on HAM is significant in Figure 4(e) (f ) .
5.5 Scalability Analysis
We compare the scalability of FOCG and the Proximal Gradient method ( PG ) [ 18 ] on the Douban data set . We obtain four sub networks from the Douban data set as follows . First , we start a breadth first search ( BFS ) from a randomly picked vertex on the cohesive network G+ until the desired number of vertices are visited . Let S be the set of all vertices visited by the BFS . We use S to induce a cohesive sub network G+ S and an oppositive sub network G− S . Last , we obtain the signed sub network GS by merging the edge sets of G+ S . The number of vertices and that of edges of the 5 networks are listed in Table 2 , where the 5 th network is simply the entire Douban data set .
S and G−
On each of the 5 data sets , we run FOCG and PG 10 times and report the average results . In each run , we randomly initialize X(0 ) by the same initialization method of PG , then run FOCG and PG using the same initialization .
Figure 5(a ) shows the objective value F ( X ∗ ) of the KKT point X ∗ detected by FOCG and PG . The objective values of FOCG and PG are close . Both FOCG and PG perform well in solving the optimization problem of Equation 2 .
1513 Table 2 : The sampled Douban data sets . 5 Sample ID
2
1
3
4 vertices ( ×103 ) Edges ( ×106 )
31.8 3.1
79.4 7.1
135.0 11.3
238.3 15.5
1,588.5 19.7
Table 3 : k OCGs detected on WordNetAdj .
Group 1
Group 2 backmost , insignificant , improvident , outgoing , outer , external , outward imprudent , short descending , down , falling junior , minor noncurrent , back , , hindermost , rear unnecessary , inessential , spare , extra proud , distinguished , courtly active , alive , operational , existent inexperienced , unfledged , unfeathered involuntary , unwilling stately , dignified , unwilled , excess , farsighted , front , advanced , inner , internal , inward , interior long , prudent , provident ascending , rising , up leading , senior , better , major frontal , advancer , advance inevitable , necessary silly , undignified , infra dig , demeaning , pathetic dormant , quiescent fledgling , fledged , feathered voluntary , inclined ready , willing , full fledged , essential , inactive ,
ID 1
2
3 4
5
6
7
8
9
10
Figure 5(b ) shows the running time of FOCG and PG . The running time increases as the number of edges increases . FOCG is two orders of magnitudes faster . PG is a generic solution for constrained optimization problems , and is not specifically designed for k OCG detection . It calculates the gradient of F ( X ) in each iteration . The computational cost in calculating such gradients is very expensive when the number of edges is large . On the contrary , all FOCG iterations are efficiently performed on small subgraphs .
5.6 Case Study
We conduct a case study on the WordNetAdj data set , where each vertex represents an adjective , a cohesive edge indicates synonymous relationship and an opposite edge indicates antonymous relationship . In this network , a cohesive subgraph consists of a group of synonyms and a k OCG is k groups of synonyms such that the adjectives in different groups are mostly antonymous with each other . Since the antonymous relationship between adjectives are usually bipolar , it is reasonable to set k = 2 .
Table 3 shows the top 10 k OCGs detected . Each row shows the two adjective groups of a detected k OCG . This case study verifies that significant k OCGs reveal interesting patterns in WordNetAdj .
6 . CONCLUSIONS
In this paper , we tackled the novel problem of finding k oppositive cohesive groups from signed networks . We formulated the k OCG detection problem as a constrained quadratic optimization problem and designed FOCG , an effective and efficient algorithm . Our extensive experiments showed that FOCG can find interesting “ gangs in war ” , and is two orders of magnitudes faster than the traditional proximal gradient method . As future work , we will extend FOCG to automatically estimate the best value of k and effectively control the size of detected subgraphs .
7 . REFERENCES [ 1 ] R . Axelrod and D . S . Bennett . A landscape theory of aggregation . BJPS , 23(02):211–233 , 1993 .
[ 2 ] S . R . Bul`o and I . M . Bomze . Infection and immunization : a new class of evolutionary game dynamics . GEB , 71(1):193–211 , 2011 .
[ 3 ] K Y Chiang , et al . Prediction and clustering in signed networks : a local to global perspective . JMLR , 15(1):1177–1213 , 2014 .
[ 4 ] K Y Chiang , et al . Scalable clustering of signed networks using balance normalized cut . In CIKM , 2012 .
[ 5 ] L . Chu , et al . Alid : scalable dominant cluster detection .
PVLDB , 8(8):826–837 , 2015 .
[ 6 ] P . Doreian and A . Mrvar . A partitioning approach to structural balance . Social Networks , 18(2):149–168 , 1996 .
[ 7 ] M . Gao , et al . On detecting maximal quasi antagonistic communities in signed graphs . DMKD , 30(1):99–146 , 2016 . [ 8 ] H . W . Kuhn and A . W . Tucker . Nonlinear programming . In
Proceedings of Berkeley Symposium , pages 481–492 , 1951 .
[ 9 ] J . Kunegis , et al . The slashdot zoo : mining a social network with negative edges . In WWW , pages 741–750 , 2009 .
[ 10 ] J . Kunegis , et al . Spectral analysis of signed graphs for clustering , prediction and visualization . In SDM , 2010 . [ 11 ] C . Liu , et al . A multiobjective evolutionary algorithm based on similarity for community detection from signed social networks . Cybernetics , IEEE Trans . on , 44(12):2274–2287 , 2014 .
[ 12 ] H . Liu , et al . Fast detection of dense subgraphs with iterative shrinking and expansion . TPAMI , 35(9):2131–2142 , 2013 .
[ 13 ] H . Liu and S . Yan . Robust graph mode seeking by graph shift . In ICML , pages 671–678 , 2010 .
[ 14 ] D . Lo , et al . Mining direct antagonistic communities in signed social networks . IPM , 49(4):773–791 , 2013 .
[ 15 ] D . Lo , et al . Mining direct antagonistic communities in explicit trust networks . In CIKM , 2011 .
[ 16 ] G . A . Miller . Wordnet : a lexical database for english .
Communications of the ACM , 38(11):39–41 , 1995 .
[ 17 ] T . S . Motzkin and E . G . Straus . Maxima for graphs and a new proof of a theorem of tur´an . CJM , 17(4):533–540 , 1965 .
[ 18 ] N . Parikh and S . Boyd . Proximal algorithms . Foundations and Trends in Optimization , 1(3):123–231 , 2013 .
[ 19 ] M . Pavan and M . Pelillo . Dominant sets and pairwise clustering . TPAMI , 29(1):167–172 , 2007 .
[ 20 ] Roulette Selection . Wikipedia . https :
//enwikipediaorg/wiki/Fitness proportionate selection .
[ 21 ] Source Code . FOCG . https://githubcom/lingyangchu/KOCGSIGKDD2016git
[ 22 ] SNAP . https://snapstanfordedu/data/ [ 23 ] J . Tang , Y . Chang , C . Aggarwal , and H . Liu . A survey of signed network mining in social media . arXiv , 2015 .
[ 24 ] V . Traag and J . Bruggeman . Community detection in networks with positive and negative links . Physical Review E , 80(3):036115 , 2009 .
[ 25 ] C . Tsourakakis , et al . Denser than the densest subgraph : extracting optimal quasi cliques with quality guarantees . In SIGKDD , pages 104–112 , 2013 .
[ 26 ] U . Von Luxburg . A tutorial on spectral clustering .
Statistics and Computing , 17(4):395–416 , 2007 .
[ 27 ] J . W . Weibull . Evolutionary game theory . MIT press , 1997 . [ 28 ] T . Xu , et al . Towards annotating media contents through social diffusion analysis . In ICDM , pages 1158–1163 , 2012 .
[ 29 ] K . Zhang , et al . Mining antagonistic communities from social networks . In PAKDD , pages 68–80 , 2010 .
[ 30 ] K . Zhang , et al . Mining indirect antagonistic communities from social interactions . KAIS , 35(3):553–583 , 2013 .
[ 31 ] Q . Zheng and D . Skillicorn . Spectral embedding of signed networks . In SDM , 2015 .
1514
