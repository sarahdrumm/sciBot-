TRIÈST : Counting Local and Global Triangles in Fully Dynamic Streams with Fixed Memory Size
Lorenzo De Stefani
Brown University
Providence , RI , USA lorenzo@csbrownedu
Matteo Riondato* Two Sigma Investments
New York , NY , USA matteo@twosigma.com
“ Ogni lassada xe persa ” 1 – Proverb from Trieste , Italy . ABSTRACT We present trièst , a suite of one pass streaming algorithms to compute unbiased , low variance , high quality approximations of the global and local ( ie , incident to each vertex ) number of triangles in a fully dynamic graph represented as an adversarial stream of edge insertions and deletions .
Our algorithms use reservoir sampling and its variants to exploit the user specified memory space at all times . This is in contrast with previous approaches , which require hard tochoose parameters ( eg , a fixed sampling probability ) and offer no guarantees on the amount of memory they use . We analyze the variance of the estimations and show novel concentration bounds for these quantities . Our experimental results on very large graphs demonstrate that trièst outperforms state of the art approaches in accuracy and exhibits a small update time . 1 .
INTRODUCTION
Exact computation of characteristic quantities of Webscale networks is often impractical or even infeasible due to the humongous size of these graphs . It is natural in these cases to resort to efficient to compute approximations of these quantities , which , when of sufficiently high quality , can be used as proxies for the exact values .
In addition to being huge , many interesting networks are fully dynamic and can be represented as a stream whose elements are edges/nodes insertions and deletions occurring in an arbitrary ( even adversarial ) order . Characteristic quantities in these graphs are intrinsically volatile , hence there is limited added value in maintaining them exactly . The goal is rather to keep track , at all times , of a high quality ∗Work partially done at Brown University . 1Any missed chance is lost forever .
Alessandro Epasto∗
Google
New York , NY , USA aepasto@google.com
Eli Upfal
Brown University
Providence , RI , USA eli@csbrownedu approximation of these quantities . For efficiency , the algorithms should aim at exploiting the available memory space as much as possible and they should require only one pass over the stream . We introduce trièst , a suite of sampling based , one pass algorithms for adversarial fully dynamic streams to approximate the global number of triangles and the local number of triangles incident to each vertex . Mining local and global triangles is a fundamental primitive with many applications ( eg , community detection [ 4 ] , topic mining [ 10 ] , spam/anomaly detection [ 3 , 27 ] , ego networks mining [ 12 ] and protein interaction networks analysis [ 29] . )
Many previous works on triangle estimation in streams also employ sampling ( see Sect . 3 ) , but they usually require the user to specify in advance an edge sampling probability p that is fixed for the entire stream . This approach presents several significant drawbacks . First , choosing a p that allows to obtain the desired approximation quality requires to know or guess a number of properties of the input ( eg , the size of the stream ) . Second , a fixed p implies that the sample size grows with the size of the stream , which is problematic when the stream size is not known in advance : if the user specifies a large p , the algorithm may run out of memory , while for a smaller p it will provide a suboptimal estimation . Third , even assuming to be able to compute a p that ensures ( in expectation ) full use of the available space , the memory would be fully utilized only at the end of the stream , and the estimations computed throughout the execution would be suboptimal . Contributions . We address all the above issues by taking a significant departure from the fixed probability , independent edge sampling approach taken even by state of the art methods [ 27 ] . Specifically : • We introduce trièst ( TRIangle Estimation from STreams ) , a suite of one pass streaming algorithms to approximate , at each time instant , the global and local number of triangles in a fully dynamic graph stream ( ie , a sequence of edges additions and deletions in arbitrary order ) using a fixed amount of memory . This is the first contribution that enjoys all these properties . trièst only requires the user to specify the amount of available memory , an interpretable parameter that is definitively known to the user . • Our algorithms maintain a sample of edges : they use the reservoir sampling [ 37 ] and random pairing [ 14 ] sampling
825 schemes to exploit the available memory as much as possible . To the best of our knowledge , ours is the first application of these techniques to subgraph counting in fullydynamic , arbitrarily long , adversarially ordered streams . We present an analysis of the unbiasedness and of the variance of our estimators , and establish strong concentration results for them . The use of reservoir sampling and random pairing requires additional sophistication in the analysis , as the presence of an edge in the sample is not independent from the concurrent presence of another edge . Hence , in our proofs we must consider the complex dependencies in events involving sets of edges . The gain is worth the effort : we prove that the variance of our algorithms is smaller than that of state of the art methods [ 27 ] , and this is confirmed by our experiments . • We conduct an extensive experimental evaluation of trièst on very large graphs , some with billions of edges , comparing the performances of our algorithms to those of existing state of the art contributions [ 18 , 27 , 32 ] . Our algorithms significantly and consistently reduce the average estimation error by up to 90 % wrt the state of the art , both in the global and local estimation problems , while using the same amount of memory . Our algorithms are also extremely scalable , showing update times in the order of hundreds of microseconds for graphs with billions of edges . Due to space constraints , the proofs and additional experimental results can be found in the extended version [ 9 ] .
2 . PRELIMINARIES
We study the problem of counting global and local triangles in a fully dynamic undirected graph as an arbitrary ( adversarial ) stream of edge insertions and deletions . Formally , for any ( discrete ) time instant t ≥ 0 , let G(t ) = ( V ( t ) , E(t ) ) be the graph observed up to and including time t . At time t = 0 we have V ( t ) = E(t ) = ∅ . For any t > 0 , at time t + 1 we receive an element et+1 = ( • , ( u , v ) ) from a stream , where • ∈ {+,−} and u , v are two distinct vertices . The graph G(t+1 ) = ( V ( t+1 ) , E(t+1 ) ) is obtained by inserting a new edge or deleting an existing edge as follows : fl E(t ) ∪ {(u , v)} if • = “ + ”
E(t ) \ {(u , v)} if • = “ − ”
.
( t+1 ) =
E
If u or v do not belong to V ( t ) , they are added to V ( t+1 ) . Nodes are deleted from V ( t ) when they have degree zero .
Edges can be added and deleted in the graph in an arbitrary adversarial order , ie , as to cause the worst outcome for the algorithm , but we assume that the adversary has no access to the random bits used by the algorithm . We assume that all operations have effect : if e ∈ E(t ) ( resp . e 6∈ E(t) ) , ( + , e ) ( resp . ( − , e ) ) can not be on the stream at time t + 1 . Given a graph G(t ) = ( V ( t ) , E(t) ) , a triangle in G(t ) is a set of three vertices {u , v , w} ⊆ V ( t ) such that {(u , v ) , ( v , w ) , ( w , u)} ⊆ E(t ) . We refer to the vertices forming a triangle as its corners . We denote with ∆(t ) the set of all triangles in G(t ) , and , for any vertex u ∈ V ( t ) , with ∆(t ) u the subset of ∆(t ) containing all and only the triangles that have u as a corner . Problem definition . We study the Global ( resp . Local ) Triangle Counting Problem in Fully dynamic Streams , which requires to compute , at each time t ≥ 0 an estimation of |∆(t)| ( resp . for each u ∈ V an estimation of |∆(t ) u | ) .
3 . RELATED WORK
The literature on triangle counting is extremely rich , including exact algorithms , graph sparsifiers [ 35 , 36 ] , complexvalued sketches [ 20 , 28 ] , and MapReduce algorithms [ 30 , 31 , 33 ] . Here we restrict the discussion to the works most related to ours , ie , to those presenting algorithms for counting or approximating the number of triangles from data streams . We refer to the survey by Latapy [ 25 ] for an in depth discussion of other works .
Many previous contributions presented algorithms for more restricted ( ie , less generic ) settings than ours , or for which the constraints on the computation are more lax [ 2 , 6 , 19 , 22 ] . For example , Becchetti et al . [ 3 ] and Kolountzakis et al . [ 21 ] present algorithms for approximate triangle counting from static graphs by performing multiple passes over the input . Pavan et al . [ 32 ] and Jha et al . [ 18 ] propose algorithms for approximating only the global number of triangles from edge insertion only streams . Kutzkov and Pagh [ 23 ] present a one pass algorithm for fully dynamic graphs , but the triangle count estimation is ( expensively ) computed only at the end of the stream and the algorithm requires , in the worst case , more memory than what is needed to store the entire graph . Ahmed et al . [ 1 ] apply the sampling and hold approach to insertion only graph stream mining to obtain , only at the end of the stream and using non constant space , an estimation of many network measures including triangles . None of these works has all the features offered by trièst : performs a single pass over the data , handles fully dynamic streams , uses a fixed amount of memory space , requires a single interpretable parameter , and returns an estimation at each time instant . Furthermore , our experimental results show that we outperform the algorithms from [ 18 , 32 ] on insertion only streams .
Lim and Kang [ 27 ] present an algorithm for insertion only streams that is based on independent edge sampling with a fixed probability . Since the memory is not fully utilized during most of the stream , the variance of the estimate is large . Our approach handles fully dynamic streams and makes better use of the available memory space at each time instant , resulting in a better estimation , as shown by our analytical and experimental results .
Vitter [ 37 ] presents a detailed analysis of the reservoir sampling scheme and discusses methods to speed up the algorithm by reducing the number of calls to the random number generator . Random Pairing [ 14 ] is an extension of reservoir sampling to handle fully dynamic streams with insertions and deletions . Cohen et al . [ 8 ] generalize and extend the Random Pairing approach to the case where the elements on the stream are key value pairs , where the value may be negative ( and less than −1 ) . In our settings , where the value is not less than −1 ( for an edge deletion ) , these generalizations do not apply and the algorithm presented by Cohen et al . [ 8 ] reduces essentially to Random Pairing .
4 . ALGORITHMS
We present trièst , a suite of three novel algorithms for approximate global and local triangle counting from edge streams . The first two work on insertion only streams , while the third can handle fully dynamic streams where edge deletions are allowed . Parameters . Our algorithms keep an edge sample S of up to M edges from the stream , where M is a positive integer
826 parameter . For ease of presentation , we realistically assume M ≥ 6 . In Sect . 1 we motivated the design choice of only requiring M as a parameter and remarked on its advantages over using a fixed sampling probability p . Our algorithms are designed to use the available space as much as possible . Counters . trièst algorithms keep counters to compute the estimations of the global and local number of triangles . They always keep one global counter τ for the estimation of the global number of triangles . Only the global counter is needed to estimate the total triangle count . To estimate the local triangle counts , the algorithms keep a set of local counters τu for a subset of the nodes u ∈ V ( t ) . The local counters are created on the fly as needed , and always destroyed as soon as they have a value of 0 . Hence our algorithms use O(M ) space ( with one exception , see Sect . 42 ) Notation . For any t ≥ 0 , let GS = ( V S , ES ) be the subgraph of G(t ) containing all and only the edges in the current sample S . We denote with N S u the neighborhood of u in GS : N S u ∩ N S u = {v ∈ V ( t ) the shared neighborhood of u and v in GS . 4.1 A first algorithm – trièst base
: ( u , v ) ∈ S} and with N S u,v = N S t is deterministically inserted in S .
We first present trièst base , which works on insertiononly streams and uses standard reservoir sampling [ 37 ] to maintain the edge sample S : • If t ≤ M , then the edge et = ( u , v ) on the stream at time • If t > M , trièst base flips a biased coin with heads probability M/t . If the outcome is heads , it chooses an edge ( w , z ) ∈ S uniformly at random , removes ( w , z ) from S , and inserts ( u , v ) in S . Otherwise , S is not modified . After each insertion ( resp . removal ) of an edge ( u , v ) from S , trièst base calls the procedure UpdateCounters that increments ( resp . decrements ) τ , τu and τv by |N S u,v| , and τc by one , for each c ∈ N S u,v . The pseudocode for trièst base is presented in Alg . 1 . v
Input : Insertion only edge stream Σ , integer M ≥ 6
Algorithm 1 trièst base 1 : S ← ∅ , t ← 0 , τ ← 0 2 : for each element ( + , ( u , v ) ) from Σ do 3 : 4 : 5 : 6 : t ← t + 1 if SampleEdge((u , v ) , t ) then S ← S ∪ {(u , v)} UpdateCounters(+ , ( u , v ) ) t ) = heads then if t ≤ M then return True else if FlipBiasedCoin( M ( u0 , v0 ) ← random edge from S S ← S \ {(u0 , v0)} UpdateCounters(− , ( u0 , v0 ) ) return True
7 : function SampleEdge((u , v ) , t ) 8 : 9 : 10 : 11 : 12 : 13 : 14 : 15 : 16 : function UpdateCounters((• , ( u , v) ) ) 17 : 18 : 19 : 20 : 21 : 22 :
N S u,v ← N S for all c ∈ N S τ ← τ • 1 τc ← τc • 1 τu ← τu • 1 τv ← τv • 1 u ∩ N S u,v do return False v n
Estimation . For any t ≥ 0 , let ξ(t ) = max M(M−1)(M−2 ) ( t ) Let τ ( t ) ( resp . τ u ) be the value of the counter τ at the end of time step t ( ie , after the edge on the stream at time t t(t−1)(t−2 )
1 , has been processed by trièst base ) ( resp . the value of the counter τu at the end of time step t if there is such a counter , 0 otherwise ) . When queried at the end of time t , trièstbase returns ξ(t)τ ( t ) ( resp . ξ(t)τ ( t ) u ) as the estimation for the global ( resp . local for u ∈ V ( t ) ) triangle count . Analysis .
Theorem 1 . We have ( t ) = τ
( t )
ξ
E.ξ
τ
( t )
τ
( t ) = |∆(t)| if t ≤ M
( t)fi = |∆(t)| if t > M .
The trièst base estimations are not only unbiased in all cases , but actually exact for t ≤ M , ie , for t ≤ M , they are the true global/local number of triangles in G(t ) . We now analyze the variance of the estimation returned by trièst base for t > M ( the variance is 0 for t ≤ M . ) Let t ≥ 0 . For any u ∈ V ( t ) , let r ( t ) u be the number of unordered pairs of distinct triangles from ∆(t ) u sharing an edge.1 Similarly , ( t ) let r(t ) = 1 u be the total number of unordered 3 pairs of distinct triangles from ∆(t ) sharing an edge . We
− r(t ) as the number of unordered also define w(t ) =,|∆(t)| pairs of distinct triangles that do not share any edge , and analogously for w
P u∈V ( t ) r
( t ) u .
2
Theorem 2 . For any t > M , let f(t ) = ξ(t ) − 1 , g(t ) = ξ
( t ) ( M − 3)(M − 4 )
( t − 3)(t − 4 ) − 1 and
We have : h(t ) = ξ
Var.ξ(t)τ
( t ) ( M − 3)(M − 4)(M − 5 )
( t − 3)(t − 4)(t − 5 ) − 1 ( ≤ 0 ) . ( t)fi = |∆(t)|f(t ) + r
( t )
( t ) h(t ) . g(t ) + w
( 1 ) In our proofs , we carefully account for the fact that , as we use reservoir sampling [ 37 ] , the presence of an edge a in S is not independent from the concurrent presence of another edge b in S . This is not the case for samples built using fixed probability independent edge sampling . When computing the variance , we must consider not only pairs of triangles that share an edge ( as for independent edge sampling approaches ) , but also pairs of triangles sharing no edge , as their respective presences in the sample are not independent events . The gain is worth the additional sophistication needed in the analysis , because the contribution to the variance by triangles not sharing edges is nonpositive ( h(t ) ≤ 0 ) , ie , it reduces the variance . A comparison of the variance of our estimator with that obtained with a fixed probability independent edge sampling approach , is discussed below .
Let h(t ) denote the maximum number of triangles sharing a single edge in G(t ) . The following concentration theorem relies on 1 . a result by Hajnal and Szemerédi [ 15 ] on graph coloring , 2 . a novel concentration result for fixedprobability independent edge sampling , and 3 . a Poissonapproximation like result on probabilities of general events under reservoir sampling wrt their probabilities under independent edge sampling . These ingredients are then combined to obtain the following result . The details can be found in our extended online version [ 9 ] . 1Two distinct triangles can share at most one edge . o
.
827 Theorem 3 . Let t ≥ 0 and assume |∆(t)| > 0.2 For any
ε , δ ∈ ( 0 , 1 ) , let
Φ = 3
8ε−2 3h(t ) + 1 |∆(t)|
If s n
. ln
( 3h(t ) + 1)e
2 ln2/3 ( tΦ )
, 12ε
δ o
M ≥ max tΦ
1 + 1
, then |ξ(t)τ ( t ) − |∆(t)|| < ε|∆(t)| with probability > 1 − δ .
−1 + e
2
, 25
Results analogous to those in Thms . 1 , 2 , and 3 hold for the local triangle count for any u ∈ V ( t ) , replacing the global quantities with the corresponding local ones . Comparison with fixed probability approaches . We now compare the variance of trièst base to the variance of the fixed probability sampling approach mascot c [ 27 ] , which samples edges independently with a fixed probability p and uses p−3|∆S| as the estimate for the global number of triangles at time t . As shown by Lim and Kang [ 27 , Lemma 2 ] , the variance of this estimator is
−3|∆S| ] = |∆(t)| ¯f(p ) + r where ¯f(p ) = p−3 − 1 and ¯g(p ) = p−1 − 1 .
Var[p
( t)¯g(p ) ,
Assume that we give mascot c the additional information that the stream has finite length T , and assume we run mascot c with p = M/T so that the expected sample size at the end of the stream is M.3 Let V(t ) fix be the resulting variance of the mascot c estimator at time t , and let V(t ) be the variance of our estimator at time t ( see ( 1) ) . For t ≤ M , V(t ) = 0 , hence V(t ) ≤ V(t ) fix .
For M < t < T , we can show the following result . Lemma 1 . Let 0 < α < 1 be a constant . For any constant
1−α , 42 ) and any t ≤ αT we have V(t ) < V(t ) fix .
M > max( 8α For example , if we set α = 0.99 and run trièst base with M ≥ 400 and mascot c with p = M/T , we have that trièst base has strictly smaller variance than mascot c for 99 % of the stream .
What about t = T ? The difference between the definitions fix and V(t ) is in the presence of ¯f(M/T ) instead of of V(t ) f(t ) ( resp . ¯g(M/T ) instead of g(t ) ) as well as the additional term w(t)h(M , t ) ≤ 0 in our V(t ) . Let M(T ) be an arbitrary slowly increasing function of T . For T → ∞ we can show ¯f(M(T )/T ) = 1 , hence , that limT→∞ informally , V(T ) → V(T )
= limT→∞ ¯g(M(T )/T ) fix , for T → ∞ .
A similar discussion also holds for the method we present in Sect . 4.2 , and explains the results of our experimental evaluations , which show that our algorithms have strictly lower ( empirical ) variance than fixed probability approaches for most of the stream . Update time . The time to process an element of the stream is dominated by the computation of the shared neighborhood Nu,v in UpdateCounters . A Mergesort based algorithm for the intersection requires O ( deg(u ) + deg(v ) ) 2If |∆(t)| = 0 , our algorithms correctly estimate 0 triangles . 3We are giving mascot c a significant advantage : if only space M were available , we should run mascot c with a sufficiently smaller p0 < p , otherwise there would be a constant probability that mascot c would run out of memory . f(T ) g(T ) time , where the degrees are wrt the graph GS . By storing the neighborhood of each vertex in a Hash Table ( resp . an AVL tree ) , the update time can be reduced to O(min{deg(v ) , deg(u)} ) ( resp . amortized time O(min{deg(v ) , deg(u)}+ log max{deg(v ) , deg(u)}) ) . 4.2 Improved insertion algorithm – trièst impr trièst impr is a variant of trièst base with small modifications that result in higher quality ( ie , lower variance ) estimations . The changes are : 1 . UpdateCounters is called unconditionally for each element on the stream , before the algorithm decides whether or not to insert the edge into S . Wrt the pseudocode in Alg . 1 , this change corresponds to moving the call to UpdateCounters on line 6 to before the if block . mascot [ 27 ] uses a similar idea , but trièst impr is significantly different as trièst impr allows edges to be removed from the sample , since it uses reservoir sampling . 2 . trièst impr never decrements the counters when an edge is removed from S . Wrt the pseudocode in Alg . 1 , we remove the call to UpdateCounters on line 13 . 3 . UpdateCounters performs a weighted increase of the counters using η(t ) = max{1 , ( t − 1)(t − 2)/(M(M − 1))} as weight . Wrt the pseudocode in Alg . 1 , we replace “ 1 ” with η(t ) on lines 19–22 ( given change 2 above , all the calls to UpdateCounters have • = + ) .
Counters . If we are interested only in estimating the global number of triangles in G(t ) , trièst impr needs to maintain only the counter τ and the edge sample S of size M , so it still requires space O(M ) . If instead we are interested in estimating the local triangle counts , at any time t trièst maintains ( non zero ) local counters only for the nodes u such that at least one triangle with a corner u has been detected by the algorithm up until time t . The number of such nodes may be greater than O(M ) , but this is the price to pay to obtain estimations with lower variance ( Thm . 5 ) . Estimation . When queried for an estimation , trièst impr returns the value of the corresponding counter , unmodified . Analysis .
Theorem 4 . We have τ ( t ) = |∆(t)| if t ≤ M and
E.τ ( t)fi = |∆(t)| if t > M .
As in trièst base , the estimations by trièst impr are exact at time t ≤ M and unbiased for t > M . We now show an upper bound to the variance of the trièstimpr estimations for t > M . The proof relies on a very careful analysis of the covariance of two triangles which depends on the order of arrival of the edges in the stream ( which we assume to be adversarial ) . Let z(t ) be the number of unordered pairs ( λ , γ ) of distinct triangles in G(t ) that share an edge g and are such that g is neither the last edge of λ on the stream nor the last edge of γ on the stream . For any node u ∈ V ( t ) , let z ( t ) u be similarly defined , but considering only the triangles incident to u .
Theorem 5 . Then , for any time t > M , we have ( t ) t − 1 − M
( t)fi ≤ |∆(t)|(η
Var.τ
( t ) − 1 ) + z
.
M
For the sake of clarity , in Thm . 5 , we chose not to present a stricter but more complex bound involving triangles that do not share any edge , which , as in Thm . 2 , would add a non positive term to the variance ( ie , reduce the variance ) .
828 The following result relies on Chebyshev ’s inequality and
Thm . 5 .
Theorem 6 . Let t ≥ 0 and assume |∆(t)| > 0 . For any
ε , δ ∈ ( 0 , 1 ) , if
M > max flr2(t − 1)(t − 2 ) δε2|∆(t)| + 2 + 1
4 + 1 2 ,
2z(t)(t − 1 )
δε2|∆(t)|2 + 2z(t ) then |τ ( t ) − |∆(t)|| < ε|∆(t)| with probability > 1 − δ .
In Thms . 5 and 6 , it is possible to replace the value z(t ) with the more interpretable r(t ) , which is agnostic to the order of the edges on the stream but gives a looser upper bound to the variance . Results analogous to those in Thms . 4 , 5 , and 6 hold for the local triangle count for any u ∈ V ( t ) , replacing the global quantities with the corresponding local ones . 4.3 Fully dynamic algorithm – trièst fd trièst fd computes unbiased estimates of the global and local triangle counts in a fully dynamic stream where edges are inserted/deleted in any arbitrary , adversarial order . It is based on random pairing ( RP ) [ 14 ] , a sampling scheme that extends reservoir sampling and can handle deletions . The idea behind the RP scheme is that edge deletions seen on the stream will be “ compensated ” by future edge insertions . Following RP , trièst fd keeps a counter di ( resp . do ) to keep track of the number of uncompensated edge deletions involving an edge e that was ( resp . was not ) in S at the time the deletion for e was on the stream . When an edge deletion for an edge e ∈ E(t−1 ) is on the stream at the beginning of time step t , then , if e ∈ S at this time , trièst fd removes e from S ( effectively decreasing the number of edges stored in the sample by one ) and increases di by one . Otherwise , it just increases do by one . When an edge insertion for an edge e 6∈ E(t−1 ) is on the stream at the beginning of time step t , if di + do = 0 , then trièst fd follows the standard reservoir sampling scheme . If |S| < M , then e is deterministically inserted in S without removing any edge from S already in S , otherwise it is inserted in S with probability M/t , replacing an uniformly chosen edge already in S . If instead di + do > 0 , then e is inserted in S with probability di/(di + do ) ; since it must be di > 0 , then it must be |S| < M and no edge already in S needs to be removed . In any case , after having handled the eventual insertion of e into S , the algorithm decreases di by 1 if e was inserted in S , otherwise it decreases do by 1 . trièst fd also keeps track of s(t ) = |E(t)| by appropriately incrementing or decrementing a counter by 1 depending on whether the element on the stream is an edge insertion or deletion . The pseudocode for trièst fd is presented in Alg . 2 where the UpdateCounters procedure is the one from Alg . 1 . Estimation . We denote as M ( t ) the size of S at the end of time t ( we always have M ( t ) ≤ M ) . For any time t , let d ( t ) i ( t ) o be the value of the counters di and do at the end of and d time t respectively , and let ω(t ) = min{M , s(t ) + d o } . ( t ) Define
( t ) i + d s(t ) d
2X j j=0
( t ) ( t ) i + d o ω(t ) − j
( cid:30)s(t ) + d
( t ) o
( t ) i + d ω(t )
.
( t ) = 1 −
κ
Input : Fully Dynamic edge stream Σ , integer M ≥ 6 t ← t + 1 s ← s • 1 if • = + then
Algorithm 2 trièst fd 1 : S ← ∅ , di ← 0 , do ← 0 , t ← 0 , s ← 0 2 : for each element ( • , ( u , v ) ) from Σ do 3 : 4 : 5 : 6 : 7 : 8 : 9 : 10 : 11 : 12 :
UpdateCounters(− , ( u , v ) ) S ← S \ {(u , v)} di ← di + 1 else do ← do + 1
UpdateCounters(+ , ( u , v ) ) if SampleEdge ( u , v ) then else if ( u , v ) ∈ S then t ) = heads then else if FlipBiasedCoin( M if do + di = 0 then if |S| < M then S ← S ∪ {(u , v)} return True Select ( z , w ) uniformly at random from S UpdateCounters(− , ( z , w ) ) S ← ( S \ {(z , w)} ) ∪ {(u , v)} return True else if FlipBiasedCoin , di
= heads then
13 : function SampleEdge(u , v ) 14 : 15 : 16 : 17 : 18 : 19 : 20 : 21 : 22 : 23 : 24 : 25 : 26 : 27 : 28 : 29 :
S ← S ∪ {(u , v)} di ← di − 1 return True do ← do − 1 return False di+do else
For any three positive integers a , b , c st a ≤ b ≤ c , define a−1Y i=0 c − i b − i
.
ψa,b,c =
When queried at the end of time t , for an estimation of the global number of triangles , trièst fd returns
( 0 if M ( t ) < 3
( t ) =
ρ
( t ) u
κ(t ) ψ3,M(t),s(t ) = τ(t ) τ(t ) κ(t ) and has the additional condition that ρ s(t)(s(t)−1)(s(t)−2 ) M(t)(M(t)−1)(M(t)−2 ) othw . u | for u ∈ V ( t ) , the definition for ρ When estimating |∆(t ) ( t ) u ( t ) u = 0 if uses τ there is no counter τu . trièst fd can keep track of κ(t ) during the execution , each update of κ(t ) taking time O(1 ) . Hence the time to return the estimations is still O(1 ) . Analysis . Let t∗ be the first t ≥ M + 1 such that |E(t)| = M + 1 , if such a time step exists ( otherwise t∗ = +∞ ) .
Theorem 7 . We have ρ(t ) = |∆(t)| for all t < t∗ , and
E.ρ(t)fi = |∆(t)| for t ≥ t∗ .
The proof relies on properties of RP and on the definitions of κ(t ) and ρ(t ) .
( t )
( t ) o + d
Var.ρ
( t)fi ≤ ( κ
Theorem 8 . Let t > t∗ st |∆(t)| > 0 and s(t ) ≥ M . i ≤ αs(t ) total unpaired 7 ln s(t )
Suppose we have d(t ) = d deletions at time t , with 0 ≤ α < 1 . If M ≥ for some α < α0 < 1 , we have :
( t))−2|∆(t)|,ψ3,M(1−α0),s(t ) − 1 + ( κ
( t))−22 5,M(1−α0),s(t ) − 1 −1 The following result relies on Chebyshev ’s inequality and
2 3,M(1−α0),s(t ) ψ
( t )
( t))−2
1 α0−α
√ 2
+ ( κ
ψ r on Thm . 8 .
829 Theorem 9 . Let t ≥ t∗ st |∆(t)| > 0 and s(t ) ≥ M . i ≤ αs(t ) for some 0 ≤ α < 1 . For any
Let d(t ) = d ε , δ ∈ ( 0 , 1 ) , if for some α < α0 < 1
( t ) o + d
( t )
(
M > max
1√ a0 − α
,
( t )
7 ln s
 3 s 2s(t)(s(t ) − 1)(s(t ) − 2 ) )
δε2|∆(t)|(κ(t))2 + 2 |∆(t)|−2 |∆(t)| r(t)s(t )
δε2|∆(t)|2(κ(t))−2 + 2r(t )
 ,
+ 2
( 1 − α
0)−1
( 1 − α0)−1
3 then |ρ(t ) − |∆(t)|| < ε|∆(t)| with probability > 1 − δ .
Results analogous to those in Thms . 7 , 8 , and 9 hold for the local triangle count for any u ∈ V ( t ) , replacing the global quantities with the corresponding local ones .
5 . EXPERIMENTAL EVALUATION
We evaluated trièst on several real world graphs with up to a billion edges . The algorithms were implemented in C++ , and ran on the Brown University CS department cluster.4 Each run employed a single core and used at most 4 GB of RAM . We report here only a subset of the results . Additional details are available in the extended online version . The code is available from http://bigdatacsbrown edu/triangleshtml
Datasets . We created the streams from the following publicly available graphs ( properties in Table 1 ) . Patent ( Co Aut . ) and Patent ( Cit ) The Patent ( CoAut . ) and Patent ( Cit . ) graphs are obtained from a dataset of ≈ 2 million US patents granted between ’75 and ’99 [ 16 ] . In Patent ( Co Aut. ) , the nodes represent inventors and there is an edge with timestamp t between two co inventors of a patent if the patent was granted in year t . In Patent ( Cit. ) , nodes are patents and there is an edge ( a , b ) with timestamp t if patent a cites b and a was granted in year t . LastFm . The LastFm graph is based on a dataset [ 7 , 34 ] of ≈ 20 million last.fm song listenings , ≈ 1 million songs and ≈ 1000 users . There is a node for each song and an edge between two songs if ≥ 3 users listened to both on day t . Yahoo! Answers . The Yahoo! Answers graph is obtained from a sample of ≈ 160 million answers to ≈ 25 millions questions posted on Yahoo! Answers [ 38 ] . An edge connects two users at time max(t1 , t2 ) if they both answered the same question at times t1 , t2 respectively . We removed 6 outliers questions with more than 5000 answers . Twitter . This is a snapshot [ 5 , 24 ] of the Twitter followers/following network with ≈ 41 million nodes and ≈ 1.5 billions edges . We do not have time information for the edges , hence we assign a random timestamp to the edges ( of which we ignore the direction ) . Ground truth . To evaluate the accuracy of our algorithms , we computed the ground truth for our smaller graphs ( ie , the exact number of global and local triangles for each time step ) , using an exact algorithm . The entire current graph is stored in memory and when an edge u , v is inserted ( or deleted ) we update the current count of local and global 4https://csbrownedu/about/system/services/hpc/grid/
Graph
|V |
|E|
|Eu|
|∆|
Patent ( Co Aut . ) 1,162,227
Patent ( Cit . )
LastFm
Yahoo! Answers
Twitter
3,660,945
2,724,036 3.53 × 106 2,745,762 13,965,410 13,965,132 6.91 × 106 43,518,693 30,311,117 1.13 × 109 681,387 2,432,573 1.21 × 109 1.08 × 109 7.86 × 1010 41,652,230 1.47 × 109 1.20 × 109 3.46 × 1010
Table 1 : Properties of the dynamic graph streams analyzed . |V | , |E| , |Eu| , |∆| refer respectively to the number of nodes appearing in the graph , the number of edge addition events , the number of distinct edges additions , and the maximum number of triangles in the graph ( for Yahoo! Answers and Twitter estimated with trièst impr M = 1000000 , otherwise computed exactly with the naïve algorithm ) .
( a ) LastFm
( b ) Yahoo! Answers
Figure 1 : Estimation by trièst impr of the global number of triangles over time . Our estimations have very small error and variance : the ground truth is indistinguishable from max/min point wise estimation over ten runs . triangles by checking how many triangles are completed ( or broken ) . As exact algorithms are not scalable , computing the exact triangle count is feasible only for small graphs such as Patent ( Co Aut. ) , Patent ( Cit . ) and LastFm . Table 1 reports the exact total number of triangles at the end of the stream for those graphs ( and an estimate for the larger ones using trièst impr with M = 1000000 ) . 5.1 Insertion only case
We now evaluate trièst on insertion only streams and compare its performances with those of state of the art approaches [ 18 , 27 , 32 ] , showing that trièst has an average estimation error significantly smaller than these methods both for the global and local estimation problems , while using the same amount of memory . Estimation of the global number of triangles . Starting from an empty graph we add one edge at a time , in timestamp order . Figure 1 illustrates the evolution , over time , of the estimation computed by trièst impr with M = 1,000,000 . For smaller graphs for which the ground truth can be computed exactly , the curve of the exact count is practically indistinguishable from our estimation showing the precision of the method . Our estimators have very small variance even on the very large Yahoo! Answers graph ( point wise max/min estimation over ten runs is almost coincident with the average estimation ) . These results show that trièst impr is very accurate even when storing less than a 0.001 fraction of the total edges of the graph . Comparison with the state of the art . We compare quantitatively with three state of the art methods : Mas
0 2e+08 4e+08 6e+08 8e+08 1e+09 1.2e+09 0 5e+06 1e+07 1.5e+07 2e+07 2.5e+07 3e+07 3.5e+07TrianglesTimeTriangle Estimation vs Timeground truthmax est.min est.avg est . 0 1e+10 2e+10 3e+10 4e+10 5e+10 6e+10 7e+10 8e+10 0 2e+08 4e+08 6e+08 8e+08 1e+09 1.2e+09TrianglesTimeTriangle Estimation vs Timemax est.min est.avg est.830 Graph
Impr .
Patent ( Cit . )
LastFm
N Y N Y N Y N Y
Max . MAPE
Avg . MAPE p Mascot 0.01 0.9231 0.01 0.1907 0.0839 0.1 0.1 0.0317 0.01 0.1525 0.01 0.0273 0.1 0.0075 0.0048 0.1 trièst Mascot 0.2583 0.6517 0.1149 0.0363 0.0605 0.0124 0.0245 0.0037 0.0627 0.0185 0.0141 0.0046 0.0028 0.0047 0.0031 0.0013 trièst Change 0.1811 72.2 % 81.4 % 0.0213 88.5 % 0.0070 91.1 % 0.0022 81.2 % 0.0118 76.2 % 0.0034 0.0015 68.1 % 72.1 % 0.0009
Table 2 : Global triangle estimation MAPE for trièst and Mascot . The rightmost column shows the reduction in terms of the avg . MAPE obtained by using trièst . Rows with Y in column “ Impr . ” refer to improved algorithms ( trièst impr and mascot i ) while those with N to basic algorithms ( trièst base and mascot c ) .
Avg . Pearson p 0.1 0.05 0.01
Mascot I
0.99 0.97 0.85 trièst 1.00 1.00 0.98
Change Mascot I +1.18 % +2.48 % +14.28 %
0.79 0.99 1.35
Avg . ε Err trièst 0.30 0.47 0.89
Change 62.02 % 52.79 % 34.24 %
Table 3 : Comparison of the quality of the local triangle estimations in LastFM between trièst impr and Mascot I ) . We outperform Mascot I using the same amount of memory . cot [ 27 ] , Jha et al . [ 18 ] and Pavan et al . [ 32 ] . Mascot is a suite of local triangle counting methods ( but provides also a global estimation ) . The other two are global triangle counting approaches . None of these can handle fully dynamic streams , in contrast with trièst fd . We first compare the three methods to trièst for the global triangle counting estimation . Mascot comes in two memory efficient variants : the basic Mascot C variant and an improved Mascot I variant.5 Both variants sample edges with fixed probability p , so there is no guarantee on the amount of memory used during the execution . To ensure fairness of comparison , we devised the following experiment . First , we run both Mascot C and Mascot I for ‘ = 10 times with a fixed p using the same random bits for the two algorithms run by run ( ie the same coin tosses used to select the edges ) measuring each time the number of edges M0 stored in the sample at the end of the stream ( by construction this the is same for the two variants run by run ) . Then , i ( for i ∈ [ ‘] ) . We do the we run our algorithms using M = M0 same to fix the size of the edge memory for Jha et al . [ 18 ] and Pavan et al . [ 32].6 This way , all algorithms use the same amount of memory for storing edges ( run by run ) .
We use the MAPE ( Mean Average Percentage Error ) to assess the accuracy of the global triangle estimators over time . The MAPE measures the average percentage of the i
5In the original work [ 27 ] , this variant had no suffix and was simply called Mascot . We add the I suffix to avoid confusion . The variant Mascot A can be forced to store the entire graph with probability 1 ( using an adversarial edge order ) so we do not consider it here . 6More precisely , we use M0 i /2 estimators in Pavan et al . as each estimator stores two edges . For Jha et al . we set the two reservoirs in the algorithm to have each size M0 i /2 . This way , all algorithms use M0 i cells for storing ( w)edges .
( a ) MAPE
( b ) Update Time
Figure 2 : Average MAPE and average update time of the various methods on the Patent ( Co Aut . ) graph with p = 0.01 – insertion only . trièst impr has the lowest error . Both Pavan et al . and Jha et al . have very high update times compared to our method and the two Mascot variants .
T t=1
|∆(t)| fififi.7 prediction error with respect to the ground truth , and is widely used in the prediction literature [ 17 ] . For t = 1 , . . . , T , let ∆(t ) be the estimator of the number of triangles at time t , the MAPE is defined as 1 fififi |∆(t)|−∆(t )
PT
In Fig 2(a ) , we compare the average MAPE of trièstbase and trièst impr as well as the two Mascot variants and the other two streaming algorithms for the Patent ( CoAut . ) graph , fixing p = 001 trièst impr has the smallest error of all the algorithms compared .
We now turn our attention to the efficiency of the methods . Figure 2(b ) shows the average update time per operation in Patent ( Co Aut . ) graph , fixing p = 001 Both Jha et al . [ 18 ] and Pavan et al . [ 32 ] are up to ≈ 3 orders of magnitude slower than the Mascot variants and trièst . This is expected as both algorithms have an update complexity of Ω(M ) ( they have to go through the entire reservoir graph at each step ) , while both Mascot algorithms and trièst need only to access the neighborhood of the nodes involved in the edge addition.8 This allows both algorithms to efficiently exploit larger memory sizes . We can use efficiently M up to 1 million edges in our experiments ,
7The MAPE is not defined for t st ∆(t ) = 0 so we compute it only for t st |∆(t)| > 0 . All algorithms we consider are guaranteed to output the correct answer for t st |∆(t)| = 0 . 8We observe that Pavan et al . [ 32 ] would be more efficient with batch updates . However , we want to estimate the triangles continuously at each update . In their experiments they use batch sizes of million of updates for efficiency .
0.01 0.1 1TRIEST BASETRIEST IMPRMASCOT CMASCOT IJHA ET AL.PAVAN ET ALAvg MAPEAvg . MAPE vs Algorithm 1 10 100 1000 10000TRIEST BASETRIEST IMPRMASCOT CMASCOT IJHA ET AL.PAVAN ET ALAvg Micros/OperationAvg . Update Time vs Algorithm831 Figure 3 : Variance of trièst impr with M = 10000 and of mascot with same expected memory , on LastFM . trièst impr has a smaller variance : the max/min estimation lines are closer to the ground truth . ( Average estimations are qualitatively similar and not shown ) . which only requires few megabytes of RAM.9 Mascot is one order of magnitude faster than trièst ( which runs in ≈ 28 micros/op ) , because it does not have to handle edge removal from the sample , as it offers no guarantees on the used memory . As we will show , trièst has much higher precision and scales well on billion edges graphs . Given the slow execution of the other algorithms on the larger datasets we compare in details trièst only with Mascot.10 Table 2 shows the average MAPE of the two approaches . The results confirm the pattern observed in Figure 2(a ) : trièst base and trièst impr both have an average error significantly smaller than that of the basic MascotC and improved Mascot variant respectively . We achieve up to a 91 % ( ie , 9 fold ) reduction in the MAPE while using the same amount of memory . This experiment confirms the theory : reservoir sampling has overall lower or equal variance in all steps for the same expected total number of sampled edges . To further validate this observation we run trièst impr and of the improved Mascot variant using the same ( expected memory ) M = 10000 . Figure 3 shows the max min estimation over 10 runs . trièst impr shows significantly lower variance over the evolution : the maxmin estimation lines are closer to the ground truth virtually all time . This confirms our theoretical observations in the previous sections . Even with very low M ( about 2/10000 of the size of the graph ) trièst gives a good estimation . Local triangle counting . We compare the precision in local triangle count estimation of trièst with that of Mascot [ 27 ] using the same approach of the previous experiment . We can not compare with Jha et al . and Pavan et al . algorithms as they provide only global estimation . As in [ 27 ] , we measure the Pearson coefficient and the average ε error ( see [ 27 ] for definitions ) . In Table 3 we report the Pearson coefficient and average ε error over all timestamps for the smaller graphs.11 trièst ( significantly ) improves
9The experiments in [ 18 ] use M in the order of 103 , and in [ 32 ] , large M values require large batches for efficiency . 10We attempted to run the other two algorithms but they did not complete after 12 hours for the larger datasets in Table 2 with the prescribed p parameter setting . 11For efficiency , in this test we evaluate the local number of triangles of all nodes every 1000 edge updates .
( a ) M vs MAPE
( b ) M vs Update Time
Figure 4 : Trade offs between M and MAPE or avg . update time ( µs ) – edge insertion only . Higher M implies lower errors but higher update times .
( ie , has higher correlation and lower error ) over the stateof the art Mascot , using the same amount of memory . Memory vs accuracy trade offs . We study the tradeoff between the sample size M vs the running time and accuracy of the estimators . Figure 4(a ) shows the tradeoffs between the accuracy of the estimation and the size M for the smaller graphs for which the ground truth number of triangles can be computed exactly using the naive algorithm . Even with small M trièst impr achieves very low MAPE value . As expected , larger M corresponds to higher accuracy and for the same M trièst impr outperforms trièst base . Figure 4(b ) shows the average time per update in microseconds ( µs ) for trièst impr as function of M . Larger M requires longer update times ( a larger sample implies larger graph on which to count triangles ) . On average a few hundreds of microseconds are sufficient for handling any update even in very large graphs with billions of edges . Our algorithms can handle hundreds of thousands of edge updates per second with very small error ( Fig 4(a) ) , and therefore can be used efficiently and effectively in high velocity contexts . Alternative edge orders . In all previous experiments the edges are added in their natural order ( ie , in order of their appearance).12 While the natural order is the most important use case , we have assessed the impact of other ordering on the accuracy of the algorithms . We experiment with both the uniform at random ( uar ) order of the edges and the random BFS order : until all the graph is explored a BFS is started from a uar unvisited node and edges are added in order of their visit ( neighbors are explored in uar order ) . The results for the random BFS order ( Fig 5 ) and for the
12Excluding twitter for which we used the random order , given the lack of timestamps .
0 2e+08 4e+08 6e+08 8e+08 1e+09 1.2e+09 1.4e+09 0 5e+06 1e+07 1.5e+07 2e+07 2.5e+07 3e+07 3.5e+07TrianglesTimeTriangle Estimation vs Timeground truthmax est . TRIEST IMPR.min est . TRIEST IMPR.max est . MASCOT Imin est . MASCOT I 0.001 0.01 0.1 1patent citlastfmMAPEMAPE vs MM=100000 BaseM=1000000 BaseM=100000 Improv.M=1000000 Improv . 1 10 100 1000 10000patent citpatent coautlastfmtwitteryahooAvg Micros/OperationAvg Micros/Operation vs MM=100000 Improv.M=1000000 Improv.832 Figure 5 : Average MAPE on Patent ( Co Aut. ) , with p = 0.01 – insertion only in Random BFS order . trièst impr has the lowest error .
Figure 7 : Trade offs between the avg . update time ( µs ) and M for trièst fd .
( a ) Patent ( Co Aut . )
( b ) Patent ( Cit . )
( c ) LastFm
( d ) Yahoo! Answers
Figure 6 : Evolution of the global number of triangles – fully dynamic case . uar ( omitted for lack of space ) confirm that trièst has the lowest error and is very scalable in every tested ordering . 5.2 Fully dynamic case
We evaluate trièst fd on fully dynamic streams . We cannot compare trièst fd with the algorithms previously used [ 18 , 27 , 32 ] as they only handle insertion only streams . In the first set of experiments we model deletions using the widely used sliding window model , where a sliding window of the most recent edges defines the current graph . The sliding window model is of practical interest as it allows to observe recent trends in the stream . For Patent ( Co Aut . ) & ( Cit . ) we keep in the sliding window the edges generated in the last 5 years , while for LastFm we keep the edges generated in the last 30 days . For Yahoo! Answers we keep the last 100 millions edges in the window13 . Figure 6 shows the evolution of the global number of triangles in the sliding window model using trièst fd using M = 200,000 ( M = 1,000,000 for Yahoo! Answers ) . The sliding window scenario is significantly more challenging than the addition only case ( very often the entire sample of edges is flushed away ) but trièst fd maintains good vari13The sliding window model is not interesting for the Twitter dataset as edges have random timestamps . We omit the results for Twitter but trièst fd is fast and has low variance .
Graph
LastFM
Pat . ( Co Aut . )
Pat . ( Cit . )
M
200000 1000000 200000 1000000 200000 1000000
Avg . Global
Avg . Local
MAPE 0.005 0.002 0.01 0.001 0.17 0.04
Pearson
0.98 0.999 0.66 0.99 0.09 0.60
ε Err . 0.02 0.001 0.30 0.006 0.16 0.13
Table 4 : Estimation errors for trièst fd . ance and scalability even when , as for LastFm and Yahoo! Answers , the global number of triangles varies quickly . Continuous monitoring of triangle counts with trièst fd allows to detect patterns that would otherwise be difficult to notice . For LastFm ( Fig 6(c ) ) we observe a sudden spike of several order of magnitudes . The dataset is anonymized so we cannot establish which songs are responsible for this spike . In Yahoo! Answers ( Fig 6(d ) ) a popular topic can create a sudden ( and shortly lived ) increase in the number of triangles , while the evolution of the Patent co authorship and co citation networks is slower , as the creation of an edge requires filing a patent ( Fig 6(a ) and ( b) ) . The almost constant increase over time14 of the number of triangles in Patent graphs is consistent with previous observations of densification in collaboration networks as in the case of nodes’ degrees [ 26 ] and the observations on the density of the densest subgraph [ 13 ] . Table 4 shows the results for both the local and global triangle counting estimation provided by trièst fd . In this case we can not compare with previous works , as they only handle insertions . It is evident that precision improves with M values , and even relatively small M values result in a low MAPE ( global estimation ) , high Pearson correlation and low ε error ( local estimation ) . Figure 7 shows the tradeoffs between memory ( ie , accuracy ) and time . In all cases our algorithm is very fast and it presents update times in the order of hundreds of microseconds for datasets with billions of updates ( Yahoo! Answers ) . Alternative models for deletion . We evaluate trièstfd using other models for deletions than the sliding window model . To assess the resilience of the algorithm to massive deletions we run the following experiment . We added edges in their natural order but each edge addition is followed with probability q by a mass deletion event where each edge cur14The decline at the end is due to the removal of the last edges from the sliding window after there are no more edge additions .
0.01 0.1 1TRIEST BASETRIEST IMPRMASCOT CMASCOT IJHA ET AL.PAVAN ET ALAvg MAPEAvg . MAPE vs Algorithm 200000 0 200000 400000 600000 800000 1e+06 1.2e+06 1.4e+06 0 1e+06 2e+06 3e+06 4e+06 5e+06 6e+06TrianglesTimeTriangle Estimation vs Timeground truthavg est.+std devavg est. std sdvavg est. 200000 0 200000 400000 600000 800000 1e+06 1.2e+06 1.4e+06 1.6e+06 0 5e+06 1e+07 1.5e+07 2e+07 2.5e+07 3e+07TrianglesTimeTriangle Estimation vs Timeground truthavg est.+std devavg est. std sdvavg est . 0 2e+07 4e+07 6e+07 8e+07 1e+08 1.2e+08 0 1e+07 2e+07 3e+07 4e+07 5e+07 6e+07 7e+07 8e+07TrianglesTimeTriangle Estimation vs Timeground truthavg est.+std devavg est. std sdvavg est. 5e+09 0 5e+09 1e+10 1.5e+10 2e+10 2.5e+10 0 5e+08 1e+09 1.5e+09 2e+09 2.5e+09TrianglesTimeTriangle Estimation vs Timeavg est.+std devavg est. std sdvavg est . 1 10 100 1000 10000patent citpatent coautlastfmyahooAvg Micros/OperationAvg Micros/Operation vs MM=200000M=500000M=1000000833 rently in the graph is deleted with probability d independently . We run experiments with q = 3,000,000−1 ( ie , a mass deletion expected every 3 millions edges ) and d = 0.80 ( in expectation 80 % of edges are deleted ) . We observe that trièst fd maintains a good accuracy and scalability even in face of a massive ( and unlikely ) deletions of the vast majority of the edges : eg , for LastFM with M = 200000 ( resp . M = 1,000,000 ) we observe 0.04 ( resp . 0.006 ) Avg . MAPE . More results are available in our full version online [ 9 ] .
6 . CONCLUSIONS
We presented trièst , the first suite of algorithms that use reservoir sampling and its variants to continuously maintain unbiased , low variance estimates of the local and global number of triangles in fully dynamic graphs streams of arbitrary edge/vertex insertions and deletions using a fixed , user specified amount of space . Our experimental evaluation shows that trièst outperforms state of the art approaches and achieves high accuracy on real world datasets with more than one billion of edges , with update times of hundreds of microseconds . Interesting directions for future work include the use of color coding techniques [ 30 ] , and the extension to 3 profiles and complex graph motifs [ 11 ] . Acknowledgments . This work was supported in part by NSF grant IIS 1247581 and NIH grant R01 CA180776 . 7 . REFERENCES [ 1 ] N . K . Ahmed , N . Duffield , J . Neville , and R . Kompella .
Graph Sample and Hold : A framework for big graph analytics . KDD’14 .
[ 2 ] Z . Bar Yossef , R . Kumar , and D . Sivakumar . Reductions in streaming algorithms , with an application to counting triangles in graphs . SODA’02 .
[ 3 ] L . Becchetti , P . Boldi , C . Castillo , and A . Gionis . Efficient algorithms for large scale local triangle counting . TKDD 4 ( 3):13:1–13:28 , 2010 .
[ 4 ] J . W . Berry , B . Hendrickson , R . A . LaViolette , and C . A .
Phillips . Tolerating the community detection resolution limit with edge weighting . Phys . Rev . E , 83(5):056119 , 2011 .
[ 5 ] P . Boldi , M . Rosa , M . Santini , and S . Vigna . Layered label propagation : A multiresolution coordinate free ordering for compressing social networks . WWW’11 .
[ 6 ] L . S . Buriol , G . Frahling , S . Leonardi ,
A . Marchetti Spaccamela , and C . Sohler . Counting triangles in data streams . PODS’06 .
[ 7 ] Ò . Celma Herrada . Music recommendation and discovery in the long tail . UPF Technical report , 2009 .
[ 8 ] E . Cohen , G . Cormode , and N . Duffield . Don’t let the negatives bring you down : sampling from streams of signed updates . SIGMETRICS’12 .
[ 9 ] L . De Stefani , A . Epasto , M . Riondato , and E . Upfal .
TRIÈST : Counting local and global triangles in fully dynamic streams with fixed memory size . CoRR , abs/1602.07424 , 2016 . http://arxivorg/pdf/160207424pdf
[ 10 ] J P Eckmann and E . Moses . Curvature of co links uncovers hidden thematic layers in the world wide web . PNAS , 99(9):5825–5829 , 2002 .
[ 11 ] E . R . Elenberg , K . Shanmugam , M . Borokhovich , and
A . G . Dimakis . Beyond triangles : A distributed framework for estimating 3 profiles of large graphs . KDD’15 .
[ 12 ] A . Epasto , S . Lattanzi , V . Mirrokni , I . O . Sebe , A . Taei , and S . Verma . Ego net community mining applied to friend suggestion . Proceedings of the VLDB Endowment , 2015 .
[ 13 ] A . Epasto , S . Lattanzi , and M . Sozio . Efficient densest subgraph computation in evolving graph . WWW’15 .
[ 14 ] R . Gemulla , W . Lehner , and P . J . Haas . Maintaining bounded size sample synopses of evolving datasets . VLDBJ , 17(2):173–201 , 2008 .
[ 15 ] A . Hajnal and E . Szemerédi . Proof of a conjecture of
P . Erdős . Combinat . theo . and its appl . , II , 601–623 , 1970 .
[ 16 ] B . H . Hall , A . B . Jaffe , and M . Trajtenberg . The NBER patent citation data file : Lessons , insights and methodological tools . NBER Technical report , 2001 . [ 17 ] R . J . Hyndman and A . B . Koehler . Another look at measures of forecast accuracy . Int . J . Forecasting , 22(4 ) : 679–688 , 2006 .
[ 18 ] M . Jha , C . Seshadhri , and A . Pinar . A space efficient streaming algorithm for estimating transitivity and triangle counts using the birthday paradox . TKDD , 9(3 ) : 15:1–15:21 , 2015 .
[ 19 ] H . Jowhari and M . Ghodsi . New streaming algorithms for counting triangles in graphs . Computing and Combinatorics , LNCS 3595 , 710–716 , 2005 .
[ 20 ] D . M . Kane , K . Mehlhorn , T . Sauerwald , and H . Sun .
Counting arbitrary subgraphs in data streams . ICALP’12 .
[ 21 ] M . N . Kolountzakis , G . L . Miller , R . Peng , and C . E .
Tsourakakis . Efficient triangle counting in large graphs via degree based vertex partitioning . Internet Mathematics , 8 ( 1–2):161–185 , 2012 .
[ 22 ] K . Kutzkov and R . Pagh . On the streaming complexity of computing local clustering coefficients . WSDM’13 .
[ 23 ] K . Kutzkov and R . Pagh . Triangle counting in dynamic graph streams . SWAT’14 .
[ 24 ] H . Kwak , C . Lee , H . Park , and S . Moon . What is Twitter , a social network or a news media ? WWW’10 .
[ 25 ] M . Latapy . Main memory triangle computations for very large ( sparse ( power law ) ) graphs . TCS , 407(1):458–473 , 2008 .
[ 26 ] J . Leskovec , J . Kleinberg , and C . Faloutsos . Graph evolution : Densification and shrinking diameters . TKDD , 1 ( 1):2 , 2007 .
[ 27 ] Y . Lim and U . Kang . MASCOT : Memory efficient and accurate sampling for counting local triangles in graph streams . KDD’15 .
[ 28 ] M . Manjunath , K . Mehlhorn , K . Panagiotou , and H . Sun .
Approximate counting of cycles in streams . ESA’11 .
[ 29 ] R . Milo , S . Shen Orr , S . Itzkovitz , N . Kashtan ,
D . Chklovskii , and U . Alon . Network motifs : simple building blocks of complex networks . Science , 298(5594 ) : 824–827 , 2002 .
[ 30 ] R . Pagh and C . E . Tsourakakis . Colorful triangle counting and a MapReduce implementation . IPL , 112(7):277–281 , 2012 .
[ 31 ] H M Park and C W Chung . An efficient MapReduce algorithm for counting triangles in a very large graph . CIKM’13 .
[ 32 ] A . Pavan , K . Tangwongsan , S . Tirthapura , and K L Wu .
Counting and sampling triangles from a graph stream . VLDB’13 .
[ 33 ] S . Suri and S . Vassilvitskii . Counting triangles and the curse of the last reducer . WWW’11 .
[ 34 ] The Koblenz Network Collection ( KONECT ) . Last.fm song network dataset . http://konectuni koblenzde/networks/lastfm_song
[ 35 ] C . E . Tsourakakis , U . Kang , G . L . Miller , and C . Faloutsos . Doulion : counting triangles in massive graphs with a coin . KDD’09 .
[ 36 ] C . E . Tsourakakis , M . N . Kolountzakis , and G . L . Miller .
Triangle sparsifiers . JGAA , 15(6):703–726 , 2011 .
[ 37 ] J . S . Vitter . Random sampling with a reservoir . TOMS , 11
( 1):37–57 , 1985 .
[ 38 ] Yahoo! Research Webscope Datasets . Yahoo! Answers browsing behavior version 10 http://webscopesandboxyahoocom
834
