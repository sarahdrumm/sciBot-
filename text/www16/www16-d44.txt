In a World That Counts : Clustering and Detecting
Fake Social Engagement at Scale
∗ Yixuan Li
Cornell Unversity
Ithaca , NY 14853 , USA yli@cscornelledu
Oscar Martinez
Google Inc .
Mountain View , CA omartinez@google.com
Xing Chen Google Inc .
Mountain View , CA chenxing@google.com
6 1 0 2 n a J
0 2
] I S . s c [
2 v 7 5 4 5 0
.
2 1 5 1 : v i X r a
Yi Li
Google Inc .
Mountain View , CA yiyili@google.com
ABSTRACT How can web services that depend on user generated content discern fake social engagement activities by spammers from legitimate ones ? In this paper , we focus on the social site of YouTube and the problem of identifying bad actors posting inorganic contents and inflating the count of social engagement metrics . We propose an effective method , Leas ( Local Expansion at Scale ) , and show how the fake engagement activities on YouTube can be tracked over time by analyzing the temporal graph based on the engagement behavior pattern between users and YouTube videos . With the domain knowledge of spammer seeds , we formulate and tackle the problem in a semi supervised manner — with the objective of searching for individuals that have similar pattern of behavior as the known seeds — based on a graph diffusion process via local spectral subspace . We offer a fast , scalable MapReduce deployment adapted from the localized spectral clustering algorithm . We demonstrate the effectiveness of our deployment at Google by achieving a manual review accuracy of 98 % on YouTube Comments graph in practice . Comparing with the state of the art algorithm CopyCatch , Leas achieves 10 times faster running time on average . Leas is now actively in use at Google , searching for daily deceptive practices on YouTube ’s engagement graph spanning over a billion users .
Keywords Fake social engagement ; Anomaly detection ; Local spectral clustering ; Seed expansion ; Social networks
∗Work done while interning at Google Inc .
John E . Hopcroft Cornell University
Ithaca , NY 14853 , USA jeh@cscornelledu
1 .
INTRODUCTION
Every day people generate a large amount of comments on YouTube but not all of those engagement activities are real . Bad actors have been trying to game the system by posting inorganic contents and inflating the count of social engagement metrics .
We consider any practice that attempts to post fake contents , or artificially inflate the number of YouTube engagement metrics through the use of automated means or as a marketplace , as illegitimate activity . Generally speaking , any engagement activity in online social media that does not reflect user ’s genuine interest can be viewed as fake social engagement .
The issue of fake social engagement came into being partly due to that third party businesses attempt to boost YouTube video engagement metrics in order for promoting contents and increasing popularity . At Google , we have seen attackers attempting to take advantage of the YouTube community by using a variety of deceptive practices [ 2 ] , including malware , fake accounts , artificial traffic spam and comment spam . Among the various forms of spam activity , fake social engagement has become the most frequently seen yet hardest to detect practice . In particular , we have discovered that abusive YouTube comments have evolved from traditionally explicit spammy like ( eg linked with bad URLs or associated with obvious advertisement ) , to a more insinuated outlook that makes them difficult to discern from those organic comments . For instance , one common type of fake YouTube comments comprises text pieces such as “ cool ” , “ oh ” , which has made approaches largely basing on text features and bad URL detection insufficient in such scenario .
At Google , we note the importance of keeping the service free of fake engagement activities that may potentially spoil the online social ecosystem . As the YouTube official policy guide on subscription [ 1 ] states , for example :
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author ’s site if the Material is used in electronic media . WWW 2016 , April 11–15 , 2016 , Montréal , Québec , Canada . ACM 978 1 4503 4143 1/16/04 . http://dxdoiorg/101145/28724272882972
Subscribing to a channel creates a relationship between a content creator and a content consumer ; the creator keeps making great videos , and the consumer keeps watching , like ing , and commenting . We take this relationship seriously . A subscription is a user initiated pledge of support to a
YouTube channel ; this means that a real human being wants this channel ’s content in their feed every day . The amount of users subscribed to a YouTube channel should be a metric that reflects genuine interest in that channel , not a gauge of automated or falsified activity .
And we believe that such policy does not only apply to YouTube Subscribes , but can also be extended to other engagement activities such as Comments as well . As a matter of fact , YouTube is far from the only social media facing the challenge of keeping its service free of deceptive practices . Twitter Followers and Facebook Likes are all buyable by the thousand online [ 11 ] , for example .
To address these issues , we study the temporal engage ment activity patterns on YouTube , making use of anonymized aggregate daily logs of YouTube Comments . We create the engagement relationship graph by taking account the frequency of common engagement activities shared between two individuals within a short period of time . The engagement graph allows us to detect orchestrated actions by sets of users which have a very low likelihood of happening spontaneously or organically . Such behavior of groups of users acting together on the same videos or channels at around the same time , is also known as lockstep behavior [ 7 ] .
To detect the lockstep behavior on YouTube , we take a semi supervised learning approach , making use of existing known abusive accounts as seeds . We demonstrate an effective method , Leas ( Local Expansion at Scale)1 , in detecting deceitful user engagement based on the local spectral graph diffusion [ 20 ] . Local spectral method has substantial advantage over traditional spectral techniques because of its capability in prioritizing and finding clusters only near a local region of the engagement graph surrounding the seed . Specifically , Leas searches for clusters consisting of suspicious nodes with similar pattern of behavior as the given seeds . We show Leas is scalable to massive datasets , with a straightforward adaption to the MapReduce implementation . Moreover , the MapReduce deployment has the same performance guarantee as the serialization since each diffusion procedure is performed locally . By clustering YouTube users based on their engagement behavior pattern , Leas can greatly expand the coverage of daily fake engagement takedown volume on YouTube . Our approach can be extended to many other settings including Twitter followers , Amazon product reviews and Facebook Likes etc .
The ultimate goal of our research effort is to help improve social media environment as well as user experience , and to ensure an online world where contents and clicks can be translated into genuine and meaningful interactions . Toward achieving the goal , this paper offers a number of contributions listed in the following :
1 . Problem Formulation : We provide a novel problem formulation — a semi supervised learning problem based on the local spectral graph diffusion — to a real world challenge realized at Google and relevant in many online settings . One advantage of our setting is its full generality . That is , it is applicable for any similarity based graph without much need for customization .
1Interestingly , the word “ leas ” has the meaning of “ wellbeing ” in old Irish .
2 . Algorithm : We offer a fast , scalable MapReduce implementation adapted from the localized spectral clustering algorithm [ 20 ] . This is the first large scale deployment of local spectral clustering to the best of our knowledge .
3 . Behavioral Analysis : We show comprehensive performance evaluations on Leas — focusing on multitudes of different characteristics exhibited by abusive accounts compared to that of general population — using both structural and contextual information .
The remainder of the paper is organized as follows . Sec tion 2 describes related work on using graph based approaches in detecting anomalies . In Section 3 and Section 4 we mathematically formulate the problem and describe how it can be solved in a semi supervised learning framework . We introduce the YouTube engagement graph dataset in Section 5 . A MapReduce implementation is discussed in Section 6 . Finally in Section 7 we offer experimental analysis , demonstrating the usefulness of our deployment at Google ; and conclude our work in Section 8 . 2 . RELATED WORK
Online spam activities are evolving as fast as the web services themselves . Abusive actions have been observed in a wide range of domains , including Email [ 10 ] , web search [ 4 , 9 , 25 , 32 , 34 ] and blogs [ 17 ] . In recent years , spam campaigns have also been prevalently emerging on major social media sites [ 12 , 28 ] , with a diverse set of application targets spanning YouTube [ 6 , 26 ] , Facebook [ 7 , 8 , 11 ] , Amazon [ 21 , 24 ] , Twitter [ 5 , 30 ] , eBay [ 27 ] , and many others .
A number of content based spam detection strategies have been exploited in the past decade [ 9 , 25 , 32 , 34 ] . Most of the proposed methods rely on extracting evidences from textual descriptions of the content , treating the text corpus as a set of objects with associated attributes , and applying classification method such as Support Vector Machine ( SVM ) [ 16 ] to detect spam [ 14 , 25 ] . A few other more sophisticated methods also take into account the multimedia information such as image features [ 23 , 35 ] .
Content and link based approaches , however , can be infeasible in identifying fake social engagement when contextual information is unavailable , or faking to be organic like . Many papers tend to devise feature based classifiers incorporating various account level as well as social relationship features [ 6 , 28 , 37 ] . While these supervised training models are useful at depicting the spam strategy behind the observed temporal dynamics , it is nonetheless unclear how generalizable they are beyond the particular product or signal studied . Furthermore , it is practically difficult to obtain large volumes of training data because manual labeling can be expensive . To this end , recent proposals based on behavioral clustering have demonstrated to be effective in spotting groups of users with similar behavior patterns in terms of engagement activities [ 7 , 8 , 15 , 24 , 31 , 29 ] . These methods often start with constructing a bipartite graph representing user product engagement relationships . Various unsupervised clustering techniques ( eg , co clustering [ 7 ] and community detection [ 29 ] ) have been applied for detecting groups of actors with similar behavior . Below we highlight a few and illustrate how our work contributes to this line .
More related to our own work , Beutel et al .
[ 7 ] investigated the problem of fake Page Likes on Facebook and ob served a lockstep behavior pattern exhibited by spammers , where groups of users often acting together and Like ing the same Pages in a loosely synchronized manner . Such collaborative spamming behavior was also observed in Twitter [ 18 ] and also Amazon product reviews [ 24 ] , where paid groups of frequent fake review writers have been trying to promote or demote certain products on Amazon . The incremental work [ 8 ] further extended the CopyCatch approach [ 7 ] to several other applications such as Facebook app install and Instagram follow . Note that our setting advances [ 7 ] by making use of possible domain information in a semi supervised manner ; and our problem formulation is also complementary to [ 24 ] which required a large number of both positive and negative examples in a fully supervised manner .
Our work builds on these papers , providing advances in two aspects : algorithmically , our clustering algorithm is operated in a fully localized fashion , which is efficient to compute and easily parallelizable ; practically , our framework is fully generalizable , which can be extended to other behavioral clustering problems and applications without much need for customization . 3 . PROBLEM FORMULATION
We now describe the mathematical formulation of our problem . We take a semi supervised approach and define suspicious behavior in terms of graph structure and edge creation times .
To make our problem definition more generalizable , we adopt the notions of actor and target in representing the entities involved in an engagement activity . For example , in the context of YouTube Comments , a target can be translated into a video .
In the following , we introduce two types of graph that can be created using the engagement activity information . A straightforward way is to build an engagement bipartite graph between the set of actors and the set of target , where we use edge to indicate the engagement timestamp . Since we are interested in clustering entities of actors , a more refined way would be to construct an engagement relationship graph , in which nodes consist of all the actors and two nodes share an edge if they have acted upon the same target(s ) . Mathematically , assuming we are provided with a set of i=1 and a set of targets Q = {qj}|K| actors , V = {vi}|V| j=1 . We are also given a set of seeds S = {sr}|S| r=1 . Each engagement activity can be described by a tuple of ( vi , qj , tvi→qj ) , where tvi→qj records the timestamp at which actor vi acted on target qj .
• Engagement Bipartite : We define B = ( V,Q,T ) as a temporal engagement bipartite graph , where each timestamped edge ( vi , qj ) ∈ T records the time at which vi ∈ V acted on qj ∈ Q . We further enforce the temporal constraint that all the actors acted on the targets in a 2∆t time window , ie ,
∃tr ∈ R st |tr − tvi→qj| ≤ ∆t ∀vi ∈ V , qj ∈ Q ( 1 ) • Engagement Relationship Graph : We define G = ( V,E,W ) as a temporal engagement relationship graph . E is the edge set , where ( vi , vj ) ∈ E if actors vi and vj have acted upon the same non empty set of target Qvi,vj ⊆ Q , with weight denoted by wvi,vj ∈ W . Further details regarding the edge weight will be discussed in Section 5 .
Throughout the paper , our methods and analysis will be focusing on the engagement relationship graph . And we will henceforth use the term engagement graph for brevity . Given : An engagement graph G = ( V,E,W ) that models the intensity engagement relationship between nodes ; and the seed set S . Output : Accomplice clusters C1 , C1 , , C|S| corresponding to each seed in the set S . Each cluster consists of suspicious nodes with similar pattern of behavior as the given seed , which satisfy the definition of [ n , m , ρ , ∆t] temporally approximate bipartite core ( T ABC ) given below .
Definition 1 . We define an [ n , m , ρ , ∆t] temporally approximate bipartite core ( T ABC ) with respect to a given seed s ∈ S , as a set of actors C ⊆ V associated with a set of edges E ⊆ E such that s ∈ C |C| ≥ n |E| ≥ ρ · n(n − 1 ) wvi,vj ≥ m ∀(vi , vj ) ∈ E
2
( 2 )
( 3 )
( 4 )
( 5 ) Here we introduce the term ρ ∈ [ 0 , 1 ] to relax the constraint in the original definition of [ n , m , ∆t] temporally coherent bipartite core ( TBC ) in [ 7 ] . We make such change since we find many loosely connected abusive clusters existing in practice . Relaxing the constraint enables us finding both tightly and loosely connected groups of suspicious actors .
4 . SEMI SUPERVISED LEARNING VIA LO
CAL SPECTRAL DIFFUSION
We use the semi supervised learning method to tackle the problem of detecting the suspicious actor groups defined in previous Section . Graph based learning approach can be viewed as a probability diffusion that propagates large values from a small set of nodes with known labels — which are usually referred to as seeds in literature — to the remaining nodes of the graph [ 13 ] . This type of approach typically starts with a graph and the labeled sample matrix S ∈ RN×K , where N is the number of nodes in the graph and K is the number of classes . Si,j = 1 if node i is labeled with class j , and Si,j = 0 otherwise . A graph based learning framework usually incorporates two essential parts . The first is to produce an N × K matrix Y which encodes the probability for each unlabeled node to be in certain classes . Specifically , Yi,j should be large if node i should be labeled as class j . In our problem setting of binary classification , the diffusion matrix can be reduced to a vector y ∈ RN , where larger value indicates a higher possibility being labeled the same as the seeds . And the second key component is to decode the diffusion values in y into a predicted label based on some graph metric optimization criterion . In the following , we will provide details on both components of our learning algorithm .
Local spectra vs . global spectra Spectral methods is one of the most widely used techniques for exploratory data analysis , with applications ranging from data clustering , image segmentation to community detection etc . Spectral clustering makes use of the first few singular vectors of the Laplacian matrix associated with a graph , which are inherently global quantities and may not be sensitive to very local information [ 22 ] . For example , in the case when provided with domain knowledge about a target region in the graph , one might be interested in finding clusters only near the specified local region in a semi supervised manner , which might not be otherwise well captured by a method using global eigenvectors . Therefore , in the semi supervised setting , our pioneer work on local spectral clustering [ 20 ] have substantial advantage over traditional spectral techniques , with the capability of prioritizing and learning more about a local region of the graph surrounding the seeds . 4.1 Degree thresholded Sampling
We apply a degree thresholded sampling procedure using breadth first search ( BFS ) to get a small subgraph Gs covering a local neighborhood region surrounding the seed . Starting from the given seed s , we take the set of frontier nodes — except for those nodes with degree larger than dmax — into the subgraph node set and repeat the process until the size of the subgraph reaches the specified upper limit N . We enforce the degree thresholding to prevent including extremely high degree nodes , which are less likely to be spammers2 . In practice , we choose the parameter of N to be at least several times larger than the maximum size of the cluster of interest |Cs| , in order to capture as many nodes in the target group as possible . 4.2 Local Spectral Subspace
Consider the subgraph graph Gs extracted from the neighborhood surrounding the seed s . We define the normalized adjacency matrix ¯As of the graph Gs as
¯As def = D
−1/2 s
( As + I)D
−1/2 s
,
( 6 ) where As and Ds denotes the adjacency matrix and the diagonal degree matrix of Gs , respectively . Let p0 denote the initial probability vector with element 1 in the entry of the seed node and 0 elsewhere . We describe how to efficiently construct the local spectra by iteratively transforming the orthonormal basis starting with a Krylov subspace defined below .
Definition 2 . The order l + 1 Krylov subspace generated by the matrix A and vector p0 is the linear spanned subspace defined by the probability vectors in l successive random walks
Kl+1(A , p0 ) = span p0 , Ap0 , , Alp0
.
( 7 )
In Algorithm 1 , we briefly summarize the procedure of calculating the local spectral subspace from a specified seed . We start by calculating the initial invariant subspace V0,l , which is the orthonormal basis of Kl+1(AS , p0 ) . And the local spectral subspace can be then obtained by iterating the process specified in Line 4 6 of Algorithm 1 . The random walk step k and subspace dimension l are the key parameters in the local spectral clustering algorithm . Following the heuristics in [ 20 ] , we set k = 3 and l = 3 respectively . Figure 1 [ 19 ] shows an example local spectral subspace V3,3 , generated from a synthetic graph with Erd˝os R´enyi G(n , p ) model . The visualization demonstrates that local spectral 2We set dmax to be 500 by default . This is because the degree of most known spammer nodes is smaller than 500 , as shown in Figure 3 .
Figure 1 : An example of local spectral subspace V3,3 . The synthetic subgraph Gs is generated with Erd˝osR´enyi G(n , p ) model with background noise p = 005 The spammer group A and B ( denoted by blue and pink respectively ) are of size 100 with edge probabolity p = 0.9 , with partially overlapped 20 nodes . The non spammer group C ( denoted by the green color ) has size 320 with p = 02 The subspace is generated by Algorithm 1 starting from the seed with index 10 in the spammer group A . subspace enables capturing the closeness of entities belonging to the same group . 4.3 Learning via Local Spectral Diffusion
With the local spectra Vk,l , we then solve the following
1 norm optimization problem . min ||y||1 st y = Vk,lz , y ≥ 0 , y(s ) ≥ 1 ,
( 8 )
( 9 ) ( 10 )
( 11 ) where the objective function itself is a regularized term with sparsity penalty . Both z and y are unknown vectors . The first constraint indicates that y is in the space of Vk,l . The element in y indicate the likelihood for the corresponding node being labeled the same as seed s , which is non negative . The third constraint enforces that seeds are in the support of sparse vector y .
To interpret the optimization formulation from a geometric perspective , we are essentially seeking a sparse vector in the span of the local spectral subspace , such that the seed is in its support . In other words , the learning objective here is a locally biased spectral program which enforces the solution to be well connected with the known seed s .
Algorithm 1 LocalSpectral(Gs , s ) Input : subgraph Gs , subspace dimension l , and random walk step k
Output : local spectra Vk,l 1 : Compute normalized adjacency matrix ¯As using ( 6 ) 2 : Initialize p0 3 : V0,l = orth(Kl+1( ¯As , p0 ) ) 4 : for i = 1 , , k do 5 :
Ri,l ∈ Rn×l is obtained by
Vi,lRi,l = ¯AsVi−1,l
QR factorization so that Vi,l is orthonormal .
6 : end for subspace 4.4 Round Diffusion Vector via Sweeping Cut The optimization result y obtained above is a real valued vector , where each element yi hints the propensity for node i to be labeled the same as seed . A commonly adopted method of rounding the diffusion values into labels is to perform a sweep cut procedure on the nodes ranked by the diffusion value , with an objective of minimizing the graph cut metric such as conductance [ 3 , 22 , 33 ] .
Definition 3 . Let x ∈ {0 , 1}N denote the binary indicator vector for the subset V ⊆ Vs and H ∈ RN×N is any symmetric matrix . The Rayleigh quotient with respect to H is expressed as the quadratic form of xT Hx xT x
ρH(x ) =
( 12 ) In particular , conductance of the set V measures the fraction of edges leaving V among all the edges incident on V , and can be expressed using a generalized Rayleigh quotient
.
Φ(V xT ( Ds − As)x
. xT Lsx xT Dsx
=
) = ρLs,Ds ( x ) =
( 13 ) We label each node in Vs by first ranking nodes in decreasing order based on the corresponding value in y . For each prefix set of node V(|V| ≥ n ) in the sorted list , we then compute the conductance of that set and return the set that achieves the minimum , ie , xT Dsx
In the engagement graph , nodes represent users and edges represent common videos or channels on which the users engage . Users that have interacted with a common video will share an edge and are consequently joined in the graph . Edge weights are by default computed based on the number of common engagement activities between two nodes . For example , in the case of users commenting on a YouTube video , this approach translates into users having and edge weight between them equal to the number of common videos they have commented upon .
Adding weight penalty The way we built the YouTube Comments engagement graph is essentially the same as above except for the subtle difference that node can be two types of entities – a user or a Google+ Page . It is worthwhile noting here that YouTube comments can be made through the Google+ social platform , without having to log into the YouTube sites . Such feature was powered by YouTube ’s Google+ comment integration system introduced in November , 2013 . Each PlusPage behaves like a unique user ID and can be used to write comments across platforms including YouTube .
C
= arg minV⊆Vs
Φ(V
)
( 14 )
Lemma 1 . The set C ⊆ Vs found by the local spectral diffusion method is an [ n , m , xT Asx xT ( J−I)x , ∆t] temporally approximate bipartite core , where x ∈ {0 , 1}N is the binary indicator vector for C and J ∈ RN×N is a matrix of all ones .
Proof . The constraint of |C| ≥ n is automatically met by the sweeping cut procedure . The fact that Gs only consists of edges with weight greater than m also ensures the xT Asx constraint specified in ( 5 ) . Furthermore , xT ( J−I)x is the quadratic equivalence to the internal density measurement of a cluster , ie , 2|E|/n(n − 1 ) .
5 . USER ENGAGEMENT GRAPH 5.1 Graph Builder
We create engagement graph by using interactions between users to model the way users interact with a video or a channel . This allows us to detect orchestrated actions by sets of users which have a very low likelihood of happening spontaneously or organically .
In practice , the YouTube Comment engagement graph is built with the anonymized aggregate YouTube user activity logs from the past 30 days window , and is updated on a daily basis using a MapReduce implementation . Here we take the snapshot of graph created on August 3rd , 2015 . The Comment engagement graph consists of hundreds of thousands of nodes and tens of millions of edges . The detailed statistics of the engagement graph in use are not discussed here for privacy reasons . Note that the engagement graph we created here constitutes a subgraph of the entire YouTube engagement graph , where we only captured entities that had activities within the scope of a month .
Figure 2 : Example of constructing Google+ pages engaged graph . It shows a group of two users using their PlusPages to spam video #1 .
In order to detect abuse originating from PlusPages , we add an additional step when constructing the graph . This modification tend to penalize those PlusPages created by the same user the following way :
˜wpi,pj = 1(u(pi ) = u(pj ) ) · |P(u(pi))| + wpi,pj ,
( 15 ) where 1(· ) is the indicator function ; u(· ) defines the owner of a PlusPages and P(· ) gives the set of PlusPages a user has created . We use wpi,pj to denote the original edge weight between PlusPages pi and pj , and is calculated by the number of common videos both pi and pj commented on . ˜wpi,pj is the updated edge weight , and is equal to wpi,pj when pi and pj share different owners . In the case where pi and pj are created by the same user , we add extra weight regulated by the total number of PlusPages the user has created . The rationale being that owning a larger number of PlusPages indicates a stronger signal of being potentially abusive .
Figure 2 gives an example of constructing Google+ pages It shows that the edge weight between engaged graph .
U1U2ABCDEGoogle+ pagesUsersVideos12345678BCDEA54331111 6 . A MAPREDUCE IMPLEMENTATION
Our local spectral diffusion method enables a straightforward adaption to the MapReduce implementation framework . In this Section , we introduce practical details and also potential caveats in applying the method at scale . The implementation is provably scalable to massive datasets and trivially parallelizable , with the capability of searching for many clusters simultaneously . Furthermore , our pipeline has the same performance guarantee as the serialization since each diffusion procedure is performed locally on the graph . Data Server The engagement graph is served using SSTableService , a distributed in memory key value serving system within Google . Each data server holds a partition containing 1/P of the total amount of data , where P denotes the number of shards ( partitions ) of the data . SSTableService allows serving graph queries in a much faster speed compared to on disk queries . The SSTableService is shared across mappers when running the job .
Data Format We use Protocol Buffers3 for defining the I/O data streams in our implementation . Each protocol buffer message is a small logical record of information , containing a series of name value pairs . The graph protocol namely stores the weighted adjacency list keyed by each node ; the seed protocol contains the IDs of the spammer seeds ; and the accomplice protocol defines the output of detected accomplice clusters consisting of suspicious nodes with similar pattern of behavior as the seed . Additionally , we define config protocol for conveniently encapsulating and passing configuration parameters to each mapper when initializing the jobs . Some tunable parameters in our pipeline include , for example , the dimensionality of local spectral subspace l , the number of short random walk steps k , the minimum cluster size n , the maximum size of the sampled subgraph N , the degree threshold dmax for sampling the subgraph , the edge weight threshold m .
Algorithm 2 MapReduce Leas Globals:graph G = ( A,E,W ) , configuration parameters 1 : InitializeReplica( ) 2 : for s ∈ S do 3 : 4 : 5 : if deg(s ) ≤ dmax then Sample subgraph Gs Vk,l = LocalSpectral(Gs , s ) compute local spectral subspace
Solve the optimization objective y in Section 4.3 C = SweepCut(y ) emit s , accomplice C
6 : 7 : 8 : 9 : 10 : end for end if
The core of the MapReduce Leas algorithm can be seen in Algorithm 2 . The module of InitializeReplica passes the parameters defined by the configuration protocol to all the mappers . And each mapper job processes one seed at a time independently . The entire pipeline of fake engagement detection is illustrated in Figure 4 , which encompasses the main components of graph builder and seed expander . The graph builder is also implemented using MapReduce framework , where the details are omitted here due to space limit .
3https://developersgooglecom/protocol buffers/
Figure 3 : Comparison of node degree distribution between spammers and the general population in YouTube Comment engagement graph . The degree distribution of seeds is depicted in magenta , whereas the distribution of general population is depicted in blue . The number of seeds used for plotting is 2k . To plot the general population distribution , we first randomly sampled 10k nodes from the engagement graph . We further excluded those known abusive nodes from the sampled population , which left us with 9,957 nodes . Note that the sampled population may contain unknown malicious nodes .
( A , B ) , ( A , C ) and ( B , C ) are all increased by 3 , which is the total number of PlusPages the user U1 has created . The clique structure formed by node A , B and C becomes more noticeable after applying the penalty .
5.2 Spammer Seeds
In the context of anomaly detection , when we find suspicious users , we often want to quickly find additional users with similar patterns of behavior that should be disabled as well . Leas makes use of those users that are identified to be abusive from other YouTube ’s security mechanisms as seeds . In practice , spammer seeds are also updated on a daily basis together with the engagement graph . Since the number of available seeds can be limited , Leas can greatly expand the coverage of daily fake engagement take down volume .
Degree distribution We started probing into the behavior pattern between the spammer nodes and the general population by examining the node degree distribution . A salient observation from Figure 3 is that the degree distribution of seeds ( depicted in magenta ) has a dissimilar tail effect compared to that of the general population ( depicted in blue ) . And the difference can be been across all engagement level activities , and it is the most evident in the Comments graph .
This observation surprisingly corresponds with the fact that spam campaigns and companies involved in selling fake engagements may have efforts in relatively modest scope and scale . For example , we looked into several existing online vendor sites that claim to sell YouTube fake engagement . Through investigation we found that YouTube comments are usually sold with package size ranging from 15 to several hundred , which matches exactly with the seed degree distribution in Figure 3 . For example , we find spammer nodes rarely have degree greater than 781 in the Comments graph .
100101102103104degree10 510 410 310 210 1100fraction of nodes Figure 4 : MapReduce implementation of YouTube fake engagement detection pipeline .
7 . EXPERIMENTAL ANALYSIS 7.1 Scalability YouTube now has over a billion users and is continuing to grow . Therefore , it is important for the algorithm scales well to large datasets in order to efficiently catch the fake engagement activities on a daily basis . We test and compare the performance with CopyCatch , which is the state ofthe art algorithm that detects fake Page Likes by analyzing the engagement graph of user Page interaction .
Firstly , we test the scalability of the algorithm by running our implementation on the YouTube Comments graph over different number of seeds . To make the test results comparable , we choose the same set of seed numbers as that reported in [ 7 ] . The number of seeds varies from 100 to 5,000 . We additionally run the pipeline with only 10 seeds to test the system starting up time . Depending on the resources availability , it usually takes about 4 ∼ 6 minutes for the system to allocate and set up the data servers and the MapReduce clusters . Figure 5a shows the comparison of running time between CopyCatch and Leas4 . It is worthwhile noting that Leas achieves 10 times faster running time with much fewer machines . For example , 3,000 mappers and 500 reducers were used for all the testing data points in [ 7 ] , whereas at most 1,500 mappers and 2 reducers are required in Leas test run with 5,000 seeds . Even fewer mappers are required for those tests with smaller number of seeds . For example , running the pipeline with 1,000 seeds uses 295 mappers , 2,000 seeds uses 597 mappers and 10,000 seeds uses 2,999 mappers . As seen in the results , we find that the running time of Leas is almost independent of the number of seeds . This is reassuring that our implementation exploits the parallelism of the problem and can continue to scale as the data scales . 7.2 Performance Evaluation
721 Graph Metrics To evaluate the accomplice clusters found by Leas , we first measure the structural properties using two commonly adopted metrics [ 36 ] .
4We refer to the experimental results originally reported in [ 7 ] for evaluation .
• Internal density measures the internal edge density of a node set V . A larger internal density value indicates a more densely connected community like structure among nodes . f ( V
2|E|
) =
|V|(|V| − 1 )
• Flake ODF is a cluster metric that takes into account both the internal and external connectivity of a set . It measure the fraction of nodes in V that have fewer edges pointing inside than to the outside of the set . Ideally , a smaller Flake ODF value indicates a better cluster quality . f ( V
|{v : v ∈ V,|{(v , u ) ∈ E : u ∈ V}| < deg(v)/2}|
) =
|V|
Figure 5 presents the measurement scores of accomplice clusters detected in three YouTube Comments engagement graph . The most striking observation is the difference concerning the internal density distribution exhibited by the Comments graph . We see that clusters detected from the engagement graph in general are compact with high internal density , which may signify the orchestration strategy when performing fake engagement — that the YouTube fake Comments spammers are exposed to have stronger lockstep behavior pattern , where groups of users acting together , commenting on the same videos at around the same time . The clusters corresponding to the tail part of the curve , on the other hand , displays a less orchestrated pattern with more likelihood to be incentivized campaigns . Our probe into the structural properties of the detected clusters also suggests that further evaluation is imperative . 722 YouTube Comment : Manual Review Results To verify the effectiveness of the algorithm , we ran the pipeline on the engagement graph built on August 3rd , 2015 within 30 days of time window , and performed intensive manual review on the detected accounts . In total , the pipeline detected roughly 24,000 unique accounts with 955 spammer seeds . Among the newly detected accounts , we find that 8,500 of them are found by more than one seed ; while the other 15,500 accounts are detected by only one seed . Figure
YouTubeengagement logGraph builderSSTableSSTableSSTableSSTableSSTableSSTableSSTableSSTableSSTableSSTableSpammer seedsSeed expansion mappersAccomplicesSSTableServiceEngagement graph ( a )
( b )
Figure 5 : ( a ) Comparison of pipeline running time with state of the art as the number of seeds increases . ( b ) Internal density and Flake ODF of detected accomplice clusters in YouTube Comments engagement graph . We filtered those seeds with degree greater than 500 , ie , dmax=500 and performed the diffusion algorithm on the rest of the seeds . The number clusters in plot is 955 . Cluster indices are sorted by the internal density value . find that this particular account was created less than 10 days ago yet had posted more than 253 posts with many quota exceeded . We manually clicked through the comments posted by these accounts , and found that most comments are short text pieces such as “ good videos ” , “ very cool ” , “ nice ” , “ oh ” , “ lol ” or emoji of smile faces . We also find the common pattern for accounts to post exactly the same or similar short , fake comments to different videos . Besides , we also discovered a few accounts posting comments under popular songs , the contents of which are irrelevant to the video content itself but rather asking for view and subscribe ( eg , “ please subscribe ” or “ subscribe now ” ) . Additionally , several other spammy accounts posting comments including malicious URLs and advertisement were detected .
Besides the contextual information , we also looked into the lifespan of each suspicious account . Although one might expect most spammer accounts to have relatively young age , it was actually quite surprising to see the age heterogeneity of those accounts , as shown in Figure 7a . Among the 36 accounts , the most frequent age falls into the range between 0.5 and 1.5 years ; whereas the oldest spammer account have already been existent for more than 6 years .
The Tier II accounts are the harder cases .
In order to guarantee the FP guards in production , we randomly selected 100 Tier II accounts that belong to an accomplice cluster with internal density greater than 07 The manual investigation shows that 98 % detected Tier II accounts to be fake5 . The comments posted by these accounts share similar pattern as those made by Tier I accounts . Quite interestingly , we indeed found a detected cluster of 15 accounts posting the same comments of either “ i love pets ” , “ yeah ” or URLs under certain videos . This further verified that the suspicious groups detected by the algorithm are of high accuracy . As for the other two accounts we are uncertain about , one has huge amount of Google+ shares of good deals although it posted nothing on YouTube comments ; another 4 month old account posts a mixture of both organic and fake like comments , which might be incentivized .
5In practice , we treat activities made by both Tier I and Tier II accounts as fake engagement .
Figure 6 : Detection frequency distribution of among the accounts detected by LEAS .
6 depicts the distribution of the frequency for each account being detected by certain seed(s ) . The fact that an account detected by several seeds is a stronger indication of being potentially abusive . We therefore divide the results into two types and perform analysis accordingly :
• Tier I : accounts that are repeatedly detected by more than one seed ( 35% ) .
• Tier II : accounts that are uniquely detected by only one seed ( 65% ) .
To investigate the Tier I accounts , we randomly selected 36 accounts without applying any metric thresholding . We manually examined each account ’s information and YouTube post history . We also take into consideration the Google internal security measures associated with each account , but will not discuss in detail here for security reasons . The manual review shows that 100 % of the Tier I accounts were verified to be fake . Among the Tier I accounts , the most frequently detected account was found by 64 seeds . We
010002000300040005000Number of seeds01000200030004000500060007000Running time ( seconds)LEASCopyCatch02004006008001000Number of seeds0200020406081012Metrics valueInternal densityFlake ODFhigh confidence regionhard cases : 98 % precision with metric thresholding ( a )
( b )
Figure 7 : ( a ) Age distribution of 36 manually reviewed Tier I suspicious accounts . ( b ) Google live runs on YouTube engagement graphs with portion of the seeds , dating from August 6th to August 13th , 2015 . The magenta curve depicts the daily volume of unique accounts detected by LEAS pipeline , and the blue curve indicates the daily number of videos these accounts have acted upon .
7.3 Deployment at Google
Leas now runs regularly at Google , expanding the coverage of fake engagement activities on YouTube . Parameters have been chosen to significantly distinguish organic user behavior from fake social engagement . There are two levels of take down actions in practice — engagement level and account level . Engagement level take down is a soft penalty which removes all the fake engagement activities happened during the day associated with the detected accounts ; account level take down is a more severe outcome , which is applied when we have very high confidence in certain bad actors committing fake engagement from time to time . Figure 7b shows the daily aggregate volume of detected accounts when running our pipeline on YouTube Comments graphs with portion of the spammer seeds , dating from August 6th to August 13th , 20156 . We do not display the entire daily take down volume here for security reasons . Note that engagement level take down was the main penalty applied during our test runs , henceforth the detected accounts didn’t exhibit a fluctuation from day to day — otherwise we would expect to see a decreasing volume of detected accounts when applying the account level take down policy . Overall , this method , in combination with other existing abuse infrastructure at Google , is effective in decreasing the volume of fake social engagement on YouTube .
8 . CONCLUSION AND EXTENSIONS
In this paper , we show how fake social engagement activities on YouTube can be tracked over time by analyzing the temporal engagement graph , which models the interactions between users and YouTube video objects . With the domain knowledge of spammer seeds , we formulate and tackle the problem of detecting fake social engagement in a semi supervised manner — with the objective of searching for individuals that have similar pattern of behavior as the known seeds — based on a graph diffusion process via local
6The decreased amount of detected account on August 8th and 9th was due to the reduced number of available seeds . In practice , the seeds data is provided by YouTube abuse team and the quantity of which may vary from day to day . spectral subspace . We show our method , Leas , is scalable to massive datasets , with a straightforward adaption to the MapReduce implementation . We demonstrate the effectiveness of our deployment at Google by achieving a manual review accuracy of 98 % on YouTube Comments graph in practice . Our examination on the anonymized YouTube log data also revealed multitudes of different patterns of behavior between abusive accounts and the general population , measured by the average co engagement intensity , monthly aggregate activity , for instance .
By clustering YouTube users based on their engagement behavior pattern , Leas has shown to greatly expand the coverage of daily fake engagement take down volume on YouTube . Our approach can be extended to many other settings including Twitter followers , Amazon product reviews and Facebook Likes etc . We envision two future directions towards which our work can evolve . First , while this paper describes the approach in a generic setting , our method can be extended by incorporating other meta signals such as IP address the engagement activities were made from . Second , we believe that better detection model can be derived by taking into account the incentivized engagement behavior , where users are offered incentives ( eg bonus point rewards ) to act on a target such as writing product reviews .
9 . ACKNOWLEDGEMENTS
The authors would like to thank Google YouTube abuse team for providing the valuable YouTube Comments data and spam seeds . Yixuan Li has been supported by US Army Research Office W911NF 14 1 0477 .
10 . REFERENCES [ 1 ] Youtube : Get legitimate subscribers . https :
//supportgooglecom/youtube/answer/6051134
[ 2 ] Youtube : Spam , deceptive practices , and scams . https : //supportgooglecom/youtube/answer/2801973 [ 3 ] R . Andersen , F . Chung , and K . Lang . Local graph partitioning using pagerank vectors . In FOCS , pages 475–486 . IEEE , 2006 .
10d1m3~4m05~15y2y3~4y6yaccount age024681012count [ 4 ] L . Becchetti , C . Castillo , D . Donato , R . Baeza Yates ,
[ 21 ] E P Lim , V A Nguyen , N . Jindal , B . Liu , and and S . Leonardi . Link analysis for web spam detection . ACM Transactions on the Web ( TWEB ) , 2(1):2 , 2008 .
[ 5 ] F . Benevenuto , G . Magno , T . Rodrigues , and
V . Almeida . Detecting spammers on twitter . In Collaboration , electronic messaging , anti abuse and spam conference ( CEAS ) , volume 6 , page 12 , 2010 .
[ 6 ] F . Benevenuto , T . Rodrigues , V . Almeida , J . Almeida , and M . Gon¸calves . Detecting spammers and content promoters in online video social networks . In SIGIR , pages 620–627 . ACM , 2009 .
[ 7 ] A . Beutel , W . Xu , V . Guruswami , C . Palow , and
C . Faloutsos . Copycatch : stopping group attacks by spotting lockstep behavior in social networks . In WWW , pages 119–130 . ACM , 2013 .
[ 8 ] Q . Cao , X . Yang , J . Yu , and C . Palow . Uncovering large groups of active malicious accounts in online social networks . In SIGSAC CCS , pages 477–488 . ACM , 2014 .
H . W . Lauw . Detecting product review spammers using rating behaviors . In CIKM , pages 939–948 . ACM , 2010 .
[ 22 ] M . W . Mahoney , L . Orecchia , and N . K . Vishnoi . A local spectral method for graphs : With applications to improving graph partitions and exploring data graphs locally . The Journal of Machine Learning Research , 13(1):2339–2365 , 2012 .
[ 23 ] B . Mehta , S . Nangia , M . Gupta , and W . Nejdl .
Detecting image spam using visual features and near duplicate detection . In WWW , pages 497–506 . ACM , 2008 .
[ 24 ] A . Mukherjee , B . Liu , and N . Glance . Spotting fake reviewer groups in consumer reviews . In WWW , pages 191–200 . ACM , 2012 .
[ 25 ] A . Ntoulas , M . Najork , M . Manasse , and D . Fetterly . Detecting spam web pages through content analysis . In WWW , pages 83–92 . ACM , 2006 .
[ 9 ] C . Castillo , D . Donato , A . Gionis , V . Murdock , and
[ 26 ] D . O’Callaghan , M . Harrigan , J . Carthy , and
F . Silvestri . Know your neighbors : Web spam detection using the web topology . In SIGIR , pages 423–430 . ACM , 2007 .
[ 10 ] P A Chirita , J . Diederich , and W . Nejdl . Mailrank : using ranking for spam detection . In CIKM , pages 373–380 . ACM , 2005 .
P . Cunningham . Network analysis of recurring youtube spam campaigns . In ICWSM , 2012 .
[ 27 ] S . Pandit , D . H . Chau , S . Wang , and C . Faloutsos .
Netprobe : a fast and scalable system for fraud detection in online auction networks . In WWW , pages 201–210 . ACM , 2007 .
[ 11 ] E . De Cristofaro , A . Friedman , G . Jourjon , M . A .
[ 28 ] G . Stringhini , C . Kruegel , and G . Vigna . Detecting
Kaafar , and M . Z . Shafiq . Paying for likes ? : Understanding facebook like fraud using honeypots . In IMC , pages 129–136 . ACM , 2014 .
[ 12 ] H . Gao , J . Hu , C . Wilson , Z . Li , Y . Chen , and B . Y .
Zhao . Detecting and characterizing social spam campaigns . In IMC , pages 35–47 . ACM , 2010 .
[ 13 ] D . F . Gleich and M . W . Mahoney . Using local spectral methods to robustify graph based learning algorithms . In SIGKDD , pages 359–368 . ACM , 2015 .
[ 14 ] P . Heymann , G . Koutrika , and H . Garcia Molina .
Fighting spam on social web sites : A survey of approaches and future challenges . Internet Computing , IEEE , 11(6):36–45 , 2007 .
[ 15 ] M . Jiang , P . Cui , A . Beutel , C . Faloutsos , and
S . Yang . Inferring strange behavior from connectivity pattern in social networks . In Advances in Knowledge Discovery and Data Mining , pages 126–138 . Springer , 2014 . spammers on social networks . In ACSAC , pages 1–9 . ACM , 2010 .
[ 29 ] G . Stringhini , P . Mourlanne , G . Jacob , M . Egele , C . Kruegel , and G . Vigna . Evilcohort : detecting communities of malicious accounts on online services . In USENIX Security Symposium , 2015 .
[ 30 ] A . H . Wang . Don’t follow me : Spam detection in twitter . In SECRYPT , pages 1–10 . IEEE , 2010 .
[ 31 ] G . Wang , T . Konolige , C . Wilson , X . Wang , H . Zheng , and B . Y . Zhao . You are how you click : Clickstream analysis for sybil detection . In Usenix Security , pages 241–256 , 2013 .
[ 32 ] Y M Wang , M . Ma , Y . Niu , and H . Chen . Spam double funnel : Connecting web spammers with advertisers . In WWW , pages 291–300 . ACM , 2007 .
[ 33 ] J . J . Whang , D . F . Gleich , and I . S . Dhillon .
Overlapping community detection using seed set expansion . In CIKM , pages 2099–2108 . ACM , 2013 .
[ 16 ] T . Joachims . Text categorization with support vector
[ 34 ] B . Wu , V . Goel , and B . D . Davison . Topical trustrank : machines : Learning with many relevant features . Springer , 1998 .
[ 17 ] P . Kolari , A . Java , T . Finin , T . Oates , and A . Joshi . Detecting spam blogs : A machine learning approach . In AAAI , volume 21 , page 1351 , 2006 .
[ 18 ] K . Lee , J . Caverlee , K . Y . Kamath , and Z . Cheng .
Detecting collective attention spam . In WebQuality , pages 48–55 . ACM , 2012 .
[ 19 ] Y . Li , K . He , D . Bindel , and J . E . Hopcroft .
Overlapping community detection via local spectral clustering . arXiv preprint arXiv:1509.07996 , 2015 .
[ 20 ] Y . Li , K . He , D . Bindel , and J . E . Hopcroft .
Uncovering the small community structure in large networks : A local spectral approach . In WWW , pages 658–668 . ACM , 2015 .
Using topicality to combat web spam . In WWW , pages 63–72 . ACM , 2006 .
[ 35 ] C T Wu , K T Cheng , Q . Zhu , and Y L Wu . Using visual features for anti spam filtering . In ICIP , volume 3 , pages III–509 . IEEE , 2005 .
[ 36 ] J . Yang and J . Leskovec . Defining and evaluating network communities based on ground truth . Knowledge and Information Systems , 42(1):181–213 , 2015 .
[ 37 ] Z . Yang , C . Wilson , X . Wang , T . Gao , B . Y . Zhao , and Y . Dai . Uncovering social network sybils in the wild . TKDD , 8(1):2 , 2014 .
