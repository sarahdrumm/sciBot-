With a Little Help from my Neighbors :
Person Name Linking Using the Wikipedia Social Network
Johanna Geiß
Heidelberg University
Michael Gertz
Heidelberg University
INF 348 , 69120 Heidelberg , Germany geiss@informatikuni heidelbergde
INF 348 , 69120 Heidelberg , Germany gertz@informatikuni heidelbergde
ABSTRACT Driven by the popularity of social networks , there has been an increasing interest in employing such networks in the context of named entity linking . In this paper , we present a novel approach to person name disambiguation and linking that uses a large scale social network extracted from the English Wikipedia . First , possible candidate matches for an ambiguous person name are determined . With each candidate match , a network substructure is associated . Based on the similarity between these network substructures and the latent network of an ambiguous person name in a document , we propose an efficient ranking method to resolve the ambiguity . We demonstrate the effectiveness of our approach , resulting in an overall precision of over 96 % for disambiguating person names and linking them to real world entities .
Keywords NEL ; Social Network ; Wikipedia ; Wikidata
1 .
INTRODUCTION
There is an increasing need for approaches in information retrieval and Web mining to uniquely identify real world persons based on mentions in text documents . For example , to obtain a textual summary or chronology for a person , respective mentions of that person in diverse types of documents need to be identified . Key to these approaches are person name disambiguation and linking techniques that identify the corresponding real world entity for a person name . This is a hard problem in particular if for an underspecified name multiple possible matches exist . Among the numerous approaches that have been proposed , clustering approaches are popular and widely used [ 13 , 16 , 22 ] . Some use context features such as links or keywords [ 14 , 16 ] . Many of these approaches either consider only a small set of documents and names or do not link a cluster to a real world entity . Other approaches make use of knowledge resources like Wikipedia [ 3 , 5 , 9 , 17 ] . A representative among these approaches that
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author ’s site if the Material is used in electronic media . WWW’16 Companion , April 11–15 , 2016 , Montréal , Québec , Canada . ACM 978 1 4503 4144 8/16/04 . http://dxdoiorg/101145/28725182891109 . is becoming increasingly popular is the use of network structures [ 15 , 18 ] . What is missing is an approach that employs 1 ) a large scale repository of real world persons , and 2 ) a social network structure among these persons in support of disambiguating person names in a wide range of documents that is efficient and easily extendable .
In this paper , we present a novel approach to person name linking using social network structures , namely the Wikipedia Social Network [ 7 ] . It consists of about 800K unique persons and 67.5M weighted relationship edges , which are determined based on co occurrences of uniquely identifiable person names in documents . The proposed method works as follows . Given a text document containing ambiguous person names , there might be several possible matching candidate persons in the network . What distinguishes these candidates from each other is their neighborhood in the network . To determine which candidate provides the best match for the ambiguous person mention , we consider the neighborhood of the ambiguous mention in the document in terms of uniquely identifiable person names . This is done efficiently by exploiting information from the social network . Compared to approaches that rely on clustering , our approach links ambiguous mentions to real world persons . Based on a subset of about 41M person mentions identified by the Stanford NE recognizer [ 6 ] in the English Wikipedia , we demonstrate the effectiveness of our approach , resulting in an overall precision of over 96 % . The approach can be applied to any type of document . To compare our approach to state of the art methods we used the AIDA CoNLL YAGO dataset [ 11 ] and received an accuracy of over 84 % , which is comparable to other approaches . Our approach even outperforms comparable systems with a precision of 94 % .
We believe that large scale social network structures in which real persons are associated with nodes provide a key ingredient to scalable and extensive name disambiguation methods . In particular , combining social networks with name disambiguation methods provides an effective means to enrich these networks as knowledge backbone for a variety of IR and text analysis tasks .
The remainder of the paper is structured as follows . After a brief review of related work in Section 2 , we give an overview of the Wikipedia Social Network construction in Section 3 . In Section 4 , we detail our disambiguation model . The result on the Wikipedia test corpus and an extensive discussion of influencing characteristics are given in Section 5 . In Section 6 , we present the evaluation results on a widely used dataset , followed by a summary and discussion of ongoing work in Section 7 .
2 . RELATED WORK
Many approaches for named entity disambiguation cluster person mentions ( and the documents they occur in ) referring to the same entity [ 1 , 13 , 14 , 22 ] . These approaches rely on co occurrences of person mentions and corresponding features from local context and/or from external sources . Different mentions are mapped to a single entity , but a link to real world objects is missing . Also , most approaches are tailored towards only small document and person sets .
The approaches in [ 3 , 5 ] exploit the category and link structure in Wikipedia and collect contextual clues and category information for each entity to disambiguate and link them to a given list of entities . Semantic networks or graphs extracted from Wikipedia are used in [ 9 ] to compare mentions to concepts/topics . A unified graph based approach to entity linking and word sense disambiguation using BabelNet is presented in [ 19 ] . Other methods make extensive use of topic models . Probabilistic inference within a topic model where each topic corresponds to a Wikipedia article is used in [ 12 ] . The focus of these approaches lies on information that describes a person entity , but the co occurring person entities are not taken into account .
Most approaches that use network structures employ some kind of graph traversal and clustering [ 15 , 18 , 20 ] . The framework in [ 11 ] is similar to our methods as it determines characteristic keyphrases for each person entity and compares them to the context of a person mention . Another comparable approach [ 2 ] makes use of hyperlinks from Wikipedia and mention context using a dictionary , a graph , and textual context . The dictionary maps surface forms to a Wikipedia articles . This is similar to our approach but instead of using anchor texts , which need to be extracted from different Wikipedia pages , we make only use of Wikidata labels and alternative names . The graph in [ 2 ] is built from the Wikipedia link structure . In our approach , however , we calculate similarities between two person in the network by the number and distance of their wikilink co occurrences within Wikipedia articles . Personalized PageRank and random walks are used in [ 2 ] to assign a Wikipedia article to a person mention . Our approach , in contrast , only relies on a social network that is constructed from co occurrences of persons , leading to more efficient neighborhood computations and in particular better disambiguation results .
3 . RESOURCES
The decision to use Wikimedia sites as knowledge backbone is based on several reasons : ( 1 ) the knowledge base is very large and not targeted towards a specific domain , ( 2 ) it deals with persons and communities that are mostly wellknown , ( 3 ) the different projects can easily be combined , and ( 4 ) a variety of information for persons is available .
3.1 Wikidata
Wikidata is a free , collaboratively edited , multilingual database launched by the Wikimedia Foundation in 2012 [ 21 ] . As of January 26 , 2015 , Wikidata includes more than 16.8M items , which represent real life topics , concepts , and subjects . Each item is described by a unique identifier , a label , a description and statements that characterize the item . We extracted about 2.6M person entries that are classified as “ instance of human ” from Wikidata . Additional information , such as gender , date of birth/death , occupation , coun try of citizenship or site links to Wikipedia is provided . Several person names ( variants , alternatives ) can be associated with a Wikidata item . The label is the most commonly used name and in addition a list of alternative names ( aliases ) is available in different languages .
3.2 Wikipedia Social Network
We built a Wikipedia Social Network ( WSN ) [ 7 ] combining wikilinks ( WL ) in the English Wikipedia with person information in Wikidata . The text of about 5.3M content pages from the English Wikipedia1 was cleaned from mark up and split into sentences . WLs are links between Wikipedia pages . They are enclosed in double square brackets as in [ [linkTarget|coveredText] ] , where coveredText is optional . To identify WLs referring to persons , we use link information in Wikidata and category information in Wikipedia . If the linkTarget is equal to the English Wikipedia sitelink of a Wikidata person item , its id is assigned to the WL . The English Wikipedia contains about 76.8M WLs of which 10.4M refer to 842 , 484 different persons . To find even more person mentions , each page is searched for all linkTargets and coveredTexts of its WLs , resulting in additional 2.6 M references to 273 , 166 persons .
321 Network Construction
The WSN was built using co occurrences of persons on Wikipedia pages ( for full details see [ 7] ) . A bipartite graph of persons and documents is projected onto the set of persons to obtain a network of persons . In the resulting multigraph , each node represents a person and each edge a cooccurrence of the two connected persons . For each edge , a weight is calculated using a decaying distance measure which takes the number of sentences between the mentions into account . The multiple edges between nodes are aggregated using a cosine similarity of adjacency vectors of nodes in the weighted node edge incidence matrix . This corresponds to a weighted cosine similarity of neighborhoods for the two incident nodes . The resulting person network2 contains over 67M edges that connect 799 , 181 different persons .
4 . DISAMBIGUATION MODEL
In our approach , person mentions are disambiguated by comparing their entity candidates to uniquely identified persons in the same document , the so called seed persons . We aim to infer the correct entity for a person mention by maximizing the relationship to the known neighborhood in the document . The overall approach is illustrated in Figure 1 and discussed in the following .
4.1 Extracting Person Mentions From Text
The first step is to detect person mentions ( occurrences of names in a text document ) . In our approach the Stanford Named Entity Recognizer [ 6 ] is used to identify person mentions . Instead of clustering all person mentions referring to the same entity across several documents , our aim is to map these mentions to a reference list of uniquely defined person entities . This mapping makes is possible to include external knowledge like date of birth/death , occupation or affiliation .
1The English Wikipedia dump from Jan . 15 , 2015 is used . 2The network is available for download from : http://dbs . ifiuni heidelbergde/indexphp?id=data#WSN
A Micro P MAP
SocNNEL Hoffart et al . 2011 [ 11 ] Houlsby & Ciaramita 2014 [ 12 ] Moro et al . 2014 [ 19 ] Barrena et al . 2015 [ 2 ]
84.4 82.5 84.9 82.1 83.6
94 81.9
95.2 89.1
Table 3 : Accuracy ( A ) in % on AIDA CoNLL YAGO Dataset test b . ferent types of entities . Secondly , it is not clear if the results of the mentioned methods are calculated over all mentions or only the ambiguous mentions . Thirdly , in contrast to the other approaches , our method does not always assign an entity .
In conclusion it can be said that our system achieves stateof the art performance with regard to accuracy , and it outperforms the AIDA system [ 11 ] in micro precision and MAP . This is remarkable since our system is just based on cooccurrences of person names in Wikipedia pages . The coherence among entities and the context similarity of mention and entity as in [ 11 ] are not taken into account , instead we rely only on the help of the neighborhood .
7 . CONCLUSION AND ONGOING WORK In this paper we presented an approach for named entity linking . We introduced a disambiguation model that employs information about the neighborhood of person names in a document and a large knowledge base : the Wikipedia Social Network . We established a weight for the relationship between a person and its neighborhood , which takes the relationship strength of two persons based on their cooccurrences in Wikipedia into account . With a large scale evaluation on more than 1.5 M person names we showed that our approach yields an overall precision of over 96 % for person name linking . The effectiveness of our disambiguation model is proven by the precision of over 89 % for selecting the correct person entity for an ambiguous person mention . We showed that the Wikipedia Social Network is a valuable resource for named entity linking and that our approach is well positioned when compared to other state of the art methods . On the standard dataset for NED we received an accuracy of over 84 % and a precision of 94 % , which is considerably higher than in comparable approaches that use extensive knowledge on context and coherence . Our method using the Wikipedia Social Network based on co occurrences is reliable and simple . It can be applied to different document types and is easily adoptable to other languages . We are working on building Wikipedia ( Social ) Networks for different languages and different named entities , for example , for place names [ 8 ] . We are currently refining our method in order to cover more person mentions and to become more independent from seed persons . We are also looking into intelligently limiting the number of candidates for person mentions by using external knowledge .
8 . REFERENCES [ 1 ] A . Bagga and B . Baldwin . Entity based cross document coreferencing using the Vector Space Model . In COLING . ACL , 1998 .
[ 2 ] A . Barrena , A . Soroa , and E . Agirre . Combining
Mention Context and Hyperlinks from Wikipedia for Named Entity Disambiguation . In *SEM . ACL , 2015 .
[ 3 ] R . Bunescu and M . P . Pasca . Using Encyclopedic Knowledge for Named Entity Disambiguation . In EACL , 2006 .
[ 4 ] P . Christen . A Comparison of Personal Name Matching : Techniques and Practical Issues . In ICDMW . IEEE , 2006 .
[ 5 ] S . Cucerzan . Large Scale Named Entity
Disambiguation Based on Wikipedia Data . In EMNLP CoNLL . ACL , 2007 .
[ 6 ] J . R . Finkel , T . Grenager , and C . Manning . Incorporating non local information into information extraction systems by Gibbs sampling . In ACL . ACL , 2005 . [ 7 ] J . Geiß , A . Spitz , and M . Gertz . Beyond Friendships and Followers : The Wikipedia Social Network . In ASONAM . IEEE , 2015 .
[ 8 ] J . Geiß , A . Spitz , J . Str¨otgen , and M . Gertz . The
Wikipedia Location Network Overcoming Borders and Oceans . In GIR , 2015 .
[ 9 ] X . Han and J . Zhao . Named entity disambiguation by leveraging wikipedia semantic knowledge . In CIKM . ACM , 2009 .
[ 10 ] J . Hoffart , Y . Altun , and G . Weikum . Discovering emerging entities with ambiguous names . In WWW . ACM Press , 2014 .
[ 11 ] J . Hoffart , M . A . Yosef , I . Bordino , H . F¨urstenau , M . Pinkal , M . Spaniol , B . Taneva , S . Thater , and G . Weikum . Robust disambiguation of named entities in text . In EMNLP , 2011 .
[ 12 ] N . Houlsby and M . Ciaramita . A Scalable Gibbs
Sampler for Probabilistic Entity Linking . In Advances in Information Retrieval ( ECIR ) , 2014 .
[ 13 ] M . Ikeda , S . Ono , I . Sato , M . Yoshida , and
H . Nakagawa . Person name disambiguation on the web by two stage clustering . In WePS , 18th WWW Conference , 2009 .
[ 14 ] D . V . Kalashnikov , R . Nuray Turan , and S . Mehrotra .
Towards breaking the quality curse . : a web querying approach to web people search . In SIGIR , 2008 .
[ 15 ] B . Malin , E . Airoldi , and K . M . Carley . A network analysis model for disambiguation of names in lists . Comput . Math . Organ . Theory , 11(2 ) , 2005 .
[ 16 ] G . S . Mann and D . Yarowsky . Unsupervised personal name disambiguation . In CoNLL , 2003 .
[ 17 ] D . N . Milne and I . H . Witten . Learning to link with wikipedia . In CIKM , 2008 .
[ 18 ] E . Minkov , W . W . Cohen , and A . Y . Ng . Contextual search and name disambiguation in email using graphs . In SIGIR , 2006 .
[ 19 ] A . Moro , A . Raganato , and R . Navigli . Entity linking meets word sense disambiguation : a unified approach . TACL , 2014 .
[ 20 ] J . Tang , Q . Lu , T . Wang , J . Wang , and W . Li . A bipartite graph based social network splicing method for person name disambiguation . In SIGIR , 2011 . [ 21 ] D . Vrandeˇci´c and M . Kr¨otzsch . Wikidata : A Free
Collaborative Knowledgebase . Communications of the ACM , 57(10 ) , 2014 .
[ 22 ] M . Yoshida , M . Ikeda , S . Ono , I . Sato , and
H . Nakagawa . Person name disambiguation by bootstrapping . In SIGIR , 2010 .
