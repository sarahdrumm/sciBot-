Advertising Keyword Generation Using Active Learning∗
Hao Wu1 , Guang Qiu1 , Xiaofei He2 , Yuan Shi1 , Mingcheng Qu1 , Jing Shen3 , Jiajun Bu1 and Chun Chen1
1,2College of Computer Science and Technology , Zhejiang University , China
3China Disabled Persons’ Federation Information Center
1{haowu , qiuguang , shiyuan , qumingcheng , bjj , chenc}@zjueducn ,
2xiaofeihe@cadzjueducn , 3shenjing@cdpforgcn
ABSTRACT This paper proposes an efficient relevance feedback based interactive model for keyword generation in sponsored search advertising . We formulate the ranking of relevant terms as a supervised learning problem and suggest new terms for the seed by leveraging user relevance feedback information . Active learning is employed to select the most informative samples from a set of candidate terms for user labeling . Experiments show our approach improves the relevance of generated terms significantly with little user effort required .
Categories and Subject Descriptors : H35 [ Information Systems ] : Information Storage and Retrieval—On line Information Services
General Terms : Algorithms , Design , Experimentation
Keywords : Active Learning , Keyword Generation , Sponsored Search
1 .
INTRODUCTION
Sponsored search is a successful form of on line advertising , with annual revenue exceeding billions of dollars . With the goal of branding or/and marketing , advertisers create ads and bid on relevant keywords . The auction winners have their ads displayed as sponsored links alongside the organic search results when bidded terms are queried . Keyword generation/suggestion methods are employed to assist advertisers in finding all the terms relevant to their products or services . The term relevance is crucial to capture valid queries and clicks from their potential customers .
Provided an initial keyword which represents a concept such as “ shoes ” ( ie a seed term ) , some typical keyword generation methods make use of a set of elements ( such as URLs , frequent queries and meta tags ) that enrich the meaning of the seed to select high co occurrence or similar terms as suggestions . To be effective , keyword generation requires even hundreds of relevant terms to be suggested for a seed . Some popular keyword generation tools ( eg Google ’s Adwords Tool ) mainly rely on query log mining and have the drawbacks of failing to suggest terms that don’t contain the seed and ignoring the semantic similarity between terms .
Recent related work tends to exploit semantic relation
∗ of China ( NO2008BAH26B02 )
Supported by the National Key Technology R&D Program
Copyright is held by the author/owner(s ) . WWW 2009 , April 20–24 , 2009 , Madrid , Spain . ACM 978 1 60558 487 4/09/04 . ships between terms . For keyword generation , Joshi and Motwani [ 3 ] present TermsNet , which captures semantic similarity between terms as a directed graph ; Abhishek and Hosanagar [ 1 ] use a web based kernel function to establish semantic similarity between terms ; Chen and et al . [ 2 ] exploit the semantic knowledge among concept hierarchy . However , there is no effort taking user relevance feedback information , especially that from advertisers , into account .
In this paper , we propose an interactive model to explore relevance feedback for keyword generation . Our approach also differs from previous work in formulating the ranking of relevant terms as a supervised learning problem , in which the term relevance is learned from several representative features rather than determined using a specific measure .
2 . KEYWORD GENERATION 2.1 The Interactive Model
We establish semantic relevance between terms by leveraging relevance feedback , which conveys direct semantic information . For a seed term , our system first employs search engines to match it with a large set of ranked candidate terms that are determined using TFIDF measure . The candidates achieve a high coverage of relevant terms , but a poor precision . Users are then required to provide relevant/irrelevant labeling on just a few candidates selected by the system . Given these labeled candidates , a regression model is trained to predict the relevance scores of unlabeled candidates to the seed , from some representative features about them . Based on the relevance scores , we re rank all the candidate terms to improve the precision . Finally , top ranked terms are selected as suggestions for the seed and returned to users .
Due to the consideration of the performance and user satisfaction , there are two requirements : ( 1 ) The samples to be selected for labeling should be as few as possible since labeling is labor intensive . ( 2 ) The quality of training samples affects the performance directly . A natural strategy is to select the most informative samples using active learning . 2.2 Candidate Term Generation
To be efficient , we represent each seed term using a characteristic document which contains retrieved snippets from top search hits . It is similar to [ 3 ] . Given a set of seed terms , the corresponding characteristic documents form a corpus . We remove stop words from these documents and stem the terms using Porter ’s stemmer as preprocessing . The TFIDF of all terms in the corpus is used as the initial weight of relevance . Top weighted terms in a characteristic document are selected as the candidates for the corresponding seed term .
WWW 2009 MADRID!Poster Sessions : Wednesday , April 22 , 20091095 2.3 Feature Representation
For each ( seed , candidate ) term pair , the following features characterizing the relevance between them are used as predictor variables : ( 1 ) TF and TFIDF of the candidate in the search snippets document of the seed ; ( 2 ) Inverse TF : the frequency of the seed in the search snippets document of the candidate ; ( 3 ) Search Snippets Similarity : the frequency with which the snippets of top search results for the seed and the candidate contain the same words . ( 4 ) Common Search URLs : the frequency with which the seed and the candidate share the same search URLs . 2.4 Active Learning i i n o s c e r P e g a r e v A
1
0.9
0.8
0.7
0.6
0.5
0.4
0
20
TED Random Baseline1 Baseline0
180
200
40
60
80
100
120
140
160
Top−N Suggested Terms
We apply an active learning approach called Transductive Experimental Design ( TED [ 4] ) , which tends to select candidates ( for labeling and training ) that are hard to predict and representative for unlabeled candidates . Let V denote both the matrix [ v1 , , vn]T ∈ R n×d and the data set {vi} , and X denote both the matrix [ x1 , , xm]T ∈ R m×d and the data subset {xi} , where X ⊂ V ( m < n ) . In our case , vi is the feature vector of a ( candidate , seed ) term pair . Define f ( x ) = wT x as the output function learned from measurements yi = wT xi + i , i = 1 , , m , where w ∈ R d is weight vector and i ∼ N ( 0 , σ2 ) is measurement error . Let yi ( label ) be the relevance score ( 1 or 0 ) associated with the feature vector xi . Consider a regularized linear regression problem , the maximum likelihood estimate of w is given by
'
T xi − yi )
2
+ μ||w||2
J(w ) = w
( w
ˆw = arg min
( 1 ) where μ > 0 and ||·|| is the vector 2 norm . It is known that the estimation e = w − ˆw has a covariance matrix given by σ2Cw , where Cw is the inverted Hessian of J(w ) i=1 mfi
−1
. ff
Cw =
∂2J(w )
∂w2
= ( X
T
X + μI )
−1
( 2 )
( nfi
The introduced regularization improves numerical stability since XT X + μI is full rank . Let f = [ f ( v1 ) , , f ( vn)]T be the function values on all the available data V , then the predictive error f − ˆf has the covariance matrix σ2Cf with ( 3 )
Cf = VCwV
X + μI )
= V(X
−1
V
T
T
T
In contrast to Cw , Cf directly characterizes the quality of predictions on the target data V . Therefore , the total predictive variance on the complete data set V is given by
( f ( vi)− ˆf ( vi ) )
2
E
= σ2T r(Cf )
( 4 ) i=1
One should find a subset X which can minimize the total predictive variance . In our case , we apply sequential optimization of Kernel Transductive Experimental Design [ 4 ] . 3 . EXPERIMENTAL RESULTS
We select 100 category names widely spread over different topics from eBay and Amazon to form the set of seed terms . They’re popular among advertisers and customers . For each characteristic document generation , top 400 Google searchhits are acquired . Top 400 weighted terms in each seed ’s characteristic document are selected as candidate terms .
Experimental results are averaged over 20 benchmark seed terms . Ground truth labeling of relevant/irrelevant was provided by 5 human evaluators who are familiar with related
Figure 1 : Average Precision Curves materials , and it was performed beforehand after we generated candidate terms , whose initial ranking is regarded as Baseline0 . For the sake of user satisfaction , we select just 10 samples from the set of each seed ’s 400 candidates for user labeling . Given these 10 labeled samples , we equivalently apply kernel regression with Gaussian kernels to predict the relevance scores of unlabeled candidates . The following methods are compared : ( 1 ) Pseudo Relevance Feedback : we select 5 samples as positive ones from the top of the initial ranking and 5 samples as negative ones from the end . It is regarded as Baseline1 since no user labeling is required ; ( 2 ) Random Sampling : we randomly select samples and repeat 100 rounds to get an average result . ( 3 ) TED is employed to select samples . μ is fixed as 00001
Figure 1 shows the average precision curves for the relevance of top 200 suggested terms after re ranking , where precision is defined as the ratio of relevant terms generated to the total number of terms generated . As illustrated , both random sampling and TED significantly outperform pseudorelevance feedback since additional user relevance feedback is used . In this case , TED consistently performs the best , with 88.3 % average precision achieved for top 100 suggestions , and 65.1 % for top 200 suggestions . TED achieves 2.2 % performance improvement for top 100 suggestions , and 2.7 % for top 200 suggestions , comparing to random sampling . This is because active learning selects the training samples which can minimize the total predictive variance . 4 . CONCLUSION AND FUTURE WORK
We have shown the effectiveness of our relevance feedback based interactive model in generating relevant terms . Experimental results highlight the advantage of the active learning algorithm in selecting the most informative samples for user labeling . Furthermore , our approach achieves a good tradeoff between the performance and user satisfaction . In practice , our keyword generation framework can be extended to other applications such as term clustering . Currently , only single word terms are considered . We are going to explore the use of phrases in the future work . 5 . REFERENCES [ 1 ] V . Abhishek and K . Hosanagar . Keyword generation for search engine advertising using semantic similarity between terms . In ICEC’07 , 2007 .
[ 2 ] Y . Chen , G R Xue , and Y . Yu . Advertising keyword suggestion based on concept hierarchy . In WSDM’08 , 2008 .
[ 3 ] A . Joshi and R . Motwani . Keyword generation for search engine advertising . In ICDM’06 , 2006 .
[ 4 ] K . Yu , J . Bi , and V . Tresp . Active learning via transductive experimental design . In ICML’06 , 2006 .
WWW 2009 MADRID!Poster Sessions : Wednesday , April 22 , 20091096
