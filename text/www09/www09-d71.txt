Measuring the Similarity between Implicit Semantic
Relations from the Web
Danushka Bollegala∗ The University of Tokyo
Hongo 7 3 1 , Tokyo 113 8656 , Japan danushka@miciiu tokyoacjp
Yutaka Matsuo
The University of Tokyo
Hongo 7 3 1 , Tokyo 113 8656 , Japan matsuo@biz modeltu tokyoacjp
Mitsuru Ishizuka
The University of Tokyo
Hongo 7 3 1 , Tokyo 113 8656 , Japan ishizuka@iu tokyoacjp
ABSTRACT Measuring the similarity between semantic relations that hold among entities is an important and necessary step in various Web related tasks such as relation extraction , information retrieval and analogy detection . For example , consider the case in which a person knows a pair of entities ( eg Google , YouTube ) , between which a particular relation holds ( eg acquisition ) . The person is interested in retrieving other such pairs with similar relations ( eg Microsoft , Powerset ) . Existing keyword based search engines cannot be applied directly in this case because , in keyword based search , the goal is to retrieve documents that are relevant to the words used in a query – not necessarily to the relations implied by a pair of words . We propose a relational similarity measure , using a Web search engine , to compute the similarity between semantic relations implied by two pairs of words . Our method has three components : representing the various semantic relations that exist between a pair of words using automatically extracted lexical patterns , clustering the extracted lexical patterns to identify the different patterns that express a particular semantic relation , and measuring the similarity between semantic relations using a metric learning approach . We evaluate the proposed method in two tasks : classifying semantic relations between named entities , and solving word analogy questions . The proposed method outperforms all baselines in a relation classification task with a statistically significant average precision score of 074 Moreover , it reduces the time taken by Latent Relational Analysis to process 374 word analogy questions from 9 days to less than 6 hours , with an SAT score of 51 % .
Categories and Subject Descriptors H33 [ Information Systems ] : Information Search and Retrieval
General Terms Algorithms
Keywords Relational Similarity , Web Mining , Natural Language Processing
∗Research Fellow of the Japan Society for the Promotion of Science ( JSPS ) Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . Distribution of these papers is limited to classroom use , and personal use by others . WWW 2009 , April 20–24 , 2009 , Madrid , Spain . ACM 978 1 60558 487 4/09/04 .
1 .
INTRODUCTION
Similarity measures can be categorized broadly into two types : attributional similarity measures and relational similarity measures . For attributional similarity measures , the objective is to compute the similarity between two given words by comparing the attributes of each word . For example , the two words car and automobile share many attributes ( eg has wheels , is used for transportation ) . Consequently , they are considered as synonyms . On the other hand , relational similarity is the correspondence between semantic relations that exist between two word pairs . Word pairs that show a high degree of relational similarity are considered as analogies . For example , the two word pairs ( ostrich , bird ) and ( lion , cat ) . Ostrich is a large bird and lion is a large cat are illustrative of high relational similarity . The semantic relation , is a large , pertains between the two words in each word pair .
The information available on the Web can be considered as a vast , hidden network of classes of objects ( eg named entities ) that is interconnected by various semantic relations applying to those objects . Measuring the similarity between semantic relations is an important intermediate step in various tasks in information retrieval and natural language processing such as relation extraction [ 7 , 8 , 40 ] , in which the goal is to retrieve instances of a given relation . For example , given the relation , ACQUIRER ACQUIREE , a relation extraction system must extract the instance ( Google , YouTube ) from the sentence Google completed the acquisition of YouTube . Bootstrapping methods [ 25 , 6 , 14 ] , which require a few seeds ( ca . 10 pairs of instances per relation ) have extracted numerous candidate instance pairs from a text corpus . Given a set of candidate instance pairs , a relational similarity measure can be used to compute the similarity between the relations in the seeds and in the candidates . Candidate instance pairs with high relational similarity with the seed pairs can then be selected as the correct instances of a relation .
Relational similarity measures have been used to find word analogies [ 10 , 24 , 31 , 33 , 38 ] . Word analogy questions have been used from the Scholastic Aptitude Test ( SAT ; Educational Testing Service ) to benchmark relational similarity measures . An SAT word analogy question consists of a stem word pair that acts as the question and five choice word pairs , out of which only one is analogous to the stem . A relational similarity measure is used to compare the stem word pair with each choice word pair and to select the choice word pair with the highest relational similarity as the answer .
An interesting application of relational similarity in information retrieval is to search using implicitly stated analogies [ 21 , 37 ] . For example , the query “ Muslim Church ” is expected to return “ mosque ” , and the query “ Hindu bible ” is expected to return “ the Vedas ” . These queries can be formalized as word pairs : ( Christian ,
WWW 2009 MADRID!Track : Semantic/Data Web / Session : Mining for Semantics651 Church ) vs . ( Muslim,X ) , and ( Christian , Bible ) vs . ( Hindu,Y ) . We can then find the words X and Y that maximize the relational similarity in each case .
Despite the wide applications of relational similarity measures , accurately measuring the similarity between implicitly stated relations remains a challenging task for several reasons . First , relational similarity is a dynamic phenomenon : it varies with time . For example , two companies can be competitors initially ; subsequently one company might acquire the other . Second , there can be more than one relation between a given word pair . For example , between the two words ostrich and bird , aside from the relation is a large , there is also the relation is a flightless . A relational similarity measure must first extract all relations between the two words in each word pair before it can compute the similarity between the word pairs . Third , there can be more than one way to express a particular semantic relation in a text . For example , the three patterns – X was acquired by Y , Y completed the acquisition of X , and Y buys X – all indicate an acquisition relation between X and Y . In addition to the problems described above , measuring relational similarity between pairs in which one or both words are named entities ( eg , company names , personal names , locations , etc . ) is even more difficult because such words are not well covered by manually created dictionaries such as WordNet1[23 ] .
As described herein , we propose a relational similarity measure that uses a Web search engine to measure the similarity between implicitly stated semantic relations in two word pairs . Formally , given two word pairs , ( a,b ) and ( c,d ) , we design a function , relsim((a , b ) , ( c , d) ) , that returns a similarity score in the range [ 0 , 1 ] . The proposed relational similarity measure first extracts implicitly stated relations that exist between the two words in each word pair . The measure then compares the extracted relations between word pairs .
Our contributions are summarized as follows : • We propose a shallow , lexical patterns based approach to represent the various semantic relations that pertain between the two words in a given word pair . The proposed pattern extraction algorithm requires no language dependent preprocessing steps such as part of speech tagging or dependency parsing , which can be time consuming or even infeasible at the Web scale . We extract numerous lexical patterns that describe various semantic relations .
• We present an efficient sequential clustering algorithm to cluster lexical patterns , to identify the different patterns that describe a particular semantic relation . The proposed clustering algorithm requires only one pass through the set of extracted patterns . For that reason , it scales linearly with the number of patterns . We then use the clusters to define features for a supervised metric learning algorithm .
• We evaluate the proposed method in two tasks : classifying semantic relations between named entities , and solving SAT word analogy questions . In the relation classification task , the proposed method significantly outperforms all baselines , including the state of the art Latent Relational Analysis ( LRA ) [ 33 ] . Moreover , the proposed method achieves an SAT score of 51.1 and reduces the time taken to answer 374 questions by LRA from 9 days to less than 6 hours .
1http://wordnetprincetonedu/
2 . RELATED WORK
The Structure Mapping Theory ( SMT ) [ 15 ] is based on the premise that an analogy is a mapping of knowledge from one domain ( base ) into another ( target ) , which conveys that a system of relations known to hold in the base also holds in the target . The target objects need not resemble their corresponding base objects . This structural view of analogy is based on the intuition that analogies are about relations , rather than simple features . Although this approach works best when the base and the target are rich in higher order causal structures , it can fail when structures are missing or flat [ 39 ] .
Turney et al . [ 35 ] combined 13 independent modules by considering the weighted sum of the outputs of each module to solve SAT analogy questions . The best performing individual module was based on the Vector Space Model ( VSM ) . In the VSM approach [ 34 ] , a vector is first created for a word pair ( X,Y ) by counting the frequencies of various lexical patterns containing X and Y . In their experiments , they used 128 manually created patterns such as “ X of Y ” , “ Y of X ” , “ X to Y ” , and “ Y to X ” . These patterns are then used as queries to a search engine . The numbers of hits for respective queries are used as elements in a vector to represent the word pair . Finally , the relational similarity is computed as the cosine of the angle between the two vectors that represent the two word pairs . Turney et al . [ 35 ] introduced a dataset containing 374 SAT analogy questions to evaluate relational similarity measures . An SAT analogy question consists of a stem word pair that acts as the question , and five choice word pairs . The choice word pair that has the highest relational similarity with the stem word pair is selected by the system as the correct answer . The average SAT score reported by high school students for word analogy questions is 57 % . The VSM approach achieves a score of 47 % on this dataset .
Turney [ 31 , 33 ] proposed Latent Relational Analysis ( LRA ) by extending the VSM approach in three ways : a ) lexical patterns are automatically extracted from a corpus , b ) the Singular Value Decomposition ( SVD ) is used to smooth the frequency data , and c ) synonyms are used to explore variants of the word pairs . Similarly , in the VSM approach , LRA represents a word pair as a vector of lexical pattern frequencies . First , using a thesaurus , he finds related words for the two words in a word pair and create additional word pairs that are related to the original word pairs in the dataset . Second , n grams of words are extracted from the contexts in which the two words in a word pair cooccur . The most frequent n grams are selected as lexical patterns to represent a word pair . Then a matrix of word pairs vs . lexical patterns is created for all the word pairs in the original dataset and the additional word pairs . Elements of this matrix correspond to the frequency of a word pair in a lexical pattern . Singular value decomposition is performed on this matrix to reduce the number of columns ( ie patterns ) . Finally , the relational similarity between two word pairs is computed as the average cosine similarity over the original word pairs and the additional word pairs derived from them . In fact , LRA achieves a score of 56.4 % on SAT analogy questions .
Both VSM and LRA require numerous search engine queries to create a vector to represent a word pair . For example , with 128 patterns , the VSM approach requires at least 256 queries to create two pattern frequency vectors for two word pairs before it can compute the relational similarity . In fact , LRA considers synonymous variants of the given word pairs . For that reason , it requires even more search engine queries . Methods that require numerous queries impose a heavy load on search engines . Despite efficient implementations , singular value decomposition of large matrices is time consuming . In fact , LRA takes over 9 days to process the 374 SAT analogy questions [ 33 ] . This is problematic when computing
WWW 2009 MADRID!Track : Semantic/Data Web / Session : Mining for Semantics652 relational similarity on the scale of the Web . Moreover , in the case of named entities , thesauri of related words are not usually available or are not complete , which becomes a problem when creating the additional word pairs required by LRA .
Veale [ 38 ] proposed a relational similarity measure based on the taxonomic similarity in WordNet . The quality of a candidate analogy A:B::C:D ( ie A to B as C to D ) is evaluated through comparison of the paths in the WordNet , joining A to B and C to D . Relational similarity is defined as the similarity between the A:B paths and C:D paths . However , WordNet does not fully cover named entities such as personal names , organizations and locations , which becomes problematic when using this method to measure relational similarity between named entities .
Using a relational similarity measure , Turney [ 32 ] proposed an unsupervised learning algorithm to extract patterns that express implicit semantic relations from a corpus . His method produces a ranked set of lexical patterns that unambiguously describes the relation between the two words in a given word pair . Patterns are ranked according to their expected relational similarity ( ie pertinence ) ; they are computed using an algorithm similar to LRA . To answer an SAT analogy question , first , ranked lists of patterns are generated for each of the six word pairs ( one stem word pair and five choice word pairs ) . Then each choice is evaluated by taking the intersection of its patterns with the stem ’s patterns . The shared patterns are scored by the average of their rank in the stem ’s list and the choice ’s lists . The algorithm picks the choice with the lowest scoring shared pattern as the correct answer . This method reports an SAT score of 546 %
Relational similarity measures have been applied in natural language processing tasks such as generating word analogies [ 10 ] , and classifying noun modifier compounds based on the relation between the head and the modifier [ 33 , 24 , 9 , 24 ] . Davidov and Rappoport [ 10 ] proposed an unsupervised algorithm to discover general semantic relations that pertain between lexical items . They represent a semantic relation with a cluster of patterns . They use the pattern clusters to generate SAT like word analogy questions for English and Russian languages . The generated questions are then solved by human subjects . They do not evaluate their method for relational similarity between named entities .
Relational similarity measures have been used to classify the relationships between the head and the modifier in noun compounds [ 33 , 24 , 9 ] . For example , in the compound viral flu , the flu ( head ) is caused by a virus ( modifier ) . The Diverse dataset of Barker and Szpakowicz [ 1 ] , which consists of 600 head modifier pairs ( nounnoun , adjective noun and adverb noun ) is used as a benchmark dataset to evaluate relation classification of noun compounds . Each noun modifier pair in this dataset is annotated with one of the following five relations : causal , temporal , spatial , participant , and quality . Nakov and Hearst [ 24 ] proposed a linguistically motivated method that utilizes verbs , prepositions , and coordinate conjunctions that can help make explicit the hidden relations between the target nouns . They report a classification accuracy of 40.5 % on the Diverse dataset using a single nearest neighbor classifier .
3 . METHOD 3.1 Outline
Given two pairs of words ( or named entities ) , ( a,b ) and ( c,d ) , the problem of measuring the similarity of implicit semantic relations between the two pairs can be viewed as a two stage process .
First , we must extract the semantic relations that pertain in each word pair . We use a web search engine to retrieve the various contexts in which the two words in a word pair cooccur . We then ex
Google to acquire YouTube for $1.65 billion in stock . Combination will create new opportunities for users and content owners everywhere
Figure 1 : A snippet returned for the query “ Google * * * YouTube ” . tract lexical patterns from the retrieved contexts to represent the various semantic relations that hold between two words . However , not all patterns represent different semantic relations . A single semantic relation can be expressed using more than one lexical pattern . For example , both lexical patterns X acquired Y and Y was bought by X indicate an ACQUISITION relation between entities X and Y . We present an efficient clustering algorithm to identify the various lexical patterns that denote a particular semantic relation .
Second , we must compare the extracted semantic relations between the two word pairs to compute their relational similarity . We model this problem as one of learning a distance metric between relationally similar and dissimilar word pairs . Unlike previously proposed relational similarity measures , we do not assume semantic relations to be independent , and learn a non Euclidean Mahalanobis distance metric . 3.2 Retrieving Contexts
We must first identify the implicitly stated relations that hold between the two words in each word pair to compute the relational similarity between two given word pairs . The context in which two words cooccur provides useful clues about the semantic relations that pertain between those words . We propose the use of text snippets retrieved using a Web search engine as an approximation of the context of two words . Snippets ( also known as dynamic teasers ) are brief summaries provided by most Web search engines along with the search results . Typically , a snippet contains a window of text selected from a document that includes the queried words . Snippets are useful for search because , most of the time , a user can read the snippet and decide whether a particular search result is relevant , without even opening the url . Using snippets as contexts is also computationally efficient because it obviates the need to download the source documents from the Web , which can be time consuming if a document is large .
A snippet for a query containing two words captures the local context in which they cooccur . For example , consider the snippet shown in Figure 1 , returned by Yahoo2 for the query “ Google * * YouTube ” . Here , the wildcard operator “ * ” matches one word or none in a document . The snippet in Figure 1 is extracted from an online newspaper article about the acquisition of YouTube by Google .
To retrieve snippets for a word pair ( A,B ) , we use the following seven types of queries : “ A * B ” , “ B * A ” , “ A * * B ” , “ B * * A ” , “ A * * * B ” , “ B * * * A ” , and A B . The queries containing the wildcard operator “ * ” returns snippets in which the two words , A and B appear within a window of specified length . We designate such queries a wildcard queries . We search for snippets in which the query words cooccur within a maximum window of three words ( tokens ) . This process is intended to approximate the local context of two words in a document . The quotation marks around a query will ensure that the two words appear in the specified order ( eg A before B in snippets retrieved for the query “ A * B ” ) . As a fallback in the case that all wildcard queries fail to return any snippets , we use the query A B ( without wildcards or quotations ) to retrieve snippets where A and B appear in any order . 2http://developeryahoocom/search/boss/
WWW 2009 MADRID!Track : Semantic/Data Web / Session : Mining for Semantics653 Once we collect snippets for a word pair using the procedure described above , we remove duplicate search results . We consider two snippets to be duplicates if they contain the exact sequence of all words . Duplicate snippets exist mainly for two reasons . First , a web page can be mirrored in more than one location , and the default de duplication mechanism of the search engine might fail to filter out the duplicates . Second , the queries we construct for a word pair are not independent . For example , a query with two wildcards might return a snippet that can also be retrieved using a query with one wildcard . However , we observed that the ranking of search results vary with the number of wildcards used . A search engine usually returns only the top ranking results ( in the case of Yahoo , only the top 1000 snippets can be downloaded ) . We use multiple queries per word pair that induce different rankings , and aggregate search results to circumvent this limitation . 3.3 Extracting Lexical Patterns
Lexical syntactic patterns have been used in various natural language processing tasks such as extracting hypernyms [ 17 , 30 ] , or meronyms [ 2 ] , question answering [ 28 ] , and paraphrase extraction [ 3 ] . Following these previous works , we present a shallow lexical pattern extraction algorithm to represent the semantic relations between two words . The proposed method requires no languagedependent preprocessing such as part of speech tagging or dependency parsing , which can be both time consuming at Web scale , and likely to produce incorrect results because of the fragmented and ill formed snippets . The pattern extraction algorithm consists of the following three steps .
Step 1 : Given a context S , retrieved for a word pair ( A , B ) according to the procedure described in section 3.2 , we replace the two words A and B , respectively , with two variables X and Y . Legal abbreviations such as Inc . , Ltd . , Corp . , and titles such as Mr . , Ms . , Prof . , Dr . , Rev . are considered as occurrences of the query terms . For example , Google Inc . is considered as an occurrence of the entity Google . We replace all numeric values by D , a marker for digits . Punctuation marks are not removed .
Step 2 : We generate all subsequences of the context S that satisfy all of the following conditions .
( i ) . A subsequence must contain exactly one occurrence of each X and Y ( ie , exactly one X and one Y must exist in a subsequence ) .
( ii ) . The maximum length of a subsequence is L words . ( iii ) . A subsequence is allowed to have gaps . However , we do not allow gaps of more than g number of words . Moreover , the total length of all gaps in a subsequence should not exceed G words .
( iv ) . We expand all negation contractions in a context . For example , didn’t is expanded to did not . We do not skip the word not when generating subsequences . For example , this condition ensures that from the snippet X is not a Y , we do not produce the subsequence X is a Y .
Step 3 : We count the frequency of all generated subsequences for all word pairs in the dataset . We select subsequences with frequency greater than N as lexical patterns to represent the semantic relations between words .
Our pattern extraction algorithm has four parameters ( ca . L , g , G and N ) . We set the values of those parameters experimentally , as
Figure 2 : Distribution of four lexical patterns in word pairs . explained later in section 4 . It is noteworthy that the proposed pattern extraction algorithm considers all the words in a snippet , and is not limited to extracting patterns only from the mid fix ( ie , the portion of text in a snippet that appears between the queried words ) . Moreover , the consideration of gaps enables us to capture relations between distant words in a snippet . We use a modified version of the prefixspan algorithm [ 26 ] to generate subsequences . The conditions in Step 2 are used to prune the search space , thereby reducing the number of generated subsequences in prefixspan . For example , some patterns extracted form the snippet shown in Figure 1 are : X to acquire Y , X acquire Y , and X to acquire Y for . Identifying Semantic Relations 3.4
A semantic relation can be expressed using more than one pattern . For example , consider the two distinct patterns , X acquired Y , and X completed the acquisition of Y . Both these patterns indicate that there exists an acquisition relation between X and Y . It is important to know whether any correspondence pertains between the sets of patterns extracted for each word pair when we compute the relational similarity between two word pairs . We can expect a high relational similarity if there are many related patterns between two word pairs .
We use the distributional hypothesis [ 16 ] to find semantically related lexical patterns . The distributional hypothesis states that words that occur in the same context have similar meanings . The distributional hypothesis has been used in various related tasks , such as identifying related words[18 ] , discovering inference rules[19 ] , and extracting paraphrases[3 ] . If two lexical patterns are similarly distributed over a set of word pairs ( ie occurs with the same set of word pairs ) , then from the distributional hypothesis it follows that the two patterns must be similar . For example , consider the distributions shown in Figure 2 for four lexical patterns : X buys Y , X acquires Y , Y CEO X , and Y chief executive X , over a set of 100 word pairs . Each distribution is normalized such that the sum of frequencies over all word pairs equals one . Figure 2 shows that the distributions of patterns Y CEO X , and Y chief executive X have a high overlap ( ie , cosine similarity of 0969 ) Similarly , the distributions of patterns X buys Y , and X acquires Y show a high overlap ( ie cosine similarity of 0853 ) However , almost no overlap is apparent between other combinations of distributions . Consequently , to recognize semantically related patterns , we cluster lexical patterns using the similarity of their distributions over word pairs .
0 0.02 0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.18 10 20 30 40 50 60 70 80 90 100Normalized FrequencyWord Pair IDsX buys YX acquires YY ceo XY chief executive XWWW 2009 MADRID!Track : Semantic/Data Web / Session : Mining for Semantics654 We represent a pattern p by a vector p of word pair frequencies . We designate p , the word pair frequency vector of pattern p . It is analogous to the document frequency vector of a word , as used in information retrieval . The value of the element corresponding to a word pair ( ai , bi ) in p , is the frequency , f ( ai , bi , p ) , that the pattern p occurs with the word pair ( ai , bi ) . As demonstrated later in the experiments of this study , the proposed pattern extraction algorithm typically extracts numerous lexical patterns ( more than 140 , 000 ) . Clustering algorithms based on pairwise comparisons among all patterns are not feasible when the patterns are numerous . Next , we present a sequential clustering algorithm to efficiently cluster the extracted patterns .
Given a set P of patterns and a clustering similarity threshold θ , Algorithm 1 returns clusters ( of patterns ) that express similar semantic relations . First , in Algorithm 1 , the function SORT sorts the patterns into descending order of their total occurrences in all word pairs . The total occurrence of a pattern p is the sum of frequencies over all word pairs ( ie , i f ( ai , bi , p) ) . After sorting , the most common patterns appear at the beginning in P , whereas rare patterns ( ie , patterns that occur with only few word pairs ) get shifted to the end . Next , in line 2 , we initialize the set of clusters , C , to the empty set . The outer for loop ( starting at line 3 ) , repeatedly takes a pattern pi from the ordered set P , and in the inner for loop ( starting at line 6 ) , finds the cluster , c∗ ( ∈ C ) that is most similar to pi . First , we represent a cluster by the centroid of all word pair frequency vectors corresponding to the patterns in that cluster to compute the similarity between a pattern and a cluster . Next , we compute the cosine similarity between the cluster centroid ( cj ) , and the word pair frequency vector of the pattern ( pi ) . If the similarity between a pattern pi , and its most similar cluster , c∗ , is greater than the threshold θ , we append pi to c∗ ( line 14 ) . We use the operator ⊕ to denote the vector addition between c∗ and pi . Then we form a new cluster {pi} and append it to the set of clusters , C , if pi is not similar to any of the existing clusters beyond the threshold θ .
The only parameter in Algorithm 1 , the similarity threshold , θ , ranges in [ 0 , 1 ] . It decides the purity of the formed clusters . Setting θ to a high value ensures that the patterns in each cluster are highly similar . However , high θ values also yield numerous clusters ( increased model complexity ) . In section 4 , we investigate , experimentally , the effect of θ on the overall performance of the proposed relational similarity measure . The computational time complexity of Algorithm 1 is O(n|C| ) , where n is the number of patterns to be clustered and |C| is the number of clusters . Usually , n is much larger than |C| ( ie n ( cid:192 ) |C| ) . Therefore , the overall time complexity of Algorithm 1 linearly scales with the number of patterns . The sequential nature of the algorithm avoids pairwise comparisons among all patterns . Moreover , sorting the patterns by their total word pair frequency prior to clustering ensures that the final set of clusters contains the most common relations in the dataset .
3.5 Measuring Relational Similarity
Evidence from psychological experiments suggest that similarity can be context dependent and even asymmetric [ 36 , 22 ] . Human subjects have reportedly assigned different similarity ratings to word pairs when the two words were presented in reverse order . However , experimental results investigating the effects of asymmetry , report that the average difference in ratings for a word pair is less than 5 percent [ 22 ] . Consequently , we assume relational similarity to be symmetric and limit ourselves to symmetric similarity measures . This assumption is in line with previous work on relational similarity described in section 2 .
We model the problem of measuring relational similarity be c∗ ← null for cluster cj ∈ C do sim ← cosine(pi , cj ) if sim > max then
Algorithm 1 Sequential pattern clustering algorithm . Input : patterns P = {p1 , . . . , pn} , threshold θ Output : clusters C 1 : SORT(P ) 2 : C ← {} 3 : for pattern pi ∈ P do 4 : max ← −∞ 5 : 6 : 7 : 8 : 9 : 10 : 11 : 12 : 13 : 14 : 15 : 16 : end if 17 : 18 : end for 19 : return C end if end for if max > θ then c∗ ← c∗ ⊕ pi C ← C ∪ {pi} max ← sim c∗ ← cj else tween word pairs as one of learning a Mahalanobis distance metric from a given set of relationally similar and dissimilar word pairs . Given two points xi , xj , the ( squared ) Mahalanobis distance between them , dA(xi , xj ) , is parametrized using a positive definite matrix A as follows , dA(xi , xj ) = ( xi − xj)T A(xi − xj ) .
( 1 )
The Mahalanobis distance is a straightforward extension of the standard Euclidean distance . In fact , if we let A be the identity matrix , then the Mahalanobis distance reduces to the Euclidean distance .
The motivation behind using Mahalanobis distance to measure relational similarity is two fold . First , Mahalanobis distance can be learned from a few data points , and efficient algorithms that can scale well to high dimensional feature spaces are known [ 13 , 12 ] . Second , unlike Euclidean distance , Mahalanobis distance does not assume that features are independent . This is particularly important for relational similarity measures because semantic relations are not always independent . A posterior analysis of the Mahalanobis matrix ( A ) can provide useful information related to the correlation between semantic relations . p∈cj
To learn a Mahalanobis distance metric , we first represent each word pair ( ai , bi ) as a feature vector xi . The j th element of xi is the total frequency of the word pair ( ai , bi ) in the j th cluster ; it is given as f ( ai , bi , p ) . Here , p is a pattern in the cluster cj , and f ( ai , bi , p ) is the number of times that the word pair ( ai , bi ) appears with the pattern p . We L2 normalize all feature vectors .
Given a set of relationally similar pairs S and dissimilar pairs D , the problem of learning a relational similarity measure becomes one of finding a positive definite matrix A , such that dA(xi , xj ) ≤ u for all ( i , j ) ∈ S , and dA(xi , xj ) ≥ l for all ( i , j ) ∈ D . Here u and l respectively signify upper and lower bounds of the decision threshold , and are set experimentally as described later in section 4 . Intuitively , word pairs that share identical semantic relations must have a higher relational similarity . We set an additional constraint that the learned Mahalanobis matrix A must be “ close ” to the identity matrix I to incorporate this prior knowledge in the learning problem at hand . This keeps the Mahalanobis distance similar to the Euclidean distance ; it also helps to prevent overfitting of the
WWW 2009 MADRID!Track : Semantic/Data Web / Session : Mining for Semantics655 data . We follow the information theoretic metric learning ( ITML ) approach proposed by Davis et al . [ 13 ] to optimize the matrix A .
We observe the fact that there exists a simple bijection ( up to a scaling function ) between the set of Mahalanobis distances and the set of equal mean multivariate Gaussian distributions to quantify the “ closeness ” between A and I . Assuming the equal mean to be µ , for a Mahalanobis distance parameterized by A , the corresponding Gaussian is given by p(x ; A ) = 1 2 dA(x , µ) ) , where Z is a normalizing constant and A−1 is the covariance of the distribution . Then , the closeness between A and I is measurable using the Kullback Liebler ( KL ) divergence between their corresponding multivariate Gaussians :
Z exp(− 1
KL(p(x ; I ) p(x ; A ) ) = p(x ; I ) p(x ; A ) Using Formula 2 , the learning problem can be stated as p(x ; I ) log dx .
A
KL(p(x ; I ) p(x ; A ) ) ( i , j ) ∈ S ( i , j ) ∈ D . min dA(xi , xj ) ≤ u dA(xi , xj ) ≥ l s.t
Algorithm 2 Information theoretic metric learning . Input : X , ( d× n matrix ) ; S , set of similar pairs ; D , set of dissimilar pairs ; u , l : distance thresholds ; I , identity matrix ; γ , slack parameter ; c , constraint index function
( cid:179 )
Output : A : Mahalanobis matrix 1 : A ← I , λij ← 0 ∀i , j 2 : ξc(i,j ) ← u for ( i , j ) ∈ S ; otherwise ξc(i,j ) ← l 3 : repeat 4 : 5 : 6 : 7 : 8 : 9 : 10 : 11 : A ← A + βA(xi − xj)(xi − xj)T A 12 : until convergence 13 : return A
Pick a constraint ( i , j ) ∈ S or ( i , j ) ∈ D p ← ( xi − xj)T A(xi − xj ) δ ← 1 if ( i , j ) ∈ S , −1 otherwise α ← min p − γ β ← δα/(1 − δαξc(i,j ) ) ξc(i,j ) ← γξc(i,j)/(γ + δαξc(i,j ) ) λij ← λij − α
( cid:180)(cid:180 )
λij , δ 2
( cid:179 )
ξc(i,j )
1
( 2 )
( 3 )
The integral form of the KL divergence presented in Formula 2 is difficult to numerically optimize directly . However , it has been shown that the KL divergence between two multivariate Gaussians can be expressed as the convex combination of a Mahalanobis distance between mean vectors and the LogDet divergence between the covariance matrices [ 11 ] . Therefore , assuming that the means of the Gaussians are equal , we have KL(p(x ; I ) p(x ; A ) ) =
( 4 ) Here , Dld(A , B ) is the LogDet divergence of n×n positive definite matrices A , B . It is given as
Dld(A , I ) .
1 2
Dld(A , B ) = tr(AB
−1 ) − log det(AB
−1 ) − n .
( 5 )
Finally , we incorporate slack variables into the formulation 3 to guarantee the existence of a feasible solution for A , and pose the following optimization problem : st
Dld(A , I ) + γDld(diag(ξ ) , diag(ξ0 ) ) min A(cid:186)0,ξ tr(A(xi − xj)(xi − xj)T ) ≤ ξc(i,j ) tr(A(xi − xj)(xi − xj)T ) ≥ ξc(i,j )
( i , j ) ∈ S ( i , j ) ∈ D ,
( 6 ) where c(i , j ) is the index of the ( i , j) th constraint , ξ is a vector of slack variables , initialized to ξ0 ( components of ξ0 are initialized to u and v , respectively , for similar and dissimilar constraints ) , and γ is the parameter that controls the tradeoff between satisfying the constraints and minimizing Dld(A , I ) . Algorithm 2 solves the optimization problem 6 by repeatedly projecting the current solution onto a single constraint . Unlike Latent Relational Analysis [ 33 ] , Algorithm 2 requires no eigen decomposition , which is time consuming for large matrices . In Algorithm 2 , a single iteration of looping through all constraints costs O(cd2 ) , where c signifies the number of constraints , and d represents the dimensionality of feature vectors .
Once we obtain a Mahalanobis matrix A from Algorithm 2 , we can use Formula 1 to compute relational distances . Distance and similarity are inversely related . Therefore , it is possible to use Formula 1 directly to compare word pairs . However , if one wants to convert distance values ranging in [ 0 , +∞ ) to similarity scores ranging in [ 0 , 1 ] , it can be done using sigmoid functions [ 27 ] .
4 . EXPERIMENTS
We use two different datasets to evaluate the proposed relational similarity measure in two tasks : classifying semantic relations between named entities , and solving SAT word analogy questions . Solving SAT word analogy questions was first proposed by Turney et al . [ 35 ] as a benchmark to evaluate relational similarity measures . An SAT analogy question consists of a stem word pair that acts as the question , and five choice word pairs . A relational similarity measure under evaluation will compare the stem word pair with each choice word pair separately , and select the choice word pair with the highest relational similarity as the correct answer . The dataset contains 374 questions .
A limitation frequently associated with the SAT dataset is that it contains no named entities or relations that Web users are typically interested in , such as relations pertaining to companies or people . Consequently , in addition to the SAT dataset , we created a dataset3 containing only entity pairs to evaluate the proposed relational similarity measure . Hereinafter , we designate this as the ENT dataset . The ENT dataset contains 100 instances ( ie named entity pairs ) of the following five relation types .
ACQUIRER ACQUIREE This relation holds between pairs of com pany names ( A,B ) , where the company B ( acquiree ) is acquired by the company A ( acquirer ) . We only consider acquisitions that have already completed .
PERSON BIRTHPLACE This relation holds between pairs ( A,B ) , where A is the name of a person , and B is the location ( place ) where A was born . We consider city names and countries as locations .
CEO COMPANY This relation holds between pairs ( A,B ) , where A is the chief executive officer ( CEO ) of a company B . We consider both current as well as past CEOs of companies .
COMPANY HEADQUARTERS This relation holds between pairs A,B , where company A ’s headquarters is located in a place B . We select names of cities as B .
PERSON FIELD This relation holds between pairs ( A,B ) , where a person A is an expert or is known for his or her abilities in a
3http://wwwmivtu tokyoacjp/danushka/reldatazip
WWW 2009 MADRID!Track : Semantic/Data Web / Session : Mining for Semantics656 Relation Type ACQUIRER ACQUIREE PERSON BIRTHPLACE CEO COMPANY , COMPANY HEADQUARTERS PERSON FIELD
Total contexts
Table 1 : Overview of the relational similarity dataset . Examples ( 20 in all for each relation type ) ( Google , YouTube ) , ( Adobe Systems , Macromedia ) , ( Yahoo , Inktomi ) ( Franz Kafka , Prague ) , ( Charlie Chaplin , London ) , ( Marie Antoinette , Vienna ) ( Terry Semel , Yahoo ) , ( Eric Scmidt , Google ) , ( Steve Jobs , Apple ) ( Microsoft , Redmond ) , ( Yahoo , Sunnyvale ) , ( Google , Mountain View ) ( Albert Einstein , Physics ) , ( Roger Federer , Tennis ) , ( Shane Warne , Cricket )
91439 72836 82682 100887 99660 field B . Instances of this relation contain scientists and their field of expertise , athletes and the sports they are associated with , and artists and the genre in which they perform .
We selected the relation types described above because previous studies of relation detection on the Web have frequently used those relations in evaluations [ 6 ] . We manually selected 20 instances for each of the five relation types . Instances were selected from various information sources such as Wikipedia4 , online newspapers , and company reviews5 .
For word pairs in SAT and ENT datasets using the YahooBOSS API6 , we download snippets as described in section 32 For each relation type in ENT dataset , in Table 1 , we show some instances and the total number of contexts . We randomly split the ENT dataset into five equal sized partitions to conduct five fold cross validation . Four partitions are used to extract patterns , clustering and training . The remaining partition is used for testing . For ENT data , positive training instances are generated by coupling word pairs that belong to the same relation type ( ie , 5× ( 20× 19)/2 = 950 instances ) , and an equal number of negative training instances are generated by randomly coupling word pairs that belong to different relation types .
We run the pattern extraction algorithm described in section 3.3 on the contexts in our dataset to extract lexical patterns . Experimentally , we set the values for the various parameters in the pattern extraction algorithm : L = 5 , g = 2 , and G = 4 . The proposed pattern extraction algorithm identifies numerous lexical patterns . For example , for ENT training data , the algorithm extracts 473910 unique patterns . However , of those , only 148655 ( 31.36 % of the total ) occur more than twice . Patterns that only occur once contain misspellings or badly formatted text . We only select the patterns that occur at least twice to filter out this noise . The remaining experiments described in this paper are performed using those patterns . We first compute the distribution of Euclidean distances over the training data to determine the values for distance thresholds u and l in Algorithm 2 . We then respectively select the 5 th and 95 th percentiles of distance distribution as u ( 1.96 ) and l ( 022 ) Slack parameter γ is set to 0.01 experimentally . 4.1 Relation Classification
We evaluate the proposed relational similarity measure in a relation classification task . Given an entity pair , the goal is to select a relation out of the five relation types in the ENT dataset that describes the relation between the two entities . This is a multi class classification problem . We use k nearest neighbor classification to assign a relation to a given entity pair . Specifically , given an entity pair ( a , b ) , for which a relation R holds , we compute the relational similarity between ( a , b ) and the remaining entity pairs in the dataset . We then sort the word pairs in the descending order of relational similarity with ( a , b ) , and select the most similar k en4http://wikipedia.org/ 5http://wwwforbescom/ 6http://developeryahoocom/search/boss/ tity pairs . We then find the relation that is given to most of those k entity pairs and assign this relation to ( a , b ) . Ties are resolved randomly . This procedure is repeated for each entity pair in the ENT dataset . Overall accuracy of relation classification is computed as
Accuracy =
No . of correctly classified entity pairs
Total no . of entity pairs
.
( 7 )
A good relational similarity measure must assign higher similarity scores to word pairs with similar implicit relations . However , the classification accuracy does not evaluate the relative rankings of similarity scores . We use average precision [ 29 ] to evaluate the top k most similar entity pairs to a given entity pair . Average precision integrates the precision at different ranks . It is frequently used as an evaluation measure in retrieval tasks . The average precision for a particular relation type R is defined as k r=1 Pre(r ) × Rel(r ) No of relevant word pairs .
AveragePrecision =
( 8 )
Here , Rel(r ) is a binary valued function that returns 1 if the entity pair at rank r has the same relation ( ie , R ) as in ( a , b ) . Otherwise , it returns zero . Furthermore , Pre(r ) is the precision at rank r , which is given as
Pre(r ) = no . of entity pairs with relation R in top r pairs r
.
( 9 )
The number of relevant entity pairs is 20 for all five relation types in our dataset . We consider the 10 most similar entity pairs ( ie , k = 10 ) for nearest neighbor classification . The average precision is computed for those top 10 entity pairs .
We use ENT training data to investigate the effect of clustering threshold θ ( Algorithm 1 ) on relation classification performance . Results are summarized in Figure 3 . Overall , in Figure 3 , we see that performance increases with θ . This is because higher values of θ result in highly similar pattern clusters that represent specific semantic relations . However , a slight drop of performance can be observed for high θ values , because it produces a large number of pattern clusters ( ie , increased model complexity ) , which results in over fitting the data . The best performance is reported for θ = 0905 The remaining experiments described in this section use this value of theta .
In Table 2 , we show the top 10 clusters with the largest number of lexical patterns . The number of patterns in each cluster is shown within brackets in the first column . For each cluster in Table 2 , we show the top four patterns that occur in the greatest number of entity pairs . For explanatory purposes , we label the clusters with the five relation types as clusters 1 and 4 ( acquirer acquiree ) ; clusters 2 , 3 , 6 , and 7 ( person field ) ; cluster 5 ( CEO company ) ; cluster 8 and 10 ( company headquarters ) ; cluster 9 ( person birthplace ) . Table 2 clarifies that patterns representing various semantic relations are extracted by the proposed pattern extraction algorithm . Moreover , we see that each cluster contains different lexical patterns that express a specific semantic relation . We can also find multiple clusters even among the top few clusters shown in Table 2 that represent
WWW 2009 MADRID!Track : Semantic/Data Web / Session : Mining for Semantics657 Table 2 : Most frequent patterns in the largest clusters .
X acquires Y Y legend X was Y champion X cluster 1 ( 2868 ) cluster 2 ( 2711 ) cluster 3 ( 2615 ) cluster 4 ( 2008 ) cluster 5 ( 2002 ) cluster 6 ( 1364 ) X revolutionized Y X and modern Y cluster 7 ( 845 ) cluster 8 ( 280 ) cluster 9 ( 144 ) cluster 10 ( 49 )
X headquarters in Y X ’s childhood in Y X headquarters in Y
X to buy Y Y founder X
X has acquired Y X ’s championship Y world Y champion X X and Y confirmed
Y founder and CEO X
X professor of Y
X offices in Y X ’s birth in Y
X ’s Y headquarters genius : X and modern Y Y in DDDD , X was past X offices in Y
X ’s Y acquisition
Y star X was X teaches Y X buy Y is
X , founder of Y in Y since X
Y born X Y based X
X , acquisition , Y
X autographed Y ball
X ’s greatest Y
Y purchase to boost X
X says Y on Y by X ago , X revolutionized Y the X conference in Y Y born X introduced the
X works with the Y
Y goes X
Y star X robbed Y players like X X is buying Y X talks up Y
X ’s contribution to Y
X ’s lectures on Y
X headquarters in Y on sobbing X left Y to
Y office of X
Table 3 : Performance of the proposed method and baselines . PROP Relation acquirer acquiree 0.9415 comp. headquarters 0.8653 person field 0.5715 CEO comp . 0.9578 person birthplace 0.3648 Overall Average Precision 0.7403 Classification Accuracy
LRA 0.9224 0.8254 0.4396 0.9612 0.2795 0.6856
VSM 0.9227 0.8455 0.4470 0.9582 0.2747 0.6896
EUC 0.9147 0.7986 0.5195 0.9058 0.3343 0.6946
0.93
0.88
0.86
0.90
Figure 3 : Performance of the proposed method against the clustering threshold ( θ ) a particular relation type . For example , cluster 1 and 4 both represent an acquirer acquiree relation , although the patterns in cluster 1 are derived from the verb acquire , whereas the patterns in cluster 4 are derived from the verbs buy and purchase . We can expect a certain level of correlation among such clusters , which justifies the use of the Mahalanobis distance instead of Euclidean distance when computing relational similarity . We compare the proposed relational similarity measure ( PROP ) to the Euclidean distance baseline ( EUC ) , vector space model based relational similarity [ 35 ] ( VSM ) and the state of the art Latent Relational Analysis [ 33 ] ( LRA ) . Next , we explain each of those relational similarity measures in detail . VSM : This is the vector space model based approach proposed by Turney et al . [ 35 ] . First , each word pair is represented using a vector of pattern frequencies . Then the relational similarity between two word pairs is computed as the cosine of the angle between the two vectors representing the two word pairs . This approach is equivalent to computing relational similarity using Formula 1 , if we define feature vectors as pattern frequency vectors and take the identity matrix as A . represent word pairs and the columns represent lexical patterns . An element of the matrix corresponds to the frequency of occurrence of a word pair in a particular lexical pattern . Next , singular value decomposition ( SVD ) is performed on this matrix to reduce the number of columns . Finally , the relational similarity between two word pairs is computed as the cosine of the angle between the corresponding row vectors . We re implemented LRA as described in the original paper . However , we do not use related word thesauri to find additional word pairs , because such resources are not available for named entities . Following , Turney ’s proposal , we used the most frequent 4000 lexical patterns in the matrix and reduced the number of columns to 300 via SVD ( ie , eigenvectors corresponding to the largest 300 eigenvalues are used to approximate the matrix ) . We used Scientific Python ’s SVD library7 for the computation of SVD . LRA is the current state of the art relational similarity measure .
EUC : We set A in Formula 1 to the identity matrix and compute relation similarity using pattern clusters . This is equivalent to computing relational similarity between two word pairs as the Euclidean distance between the corresponding two feature vectors created using pattern clusters . This baseline is a cut down version of the proposed method , where all clusters are assumed to be independent . This baseline is expected to show the decrease in the performance when we do not use Mahalanobis distance learning .
PROP : This is the proposed relational similarity measure , defined in Formula 1 . For both EUC and PROP , we used the same set of clusters . Therefore , any difference in performance can be attributable to using the Mahalanobis distance when computing relational similarity . We used the 10447 clusters derived by setting the clustering threshold θ to the value 0905
LRA : This is the Latent Relational Analysis ( LRA ) proposed by Turney [ 33 ] . First , a matrix is created , in which the rows
7wwwscipyorg
0 20 40 60 80 100 0 0.2 0.4 0.6 0.8 1PerformanceClustering ThresholdAccuracyAverage PrecisionWWW 2009 MADRID!Track : Semantic/Data Web / Session : Mining for Semantics658 Table 4 : Performance on the SAT dataset .
Algorithm Random guessing Jiang & Conrath [ 33 ] Lin [ 33 ] Leacock & Chodrow [ 33 ] Hirst & St. Onge [ 33 ] Resnik [ 33 ] PMI IR [ 33 ] SVM [ 5 ]
Algorithm score 20.0 % LSA+Predictation [ 20 ] 27.3 % Veale ( WordNet ) [ 38 ] 27.3 % Bicici & Yuret [ 4 ] 31.3 % VSM [ 34 ] 32.1 % PROPOSED 33.2 % Pertinence [ 32 ] 35.0 % LRA [ 33 ] 40.1 % Human score 42.0 % 43.0 % 44.0 % 47.1 % 51.1 % 53.5 % 56.1 % 57.0 %
The four methods described above presented for comparison in Table 3 . For each relation type , Table 3 shows the average precision scores computed using Formula 8 . Moreover , the overall performance is reported using both average precision and classification accuracy . The proposed method ( PROP ) reports the highest overall average precision ( 0.7403 ) in Table 3 . In fact , PROP has the best average precision scores for four out of the five relation types . Analysis of variance ( ANOVA ) reveals that the average precision scores in Table 3 are statistically significant . Moreover , paired ttests conducted between the proposed method ( PROP ) and each of the remaining three methods in Table 3 , reveal that the improvement shown by PROP over VSM , EUC , and LRA is statistically significant ( α = 001 ) PROP has the highest classification accuracy ( 0.93 ) , followed by EUC , LRA , and VSM , in that order . It is noteworthy that the EUC baseline that does not consider intercluster correlation performs better than the VSM method . This result shows that clustering similar patterns prior to computing relational similarity indeed improves performance . Among the five relation types compared in Table 3 , high average precision scores are reported for the following three relation types : acquirer acquiree , company headquarters , and CEO company . Lowest performance is reported for the person birthplace relation . A closer look into the snippets extracted for the person birthplace pairs revealed that there were many snippets that convey information related to places that people associate with places other than their place of birth . For example , regarding actors , the locations where they gave their first performance are incorrectly extracted as contexts for the personbirthplace relation . 4.2 Solving SAT Word Analogy Questions
Following the previous work on relational similarity measures , we use the proposed method to solve SAT word analogy questions . We split the SAT dataset ( 374 questions ) randomly into five partitions and select four partitions as training data and the remainder as test data . The procedure is repeated with different partitions . Then the experimental results are reported for five fold cross validation . For all word pairs in the SAT dataset , we download contexts from the Web ( section 3.2 ) , and extract lexical patterns ( section 33 ) We then cluster the extracted patterns using Algorithm 1 . Next , for each SAT question in the training dataset , we create a positive training instance by coupling the stem word pair with the correct answer . Similarly , negative training instances are created by coupling the stem word pair with incorrect answers . We then use Algorithm 2 to learn a Mahalanobis distance matrix from the training data . To solve an SAT question in the test dataset , we compute the relational similarity ( alternatively distance ) between the stem word pair and each choice word pairs using Formula 1 , and select the choice with the highest relational similarity ( lowest distance ) as the correct answer . The SAT score is computed as the percentage of correctly answered questions to the total questions in the dataset .
As shown in Table 4 the proposed method reports an SAT score of 51.1 % ; it is ranked 3rd among 16 systems . The average SAT score reported by high school students is 57 % . Randomly guessing one out of five choices gives the lower bound of 20 % . The proposed method outperforms WordNet based relational similarity measures ( Veale [ 38 ] ) as well as various corpus based approaches . The two systems that perform better than the proposed method ( ie , Pertinence and LRA ) use a synonym dictionary to find similar word pairs . However , the proposed method requires no external resources such as synonym dictionaries to compute relational similarity . In fact , synonym dictionaries for named entities are either not available or incomplete . Moreover , as stated in the original paper , LRA takes over 9 days to answer the 374 questions in the SAT dataset , whereas the proposed method requires less than 6 hours to answer the same set of questions . The gain in processing time can be attributable to two factors . First , unlike LRA and Pertinence , the proposed method requires no singular value decomposition ( SVD ) . Performing SVD on large matrices is time consuming . For example , in LRA the data matrix consists of 2176 word pairs ( rows ) and 4000 patterns ( columns ) . Second , compared to LRA , the proposed method requires much fewer search engine queries . In LRA , to compute the feature vector for a word pair we must issue a query for each pattern extracted . For example , with 4000 patterns , LRA requires at least 8000 ( 4000×2 word pairs ) search engine queries to compute the relational similarity between two word pairs . On the other hand , the proposed method searches for patterns only within the snippets downloaded for a word pair . Because multiple snippets can be downloaded by issuing a single query , the proposed method requires only two search engine queries to compute the relational similarity between two word pairs . Moreover , the number of search engine queries is independent of the number of patterns . Therefore , the proposed method is more appropriate in an online setting ( eg , web search ) , in which we must quickly compute relational similarity for unseen word pairs .
The definition of relational similarity , as given in Formula 1 can be viewed as a general framework into which all existing relational similarity measures can be integrated . The existing approaches differ in their definition of matrix A . For example , in VSM , A is the identity matrix , and in LRA it is computed via SVD . The proposed method learns a Mahalanobis distance matrix as A using training data . The task of designing relational similarity measures can be modeled as searching for a matrix A that best reflects the notion of relational similarity possessed by humans .
5 . CONCLUSION
We proposed a method to compute the similarity between implicit semantic relations in two word pairs . Given two word pairs , the proposed relational similarity measure first finds contexts in which the two words in each word pair cooccur on the Web . We used text snippets returned by a Web search engine as contexts , and proposed a shallow lexical pattern extraction algorithm to represent the various semantic relations that exist between two words . The proposed pattern extraction algorithm requires no language specific preprocessing techniques such as part of speech taggers or dependency parsers . We then cluster the extracted patterns to identify the different lexical patterns that convey a particular semantic relation . We proposed a sequential clustering algorithm that scales linearly with the number of patterns to cluster a larger number of patterns efficiently . We create a feature vector using the formed pattern clusters , and compute the relational similarity between two word pairs as the Mahalanobis distance between the two feature vectors . Experimental results on a relation classification task and SAT wordanalogy task , showed that the proposed method markedly outperforms various baselines and reduces the processing time of previously proposed latent relational analysis . In future studies , we
WWW 2009 MADRID!Track : Semantic/Data Web / Session : Mining for Semantics659 intend to employ the proposed relational similarity measure to retrieve a set of word pairs for a given implicit relation from the Web .
6 . REFERENCES [ 1 ] K . Barker and S . Szpakowicz . Semi automatic recognition of noun modifier relationships . In Proc . of COLING’98 , pages 96–102 , 1998 .
[ 2 ] M . Berland and E . Charniak . Finding parts in very large corpora . In Proc . of ACL’99 , pages 57–64 , 1999 .
[ 3 ] R . Bhagat and D . Ravichandran . Large scale acquisition of paraphrases for learning surface patterns . In Proc . of ACL’08 : HLT , pages 674–682 , 2008 .
[ 4 ] E . Bicici and D . Yuret . Clustering word pairs to answer analogy questions . In Proc . of TAINN’06 , 2006 .
[ 5 ] D . Bollegala , Y . Matsuo , and M . Ishizuka . Www sits the sat :
Measuring relational similarity on the web . In Proc . of ECAI’08 , pages 333–337 , 2008 .
[ 6 ] R . C . Bunescu and R . Mooney . Learning to extract relations from the web using minimal supervision . In Proc . of ACL’07 , pages 576–583 , 2007 .
[ 7 ] P . Cimiano and J . Wenderoth . Automatic acquisition of ranked qualia structures from the web . In Proc . of ACL’07 , pages 888–895 , 2007 .
[ 8 ] A . Culotta and J . Sorensen . Dependency tree kernels for relation extraction . In Proc . of ACL’04 , pages 423–429 , 2004 .
[ 9 ] D . Davidov and A . Rappoport . Classification of semantic relationships between nominals using pattern clusters . In Proc . of the ACL’08 , 2008 .
[ 10 ] D . Davidov and A . Rappoport . Unsupervised discovery of generic relationships using pattern clusters and its evaluation by automatically generated sat analogy questions . In Proc . of ACL’08 HLT , pages 692–700 , 2008 .
[ 11 ] J . V . Davis and I . S . Dhillon . Differential entropic clustering of multivariate gaussians . In Proc . of NIPS’06 , pages 337–344 , 2006 .
[ 12 ] J . V . Davis and I . S . Dhillon . Structured metric learning for high dimensional problems . In Proc . of KDD ’08 , pages 195–203 , 2008 .
[ 13 ] J . V . Davis , B . Kulis , P . Jain , S . Sra , and I . S . Dhillon .
Information theoretic metric learning . In IProc . of CML’07 , pages 209–216 , 2007 .
[ 14 ] O . Etzioni , M . Cafarella , D . Downey , A . Popescu , T . Shaked ,
S . Soderl , D . S . Weld , and E . Yates . Unsupervised named entity extraction from the web : An experimental study . Artificial Intelligence , 165:91–134 , 2005 .
[ 15 ] B . Falkenhainer , K . Forbus , and D . Gentner . Structure mapping engine : Algorithm and examples . Artificial Intelligence , 41:1–63 , 1989 .
[ 16 ] Z . Harris . Distributional structure . Word , 10:146–162 , 1954 . [ 17 ] M . Hearst . Automatic acquisition of hyponyms from large text corpora . In Proc . of 14th COLING , pages 539–545 , 1992 .
[ 18 ] D . Lin . Automatic retrieval and clustering of similar words .
In Proc . of COLING ACL’98 , pages 768–774 , 1998 .
[ 19 ] D . Lin and P . Pantel . Dirt : Discovery of inference rules from text . In Proc . of ACM SIGKDD’01 , pages 323–328 , 2001 .
[ 20 ] P . Mangalath , J . Quesada , and W . Kintsch . Analogy making as predictation using relational information and lsa vectors . In Proc . of Int’l Conf . on Research in Computational Linguistics , 2004 .
[ 21 ] Z . Marx , D . Ido , B . Joachim , and S . Eli . Coupled clustering : A method for detecting structural correspondance . Journal of Machine Learning Research , 3:747–780 , 2002 .
[ 22 ] D . Medin , R . Goldstone , and D . Gentner . Respects for similarity . Psychological Review , 6(1):1–28 , 1991 . [ 23 ] G . Miller , R . Beckwith , C . Fellbaum , D . Gross , and K . Miller . Introducton to wordnet : An on line lexical database . International Journal of Lexicography , 3:238–244 , 1990 .
[ 24 ] P . Nakov and M . Hearst . Solving relational similarity problems using the web as a corpus . In Proc . of ACL’08 HLT , pages 452–460 , 2008 .
[ 25 ] M . Pasca , D . Lin , J . Bigham , A . Lifchits , and A . Jain .
Organizing and searching the world wide web of facts step one : the one million fact extraction challenge . In Proc . of AAAI’06 , pages 1400–1405 , 2006 .
[ 26 ] J . Pei , J . Han , B . Mortazavi Asi , J . Wang , H . Pinto , Q . Chen ,
U . Dayal , and M . Hsu . Mining sequential patterns by pattern growth : the prefixspan approach . IEEE Transactions on Knowledge and Data Engineering , 16(11):1424–1440 , 2004 .
[ 27 ] J . Platt . Probabilistic outputs for support vector machines and comparison to regularized likelihood methods . Advances in Large Margin Classifiers , pages 61–74 , 2000 .
[ 28 ] D . Ravichandran and E . Hovy . Learning surface text patterns for a question answering system . In Proc . of ACL ’02 , pages 41–47 , 2001 .
[ 29 ] G . Salton and C . Buckley . Introduction to Modern
Information Retreival . McGraw Hill Book Company , 1983 . [ 30 ] R . Snow , D . Jurafsky , and A . Ng . Learning syntactic patterns for automatic hypernym discovery . In Proc . of Advances in Neural Information Processing Systems ( NIPS ) 17 , pages 1297–1304 , 2005 .
[ 31 ] P . Turney . Measuring semantic similarity by latent relational analysis . In Proc . of IJCAI’05 , pages 1136–1141 , 2005 . [ 32 ] P . Turney . Expressing implicit semantic relations without supervision . In Proc . of Coling/ACL’06 , pages 313–320 , 2006 .
[ 33 ] P . Turney . Similarity of semantic relations . Computational
Linguistics , 32(3):379–416 , 2006 .
[ 34 ] P . Turney and M . Littman . Corpus based learning of analogies and semantic relations . Machine Learning , 60:251–278 , 2005 .
[ 35 ] P . Turney , M . Littman , J . Bigham , and V . Shnayder .
Combining independent modules to solve multiple choice synonym and analogy problems . In Proc . of RANLP’03 , pages 482–486 , 2003 .
[ 36 ] A . Tversky . Features of similarity . Psychological Review ,
84(4):327–352 , 1997 .
[ 37 ] T . Veale . The analogical thesaurus . In Proc . of 15th
Innovative Applications of Artificial Intelligence Conference ( IAAI’03 ) , pages 137–142 , 2003 .
[ 38 ] T . Veale . Wordnet sits the sat : A knowledge based approach to lexical analogy . In Proc . of ECAI’04 , pages 606–612 , 2004 .
[ 39 ] T . Veale and M . T . Keane . The competence of structure mapping on hard analogies . In Proc . of IJCAI’03 , 2003 .
[ 40 ] D . Zelenko , C . Aone , and A . Richardella . Kernel methods for relation extraction . Journal of Machine Learning Research , 3:1083–1106 , 2003 .
WWW 2009 MADRID!Track : Semantic/Data Web / Session : Mining for Semantics660
