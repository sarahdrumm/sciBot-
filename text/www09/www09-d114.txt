Adaptive Bidding for Display Advertising
Arpita Ghosh Yahoo! Research
2821 Mission College Blvd . arpita@yahoo inc.com
Santa Clara , CA 95054
Sergei Vassilvitskii
Yahoo! Research
111 West 40th St . , 17th Floor sergei@yahoo inc.com
New York , NY 10018
ABSTRACT Motivated by the emergence of auction based marketplaces for display ads such as the Right Media Exchange , we study the design of a bidding agent that implements a display advertising campaign by bidding in such a marketplace . The bidding agent must acquire a given number of impressions with a given target spend , when the highest external bid in the marketplace is drawn from an unknown distribution P . The quantity and spend constraints arise from the fact that display ads are usually sold on a CPM basis . We consider both the full information setting , where the winning price in each auction is announced publicly , and the partially observable setting where only the winner obtains information about the distribution ; these differ in the penalty incurred by the agent while attempting to learn the distribution . We provide algorithms for both settings , and prove performance guarantees using bounds on uniform closeness from statistics , and techniques from online learning . We experimentally evaluate these algorithms : both algorithms perform very well with respect to both target quantity and spend ; further , our algorithm for the partially observable case performs nearly as well as that for the fully observable setting despite the higher penalty incurred during learning .
Categories and Subject Descriptors F20 [ Analysis of Algorithms and Problem Complexity ] : General ; J.4 [ Social and Behavioral Sciences ] : Economics ; I26 [ Artificial Intelligence ] : Learning
General Terms Algorithms , Economics , Theory
Keywords Display advertising , guaranteed delivery , adaptive bidding , guess then double algorithms , concentration bounds
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . Distribution of these papers is limited to classroom use , and personal use by others . WWW 2009 , April 20–24 , 2009 , Madrid , Spain . ACM 978 1 60558 487 4/09/04 .
Benjamin I . P . Rubinstein Computer Science Division
University of California , Berkeley
Berkeley , CA 94720 benr@csberkeleyedu
Martin Zinkevich Yahoo! Research
2821 Mission College Blvd . Santa Clara , CA 95054 maz@yahoo inc.com
1 .
INTRODUCTION
A bidding agent is an entity that implements an online advertising campaign by bidding in ad auctions on behalf of an advertiser . A recent development in Web advertising is the emergence of an auction based marketplace for display ads , where advertisers can bid on individual display advertising opportunities in real time auctions , as in sponsored search . Such a marketplace allows advertisers greater flexibility in the design and implementation of their display advertising campaigns , which were previously restricted to contracts with publishers at pre negotiated prices . In this paper , we study the design of bidding agents for display advertising , which implement an ad campaign by bidding in such an auction based marketplace . The bidding agent in question could either be an advertiser herself , or an intermediary acting on behalf of the advertiser .
Since display advertising is usually sold on a per impression ( CPM ) basis , a campaign for display advertising has different goals and metrics than one for sponsored search [ 2 ] . A CPM based campaign typically has a target quantity of impressions that need to be acquired over a certain duration with certain targeting characteristics ( the targeting can include information both about the webpage on which the ad will appear , as well as the user viewing the page ) . In addition to the target quantity , a typical constraint in a CPM campaign is a budget constraint on the total spend , since payment is made on a CPM rather than a per click ( CPC ) basis . We will assume that the bidding agent wants to exhaust , rather than simply stay within , the allocated budget , for the following reason . Different advertisers often have different pieces of information regarding how valuable a particular user might be , and often a high bid for an impression reflects this information ; thus a high price might indicate high value1 . This also agrees with anecdotal observations that advertisers prefer to exhaust their budgets .
Consider a bidding agent that needs to win d impressions and has a total budget T . We assume that the bidding agent knows the total supply n of impressions satisfying the tar
1We assume that an intermediary implementing a campaign on behalf of an advertiser would also like to deliver highvalue impressions subject to the chosen budget . Since our algorithms target supply over budget when they are not simultaneously feasible , the intermediary can deliver the cheapest impressions if desired by choosing a small enough budget .
WWW 2009 MADRID!Track : Internet Monetization / Session : Web Monetization251 geting requirements ( this is clearly not true in practice , but a lower bound on the supply can be used instead ) . Define f = d/n to be the fraction of the supply that the agent needs to win , and define t = T /d to be target spend per impression won . We suppose that the highest bids from other bidders are drawn iid2 from a distribution with CDF P , and that each impression is sold using a second price auction . In general , a given target quantity and spend need not be simultaneously feasible for the distribution P—if this happens , we always choose in favor of quantity ( our algorithms can be modified to make the opposite choice ) . If the distribution P is known to the bidding agent , then the problem is simple ( under weak conditions described in Section 2 ) . Let z(cid:63 ) = P−1(f ) be the bid that would win fraction f of the supply . Define p(cid:63 ) such that EP [ X | X ≤ p(cid:63 ) ] = t , that is , p(cid:63 ) is the bid that achieves the target spend t in If z(cid:63 ) ≤ p(cid:63 ) then bidding p(cid:63 ) with probability expectation . A = f /P(p(cid:63 ) ) independently on each available impression achieves both the supply and spend targets in expectation . Otherwise , prioritizing supply , we bid z(cid:63 ) achieving the desired fraction of supply in expectation . In practice , of course , the distribution P is not known to the bidding agent . Our problem is therefore one of learning the unknown distribution P in order to meet the target quantity and spend constraints . However , learning incurs a penalty , leading to an explore exploit tradeoff . The nature of the penalty depends on the assumptions made about the extent of information available to the bidding agent . We consider two settings :
• Fully Observable Exchange . Here , the winning bid in each auction is announced publicly , so that the bidding agent can learn without placing any bids and therefore expending any budget . The only tradeoff here is between accuracy and length of exploration , which could affect feasibility during exploitation .
• Partially Observable Exchange . A harder problem is when the winning bid is not announced publicly— only the winner receives information about the price and therefore the distribution ( a realistic setting in online advertising ) . Thus the bidding agent can infer information about P only by bidding high enough to win , ie , it must pay for every sample it observes from the distribution .
We begin in Section 2 with algorithm Learn Then Bid for the fully observable case , and provide performance guarantees using non asymptotic uniform convergence results for empirical processes . While the algorithm is simple—it observes and then bids according to the empirical distribution , the analysis is a useful first step for the partially observable case . A natural improvement is to continue to learn while exploiting ; this algorithm indeed outperforms Learn ThenBid as shown experimentally in Section 4 .
In Section 3 we move on to the partially observable case , which is harder since a cost must be paid for every bid that is observed from the distribution . We give an algorithm Guess Double Panic that explores the distribution gradually based on a guess then double pattern , in order to control the spend in the learning phase . A simple guess then double algorithm does not suffice since the distribution may have mass concentrated right above a guess , leading to severe
2See Section 5 for a discussion . overspending upon doubling . We introduce a panic phase to the algorithm to deal with this problem , which limits the overspending and admits performance guarantees .
In Section 4 we experimentally evaluate these algorithms , as well as some additional heuristics , on realistic data derived from the Right Media Exchange . Both Learn ThenBid ( and its improved version Learn While Bid ) and GuessDouble Panic perform very well for a wide range of target fractions and spends . The experiments also demonstrate that natural heuristics for the partially observable case are indeed inadequate , and are well outperformed by GuessDouble Panic . Most interestingly , the lack of full information is not a severe handicap : Guess Double Panic does nearly as well as Learn Then Bid despite access to only partial information .
Related work : Although there are many commercial ventures that optimize campaigns on behalf of advertisers , the design and analysis of bidding agents for online advertising has not received much attention in the research literature . The focus has largely been on bidding agents for sponsored search keyword auctions—for instance , Cary et al . [ 2 ] propose and analyze a pragmatic bidding agent for sponsored search . Unlike display advertising , the goal there is to choose the optimal ( utility maximizing ) slot to bid on for each keyword ; the authors show that there is a greedy bidding strategy that leads to convergence to equilibrium when all advertisers use the same strategy .
In this paper , we consider approaches inspired by online learning ( cf . [ 3 ] for a survey ) . In particular , our results are similar to those on the multi armed bandit algorithm UCB1 [ 1 ] where there is an unknown stationary distribution over events from round to round ; we do almost as well asymptotically as we would had the distribution been known in advance . However , although this work has been extended to uncountably infinite action spaces [ 5 ] , it differs in two major factors : we try to get the correct average behavior ( ie , to behave correctly on average ) . Regret is inappropriate for this setting : bids going over budget result in a payoff of −∞ . Second , the expected price obtained on a given round as a function of the bid ( roughly analogous to cost in [ 6 ] ) is not only non convex , but there is also no pre determined Lipschitz constant K , making discretization of the action space unboundedly inefficient as a method of approximation . As an alternative , we focus on the specific properties of the problem to more efficiently explore and exploit .
2 . FULLY OBSERVABLE EXCHANGE
We first consider a fully observable exchange where the winning bid is revealed after every auction . After describing the algorithm we use the DKW inequality to bound the error on our estimates and the suboptimality of our performance . Learn Then Bid takes as input a target fraction f , spend t , supply n and exploration length m . It explores for m steps by bidding 0 , that is , simply waiting and forms the empirical CDF Pm from the observations Ei ∼ P . It then computes bid value3 P ( cid:63 ) m that would achieve the target spend t , and Z ( cid:63 ) m that would achieve the necessary fraction , and bids P ( cid:63 ) m with probability Am if is feasible to achieve both targets on Pm , else it bids Z ( cid:63 ) m .
We prove that the expected future fraction of impressions won and amount spent per impression by Learn Then Bid 3We follow the convention that inf ∅ := +∞ .
WWW 2009 MADRID!Track : Internet Monetization / Session : Web Monetization252 2 : Pm(x ) ← m−1m
Algorithm Learn Then Bid ( f , t , n , m ) 1 : Bid 0 for the first m opportunities ; m ← inf {p : EPm [ X | X ≤ p ] ≥ t} i=1 1 [ Ei ≤ x ] ; f n
( n−m)Pm(P ( cid:63 ) m )
3 : P ( cid:63 ) 4 : Am ← 5 : Z ( cid:63 ) 6 : if P ( cid:63 ) 7 : 8 : 9 : else 10 : 11 : end if m ← inf m ≥ Z ( cid:63 ) for opportunities i ∈ {m + 1 , . . . , n} do z : Pm(z ) ≥ f n n−m m then
Bid P ( cid:63 ) m with probability Am , and 0 otherwise . for opportunities i ∈ {m + 1 , . . . , n} do Bid Z ( cid:63 ) m . converge in probability with rates exponential in the learning phase length . We assume that the distribution P is continuous , strictly monotonic , has support on [ a , b ] where 0 ≤ a < b < ∞ and P(a ) = 0 . This implies that g(y ) = EP [ X | X ≤ y ] is welldefined , continuous and strictly increasing over [ a , b ] , and so P−1 and g−1 are well defined also .
Many of the results we obtain depend upon the problem being feasible after exploration . In Section 4 we show experimentally that m can be chosen small enough so that the problem remains feasible for most f and t . Moreover in normal scenarios , one needs a small number of impressions and has a small budget , and the total number of impressions tends to be large .
Definition 1 . Define γ = f n n−m . If t ≤ EP [ X ] , define p(cid:63 ) = g−1(t ) . A problem is feasible after exploration if t ≤ EP [ X ] and P(p(cid:63 ) ) ≥ γ . Note that this also implies γ ≤ 1 . We will refer to γ and p(cid:63 ) throughout this section as defined above . 2.1 Measurement Errors
The performance of the algorithm depends primarily upon the accuracy of the exploration phase measurements .
Definition 2 . For a given > 0 , the algorithm has accurate observations if for all x ∈ [ a , b ] :
|P(x ) − Pm(x)| ≤ .
( 1 )
The following is a restatement of the DKW inequality [ 4 ] . For the remainder of the analysis , we will condition our results on the observations being accurate .
Corollary 3 . For > 0 , the probability of the algorithm having accurate observations is greater than or equal to
1 − 2 exp,−2m 2 .
We next link accuracy to the expected fraction of supply won when bidding Z ( cid:63 ) m .
Lemma 4 . Given > 0 , if the problem is feasible after exploration , and the Learn Then Bid algorithm has accurate observations then m ) − γ| ≤ . Proof . We first consider bidding Z ( cid:63 )
|P(Z ( cid:63 ) m on each round of the bidding phase ; our goal is to prove that the expected fraction won P(Z ( cid:63 ) m ) is close to the target fraction γ whp If
( 2 )
γ ≤ , then P(Z ( cid:63 ) m ) ≥ 0 ≥ γ − . If γ > , then ( 0 , γ − ] = ∅ , and for any ∈ ( 0 , γ − ] , define z(cid:63)− = P−1(γ − − ) . Because the algorithm has accurate observations :
,z(cid:63)− ≤ P,z(cid:63)− + = γ −
Pm
< γ ≤ Pm ( Z ( cid:63 ) m ) , and so z(cid:63)− < Z ( cid:63 ) for all ∈ ( 0 , γ − ] , P(Z ( cid:63 ) P(Z ( cid:63 ) m by the monotonicity4 of Pm . Therefore , m ) > P(z(cid:63)− ) = γ − − , implying m ) ≥ γ − . By a similar argument , P(Z ( cid:63 ) m ) ≤ γ + . 2.2 Approximation of Target Supply Won
Our first main result states that Learn Then Bid wins close to f n opportunities , if the algorithm has accurate observations and the problem is feasible after exploration . The following lemma is a consequence of a positive partial derivative .
Lemma 5 . For γ , > 0 , xγ(x+ )−1 is strictly increasing , and xγ(x − )−1 is strictly decreasing .
Theorem 6 . Given > 0 , and j > m , let Bj be the jth bid of the Learn Then Bid algorithm . If the problem is feasible after exploration and the algorithm has accurate observations , then : m and therefore Bj = Z ( cid:63 )
γ − ≤ E[P(Bj)|E1 . . . Em ] ≤ γ − γ − 2 γ . ( 3 ) Proof . From Lemma 4 , we know that |P(Z ( cid:63 ) m ) − γ| ≤ . m ≥ P ( cid:63 ) m , then γ − ≤ P(Bj ) ≤ If Z ( cid:63 ) γ + ≤ γ− γ−2 γ . Therefore for the remainder of the proof we assume that P(P ( cid:63 ) m with probability Am , and zero otherwise ( P(0 ) = 0 ) . The conditional probability of winning bid j given the outcome of the exploration phase is P(P ( cid:63 ) it is this value we wish to show is close to the target γ : P(P ( cid:63 )
In this case , Bj = P ( cid:63 )
γ ≥ γ − m ) ≥ P(Z ( cid:63 ) m ) ≥ γ − . m)Am :
γ . m ) m)Am =
γ ≥ P(P ( cid:63 ) P(P ( cid:63 )
P(P ( cid:63 ) m ) Pm(P ( cid:63 ) m ) m ) +
γ
The first equality follows by definition of Am , the first inequality follows due to the accurate observations , and the final inequality is a consequence of Lemma 5 and the inequality P(P ( cid:63 ) m ) ≥ γ − . We upper bound the expected fraction won in a similar fashion : m ) ≥ P(Z ( cid:63 )
P(P ( cid:63 ) m ) Pm(P ( cid:63 ) m )
γ ≤ P(P ( cid:63 ) P(P ( cid:63 ) m ) m ) −
γ ≤ γ − γ − 2
γ .
2.3 Approximation of Target Spend
Our second theorem establishes that Learn Then Bid spends close to budget if the observations are accurate and the problem is feasible after exploration . To prove this , we first convert DKW type uniform closeness of true and empirical CDFs to uniform closeness of expected spend . This “ uniformity ” is gained by focusing only on the area of interest , bids that obtain at least γ − impressions . ( γ− )(γ−2 ) + ( b−a ) γ−2 ,
For a given ∈ ( 0 , γ/2 ) , define − = b
γ(γ− ) + ( b−a )
γ and + = b 4It is important that Pm(z(cid:63)− ) is strictly less than Pm(Z ( cid:63 ) m ) because Pm is weakly monotonic , thus the need for > 0 .
.
WWW 2009 MADRID!Track : Internet Monetization / Session : Web Monetization253 Lemma 7 . Given ∈ ( 0 , γ/2 ) , let z(cid:63)− = P−1(γ − ) and define the function gm(y ) = EPm [ X | X ≤ y ] . If the algorithm has accurate observations , then if Y ≥ z(cid:63)− : gm(Y ) −
− ≤ g(Y ) ≤ gm(Y ) + + .
Proof . Because the algorithm has accurate observations , both of the following relations hold5 for all y ∈ [ a , b ] : fifififi y a
( 1 − P(x ) ) dx − y a
|P(y ) − Pm(y)| ≤ ( 1 − Pm(x ) ) dx fifififi ≤ ( b − a ) .
Lower bounding gm(Y ) with the above relations , identity c+ = d c(c+ ) , and P(Y ) ≥ P(z(cid:63)− ) = γ − : c − d d gm(Y ) = a ( 1 − Pm(x ) ) dx
Pm(Y ) a + Y ≥ a + Y = g(Y ) − ( a + Y a ( 1 − P(x ) ) dx P(Y ) +
− ( b − a ) P(Y ) + a ( 1 − P(x ) ) dx ) P(Y )(P(Y ) + ) − ( b − a ) b
.
γ(γ − )
γ
≥ g(Y ) −
− ( b − a ) P(Y ) +
( 4 )
Upper bounding gm(Y ) proceeds by the same arguments and identity d c− = d c + d c(c− ) .
Theorem 8 . Given the problem is feasible and ∈ ( 0 , γ/2 ) , if the algorithm has accurate observations , j > m and Bj is the jth bid and Bj > 0 , then : t − − ≤ g(Bj ) ≤ t + + .
Proof . t −
− ≤ g(max(Z ( cid:63 ) m , P ( cid:63 ) m ) ) ≤ t + + .
( 5 ) m , P ( cid:63 )
Note that if j > m and Bj > 0 then Bj = g(max(Z ( cid:63 ) m) ) . As with Lemma 4 , we need to analyze values that bracket the value of interest . In particular , the first value of interest is z(cid:63)− = P−1(γ − ) . If g(z(cid:63)− ) ≥ t − − , then by Lemma 4 , m ≥ z(cid:63)− , and by the monotonicity of max(Z ( cid:63 ) m , P ( cid:63 ) m ) ) ≥ g(z(cid:63)− ) ≥ t − − . Therefore , we can g , g(max(Z ( cid:63 ) assume that g(z(cid:63)− ) < t− − . Since t > t− − > g(z(cid:63)− ) ≥ a , t − − is in the range of g and g−1(t − − ) ≥ z(cid:63)− . For ∈ ( 0 , t − − − a ] , define p(cid:63)− = g−1(t − − − ) . m ) ≥ Z ( cid:63 ) m , P ( cid:63 ) gm(p(cid:63)−
) − = t −
) ≤ g(p(cid:63)− < t ≤ gm(P ( cid:63 ) m ) , m , P ( cid:63 ) so p(cid:63)− ≤ P ( cid:63 ) creasing , for any > 0 , t − − − ≤ g(P ( cid:63 ) t − − ≤ g(P ( cid:63 ) t + + ≥ g(P ( cid:63 ) From Corollary 3 the algorithm has accurate observations m . Therefore , because g is monotonically inm ) , implying m ) ≤ g(max(Z ( cid:63 ) m) ) . By a similar argument , m ) . with probability 1 − 2 exp,−2n 2 . Combining this with ration . If ∈ ( 0 , γ/2 ) : With probability 1 − 2 exp,−2n 2 :
Theorems 6 and 8 proves that Learn Then Bid ’s performance converges to the targets in probability with fast rates :
Theorem 9 . Given a problem that is feasible after explo t −
− ≤ g(Bj ) ≤ t + + if Bj > 0
( 6 )
γ − ≤ E[P(Bj)|e1 . . . em ] ≤ γ − γ − 2
( 7 ) 5The integrals are well defined because P and Pm are bounded , monotonic functions .
γ .
3 . PARTIALLY OBSERVABLE EXCHANGE We now move on to the partially observable case , where information is revealed only to an auction ’s winner . This problem is more difficult because the bidder must pay a cost in order to obtain information ; specifically , we cannot simply learn about the auction by bidding zero for a while . The most brute force approach is to bid ∞ for an exploration period , but that can cause overspending by almost b/t when the target fraction is small . In this section , we will try to be approximately optimal . If b/t is small then we can bid b : however , we also want to handle the case where b/t is large . Consider a simple algorithm that works rather well : bid 2t blindly until the correct number of impressions are obtained . Observe that since the minimum bid to get f n impressions is less than the bid that gets an expected price of t , then the expected price paid when a bid is made which obtains f n is less than or equal to t . Therefore , by Markov ’s inequality , the number of the lowest f n impressions below 2t is f n/2 . Moreover , the most that one can spend is 2tf n , and since the budget is tf n , this is only twice the budget . Therefore , this algorithm will not dramatically overspend and it will obtain half the required impressions .
Instead of either of these extremes ( bidding 2t blindly or aggressively exploring with b ) , we will apply the guess thendouble pattern . This approach is used in a variety of domains . For instance , if we want to create an array of items but do not know how many elements it will contain , we make a guess , and if we need more space , we double the size of the array . Thus , the number of new allocations is logarithmic in the number of elements entered , and the number of copies is linear , and the size may be off by no more than a factor of two . Of course , doubling is only one possibility : in the case of the array , multiplying by a factor φ smaller than 2 will result in more copies but greater efficiency in space .
In the Guess Double Panic algorithm , we apply a modification of this technique to bids in the exploration phase . We will refer to a bid being used during exploration as an exploration bid . A “ safe ” bid6 is t , the target spend , since there is no danger of going over budget . From this point , we exponentially increase our exploration bid , exploring enough with each new bid to learn the distribution below this bid . At some point we notice our exploration bid exceeds p(cid:63 ) .
A na¨ıve approach is to simply test for this condition at each iteration , and then react to our experience at the end of each phase of the exploration ( ie , remove lines 8 9 ) . However , this can result in a large amount of overspending , as the following example shows.7 The target price is 10 cents and we need to obtain 10 % of the 1000 impressions . Therefore , we are searching for 100 impressions for $10.00 total . The distribution of bids is : 9.9 % are at 1 cent . 0.1 % are at $901 Finally , the remaining 90 % of the bids are at $1000 An ideal bid is $901 However , it is difficult to say whether this one bid will be observed . Unless there is a very slow exploration , the bids will likely exceed $10.00 during exploration . Thus , there will be a high penalty where the algorithm will most likely pay 10 times its budget .
Instead , if we start overspending during the exploration phase , we go to the Panic( ) subroutine , where we move into
6There is also the possibility that we underspend . This can happen if we get many opportunities while we are bidding too low . However , this is not a problem so long as the exploration period is sufficiently short with respect to γn . 7A similar continuous distribution is easy to construct .
WWW 2009 MADRID!Track : Internet Monetization / Session : Web Monetization254 a new phase of “ cautious exploration ” . Effectively , if we are overspending , then we momentarily ignore the budget , and target solely the number of impressions obtained . As before , we continue to increase the bids , but if we realize that we can get enough impressions in the exploitation phase , we immediately move on to the exploitation phase .
The algorithm continues to explore ( or panic ) until it finds a price Bi(cid:63 ) where it estimates its budget can be exhausted and it can win enough impressions ( or it has explored at b or above ) . As with the observable case , we have a good approximation of the outcome of bidding any price below Bi(cid:63 ) as we leave the exploration phase .
In particular , there are now three modes of operation . The first mode is exploration : the algorithm explores until it either gets enough information or the budget becomes tight . The second ( optional ) mode is panic : the budget is tight , but the algorithm does not have enough information to obtain the right number of impressions , so it aggressively grabs impressions until it reaches a more stable scenario . The third stage is exploitation . In the exploitation stage , if there is sufficient budget to obtain the right number of impressions , then the algorithm tries to exhaust the budget . Otherwise , it is thrifty and tries to get the right number of impressions at a discount price .
For the following algorithm , all variables are global .
Algorithm Guess Double Panic(f , t , n , m , φ ) 1 : Initialize : gremain ← f n ; budget ← tgremain 2 : Initialize : P0 ← 0 ; T0 ← 0 ; B0 ← 0 ; i ← 0 ; j ← 0 3 : while ( Tigremain < budget or Pi(n − j ) < gremain ) and
Bi < b do i ← i + 1 . Si ← ∅ to be a multiset . for k = 1 to m do
4 : 5 : Bi ← t(φ)i−1 . 6 : 7 : 8 : 9 : 10 : 11 : 12 : 13 : 14 : 15 : 16 : 17 : 18 : 19 : 20 : end if end for if Si = ∅ then Ti ← 1|Si| Pi ← |Si| 21 : m . 22 : end while 23 : i(cid:63 ) ← i . 24 : return Exploit( ) . return Panic( ) if ( gremain − 1)Ti−1 + Bi−1 > budget then j ← j + 1 . if gremain = 0 then Terminate . Bid Bi . if Bid wins then
Define pj ← price won . gremain ← gremain − 1 . budget ← budget − pj . Add pj to Si . p else Ti ← 0 . p∈Si
The first danger of using any exploration technique is that the problem may be unsolvable if one spends too much time exploring . Note that there will be no more than r = ( cid:100)logφ(b/t ) + 1 rounds of exploration , because then the bid will be above b . In each round , there are m bids , so mr is the maximum number of steps of exploration .
Definition 10 . Define γ = f n n−mr . If t ≤ EP [ X ] , define p(cid:63 ) = g−1(t ) . A problem is feasible after exploration if t ≤ EP [ X ] and P(p(cid:63 ) ) ≥ γ . ( Again , this implies γ ≤ 1 . ) if gremain < Pi−1(n − j ) then
Define pj ← price won . gremain ← gremain − 1 . budget ← budget − pj . Add pj to Si . end if j ← j + 1 . Bid Bi . if Bid wins then
Subroutine Panic 25 : while Bi−1 < b do 26 : while k ≤ m do 27 : i(cid:63 ) ← i − 1 . 28 : 29 : return Exploit( ) . 30 : 31 : 32 : 33 : 34 : 35 : 36 : 37 : 38 : 39 : 40 : 41 : 42 : end if k ← k + 1 . end while k ← 1 . if Si = ∅ then Ti ← 1|Si| Pi ← |Si| m . i ← i + 1 . Si ← ∅ to be a multiset .
43 : 44 : 45 : Bi = t(φ)i−1 . 46 : 47 : end while 48 : i(cid:63 ) ← i − 1 . 49 : return Exploit( ) . p∈Si p else Ti ← 0 .
Let us consider the period that generated Si . Define S(cid:63 ) i to be the multiset of all prices ( observed and unobserved ) during this period ( clearly not an observed set ) . As in the observed case , there are several observations we could make about this distribution ( although in this case only theoretically ) . Formally , define :
P i m(x ) = m
−1|{y ∈ S(cid:63 ) i |y ≤ x}| .
( 8 )
Moreover , we can look at these independently from the algorithm itself .
Definition 11 . The algorithm has accurate observam(x)−P(x)| ≤ tions if for each i ∈ {1 . . . r} , argmaxx∈[a,b ] |P i . servations is at most 2((cid:100)logφ(b/t ) + 1 ) exp,−2m 2 .
Lemma 12 . The probability of not having accurate ob
The probability of accurate observations can be determined by applying the DKW inequality to each round of exploration/panicking , and then applying a union bound .
Define Cexplore , Cpanic and Cexploit to be the spend during exploration , panic and exploitation , respectively . Define nexplore , npanic and nexploit to be the number of impressions won during exploration , panic and exploitation phases , respectively . Define m to be the number of opportunities during the exploration and panic phases combined . Define n(cid:63 ) exploit to be the target number of impressions that remain after the exploration and panic phases . Note that this is equal to gremain at the beginning of the exploitation phase . Instead of targeting γ as we did before , we are tarexploit ≤ f n geting γ = and m ≤ mr , implying that γ ≤ 1 . Because the number of impressions obtained is a priority , the proof that this is achieved is fairly straightforward . The spend we will bound is C = Cexplore + Cpanic + E[Cexploit|E1 . . . Em ] .
, where γ ≤ γ because n(cid:63 ) n(cid:63 ) exploit n−m
WWW 2009 MADRID!Track : Internet Monetization / Session : Web Monetization255 Subroutine Exploit 50 : If gremain ≤ 0 or j ≥ n then Terminate . 51 : Bfinal ← Bi(cid:63 ) . 52 : A ← gremain Pi(cid:63 ) ( n−j ) . 53 : if Pi(cid:63 ) ( n − j ) > gremain and Ti(cid:63 ) gremain > budget then Sort p ∈ Si(cid:63 ) : define qk to be the kth smallest p in Si(cid:63 ) . 54 : 55 : ks ←(cid:108 ) gremain
( cid:109 ) n−j m k
. k gremain i=1 qi . for k = 1 to |Si(cid:63)| do gk ← 1 t(cid:63 ) ← budget kp ← mink:gk≥t(cid:63 ) k . k(cid:63 ) ← max(ks , kp ) .
56 : 57 : 58 : 59 : 60 : Bfinal ← qk(cid:63 ) . 61 : A ← k(cid:63 ) m . 62 : A ← gremain A(n−j ) . 63 : end if 64 : while More rounds and gremain > 0 do 65 : 66 : 67 : end while
Bid Bfinal with probability A , 0 otherwise . If Bid won then gremain ← gremain − 1 .
Theorem 13 . If the problem is feasible after exploration , and the algorithm has accurate observations , then : f n ≥ nexplore + npanic + ( n − m where Bfinal and A are as in Line 65 .
)P(Bfinal)A ≥ f n − , m , and qkp is analogous to P ( cid:63 )
Proof . The upper bound is true because there is always a check that gremain > 0 before any bid is made . The proof of the lower bound has the same rough outline as Theorem 6 . qks is analogous to Z ( cid:63 ) m . Now the target fraction of impressions to win during exploitation may be lower than γ , due to some being won during the exploration and panic . However , it is still easy to prove that |P(qks ) − γ| ≤ using techniques similar to Lemma 4 , because the proof does not depend upon the target . The most serious issue is when kp ≥ ks ( analogous to P ( cid:63 ) m ) , there is no implicit lower bound on P(qkp ) outside of γ . This makes the upper bounds that we obtained in Theorem 6 impossible to obtain , and why we explicitly bound the number of impressions obtained from above . However , the lower bounds on AP(qkp ) work out just as in Theorem 6 . 3.1 Bounding the Amount Spent m ≥ Z ( cid:63 )
We prove an upper bound on the spend of the algorithm .
Theorem 14 . If the algorithm has accurate observations and the problem is feasible after exploration , then C ≤ φtf n + ( 1/3 + 2/3)nb .
Proof . With Lemmas 15 21 , we cover overspending based upon every outcome of exploration and panic , as well as the relationship between ks and kp . In particular :
1 . If the algorithm exits exploration on Line 24 , then Lemma 15 applies if kp ≥ ks , and Lemma 21 applies if kp < ks .
2 . If the algorithm exits exploration on Line 11 , then
Lemma 16 applies .
3 . If the algorithm exits exploration on Line 9 , then Lemma 17 applies if no panic bids are made , Lemma 18 applies if a panic bid of Bi(cid:63)+1 is made , Lemma 20 applies if the largest panic bid is Bi(cid:63 ) and kp ≤ ks , and Lemma 19 applies if kp > ks .
Lemma 15 . If the algorithm exits the exploration phase at Line 24 , the algorithm has accurate observations , the problem is feasible after exploration , and kp ≥ ks , then the amount overspent is less than C ≤ tf n + ( 1/3 + 2/3)bn .
Proof . As before , if a large fraction of the impressions remains , then the estimates will be accurate . On the other hand , if many of the impressions are already gone , the impact of making a mistake is less . We choose a point , γ(cid:63 ) = 1/3+ , as a threshold : if γ > γ(cid:63 ) , we can bound the spend normally . If γ ≤ γ(cid:63 ) , then the most we can spend is γ(cid:63)b .
As we consider the bound proven in Lemma 7 , if we replace
γ with γ(cid:63 ) in Equation 4 , then we get : gm(Y ) ≥ g(Y ) − b
γ(cid:63)(γ(cid:63 ) − ) b
− ( b − a )
γ(cid:63 )
− ( b − a )
1/3
( + 1/3)( 1/3 )
= g(Y ) − ≥ g(Y ) − 1/3b − 2/3(b − a ) ≥ g(Y ) − 1/3b − 2/3b .
( 9 )
( 10 )
( 11 )
( 12 )
Equation 12 follows because decreasing the denominator ( replacing + 1/3 with ) makes the term larger , but making a negative term larger makes the overall expression smaller . Also , since ≤ 1 , 2/3 ≥ , implying γb ≤ 1/3b + 2/3b .
Lemma 16 . If exploration exits due to Line 11 , then C ≤
φtf n .
Proof . Define B(cid:63 ) to be equal to budget at the last time Line 8 was visited . This is the ideal amount to bid on the last bid such that the budget is exactly met . The maximum amount that could be bid would be Bi . Before the last bid was made , gremain = 1 and ( due to Line 8 ) , Bi−1 ≤ B(cid:63 ) . Therefore , Bi ≤ φB(cid:63 ) . The maximum amount overspent would be Bi − B(cid:63 ) ≤ ( φ − 1 ) . Since B(cid:63 ) ≤ tf n , the result follows .
Lemma 17 . If exploration exits on Line 9 , and no panic bids ( Line 32 ) are made , then C ≤ φtf n + ( 1/3 + 2/3)nb . Proof . During the middle of an exploration phase , an impression is won ( which we will call the overpriced impression ) and Line 8 is true . Define pop to be the price of this bid . At the time when the expression in Line 8 is true : tf n − budget = Cexplore + Cpanic gremain = n(cid:63 ) exploit .
( 13 )
( 14 )
Consider the last time that Line 8 is false , iewhen one less impression was won and pop less was spent . tf n − budget = Cexplore + Cpanic − pop ( 15 ) gremain − 1 = n(cid:63 ) ( 16 ) exploit
( gremain − 1)Ti−1 + Bi−1 ≤ budget ( n(cid:63 ) exploit)Ti−1 + Bi−1
( 17 )
≤ tf n + pop − ( Cexplore + Cpanic ) .
( 18 ) In this case , since we go through panic , at this time i−1 = i(cid:63 ) , we can reframe this as a bound on the “ spend ” :
Cexplore + Cpanic + ( n(cid:63 ) exploit)Ti(cid:63 ) ≤ tf n + pop − Bi(cid:63 ) .
Because pop − Bi(cid:63 ) ≤ ( φ − 1)Bi(cid:63 ) ≤ ( φ − 1)tf n :
Cexplore + Cpanic + ( n(cid:63 ) exploit)Ti(cid:63 ) ≤ φtf n .
( 19 )
WWW 2009 MADRID!Track : Internet Monetization / Session : Web Monetization256 The final issue is that Ti(cid:63 ) is not necessarily equal to g(Bi(cid:63 ) ) ( even though Ti(cid:63 ) is an estimate of g(Bi(cid:63 ) ) ) . The remainder is similar to Lemma 15 . There are two scenarios : either Pi(cid:63 ) is small , and therefore few impressions are left to obtain , or Pi(cid:63 ) is large and Ti(cid:63 ) is accurate . Formally , consider γ(cid:63 ) = + 1/3 . If Pi(cid:63 ) ≤ γ(cid:63 ) , then because the expression in Line 27 is true , exploit ≤ nγ(cid:63 ) . If Pi(cid:63 ) ≥ γ(cid:63 ) , then P(Bi(cid:63 ) ) ≥ γ(cid:63 ) − , then n(cid:63 ) substituting γ(cid:63 ) for γ in Lemma 7 : g(Bi(cid:63 ) ) ≤ Ti(cid:63 ) +
( b − a )
γ(cid:63 )
+ b
γ(cid:63)(γ(cid:63 ) − ) b
( b − a ) + 1/3
( 1/3 + )( 1/3 )
= Ti(cid:63 ) + + ≤ Ti(cid:63 ) + 1/3b + 2/3(b − a ) ≤ Ti(cid:63 ) + 1/3b + 2/3b .
( 20 )
( 21 )
( 22 )
( 23 )
Summarizing : exploit ) ≤ max(γ(cid:63)nb , ( Ti(cid:63 ) + 1/3b + 2/3b)f n ) g(Bi(cid:63 ) )(n(cid:63 ) Cexplore + Cpanic + n(cid:63 ) exploitg(Bi(cid:63 ) ) ≤
φtf n + max(γ(cid:63)nb , ( 1/3b + 2/3b)f n ) .
Because γ(cid:63 ) = + 1/3 , and f ≤ 1 , the result follows .
Lemma 18 . If , during the Panic( ) algorithm , a bid of Bi(cid:63)+1 is the highest bid that is actually made , the problem is feasible after exploration , and the algorithm has accurate observations , then C ≤ f n(tφ + b ) .
Proof . During exploitation , the algorithm bids no more than Bi(cid:63 ) , so the expected price per impression is at most g(Bi(cid:63 ) ) . This is the easy part ; the hard part is bounding the spend during exploration and panic . Define b(cid:63 ) = min(Bi(cid:63)+1 , b ) , the largest effective bid during panicking . How many impressions need to obtained before the algorithm realizes it can bid Bi(cid:63 ) for the remainder ? Formally : max #big bids won = f n − ( P(Bi(cid:63 ) ) − )(n − mr )
= f n
= f n
= f n
Cpanic + Cexploit ≤ f n f n
1 − ( P(Bi(cid:63 ) ) − )(n − mr )
1 − ( P(Bi(cid:63 ) ) − ) γ − ( P(Bi(cid:63 ) ) − ) γ − ( P(Bi(cid:63 ) ) − )
γ
γ b(cid:63 ) .
γ
In other words , the maximum fraction of bids won during exploration and panic is ( + γ − P(Bi(cid:63 ) ) ) γ−1 . Note that if the algorithm were to bid P−1(γ ) ≤ p(cid:63 ) , then in expectation ( γ − P(Bi(cid:63 ) ) ) γ−1 bids would be Bi(cid:63 ) or above . Therefore , if the problem is feasible after exploration : t = g(p(cid:63 ) ) ≥ g(P−1(γ ) ) ≥ γ − P(Bi(cid:63 ) )
γ
Bi(cid:63 ) +
P(Bi(cid:63 ) )
γ g(Bi(cid:63 ) )
γ tφ ≥ γ − P(Bi(cid:63 ) ) ≥ γ − P(Bi(cid:63 ) ) tφ + b(cid:63 ) ≥ γ − P(Bi(cid:63 ) )
γ
P(Bi(cid:63 ) )
Bi(cid:63 ) φ + g(Bi(cid:63 ) )
γ P(Bi(cid:63 ) ) b(cid:63 ) +
γ g(Bi(cid:63 ) ) P(Bi(cid:63 ) )
γ P(Bi(cid:63 ) )
γ g(Bi(cid:63 ) ) b(cid:63 ) + b(cid:63 ) + g(Bi(cid:63 ) )
≥ + γ − P(Bi(cid:63 ) ) b(cid:63 ) +
γ
γ f n(tφ + b ) ≥ Cexplore + Cpanic + E[Cexploit|E1 . . . Em ] ] . The last line is due to the fact that b(cid:63 ) is a bound on the price during exploration and panic , g(Bi(cid:63 ) ) is a bound on the expected price during exploitation , and the worst case scenario is to have the maximum number of bids during the exploration and panic phases .
Lemma 19 . If the largest panic bid is Bi(cid:63 ) , during exploitation ks < kp ( such that the bid during exploitation is based upon the target spend t ) , the problem is feasible after exploration , and the algorithm has accurate observations , then C ≤ tf n + ( 1/3 + 2/3)bn . Proof Sketch . This scenario is rare , in that it implies that the algorithm panicked , but then somehow the budget recovered . One possibility is that a very high but unlikely bid was obtained , followed by small but unlikely bids .
Since the last round is accurate , the argument is similar to Lemma 15 .
Lemma 20 . If the largest panic bid is Bi(cid:63 ) , during exploitation ks ≥ kp ( such that the bid during exploitation is based upon the target number of impressions ) , the problem is feasible after exploration , and the algorithm has accurate observations , then C ≤ φtf n + nb . In this case , we know that P(Bi(cid:63)−1 ) ≤ Proof Sketch . γ + , and for however long we are exploring and panicking , we know that Bi(cid:63)−1 is not expected to give us enough impressions , just as with Bi(cid:63 ) in Lemma 18 . If the exploitation bid B was less than or equal to Bi(cid:63)−1 ( eg , due to a change in the estimation from Si(cid:63)−1 to Si(cid:63 ) ) , then the analysis from Lemma 18 holds , with i(cid:63 ) − 1 replacing i(cid:63 ) . If B > Bi(cid:63)−1 , we know that all the bids we obtained during exploration and panicking were not enough , and during exploitation , we choose a bid such that we get just enough impressions above Bi(cid:63)−1 . Thus , these impressions above Bi(cid:63)−1 during exploitation and the impressions during exploration and panicking are almost exactly enough such that bidding Bi(cid:63)−1 during exploitation would have won the remainder . Therefore , Lemma 18 ’s argument completes the result .
Lemma 21 . If the algorithm exits the exploration phase at Line 24 , the algorithm has accurate observations , the problem is feasible after exploration , and kp < ks , then C ≤ φtf n + ( 1/3 + 2/3)nb .
Proof . This is similar to Lemma 17 , in that the algorithm does not have more than one impression that is overpriced ( note that the last impression won during exploration may be overpriced ) . Therefore , with the exception that i(cid:63 ) = i , a variant of Equation 19 holds here .
Cexplore + Cpanic + ( n(cid:63 )
( 24 ) If Bfinal ≤ Bi(cid:63)−1 , then the argument from Lemma 17 holds , in that the algorithm might has well of panicked . exploit)Ti(cid:63)−1 ≤ φtf n .
WWW 2009 MADRID!Track : Internet Monetization / Session : Web Monetization257 If Bfinal > Bi(cid:63)−1 , then the algorithm might as well have panicked : the key condition ( that it needs more impressions that it believes will be obtained by Bi(cid:63)−1 ) is satisfied at the end of the exploration phase , which is loosely what is required in Lemma 20 . Note that the bound in Lemma 17 is looser than the bound in Lemma 20 .
Unfortunately , there are cases where the algorithm can underspend . For instance , suppose that the objective is to obtain a very small number of impressions at a very high price . For instance , 10 % of the impressions are at $11.00 , and 90 % are at $1.00 , and the target spend is $2.00 , and the algorithm wants 1 % of the impressions . Therefore , bidding $11.00 is ideal . However , if the algorithm starts by bidding $2.00 , it is possible that before exploration is over , the algorithm obtains enough impressions , but has only spent half the budget . Of course , in this case , the algorithm which starts by bidding b to explore is doing just the right thing .
Figure 1 : The observed and modeled distribution of the winning bid on the Right Media Exchange .
4 . EXPERIMENTS
In this section we evaluate our algorithms on synthetically derived data drawn from a log normal distribution , which fits data observed from the Right Media Exchange . Algorithms for the fully observable case are evaluated in Section 4.2 , and the partially observable case in Section 43 4.1 Methodology and Data
To evaluate our algorithms , we collected winning bids from live auctions run on the Right Media Exchange , which has over 50,000 buyers and sellers and processes over 6 billion impressions daily . The bids we collected represent a 1 % uniform sample across a variety of individual publishers . Focusing on a single publisher , we plot the CDF of the empirical distribution of the bids in Figure 1 .
While it is difficult to predict the winning bid on any particular impression , for a fixed publisher the data can be fitted with a log normal distribution with the appropriate mean and variance . In Figure 1 we provide such a fit for a single publisher ( 350,000 auctions total ) . While the exact variance changes from publisher to publisher , on all instances the data can be fitted well with a log normal distribution .
Based on the above fit , we sample iid from a log normal distribution with mean and variance one.8 While very large prices are never observed on the exchange , the log normal distribution supports arbitrarily large prices . We deal with this by discarding samples larger than an upper limit b , chosen to be the 99.7th percentile . That is , we sample from the log normal distribution conditioned on {X ≤ b} .
We set the supply to be n = 10 , 000 impressions . To evaluate each algorithm we choose 16 evenly spaced values of target f and target t from the interval ( 0 , 1 ) , and measure the actual fraction and spend against the targets ( we include only 4 data points each for clarity ) . For each of the 256 parameter settings , we run each algorithm on 500 iid samples to average out effects of sampling . 4.2 Results : Fully Observable Exchange m , Am and Z ( cid:63 )
The Learn Then Bid algorithm waits for a significant exploration period before bidding . An obvious improvement is the Learn While Bid algorithm which continues to learn during exploitation : Pm , P ( cid:63 ) m are updated after each bid , as in Learn Then Bid lines 2–5 but with adaptive targets . Although harder to analyze , this has the advantage of a possibly shorter exploration phase without compromising estimation accuracy . We compare the performance of these two algorithms experimentally : on average both algorithms perform very close to ideal . However , Learn WhileBid spending is more tightly concentrated around the ideal than Learn Then Bid for the same exploration only phase . Figures 2 and 3 show the spending of Learn Then Bid and Learn While Bid respectively . The dotted lines depict the minimum spending necessary to achieve the target fraction of supply as given by max{E [ X | X ≤ z(cid:63 ) ] , t} : when the fraction and spend goals cannot simultaneously be satisfied , both algorithms prioritize the former while minimizing over spending . The distribution of each algorithm ’s spending , for each ( f , t ) pair , is summarized by a box and whisker plot : each box depicts the 25 % , 50 % ( the median ) and 75 % quantiles representing the spread of spending . As is evident in the figures , more runs of Learn While Bid have spend close to the ideal . To achieve comparable concentration with LearnThen Bid , m must be increased . However this can lead to infeasibility for high f ( eg for m = 1 , 000 and f = 0.94 the problem becomes infeasible leading to underdelivery ) . Figure 4 plots the performance of the algorithms with respect to supply . Both algorithms win close to the target fraction of supply for a wide range of target spending goals .
Figure 5 compares theory and practice , depicting our bounds on the concentration of the fraction of supply won and the spending per impression won , with respect to increasing exploration length . As exploration increases , the bounds become tighter but at the same time the problem becomes harder to satisfy until it becomes infeasible ( occurring at the maximum m shown ) . Also shown are empirical results for running Learn Then Bid . In particular for each m value ( exploration phase length ) , Learn Then Bid was run 1 , 000 times . For each run the fraction won during exploitation , and the spend per impression won , were calculated and the 95 % two sided quantiles were computed and overlayed . In this case the distribution free theory matches the empirical results well , particularly for concentration of fraction won .
8We note that increasing the variance of the log normal distribution does not affect our algorithms’ behavior ; they deliver the same supply and actually overspend less ( since there is a larger fraction of lower priced impressions ) .
00102030405060708091 Empirical CDFLog Normal Model CDFWWW 2009 MADRID!Track : Internet Monetization / Session : Web Monetization258 Figure 2 : Actual & ideal spend per impression won by Learn Then Bid with m = 100 for 4 values of f .
Figure 3 : Actual & ideal spend per impression won by Learn While Bid with m = 100 for 4 values of f .
Figure 4 : Fraction of supply won by Learn Then Bid and Learn While Bid with m = 100 for 4 values of t .
Figure 5 : Learn Then Bid supply and spend 95 % confidence bands given by : the concentration bounds , and 1,000 sample empirical quantiles .
4.3 Results : Partially Observable Exchange
In this section we evaluate algorithms for bidding in a partially observable exchange . The Guess Double Panic algorithm outperforms the strawman bidders in terms of target spend for a wide range of target supply fractions . More interestingly , the lack of full information does not handicap the Guess Double Panic algorithm : the accuracy of supply and spend are very close to those for full information .
Figures 6 and 7 plot the supply and spend for GuessDouble Panic as well as two strawman algorithms , MaxThen Bid and Bid Two t . Given that Learn Then Bid performs well even for very short exploration phases , it is natu ral to apply the same idea in the partially observable setting : Max Then Bid bids b in the length m exploration phase and then exploits based on the empirical distribution.9
While Max Then Bid performs well on supply it is an inferior strategy for target spend , since the spending during exploration can be very high : specifically when f and t are both small the algorithm must acquire the right number of
9Max Then Bid dominates Learn Then Bid in number of impressions acquired despite partial information : MaxThen Bid wins every impression during exploration in contrast to Learn Then Bid which wins zero . Also , if the problem is feasible after Learn Then Bid ’s exploration then it will be feasible for Max Then Bid .
000204060810000204060810Target Spend Per Impression Won tActual Spend Per Impression Wonllllllllllllllllidealf = 0.059f = 0.353f = 0.647f = 0941l000204060810000204060810Target Spend Per Impression Won tActual Spend Per Impression Wonllllllllllllllllidealf = 0.059f = 0.353f = 0.647f = 0941l000204060810000204060810Target Fraction of Impressions fAttained Fraction of ImpressionsLTBLWBt = 0.059t = 0.353t = 0.647t = 0.941ideal100020003000400001234567Exploration Duration mSpending Per Impression Won000204060810Fraction Won During ExploitationIdealTheoryExperimentSupplySpendWWW 2009 MADRID!Track : Internet Monetization / Session : Web Monetization259 Figure 6 : Fraction of supply won by Bid Two t , MaxThen Bid and Guess Double Panic with m = 100 for 4 values of t .
Figure 7 : Spend per impression won by Bid Twot , Max Then Bid and Guess Double Panic with m = 100 for 4 values of f . impressions at a low price , and Max Then Bid is very likely to overspend . Guess Double Panic will perform well precisely in this setting due to its more cautious exploration starting with a bid of t as opposed to b . This comparison is borne out in Figure 7 where Max Then Bid overspends most dramatically relative to Guess Double Panic for the lowest target fraction f = 0.059 ; overspending is evident for higher values up to f = 059 The Bid Two t strawman algorithm does not perform much better than expected from theory , which predicts supply and spend within only a loose multiplicative factor of the targets .
5 . CONCLUSIONS
We study the problem of acquiring a given number of impressions with a given budget constraint by bidding against an unknown distribution . Our approach consists of learning the distribution in an exploration phase , and then bidding according to the empirical distribution of observations from exploration . We consider both the fully observable and the harder partially observable case , and present algorithms with theoretical performance guarantees that also perform very well in experimental evaluations against realistic data . The experiments indicate that in addition to performing well with respect to both constraints , our algorithm for partial information does nearly as well as algorithms in the full information setting despite the fact that a cost must be paid for every sample during exploration . The performance of the algorithms improves as the supply increases , and is asymptotically optimal since a longer exploration phase can be used for higher accuracy ; also , the actual number of impressions won and the total spend are more tightly concentrated around their means as n increases .
The most interesting direction for further research is removing the iid assumption , and considering a game theoretic perspective : we assume that every other bidder in each individual auction has unit demand and therefore bids his value ; one can instead consider best response and equilibrium analysis when a number of bidding agents compete in such a marketplace . Acknowledgements We gratefully acknowledge the support of the NSF through grant DMS 0707060 .
6 . REFERENCES [ 1 ] P . Auer , N . Cesa Bianchi , and P . Fischer . Finite time analysis of the multi armed bandit problem . Machine Learning , 47:235–256 , 2002 .
[ 2 ] M . Cary , A . Das , B . Edelman , I . Giotis , K . Heimerl ,
A . Karlin , C . Mathieu , and M . Schwarz . Greedy bidding strategies for keyword auctions . In EC ’07 : Proceedings of the 8th ACM Conference on Electronic Commerce , pages 262–271 , 2007 .
[ 3 ] N . Cesa Bianchi and G . Lugosi . Prediction , Learning , and Games . Cambridge University Press , 2006 .
[ 4 ] A . Dvoretzky , J . Kiefer , and J . Wolfowitz . Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator . Annals of Mathematical Statistics , 27(3):642–669 , 1956 .
[ 5 ] N . Littlestone and M . K . Warmuth . The weighted majority algorithm . Information and Computation , 108(2):212–261 , February 1994 .
[ 6 ] M . Zinkevich . Online convex programming and generalized infinitesimal gradient ascent . In Proceedings of the Twentieth International Conference on Machine Learning , pages 928–936 , 2003 .
000204060810000204060810Target Fraction of Impressions fAttained Fraction of Impressionslllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllt = 0.059t = 0.353t = 0.647t = 0941BTTMTBGDPideal000204060810000204060810Target Spend Per Impression Won tAttained Spend Per Impression Wonlllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllf = 0.059f = 0.353f = 0.647f = 0.941BTTMTBGDPidealWWW 2009 MADRID!Track : Internet Monetization / Session : Web Monetization260
