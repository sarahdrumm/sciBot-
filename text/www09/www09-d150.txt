Personalized Recommendation on Dynamic Content
Using Predictive Bilinear Models
Wei Chu Yahoo! Labs .
2821 Mission College Blvd
Santa Clara , CA 95054 chuwei@yahoo inc.com
Seung Taek Park
Yahoo! Labs .
2821 Mission College Blvd
Santa Clara , CA 95054 parkst@yahoo inc.com
ABSTRACT In Web based services of dynamic content ( such as news articles ) , recommender systems face the difficulty of timely identifying new items of high quality and providing recommendations for new users . We propose a feature based machine learning approach to personalized recommendation that is capable of handling the cold start issue effectively . We maintain profiles of content of interest , in which temporal characteristics of the content , eg popularity and freshness , are updated in real time manner . We also maintain profiles of users including demographic information and a summary of user activities within Yahoo! properties . Based on all features in user and content profiles , we develop predictive bilinear regression models to provide accurate personalized recommendations of new items for both existing and new users . This approach results in an offline model with light computational overhead compared with other recommender systems that require online re training . The proposed framework is general and flexible for other personalized tasks . The superior performance of our approach is verified on a large scale data set collected from the Today Module on Yahoo! Front Page , with comparison against six competitive approaches .
Categories and Subject Descriptors H10 [ Models and Principles ] : General ; H33 [ Information Search and Retrieval ] : Information filtering ; H35 [ Online Information Services ] : Web based services
General Terms Algorithms , Experimentation , Design , Performance
Keywords Personalization , Dynamic Features , Bilinear , Regression , Ranking , User and Content Profiles , Recommender Systems
1 .
INTRODUCTION
The Internet provides an unparalleled opportunity for organizations to deliver digital content to their visitors instantaneously . Content consumers usually have short attention span , while possibly a large number of content venders . The
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . Distribution of these papers is limited to classroom use , and personal use by others . WWW 2009 , April 20–24 , 2009 , Madrid , Spain . ACM 978 1 60558 487 4/09/04 . biggest challenge most organizations face is not lack of content , but how to optimize the content they already own by identifying the most appropriate customers at the right time . Personalized recommendation has become a desirable feature of e business Web sites to improve customer satisfaction and customer retention [ 8 ] , by tailoring content presentation to suit an individual ’s needs rather than take the traditional “ one size fits all ” approach .
Personalized recommendation involves a process of gathering and storing information about site visitors , managing the content assets , analyzing current and past user interactive behavior , and , based on the analysis , delivering the right content to each visitor [ 31 ] . Search engines help index available content assets and return relevant information to users , if the users are looking for something specific that can be summarized as a keyword query . However , in many cases , users are looking for things might interest them , but do not have concrete desideration in mind when browsing a Web site . In such cases , it is a recommendation engine that presents the most plausible content that the user may want , based on her interests as demonstrated by her past activities . Traditional recommendation engines could be distinguished into three different approaches : rule based filtering , contentbased filtering , and collaborative filtering [ 32 ] . Rule based filtering creates a user specific utility function and then applies it to the items under consideration . This approach is closely related to customization , which requires users to identify themselves , configure their individual settings , and maintain their personalized environment over time [ 21 ] . It is easy to fail since the burden of responsibility falls on the users . Content based filtering generates a profile for a user based on the content descriptions of the items previously rated by the user . The main drawback of this approach is the recommended items are similar to the items previously seen by the user . Mladenic [ 30 ] provided a survey of the commonly used text learning techniques in the context of content filtering . Collaborative filtering ( CF ) is one of the most successful and widely used recommender system technology [ 37 ] . CF analyzes users’ ratings to recognize commonalities between users on the basis of their historical ratings , and then generates new recommendations based on like minded users’ preferences . CF provides a good solution to “ a closed world ” , where overlaps in ratings across users are relatively high and the universe of content items is almost static .
In many scenarios , such as news filtering [ 15 ] , where the content universe changes rapidly and significant portion of users are new users , CF will suffer from the cold start problem . Several hybrid recommender systems have been devel
WWW 2009 MADRID!Track : Social Networks and Web 2.0 / Session : Recommender Systems691 oped to tackle the cold start problem by combining two or more recommendation techniques . The inability of CF to recommend new items is commonly leveraged by coupling with a content based filtering , such as in Fab [ 3 ] , a recommender system for the Web content . Burke [ 10 ] provided a comprehensive analysis of approaches to generating hybrid recommendation engines .
Although hybridization can alleviate some of the weaknesses associated with CF and other recommendation techniques , there are still a few important issues that haven’t been well studied in literature :
• Dynamic Content : We consider not only the item set undergoes insertions and deletions frequently , but also the content value and then the appraisement from users are changing rapidly as well . For example , the lifetime of breaking news on the Internet is usually a couple of hours , and the value of the news ( such as click through rate ) is decaying temporally as people get to know it , see Figure 3(a ) for an example . Traditional recommender systems usually treat users’ feedback static , so that feedback on the same items given at different time stamps is still comparable . This assumption doesn’t hold on dynamic content . Rebuilding the model on very recent data is typically an expensive task , and tends to lose long term interests of users . On dynamic content , recommender systems always face the coldstart problem for new items .
• Users with Open Profiles : A typical user profile in a CF system is a list of ratings on items of interest . In practice , we can legally collect user information to develop a general profile for a site visitor [ 19 ] , which is not limited to the content universe only . The general profile may include declared demographic information , activities on relevant sites , consumption history , etc . The objective is to provide valuable insight into users’ preferences , interests and wants . Clearly , the general profile can help tackle the cold start problem on new users . Demographic recommender systems , eg [ 34 ] , aim to segment users based on personal attributes and make recommendations according to demographic classes . However , the history of user ratings and content features haven’t been jointly exploited to form “ people to people ” correlation .
In this paper , we propose a machine learning approach to handling both issues in personalized recommendation . The key idea is to maintain profiles for both content and users , and build a feature based bilinear regression model to quantify the associations between heterogeneous features by fitting the historical interactive data . The feature based predictive model can then be applied to recommending new and existing items for both new and existing users .
The goodness of dynamic content over time is a crucial ingredient in content management . We insert dynamic features , such as instantaneous click through rate ( CTR ) to indicate temporal popularity , into the content feature set . We continuously update these dynamic features in the delivery phase by aggregating users’ interactions over content items in a real time manner . We demonstrate that maintaining content profiles with dynamic features is an effective strategy to overcome the cold start problem on dynamic content .
Figure 1 : An illustration of unfolding a multidimensional event .
The open profiles of users provide valuable information about user preferences and interests that helps in recommending content for new users . Historical feedback given by users on content of interest , such as ratings or click stream , directly reveals users’ opinion on the content universe . The bilinear regression models we proposed can discover association patterns between the general user profiles and the content features by exploiting the interactive data ( the typical user profile in traditional CF ) . The established associations are then applied to evaluating individualized appraisement over currently available items for accurate and prompt personalized recommendations in real time .
This work is motivated by a personalized content optimization task for the Today Module on Yahoo! Front Page . The effectiveness of the bilinear models is verified on a largescale real world data set collected in the application . This approach results in an offline model except online tracked dynamic features in content profiles . The computational overhead in online recommendation is minor compared with recommender systems that require online re training . The framework is general and flexible , which can be adapted to other personalized tasks .
The paper is organized as follows : We introduce data representation in Section 2 , which includes content profiling , user profiling and interactive feedback ; In Section 3 we describe a family of probabilistic bilinear models in detail that covers training algorithms and further discussions on potential capabilities ; We review related work in Section 4 ; We report the experimental results on the data set collected from the Today Module with comparison against six competitive alternatives in Section 5 and conclude in Section 6 .
2 . DATA REPRESENTATION
The observational data is naturally recorded in multidimensional format . A logistic event is associated with at least three types of objects , user × content × timestamp . These multi dimensional events can always be flattened into two way form without loss of generality , see Figure 1 for an illustration . In personalization on dynamic content , we can treat content×timestamp as items of interest . Note that the dimension of timestamp is usually not considered in traditional recommender systems . The flattened dimensions form a new content item space , in which features are extracted for profiling . We generate and maintain three sets of data : content profiles , user profiles , and interactive feedback on content items of interest . 2.1 Content Profiles
When a content is either created or acquired , the informa
UserflItemflTimestampflUserflItem atfltimestampflWWW 2009 MADRID!Track : Social Networks and Web 2.0 / Session : Recommender Systems692 tion related to the content , such as manufacturer , product name and categories etc . , constitutes an initial part of the profile . Continuous refinement of the content profile helps to optimize the use of the content assets . In the delivery phase , the content is delivered to users and interactions on the content are logged and analyzed , providing the ability to assess the content popularity in a real time manner . The content popularity over time is a crucial ingredient in content management , since the commercial value of most content is varying or decaying temporally , especially for breaking news .
We consider generalized content items here , which are redefined with both temporal characteristics and other conditions . In a content profile , there are at least two groups of features :
• Static descriptors : Such as categories , manufacturer name , title , bag of words of textual content etc .
• Temporal characteristics : Such as popularity , clickthrough rate ( CTR ) and price at current time stamp or the hours elapsed after content acquisition .
We can collect any features related to the content items . For example , in search the items become webpages fused with a query , and then joint features , such as contextual co occurrences , can be constructed .
Each content is represented as a vertical vector , denoted by z , where z ∈ 4C and C is the number of content features . 2.2 User Profiles
The objective of collecting visitor information is to develop a user profile that describes a site visitor ’s interests , consumption history , and other descriptors important to the site owner . A review of various user profiling techniques is provided in [ 19 ] . Explicit profiling requests each visitor to declare personal information , such as age , gender and occupation , or to fill out questionnaires that explicitly state their preferences . Implicit profiling tracks the visitors’ behavior and it is generally transparent to the visitor . Browsing and purchasing patterns are the behaviors most often assessed . The profile combined with demographic , transaction , and navigation data implicitly represents a user ’s preferences and recent interests .
The user feature space is spanned by legally usable features . Each user is represented as a vertical vector , denoted by x , where x ∈ 4D and D is the dimensionality of the user feature space .
2.3
Interactive Feedback
In traditional collaborative filtering ( CF ) , the feedback given by users on content of interest are used as user profiles to evaluate commonalities between users . In our regression approach , we separate the feedback from user profiles . The feedback on content of interest is utilized as targets that relate patterns in user features to content features .
Although the interactions between the users and the available items vary depending on the types of items involved , we can always observe or measure some feedback from user side . For example , a user may purchase a product or a service after review , and even rate it later . For a content posted on a Web page , a user may click to see more details . The ratings and actions ( click or not , purchase or not ) provide explicit feedback.1 There are a range of efforts attempted to measure various kinds of implicit feedback indicators from linger time [ 13 ] to eye movements [ 36 ] . We focus on two types of feedback in this paper :
• Continuous scores : most implicit feedback and ratings can be converted as continuous scores .
• Binary actions : such as click or not , purchase or not after reviewing an item .
We have collected three sets of data , including content features , user profiles and interactive data between users and items . Let index the i th user as xi and the j th content item as zj , and denote by rij the interaction between the user xi and the item zj . We only observe interactions on a small subset of all possible user/item pairs , and denote by the set of observations {rij} .
3 . BILINEAR REGRESSION MODELS
The user and content profiles provide timely descriptions of users and items respectively . As the two feature spaces are usually dichotomous , it is hard to apply the contextual data mining techniques [ 9 ] here . However , the interactive feedback reveals the correlations between user patterns and content features . In this section , we describe a family of predictive bilinear models to discover pattern affinities between heterogeneous features . A set of weight coefficients is introduced to capture the pairwise associations between user and content features . The parametric model is optimized by fitting the observed interactive feedback . 3.1 Bilinear Indicator
The bilinear models can be regarded as a special case in the Tucker family [ 14 ] , which have been widely applied in machine learning applications . For example , Tenenbaum and Freeman [ 39 ] developed a bilinear model for separating “ style ” and “ content ” in images , and recently Chu and Ghahramani [ 11 ] derived a probabilistic framework of the Tucker family for modeling structural dependency from partially observed high dimensional array data .
We define an indicator as a bilinear function of xi and zj in the following : sij = xi,bzj,awab ,
( 1 )
C:a=1
D:b=1 where D and C are the dimensionality of user and content features respectively , zj,a denotes the a th feature of zj and xi,b denotes the b th feature of xi . The weight variable wab is independent of user and content features and quantifies the affinity of these two factors xi,b and zj,a in interactions.2
The scalar sij is generated by mixing these basis vectors with coefficients given by the Kronecker product of xi and zj . The indicator can be equivalently rewritten as sij = w
( zj ⊗ xi ) ,
1Clicks and user purchase history are often considered as implicit feedback in other collaborative filtering literature since these may not reflect real user preferences . For example , a user may find that an article is uninteresting after clicking and reading it . However , we refer these actions as explicit feedback since the user intentions of these actions are clearer than those of other implicit feedback such as linger time and eye movement . 2In practice , we also insert an individual specific offset for
WWW 2009 MADRID!Track : Social Networks and Web 2.0 / Session : Recommender Systems693 where w is a column vector of entries {wab} , and zj ⊗ xi denotes the Kronecker product of xi and zj , a column vector of entries {xi,bzj,a} . In matrix form , eq(1 ) can be rewritten as sij = x i W zj ,
( 2 ) i,dzj,d , i Ws , x a=1 ˜xi,azj,a . i,szj,s + ˜x zj,d = ˜x where W denotes a D× C matrix with entries {wab} , which describes a linear projection from the user feature space onto the item feature space . The projected user profile Wxi is aligned to the item features , denoted by ˜xi , which can be explained as users’ preferences on item characteristics accordingly . Then the indicator becomes a dot product , ie sij = ˜x
To further examine the feature functions , let us distinguish dynamic features in the item feature vector as zj = i zj =2C zj,s zj,d , where zj,s denotes static features and zj,d denotes sij =Dx dynamic features that vary along time . The indicator sij can then be rewritten as follows , i WdE zj,s where Ws and Wd denote the columns in W associated with the static and dynamic item features respectively , and ˜xi,s and ˜xi,d denote the i th user ’s preferences on the static and dynamic item features respectively . Note that a user ’s score sij on an item is composed of three parts : ˜x i,szj,s reflects long term personal preferences on content features learnt from historical activities ; zj,d is of dynamic characteristics , in our work which include temporal popularity over the whole user population , ie article quality ; the tradeoff between static personal preferences and article quality is determined by ˜xi,d . On cold start with new items , the user ’s preferences on static item features ˜x i,szj,s play an important role , as the dynamic features couldn’t be accurately estimated at the beginning stage . Similarly , on cold start with new users , recommendations are fully determined by the users’ preferences on content features ˜xi , which are projected from the user profile xi.3 As we will show in the following , the projection W can be learnt from the historical interactive feedback . 3.2 Probabilistic Framework
We employ appropriate likelihood functions to relate the indicator sij to different types of observed interactions .
• Continuous scores with Gaussian measurement noise : p(rij|sij ) =
1√ 2πσ exp − ( rij − sij)2
2σ2
, where σ stands for the noise level.4 each user . The final scalar is evaluated as sij =
C:a=1
D:b=1 where µi ∈ 4 denotes a user specific offset . Here µi is used to tradeoff the user ’s activity level , since some users are active clickers while some are casual users . 3There is an implicit assumption that the user profile is rich enough to be transformed into preferences on item characteristics . This condition can be easily satisfied in practice . 4In practice , the noise level could be prefixed at an appropriate value based on the signal/noise ratio . xi,bzj,awab + µi ,
∂L(w ) ∂wab
=
∂ log p(rij|sij )
∂sij xi,bzj,a ,
( 7 )
• Binary actions with rij ∈ {−1 , 1} . The logistic function is widely used as the likelihood function , which is defined as p(rij|sij ) =
1
1 + exp(−rijsij + γ )
, where γ denotes a bias term , usually set at 1 .
Given a set of w , the likelihood of observing the interac tive data can be evaluated by p(rij|sij ) ,
( 3 ) p( |w ) =;ij
( 4 )
( 5 ) where the index ij runs over the observational set . weight variables as a priori ,
We also specify a standard Gaussian distribution over the p(w ) =
1√ 2πς where ς 2 is the variance . exp −2ab w2 2ς 2 , ab
Based on the Bayes’ theorem , the posterior distribution of w is proportional to the product of the likelihood and the prior , where p(w ) is the prior distribution defined as in eq(4 ) and p(w| ) ∝ p( |w ) p(w ) . p( |w ) is the likelihood defined as in eq(3 ) . 3.3 Offline Modeling
In this section , we describe a training algorithm in batch mode to estimate the posterior distribution of the weight coefficients p(w| ) as in eq(5 ) . For continuous scores with
Gaussian noise , the posterior distribution is still a Gaussian due to the conjugate property . With non Gaussian likelihood functions , the posterior distribution becomes nonGaussian . However we can always approximate the true distribution by a Gaussian distribution . One of the most popular techniques is the Laplace approximation [ 26 ] , which finds the mode of the true posterior as the approximate mean and approximates the inverse covariance matrix by the Hessian matrix , the second order derivatives with respect to the weights at the mode point .
The mode , also known as the maximum a posteriori ( MAP ) estimate , can be found by maximizing the joint probabil ity p( |w)p(w ) . The optimization problem is equivalent to minimizing the negative logarithm of the joint probability , ie min w
L(w ) = log p(rij|sij ) ,
( 6 ) where ς 2 plays a role of tradeoff . The gradient with respect to wab can be computed as follows , w2 ab −:ij
1
2ς 2:ab ς 2 −:ij wab and gradient decent packages can then be employed to find the minimum . Note that the objective functional is convex and the minimum is unique . The detailed formulations are given in Table 1 and the gradient descent algorithm is summarized as in Table 2 . Each objective/gradient evaluation costs O(N CD ) , where CD is the size of w and N is the size of the observed set . Note that matrix inverse can
WWW 2009 MADRID!Track : Social Networks and Web 2.0 / Session : Recommender Systems694 Table 1 : The logarithm likelihood functions and the first order derivatives . ∂ log p(rij|sij ) log p(rij|sij )
Target
Continuous
Binary
− ( rij−sij )2 2 log(2πσ ) − log(1 + exp(−rijsij + γ ) )
− 1
2σ2
∂sij sij−rij
σ2 rijp(−rij|sij )
Table 2 : The gradient descent algorithm for MAP . 1 . 2 . While objective/gradient evaluation at w is requested :
Initialize w = 0 , given σ2 and ς 2
Compute the objective as in eq(6 ) ; Compute the gradients for w as in eq(7 ) ; Return the objective/gradients to the package .
3 . Until the optimization package returns the final w . be applied directly to the case of continuous targets for an solution , but the computational cost is O(N C 2D2 + C 3D3 ) . It is very expensive for the cases having a large number of features . 3.4 Prediction
The MAP estimate , denoted as wMAP , is then applied to new user/item pairs for prediction . For any pair of xi and zj in test , the best guess of the indicator sij is determined as follow ,
ˆsij = xi,bzj,awMAP ab
,
( 8 )
C:a=1
D:b=1 is an entry of the MAP estimate wMAP . ab where wMAP 3.5 Discussions
In this section , we discuss model selection and some potentials of the framework we proposed , such as online learning and active learning .
351 Model Selection
The prior variance ς 2 is an important model parameter in the regression framework . The most common approach in practice to determine the best model setting is cross validation . In k fold cross validation , the original training data is randomly partitioned into several folds , whereas in our application having time series of dynamical features we have to split the training data by a temporal point into two folds , usually with size ratio 2 : 1 . Given a particular set of model parameters , we run the training algorithm on the fold of earlier data to estimate the weight coefficients , and test the resulting model on the left out fold to obtain the validation error . The predictive performance indicates the goodness of the model parameter setting . We try grid search over a set of parameter values to find the optimal one on which we observe the best performance on the validation data . The optimal weight coefficients in the regression model are finally obtained by training on the whole training data set using the best set of model parameters .
352 Online Learning and Active Learning
In this work we only focus on training an offline model coupled with dynamic features , whereas the probabilistic framework we employed provides the capacity of online learning as well . Assumed density filtering ( ADF ) is a one pass , sequential method for computing an approximate posterior distribution [ 17 ] . In ADF , observations are processed one by one , updating the posterior distribution which is usually approximated as a Gaussian before processing the next observation . The approximate posterior is found by minimizing KL divergence to preserve a specific set of posterior expectations . Recently , Expectation Propagation [ 29 ] extends ADF to incorporate iterative refinement of the approximations , which iterates additional passes over the observations and does not require corresponding with time of arrival as in time series .
Learning could be made more efficient if we can actively select salient data points . Within the probabilistic regression framework , the expected informativeness of a new observation can be measured by the change in entropy of the posterior distribution of the weight coefficients after inclusion of the candidate [ 24 ] . The new posterior distribution with the inclusion of the unused sample can be approximated as a Gaussian by ADF like online learning algorithms . Based on information theoretical principles , the entropy gain on the posterior distribution of weight variables can then be applied as the criterion for candidate election .
4 . RELATED WORK
Our work is closely related to adaptive news systems , one of the most popular types of personalized Web based service [ 6 ] . The most relevant previous work to our study would be the Google News recommender system [ 15 ] , a contentagnostic system which combines three different algorithms using a linear model to generate recommendations in News domain . However , since the proposed approach is a pure collaborative filtering , it does not solve the cold start problem for new users . Even though ratings from new users can be updated in near real time by gridifying their algorithm , it still needs to wait until new users provide ratings or clicks before making recommendations . Also , the reported results are based on two heavy user data sets ( top 5K heavy users with 370K clicks and 500K users with 10M clicks ) , where effects of new and casual users haven’t been considered . In our application of the Today Module on Yahoo! Front Page , 40 % of clickers are new clickers with no historical clicks , 82 % of clickers have less or equal to 5 historical clicks , 92 % of clickers have no more than 10 historical clicks as shown in the Figure 3(b ) . Another key difference lies in that Google News [ 15 ] is a content agnostic system which doesn’t resort to either content features or user information . YourNews [ 2 ] allows users to customize their interest profiles through a user model interface . The study on user behavior shows the benefit from customization but also cautions the downside on system performance . In our application , we build up user and content profiles without any solicitation on users . Newsjunkie [ 18 ] provided personalized news feeds for users by measuring news novelty in the context of stories the users have already read . Our content profiles can also maintain dynamic features in addition to context novelty , such as popularity and freshness . Our model also leverages user profiles to facilitate cold start on new users .
Our work is also related to personalized search , though the tasks are quite different . Micarelli et al . [ 28 ] gave a nice review on this direction . Personalized search builds models of short term and long term user needs based on observed user actions , which is able to satisfy the users better than standard search engines based on traditional Information Retrieval ( IR ) techniques . Speretta and Gauch [ 38 ] devel
WWW 2009 MADRID!Track : Social Networks and Web 2.0 / Session : Recommender Systems695 oped user profiles from their query histories and used these profiles to re rank the results returned by an independent search engine by giving more importance to the documents related to topics contained in the user profile . Ahn et al . [ 2 ] designed the TaskSieve system that utilizes a relevance feedback based profile for personalized search . Both systems employ the traditional linear approach to combine personal preferences and query relevance . The combined score is calculated as αf ( xi , zj)+(1−α ) r(zj ) , where xi is a user profile , zj is a content item fused with the query and α is the tradeoff . There is a strong correspondence to the terms in eq(2 ) . By replacing the dynamic features of zj by the query relevance r(zj ) and implement f ( xi , zj ) in the parametric form of the long term preferences as in eq(2 ) , our bilinear model provides a flexible framework to learn the personal preference function and the tradeoff term from the click stream in a principled manner .
A personalized service may not be exactly based on individual user behaviors . The content of a website can be tailored for a predefined audience , based on offline research of conjoint analysis , without online gathering knowledge on individuals for service . Conjoint analysis is one of the most popular market research methodologies for assessing how customers with heterogeneous preferences appraise various objective characteristics in products or services . Analysis of tradeoffs driven by heterogeneous preferences on benefits derived from product attributes provides critical inputs for many marketing decisions , eg optimal design of new products , target market selection , and pricing a product . In very early studies [ 40 ] , homogeneous groups of consumers are entailed by the use of a priori segmentation . For example , consumers are assigned to groups on the basis of demographic and socioeconomic variables , and the conjoint models are estimated within each of those groups . This is closely related to demographic recommender systems [ 23 , 34 ] , in which recommendations are based on demographic classes categorized by users’ personal attributes . However , the criteria in the two steps are not necessarily related : one is the homogeneity of customers in terms of their descriptor variables and another is the conjoint preferences within segments . Traditionally , conjoint analysis procedures are of two stage : 1 ) estimating a parametric function which represents customers’ preference at individual level in terms of user profiles , eg hierarchical Bayesian methods [ 25 ] ; 2 ) through clustering algorithms , grouping users into segments where users share similar individual level preferences . Jiang and Tuzhilin [ 22 ] experimentally demonstrated both 1 to1 personalization and segmentation approaches significantly outperform aggregate modeling .
In the extreme cold start setting with dynamic content and a large amount of new users , traditional collaborative filtering methods cannot provide recommendation effectively . A number of hybrid methods , which combine information filtering and other collaborative filtering techniques , have been proposed , such as [ 12 ] of an online newspaper and the Fab system [ 3 ] . Good et al . [ 20 ] improved accuracy by introducing personal agents , and Park et al . [ 33 ] further improved its performance in cold start situations by adding small number of artificial users who have rated all items . However , this approach performs better only if a user has rated a few items but does not solve the cold start problem [ 5 ] utilized social infordirectly for new users . Basu et al . mation in content based filtering . Melville et al . [ 27 ] em
Figure 2 : A snapshot of the default “ Featured ” tab in the Today Module on Yahoo! Front Page . There are four articles displayed at footer positions . One of the four articles is highlighted at the story position . ployed a content based predictor to enhance existing user data , and then provided personalized suggestions through collaborative filtering . Basilico and Hofmann [ 4 ] developed a framework that incorporates all available information by using a suitable kernel or similarity function between useritem pairs . Hybrid methods are especially useful when data is sparse , for example in cold start situations [ 35 ] , but to our best knowledge none of previous work has been integrated with continuous online attributes , such as popularity or freshness .
5 . CASE STUDIES
In this section , we verify the capacity of the proposed bilinear models on a real world application . We start with an introduction of the problem settings in Yahoo! TodayModule and describe the attributes we collected in user/content profiling . We also define performance metrics to evaluate predictive results and report experimental results with comparison to competitive approaches . 5.1 Yahoo! Today Module
Today Module is the most prominent panel on Yahoo! Front Page , which is also one of the most visited pages on the Internet , see a snapshot in Figure 2 . The default “ Featured ” tab in Today Module highlights one of four high quality articles , mainly news , while the four articles are selected from a daily refreshed article pool curated by human editors . As illustrated in Figure 2 , there are four articles at footer positions , indexed by F1 , F2 , F3 and F4 respectively . Each article is represented by a small picture and a title . One of the four articles is highlighted at the story position , which is featured by a large picture , a title and a short summary along with related links . At default , the article at F1 is highlighted at the story position . A user can click on the highlighted article at the story position to read more details if she is interested in the article . The event is recorded as a story click . If a user is interested in an article at F2∼F4 positions , she can highlight the article at the story position by clicking on the footer position . To draw visitors’ attention , we would like to rank available articles according to visitors’ interests , and highlight the most attractive article at F1 position .
It is difficult to adopt a traditional collaborative filtering algorithm such as user user [ 7 ] or item based [ 16 ] in the
WWW 2009 MADRID!Track : Social Networks and Web 2.0 / Session : Recommender Systems696 Today Module . Retrieving historical ratings of users for similarity evaluation in the online service is hard . Lifetime of an article is very short ( only a few hours ) and old articles will be pulled out of content pool regularly . Another difficulty is that we always need to recommend new items and significant portion of users is taken by new users . As shown in Figure 3(b ) and ( c ) , 40 % clickers in the test data are the first time clickers without any historical clicks , and on average 60 % articles are new everyday . Thus , traditional collaborative filtering methods suffer from the cold start problem . Furthermore , the article popularity is temporally decaying , see Figure 3(a ) for an example where CTR decreases to 1/6 of its peak value at the end of the article ’s lifetime . It is difficult to compare users’ feedback on the same article received at different time slots . 5.2 Data Collection
We collected events from a random bucket in July 2008 . In the random bucket , articles are randomly selected from the content pool to serve users . An event records a user ’s action on the article at the story position , which is either “ view ” or “ click ” encoded as −1 and 1 respectively . Note that a user may click on the same article multiple times but at different time slots.5 In our approach , these binary events are distinguishable , because a content item is defined by both the article and the time slot of the event of interest , see Figure 1 . This is a conceptual difference from traditional approaches .
We collected about 40 million click/view events by about 5 million users from the random bucket before a certain time stamp for training . We also collected about 0.6 million click events after that time stamp for test .
The features of users and items were selected by “ support ” . The “ support ” of a feature means the number of users having the feature . We only selected the features of high support above a prefixed threshold , eg 10 % of the population . Then each user is represented by a vector of more than one thousand categorical features , which include :
• Demographic information : gender ( 2 classes ) and age discretized into ten classes ;
• Geographic features : about two hundred locations of countries or US States ;
• Behavioral categories : about one thousand binary categories that summarize the user ’s consumption behavior within Yahoo! properties ;
Each article is profiled by a vector of about one hundred static features and a dynamic feature . The static features include :
• URL categories : tens of classes inferred from the URL of the article resource ;
• Editor categories : tens of topics tagged by human ed itors to summarize the article content ;
The dynamic feature is of estimated click through rate ( CTR ) at events of interest , which differentiates the same article at different time slots . We adapted the Kalman filter designed
5For anti robot purpose , the number of clicks generated by one user on the same article could be at most 1 within a single time slot ( eg 5 minutes ) .
Figure 3 : ( a ) A typical pattern of article CTR ; ( b ) Historical click counts of clickers in test ; ( c ) New article percentage per day in test . and implemented by our team [ 1 ] for CTR tracking , which yields a good indicator of article quality and popularity temporally . Note that other dynamic features , eg freshness , can be added into the content profiles as well .
√
Categorical features are encoded as binary vectors with non zero indicators . For example , “ gender ” of two classes is translated into two binary features , ie , “ male ” is encoded as [ 0 , 1 ] , “ female ” is encoded as [ 1 , 0 ] and “ unknown ” is [ 0 , 0].6 As the number of non zero entries in these binary feature vectors varies , we further normalized each vector into unit length , ie , non zero entries in the normalized vector are replaced by 1/ k , where k is the number of non zero entries . For user features , we normalized behavioral categories and the remaining features ( age , gender and location ) separately , due to the variable length of behavioral categories per user . For article features , we normalized URL and Editor categories together , and kept the CTR term ( a real value ) intact . Following conventional treatment , we also augmented each feature vector by a constant term 1 . Each content item is represented by a feature vector of 83 entries , while each user is represented by a feature vector of 1193 entries . 5.3 Performance Metric
For each user in test , we computed predictive scores as in eq(8 ) for all available articles at the time stamp of the event , and ranked these articles in descending order according to the scores . On click events , we measured the rank position of the article being clicked by the user .
The first metric we use is the number of clicks in each rank position . A good predictive model should have more clicks on the top ranked positions and lesser clicks on the lowerranked position . In our application , we mainly concern the performance on the top 4 positions .
We also proposed a simple utility function to quantify the predictive performance , which is defined as follows :
4:r=1
6The “ unknown ” category coded with zero entries has little contribution to our linear models .
U =
Ur 2r−1 ,
( 9 )
20406080100120140160180Time Index ( 5 Minutes)CTR01 2 3 4 5 6 7 8 9 1000102030405Number of ClicksNumber of Users ( %)123456789002040608Time Index ( One Day)New Articles ( %)(a ) ( b ) ( c ) WWW 2009 MADRID!Track : Social Networks and Web 2.0 / Session : Recommender Systems697 where Ur denotes the percentage of clicks at the rank position r in the whole test clicks .
5.4 Competitive Approaches
We implemented three sets of competitive approaches for comparison purpose .
541 Aggregate Level ( EMP )
As a baseline , we aggregated clicks and views per article along time over the whole population , and ranked articles by the global CTR only . The CTR online tracking was implemented with the Kalman filter designed in [ 1 ] , which has yielded very strong performance in the product . In this approach , denoted by EMP , users are served with the same content ( the estimated most popular article ) at the same time stamp .
542
Segmentation Level ( GM and SEG5 )
Presupposing the existence of heterogeneity in users’ preferences on articles , we carried out two conjoint analysis methods on the Today Module data : a ) GM : We simply grouped users into 6 clusters based on rules of their demographic variables ( age and gender ) ; b ) SEG5 : We estimated users’ preferences on article features first following the hierarchical Bayes approach discussed by [ 25 ] and then clustered homogeneous users with similar preferences by K means.7 At segmentation level , we aggregated clicks and views per article within user segments , and estimated the article CTR within segments . A user will be served with the most popular article in the segment she belongs to . The CTR estimation within segments suffers from low traffic issues when the number of segments is large . On this application , we tried 2 , 5 , 10 and 20 segments and found the performance of 5 segments is the best out of the four settings .
At both aggregate and segmentation level , we applied the same online CTR tracking technique [ 1 ] , which was also used for updating the dynamic feature of article CTR at aggregate level in content profiles .
543 Individual Level ( IBCF , CB and CB+EMP )
We implemented three alternative individual level approaches to compare against our bilinear models .
Item based collaborative filtering ( IBCF ) .
We implemented a standard item based collaborative filtering algorithm as in [ 16 ] . We update the item item similarity matrix in every hour by calculating cosine similarity of two articles in the user click behaviors . When the algorithm cannot recommend anything due to lack of user information ( ie new users ) , the algorithm rank candidate articles based on the aggregate CTR .
Content based filtering ( CB ) .
As we discussed in Section 5.2 , each user xi and item zj can be represented as a vector of categorical features ( without dynamic features ) as xi = {xi,1 , , xi,D} and zj = {zj,1 , , zj,C} respectively . We normalized user and item veck=1 zj,k = 1 . tors into unit sum , ie 2D k=1 xi,k = 1 and2C
7Monte Carlo sampling methods suggested in [ 25 ] cannot be applied to our application . We resorted to the MAP estimate via gradient descent methods . More details of segmentation analysis will be reported in another paper .
For each vector , xi,k = 1|xi| if the user has the k th userfeature and xi,k = 0 otherwise , where |xi| denotes the number of non zero features in xi .
We maintained two affinity matrices between heterogeneous features for click and view events respectively . For a click/view event of xi and zj , the click/view affinity between the b th user feature and the a th item feature is accumulated with xi,bzj,a . Note that the total contribution from a single event is always one . For each pair of heterogeneous features , we aggregated the contributions over all click/view events in the training samples , and then calculated the affinity ratio between click and view , denoted as υab .
After we learnt the affinities for all feature pairs , the preference score given by a user xi on an item zj is calculated as b=1 xi,bzj,aυab which is analogous to our bilinear model in eq(1 ) but is of different feature normalization and affinity estimation . cij =2C a=12D
CB with online CTR ( CB+EMP ) .
Since the estimated CTR of an item at time t , denoted by CT Rj,t , provides tremendous insight on the quality of the item at time t , we followed the hybrid approaches [ 10 ] to combine CTR with the score from the content based approach . Motivated by the combinations proposed in personalized search [ 38 , 2 ] , the final score given by a user xi on an item zj at time t was evaluated by ( 1 − α ) cij + α CT Rj,t where CT Rj,t denotes CTR of the article zj at time t , and 0 ≤ α ≤ 1 is a trade off parameter determined by cross validation . We found α = 0.8 yields the best validation results . 5.5 Results
We implemented two versions of the probabilistic bilinear models . One treated the feedback as continuous scores ( RG ) , whereas another took the click or not events as binary targets ( LRG ) . We employed a gradient descent package for the MAP estimate in the posterior distribution of the weights as described in Section 33 The model parameter ς 2 was determined by cross validation on [ 0.01 , 0.1 , 1 , 10 ] , as discussed in Section 351 For each user in test , we computed the expected score ˆsij as in eq(8 ) for all available articles at the event , and ranked these articles in descending order according to the scores .
In Table 3 , we presented the portions of clicks at the top 16 rank positions of all the methods we have implemented and computed the utility function defined as in eq(9 ) . We also carried out Wilcoxon rank sum tests on the predicted click ranks to evaluate the significance of the difference between the LRG ’s ranks and other methods’ predictions , and reported the p values in Table 3 . A p value close to zero means the two predictive results are significantly different , while near 1 means the difference is not significant . Usually we set the level of significance at 005 LRG greatly outperforms other methods on both click portions on the top 4 positions and the utility function . The hypothesis testing results also show the improvement is significant over all competitors . GM , a rule based segmentation , doesn’t result in much improvement , compared with SEG5 that fuses profiles and feedback for user segmentation .
CB relying on user/item static features only recommends items similar to what a user has already rated , but it is hard to capture new features that the user might like and to provide serendipity finding which collaborative filtering can do . CB+EMP , a combined approach , performs slightly better
WWW 2009 MADRID!Track : Social Networks and Web 2.0 / Session : Recommender Systems698 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
EMP 12.47 % 9.93 % 8.80 % 8.00 % 7.24 % 6.85 % 6.51 % 6.08 % 5.60 % 5.20 % 4.86 % 4.46 % 4.08 % 3.60 % 3.18 % 2.82 %
12.52 % 10.06 % 8.81 % 7.99 % 7.29 % 6.83 % 9.47 % 6.03 % 5.60 % 5.17 % 4.78 % 4.43 % 4.02 % 3.57 % 3.17 % 2.9 %
CB
IBCF
SEG5 13.08 % 10.01 % 8.09 % 8.46 % 7.87 % 10.43 % 7.80 % 7.32 % 9.02 % 7.41 % 7.34 % 8.18 % 7.39 % 6.72 % 6.74 % 6.52 % 6.63 % 6.92 % 6.56 % 6.52 % 6.40 % 6.18 % 6.12 % 5.87 % 5.58 % 5.81 % 6.13 % 5.68 % 6.41 % 5.06 % 5.29 % 5.82 % 4.67 % 5.06 % 5.22 % 4.27 % 4.89 % 4.75 % 3.82 % 3.35 % 4.73 % 5.11 % 4.21 % 4.75 % 2.99 % 2.63 % 4.15 % 4.59 % 2.41e 24 0.2157
0.1712
0.1477
12.49 % 9.92 % 8.81 % 7.98 % 7.26 % 6.88 % 6.47 % 6.07 % 5.68 % 5.24 % 4.75 % 4.45 % 4.04 % 3.62 % 3.18 % 2.79 % 3 e201 0.2065
9.08 % 8.70 % 8.15 % 7.67 % 7.29 % 6.92 % 6.58 % 6.22 % 5.84 % 5.63 % 5.38 % 4.98 % 4.48 % 4.35 % 4.18 % 4.02 %
0
0.1642
13.34 % 13.45 % 10.57 % 10.60 % 9.23 % 9.28 % 8.21 % 8.28 % 7.56 % 7.5 % 6.85 % 6.98 % 6.34 % 6.40 % 5.84 % 5.90 % 5.49 % 5.37 % 4.98 % 4.98 % 4.56 % 4.55 % 4.22 % 4.16 % 3.81 % 3.74 % 3.22 % 3.32 % 2.93 % 2.85 % 2.41 % 2.47 % 0.1022 0.2198
0.2209
1
Table 3 : Click portions on predictive rank positions , along with Ranksum Test and Utility results . LRG
LRG CTR
CB+EMP
Rank Position
GM
RG
Ranksum Test
7.109e 212
1.145e 182
Utility
0.2063
0.2075
0
0
6 . CONCLUSIONS
We proposed a feature based bilinear regression framework for personalized recommendation on dynamic content . We quantified associations between attributes in user profiles and content profiles through learning a parametric bilinear regression function from interactive feedback . This approach results in an offline model but with the dynamic features in content profiles , which provides the capacity of recommending new high quality content promptly and accurately . In contrast to traditional recommender systems , our approach also greatly alleviates the cold start issue of recommending for new users , by leveraging interest patterns in user profiles recognized from regression over historical interactive feedback . We found the personalized predictive models significantly outperform six competitive approaches at aggregate , segmentation or individual levels on the application of Yahoo! Front Page Today Module .
The potentials of the probabilistic bilinear regression frame work haven’t been fully exploited . It is straightforward to implement online learning algorithms within the proposed regression framework , which may be useful in tracing users’ short term interests . Based on information theoretical principles , efficient learning could be achieved by actively electing salient samples . The techniques we proposed for dynamic content can be adapted for personalized search as well . We plan to investigate these directions in future work .
7 . ACKNOWLEDGMENTS
We thank Raghu Ramakrishnan , Scott Roy , Deepak Agarwal , Bee Chung Chen , Pradheep Elango , and Ajoy Sojan for many discussions and helps on data collection .
8 . REFERENCES [ 1 ] D . Agarwal , B . Chen , P . Elango , N . Motgi , S . Park ,
R . Ramakrishnan , S . Roy , and J . Zachariah . Online models for content optimization . In Advances in Neural Information Processing Systems 21 , 2009 .
[ 2 ] J . Ahn , P . Brusilovsky , J . Grady , D . He , and S . Y . Syn .
Open user profiles for adaptive news systems : help or
Figure 4 : Lift over EMP ( the baseline at aggregate level ) on click portion at the top 4 positions . than EMP , but the improvement gained from the weighted sum is insignificant . Traditional item based collaborative filtering ( IBCF ) performs worse than EMP since the great portion of users in our dataset are new or casual users who do not click much . Note that 92 % of clickers in our test data have clicked no more than 10 articles , while Google News [ 15 ] and other collaborative filtering literatures only consider a group of heavy users who have rated at least 20 items , often more than 100 items . We also measured the performance of LRG after removing the dynamic CTR feature ( LRG CTR ) to see its impact on performance . As seen in the Table 3 , removing the dynamic feature causes significant performance degradation that shows the CTR feature is a crucial part in our application .
We presented the portion lift at the top 4 positions in Figure 4 . SEG5 also yields about 5 % lift over the EMP approach , and LRG gives 8 % lift . RG also performs well but is worse than LRG , as shown in Table 3 . On this application with click or not feedback , it is prudent to apply LRG on the binary targets .
  WWW 2009 MADRID!Track : Social Networks and Web 2.0 / Session : Recommender Systems699 harm ? In Proceedings of the International World Wide Web Conference , 2007 .
[ 3 ] M . Balabanovic and Y . Shohan . Fab : Content based , collaborative recommendation . Communications of the ACM , 40 , 1997 .
American Association of Artificial Intelligence , pages 439–446 , 1999 .
[ 21 ] R . Guttman , A . Moukas , and P . Maes . Agent mediated electronic commerce : A survey . Knowledge Engineering Review , 13(3 ) , June 1998 .
[ 4 ] J . Basilico and T . Hofmann . A joint framework for
[ 22 ] T . Jiang and A . Tuzhilin . Segmenting customers from collaborative and content filtering . In Proceedings of the International ACM SIGIR Conference , 2004 .
[ 5 ] C . Basu , H . Hirsh , and W . W . Cohen . Recommendation as classification : Using social and content based information in recommendation . In Proceedings of the Fifteenth National Conference on Artificial Intelligence , pages 714–720 , 1998 .
[ 6 ] D . Billsus and M . Pazzani . Adaptive news access . In P . Brusilovsky , A . Kobsa , and W . Nejdl , editors , The Adaptive Web — Methods and Strategies of Web Personalization , volume 4321 of Lecture Notes in Computer Science . Springer Berlin / Heidelberg , 2007 .
[ 7 ] J . S . Breese , D . Heckerman , and C . Kadie . Empirical analysis of predictive algorithms for collaborative filtering . In Proceedings of the Conference on Uncertainty in Artificial Intelligence , pages 43–52 , 1998 .
[ 8 ] P . Brusilovsky , A . Kobsa , and W . Nejdl , editors . The
Adaptive Web — Methods and Strategies of Web Personalization , volume 4321 of Lecture Notes in Computer Science . Springer Berlin / Heidelberg , 2007 .
[ 9 ] A . G . B¨uchner , J . G . Hughes , and D . A . Bell . Contextual data and domain knowledge for incorporation in knowledge discovery systems . In J . Wang , editor , Modeling and Using Context , volume 1688 , pages 831–832 , 1999 .
[ 10 ] R . Burke . Hybrid systems for personalized recommendations . In B . Mobasher and S . S . Anand , editors , Intelligent Techniques for Web Personalization . Springer Verlag , 2005 .
[ 11 ] W . Chu and Z . Ghahramani . Probabilistic models for incomplete multi dimensional arrays . In Proceedings of the 12th International Conference on Artificial Intelligence and Statistics , 2009 .
[ 12 ] M . Claypool , A . Gokhale , T . Miranda , P . Murnikov ,
D . Netes , and M . Sartin . Combining content based and collaborative filters in an online newspaper . In ACM SIGIR Workshop on Recommender Systems , 1999 .
[ 13 ] M . Claypool , P . Le , M . Wased , and D . Brown . Implicit interest indicators . In the 6th International Conference on Intelligent User Interfaces . ACM Press , 2002 .
[ 14 ] R . Coppi and S . Bolasco , editors . Multiway data analysis .
North Holland Publishing Co . , Amsterdam , The Netherlands , The Netherlands , 1989 .
[ 15 ] A . Das , M . Datar , A . Garg , and S . Rajaram . Google news personalization : scalable online collaborative filtering . In Proceedings of the International World Wide Web Conference , 2007 .
[ 16 ] M . Deshpande and G . Karypis . Item based top n recommendation algorithms . ACM Transactions on Information Systems ( TOIS ) , 22(1):143–177 , Jan 2004 .
[ 17 ] B . J . Frey , R . Patrascu , T . Jaakkola , and J . Moran .
Sequentially fitting inclusive trees for inference in noisy or networks . In Advances in Neural Information Processing Systems 13 . MIT Press , 2000 .
[ 18 ] E . Gabrilovich , S . Dumais , and E . Horvitz . Newsjunkie : providing personalized newsfeeds via analysis of information novelty . In Proceedings of the International World Wide Web Conference , 2004 .
[ 19 ] S . Gauch , M . Speratta , A . Chandranouli , and A . Micarelli .
User profiles for personalized information access . In P . Brusilovsky , A . Kobsa , and W . Nejdl , editors , The Adaptive Web — Methods and Strategies of Web Personalization . Springer Berlin / Heidelberg , 2007 .
[ 20 ] N . Good , J . B . Schafer , J . A . Konstan , A . Borchers , B . M .
Sarwar , J . L . Herlocker , and J . Riedl . Combining collaborative filtering with personal agents for better recommendations . In Proceedings of the Conference of the population to individuals : does 1 to 1 keep your customers forever ? IEEE Transactions on Knowledge and Data Engineering , 18(10):1297–1311 , 2006 .
[ 23 ] B . Krulwich . Lifestyle finder : Intelligent user profiling using large scale demographic data . Artificial Intelligence Magazine , 18(2):37–45 , 1997 .
[ 24 ] N . Lawrence , M . Seeger , and R . Herbrich . The informative vector machine . In Advances in Neural Information Processing Systems 15 . MIT Press , 2003 .
[ 25 ] P . J . Lenk , W . S . DeSardo , P . E . Green , and M . R . Young . Hierarchical Bayes conjoint analysis : Recovery of partworth heterogeneity from reduced experimental designs . Marketing Science , 15(2):173–191 , 1996 .
[ 26 ] D . J . C . MacKay . The evidence framework applied to classification networks . Neural Computation , 4(5):720–736 , 1992 .
[ 27 ] P . Melville , R . Mooney , and R . Nagarajan . Content boosted collaborative filtering . In Proceedings of the Conference of the American Association of Artificial Intelligence , 2002 .
[ 28 ] A . Micarelli , F . Gasparetti , F . Sciarrone , and S . Gauch .
Personalized search on the World Wide Web . In P . Brusilovsky , A . Kobsa , and W . Nejdl , editors , The Adaptive Web — Methods and Strategies of Web Personalization , volume 4321 of Lecture Notes in Computer Science . Springer Berlin / Heidelberg , 2007 .
[ 29 ] T . P . Minka . A family of algorithms for approximate
Bayesian inference . PhD thesis , Massachusetts Institute of Technology , January 2001 .
[ 30 ] D . Mladenic . Text learning and related intelligent agents :
A survey . IEEE Intelligent Agents , pages 44–54 , 1999 .
[ 31 ] B . Mobasher and S . S . Anand , editors . Intelligent
Techniques for Web Personalization , volume 3169 of Lecture Notes in Artificial Intelligence . Springer Verlag , 2005 .
[ 32 ] O . Nasraoui . World Wide Web personalization . In J . Wang , editor , Encyclopedia of Data Warehousing and Mining , pages 1235–1241 . Idea Group , 2005 .
[ 33 ] S T Park , D . M . Pennock , O . Madani , N . Good , and
D . DeCoste . Na¨ıve filterbots for robust cold start recommendations . In Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining , 2006 .
[ 34 ] M . J . Pazzani . A framework for collaborative , content based and demographic filtering . Artificial Intelligence Review , 13 , 1999 .
[ 35 ] A . Popescul , L . Ungar , D . Pennock , and S . Lawrence .
Probabilistic models for unified collaborative and content based recommendation in sparse data environments . In Proceedings of the Conference on Uncertainty in Artificial Intelligence , pages 437–444 , 2001 . [ 36 ] J . Saloj¨arvi , K . Puolam¨aki , and S . Kaski . Implicit relevance feedback from eye movements . In Proceedings of the 15th International Conference on Artificial Neural Networks , pages 513–518 , 2005 .
[ 37 ] J . B . Schafer , K . J . , and J . Riedl . Recommender systems in e commerce . In Proceedings of the ACM Conference on Electronic Commerce , 1999 .
[ 38 ] M . Speretta and S . Gauch . Personalized search based on user search histories . In Web Intelligence . IEEE Computer Society , 2005 .
[ 39 ] J . B . Tenenbaum and W . T . Freeman . Separating style and content with bilinear models . Neural Computation , 12:1247–1283 , 2000 .
[ 40 ] Y . Wind . Issue and advances in segmentation research .
Journal of Marketing Research , 15:317–337 , 1978 .
WWW 2009 MADRID!Track : Social Networks and Web 2.0 / Session : Recommender Systems700
