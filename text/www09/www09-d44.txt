Towards Context Aware Search by Learning A Very Large Variable Length Hidden Markov Model from Search Logs
∗
Huanhuan Cao1 Hang Li2 1University of Science and Technology of China 2Microsoft Research Asia 3Simon Fraser University
Enhong Chen1
Daxin Jiang2
Jian Pei3
1{caohuan , cheneh}@ustceducn
2{djiang , hangli}@microsoft.com 3jpei@cssfuca
ABSTRACT Capturing the context of a user ’s query from the previous queries and clicks in the same session may help understand the user ’s information need . A context aware approach to document re ranking , query suggestion , and URL recommendation may improve users’ search experience substantially . In this paper , we propose a general approach to context aware search . To capture contexts of queries , we learn a variable length Hidden Markov Model ( vlHMM ) from search sessions extracted from log data . Although the mathematical model is intuitive , how to learn a large vlHMM with millions of states from hundreds of millions of search sessions poses a grand challenge . We develop a strategy for parameter initialization in vlHMM learning which can greatly reduce the number of parameters to be estimated in practice . We also devise a method for distributed vlHMM learning under the map reduce model . We test our approach on a real data set consisting of 1.8 billion queries , 2.6 billion clicks , and 840 million search sessions , and evaluate the effectiveness of the vlHMM learned from the real data on three search applications : document re ranking , query suggestion , and URL recommendation . The experimental results show that our approach is both effective and efficient .
Categories and Subject Descriptors H33 [ Information Search and Retrieval ] : Search process
General Terms Algorithms , Experimentation
Keywords Context aware search , variable length Hidden Markov Model
1 .
INTRODUCTION
Capturing the context of a user ’s query from the previous queries and clicks in the same session may help understand the user ’s information need . A context aware approach to
∗The work was done when Huanhuan Cao was an intern at
Microsoft Research Asia .
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . Distribution of these papers is limited to classroom use , and personal use by others . WWW 2009 , April 20–24 , 2009 , Madrid , Spain . ACM 978 1 60558 487 4/09/04 . document re ranking , query suggestion , and URL recommendation may improve users’ search experience substantially .
Example 1
( Motivation ) . Ada plans to buy a new car . Thus , she wants to compare the models , price , availability , and deals of various brands . If Ada does not know how to formulate an effective query to describe her information need , she may issue a series of queries to search for individual brands and models and browse many results one by one . Actually , what Ada needs is some review web sites such as wwwautohomecom This web site is returned as a search result when a user raises a query such as “ Ford new cars ” or “ Toyota new cars ” . However , since most search engines treat a user query individually and rank the documents based on the relevance to only the current query ( eg , “ Ford new cars ” ) , the review web site is usually ranked lower than the sites/pages dedicated to the brand in the query . Consequently , it is not easy for Ada to notice the review web site .
SID Search session
Ford ⇒ Toyota ⇒ GMC ⇒ Allstate
↓
S1
S2
S3
S4
Ford cars ⇒ Toyota cars ⇒ GMC cars ⇒ Allstate wwwautohomecom ↓
Ford cars⇒ Toyota cars⇒ Allstate wwwautohomecom
↓ wwwallstatecom
GMC ⇒ GMC dealers
↓ wwwgmccom
Table 1 : Four search sessions .
To understand why context aware search may help , let us consider the search log data shown in Table 1 which contains four sessions . The ‘↓’ symbol indicates the user clicks a URL . A pattern in the sessions is that in 50 % of the sessions , a user clicks on www . autohome . com after asking a series of queries about different brands of cars . Using this pattern , a search engine should promote URL wwwautohomecom in the ranked list of search results for Ada . Another pattern that can be found in the sessions is that in 75 % of the sessions , after a series of queries about different brands of cars , users will search for car insurance . Using this context information , a search engine can provide the corresponding query and URL suggestions to improve users’ search experience .
WWW 2009 MADRID!Track : Data Mining / Session : Learning191 ries of car companies and clicked corresponding homepages , the probability of searching for car review sites may significantly increase , while the probability of searching for the GMC homepage may decrease . Consequently , the vlHMM will boost the car review web sites , and provide suggestions about car insurance instead of the specific car dealers .
Learning Hidden Markov Models and variants has been well adopted in many applications . However , applying the Hidden Markov Models in context aware search is far from trivial . Due to the extremely large search session data , it is impractical to apply the existing algorithms . In a commercial search engine , search logs may contain hundreds of millions of training examples . For instance , in the data set used in our experiments , there are 840 million search sessions . Moreover , search logs may contain millions of unique queries and URLs , eg , 1.8 million unique queries and 8.3 million unique URLs in our experimental data , which makes the number of model parameters extremely large .
To tackle the problem , in this paper , we develop a strategy for parameter initialization in vlHMM learning which can greatly reduce the number of parameters to be estimated in practice . We also devise a method for distributed vlHMM learning under the map reduce model [ 9 ] . Once the vlHMM is trained offline , it can be used online to support contextaware search in various applications such as document reranking , query suggestion , and URL recommendation .
We make the following contributions in this paper . First , we propose a novel model to support context aware search . To the best of our knowledge , this is the first approach towards comprehensive context modeling for context aware search . Second , we develop efficient algorithms and strategies for learning a very large vlHMM from huge log data . Finally , we test our approach on a real log data set containing 1.8 billion queries , 2.6 billion clicks , and 840 million search sessions . We examine the effectiveness of the trained vlHMM on three search applications : document re ranking , query suggestion , and URL recommendation , as well as the efficiency of our training algorithms . The experimental results clearly show our approach is effective and efficient .
The rest of the paper is organized as follows . Section 2 briefly reviews the related work . In Section 3 , we introduce the vlHMM model for search logs . The training methods of very large vlHMM and the applications in context aware search are presented in Sections 4 and 5 , respectively . In Section 6 , we report the experimental results . The paper is concluded in Section 7 .
2 . RELATED WORK
Traditional approaches to query understanding often rely on explicit , implicit , or pseudo relevance feedback ( eg , [ 14 , 18 , 20 ] ) or user profiles ( eg , [ 7 , 19] ) . In terms of modeling contexts of queries , Bai et al . [ 3 ] constructed a language model using the context both around and within a query . Although these techniques are helpful to understand users’ search intent , they do not use search log data and do not provide query or URL suggestions .
Some recent studies mined users’ search or browsing logs and used wisdom of the crowds to improve users’ search experience . For example , White et al . [ 23 ] proposed mining popularly visited web sites from browsing logs and recommending to a user the web sites frequently visited by other users with similar information needs . Huang et al . [ 13 ] mined query pairs frequently co occurring in search sessions ,
Figure 1 : Graphical structure of the vlHMM .
Modeling query contexts by mining search sessions is a fundamental and challenging problem . Although some progress has been made by the previous studies [ 6 , 15 , 23 ] , most of them only consider correlations within query pairs . Such a method cannot capture well the contexts exemplified in Example 1 which are carried by a series of queries and clicks . Moreover , each of the previous methods builds a model only for a specific search application . To achieve general context aware search , we need a comprehensive model which can be used simultaneously for multiple applications such as document re ranking , query suggestion , and URL recommendation .
In this paper , we propose modeling query contexts by a variable length Hidden Markov Model ( vlHMM for short ) for context aware search . As well recognized by many previous studies such as [ 12 ] , a user often raises multiple queries and conducts multiple rounds of interaction with a search engine for an information need . For instance , in Example 1 , Ada may decompose her general search task , comparing various cars , into several specific sub tasks , such as searching the cars of Ford . In each sub task , Ada may bear a particular search intent in mind and formulate a query to describe the intent . Moreover , Ada may selectively click on some related URLs to browse . A Hidden Markov Model ( HMM for short ) naturally describes the search process . We can model each search intent as a state of the HMM , and consider the query and clicked URLs as observations generated by the state . The whole search process can be modeled as a sequence of transitions between states as illustrated in Figure 1 . It is possible that a state transits to itself .
Let qt be the current query . The vlHMM can re rank the search results by the posterior probability distribution P ( st|qt , O1···t−1 ) , where st is the current search intent hidden in the user mind and O1···t−1 is the context of qt , which is captured by the past queries q1 . . . qt−1 as well as the clicks of those queries . Moreover , the vlHMM can even predict the user ’s next search intent st+1 by P ( st+1|qt , O1···t−1 ) and generate query suggestions and URL recommendations accordingly .
The probability distributions of st and st+1 are inferred from not only the current query , but also the whole context observed so far . For instance , in Example 1 , given the current query “ GMC ” alone , the probability of Ada searching for the homepage of GMC is likely to be higher than that of searching for car review web sites . Therefore , the company homepage is ranked higher than wwwautohomecom and suggestions such as “ GMC dealers ” are more likely to be served . However , given the context O1···t−1 that Ada has input a se u1ut 1utq1qt 1s1st 1stqtnt 1ntO1t 1n1 : Probability dependence : State transition : Multiple clicksWWW 2009 MADRID!Track : Data Mining / Session : Learning192 and used the queries in those pairs as suggestions for each other . Fonseca et al . [ 12 ] and Jones et al . [ 15 ] extracted adjacent queries in sessions for query expansion and query substitution , respectively . Beeferman et al . [ 5 ] , Wenet al . [ 22 ] , and Baeza Yates et al . [ 1 ] applied various clustering algorithms to find similar queries from click through data and used them as candidates in query suggestion . Those studies can be regarded as initiatives to model partial contexts of queries using simple mechanisms . However , query contexts are not comprehensively modeled due to the limitation of the mechanisms which often consider only query pairs instead of a sequence of queries .
In [ 6 ] , the authors proposed a context aware and conceptbased method CACB for query suggestion . CACB considers the user ’s previous queries in the same session as the context for query suggestion . Moreover , to make query suggestion robust , CACB summarizes similar queries into concepts , where each concept corresponds to a search intent .
The vlHMM approach developed in this paper is fundamentally different from CACB in three aspects . First , CACB constrains that each query represents only one search intent ( concept ) . This limits the applicability of CACB since a query in practice ( eg , “ java ” ) may be used by different users for different search intents . By contrast , in the vlHMM approach , a query may be associated with multiple search intents with a probability distribution , which makes it more general and powerful than CACB .
Second , CACB only considers the previous queries in the same session as the context of a query . In the vlHMM approach , we consider both previous queries and previous clicks in the same session as the context . Therefore , vlHMM exploits more information available and thus can capture contexts of queries more accurately .
Finally , CACB is only able to provide query suggestions ; it cannot handle other search applications such as document re ranking and URL recommendation . By contrast , the vlHMM approach is a general model which can be used to support context aware search in various applications simultaneously .
HMMs have been widely used in various domains such as speech recognition [ 17 ] and bioinformatics [ 11 ] . In [ 21 ] , Wang et al . developed the notion of vlHMMs and applied a vlHMM to mine four kinds of interesting patterns from 3D motion capture data . We use a vlHMM to model query contexts in this paper . Our approach is critically different from [ 21 ] : our vlHMM automatically adapts to users’ search sessions instead of learning an optimized set of contexts .
The training of HMMs has also been well studied in the literature . The classical learning algorithm is the Baum Welch algorithm [ 4 ] , which is essentially an EM algorithm [ 10 ] . However , the existing methods cannot be scaled up to huge log data because of their high computational complexity . Recently , parallel and distributed training of very large machine learning models has attracted much interest . For example , Chu et al . [ 8 ] applied the map reduce programming model [ 9 ] to a variety of learning algorithms . However , how to train a very large HMM from huge log data remains a challenging open problem .
3 . VLHMM MODEL
We choose a Hidden Markov Model rather a Markov Chain to model query contexts because search intents are not observable . Different users may raise different queries to de scribe the same search intent . For example , to search for Microsoft Research Asia , queries “ Microsoft Research Asia ” , “ MSRA ” or “ MS Research Beijing ” may be formulated . Moreover , even two users raise exactly the same query , they may choose different URLs to browse . If we model individual queries and URLs directly as states in a Markov Chain , we not only increase the number of states and thus the complexity of the model , but also lose the semantic relationship among the queries and the URLs clicked by the same search intent . To achieve better modeling , we assume that queries and clicks are generated by some hidden states where each hidden state corresponds to one search intent .
There are different types of HMMs . The first order HMMs ( 1 HMMs ) have been widely used in various applications such as speech recognition [ 17 ] and bioinformatics [ 11 ] . For context aware search , we choose higher order HMMs . This is because the 1 HMM assumes the probability distribution of the state st is independent of the previous states s1 , . . . , st−2 , given the immediately previous state st−1 . In search processes , this assumption usually does not hold . For example , given that a user searched for Ford cars at time point t − 1 , the probability that the user searches for GMC cars at the current time point t still depends on the states s1 . . . st−2 . As an intuitive instance , that probability will be smaller if the user searched for GMC cars at any time point before t−1 . Therefore we consider higher order HMMs rather than 1 HMMs . In particular , we consider the vlHMM instead of the fixed length HMM because the vlHMM is more flexible to adapt to variable lengths of user interactions in different search sessions . Given a set of hidden states {s1 , . . . , sNs} , a set of queries {q1 , . . . , qNq} , a set of URLs {u1 , . . . , uNu} , and the maximal length Tmax of state sequences , a vlHMM is a probability model defined as follows .
• The transition probability distribution ∆ = {P ( si|Sj)} , where Sj is a state sequence of length Tj < Tmax , P ( si|Sj ) is the probability that a user transits to state si given the previous states sj,1sj,2 , . . . , sj,Tj , and sj,t(1 ≤ t ≤ Tj ) is the t th state in sequence Sj .
• The initial state distribution Ψ = {P ( si)} , where P ( si ) is the probability that state si occurs as the first element of a state sequence .
• The emission probability distribution for each state sequence Λ = {P ( q , U|Sj)} , where q is a query , U is a set of URLs , Sj is a state sequence of length Tj ≤ Tmax , and P ( q , U|Sj ) is the joint probability that a user raises the query q and clicks the set of URLs U from state sj,Tj after the user ’s ( Tj − 1 ) steps of transitions from state sj,1 to sj,Tj .
To keep the model simple , given a user is currently at state sj,Tj , we assume the emission probability is independent of the user ’s previous search states sj,1 . . . sj,Tj−1 , ie , P ( q , U|Sj ) ≡ P ( q , U|sj,Tj ) . Moreover , we assume that query q and URLs U are conditionally independent given the state sj,Tj , u∈U P ( u|sj,Tj ) . Under the ie , P ( q , U|sj,Tj ) ≡ P ( q|sj,Tj ) above two assumptions , the emission probability distribution Λ becomes ( Λq , Λu ) ≡ ( {P ( q|si)},{P ( u|si)} ) .
The task of training a vlHMM model is to learn the parameters Θ = ( Ψ , ∆ , Λq , Λu ) from search logs . A search log is basically a sequence of queries and click events . We can extract and sort each user ’s events and then derive sessions based on a widely used method [ 23 ] : two consecutive
WWW 2009 MADRID!Track : Data Mining / Session : Learning193 events ( either queries or clicks ) are segmented into two sessions if the time interval between them exceeds 30 minutes . The sessions formed as such are then used as training examples . Let X = {O1 , . . . , ON} be the set of training sessions , where a session On ( 1 ≤ n ≤ N ) of length Tn is a sequence of pairs ( qn,1 , Un,1 ) . . . ( qn,Tn , Un,Tn ) , where qn,t and Un,t ( 1 ≤ t ≤ Tn ) are the t th query and the set of clicked URLs among the query results , respectively . Moreover , we use un,t,k to denote the k th URL ( 1 ≤ k ≤ |Un,t| ) in Un,t . rameters Θ . We want to find Θ∗ such that
We use the maximum likelihood method to estimate pa
∗
Θ
= arg max
Θ ln P ( X|Θ ) = arg max
Θ ln P ( On|Θ )
( 1 ) n
Let Y = {S1 . . . , SM} be the set of all possible state sequences , sm,t be the t th state in Sm ∈ Y ( 1 ≤ m ≤ M ) , and St−1 m be the subsequence sm,1 , . . . , sm,t−1 of Sm . Then , the likelihood can be written as ln P ( On|Θ ) = ln and the joint distribution can be written as
P ( On , Sm|Θ ) = P ( On|Sm , Θ)P ( Sm|Θ ) P ( un,t,k|sm,t )
P ( qn,t|sm,t )
= m P ( On , Sm|Θ ) ,
Tn ( cid:195 ) t=1
( cid:195 )
× k
Tn t=2
P ( sm,1 )
P ( sm,t|St−1 m )
.
( 2 )
Since optimizing the likelihood function in an analytic way may not be possible , we employ an iterative approach and apply the Expectation Maximization algorithm ( EM for short ) [ 10 ] .
At the E Step , we have
Q(Θ , Θ(i−1 ) ) = E ln P ( X ,Y|Θ)|X , Θ(i−1 ) P ( Sm|On , Θ(i−1 ) ) ln P ( On , Sm|Θ) ] ,
=
( 3 ) n,m where Θ(i−1 ) is the set of parameter values estimated in the last round of iteration . P ( Sm|On , Θ(i−1 ) ) can be written as
P ( Sm|On , Θ(i−1 ) ) =
P ( On , Sm|Θ(i−1 ) )
P ( On|Θ(i−1 ) )
.
( 4 )
Substituting Equation 2 in Equation 4 , and then substituting Equations 2 and 4 in Equation 3 , we get
Q(Θ , Θ(i−1))∝
P ( i−1)(qn,t|sm,t )
P ( i−1)(un,t,k|sm,t )
 Tn
P ( i−1)(sm,1 ) Tn
Tn n,m t=2 t=1
×
+ k
 ×  Tn Tn t=1
  .
P ( i−1)(sm,t|St−1 m ) ln P ( qn,t|sm,t ) ln P ( un,t,k|sm,t ) + ln P ( sm,1 ) + ln P ( sm,t|St−1 m ) t=1 k t=2
At the M Step , we maximize Q(Θ , Θ(i−1 ) ) iteratively us ing the following formula until the iteration converges .
P ( si ) =
P ( q|si ) =
P ( u|si ) =
P ( si|Sj ) = n,m P ( Sm|On , Θ(i−1))δ(sm,1 = si )
( 5 ) n,m P ( Sm|On , Θ(i−1 ) ) t δ(sm,t = si ∧ q = qn,t ) n,m P ( Sm|On , Θ(i−1 ) ) n,m P ( Sm|On , Θ(i−1 ) )
( 6 ) t δ(sm,t = si ∧ u ∈ Un,t ) n,m P ( Sm|On , Θ(i−1 ) ) n,m P ( Sm|On , Θ(i−1 ) ) n,m P ( Sm|On , Θ(i−1))δ(∃t St−1
( 7 ) m = Sj ∧ sm,t = si ) t δ(sm,t = si ) t δ(sm,t = si ) n,m P ( Sm|On , Θ(i−1))δ(∃t St−1 m = Sj )
( 8 )
In the above equations , δ(p ) is a boolean function indicating whether predicate p is true ( = 1 ) or false ( = 0 ) .
4 . TRAINING A VERY LARGE VLHMM
Although the EM algorithm has been widely used to train HMMs , there are still several challenges to apply it on huge search log data .
First , the EM algorithm needs a user specified number of hidden states . However , in our problem , the hidden states correspond to users’ search intents , whose number is unknown . To address this challenge , we apply the mining techniques developed in [ 6 ] as a prior process to the parameter learning process . To be specific , we construct a click through bipartite and derive a collection of query clusters as in [ 6 ] . For each cluster Q of queries , we find all URLs U such that each URL u ∈ U is connected to at least one query q ∈ Q in the click through bipartite . A duple of query and URL cluster ( Q , U ) is considered to correspond to a hidden state . The total number of hidden states is determined by the total number of clusters . For example , Table 2 shows a state which is mined from a real data set .
Queries city of bothell bothell wa bothell washington city of bothell washington city of bothell wa city bothell washington URLs cibothellwaus bothellwashington.com cibothellwaus/dept/pd/pdindexhtml beckwithconsultcom/bothellcityhallhtml explorebothell.com allgetawayscom/city guideasp nwmaps.net/bothell ihsadvantage.com/h/hotels/bothell/wa/us wecandoitall.com dianasflowers.com mrscorg/Contracts/B67 SEWERpdf
P 0(q|s ) 0.52 0.20 0.14 0.07 0.06 0.01 P 0(u|s ) 0.21 0.17 0.15 0.14 0.14 0.09 0.05 0.02 0.01 0.01 0.01
P ( q|s ) 0.43 0.27 0.19 0.05 0.05 0.01 P ( u|s ) 0.15 0.14 0.15 0.17 0.19 0.11 0.08 0.01 0.00 0.00 0.00
Table 2 : An example of a hidden state and the emission probabilities before and after the training .
Second , search logs may contain hundreds of millions of training sessions . It is impractical to learn a vlHMM from such a huge training data set using a single machine . To address this challenge , we deploy the learning task on a distributed system under the map reduce programming model [ 9 ] .
WWW 2009 MADRID!Track : Data Mining / Session : Learning194 We will describe the map stage and the reduce stage in Section 41
Last , although the distributed computation partitions the training data into multiple machines , each machine still needs to hold the values of all parameters to conduct local estimation . Since the log data usually contains millions of unique queries and URLs , the space of parameters is extremely large . For example , the real data set used in our experiments leads to more than 1030 parameters . Clearly , the EM algorithm in its original form cannot finish in practical time for even one round of iteration . To address this challenge , we develop a special initialization strategy based on the clusters mined from the click through bipartite . We will show in Section 4.2 that , in practice , our initialization strategy reduces the number of parameters to be re estimated in each round of iteration to a much smaller number . Moreover , theoretically the number has an upper bound . 4.1 Distributed Learning of Parameters
Map Reduce is a programming model for distributed processing of large data sets [ 9 ] . In the map stage , each machine ( called a process node ) receives a subset of data as input and produces a set of intermediate key/value pairs . In the reduce stage , each process node merges all intermediate values associated with the same intermediate key and outputs the final computation results .
In our learning process , we first partition the training data into subsets and distribute each subset to a process node . In the map stage , each process node scans the assigned subset of training data once . For each training session On , the process node infers the posterior probability pn,m = P ( Sm|On , Θ(i−1 ) ) by Equation 4 for each possible state sequence Sm and emits the key/value pairs as shown in Table 3 .
Key si
( si , qj )
( si , uj )
( si , Sj )
Value V aluen,1 = V aluen,2 = V aluen,1 = V aluen,2 = V aluen,1 = V aluen,2 = V aluen,1 = V aluen,2 = m pn,mδ(sm,1 = si ) m pn,m m pn,m m pn,m m pn,m m pn,m m pn,mδ(∃t St−1 m pn,mδ(∃t St−1 t δ(sm,t = si ∧ qj = qn,t ) t δ(sm,t = si ) t δ(sm,t = si ∧ uj ∈ Un,t ) t δ(sm,t = si ) m = Sj ∧ sm,t = si ) m = Sj )
Table 3 : The key/value pairs emitted at the map stage . i V aluei,1 i V aluei,2
In the reduce stage , each process node collects all values for an intermediate key . For example , suppose the intermediate key si is assigned to process node nk . Then nk receives a list of values {(V aluei,1 , V aluei,2)} ( 1 ≤ i ≤ N ) and de . The other parameters , P ( q|si ) , rives P ( si ) by P ( u|si ) , and P ( si|Sj ) are computed in a similar way . 4.2 Assigning Initial Values In the vlHMM model , we have four sets of parameters , the initial state probabilities {P ( si)} , the query emission probabilities {P ( q|si)} , the URL emission probabilities {P ( u|si)} , and the transition probabilities {P ( si|Sj)} . Suppose the number of states is Ns , the number of unique queries is Nq , the number of unique URLs is Nu , and the maximal length of a training session is Tmax . Then , |{P ( si)}| = Ns ,
Tmax t=2 N t
Tmax
|{P ( q|si)}| = Ns · Nq , |{P ( u|si)}| = Ns · Nu , |{P ( si|Sj)}| = s , and the total number of parameters is N = Ns·(1+Nq +Nu+ ) . Since a search log may contain millions of unique queries and URLs , and there may be millions of states derived from the click through bipartite , it is impractical to estimate all parameters straightforwardly . Can we reduce the number of parameters that need to be reestimated in each round of iteration ? t=2 N t−1 s
Our idea is to take the advantage on the semantic correlation among queries , URLs , and search intents . For example , a user is unlikely to raise the query “ Harry Potter ” to search for the official web site of Beijing Olympic 2008 . Similarly , a user who raises query “ Beijing Olympic 2008 ” is unlikely to click on the URL http://harrypotterwarnerbroscom This observation suggests that , although we have a huge space of possible parameters , the optimal solution is sparse – the values of most emission and transition probabilities are zero .
To reflect the inherent relationship among queries , URLs , and search intents , we can assign the initial parameter values based on the correspondence between a cluster Ci = ( Qi , Ui ) and a state si . As illustrated in Table 2 , the queries Qi and the URLs Ui of a cluster Ci are semantically correlated and jointly reflect the search intent represented by state si . As a possible method , we may assign a nonzero probability to P ( q|si ) and P ( u|si ) , respectively if q ∈ Ci and u ∈ Ci . However , such assignments make the model deterministic since each query can belong to only one cluster . Alternatively , we can conduct random walks on the clickthrough bipartite . P ( q|si ) ( P ( u|si ) ) can be initialized as the average probability of the random walks that start from q ( u ) and stop at the queries ( URLs ) belonging to cluster Ci . However , as indicated in [ 6 ] , the click through bipartite is highly connected – there may exist paths between two completely unrelated queries or URLs . Consequently , random walks may assign undesirable large emission probabilities to queries and URLs generated by an irrelevant search intent . We design an initialization strategy to balance the above two approaches . We apply random walks up to a restricted number of steps . Such an initialization allows a query ( as well as a URL ) to represent multiple search intents , and at the same time avoids the problem of assigning undesirable large emission probabilities . We limit random walks within two steps . First , we exi ) where Q i , U i = ( Q pand each cluster Ci = ( Qi , Ui ) into C is a set of queries such that each query q ∈ Q i i is connected to at least one URL u ∈ Ui in the click through bipartite , and U i is connected to at least one query q ∈ Q i . Then , we assign P 0(q|si ) = Count(q,u ) and P 0(u|si ) =
Count(q,u ) , where Count(·,· ) is the number i is a set of URLs such that each URL u ∈ U
Count(q,u )
Count(q,u ) u∈U u∈U q∈Q q∈Q i i i i q∈Q i u∈U i of times that a URL is clicked as an answer to a query in the search log .
The initial emission probabilities have the following nice property .
Lemma 1 . The query emission probability at the i th round of iteration P i(q|si ) = 0 if the initial value P 0(q|si ) = 0 .
Proof . The denominator in Equation 6 is a constant . Thus , we only need to consider the numerator . For any
WWW 2009 MADRID!Track : Data Mining / Session : Learning195 pair of On and Sm , if On does not contain query q , the enumerator is zero since t δ(sm,t = si ∧ qn,t = q ) = 0 .
( cid:180 )
( cid:179 )
( cid:179 )
Suppose On contains query q . Without loss of generality , suppose q appears in On only at step t1 , ie , qn,t1 = q . If sm,t1 = si , then the enumerator is zero since t δ(sm,t = ( cid:180 ) si ∧ qn,t = q ) = δ(sm,t1 = si ∧ qn,t1 = q ) = 0 . Last , if sm,t1 = si and qn,t1 = q , P ( On|Sm , Θ(i−1 ) ) = P ( i−1)(q|si)· t P ( i−1)(Un,t|sm,t ) Therefore , if P ( i−1)(q|si ) ) = 0 , P ( On|Sm , Θ(i−1 ) ) = 0 , and thus P ( Sm|On , Θ(i−1 ) ) = 0 ( Equation 4 ) . In summary , for any On and Sm , if P ( i−1)(q|si ) = 0 , t δ(sm,t = si ∧ qn,t = q ) = 0 and P i(q|si ) = 0 . By induction , we have P i(q|si ) = 0 if P 0(q|si ) = 0 .
P ( Sm|On , Θ(i−1 ) ) ·
P ( i−1)(qn,t|sm,t ) t=t1
·
.
Similarly , we can show the following .
Lemma 2 . The URL emission probability at the i th round of iteration P i(u|si ) = 0 if the initial value P 0(u|si ) = 0 .
Based on Lemmas 1 and 2 , for each training session On , we can construct a set of candidate state sequences Γn which are likely to generate On . To be specific , let qn,t and {un,t,k} be the t th query and the t th set of clicked URLs in On , respectively , and Candn,t be the set of states s such that ( P 0(qn,t|s ) = 0 ) ∧ ( ∀kP 0(un,t,k|s ) = 0 ) . From Equations 2 and 4 and Lemmas 1 and 2 , we have P ( Sm|On , Θ(i−1 ) ) = 0 for any Sm if sm,t ∈ Candn,t . Therefore , the set of candidate state sequences Γn for On can be constructed by joining Candn,1 , . . . , Candn,Tn . It is easy to see that for any Sm ∈ Γn , P ( Sm|On , Θ(i−1 ) ) = 0 . In other words , for each training session On , only the state sequences in Γn are possible to contribute to the update of parameters in Equations 5 8 . After constructing candidate state sequences , we assign the values to P 0(si ) and P 0(si|Sj ) as follows . First , we compute the whole bag of candidate state sequences Γ+ = Γ1 + . . . + ΓN , where ‘+’ denotes the bag union operation , and N is the total number of training sessions . We then assign P 0(si ) = Count(si ) , where Count(si ) , Count(Sj ) , Count(Sj◦si ) are the numbers of the sequences in Γ+ that start with state si , subsequence Sj , and the concatenations of Sj and si , respectively . and P 0(si|Sj ) = Count(Sj◦si )
Count(Sj )
|Γ+|
The above initialization limits the number of active parameters ( ie , the parameters updated in one iteration of the training process ) to an upper bound C as indicated in the following theorem .
Theorem 1 . Given training sessions X = {O1 . . . ON} and the initial values assigned to parameters as described in this section , the number of parameters updated in one iteration of the training of a vlHMM is at most
C = Ns · ( 1 + Nsq + Nsu ) + |Γ| · ( T − 1 ) , where Ns is the number of states , Nsq and Nsu are the average sizes of {P 0(q|si)| P 0(q|si ) = 0} and {P 0(u|si)| P 0(u|si ) = 0} over all states si , respectively , Γ is the set of unique state sequences in Γ+ , and T is the average length of the state sequences in Γ .
Proof . Let(cid:102)Ψi,(cid:102)∆i,(cid:102)Λi ing Lemmas 1 and 2 , we immediately have |(cid:102)Λi u be the sets of active initial state probabilities , transition probabilities , query and URL emission probabilities in the i th iteration , respectively . Usq| ≤ Ns · Nsq q and ( cid:102)Λi u| ≤ Ns · Nsu . Moreover , from the construction of Γ , we can see that , in any iteration of the training process , any state sequences Sm ∈ Γ cannot contribute to the update of and |(cid:102)Λi P ( si ) and P ( si|Sj ) . Therefore , |(cid:102)Ψi| ≤ |{P 0(si)| P 0(si ) = 0}| ≤ Ns and |(cid:102)∆i| ≤ |Γ| · ( T − 1 ) .
In practice , the upper bound C given by Theorem 1 is often much smaller than the size of the whole parameter space N = Ns · ( 1 + Nq + Nu + ) . For example , in our experimental data , Nsq = 4.5 ( cid:191 ) Nq = 1.8 × 106 , Nsu = 47.8 ( cid:191 ) Nu = 8.3×106 , and |Γ|·(T −1 ) = 1.4×106 ( cid:191 ) t=2 N t−1
Tmax s
Ns ·Tmax t=2 N t−1 s = 4.29 × 1030 .
Our initialization strategy also enables an efficient training process . According to Equations 5 8 , the complexity of the training algorithm is O(k · N ·|Γn| ) , where k is the number of iterations , N is the number of training sessions , and Γn is the average number of candidate state sequences for a training session . In practice , Γn is usually small , eg , 4.7 in our experiments . Although N is a very large number ( 840 million in our experiments ) , we can distribute the training sessions on multiple machines as discussed in Section 41 Our empirical study shows that the training process converges fast . In our experiments , k is around 10 .
5 . MODEL APPLICATION
In this section , we discuss how to apply the learned vlHMM to various search applications including document re ranking , query suggestion and URL recommendation .
Suppose the system receives a sequence O of user events , where O consists of a sequence of queries q1 , . . . , qt , and for each query qi ( 1 ≤ i < t ) , the user click on a set of URLs Ui . We first construct the set of candidate state sequences ΓO as described in Section 4.2 and infer the posterior probability P ( Sm|O , Θ ) for each state sequence Sm ∈ ΓO , where Θ is the set of model parameters learned offline . We can derive the probability distribution of the user ’s current state st by P ( st|O , Θ ) = , where δ(sm,t = st ) indicates whether st is the last state of Sm ( =1 ) or not ( =0 ) .
P ( Sm|O,Θ)·δ(sm,t=st )
P ( Sm|O,Θ )
Sm∈Γo
Sm∈Γo
Sm∈Γo
One strength of the vlHMM is that it provides a systematic approach to not only inferring the user ’s current state st , but also predicting the user ’s next state st+1 . Specifically , P ( st+1|Sm ) · P ( Sm|O , Θ ) , we have P ( st+1|O , Θ ) = where P ( st+1|Sm ) is the transition probability learned offline . To keep our presentation simple , we omit the parameter Θ in the remaining part of this section . Once the posterior probability distributions of P ( st|O ) and P ( st+1|O ) have been inferred , we can conduct the following context aware actions . Document re ranking . Let St = {st| P ( st|O ) = 0} and U be a ranked list of URLs returned by a search engine as the answers to query qt . We compute the posterior probability P ( u|O ) for each URL u ∈ U by st∈S P ( u|st)· P ( st|O ) . Then , we re rank the URLs in the posterior probability descending order . Query suggestion . Let St+1 = {st+1| P ( st+1|O ) = 0} and Qt+1 = {q| st+1 ∈ St+1 , P ( q|st+1 ) = 0} . For each query q ∈ Qt+1 , we compute the posterior probability P ( q|O ) = P ( q|st+1 ) · P ( st+1|O ) , and suggest the top Kq queries with the highest probabilities , where Kq is a userspecified parameter . st+1∈St+1
WWW 2009 MADRID!Track : Data Mining / Session : Learning196 URL recommendation . Let Ut+1 = {u| st+1 ∈ St+1 ,
P ( u|st+1 ) = 0} . For each URL u ∈ Ut+1 , we compute P ( u|st+1 ) · the posterior probability P ( u|O ) = P ( st+1|O ) , and recommend the top Ku URLs with the highest probabilities , where Ku is a user specified parameter . st+1∈St+1
There are two issues in the online application of the vlHMM . First , users may raise new queries and click URLs which do not appear in the training data . In the i th ( 1 ≤ i < t ) round of interaction , if either the query or at least one URL has been seen by the vlHMM in the training data , the vlHMM can simply ignore the unknown queries or URLs , and still make the inference and prediction based on the remaining observations ; otherwise , the vlHMM just skips this round . If the current query qt is unknown to the vlHMM , the vlHMM takes no action .
Second , the online application of our vlHMM may have a strong requirement on efficiency . Given a user input sequence O , the major cost in applying the vlHMM depends on the sizes of the candidate sets ΓO , St , St+1 , Qt+1 , and Ut+1 . In our experiments , the average numbers of ΓO , St , and St+1 are all less than 10 and the average numbers of Qt+1 and Ut+1 are both less than 100 . Moreover , the average runtime of applying the vlHMM to one user input sequence is only 0.1 millisecond .
In cases where the sizes of candidate sets are very large or the session is extremely long , we can approximate the optimal solution by discarding the candidates with low probabilities or truncating the session . Since we only re rank the top URLs returned by a search engine and suggest the top queries and URLs generated by the vlHMM , such approximations will not lose much accuracy . 6 . EXPERIMENTAL RESULTS
In this section , we report the results from a systematic empirical study using a large search log from a major commercial search engine . We examine the efficiency of our vlHMM training method and the effectiveness of using the learned vlHMM in context aware document re ranking , query suggestion , and URL recommendation . 6.1 Data Set and Preparation
We use a large search log from a major commercial search engine to train a vlHMM . We only focus on the Web searches in English from the US market . The log data set contains 1.8 billion queries , 2.6 billion clicks , and 840 million sessions . The data set involves 151 million unique queries and 114 million unique URLs .
From the raw search log , we first extract user sessions as described in Section 3 . Since we want to train a vlHMM to model the common search behavior of the crowds , infrequent sessions should be removed . However , we find that user sessions , especially long sessions , are extremely sparse . If we aggregate directly on the search sequences which include both queries and clicks , most of the sessions will be pruned . Therefore , instead of counting the frequencies of search sequences , we count the frequencies of query sequences . To be specific , we remove a user session ( q1 , U1 ) , . . . , ( qT , UT ) only if the frequency of the query sequence ( q1 , . . . , qT ) is less than a threshold min sup . In our experiments , min sup is set to 5 . Consequently , 48 % of the sessions in the log data set are pruned .
We examine the distribution of the lengths of the surviving sessions and find it follows the power law . Moreover ,
Num . of unique queries Num . of unique URLs Num . of query occurrences Num . of clicks Num . of sessions
Raw search log Training data 1,835,270 8,309,988 926,442,156 1,321,589,933 437,245,177
151,869,102 114,882,486 1,812,563,301 2,554,683,191 840,356,624
Table 4 : The data statistics before and after the pre processing .
( a )
( b )
Figure 2 : The number of states with respect to the number of nonzero initial ( a ) query and ( b ) URL emission probabilities . more than 50 % of the sessions contain at least two rounds of interaction . These observations are consistent with those in previous studies ( eg , [ 13] ) . We manually inspect some sessions with lengths longer than 5 , and find many of them contain meaningless query sequences . We suspect that those sessions were generated by bots . To reduce those noise sessions , we further remove the sessions longer than 5 . There are 22 , 919 such sessions , about 0.005 % of the whole data set .
Table 4 shows the statistics of the data set before and after the pre processing . Although 98.8 % unique queries and 92.8 % unique URLs are removed by the pre processing , the resulting data set still keeps 51.1 % of the original query occurrences , 51.7 % of the original URL clicks , and 52 % of the original user sessions . As shown in many previous works ( eg , [ 2] ) , this is because the query occurrences and URL clicks in search logs follow the power law distribution . 6.2 Efficiency of Training the vlHMM
To determine the number of states and assign initial parameter values , we apply the clustering algorithm in [ 6 ] and derive 1,346,146 clusters of queries . We thus have 1,346,146 states in the vlHMM , and then initialize the parameter values as described in Section 42 As an example , Table 2 shows the initial emission probability distribution of state s753 . For all queries q and URLs u not in the table , P 0(q|s753 ) and P 0(u|s753 ) are set to 0 .
Figures 2(a ) and 2(b ) show the distributions of the number of states with respect to the number of nonzero initial query and URL emission probabilities , respectively . Both approximately follow the power law distribution . Let Nsq and Nsu be the average numbers of nonzero parameters P 0(q|s ) and P 0(u|s ) in all states , respectively . In our experiments , Nsq = 4.5 and Nsu = 478 It means that on average , different users formulate 4.5 queries and click 47.8 URLs for a common search intent .
We further compute the set of candidate state sequences
100102104101103100102104106101103105Number of queriesNumber of states distributionpower law : a * x−1.98100102103104101105100105101102103104Number of URLsNumber of states distributionpower law : a * x−1.44WWW 2009 MADRID!Track : Data Mining / Session : Learning197 #P ( si ) #P ( q|si ) #P ( u|si ) #P ( si|Sj )
Actual number Upper bound Whole space 1,346,146 2.47 × 1012 1.12 × 1013 4.29 × 1030
1,346,146 6,057,657 64,345,778 1,399,498
1,146,346 3,513,441 56,624,285 1,275,708
Table 5 : Comparison of the actual number , the upper bound , and the whole space of the parameters .
( a )
( b )
Figure 3 : The ( a ) value of Q(Θ , Θ(i−1 ) ) and ( b ) average difference of all parameters in one iteration .
Γ given the initialization of P 0(q|s ) and P 0(u|s ) . For the 437 , 245 , 177 training sessions , there are only 2 , 621 , 854 unique candidate state sequences , since users with similar search intents often have similar search sequences , and thus can be modeled by the same state sequence . This verifies the power of a vlHMM as a compact statistical model to summarize the huge search logs .
Table 5 compares the size of the whole parameter space , the actual number of parameters estimated in the training process , and the upper bound given by Theorem 1 . Clearly , the actual number of estimated parameters is dramatically smaller than the size of the whole parameter space and the upper bound is tight . In particular , the actual number of estimated transition parameters is smaller than the size of the parameter space by a factor of 1024 . There are two reasons for this factor . First , as mentioned in Section 6.1 , the session length follows the power law distribution and a large part of sessions are short – of length 1 or 2 . Second , queries and clicked URLs in the same sessions are semantically related . Thus , the actual number of state sequences appeared in logs is dramatically smaller than that of all possible combinations . Figures 3(a ) and 3(b ) show the value of the object function Q(Θ , Θ(i−1 ) ) and the average difference of all parameters in one iteration , respectively . Clearly , the training process converges fast under our initialization method .
Last , we test the runtime and scalability of the training algorithm . Since we run the training algorithm on a distributed system shared by multiple users , it is hard to measure the exact runtime of the training process . Thus , we simulate a process node in the distributed system by a standalone server using an Intel Core 2 2.0 GHZ ×2 CPU , 4 GB main memory , and test the runtime and the scalability on sampled subsets of the whole training data of different sizes . For each size , we randomly sample a subset 10 times and report the average result on the random samples in Figures 4 . By using our initialization method , the training algorithm is efficient and scales up well .
( a )
( b )
Figure 4 : The ( a ) runtime and ( b ) number of parameters of the training process on different sizes of sampled data .
6.3 Effectiveness of vlHMMs
To evaluate the effectiveness of the trained vlHMM , we extract 100 , 000 sessions as the test data set from a separate search log other than the one used as the training data set . We use each session ( q1 , U1 ) , . . . , ( qT , UT ) in the test set to test the vlHMM . First , the vlHMM performs re ranking , suggestion , and recommendation , for query q1 . Second , U1 is sent to the vlHMM as the URLs clicked by a user for q1 , and query q2 is sent to the vlHMM as the next query . The vlHMM then performs re ranking , suggestion , and recommendation for q2 based on the context introduced by q1 and U1 . Generally , a session of length T is treated as a sequence of T test cases where each case corresponds to a query .
We call a test case is covered by the vlHMM if the query can be recognized and the model can perform the corresponding re ranking , suggestion , and recommendation . The coverage of the vlHMM is 583 % The uncovered queries are tail queries which either do not appear in the raw training log or have been removed in the pre processing due to a very low frequency .
To better examine the effectiveness of context information , we further divide the test cases into two subsets : Test0 contains the cases of the first queries in the sessions , that is , no context is available ; and Test1 contains the others . In Test1 , the contexts of 25.5 % of the covered cases can be recognized by the vlHMM . This indicates that , in many cases when context is available , the vlHMM is able to exploit such information .
In our implementation of the vlHMM , we use a set of queries Q and a set of URLs U to represent each state . Since the queries and URLs are very sparse in the log data , the coverage of the vlHMM and the percentage of recognized contexts are not high . In fact , we can simply expand the vlHMM learned from log data by building a language model [ 16 ] for each state based on the document text of the URLs in U . In this way , the ability of the vlHMM to generalize to unknown queries and URLs will be greatly enhanced , and the coverage as well as the percentage of recognized contexts will be improved substantially .
631 Document Re ranking We evaluate the quality of document re ranking using the trained vlHMM on the top 10 results from a commercial search engine . We randomly select 500 re ranked pairs of documents from the covered test cases in Test0 and 500 pairs from the cases in Test1 where the context can be recognized
024681012−322−32−318−316−314−312−31−308−306x 108IterationQ(Θ , Θi−1)0246810120001002003004005IterationAvg update of all params0510152025300200400600800100012001400Training data(%)Run time(s)05101520253001234567x 107Training data(%)Number of parametersWWW 2009 MADRID!Track : Data Mining / Session : Learning198 Context
Test query
Re ranked document pairs online games
↓ http://gamesyahoocom http://wwwminiclipcom ask.com
↓ http://wwwaskcom
1
2
Disney channel
Ask Jeeves
↑ Games Disney Channel http://tvdisneygocom/disneychannel/games/indexhtml
↓ Disney Channel http://wwwdisneygocom/disneychannel
↑ Ask Jeeves : Wikipeadia Free encyclopeida http://enwikipediaorg/wiki/Ask Jeeves#International
↓ Ask.com Search Engine , Better Web Search http://wwwaskcom
Table 6 : Examples of re ranked documents pairs by the vlHMM . by the model . For each test case , we present the test query to 3 judges and ask them to compare the relevance of the document pair . For cases from Test1 , the judges are also presented with the past queries and clicked URLs of the test query . For a pair of documents A and B , there are three labels : A is more relevant than B , A is less relevant than B , and unsure .
( a )
( b )
Figure 5 : The effectiveness of re ranking by the vlHMM and Bbaseline1 on ( a ) Test0 and ( b ) Test1 .
The existing re ranking methods either do not consider the click through information ( eg , [ 24 ] ) or combine clickthrough information with other features such as document text ( eg , [ 25] ) . It is not meaningful to make a direct comparison between our method and those existing methods . We use a baseline ( denoted by Baseline1 ) which purely relies on click through data , ie , to re rank documents A and B if the order of their click numbers with respect to the test query is reversed with their original order . One difference between Baseline1 and the vlHMM is that the former does not consider the context of the test query .
Figures 5(a ) and 5(b ) compare the quality of re ranking performed by vlHMM and Baseline1 . In the figures , the “ Improved ” category counts the cases where re ranking improves the ordering of the documents , while “ Degraded ” counts the opposite cases . The unsure cases are not counted . The vlHMM has a comparable performance with Baseline1 for cases in Test0 where context information is not available ( Figure 5(a) ) . However , in Test1 , while the baseline achieves a similar performance as in Test0 , the vlHMM shows a substantial gain ( Figure 5(b) ) . This clearly indicates that the vlHMM is effective to model the context information and thus understands users’ search intents better .
Table 6 shows two examples of re ranked document pairs by the vlHMM . In the first example , when a user raises query “ Disney channel ” , the search engine ranks the homepage of
Disney Channel higher than its game site . The vlHMM is able to consider the context that the user actually searches online games before this query , and accordingly boosts the game site on top of the homepage .
In the second example , the user inputs query “ Ask Jeeves ” . Unsurprisingly , wwwaskcom is ranked higher than the wikipedia page about the company . However , the vlHMM notices that the user input query “ ask.com ” and clicked www . ask.com before query “ Ask Jeeves ” . This context provides the hint that the user may not be interested in the search service provided by wwwaskcom but instead be interested in the background information of the company . Consequently , the vlHMM boosts the wikipedia page . 632 URL Recommendation and Query Suggestion We evaluate the performance of the vlHMM on URL recommendation using the “ leave one out ” method . Specifically , for each extracted session O = ( q1 , U1 ) , . . . , ( qT , UT ) , we use qT−1 as the test query and consider UT , the set of URLs really clicked by the user , as the ground truth . The performance is then measured by precision and recall . Suppose the vlHMM model recommends a set of URLs R , the precision is and the recall is
|R∩UT |
|R∩UT | |UT |
.
|R|
Since there has been little work on URL recommendation using search logs , we use a baseline ( denoted by Baseline2 ) which borrows the idea from [ 23 ] where browsing logs rather than search logs are used . Given a test query q , Baseline2 counts in the training data the frequency of a URL occurring in the interactions following the round of q , and recommends the top K URLs with the highest co occurring frequencies . Baseline2 does not consider the context of q .
Figures 6(a ) and 6(b ) compare the precision of the vlHMM and Baseline2 with respect to the number of recommendations K in Test0 and Test1 , respectively , while Figures 6(c ) and 6(d ) compare the recall . In both methods and in both test sets , the precision drops and the recall increases when K increases . Although the vlHMM and Baseline2 have comparable precision and recall in Test0 , the vlHMM outperforms the baseline substantially in Test1 , where the context information is available .
Table 7 shows an example of URL recommendation when the user inputs query “ Walmart ” . Without considering the context , Baseline2 recommends the homepage of Sears as the first choice . Although this recommendation is meaningful , if we consider the user searched “ circuit city ” before , the URL wwwbestbuycom recommended by the vlHMM looks a better choice .
Last , we follow the evaluation method described in [ 6 ] to compare the quality of query suggestions generated by
ImprovedDegraded05101520253035404550Percentage( % ) Baseline1vlHMMImprovedDegraded05101520253035404550Percentage( % ) Baseline1vlHMMWWW 2009 MADRID!Track : Data Mining / Session : Learning199 ( a ) Precision on Test 0
( b ) Precision on Test1
( c ) Recall on Test0
( d ) Recall on Test1
Figure 6 : The precision and recall of the URLs recommended by the vlHMM and Baseline2 . circuit city → http://wwwcircuitcitycom
Context : Test query : Walmart
URL recommendation vlHMM
Baseline2 http://wwwbestbuycom http://wwwsearscom
Table 7 : An example of URL recommendation . vlHMM and CACB [ 6 ] . Since both methods consider the context information , we find the qualities of query suggestions by the two methods are comparable . We also compare the percentage of recognized contexts by the two methods . Among the covered test cases in Test1 , the CACB can only recognize the contexts of 16.5 % cases , while the vlHMM improves the coverage by 55 % . The reason is that the vlHMM considers both queries and clicked URLs in the context , and is able to recognize the context when either the queries or clicked URL are seen in the training data . Moreover , as mentioned before , the coverage and the percentage of recognized contexts of vlHMM can be readily improved via the URLs in the states , while the expansion for CACB is not straightforward since CACB only considers queries .
In summary , the extensive empirical study using a large real data set from a major commercial search engine clearly verifies that our vlHMM method is effective in context aware search , and is efficient in model learning .
7 . CONCLUSIONS
In this paper , we propose a general approach to contextaware search by learning a vlHMM from search sessions extracted from log data . We tackle the challenges of learning a large vlHMM with millions of states from hundreds of millions of search sessions by developing a strategy for parameter initialization which can greatly reduce the number of parameters to be estimated in practice . We also devise a method for distributed vlHMM learning under the mapreduce model . The experimental results on a large real data set clearly show that our context aware approach is both effective and efficient .
8 . REFERENCES [ 1 ] Baeza Yates , RA , et al . Query recommendation using query logs in search engines . In EDBT 2004 Workshop on Clustering Information over the Web , pages 588–596 , 2004 . [ 2 ] Baeza Yates,RA , et al . Extracting semantic relations from query logs . In KDD’07 , pages 76–85 , 2007 .
[ 3 ] Bai , J . , et al . Using query contexts in information retrieval .
In SIGIR’07 , pages 15–22 , 2007 .
[ 4 ] Baum , LE , et al . A maximization technique occurring in the statistical analysis of probabilistic functions of markov chains . Ann . Math . Statist . , 41(1):164–171 , 1970 .
[ 5 ] Beeferman , D . , et al . Agglomerative clustering of a search engine query log . In KDD’00 , pages 407–416 , 2000 .
[ 6 ] Cao , H . , et al . Context aware query suggestion by mining click through and session data . In KDD’08 , pages 875–883 , 2008 .
[ 7 ] Chirita , PA , et al . Personalized query expansion for the web . In SIGIR’07 , pages 7–14 , 2007 .
[ 8 ] Chu , CT , et al . Map reduce for machine learning on multicore . In NIPS , pages 281–288 , 2006 .
[ 9 ] Dean , J . , et al . MapReduce : simplified data processing on large clusters . In OSDI’04 , pages 137–150 , 2004 .
[ 10 ] Dempster , AP , et al . Maximal Likelihood from Incomplete
Data Via the EM Algorithm . Journal of the Royal Statistical Society , Ser B(39):1–38 , 1977 .
[ 11 ] Durbin , R . , et al . Biological sequence analysis : probabilistic models of proteins and nucleic acids . Cambridge University Press , 1998 .
[ 12 ] Fonseca , BM , et al . Concept based interactive query expansion . In CIKM’05 , pages 696–703 , 2005 .
[ 13 ] Huang , C . , et al . Relevant term suggestion in interactive web search based on contextual information in query session logs . Journal of the American Society for Information Science and Technology , 54(7):638–649 , 2003 .
[ 14 ] Joachims , T . , et al . Optimizing search engines using clickthrough data . In KDD’02 , pages 133–142 , 2002 .
[ 15 ] Jones , R . , et al . Generating query substitutions . In
WWW’06 , pages 387–396 , 2006 .
[ 16 ] Liu , X . , et al . Cluster based retrieval using language models . In SIGIR’04 , pages 186–193 , 2004 .
[ 17 ] Rabiner , LR A tutorial on hidden Markov models and selected applications inspeech recognition . Proceedings of the IEEE , 77(2):257–286 , 1989 .
[ 18 ] Rocchio , J . Relevance feedback information retrieval .
Prentice Hall Inc . , 1971 .
[ 19 ] Sugiyama , K . , et al . Adaptive web search based on user profile constructed without any effort from users . In WWW’04 , pages 675–684 , 2004 .
[ 20 ] Tao , T . and Zhai , C . A two stage mixture model for pseudo feedback . In SIGIR’04 , pages 486–487 , 2004 .
[ 21 ] Wang , Y . , et al . Mining complex time series data by learning Markovian models . In ICDM’06 , pages 1136–1140 , 2006 .
[ 22 ] Wen , J . , et al . Clustering user queries of a search engine . In
WWW’01 , pages 162–168 , 2001 .
[ 23 ] White , RW , et al . Studying the use of popular destinations to enhance web search interaction . In SIGIR’07 , pages 159–166 , 2007 .
[ 24 ] Xu , J . , et al . AdaRank : A boosting algorithm for information retrieval . In SIGIR’07 , pages 391–398 , 2007 .
[ 25 ] Zhao , M . , et al . Adapting document ranking to users preferences using click through Data . In AIRS’06 , pages 26–42 , 2006 .
123450010203040506Average precisonK Baseline2vlHMM123450010203040506Average precisonK Baseline2vlHMM123450020406081Average recallK Baseline2vlHMM123450020406081Average recallK Baseline2vlHMMWWW 2009 MADRID!Track : Data Mining / Session : Learning200
