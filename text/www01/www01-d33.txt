On Integrating Catalogs
Rakesh Agrawal
Ramakrishnan Srikant
IBM Almaden Research Center
650 Harry Road
San Jose , CA 95120 , USA
ABSTRACT We address the problem of integrating documents from different sources into a master catalog . This problem is pervasive in web marketplaces and portals . Current technology for automating this process consists of building a classifier that uses the categorization of documents in the master catalog to construct a model for predicting the category of unknown documents . Our key insight is that many of the data sources have their own categorization , and classification accuracy can be improved by factoring in the implicit information in these source categorizations . We show how a Naive Bayes classification can be enhanced to incorporate the similarity information present in source catalogs . Our analysis and empirical evaluation show substantial improvement in the accuracy of catalog integration .
Keywords : Classification , Categorization , Data Mining , Catalog Integration , Web Portals , Web Marketplaces
1 .
INTRODUCTION
Imagine you are a marketplace for electronic components . Your catalog features nearly ten million parts categorized into 5000 categories . Noticing your success , a major distributor wants to join your marketplace . This distributor ’s catalog contains nearly a million parts categorized into 2000 categories . Your problem is how to quickly integrate this distributor ’s catalog into your catalog .
This problem is pervasive on the web , given many websites are aggregators of information from various sources . B2C shops like Amazon need to integrate catalogs from multiple vendors . B2B portals , Chipcenter and Questlink , each with a large catalog of their own , recently merged to form eChips . Information portals like Yahoo! and Google categorize documents into categories . One can easily conceive a web service that combines the two portals . Many corporate portals are now merging intra company and external information into a uniform categorization .
This paper presents a new technique to help automate the task of catalog integration . Let us call your marketplace MrCurrent and
Copyright is held by the author/owner . WWW10 , May 1 5 , 2001 , Hong Kong . ACM 1 58113 348 0/01/0005 . the distributor who wants to join you MrNew . A straightforward approach to attacking the catalog integration problem would be to formulate it as a classification problem [ 13 ] . Take the MrCurrent catalog , treat each category in the catalog as a class , and the information about the products belonging to each category as training examples for the corresponding class . We thus have a well posed classification problem and a training set and we can build a predictive model for classifying MrNew ’s products into MrCurrent ’s categories .
Our key contribution is how to incorporate the implicit information contained in MrNew ’s catalog into the classification process . We show that this additional information can substantially boost classification accuracy . 1.1 Problem Statement
Notice , however , in this straightforward approach , we completely ignored MrNew ’s categorization . On the other hand , MrNew ’s categorization contains valuable implicit information about product similarity . Suppose the classifier ’s prediction is such that 98 % of the products belonging to some category in MrNew ’s catalog fall in one category in MrCurrent ’s catalog and 2 % in a different category . Those 2 % predictions are quite possibly errors , but it will also be a mistake to take a winner takes all attitude and assume that those 2 % are necessarily errors .
A documentd is an object consisting of i ) a set of words , and/or ffl A master catalogM with a set of categoriesC ;C ;:::;Cn ffl A source catalogN with a set of categoriesS ;S ;:::;Sm We need to find the category inM for each document inN .
We now formally define the catalog integration problem we are ii ) a set of attribute value pairs . By including attribute value pairs , we are able to cover both text documents as well as product descriptions .
A catalog is a partitioning of a set of documents into a set of categories1 . We are given two catalogs : solving . and a set of documents in each category . and another set of documents .
Catalogs are often organized as hierarchies . We assume that any documents assigned to an interior node really belong to a conceptual leaf node that is a child of that interior node . Since we now have documents only at leaf nodes , we can flatten the hierarchy to a single level and treat it as a set of categories . Note that a document can still belong to multiple leaf nodes , but documents are only in leaf nodes and not interior nodes . overlap .
1.2 Limitations
An assumption underlying our model is that the categorizations
We optionally identify documents inN that do not fit well in M and give the user the option of adding these as new categories inM . used by catalogsM andN are homogenous and have significant It is possible that the categorizations used byM and N may be completely orthogonal to each other . For instance , contion inM is by business type , whereas the categorization inN is N will not help us better categorize the documents intoM . inN is quite different fromM , the classification accuracy will cerof using the similarity information inN . inN can be easily incorporated in a Naive Bayes hierarchical clasAnother issue related to hierarchies is that the hierarchy inM may be more detailed thanN or vice versa . IfM is more detailed thanN , our technique can still be helpful . For example , ifN has a category “ Cars ” , whileM has “ Sports Cars ” and “ Sedans ” , our egories and say “ Trucks ” . On the other hand , ifN is more detailed thanM , the detailed categories inN can be first merged into a ments in the categories inN leads to better results . )
Our model flattens the catalog hierarchy and treats it as a set of categories . Past studies [ 6 ] [ 3 ] have shown that exploiting the hierarchical structure can lead to better classification results than using the flattened structure . Our enhancements for using the information super category and our technique can then be applied . ( While our technique would be effective even if applied without merging the detailed categories , we show in Section 5.2 that having more docu
Vocabulary changes are a problem for classification in general . For instance , it was observed in [ 9 ] that patents about similar inventions can contain very different terminology . If the vocabulary sifier , such as one used in [ 3 ] . Incorporation of these enhancements into other classification schemes , such as the SVM classifier used in [ 6 ] , requires further work . technique will not help distinguish between “ Sports Cars ” and “ Sedans ” . However , it will help distinguish between these two cat sider a corpus of documents describing businesses . The categoriza tainly be affected . However , this problem is orthogonal to the idea by geographical location . In such cases , the implicit information in
1.3 Related Work
Inducing classification model for a set of categories given examples of objects for each category is a much studied topic in the statistics , machine learning , and data mining literature . See , for instance , [ 13 ] for a comprehensive review of various classification techniques . Naive Bayes classifiers [ 7 ] are competitive with other techniques in accuracy [ 3 ] [ 10 ] [ 8 ] [ 15 ] [ 12 ] . They are also fast : building the model requires only a single pass over the documents and they quickly classify new documents . Our proposed solution is also Bayesian .
The observation that the classification techniques can be used to assign documents to a hierarchy has been previously made in connection with folder systems . Proposals on the development of classification models for the purpose of routing e mail include [ 1 ] [ 4 ] [ 16 ] [ 18 ] . Other systems provide agents that assist e mail users by predicting an action the user is likely to take [ 11 ] [ 14 ] . SONIA [ 17 ] uses agglomerative text clustering to organize the results of queries to networked information sources , and Naive Bayes clas sification to organize new documents within an existing categorization scheme . Text classification has also been applied in other domains , eg [ 5 ] showed how well SEC ( Security Exchange Commission ) filings can be classified into SIC categories . None of these systems address the task of merging hierarchies .
The Athena system [ 1 ] includes the facility of reorganizing a folder hierarchy into a new hierarchy . The user provides examples of documents for every node of the new hierarchy , which is used as the training set for learning the classification model for new hierarchy . The documents from old hierarchy are then routed to the new hierarchy using this model . But no information from the old hierarchy is used in either building the model or routing the documents . 1.4 Paper Organization
CATALOG INTEGRATION
The Naive Bayes classifier estimates the posterior probability of
2 . STRAIGHTFORWARD APPROACH TO
We start with a quick review of Naive Bayes classification and then give the basic algorithm that applies this technique for merging catalogs in a straightforward manner . 2.1 Naive Bayes Classification
The rest of the paper is organized as follows . In Section 2 , we review Naive Bayes classification and give the basic algorithm that applies this technique in a straightforward manner to merge documents from a source catalog into an existing catalog . In Section 3 , we present our enhanced algorithm that uses the implicit information in the source catalog to improve the accuracy of catalog integration . We present an analysis in Section 4 that shows why using implicit information is a win . We present an empirical evaluation in Section 5 that gives improvements in accuracy realized in our experiments . We conclude with a summary in Section 6 . categoryCi given a documentd via Bayes’ rule [ 13 ] : Pr(Cijd)=Pr(Ci)Pr(djCi ) Pr(d ) We can ignorePr(d ) since it is the same for all categories and we need only the relative probability of the categories to determined ’s category assignment.Pr(Ci ) is estimated by Pr(Ci)= Number of documents in categoryCi We treatPr(djCi ) as an input in our enhanced algorithm . We review here how to computePr(djCi ) only for the case of text , and that the words ind are independent of each other . We get Pr(djCi)="Yt dPr(tjCi)# attributes to computePr(djCi)=Pr(dtextjCi).Pr(dattrjCi ) , wheredtext is the text for the document description , anddattr the refer readers to [ 13 ] for extensions to the case when the document also contains a set of attribute value pairs.2
The essential idea is that if the document consists of both text and attributes , we can assume independence between the text and the
To estimate the first term on the right hand side of Eq 3 , assume
Total number of documents in the dataset which is easy to compute .
( 3 )
( 1 )
( 2 ) set of attributes for the document .
Figure 1 : Basic Algorithm using the statistics computed in Step 1 ( Eqs . 1 and 3 ) . compute the frequency of occurrence of every word appearing in any of the textual descriptions of the set of documents in cate
1 . For each categoryCi inM , computePr(Ci ) and Pr(tjCi ) . ( Eqs . 2 and 4 , respectively ) . 2 . For each categoryS inN : For each documentd inS : ( a ) ComputePr(Cijd ) for each categoryCi inM ( b ) Assignd to the category with the highest value forPr(Cijd ) . wheret represents the words ( tokens ) . To estimatePr(tjCi ) , we goryCi . Letn(Ci;t ) be the number of occurrences of wordt in documents in categoryCi ( counting multiple occurrences ) , and n(Ci)=Ptn(Ci;t ) the total number of words in documents in categoryCi . Then the maximum likelihood estimate forPr(tjCi ) is simplyn(Ci;t)=n(Ci ) . However , using this estimate would give documents in the category , and thus result inPr(djCi ) being zero for any documentd that contained a word not present in category Ci . Following [ 1 ] , we address this problem by using Lidstone ’s   , we estimatePr(tjCi ) to be Pr(tjCi)=n(Ci;t)+ n(Ci)+jVj wherejVj is the size of the vocabulary ( ie , the number of disestimaten(Ci;t)=n(Ci ) and the uniform prior =jVj . The optimal value of is computed by using a randomly selected subset of documents inM as a validation set , ie , we build the classification model using the rest ofM , and compute the accuracy of the model for different values of on the validation set . of documents already inM . This classification model is then used to place documents fromN intoM . ffl A documentd may be assigned to more than one category ( sayCi andCj ) ifPr(Cijd ) andPr(Cjjd ) both have high ffl If for some documentd , the value ofPr(Cijd ) is low for all the categories,d may be kept aside for manual classification , possibly into a new category ofM . ffl If for some categoryS inN , a large fraction of the documents satisfy the previous condition,S may be flagged as a candidate for becoming a new category ofM . racy by incorporating the implicit information present inN . For
Figure 1 presents the basic method that uses the standard Naive Bayes technique . We first build a classification model using the set tinct words in the textual descriptions in all of the documents ) . The above estimate is a linear interpolation of the maximum likelihood a probability of zero for any word that does not occur in any of the law of succession to smooth the maximum likelihood estimate . For
Our main focus in this paper is on boosting the classification accu
Note that depending on policy parameters :
2.2 Basic Algorithm values .
Our proposed method uses the similarity information implicit in
3 . ENHANCED ALGORITHM sification models . The intuition is that if two documents belong to ease of exposition , therefore , we assume in the remainder of the paper that each document inN is assigned to exactly one category inM . the categorization of documents inN to build more accurate clasthe same category inN , they are more likely to belong to the same category inM . LetS denote a category inN . We can extend Bayes rule from Eq 1 to incorporate the implicit information inS . We will use the standard notationPr(x;y ) to refer toPr(x andy ) . We also use Pr(S ) to refer toPr(d S ) , andPr(Ci ) to refer toPr(d Ci ) . The posterior probability of categoryCi inM given a documentd belonging to categoryS inN is computed as : Pr(Cijd;S ) =Pr(Ci;d;S ) Pr(d;S ) =Pr(Ci)Pr(S;djCi ) Pr(d;S ) =Pr(Ci)Pr(SjCi)Pr(djCi ) Pr(S;d ) assumingd,S are independent givenCi =Pr(S)Pr(CijS)Pr(djCi ) Pr(S;d ) sincePr(CijS)Pr(S)=Pr(SjCi)Pr(Ci ) =Pr(CijS)Pr(djCi ) Pr(djS ) Eq 5 is similar to Eq 1 , except that we havePr(CijS ) instead of Pr(Ci ) . ( We also havePr(djS ) instead ofPr(d ) in the denominaTo estimatePr(CijS ) , we first classify the documents using the basic algorithm , then use the categories of the documents inS to Pr(CijS)= Number of documents inS predicted to be inCi Total number of documents inS Pr(Ci ) ( Eq 2 ) , that equation was based on real frequencies , while perhaps .1/k fork other categories assuming the errors are evenly split among them . In this case , we would likePr(CijS ) to be 1 use an indexw  that reflects the similarity between the cate
As an illustration , consider a scenario where we know that the source catalog categories are identical to the master catalog categories . With a perfect classifier , the above estimate will be 1 for the true category and 0 for all other categories . With a classifier that is 90 % accurate , the estimate will be .9 for the true category , and for the category with the most number of documents , and 0 for the other categories , ie , use the majority rule . More generally , we can this equation is based on estimated frequencies . The accuracy of the estimate depends on the accuracy of the classifier . tor , but since this term is the same for all classes , it does not affect relative probabilities . )
However , while this equation is identical in form to the estimate for compute the estimate . A simple estimate could be :
( 5 ) gorization of the two catalogs to decide the amount of weight to give to the implicit information . We would also like to smooth our
( 4 )
Figure 2 : Enhanced Algorithm using the basic algorithm ( Figure 1 ) .
( b ) Use the results of Step 2(a)(ii ) and Eq 6 to
1 . For each categoryCi inM , computePr(Ci ) and Pr(tjCi ) ( Eqs . 2 and 4 , respectively ) . 2 . For each categoryS inN : ( a ) For each documentd inS : ( i ) ComputePr(Cijd ) for each categoryCi inM ( ii ) Tentatively assignd to the category with the highest value forPr(Cijd ) . computePr(CijS ) . ( c ) Re classify each document inS usingPr(CijS ) instead ofPr(Ci ) in the classification modelC ( Eq 5 ) . estimate using the statistics forPr(Ci ) fromM , and have the property that forw=  , our enhanced classifier defaults to the standard Pr(CijS)=jCij.(Number of docs inS predicted to be inCi)w Pnj= ( jCjj.(Number of docs inS predicted to be inCj)w ) wherejCij is the number of documents in categoryCi inM . For w= ,Pr(CijS)=jCijBi=Pj(jCjjBj ) , whereBi is 1 if at least one of the documents inS was predicted to be in categoryCi , the standard classifier predicted for any of the documents inS is the same as the prediction of the standard classifier whenw=  . Figure 2 describes the enhanced algorithm , for a given weightw . Before describing the method for selecting weightw , we first motivate the need for selecting a good value forw . Example Consider a master catalogM in which there are sepaWhen we integrate products from the source catalogN , let the baproducts in one of the categories inN . egory ( to simplify the example ) . With a weight of 1,Pr(CamerajS ) = 4*10/(4*10+1*10 ) = 0.8 andPr(PeripheralsjS ) = 1*10/(4*10
Based on these probabilities , four out of the five products belong to Camera and one to Peripherals . In the master catalog , let there be 10 products each of these two categories , and none in any other cat and 0 otherwise . Notice that even though the absolute probabilities are different , the relative probabilities among the set of classes that rate categories for “ Digital Cameras ” and “ Computer Peripherals ” . the same . Hence the prediction of the enhanced classifier will be sic algorithm come up with the following probabilities for the five
3.1 Determining Weight classifier . A formula that satisfies these goals is :
Peripherals Camera
P1 P2 P3 P4 P5
.9 .8 .8 .8 .1
.1 .2 .2 .2 .9
( 6 )
+1*10 ) = 02 After incorporating these probabilities ( and normalizing ) , the enhanced algorithm would assign : result in :
.03 .06 .06 .06 .69
.01 .02 .02 .02 .36
P1 P2 P3 P4 P5
P1 P2 P3 P4 P5
.99 .98 .98 .98 .64
.97 .94 .94 .94 .31
Peripherals Camera
Peripherals Camera
311 Method
To determine a good value for the weight , we need a tune set
Thus the classification of P5 does not change with a weight of 1 , but switches to the majority category with a weight of 2 .
With a weight of 2,Pr(CamerajS ) = 16*10/(16*10+1*10 ) = 0.94 andPr(PeripheralsjS ) = 1*10/(16*10+1*10 ) = 006 This would of documents inN for which we know the correct categorization with respect toM . If there are some common documents between M andN , we can use these common documents as the tune set . If subset of the documents inN , and present these to the user to get their categorization inM . documents inN , allowing us to computePr(CijS ) for a given weightw . Next , for each document in the tune set , for a set of values forw , we go through steps 2(b ) and 2(c ) in Figure 2 and determine the values ofw for which the document is correctly classet of possible values ofw , eg ( 0 , 1 , 3 , 10 , 30 , 100 , 300 , 1000 ) . overweight the similarity implied by the hierarchyN . ments inN , we make a first pass through Step 2 for those docuspect to weightw . We then show that with a good choice for the value ofw , the enhanced algorithm will do no worse , and can do ments , and discard those which have the same categorization for all the weights . Since the categorization does not change , knowing the true category for these documents will not help us choose the weight . We then present the remaining documents to the user , and choose the weight that gives the highest accuracy on these documents . We empirically found in Section 5.2 that by following this strategy , feedback from the user on just 5 to 10 documents was sufficient to get a near optimal value for the weight .
We then select the weight that gives the highest accuracy on the documents in the tune set . If a set of weights give the same accuracy , we break the tie by choosing the smallest weight , and thus not
Depending on the cost of getting a tune set and the size of the catalog , we either choose a global weight for the entire catalog , or tune weights differently for different sections of the catalog .
We can reduce the number of documents the user has to inspect by making two passes . After selecting a random subset of docu there are no common documents between the two catalogs , the creation of the tune set requires user interaction . We select a random sified . We typically use an exponentially increasing series for the
We first make one pass through step 2(a ) in Figure 2 for all the
We first study the behavior of the enhanced algorithm with re
4 . ANALYSIS substantially better than the basic algorithm .
X
Predicted Category to be in that category . Denote
Figure 3 : Movement of Documents from a less frequent category to a more frequent category , where
4.1 Effect of Weight on Accuracy
Cx Cx Cx Cx Cx X(= Cx Cx X(= , X(= TrueCx , X( CategoryCx , Cx Consider the documents belonging to a categoryS inN . Our first theorem shows that as we increase the weightw , the predicted category of a document inS will either stay the same or switch frequency of a category is the number of documents inS predicted fx:= Number of documents fromS predicted to be inCx THEOREM 1 . For any pair of weightsw ;w   , letw > w , letCx be the predicted category of documentd at weightw , andCx the predicted category at weightw . Thenfx fx . Proof : See Appendix A . LetCx ;Cx ;:::;Cxn represent the categories ordered by their frequency in the predicted categories of the documents inS , ie , fx fx :::fxn , Figure 3 shows the movement of docAs we increasew , documents will move from the first class to the THEOREM 2 . For each documentd , there either exists a single interval(w ;w ); w w in which the document will be Proof : See Appendix A . vals(w l;w g);(w l;w g);:::;(wnl;wng ) for the weight such second , and from the second to the third . If more documents move from 1 to 2 than move from 2 to 3 , accuracy will increase . On the other hand , if more documents move from from 2 to 3 than move from 1 to 2 , accuracy will drop . 4.2 Superiority of the Enhanced Algorithm uments with increasing weight . We can split the documents into three classes : correctly classified , or the document will never be correctly classified .
LEMMA 1 . Given a set of documents , there exists a set of inter
1 . Benefit : Those to the right of the X ’s that can move to the
2 . At Risk : Those currently in the X ’s that might move to the
3 . Lost Cause : Those to the left of the X ’s . left of the X ’s .
X ’s . that the number of correctly classified documents is highest in these intervals .
THEOREM 3 . The highest possible accuracy achievable with the enhanced algorithm is no worse than what can be achieved with the basic algorithm .
We present experimental results using two types of datasets :
5 . EXPERIMENTAL RESULTS
Synthetic Catalogs Start with a real world catalog and consider it
Proof : Basic algorithm is the special case of the enhanced algo
The catch is that the optimum value of the weight for which the enhanced algorithm achieves highest accuracy is data dependent . The method using a tune set described in the previous section attempts to select a good value for the weight , but there is no guarantee of success . Our experimental results in the next section show that we were able to get substantial accuracy improvements using this method . rithm for weight 0 . to be the master catalogM . Derive source catalogsN fromM using various distributions . Consider a specific categoryCm inM . Some of the documents fromCm are assigned to the corresponding category inN , while some are spread over other categories . Use a ent degrees of overlap betweenM andN . We use a variety ranging Now consider a specific documentd fromCm inM that the synthetic data generation assigns to the categorySn inN . While integratingN intoM , ifd is assigned a category other thanCm , uments as the master catalogM . Remove from the second catalog ments in the second catalog as the source catalogN . We thus know for each document inN the correct classification inM . The goal for each document inN its correct category inM . We do these ffl Accuracy advantage of the enhanced algorithm over the basic ffl The effect of weight on the accuracy of the enhanced algoffl The size of tune set needed for the enhanced algorithm . ffl The effect of the number of documents per category in the Number of documents inN that are correctly classified Total number of documents inN from a “ perfect ” match between the two catalogs , to a “ Gaussian ” distribution where there is only a moderate amount of similarity . We generate synthetic catalogs from three master catalogs : a collection of news articles from Reuters , the Pangea electronics part descriptions dataset , and a slice of the Google hierarchy . distribution to determine how many documents are distributed over how many categories . For example , a simple 80 20 distribution will send 80 % of the documents to the corresponding category and 20 % to some other category . Different distributions result in differ
Real Catalogs Start with two real world catalogs that have some common documents . Treat the first catalog minus the common doc
Experiments Our goal is to understand the following performance characteristics : we count it as a classification error ; otherwise the assignment is correct . all documents except the common ones . Treat the remaining docu for the catalog integration algorithm now is to successfully predict
We use the classification accuracy as the metric for measuring the success of our approach . Accuracy is defined as experiments using Google and Yahoo! categories . source catalog on the classification accuracy . algorithm . rithm .
Figure 6 : Generating Synthetic Catalog
Figure 7 shows the actual distributions for the synthetic catalogs . These are slightly different from the target distributions because of the skew in category sizes of the master catalogs .
//n : number of categories inM //f ;f ;:::;fm : cumulative frequency distribution //f  := 0 ( to simplify the description ) for i := 1 ton begin foreach documentd inCi begin Letr := uniformly distributed random number in [ 0 , 1 ) . Findp such thatfpr<fp+ . j :=(i+p ) modulon ; Assignd to categorySj . Figure 6 gives the details of the algorithm for generatingN . the differences betweenPr(djCi ) for different categories becomes putePr(CijS).3 We then select a random document , and check
Figure 8 shows that the enhanced algorithm can substantially outperform the basic algorithm . The graphs show the accuracy for each of the source catalogs as we change the weight ; the “ Base ” line is the accuracy of the basic algorithm . The accuracy numbers were computed using 10 fold cross validation , ie , we randomly partition the data into 10 sets , and for each set , train on the remaining 9 sets , and test on this set [ 2 ] . With a “ Perfect ” second catalog , the absolute increase in accuracy ( at the best weight ) is 12 % for Reuters , 20 % for Pangea and 29 % for Google ; the number of errors drops by 85 % for Reuters , 73 % for Pangea , and 65 % for Google . With a distribution like GaussianA that results in considerable mismatch between the source and master catalogs , we still get an absolute increase of 5 % for Reuters , 12 % for Pangea and 15 % for Google ; the number of errors drops by 39 % for Reuters , 43 % for Pangea and 33 % for Google . Notice that for distributions ( for generating source catalogs ) that are not a good match to the main catalog , very high weights can cause the enhanced algorithm to under perform the basic classifier . Of course , once we use a tune set , we will avoid those weights . larger and hence a higher weight is needed to influence the results . The documents from the Google dataset are significantly longer than those from Reuters or Pangea ; hence for the same distribution of the synthetic hierarchy , the optimal weight is higher for Google .
In general , the optimal value of weight increases with increasing similarity between the two hierarchies . The other factor is the size of the documents in the dataset : as documents become longer ,
To select the tune set , we first make one pass with the base classifier to get the prediction for each document , enabling us to com
5.2 Experiments with Synthetic Catalogs
521 Effect of Weight on Accuracy
522 Tune Set Size
We reuse the computation , so this does not increase execution time . end end
Dataset Reuters Pangea Google.Outdoors
Categories
82 1148 38
Docs 11,367 37,012 7,431
Figure 4 : Dataset Characteristics : Reuters , Pangea & Google.Outdoors
Distribution 100 90 , 10 80 , 20
Figure 5 : Target Distributions for Synthetic Catalogs
Name Perfect 90 10 80 20 GaussianA 68.2 , 27.2 , 4.3 , 0.3 GaussianB 38.3 , 29.9 , 18.4 , 8.8 , 3.4 , 0.9 , 0.3
In the rest of this section , we describe in detail the datasets and the experimental results . Section 5.1 discusses the synthetic datasets and Section 5.2 the results with these datasets . Section 5.3 discusses the real datasets , and Section 5.4 reports results with these datasets . 5.1 Synthetic Catalogs ffl Reuters : This is a collection of news articles , and a popular ffl Pangea : This is a dataset of electronic component descripffl Google.Outdoors : This is the set of web pages in the “ Recre benchmark in the information retrieval community . We used the version of Distribution 1.0 of Reuters 21578 in which each document is assigned a single category ( available from http://wwwresearchattcom/ lewis ) .
Master Catalogs We used the following master catalogs for generating synthetic catalogs : tions used in building the experimental B2B Pangea portal at IBM Almaden . ation/Outdoors ” category in Google ( available from http:// directorygooglecom/Top/Recreation/Outdoors/ ) For each category in “ Outdoors ” , we got the links both on the category page , and from each of the subcategories , and merged the set of links .
Figure 4 shows the number of categories and total number of documents for these catalogs .
Target Distributions for Synthetic Catalogs
Our synthetic catalogs have as many categories as the master catalog . We spread documents from a certain category in the master catalog to multiple categories in the synthetic catalog . Figure 5 shows the various target distributions we used for spreading documents . For the Perfect distribution , each category in the synthetic catalog will have documents from a single category in the master catalog . On the other hand , for GaussianB distribution , documents from a category in the master catalog will be spread over 7 categories in the synthetic catalog , and each category in the synthetic catalog will include documents from 7 categories in the master catalog . The intent was to evaluate the performance of our approach to catalog merging over a wide range of similarity characteristics between the categorizations of the two catalogs .
Distribution Reuters Perfect 90 10 80 20 GaussianA GaussianB
100 91.2 , 8.8 82.0 , 18.0 70.8 , 25.5 , 3.5 , 0.2 51.2 , 27.5 , 11.8 , 6.5 , 2.1 , 0.9
Pangea 100 90.6 , 9.4 80.9 , 19.1 69.2 , 27.1 , 3.5 , 0.1 45.2 , 28.4 , 15.8 , 8.1 , 2.2 , 0.3
Google 100 91.1 , 8.9 82.6 , 17.4 68.5 , 28.0 , 3.4 , 0.1 42.2 , 28.8 , 18.9 , 7.2 , 2.5 , 0.3
Figure 7 : Actual Distributions : Reuters , Pangea & Google.Outdoors
( a ) Reuters
( a ) Reuters y c a r u c c A y c a r u c c A y c a r u c c A
100
98
96
94
92
90
88
86
84
82
100
95
90
85
80
75
70
65
100
95
90
85
80
75
70
65
60
55
50
Perfect 90 10 80 20 GaussA GaussB Base
Perfect 90 10 80 20 GaussA GaussB Base
10 Weight
100
200
( b ) Pangea
10 Weight
100
200
( c ) Google.Outdoors
Perfect 90 10 80 20 GaussA GaussB Base
1
1
1
10
Weight
100
1000 y c a r u c c A y c a r u c c A y c a r u c c A
100
98
96
94
92
90
88
86
84
82
100
95
90
85
80
75
70
65
100
95
90
85
80
75
70
65
60
55
50
Perfect 90 10 80 20 GaussA GaussB Base
Perfect 90 10 80 20 GaussA GaussB Base
Perfect 90 10 80 20 GaussA GaussB Base
0 5 10
20
35
Tune Set Size
50
( b ) Pangea
0 5 10
20
35
Tune Set Size
50
( c ) Google.Outdoors
0 5 10
20
35
Tune Set Size
50
Figure 8 : Accuracy vs . Weight
Figure 9 : Accuracy vs . Tune Set Size
523 Catalog Size likely to be off by quite a bit from the true value ; hence it is not surprising that the accuracy increases with the category size . However , note that for Pangea and Google , we still get a substantial part of the accuracy boost even with median category sizes of just over 5 documents .
5.3 Real Catalogs whether the enhanced classifier classifies it differently based on the weight . If so , we add it to the tune set ; else we pick another document .
Figure 9 shows that very small tune sets are sufficient to choose the right weight . With just 5 carefully chosen examples , we are able to do almost as well as with 10 to 50 examples : there are only slight improvements beyond 10 examples . The reason why so few examples are sufficient is that changes in weights only change the classification of a small fraction ( typically around 10 % ) of the total documents to be classified . By choosing only such documents to present for tuning , we get the same effect as we would by presenting 10 times as many random documents .
Figure 10 shows the effect on accuracy as we increase the number of documents in the second catalog . The x axis shows the weighted median category size , ie , if the category size is 10 documents , half the documents are in categories ( in the second catalog ) with 10 or fewer documents , and half the documents are in categories with 10 more documents.4 We used a modified version of 5 fold cross validation : the training set was always 80 % of the data , but the test set ranged from 20 % of the data to samples of that 20 % . The weight was determined using a tune set of 10 docu ments.5 With small category sizes , our estimates ofPr(CijS ) are To evaluate our approach using real catalogs forN , we wrapped the Google and Yahoo! websites , extracted over 100,000 links from 5 different sections of their categorizations , and retrieved the corresponding web pages.6 Incidently , we found less than 10 % overlap between the links in Google and Yahoo! . Figure 11(a ) shows the number of categories , number of links obtained from the website , and number of documents ( after dropping the common documents and those documents our crawler could not get ) . When computing the set of common links , we ignored links that had multiple categories . Figure 11(b ) shows similar numbers for the set of common documents . We include both the weighted median and the average documents per category , since the median can sometimes be much higher . This figure also shows the distributions of the categories . For instance , a single category in Google.Autos had , on average , 78 % of documents from a single category in Yahoo.Autos , 9 % from a second category in Yahoo.Autos , 5 % from a third category , and so on . These distributions look similar to the Gaussian distributions we used in the synthetic catalogs , except that the tails are longer .
The median was averaged over the different test sets ; hence it is not an integer . The tune set of 10 documents was selected from the entire 20 % in order not to affect the results . From Google ( http://directorygooglecom ) , we got Recreation/Autos , Arts/Movies , Recreation/Outdoors , Arts/Photography and Computers/Software . From Yahoo! ( http://diryahoocom ) , we got the corresponding categories : Recreation/Automotive , Entertainment/Movies and Film , Recreation/Outdoors , Arts/Visual Arts/Photography , and Computers and Internet/Software . y c a r u c c A y c a r u c c A y c a r u c c A
100
98
96
94
92
90
88
86
84
82
100
95
90
85
80
75
70
65
100
95
90
85
80
75
70
65
60
55
50
( a ) Reuters
Perfect 90 10 80 20 GaussA GaussB Base
10
100
Median Category Size
600
( b ) Pangea
Perfect 90 10 80 20 GaussA GaussB Base
5
10 Median Category Size
50
( c ) Google.Outdoors
Perfect 90 10 80 20 GaussA GaussB Base
5
10
Median Category Size
100
Figure 10 : Accuracy vs . Median Size of Categories in Synthetic Catalog
( a ) All Documents
Dataset Google.Autos Yahoo.Autos Google.Movies Yahoo.Movies Google.Outdoors Yahoo.Outdoors Google.Photography Yahoo.Photography Google.Software Yahoo.Software
Categories
26 59 40 45 38 68 26 35 77 46
Links 8095 7202 7285 8531 7707 8756 3661 3575 20471 12222
Docs 7351 6021 6483 7433 7260 8162 3233 3014 18864 10673
( b ) Common Documents Docs/Category
Categories Docs Average Median Distribution
23 36 32 38 30 37 22 26 55 37
223 223 130 130 135 135 148 148 189 189
9.7 6.2 4.1 3.4 4.5 3.6 6.7 5.7 3.4 5.1
52 49 8 7 6 7 15 11 8 7
78 , 9 , 5 , 4 , 3 , 1 , .4 76 , 13 , 5 , 2 , 1 , .9 , .9 , .4 , .2 , .2 69 , 15 , 6 , 3 , 3 , 1 , 1 , .7 , .7 , .7 64 , 20 , 8 , 4 , 2 , 1 , .6 , .2 76 , 16 , 6 , 1 80 , 11 , 3 , 2 , 1 , .7 , .7 , .5 , .2 , .2 67 , 18 , 6 , 4 , 2 , 2 , 2 , .5 59 , 17 , 9 , 5 , 3 , 2 , 2 , .9 , .4 , .4 69 , 15 , 7 , 4 , 3 , .9 , .3 , .3 , .3 , .3 50 , 14 , 8 , 6 , 4 , 3 , 2 , 1 , .9 , .9
Figure 11 : Dataset Characteristics : Google & Yahoo! Slices ( October 2000 )
( a ) Yahoo! to Google ( Train : Google , Test : Yahoo! ) Improvement
Accuracy
Dataset Autos Movies Outdoors
Photography
Software Average
Basic Enhanced Absolute Relative 60.5 27.1 65.2 50.7 47.6 50.2
40 % 21 % 36 % 25 % 28 % 30 %
76.2 42.6 77.8 62.8 62.4 64.4
15.7 15.5 12.6 12.1 14.8 14.1
( b ) Google to Yahoo! ( Train : Yahoo! , Test : Google ) Improvement
Accuracy
Dataset Autos Movies Outdoors
Photography
Software Average
Basic Enhanced Absolute Relative 50.2 28.5 55.9 45.4 43.0 44.6
46 % 25 % 22 % 11 % 27 % 26 %
73.1 46.2 65.4 51.3 58.6 58.9
22.9 17.7 9.5 5.9 15.6 14.3
Figure 12 : Google & Yahoo! : Classification Accuracy
5.4 Experiments with Real Catalogs
Figure 12 shows the performance of the algorithm on the 10 datasets given in Figure 11 . We tested the accuracy of the classifiers when merging the Yahoo! categorization into the corresponding Google categorization and vice versa . The enhanced algorithm did very well even though the two catalogs were quite different : 30 % fewer errors on average ( 14.1 % difference in absolute accuracy ) when classifying Yahoo! into Google , and 26 % fewer errors on average ( 14.3 % difference in absolute accuracy ) when classifying Google into Yahoo! .
6 . CONCLUSIONS
We presented a technique for integrating documents from a source catalog into a master catalog that takes advantage of the implicit information present in the source catalog : that documents in the same category in the source catalog are similar . Our technique enhances the standard Naive Bayes classification by incorporating this information when classifying source documents . We showed through analysis that the highest accuracy achievable with our enhanced technique can be no worse than what can be achieved with the standard Naive Bayes classification .
Our experiments using synthetic as well as real data indicate that the proposed technique can result in large accuracy improvements . Using a tune set for selecting the weight to give the implicit information allows our enhanced algorithm to do substantially better , and never do significantly worse . Our experiments also showed that the size of the tune set can be very small and hence not place a significant burden on the user of the system .
7 . REFERENCES [ 1 ] R . Agrawal , R . Bayardo , and R . Srikant . Athena :
Mining based Interactive Management of Text Databases . In Proc . of the Seventh Int’l Conference on Extending Database Technology ( EDBT ) , Konstanz , Germany , March 2000 .
[ 2 ] L . Breiman , J . H . Friedman , R . A . Olshen , and C . J . Stone . Classification and Regression Trees . Wadsworth , Belmont , 1984 .
[ 3 ] S . Chakrabarti , B . Dom , R . Agrawal , and P . Raghavan . Using
Taxonomy , Discriminants , and Signatures for Navigating in Text Databases . In Proc . of the 23rd Int’l Conf . on Very Large Databases , pages 446–455 , 1997 .
[ 4 ] W . Cohen . Learning Rules that Classify E Mail . In Proc . of the 1996 AAAI Spring Symposium on Machine Learning in Information Access , 1996 .
[ 5 ] R . Dolin , J . Pierre , M . Butler , and R . Avedon . Practical evaluation of IR within automated classification systems . In Proc . of the 8th Int’l Conf . on Information and Knowledge Management ( CIKM ) , Kansas City , Nov . 1999 .
[ 6 ] S . T . Dumais and H . Chen . Hierarchical classification of web content . In Proc . of the 23rd Int’l ACM Conf . on Research and Development in Information Retrieval ( SIGIR ) , pages 256–263 , Athens , Greece , August 2000 .
[ 7 ] I . Good . The Estimation of Probabilities : An Essay on
Modern Bayesian Methods . MIT Press , 1965 .
[ 8 ] K . Lang . News Weeder : Learning to Filter Net News . In Proc . of the 12th Int’l Conf . on Machine Learning , pages 331–339 , 1995 .
[ 9 ] L . S . Larkey . A patent search and classification system . In The Fourth ACM Conference on Digital Libraries , pages 79–87 , Berkeley , CA , August 99 .
[ 10 ] D . Lewis and M . Ringuette . A comparison of two learning algorithms for text categorization . In In Third Annual Symposium on Document Analysis and Information Retrieval , pages 81–92 , 1994 .
[ 11 ] P . Maes . Agents that Reduce Work and Information
Overload . Communications of the ACM , 37(7):31–40 , 1994 .
LEMMA 2 . For any categoryCp , if there exists someCj such thatfj>fp andbjbp , orfj=fp andbj>bp , thenCp will never be the classification of documentd . Proof : Let there be someCj such thatfj>fp andbjbp . Thenbjfwj>bpfwp for any positivew , andPrw(Cjjd;S)> Prw(Cpjd;S ) for any positivew , andCj will always be preferred toCp . A similar argument holds for the other case . LEMMA 3 . LetCp;Cq be two categories such thatfp>fq andbp<bq . Then there exists some weightwt>  such that for allw>wt,Prw(Cpjd;S)>Prw(Cqjd;S ) , and for allw<wt , Prw(Cpjd;S)<Prw(Cqjd;S ) . Proof : Letwt=log(bq=bp)=log(fp=fq ) . Sincefp>fq and bq>bp,wt>  . Now , for anyw>wt : w>log(bq=bp)=log(fp=fq ) wlog(fp=fq)>log(bq=bp ) ( fp=fq)w>(bq=bp ) Kbpfwp>Kbqfwq Similarly for anyw<wt : w<log(bq=bp)=log(fp=fq ) Kbpfwp<Kbqfwq
THEOREM 2 . For each documentd , there either exists a single interval(w ;w ), w w in which the document will be Proof : LetCp be the correct classification for documentd . We fflGalways=fCjjfj>fp andbjbp ; orfj=fp andbj> bpg . From Lemma 2 , ifGalways is non empty , the document fflGnever=fCjjfj<fp andbj<bpg.Cp will always be preferred to anyCj Gnever . fflGequal=fCjjfj=fp andbj=bpg . We assume that fflGhigh=fCjjfj>fp andbj<bpg . From Lemma 3 , there exists some weightwhigh such that for allw<whigh , Prw(Cpjd;S)>max(fPrw(Cjjd;S)jCj Ghighg ) , fflGlow=fCjjfj<fp andbj>bpg . From Lemma 3 , there exists some weightwlow such that for allw>wlow , Prw(Cpjd;S)>max(fPrw(Cjjd;S)jCj Glowg ) . Hence ifGalways is non empty , or ifwhigh<wlow,Cp will never will be correctly classified in the interval(wlow;whigh ) . correctly classified , or the document will never be correctly classified . if two classes have the same probability , the document is assigned to both classes , and thus ignore this case . the the classification for the document . Otherwise , the document split all other categories into five groups : will never be correctly classified .
[ 12 ] A . McCallum and K . Nigam . A Comparison of Event
[ 15 ] M . Pazzani and D . Billsus . Learning and Revising User
[ 16 ] M . Sahami , S . Dumais , D . Heckerman , and E . Horvitz . A
APPENDIX A . PROOFS
[ 17 ] M . Sahami , S . Yusufali , and M . Baldonado . Sonia : A service
Profiles : The identification of interesting web sites . Machine Learning , 27:313–331 , 1997 . for organizing networked information autonomously . In Proc . of the Third ACM Conference on Digital Libraries , pages 200–209 , 1998 .
Bayesian Approach to Filtering Junk E mail . In Proc . of the AAAI’98 Workshop on Learning for Text Categorization , Madison , Wisconsin , 1998 .
[ 18 ] R . Segal and J . Kephart . MailCat : An Intelligent Assistant for Organizing E Mail . In Proc . of the Third Int’l Conf . on Autonomous Agents , 1999 .
Models for Naive Bayes Text Classification . In AAAI 98 Workshop on “ Learning for Text Categorization ” , 1998 . [ 13 ] T . M . Mitchell . Machine Learning . McGraw Hill , 1997 . [ 14 ] T . Payne and P . Edwards . Interface Agents that Learn : An Investigation of Learning Issues in a Mail Agent Interface . Applied Artificial Intelligence , 11:1–32 , 1997 .
Consider the documents belonging to a categoryS inN . Let fi:= Number of documents fromS predicted to be inCi For a documentd , letbi:=jCij.Pr(djCi ) From Eqs . 5 and 6 , for a weightw Pr(Cijd;S)=Kbifwi whereK is the same for all the documents inS ( K is the product Prw(Cijd;S ) to denotePr(Cijd;S ) for a weightw . THEOREM 1 . For any positive pair of weightsw ;w , letw > w , letCx be the predicted category of documentd at weightw , andCx the predicted category at weightw . Thenfx fx . Proof : SinceCx is the classification at weightw , Prw ( Cx jd;S)Prw ( Cx jd;S ) . Expanding , we get Kbx fx w Kbx fx w ( bx =bx )(fx =fx )w Similarly , sincePrw ( Cx jd;S)Prw ( Cx jd;S ) , we get Kbx fx w Kbx fx w ( bx =bx )(fx =fx )w ( bx =bx )(fx =fx )w ( bx =bx )(fx =fx )w ( fx =fx )(w ,w ) ( sincew ,w >  ) fx =fx fx fx of the denominators in the two equations ) . We use the notation
( 7 )
( 8 )
Combining equations 7 and 8 , we get
