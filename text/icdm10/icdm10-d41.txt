Co clustering of Lagged Data
Eran Shaham
Department of Computer Science
David Sarne
Department of Computer Science
Boaz Ben Moshe
Department of Computer Science
Bar Ilan University
Ramat Gan , 52900 Israel erans@macsbiuacil
Bar Ilan University
Ramat Gan , 52900 Israel sarned@macsbiuacil
Ariel University Center
Ariel , 44837 Israel benmo@arielacil
Abstract—The paper focuses on mining clusters that are characterized by a lagged relationship between the data objects . We call such clusters lagged co clusters . A lagged co cluster of a matrix is a submatrix determined by a subset of rows and their corresponding lag over a subset of columns . Extracting such subsets ( not necessarily successive ) may reveal an underlying governing regulatory mechanism . Such a regulatory mechanism is quite common in real life settings . It appears in a variety of fields : meteorology , seismic activity , stock market behavior , neuronal brain activity , river flow and navigation , are but a limited list of examples . Mining such lagged co clusters not only helps in understanding the relationship between objects in the domain , but assists in forecasting their future behavior . For most interesting variants of this problem , finding an optimal lagged co cluster is an NP complete problem . We present a polynomial time Monte Carlo algorithm for finding a set of lagged co clusters whose error does not exceed a pre specified value , which handles noise , anti correlations , missing values , and overlapping patterns . Moreover , we prove that the list includes , with fixed probability , a lagged co cluster which is optimal in its dimensions . The algorithm was extensively evaluated using various environments . First , artificial data , enabling the evaluation of specific , isolated properties of the algorithm . Secondly , real world data , using river flow and topographic data , enabling the evaluation of the algorithm to efficiently mine relevant and coherent lagged co clusters in environments that are temporal , ie , time reading data , and non temporal , respectively .
Keywords clustering ; co clustering ; lagged clustering ; time lagged ; data mining ;
I . INTRODUCTION
In order to benefit from the continuous improvements in digital data collection capabilities , efficient data mining and analysis tools are required . One important tool in this context , which has numerous applications is clustering [ 1 ] . Following seminal work by Cheng and Church [ 2 ] in the area of gene expression using microarray technology , substantial focus has been placed in recent years on co clustering . Co clustering extends clustering by allowing simultaneous clustering of the rows and columns of a data matrix , aiming to identify a subset of rows which exhibit similar behavior across a subset of columns , or vice versa [ 3 ] , [ 4 ] . While many co clustering techniques have been proposed over the
This work was supported in part by the Israeli Science Foundation grant no . 1401/09 years ( kernel based [ 5 ] , [ 6 ] , exhaustive enumeration [ 7 ] , spectral analysis [ 8 ] , greedy [ 2 ] , CTWC [ 9 ] and others , surveyed in [ 4 ] and [ 3] ) , few have considered the problem of finding co clusters involving lagged correlations between the behavior of a subset of rows ( objects ) over a subset of columns [ 10 ] . Yet this latter case , which may reveal an underlying regulatory mechanism governing the value of the participating objects , is quite common in real life settings . For example , consider the problem of identifying a group of people coordinating their movements in a crowd ( eg , trying to get from point A to point B ) . If the group keeps its original formation , then the trajectories of the members’ spatial positions over time form a lagged pattern . Similarly , consider the application of oil and gas exploration based on reflection seismology [ 11 ] . Here , seismometers are placed on the surface , recording seismic waves . A single initiated explosion creates a wave which is reflected from each underground layer with varying time differences ( depending on the depth and structure of that layer ) . Therefore , an appropriate time lagged analysis of the reflections received by different seismometers placed in different locations on the ground may reveal the structures and dimensions of the layers [ 11 ] .
We denote this problem of extending co clusters to capture lagged correlations between a subset of rows over a subset of columns as a ‘lagged pattern’ ( see Figure 1 , based on [ 10] ) . While the idea of finding lagged patterns between different streams of data is not new , existing methods are inherently limited to comparing pairs of objects [ 12 ] , [ 13 ] or mining clusters with contiguous columns [ 14]–[16 ] and thus cannot be successfully applied to the general lagged co clustering problem .
As in most clustering problems , there are various measures for the quality of clusters found . Given the fact that co clustering is a specific case of lagged co clustering , with a zero lag , the latter problem is NP complete for any measure for which the non lagged co clustering problem is NPcomplete . In particular , we base our model on [ 2 ] , [ 15 ] adding to it a lag aspect , which is also proved to be NPcomplete . Therefore , the main contribution of the paper is a polynomial time Monte Carlo algorithm for lagged coclustering denoted LC , which is the first attempt , to the best
( a ) Dataset Figure 1 . Example dataset : ( 1a ) example of matrix dataset . For simplicity , certain cells have been left blank in the table . ( 1b ) the same matrix after row permutation . Two clusters emerge from ( 1b ) : A decadent type of lagged co cluster , with no lag , marked with black fonts , blue shadow and orange dashed envelope ( visually presented in ( 1c) ) ; and lagged co cluster , marked with red fonts , gray shadow and black solid envelope ( visually presented in ( 1d) ) .
( d ) Lagged co cluster
( b ) Lagged dataset
( c ) Co cluster of our knowledge , to develop a polynomial approximation to the problem . The LC algorithm takes as input a real number matrix and a maximum error value and outputs a set of lagged co clusters whose errors do not exceed the prespecified value . As part of the analysis we prove that the output includes , with fixed probability , a lagged co cluster which is optimal according to any monotonically increasing objective function of the cluster dimension . The algorithm handles many of the inherent properties common to nonlagged data [ 4 ] . For example , it overcomes noise ( erroneous reading due to local noise , equipment accuracy , experimental or human error ) , anti correlations ( down regulated , adapting gene expression terminology ) , missing values ( eg , due to equipment malfunction ) and overlapping patterns . Furthermore , the lagged co clusters are mined even if the amplitude of the reflected values fades along columns ( as in the seismometers example ) .
The algorithm and its properties are extensively evaluated using artificial data and real world data from two different domains ( topographic data and river flow data ) . The artificial data is used mainly to demonstrate the efficiency of the algorithm in mining relevant and coherent lagged co clusters , to verify the theoretical bounds and to show actual performance . The data from the two other domains are used to demonstrate the ability of the algorithm to produce relevant and valid clusters based on overlapping , partially missing and noisy real data .
The remainder of the paper is organized as follows : in the following section we review related work . In Section III we define the model and show that for most interesting variants of the problem it is an NP Complete problem . Section IV presents the algorithm while Section V gives proof of the probabilistic guarantee to efficiently mine relevant lagged co clusters . Section VI analyzes the running time and Section VII presents the experiments conducted and results . We conclude with a discussion and directions for future research in Section VIII .
II . RELATED WORK
A wealth of research has been undertaken studying clustering ( see [ 1 ] for a survey ) . The research has emerged from a variety of fields : biology , physics , economics , computer science and more . Typically , in clustering problems , clusters are extracted from a matrix dataset where the rows represent objects and the columns represent the features of the object [ 1 ] , [ 3 ] .
Simple mining techniques look for fully dimensional clusters : subsets of rows over all columns , or subsets of columns over all rows [ 12 , inter alia ] . These techniques have several inherent vulnerabilities , eg , difficulty in handling irrelevant , noisy or missing features , which often exist , inaccuracy due to the ‘curse of dimensionality’ [ 17 ] and even counter productivity as they increase the background noise [ 3 ] , [ 4 ] .
To overcome these obstacles , the data analysis has to find the relevant subspace for a particular pattern and ignore the rest , ie , mining clusters contained in subset of rows over a subset of columns . This type of clustering is known as biclustering , co clustering , co regulation or simply clustering . The different approaches for co clustering ( see [ 2 ] , [ 5]–[10 ] , [ 14 ] , [ 15 ] , [ 18]–[20 ] , surveyed in [ 4 ] and [ 3] ) , are based on different models ( additive vs . multiplicity , axis alignment , rows over columns preferment , cluster scoring function , overlapping , etc . ) and algorithmic strategies ( greedy , divide and conquer , kernel based , bayesian networks , etc ) Substantial effort has been directed at non lagged co clustering of datasets with temporal nature ( surveyed in [ 21] ) .
The lagged co clustering model generalizes the coclustering model by introducing lags ( shifts ) between the dataset ’s objects . Most algorithms trying to mine lagged coclusters do so by working on pairs of rows . They differ in the correlation techniques being used : cross correlation , normalized , Granger , Pearson , partial and others [ 12 ] , [ 13 , inter alia ] . Extending these algorithms to mine clusters of more than two rows demands some combinatorial solution ( eg , merging ) , which is both time consuming and heavily dependent on the closeness merit function . In addition , correlated pairs do not necessarily have the transitive property [ 12 ] .
Among the few studies that have considered a lagged coclustering model involving clusters of more than two rows , c1c2c3c4c5c6c7c8c9r141132r22423111r317144125r421423211r5862264r663129331r710720315552r841836321r9r1041133Hj243113GiTic1c2c3c4c5c6c7c8c910r2242311150r7107203155522 1r8418363213 2r66312933111r42142321110r14113240r31714412520r586226410r1041133r905101520c3c4c5c6c7r1r3r5r100510152025c1c2c3c4c5c6c7c8r2r7r8r6r4 most were focused on a decadent variant in which the goal was finding a subset of rows over a contiguous subset of columns [ 14]–[16 ] , [ 18 ] .
One algorithmic approach for this variant is to discretize the real number input matrix by transforming onto a finite alphabet matrix , Σm × n , enabling the use of fast string matching techniques that run in a polynomial time ( see q cluster algorithm [ 14 ] , [ 16 ] and the CCC Biclustering algorithm [ 15] ) . The main drawback of this approach is the alphabet size . Since it requires data discretization , a coarse abstraction using a small alphabet may lead to greater errors and finer clusters being missed . Using large |Σ| will have a dramatic influence on the run time as it is exponentially dependent on |Σ| .
Another approach suggested for this variant uses the dynamic programming method . It first searches for small coherent clusters to serve as building blocks . Then , it hierarchically merges them , while activating pruning methods ( see S2D3 algorithm [ 18] ) . The main drawback of this approach is an exponential run time .
The work most relevant to our research is the ts Cluster algorithm proposed by Yin et al . [ 10 ] . The algorithm uses dynamic programming and a hierarchical merge approach in order to mine lagged co clusters . The main drawbacks of the algorithm are the reduction to a small alphabet , Σ={up , non , down} , looking for trend like clusters rather than a more subtle model . Furthermore , and most importantly , the running time of the ts Cluster algorithm is exponential .
III . MODEL
In order to present the lagged co clustering model , we augment the legacy co cluster definition [ 2 ] to include the lagging aspects . A lagged co cluster of an m × n real number matrix X , is a submatrix determined by a subset I of the rows and their corresponding T lags ( |T| = |I| ) over a subset J of the columns , aligned to some extent to a lagged mechanism ( see Figure 1 ) . A lagged regulatory mechanism holds if for every two rows i1 , i2 ∈ I and their corresponding lag Ti1 , Ti2 , the proportion between the entries over all j ∈ J is constant independent of j : = Ci1,i2 ∀j ∈ J , revealing : a latent Xi1,j+Ti1 variable Gi indicating object i ’s regulation strength ; a latent variable Ti indicating the influencing lag of object i and a latent variable Hj indicating the regulatory intensity in sample j ( see Figure 1b).1 Therefore , in a lagged cocluster , we expect the submatrix elements to comply with the relation : Xi,j ≈ GiHj+Ti for all ( i , j ) ∈ ( I , J ) . A particular measure for the deviation in Xi,j from the approximation is the modification of the relative error criteria GiHj+Ti used for non lagged co clusters [ 19 ] : GiHj+Ti/Xi,j . Our goal is to mine large submatrices , with a relative error
/Xi2,j+Ti2
1Based on the standard co cluster definition for multiplicative model [ 19 ] , according to which ∀j ∈ J , Xi1,j /Xi2,j = Ci1,i2 ( additive model [ 2] ) .
|I| + |J| , area , below a certain pre defined threshold . The optimal size submatrix depends on the merit function , f ( |I|,|J| ) , used for evaluating the submatrix size rank . We can rank a |I| · |J| , or submatrix by its perimeter , any other trade off between the number of rows and the number of columns . Previous work ( eg , [ 6 ] ) mainly handled biological datasets characterized by thousands of rows over tens of columns [ 3 ] . Therefore , it is reasonable to consider a trade off µ(|I|,|J| ) = |I|/ψ|J| , 0 < ψ < 1 , as in the case of m * n the inclusion of an additional column is worth the exclusion of a relatively large number of rows . In contrast , lagged co cluster datasets can be characterized by time readings . This results in hundreds or thousands of columns , or , in an on line version , an infinite stream of columns . Therefore , any assumption regarding the relation between the number of rows and the number of columns is futile . Consequently , we allow the use of any monotonically growing objective function µ(|I|,|J| ) . Our problem thus turns into finding an optimal size submatrix with a relative error below a certain threshold :
1 η
≤ GiHj+Ti
Xi,j
≤ η , ∀ i ∈ I , j ∈ J .
( 1 )
To facilitate analysis , we switch from a multiplicative model to an additive model by applying logarithm transformation , setting Ai,j = log Xi,j , Ri = log Gi , Cj+Ti = log Hj+Ti and ε = log η . Therefore , our problem translates to finding Ri , Ti and Cj such that for all i , j , −ε ≤ ( Ri + Cj+Ti ) − Ai,j ≤ ε . for lagged anti correlations , ie , Xi,j ≈
Notice that Gi/Hj+Ti , one should use :
−ε ≤ ( Ri − Cj+Ti ) − Ai,j ≤ ε .
We note that other models , such as derivative or power law , can be easily incorporated in the above formulation .
Definition 1 : The sleeve width of a submatrix A , defined by a subset J of columns , a subset I of rows and their corresponding lag T , is : swT ( I , J ) = 2 min R,T,C max i∈I,j∈J
|Ai,j − Ri − Cj+Ti|
( 2 )
The notion of sleeve width reflects the extent to which an entry i , j in the lagged co cluster is allowed to deviate from being considered as the summation of Ri + Cj+Ti .
At this point , we have all we need in order to formally define a lagged co cluster . However , we extend the model to include two additional parameters , β and γ , that allow the user to specify the minimum dimensions of the mined cluster : β the minimum number of the rows expressed as a fraction of m ; γ the minimum number of the columns expressed as a fraction of n . If the user wishes not to constrain the cluster ’s dimensions , trivial defaults can be used , ie , |I|,|J| ≥ 2 .
Definition 2 : Let 0 < β , γ < 1 . A lagged co cluster of matrix A with a sleeve width w > 0 is a triple ( I , T , J ) , with J a subset of the columns , I a subset of the rows and T their corresponding lag , that satisfies the following : • Size : The number of the rows is 2 ≤ βm ≤ |I| = |T| and the number of the columns is 2 ≤ γn ≤ |J| . • Sleeve width : swT ( I , J ) ≤ w . ie , for all i ∈ I and j ∈ J there are Ri , Ti and Cj , such that |Ai,j − Ri − Cj+Ti| ≤ w/2 . Ri , i ∈ I will be called a column profile , Ti , i ∈ I will be called a lagged column profile and Cj , j ∈ J will be called a row profile .
Therefore , lagging and shifting row i by Ti and Ri , respectively , will place each column j ∈ J within a sleeve width of w surrounding the row profile . For the specific case where Ti = 0 , we obtain a definition equivalent to the one used for non lagged co clustering [ 19 ] .
Our goal is thus to mine an optimal size submatrix with a sleeve width not exceeding a pre defined sleeve width w . As we prove in the following theorem , this problem is NPcomplete . Theorem 1 : The problem of finding an optimal |I| = |J| or |I| · |J| lagged co cluster is NP complete .
Proof : We reduce our lagged co clustering problem ( I , T , J ) to a non lagged co clustering problem ( I , J ) , which is proven to be NP complete [ 2 ] , [ 5 ] . We apply a polynomial time reduction by converting the lagged matrix , A , into a non lagged one , A , as follows . First , we randomly choose a row p ∈ A . From every other row i ∈ A , we create 2n new entries in A , each with a different lag in comparison to p ( ie , −n ≤ lag ≤ n ) . Null entries resulting from such alignments are marked as missing values . The resulting matrix A is a non lagged co clustering problem of size 2nm × 3n .
IV . THE LC ALGORITHM
In this section , we present the LC algorithm , a polynomial time Monte Carlo algorithm . Naturally , the design of LC is mostly influenced by solution concepts introduced for non lagged co clustering problems [ 5 ] , [ 19 ] . The LC algorithm guarantees with fixed probability the mining of optimal dimension lagged co clusters with a sleeve width not exceeding a pre specified value . The algorithm ’s input is a matrix of real numbers and its output is a list of lagged co clusters . It makes use of random projection , which is a common technique for mining co clusters [ 5 ] , [ 6 ] . The algorithm inherently handles noise and overlapping : noise by allowing the lagged co cluster to be of some maximal pre specified sleeve width ; overlapping by utilizing the independent random projection to reveal sub dimensions relevant only to a specific cluster . Missing values are overcome by calculating the coherence of a lagged co cluster on the nonmissing values of the submatrix [ 19 ] , [ 20 ] .
Figure 2 presents the LC algorithm . Generally , the algorithm can be divided into the following phases : ( 1 )
Initialization : randomly choose a discriminating row and a discriminating set of columns as seeds ; ( 2 ) Row addition : go over all rows and lags and add those that comply with the sleeve width criteria ; ( 3 ) Column addition : go over all the columns and add the ones that comply with the sleevewidth criteria . The inclusion of a row or a column only after complying with the sleeve width criteria , guarantees that only relevant rows and columns are added to the lagged co cluster .
LC Algorithm Input : X , an m × n matrix of real numbers , and w ≥ 0 , the maximum acceptable sleeve width . Output : List of ( I , T , J ) , a list of lagged co clusters that are submatrices of X with columns subsets J , rows subsets I and their corresponding lag T , which have a sleeve width score that does not exceed w . Initialization : Setting of p , S and |S| is thoroughly discussed in the following section . loop p times randomly choose row p : 1 ≤ p ≤ m ; loop S times randomly choose a set of columns S ; set ( I , T ) ← ( p , 0 ) ; for each ( i , t ) : 1 ≤ i ≤ m , −n ≤ t ≤ n do if swT ( I ∪ {i} , S ) ≤ w then add ( i , t ) to ( I , T ) ; end for J ← S ; for each j : 1 ≤ j ≤ n do if swT ( I , J ∪ {j} ) ≤ w then add j to J ;
1 : 2 : 3 : 4 : 5 : 6 : 7 :
8 : 9 : 10 :
11 : end for if |I| < βm or |J| < γn then discard ( I , T , J ) ; end S loop end p loop
12 : return a list of the ( I , T , J ) ;
Figure 2 . LC algorithm for finding lagged co clusters
The calculation of swT ( I , J ) ( line 7 , 10 ) is done by computing sw(I , J ) [ 19 ] on the non lagged submatrix . Such a non lagged submatrix is obtained by lagging each row i ∈ I relative to p by Ti ( Tp = 0 ) . Null entries caused by the lagging process are marked as missing values .
V . OPTIMALITY OF LC ALGORITHM
Next we show some guarantees of the LC algorithm ’s ability to efficiently mine relevant and coherent lagged coclusters . These guarantees are demonstrated experimentally in Section VII .
We prove that the LC algorithm guarantees finding an optimal lagged co cluster of sleeve width w with a fixed probability in a polynomial number of iterations . The structure of the proof is inspired by [ 19 ] and consists of two major stages . First , we show that an optimal lagged cocluster can be mined using a log size discriminating set with probability 05 Based on this capability , we then show that when running the LC algorithm in a polynomial number of iterations , it mines the optimal lagged co cluster with a probability of at least 05
The proof relies on the important insight that a sufficient size for a discriminating set is logarithmic in the size of the set [ 5 ] , [ 6 ] . This latter result enables the use of a small subset , of O(log mn ) size , randomly chosen from the columns , which discriminates the participating rows and their lags .
The definition of a discriminating set for the lagged model is given as follows . Definition 3 : Let ( I , T , J ) be a lagged co cluster of sleeve width w , and p ∈ I . S ⊆ J is a discriminating set for ( I , T , J ) with respect to p if it satisfies :
1 . swT ( {i , p} , S ) ≤ w for all i ∈ I . 2 . swT ( {i , p} , S ) > w for all i /∈ I . for an optimal
We next show that lagged co cluster ( I∗ , T ∗ , J∗ ) , there are many small sets of size O(log mn ) , each of which is a discriminating set with a probability of 05 This latter result is important since upon selecting p ∈ I∗ and S ⊆ J∗ , we can deduce I∗ , T ∗ and J∗ . Furthermore , the capability of finding a discriminating set with probability 0.5 , is later used by Theorem 3 to mine an optimal lagged co cluster , in a polynomial number of iterations . Theorem 2 : Let ( I∗ , T ∗ , J∗ ) be an optimal lagged cocluster of sleeve width w , with γ ≤ ( |J∗|/n ) < γ , and let p ∈ I∗ . Any randomly chosen subset S of J∗ , of size |S| ≥ log(4mn)/ log(1/3γ ) , is a discriminating set for ( I∗ , T ∗ , J∗ ) , with respect to p with probability at least 05 Proof : We show that for any S that satisfies the above , condition ( 1 ) of Definition 3 always holds and the probability that condition ( 2 ) does not hold is less than 05 i , i ∈ I∗ , be a column profile , T ∗ i , i ∈ I∗ a j , j ∈ J∗ , a row profile lagged column profile , and C∗ for ( I∗ , T ∗ , J∗ ) . Condition ( 1 ) of definition 3 is always satisfied , since {i , p} ⊆ I∗ and S ⊆ J∗ , so swT ( {i , p} , S ) ≤ swT ∗ ( I∗ , S ) ≤ swT ∗ ( I∗ , J∗ ) ≤ w . Moving to condition ( 2 ) of Definition 3 we note that S fails to be a discriminating set for I∗ with respect to p , only if there exists a row i /∈ I∗ such that swT ( {i , p} , S ) ≤ w . We next show that the probability of this for a particular row i and lag t is at most ( 3|J∗|/n)|S| < ( 3γ)|S| . According to Definition 2 , swT ( {i , p} , S ) ≤ w means that there are Ri , Ti , Rp , Tp(= 0 ) , and Cj , j ∈ S , such that : , ∀j ∈ S . |Ai,j−Ri−Cj+Ti| ≤ w 2 Shifting each row i ∈ I ( in the first inequality ) by Ti and subtracting the second inequality ( of row p ) we obtain
, |Ap,j−Rp−Cj+Tp| ≤ w 2
Let R∗
2 w .
2 w , 1
Therefore , j − R∗ j − R∗
2 w,− 1
2 w ] , [ − 1 j − R∗
2 w , 3 j − R∗ p| ≤ 1 j − R∗ p − R ≤ ( Ap,j − C∗
If |Ai,j − Ap,j − R| ≤ w then : ( Ap,j − C∗
|Ai,j−Ap,j−R| ≤ w for all j ∈ S , and some R(= Ri−Rp ) . Due to the lagged co cluster optimality , we show that there are no more than 3|J∗| columns j that satisfy this inequality . p ) − w ≤ Ai,j − C∗ p ) + w . Since j − R∗ |Ap,j − C∗ 2 w for all j ∈ J∗ , it follows that − 3 2 w ≤ Ai,j − C∗ p − R ≤ 3 j −r| ≤ Lemma 1 : Let J ⊆ J∗ , and let i /∈ I∗ . If |Ai,j−C∗ w/2 for some r and all j ∈ J , then |J| < |J∗| . Proof : ( I , T , J ) , with |J| ≥ |J∗| and I = I∗ ∪ {i} , is a lagged co cluster of sleeve width w satisfying µ(I , J ) > µ(I∗ , J∗ ) , contradicting the optimality of ( I∗ , T ∗ , J∗ ) . Therefore , for a row i /∈ I∗ , lag t and for each of the intervals : [ − 3 2 w ] , there are 2 w ] and [ 1 at most |J∗| columns j such that Ai,j − C∗ p − r lies in that interval , summing to at most 3|J∗| columns satisfying |Ai,j − Ap,j − R| ≤ w . the occurrence probability for some lag t ( −n ≤ t ≤ n ) and some row i ( 1 ≤ i ≤ m ) is bounded ( after substituting |S| ≥ log(4mn)/ log(1/3γ ) ) by 2mn(3γ)|S| ≤ 05 According to Theorem 2 any randomly selected set of size |S| ≥ log(4mn)/ log(1/3γ ) is a discriminating set with probability of at least 05 The bound is very hard to set as γ is unknown . In Section VII we show experimentally that a random subset of size 0.4 log(4mn ) + 2 will do , freeing the user from specifying the γ trade off . Theorem 3 : Let S be a discriminating set for an optimal lagged co cluster ( I∗ , T ∗ , J∗ ) of sleeve width w . Provided p ≥ ln 4/β and S ≥ 2 ln 4/γ|S| , the LC algorithm will mine the optimal lagged co cluster , with probability of at least 05 Proof : As |I∗| ≥ βm , the probability of choosing a row in the outer loop that satisfies p ∈ I∗ is at least β . Thus , the probability of the outer loop failing in all p tries is bounded by ( 1 − β)p ≤ 1/4 . In the inner loop , the probability of satisfying the columns discriminating set S ⊆ J∗ is at least γ|S| , since |J∗| ≥ γn . Following Theorem 2 , any given S ⊆ J∗ is a discriminating set with probability of at least 0.5 with respect to p . Therefore , the probability that all S inner loops iterations fail to find a discriminating set does not exceed ( 1− 1 2 γ|S|)S ≤ 1/4 . It follows that LC chances of mining the optimal lagged co cluster upon a p ∈ I∗ and S ⊆ J∗ is at least 3/4 · 3/4 > 1/2 . When it does , from the discriminating property of S we get that I = I∗ and T = T ∗ . The set J satisfies J ⊇ J∗ as for any column j ∈ J , I∗ and T ∗ : swT ∗ ( I∗ , J∗ ) ≤ swT ∗ ( I∗ , J∗ ∪ {j} ) ≤ w .
From the optimality of ( I∗ , T ∗ , J∗ ) , we obtain J = J∗ .
VI . RUNNING TIME
The total number of iterations is bounded by Theorem 3 as N = pS = O(1/(βγ|S|) ) . The inner for loops running time is O(β(m|S| + n)mn ) , where |S| = O(log mn ) ( see Theorem 2 ) . In all , the running time is polynomial and independent of β : O((m|S| + n)mn/γ|S| ) , for some 0 < γ < 1 . Experiments reported in Section VII show that |S| can be taken as 0.4 log(4mn)+2 and that the number of iterations is always significantly less than the above bound .
VII . EXPERIMENTS
The LC algorithm is extensively evaluated using both artificial and real world data . The use of artificial data , which naturally enables tighter control , is important as it facilitates the examination of specific , isolated properties of the algorithm . Complementary experiments with realworld data include river flow and topographic data . The latter experiments demonstrate the LC algorithm ’s capability in mining both temporal , ie , time reading data , and nontemporal datasets .
A . Experiments with Artificial Data
The advantage of using artificial data is that we have the maximum control in verifying the validity of clusters found ( in comparison to real world data ) . Specifically , the contributions of the experimentation used for the LC algorithm with artificial data are threefold . First , they establish a “ best practice ” for the setting of parameters . Secondly , they enable the verification of theoretical bounds and show that these bounds are coarse while better performance is achieved in practice . Finally , through the experiments , the actual runtime of the algorithm is demonstrated.2
1 ) Sleeve width default : An artifact cluster is a submatrix that was not formed due to some hidden regulatory mechanism but as a mere aggregation of noise . Such artifacts are undesirable as they add irrelevant output . We wish to examine the lagged model from the aspect of finding artifact lagged co clusters , ie , whether it is common to mine such artifacts . In order to answer the question , one must specify the desired sleeve width and the required cluster dimensions . Intuitively , the larger the sleeve width and the smaller the dimensions , the greater the chance of mining artifact clusters . A sleeve width of 5 % of the matrix range , has been shown to be a good trade off for a non lagged model , levelling between mining relevant co clusters and not having artifact , falsified co clusters , due to noise [ 2 ] , [ 19 ] . To examine the efficiency of a 5 % sleeve width for mining lagged co clusters we conducted the following experiment . Random matrices , with values in the range of [ 100 , 1100 ] , of various sizes : [ 100×100 ] , [ 1000×100 ] and [ 10000×100 ] were created . For each random matrix , one million random lagged submatrices were created using different dimensions over all possible lags . The sleeve width for each random lagged submatrix was then computed . Table I presents the result of the experiment . The rows and columns rubrics
2 While the number of iterations is proved to be polynomial , we want to make sure that the actual running time for large inputs is feasible .
Table I
DISTRIBUTION OF SLEEVE WIDTHS . rows columns
2 5 5 8 8
4 2 4 4 8 tail
1.32 % 0.36 % 0.00 % 0.00 % 0.00 % specify the dimension of the random submatrix . The tail rubric specifies the average percentage of cases of which the random lagged submatrix had a sleeve width of at most 5 % . As evident from the table , the larger the submatrix dimensions , the lower the chance of mining an artifact . Even when using very small dimensions ( eg , 5 × 4 ) , the probability of mining lagged co clusters with a sleeve width of 5 % or less is insignificant . Therefore , ordinary mining using practical dimensions , has a non significant probability of mining artifacts .
It is notable that sleeve width is highly dependent on the “ nature ” of the dataset being mined . Nevertheless , in the absence of any prior knowledge , a sleeve width of 5 % is a good default value to use . 2 ) Discriminating set size : The discriminating set size , |S| , directly affects the run time of the LC algorithm . Theorem 2 provides us with the following bound : |S| ≥ log(4mn)/ log(1/3γ ) , where γ specifies the ratio between the number of columns in an optimal lagged co cluster and the number of matrix columns . The bound undesirably depends on γ , a parameter of which the user has no knowledge . In order to get a sense of what the value of |S| is in practice , we conducted the following experiment . We first created random matrices of various sizes : from small ones of [ 10 × 10 ] to large ones of [ 100000 × 100 ] . We set the dimensions of the cluster size to β , γ ∈ {0.1 , 0.4 , 0.6 , 08} Then we generated a random lagged co cluster within the specified dimensions and put it at a random location in the matrix , overriding the existing values . Then , a subset of the lagged co cluster columns was chosen at random 100 , 000 times , and checked whether it was a discriminating set according to Definition 3 . We consider a set of size |S| to be discriminating , if it can successfully discriminate in all of the 100 , 000 times . the relationship between |S| and log(4mn ) . We observe the reconstruction of the linear relationship derived from Theorem 2 . In addition , we obtain from Figure 3 an easy to use , γ free , formula for setting |S| : |S| = 0.36 log2(4mn ) + 2.33 ≈ 0.4 log2(4mn ) + 2 . 3 ) Run time , Number of Iterations and Hit Rate : Theorem 3 states that for N = pS ≥ 2ln24/(βγ|S| ) tries , we are guaranteed to find an optimal lagged co cluster , with a probability of at least 05 The following experiment was conducted in order to test the practical behavior of the following boundaries : ( 1 ) The 0.5 probability boundary ; ( 2 )
Figure 3 depicts
Figure 3 . Discriminating column set size |S| as a function of matrix log size log2(4mn ) .
Figure 4 . Number of iterations needed to mine a lagged co cluster vs . the theoretical bound , for γ = 05
The number of iterations N ; ( 3 ) The actual run time it takes to find a lagged co cluster ( in ms ) . For these purposes we generated a random matrix of size m × n , m = 1000 , n = 1000 , with values in the range of [ 100 , 1100 ] . Inside the matrix , a random lagged co cluster was randomly placed , overriding the original values . The lagged co cluster was of a random size β ∈ [ 0.05 − 0.9 ] , γ ∈ {0.3 , 0.5 , 0.8} and a sleeve width of 5 % . |S| was set to 10 , using the previous experimental result ( see VII A2 ) , for a matrix of size 1000×1000 . Setting N to the limit given in Theorem 3 , and repeating the execution of the algorithm 100 times for each cluster size , we counted : ( 1 ) Hit rate : how many times out of the 100 repetition the algorithm managed to precisely mine the planted cluster ; ( 2 ) Iterations : how many iterations it took in practice to mine the cluster ; ( 3 ) Run time : how long ( in ms ) it took to mine the cluster . The experiments were conducted using the platform : Intel core i7 ( 920 ) @ 2.67GHz CPU with 6GB RAM , Windows 7 64 bit . The algorithm was programmed in Java 17
The results obtained are as follows . • Hit Rate : While the theoretical bound is set for 50 % the actual average hit rate is 91 % .
• Number of Iterations : Figure 4 presents the actual number of iterations needed to mine a lagged co cluster in relation to the theoretical boundary . We present here only results with γ = 0.5 , as the results for the other γ values were insignificantly different . As both γ and |S|
( a ) Smooth terrain with a stream ( b ) Highly complex noisy terrain
Figure 5 . Elevation maps the brighter the greater the elevation . Each map is of size 25× 25 km2 . Map ( 5a ) represents a simple terrain with few dramatic changes . Map ( 5b ) represents a complicated terrain with many hills , mountains , canyons etc . were held fixed at 0.5 and 10 , respectively , we expect N = O(1/β ) . In practice , not only is such behavior found , but the actual number of iterations needed is much smaller at 30% 60 % of the theoretical bound . • Run time : The boundary specified in Section VI is : t = O((m|S|+n)mn/γ|S| ) . Fitting the actual run time to the equation of type : t = c/(βxγy ) ( t in ms ) , where c = ( m|S| + n)mn , we obtain : x = −0.39 , y = 8.87 and c = 32529 As expected , the power of β is almost 0 and the power of γ is close to 10 ( |S| = 10 ) .
To summarize , the LC algorithm managed to mine optimal lagged co clusters with a probability of 91 % which is substantially better than the 50 % theoretical guarantee , and did so in a feasible running time , requiring only 30% 60 % of the theoretical bound for the number of iterations .
B . Experiments on Topographic Data
A topographic map is a 3D representation of a surface ( see Figure 5 ) . Such a map is often represented as a Digital Elevation Map ( DEM ) which is a grid based sample of the surface elevation . Detailed DEM maps are large datasets , eg , consider a 100×100 km2 map with 1 meter grid sample . Such a map has 1010 elevation samples or in other words such a map has 10 Giga pixels . Manipulating and querying such datasets often requires sophisticated algorithms , and in many cases due to the nature of the problem or the size of the dataset , efficient heuristics rather than exact ones [ 22 ] . In this experiment , we wish to examine the capability of the LC algorithm to cluster random viewpoints , ie , skylines seen from different angles . The experiment consisted of 17 different high resolution elevation maps representing various types of terrain such as plains , hills , mountains , lakes and dunes . Each map represents a rectangular area of 25 × 25 km2 , and includes 1.625·106 grid samples . For each terrain , 100 3000 random locations were chosen within it using two steps : ( 1 ) Locating 10 50 random points as centers ; ( 2 ) For each location , ascribing a random center from which the distance is within a random range of [ 0.5 4 ] km . In order to overcome minor obstacles within close range of the observer , y = 0.3648x + 2.3264|S| ≈ 0.4 log2(4mn ) + 20369121507142128|S|log2(4mn)020,00040,00060,00080,0000010203040506070809# IterationsβPractical #iterationsTheoretical #iterations to the angle of the viewpoint .
To strengthen our belief that clusters in such datasets can only be found using the lagged model , we ran a nonlagged co cluster algorithm [ 19 ] on the same datasets , with the same clustering requirements . As expected , in this latter experiment no co clusters were found .
In conclusion , we have shown that , given a topographic map and a skyline view , it is possible to derive the location from which the skyline was seen using the mining of lagged co clusters . The LC algorithm performed well in this case , managing to successfully mine lagged co clusters from different terrain types , with a small number of artifact clusters . The algorithm can thus be used as a classifier in this domain and even as a means of navigation if used continuously [ 23 ] . In addition to the derived spatial location , we can also infer the angle of the viewpoint . The failure of the non lagged algorithm and the success of the LC algorithm implies that the lagged co clusters were mined due to their lagged nature and not as a result of terrain properties . However , terrains that are very flat ( ie , no reference points ) or highly noisy ( a slight location change may lead to a significant skyline change due to the effect of hiding and distortions ) can be a challenge .
C . Experiments on River Flow Data
The final dataset used for our experiments was realtime water data obtained from the US Geological Survey ( USGS ) [ 24 ] . We compiled a dataset containing flow readings of rivers in the states of New Mexico , Colorado and Nevada . There are 539 rows ( objects ) each representing a gauge . The columns show the gauge ’s discharge ( ft3/s ) readings for March 2010 , sampled every 15 minutes , resulting in 2877 columns .
A relevant lagged co cluster will naturally be formed by readings from gauges located along the same river , as water flowing downstream will present a correlated flow between different measuring stations with a lag of time .
The flow of a stream depends on multiple parameters . Many of them change dramatically over time and space : nature ( local and global weather conditions , joining and forking rivers , water evaporation , water loss through the river bed , etc . ) and human influence ( dams , factories , irrigation pools , settlements , pumping stations , sewage systems , etc ) In addition , the data are very noisy due to human and equipment inaccuracy and are characterized by a high missing data ratio ( 23 % ) caused by various reasons : equipment malfunction , river conditions ( effect of ice , flood damage , zero flow ) , station only recording seasonally , etc . Therefore , mining such datasets for lagged co clusters is highly complicated . We consider a cluster to be accurate if all the participating gauges are located within the same basin . We note that it is unlikely to mine a cluster containing all the gauges in a basin . For example , gauges located at the exit of a dam or those which are malfunctioning would not be included .
Figure 6 . Skyline computation : ( A ) The original figure . ( B ) The horizon , only . ( C ) Edge detection . ( D ) The Skyline blocking angle , X axis represents horizontal angle , Y axis represents the vertical angle ( blocking angle ) .
Figure 8 . Relative angle of viewpoint vs . relative lag . For the complex terrain map ( 7c ) there is a 70 % chance of the lag being equal to the angle , and in total , 94 % chance for the lag to be in the range ±1 from the angle of viewpoint . For the complicated terrain map ( 7b ) the chance of the lag equaling the angle climbs to 89 % with a total chance of 99 % of being in the range of ±1 . For the simple terrain map ( 7a ) the chance of a lag equaling the angle is 97 % with a total chance of 100 % of being in the range of ±1 . a random height value in the range of [ 10 30 ] meters above ground was assigned to each location . In order to create a viewpoint , each location was assigned a random angle value a0 in the range of [ 0,60 ] degrees representing the skyline starting angle . Each skyline consisted of 300 samples representing the angle range of [ a0 , a0 + 300 ] degrees . For each angle the maximal z − blocking angle was computed , as shown in Figure 6 .
The results obtained indicate that the algorithm can mine precise and valid clusters . Figures ( 7a ) , ( 7b ) and ( 7c ) present lagged co cluster results for various terrain maps . Each black dot represents a viewpoint , while red lines represent a lagged co cluster , binding those viewpoints . that ,
It would seem only natural for this dataset in every mined lagged co cluster , the angle between any two viewpoints will be equal to the lag between them . Figure 8 presents the probability of occurrences of ( Angle − Lag ) ( 0 means Angle ≡ Lag ) corresponding to the above terrain maps . The graph shows that in all the different terrain maps , there is a very high chance of the mined lag being very close
0%20%40%60%80%100% 2 1012Angle Lagcomplex mapcomplicated mapsimple map ( a ) simple terrain map
( b ) complicated terrain map
( c ) complex terrain map
Lagged co clusters in different terrain types . Map ( 7a ) represents a simple terrain . The terrain is characterized by tight , remotely situated Figure 7 . centroids , with condensed surrounding viewpoints . There are no artifact clusters found ( no inter cluster line ) . Map ( 7b ) represents a complicated terrain . The terrain is characterized by clusters’ centroids being close to each other , while the clusters’ diameters are large ( viewpoints are spread ) . The mined lagged co clusters are still relevant ( belong to the same spatial cluster ) and tight as there are very few inter cluster connections . Map ( 7c ) represents a complex terrain . The terrain contains close , sometimes overlapping spatial clusters with highly scattered viewpoints . This makes it hard in some cases , to even visually classify a viewpoint to a spatial cluster . Here , we have a reasonable number of artifact clusters ( inter cluster lines ) .
92 % followed the above logic . The other 8 % had the following characteristics : ( 1 ) Human intervention , eg , a dam or an irrigation area ( 35 clusters ) ; ( 2 ) Environment factors , eg , a high lake feeding two streams ( 6 clusters ) . Therefore , the lag proved to be a good indication of the direction of water flow .
As with the topographic data , we ran a non lagged clustering algorithm [ 19 ] on the above dataset finding only 4 clusters ( in comparison to 488 found by the LC algorithm ) . All clusters were trivial and caused by : ( 1 ) Irrigation area ; ( 2 ) Station position at the exit of a dam ; ( 3 ) Short distance between stations ( ie , river sampling of 15 minutes is a gross granularity ) .
VIII . DISCUSSION , CONCLUSIONS AND FUTURE WORK The importance of co clustering is unquestionable and has been thoroughly discussed and demonstrated in cited prior work . The lagged co clustering model generalizes the coclustering model , enabling the inclusion of an additional important dimension , a lag aspect , in the regulatory paradigm . The real life datasets used in the former section were large , highly noisy , contained many missing values and were rich in overlapping clusters . While the LC algorithm managed to find precise , coherent and relevant lagged co clusters in a practicable time and with almost no artifacts , the use of a non lagged co clustering method did not result in any relevant clusters . This encouraging result is important in the sense of model validation and suggests a great potential for mining lagged co clusters in many other fields of science , technology and medicine ( eg , gene expression data [ 8 ] , [ 9 ] , MRI data [ 1] ) . It is notable that not only datasets with a time aspect can benefit from such use of the algorithm , and the lagged aspect can have various interpretations ( eg , in the topographic dataset used in our experiment , the lagged aspect is the point of view ) .
As a generalization of the co clustering problem , the lagged problem is NP complete for most interesting optimality measure . The LC algorithm presented in this paper relies
Figure 9 . Northern river lagged co clusters along the Pyramid river , Nevada , USA . There are 7 stations and 14 lagged co clusters marked by dotted green balloons ( gauge stations ) and cyan lines ( connecting cluster ’s members ) . Southern river a lagged co cluster along the Carson river , Nevada , USA . Pink starred balloons mark the gauges while an orange line marks connected cluster ’s members . For visibility purposes , the rivers’ routes are partially painted in blue .
Using the LC algorithm , we mined 488 lagged co clusters ( see example in Figure 9 ) . Of those , 461 clusters ( 94 % ) were in the same state . Manually checking the 27 inter state clusters , we found that at least one gauge is located at the exit of a dam thus changing the flow of the river . 405 clusters ( 83 % ) were in the same basin . Manually checking the 56 inter basin clusters reveals the following reasons for the mismatch : ( 1 ) Technical administrative division of basins into upper middle ( 2 ) Fork in a river : streams and lower part ( 12 clusters ) ; merging from different basins ( 36 clusters ) ; ( 3 ) Gauges are located in swampy areas ( 8 clusters ) . Therefore , we achieved an accuracy of 94 % on a state granularity and an accuracy of 93 % on a basin granularity ( considering ( 1 ) and ( 2 ) above as valid ) , while providing relevant explanations for the artifact lagged co clusters ( dams and swampy areas ) enabling future pre processing exclusion .
As water flows downstream , we expect the lag difference between any two stations to be positive if their altitude difference is also positive . Out of the 488 clusters found , on a strong theoretical base , enabling a probability promise on mining an optimal lagged co cluster and a theoretical bound to the number of iterations it will take . The experiments using artificial environment , reported in the former section , reveal a substantially better actual performance in terms of accuracy and efficiency ( in comparison to the theoretical bounds ) . Unlike other algorithms , LC does not assume any specific scoring merit on the mined clusters . Furthermore , the optimal cluster is mined with no additional rows or columns , ie , ( I , T , J ) = ( I∗ , T ∗ , J∗ ) . Since the LC algorithm iterations are independent , it can be reconstructed as a polynomial time approximation scheme ( PTAS ) in order to increase precision . The use of parallel computing or special hardware can boost the performance even further .
The algorithm has several configurable parameters , for which this paper presents default values . As in non lagged co clustering models , one of the key parameters that needs to be set carefully in order to mine meaningful clusters is the sleeve width . Setting it too high might result in many artifact clusters , while setting it too low might preclude valid clusters . In order to choose an appropriate value for this parameter , one can adopt any of the methods suggested for non lagged co clustering ( eg , gradual increase , starting from a relatively small sleeve ) .
As in non lagged co clustering , the ability to mine lagged co clusters offers important functionalities , eg , using the tool as a classifier . Nevertheless , unlike non lagged coclustering , the ability to mine lagged co clusters encapsulates also a forecasting functionality , which can be highly useful in numerous applications ranging from meteorology to stock markets . While the current results supply some basic forecasting functionality ( following the lagged pattern found ) , we believe there is far more that can be developed in this aspect in terms of future research .
REFERENCES
[ 1 ] A . Jain , M . Murty , and P . Flynn , “ Data clustering : a review , ” ACM computing surveys , vol . 31 , no . 3 , pp . 264–323 , 1999 .
[ 2 ] Y . Cheng and G . Church , “ Biclustering of expression data , ” in Proceeding of ISMB’00 . AAAI Press , 2000 , pp . 93–103 .
[ 3 ] D . Jiang , C . Tang , and A . Zhang , “ Cluster analysis for gene expression data : A survey , ” IEEE Transactions on Knowledge and Data Engineering , vol . 16 , no . 11 , pp . 1370–1386 , 2004 .
[ 4 ] S . Madeira and A . Oliveira , “ Biclustering algorithms for biological data analysis : a survey , ” TCBB , vol . 1 , no . 1 , pp . 24–45 , 2004 .
[ 7 ] A . Tanay , R . Sharan , and R . Shamir , “ Discovering statistically significant biclusters in gene expression data , ” Bioinformatics , vol . 1 , no . 1 , pp . 1–9 , 2002 .
[ 8 ] Y . Kluger , R . Basri , J . Chang , and M . Gerstein , “ Spectral biclustering of microarray data : coclustering genes and conditions , ” Genome Research , vol . 13 , no . 4 , pp . 703–716 , 2003 .
[ 9 ] G . Getz , E . Levine , and E . Domany , “ Coupled two way clustering analysis of gene microarray data , ” PNAS , vol . 97 , no . 22 , pp . 12 079–12 084 , 2000 .
[ 10 ] Y . Yin , Y . Zhao , B . Zhang , and G . Wang , “ Mining TimeShifting Co regulation Patterns from Gene Expression Data , ” Advances in Data and Web Management , pp . 62–73 , 2007 .
[ 11 ] O . Yilmaz and S . Doherty , Seismic data analysis . of Exploration Geophysicists Tulsa , 2001 .
Society
[ 12 ] D . Y . Kenett , Y . Shapira , and E . Ben Jacob , “ RMT Assessments of the Market Latent Information Embedded in the Stocks’ Raw , Normalized and Partial Correlations , ” Journal of Probability and Statistics . Article ID 249370 , 2009 .
[ 13 ] C . Granger , “ Investigating causal relations by econometric models and cross spectral methods , ” Econometrica : Journal of the Econometric Society , vol . 37 , no . 3 , pp . 424–438 , 1969 .
[ 14 ] L . Ji and K . Tan , “ Identifying time lagged gene clusters using gene expression data , ” Bioinformatics , vol . 21 , no . 4 , pp . 509– 516 , 2005 .
[ 15 ] S . C . Madeira , J . P . Gonc¸alves , and A . L . Oliveira , “ Efficient Biclustering Algorithms for identifying transcriptional regulation relationships using time series gene expression data , ” INESC ID Tec . Rep . 22/2007 , 2007 .
[ 16 ] J . Huang , “ Identifying co regulated gene group from timelagged gene cluster using cell cycle expression data , ” PhD dissertation , National Central University , Taiwan , 2005 .
[ 17 ] R . Bellman , “ Dynamic Programming , ” Science , vol . 153 , no .
3731 , pp . 34–37 , 1966 .
[ 18 ] X . Xu , Y . Lu , K . Tan , and A . Tung , “ Finding Time lagged
3D Clusters , ” in Proc . of ICDE’09 , 2008 , pp . 445–456 .
[ 19 ] A . Melkman and E . Shaham , “ Sleeved CoClustering , ” in Proc . of KDD’04 . ACM , 2004 , pp . 635–640 .
[ 20 ] J . Yang , H . Wang , W . Wang , and P . Yu , “ Enhanced BiclusIEEE tering on Expression Data , ” in Proc . of BIBE’03 . Computer Society , 2003 , pp . 321–327 .
[ 21 ] J . Roddick and M . Spiliopoulou , “ A survey of temporal knowledge discovery paradigms and methods , ” TKDE , vol . 14 , no . 4 , pp . 750–767 , 2002 .
[ 22 ] T . Abraham and J . Roddick , “ Survey of spatio temporal databases , ” GeoInformatica , vol . 3 , no . 1 , pp . 61–99 , 1999 .
[ 5 ] S . Lonardi , W . Szpankowski , and Q . Yang , “ Finding biclusters by random projections , ” Theoretical Computer Science , vol . 368 , no . 3 , pp . 217–230 , 2006 .
[ 23 ] H . Zhang , P . Yin , X . Zhang , and X . Shen , “ A robust adaptive horizon recognizing algorithm based on projection , ” Transactions of the Institute of Measurement and Control , 2010 .
[ 6 ] C . Procopiuc , M . Jones , P . Agarwal , and T . Murali , “ A Monte Carlo algorithm for fast projective clustering , ” in Proc . of SIGMOD’02 , 2002 , pp . 418–427 .
[ 24 ] US Geological Survey Real Time Water Data , US Information System ,
Geological Survey , National Water 2001 . [ Online ] . Available : http://waterdatausgsgov/nwis
