Learning Markov Network Structure with Decision Trees
Daniel Lowd∗ and Jesse Davis†
∗Department of Computer and Information Science
University of Oregon , Eugene , OR 97403
Email : lowd@csuoregonedu
† Department of Computer Science , Katholieke Universiteit Leuven
Celestijnenlaan 200A , POBox 2402 , 3001 Heverlee , Belgium
Email : jessedavis@cskuleuvenbe
Abstract—Traditional Markov network structure learning algorithms perform a search for globally useful features . However , these algorithms are often slow and prone to finding local optima due to the large space of possible structures . Ravikumar et al . [ 1 ] recently proposed the alternative idea of applying L1 logistic regression to learn a set of pairwise features for each variable , which are then combined into a global model . This paper presents the DTSL algorithm , which uses probabilistic decision trees as the local model . Our approach has two significant advantages : it is more efficient , and it is able to discover features that capture more complex interactions among the variables . Our approach can also be seen as a method for converting a dependency network into a consistent probabilistic model . In an extensive empirical evaluation on 13 datasets , our algorithm obtains comparable accuracy to three standard structure learning algorithms while running 1 4 orders of magnitude faster .
Keywords Markov networks ; structure learning ; decision trees ; probabilistic methods
I . INTRODUCTION
Markov networks are an undirected , probabilistic graphical model for compactly representing a joint probability distribution over set of variables . Traditional Markov network structure learning algorithms perform a global search to learn a set of features that accurately captures high probability regions of the instance space . These approaches are often slow for two reasons . First , the space of possible structures is exponential in the number of variables . Second , evaluating candidate structures requires assigning a weight to each feature in the model . Weight learning requires performing inference over the model , which is often intractable .
Recently , Ravikumar et al . [ 1 ] proposed the alternative idea of learning a local model for each variable and then combining these models into a global model . Their method builds an L1 logistic regression model to predict the value of each variable in terms of all other variables . Next , it constructs a pairwise feature between the target variable and each other variable with non zero weight in the L1 logistic regression model . Finally , it adds all constructed features to the model and learns their associated weights using any standard weight learning algorithm . While this approach greatly improves the tractability of structure learning , it is limited to modeling pairwise interactions , ignoring all higher order effects . Furthermore , it still exhibits long run times for domains that have large numbers of variables .
In this paper , we propose DTSL ( Decision Tree Structure Learner ) , which builds on the approach of Ravikumar et al . by substituting a probabilistic decision tree learner for L1 logistic regression . Probabilistic decision trees can represent much richer structures that model interactions among large sets of variables . DTSL learns probabilistic decision trees to predict the value of each variable and then converts the trees into sets of conjunctive features . We propose and evaluate several different methods for performing the conversion . Finally , DTSL merges all learned features into a global model . Weights for these features can be learned using any standard Markov network weight learning method .
We conducted an extensive empirical evaluation on 13 real world datasets . We found that DTSL is 1 4 orders of magnitude faster than alternative structure learning algorithms while still achieving equivalent accuracy .
The remainder of our paper is organized as follows . Section 2 provides background on Markov networks . Section 3 describes our method for learning Markov networks using decision trees . Section 4 presents the experimental results and analysis and Section 5 contains conclusions and future work .
II . MARKOV NETWORKS
A . Representation
A Markov network is a model for the joint distribution of a set of variables X = ( X1 , X2 , . . . , Xn ) [ 2 ] . It is composed of an undirected graph G and a set of potential functions φk . The graph has a node for each variable , and the model has a potential function for each clique in the graph . The joint distribution represented by a Markov network is :
P ( X = x ) =
φk(x{k} )
( 1 )
1
Z￿k where x{k} is the state of the kth clique ( ie , the state of the variables that appear in that clique ) , and Z is a normalization constant called the partition function . Markov networks are often conveniently represented as log linear models , with each clique potential replaced by an exponentiated weighted sum of features of the state :
( 2 )
P ( X = x ) =
1 Z exp￿j wjfj(x)
A feature fj(x ) may be any real valued function of the state . For discrete data , a feature typically is a conjunction of tests of the form Xi = xi , where Xi is a variable and xi is a value of that variable . We say that a feature matches an example if it is true of that example .
B . Inference
The main inference task in graphical models is to compute the conditional probability of some variables ( the query ) given the values of some others ( the evidence ) , by summing out the remaining variables . This problem is #P complete . Thus , approximate inference techniques are required . One widely used method is Markov chain Monte Carlo ( MCMC ) [ 3 ] , and in particular Gibbs sampling , which proceeds by sampling each variable in turn given its Markov blanket , the variables it appears with in some potential . These samples can be used to answer probabilistic queries by counting the number of samples that satisfy each query and dividing by the total number of samples . Under modest assumptions , the distribution represented by these samples will eventually converge to the true distribution . However , convergence may require a very large number of samples , and detecting convergence is difficult .
C . Weight Learning
The goal of weight learning is to select feature weights that maximize a given objective function . One of the most popular objective functions is the log likelihood of the training data . In a Markov network , log likelihood is a convex function of the weights , and thus weight learning can be posed as a convex optimization problem . However , this optimization typically requires evaluating the log likelihood and its gradient in each iteration . This is typically intractable to compute exactly due to the partition function . Furthermore , an approximation may work poorly : Kulesza and Pereira [ 4 ] have shown that approximate inference can mislead weight learning algorithms .
A more efficient alternative , widely used in areas such as spatial statistics , social network modeling and language processing , is to optimize the pseudo likelihood [ 5 ] instead . Pseudo likelihood is the product of the conditional probabilities of each variable given its Markov blanket : log P •w(X = x ) =
￿V j=1￿N i=1 log Pw(Xi,j = xi,j|M Bx(Xi,j ) )
( 3 ) where V is the number of variables , N is the number of examples , xi,j is the value of the jth variable of the ith example , M Bx(Xi,j ) is the state of Xi,j ’s Markov blanket in the data . Pseudo likelihood and its gradient can be computed efficiently and optimized using any standard convex optimization algorithm , since the pseudo likelihood of a Markov network is also convex .
D . Structure Learning
Della Pietra et al . ’s algorithm [ 2 ] is the standard approach to learning the structure of a Markov network . The algorithm starts with a set of atomic features ( ie , just the variables in the domain ) . It creates candidate features by conjoining each feature to each other feature , including the original atomic features . It calculates the weight for each candidate feature by assuming that all other feature weights remain unchanged , which is done for efficiency reasons . It uses Gibbs sampling for inference when setting the weight . Then , it evaluates each candidate feature f by estimating how much adding f would increase the log likelihood . It adds the feature that results in the largest gain to the feature set . This procedure terminates when no candidate feature improves the model ’s score .
Recently , Davis and Domingos [ 6 ] proposed an alternative bottom up approach , called BLM , for learning the structure of a Markov network . BLM starts by treating each complete example as a long feature in the Markov network . The algorithm repeatedly iterates through the feature set . It considers generalizing each feature to match its k nearest previously unmatched examples by dropping variables . If incorporating the newly generalized feature improves the model ’s score , it is retained in the model . The process terminates when no generalization improves the score . to predict
A recent L1 regularization based approach to structure learning is the method of Ravikumar et al . [ 1 ] . It learns the structure by trying to discover the Markov blanket of each variable ( ie , its neighbors in the network ) . It considers each variable Xi in turn and builds an L1 logistic regression the value of Xi given the remaining model variables . L1 regularization encourages sparsity , so that most of the variables end up with a weight of zero . The Markov blanket of Xi is all variables that have non zero weight in the logistic regression model . In the limit of infinite data , consistency is guaranteed ( ie , Xi is in Xj ’s Markov blanket if and only if Xj is in Xi ’s Markov blanket ) . In practice , this is often not the case and there are two methods to decide which edges to include in the network . One includes an edge if either Xi is in Xj ’s Markov blanket or Xj is in Xi ’s Markov blanket . The other includes an edge if both Xi is in Xj ’s Markov blanket and Xj is in Xi ’s Markov blanket . Finally , all features are added to the model and their weights are learned globally using any standard weight learning algorithm .
III . ALGORITHM
We now describe our method for learning Markov network structure from data , DTSL ( Decision Tree Structure
Table I
THE DTSL ALGORITHM
Table II
DTSL TREE LEARNING SUBROUTINE function DTSL(D , X ) F ← ∅ for Xi ∈ X do
Ti ← LEARNTREE(Xi , D ) Fi ← GENERATEFEATURES(Ti ) F ← F ∪ Fi end for M ←LEARNWEIGHTS(F , D ) return M
.+)/+$%+,0(((1(
+$(
+,(
!"#$%"#&'( !"#)%"#*'( !"#*%"#)'(
Figure 1 . Example of a probabilistic decision tree .
Learning ) . Table I outlines out basic approach . For each variable Xi , we learn a probabilistic decision tree to represent the conditional probability of Xi given all other variables , P ( Xi|X − Xi ) . Each tree is converted to a set of conjunctive features capable of representing the same probability distribution as the tree . Finally , all features are taken together in a single model and weights are learned globally using any standard weight learning algorithm .
This is similar in spirit to learning a dependency network [ 7 ] : Both dependency networks ( with tree distributions ) and DTSL learn a probabilistic decision tree for each variable and combine the trees to form a probabilistic model . However , a dependency network may not represent a consistent probability distribution , and inference can only be done by Gibbs sampling . In contrast , the Markov networks learned by DTSL always represent consistent probability distributions and allow inference to be done by any standard technique , such as loopy belief propagation [ 8 ] , mean field , or MCMC .
We now describe each step of DTSL in more detail .
A . Learning Trees
A probabilistic decision tree represents a probability distribution over a target variable , Xi , given a set of inputs . Each interior node tests the value of an input variable and each of its outgoing edges is labeled with one of the outcomes of that test ( eg , true or false ) . Each leaf node contains the conditional distribution ( eg , multinomial ) of the target variable given the test outcomes specified by its ancestor nodes and edges in the tree . We focus on discrete variables and consider tests of the form Xj = xj , where function LEARNTREE(Xi , D ) best split ← ∅ best score ← 0 for Xj ∈ X − Xi do for xj ∈ Val(Xj ) do S ← ( Xj = xj ) if SCORE(S , Xi , D ) > best split then best split ← S best score ←SCORE(S , Xi , D ) end if end for end for if best score > log κ then
( Dt , Df ) ←SPLITDATA(D , best split ) TL ←LEARNTREE(Xi , Dt ) TR ←LEARNTREE(Xi , Df ) return new TreeVertex(best split , TL , TR ) else end if
Use D to estimate P ( Xi ) return new TreeLeaf(P ( Xi ) )
Xj is a variable and xj is value of that variable . Each conditional distribution is represented by a multinomial . Figure 1 contains an example of a probabilistic decision tree . We can learn a probabilistic decision tree from data in a depth first manner , one split at a time . We select a split at the root , partition the training data into the sets matching each outgoing branch , and recurse . We select each split to maximize the conditional log likelihood of the target variable . This is very similar to using information gain as the split criterion . We used multinomials as the leaf distributions with a Dirichlet prior ( α = 1 ) for smoothing . In order to help avoid overfitting , we used a structure prior P ( S ) ∝ κp , where p is the number of parameters , as in Chickering et al . [ 9 ] .
Pseudocode for the tree learning subroutine is in Table II .
B . Generating Features
While decision trees are not commonly thought of as a log linear model , any decision tree can be converted to a set of conjunctive features . In addition to a direct translation ( DEFAULT ) , we explored four modifications ( PRUNE , PRUNE 10 , PRUNE 5 , and NONZERO ) which could yield structures with easier weight learning or better generalization .
The DEFAULT feature generation method is a direct translation of a probabilistic decision tree to an equivalent set of features . For each leaf in the decision tree , we generate a rule for each state of the target variable , containing a condition for each ancestor in the decision tree . For example , to convert the decision tree in Figure 1 to a set of rules , we generate two features for each leaf , one where X4 is true and one where X4 is false . The complete list of features is as follows :
1 ) X1 = T ∧ X4 = T
2 ) X1 = T ∧ X4 = F 3 ) X1 = F ∧ X2 = T ∧ X4 = T 4 ) X1 = F ∧ X2 = T ∧ X4 = F 5 ) X1 = F ∧ X2 = F ∧ X4 = T 6 ) X1 = F ∧ X2 = F ∧ X4 = F By using the log probability at the leaf as the rule ’s weight , we obtain a log linear model representing the same distribution . By applying this transformation to all decision trees , we obtain a set of conjunctive features that comprise the structure of our Markov network . However , their weights may be poorly calibrated ( eg , due to the same feature appearing in several decision trees ) , so weight learning is still necessary .
The PRUNE method expands the set of features generated by DEFAULT in order to make learning and inference easier . One disadvantage of the DEFAULT procedure is that it generates very long features with many conditions when the source trees are deep . Intuitively , we would like to capture the coarse interactions with short features and the finer interactions with longer features , rather than representing everything with long features . In the PRUNE method , we generate additional features for each path from the root to an interior node , not just paths from the root to a leaf . This is equivalent to applying the default feature generation method to all possible “ pruned ” versions of a decision tree , that is , where one or more interior nodes are replaced with leaves . This yields two additional rules , in addition to those enumerated above :
1 ) X1 = F ∧ X4 = T 2 ) X1 = F ∧ X4 = F The PRUNE 10 and PRUNE 5 methods extend PRUNE by limiting the tree to a maximum depth of 10 and 5 , respectively . This can help avoid overfitting .
Our final feature generation method , NONZERO , is similar to DEFAULT , but removes all false variable constraints in a post processing step . For example , the decision tree in Figure 1 would be converted to the following set of rules :
1 ) X1 = T ∧ X4 = T 2 ) X1 = T 3 ) X2 = T ∧ X4 = T 4 ) X2 = T 5 ) X4 = T
This simplification is designed for sparse binary domains such as text , where a value of false or zero contains much less information than a value of true or one .
C . Asymptotic Complexity
Let n be the number of variables , m be the number of training examples , and l be the number of values per variable . The complexity of selecting the first split is O(lmn ) , since we must compute statistics for each of the l values of each of the n variables using all of the m examples . At the next level , we now have two splits to select : one for the left child and one for the right child of the original split . However , since the split partitions the training data into two sets , each of the m examples is only considered once , either for the left split or the right split , leading to a total time of O(lmn ) at each level . If each split assigns a fraction of at least 1/k examples to each child , then the depth is at most O(logk(m) ) , yielding a total complexity of O(lmn logk(m ) ) for one tree , and O(lmn2 logk(m ) ) for the entire structure . Depending on the patterns present in the data , the depth of the learned trees could be much less than logk(m ) , leading to faster run times in practice . For large datasets or streaming data , we can apply the Hoeffding tree algorithm instead [ 10 ] , which uses the Hoeffding bound to select decision tree splits after enough data has been seen to make a confident choice , rather than using all available data .
IV . EMPIRICAL EVALUATION
We evaluate our approach on 13 real world datasets . The goals of our experiments are two fold . First , we want to compare the run time and accuracy of DTSL to several other state of the art Markov network structure learners : the algorithm of Della Pietra et al . [ 2 ] , which we refer to as DP ; BLM [ 6 ] ; and L1 regularized logistic regression [ 1 ] . Second , we want to evaluate whether DTSL ’s pruning heuristics result in more accurate models .
A . Methods
We used DTSL and each of the baselines to learn struc tures for all 13 datasets .
DTSL was implemented in OCaml . For both BLM and DP , we used the publicly available code of Davis and Domingos [ 6 ] . For Ravikumar et al . ’s approach , we used the OWL QN software package [ 11 ] for performing the L1 logistic regression .
The output of each structure learning algorithm is a set of conjunctive features . To learn weights , we optimized the pseudo likelihood of the data via the limited memory BFGS algorithm [ 12 ] since optimizing the likelihood of the data is prohibitively expensive for the domains we consider .
Like Lee et al . [ 13 ] , we evaluated our algorithm using test set conditional marginal log likelihood ( CMLL ) . Calculating the CMLL required dividing the variables into a query set Q and an evidence set E . Then , for each test example we computed CM LL(X = x ) = ￿i∈Q log P ( Xi = xi|E ) .
For each domain , we divided the variables into four disjoint groups . One set served as the query variables while the remaining three sets served as evidence . We repeated this procedure such that each set served as the query variables . We computed the conditional marginal probabilities using the MC SAT inference algorithm [ 14 ] . For all three domains , we set the burn in to 1,000 samples and then computed the probability using the next 10,000 samples .
Table III
DATA SET CHARACTERISTICS
Data Set
NLTCS MSNBC KDDCup 2000 Plants Audio Jester Netflix MSWeb Book EachMovie WebKB 20 Newsgroups Reuters 52
Train Set Size 16,181 291,326 180,092 17,412 15,000 9,000 15,000 29,441 8,700 4,524 2,803 11,293 6,532
Tune Set Size 2,157 38,843 19,907 2,321 2,000 1,000 2,000 3,270 1,159 1,002 558 3,764 1,028
Test Set Size 3,236 58,265 34,955 3,482 3,000 4,116 3,000 5,000 1,739 591 838 3,764 1,540
Num . Vars .
Density
16 17 64 69 100 100 100 294 500 500 843 930 941
0.332 0.166 0.008 0.180 0.198 0.610 0.541 0.010 0.016 0.058 0.063 0.049 0.037
We tuned all algorithms using separate validation sets , the same validation sets used by Davis and Domingos . For DTSL , we selected the structure prior κ for each domain that minimized the total log loss of all probabilistic decision trees on the validation set . The values of κ we used were powers of 10 , ranging from 0.0001 to 10 For each feature generation method , we then tuned the Gaussian weight prior to maximize CMLL on the validation set , with values of 100 , 10 , 1 , and 01 For comparisons to other algorithms , we selected the DTSL model with the best overall CMLL score on the validation set .
For L1 , on each dataset we tried the following values of the prior λ : 1 , 2 , 5 , 10 , 25 , 50 , 100 , 200 , 500 , and 1000 . We also tried both methods of making the Markov blankets consistent , and tuned the weight prior as we did with DTSL . ( Tuning the Gaussian weight prior allowed us to get better results than reported by Davis and Domingos [ 6] . )
For BLM and DP , we kept the tuning settings used by Davis and Domingos . Additional tuning of the weight prior might lead to slightly better results .
All of our code is available at http://ixcsuoregonedu/
∼lowd/dtsl under a modified BSD license . B . Data Sets
For our experiments , we selected a subset of the domains used by Davis and Domingos [ 6].1 We excluded the domains that had multivalued variables encoded as multiple binary variables , since this leads to artificial deterministic dependencies . Table III describes the characteristics of each dataset . Datasets are listed in increasing order by number of variables .
From the UCI machine learning repository [ 15 ] we used : KDDCup 2000 data , MSNBC anonymous web data , MSWeb anonymous web data and Plants domains . The KDD Cup 2000 clickstream prediction data set [ 16 ] consists of web session data taken from an online retailer . Using the subset of
1Publicly available at http://alchemycswashingtonedu/papers/davis10a
Hulten and Domingos [ 17 ] , each example initially consisted of 65 Boolean variables , corresponding to whether or not a particular session visited a web page matching a certain category . We dropped one variable that was always set to zero in the training data . The MSNBC anonymous web data contains information about whether a user visited a top level MSNBC page during a particular session . We created one variable for each page , which is true if the user visited that particular page during a session . The MSWeb anonymous web data contains visit data for 294 areas ( Vroots ) of the Microsoft web site , collected during one week in February 1998 . Again , we created one variable for each page , which is true if the user visited that particular page during a session . The Plants dataset consists of different plant types and locations where they are found . We constructed one binary feature for each location , which is true if the plant is found there .
The National Long Term Care Survey ( NLTCS ) data consist of binary variables that measure an individual ’s ability to perform different daily living activities.2
We used three text domains : 20 Newsgroups , Reuters52 and WebKB.3 For 20 Newsgroups , we only considered words that appeared in at least 200 documents . For Reuters and WebKB , we only considered words that appeared in at least 50 documents . For all three datasets , we created one binary feature for each word . The text domains contained roughly a 50 50 train test split , whereas all other domains used around 75 % of the data for the training , 10 % for tuning , and 15 % for testing . Thus we split the test set of these domains to make the proportion of data devoted to each task more closely match the other domains used in the empirical evaluation .
Finally , we considered several collaborative filtering problems : Audio , Book , EachMovie , Jester and Netflix . The Audio dataset consists of information about how often a user listened to a particular artist.4 The data was provided by the company Audioscrobbler before it was acquired by Lastfm We focused on the 100 most listened to artists . We used a random subset of the data and reduced the problem to “ listened to ” or “ did not listen to . ” The Book Crossing ( Book ) dataset [ 18 ] consists of a users rating of how much they liked a book . We considered the 500 most frequently rated book . We reduced the problem to “ rated ” or “ not rated ” and considered all people who rated more than of these books . EachMovie5 is a collaborative filtering dataset in which users rate movies they have seen . We focused on the 500 most rated movies , and reduced each variable to “ rated ” or “ not rated ” . The Jester dataset [ 19 ] consists of users’ real valued ratings for 100 jokes . For Jester we
2http://libstatcmuedu/datasets/ 3http://webistutlpt/∼acardoso/datasets/ 4http://www etudiroumontrealca/∼bergstrj/audioscrobbler data.html 5Provided by Compaq at http://researchcompaqcom/SRC/eachmovie/ ; no longer available for download , as of October 2004 . selected all users who had rated all 100 jokes , and reduced their preferences to “ like ” and “ dislike ” by thresholding the real valued preference ratings at zero . Finally , we considered a random subset of the Netflix challenge data and focused on the 100 most frequently rated movies and reduced the problem to “ rated ” or “ not rated . ”
C . Results
First , we compared the accuracy of the different DTSL feature generation methods : DEFAULT , PRUNE , PRUNE 5 , PRUNE 10 , and NONZERO . Results are in Table IV . On 11 out of 13 datasets , PRUNE is more accurate than DEFAULT , sometimes substantially so . PRUNE 10 and PRUNE 5 sometimes improve on the accuracy of PRUNE when PRUNE seems to be overfitting , such as on MSWeb and the text datasets ( WebKB , 20 Newsgroups , Reuters 52 ) . NONZERO worked surprisingly well , yielding the most accurate models on eight out of 13 datasets . Its use of fewer and shorter features may be key to avoiding overfitting . Overall , PRUNE or NONZERO is almost always the best choice , yielding the best CMLL on 11 datasets and a close second on the remaining two .
Additional characteristics of the features generated by each method are in Table V . “ Average Feature Length ” is the average number of conditions per feature . The PRUNE method leads to roughly twice as many features as DEFAULT , which is what one would expect , since half of the nodes in a balanced binary tree are leaves and the other half are interior nodes . NONZERO typically yields the shortest and the fewest rules , as expected .
We then compared DTSL to three standard Markov network structure learners : L1 regularized logistic regression [ 1 ] , BLM [ 6 ] , and DP [ 2 ] . We also include Atomic , a model that assumes all variables are independent , as a simple baseline . Accuracy and timing results are in Table VI . For the comparison , we selected the DTSL method that performed best on the validation set . In some cases , such as KDDCup 2000 , this was not the method that performed best on the test data . Figure 2 contains scatterplots comparing DTSL to each baseline method .
DTSL achieves the best overall performance on five of the 13 datasets . We compare the performance of DTSL to the other algorithms using the Wilcoxon signed ranks tests , where the test set CMLL of each dataset appears as one sample in the significance test . DTSL outperforms L1 on six of the 13 domains which results in no significant difference according to a Wilcoxon signed ranks test . Even for the datasets where DTSL performs worse than L1 , it offers comparable accuracy , as shown by the scatterplots . DTSL ’s accuracy is substantially better than L1 ’s on the Plants and MSNBC domains . The average feature length for DTSL is 7.61 and 10.42 for Plants and MSNBC , respectively , which supports the hypothesis that inducing longer features can improve the performance of a model .
DTSL achieves a better CMLL score than BLM on 10 of the 13 domains . DTSL significantly outperforms BLM at the 0.006 significance level according to a Wilcoxon signedranks test . DTSL beats Della Pietra et al . ’s algorithm on 12 of the 13 domains . DTSL significantly outperforms Della Pietra et al . at the 0.0008 significance level according to a Wilcoxon signed ranks test .
On average , DTSL is 16 times faster than L1 and 870 times faster than BLM . DTSL has a faster run time than L1 , BLM and Della Pietra et al . ’s algorithm on all 13 domains . DTSL is significantly faster than each of the other algorithms at less than 0.001 significance level according to a Wilcoxon signed ranks test .
For all algorithms , timing results are for structure selection only , excluding tuning and weight learning , which were not heavily optimized . For BLM and Della Pietra et al . , structure learning is the bottleneck , always taking significantly longer than weight learning . Due to L1 ’s greater speed , weight learning was slower than L1 structure learning on three datasets . Since DTSL is even faster , weight learning was slower than DTSL structure learning on every dataset . Furthermore , because DTSL often selected structures with longer or more features than L1 , weight learning was often slower on DTSL ’s models than L1 ’s , in spite of the fact that the same weight learning methods were employed for all models . Since DTSL effectively solves the problem of slow structure learning , efficient weight learning becomes increasingly important . A stochastic optimization algorithm , such as SGD QN [ 20 ] , might yield significantly better performance .
Since DTSL is always faster than the baseline algorithms and often more accurate , it is a good choice to consider when performing Markov network structure learning . Whether or not DTSL is most accurate depends on the dataset . Some domains are best captured by a large number of pairwise interactions ; in such cases , L1 performs best . Others depend on higher order interactions that are easily discovered by DTSL .
DTSL has two weaknesses . The first is a higher risk of overfitting , since it often generates many very specialized features . For the most part , this can be remedied with careful tuning on a validation set . The second is a limited ability to capture many independent interactions . For instance , to capture pairwise interactions between a variable and k other variables would require a decision tree with 2k leaves , even though such interactions could be represented exactly by O(k ) features . For future work , we would like to learn sets of decision trees or other structures that can capture more independent interactions without making the overly restrictive pairwise assumption of L1 .
V . CONCLUSIONS AND FUTURE WORK
In this paper , we presented DTSL , a new approach to learning Markov networks using decision trees . DTSL is
L L M C d e z i l a m r o N L S T D
L L M C d e z i l a m r o N L S T D
0 0.1 0.2 0.3 0.4 0.5 0.6
0.6 0.5 0.4 0.3 0.2 0.1 L1 Normalized CMLL
0 0.1 0.2 0.3 0.4 0.5 0.6
0.6 0.5 0.4 0.3 0.2 0.1 DP Normalized CMLL
0
0
L L M C d e z i l a m r o N L S T D
L L M C d e z i l a m r o N L S T D
0 0.1 0.2 0.3 0.4 0.5 0.6
0.6 0.5 0.4 0.3 0.2 0.1 BLM Normalized CMLL
0 0.1 0.2 0.3 0.4 0.5 0.6
0.6 0.5 0.4 0.3 0.2 0.1 Atomic Normalized CMLL
0
0
Figure 2 . Normalized CMLL of DTSL vs . the normalized CMLL of each baseline method . CMLLs were normalized by dividing by the number of variables . Points above the line are where DTSL outperforms the baseline .
TEST SET CMLL FOR DIFFERENT FEATURE GENERATION METHODS .
Table IV
Data Set NLTCS MSNBC KDDCup 2000 Plants Audio Jester Netflix MSWeb Book EachMovie WebKB 20 Newsgroups Reuters 52
Default 5.313 5.724 2.696 10.814 38.093 51.021 54.389 29.757 35.484 54.400 158.790 195.607 128.009
Prune
5.210 5.745 2.155 9.988 37.893 50.818 54.177 28.648 34.451 51.043 151.195 199.516 107.613
Prune 10 5.213 5.888 2.104 10.074 37.900 50.818 54.179 21.891 34.451 51.088 151.104 201.060 106.547
Prune 5 5.205 6.111 2.107 10.636 38.405 51.155 54.561 16.589 34.718 52.464 151.577 169.877 100.283
Nonzero 5.224 5.870 2.085 11.054 37.484 50.212 53.234 9.278 35.238 52.197 150.529 154.825 82.929
FEATURE CHARACTERISTICS FOR DIFFERENT FEATURE GENERATION METHODS .
Table V
Average Feature Length
Number of Features in the Learned Model
Data Set NLTCS MSNBC KDDCup 2000 Plants Audio Jester Netflix MSWeb Book EachMovie WebKB 20 Newsgroups Reuters 52
DEFAULT 7.20 11.39 8.44 7.58 6.80 6.20 6.67 20.12 4.22 5.15 4.09 5.78 5.09
PRUNE 6.32 10.42 7.61 6.69 5.93 5.35 5.79 20.03 3.59 4.42 3.48 4.99 4.40
PRUNE 10 6.24 8.17 6.11 6.17 5.78 5.34 5.79 5.04 3.59 4.40 3.47 4.89 4.29
PRUNE 5 4.17 4.17 3.94 4.15 4.17 4.18 4.18 3.41 3.22 3.60 3.14 3.79 3.44
NONZERO 3.96 4.50 2.87 3.61 3.09 3.70 3.75 2.49 2.06 2.48 2.15 2.69 2.44
DEFAULT 1,529 12,356 4,403 6,264 7,097 5,834 7,897 7,744 6,466 10,343 10,004 28,622 16,390
PRUNE 2,958 24,530 8,585 12,289 13,866 11,308 15,437 14,788 11,720 19,568 17,971 55,005 30,684
PRUNE 10 2,910 12,530 6,941 11,439 13,510 11,292 15,433 9,392 11,720 19,504 17,939 54,241 30,232
PRUNE 5
NONZERO
899 1,015 2,831 3,865 5,851 5,832 5,897 5,665 10,408 14,704 16,247 35,533 23,042
980 4,159 2,274 4,303 4,946 4,796 6,659 3,879 3,454 6,999 5,858 21,008 10,485
TEST SET CMLL AND RUNNING TIME FOR DTSL AND BASELINES . DTSL FEATURE GENERATION METHOD SELECTED USING THE VALIDATION SET .
Table VI
Data Set NLTCS MSNBC KDDCup 2000 Plants Audio Jester Netflix MSWeb Book EachMovie WebKB 20 Newsgroups Reuters 52
DTSL
5.213 5.745 2.107 9.988 37.484 50.212 53.234 9.278 34.451 51.043 150.529 154.825 82.929
L1
5.231 6.286 2.124 10.962 36.972 49.508 52.329 9.075 36.814 51.861 150.249 154.540 81.285
CMLL BLM
5.253 5.892 2.099 10.960 37.385 53.025 56.598 8.936 34.768 58.852 165.736 161.269 91.196
DP
5.220 5.957 2.112 11.143 39.224 53.999 57.429 9.187 39.254 67.175 176.208 171.380 105.664
Atomic 9.241 6.780 2.456 31.321 49.362 63.891 64.578 11.720 41.308 84.102 180.640 172.908 108.262
DTSL < 0.1 0.4 2.0 0.2 0.3 0.2 0.3 2.2 1.9 1.1 1.6 11.0 4.5
Run Time ( Minutes )
L1
0.1 1.1 9.8 3.2 2.7 4.4 6.1 43.9 24.2 39.5 45.0 347.7 105.5
BLM 24.5 203.5 62.9 514.6 434.3 350.2 1367.8 64.8 47.3 41.3 49.9 468.9 170.9
DP
15.8 1440.0 1440.0 1440.0 1398.5 1440.0 1440.0 1440.0 1440.0 1440.0 1440.0 1440.0 1440.0 similar to the approach of Ravikumar et al . [ 1 ] , except that we use decision trees in place of L1 logistic regression . This allows us to learn longer features capturing interactions among more variables , which yields substantially better performance in several domains . DTSL is also similar to methods for learning dependency networks with tree conditional probability distributions [ 7 ] . However , dependency networks may not represent consistent probability distributions and require that inference be done with Gibbs sampling , while the Markov networks learned by DTSL have neither of those limitations .
In terms of speed , we found DTSL to be an order of magnitude faster than L1 logistic regression , and 3 4 orders of magnitude faster than the global structure learning approaches of BLM [ 6 ] and Della Pietra et al . [ 2 ] . In terms of accuracy , DTSL is comparable in accuracy to other approaches , placing first on 5 out of 13 datasets .
Future work includes exploring other methods of learning
FEATURE CHARACTERISTICS FOR DTSL AND BASELINES . DTSL FEATURE GENERATION METHOD SELECTED USING THE VALIDATION SET .
Table VII
Data Set
NLTCS MSNBC KDDCup 2000 Plants Audio Jester Netflix MSWeb Book EachMovie WebKB 20 Newsgroups Reuters 52
DTSL 6.24 10.42 3.94 7.61 3.09 3.70 3.75 2.49 3.59 4.42 2.15 2.69 2.44
Average Feature
Length L1 2.00 2.00 2.00 2.00 2.00 2.00 2.00 2.00 2.00 2.00 2.00 2.00 2.00
BLM 4.63 4.47 2.46 3.18 2.71 6.27 6.29 2.81 2.07 3.61 11.86 10.95 10.52
DP 3.12 4.20 4.12 2.76 2.03 3.13 2.55 2.26 2.14 2.05 2.11 2.10 2.11
Number of Features in the Learned Model
BLM DP 137 845 584 325 272 191 186 397 120 158 37 20 27
458 3,168 2,421 1,148 2,755 479 1,040 4,504 5,577 1,615 2,152 3,376 3,481
DTSL 2,910 24,530 2,831 12,289 4,946 4,796 6,659 3,879 11,720 19,568 5,858 21,008 10,485
L1 155 167 2,144 2,255 5,101 5,121 5,148 13,663 12,036 11,155 7,671 29,349 37,413 local structure , such as rule sets , boosted decision trees , and neural networks ; determining sufficient conditions for the asymptotic consistency of local learning ; further improving speed , perhaps by using frequent itemsets ; and incorporating faster methods for weight learning , since structure learning is no longer the bottleneck .
ACKNOWLEDGMENTS
This research was partly funded by ARO grant W911NF08 1 0242 . The views and conclusions contained in this document are those of the authors and should not be interpreted as necessarily representing the official policies , either expressed or implied , of ARO or the United States Government .
REFERENCES
[ 1 ] P . Ravikumar , M . J . Wainwright , and J . Lafferty , “ Highdimensional ising model selection using L1 regularized logistic regression , ” Annals of Statistics , 2009 .
[ 2 ] S . Della Pietra , V . Della Pietra , and J . Lafferty , “ Inducing features of random fields , ” IEEE Transactions on Pattern Analysis and Machine Intelligence , vol . 19 , pp . 380–392 , 1997 .
[ 3 ] W . R . Gilks , S . Richardson , and D . J . Spiegelhalter , Eds . , London , UK :
Markov Chain Monte Carlo in Practice . Chapman and Hall , 1996 .
[ 4 ] A . Kulesza and F . Pereira , “ Structured learning with approx imate inference , ” in NIPS 20 , 2007 , pp . 785–792 .
[ 5 ] J . Besag , “ Statistical analysis of non lattice data , ” The Statis tician , vol . 24 , pp . 179–195 , 1975 .
[ 6 ] J . Davis and P . Domingos , “ Bottom up learning of Markov the Twenty Seventh Haifa , network structure , ” in Proceedings of International Conference on Machine Learning . Israel : ACM Press , 2010 .
[ 7 ] D . Heckerman , D . M . Chickering , C . Meek , R . Rounthwaite , and C . Kadie , “ Dependency networks for inference , collaborative filtering , and data visualization , ” Journal of Machine Learning Research , vol . 1 , pp . 49–75 , 2000 .
[ 8 ] K . P . Murphy , Y . Weiss , and M . I . Jordan , “ Loopy belief propagation for approximate inference : An empirical study , ” in Proc . UAI’99 , 1999 .
[ 9 ] D . Chickering , D . Heckerman , and C . Meek , “ A Bayesian approach to learning Bayesian networks with local structure , ” in Proceedings of the Thirteenth Conference on Uncertainty in Artificial Intelligence . Providence , RI : Morgan Kaufmann , 1997 , pp . 80–89 .
[ 10 ] P . Domingos and G . Hulten , “ Mining high speed data streams , ” in Proceedings of the Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining . Boston , MA : ACM Press , 2000 , pp . 71–80 .
[ 11 ] G . Andrew and J . Gao , “ Scalable training of l1 regularized log linear models , ” in Proc . ICML’07 , 2007 , pp . 33–40 .
[ 12 ] D . C . Liu and J . Nocedal , “ On the limited memory BFGS method for large scale optimization , ” Mathematical Programming , vol . 45 , no . 3 , pp . 503–528 , 1989 .
[ 13 ] S I Lee , V . Ganapathi , and D . Koller , “ Efficient structure learning of Markov networks using L1 regularization , ” in NIPS 19 , 2007 , pp . 817–824 .
[ 14 ] H . Poon and P . Domingos , “ Sound and efficient inference with probabilistic and deterministic dependencies , ” in Proc . AAAI’06 , 2006 , pp . 458–463 .
[ 15 ] C . Blake and C . J . Merz , “ UCI repository of machine learning databases , ” Dept . ICS , UC Irvine , CA , Tech . Rep . , 2000 , http://wwwicsuciedu/∼mlearn/MLRepositoryhtml
[ 16 ] R . Kohavi , C . Brodley , B . Frasca , L . Mason , and Z . Zheng , report : Peeling the onion , ”
“ KDD Cup 2000 organizers’ SIGKDD Explorations , vol . 2 , no . 2 , pp . 86–98 , 2000 .
[ 17 ] G . Hulten and P . Domingos , “ Mining complex models from arbitrarily large databases in constant time , ” in Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining . Edmonton , Canada : ACM Press , 2002 , pp . 525–531 .
[ 18 ] C . Ziegler , S . McNee , J . Konstan , and G . Lausen , “ Improving recommendation lists through topic diversification , ” in Proc . WWW’05 , 2005 , pp . 22–32 .
[ 19 ] K . Goldberg , T . Roeder , D . Gupta , and C . Perkins , “ Eigentaste : A constant time collaborative filtering algorithm , ” Information Retrieval , vol . 4 , no . 2 , pp . 133–151 , 2001 .
[ 20 ] A . Bordes , L . Bottou , and P . Gallinari , “ SGD QN : Careful quasi Newton stochastic gradient descent , ” Journal of Machine Learning Research , vol . 10 , pp . 1737–1754 , 2009 .
