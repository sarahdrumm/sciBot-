2010 IEEE International Conference on Data Mining
Averaged Stochastic Gradient Descent with Feedback :
An Accurate , Robust , and Fast Training Method
âˆ—
â€ 
, Hisashi Kashima
, Takuya Matsuzaki
âˆ— Xu Sun âˆ—
â€¡ , and Naonori Ueda Department of Mathematical Informatics , The University of Tokyo
â€  Department of Computer Science , The University of Tokyo â€¡ NTT Communication Science Laboratories , Kyoto , Japan
{xusun , kashima}@mistiu tokyoacjp matuzaki@issu tokyoacjp ueda@cslabkeclnttcojp
Abstractâ€”On large datasets , the popular training approach has been stochastic gradient descent ( SGD ) . This paper proposes a modification of SGD , called averaged SGD with feedback ( ASF ) , that significantly improves the performance ( robustness , accuracy , and training speed ) over the traditional SGD . The proposal is based on three simple ideas : averaging the weight vectors across SGD iterations , feeding the averaged weights back into the SGD update process , and deciding when to perform the feedback ( linearly slowing down feedback ) . Theoretically , we demonstrate the reasonable convergence properties of the ASF outperforms several strong baselines in terms of accuracy , robustness over the noise , and the training speed . To our knowledge , this is the first study of â€œ feedback â€ in stochastic gradient learning . Although we choose latent conditional models for verifying the ASF in this paper , the ASF is a general purpose technique just like SGD , and can be directly applied to other models . the ASF . Empirically ,
I . INTRODUCTION
Structured classification is a general task that encompasses many problems in data mining and other areas . Real world problems may contain hidden structures that are difficult to be captured by conventional structured classification models without latent variables . For example , in the syntactic parsing task for natural language , the hidden structures can be refined grammars which are unobservable in the supervised training data [ 1 ] . In the gesture recognition task of the computational vision area , there are also hidden structures which are crucial for successful gesture recognition [ 2 ] . There are also plenty of hidden structure examples in other tasks among different areas [ 3 ] , [ 4 ] , [ 5 ] . In such cases , models that exploit latent variables are advantageous in learning .
Training latent conditional models ( more formally , discriminative probabilistic latent variable models , DPLVMs ) is quite challenging . Standard gradient descent methods are normally batch training methods , in which the true gradient is used to update the parameters of the model , for example , the quasi Newton methods like Limited memory BFGS ( LBFGS ) [ 6 ] . The true gradient is usually the sum of the gradients from each individual training instance . Therefore , batch gradient descent requires the training method to go through the entire training set before updating the parameters . For this reason , the batch training methods are intolerably slow on training DPLVMs [ 1 ] , [ 4 ] .
A promising fast probabilistic training method is the stochastic gradient method , for example , the SGD [ 7 ] , [ 8 ] , [ 9 ] . In the stochastic gradient method , the true gradient is approximated by the gradient of a small set , or more aggressively , a single training example . The parameter vector is updated based on the approximate gradients . The parameters of the model are updated much more frequently , and much fewer iterations are needed before the convergence . For large scale data sets , the SGD can be faster than batch gradient based training methods .
However , there are problems on the current SGD literature : 1 ) The SGD is sensitive to noise . The accuracy of the SGD training is limited when the data is noisy . 2 ) The SGD is not robust . It contains many hyper parameters ( not only regularization , but also decaying rate ) and it is quite sensitive to them . Tuning the hyper parameters for SGD is not a easy task . 3 ) The speed is still not fast enough . It is time consuming to perform regularization with an online setting .
To deal with the problems of the traditional stochastic methods , we present a new stochastic gradient learning method . The proposal can significantly improve the accuracy of stochastic training by smoothening out noise . In addition , according to the experiments , the proposal is quite robust and fast for structured classification tasks in data mining .
II . BACKGROUND
A . Latent Conditional Model
Given the training data , the task is to learn a mapping between a sequence of observations x = ğ‘¥1 , ğ‘¥2 , . . . , ğ‘¥ğ‘š and a sequence of labels y = ğ‘¦1 , ğ‘¦2 , . . . , ğ‘¦ğ‘š . Each ğ‘¦ğ‘— is a class label for the ğ‘—â€™th token of a word sequence , and is a member of a set Y of possible class labels . For each sequence , the model also assumes a sequence of latent variables h = â„1 , â„2 , . . . , â„ğ‘š , which is unobservable in training examples .
1550 4786/10 $26.00 Â© 2010 IEEE DOI 101109/ICDM201026
1067
The DPLVM model1 is defined as follows [ 10 ] : ğ‘ƒ ( yâˆ£h , x , Î˜)ğ‘ƒ ( hâˆ£x , Î˜ ) ,
ğ‘ƒ ( yâˆ£x , Î˜ ) â‰œ
âˆ‘ h where Î˜ represents the parameter vector of the model . DPLVM models can be seen as a natural extension of CRF models , and CRF models can be seen as a special case of DPLVMs that employ only one latent variable for each label . To make the training and inference efficient , the model is restricted to have disjointed sets of latent variables associated with each class label . Each â„ğ‘— is a member in a set Hğ‘¦ğ‘— of possible latent variables for the class label ğ‘¦ğ‘— . H is defined as the set of all possible latent variables , ie , the union of all Hğ‘¦ğ‘— sets . Since sequences which have any â„ğ‘— /âˆˆ Hğ‘¦ğ‘— will by definition have ğ‘ƒ ( yâˆ£â„ğ‘— , x , Î˜ ) = 0 , the model can be further defined as : ğ‘ƒ ( yâˆ£x , Î˜ ) â‰œ
ğ‘ƒ ( hâˆ£x , Î˜ ) ,
âˆ‘ hâˆˆHğ‘¦1
Ã—Ã—Hğ‘¦ğ‘š where ğ‘ƒ ( hâˆ£x , Î˜ ) is defined by the usual conditional random field formulation :
ğ‘ƒ ( hâˆ£x , Î˜ ) =
âˆ‘ exp Î˜â‹…f ( h , x ) âˆ€h exp Î˜â‹…f ( h , x )
, in which f ( h , x ) is a feature vector . Given a training set consisting of ğ‘› labeled sequences , ( xğ‘– , yğ‘– ) , for ğ‘– = 1 . . . ğ‘› , parameter estimation is performed by optimizing the objective function . In what follows , we denote the conditional log likelihood of each sample log ğ‘ƒ ( yğ‘–âˆ£xğ‘– , Î˜ ) as ğ¿ğ‘ (ğ‘– , Î˜ ) . Then , the objective function is ( if use ğ¿2 regularization ) :
ğ¿(Î˜ ) =
ğ‘›âˆ‘
ğ‘–=1
ğ¿ğ‘ (ğ‘– , Î˜ ) âˆ’ âˆ£âˆ£Î˜âˆ£âˆ£2
2ğœ2
.
( 1 )
B . Stochastic Gradient Descent
The SGD uses a small randomly selected subset of the training samples to approximate the gradient of the objective function given by Equation 1 . The extreme case is a batch size of 1 , and it gives the maximum frequency of updates , which we adopt in this work . The model parameters are updated in such a way :
Î˜ğ‘˜+1 = Î˜ğ‘˜ + ğ›¾ğ‘˜
âˆ‚ âˆ‚Î˜
( ğ¿ğ‘ (ğ‘– , Î˜ ) âˆ’ âˆ£âˆ£Î˜âˆ£âˆ£2
) ,
2ğ‘›ğœ2 where ğ‘˜ is the update counter and ğ›¾ğ‘˜ is the learning decaying rate . A typical convergent choice of learning rate can be found in [ 11 ] :
ğ›¾ğ‘˜ =
ğ›¾0
,
1 + ğ‘˜/ğ‘› where ğ›¾0 is a constant . This scheduling guarantees ultimate convergence [ 9 ] . In this paper we adopt this decaying schedule for the SGD .
1The implementation source code of DPLVMs and CRFs is available at http://wwwibistu tokyoacjp/XuSun
1068
Notes ğ‘š is the number of periods when the ASF reaches the convergence ; ğ‘ is the current number of period ; ğ‘ is the current number of iteration ; ğ‘› is the number of training samples ; The decaying rate , ğ›¾ â†âˆ’ ğ›¾0 1+ğ‘/ğ‘ , is only for theoretical analysis . In practice we can simply set ğ›¾ â† 1 , ie , remove the decaying rate .
Procedure ASF train
Initialize Î˜ with random values ğ‘ â†âˆ’ 0 for ğ‘ â†âˆ’ 1 to ğ‘š ğ›¾ â†âˆ’ ğ›¾0 . for 1 to ğ‘ . . ğ‘ â†âˆ’ ğ‘ + ğ‘ . . Î˜ â†âˆ’ Î˜ğ‘–ğ‘¡ğ‘’ğ‘Ÿ(ğ‘ ) Return Î˜ in Eq 2
1+ğ‘/ğ‘ with ğ‘ â‰« ğ‘› , or simply ğ›¾ â† 1 Î˜ â†âˆ’ SGD update(Î˜ )
Procedure SGD update(Î˜ ) for 1 to ğ‘› . . Î˜ â†âˆ’ Î˜ + ğ›¾ âˆ‚ Return Î˜ select a sample ğ‘— randomly âˆ‚Î˜ ğ¿ğ‘ (ğ‘— , Î˜ )
Figure 1 . The major steps of the ASF training .
III . PROPOSAL : AVERAGED SGD WITH FEEDBACK We will present the averaged SGD , and more importantly , we will show that a reasonable feedback schedule is the key to make the averaged SGD being robust and accurate .
The naive version of averaged SGD is inspired by the averaged perceptron technique [ 12 ] . Let Î˜ğ‘–ğ‘¡ğ‘’ğ‘Ÿ(ğ‘),ğ‘ ğ‘ğ‘šğ‘ğ‘™ğ‘’(ğ‘‘ ) be the parameters after the ğ‘‘â€™th training example has been processed in the ğ‘â€™th iteration over the training data . We define the averaged parameters at the end of the iteration ğ‘â€² as :
Î˜ğ‘–ğ‘¡ğ‘’ğ‘Ÿ(ğ‘â€² ) â‰œ
ğ‘=1ğ‘â€² , ğ‘‘=1ğ‘› Î˜ğ‘–ğ‘¡ğ‘’ğ‘Ÿ(ğ‘),ğ‘ ğ‘ğ‘šğ‘ğ‘™ğ‘’(ğ‘‘ )
ğ‘›ğ‘â€²
.
( 2 )
âˆ‘
However , a straightforward application of parameter averaging is not adequate . A potential problem of traditional parameter averaging is that the model parameters Î˜ receive no information from the averaged parameters : the model parameters Î˜ are trained exactly the same like before ( SGD without averaging ) . Î˜ could be misleading as the training goes on . To solve this problem , a natural idea is to reset Î˜ by using the averaged parameters , which are more reliable . We propose a refined version of averaged SGD by further applying a â€œ periodic feedback â€ .
We periodically reset the parameters Î˜ by using the averaged parameters Î˜ . The interval between a feedback operation and its previous operation is called a training period or simply a period . It is important to decide when to do the feedback , ie , the length of each period should be adjusted reasonably as the training goes on . For example , at the early stage of the training , the Î˜ is highly noisy , so that the feedback operation to Î˜ should be performed more frequently . As the training goes on , less frequent feedback operation would be better in order to adequately optimize the parameters . In practice , we adopt a schedule of linearly slowing down feedback , and we will show the reasonable convergence properties of this scheduling in Section III A . In what follows , we call the proposal as averaged SGD with feedback ( ASF)2 . Figure 1 shows the steps of the ASF . Now , we analyze the averaged parameters produced by each period . We denote Î˜ğ‘,ğ‘,ğ‘‘ as the model parameters after the ğ‘‘â€™th sample is processed in the ğ‘â€™th iteration of the ğ‘â€™th period . Without making any difference , we denote Î˜ğ‘,ğ‘,ğ‘‘ more simply as Î˜ğ‘,ğ‘ğ‘›+ğ‘‘ where ğ‘› is the number of samples in a training data . Similarly , we use ğ‘”ğ‘,ğ‘ğ‘›+ğ‘‘ to denote âˆ‚ âˆ‚Î˜ ğ¿ğ‘ (ğ‘‘ , Î˜ ) in the ğ‘â€™th iteration of the ğ‘â€™th period . Let ğ›¾(ğ‘ ) be the decaying rate in the ğ‘â€™th period . Let Î˜(ğ‘ ) be the averaged parameters produced by the ğ‘â€™th period . We can induce the explicit form of Î˜(1 ) : âˆ‘
ğ‘› âˆ’ ğ‘‘ + 1
Î˜(1 ) = Î˜1,0 + ğ›¾(1 )
ğ‘”1,ğ‘‘ .
( 3 )
ğ‘›
ğ‘‘=1ğ‘› ends , the
2nd period are When again averaged over all previous model parameters , Î˜1,0 , . . . , Î˜1,ğ‘› , Î˜2,0 , . . . , Î˜2,2ğ‘› , and it can be expressed as : parameters the
Î˜(2 ) = Î˜1,0 + ğ›¾(1 ) âˆ‘
+ ğ›¾(2 )
âˆ‘
ğ‘› âˆ’ ğ‘‘ + 1
ğ‘‘=1ğ‘›
ğ‘› 2ğ‘› âˆ’ ğ‘‘ + 1
ğ‘”1,ğ‘‘
( 4 )
ğ‘”2,ğ‘‘ .
ğ‘‘=12ğ‘›
3ğ‘›
Similarly , the averaged parameters produced by the ğ‘â€™th period can be expressed as follows : âˆ‘
âˆ‘
Î˜(ğ‘ ) = Î˜1,0 +
( ğ›¾(ğ‘– )
ğ‘–ğ‘› âˆ’ ğ‘‘ + 1 ğ‘›ğ‘–(ğ‘– + 1)/2
ğ‘”ğ‘–,ğ‘‘ ) .
( 5 )
ğ‘–=1ğ‘
ğ‘‘=1ğ‘–ğ‘›
The procedure of deriving Eq 5 is sketched in Appendix .
While it is strongly recommended for LBFGS and SGD to perform regularization , the ASF does not strongly rely on regularization . A possible reason is that the averaging performs as an â€œ implicit regularization â€ for improving the generality . For this reason , we currently only perform simple lazy regularization on ASF , ie , do the regularization after the ASF training is done . We find the removing the lazyregularization do not undermine the performance of ASF : the ASF without regularization still outperforms the SGD with tuned regularizer .
2The implementation source code will be available online at http://www . ibistu tokyoacjp/XuSun
A . Convergence Analysis
The best possible convergence result for stochastic learning is the â€œ almost sure convergence â€ : to prove that the stochastic algorithm converges towards the solution with probability 1 [ 9 ] . We will show that the proposed method guarantees to achieve almost sure convergence . We first introduce the general convexity assumption : everywhere in the parameter space , the opposite of the gradient must point toward a unique minimum Î˜âˆ— . Such a strong assumption is only valid for a few simple learning algorithms . Nevertheless , the assumption usually holds within the final convergence region because the cost function is locally convex in many practical applications .
If a stochastic update is convergent , it means that either the gradients or the learning rates must vanish near the optimum [ 13 ] . According to [ 13 ] , it is reasonable to assume that the variance of the stochastic gradient does not grow faster than the norm of the real gradient itself . Also , it is reasonable âˆ‚Î˜ ğ¿(Î˜)âˆ£âˆ£2 behaves quadratically within the to assume that âˆ£âˆ£ âˆ‚ final convergence region . Both assumptions are conveniently expressed as follows :
Eğ‘–[
âˆ‚ âˆ‚Î˜
ğ¿ğ‘ (ğ‘– , Î˜)2 ] < ğ´ + ğµ(Î˜ âˆ’ Î˜âˆ—)2 ,
( 6 ) where ğ´ â‰¥ 0 and ğµ â‰¥ 0 . Based on the assumptions , the convergence theorem has been given [ 13 ] : two conditions on the learning rate are sufficient conditions for the almost sure convergence of the SGD to the optimum Î˜âˆ— . The two conditions on the learning rate are as follows [ 13 ] :
âˆ‘
ğ›¾ğ‘˜ = âˆ ğ‘ğ‘›ğ‘‘
âˆ‘
ğ‘˜ < âˆ . ğ›¾2
( 7 )
Too fast decaying rate may make the SGD fail to reach the optimum if it is far away , while too slow decaying rate may make the SGD keep oscillating around .
With those preparations , we have the convergence theorem for the ASF :
Theorem 1 : Let the optimization procedure be defined in Figure 1 . Given the convex assumption and the assumption Eq 6 , the averaged parameters produced at the end of each period of the optimization procedure are â€œ almost surely convergent â€ towards the optimum Î˜âˆ—
.
The proof of Theorem 1 is sketched in Appendix . As we discussed before , although the convex assumption is a strong one , in practice the assumption usually holds within the final convergence region for non convex cost functions . From another point of view , for non convex cost functions , the convergence is probably not a big issue for practitioners because normally the training has to be terminated at a certain number of iterations in practice [ 7 ] .
IV . EXPERIMENTS AND DISCUSSION
We choose two real world structured classification tasks for our experiments : biomedical named entity recognition , and sensor based action recognition .
1069
FEATURES USED IN THE BIO NER TASK . ğ‘¤ğ‘– IS THE CURRENT WORD , ğ‘¡ğ‘–
IS THE POS TAG , ğ‘œğ‘– IS THE ORTHOGRAPHY MODE , AND â„ğ‘– IS THE LATENT VARIABLE ( FOR LATENT MODELS ) OR THE LABEL ( FOR
Table I
CONVENTIONAL MODELS ) .
Word Features : {ğ‘¤ğ‘–âˆ’2 , ğ‘¤ğ‘–âˆ’1 , ğ‘¤ğ‘– , ğ‘¤ğ‘–+1 , ğ‘¤ğ‘–+2 , ğ‘¤ğ‘–âˆ’1ğ‘¤ğ‘– , ğ‘¤ğ‘–ğ‘¤ğ‘–+1} Ã—{â„ğ‘– , â„ğ‘–âˆ’1â„ğ‘–} POS Features : {ğ‘¡ğ‘–âˆ’2 , ğ‘¡ğ‘–âˆ’1 , ğ‘¡ğ‘– , ğ‘¡ğ‘–+1 , ğ‘¡ğ‘–+2 , ğ‘¡ğ‘–âˆ’2ğ‘¡ğ‘–âˆ’1 , ğ‘¡ğ‘–âˆ’1ğ‘¡ğ‘– , ğ‘¡ğ‘–ğ‘¡ğ‘–+1 , ğ‘¡ğ‘–+1ğ‘¡ğ‘–+2 , ğ‘¡ğ‘–âˆ’2ğ‘¡ğ‘–âˆ’1ğ‘¡ğ‘– , ğ‘¡ğ‘–âˆ’1ğ‘¡ğ‘–ğ‘¡ğ‘–+1 , ğ‘¡ğ‘–ğ‘¡ğ‘–+1ğ‘¡ğ‘–+2} Ã—{â„ğ‘– , â„ğ‘–âˆ’1â„ğ‘–} Orth . Features : {ğ‘œğ‘–âˆ’2 , ğ‘œğ‘–âˆ’1 , ğ‘œğ‘– , ğ‘œğ‘–+1 , ğ‘œğ‘–+2 , ğ‘œğ‘–âˆ’2ğ‘œğ‘–âˆ’1 , ğ‘œğ‘–âˆ’1ğ‘œğ‘– , ğ‘œğ‘–ğ‘œğ‘–+1 , ğ‘œğ‘–+1ğ‘œğ‘–+2} Ã—{â„ğ‘– , â„ğ‘–âˆ’1â„ğ‘–}
RESULTS IN THE BIO NER TASK . THE VALUES IN THE BRACKETS ARE
THE STANDARD DEVIATIONS OF THREE REPEATED EXPERIMENTS .
Table II
)
%
( y c a r u c c A
93.5
93
92.5
92
91.5
91
ASF Averaged SGD SGD
0 1 3 5
10
15
20
25
30
35
Number of Iterations
Figure 2 . Curves of token accuracies while varying the number of iterations in the Bio NER task : the proposal method vs . the SGD .
Methods DPLVM , ASF ( ** ) DPLVM , Averag . SGD ( * ) DPLVM , SGD DPLVM , LBFGS CRF , SGD CRF , LBFGS Averag . Perc .
F score % Iterations 71.1 ( 0.2 ) 70.6 ( 0.2 ) 69.7 ( 0.2 )
20 50 40
N/A
69.2 ( 0.3 ) 68.8 ( 0.2 ) 68.9 ( 0.3 )
>400
40 400 20
Time 4 hours 11 hours 9 hours > 3 days 4 hours 22 hours 1 hour
A . Biomedical Named Entity Recognition ( Bio NER )
The bio NER task is for recognizing 5 kinds of biomedical named entities , including DNAs , Proteins , RNAs , CellTypes , Cell Lines on the GENIA corpus [ 14 ] . The typical approach to this problem recast it as a sequential labeling task with the BIO Entity encoding , with 11 classification labels . The data consists of 1,800 abstracts ( 18,546 sentences ) from MEDLINE for training , 200 abstracts for the development data , and 404 abstracts for testing . The standard evaluation metrics [ 14 ] are precision ğ‘ , recall ğ‘Ÿ , and the F score given by ğ¹ = 2ğ‘ğ‘Ÿ/(ğ‘ + ğ‘Ÿ ) .
1 ) Experimental Settings : We use word features , POS features and orthography features ( prefix , uppercase/lowercase , etc. ) , as listed in Table I . We use exactly the same feature set for all systems . To reduce overfitting , we employed a ğ¿2 prior for both stochastic training methods and batch training methods . We varied the variance of the Gaussian prior , and according to the performance on development data , we set ğœ = 5.0 for stochastic training methods and ğœ = 2.0 for the batch training method ( LBFGS ) . For the stochastic training methods , according to the performance on development data , we set the ğ›¾0 as 10
2 ) Results and Discussion : The experimental results are shown in Table II . Note that , to make the comparisons fair enough , the term â€œ iteration â€ has a strict meaning in this paper . The â€œ number of iterations â€ of ASF is really the number of iterations just like the SGD : it is not the number of feedback periods . As can be seen in the table , with the same feature set , the proposed stochastic training method ASF
1070
Table III
FEATURES USED IN THE ACTION RECOGNITION TASK . ğ‘¡ğ‘– IS THE
CURRENT TIME , ğ‘¥ğ‘– , ğ‘¦ğ‘– , ğ‘§ğ‘– ARE THE ACCELERATION VALUES ON x , y AND z AXIS , RESPECTIVELY .
Time Features : {ğ‘¡ğ‘–+1 âˆ’ ğ‘¡ğ‘– , ğ‘¡ğ‘– âˆ’ ğ‘¡ğ‘–âˆ’1} Ã—{â„ğ‘– , â„ğ‘–âˆ’1â„ğ‘–} Acceleration Features : {ğ‘¥ğ‘–âˆ’2 , ğ‘¥ğ‘–âˆ’1 , ğ‘¥ğ‘– , ğ‘¥ğ‘–+1 , ğ‘¥ğ‘–+2 , ğ‘¥ğ‘–âˆ’1ğ‘¥ğ‘– , ğ‘¥ğ‘–ğ‘¥ğ‘–+1} Ã—{â„ğ‘– , â„ğ‘–âˆ’1â„ğ‘–} {ğ‘¦ğ‘–âˆ’2 , ğ‘¦ğ‘–âˆ’1 , ğ‘¦ğ‘– , ğ‘¦ğ‘–+1 , ğ‘¦ğ‘–+2 , ğ‘¦ğ‘–âˆ’1ğ‘¦ğ‘– , ğ‘¦ğ‘–ğ‘¦ğ‘–+1} Ã—{â„ğ‘– , â„ğ‘–âˆ’1â„ğ‘–} {ğ‘§ğ‘–âˆ’2 , ğ‘§ğ‘–âˆ’1 , ğ‘§ğ‘– , ğ‘§ğ‘–+1 , ğ‘§ğ‘–+2 , ğ‘§ğ‘–âˆ’1ğ‘§ğ‘– , ğ‘§ğ‘–ğ‘§ğ‘–+1} Ã—{â„ğ‘– , â„ğ‘–âˆ’1â„ğ‘–} significantly outperforms the baselines ( McNemar â€™s significance test ) . The number of training iterations is determined by using the SGD or LBFGS on the development data . Compared with the SGD training for DPLVMs , the ASF training not only achieved significant better performance , but also with faster training speed .
In Figure 2 , we show the curves of token accuracies on varying the number of training iterations of the ASF and the SGD . As can be seen , the ASF training demonstrates consistent superiority over the SGD training . The ASF already reached the plateau in around 20 iterations . Most importantly , the ASF curve is much more stable/robust than the SGD curve . The stable curve of ASF demonstrates the robustness of the proposed method over the noisy gradients .
B . Sensor based Action Recognition
Acceleration sensor based action recognition is useful in practical applications [ 15 ] . For example , in some medical programmes , researchers hope to prevent lifestyle diseases to be deteriorated . In sensor based action recognition , an accelerometer is employed ( eg , attached on the wrist of people ) to automatically capture the acceleration statistics ( a temporal sequence of 3 dimension acceleration signals ) in the daily life of counselees .
We use one month data of the ALKAN dataset [ 16 ] for experiments . This data contains 2,061 sessions , with totally 3,899,155 time windows ( in a temporal se
RESULTS IN THE ACTION RECOGNITION TASK ( AVERAGED OVER THREE
REPEATED EXPERIMENTS ) .
Table IV
Methods DPLVM , ASF ( ** ) DPLVM , Averag . SGD ( * ) DPLVM , SGD DPLVM , LBFGS CRF , SGD CRF , LBFGS
Accuracy ( % )
Iterations
70.9 ( 0.1 ) 69.6 ( 0.1 ) 61.3 ( 1.1 ) 68.9 ( 3.7 ) 63.2 ( 0.9 ) 66.6 ( 0.4 )
20 60 35 400 35 400
Time 1 hour 4 hours 2 hours 14 hours 1 hour 6 hours
ASF Averaged SGD SGD
)
%
( y c a r u c c A
75
70
65
60
55
50
0 1
3
5
10
15
20
25
30
35
Number of Iterations
Figure 3 . Curves of token accuracies while varying the number of iterations on the sensor based action recognition task : the proposal method vs . the SGD . This figure comes from one of the repeated experiments , which have similar tendencies .
0.145(g ) , quence ) . A time window contains 4 values : {time ( the from the beginning of a session ) , x axisseconds past acceleration , y axis acceleration , z axis acceleration} , for example , {539.266(s ) , 0.091(g ) , 1051(g)}3 There are three kinds of action labels : label 1 means â€œ Walking/Running â€ , label 2 means â€œ On Vehicle ( Taking Train/Bus/Car/Bicycle ) â€ and label 3 means â€œ Others â€ . We split this data into a training data ( 85% ) , a development data for hyper parameters ( 5% ) , and the final evaluation data ( 10% ) . The evaluation metric are token accuracy ( % ) . The features are listed in Table III . The remaining experimental settings are very similar to the biomedical named entity recognition task , therefore we will not repeat the description for the space .
The experimental results are listed in Table IV . As we can see , similar to the previous task , the DPLVM ASF significantly outperforms its latent conditional baselines and traditional baselines , on both the accuracy and the speed .
In Figure 3 , we show the curves of token accuracies on varying the number of training iterations of the ASF and the SGD . As can be seen , the ASF training is much more stable/robust than the SGD training . The fluctuation of the SGD is more drastic than the previous task , probably due to
3In the example , â€˜gâ€™ is the acceleration of gravity .
1071 the more noisy data . The robustness of the ASF method is closely related to the stable nature of averaging with feedback .
V . CONCLUSIONS , DISCUSSION , AND FUTURE WORK The ASF significantly improves the performance ( robustness , accuracy , and training speed ) over the traditional SGD . The ASF is based on three simple ideas : averaging the weights , feedback , and a heuristic on deciding when to perform the feedback . It is important to linearly slowing down the feedback , because it performs much better than other alternative settings ( not reported for space ) . Further study on this direction is interesting .
The design of decaying rate and lazy regularization of the ASF is quite different from traditional SGD . A study on them can be a future work . For faster speed or simplicity , the decaying rate and the lazy regularization can be removed from ASF . The ASF without decaying rate and regularization will still work well enough in general . On the other hand , the SGD without decaying rate or regularization will suffer performance loss considerably .
If the objective function of the ASF and the SGD is the same and the function is convex ( eg , for CRFs ) , it is then supposed that they will arrive the same optimum . However , our extra experiments show that the ASF outperforms the SGD considerably . The reason is unknown , and further analysis is a future work . This is also not very surprising . Similar phenomenon happens between the SGD and the LBFGS with the same objective function : they are supposed to achieve the same optimum after the convergence , but in fact their performance can be quite different .
In practice , it is important to choose a good weight vector by using development data . If the evaluation on development data was performed after each period of ASF , it may neglect good weight vector during the iterations of a period , because there could be many iterations in a period . Therefore , it is recommended to evaluate the averaged weights after each iteration rather than after each period .
ACKNOWLEDGMENT
XS , HK , and NU were supported by the FIRST
Program of Japan Society for Promotion of Science .
REFERENCES
[ 1 ] S . Petrov and D . Klein , â€œ Discriminative log linear grammars with latent variables , â€ in Advances in Neural Information Processing Systems 20 ( NIPS ) , 2008 , pp . 1153â€“1160 .
[ 2 ] S . B . Wang , A . Quattoni , L P Morency , D . Demirdjian , and T . Darrell , â€œ Hidden conditional random fields for gesture recognition , â€ in Proceedings of CVPRâ€™06 . IEEE Computer Society , 2006 , pp . 1521â€“1527 .
[ 3 ] X . Sun , N . Okazaki , and J . Tsujii , â€œ Robust approach to abbreviating terms : A discriminative latent variable model with global the ACLâ€™09 , information , â€ in Proceedings of Suntec , Singapore , August 2009 , pp . 905â€“913 .
[ 4 ] X . Sun , T . Matsuzaki , D . Okanohara , and J . Tsujii , â€œ Latent variable perceptron algorithm for structured classification , â€ in Proceedings of the 21st International Joint Conference on Artificial Intelligence ( IJCAI 2009 ) , 2009 , pp . 1236â€“1242 .
[ 5 ] S . Petrov , â€œ Products of random latent variable grammars , â€ in
Proceedings of NAACLâ€™10 , 2010 , to appear .
[ 6 ] J . Nocedal and S . J . Wright , â€œ Numerical optimization , â€
Springer , 1999 .
[ 7 ] Y . Tsuruoka , J . Tsujii , and S . Ananiadou , â€œ Stochastic gradient descent training for l1 regularized log linear models with cumulative penalty , â€ in Proceedings of ACLâ€™09 , Suntec , Singapore , August 2009 , pp . 477â€“485 .
[ 8 ] S . Shalev Shwartz , Y . Singer , and N . Srebro , â€œ Pegasos : Primal estimated sub gradient solver for svm , â€ in Proceedings of ICMLâ€™07 , 2007 .
[ 9 ] L . Bottou , â€œ Online algorithms and stochastic approximations , â€ Online Learning and Neural Networks . Saad , David . Cambridge University Press , 1998 .
[ 10 ] L P Morency , A . Quattoni , and T . Darrell , â€œ Latent dynamic discriminative models for continuous gesture recognition , â€ in Proceedings of CVPRâ€™07 , 2007 , pp . 1â€“8 .
[ 11 ] M . Collins , A . Globerson , T . Koo , X . Carreras , and P . L . Bartlett , â€œ Exponentiated gradient algorithms for conditional random fields and max margin markov networks , â€ J . Mach . Learn . Res . ( JMLR ) , vol . 9 , pp . 1775â€“1822 , 2008 .
[ 12 ] M . Collins , â€œ Discriminative training methods for hidden markov models : Theory and experiments with perceptron algorithms , â€ in Proceedings of EMNLPâ€™02 , 2002 , pp . 1â€“8 .
[ 13 ] L . Bottou , â€œ Stochastic learning , â€ Advanced Lectures on Ma chine Learning , pp . 146â€“168 , 2004 .
[ 14 ] J D Kim , T . Ohta , Y . Tsuruoka , and Y . Tateisi , â€œ Introduction to the bio entity recognition task at JNLPBA , â€ in Proceedings of BioNLPâ€™04 , 2004 , pp . 70â€“75 .
[ 15 ] T . Huynh , M . Fritz , and B . Schiele , â€œ Discovery of activity patterns using topic models , â€ in Proceedings of the 10th international conference on Ubiquitous computing . ACM , 2008 , pp . 10â€“19 .
[ 16 ] Y . Hattori , M . Takemori , S . Inoue , G . Hirakawa , and O . Sudo , â€œ Operation and baseline assessment of large scale activity gathering system by mobile device , â€ in Proceedings of DICOMOâ€™10 , 2010 .
APPENDIX
Derivation of Eq 5 : We follow the denotations of Î˜ğ‘,ğ‘ğ‘›+ğ‘‘ , ğ‘”ğ‘,ğ‘ğ‘›+ğ‘‘ , ğ›¾(ğ‘ ) and defined in Section III . For the 1st period , the parameters
Î˜(ğ‘ ) after each update is as follows :
Î˜1,1 = Î˜1,0 + ğ›¾(1)ğ‘”1,1 , Î˜1,2 = Î˜1,1 + ğ›¾(1)ğ‘”1,2 = Î˜1,0 + ğ›¾(1)ğ‘”1,1 + ğ›¾(1)ğ‘”1,2 , . . . Î˜1,ğ‘› = Î˜1,ğ‘›âˆ’1 + ğ›¾(1)ğ‘”1,ğ‘›
= Î˜1,0 + ğ›¾(1)ğ‘”1,1 + ğ›¾(1)ğ‘”1,2 + â‹…â‹…â‹… + ğ›¾(1)ğ‘”1,ğ‘› .
At the end of the 1st period , the parameters are averaged as follows :
âˆ‘
Î˜(1 ) =
ğ‘‘=1ğ‘› Î˜1,ğ‘‘
ğ‘›
= Î˜1,0 + ğ›¾(1 )
âˆ‘
ğ‘› âˆ’ ğ‘‘ + 1
ğ‘‘=1ğ‘›
ğ‘›
ğ‘”1,ğ‘‘ .
At the beginning of the 2nd period , we do the feedback : Î˜2,0 â†âˆ’ Î˜(1 ) . When the 2nd period ends , the parameters are again averaged over all previous model parameters , Î˜1,0 , . . . , Î˜1,ğ‘› , Î˜2,0 , . . . , Î˜2,2ğ‘› :
ğ‘‘=12ğ‘›(2ğ‘› âˆ’ ğ‘‘ + 1)ğ‘”2,ğ‘‘ ]
Î˜(2 ) =
=
=
âˆ‘
âˆ‘
ğ‘‘=1ğ‘› Î˜1,ğ‘‘ +
ğ‘‘=12ğ‘› Î˜2,ğ‘‘
âˆ‘
ğ‘› + 2ğ‘› ğ‘‘=12ğ‘› Î˜2,ğ‘‘ 3ğ‘›
ğ‘›Î˜(1 ) + ğ‘›Î˜(1 ) + [ 2ğ‘›Î˜(1 ) + ğ›¾(2 ) âˆ‘ 3ğ‘› ğ‘› âˆ’ ğ‘‘ + 1
âˆ‘
= Î˜1,0 + ğ›¾(1 ) âˆ‘
+ ğ›¾(2 )
ğ‘‘=1ğ‘›
ğ‘› 2ğ‘› âˆ’ ğ‘‘ + 1
ğ‘”1,ğ‘‘
ğ‘”2,ğ‘‘ .
ğ‘‘=12ğ‘›
3ğ‘›
Î˜(ğ‘ ) = Î˜1,0 +
( ğ›¾(ğ‘– )
âˆ‘
âˆ‘
ğ‘–=1ğ‘ Proof of theorem 1 : In Eq 8 , notice that the Î˜(ğ‘ )
ğ‘‘=1ğ‘›ğ‘–
In a similar way , it is straightforward to conclude that :
ğ‘›ğ‘– âˆ’ ğ‘‘ + 1 ğ‘›ğ‘–(ğ‘– + 1)/2
ğ‘”ğ‘–,ğ‘‘ ) .
( 8 ) can be explicitly expressed as the form Î˜(ğ‘ ) = Î˜1,0 + ğ›¾1ğ‘”1 + ğ›¾2ğ‘”2 +â‹…â‹…â‹… + ğ›¾ğ‘–ğ‘”ğ‘– , where ğ‘”1 . . . ğ‘”ğ‘– represents the respective gradients in the right side of Eq 8 and ğ›¾1 . . . ğ›¾ğ‘– are the corresponding factors of those gradients .
We then prove that the decaying rates ğ›¾1 . . . ğ›¾ğ‘– satisfy the
âˆ‘
âˆ‘ two conditions :
âˆ‘ lim ğ‘â†’âˆ
ğ›¾ğ‘– = lim ğ‘â†’âˆ
ğ›¾ğ‘– = âˆ and ( ğ›¾(ğ‘– )
âˆ‘
ğ‘– < âˆ ( see Eq 7 ) . ğ›¾2 âˆ‘
ğ‘›ğ‘– âˆ’ ğ‘‘ + 1 ğ‘›ğ‘–(ğ‘– + 1)/2 âˆ‘
)
ğ‘›ğ‘– âˆ’ ğ‘‘ + 1 ğ‘›ğ‘–(ğ‘– + 1)/2
)
ğ‘‘=1ğ‘›ğ‘– ğ›¾0
ğ‘‘=1ğ‘›ğ‘–
ğ‘‘=1ğ‘›ğ‘–(ğ‘›ğ‘– âˆ’ ğ‘‘ + 1 )
( 1 + ğ‘–/ğ‘ âˆ‘
ğ‘›ğ‘–2(ğ‘– + 1)/2
= âˆ
1 ğ‘–
= lim ğ‘â†’âˆ
= lim ğ‘â†’âˆ
= lim ğ‘â†’âˆ
ğ‘–=1ğ‘
âˆ‘
ğ‘–=1ğ‘
âˆ‘
ğ‘–=1ğ‘
âˆ‘
ğ‘–=1ğ‘
Similarly , âˆ‘ lim ğ‘â†’âˆ
ğ›¾2 ğ‘– = lim ğ‘â†’âˆ
= lim ğ‘â†’âˆ
âˆ‘
[ (
ğ‘–=1ğ‘
âˆ‘
ğ‘–=1ğ‘
1 ğ‘–3
ğ›¾0
1 + ğ‘–/ğ‘ < âˆ
âˆ‘
)2
ğ‘‘=1ğ‘›ğ‘–
ğ‘›ğ‘– âˆ’ ğ‘‘ + 1 ğ‘›ğ‘–(ğ‘– + 1)/2
(
)2 ]
Then , applying those two conditions into the convergence theorem ( see Section III A ) completes the proof . âŠ“âŠ”
1072
