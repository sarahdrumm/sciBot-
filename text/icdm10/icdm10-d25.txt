Probabilistic Inference Protection on Anonymized Data
Raymond Chi Wing Wong1 , Ada Wai Chee Fu2 , Ke Wang3 , Yabo Xu4 , Jian Pei3 , Philip S . Yu5
1The Hong Kong University of Science and Technology
2The Chinese University of Hong Kong , 3Simon Fraser University
4Sun Yat sen University , 5University of Illinois at Chicago raywong@cseusthk , adafu@csecuhkeduhk ,
{wangk,jpei}@cssfuca , xuyabo@mailsysueducn , psyu@csuicedu
Abstractâ€”Background knowledge is an important factor in privacy preserving data publishing . Probabilistic distributionbased background knowledge is a powerful kind of background knowledge which is easily accessible to adversaries . However , to the best of our knowledge , there is no existing work that can provide a privacy guarantee under adversary attack with such background knowledge . The difficulty of the problem lies in the high complexity of the probability computation and the non monotone nature of the privacy condition . The only solution known to us relies on approximate algorithms with no known error bound . In this paper , we propose a new bounding condition that overcomes the difficulties of the problem and gives a privacy guarantee . This condition is based on probability deviations in the anonymized data groups , which is much easier to compute and which is a monotone function on the grouping sizes .
I . INTRODUCTION
With the increasing collections of data containing information of vast populations , which are potentially useful for different kinds of analysis , the issue of privacy preserving data publishing has become an important topic for database communities .
In our problem , a table such as Table I is to be anonymized for publication . We assume that each tuple in the table is owned by an individual and each individual owns at most one tuple . The table has two kinds of attributes , ( 1 ) the quasiidentifier ( QI ) attributes and ( 2 ) the sensitive attribute . The QI attributes can be an individual identifier in the table . In our example , the QI attributes are Gender and Age . [ 10 ] points out that in a real dataset , with the help of a publicly available external table such as a voter registration list , about 87 % of individuals can be uniquely identified by only three QI attributes , namely sex , date of birth and 5 digit zip code . An example of a voter registration list is shown in Table II . The sensitive attribute contains some sensitive values that should be protected . In our example , the sensitive attribute is â€œ Disease â€ with sensitive values such as Lung Cancer and HIV . Note that the attribute â€œ Name â€ is an obvious identifier and will be removed before publication . The target of privacy preserving data publishing is to anonymize ğ‘‡ and publish an anonymized dataset ğ‘‡ âˆ— to satisfy some privacy requirements . A common technique is
. to horizontally partition ğ‘‡ into multiple tuple groups , also called anonymized groups or A groups . Let ğ¿ be a resulting group . Each group is given a unique ID called GID . The linkage between individual records and the sensitive attribute in each A group is broken . One way to achieve this is bucketization , forming two tables , the QI table ( Table III(a ) ) for the QI attributes and the sensitive table ( Table III(b ) ) for the sensitive attribute . These two tables form the anonymized dataset ğ‘‡ âˆ— Let us consider a simplified setting of the ğ‘™ diversity model [ 8 ] as a privacy requirement for published data ğ‘‡ âˆ— . An A group is said to be ğ‘™ diverse or satisfy ğ‘™ diversity if in the A group the number of occurrences of any sensitive value is at most 1/ğ‘™ of the group size . A table satisfies ğ‘™ diversity ( or it is ğ‘™ diverse ) if all A groups in it are ğ‘™ diverse . Suppose that Table I is anonymized to Table III . It is easy to see that Table III satisfies 2 diversity . The target of 2 diversity is that each individual cannot be linked to a disease with a probability of more than 05 However , we show below that this table does not meet this target if we consider distribution based background knowledge . In the following , we simply refer to the A group with GID equal to ğ¿ğ‘– by ğ¿ğ‘– .
Example 1 : Consider ğ¿1 in Table III . In ğ¿1 , Lung Cancer and Hypertension are values of the sensitive attribute Disease . If we are given the voter registration list as shown in Table II , one can determine that the two tuples in ğ¿1 correspond to Alan and Betty . Without additional information one concludes that each of Alan and Betty has a 50 % chance of linking to Lung Cancer ( Hypertension ) . However , suppose we are given Table IV which discloses that the probability of a male patient being linked to Lung Cancer is 0.1 and that of a female patient is 0003 With this distribution , the adversary can deduce that Betty , being a female patient , has less chance of having Lung Cancer while Alan , being a male patient , has a higher chance . The intended protection guarantee of 50 % threshold is thus violated .
The above example shows that background knowledge has important impact on privacy preserving data publishing . Although in the example , the anonymization is based on
Name Alan Betty
Catherine
Diana
Gender Male Female Female Female
Age 41 42 63 64
Disease
Lung Cancer Hypertension
Flu HIV
Table I
GIVEN DATASET ğ‘‡
Name Alan Betty
Catherine
Diana
Gender Male Female Female Female
Age 41 42 63 64
Table II
VOTER REGISTRATION LIST bucketization , the same issue arises with a generalization based method . The reason is that the adversary has at his/her disposal the external table with which he/she may be able to look up the details of individuals who are mapped to an A group . For example , if the QI values of ğ¿2 in Table III are generalized to { Female , 6* } , and if Catherine and Diana are the only female patients with Age of 6* in the external table , Table II , then the adversary can determine that they are the owners of the two tuples in ğ¿2 and all their exact QI values can be determined . Once the details are determined , the adversary can estimate the revised probabilities .
In this paper , we consider background knowledge in the form of QI based distribution , which is the distribution of the values in the sensitive attribute restricted to individuals with the same values on some QI attributes . For example , the distribution of the sensitive attribute values according to female patients may be encoded as {(Female : â€œ Lung Cancer â€ , 0.003 ) , ( Female : â€œ Hypertension â€ , 0.21 ) , } where ( Female:ğ‘¥ , ğ‘ ) denotes that the probability that a female is linked to a value ğ‘¥ is ğ‘ . This is called the patient apriori distribution since it is assumed to be known by the adversary before ğ‘‡ âˆ— is published . It can be seen that such background knowledge is not difficult to come by given a lot of statistics available from the government or other agencies ( eg , statistical reports from the US Department of Health and Human Services and other statistical data sources given in [ 7 ] , [ 9] ) .
Given that the linkage probability can be affected by an apriori probabilistic distribution that is known by the adversary , one obvious approach is to incorporate the revised probability into an existing anonymization method so that the new probability is measured against the threshold in each validation step . This is in fact the strategy in [ 7 ] . The authors have adopted the algorithm of Mondrian [ 3 ] and incorporated bucketization for the result generation . However , this straight forward approach has a major obstacle . The complexity of computing the above linkage probability , also called posterior belief in [ 7 ] ( as opposed to the apriori distribution ) , is very high . As pointed out in [ 7 ] , this problem is # P complete . Also , with Mondrian or other anonymization methods , the computation is carried out many times during the state space search . Therefore , they have resorted to an approximation algorithm for computing the probabilities . To our knowledge , [ 7 ] is the only previous work that has dealt with probabilistic adversary knowledge of QI based distribution . However , the use of approximated probability computation implies that there is no solid guarantee on the privacy protection . Such a solution may not be desirable since it compromises the one issue that users are most concerned about . In this paper , we propose a new bounding condition that solves this problem with a solid guarantee .
The key to the bounding condition is that one does not need to compute the exact linkage probabilities in order to provide a guarantee . Instead , we prove that once the anonymization satisfies certain conditions that are easy to compute , the privacy is guaranteed . The essence of our bounding condition is the principle of similar linkage . Specifically , we observe that privacy is breached whenever an individual in an A group has a much higher chance of linking to a sensitive value compared with another individual in the A group according to the QI based distribution . Based on this observation , we propose the principle of similar linkage such that all individuals in each A group have â€œ similar â€ chances of linking to any sensitive value in the group , according to the distribution . Since they have â€œ similar â€ chances , it is not possible for the adversary to pinpoint any linkage of an individual to a sensitive value with a higher chance . This observation has motivated us to translate this idea into a concrete formulation of some computable properties of the A groups . We define a measurement called Greatest Probability Deviation , â–³ğ‘šğ‘ğ‘¥ , to model the fluctuation of probabilities in an A group . A bound is derived for this measurement to ensure privacy . Instead of enforcing the required probabilities , we enforce this required condition on â–³ğ‘šğ‘ğ‘¥ which is much easier to compute .
Note also that the above linkage probability or posterior belief is not monotone in that an A group violating privacy can be split into two groups that preserve privacy . For example , an A group with 2 female patients and 2 male patients may violate privacy , but when it is split into a group of 2 female patients and another group of 2 male patients , the privacy can be preserved . However , most existing anonymization methods depend on the monotone property of the privacy guarantee . The implication is that a supposedly exhaustive algorithm like Incognito [ 4 ] is neither exhaustive nor optimal .
Our contribution can be summarized as follows . To the best of our knowledge , we are the first to propose new bounding conditions that are easy to compute and give a privacy guarantee . This condition is based on probability deviations in the anonymized data groups , which is much easier to compute and which is a monotone function on the grouping sizes .
Gender Male Female Female Female
Age 41 42 63 64
GID ğ¿1 ğ¿1 ğ¿2 ğ¿2
GID ğ¿1 ğ¿1 ğ¿2 ğ¿2
Disease
Lung Cancer Hypertension
Flu HIV
( a ) QI Table
( b ) Sensitive table
Table III
2 DIVERSE ğ‘‡ âˆ—
ğ‘( ) Male Female
Lung Cancer
Not Lung Cancer
0.1 0.003
Table IV
0.9 0.997
A QI BASED PROBABILITY DISTRIBUTION FOR â€œ GENDER â€
II . PROBLEM DEFINITION
Let ğ‘‡ be a table . We assume that one of the attributes is a sensitive attribute ğ‘‹ where some values of this attribute should not be linkable to any individual . These values are called sensitive values . The value of the sensitive attribute of a tuple ğ‘¡ is denoted by ğ‘¡ğ‘‹ A quasi identifier ( QI ) is a set of attributes of ğ‘‡ , ğ´1 , ğ´2 , , ğ´ğ‘ , that may serve as identifiers for some individuals . Each tuple in the table ğ‘‡ is related to one individual and no two tuples are related to the same individual . With publicly available voter registration lists ( like Table II ) , the QI values can often be used to identify a unique individual .
The first step of privacy preserving data publication is to determine the target of protection . In our problem setting , the target of protection is to limit the probability of a linkage from an individual to some sensitive value based on the knowledge of an adversary . In the literature [ 14 ] , [ 12 ] , [ 6 ] , [ 5 ] , it is assumed that the knowledge of an adversary includes ( 1 ) the published dataset ğ‘‡ âˆ— , ( 2 ) a publicly available external table ğ‘‡ ğ‘’ such as a voter registration list that maps QIs to individuals [ 10 ] , [ 12 ] and ( 3 ) some background knowledge . We also follow these assumptions in our analysis . We focus on the QI based distribution as background knowledge .
The QI is made up of a set of attributes . Each possible value for an attribute set such as â€œ Gender â€ in our example is called a signature . In general , there can be different attribute sets , such as { â€œ Gender â€ , â€œ Age â€ } , for which a signature ğ‘  can be {( â€œ Gender â€ , â€œ Male â€ ) , ( â€œ Age â€ , â€œ 41 â€ )} . For convenience , we often drop the attribute names , and thus we have { â€œ Male â€ , â€œ 41 â€ } for the above signature . The first tuple in Table III(a ) matches { â€œ Male â€ } but the second does not . Definition 1 ( Signature ğ‘¡.ğ‘  ) : Given a QI attribute set ğ’œ with ğ‘ attributes ğ´1 , , ğ´ğ‘ . A signature ğ‘  of ğ’œ is a set of attribute value pairs ( ğ´1 , ğ‘£1 ) , , ( ğ´ğ‘ , ğ‘£ğ‘ ) which appear in the published dataset ğ‘‡ âˆ— , where ğ´ğ‘– is a QI attribute and ğ‘£ğ‘– is a value . A tuple ğ‘¡ in ğ‘‡ âˆ— is said to match ğ‘  if ğ‘¡.ğ´ğ‘– = ğ‘£ğ‘– for all ğ‘– = 1 , 2 , , ğ‘ . We also say that ğ‘¡.ğ‘  = ğ‘  . The QI based apriori distribution for the attribute set { â€œ Gender â€ } is described in Table IV . Each probability in the table is called an aprori probability . The sample space for each such discrete probability distribution consists of the possible assignments of the sensitive values such as ğ‘¥ to an individual with the particular gender . For signature ğ‘  , the sample space is denoted by Î©ğ‘  . Definition 2 ( Apriori Distribution ğº ) : Given an attribute set ğ’œ , the QI based distribution ğº of ğ’œ contains a set of entries ( ğ‘  : ğ‘¥ , ğ‘ ) for each possible signature ğ‘  of ğ’œ , where ğ‘ is equal to ğ‘(ğ‘  : ğ‘¥ ) which denotes the apriori probability that a tuple matching signature ğ‘  is linked to ğ‘¥ . For example , ğº may contain ( â€œ Female â€ : â€œ Lung Cancer â€ , 0.003 ) and ( â€œ Male â€ : â€œ Lung Cancer â€ , 01 ) This involves two sample spaces Î©ğ¹ ğ‘’ğ‘šğ‘ğ‘™ğ‘’ and Î©ğ‘€ ğ‘ğ‘™ğ‘’ .
Definition 3 ( ğ‘Ÿ robustness ) : Assume that an adversary has the background knowledge of the QI based distribution . A dataset ğ‘‡ âˆ— is ğ‘Ÿrobust ) if , for any individual ğ‘¡ and any sensitive value ğ‘¥ , the probability that ğ‘¡ is linked to ğ‘¥ , ğ‘(ğ‘¡ : ğ‘¥ ) , does not exceed 1/ğ‘Ÿ . is said to satisfy ğ‘Ÿ robustness ( or ğ‘‡ âˆ—
In this paper , we study the following problem . Definition 4 ( problem ) : Given a dataset ğ‘‡ , generate an from ğ‘‡ which satisfies ğ‘Ÿ robustness anonymized dataset ğ‘‡ âˆ— and at the same time minimizing the information loss .
There have been different definitions for information loss in the literature . In our experiments , we shall adopt the measurement of accuracy in query results from ğ‘‡ âˆ— versus that from ğ‘‡ . We assume that the published data is meant for data analysis and most data analysis can be modeled by certain aggregate queries on the dataset . It has been found in previous studies [ 14 ] , [ 12 ] , [ 6 ] that the accuracy in certain types of queries can give an indication of the utility of the published dataset .
The only previous work that deals with QI based distribution is [ 7 ] . Their problem definition , however , is based on a relative bound on a distance measure between the aprior linkage probability before the published table is given and the posterior probability after the data is published . We believe that both an absolute bound such as 1/ğ‘Ÿ in our definition and a relative bound have their merits . An absolute bound may be too rigid in case the prior probability already exceeds the given bound , though this problem can be handled by setting ğ‘Ÿ appropriately . On the other hand , a good relative bound may be too complex to be understandable for naive users , for example , the distance measure used in [ 7 ] involves kernel smoothing and JS divergence . In this paper , we focus on an absolute bound .
III . PROBABILITY FORMULATION
There are two common approaches for anonymization , which generates ğ‘‡ âˆ— from ğ‘‡ : generalization and bucketization . In both approaches , the tuple set of ğ‘‡ is partitioned into multiple anonymized groups or A groups . Bucketization is more challenging since the adversary is saved the effort to uncover the QI values for individuals in an A group . We focus on bucketization but our results apply readily to generalization . With anonymization , there is a mapping which maps each tuple in ğ‘‡ to an A group in ğ‘‡ âˆ— . For example , the first tuple ğ‘¡1 in Table I is mapped to A group ğ¿1 . Suppose there are ğ‘š possible signatures for attribute set ğ’œ , namely ğ‘ 1 , ğ‘ 2 , , ğ‘ ğ‘š . Let ğº be the background knowledge consisting of the set of all QI based distributions . In ğº , the probability that ğ‘ ğ‘– is linked to a sensitive value ğ‘¥ is given by ğ‘(ğ‘ ğ‘– : ğ‘¥ ) . Given ğº , the formula for ğ‘(ğ‘¡ : ğ‘¥ ) , the probability that a tuple ğ‘¡ is linked to sensitive value ğ‘¥ , is derived below .
Definition 5 ( Possible World ) : Consider an A group ğ¿ with ğ‘ tuples , namely ğ‘¡1 , ğ‘¡2 , , ğ‘¡ğ‘ , with corresponding values in sensitive attribute ğ‘‹ of ğ›¾1 , ğ›¾2 , ğ›¾ğ‘ . A possible world ğ‘¤ for ğ¿ is a possible assignment mapping the tuples in set {ğ‘¡1 , ğ‘¡2 , , ğ‘¡ğ‘} to values in multi set {ğ›¾1 , ğ›¾2 , ğ›¾ğ‘} in ğ¿ .
Given an A group ğ¿ with a set of tuples and a multi set of the values in ğ‘‹ . Considering all possible worlds , we form a sample space . More precisely , the sample space Î©ğ¿ consists of all the possible assignments of the sensitive values in ğ¿ to the ğ‘ tuples in ğ¿ . We call each possible assignment a possible world . For each such possible world ğ‘¤ , according to the QI based distribution ğº based on attribute set ğ’œ , we can determine the probability ğ‘(ğ‘¤âˆ£ğ¿ ) that ğ‘¤ occurs given ğ¿ .
Definition 6 ( Primitive Events , Projected Events ) : A mapping ğ‘¡ : ğ‘¥ from an individual or tuple ğ‘¡ to a value ğ‘¥ in the set of sensitive attributes is called a sensitive event . Such an event corresponds to the set of possible worlds in Î©ğ¿ where ğ‘¡ is assigned ğ‘¥ . Denote the signature of tuple ğ‘¡ by ğ‘¡ğ‘  Let us call an event for the corresponding signature , â€œ ğ‘¡.ğ‘  : ğ‘¥ â€ , a projected event for ğ‘¡ .
The probability of a sensitive event , ğ‘(ğ‘¡ : ğ‘¥ ) , is the probability of interest for the adversary . The projected event , ( ğ‘  : ğ‘¥ ) , is an event of sample space Î©ğ‘  which consists of possible worlds of assigning different values to ğ‘  . The probability ğ‘(ğ‘  : ğ‘¥ ) is assumed to be known since we assume the knowledge of the set of QI based distributions ğº . Note that ğ‘(ğ‘  : ğ‘¥ ) is independent of ğ¿ .
The probability that ğ‘¤ occurs given ğ¿ is proportional to the product of the probabilities of the corresponding projected events for the tuples ğ‘¡1 , ğ‘¡ğ‘ in ğ¿ , we shall denote this product as ğ‘(ğ‘¤ ) :
ğ‘(ğ‘¤ ) = ğ‘1,ğ‘¤ Ã— ğ‘2,ğ‘¤ Ã— Ã— ğ‘ğ‘,ğ‘¤
( 1 ) where ğ‘ğ‘—,ğ‘¤ is the probability that ğ‘¡ğ‘— is linked to a value in the sensitive attribute specified in ğ‘¤ . Suppose ğ‘¡ğ‘— matches signature ğ‘ ğ‘– . If ğ‘¡ğ‘— is linked to ğ‘¥ in ğ‘¤ , then ğ‘ğ‘—,ğ‘¤ = ğ‘(ğ‘ ğ‘– : ğ‘¥ ) . Let the set of all the possible worlds for ğ¿ be ğ’² . The sum of probabilities of all the possible worlds given ğ¿ must be 1 , since they form the sample space Î©ğ¿ . Therefore , we want to make sure that
ğ‘¤âˆˆğ’² ğ‘(ğ‘¤âˆ£ğ¿ ) = 1 .
âˆ‘
Hence , the probability of ğ‘¤ given ğ¿ is given by :
ğ‘(ğ‘¤âˆ£ğ¿ ) =
âˆ‘
ğ‘(ğ‘¤ ) ğ‘¤â€²âˆˆğ’² ğ‘(ğ‘¤â€² )
( 2 )
âˆ‘ it is easy to verify that
With the above equation , ğ‘¤âˆˆğ’² ğ‘(ğ‘¤âˆ£ğ¿ ) = 1 . We aim to find the probability that an individual ğ‘¡ğ‘— in ğ¿ is linked to a sensitive value ğ‘¥ . This is given by the sum of the probabilities ğ‘(ğ‘¤âˆ£ğ¿ ) of all the possible worlds ğ‘¤ where ğ‘¡ğ‘— is linked to ğ‘¥ .
ğ‘(ğ‘¡ğ‘— : ğ‘¥ ) =
âˆ‘
ğ‘¤âˆˆğ’² ( ğ‘¡ğ‘— :ğ‘¥ )
ğ‘(ğ‘¤âˆ£ğ¿ )
( 3 ) where ğ’² ( ğ‘¡ğ‘— :ğ‘¥ ) is the set of all possible worlds ğ‘¤ in ğ’² in which ğ‘¡ğ‘— is assigned value ğ‘¥ . in [ 7 ] despite different
Note that our probabilistic formulation is basically the same as that terminologies . As pointed out in [ 7 ] , we can compute ğ‘(ğ‘¡ : ğ‘¥ ) by enumerating all the possible worlds in Î©ğ¿ . However , the total number of possible words is exponential in the size of ğ¿ . If the sensitive values in ğ¿ are ğ‘1 , , ğ‘ğ‘š , and the frequency of ğ‘ğ‘– in ğ¿ is ğ‘“ğ‘– , then the number of possible worlds is ğ‘–=1 ğ‘“ğ‘–! , where âˆ‘
ğ‘ !âˆğ‘š
ğ‘– ğ‘“ğ‘– = âˆ£ğ¿âˆ£(= ğ‘ ) .
IV . THEORETICAL PROPERTIES
Given the problem definition our next task is to find an anonymization algorithm . Most known algorithms belong to one of two main categories : top down and bottom up . With top down approach [ 2 ] , we start with the whole table as a single A group and recursively split the current groups until the privacy condition is violated and report the smallest qualified A groups . Smaller A groups are more favorable since they tend to incur less information loss . Note that the privacy condition is checked at each splitting . The bottomup approach [ 11 ] goes in the reverse direction : starting with single tuple A groups , we merge A groups until the privacy condition is met . Both approaches depends on a monotone property of the privacy condition : if an A group violates privacy , then splitting the group into smaller groups will also violate privacy .
A naive approach for ğ‘Ÿ robustness is to adopt some known anonymization algorithm ğ´ and replace the probability measure in ğ´ by ğ‘(ğ‘¡ : ğ‘¥ ) . However , the complexity of computing ğ‘(ğ‘¡ : ğ‘¥ ) is very high . Moreover , ğ‘Ÿ robustness is not monotone so that an ğ´ group that violates ğ‘Ÿ robustness into small groups that are ğ‘Ÿ robust , while may be split top down or bottom up algorithms are based on monotone privacy conditions .
In this section , we presents an important theoretical property for this problem which can help us to overcome the above difficulties . Our theoretical property allows us to set up a new privacy condition that does not require the computation of ğ‘(ğ‘¡ : ğ‘¥ ) .
In Section I , we observe that privacy is breached easily whenever an individual in an A group has a much higher chance of linking to a sensitive value compared with another individual in the A group . For example , consider the Agroup ğ¿1 in Table III . From the QI based distribution ( Table IV ) , it is more likely that a male patient is linked to Lung Cancer compared with a female patient . Note that the apriori probability of a male patient linking to Lung Cancer , ğ‘“1 , is 0.1 and that of a female patient , denoted by ğ‘“2 , is 0003 The difference in the apriori probabilities is 0.1 âˆ’ 0.003 = 0097 This difference is the culprit that aids privacy breach .
Consider a tuple ğ‘¡ğ‘£ in an A group ğ¿ and a sensitive value ğ‘¥ . We want to show that if ğ¿ satisfies a certain condition , the privacy of ğ‘¡ğ‘£ can be guaranteed ( ie , ğ‘(ğ‘¡ğ‘£ : ğ‘¥ ) â‰¤ 1/ğ‘Ÿ ) . The condition essentially limits the deviations in the apriori probabilities in terms of the group size .
In the following , we require that for each sensitive value ğ‘¥ in ğ‘‹ , each A group ğ¿ contains at most one occurrence of ğ‘¥ . This requirement ( called ğ‘š uniqueness in [ 15 ] ) helps to increase the number of possible sensitive values in ğ¿ and weaken the linkage to any such value . It also allows us to determine any privacy breach in ğ‘‚(1 ) time . It can be easily satisfied if the frequency of each sensitive value is not high . Note that similar requirements are found in other including ğ‘š invariance [ 15 ] and Anatomy [ 14 ] , models , which requires that each sensitive value appears at most once in each group for â„“ diversity . Conceptually , if the frequency of a value is high , then it is a common phenomenon , and common phenomena are typically not sensitive . In the following , we consider the QI based apriori distribution ğº on a certain attribute set ğ’œ . How to handle multiple attribute sets will be discussed at the end of this section . Definition 7 ( Probability Deviation , â–³ğ‘£ ) : Let ğ¿ be an Awith tuples ğ‘¡1 , ğ‘¡2 , ğ‘¡ğ‘ and ğ‘ â‰¥ ğ‘Ÿ . Let ğ‘¥ be group in ğ‘‡ âˆ— a sensitive value that appears exactly once in ğ¿ . Let the signature of ğ‘¡ğ‘£ be ğ‘¡ğ‘£.ğ‘  , ğ‘£ âˆˆ [ 1 , ğ‘ ] . Suppose that for tuple ğ‘¡ğ‘£ , the apriori probability ğ‘(ğ‘¡ğ‘£.ğ‘  : ğ‘¥ ) = ğ‘“ğ‘£ .
Let ğ‘“ğ‘šğ‘ğ‘¥ = maxğ‘£âˆˆ[1,ğ‘ ] ğ‘“ğ‘£ . The probability deviation of ğ‘¡ğ‘£ given ğ‘“ğ‘šğ‘ğ‘¥ is : â–³ğ‘£ = ğ‘“ğ‘šğ‘ğ‘¥ âˆ’ ğ‘“ğ‘£ In our running example , for ğ¿1 , let the tuples be ğ‘¡1 , ğ‘¡2 . Let ğ‘ 1 = { â€œ Male â€ } and ğ‘ 2 = { â€œ Female â€ } . ğ‘¡1.ğ‘  = ğ‘ 1 , and ğ‘¡2.ğ‘  = ğ‘ 2 . If we set ğ‘¥ to be â€œ Lung Cancer â€ , then ğ‘“1 = 0.1 and ğ‘“2 = 0003 ğ‘“ğ‘šğ‘ğ‘¥ is equal to 01 â–³1 = ğ‘“ğ‘šğ‘ğ‘¥ âˆ’ ğ‘“1 = 0.1 âˆ’ 0.1 = 0 and â–³2 = ğ‘“ğ‘šğ‘ğ‘¥ âˆ’ ğ‘“2 = 0.1 âˆ’ 0.003 = 0097 Now we are ready to introduce a property whereby an Theorem 1 ( â–³ Bounding Condition ) : Let ğ‘Ÿ be the privacy parameter in ğ‘Ÿ robustness where ğ‘Ÿ > 1 . Following the
A group can guarantee ğ‘Ÿ robustness . symbols in Definition 7 , if for all ğ‘£ âˆˆ [ 1 , ğ‘ ] ,
( ğ‘ âˆ’ ğ‘Ÿ)ğ‘“ğ‘šğ‘ğ‘¥
â–³ğ‘£ â‰¤
ğ‘“ğ‘šğ‘ğ‘¥(ğ‘Ÿ âˆ’ 1)/(1 âˆ’ ğ‘“ğ‘šğ‘ğ‘¥ ) + ( ğ‘ âˆ’ 1 )
( 4 ) then for all ğ‘£ âˆˆ [ 1 , ğ‘ ] , ğ‘(ğ‘¡ğ‘£ : ğ‘¥ ) â‰¤ 1/ğ‘Ÿ Proof : For the sake of space , we omit the complete proof . Details can be found in [ 13 ] . The major idea of the proof is to enumerate all possible worlds and find all possible worlds that tuple ğ‘¡ğ‘£ is linked to sensitive value ğ‘¥ . According to these possible worlds , we derive a formula for ğ‘(ğ‘¡ğ‘£ : ğ‘¥ ) . If we have the condition specified in ( 4 ) , we can prove that ğ‘(ğ‘¡ğ‘£ : ğ‘¥ ) â‰¤ 1/ğ‘Ÿ .
Definition 8 ( â–³ğ‘ğ‘’ğ‘–ğ‘™ , â–³ğ‘šğ‘ğ‘¥ ) : â–³ğ‘ğ‘’ğ‘–ğ‘™
RHS of Inequality ( 4 ) . That is , is defined to be the
â–³ğ‘ğ‘’ğ‘–ğ‘™ =
( ğ‘ âˆ’ ğ‘Ÿ)ğ‘“ğ‘šğ‘ğ‘¥
ğ‘“ğ‘šğ‘ğ‘¥(ğ‘Ÿ âˆ’ 1)/(1 âˆ’ ğ‘“ğ‘šğ‘ğ‘¥ ) + ( ğ‘ âˆ’ 1 )
Define the Greatest Probability Deviation as
â–³ğ‘šğ‘ğ‘¥ = max ğ‘£âˆˆ[1,ğ‘ ]
{â–³ğ‘£}
â–³ğ‘šğ‘ğ‘¥ is the greatest difference in the apriori probabilities linking to ğ‘¥ in an A group . Note that â–³ğ‘ğ‘’ğ‘–ğ‘™ â‰¥ â–³ğ‘šğ‘ğ‘¥ â‰¥ 0 . In our running example , since â–³1 = 0 and â–³2 = 0.097 , we have â–³ğ‘šğ‘ğ‘¥ = max{0 , 0.097} = 0097 Rewriting Theorem 1 , we have : Corollary 1 ( â–³ bounding condition ) : Let ğ‘Ÿ be the pri vacy parameter in ğ‘Ÿ robustness where ğ‘Ÿ > 1 .
If â–³ğ‘šğ‘ğ‘¥ â‰¤ â–³ğ‘ğ‘’ğ‘–ğ‘™ then for all ğ‘£ âˆˆ [ 1 , ğ‘ ] , ğ‘(ğ‘¡ğ‘£ : ğ‘¥ ) â‰¤ 1/ğ‘Ÿ
( 5 )
Example 2 : If an A group ğ¿ contains three tuples matching ğ‘ 1 , ğ‘ 2 and ğ‘ 3 with ğ‘“1 = 0.1 , ğ‘“2 = 0.08 and ğ‘“3 = 009 Then , ğ‘ = 3 and ğ‘“ğ‘šğ‘ğ‘¥ = 01 â–³ğ‘šğ‘ğ‘¥ = 0.1 âˆ’ 0.08 = 002 Suppose ğ‘Ÿ = 2 . The RHS of ( 4 ) is â–³ğ‘ğ‘’ğ‘–ğ‘™ = ( 3 âˆ’ 2 ) Ã— 01/[01 Ã— ( 2 âˆ’ 1)/(1 âˆ’ 0.1 ) + ( 3 âˆ’ 1 ) ] = 00474 Since â–³ğ‘šğ‘ğ‘¥ â‰¤ 0.0474 , from Theorem 1 , for all tuples ğ‘¡ğ‘£ in ğ¿ , ğ‘(ğ‘¡ğ‘£ : ğ‘¥ ) â‰¤ 1/ğ‘Ÿ .
The inequality in Theorem 1 ( or Corollary 1 ) corresponds to the principle of similar linkage we mentioned in Section I . Intuitively , the greatest difference in the aprioir probabilities linking to ğ‘¥ in an A group should be bounded . In other words , the apriori probabilities should be â€œ similar â€ . Note that the computation of â–³ğ‘ğ‘’ğ‘–ğ‘™ takes ğ‘‚(1 ) time . After we obtain the value of â–³ğ‘ğ‘’ğ‘–ğ‘™ , we can determine whether ğ‘(ğ‘¡ğ‘£ : ğ‘¥ ) â‰¤ 1/ğ‘Ÿ by Inequality ( 4 ) in O(1 ) time , which is quite efficient .
Let us consider the effects of the values of ğ‘“ğ‘šğ‘ğ‘¥ and ğ‘ to understand the physical meaning of Theorem 1 . If ğ‘“ğ‘šğ‘ğ‘¥ = 1 or ğ‘“ğ‘šğ‘ğ‘¥ = 0 , then â–³ğ‘šğ‘ğ‘¥ = 0 . Hence , the QI based distributions of all tuples in ğ¿ should be the same to guarantee privacy . Table V shows the values of â–³ğ‘ğ‘’ğ‘–ğ‘™ with some chosen values of ğ‘ , ğ‘Ÿ and ğ‘“ğ‘šğ‘ğ‘¥ . It can be seen that â–³ğ‘ğ‘’ğ‘–ğ‘™ is small
ğ‘ ğ‘Ÿ 3 2 2 3 2 3 2 3 2 4 6 2 3 6 6 4
ğ‘“ğ‘šğ‘ğ‘¥ â–³ğ‘ğ‘’ğ‘–ğ‘™ 0.0474 0.1 0.1235 0.3 0.1667 0.5 0.0818 0.9 0.1750 0.3 0.3 0.2211 0.1537 0.3 0.3 0.0955
VALUES OF â–³ğ‘ğ‘’ğ‘–ğ‘™ WITH SOME CHOSEN VALUES OF ğ‘ , ğ‘Ÿ AND ğ‘“ğ‘šğ‘ğ‘¥
Table V when ğ‘“ğ‘šğ‘ğ‘¥ is near the extreme values of 0 or 1 , since the apriori probability of a tuple is more pronounced . Consider Inequality ( 4 ) again . If ğ‘ â†’ âˆ , then â–³ğ‘šğ‘ğ‘¥ â‰¤ ğ‘“ğ‘šğ‘ğ‘¥ . Since ğ‘“ğ‘šğ‘ğ‘¥ is the greatest possible apriori probability in ğ¿ , it means that â–³ğ‘šğ‘ğ‘¥ can be any feasible value ( ie , 0 â‰¤ â–³ğ‘šğ‘ğ‘¥ â‰¤ ğ‘“ğ‘šğ‘ğ‘¥ ) . Therefore , when the A group is extremely large , under Theorem 1 , there will be no privacy breach . When ğ‘ = ğ‘Ÿ , â–³ğ‘šğ‘ğ‘¥ â‰¤ 0 . That is , the apriori probabilities of all tuples in ğ¿ should be equal . Otherwise , there may be a privacy breach . Furthermore , ğ‘ has the following relation with â–³ğ‘ğ‘’ğ‘–ğ‘™ . Theorem 2 ( Monotonicity ) : â–³ğ‘ğ‘’ğ‘–ğ‘™ is a monotonically in creasing function on ğ‘ . Proof : Let ğ‘“ = ğ‘“ğ‘šğ‘ğ‘¥ .
ğ‘‘â–³ğ‘ğ‘’ğ‘–ğ‘™ ğ‘‘ğ‘
=
( ğ‘Ÿ âˆ’ 1 ) Ã— ğ‘“ 2 [ (ğ‘Ÿ âˆ’ 1 ) Ã— ğ‘“
1âˆ’ğ‘“ + ( ğ‘Ÿ âˆ’ 1 ) Ã— ğ‘“ 1âˆ’ğ‘“ + ( ğ‘ âˆ’ 1)]2
â‰¥ 0
From the above , in order to guarantee ğ‘(ğ‘¡ğ‘£ : ğ‘¥ ) â‰¤ 1/ğ‘Ÿ , we can increase the size ğ‘ of the A group ğ¿ . With a greater value of ğ‘ , the upper bound â–³ğ‘ğ‘’ğ‘–ğ‘™ increases , and the constraint as dictated by Inequality ( 4 ) is relaxed , making it easier to reach the guarantee . The upper bound â–³ğ‘ğ‘’ğ‘–ğ‘™ corresponds to the new bounding condition described in Section I . Consider that the data is anonymized . If an A group ğ¿ satisfies the inequality in Theorem 1 with respect to attribute set ğ’œ and , in ğ¿ , each sensitive value occurs at most once , we say that ğ¿ satisfies the â–³ bounding condition with respect to ğ’œ . Otherwise , ğ¿ violates the â–³ bounding condition . This â–³ bounding condition suggests some hints for anonymization . We can adopt a bottom up approach for this purpose . Initially , each tuple forms an A group . We repeat the following process until each A group satisfies the â–³ bounding condition with respect to any attribute set . If there exists an A group ğ¿ and an attribute set ğ’œ such that ğ¿ violates the â–³ bounding condition with respect to ğ’œ . Such a group is merged with other existing groups so that the resulting group satisfies the condition .
V . CONCLUSION
In this paper , we consider the background knowledge of QI based probabilistic distribution that may be possessed by the adversary in privacy preserving data publishing . While the problem is difficult due to high complexity in the probability computation , the setting is realistic and powerful in that it covers some other known background knowledge such as positive associations and negative associations [ 1 ] . For future work , we may investigate how to anonymize the dataset with this new bounding condition . We also plan to study the anonymization considering other kinds of probabilistic background knowledge , including the association among individuals such as members of the same family .
Acknowledgement : The research of Raymond Chi Wing Wong is supported by HKRGC GRF 621309 . The research of Ke Wang is supported by a Discovery Grant from NSERC . The research of Philip S . Yu is supported by US NSF through grants IIS 0914934 , DBI 0960443 , OISE0968341 and OIA 0963278 .
REFERENCES
[ 1 ] B C Chen , K . LeFevre , and R . Ramakrishnan . Privacy skyline : Privacy with multidimensional adversarial knowledge . In VLDB , 2007 .
[ 2 ] B . C . M . Fung , K . Wang , and P . S . Yu . Top down specialIn ICDE , ization for information and privacy preservation . 2005 .
[ 3 ] K . LeFevre , D . DeWitt , and R . Ramakrishnan . Mondrian multidimensional k anonymity . In ICDE , 2006 .
[ 4 ] K . LeFevre , D . J . DeWitt , and R . Ramakrishnan . Incognito :
Efficient full domain k anonymity . In SIGMOD , 2005 .
[ 5 ] N . Li and T . Li .
ğ‘¡ closeness : Privacy beyond ğ‘˜ anonymity and ğ‘™ diversity . In ICDE , 2007 .
[ 6 ] T . Li and N . Li . Injector : Mining background knowledge for data anonymization . In ICDE , 2008 .
[ 7 ] T . Li , N . Li , and J . Zhang . Modeling and integrating In ICDE , background knowledge in data anonymization . 2009 .
[ 8 ] A . Machanavajjhala , J . Gehrke , and D . Kifer . privacy beyond ğ‘˜ anonymity . In ICDE , 2006 .
ğ‘™ diversity :
[ 9 ] D . J . Martin , D . Kifer , A . Machanavajjhala , and J . Gehrke . Worst case background knowledge for privacy preserving data publishing . In ICDE , 2007 .
[ 10 ] L . Sweeney . k anonymity : a model for protecting privacy . International journal on uncertainty , Fuzziness and knowldege based systems , 10(5 ) , 2002 .
[ 11 ] K . Wang , P . S . Yu , and S . Chakraborty . Bottom up generIn alization : A data mining solution to privacy protection . ICDM , 2004 .
[ 12 ] R . Wong , A . Fu , K . Wang , and J . Pei . Minimality attack in privacy preserving data publishing . In VLDB , 2007 .
[ 13 ] R . C W Wong , A . W C Fu , K . Wang , Y . Xu , Probabilistic inference protection on J . Pei , and P . Yu . anonymized data . In http://wwwcseusthk/âˆ¼raywong/paper/ probInferenceProtection technical.pdf , 2010 .
[ 14 ] X . Xiao and Y . Tao . Anatomy : Simple and effective privacy preservation . In VLDB , 2006 .
[ 15 ] X . Xiao and Y . Tao . ğ‘š invariance : Towards privacy preserving re publication of dynamic datasets . In SIGMOD , 2007 .
