2010 IEEE International Conference on Data Mining
A Pairwise Systematic Microaggregation for Statistical Disclosure Control
Md Enamul Kabir , and Hua Wang
Department of Mathematics and Computing
University of Southern Queensland Toowoomba , QLD 4350 , Australia Emails : {kabir , wang}@usqeduau
Yanchun Zhang
Centre for Applied Informatics Research
School of Engineering and Science
Victoria University
PO Box 14428 , Melbourne , VIC 8001 , Australia
Email : YanchunZhang@vueduau
Abstractâ€”Microdata protection in statistical databases has recently become a major societal concern and has been intensively studied in recent years . Statistical Disclosure Control ( SDC ) is often applied to statistical databases before they are released for public use . Microaggregation for SDC is a family of methods to protect microdata from individual identification . SDC seeks to protect microdata in such a way that can be published and mined without providing any private information that can be linked to specific individuals . Microaggregation works by partitioning the microdata into groups of at least ğ‘˜ records and then replacing the records in each group with the centroid of the group . An optimal microaggregation method must minimize the information loss resulting from this replacement process . The challenge is how to minimize the information loss during the microaggregation process . This paper presents a pairwise systematic ( P S ) microaggregation method to minimize the information loss . The proposed technique simultaneously forms two distant groups at a time with the corresponding similar records together in a systematic way and then anonymized with the centroid of each group individually . The structure of P S problem is defined and investigated and an algorithm of the proposed problem is developed . The performance of the P S algorithm is compared against the most recent microaggregation methods . Experimental results show that P S algorithm incurs less than half information loss than the latest microaggregation methods for all of the test situations .
Keywords Privacy ; Microaggregation ; Microdata protection ;
ğ‘˜ anonymity ; Disclosure control ;
I . INTRODUCTION
In recent years , the phenomenal advance of technological developments in information technology enable government agencies and corporations to accumulate an enormous amount of personal data for analytical purposes . These agencies and organizations often need to release individual records ( microdata ) for research and other public benefit purposes . This propagation has to be in accordance with laws and regulations to avoid the propagation of confidential information . In other words , microdata should be published in such a way that preserve the privacy of the individuals . To protect personal data from individual identification , SDC is often applied before the data are released for analysis [ 2 ] , [ 25 ] . The purpose of microdata SDC is to alter the original microdata in such a way that the statistical analysis from the original data and the modified data are similar and the disclosure risk of identification is low . As SDC requires suppressing or altering the original data , the quality of data and the analysis results can be damaged . Hence , SDC methods must find a balance between data utility and personal confidentiality .
Microaggregation is a family of SDC methods for protecting microdata sets that have been extensively studied recently [ 3 ] , [ 4 ] , [ 6 ] , [ 7 ] , [ 10 ] , [ 11 ] , [ 19 ] , [ 21 ] . The basic idea of microaggregation is to partition a dataset into mutually exclusive groups of at least ğ‘˜ records prior to publication , and then publish the centroid over each group instead of individual records . The resulting anonymized dataset satisfies ğ‘˜anonymity [ 17 ] , requiring each record in a dataset to be identical to at least ( ğ‘˜âˆ’ 1 ) other records in the same dataset . As releasing microdata about individuals poses privacy threat due to the privacy related attributes , called quasi identifiers , both ğ‘˜ anonymity and microaggregation only consider the quasi identifiers . Microaggregation is traditionally restricted to numeric attributes in order to calculate the centroid of records , but also has been extended to handle categorical and ordinal attributes [ 4 ] , [ 7 ] , [ 18 ] . In this paper we propose a microaggregated method that is also applicable to numeric attributes . the anonymized dataset
The effectiveness of a microaggregation method is measured by calculating its information loss . A lower information loss implies that is less distorted from the original dataset , and thus provides better data quality for analysis . ğ‘˜ anonymity [ 16 ] , [ 17 ] , [ 20 ] , [ 24 ] provides sufficient protection of personal confidentiality of microdata , while ensuring the quality of the anonymized dataset , an effective microaggregation method should incur as little information loss as possible . In order to be useful in practice , the dataset should keep as much informative as possible . Hence , it is necessary to seriously consider the tradeoff between privacy and information loss . To minimize the information loss due to microaggregation , all records are partitioned into several groups such that each group contains at least ğ‘˜ similar records , and then the records in each group are replaced by their corresponding mean such that the values of each variable are the same . Such similar groups are known as clusters . In the context of data mining , clustering is a useful technique that partitions records into
1550 4786/10 $26.00 Â© 2010 IEEE DOI 101109/ICDM2010111
266 groups such that records within a group are similar to each other , while records in different groups are most distinct from one another . Thus , microaggregation can be seen as a clustering problem with constraints on the size of the clusters .
Many microaggregation methods derive from traditional clustering algorithms . For example , Domingo Ferrer and Mateo Sanz [ 3 ] proposed univariate and multivariate ğ‘˜Ward algorithms that extend the agglomerative hierarchical clustering method of Ward et al . [ 22 ] . Domingo Ferrer and Torra [ 5 ] , [ 6 ] proposed a microaggregation method based on the fuzzy ğ‘ means algorithm [ 1 ] , and Laszlo and Mukherjee [ 12 ] extended the standard minimum spanning tree partitioning algorithm for microaggregation [ 26 ] . All of these microaggregation methods build all clusters gradually but simultaneously . There are some other methods for microaggregation that have been proposed in the literature that build one/two cluster(s ) at a time . Notable examples include Maximum Distance [ 14 ] , Diameter based Fixed Size microaggregation and centroid based Fixed size microaggregation [ 12 ] , Maximum Distance to Average Vector ( MDAV ) [ 7 ] , MHM [ 8 ] and the Two Fixed Reference Points method [ 27 ] . Most recently , Lin et al . [ 28 ] proposed a densitybased microaggregation method that forms records by the descending order of their densities , and then fine tunes these clusters in reverse order .
The reminder of this paper is organized as follows . We introduce a problem of microaggregation in Section II . Section III introduces the basic concept of microaggregation . Section IV reviews previous microaggregation methods . We present a brief description of our proposed microaggregation method in Section V . Section VI shows experimental results of the proposed method . Finally , concluding remarks are included in Section VII .
II . PROBLEM STATEMENT
The algorithms for microaggregation works by partitioning the microdata into groups , where within groups the records are homogeneous but between groups the records are heterogeneous so that information loss is low . The similar groups are also called clusters . The level of privacy required is controlled by a security parameter ğ‘˜ , the minimum number of records in a cluster . In essence , the parameter ğ‘˜ specifies the maximum acceptable disclosure risk . Once a value for ğ‘˜ has been selected by the data protector , the only job left is to maximize data utility . Maximizing utility can be achieved by microaggregating optimally , ie with minimum within groups variability loss . So the main challenge in microaggregation is how to minimize the information loss during the clustering process . Although plenty of work has been done , to maximize the data utility by forming the clusters , this is not yet sufficient in terms of information loss . So more research needs to be done to form the clusters such that the information loss is as low as possible . This paper analyses the problem with a new pairwise approach such that the information loss is minimal .
Observing this challenge , this work presents a new clustering based method for microaggregation , where two distant clusters are made simultaneously in a systematic way . According to this method , sort all records in ascending order by using a sorting function so that the first record and the last record are most distant to each other . Form a cluster with the first record and its ( ğ‘˜ âˆ’ 1 ) nearest records and another cluster with the last record and its ( ğ‘˜ âˆ’ 1 ) nearest records . Sort the remaining records ( (ğ‘› âˆ’ 2ğ‘˜ ) , if dataset contains ğ‘› records ) by using the same sorting function and continue to build pair clusters at the same time by using the first and the last record as seeds until some specified records remain . Finally form one/two cluster(s ) depending on the remaining records . Thus all clusters produced in this way contain ğ‘˜ records except the last cluster that may contain at the most ( 2ğ‘˜ âˆ’ 1 ) records . Performance of the proposed method is compared against the most recent widely used microaggregation methods . The experimental results show that the proposed microaggregation method outperforms the recent methods in the literature in all test situations .
III . BACKGROUND
Microdata protection through microaggregation has been intensively studied in recent years . Many techniques and methods have been proposed to deal with this problem . In this section we describe some fundamental concepts of microaggregation .
When we microaggregate data we should keep in mind two goals : data utility and preserving privacy of individuals . For preserving the data utility we should introduce as little noise as possible into the data and preserving privacy data should be sufficiently modified in such a way that it is difficult for an adversary to reidentify the corresponding individuals . Figure 1 shows an example of microaggregated data where the individuals in each cluster are replaced by the corresponding cluster mean . The figure shows that after aggregating the chosen elements , it is impossible to distinguish them , so that the probability of linking any respondent is inversely proportional to the number of aggregated elements . Consider a microdata set ğ‘‡ with ğ‘ numeric attributes and ğ‘› records , where each record is represented as a vector in a ğ‘ dimensional space . For a given positive integer ğ‘˜ â‰¤ ğ‘› , a microaggregation method partitions ğ‘‡ into ğ‘” clusters , where each cluster contains at least ğ‘˜ records ( to satisfy ğ‘˜anonymity ) , and then replaces the records in each cluster with the centroid of the cluster . Let ğ‘›ğ‘– denote the number of records in the ğ‘–th cluster , and ğ‘¥ğ‘–ğ‘— , 1 â‰¤ ğ‘— â‰¤ ğ‘›ğ‘– , denote the ğ‘—th record in the ğ‘–th cluster . Then , ğ‘›ğ‘– â‰¥ ğ‘˜ for ğ‘– = 1 to ğ‘” , ğ‘–=1 ğ‘›ğ‘– = ğ‘› . The centroid of the ğ‘–th cluster , denoted and by Â¯ğ‘¥ğ‘– is calculated as the average vector of all the records in the ğ‘–th cluster .
âˆ‘ğ‘”
267
Micro aggregated Data constraint optimization problem as follows :
Original Data
Aggregating for k=3
45 2 42 31 51 5 22 26 6 25
46 11 mean mean mean
46 6 46 26 46 6 26 26 6 26 46 6
Definition 1 ( Microaggregation problem ) Given a dataset ğ‘‡ of ğ‘› elements and a positive integer ğ‘˜ , find a partitioning ğ‘® = {ğº1 , ğº2 , , ğºğ‘”} of ğ‘‡ such that
ğ‘–=1ğºğ‘– = ğ‘‡ ,
1 ) ğºğ‘– âˆ© ğºğ‘— = Î¦ , for all ğ‘– âˆ•= ğ‘— = 1 , 2 , , ğ‘ , 2 ) âˆªğ‘ 3 ) ğ‘†ğ‘†ğ¸ is minimized , 4 ) for all ğºğ‘– âˆˆ ğ‘‡ , âˆ£ ğºğ‘– âˆ£â‰¥ ğ‘˜ for any ğºğ‘– âˆˆ ğ‘® . The microaggregation problem stated above can be solved in polynomial time for a univariate dataset [ 11 ] but has been shown to be NP hard for multivariate dataset [ 13 ] . It is a natural expectation that ğ‘†ğ‘†ğ¸ is low if the number of clusters is large . Thus the number of records in each cluster should be kept close to ğ‘˜ . Domingo Ferrer and Mateo Sanz [ 3 ] showed that no cluster should contain more than ( 2ğ‘˜ âˆ’ 1 ) records since such clusters can always be partitioned to further reduce information loss .
IV . PREVIOUS MICROAGGREGATION METHODS
Previous microaggregation methods have been roughly divided into two categories , namely fixed size and dataoriented microaggregation [ 3 ] , [ 8 ] . For fixed size microaggregation , the partition is done by dividing a dataset into clusters that have size ğ‘˜ , except perhaps one cluster which has a size between ğ‘˜ and ( 2ğ‘˜ âˆ’ 1 ) , depending on the total number of records ğ‘› and the anonymity parameter ğ‘˜ . For the data oriented microaggregation , the partition is done by allowing all clusters with sizes between ğ‘˜ and ( 2ğ‘˜ âˆ’ 1 ) . Intuitively , fixed size methods reduce the search space , and thus are more computationally efficient than data oriented methods [ 28 ] . However , data oriented methods can adapt to different values of ğ‘˜ and various data distributions and thus may achieve lower information loss than fixed size methods . Domingo Ferrer and Mateo Sanz [ 3 ] proposed a multivariate fixed size microaggregation method , later called the Maximum Distance ( MD ) method [ 14 ] . The MD method repeatedly locates the two records that are most distant to each other , and forms two clusters with their respective ( ğ‘˜ âˆ’ 1 ) nearest records until fewer than 2ğ‘˜ records remain . If at least ğ‘˜ records remain , it then forms a new cluster with all remaining records . Finally when there are fewer than ğ‘˜ records not assigned to any cluster yet , this algorithm then individually assigns these records to their closest clusters . This method has a time complexity of ğ‘‚(ğ‘›3 ) and works well for most datasets . Laszlo and Mukherjee [ 12 ] modified the last step of the MD method such that each remaining record is added to its own nearest cluster and proposed Diameterbased Fixed size microaggregation . This method is however not a fixed size method because it allows more than one cluster to have more than ğ‘˜ records .
The MDAV method is the most widely used microaggregation method [ 14 ] . MDAV is the same as MD except in
Figure 1 . Example of Microaggregation using mean
In the same way , the centroid of ğ‘‡ , denoted by Â¯ğ‘¥ , is the average vector of all the records in ğ‘‡ . Information loss is used to quantify the amount of information of a dataset that is lost after applying a microaggregation method . In this paper we use the most common definition of information loss by Domingo Ferrer and Mateo Sanz [ 3 ] as follows :
ğ¼ğ¿ =
ğ‘†ğ‘†ğ¸ ğ‘†ğ‘†ğ‘‡
( 1 ) where ğ‘†ğ‘†ğ¸ is the within cluster squared error , calculated by summing the Euclidean distance of each record ğ‘¥ğ‘–ğ‘— to the average value Â¯ğ‘¥ğ‘– as follows :
ğ‘”âˆ‘
ğ‘›ğ‘–âˆ‘
( ğ‘¥ğ‘–ğ‘— âˆ’ Â¯ğ‘¥ğ‘– )
â€²
( ğ‘¥ğ‘–ğ‘— âˆ’ Â¯ğ‘¥ğ‘– )
ğ‘†ğ‘†ğ¸ =
( 2 )
ğ‘–=1
ğ‘—=1 and ğ‘†ğ‘†ğ‘‡ is the sum of squared error within the entire dataset ğ‘‡ , calculated by summing the Euclidean distance of each record ğ‘¥ğ‘–ğ‘— to the average value Â¯ğ‘¥ as follows : ( ğ‘¥ğ‘–ğ‘— âˆ’ Â¯ğ‘¥ )
( ğ‘¥ğ‘–ğ‘— âˆ’ Â¯ğ‘¥ )
ğ‘†ğ‘†ğ‘‡ =
â€²
ğ‘”âˆ‘
ğ‘›ğ‘–âˆ‘
( 3 )
ğ‘–=1
ğ‘—=1
For a given dataset ğ‘‡ , ğ‘†ğ‘†ğ‘‡ is fixed regardless of how ğ‘‡ is partitioned . On the other hand , SSE varies of a dataset depending on the partition of the dataset . In essence , SSE measures the similarity of the records in a cluster . The lower the SSE , the higher the within cluster homogeneity and the higher the SSE , the lower the within cluster homogeneity . If all the records in a cluster are the same , then the SSE is zero indicating no information is lost . On the other hand , if all the records in a cluster are more diverse , SSE is large indicating more information is lost . In this paper , we used SSE as a measure of similarity indicating a record will be included in a particular cluster if it causes least SSE among all other records in the dataset . Therefore , the microaggregation problem can be enumerated as a
268 the first step . MDAV finds the record ğ‘Ÿ that is furthest from the current centroid of the dataset and the record ğ‘  that is furthest from ğ‘Ÿ instead of finding the two records that are most distant to each other , as is done in MD . Then form a cluster with ğ‘Ÿ and its ( ğ‘˜ âˆ’ 1 ) nearest records and form another cluster with ğ‘  and its ( ğ‘˜ âˆ’ 1 ) nearest records . For the remaining records , repeat this process until fewer than 2ğ‘˜ records remain . If between ğ‘˜ and ( 2ğ‘˜âˆ’1 ) records remain , MDAV simply forms a new group with all of the remaining records . On the other hand , if the number of the remaining records is below ğ‘˜ , it adds all of the remaining records to their nearest clusters . So MDAV is a fixed size method . Lin et al . [ 28 ] proposed a modified MDAV , called MDAV 1 . The MDAV 1 is similar to MDAV except when the number of the remaining records is between ğ‘˜ and ( 2ğ‘˜ âˆ’ 1 ) , a new cluster is formed with the record that is the furthest from the centroid of the remaining records , and its ( ğ‘˜âˆ’ 1 ) nearest records . Any remaining records are then added to their respective nearest clusters . Experimental results indicate that MDAV 1 incurs slightly less information loss than MDAV [ 28 ] . Another variant of the MDAV method , called MDAVgeneric , is proposed by Domingo Ferrer and Torra [ 7 ] , where by the threshold 2ğ‘˜ is altered to 3ğ‘˜ . If between 2ğ‘˜ and ( 3ğ‘˜ âˆ’ 1 ) records remain , then find the record ğ‘Ÿ that is furthest from the centroid of the remaining records and form a cluster with ğ‘Ÿ and its ( ğ‘˜ âˆ’ 1 ) nearest records and another cluster with the remaining records . Finally when fewer than 2ğ‘˜ records remain , this algorithm then forms a new cluster with all the remaining records . Laszlo and Mukherjee [ 12 ] proposed another method , called Centroid based Fixed size microaggregation that is also based on a centroid but builds only one cluster during each iteration . This algorithm first find a record ğ‘Ÿ that is furthest from the current centroid of the dataset and then find a cluster with ğ‘Ÿ and its ( ğ‘˜ âˆ’ 1 ) nearest records . For the remaining records repeat the same process until fewer than ğ‘˜ records remain . Finally add each remaining record to its nearest clusters . This method is not a fixed size method as more than one cluster has more than ğ‘˜ records . Solanas et al . [ 15 ] proposed a variable size variant of MDAV , called V MDAV . V MDAV first builds a new cluster of ğ‘˜ records and then tries to extend this to up to ( 2ğ‘˜ âˆ’ 1)records based on some criteria . V MDAV adopts a user defined parameter to control the threshold of adding more records to a cluster . Chang et al . [ 27 ] proposed the Two Fixed Reference Points ( TFRP ) method to accelerate the clustering process of ğ‘˜ anonymization . During the first phase , TFRP selects two extreme points calculated from the dataset . Let ğ‘ğ‘šğ‘–ğ‘› and ğ‘ğ‘šğ‘ğ‘¥ be the minimum and maximum values over all attributes in the datasets , respectively , then one reference point ğº1 has ğ‘ğ‘šğ‘–ğ‘› as its value for all attributes , and another reference point ğº2 has ğ‘ğ‘šğ‘ğ‘¥ as its value for all attributes . A cluster of ğ‘˜ records is then formed with the record ğ‘Ÿ that is the furthest from ğº1 and the ( ğ‘˜âˆ’1 ) nearest records to ğ‘Ÿ . Similarly another cluster of ğ‘˜ records is formed with the record ğ‘  that is the furthest from ğº2 and ( ğ‘˜ âˆ’ 1 ) nearest records to ğ‘  . These two steps are repeated until fewer than ğ‘˜ records remain . Finally , these remaining records are assigned to their respective nearest clusters . This method is quite efficient as ğº1 and ğº2 are fixed throughout the iterations . When all clusters are generated , TFRP applies a enhancement step to determine whether a cluster should be retained or decomposed and added to other clusters .
Lin et al . [ 28 ] proposed a density based algorithm ( DBA ) for microaggregation . The DBA has two different scenarios . The first state of DBA ( DBA 1 ) repeatedly builds a new cluster using the ğ‘˜ neighborhood of the record with the highest ğ‘˜ density among all records that are not yet assigned to any cluster until fewer than ğ‘˜ unassigned records remain . These remaining records are then assigned to their respective nearest clusters . The DBA 1 partitions the dataset into some clusters , where each cluster contains no fewer than ğ‘˜ records . The second state of DBA ( DBA 2 ) attempts to fine tune all clusters by checking whether to decompose a cluster and merge its content with other clusters . Notably , all clusters are checked during the DBA 2 by the reverse of the order that they were added to clusters in the DBA 1 . After several clusters are removed and their records are added to their nearest clusters in the DBA 2 , some clusters may contain more than ( 2ğ‘˜ âˆ’ 1 ) records . At the end of the DBA 2 , the MDAV 1 algorithm is applied to each cluster with size above ( 2ğ‘˜ âˆ’ 1 ) to reduce the information loss . This state is finally called MDAV 2 . Experimental results show that the DBA attains a reasonable dominance over the latest microaggregation methods .
All of the microaggregation methods described above repeatedly choose one/ two records according to various heuristics and form one/two cluster(s ) with the chosen records and their respective ( ğ‘˜ âˆ’ 1 ) other records . However there are other microaggregation methods that build all clusters simultaneously and work by initially forming multiple clusters of records in the form of trees , where each tree represent a cluster . The multivariate ğ‘˜ Ward algorithm [ 3 ] first finds the two records that are furthest from each other in the dataset and build two clusters from these two records and their respective ( ğ‘˜ âˆ’ 1 ) nearest records . Each of the remaining record then forms its own cluster . These clusters are repeatedly merged until all clusters have at least ğ‘˜ records . Finally the algorithm is recursively applied to each cluster containing 2ğ‘˜ or more records . Domingo Ferrer et al . [ 9 ] proposed a multivariate microaggregation method called ğœ‡ Approx . This method first builds a forest and then decomposes the trees in the forest such that all trees have sizes between ğ‘˜ and max(2ğ‘˜ âˆ’ 1 , 3ğ‘˜ âˆ’ 5 ) . Finally , for any tree with size greater than ( 2ğ‘˜âˆ’ 1 ) , find the node in the tree that is furthest from the centroid of the tree . Form a cluster with this node and its ( ğ‘˜âˆ’ 1 ) nearest records in the tree and form another cluster with the remaining records in the tree . Hansen an Mukherjee [ 11 ] proposed a microaggrega
269 tion method for univariate datasets called HM . After that Domingo Ferrer et al . [ 8 ] proposed a multivariate version of the HM method , called MHM . This method first uses various heuristics , such as nearest point next ( NPN ) , maximum distance ( MD ) or MDAV to order the multivariate records . Steps similar to the HM method are then applied to generate clusters based on this ordering . Domingo Ferrer et al . [ 6 ] proposed a microaggregation method based on fuzzy ğ‘means algorithm ( FCM ) [ 1 ] . This method repeatedly runs FCM to adjust the two parameters of FCM ( one is the number of clusters ğ‘ and another is the exponent for the partition matrix ğ‘š ) until each cluster contains at least ğ‘˜ records . The value of ğ‘ is initially large ( and ğ‘š is small ) and is gradually reduced ( increased ) during the repeated FCM runs to reduce the size of each cluster . The same process is then recursively applied to those clusters with 2ğ‘˜ or more records .
V . THE PROPOSED APPROACH
This section presents the proposed pairwise systematic algorithm for microaggregation that minimizes the information loss and satisfies the ğ‘˜ anonymity requirement . The proposed approach builds and refines simultaneously two distant clusters at a time with the corresponding similar records together in a systematic way .
A . Sorting Function
According to the proposed approach , first sort all records with respect to the attributes , so it is necessary to define a sorting function to sort all the records in the dataset . Consider a microdata set ğ‘‡ with ğ‘ numeric attributes , namely ğ‘Œ1 , ğ‘Œ2 , , ğ‘Œğ‘ and ğ‘› records . Thus each record is represented as a vector in a ğ‘ dimensional space . To sort all the records with respect to the numeric attributes , we define the ğ‘—th sorted record in the dataset ğ‘‡ as follows :
ğ‘†ğ¹ğ‘— =
ğ‘âˆ‘
ğ‘–=1
( ğ‘¦ğ‘–ğ‘— âˆ’ Â¯ğ‘¦ğ‘– ) ,
ğ‘— = 1 , 2 , ğ‘› .
( 4 ) where , ğ‘¦ğ‘–ğ‘— is the ğ‘—th record of the ğ‘–th attribute and Â¯ğ‘¦ğ‘– is the centroid of the ğ‘–th attribute . The SF stated above measures the distance between the records and their corresponding centroid . In this study , the SF is arranged in ascending order indicating records are arranged in order of magnitude . The lower the values of SF , the more the records are below their respective centroid and the higher the values of SF , the more the records are above their respective centroid . Thus the records in the dataset ğ‘‡ , sorted in ascending order based on the SF and the first and the last record , are most distant among all other records in the dataset ğ‘‡ .
B . Pairwise Systematic microaggregation algorithm
Based on the information loss measure in equation ( 1 ) and the definition of the microaggregation problem , we are now ready to discuss the Pairwise Systematic ( P S ) microaggregation algorithm .
According to this method , first sort all records of ğ‘› in the dataset ğ‘‡ in ascending order by using the SF in equation ( 4 ) . Thus in the sorting dataset , the first record and the last record are the most distant to each other among all other pair records in the dataset ğ‘‡ . The algorithm ( see Fig 2 ) repeatedly builds pair clusters using the first record and the last record in the sorting dataset and their corresponding ( ğ‘˜ âˆ’ 1 ) nearest records until fewer than 3ğ‘˜ records remain ( see steps 2 6 of Fig 2 ) . The nearest records in a cluster are chosen in such a way that the inclusion of these records causes less SSE than the other records in the dataset . If between 2ğ‘˜ and ( 3ğ‘˜âˆ’1 ) records remain , then sort these records in ascending order by using the same sorting function in equation ( 4 ) and find the first record ğ‘“ . Form a cluster with ğ‘“ and its ( ğ‘˜ âˆ’ 1 ) nearest records , and another cluster with the remaining records ( see step 7 of Fig 2 ) . Moreover , if fewer than 2ğ‘˜ records remain , then form a new cluster with all remaining records ( see step 9 of Fig 2 ) .
The P S microaggregation algorithm stated above endeavor to repeatedly build two clusters simmultaneously in a systematic way . As the records in the dataset ğ‘‡ are arranged in ascending order and the first record and the last record are most distant to each other , building clusters in this systematic way , the algorithm easily captures if there are any extreme values in the dataset .
Definition 2 ( Systematic clustering based microaggregation decision problem ) In a given dataset ğ‘‡ of ğ‘› records , there is a clustering scheme ğ‘® = {ğº1 , ğº2 , , ğºğ‘”} such that 1 ) âˆ£ ğºğ‘– âˆ£â‰¥ ğ‘˜ , 1 < ğ‘˜ â‰¤ ğ‘› : the size of each cluster is
2 ) greater than or equal to a positive integer ğ‘˜ , and âˆ‘ğ‘” ğ‘–=1 ğ¼ğ¿(ğºğ‘– ) < ğ‘ , ğ‘ > 0 : the total information loss of the clustering scheme is less than a positive integer c . where each cluster ğºğ‘–(ğ‘– = 1 , 2 , , ğ‘ ) contains the records that are more similar to each other such that the cluster means are close to the values of the clusters and thus cause the least information loss .
VI . EXPERIMENTAL RESULTS
The objective of our experiment is to investigate the recital of our approach in terms of data quality . This section experimentally evaluates the P S microaggregation algorithm . The following three datasets [ 8 ] , which have been used as benchmarks in previous studies to evaluate various microaggregation methods , were adopted in our experiments . the effectiveness of
1 ) The â€œ Tarragona â€ dataset contains 834 records with 13 numerical attributes .
2 ) The â€œ Census â€ dataset contains 1,080 records with 13 numerical attributes .
270
Figure 2 . P S microaggregation algorithm
3 ) The â€œ EIA â€ dataset contains 4,092 records with 11 numeric attributes ( plus two additional categorical attributes not used here ) .
To accurately evaluate our approach , the performance of the proposed P S microaggregation algorithm is compared in this section with various microaggregation methods . Tables I III show the information losses of these microaggregation methods . The lowest information loss for each dataset and each ğ‘˜ value is shown in bold face . The information losses of methods DBA 1 , DBA 2 , MDAV 1 and MDAV 2 are quoted from [ 28 ] ; the information losses of methods MDAVMHM , MD MHM , CBFS MHM , NPN MHM and M d ( for ğ‘˜ = 3 , 5 , 10 ) are quoted from [ 8 ] ; the information losses of methods ğœ‡ Approx and M d ( for ğ‘˜ = 4 ) are quoted from [ 9 ] , and the information losses of methods TFRP 1 and TFRP 2 are quoted from [ 27 ] . TFRP is a two stage method and its two stages are denoted as TRFP 1 and TRFP 2 respectively . The TFRP 2 is similar to the DBA 2 but disallows merging a record to a group of size over ( 4ğ‘˜ âˆ’ 1 ) .
Tables I III show the information loss for several values of ğ‘˜ and the Tarragona , Census and for the EIA datasets respectively . The information loss is compared with the P S microaggregation algorithm among the latest microaggregation methods listed above . Information loss is measured as Ã—100 , where SST is the total sum of the squares of SSE SST the dataset . Note that the within groups sum of squares SSE is never greater than SST so that the reported information loss measure takes values in the range [ 0,100 ] . Tables I III illustrate that in all of the test situations , the P S microaggregation algorithm causes significantly less information loss than any of the microaggregation methods listed in the table . Essentially , the P S microaggregation algorithm causes less than 50 % information loss compared to any of the previous methods listed above and for any of the datasets . This shows the utility and the effectiveness of the proposed algorithm .
VII . CONCLUSION
Microaggregation is an effective method in SDC of protecting privacy in microdata and has been extensively used world wide . The level of privacy required is controlled by a parameter ğ‘˜ , often called anonymity parameter for ğ‘˜anonymization that is basically the minimum number of records in a cluster . Once the value of ğ‘˜ has been chosen , the data protector and the data users are interested in minimizing the information loss . This work has presented a new Pairwise Systematic ( P S ) microaggregation method for numerical attributes . The new method consists of pairwise clustering individual records in microdata in a number of disjointed clusters in a systematic way , using a sorting function prior publication and then publishing the mean over each cluster instead of individual records . A comparison has been made of the proposed algorithm with the most widely used microaggregation methods through experimenting with the three benchmark datasets ( Tarragona , Census and the EIA ) . The experimental results show that the proposed
271
INFORMATION LOSS COMPARISON USING TARRAGONA DATASET
Table I
ğ‘˜ = 3 16.9326 16.9829 16.9714 17.3949 16.6300
17.10 17.228 16.881
16.93258762 16.38261429 20.69948803 16.15265063 5.494040549
ğ‘˜ = 4
19.66 20.51 19.396 19.181
19.54578612 19.01314997 23.82761456 22.67107728 8.329209112
Table II
ğ‘˜ = 5 22.4617 22.5269 22.8227 27.0213 24.5000
26.04 22.110 21.847
ğ‘˜ = 10 33.1923 33.1834 33.2188 40.1831 38.5800
38.80 33.186 33.088
22.46128236 22.07965363 26.00129826 25.45039236 10.8749404
33.19235838 33.17932950 35.39295837 34.80675148 17.01194228
INFORMATION LOSS COMPARISON USING CENSUS DATASET
ğ‘˜ = 3 5.6523 5.69724 5.6734 6.3498 6.1100
6.25 5.931 5.803
5.692186279 5.656049371 6.144855154 5.581605762 1.782851535
ğ‘˜ = 4
8.24 8.47 7.880 7.638
7.494699833 7.409645342 9.127883805 7.591307664 2.54581108
Table III
ğ‘˜ = 5 9.0870 8.98594 8.8942 11.3443 10.3000
10.78 9.357 8.980
ğ‘˜ = 10 14.2239 14.3965 13.8925 18.7335 17.1700
17.01 14.442 13.959
9.088435498 9.012389597 10.84218735 9.046162117 2.698883298
14.15593043 13.94411775 15.78549732 13.52140518 4.967556756
INFORMATION LOSS COMPARISON USING EIA DATASET
ğ‘˜ = 3 0.4081 0.4422 0.5525
0.43 0.530 0.428
ğ‘˜ = 4
0.59 0.661 0.599
ğ‘˜ = 5 1.2563 1.2627 0.9602
0.83 1.651 0.910
ğ‘˜ = 10 3.7725 3.6374 2.3188
2.26 3.242 2.590
0.482938725 0.411101515 1.090194828 0.421048322 0.213174523
0.671345141 0.587381756 0.84346907 0.559755523 0.32351185
1.666657361 0.946263963 1.895536919 0.81849828 0.435562877
3.83966422 3.16085577 4.265801303 2.080980825 1.044292097
Method
MDAV MHM
MD MHM CBFS MHM NPN MHM
M d
ğœ‡ Approx TFRP 1 TFRP 2 MDAV 1 MDAV 2 DBA 1 DBA 2
P S
Method
MDAV MHM
MD MHM CBFS MHM NPN MHM
M d
ğœ‡ Approx TFRP 1 TFRP 2 MDAV 1 MDAV 2 DBA 1 DBA 2
P S
Method
MDAV MHM
MD MHM NPN MHM ğœ‡ Approx TFRP 1 TFRP 2 MDAV 1 MDAV 2 DBA 1 DBA 2
P S algorithm has a significant dominance over the recent microaggregation methods with respect to information loss . Thus the proposed method is very effective in preserving the privacy of respondentsâ€™ contribution to microdata sets and can be used as a microaggregation method in SDC .
REFERENCES
[ 1 ] JC Bezdek , Pattern recognition with fuzzy objective function algorithms . Norwell , MA : Academic Publishers , 1981 .
[ 2 ] J . Domingo Ferrer and V . Torra , â€œ Privacy in data mining , â€ Data Mining and Knowledge Discovery , vol . 11 , no . 2 , pp . 117â€“119 , 2005 .
[ 3 ] J . Domingo Ferrer and J . Mateo Sanz , â€œ Practical data oriented microaggregation for statistical disclosure control , â€ IEEE Transactions on Knowledge and Data Engineering , vol . 14 , no . 1 , pp . 189 201 , 2002 .
[ 4 ] J . Domingo Ferrer and V . Torra , â€œ Extending microaggregation procedures using defuzzification methods for categorical variables , â€ in Proc . 1st international IEEE symposium on intelligent systems , Verna , Sept . 2002 , pp . 44â€“49 .
[ 5 ] J . Domingo Ferrer and V . Torra , â€œ Towards fuzzy ğ‘ means based microaggregation , â€ in Soft methods in probability , statistics and data analysis , P . Grzegorzewski , O . Hryniewicz and MA Gil , Eds . Heidelberg : Physica Verlag , 2002 , Advances in soft computing , vol . 16 , pp . 289 294 .
272
[ 6 ] J . Domingo Ferrer and V . Torra , â€œ Fuzzy microaggregation for microdata protection , â€ Journal of Advanced Computational Intelligence and Intelligent Informatics , vol . 7 , no . 2 , pp . 153159 , 2003 .
[ 7 ] J . Domingo Ferrer and V . Torra , â€œ Ordinal , continuous and heterogeneous kanonymity through microaggregation , â€ Data Mining and Knowledge Discovery , vol . 11 , no . 2 , pp . 195 212 , 2005 .
[ 8 ] J . Domingo Ferrer , A . Martinez Balleste , JM Mateo Sanz and F . Sebe , â€œ Efficient multivariate data oriented microaggregation , â€ The VLDB Journal , vol . 15 , no . 4 , pp . 355 369 , 2006 .
[ 17 ] L . Sweeney , â€œ ğ‘˜ Anonymity : A model for protecting privacy , â€ International Journal on Uncertainty , Fuzziness and Knowledge based Systems , vol . 10 , no . 5 , pp . 557 570 , 2002 .
[ 18 ] V . Torra , â€œ Microaggregation for categorical variables : A median based approach , â€ in PSD 2004 , J Domingo Ferrer and V . Torra , Eds . Heidelberg : Springer , 2004 , LNCS , vol . 3050 , pp . 162 174 .
[ 19 ] ME Kabir and H . Wang , â€œ Systematic Clustering based Microaggregation for Statistical Disclosure Control , â€ in Proc . IEEE International Conference on Network and System Security , Melbourne , Sep . 2010 , pp . 435 441 .
[ 9 ] J . Domingo Ferrer , F . Sebe and A . Solanas , â€œ A polynomialtime approximation to optimal multivariate microaggregation , â€ Computer and Mathematics with Applications , vol . 55 , no . 4 , pp . 714 732 , 2008 .
[ 20 ] ME Kabir , H . Wang , E . Bertino and Y . Chi , â€œ Systematic Clustering Method for ğ‘™ diversity Model , â€ in Proc . Australasian Database Conference , Brisbane , Jan . 2010 , pp . 93102 .
[ 10 ] J M Han , T, T Cen , H Q Yu and J . Yu , â€œ A multivariate immune clonal selection microaggregation algorithm , â€ in Proc . IEEE international conference on granular computing , Hangzhou , Feb . 2008 , pp . 252 256 .
[ 11 ] S . Hansen and S . Mukherjee , â€œ A polynomial algorithm for optimal univariate microaggregation , â€ IEEE Transactions on Knowledge and Data Engineering , vol . 15 , no . 4 , pp . 10431044 , 2003 .
[ 12 ] M . Laszlo and S . Mukherjee , â€œ Minimum spanning tree partitioning algorithm for microaggregation , â€ IEEE Transactions on Knowledge and Data Engineering , vol . 17 , no . 7 , pp . 902 911 , 2005 .
[ 13 ] A . Oganian and J . Domingo Ferrer , â€œ On the complexity of optimal microaggregation for statistical disclosure control , â€ Statistical Journal of the United Nations Economic Commission for Europe , vol.18 , 345 354 , 2001 .
[ 21 ] ME Kabir and H . Wang , â€œ Microdata Protection Method Through Microaggragation : A Median Based Approach , â€ Information Security Journal : A Global Perspective , ( in Press ) .
[ 22 ] JHJ Ward , â€œ Hierarchical grouping to optimize an objective function , â€ Journal of the American Statistical Association , vol . 58 , no . 301 , pp . 236 244 , 1963 .
[ 23 ] H . Wang , Y . Zhang and J . Cao , â€œ Effective collaboration with information sharing in virtual universities , â€ IEEE Transactions on Knowledge and Data Engineering , vol . 21 , no . 6 , pp . 840â€“ 853 , 2009 .
[ 24 ] X . Sun , H . Wang and L . Sun , â€œ Extended ğ¾ Anonymity Models Against Attribute Disclosure , â€ Computer Communication , ( in Press ) .
[ 25 ] L . Willenborg and TD Waal , â€œ Elements of statistical disclo sure control , â€ Lecture notes in statistics , vol . 155 , 2001 .
[ 14 ] A . Solanas , â€œ Privacy protection with genetic algorithms , â€ in Success in evolutionary computation , A . Yang , Y . Shan and LT Bui , Eds . Heidelberg : Springer , 2008 , Studies in Computional Intelligence , vol . 92 , pp . 215 237 .
[ 15 ] A . Solanas , A . Martinez Balleste and J . Domingo Ferrer , â€œ ğ‘‰ âˆ’ ğ‘€ ğ·ğ´ğ‘‰ : A multivariate microaggregation with variable group size , â€ in Proc . 17th COMPSTAT Symposium of the IASC , Rome , Aug . 2006 .
[ 16 ] P . Samarati , â€œ Protecting respondent â€™s privacy in microdata release , â€ IEEE Transactions on Knowledge and Data Engineering , vol . 13 , no . 6 , pp . 1010â€“1027 , 2001 .
[ 26 ] CT Zahn , â€œ Graph theoretical methods for detecting and describing gestalt clusters , â€ IEEE Transactions on Computers , vol . ğ¶ 20 , no . 1 , pp . 68 86 , 1971 .
[ 27 ] C C Chang , Y C Li and W H Huang , â€œ TFRP : An efficient microaggregation algorithm for statistical disclosure control , â€ Journal of Systems and Software , vol . 80 , no . 11 , pp . 1866â€“ 1878 , 2007 .
[ 28 ] J L Lin , T H Wen , J C Hsieh and P C Chang , â€œ Densitybased microaggregation for statistical disclosure control , â€ Expert Systems with Applications , vol . 37 , no . 4 , pp . 3256â€“3263 , 2010 .
273
