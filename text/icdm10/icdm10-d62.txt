2010 IEEE International Conference on Data Mining
Exploiting Local Data Uncertainty to Boost Global Outlier Detection
Bo Liu∗ , Jie Yin† , Yanshan Xiao∗ , Longbing Cao∗ and Philip S . Yu‡
∗Faculty of Engineering and IT , QCIS
Email : csbliu@gmail.com , syxiao@itutseduau , lbcao@itutseduau
University of Technology , Sydney †Information Engineering Laboratory
CSIRO ICT Centre , Australia
Email : JieYin@csiroau
‡Department of Computer Science University of Illinois at Chicago
851 S . Morgan Street , Chicago , IL 60607 0753
Email : psyu@csuicedu
Abstract—This paper presents a novel hybrid approach to outlier detection by incorporating local data uncertainty into the construction of a global classifier . To deal with local data uncertainty , we introduce a confidence value to each data example in the training data , which measures the strength of the corresponding class label . Our proposed method works in two steps . Firstly , we generate a pseudo training dataset by computing a confidence value of each input example on its class label . We present two different mechanisms : kernel kmeans clustering algorithm and kernel LOF based algorithm , to compute the confidence values based on the local data behavior . Secondly , we construct a global classifier for outlier detection by generalizing the SVDD based learning framework to incorporate both positive and negative examples as well as their associated confidence values . By integrating local and global outlier detection , our proposed method explicitly handles the uncertainty of the input data and enhances the ability of SVDD in reducing the sensitivity to noise . Extensive experiments on real life datasets demonstrate that our proposed method can achieve a better tradeoff between detection rate and false alarm rate as compared to four state of the art outlier detection algorithms .
Keywords Outlier detection ; Data uncertainty ; SVDD
I . INTRODUCTION
Outlier detection has attracted increasing attention in machine learning and data mining areas due to its wideranging applications from machine fault detection , credit card fraud detection , network intrusion to medical diagnosis . Outliers refer to the data objects that are markedly different from or inconsistent with the remaining set of data [ 8 ] , [ 13 ] . Traditional outlier detection algorithms typically assume that outliers are difficult or costly to obtain due to their rare occurrences in real world applications . Therefore , most of previous approaches mainly focus on modelling a representation of the normal data so as to identify outliers that do not fit the model well .
Depending on the nature of representation models , previous approaches to outlier detection can be classified into four broad categories : ( 1 ) distribution based approaches [ 4 ] ,
1550 4786/10 $26.00 © 2010 IEEE DOI 101109/ICDM201010
304 in which a pre specified probability distribution is usually used to model the normal data and then a statistical test is applied to detect if a data point is an outlier ; ( 2 ) densitybased approaches [ 3 ] , [ 6 ] , [ 12 ] , in which local outliers are identified by examining the distances to their nearest neighbors ; ( 3 ) clustering based approaches [ 14 ] , which find outliers as by product of a clustering algorithm ; ( 4 ) modelbased approaches [ 18 ] , which typically use a predictive model to characterize the normal data and detect outliers as deviations from the model . In this category , the support vector data description ( SVDD ) proposed by Tax and Duin [ 25 ] , [ 26 ] has been demonstrated to be capable of detecting outliers in various application domains .
Despite much progress in this area , most of the existing works on outlier detection have not explicitly dealt with the uncertainty of the input data . An underlying assumption is that the training dataset is perfectly labeled for building outlier detection models or classifiers . However , in many realworld applications , the data may be corrupted with noise or may only be partially complete [ 2 ] , [ 5 ] . For example , sensor networks typically generate a large amount of uncertain data subject to sampling errors or instrument imperfections . Thus , a normal example may behave like an outlier , even though the example itself may not be an outlier . Such uncertain information might introduce labeling imperfections or errors into the training data , which further limits the accuracy of subsequent outlier detection . Moreover , another important observation is that , negative examples or outliers , although very few , do exist in many applications . For example , in the network intrusion domain , in addition to extensive data about the normal traffic conditions in the network , there also exist a small number of cyber attacks that can be collected to facilitate outlier detection . Although these outliers are not sufficient for constructing a binary classifier , they can be incorporated into the training process to refine the decision boundary around the normal data for outlier detection .
In this paper , we address the problem of outlier detection with very few labeled negative examples . In order to cope with data uncertainty , we propose a novel hybrid approach to outlier detection by generalizing the SVDD learning framework on imperfectly labeled training dataset . Specifically , we associate each example in the training dataset not only with a class label but also a confidence value which measures the strength of the corresponding label . Our proposed approach works in two steps . In the first step , we generate a pseudo training dataset by computing a confidence value of each input example on its class label based on the local data behavior . Two different mechanisms are proposed to generate the confidence values : kernel k means clustering methods and kernel LOF based method . In the second step , we construct a global classifier for outlier detection by generalizing the SVDD based learning process . Associated with a confidence value , each data point can have different contributions to the learning of the decision boundary . By integrating local and global outlier detection , our proposed method explicitly handles the uncertainty of the input data and enables the ability of SVDD in reducing the sensitivity to noise . Extensive experiments on real life datasets show that our proposed method can offer a better tradeoff between detection rate and false alarm rate as compared to three stateof the art outlier detection algorithms .
The rest of the paper is organized as follows . Section II discusses previous works related to our outlier detection problem . Section III presents our proposed method to outlier detection in detail . Section IV reports extensive experimental results on real world datasets . Section V concludes the paper and discusses possible directions for future work .
II . RELATED WORK
In this section , we discuss previous work related to our outlier detection problem in three parts . In Section II A , we first review previous work on outlier detection in the data mining area . In Section II B , we discuss another branch of related work on learning from imbalanced data and costsensitive learning . Finally , in Section II C , we give a brief description of support vector data description .
A . Outlier Detection
Outlier detection techniques can be classified into four categories : distribution based approaches [ 10 ] , density based approaches [ 6 ] , [ 12 ] , clustering based approaches [ 14 ] , [ 22 ] and model based approaches [ 8 ] . Distribution based approaches [ 10 ] are the earliest algorithms developed for outlier detection , which fit a statistical model ( eg Normal , Poisson , Gaussian , etc . ) to the normal data and then apply a statistical test to determine if an unseen data point belongs to this model or not . Points that have low probability of belonging to the learned model are detected as outliers . The key disadvantage of distribution based approaches is that they rely on the assumption that the data is generated from a particular distribution . However , this assumption often does
305
For density based approaches [ 6 ] , [ 12 ] , the main task is to define pairwise distances between data points and identify outliers by examining the distance or relative density of each data point to its local neighbors . Representative methods include LOF ( Local Outlier Factor ) [ 6 ] and its variants , which assign an outlier score to any given data point , depending on its distances in the local neighborhood . The advantage of these approaches is that they do not make any assumption for the generative distribution of the data . However , these approaches incur a high computational complexity in the testing phase , since they involve calculating the distance between each test instance and all the other instances to compute nearest neighbors .
Clustering based approaches [ 14 ] , [ 22 ] mainly rely on applying clustering techniques to characterize the local data behavior . As a by product of clustering , small clusters that contain significantly less data points than other clusters are considered as outliers . Clustering based approaches are unsupervised in nature without requiring any labeled training data . However , the performance of unsupervised outlier detection is limited .
Model based approaches [ 15 ] typically characterize the normal data via a predictive model and detect outliers as deviations from the learned model . Among others , support vector data description ( SVDD ) [ 25 ] , [ 26 ] has been demonstrated empirically to be capable of detecting outliers in various domains . The most attractive feature of SVDD is that it can transform the original data into a feature space and detect global outliers more effectively for high dimensional data . However , its performance is sensitive to the noise involved in the input data . not hold true in practice , especially for high dimensional real data sets .
Depending on the availability of a training dataset , outlier detection techniques described above operate in two different modes : supervised and unsupervised . Distribution based approaches and model based approaches fall into the category of supervised outlier detection , which assumes the availability of a training dataset that has labeled instances for normal class ( as well as anomaly class sometimes ) . For supervised outlier detection , obtaining accurate and representative labels for the training dataset , especially for the anomaly class is usually very challenging . Several techniques [ 1 ] , [ 23 ] , [ 27 ] have been proposed that inject artificial anomalies into a normal dataset to obtain a labeled training data set . In addition , the work of [ 24 ] presents a new method to detect outliers by utilizing the instability of the output of a classifier built on bootstrapped training data .
The method we propose in this work is a hybrid approach to outlier detection , which captures local data uncertainty by generating the confidence of each input example on its class label based on the local neighborhood . Such information is then incorporated into the generalized SVDD framework to enhance a global classifier for outlier detection .
B . Difference from Imbalanced Data Classification
The outlier detection problem that we consider in this paper is also related to the problem of imbalanced data classification [ 9 ] , in which outliers corresponding to the negative class are extremely small in proportion as compared to the normal data corresponding to the positive class .
Research on imbalanced data classification falls into two main categories . The first category attempts to modify the class distribution of training data before applying any learning algorithms [ 7 ] . This is usually done by oversampling , which replicates the data in the minority class , or under sampling , which throws away part of the data in the majority class . The second category focuses on making a particular classifier learner cost sensitive , by setting the false positive and false negative costs very differently and incorporating the cost factors into the learning process [ 9 ] . Representative methods include cost sensitive decision trees [ 16 ] and cost sensitive SVMs [ 11 ] , [ 19 ] . When imbalanced data are present , researchers have argued for the use of ranking based metrics , such as the ROC curve and the area under ROC curve ( AUC ) [ 20 ] instead of using accuracy .
The difference between imbalanced data classification and our outlier detection problem is that : in imbalanced data classification , the examples from one or more minority classes are often self similar , potentially forming compact clusters , while in outlier detection , the outliers are typically scattered so that the distribution of the negative class cannot be well represented by the very few negative training examples . To solve our problem , we can exploit cost sensitive learning algorithms , but the false positive and false negative costs are usually unknown to us in real life applications . Therefore , we exploit a novel one class classification method for outlier detection , which aims at building a decision boundary around the normal data , and utilize the few negative examples to refine the boundary .
C . Support Vector Data Description
The Support Vector Data Description ( SVDD ) [ 25 ] is one of the best known support vector learning methods for oneclass classification . Given a set of target data {xi} , i = 1 , . . . , l , where xi ∈ Rm , the basic idea is to find a sphere that contains most of target data such that its corresponding radius R is minimized : min st l . i=1
F ( R , o , ξi ) = R2 + C fi xi − o fi2 ≤ R2 + ξi , ξi ≥ 0 ,
ξi ,
( 1 ) where slack variables ξi are introduced to allow some data points to lie outside the sphere , and C > 0 controls the tradeoff between the volume of the sphere and the number of i=1 ξi means the penalty for misclassified patterns . errors . fil
306
O r i g i n a l b o u n a d r y
R e f i n e d b o u n a d r y
Figure 1 . Motivation behind our proposed approach
αi(xi · xi ) − l . . i=1 i=1
0 ≤ αi ≤ C , k=1
By introducing Lagrange multipliers , the above optimiza tion problem is transformed into the dual formulation : αiαk(xi · xk ) l . l . max i st
αi = 1 .
( 2 ) The solution of Equation ( 2 ) gives a set of {αi} . Data points with αi > 0 are called the support vectors of the description . For a test point x , the distance to the center of the sphere is calculated as : fi x − o fi2 = ( x · x ) − 2 i αi(xi · x ) + fi i,j αiαj(xi · xj ) . The point x is classified as normal data when this distance is less than or equal to the radius R . Otherwise , it is flagged as an outlier . fi
To allow a more flexible description , the original data points are typically mapped into a feature space via a nonlinear mapping function φ(· ) . The mapping is performed implicitly by replacing the inner products ( ·,· ) in Equation ( 2 ) by a kernel function K(x , xi ) = φ(x ) · φ(xi ) . The most attractive feature of SVDD is that it can transform the input data into a feature space and detect global outliers effectively for high dimensional data . However , its performance is sensitive to the noise involved in the input data . Our proposed method generalizes SVDD to incorporate the confidence of class labels into the training process , which mitigates the effect of noise on outlier detection .
III . OUR PROPOSED ALGORITHM
In this section , we provide a detailed description about our proposed approach to outlier detection . Given a set of training data D which consists of l normal examples and a small amount of n outlier ( or abnormal ) examples , the objective is to build a classifier using both normal and abnormal training data and the classifier is thereafter applied to classify unseen test data . However , subject to sampling errors or device imperfections , an normal example may behave like an outlier , even though the example itself may not be an outlier . Such error factors might result in an imperfectly labeled training data , based on which the subsequent outlier detection becomes grossly inaccurate .
To deal with label imperfections , we propose to associate each input data with a confidence value , which indicates the likelihood of an input data belonging to its corresponding class label . Such information is thereafter incorporated into the construction of a global classifier for outlier detection . The motivation behind our proposed method is illustrated in Figure 1 . In the figure , positive examples are depicted as circles and negative examples squares . The size of the circles/squares indicates their associated confidence values . Intuitively , the higher confidence we have on a label , the larger force we want to have on that sample towards the decision boundary . The dashed line is the original decision boundary derived from the standard SVDD training , and the solid line is the refined decision boundary after taking labels’ confidence values into consideration .
Based on this idea , our proposed method works in two steps as follows :
• In the first step , we generate a pseudo training dataset by computing a confidence value for each input data on its class label based on local data behavior .
• In the second step , we construct a global SVDD based classifier for outlier detection by using both normal and abnormal examples as well as the confidence values associated with their class labels .
In the following , we describe the two steps in detail .
A . Computing Confidence on the Class Labels
The main task of this step is to create a pseudo training dataset by computing a confidence value for each input data on its class label . The generated pseudo training data consists of two parts : ( x1 , mT ( x1) ) , . . . , ( xl , mT ( xl ) ) for l normal examples and ( xl+1 , mN ( xl+1) ) , . . . , ( xl+n , mN ( xl+n ) ) for n abnormal examples , were mT ( x1 ) and mN ( xj ) indicate the likelihood of example x belonging to the the normal class and the outlier class , respectively .
We propose two different schemes to compute a confidence value for each input data , inspired by clustering based and density based approaches to outlier detection . The basic idea is to capture the local data uncertainty by examining the relative distances of each input data to its local neighbors . 1 ) Kernel K Means Clustering Method : We adopt the kernel k means clustering algorithm to generate a confidence value for each input data . Based on a nonlinear mapping function φ : x → φ(x ) , kernel k means clustering minimizes the following objective function :
J = k . l+n . i=1 j=1 fiφ(xj ) − φ(vi)fi2 ,
( 3 ) where k is the number of clusters and vi is the cluster center of the ith cluster .
By solving this optimization problem , k means clustering returns a set of local clusters , in which data points belonging to a same cluster are more similar to each other . Intuitively , for a data point , if most of data point in the same cluster are normal , it would have a high probability of being normal , and if there is an outlying point that doe not belong to any cluster , it would have a high probability of being an outlier . Therefore , we calculate the confidence values as follows . For a given cluster j , assume there exist lp j normal examples and ln j negative examples . The confidence value of a normal example belonging to the normal class is calculated as mT ( xt ) = lp j . Similarly , the confidence value of an abnormal example belonging to the negative class is computed as mN ( xn ) = ln j + ln j + ln j . j /lp j /lp
The advantage of kernel k means is that it can partition the dataset into a set of local clusters that are non linearly separable in the input space . However , the main limitation is that it does not work well on datasets with varying densities by using a global distance function , which causes the generated confidence values to be inaccurate .
2 ) Kernel LOF based Method : To cope with datasets with varying densities , we propose a local density based method to compute a confidence value for each input data . Inspired by the LOF algorithm [ 6 ] , the basic idea is to examine the relative distance of a point to its local neighbors . Specifically , we extend the original LOF into the kernel space by using kernel methods and generate the confidence values in the kernel space instead of the input space .
For each point xi , we first compute its local reachability density , which is the average reachability distance based on the k nearest neighbors of xi . . reach listk(xi , xj ) ,
( 4 ) lrdk(xi ) =
1 k xj∈Nk(xi ) where Nk(xi ) is a set of k nearest neighbors of point xi . Here , reach listk(xi , xj ) denotes the reachability distance of object xi with respect to object xj in the feature space . It is computed as the larger value between A and B , where A is the actual distance between xj and xi , and B is the distance between xi and its kth nearest neighbor . Interested readers please refer to [ 6 ] for detailed definitions .
After the local reachability density lrdk(xi ) is computed , for the point xi , we find its lrd neighborhood Nlrd(xi ) = {xj ∈ D | fiφ(xi ) − φ(xj)fi2 ≤ lrdk(xi)} . The distance between xi and xj in the feature space is computed as fiφ(xi)−φ(xj)fi2 = K(xi , xi)+K(xj , xj)−2K(xi , xj ) . ( 5 ) For a positive sample , suppose that there exist lt examples out of |Nlrd(xi)| nearest neighbors belonging to the positive class . The confidence value of xt towards positive class is defined as mT ( xt ) = lt/|Nlrd(xi)| , where |Nlrd(xi)| denotes the number of nearest neighbors in the lrd neighborhood . Similarly , for a negative example , assume there exist ln examples out of |Nlrd(xi)| nearest neighbors belonging to the negative class , The confidence value of xn towards negative class in feature space is given as mN ( xn ) = ln/|Nlrd(xi)| .
307 st l+n . j=l+1 mN ( xj)ξj
B . Constructing Soft SVDD Classifiers
After generating a pseudo training dataset , the next step is to build a global SVDD based classifier for outlier detection . Below , we give a new formulation of SVDD by using both normal and abnormal data as well as the associated confidence on the class labels .
1 ) Primal Formulation : Since the membership functions mT ( xi ) and mN ( xj ) indicate the degree of the belongingness of data example xi toward target class and negative class , the solution to soft SVDD can be achieved by solving the following optimization problem : min st mT ( xi)ξi + C2 l . i=1
F = R2 + C1 fi xi − o fi2 ≤ R2 + ξi , fi xj − o fi2 ≥ R2 − ξj , ξi ≥ 0 , ξj ≥ 0 ,
( 6 )
Above , Parameters C1 and C2 control the tradeoff between the sphere volume and the errors . Parameters ξi are ξj are defined as a measure of error , as in SVDD . The terms mT ( xi)ξi and mN ( xj)ξj can be therefore considered as a measure of error with different weighing factors . Note that a smaller value of mT ( xi ) could reduce the effect of the parameter ξi in Equation ( 6 ) , such that the corresponding data example xi becomes less significant in the training .
2 ) Dual Problem : To solve the above optimization probj ≥ 0 , lem , we introduce Lagrange multipliers αT j ≥ 0 , and convert problem ( 6 ) into problem ( 7 ) . i ≥ 0 , βN βT i ≥ 0 , αN
L = R2 + C1 l . l+n . i=1 j=l+1 mT ( xi)ξi + C2 mN ( xj)ξj i ( R2 + ξi − fi Φ(xi ) − o fi2 ) − l+n . i ξi − l+n . j ( fi Φ(xj ) − o fi2 − R2 − ξj ) . αN
βN j ξj j=l+1
αT
βT j=l+1
−
− l . i=1 l . i=1
( 7 ) Setting the partial derivatives of L with respect to R , o , ξi , ξj equal to zeros respectively , we can obtain
= 0 −→ l . i − l+n .
αT
αN j = 1 , i=1 j=l+1
= 0 −→ l . i ( o − Φ(xi ) ) = αT i=1 l+n . j=l+1 j ( o − Φ(xj) ) , αN
= 0 −→ αT = 0 −→ αN i + βT i = C1mT ( xi ) , j + βN j = C2mN ( xj ) .
∂L ∂R
∂L ∂o ∂L ∂ξi ∂L ∂ξj
Replacing these into Equation ( 7 ) , we get the following dual formulation : l . max
αT i K(xi , xi ) + 2 l . l+n . i=1 j=l+1
αT i αN j K(xi , xj ) l . k=1
αT i αT k K(xi , xk ) i=1
− l+n . j=l+1 j=l+1
− l+n . 0 ≤ αT 0 ≤ αN l .
αT
αN j K(xj , xj ) − l . l+n . i=1 v K(xj , xv ) v=l+1
αN j αN i ≤ C1mT ( xi ) , j ≤ C2mN ( xj ) , i − l+n .
αN j = 1 .
( 8 ) i=1 j=l+1 i ( i = 1 , 2 , . . . , l ) , αi = αN
By setting αi = αT i ( i = l + 1 , l + 2 , . . . , l + n ) , Ci = C1mT ( xi)(i = 1 , 2 , . . . , l ) and Ci = C2mN ( xi)(i = l +1 , l +2 , . . . , l +n ) , the optimization Problem ( 8 ) is rewritten as follows : max st l+n .
αiK(xi , xi ) − l+n . l+n .
αiαjK(xi , xj ) ( 9 ) i=1 j=1 i = 1 , 2 , . . . , l + n , i=1
0 ≤ αi ≤ Ci l+n .
αi = 1 . i=1
After solving the above dual problem , we obtain the Lagrange multipliers αi(1 ≤ i ≤ l + n ) , which give the centroid of the minimum sphere as a linear combination of xi : l+n . o =
αiΦ(xi ) .
( 10 ) Above , we find only the patterns with αi = 0 construct the centroid of the minimum sphere , and these pattern are called support vectors . i=1
3 ) Decision Boundary Construction : By applying Karush Kuhn Tucker conditions [ 28 ] , we then obtain the radius R of the decision hyperplane . Assume xu is one of the patterns lying on the surface of sphere , R can be calculated as follows :
R2 = fixu − ofi2
= K(xu , xu ) + ( o , o ) − 2K(xu , o ) l+n . l+n .
= K(xu , xu ) +
αiαkK(xi , xk )
( 11 ) i=1 k=1
αi(xi , xu )
−2 l+n . i=1
308
To classify a test point x , we just calculate its distance to the centroid of the hypersphere . If this distance is less than or equal to R , ie fix − ofi2 ≤ R2 ,
( 12 ) x is accepted as the normal data . Otherwise , it is detected as an outlier .
4 ) Complexity Analysis : The computational complexity of solving the optimization Problem ( 9 ) is O(l + n)2 . Since outliers only take a very small portion of the training set , ie n ( l , Soft SVDD has approximately the same complexity as the standard SVDD ( O(l2) ) .
IV . EXPERIMENTAL EVALUATION
To validate the effectiveness of our proposed method , we perform extensive experiments on 10 real life datasets . For all reported results , the test platform is a Dual 2.8GHz Intel Core2 T9600 PC with 3.45GB RAM .
A . Baselines and Metrics
We implemented two variants of our proposed method using two mechanisms to compute the confidence values : kernel k means clustering and kernel LOF , which are referred to as CLU Soft SVDD and LOF Soft SVDD , respectively . For comparison , four state of the art outlier detection algorithms are used as baselines .
1 ) The first one is kernel k means clustering [ 22 ] , [ 8 ] which finds outliers from resulting clusters in the feature space .
2 ) The second one is the kernel LOF algorithm , which generalizes the LOF algorithm [ 6 ] by computing the outlier factor in the feature space .
The first two baselines are used to show the improvement of our proposed method over clustering based and densitybased approaches to outlier detection .
3 ) The third one is SVDD [ 25 ] , which builds a oneclass classifier solely based on the normal data . This baseline is used to test the ability of our proposed method in reducing the sensitivity of SVDD to noise . 4 ) The fourth algorithm is the cost sensitive SVM ( CSSVM ) [ 19 ] , which assigns different costs to the normal data and abnormal data so as to learn a binary classifier for outlier detection . This baseline is used to test the effectiveness of our proposed method when very few labeled negative examples are available for training . The performance of outlier detection algorithms can be evaluated based on two error rates : detection rate and false alarm rate . The detection rate is computed as the ratio of the number of correctly detected outliers to the total number of outliers . The false alarm rate is computed as the ratio of the number of normal examples that are incorrectly detected as outliers to the total number of normal examples . We compare the six algorithms using the ROC curve which plots the detection rate against the false alarm rate . We also explicitly compute the AUC values [ 20 ] to compare the six algorithms . A desirable algorithm with a high detection rate and a low false alarm rate should have an AUC value closer to one .
B . Datasets and Parameter Settings
In our experiments , we used 10 real life datasets that have been used earlier by other researchers for outlier detection [ 17 ] , [ 29 ] . These datasets include Abalone class 1 8 , Spambase other , Thyriod hyperfunction , Waveform 1 , Satellite Grey soil , Delft pump 5x1 , Diabetes present , Breast Wisconsin , Heart Cleveland , and Arrhythmia normal 1 . To perform outlier detection with very few abnormal data , we randomly selected 50 % of positive data and a small number of abnormal data for training , such that 95 % percent of the training data belong to the positive class and only 5 % percent belong to the negative class . All the remaining data are used for testing .
For all the algorithms , the Gaussian RBF kernel was used in the experiments
K(x , xi ) = exp(−fi x − xi fi2/2σ2 ) .
( 13 )
We used cross validation on the training data to tune the parameters for CLU Soft SVDD , LOF Soft SVDD , SVDD and CS SVM . The parameter σ in the RBF kernel was searched in the range from 2−3 to 24 . In addition , the parameter C in SVDD , as well as C1 , C2 in Soft SVDD and CS SVM was selected from 20 to 24 . All the reported ROC and AUC results are based on this setting .
For CLU Soft SVDD and kernel k means , we varied the number of clusters from 2 to l+n and obtained the optimal number of clusters k∗ by minimizing the external criteria 2 in [ 21 ] . For LOF Soft SVDD , we set the number of nearest neighbors k used for computing confidence values to the number of negative samples in the training set . For kernel LOF , we followed the experimental setting in [ 6 ] to compute the maximum LOF by varying k in the range from 30 to 50 .
C . Classification Accuracy
We first performed experiments to compare the classification accuracy of the six algorithms . For each dataset , we generated the training data by randomly selecting positive examples and negative examples at the ratio of 95 % to 5 % , and applied the six algorithms to the training data and evaluated the performance on the remaining test data . Figure 2 shows the ROC curves for six out of 10 datasets . Our proposed method , CLU Soft SVDD and LOF Soft SVDD , can be observed to outperform other baselines . Note that , due to limited space , we only show the ROC curves for six datasets , and in the following experiments , we will also report detailed analysis results for six datasets . However , the reported results are all consistent on the 10 datasets .
1The 10 datasets used in our experiments are all available online from http://homepagetudelftnl/n9d04/occ/indexhtml
309
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1 e t a R n o i t c e t e D
LOF−Soft−SVDD CLU−Soft−SVDD SVDD CS−SVM Kernel−LOF Kernel−K−Means
0
0
0.2
0.4 0.6 False Alarm Rate
0.8
1
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1 e t a R n o i t c e t e D
LOF−Soft−SVDD CLU−Soft−SVDD SVDD CS−SVM Kernel−LOF Kernel−K−Means
0
0
0.2
0.4 0.6 False Alarm Rate
0.8
1
( a ) Alalome
( b ) Spambase
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1 e t a R n o i t c e t e D
LOF−Soft−SVDD CLU−Soft−SVDD SVDD CS−SVM Kernel−LOF Kernel−K−Means
0
0
0.2
0.4 0.6 False Alarm Rate
0.8
1
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1 e t a R n o i t c e t e D
LOF−Soft−SVDD CLU−Soft−SVDD SVDD CS−SVM Kernel−LOF Kernel−K−Means
0
0
0.2
0.4 0.6 False Alarm Rate
0.8
1
( c ) Thyroid
LOF−based Soft SVDD Clustering−Based Soft SVDD SVDD CS−SVM LOF Clustering
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1 e t a R n o i t c e e D t
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1 e t a R n o i t c e e D t
( d ) Waveform
LOF−based Soft SVDD Clustering−Based Soft SVDD SVDD CS−SVM LOF Clustering
0
0
0.2
0.4 0.6 False Alarm Rate
0.8
1
0
0
0.2
0.4 0.6 False Alarm Rate
0.8
1
310
AVERAGE AUC VALUES AND THE STANDARD DEVIATIONS ON THE 10 DATASETS
Table I
CLU
Soft SVDD 0894±0033 0849±0059 0821±0045 0924±0036 0935±0044 0961±0057 0753±0072 0958±0033 0753±0059 0903±0063
LOF
Soft SVDD 0911±0035 0866±0054 0840±0042 0936±0026 0944±0045 0963±0039 0769±0068 0977±0038 0797±0078 0913±0052
SVDD
0878±0041 0830±0076 0806±0042 0919±0045 0907±0052 0948±0042 0736±0078 0943±0039 0728±0098 0853±0073
CS SVM 0855±0044 0814±0079 0812±0050 0866±0049 0917±0050 0942±0060 0726±0089 0942±0043 0746±0073 0872±0063
KernelLOF
0848±0041 0808±0082 0769±0058 0837±0069 0870±0058 0938±0072 0652±0098 0908±0050 0674±0127 0832±0081
Kernel k Means 0842±0048 0749±0090 0756±0068 0815±0069 0859±0062 0927±0079 0601±0116 0873±0078 0648±0128 0798±0079
Datasets Abalone Spambase Thyroid Waveform
Satellite Grey soil
Delf Pump Diabetes
B.Wisconsin H.Cleveland Arrhythmia uncertain patternvx v vector Pattern x x z y
Figure 3 . Illustration of the method used to add the noise to a data example : x is an original data example , v is a noise vector , xv is the new data example with added noise . Here we have xv = x + v .
Figure 3 illustrates the basic idea of the method used to add the noise to data examples . Specifically , the standard deviation σ0 i of the entire data along the ith dimension was first obtained . In order to model the difference in noise on different dimensions , we defined the standard deviation σi along the ith dimension , whose value was randomly drawn from the range [ 0 , 2 · σ0 i ] . Then , for the ith dimension , we added noise from a random distribution with standard deviation σi . In this way , a data example xj was added with the noise , which can be presented as a vector n−1 , σxj n ] .
2 ,··· , σxj
( 14 )
σxj = [ σxj
1 , σxj
Here , n denotes the number of dimensions for a data i , i = 1,··· n represents the noise added example xj , and σxj into the ith dimension of the data example .
In our experiments , we made the percentage of the data corrupted by noise vary from 0 % to 30 % , and applied the six methods on these datasets . Figure 4 shows the AUC values achieved by the six algorithms with respect to different percentages of training data corrupted by noise . We can see that , as more noise is added into the training data , the overall performance of the six methods degrades .
311
This occurs because , when more noise is involved , target class becomes more indistinguishable from negative class . However , we can clearly see that , the two methods , LOFsoft SVDD and CLU soft SVDD , can still consistently yield higher accuracy than kernel LOF , kernel k means , SVDD , and CS SVM . This concludes that , our proposed soft SVDD can effectively reduce the effect of noise .
E . Impact of Imbalanced Data Distribution
So far we have demonstrated that our proposed method can consistently outperform CS SVM when the number of abnormal data is much smaller than the number of normal data . However , it is still interesting to see how the performance of the three algorithms would be affected when more abnormal data are available for training .
COMPARISON OF AUC VALUES WITH RESPECT TO DIFFERENT RATIOS OF NORMAL DATA SIZE TO ABNORMAL DATA SIZE IN THE TRAINING
Table II
DATASET
Datasets
Abalone
Spambase
Thyroid
Waveform
Delft Pump
Satellite Grey soil
Ratio
98:2 95:5 90:10 98:2 95:5 90:10 98:2 95:5 90:10 98:2 95:5 90:10 98:2 95:5 95:10 95:2 95:5 90:10
CLU
Soft SVDD
LOF
Soft SVDD
CS SVM
0.887 0.904 0.913 0.835 0.840 0.844 0.804 0.813 0.825 0.934 0.944 0.957 0.946 0.961 0.968 0.924 0.935 0.938
0.892 0.913 0.918 0.843 0.850 0.858 0.813 0.836 0.840 0.939 0.955 0.966 0.951 0.963 0.968 0.935 0.944 0.948
0.765 0.842 0.915 0.746 0.803 0.853 0.786 0.812 0.836 0.706 0.856 0.953 0.826 0.942 0.961 0.807 0.917 0.944
Table II shows the AUC values with respect to different ratios of normal data size to abnormal data size in the training data . It is noted that as more abnormal examples are added into the training dataset , CS SVM offers increasing
C U A
0.9
0.85
0.8
0.75
0.7
0.65
0.6
0.55
0.85
0.8
0.75
C U A
0.7
0.65
0.6
0.55
0.95
0.9
0.85
C U A
0.8
0.75
0.7
C U A
0.85
0.8
0.75
0.7
0.65
0.6
0.55
0.5
LOF−Soft−SVDD CLU−Soft−SVDD SVDD CS−SVM Kernel−LOF Kernel−K−Means
0 %
8 %
16 %
Percentage of Noise
24 %
30 %
( a ) Alalome
LOF−Soft−SVDD CLU−Soft−SVDD SVDD CS−SVM Kernel−LOF Kernel−K−Means
0 %
8 %
16 %
Percentage of Noise
24 %
30 %
( c ) Thyroid
LOF−based Soft SVDD Clustering−Based Soft SVDD SVDD CS−SVM LOF Clustering
0 %
8 %
16 %
24 % Percentage of Noise ( e ) Delft Pump
30 %
1
0.95
0.9
0.85
0.8
C U A
0.75
0.7
0.65
0.6
0.55
0.5
LOF−Soft−SVDD CLU−Soft−SVDD SVDD CS−SVM Kernel−LOF Kernel−K−Means
0 %
8 %
16 %
Percentage of Noise
24 %
30 %
( b ) Spambase
LOF−Soft−SVDD CLU−Soft−SVDD SVDD CS−SVM Kernel−LOF Kernel−K−Means
0 %
8 %
16 %
Percentage of Noise
24 %
30 %
( d ) Waveform
1
0.95
0.9
0.85
C U A
0.8
0.75
0.7
0.65
0.6
LOF−based Soft SVDD Clustering−Based Soft SVDD SVDD CS−SVM LOF Clustering
0 %
8 %
16 %
Percentage of Noise
24 %
30 %
( f ) Satellite Grey soil
Figure 4 . Comparison of AUC values with respect to different percents of training data corrupted by noise accuracy . This is because more negative examples can offer more information from negative class to build a more accurate SVM . However , when the ratio of normal data size to abnormal data size are 98 : 2 and 95 : 5 for which the number of abnormal examples are very few , LOF Soft SVDD and CLU Soft SVDD can remarkably outperform CS SVM . This is because , based on insufficient abnormal data , CSSVM cannot construct an accurate decision boundary to distinguish two classes . This indicates that , our proposed method can yield higher accuracy in real world applications where abnormal data are very scarce .
V . CONCLUSION AND FUTURE WORK
In this paper , we propose a new model based approach to outlier detection by introducing a confidence value to each input data into the SVDD training phase . Our proposed method first captures the local uncertainty by computing a confidence value based on each example ’s local data behavior , and then builds a global classifier for outlier detection by extending the SVDD based learning framework . Experiments on 10 real life datasets have shown that our proposed method can achieve a better tradeoff between detection rate and false alarm rate for outlier detection .
We plan to extend our work in several directions . First , we would like to investigate how to design better mechanisms to generate confidence values based on the data characteristics in a given application domain . Second , we will look into how to use an online process to learn the hypersphere boundary of Soft SVDD in streaming environments .
312
[ 16 ] U . Knoll , G . Nakhaeizadeh , and B . Tausend . CostIn ECML 1994 , sensitive pruning of decision trees . pages 383–386 , Catania , Italy , April 1994 .
[ 17 ] A . Lazarevic and V . Kumar . Feature bagging for outlier In KDD 2005 , pages 157–166 , Chicago , detection . Illinois , USA , August 2005 .
[ 18 ] C . Li and W . H . Wong . Model based analysis of oligonucleotide arrays : Expression index computation and outlier detection . In Proceedings of the National Academy of Sciences USA , volume 98 , pages 31–36 , January 2001 .
[ 19 ] Y . Lin , Y . Lee , and G . Wahba . Support vector machine for classification in nonstandard situations . Machine Learning , 46:191–202 , 2002 .
[ 20 ] C . X . Ling , J . Huang , and H . Zhang . Auc : a statistically consistent and more discriminating measure than accuracy . In In IJCAI 2003 , pages 519–526 , Acapulco , Mexico , August 2003 .
[ 21 ] Y . Batistakis M . Halkidi and M . Vazirgiannis . Cluster ACM SIGMOD Record , validity methods : Part I . 31:40–45 , 2002 .
[ 22 ] R . Smith , A . Bivens , M . Embrechts , C . Palagiri , and B . Szymanski . Clustering approaches for anomaly based intrusion detection . In Proceedings of Intelligent Engineering Systems through Artificial Neural Networks , pages 579–584 . ASME Press , 2002 .
[ 23 ] I . Steinwart , D . Hush , and C . Scovel . A classification framework for anomaly detection . JMLR , 6:211–232 , 2005 .
[ 24 ] David Tax and R . Duin . Outlier detection using classifier instability . In Advances in Pattern Recognition , Lecture notes in Computer Science , pages 593–601 , 1998 .
[ 25 ] D . M . J . Tax and R . P . W . Duin . Support vector data description . Machine Learning , 54(1):45–66 , 2004 .
[ 26 ] D . M . J . Tax , A . Ypma , and R . P . W . Duin . Support vector data description applied to machine vibration analysis . In ASCI 1999 , pages 398–405 , Heijen , The Netherlands , June 1999 .
[ 27 ] J . Theller and DM Cai . Resampling approach for anomaly detection in multispectral images . In Proceedings of the SPIE , volume 5093 , pages 230–240 , San Diego , CA , USA , August 2003 .
[ 28 ] V . N . Vapnik . Statistical learning theory . John Wiley and Sons , 1998 .
[ 29 ] M . Wu and J . Ye . A small sphere and large margin approach for novelty detection using training data with outliers . IEEE TPAMI , 31(11):2088–2092 , 2009 .
VI . ACKNOWLEDGMENT
This work is sponsored in part by UTS QCIS , Australian Research Council through grants DP1096218 , DP0988016 , LP100200774 and LP0989721 , and US NSF through grants IIS 0905215 , DBI 0960443 , OISE 0968341 and OIA0963278 .
REFERENCES
[ 1 ] N . Abe , B . Zadrozny , and J . Langford . Outlier detection by active learning . In KDD 2006 , pages 504–509 , Philadelphia , USA , 2006 .
[ 2 ] C . C . Aggarwal and P . S . Yu . Outlier detection with uncertain data . In SDM 2008 , pages 483–493 , Atlanta , Georgia , USA , 2008 .
[ 3 ] F . Angiulli and C . Pizzuti . Outlier mining in large high dimensional data sets . TKDE , 17(2):203–215 , 2005 .
[ 4 ] V . Barnett and T . Lewis . Outliers in statistical data .
John Wiley , Chichester , 1994 .
[ 5 ] J . Bi and T . Zhang . Support vector classification with input data uncertainty . In NIPS 2004 , volume 17 , pages 161–168 , Vancouver , Canada , 2004 .
[ 6 ] MM Breunig , HP Kriegel , RT Ng , and J . Sander . LOF : identifying density based local outliers . In SIGMOD 2000 , pages 93–104 , Dallas , USA , May 2000 . [ 7 ] P . Chan and S . Stolfo . Toward scalable learning with In In KDD non uniform class and cost distributions . 1998 , pages 164–168 , New York , NY , USA , 1998 .
[ 8 ] V . Chandola , A . Banerjee , and V . Kumar . Anomaly detection : A survey . ACM Computing Surveys , 41(3):Article 15 , July 2009 .
[ 9 ] C . Elkan . The foundations of cost sensitive learning .
In IJCAI 2001 , pages 973–978 , Seattle , USA , 2001 .
[ 10 ] E . Eskin . Anomaly detection over noisy data using learned probability distributions . In ICML 2000 , pages 255–262 , San Francisco , CA , USA , June–July 2000 . [ 11 ] G . Fumera and F . Roli . Cost sensitive learning in support vector machines . In Proceedings of the Workshop on Machine Learning , Methods and Applications , Siena , Italy , September 2002 .
[ 12 ] A . Ghoting , S . Parthasarathy , and M . E . Otey . Fast mining of distance based outliers in high dimensional datasets . DMKD , 16(3):349–364 , June 2008 .
[ 13 ] V . J . Hodge and J . Austin . A survey of outlier detection methodologies . Artificial Intelligence Review , 22(2):85–126 , 2004 .
[ 14 ] S . Y . Jiang and Q B An . Clustering based outlier detectiion method . In ICFSKD 2008 , pages 429–433 , Jinan , Shandong , China , October 2008 .
[ 15 ] E . M . Jordaan and G . F . Smits . Robust outlier detection In IJCNN 2004 , pages 1098– using svm regression . 7576 , Budapest , Hungary , July 2004 .
313
