2010 IEEE International Conference on Data Mining
Detecting Blackhole and Volcano Patterns in Directed Networks
Zhongmou Li1 , Hui Xiong1 , Yanchi Liu1,2 , Aoying Zhou3
1MSIS Department , Rutgers Business School Newark and New Brunswick
Rutgers , the State University of New Jersey , Newark , NJ 07102 , USA
2School of Economics and Management , University of Science and Technology Beijing , Beijing , China mosesli@pegasusrutgersedu , hxiong@rutgers.edu
3Software Engineering Institute , East China Normal University , Shanghai , China liuyanchi@manageustbeducn ayzhou@seiecnueducn
Abstract—In this paper , we formulate a novel problem for finding blackhole and volcano patterns in a large directed graph . Specifically , a blackhole pattern is a group which is made of a set of nodes in a way such that there are only inlinks to this group from the rest nodes in the graph . In contrast , a volcano pattern is a group which only has outlinks to the rest nodes in the graph . Both patterns can be observed in real world . For instance , in a trading network , a blackhole pattern may represent a group of traders who are manipulating the market . In the paper , we first prove that the blackhole mining problem is a dual problem of finding volcanoes . Therefore , we focus on finding the blackhole patterns . Along this line , we design two pruning schemes to guide the blackhole finding process . In the first pruning scheme , we strategically prune the search space based on a set of pattern size independent pruning rules and develop an iBlackhole algorithm . The second pruning scheme follows a divide and conquer strategy to further exploit the pruning results from the first pruning scheme . Indeed , a target directed graphs can be divided into several disconnected subgraphs by the first pruning scheme , and thus the blackhole finding can be conducted in each disconnected subgraph rather than in a large graph . Based on these two pruning schemes , we also develop an iBlackholeDC algorithm . Finally , experimental results on real world data show that the iBlackhole DC algorithm can be several orders of magnitude faster than the iBlackhole algorithm , which has a huge computational advantage over a brute force method .
Keywords blackhole pattern ; volcano pattern ; fraud detec tion ; graph mining ; network model
I . INTRODUCTION
Financial institutions and government agencies , such as US Securities and Exchange Commission ( SEC ) , are facing some daunting challenges in the field of financial fraud detection . The sophistication of criminals’ tactics makes detecting and preventing fraud difficult , especially as the number of trading accounts and the volume of transactions grow dramatically . Indeed , the trading networks are vulnerable to these fast growing accounts and the volume of transactions . Particularly , criminals know fraud detection systems are not good at correlating user behavior across multiple trading accounts . This weakness opens the door for cross account collaborative fraud , which is difficult to discover , track and resolve because the activities of the fraudsters usually appear to be normal trading activities . For instance , consider a trading network with a large number of nodes and directed edges , a trader or a group of traders can perform trading only within several accounts for the purpose of manipulating the market . This kind of illegal trading activities is widely known as trading ring .
In this paper , we study a special type of trading ring patterns , called blackhole and volcano patterns . Given a directed graph , a blackhole pattern is a group which is made of a set of nodes in a way such that there are only inlinks to this group from the rest nodes in the graph . In contrast , a volcano pattern is a group which only has outlinks to the rest nodes in the graph . To the best of our knowledge , this is the first time to have the concepts of blackhole and volcano patterns in the directed graphs . In fact , both blackhole and volcano patterns can be observed in realworld trading networks . For example , a blackhole pattern can represent a group of traders who are manipulating the market by performing transactions on a specific stock among themselves for a specific time period . In other words , the overall shares of the target stock in their trading accounts can only increase during this time period , while these traders have produced a large volume of transactions on this stock . After the stock price goes up to a certain degree , these traders start selling off their shares to the public . In this stage , these trading accounts form a volcano pattern which only has outlinks to the rest public accounts .
However , the process for finding blackhole and volcano patterns can be computationally prohibited , since this is a combinatorial problem in nature . To address this challenge , we first prove that the blackhole pattern mining problem is a dual problem of finding volcano patterns . Therefore , we can focus on finding the blackhole patterns . Along this line , we design two pruning schemes to guide the blackhole pattern mining process . In the first pruning scheme , we identify a set of pattern size independent pruning rules by studying the structural graph properties of blackhole patterns . These pruning rules can be used for pruning the search space no matter the size of the patterns is . Based on the first pruning scheme , we design an iBlackhole algorithm for finding
1550 4786/10 $26.00 © 2010 IEEE DOI 101109/ICDM201037
294 blackhole patterns . In contrast , the second pruning scheme follows a divide and conquer strategy to further exploit the pruning results from the first pruning scheme . Specifically , because a target directed graph have been divided into several disconnected subgraphs by the first pruning scheme , it becomes much more efficient to find blackhole patterns in each disconnected subgraphs rather than in a large graph . Based on these two pruning schemes , we develop an even more effective algorithm , named iBlackhole DC , for mining blackhole patterns in directed graphs . Furthermore , we have provided the proof of the completeness and correctness of both iBlackhole and iBlackhole DC algorithms .
Finally , experimental results on several real world data sets are provided to show the pruning effect of two pruning schemes . As shown in experiments , the iBlackhole algorithm has a huge computational advantage over the brute force approach . Also , the iBlackhole DC algorithm is several orders of magnitude faster than the iBlackhole algorithm . Finally , we show the effectiveness of blackhole patterns for finding some interesting stock movement patterns .
II . PRELIMINARIES
In this section , we introduce some basic concepts and notations that will be used in this paper .
First , consider a directed graph 𝐺 = ( 𝑉 , 𝐸 ) [ 1 ] , where 𝑉 is the set of all nodes and 𝐸 is the set of all edges . Assume that 𝐺 has no self loop and has no more than one edge from one node to another . A directed edge 𝑒 in 𝐺 is denoted as 𝑒 = ( 𝑥 , 𝑦 ) , where 𝑥 and 𝑦 are nodes of 𝐺 and an arc is directed from 𝑥 to 𝑦 . Each edge 𝑒 has a positive weight , denoted as 𝜔𝑒 , associated with this edge . Definition 1 ( in weight / out weight ) : Given a directed graph 𝐺 = ( 𝑉 , 𝐸 ) , 𝐵 is a set of nodes and 𝐵 ⊆ 𝑉 . Let 𝐶 = 𝑉 ∖ 𝐵 . The in weight of 𝐵 is defined as : 𝑒=(𝑥,𝑦)∈𝐸,𝑥∈𝐶,𝑦∈𝐵 𝜔𝑒 . Also , the definition of 𝑑𝑖𝑛(𝐵 ) = 𝑒=(𝑥,𝑦)∈𝐸,𝑥∈𝐵,𝑦∈𝐶 𝜔𝑒 . the out weight of B is : 𝑑𝑜𝑢𝑡(𝐵 ) = Figure 1 shows an example of the in weight and outweight of a set of nodes . The number associated with each edge is the weight of that edge . In this figure , the in weight of 𝐵 is 6+5 = 11 , while the out weight is 3+3+1+2 = 9 .
∑
∑
3
1
4
2
2
4
5
1
3
6
B
5
4
2
3
2
3
1
Figure 1 .
Illustration : in weight and out weight .
Next , we give the definition of blackhole and volcano in a directed graph as follows .
295
Definition 2 ( blackhole ) : Given a directed graph 𝐺 = ( 𝑉 , 𝐸 ) , we say that a set of nodes 𝐵 ⊆ 𝑉 form a blackhole , if and only if the following two conditions are satisfied : 1 ) ∣𝐵∣ ≥ 2 , and the subgraph 𝐺(𝐵 ) induced by 𝐵 is weakly connected , and 2 ) 𝑑𝑖𝑛(𝐵 ) − 𝑑𝑜𝑢𝑡(𝐵 ) > 𝜃 , where 𝜃 is a predefined positive threshold and is typically a very large value . Definition 3 ( volcano ) : Given a directed graph 𝐺 = ( 𝑉 , 𝐸 ) , we say that a set of nodes 𝑉 𝑜𝑙 ⊆ 𝑉 form a volcano , if and only if the following two conditions are satisfied : 1 ) ∣𝑉 𝑜𝑙∣ ≥ 2 , and the subgraph 𝐺(𝑉 𝑜𝑙 ) induced by 𝑉 𝑜𝑙 is weakly connected , and 2 ) 𝑑𝑜𝑢𝑡(𝑉 𝑜𝑙)− 𝑑𝑖𝑛(𝑉 𝑜𝑙 ) > 𝜃 , where 𝜃 is a pre defined positive threshold and is typically a very large value .
III . PROBLEM FORMULATION
In this section , we formulate the problems of detecting blackhole and volcano patterns in a directed graph .
A . A General Problem Formulation
Given a directed graph 𝐺 = ( 𝑉 , 𝐸 ) , the goal of detecting blackhole patterns in 𝐺 is to find out the blackhole set , denoted as 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 , such that , 1 ) for each element 𝐵 ∈ 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 , 𝐵 ⊆ 𝑉 and 𝐵 satisfies the definition of blackhole , and 2 ) for any other set of nodes 𝐶 ⊆ 𝑉 and 𝐶 ∕∈ 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 , C does not satisfy the definition of blackhole . The problem of detecting volcano patterns can be formulated in a similar fashion .
Next , we show that the problem of detecting blackhole patterns is a dual problem of detecting volcano patterns .
Theorem 1 : The problem of finding out the blackhole set in a directed graph is a dual problem of finding out the volcano set in the same directed graph . Proof : Consider a directed graph 𝐺 = ( 𝑉 , 𝐸 ) . Let 𝐺′ = ( 𝑉 , 𝐸′ ) be the inverse graph of 𝐺 , where all the nodes in 𝐺′ are the same as in 𝐺 ; while for each edge 𝑒 = ( 𝑥 , 𝑦 ) ∈ 𝐸 , there is an edge 𝑒′ = ( 𝑦 , 𝑥 ) ∈ 𝐸′ , and the weight associated with 𝑒′ are exactly the same as the weight associated with 𝑒 . Therefore , the in weight of a set of nodes 𝐵 in 𝐺 are exactly the same as the out weight of 𝐵 in 𝐺′ , and vice versa . If 𝐵 is a blackhole in 𝐺 , which means 𝑑𝑖𝑛(𝐵)− 𝑑𝑜𝑢𝑡(𝐵 ) > 𝜃 in , we have 𝑑𝑜𝑢𝑡(𝐵)−𝑑𝑖𝑛(𝐵 ) > 𝜃 . Therefore , 𝐵 𝐺 , then in 𝐺′ forms a volcano in 𝐺′ . As a result , the problem of finding out the blackhole set in 𝐺 is equivalent to the problem of finding out the volcano set in 𝐺′
.
Now that we know the problem of detecting the blackhole set in the original directed graph is equivalent to the problem of detecting the volcano set in the inverse graph . Therefore , in the rest of this paper , we can focus on detecting blackhole patterns in a directed graph .
B . A Simplified Problem Formulation
The above general problem of detecting blackhole patterns is very complex . Instead , in this paper , we focus on a more
Black hole 1
B lackhole 2
Figure 2 . An illustration of the simplified blackhole practical version of this problem . Specifically , we exploit two constraints to simplify the general problem as follows . 1 ) The weights associated with all edges are all equal to 1 . This constraint results that the in weight of a node becomes the in degree and the out weight becomes the out degree ; 2 ) Instead of considering the general version of a blackhole , which satisfies 𝑑𝑖𝑛(𝐵 ) − 𝑑𝑜𝑢𝑡(𝐵 ) > 𝜃 , we simplify the 𝑏𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 definition with 𝑑𝑜𝑢𝑡(𝐵 ) = 0 .
Figure 2 shows an example of the simplified blackhole patterns . In this figure , there are two blackhole patterns , which have been highlighted by dashed circles .
IV . ALGORITHM DESIGN
In this section , we introduce the algorithms for detecting blackhole patterns in a directed graph .
A . A Brute Force Approach First , we present a brute force approach for finding blackhole patterns . From the definition , a set of nodes 𝐵 ⊆ 𝑉 is a simplified blackhole , if and only if : 1 ) ∣𝐵∣ ≥ 2 , and the subgraph 𝐺(𝐵 ) induced by 𝐵 is weakly connected , and 2 ) 𝑑𝑜𝑢𝑡(𝐵 ) = 0 . Therefore , the intuition is really simple : all the possible combinations of the nodes in 𝐺 are checked using the exhaustive search method . For each combination 𝐵 , if the subgraph 𝐺(𝐵 ) induced by 𝐵 is weakly connected and 𝑑𝑜𝑢𝑡(𝐵 ) = 0 , then 𝐵 is a blackhole in 𝐺 .
In real world scenarios , it is typically computational prohibited to find all blackhole patterns , since the number of combinations of the nodes is exponentially increased as the number of nodes increase . A practical way is to find blackhole patterns which include only limited number of nodes . Here , we introduce a concept of 𝑛 𝑛𝑜𝑑𝑒 𝑏𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 . Definition 4 ( n node blackhole ) : Given a directed graph 𝐺 = ( 𝑉 , 𝐸 ) , we say that a set of nodes 𝐵 ⊆ 𝑉 is an n node blackhole , if and only if the following two conditions are satisfied : 1 ) 𝐵 is a blackhole in 𝐺 , and 2 ) 𝐵 ∈ 𝑉 ( 𝑛 ) , where 𝑉 ( 𝑛 ) is the set of all possible subsets containing 𝑛 nodes in V ; that is , ∣𝐵∣ = 𝑛 .
Figure 3 shows the pseudocode of the brute force algorithm to detect 2 through n node blackhole patterns in a directed graph 𝐺 . Since we have considered all the possible combinations of nodes in 𝐺 from 2 through n , this algorithm is complete . Also , since for each combination of nodes , we have checked whether it satisfies the definition of blackhole , this algorithm is correct .
ALGORITHM BRUTE FORCE(𝐺 = ( 𝑉 , 𝐸 ) , 𝑛 ) Input :
𝐺 : the directed graph 𝑉 : the set of all nodes 𝐸 : the set of all edges 𝑛 : max number of nodes each blackhole may contain
Output :
1 . 2 . 3 . 4 . 5 . 6 . 7 . 8 . 9 . 10 . 11 .
𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 : 2 to n node blackhole set of 𝐺 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 ← ∅ for 𝑖 ← 2 to 𝑛 do for each 𝐵 ∈ 𝑉 ( 𝑖 ) do if 𝐺(𝐵 ) is weakly connected then 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 ← 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 if 𝑑𝑜𝑢𝑡(𝐵 ) == 0 then
∪
𝐵 end if end if end for end for return 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒
Figure 3 . The brute force algorithm
B . A Scheme of the iBlackhole Algorithm
In general , finding blackhole patterns in a directed graph is a combinatorial problem . Therefore , as the number of nodes 𝑛 increases , the computation time increases exponentially , making the brute force algorithm unrealistic to obtain the result for a large 𝑛 value . To this end , we introduce some pattern size independent pruning rules to reduce the search space . The key idea behind these pruning rules is to find out irrelevant nodes that have no chance to form an n node blackhole as many as possible , and eliminate these nodes from the candidate search list . In this way , the search space can be reduced dramatically . The algorithm developed based on these pruning rules is named as iBlackhole .
ALGORITHM iBlackhole(𝐺 = ( 𝑉 , 𝐸 ) , 𝑛 ) Input :
𝐺 : the directed graph 𝑉 : the set of all nodes 𝐸 : the set of all edges 𝑛 : max number of nodes each blackhole may contain
Output :
1 . 2 . 3 . 4 . 5 . 6 . 7 . 8 . 9 . 10 .
𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 : 2 to n node blackhole set of 𝐺 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 ← ∅ for 𝑖 ← 2 to 𝑛 do establish potential list 𝑃𝑖 remove irrelevant nodes from 𝑃𝑖 , get candidate list 𝐶𝑖 remove irrelevant nodes from 𝐶𝑖 , get final list 𝐹𝑖 apply the Brute Force Algorithm on 𝐹𝑖 to find out i node blackhole pattern set 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒𝑖 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 ← 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 end for return 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒
𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒𝑖
∪
Figure 4 . A scheme of the iBlackhole algorithm
Figure 4 shows the scheme of the iBlackhole algorithm for detecting 2 through n node blackhole patterns in a
296
P3
P3
P3
S
V
S
V
S
V
( a )
( b )
( c )
Figure 5 .
Illustration : the cascading delete process directed graph 𝐺 . In this algorithm , all blackhole patterns are identified one by one according to their number of nodes . In each step of finding the i node blackhole patterns , a potential list 𝑃𝑖 is first established . Only the nodes in this potential list have possibilities to form an i node blackhole . In other words , nodes that are not in this list have no chance to be in an i node blackhole pattern . Then nodes in 𝑃𝑖 will be examined one after another and irrelevant nodes will be deleted based on some pruning rules . The results of this pruning form a candidate list 𝐶𝑖 . For each node v in 𝐶𝑖 , we will check it again and remove irrelevant nodes from 𝐶𝑖 using some additional pruning rules . Finally , we will have the final search list 𝐹𝑖 , and then we can apply the brute force algorithm on 𝐹𝑖 to find out all i node blackhole patterns . More details about this algorithm will be given after we introduce some pruning rules .
C . Pruning Rules
In this section , we introduce pruning rules associated with the potential list , the candidate list , and the final search list . Definition 5 ( directed path ) : Given a directed graph 𝐺 = ( 𝑉 , 𝐸 ) , 𝑣0 , 𝑣1 , 𝑣2 , . . . , 𝑣𝑘 ∈ 𝑉 , 𝑒1 , 𝑒2 , . . . , 𝑒𝑘 ∈ 𝐸 , where 𝑒𝑖 = ( 𝑣𝑖−1 , 𝑣𝑖 ) . We say that the sequence of 𝑣0𝑒1𝑣1𝑒2𝑣2 . . . 𝑒𝑘𝑣𝑘 forms a directed path from 𝑣0 to 𝑣𝑘 , if 𝑣𝑖 ∕= 𝑣𝑗 for all 0 ≤ 𝑖 , 𝑗 ≤ 𝑘 , 𝑖 ∕= 𝑗 . The length of this directed path is 𝑘 . Definition 6 ( reachable ) : Given a directed graph 𝐺 = ( 𝑉 , 𝐸 ) , 𝑢 , 𝑣 ∈ 𝑉 . We say that 𝑣 is reachable from 𝑢 if there is a directed path that starts from 𝑢 and ends at 𝑣 . Definition 7 ( predecessor and successor ) : Given a directed graph 𝐺 = ( 𝑉 , 𝐸 ) , 𝑢 , 𝑣 ∈ 𝑉 . If 𝑣 is reachable from 𝑢 , then we say 𝑢 is a predecessor of 𝑣 , and 𝑣 is a successor of 𝑢 . If there is an edge from 𝑢 to 𝑣 , then 𝑢 is a direct predecessor of 𝑣 , and 𝑣 is a direct successor of 𝑢 . Lemma 1 : If a node 𝑣 ∈ 𝐵 , where 𝐵 ⊆ 𝑉 is a blackhole , then all the direct successors of 𝑣 are all in 𝐵 . Proof : This can be proved by contradiction . Assume that there is at least one of 𝑣′𝑠 direct successors 𝑠 , and 𝑠 ∕∈ 𝐵 , then we have 𝑑𝑜𝑢𝑡(𝐵 ) ≥ 1 since 𝑒 = ( 𝑣 , 𝑠 ) ∈ 𝐸 and 𝑠 ∕∈ 𝐵 . This contradicts with the definition of blackhole . Therefore , all direct successors of 𝑣 should be in 𝐵 . Based on Lemma 1 , we have the following lemma .
Lemma 2 : In an n node blackhole 𝐵 , the maximum out degree of any node in 𝐵 is 𝑛 − 1 .
Proof : This can be proved by contradiction . Suppose there is a node 𝑣 with out degree at least 𝑛 in an n node blackhole 𝐵 , then 𝑣 should have at least 𝑛 direct successors , denoted as 𝑠1 , 𝑠2 , . . . , 𝑠𝑛 . According to Lemma 1 , if 𝑣 ∈ 𝐵 , all of 𝑠1 , 𝑠2 , . . . , 𝑠𝑛 should be in 𝐵 , which makes the size of this blackhole at least 𝑛 + 1 . Then we find a contradiction here . Therefore , the maximum out degree of any node in an n node blackhole should be no greater than 𝑛 − 1 .
According to Lemma 2 , we can derive the following theorem for pruning the potential list 𝑃𝑖 .
Theorem 2 : For the potential list 𝑃𝑖 , only nodes with out degree less than 𝑖 need to be considered . Proof : By Lemma 2 , the maximum out degree of any node in an n node blackhole is 𝑛− 1 . In other words , nodes with out degree greater than 𝑖 − 1 have no chance to be in an i node blackhole . Therefore , only nodes with out degree less than 𝑖 needs to be included in the potential list 𝑃𝑖 .
According to Theorem 2 , only the nodes with out degree less than 𝑖 are used to establish the potential list 𝑃𝑖 . After having 𝑃𝑖 , some additional pruning rules can be applied to remove irrelevant nodes from 𝑃𝑖 to get the candidate list 𝐶𝑖 . Lemma 3 : For each node 𝑣 ∈ 𝑃𝑖 , if there is at least one of 𝑣′𝑠 direct successors 𝑠 ∕∈ 𝑃𝑖 , then 𝑣 ∕∈ 𝐶𝑖 . Proof : This can be proved by contradiction . Since 𝑠 ∕∈ 𝑃𝑖 , this means 𝑠 has no chance to be in an inode blackhole . Assume that finally 𝑣 belongs to an inode blackhole 𝐵 . According to Lemma 1 , all 𝑣′𝑠 direct successors , which include 𝑠 , will also belong to 𝐵 . Then we have a contradiction here . Therefore , 𝑣 has no chance to form an i node blackhole , and thus 𝑣 can be removed from 𝑃𝑖 safely ; that is , 𝑣 ∕∈ 𝐶𝑖 .
After a node is removed from 𝑃𝑖 , there are some other nodes associated with it can also be removed from 𝑃𝑖 .
Lemma 4 : If a node 𝑣 is removed from 𝑃𝑖 , then all of its direct predecessors can also be removed from 𝑃𝑖 . Proof : For each of 𝑣′𝑠 direct predecessors 𝑝 , 𝑣 is 𝑝′𝑠 direct successor . Since 𝑣 has been removed from 𝑃𝑖 , then 𝑣 ∕∈ 𝑃𝑖 . According to Lemma 3 , 𝑝 should also be removed from 𝑃𝑖 . Therefore , all 𝑣′𝑠 direct predecessors can be removed from 𝑃𝑖 .
297
ALGORITHM iBlackhole(𝐺 = ( 𝑉 , 𝐸 ) , 𝑛 ) Input :
𝐺 : the directed graph 𝑉 : the set of all nodes 𝐸 : the set of all edges 𝑛 : max number of nodes each blackhole may contain
𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 : 2 to n node blackhole set of 𝐺 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 ← ∅ for 𝑖 ← 2 to 𝑛 do
𝑃𝑖 ← {𝑣∣𝑑𝑜𝑢𝑡(𝑣 ) < 𝑖} for each 𝑣 in 𝑃𝑖 do if at least one of 𝑣′𝑠 directed successors are not in 𝑃𝑖 then remove 𝑣 from 𝑃𝑖 remove all 𝑣′𝑠 predecessors from 𝑃𝑖 end if end for 𝐶𝑖 ← 𝑃𝑖 for each 𝑣 in 𝐶𝑖 do if ∣𝑣+∣ > 𝑖 then remove 𝑣 from 𝐶𝑖 remove all 𝑣′𝑠 predecessors from 𝐶𝑖 end if if ∣𝑣+∣ == 𝑖 then
𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 ← 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 remove 𝑣 from 𝐶𝑖 remove all 𝑣′𝑠 predecessors from 𝐶𝑖
𝑣+
∪ end if end for 𝐹𝑖 ← 𝐶𝑖 for each 𝐵 ∈ 𝐹𝑖(𝑖 ) do if 𝐺(𝐵 ) is weakly connected then 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 ← 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 if 𝑑𝑜𝑢𝑡(𝐵 ) == 0 then
∪
𝐵 end if end if end for end for return 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒
Figure 7 . The iBlackhole algorithm
Output :
1 . 2 . 3 . 4 . 5 . 6 . 7 . 8 . 9 . 10 . 11 . 12 . 13 . 14 . 15 . 16 . 17 . 18 . 19 . 20 . 21 . 22 . 23 . 24 . 25 . 26 . 27 . 28 . 29 . 30 . 31 . 32 .
′′𝑣′′
By Lemma 4 , when removing a node 𝑣 from 𝑃𝑖 , all its direct predecessors should also be removed . Then , the newly s . Finally , removed direct predecessors become the new the cascading delete will spread to all 𝑣′𝑠 predecessors . Figure 5 shows an example of the cascading delete process when removing node 𝑣 from the potential list 𝑃3 . The shadow nodes in the figures are nodes removed from 𝑃3 . In Figure 5(𝑎 ) , 𝑠 has an out degree of 3 , which makes it exclude from 𝑃3 at the first place . When nodes in 𝑃3 are checked one after another , it can be noticed that 𝑣 has a successor 𝑠 not in 𝑃3 . Therefore , 𝑣 is removed from 𝑃3 . Then all of 𝑣′𝑠 direct predecessors are all deleted from 𝑃3 as shown in Figure 5(𝑏 ) , and this process spreads to all 𝑣′𝑠 predecessors in Figure 5(𝑐 ) .
By applying Lemma 3 and Lemma 4 , we prune rules irrelevant nodes from 𝑃𝑖 , and get the candidate list 𝐶𝑖 . Before going any further , we would like to introduce another concept first . e d v b a c f g h
Figure 6 . An example of the closure of node 𝑣
Definition 8 ( closure ) : Given a directed graph 𝐺 = ( 𝑉 , 𝐸 ) , 𝑣 ∈ 𝑉 . The closure of 𝑣 , denoted as 𝑣+ , is defined as : 𝑣+ = {𝑠 ∣ there is a directed path from v to s} ∪ {𝑣} . Figure 6 shows an example of the closure of node 𝑣 . In this figure , 𝑣+ = {𝑣 , 𝑎 , 𝑐 , 𝑏 , ℎ , 𝑔} . Indeed , the closure of a node has an important feature as the following .
Theorem 3 : The closure of a node 𝑣 is a blackhole . Moreover , it is a subset of any blackhole that contains 𝑣 . Proof : For the first part of this theorem , by the definition of closure , 𝑣+ is the set of all nodes reachable from 𝑣 , together with 𝑣 . If 𝑣+ does not form a blackhole , there have to be at least an edge 𝑒 = ( 𝑠 , 𝑡 ) ∈ 𝐺 , such that 𝑠 ∈ 𝑣+ and 𝑡 ∕∈ 𝑣+ . If 𝑠 = 𝑣 , then 𝑡 is reachable from 𝑣 , we have 𝑡 ∈ 𝑣+ ; If 𝑠 ∕= 𝑣 , since there is a directed path from 𝑣 to 𝑠 , and 𝑒 = ( 𝑠 , 𝑡 ) , 𝑡 can be reached from 𝑣 . We can also have 𝑡 ∈ 𝑣+ . In either condition , we can have a contradiction here . Therefore , 𝑣+ is a blackhole . For the second part of this theorem , if a blackhole 𝐵 contains 𝑣 , by Lemma 1 , all 𝑣′𝑠 direct successors should all be in 𝐵 . And then these direct successors become the new ′′𝑣′′ s . Eventually , this procedure will be spread to all the 𝑣′𝑠 successors . The above leads to 𝑣+ ⊆ 𝐵 .
The feature of closure ( Theorem 3 ) can be used to derive some pruning rules to remove some irrelevant nodes from 𝐶𝑖 , and finally lead to the final search list 𝐹𝑖 .
298
Lemma 5 : For each node 𝑣 ∈ 𝐶𝑖 , if ∣𝑣+∣ > 𝑖 , then 𝑣 and all its predecessors are not in 𝐹𝑖 .
Proof : By Theorem 3 , 𝑣+ is a subset of any blackhole which contains 𝑣 . Suppose 𝑣 is in an i node blackhole 𝐵 . Then we have 𝑣+ ⊆ 𝐵 . So ∣𝐵∣ ≥ ∣𝑣+∣ > 𝑖 . We can have a contradiction here . Therefore , 𝑣 has no chance to form an i node blackhole , and we can remove 𝑣 from 𝐶𝑖 safely . Then , the similar cascading delete procedure can be applied , and thus all the 𝑣′𝑠 predecessors can be deleted from 𝐶𝑖 . Therefore , 𝑣 and all its predecessors will not be in 𝐹𝑖 . Lemma 6 : For each node 𝑣 ∈ 𝐶𝑖 , if ∣𝑣+∣ = 𝑖 , then 𝑣+ can be outputted as an i node blackhole . Also , 𝑣 and all its predecessors can be removed from 𝐶𝑖 . Proof : According to Theorem 3 , 𝑣+ is a blackhole . Since ∣𝑣+∣ = 𝑖 , 𝑣+ can be outputted as an i node blackhole . Assume that 𝑣 will also be in another blackhole 𝐵 . By
P3 a b s c v d h i j k g e f
( a )
C3 a b s c v d h i j k g e f
( b )
F3 a b s c v d h i j k g e f
( c )
F 3 a b s c v d h i j k g e f
( d )
Figure 8 . An example of the procedure of the iBlackhole Algorithm
Theorem 3 , 𝑣+ ⊆ 𝐵 . If ∣𝐵∣ > 𝑖 , 𝐵 is not an i node blackhole and cannot be outputted as an i node blackhole ; If ∣𝐵∣ = 𝑖 , then 𝐵 is exactly 𝑣+ , and has already been out putted as an i node blackhole . In either situation , we can remove 𝑣 from 𝐶𝑖 . Then the similar cascading delete procedure can be applied , and finally all 𝑣′𝑠 predecessors will be deleted from 𝐶𝑖 .
Lemma 5 and Lemma 6 are used as pruning rules to prune the candidate list 𝐶𝑖 and get the final search list 𝐹𝑖 . After having 𝐹𝑖 , we can apply the brute force approach on 𝐹𝑖 to find out all i node blackhole patterns . In the next subsection , we will give the details of the iBlackhole algorithm .
D . The iBlackhole Algorithm
The iBlackhole algorithm exploits the pruning rules stated from Lemma 1 to Lemma 6 . Figure 7 shows the detailed pseudocode of the iBlackhole algorithm . Specifically , Line 3 establishes the potential list 𝑃𝑖 . Lines 4 11 remove irrelevant nodes from 𝑃𝑖 , and get the candidate list 𝐶𝑖 . Lines 12 23 remove irrelevant nodes from 𝐶𝑖 , and get the final search list 𝐹𝑖 . Lines 24 30 apply the brute force approach on 𝐹𝑖 to find out all i node blackhole patterns .
Completeness and Correctness . In the iBlackhole algorithm , since only the nodes that have no chance to form an inode blackhole pattern are removed in each iteration 𝑖 ( this is guaranteed by Lemma 1 through Lemma 6 ) . In other words , all the possible combinations of nodes have been checked to produce 𝐹𝑖 , this algorithm is complete . Also , for each candidate blackhole pattern , since we have checked whether this candidate pattern satisfies the definition of blackhole or not , this algorithm is correct .
Figure 8 shows an example of the procedure of the iBlackhole algorithm when searching the 3 node blackhole patterns . The shadow nodes in the figures are nodes which have been deleted . In Figure 8(𝑎 ) , 𝑠 has an out degree of 3 , so 𝑠 can be deleted from 𝑃3 at the first place . In Figure 8(𝑏 ) , when we check the nodes in 𝑃3 one after another , we notice that 𝑣 has a successor 𝑠 not in 𝑃3 . Therefore , we can remove 𝑣 from 𝑃3 . Then , all the direct predecessors of 𝑣 can be cascaded deleted from 𝑃3 , and this delete process spreads to all 𝑣′𝑠 predecessors . Finally , we have the candidate list 𝐶3 = {𝑎 , 𝑏 , 𝑐 , 𝑖 , 𝑗 , 𝑘} . In Figure 8(𝑐 ) , we find that ∣𝑖+∣ = 3 . Therefore , we output 𝑖+ = {𝑖 , 𝑗 , 𝑘} as a 3 node blackhole , and delete 𝑖 from 𝐶3 . Now , we have the final search list 𝐹3 = {𝑎 , 𝑏 , 𝑐 , 𝑗 , 𝑘} . In Figure 8(𝑑 ) , we examine each 3combination of nodes in 𝐹3 , and find out a 3 node blackhole
{𝑎 , 𝑏 , 𝑐} . Therefore , there are two 3 node blackhole patterns in this example , {𝑎 , 𝑏 , 𝑐} and {𝑖 , 𝑗 , 𝑘} respectively .
E . The iBlackhole DC Algorithm
While the search space has been reduced dramatically in the iBlackhole algorithm , it is still possible to develop some pruning strategies for the graphs with some special characteristics . Indeed , for a node 𝑣 ∈ 𝑉 , 𝑣 can only form a blackhole pattern with nodes within the same weakly in 𝐺 by the blackhole definition . connected component Therefore , if a directed graph has several weakly connected components , which are not connected to each other , a divide and conquer pruning strategy can be exploited for first identifying these weakly connected components and the blackhole finding method can be conducted in each weakly connected component . This pruning strategy can drastically divide a large exponential growth search space into several much smaller exponential growth search space , and thus reducing a lot of computational cost .
Along this line , we combine the iBlackhole algorithm with this divide and conquer pruning strategy and develop an even more effective algorithm , named iBlackhole DC , for finding blackhole patterns . Figure 9 shows the scheme of this algorithm for finding out 2 through n node blackhole patterns in a directed graph 𝐺 .
ALGORITHM iBlackhole DC(𝐺 = ( 𝑉 , 𝐸 ) , 𝑛 ) Input :
𝐺 : the directed graph 𝑉 : the set of all nodes 𝐸 : the set of all edges 𝑛 : max number of nodes each blackhole may contain
𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 : 2 to n node blackhole set of 𝐺 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 ← ∅ for 𝑖 ← 2 to 𝑛 do establish potential list 𝑃𝑖 remove useless nodes from 𝑃𝑖 , get candidate list 𝐶𝑖 remove useless nodes from 𝐶𝑖 , get final list 𝐹𝑖 for each weakly connected component in 𝐺(𝐹𝑖 ) do apply the Brute Force Algorithm to find out i node blackhole pattern set 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒𝑖 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒 ← 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒
𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒𝑖
∪ end for end for return 𝐵𝑙𝑎𝑐𝑘ℎ𝑜𝑙𝑒
Figure 9 . A scheme of the iBlackhole DC algorithm
Output :
1 . 2 . 3 . 4 . 5 . 6 . 7 . 8 . 9 . 10 . 11 . 12 .
299
The completeness and correctness of the iBlackholeDC algorithm is straightforward . Since the only difference between iBlackhole and iBlackhole DC is the use of the divide and conquer strategy . We know that the iBlackhole algorithm is complete and correct . Also , the divide andconquer strategy only separates the nodes which cannot form blackhole patterns . Therefore , the iBlackhole DC algorithm is also complete and correct .
V . EXPERIMENTAL RESULTS
In this section , we present the experimental results to evaluate the performances of Brute Force , iBlackhole and iBlackhole DC algorithms .
A . The Experimental Setup
Experimental Data . The experiments were conducted on four real world data sets : Wiki , Amazon , Roget , and Stock . Table I shows some basic characteristics of these data sets .
Table I
DATA CHARACTERISTICS
Data set Wiki Wiki500 Wiki1000 Wiki1500 Wiki1500 full Amazon Amazon1000 Amazon500 full Roget Roget full Stock 0.35
# nodes 7,115 500 1,000 1,500 1,500 262,111 1,000 500 1,022 1,022 2,453
# egdes 103,689 3,865 9,741 16,389 16,820
1,234,877
3,952 1,911 5,075 5,127 273
Wiki Data Set . There are 7,115 nodes and 103,689 edges in the Wiki data set [ 2 ] . To make the brute force algorithm runnable , we derived three subgraphs from the original graph , with the number of nodes 500 , 1,000 , and 1,500 respectively . These subgraphs are named as Wiki500 , Wiki1000 , and Wiki1500 separately . In addition , we synthesized a weakly connected directed graph , named as Wiki1500 full , by adding some edges to Wiki1500 data set .
Amazon Data Set . There are 262,111 nodes and 1,234,877 edges in the Amazon data set [ 3 ] . Similar to the Wiki data set , we derived a subgraph Amazon1000 with 1000 nodes , and synthesized a weakly connected directed graph Amazon500 full from the original graph .
Roget Data Set . There are 1,022 nodes and 5,075 edges in the Roget data set [ 4 ] . Also , we synthesized a weakly connected directed graph Roget full from the original graph , by adding some edges to it .
Stock Data Set . This is a data set generated by ourselves . Specifically , we collected daily stock prices from Wharton Research Data Services [ 5 ] of 3,081 instruments in
Figure 10 . An overview of the Dow Jones Index from Jan 08 to Jun 08
, 𝑝𝑖2
, . . . , 𝑝𝑖𝑡
, . . . , 𝑏𝑖124
, . . . , 𝑝𝑖125 the US stock market over a period of 125 consecutive trading days from Jan 2 , 2008 to Jun 30 , 2008 . We tried to avoid selecting the period with a strong movement trend in the stock market , since the movements of all instruments during that period tend to have high correlations among each other . As can be seen in Figure 10 , there was no strong trend in the Dow Jones index during the selected period . Then we removed instruments in Dow Jones and S&P 500 indexes from our collection . Those instruments are more representative in the stock market and therefore tend to have high correlations with the other instruments . Since we target on finding out some not so obvious blackhole patterns , we only consider instruments not in Dow Jones and S&P 500 indexes . After that , we constructed the Stock data set as follows . 1 ) Nodes in this data set correspond to instruments . There are 2,453 nodes in this data set ; 2 ) we build a vector 𝑃𝑖 = } for each instrument , where 𝑝𝑖𝑡 {𝑝𝑖1 is the closing price of instrument 𝑖 on day 𝑡 ; 3 ) we create a Boolean vector 𝐵𝑖 = {𝑏𝑖1 } based , 𝑜𝑡ℎ𝑒𝑟𝑤𝑖𝑠𝑒 0 ; 4 ) For = 1 , 𝑖𝑓 𝑝𝑖𝑡+1 on 𝑃𝑖 , where 𝑏𝑖𝑡 𝑋 = {𝑥1 , . . . , 𝑥𝑡 , . . . , 𝑥𝑛} and 𝑌 = {𝑦1 , . . . , 𝑦𝑡 , . . . , 𝑦𝑛} , 𝜌𝑥𝑦(𝑘 ) is the lagged correlation when 𝑌 is delayed by 𝑘 . A symmetric situation can be applied to get 𝜌𝑦𝑥(𝑘 ) . We compute the lagged correlations 𝜌𝑖𝑗(1 ) and 𝜌𝑗𝑖(1 ) for each pair of instrument 𝑖 and 𝑗 ; 5 ) there is an edge from node 𝑗 to node 𝑖 , if 𝜌𝑖𝑗(1 ) > 𝜃 , where 𝜃 is a pre defined threshold , and vice versa . Since we compute the lagged correlation of 1day delay between two instruments , if there is an edge from node 𝑗 to node 𝑖 , it indicates the movement of instrument 𝑗 followed the movement of instrument 𝑖 on the previous day . Here , we specify 𝜃 as 0.35 to get Stock 0.35 data set . Note that the method we used to construct the Stock data set is similar to the way in [ 6 ] . However , there are some differences . We used the lagged Pearson correlation among instruments , and ended up with a directed graph . While Boginski et al [ 6 ] employed the general Pearson correlation and constructed an undirected graph .
, 𝑏𝑖2 , . . . , 𝑏𝑖𝑡 ≥ 𝑝𝑖𝑡
Experimental Platform . All the experiments were performed on a Dell Optiplex 960 Desktop with Intel Core 2 Quad Processor Q9550 and 4 GB of memory running the Windows XP Professional Service Pack 3 operating system .
300 i
) c e s ( e m T g n n n u R i i
) c e s ( e m T g n n n u R i
105
104
103
102
101
100
10−1
10−2
2
104
103
102
101
100
10−1
10−2
10−3
10−4
2
Brute−Force iBlackhole iBlackhole−DC
3
4
5
6
7
Number of Nodes
8
9
10 i
) c e s ( e m T g n n n u R i
105
104
103
102
101
100
10−1
10−2
10−3
2
Brute−Force iBlackhole iBlackhole−DC
3
4
5
6
7
8
9
10
Number of Nodes i
) c e s ( e m T g n n n u R i
105
104
103
102
101
100
10−1
10−2
10−3
2
Brute−Force iBlackhole iBlackhole−DC
3
4
5
6
7
Number of Nodes
8
9
10
( a ) Wiki1000
( b ) Amazon1000
( c ) Roget
Figure 11 . The running time of Brute Force , iBlackhole , and iBlackhole DC algorithms on different data sets
Brute−Force iBlackhole iBlackhole−DC
Brute−Force iBlackhole iBlackhole−DC i
) c e s ( e m T g n n n u R i
105
104
103
102
101
100
10−1
10−2
2
3
4
8
9
10
3
4
5
6
7
Number of Nodes
5
6
7
8
9
10
Number of Nodes i
) c e s ( e m T g n n n u R i
106
105
104
103
102
101
100
10−1
10−2
2
Brute−Force iBlackhole iBlackhole−DC
3
4
5
6
7
Number of Nodes
8
9
10
( a ) Wiki500
( b ) Wiki1000
( c ) Wiki1500
Figure 12 . The running time of Brute Force , iBlackhole , and iBlackhole DC algorithms for different # nodes
B . An Overall Comparison
In this subsection , we provide an overall comparison of
Brute Force , iBlackhole , and iBlackhole DC algorithms .
First , we compare the performances of three algorithms on different data sets with almost the same number of nodes . In this experiment , we choose data sets Wiki1000 , Amazon1000 , and Roget . Figure 11 shows the running time of these algorithms . As can be seen , both BruteForce and iBlackhole algorithms are runnable within certain number of nodes , while iBlackhole can go a litter bit further than Brute Force . In contrast , the iBlackhole DC algorithm is runnable for finding n node blackhole patterns with a large 𝑛 value .
The running time of three algorithms for detecting blackhole patterns with different number of nodes forms three approximately straight lines in logarithm scale for all three data sets . ( For iBlackhole DC , it is more clear if we only focus on 𝑛 ≥ 4 ) . This indicates that the running time for those algorithms follow an exponential increasing time . Also , the slopes of three performance curves for each data set are significantly different . For Brute Force , since we do the exhaust search at the beginning and the number of nodes of the three data sets are almost the same , the slopes in those three subfigures are almost the same . For iBlackhole , as well as iBlackhole DC , they are a little different . The slope of the curve on the Wiki1000 data set is larger than slopes in Amazon1000 and Roget . For both iBlackhole and iBlackhole DC , we prune irrelevant nodes from each data set . However , the pruning effect depends on the graph properties of each data set ( ie the average in degree and out degree plays an important role ) . This makes the running time of iBlackhole and iBlackhole DC algorithms vary for different data sets , but after all , much less than the BruteForce algorithm .
Next , we compare the performances of three algorithms on the same data set with different number of nodes . In this experiment , we choose data sets Wiki500 , Wiki1000 , and Wiki1500 . Figure 12 shows the running time of these three algorithms on those three data sets .
The overall performances of these three algorithms are very similar to the first experiment . However , there are still something interesting here . We can observe that the slopes of the three lines in these three data sets are almost the same . ( For iBlackhole DC , it is more clear if we only focus on 𝑛 ≥ 4 ) . Since these three subgraphs are derived from the same network , the inherent graph properties of these data sets are similar . The above might be the reason that similar slopes are observed in the results .
C . iBlackhole vs . iBlackhole DC
In this compare subsection , we the performances of iBlackhole and iBlackhole DC algorithms . We show how significant strategy improves the performance of In this experiment , we choose three synthetical weakly connected directed networks , Amazon500 full , Roget full , and Wiki1500 full . the divide and conquer iBlackhole .
Figure 13 shows the running time of these two algorithms on those three data sets . In the figure , we can see that the performance of iBlackhole DC is several orders of magnitude faster than the performance of iBlackhole , since it drastically divides a large exponential growth search space into several much smaller exponential growth search space , and thus reduces a lot of computational cost .
301 i
) c e s ( e m T g n n n u R i
105
104
103
102
101
100
10−1
10−2
10−3
2
3
4 iBlackhole iBlackhole−DC
104
102
100
10−2 i
) c e s ( e m T g n n n u R i
5
6
7
Number of Nodes
8
9
10
2
3
4 iBlackhole iBlackhole−DC iBlackhole iBlackhole−DC
104
102
100 i
) c e s ( e m T g n n n u R i
8
9
10
10−2
2
3
4
5
6
7
Number of Nodes
8
9
10
5
6
7
Number of Nodes
( a ) Amazon500 full Figure 13 . The running time of iBlackhole algorithm and iBlackhole DC algorithm on different data sets
( c ) Wiki1500 full
( b ) Roget full
Figure 14 shows the visualizations of the structures of different data sets before and after applying the first pruning scheme to these data sets while detecting 7 node blackhole patterns . This figure is drawn with Pajek [ 7 ] . From this figure , we can observe that the number of nodes in each data set decreases dramatically after pruning , and each network becomes very sparse . Table II shows some main characteristics of the data sets after pruning . As can be seen , while the original data sets are all weakly connected , we can still get a large number of connected components after pruning . Therefore , the divide and conquer strategy can help dramatically reduce the search space .
CHARACTERISTICS OF DATA SETS AFTER PRUNING
Table II
Data set
Amazon500
Roget
Wiki1500
# nodes
# edges
# connected comp
14 32 252
36 37 209
3 11 43 i g n n u r P e r o f e B i g n n u r P r e Ğ A
Pajek
Pajek
Pajek
Amazon500
Pajek
Roget
Pajek
Wiki1500
Pajek
Figure 14 . Structures of different data sets before and after pruning
D . Blackhole Patterns in the Stock Data
Here , we show an application of blackhole patterns for understanding the structural relationship of stock movement .
Figure 15 shows two blackhole patterns identified in the Stock 0.35 data set . Owens Corning ( OC ) is in the left blackhole pattern . The Westmoreland Coal Company ( WLB ) has an outlink to OC . This indicates that the price movement of WLB followed the price movement of OC . By doing some research , we find out Owens Corning is one
302
OC
WLB
CDL
ISIL
A DCT
T KR
TRID
VQ
H P
MTEX
ZRAN
Figure 15 . Two blackhole patterns identified in Stock 0.35 data set of the biggest building material producers in the country . Its products include the manufactured stone products used in the building . In recent years , there is a trend in the industry that companies are developing new innovative building materials by recycling the waste in the energy industry , which are primarily the residual byproducts of coal combustion . As an energy company , WLB owns five coal mines . Therefore , it is understandable that the stock price of the Westmoreland Coal Company has a lag correlation with the stock price of Owens Corning . The other two companies in this pattern are Venoco Inc . ( VQ ) and Helmerich & Payne Inc . ( HP ) . Venoco Inc . is an energy company primarily engaged in the acquisition , exploration , exploitation , and development of oil and natural gas properties , while Helmerich & Payne Inc . is a contract drilling company drilling oil and gas wells for others . Therefore , it is not surprising that the stock price movements of these two companies are lag correlated with the stock price of the Westmoreland Coal Company .
The second blackhole pattern is a star shaped blackhole , which indicates the stock prices for the other six instruments are triggered by Citadel Broadcasting Corp . ( CDL ) . Among these six companies , there are one telecommunication company ( ADCT ) , three IC related companies ( ISIL , TRID , and ZRAN ) , and one highly engineered steel produce company ( TKR ) , which are all related to the Broadcasting Corporation to some extent . The other company is a wellness solution provider , which may be involved in this pattern by chance or for some unknown reasons .
This application is just a simple indication of the use of the blackhole patterns . Indeed , the blackhole patterns can provide an unique view of some structural properties , and help us better understand the interactions among some nodes in the network . However , we should note that this use of blackhole patterns is still preliminary and more comprehensive studies are expected in the future .
VI . RELATED WORK
Related work can be grouped into two categories . The first category includes the work on frequent subgraph mining , which studies how to efficiently find frequent subgraphs in the graph data . For instance , Jiang et al . [ 8 ] proposed a measure for mining globally distributed frequent subgraphs in a single labeled graph . Meanwhile , there are many works in mining frequent subgraphs in multiple labeled graphs [ 9 ] , [ 10 ] , [ 11 ] , [ 12 ] , [ 13 ] , [ 14 ] . The problem of detecting blackhole patterns is different from the above works for two reasons . First , the definition of blackhole patterns is different from the definition of frequent subgraphs . Second , blackhole patterns are identified whether they are frequent or not .
The second category includes the works for detecting community structures in large networks . Communities in a network are groups of nodes within which connections are dense , but between which connections are sparse [ 15 ] . There are a lot of works on how to detect communities in a network . For instance , Newman and Girvan [ 16 ] , [ 17 ] proposed a betweenness based method , Hopcroft [ 18 ] proposed a stable method , and Ghosh [ 19 ] proposed a global influence based method to detect community structures . All these methods detect community structures based on certain definitions and criteria . However , the definition of blackhole patterns is different from the above definitions of communities . Also , once a network has been decided , the number of n node blackhole patterns is determined . In contrast , it is usually difficult to know how many community structures are in the network .
VII . CONCLUDING REMARKS
In this paper , we formulated a problem of finding blackhole and volcano patterns in directed networks . Both blackhole and volcano patterns can be observed in real world scenarios , such as the trading ring for market manipulation . Indeed , it is essentially a combinatorial problem for mining blackhole or volcano patterns . To reduce the complexity of the problem , we first proved that the problem of finding blackhole patterns is a dual problem of finding volcano patterns . Thus , we could be only focused on mining blackhole patterns . To that end , we derived two pruning schemes . The first scheme is based on a set of size independent pruning rules which can help to prune the candidate search space effectively and thus can dramatically reduce the computational cost of blackhole mining . Based on the first pruning scheme , we developed the iBlackhole algorithm for mining blackhole patterns . In addition , the second scheme is to take advantage of an unique graph property ; that is , we could search in each individual subgraphs if the target directed graph contains several disconnected subgraphs . Therefore , by exploiting these two pruning schemes , we developed the iBlackhole DC algorithm for finding blackhole patterns .
Finally , as shown in the experimental results , the pruning effect of both pruning schemes is significant and the iBlackhole DC algorithm is several order of magnitude faster than the iBlackhole algorithm , which outperforms a brute force approach by several orders of magnitude as well .
VIII . ACKNOWLEDGEMENTS
The authors were supported in part by National Science Foundation ( NSF ) via grant number CCF 1018151 , and National Natural Science Foundation of China ( NSFC ) via project number 60925008 .
REFERENCES
[ 1 ] R . Diestel , Graph Theory ( Graduate Texts in Mathematics ) .
Springer , 2006 .
[ 2 ] J . Leskovec , K . Lang , and et al , “ Community structure in large networks : Natural cluster sizes and the absence of large well defined clusters , ” in arXiv:0810.1355 , 2008 .
[ 3 ] J . Leskovec , L . Adamic , and B . Adamic , “ The dynamics of viral marketing , ” ACM TWEB , vol . 1 , 2007 .
[ 4 ] V . Batagelj and A . Mrvar .
Pajek datasets , 2006 . http://vladofmfuni ljsi/pub/networks/data
[ 5 ] Wharton Research Data Services , University of Pennsylvania . https://wrdswhartonupennedu/wrdsauth/memberscgi
[ 6 ] V . Boginski , S . Butenko , and P . M . Pardalos , “ Statistical analysis of financial networks , ” Computational Stat . and Data Analysis , vol . 48 , pp . 431–443 , 2005 .
[ 7 ] W . Nooy , A . Mrvar , and V . Batagelj , Exploratory Social Network Analysis with Pajek . Cambridge University Press , 2005 .
[ 8 ] X . Jiang , H . Xiong , C . Wang , and A . H . Tan , “ Mining globally distributed frequent subgraphs in a single labeled graph , ” Data and Knowledge Engineering , vol . 68 , pp . 1034–1058 , 2009 .
[ 9 ] X . Yan and J . Han , “ gspan : Graph based substructure pattern mining . ” in IEEE ICDM’02 , 2002 .
[ 10 ] C . Wang , W . Wang , J . Pei , Y . Zhu , and B . Shi , “ Scalable mining of large disk based graph databases , ” in ACM SIGKDD’04 , 2004 .
[ 11 ] J . Huan , W . Wang , and J . Prins , “ Efficient mining of frequent subgraphs in the presence of isomorphism , ” in IEEE ICDM’03 , 2003 .
[ 12 ] J . Wang , W . Hsu , M . Lee , and C . Sheng , “ A partition based approach to graph mining , ” in ICDE 2006 , 2006 , p . 74 .
[ 13 ] M . Kuramochi and G . Karypis , “ Finding frequent patterns in a large sparse graph . ” Data Min . Knowl . Discov . , vol . 11 , no . 3 , pp . 243–271 , 2005 .
[ 14 ] D . J . Cook and L . B . Holder , “ Substructure discovery using minimum description length and background knowledge . ” J . Artif . Intell . Res . ( JAIR ) , vol . 1 , pp . 231–255 , 1994 .
[ 15 ] M . E . J . Newman , “ Detecting community structure in net works , ” Eur . Phys . J . B , vol . 38 , pp . 321–330 , 2004 .
[ 16 ] M . E . J . Newman and M . Girvan , “ Finding and evaluating community structure in networks , ” Phys . Rev . E 69 , vol . 026113 , 2004 .
[ 17 ] M . Girvan and M . E . J . Newman , “ Community structure in social and biological networks , ” in Proc . National Acad . Science , 2002 .
[ 18 ] J . Hopcroft , O . Khan , and et al , “ Natural communities in large linked networks , ” in ACM SIGKDD’03 , 2003 .
[ 19 ] R . Ghosh and K . Lerman , “ Community detection using a measure of global influence , ” in SNA KDD’08 , 2008 .
303
