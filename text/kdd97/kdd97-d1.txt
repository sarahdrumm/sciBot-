From : AAAI Technical Report WS 98 07 . Compilation copyright © 1998 , AAAI ( wwwaaaiorg ) All rights reserved .
A Probabilistic
Approach to Fast Pattern Matching
Databases in Time Series
Eamonn Keogh Smyth* Department of Information and Computer Science and Padhraic
University of California , Irvine
CA 92697 3425
{eamonn , smyth}¢ics , uci . edu
Abstract
The problem of efficiently and accurately locating patterns of interest in massive time series data sets is an important and non trivial problem in a wide variety of applications , including diagnosis and monitoring of complex systems , biomedicM data analysis , and exploratory data analysis in scientific and business time series . In this paper a probabflistic approach is taken to this problem . Using piecewise linear segmentations as the underlying representation , local features ( such as peaks , troughs , and plateaus ) are defined using prior distribution on expected deformations from a basic template . Global shape information is represented using another prior on the relative locations of the individual features . An appropriately defined probabilistic model integrates the local and global information and directly leads to an overall distance measure between sequence patterns based on prior knowledge . A search algorithm using this distance measure is shown to efficiently and accurately find matches for a variety of patterns on a number of data sets , including engineering sensor data from space Shuttle mission archives . The proposed approach provides a natural framework to support user customizable "query by content" on time series data , taking prior domain information into account in a principled manner .
Introduction and Motivation
Massive time series data sets are commonplace in a variety of online monitoring applications in medicine , finance , and so forth . As an example , engineering , consider mission operations for NASA ’s Space Shuttle . Approximately 20,000 sensors are telemetered once per second to Mission Control at Johnson Space Center , Houston . Entire multi day missions are archived at this 1 Hz rate for each of the 20,000 sensors . From a mission operations viewpoint , only a tiny fraction of the data can be viewed in real time , and the archives are too vast to ever investigate . Yet , the data are potentially very valuable for supporting diagnosis , anomaly detection , and prediction . This is a
*Also with the Jet Propulsion Laboratory 525 3660 , Cal ifornia Institute of Technology , Pasadena , CA 91109 . familiar problem in archived time series storage : highdimensional data sets at very high resolution make manual exploration virtually In this paper we address impossible . the general problem of
( called a query Q ) the reference sequence matching a sequential pattern a time series database ( called /~ ) . We will assume that Q and R are each realvalued univariate sequences . Generalizations to multivariate and categorical valued sequences are of significant practical interest but will not be discussed here . To keep the discussion and notation simple we will assume that the sequence data are uniformly sampled ( ie , uniformly spaced in time ) . The generalization to the non uniformly sampled case is straightforward and will not be discussed . The problem is to find the k closest matches in R to the query Q . Most solutions to this problem rely on three specific components : ( 1 ) representation shape in some sense , ( 2 ) a distance measure for pairs sequence segments , and ( 3 ) an efficient search mechanism for matching queries to reference sequences . The contribution of this paper is primarily in components ( 1 ) and ( 2 ) . A piecewise linear representation scheme is proposed and combined with a generative probabilistic model on expected pattern deformations , leading to a natural distance metric incorporating relevant prior knowledge about the problem . technique which abstracts the notion of
Related
Work techniques for There are a large number of different efficient subsequence matching . The work of Faloutsos , Ranganathan , and Manolopolous ( 1994 ) is fairly typical . Sequences are decomposed into windows , feafrom each window ( locally estitures are extracted mated spectral coefficients in this case ) , and efficient matching is then performed using an R* tree structure in feature space . Agrawal et al . ( 1995 ) proposed alternative approach which can handle amplitude scaling , offset translation , and "don’t care" regions in the data , where distance is determined from the envelopes of the original sequences . Berndt and Clifford ( 1994 ) use dynamic time warping approach to allow for "elasticity" in the temporal axis when matching a query Q
52 the notion of shape . Relational to a reference sequence R . Another popular approach is to abstract trees can be used to capture the hierarchy of peaks ( or valleys ) in a sequence and tree matching algorithms can then be used to compare two time series ( Shaw and DeFigueiredo , 1990 ; Wang , et al . , 1994 ) .
A limitation of these approaches in general is that they do not provide a coherent language for expressing prior knowledge , handling uncertainty in the matching process , or integrating shape cues at both the local and global level . In this paper we investigate a probabilistic approach which offers a theoretically sound formalism for * . Integration of local and global shape information , . Graceful handling of noise and uncertainty , and ¯
Incorporation of prior knowledge in an intuitive manner .
The probabilistic approach to template matching is relatively well developed in the computer vision literature . The method described in this paper is similar in spirit to the recent work of Burl and Perona ( 1996 ) .
A Segmented Piecewise Linear
Representation
, 0
, 0.5
, 1
: 15
Seconds
, 2
: 25 x 104
Figure 1 : Automated segmentation of an inertial navigation sensor from Space Shuttle mission STS 57 . ( a ) original data , the first 7.5 hours of the mission , originally 27,000 data points , ( b ) the segmented version this sequence , K = 43 segments chosen by the multiscale merging algorithm described in the text . critically for representing seThere are numerous techniques quence data . The representation impacts the sensitivity of the distance measure to various distortions and also can substantially determine the efficiency of the matching process . Thus , one seeks robust to representations which are computationally efficient work with . Spectral representations are well suited to sequences which are locally stationary in time , eg , the direct use of Fourier coefficients ( as in Faloutsos et al . ( 1995 ) ) or parametric spectral models ( eg , Smyth , 1994 ) . However , many sequences , in particular those containing transient behavior , are quite non stationary and may possess very weak spectral signatures even locally . Furthermore , from a knowledge discovery viewpoint , the spectral methods are somewhat indirect . We are interested here in pursuing a representational language which can directly capture the notion of sequence shapes and which is intuitive as a language for human interaction .
There is considerable psychological evidence ( going back to Attneave ’s famous cat diagram , 1954 ) that the human visual system segments smooth curves into piecewise straight lines . Piecewise linear segmentations provide both an intuitive and practical method for representing curves in a simple parametric form ( generalizations to low order polynomial and spline representations are straightforward ) . There are a large number of different algorithms for segmenting a curve into linear segments ( eg , Pavlidis ( 1974) ) . We use a computationally efficient and flexible approach based on "bottom up" merging of local segments into a hierarchical multi scale the K "best" piecewise increase likelihood segmentation , where at each step the two local segin ments are merged which lead to the least squared error . Automated approaches to finding the best number of segments K can be based on statistical arguments ( penalized for example or Minimum Description Length as in Pednault ( 1991 ) for this problem ) . We found that for piecewise linear segmentations , simple heuristic techniques for finding good values of K worked quite well , based on halting the bottom up merging process when the change in approximation error in going from K to K 1 increased substantially . Figure 1 shows the segmentation of an inertial navigation sensor from the first 8 hours of a Space Shuttle mission by this method . For practical applications it may be desirable to have K chosen directly by the user to reflect a particular resolution at which matching is to be performed .
Probabilistic
Similarity Measures
Defining "similarity" metrics is a long standing problem in pattern recognition and a large number of dishave been tance measures based on shape similarity proposed in the literature . Typically these similarity measures are designed to have certain desirable properties such as invariance to translation or scaling .
Here we propose a probabilistic distance model template based on the notion of an ideal prototype to a prior which can then be "deformed" according probability distribution to generate the observed data . The model consists of local features which are then composed into a global shape sequence . The local features are allowed some degree of deformation and the
53 global shape sequence has a degree of elasticity allowing stretching in time and amplitude of the signal . The degree of deformation and elasticity are governed by prior probability distributions .
Specifically , let Q be a query sequence consisting of k local features , ie , Q = {ql , , q~} . For example , ql and q3 could be peaks and q2 could be a plateau . Let 14 , 1 < i < k 1 , be the observed distances between the centroids of feature i and feature i + 1 . Each I4 is a pair ( x4 , y4 ) containing the temporal distance and amplitude distance respectively . Let d4 , 1 < i < k , be the observed deformation ( defined in the next section ) between local feature q4 and the observed data at location i in the sequence . Let Dh = {dl , ¯ ,dk , be a particular tances corresponding to set of candidate features . We will refer to Dh as a candidate hypothesis . We can rank candidate hypotheses by evaluating the likelihood p(Dh ]Q ) . It remains to define the "generative" probability model p(Dh [ Q ) . set of observed deformations and dis ll,,lk t}
Models for p(Dh ]Q ) can be defined to varying levels of complexity depending on both ( 1 ) the independence structure of the model , and ( 2 ) the functional forms the component probability distributions . In this paper we illustrate the concept with a simple model which assumes feature independence and uses simple parametric distributions . However , in general , the model could incorporate much more complex dependencies such as pattern dependence on global "hidden" scale and deformation variables ( see Smyth , Heckerman and Jordan ( 1996 ) for a discussion of how to efficiently construct and utilize formalisms ) . For our simple model , we have : such models using graph theoretic q~ : ) p(DhlQ ) = p(dl , , & : , 11 , , = p(d lq ) l’I p(d , l lq4 ) k 1 lk llql , ,
4=1
( assuming local features are generated independently ) k 1 k 1
= 1 [ p( 41q4 ) rI p(z41q
4=I
4=i
( assuming deformations and distances are conditionally independent ) .
The models p(di ]q4 ) and p(li Iqi ) are chosen based on prior knowledge of how the features are expected to be deformed and "spread out." Again we illustrate with some relatively simple models . In this paper we use an exponential model for local deformation distances : p(d4 IQ ) = ;~e ~’’~’ , which imposes a monotonically decreasing prior belief the smaller the deformaon deformation distance , ie , tion , the observation came from Q . hi the more likely
54
Figure 2 : A simple query consisting of 2 feature shapes . The horizontal al , or equivalently , the degree of horizontal elasticity which is allowed between the 2 features . line at the bottom indicates is chosen to reflect the degree of expected deformation : large hi allows less deformation , small hi is more permissive .
The inter feature distance model for li = ( x4 , y~ ) a joint density on temporal and amplitude elasticity between features . One could for example use bivariate mixture models on xi and y~ to express complex beliefs on global shape patterns . Here we use a simpler model . We assume that Yi ( amplitude ) obeys a uniform distribution independent of x~ given q~ . We further assume that x4 obeys a lognormal distribution , or equivalently that log x4 has a Normal distribution with mean #/and variance e~ . #/ determines how far away features are expected to be and ~4 determines how "elastic" these distances are ( eg , see Figure 2 ) . and is conditionally
Given these particular models , it is straightforward to show that logp(Dh IQ ) log x4 P4
1
+
4 modulo a few extra conditions where this density is zero . Thus , the probabilistic model naturally defines a distance metric which integrates both local and global evidence weighted appropriately according to prior belief . For example , as the A ’s are increased , fidelity to local feature shape becomes more important than the distances between features .
Searching for High Likelihood Query
Matches
Local Feature Matching Local feature matching is performed by placing the start of the segmented feature at each breakpoint in the segmented reference sequence and computing the local distance for each location . We use a simple robust method for computing local deformation distances . Consider having placed a feature at a particular reference breakpoint : say there are l breakpoints project all in the feature and m breakpoints in the part of the reference sequence which does not extend beyond the end of the feature . We vertically l + m breakpoints to the "other sequence" to get l + m vertical "projection" distances . The overall deformation distance is defined as the standard deviation of these vertical projection distances . We have found this to be a robust and efficient way to locally match piecewise linear features . The output of this scanning process is a list of roughly K distances , where K is the number of segments in the reference sequence . For a query with Qf features , this process is repeated for each feature , resulting in a table of size Q/× K .
Queries
Finding Global High Likelihood Once we have built the table , we must then search it to find the best possible match for our compound query . The size of the search space scales exponentially with the number of features in the query so we rely on a variety of heuristic search techniques , including greedy ordering and branch and bound .
Search Complexity Let NR , NQ , and Nj be the number of data points in the ( unsegmented ) reference sequence , query subsequence , and feature subsequences , respectively ( asthat all features have the same sume for simplicity number of underlying data points ) . In a similar manner , let KR , KQ , and K1 be the number of segments in the segmented reference sequence , query subsequence , and feature subsequences , respectively . Let factor s = NR/KR NQ/Kq Nj/K ] be the scaling resulting from segmentation ( assumed the same across reference , query , and feature sequences for simplicity ) . Q/ denotes the number of features in query Q ( thus , Q/ = KQ/K ] = Nq/N ] in this simplified model ) .
1 tables
Qs ) s >> 1 . Finding the distance tables
The time complexity of finding takes O(N~f ) and O((NR/s ) the best match for a feature in a reference sequence using "brute force" correlation on the raw data ( aka sequential scanning ) is O(NRNj ) . The complexity of sequential scanning ¯ is O( 82 ) , where s > 1 , and on segmented data typically to running each of the set up a query search requires above searches Q/ times . Exhaustive query search on the distance for the unsegmented and segmented data respectively . The application of heuristic search techniques can retimes by a factor of ~ where 1 a is the duce these fraction of the search space elimmated by the heuristics . Thus , for unsegmented data and brute force search , the overall time complexity of matching a query scales as O(NRIV/+ g~’ ) , whereas for segmented data with heuristic query search has a time complexity of NRN + For large s and small the savings are substantial . The experimental results section ( below ) provides empirical run time data on real data sets .
Figure 3 : Results of matching the query in Figure 2 with the data in Figure 1 , showing the 2 best matches found .
Experimental
Results
Due to space limitations we can only present a small subset of our experimental results . Generally , the methods work as one might expect : the matching is relatively insensitive to the exact values of ~ and ~ and it is quite straightforward to specify query templates and prior distributions . In all of the experiments below , Ai is set such that the local deformation has a 50 % chance of being less than 0.25 ymax where yma× is i . The #i and the maximum vertical extent of feature cr~ parameters are chosen differently for each experiment and the uniform distribution on vertical elasticity between features is made broad enough to essentially make any vertical offsets irrelevant .
As mentioned earlier , the Space Shuttle Mission
~0 ,~0 ~0 ,0~
8econ~
,,~0
,~
,~
Figure 4 : Result of matching a complex query with 4 features on the Shuttle data in Figure 1 .
55
0
1000
2000
3000
4000
5000 6000
7000
8000
9000
Figure 5 : ( a ) 24 years of daily US 5 Year Treasury Constant Maturity Rate reports , originally 8749 points . ( b ) segmented into 400 segments using the multi scale merging algorithm . ( Axes in units of days for both figures )
0
I0
20
30 4o so
6o 7o so
90 too
344O 34a0 S4SO 3SO0 3s=o 3640 36e0 3seo
:)eoo
Figure 6 : A relatively simple query consisting of 2 feature shapes with ai shown horizontally at the bottom .
Data Archives consist of multiple sensors which are archived once per second for each multi day shuttle mission . We are investigating the use of fast query matching to support Shuttle mission operations , specifically to facilitate exploration of the vast mission archives for diagnosis , trouble shooting , and prediction tasks . Figure 2 shows a simple query on the sensor record in Figure 1 . The query consists of a steep valley followed by a gentle slope some time later . The mean distance between the two features is 48 minutes . Figure 3 shows the 2 best matches which were found : note that the "elasticity" as encoded by the relatively large value of ~ in Figure 2 allows for considerable flexibility in how far away the features are which can be matched . Figure 4 shows the result of matching a more complex query with 2 peaks separated by 2 linear segments .
Another example of the method is provided on the US Daily 5 Year Treasury Constant Maturity Rate . Figure 5 shows the original and segmented data , Figure 6 shows a particular query , a "corner" followed by a peak . Figure 7 shows the three best matches obtained , again showing the flexibility of the approach .
~
7e
Figure 7 : Results of matching the query in Figure 6 with the data in Figure 5 , showing the 3 best matches found , with the best at the top . The distance measures are shown alongside , normalized so that a distance of 0 is a perfect match . Axes are in units of days .
56 sequence data sets and queries . Numbers with asterisks than obtained from experimental results . The artificial
Table 1 : Experimental and estimated computation times for different different rather there is no corresponding raw data set to apply sequential scanning for these sequences . Exhaustive Table Search
Number of Segments
Number of Features search strategies on that these quantities were calculated indicate data were simulated as segmented waveforms , so and representations in Query Q
Name of Data Set Artificial Artificial Artificial Artificial Artificial Artificial Artificial Artificial Artificial Shuttle Shuttle Shuttle Treasury Treasury Treasury m/~ 20O 400 800 2OO 400 8OO 200 400 800 43 43 43 400 400 400
Sequential Scanning ( seconds )
Segment Matching ( seconds )
( seconds )
1 1 1 2 2 2 3 3 3 1 2 3 1 2 3
2.31 4.27 6.28 5.01 8.54 " 12.17 7.78 13.08 19.84 0.92 1.45 2.76 3.98 6.78 11.22
0 0.07 0.ii 148.28 598.61 2304.55 1728" 13824* 110592*
0.05 4.94 9.97 0.17 571.1 23000*
26603 53200* 79800*
912 2081 3014
Heuristic
Table Search
( seconds )
0 0.06 0.11 0.22 0.27 0.49 0.44 0.48 0.61 0.05 0.16 0.39 0.08 0.29 0.49 tend to use different
Experimental evaluation of pattern matching systo carry out in a rigorous tems are somewhat difficult manner . Researchers sequence and query data sets and there is no clear objective "gold standard" for measuring the quality of a particular scheme . An ideal state of affairs would be the widespread use of systematic evaluations on data sets which are common across different studies .
Table 1 summarizes computation times for finding the single best query over a variety of queries and sequences . From the table it is clear that segment matching can be much faster scanning of the raw data . For complex queries ( multiple features ) , heuristic search universally provides multiple order of magnitude speed ups over exhaustive search . than sequential
Acknowledgments
Part of the research described in this paper was carried out by the Jet Propulsion Laboratory , California Institute of Technology , under a contract with the National Aeronautics and Space Administration .
References
Agrawal , R . , Lin , K . I . , Sawhney , H . S and Shim , K . ’Fast Similarity Search in the Presence of Noise , Scaling , and Translation in Time Series Databases,’ In VLDB , pp.490 501 , September 1995 . Attneave , F . , ’Some informational aspects of visual perception,’ Psychol . Rev . , 61,183 193 , 1954 . Berndt , D . J . , Clifford , Warping to Find Patterns
’Using Dynamic Time in KDD
J . , in Time Series,’
57
94 : AAAI Workshop on Knowledge Discovery in Databases , 359 370 , Seattle , Washington , July 1994 . Burl , M . and Perona , P . ’Recognition of planar object classes,’ Proceedings of the 1996 Computer Vision and Pattern Recognition Conference , IEEE Press , 1996 .
SIGMOD Proceedings of Annual Con
Faloutsos , C . , Ranganathan , M . , Manolopoulos , Y . ’Fast Subsequence Matching in Time Series Databases,’ ference , Minneapolis , May 1994 . Pavlidis , T . , ’Waveform segmentation through functional approximation,’ IEEE Trans . Comp . , C 22 , no.7 , 689 697 , 1974 . Pednault , E . , ’Minimum length encoding and inductive in Databases , G . Piatetsky Shapiro and W . Frawley ( eds. ) , pp.71 92 , AAAI Press , 1991 . in Knowledge Discovery inference,’
Shaw , S . W . , Defigueiredo , R . J . P . , ’Structural Processing of Waveforms as Trees,’ IEEE Trans . ASSP , Vol.38 , No.2 , 328 338 , February 1990 . Smyth , P . , "Hidden Markov models for fault detection in dynamic systems," Pattern Recognition , 27(1 ) , 149 164 , 1994 . Smyth , P . , D . Heckerman , M . Jordan , ’Probabilistic independence networks for hidden Markov probability models,’ Neural Computation , 9(2 ) , 227 269 , 1997 . Wang , J . T . , Zhang , K . , Jeong , K and Shasha , D . ’A System for Approximate Tree Matching,’ IEEE TKDE . , 6 , no 2 April 1994 .
