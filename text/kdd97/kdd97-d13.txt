From : KDD 97 Proceedings . Copyright © 1997 , AAAI ( wwwaaaiorg ) All rights reserved .
Deep Knowledge Discovery from Natural Language Texts
Udo Hahn & Klemens Schnattinger m Computational Linguistics Lab Text Knowledge Engineering Group
Freiburg University , Werthmannplatz , D 79085 Freiburg , Germany
( hahn,schnattinger)@colinguni freiburgde http://wwwcolinguni freiburgde
Abstract
We introduce a knowledge based approach to deep knowledge discovery from real world natural language texts . Data mining , data interpretation , and data cleaning are all incorporated in cycles of quality based terminological reasoning processes The methodology we propose identifies new knowledge items and assimilates them into a continuously updated domain knowledge base .
Introduction
I,,, , ,
, 2,:I,+ : ,
& , 1 , ^^_ , ,a , ,
The work reported in this paper is part of a large scale project aiming at the development of SYNDIKATE , a Germaii lmg;uagc : CGAL lul ” wlc;ugc ; zmsIuuIiaLI ” ,I system ( Hahn , Schnattinger , & Romacker 1996 ) . ‘Iwo real world application domains are currently under active investigation test reports on information technology products ( 101 documents with lo5 words ) and , the major application , medical reports ( approximately 120,000 documents with lo7 words ) . The task of the system is to aggressively assimilate any facts , propositions and evaluative assertions it can glean from the source texts and feed them into a shared text knowledge pool . This goal is actually even more ambitious than the MUC task ( for a survey , cf . ( Grishman & Sundheim 1996 ) ) which requires mapping natural language texts onto a highly selective and fixed set of knowledge templates in order to extract factual knowledge items only .
Given that only a few of the relevant domain concepts can be supplied in the hand coded initial domain knowledge base , a tremendous concept learning problem arises for text knowledge acquisition systems . Any other KDD system running on natural language text input for the purpose of knowledge extraction also faces the challenge of an open set of knowledge templates ; even more so when it is specifically targeted at R~XJ knowledge items . In order to break the high complexity barrier of a system integrating text understanding and concept learning under realistic conditions , we supply a natural language parser ( Neuhaus & Hahn 1996 ) that is inherently robust and has various strategies to get nearly optimal results out of deficient , ie , underspecified 1 ., J ~~~~ *~ I E ~ .* I I . ~&J 3 ~&I ~~_ mowleage sources m rems 01 pamal , nmma aepm parsing . The price we pay for this approach is underspecification and uncertainty associated with the knowledge we extract from texts . To cope with these problems , we build on expressively rich knowledge representation models of the ‘Copyright 01997 , American Association for Artificial Intel ligence ( wwwaaaiorg ) All rights reserved . underlying domain ( Hahn , Klenner , & Schnattinger 1996 ) . Accordingly , we provide a start up core ontology ( such as the Penman Upper Model ( Bateman et al . 1990 ) ) in the format of terminological assertions . The task of the module we describe in this paper is then to position stew knowledge items which occur in a text in that concept hierarchy and to link them with valid conceptual roles , role fillers and role filler constraints ; hence , deep knowledge discovery .
In:Ta . ,a nnn.v n el e
Concept hypotheses reflecting different conceptual readings for new knowledge items emerge and are updated on the basis of two types of evidence . First , we consider the type of Zinguistic construction in which an unknown lexical :+a , n,,, ” ; . , , , +a%?+ L ,+? 4 ,A 1CU‘ll “ bbL&lJ 111 4 Cl2.L \JIUbtz we ( WDUUIFi L114l . UK cI ” IILcaL auu type of granunatical construction forces a particular interpretation on the unknown item ) ; second , conceptual criteria are accounted for which reflect structural patterns of consistency , mutual justification , analogy , etc . of concept hypotheses with concept descriptions already available in the domain knowledge base . Both kinds of evidence are represented by a set of qua&y labels . The general concept learning problem can then be viewed as a quality based decision task which is decomposed into three constituent parts : the continuous generation of quality labels for single concept hypotheses ( reflecting the reasons for their formation and their significance in the light of other hypotheses ) , the estimation of the overall credibility of single concept hypotheses ( taking the available set of quality labels for each hypothesis into account ) , and the computation of a.preference order for the entire set of competing hypotheses ( based on these accumulated quality judgments ) to select the most plausible ones . These phases directly correspond to the major steps underlying KDD procedures ( Fayyad , PiatetskyShapiro , & Smyth 1996 ) , viz . data mining , data interpretation , and data cleaning , respectively .
A Scenario for Deep Knowledge Discovery
‘2 ,
In order to illustrate our problem , consider the following knowledge discovery scenario . Suppose , your knowledge of the information technoloav domain tells vou that Aauar 1. ius is a company . In addition , you incidentally know that AS 168 is a computer system manufactured by Aquarius . By convention , you know absolutely nothing about MeImagine , one day your favorite computer magagaline . zine features an article starting with “ The Megaline unit by Aquarius ‘I Has your knowledge increamo , what did you learn already from just this phrase ?
, ~~~~
Hahn
175
3 : rl
IT cus here on the issues of learning accuracy and the learning rate . Due to the given learning environment , the measures we apply deviate from those commonly used in the machine learning community . In concept learning algorithms like IBL ( Aha , Kibler , & Albert 1991 ) there is no hierarchy of 2 Al llcTT L ql :COiiCeptS Hence , any preamuon 01 cue class memoersmp of a new instance is either true or false . However , as such hierarchies naturally emerge in terminological frameworks , a prediction can be more or less precise , ie , it may approximate the goal concept at different levels of specificity . This is captured by our measure of learning accuracy which takes into account the conceptual distance of a hypothesis to the goal concept of an instance rather than simply relating the number of correct and false predictions , as in IBL . r&e r r
Thnn . ^ __ I , jp~~??jqy wp . nrnnnse the m easgre __
In our approach , learning is achieved by the refinement of multiple hypotheses about the class membership of an instance . is concerned with the reduction of hypotheses as more and more information becomes available about one particular new instance . In contrast , IBL style algorithms consider only one concept hypothesis per learning cycle and their notion of learning rate relates to the increase of correct predictions as more and more instances are being processed . We considered a total of 101 texts taken from a corpus of information technology magazines . For each of them 5 to 15 learning steps were considered . A learning step is operationalized by the representation structure that results from the semantic interpretation of an utterance which contains the unknown lexical item . Since the unknown item is usually referred to several times in a text , several learning steps result . For instance , the learning steps associated with our scenario are given by : MEGALINE INST OF UNIT and MEGALINE PRODUCT OF AQUARIUS . of
Learning Accuracy In a first series of experiments , we investigated the learning accuracy of the system , ie , the degree to which the system correctly predicts the concept class which subsumes the target concept under consideration . Learning accuracy for a single lexical item ( LA ) is here defined as ( n being the number of concept hypotheses for that item ) :
LA
:= x iE{ltl}
LAi y with LA
:=
I
SPi specifies the length of the shortest path ( in terms of the number of nodes traversed ) from the TOP node of the concept hierarchy to the maximally specific concept subsuming the instance to be learned in hypothesis i ; CPi specifies the length of the path from the TOP node to that concept node in “ njipo’r ” leSiS ,i which is COiiiniOii boih for ihe shortest path ( as defined above ) and the actual path to the predicted concept ( whether correct or not ) ; FP, specifies the length of the path from the TOP node to the predicted ( in this case false ) concept and DPi denotes the node distance between the predicted node and the most specific concept correctly subsuming the target in hypothesis i , respectively . As an example , consider Fig 1 . If we assume MEGALINE to stand for a COMPUTER , then hypothesizing HARDWARE ( correct , but too general ) receives an LA = .75 ( note that OBJECT ISA TOP ) , while hypothesizing PRINTER ( incorrect , but still not entirely wrong ) receives an LA = 6
.
0.7
ALL
1.0 IACB
,__ : _ , : . . . i .i . . . . . . . . . . . . i ; ,
Fig 2 depicts the learning accuracy curve for the entire data set . It starts at LA values in the interval between 48 % to 54 % for LA , LA TH and LA CB in the first learning step . LA CB gives the accuracy rate for full qualifithe calculus cation including thresh 5 old and credibility criteria , LA TH considers linguist;c cg&pIa nnlv . 9 , while LA depicts the accuracy values without incorporating quality criteria at all , though terminological reasoning is still employed . In the final step , LA rises up to 79 % , 83 % and 87 % for LA , LA TH and LA CB , respectively . Hence , the pure terminological reasoning machinery which does not incorporate the qualification calculus always achieves an inferior level of learning accuracy than the learner equipped with it .
2 Figure 2 : Learning Accuracy
OA _ o.3 . 0.2 O.l ’ 1
9 10 11 12 13 14 15
6 Learningsteps
4
3
5
7
5 a
Learning Rate The learning accuracy focuses on the predictive power and validity of the learning procedure . By considering rate ( LR ) , we supply data from the stepthe learning wise reduction of alternatives in the learning process . Fig 3 depicts the mean number of transitively included concepts for all considered hypothesis spaces per learning step ( each concept hypothesis relates to concept which transitively subsumes various subconcepts ; hence , pruning of concept subhierreduces archies the number of concepts being considered as hypotheses ) . Note that the most general concept hypothesis in our example denotes OBJECT which currently includes 196 concepts . In _^^^_^ 1 __.^ 1 . ,^_^ 1 I ,.b . ,,* : , ,l, , , . A AL , , , ^ gwGLq WG “ “ SaVGlJ il auuul ; UG~slU ” c ; s,upc ; “ I Lllci GUIVG for the learning rate . After the first step , slightly less than 50 % of the included concepts are pruned ( with 93,94 and 97 remaining concepts for LR CB , LR TH and LR , respectively ) . Summarizing this evaluation experiment , the system yields competitive accuracy rates ( a mean of 87% ) , while at the same time exhibiting significant and valid reductions of the predicted concepts .
2 3 Figure 3 : Learning Rate
6 Learningsteps
9 10 11 12 13 14
’
1
4
5
7
8
5
Hahn
177
Related Work
The issue of text analysis is only rarely dealt with in the KDD community . The reason for this should be fairly obvious . Unlike pre structured data repositories ( eg , schemata and relations in database systems ) , data mining in textual sources requires to determine content based formal structures in text strings prior to putting KDD procedures to work . Similar to approaches in the field of information retrieval ( Dumais 1990 ) , statistical methods of text structuralization are favored in the KDD framework ( Feldman & Dagan 1995 ) . While this leads to the determination of associative relations between lexical items , it does not allow the identification and relation of particularfacts and assertions about or even evaluations to particular concepts . If this kind of deep knowledge is to be discovered , sophisticated natural language processing methodologies must come into play . Our approach bears a close relationship to the work of , eg , ( Rau , Jacobs , & Zernik 1989 ) and ( Hastings 1996 ) , who aim at the automated learning of word meanings from the textual context using a knowledge intensive approach . But our work differs from theirs in that the need to cope with several competing concept hypotheses and to aim at a reason based selection is not an issue in those studies . In the SCISOR system ( Rau , Jacobs , & Zernik 1989 ) , eg , the selection of hypotheses depends only on an ongoing discrimination process based on the availability of linguistic and conceptual clues , but does not incorporate a dedicated inferencing scheme for reasoned hypothesis selection . The difference in learning performance in the light of our evaluation study discussed in the previous section , at least ul‘ , “ U,,LU C ” ” 10 , U ” IIUIUUIIA,E ) LllV UlllWl ” ll ” Y “ “ L ” “ V ” ll U‘ ) omnnn+n ( plain terminological reasoning ) and LA CB values ( terminological me&reasoning based on the qualification calculus ) . Acquiring knowledge from real world textual input usually provides the learner with only sparse , highly fragmentary clues , such that multiple concept hypotheses are likely to be derived from that input . So we stress the need for a hypothesis generation & evaluation component as an integral part of large scale real world text understanders “ pcaar,Il~ 111 LaIIuwll WlLIl nu ” wls2 ” ~G uK%vv ay Uc2 ” IL,~D . e,,,, : , This requirement also distinguishes our approach from the currently active field of information extraction ( IE ) ( eg , ( Appelt et al . 1993) ) . The IE task is defined in terms of a$xed set of apriori templates which have to be instantiated ( ie , filled with factual knowledge items ) in the course of text analysis . In contradistinction to our approach , no new templates have to be created . r~.naL l~rinn rliff~vaanrw tn QUA hdrrrsan l,,l,A* ,
T.A
,I:,,,., , ,
A,,:, . , ” thra
,:+l
:
. . .
Tl
Conclusion
We have introduced a new quality based knowledge discovery methodology the constituent parts of which can be equated with the major steps underlying KDD procedures ( Fayyad , Piatetsky Shapiro , & Smyth 1996 ) the generation of quality labels relates to the data mining ( pattern extraction ) phase , the estimation of the overall credibility of a single concept hypothesis refers to the data interpretation phase , while the selection of the most suitable concept hypothesis corresponds to the data cleaning mode .
178
KDD 97 l nt lu4L
“ nnm ” 5~~1113
Our approach is quite knowledge intensive since knowledge discovery is fully integrated in the text understanding mode . No specialized learning algorithm is needed , since concept formation is turned into an inferencing task carried out by the classifier of a terminological reasoning system . Quality labels can be chosen from any knowledge “ , ,l,e,,P D ” UIb,cI ity . These labels also achieve a high degree of pruning of the search space for hypotheses in very early phases of the learning cycle . This is of major importance for considering our approach a viable contribution to KDD methodology . Acknowledgments . We would like to thank our colleagues in the CLIF group for fruitful discussions and instant support , in particular Joe Bush who polished the text as a native speaker . K . Schnattinger is supported by a grant from DFG ( Ha 2097/3 l ) .
I , “ a: Cl1113 cxJ ” II11~
~r\m:st b ” IIY~IIIGlIL ,
l dlAl Lu.qJL’I ” ll
A_ , c;clsy
I “ “
11 yya
~mnermnrld
Terhnirnl L ” “ YVYI rmw wt TVWlTCT ‘y.z ” .C , “ “ WI ” 1 .
References Aha , D . ; Kibler , D . ; and Albert , M . 199 1 . Instance based learning algorithms . Machine Learning 6:37 66 . Appelt , D . ; Hobbs , J . ; Bear , J . ; Israel , D . ; and ‘I@on , M . 1993 . FASTUS : A finite state processor for information extraction from real world text . In IJCAZ’93 Proc . 13th Intl . Joint ConJ( : on ArtiJicial Intelligence , 1172 l 178 . Bateman , J . ; Kasper , R . ; Moore , J . ; and Whitney , R . 1990 . A general organization of knowledge for natural language processing : The PFJNMAN A ” A A . l Dumais , S . 1990 . Text information retrieval . In Helander , M . , ed . , Handbook of Human Computer Interaction , 673 700 . Amsterdam : North Holland . Fayyad , U . ; Piatetsky Shapiro , G . ; and Smyth , I ? 1996 . From data mining to knowledge discovery in databases . AI Magazine 17(3):37 54 . Feldman , R . , and Dagan , I . 1995 . Knowledge discovery in textual T f in KUU 93 Proc . ist inti . Con& on Knowiedge databases ( WTj . Discovery and Data Mininn . Grishman , R . , and Sundhim , B . 1996 . Message understanding conference 6 : A brief historv . In COLZNG’96 Proc . 36th Ind ConJ : on Computational Linguistics , 466 471 . Hahn , U . , and Schnattinger , K . 1997 . A qualitative growth model for real world text knowledge bases . In RZAO’97 Proc . 5th Con& on Computer Assisted Information Searching on the Internet . Hahn , U . ; Klenner , M . ; and Schnattinger , K . 1996 . Learning from texts : A terminological metareasoning perspective . In Wermter , Y . , I.1IV11 , Y . ) UaaU YYUVI ” ‘ , A , UYY . , ~ “ rrr‘rv,r* “ r “ o‘ , “ ‘UI‘t‘IIU‘ U,‘U ,*,I 9 . Rilnff f 2 Symbolic Approaches to Learningfor Natural Language Processing , 453 468 . Berlin : Springer . Hahn , U . ; Schnattinger,~K . ; and Romacker , M . 1996 . Automatic knowledge accluisition from medical texts . In AMZA’96 Proc . AMZA Aim&Fall I%ploiting Hastings , F! 1996 . Implications of an automatic lexical acquiAti ^_._A , .l, L SIUOII 111 we111w21 , Connectionist , Statistical and Symbolic Approaches in Natural Language Processing , 261 274 . Berlin : Stringer . Neuhaus , P . , aid I&hn , U . 1996 . Trading off com$ete.ess for efficiency : The PARSETALK nerformance grammar aDDroach to real worid text parsing . In FtiZRS’96 P&z . 9th Fbzda Art@cial Intelligence Research Symposium , 60 65 . Rau , L . ; Jacobs , P . ; and Zemik , U . 1989 . Information extraction and text summarization using linguistic knowledge acquisition . Information ProcessinR & Management 2X4):419 428 . Schnatinger , K . , and Hahn, % . 1996.2 termino&ical oualification calculus for ureferential reasoning under unce&intv.?n KZ’96 Proc . 20th An&al German Con$ oiArh&ial 349362 . Berlin : Springer .
Symposium . Beyond the Superhighway : the Internet with Medical
l n * r m dnu
3 . acneler , u . , ea . , to Learning
Informatics , 383 387 . n n:l m n 0 . ; 3 . ;
.arln P,mnnrt;,m:rt
Intellig&ce ,
. nnrt Crhdnr
P* “ t:nr:rnl system .
KIIUII ,
F
