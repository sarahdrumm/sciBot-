Activity Analysis Based on Low Sample Rate Smart Meters Feng Chen1 Jing Dai2 Bingsheng Wang3 Sambit Sahu4 Milind Naphade5 Chang Tien Lu6 1 , 3 , 6 Computer Science Department , Virginia Tech
2 , 4 , 5 Watson Research Center , IBM
7054 Haycock Road
Falls Church , VA
19 Skyline Drive Hawthorne , NY
{1chenf , 3claren89 , 6ctlu} @vt.edu
{2jddai , 4sambits , 5naphade} @usibmcom framework
ABSTRACT Activity analysis disaggregates utility consumption from smart meters into specific usage that associates with human activities . It can not only help residents better manage their consumption for sustainable lifestyle , but also allow utility managers to devise conservation programs . Existing research efforts on disaggregating consumption focus on analyzing consumption features with high sample rates ( mainly between 1 Hz ~ 1MHz ) . However , many smart meter deployments support sample rates at most 1/900 Hz , which challenges activity analysis with occurrences of parallel activities , difficulty of aligning events , and lack of consumption features . We propose a novel statistical for disaggregation on coarse granular smart meter readings by modeling fixture characteristics , household behavior , and activity correlations . This framework has been implemented into two approaches for different application scenarios , and has been deployed to serve over 300 pilot households in Dubuque , IA . Interesting activity level consumption patterns have been identified , and the evaluation on both real and synthetic datasets has shown high accuracy on discovering washer and shower . Categories and Subject Descriptors H28 [ Database Management ] : Database Applications General Terms Algorithms , Design , Experimentation , Performance Keywords Smart Meter , Low Sample Rate , Disaggregation , Classification , Hidden Markov Model , Gaussian Mixture Model . 1 . INTRODUCTION Sustainability and design of sustainable technologies have become urgent and the unprecedented level of resource demand water , energy , transit , healthcare , public safety to every imaginable service that makes a city attractive and desirable . At the same time , digital reification of cyber physical world has been possible with widespread penetration of sensing and monitoring technologies . These two important catalysts have fuelled significant interest and cross organizational collaboration among researchers , industries , urban planners , and government . A lot of technology and research has important priority for cities given innovative approaches recently focused on leveraging information from such digital reification of cyber physical world to help manage various services more efficiently . Our paper takes a step in that direction examines the feasibility and provides towards influencing people ’s consumption behavior . More precisely , we provide activity analysis based on smart water meter readings . Given the real world constraints , we research the feasibility of activity analysis to identify activities from smart utility meter readings . Our study is based on the hypothesis that consumption activities disaggregated from meter readings will empower residents with appropriate insights to influence and shape their behavior . This has been rightly validated through a city wide survey [ 1 ] followed by four month long experimentation with a real city [ 2 ] . In addition , from disaggregated consumption , utility managers can design and assess conservation programs , and prioritize energy saving potential retrofits . Research on disaggregating electricity or water load has been conducted on smart meter readings with fine granularity ( mainly between 1 Hz ~ 1MHz ) . Existing approaches identify appliances/ fixtures based on analyzing steady state or transient state change in real time consumption . However , they are not suitable for many existing smart meter infrastructure . Real world deployments of smart meters are designed for utility billing and some basic analysis requirement , but many of them are not suitable for consumption disaggregation . Smart meters transmit consumption readings using wireless protocols , which consume battery and have dependency on physical environments . Although the meters can sample at a rate even higher than 1MHz , many of existing deployments have chosen to accumulate to 15 min or even longer intervals to ensure reliable data transmission . However , physical environment may still affect the data transmission . This scenario brings to consumption disaggregation : 1 ) Parallel usage activities , eg , a toilet flush and shower in the same 15 minute interval . 2 ) Difficulty of aligning usage events temporally , eg , a shower may appear in one or two intervals . 3 ) Lack of features , ie , only aggregated consumption and start time of each interval can be used to identify usage activity . An example of such water meter data and expected disaggregated activities is illustrated in Figure 1 . following challenges the
Toilet
Washer
Toilet Washer Washer Washer Washer Dishwasher
Figure 1 . An Example of Data and Disaggregated Activities .
Toilet Toilet
Two Showers
Toilet
To handle these challenges , we have designed a novel statistical framework for activity analysis on coarse granular smart water
240 meter readings , and deployed it as a component in Smarter Water Service for Dubuque , IA . In this framework , fixture characteristics , household behavior , and activity correlations are utilized to disaggregate consumption . To implement this framework , we propose two approaches to identify activities . The first approach applies hidden Markov model to capture the relationship among consumption events and hidden activities . The second approach utilizes classification techniques to learn from labeled activities , and a Gaussian mixture model is used for disaggregation . The proposed approaches have been validated using both real world water consumption and synthetic datasets . The experiments have the proposed disaggregation demonstrated framework , for disaggregation in various applications , and revealed interesting usage insights from 300+ pilot households . In summary , the major contributions of this work include :
Providing activity level consumption insights to residents and the city management team to support decision making . the capability of illustrated appropriate
Designing a general disaggregation framework with two sample rate the implementations for different scenarios . Exploring appropriate smart meter sample rate to enable consumption disaggregation .
Revealing interesting consumption patterns from the disaggregation results .
This paper is organized as follows : Section 2 illustrates the application deployment for the proposed approach , and introduces the related challenges . A novel general statistical framework for is proposed disaggregation in Section 3 . The detailed implementations for water consumption disaggregation are described in Section 4 . Section 5 evaluates the performance of the proposed approaches under different scenarios with real world and synthetic datasets and demonstrates some interesting findings from the pilot households . The related work is reviewed in Section 6 . Finally , Section 7 concludes our work with future directions . 2 . BACKGROUND & PROBLEM 2.1 Application Deployment
300+ Pilot Homes
Wireless Gateway
City
FTP site
IBM Cloud delivered Solution
15 min hourly
Anonymous Data
6 Volunteers
10 sec Reading ; Water Journal
Manually uploaded
Figure 2 . Data Acquisition .
The activity analysis is an important function provided in Smarter Water Service based on smart water meters . The deployed environment of our smart water meter infrastructure is shown in Figure 2 . Since August 2010 , over 300 pilot households have volunteered to install Neptune R900 smart water meters [ 3 ] with UFR ( Unmeasured Flow Reducer ) , which transmit a new aggregated reading roughly every 15 minutes through 900MHz wireless connection . Each aggregated reading is broadcasted repeatedly within the entire interval to ensure the success of logger which transmission . Wireless gateways have been deployed in the city to collect these readings , attach timestamps , and send to a data center through 3G network every hour . In addition , 6 volunteer households had applied data records water consumption every 10 seconds , and had done water usage activity journaling accordingly for a week . All the meter readings have been anonymized and sent to IBM Computing Cloud for analytics . The software architecture of the deployment is visualized in Figure 4 . The smart meter data are first cleaned and transformed by InfoSphere Information Server®(IIS ) , and then stored in a Smart Meter Database managed by DB2® . On top of this database , Cognos® to provide OLAP functions such as consumption metric and pattern monitoring ; a java based module is developed to perform advanced analytics functions such as disaggregation and prediction . IBM WebSphere Application Server®(WAS ) hosts the service layer to allow users interact with the services . In addition , a community engagement component plays the role of motivating residents through competition and collaboration via multiple media channels . The whole system , as a $850K deployment engagement with Dubuque , IA , has been deployed on IBM Smarter Cities Sustainable Model Cloud , and provides services to residents ( 300+ pilot households ) and the city management team ( about 10 government employees)[2 ] . is utilized
Smarter Cities Sustainability Model Cloud
Smarter Water Services Layer
( WAS )
CITY/ UTILITY ( ~10 users )
Disaggregation and Other Analytics
( Custom analytics ( Java ) )
Metric Monitoring and Insights
( Cognos Express )
Community Engagement
RESIDENTS ( 300+ users )
Information Integration and Sensor Data Management
( IIS , DB2 )
Smart Water Meter
Data Stream
Figure 4 . Smarter Water Service Architecture .
The main objective of this Smarter Water Service is to provide affective services that can help the volunteers modify their behavior to be more sustainable , in other words , let the residents know what they need to know to change their behavior . To achieve that goal , one important process is to reveal disaggregated water consumption , so that the users can know where in their houses they could conserve water , and sustainable operations or investment can be suggested . As a component of Smarter Water Service , activity analysis shared the computing resources with the other custom analytics . It works as a backend service that outputs activity level consumption distribution reports every month from 15 minute aggregated consumption . This component will continuously provide consumption insights as part of the Smarter Water Service , and will be updated by enhancing learning ability and expanded to the expected 4000 households with hourly readings by 2013 . summary has
A preliminary shown 6.6 % normalized accumulative consumption reduction in 8 weeks after the Smarter Water Service was published in September 2010 . In addition , a survey conducted in December 2010 showed that since September ,
Interval Consumption Con(T )
Event
Extraction
Events e(T )
Model
Selection & Training
Estimated Distribution Model D(E(T);θ )
Events of Parallel Activities P(e(T ) )
Parallel Activities Detection
Parallel Size Estimation
Size of Parallel Activities |et
( s)|
Hidden Activity
Identification
Parallel Activities at
( s )
Consumption Decomposition
Activityevent Pairs ( a , e)(T )
Figure 3 . Disaggregation Framework .
241 out of 64 respondents , 15 households had fixed leaks , 13 respondents had shortened their showers , and 14 purchases on water efficient toilet/appliances had been made . 2.2 Problem & Definitions The problem of disaggregation from coarse granular smart water meter readings can be informally described as follows : Problem : Given a sequence of aggregated consumption ( cid:2159)(cid:2197)(cid:2196)(cid:4666)(cid:4667)(cid:4666)(cid:1829)(cid:1867),…,(cid:1829)(cid:1867)(cid:4667 ) , where ( cid:1829)(cid:1867 ) refers to the  (cid:3435)(cid:4666)(cid:1827),(cid:1831)(cid:4667),…,(cid:4666)(cid:1827)(cid:3038),(cid:1831)(cid:3038)(cid:4667)(cid:3439 ) that are most aggregated consumption ( cid:2159)(cid:2197)(cid:2196)(cid:4666)(cid:4667 ) , where ( cid:1827 ) refers to an activity state ( eg , washer , shower , or toilet uses ) , and ( cid:1831 ) refers to an aggregated water consumption at the i th time interval , the proposed activities the of to cause observation ( event ) of water consumption for this activity state and is represented by a vector of event features , including total water consumption and start/end time intervals . The related terms and their definitions are summarized in Table 1 , and will be used in the rest of the paper . We use capital letters to denote random variables and small letters to denote observations . interval water set a likely solution should return
Table 1 . Terms & Definitions .
Symbol
Definition
Term
Consumption
Interval
Activity
Event
Event sequence
Parallel activities Events of parallel activities
Parallel sub events
Con Int
Amount of water used in terms of gallons . The time period between 2 consecutive meter readings . Integer value that represents one of the following : sink , toilet , shower , and washer . A vector of features to represent an event . The event features include total consumption , start/end time , etc . A sequence of events occurs in a time window ( eg , 24 hours ) , where T is the number of events .
( cid:1827 ) ( cid:1831 ) ( cid:4666)(cid:1831),…,(cid:1831)(cid:4667 ) ( cid:4666)(cid:1827)(cid:3047),…,(cid:1827)(cid:3047)(cid:3046)(cid:4667 ) s activities occur together in event Et A set of events in ( cid:4666)(cid:1831),…,(cid:1831)(cid:4667) generated by ( cid:4666)(cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3046)(cid:4667 ) generates the event (cid:1831)(cid:3047 ) . Each sub event ( cid:1831)(cid:3047 ) is generated by a single activity (cid:1827)(cid:3047 ) . parallel activities . A set of parallel sub events whose aggregation
P(E(T ) )
2.3 Research Challenges General challenges for usage disaggregation from single main meter include the following : 1 ) Appliances/fixtures with similar consumption patterns , eg , certain sink usage and a toilet flush ; 2 ) Appliances/fixtures with multiple settings , eg , normal , dedicated , and permanent of a washer ; 3 ) Load variation , eg , low , medium , and full load of a washer , or length of showers ; 4 ) Multiple cycles , eg , washer and dishwasher ; 5 ) Lack of real world ground truth , ie , hard to collect sufficient labeled data from consumers . Disaggregation with the above challenges can be treated as a realworld classification problem . In addition , the specific application scenario introduced in the previous section brings more challenges because of the coarse granularity and unstable reading intervals caused by unreliable communication . These limitations cause : 1 ) Parallel usage activities , eg , two toilet flushes and a shower in the same 15 minute interval . 2 ) Difficulty of aligning usage events temporally , eg , a shower may appear in one or two intervals . 3 ) Lack of features , ie , only aggregated consumption and start time of each interval can be used to identify usage activity . These specific challenges make the task of water usage disaggregation more than a classification problem and difficult to solve . The existing disaggregation approaches focus on analyzing steady state or transient state changes . They cannot handle the specific challenges in this scenario , because no steady state or transient state can be detected with such a low sample rate .
2.4 Observations Due to the challenges discussed , the aggregated consumption of each interval alone surely cannot provide confident disaggregation results . We need to investigate the available ground truth on what other factors may help improve the disaggregation accuracy . After a study over the activity journaling from the volunteers , we have found three useful characteristics of water usage activities : fixturedependant , household dependant , and time dependant . 241 Fixture dependant Pattern Each fixture category has its own usage pattern in term of consumption and duration that can be used to distinguish it from the others . Specifically , the amount of water consumed in a toilet flush usually fell in several small ranges between 1.5 ~ 5 gallons , and was consistent for a specific toilet . A load of washer generally lasted between 30~60 minutes , and consisted of multiple cycles with similar water usage . Showers had consistent flow rate most of the time , and lasted from 5 minutes to 15 minutes in most cases . Sink usage was usually short in time and low in consumption . These patterns can help briefly categorize the usage events . For example , any interval with flow rate lower than 0.1 gallons per 15 minutes can be filtered out as sink usage . However , using a fixture specification library is not enough to identify parallel activities , or to deliver customized models for each household . 242 Household dependant Pattern Activity patterns heavily depend on the fixture models and occupants of a specific household . For example , households with kids generally spent more time on shower every day ; households with open leaks showed continuous usage for a long time ; some households have 3 toilets and each has a different specification . Therefore , each household needs to be modeled separately to ensure accurate disaggregation . These models can be learned from historical consumption records and household profiles if available . 243 Time dependant Pattern According to human behavior , some activities may happen frequently during a specific time period , which can be used to distinguish ambitious water usage . One interesting example of such pattern is shower . Most of the labeled showers happened either close to the first event of usage in the morning or close to the first event after work . Although toilet flush occurred almost any time in a day , it was less frequent in working hours and midnight than the rest of a day . Not only time of day , but also day of week has been found drawing impacts on activity patterns . An example could be washer usage which happened mostly during weekends in some households . In addition , some activities are found temporally associated . For instance , a toilet flush in many cases was followed by a short sink usage for hand washing . According to the timedependant activity patterns , timestamps of usage events should be able to improve disaggregation results significantly . 3 . A NEW STATISTICAL
DISAGGREGATION FRAMEWORK
Coarse granular smart meter readings cause a large portion of parallel activities , and disaggregation of parallel activities has become a critical and important challenge . This section introduces a new General Disaggregation Framework ( GDF ) to address the disaggregation problem . As illustrated in Figure 3 , the GDF framework applies six phases to disaggregate water consumption . The work flow is described as follows : Phase 1 Event extraction : Given a sequence of aggregated interval consumption (cid:2159)(cid:2197)(cid:2196)(cid:4666)(cid:4667)(cid:4666)(cid:1829)(cid:1867),…,(cid:1829)(cid:1867)(cid:4667 ) , the intervals with continuous consumption are grouped to generate events where
242 Phase 2 Model selection and training : Select an appropriate each represents one activity or parallel activities . The output of this phase is an event observation sequence of a given time window :
( cid:2187)(cid:4666)(cid:4667)(cid:4666)(cid:1857),(cid:1857)(cid:2870),…,(cid:1857)(cid:4667 ) . Hence , ( cid:2187)(cid:4666)(cid:4667 ) is regarded as one observation of the event random variables (cid:2161)(cid:4666)(cid:4667)(cid:4666)(cid:1831),(cid:1831)(cid:2870),…,(cid:1831)(cid:4667 ) . Each event ( cid:1831 ) may be generated by a hidden activity ( cid:4666)(cid:1827)(cid:4667 ) or several parallel hidden activities (cid:4666)(cid:1827),…,(cid:1827)(cid:3046)(cid:4667 ) . stochastic model (cid:2160)(cid:3435)(cid:2161)(cid:4666)(cid:4667);(cid:2242)(cid:3439 ) , such as HMM or GMM , and estimate parameters ( cid:2242)(cid:3553 ) based on historical labeled or unlabeled observations . stochastic model (cid:2160)(cid:3435)(cid:2161)(cid:4666)(cid:4667);(cid:2242)(cid:3553)(cid:3439 ) , the events with parallel activities ( cid:2172)(cid:3435)(cid:2187)(cid:4666)(cid:4667)(cid:3439 ) can be identified from anomalous events (cid:2171)(cid:3435)(cid:2187)(cid:4666)(cid:4667)(cid:3439 ) .  (cid:2171)(cid:3435)(cid:2187)(cid:4666)(cid:4667)(cid:3439)(cid:3419)(cid:1857)(cid:3047) |(cid:1857)(cid:3047)(cid:1488)(cid:2174)(cid:3435)(cid:2161)(cid:4666)(cid:3047)(cid:4667)(cid:2187)(cid:4666)(cid:3047)(cid:4667),(cid:2009)(cid:3439)(cid:3423 ) , where ( cid:2161)(cid:4666)(cid:3047)(cid:4667 ) ( cid:4666)(cid:1831),…,(cid:1831)(cid:3047),(cid:1831)(cid:3047),…,(cid:1831)(cid:4667 ) , ( cid:2187)(cid:4666)(cid:3047)(cid:4667)(cid:4666)(cid:1857),…,(cid:1857)(cid:3047),(cid:1857)(cid:3047),…,(cid:1857)(cid:4667 ) . ( cid:2174)(cid:4666)(cid:1668)(cid:4667 ) refers to the outlying region of normal event ( cid:1831)(cid:3047 ) that is defined based on the conditional distribution of ( cid:3427)(cid:1831)(cid:3047)| (cid:2161)(cid:4666)(cid:3047)(cid:4667)(cid:2187)(cid:4666)(cid:3047)(cid:4667)(cid:3431 ) and a confidence level ( cid:2009 ) ( eg , 099 ) The calculation of outlying regions
Anomalous events can be obtained using leave one out test , ie ,
Phase 3 Parallel activity detection : Given the estimated to the water consumption , the earliest start time , and the latest end time of
( 1 ) the parallel activities ( random based on HMM and GMM models will be discussed in Section 4 . This phase assumes all anomalous events are generated due to parallel activities . An anomalous event may also be generated by true abnormal activities such as a shower lasting more than an hour . However , it is difficult to differentiate these only based on coarse granular meter readings . Hence , we only consider parallel activities . Phase 4 Parallel size estimation : For each anomalous event is that heavy consumption ( a washer load ) can always be decomposed into a large number of small activities ( eg , toilet flushes ) , which is not reasonable . Phase 5 Hidden activity identification : For each abnormal observation (cid:1857)(cid:3047)(cid:1488)(cid:1841)(cid:3435)(cid:2187)(cid:4666)(cid:4667)(cid:3439 ) , the number of parallel activities that generate (cid:1857)(cid:3047 ) can be estimated by min(cid:3419)|(cid:1857)(cid:3047)(cid:1488)(cid:2174)(cid:3002)(cid:3034)(cid:3034 ) ( cid:3435)(cid:2161)(cid:4666)(cid:3047)(cid:4667)(cid:2187)(cid:4666)(cid:3047)(cid:4667),(cid:1827)(cid:1859)(cid:1859)(cid:4666)(cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3046)(cid:4667),(cid:2009)(cid:3439)(cid:3423 ) where ( cid:4668)(cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3046)(cid:4669 ) refers variables ) whose aggregation generates the event ( cid:1857)(cid:3047 ) , ( cid:1827)(cid:1859)(cid:1859) (cid:4666)(cid:1668)(cid:4667 ) refers to the vector of aggregated features , and ( cid:2174)(cid:3002)(cid:3034)(cid:3034 ) ( cid:4666)(cid:1668)(cid:4667 ) refers to the normal region of the aggregated features ( cid:1827)(cid:1859)(cid:1859)(cid:4666)(cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3046)(cid:4667 ) . ( cid:1827)(cid:1859)(cid:1859)(cid:4666)(cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3046)(cid:4667 ) returns aggregated features , such as the total the sub events (cid:4668)(cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3046)(cid:4669 ) . The reason of selecting the minimal s event (cid:1831)(cid:3047)(cid:1488)(cid:1841)(cid:4666)(cid:1831)(cid:4667 ) , given  , the estimated size of parallel activities , this phase estimates the disaggregated activities ( cid:4668)(cid:1853)(cid:3047),…,(cid:1853)(cid:3047)(cid:3046)(cid:4669 ) : ( cid:4666)(cid:1853)(cid:3047),…,(cid:1853)(cid:3047)(cid:3046)(cid:4667)arg ( cid:4666)(cid:3028)(cid:3295)(cid:3117),…,(cid:3028)(cid:3295)(cid:3294)(cid:4667)(cid:1488)(cid:4668),…,(cid:3040)(cid:4669)(cid:3294)Pr(cid:3435)(cid:1827)(cid:3047)(cid:1853)(cid:3047),…,(cid:1827)(cid:3047)(cid:3046)(cid:1853)(cid:3047)(cid:3046) | (cid:2161)(cid:4666)(cid:3047)(cid:4667 ) max ( cid:2187)(cid:4666)(cid:3047)(cid:4667),Agg(cid:4666)(cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3046)(cid:4667)(cid:1857)(cid:3047)(cid:4667 ) , where ( cid:1865 ) is the total number of activity types ( eg , shower , washer ) . parallel activities ( cid:4668)(cid:1853)(cid:3047),…,(cid:1853)(cid:3047)(cid:3046)(cid:4669 ) estimated in Phase 5 , the related ( cid:3435)(cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:3047)(cid:4667),…,(cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:3047)(cid:3046)(cid:4667)(cid:3439 ) ( cid:3004)(cid:3042)(cid:4666)(cid:3032)(cid:3295)(cid:3117)(cid:4667),…,(cid:3004)(cid:3042)(cid:4666)(cid:3032)(cid:3295)(cid:3294)(cid:4667)(cid:1838)(cid:3435)(cid:1829)(cid:1867)(cid:4666)(cid:1831)(cid:3047)(cid:4667)(cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:3047)(cid:4667),…,(cid:1829)(cid:1867)(cid:4666)(cid:1831)(cid:3047)(cid:3046)(cid:4667 ) arg max ( cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:3047)(cid:3046)(cid:4667)|(cid:2161)(cid:4666)(cid:3047)(cid:4667)(cid:2187)(cid:4666)(cid:3047)(cid:4667),(cid:1827)(cid:3047)(cid:1853)(cid:3047),…,(cid:1827)(cid:3047)(cid:3040 ) ( cid:1853)(cid:3047)(cid:3046),(cid:1827)(cid:1859)(cid:1859)(cid:4666)(cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3046)(cid:4667)(cid:1857)(cid:3047)(cid:4667 ) , ( cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:3047)(cid:4667 ) is where ( cid:1838 ) is consumption feature of the sub event observation ( cid:1857)(cid:3047),i1,,s intervals (cid:2159)(cid:2197)(cid:2196)(cid:4666)(cid:4667)(cid:4666)(cid:1829)(cid:1867),…,(cid:1829)(cid:1867)(cid:4667 ) , GDF is able to identify true hidden activities  (cid:3435)(cid:4666)(cid:1827),(cid:1831)(cid:4667),…,(cid:4666)(cid:1827)(cid:3038),(cid:1831)(cid:3038)(cid:4667)(cid:3439 ) of ( cid:2159)(cid:2197)(cid:2196)(cid:4666)(cid:4667 ) , if the following water consumption of these hidden activities can be estimated as : ( 3 )
To evaluate the correctness of GDF , we have the theorem as : Theorem : Given a sequence of aggregated consumption
Phase 6 Consumption decomposition : Given the hidden likelihood function , and the
( 2 ) assumptions are satisfied : a ) In Phase 1 , The events can be correctly identified and the features extracted are sufficient ; b ) The distribution ( cid:2160)(cid:3435)(cid:2161)(cid:4666)(cid:4667);(cid:2242)(cid:3439 ) is correctly selected and estimated ; c ) All distribution of hidden activities of (cid:2159)(cid:2197)(cid:2196)(cid:4666)(cid:4667 ) . It follows that the anomalous events are due to parallel activities ; d ) The minimal s selected in Phase 4 is correct . Proof Sketchy : The four conditions stated above assure that the built statistical model by GDF is consistent with the true activities identified by GDF are most probable results and should be consistent with true hidden activities . 4 . DISAGGREGATION APPROACHES This section presents two approaches based on GDF to handle different disaggregation scenarios . When there is no sufficient training data available , which is true in many real world scenarios , we propose an approach to learn hidden relationship among consumption events and activities without user input based on hidden Markov model ( HMM ) . When labeled activities are available for training , we design the second approach to construct statistical models using classification techniques and disaggregate parallel activities using Gaussian mixture model ( GMM ) . 4.1 HMM based Approach This section presents an implementation of GDF based on HMM . It is trained based on unlabeled data and performs disaggregation without user input . For the purpose of simplicity , each event ( cid:1831 ) is represented by a single feature , the total water consumption . Other features , such as start/end time intervals , and duration can be included to this approach in a straightforward manner . 411 Event Extraction ( GDF Phase 1 ) The key challenge of event extraction is the segmentation process . Without labeled historical data , it is necessary to define a set of heuristic rules to generate meaningful events based on domain knowledge . The basic criterion is to keep adjacent interval consumption in a single event if they possibly relate to one activity or parallel activities . This is to avoid the situation where one activity is divided to two separate events , which is not recoverable in our approach . If two nonparallel activities are mistakenly grouped to one event , they can still be identified in the consequent disaggregation process . Similar to the idea of hierarchical clustering , a bottom up based segmentation algorithm is proposed as follows : Step 1 : Preprocessing . Remove leaking effects , and filter out all zero consumption intervals . Step 2 : Initialization . Regard each left interval as one event .
Then we have the sequence of initial events (cid:4666)(cid:1857),…,(cid:1857)(cid:3038)(cid:4667 ) , where ( cid:1863 ) is threshold (cid:1282 ) ( eg , 5.5 gallons for 15 minute size intervals ) . For each continuous event pair (cid:4666)(cid:1857),(cid:1857)(cid:4667 ) , if ( cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:4667)(cid:3408)(cid:2036 ) and (cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:4667)(cid:3408)(cid:2036 ) , merge ( cid:1857 ) and ( cid:1857 ) . Repeat until no such pair exists . Step 4 : Merging light events . For each event ( cid:1857 ) with (cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:4667)(cid:3408 ) ( cid:2036 ) , if 0(cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:4667 ) , then merge ( cid:1857 ) and (cid:1857 ) . Similarly , if 0 ( cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:4667 ) , then merge ( cid:1857 ) and (cid:1857 ) . If there is an event ( cid:1857 ) with 0 ( cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:4667 ) , and both ( cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:4667 ) and ( cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:4667 ) greater than (cid:1282 ) , then ( cid:1857 ) ( (cid:1829)(cid:1867)(cid:4666)(cid:1857)(cid:4667),(cid:1829)(cid:1867)(cid:3435)(cid:1857)(cid:3439 ) ) if ( cid:1856)(cid:1861)(cid:3435)(cid:1857), (cid:1857)(cid:3439)τ , where ( cid:1856)(cid:1861)(cid:3435)(cid:1857), (cid:1857)(cid:3439 ) ( cid:3046)(cid:3047)(cid:3028)(cid:3045)(cid:3047)(cid:3435) (cid:1857)(cid:3439)(cid:3032)(cid:3031)(cid:4666)(cid:1857)(cid:4667 ) , and ( cid:3046)(cid:3047)(cid:3028)(cid:3045)(cid:3047)(cid:4666)(cid:1668)(cid:4667 ) and ( cid:3032)(cid:3031)(cid:4666)(cid:1668)(cid:4667 ) refer to the start if its total water consumption is greater than a threshold γ ( eg , 20 the number of nonzero consumption intervals . Step 3 : Merging heavy events . Define a water consumption is merged to the segment with the smallest consumption . Step 5 : Merging peak events . Merge and end time of an event respectively . We define an event as a peak two peak events gallons ) . This step is specifically designed for fixtures like washers ,
243 which consists of multiple peaks with more than 15 minutes empty cycle ( no water consumption ) between peaks . 412 HMM Parameter Estimation ( GDF Phase 2 ) A hidden Markov model is usually trained based on EM algorithm , which can only guarantee local optimum . Given a large number of parameters to be estimated in a HMM model , including the number of hidden states , the initial probabilities , the emission distribution of each state , and the transition matrix , it is critical to find appropriate initial settings for these parameters . By empirical evaluation , we decided a mixture model of three Gaussians for sink events , and Gaussian models for other activity events . This section presents a heuristic based approach to seek initial settings for each household based on generic domain knowledge : Step 1 : Toilet identification . Hierarchical clustering is applied on events to identify toilet clusters . By domain knowledge , toilet clusters could be identified by requiring the cluster size to be greater than 3 times the total number of days in the training data , and the consumption standard deviation smaller than 0.5 gallons . Step 2 : Sink identification . Sink events can be identified as the events with consumption lower than ( cid:4666)(cid:2020)2(cid:1499)(cid:2026)(cid:4667 ) , where ( cid:2020 ) and ( cid:2026 ) are the mean and standard deviation of the toilet cluster with the smallest mean consumption in all toilet clusters . Step 3 : Frequent pattern identification . After removing sink events and toilet clusters , hierarchical clustering is applied on the remaining events to identify other qualified clusters . In order to control the HMM complexity , we only keep the 12 clusters with the smallest standard deviation . Step 4 : Cluster labeling . This step gives labels to the qualified clusters based on predefined rules such as a shower usage should be within 5~25 gallons . If some clusters are still not labeled , we label these clusters as “ others ” , which may relate to some unknown activity state or frequent combination of parallel activities . Step 5 : Anomaly removal . The anomalous events are identified based on a Gaussian mixture distribution estimated from qualified clusters . These outliers will impact the training of HMM , therefore they are removed from training data . Step 6 : Probability estimation . Regarding each qualified cluster as a hidden state , we can get the number of hidden states , the mean and standard deviation of each hidden state . The transition matrix and initial probabilities can be estimated based on labeled events . 413 Disaggregation and Labeling ( GDF Phase 3 6 ) First , several notations are defined as follows . The set of activity states is (cid:4668)1,…,(cid:1865)(cid:4669 ) , ( cid:1830 ) is an ( cid:1865 ) by ( cid:1865 ) transition matrix , ( cid:2024 ) is the initial probability of the ( cid:1865 ) states , ( cid:1868)(cid:4666)(cid:1857)(cid:3047) (cid:4667)(cid:1842)(cid:4666)(cid:1831)(cid:3047)(cid:1857)(cid:3047) | (cid:1827)(cid:3047)(cid:1861)(cid:4667 ) , and ( cid:4666)(cid:4667)(cid:1842)(cid:4666)(cid:1827)(cid:3047)(cid:1861)(cid:4667 ) . For the purpose of simplicity , we assume that each event ( cid:1831)(cid:2930 ) conditioned on activity state ( cid:1827)(cid:3047 ) follows a Gaussian distribution ( cid:4670)(cid:1831)(cid:3047)|(cid:1827)(cid:3047)(cid:1861)(cid:4671) ~ (cid:2280)(cid:3435)(cid:2020),(cid:2026)(cid:2870)(cid:3439 ) . Note Let (cid:1842)(cid:4666)(cid:1857)(cid:4667)(cid:3429)(cid:1868)(cid:4666)(cid:1857)(cid:4667 ) 0 0 0 ( cid:1868)(cid:3046)(cid:4666)(cid:1857)(cid:4667)(cid:3433)(cid:1488)(cid:1337)(cid:3046)(cid:3400)(cid:3046),(cid:2009)(cid:3047)Pr(cid:4666)(cid:1857),…,(cid:1857)(cid:3047),(cid:1827)(cid:3047)(cid:4667)(cid:1488)(cid:1337)(cid:3046 ) , 0 0 … 0 ( cid:2009)(cid:3047)(cid:4666)(cid:1853)(cid:3047)(cid:4667)(cid:2009)(cid:3047)Pr(cid:4666)(cid:1857),…,(cid:1857)(cid:3047),(cid:1827)(cid:3047)(cid:1853)(cid:3047)(cid:4667)(cid:1488)(cid:1337),(cid:2010)(cid:3047)Pr(cid:4666)(cid:1857)(cid:3047),…,(cid:1857)|(cid:1827)(cid:3047)(cid:4667)(cid:1488)(cid:1337)(cid:3046 ) , ( cid:2010)(cid:3047)(cid:4666)a(cid:2930)(cid:4667)Pr(cid:4666)(cid:1857)(cid:3047),…,(cid:1857)|(cid:1827)(cid:3047)(cid:1853)(cid:3047)(cid:4667)(cid:1488)(cid:1337),and (cid:1828)(cid:3047)(cid:1830)(cid:1842)(cid:4666)(cid:1857)(cid:3047)(cid:4667 ) . The probability density function  ( cid:1842)(cid:3435)(cid:1831)(cid:3047)(cid:1857) | (cid:1831)(cid:4666)(cid:3047)(cid:4667)(cid:1857)(cid:4666)(cid:3047)(cid:4667)(cid:3439)(cid:2009)(cid:3047 ) ( cid:1830)(cid:1842)(cid:4666)(cid:1857)(cid:4667)(cid:2010)(cid:3047 ) ( cid:2009)(cid:3047 ) ( cid:1830)(cid:2010)(cid:3047 ) ( cid:3533)(cid:1875)(cid:4666)(cid:4667)(cid:1868)(cid:4666)(cid:1857)(cid:4667 ) , where ( cid:1875)(cid:4666)(cid:4667 ) ( cid:3031)(cid:3284)(cid:4666)(cid:3047)(cid:4667 ) ,(cid:1856)(cid:4666)(cid:4667)(cid:4670)(cid:2009)(cid:3047 ) ( cid:1830)(cid:4671)(cid:4670)(cid:2010)(cid:3047)(cid:4671 ) . It indicates that ( cid:3427)(cid:1831)(cid:3047)(cid:1857) | (cid:1831)(cid:4666)(cid:3047)(cid:4667)(cid:1857)(cid:4666)(cid:3047)(cid:4667)(cid:3431 ) follows a GMM : ( cid:3031)(cid:3285)(cid:4666)(cid:3047)(cid:4667 ) ∑ ( cid:3288)(cid:3285)(cid:3128)(cid:3117 ) the following derivations can also be straightforwardly extended to Gaussian mixture distributions .
The HMM implementations of GDF Phase 3 to 6 are as follows : GDF Phase 3 : Parallel activity detection that
( cid:3427)(cid:1831)(cid:3047)(cid:1857) | (cid:1831)(cid:4666)(cid:3047)(cid:4667)(cid:1857)(cid:4666)(cid:3047)(cid:4667)(cid:3431) ~ (cid:3533)(cid:1875)(cid:4666)(cid:4667)(cid:2280)(cid:4666)(cid:1876)|(cid:2020),(cid:2026)(cid:2870)(cid:4667 ) ( cid:2174)(cid:3435)(cid:2187)(cid:4666)(cid:3047)(cid:4667),(cid:2009)(cid:3439)(cid:3420)(cid:1857)(cid:3628)| (cid:1857)(cid:2020)(cid:3038)(cid:1499)|(cid:3408)(cid:2026)(cid:3038)(cid:1499)Φ(cid:3436)1(cid:2009)2 ( cid:3440)(cid:3424 ) ,
The outlying region of the GMM model can be calculated as where ( cid:1863)(cid:1499 ) is the Gaussian component closest to ( cid:1857 ) , and ( cid:2004)(cid:4666)(cid:1668)(cid:4667 ) is the
It implies that
By linear transformation , we have that cumulative density function ( CDF ) of a standard Gaussian distribution . Here , we assume that the statistics of outlying events are dominated by the component closest to the observation . This outlying region estimation has been justified in [ 4 ] using extreme value statistics . GDF Phase 4 : Parallel size estimation The probability density function
( cid:1842)(cid:3435)(cid:1831)(cid:3047)(cid:1857)(cid:3047),…,(cid:1831)(cid:3047)(cid:3046)(cid:1857)(cid:3047)(cid:3046) | (cid:2187)(cid:4666)(cid:3047)(cid:4667)(cid:3439)(cid:2009)(cid:3047 ) ∏ ( cid:4668)(cid:1830)(cid:1842)(cid:4666)(cid:1857)(cid:3047)(cid:4667)(cid:4669 ) ( cid:2010)(cid:3047 ) ( cid:3046)(cid:2880 ) ( cid:2009)(cid:3047 ) ( cid:1830)(cid:3046)(cid:2010)(cid:3047 ) ( cid:3533 ) ( cid:1875)(cid:3039)(cid:3117),…,(cid:3039)(cid:3294)(cid:1842)(cid:3039)(cid:3117)(cid:4666)(cid:1857)(cid:3047)(cid:4667)(cid:1668)(cid:1668)(cid:1668)(cid:1842)(cid:3039)(cid:3288)(cid:4666)(cid:1857)(cid:3047)(cid:3046)(cid:4667 ) , where ( cid:1875)(cid:3039)(cid:3117),…,(cid:3039)(cid:3288 ) is the weight that can be calculated based on the ( cid:4666)(cid:3039)(cid:3117),…,,(cid:3039)(cid:3294)(cid:4667)(cid:1488)(cid:4668),…,(cid:3040)(cid:4669)(cid:3294 ) ( cid:1668)(cid:2010)(cid:3047)(cid:4669)/(cid:2009)(cid:3047 ) ( cid:1830)(cid:3046)(cid:2010)(cid:3047 ) . form ( cid:4668)(cid:2009)(cid:3047 ) ( cid:1668)∏ ( cid:4668)(cid:1830)(cid:1842)(cid:4666)(cid:1857)(cid:3047)(cid:4667)(cid:4669 ) ( cid:3046)(cid:2880 ) ( cid:3427)(cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3046) | (cid:2161)(cid:4666)(cid:3047)(cid:4667)(cid:2187)(cid:4666)(cid:3047)(cid:4667)(cid:3431) ~ ( cid:3533 ) ( cid:1875)(cid:3039)(cid:3117),…,(cid:3039)(cid:3294)(cid:2280)(cid:4672)(cid:3427)(cid:2020)(cid:3039)(cid:3117),…,(cid:2020)(cid:3039)(cid:3294)(cid:3431),diag(cid:3435)(cid:2026)(cid:3039)(cid:3117)(cid:2870),…,(cid:2026)(cid:3039)(cid:3294)(cid:2870)(cid:3439) (cid:4673 ) ( cid:4666)(cid:3039)(cid:3117),…,,(cid:3039)(cid:3294)(cid:4667)(cid:1488)(cid:4668),…,(cid:3040)(cid:4669)(cid:3294 ) ( cid:3427)(cid:1831)(cid:3047)(cid:3397)(cid:1668)(cid:1668)(cid:1668)(cid:3397)(cid:1831)(cid:3047)(cid:3046) | (cid:2161)(cid:4666)(cid:3047)(cid:4667)(cid:2187)(cid:4666)(cid:3047)(cid:4667)(cid:3431)~ ( cid:3533 ) ( cid:1875)(cid:3039)(cid:3117),…,(cid:3039)(cid:3294)(cid:2280)(cid:3436)(cid:3533 ) ( cid:2020)(cid:3039)(cid:3284 ) .  (cid:3440 ) ,(cid:3533 ) ( cid:2026)(cid:3039)(cid:3284)(cid:2870 ) ( cid:3046)(cid:3038)(cid:2880 ) ( cid:3046)(cid:3038)(cid:2880 ) that here  (cid:1827)(cid:1859)(cid:1859)(cid:4666)(cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3040)(cid:4667)(cid:1831)(cid:3047)(cid:3397)(cid:1668)(cid:1668)(cid:1668)(cid:3397)(cid:1831)(cid:3047)(cid:3046 ) . Since ( cid:4666)(cid:3039)(cid:3117),…,,(cid:3039)(cid:3294)(cid:4667)(cid:1488)(cid:4668),…,(cid:3040)(cid:4669)(cid:3294 ) ( cid:3427)(cid:1827)(cid:1859)(cid:1859)(cid:4666)(cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3040)(cid:4667)| (cid:2161)(cid:4666)(cid:3047)(cid:4667)(cid:2187)(cid:4666)(cid:3047)(cid:4667)(cid:3431 ) follows a Gaussian mixture distribution , the normal region ( cid:2174)(cid:3002)(cid:3034)(cid:3034 ) ( cid:4666)(cid:1668)(cid:4667 ) can be estimated similarly Pr(cid:3435)(cid:1827)(cid:3047)(cid:1853)(cid:3047),…,(cid:1827)(cid:3047)(cid:3046)(cid:1853)(cid:3047)(cid:3046) | (cid:2161)(cid:4666)(cid:3047)(cid:4667)(cid:2187)(cid:4666)(cid:3047)(cid:4667),(cid:1831)(cid:3047)(cid:3397)(cid:1710)(cid:3397)(cid:1831)(cid:3047)(cid:3046)(cid:1857)(cid:3047)(cid:3439 ) ( cid:1857)(cid:3047)|(cid:1853)(cid:3047),…,(cid:1853)(cid:3047)(cid:3046)(cid:4667)(cid:2010)(cid:3047)(cid:3046)(cid:4666)(cid:1853)(cid:3047)(cid:3046)(cid:4667 ) ( cid:2009)(cid:3047)(cid:4666)(cid:1853)(cid:3047)(cid:4667)∏ Pr(cid:3435)(cid:1853)(cid:3047)(cid:4666)(cid:4667)|(cid:1853)(cid:3047)(cid:3439 ) , ( cid:3046)(cid:2880 ) where ( cid:1838 ) is the likelihood of the whole sequence and can be neglected when solving the problem ( cid:4666)2(cid:4667 ) . Note that the random variables ( cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3046 ) are independent to each other given their hidden activity states (cid:1827)(cid:3047),…,(cid:1827)(cid:3047)(cid:3046 ) . The probability density function Pr(cid:4666)∑ ( cid:1831)(cid:3047)(cid:3038 ) ( cid:1857)(cid:3047)|(cid:1853)1,…,(cid:1853)(cid:4667 ) can be calculated by simple linear ( cid:3038 ) Given the hidden activity states (cid:4668)(cid:1853)(cid:3047),…,(cid:1853)(cid:3047)(cid:3046)(cid:4669 ) , we have that ( cid:4670)(cid:1831)(cid:3047),…,(cid:1831)(cid:3047)(cid:3046) | (cid:1853)(cid:3047),…,(cid:1853)(cid:3047)(cid:3046)(cid:4671) ~ (cid:2280)(cid:4666)(cid:2246),(cid:2227)(cid:4667 ) ,  (cid:2246)(cid:3427)(cid:2020)(cid:3028)(cid:3295)(cid:3117),…,(cid:2020)(cid:3028)(cid:3295)(cid:3294)(cid:3431),(cid:2227)diag(cid:3435)(cid:2026)(cid:3028)(cid:3295)(cid:3117)(cid:2870 ) ,…,(cid:2026)(cid:3028)(cid:3295)(cid:3294)(cid:2870)(cid:3439 ) . solution of the problem ( cid:4666)3(cid:4667 ) can be obtained as [ 5 ] ( cid:4670)(cid:1857)(cid:3047),…,(cid:1857)(cid:3047)(cid:3046)(cid:4671)T(cid:2246)(cid:2227)(cid:2778)(cid:4666)(cid:2778)(cid:2227)(cid:2778)(cid:4667)(cid:4666)(cid:2778)(cid:2246)(cid:1857)(cid:3047)(cid:4667 ) . as in the above GDF Phase 3 . GDF Phase 5 : Hidden activity identification The probability density function transformation of independent Gaussian random variables . GDF Phase 6 : Consumption decomposition
Pr(cid:4666)∑ ( cid:1831)(cid:3047)(cid:3038 ) ( cid:1838 ) ( cid:3038 )
Note
The optimal
  where
4.2 Classification GMM based Approach Different from the HMM based approach , this section presents a mixed model approach to the disaggregation problem that requires labeled data for training . It first applies a classification model ( eg , support vector machine , neural network , and k nearest neighbor classifier ) to classify each event as a single activity , or a known
244 421 Event Extraction ( GDF Phase 1 ) This phase first applies the same procedure as in Section 321 to frequent combination of parallel activities , or an unknown infrequent combination of parallel activities . For the events classified to the last category ( unknown infrequent combinations ) , it applies an implementation of the GDF framework based on GMM to disaggregate parallel activities . Assume that we are given a sequence of aggregated interval consumption (cid:2159)(cid:2197)(cid:2196)(cid:4666)(cid:3117)(cid:4667)(cid:3435)(cid:1829)(cid:1867)(cid:1499),…,(cid:1829)(cid:1867)(cid:3117)(cid:1499)(cid:3439 ) and the related hidden activities  (cid:3435)(cid:4666)(cid:1853)(cid:1499),(cid:1857)(cid:1499)(cid:4667),…,(cid:4666)(cid:1853)(cid:3038)(cid:1499),(cid:1857)(cid:3038)(cid:1499)(cid:4667)(cid:3439 ) as the labeled training data . The objective is to build a model on ( cid:2159)(cid:2197)(cid:2196)(cid:4666)(cid:3117)(cid:4667 ) that can identify unknown hidden activities ( cid:3435)(cid:4666)(cid:1853),(cid:1857)(cid:4667),…,(cid:4666)(cid:1853)(cid:3038),(cid:1857)(cid:3038)(cid:4667)(cid:3439 ) of a new aggregated intervals consumption sequence (cid:2159)(cid:2197)(cid:2196)(cid:4666)(cid:4667)(cid:4666)(cid:1829)(cid:1867),…,(cid:1829)(cid:1867)(cid:4667 ) . identify a sequence of events . Here each ( cid:1857 ) has six features , which The event extraction phase returns an event sequence (cid:4666)(cid:1857),…,(cid:1857)(cid:3038)(cid:4667 ) , where each ( cid:1857 ) is represented by a vector of six features ( (cid:1857)(cid:1488)(cid:1337)(cid:2874) ) . ( cid:4666)(cid:1857),…,(cid:1857)(cid:3038)(cid:4667 ) as a set of independent training instances : ( cid:4668)(cid:1857),…,(cid:1857)(cid:3038)(cid:4669 ) . Based on the labels (cid:4666)(cid:1853)(cid:1499),(cid:1857)(cid:1499)(cid:4667),…,(cid:4666)(cid:1853)(cid:3038)(cid:1499),(cid:1857)(cid:3038)(cid:1499)(cid:4667 ) , it is able to identify hidden activities of each event (cid:1857 ) . To decide class labels , not only include the start time , duration , total consumption , minimal interval consumption , maximal interval consumption , and number of peaks . 422 Classification ( GDF Phase 2 )
Note that all the features are mapped to real type values , in order to apply classification models such as SVM and neural network . Here , we neglect the dependencies between events and treat single activities ( eg , toilet , shower , and washer ) are treated as distinct classes , but also frequent combinations of parallel activities are regarded as distinct classes . The current setting is that frequent parallel activities should occur at least once per week . 423 GMM based Disaggregation ( GDF Phase 3 6 ) After the classification process , each event has been labeled as a single activity , or known/unknown combination of parallel activities . For parallel activities , a GMM based implementation of the GDF framework is proposed to disaggregate parallel activities . The basic procedures are as follows :
Based on the labels of training events (cid:4668)(cid:1857),…,(cid:1857)(cid:3038)(cid:4669 ) , it is able to each event (cid:1857 ) . Each single activity related event ( (cid:1831)(cid:3047 ) ) can modeled by a Gaussian mixture distribution as ( cid:1831)(cid:3047)~∑ ( cid:2024)(cid:2280)(cid:3435)(cid:2020),(cid:2026)(cid:2870)(cid:3439 ) , where ( cid:2024 ) is the prior probability of the activity state (cid:1861 ) , and ( cid:2280)(cid:3435)(cid:2020),(cid:2026)(cid:2870)(cid:3439 ) is the event distribution of activity (cid:1861 ) . Given an event ( cid:1857)(cid:3047 ) that is classified as parallel activities , the  (cid:3435)(cid:4666)(cid:1853)(cid:3047),(cid:1857)(cid:3047)(cid:4667),…,(cid:4666)(cid:1853)(cid:3047)(cid:3046),(cid:1857)(cid:3047)(cid:3046)(cid:4667)(cid:3439 ) with ( cid:1827)(cid:1859)(cid:1859)(cid:4666)(cid:1857)(cid:3047),…,(cid:1857)(cid:3047)(cid:3046)(cid:4667)(cid:1857)(cid:3047 ) . Here the aggregation function ( cid:1827)(cid:1859)(cid:1859 ) is the summation function ∑(cid:4666)(cid:1668)(cid:4667 ) . The ( cid:1833)(cid:1830)(cid:1832 ) disaggregation framework can be employed here , which can collect training instances for each activity state , such as toilet , shower , and washer . For simplicity , in this disaggregation step , we only consider a single feature ( the total water consumption ) , for objective is to identify the most probable hidden activities
( cid:3040)(cid:2880 ) be regarded a simplified case of HMM based approach . Readers are referred to [ 15 ] for detailed specifications . 5 . EVALUATION & FINDINGS The framework has been implemented using JDK 1.5 and deployed in the Custom Analytics Layer of the Smarter Water Service ( Figure 4 ) . Pie charts of activity consumption distribution are generated to illustrate how each fixture has been used on monthly basis . From the Smarter Water Service layer interface , the residents can browse their own consumption distribution ; meanwhile , the government agency and utility manager can explore how water has been consumed by each activity at regional level .
Both HMM based and GMM based approaches have been implemented and evaluated . Specifically , for the GMM based approach , we have assessed three classification methods , k Nearest Neighbor classification ( kNN GMM ) , Artificial Neural Network ( ANN GMM ) , and Support Vector Machine ( SVM GMM ) accordingly . Given the available labeled activities , the evaluation focused on identifying toilet flushes , showers , and washer loads . To evaluate the effectiveness of consumption disaggregation on identifying these activities , we adopted three metrics , precision , recall , and F measure . The major reason of using these metrics is that the disaggregation evaluation is similar to an information retrieval process , where subsets of intervals represent certain true activities and the testing results are also subsets of intervals labeled as activities . The metrics need to capture not only how many labels are matched , but also how many true activities are missed and how many false labels are placed . These metrics are defined as follows : Precision refers to the portion of matched activities within the corresponding disaggregation results ; Recall refers to the portion of matched activities within the corresponding true activities ; Fmeasure is the harmonic mean of precision and recall . To evaluate the proposed disaggregation solution , we have applied both HMM based and GMM based approaches on the consumption of 6 volunteer households , as well as 50 simulation datasets that were generated based on their labeled consumption . In addition , we varied the sample rate in these datasets to investigate its impact on disaggregation results . The correlation between sample rate and effectiveness can provide guidance to future planning and deployment of human activity analysis applications . Due to the lack of labeled activities from most of the pilot households , we only applied the HMM based model to analyze activities of the 300+ pilot households . Some interesting patterns discovered can illustrate common human behavior characteristics . 5.1 Datasets A real world dataset was collected from 6 volunteer households . It consists of 1/10 Hz water reading and the corresponding usage journaling records for 7 days . The usage journaling was input manually by these volunteers , so it always has approximated timestamps and missing activities , which introduce inaccuracy which needs to be handled carefully . Note that these households came showed significantly different consumption patterns . A summary of labeled activities from one volunteer is listed in Table 2 as an example . from various demographic categories and
Table 2 . Water Journaling of One Household .
Occurrences
71 57 366 217 68 186
5 5 9 43 33 N/A
7 % 6 % 38 % 24 % 7 % 19 %
Total Amount Percentage
Fixture Shower 1 Shower 2 Washer Toilet 1 Toilet 2 Others ( sink & unlabeled ) 50 simulation datasets were generated by simulating occurrences and corresponding consumption of activities according to their distributions in the labeled dataset from the 6 volunteer households . Firstly , from the labeled activities , the number of instances of each activity in a week was estimated using Poisson distribution . Each instance was randomly assigned to a day and time according to the distributions of labeled activities in day of week and time of day domains . These distributions were captured by activity occurrence histograms generated from labeled activities and smoothed by kernel density . Once date and start time of an instance was determined , its consumption and duration was randomly picked from a dictionary of the corresponding labeled activities . Finally , consumption noise of each day was randomly picked from 42 ( 6
245 households * 7 days ) samples , of which each contains unlabeled consumption ( <2 gallons ) of a whole day . In this way , simulated consumption data for 6 months were generated in each dataset . A live dataset was constructed from the 15 min consumption of all the pilot households since August 2010 . This dataset has inconsistent reading intervals all the time , missing readings due to communication failure , and even water leaks that can impair the disaggregation results . 5.2 Parameter Settings & Baseline Methods For HMM based approach , the major settings are as follows : 1 ) in GDF Phase 1 ( event extraction ) Step 3 ( merging heavy events ) , the threshold ( cid:1282 ) was set to 5.5 gallons ; 2 ) in GDF Phase 1 ( event extraction ) Step 5 ( merging peak events ) , the thresholds τ and γ were set to 15 minutes and 20 gallons , respectively ; 3 ) in GDF Phase 2 ( HMM parameter estimation ) Step 4 ( cluster labeling ) , the clusters with mean consumption between 1.2 gallon and 6 and frequency greater than two times per day were labeled as toilets ; the clusters with mean consumption between 8 and 30 were labeled as showers ; the clusters with mean consumptions between 30 and 55 gallons were labeled as washers ; the clusters with frequency smaller than 1 times per day were disregarded ; and the left clusters were labeled as “ others ” ; 4 ) the number of states in HMM was decided automatically ( See GDF Phase 2 step 3 ) . Note that all the preceding parameters were decided based on domain experiences . For kNN GMM based approach , the event extraction phase was the same as that in HMM based approach . Note that the same event extraction process was also used in all other compared approaches . The kNN classifier used in the experiments was provided by MATLAB 2008a Bioinformatics Toolbox . One major parameter is the number of nearest neighbors used in the classification . We applied 10 folder cross validation to select the best k from the candidate values from 5 to 15 . For ANN GMM based approach , the neural network classifier was provided by MATLAB 2008a Neural Network Toolbox . We used one per class cording for multiclass classification . In one perclass coding , each output neuron is designated the task of identifying a given class . The output code for that should be 1 at this neuron and 0 for others . We used Levenberg Marquardt backpropagation , which is the default training algorithm in MATLAB . 10 folder cross validation was used to select the best parameter “ the number of hidden layers ” in the range from 2 layers to 8 layers . Other parameters were the default settings . Note that , another popular training algorithm is “ Gradient descent back propagation ” with two major parameters “ learning rate ” and “ the number of hidden layers ” . We have also tried this training algorithm in experiments . But results indicate that the LevenbergMarquardt backpropagation method is more accurate and efficient . For SVM GMM based approach , the SVM classifier was provided by LIBSVM [ 6 ] . We used the popular radial basis function as the kernel function . There are two parameters including cost ( c ) and gamma ( g ) . These two parameters were tuned by 10 folder cross validations , and the best parameters was selected from different combinations of the cost parameter ( c ) range : ( cid:1864)(cid:1867)(cid:1859)(cid:2870)(cid:4666)(cid:1855)(cid:4667)1:0.25:5 , and the gamma parameter ( g ) range: (cid:1864)(cid:1867)(cid:1859)(cid:2870)(cid:4666)(cid:1859)(cid:4667)7:025:1 We used the “ one against one ” method for multiclass classification . Two baseline approaches , named random pick and knapsack based , were applied to evaluate the effectiveness of the above four proposed methods . The random pick method is described as follows : First , conduct the same event extraction as in HMM based method ; second , the events with consumption smaller than 2 gallons are labeled as sink uses ; third , the left events are randomly labeled to toilet , shower , and washer uses .
The knapsack based method is described as follows : First , conduct the same event extraction as in HMM based method ; second , knapsack each segment to the best combination of the following activities : “ Toilet old ( 1.6 gallons ) ” , “ Toilet new ( 4 gallons ) ” , “ Shower Low flow ( 15 gallons ) ” , “ Shower Standard ( 30 gallons ) ” , “ Laundry ( 50 gallons ) ” , and “ Sink ( <=1.6 ) ” . 5.3 Effectiveness Comparison To demonstrate the effectiveness of proposed approaches , we used the labeled activities from water journaling and the simulation datasets as ground truth , and compared the proposed approaches . The comparison was conducted among 4 versions of disaggregation approaches , HMM , kNN GMM , ANN GMM , and SVM GMM ; and the two baseline solutions , random pick and knapsack . Cross validation was applied to find the best parameters for the corresponding classification methods . As shown in Table 3 , all the proposed approaches achieved about 95 % precision on shower identification , while the recall was relatively low ( 77~81% ) . It was because the deviation of shower consumption is very high in real life . In many cases , consumption of a shower may be similar to that of two toilet flushes , or a frontload washer . Therefore , some true showers could not be correctly identified . But once an activity is labeled as a shower , it ’s very likely to be true . Although these four methods performed similarly on labeling showers , SVM GMM achieved the highest scores . Table 3 . Precision , Recall , and F measure on Simulation Data .
Toilet
Mean ( Standard
Shower
Washer
Mean ( Standard
Mean ( Standard
Precision , Recall , F measure HMM kNN GMM
ANN GMM
SVM GMM
Random Pick
Knapsack
Deviation ) 0.7704 ( 0.08 ) , 0 . 6651 ( 0.04 ) , 0.7110 ( 0.04 ) 0.7291 ( 0.07 ) , 0.8552 ( 0.03 ) , 0.7850 ( 0.04 ) 0.5982 ( 0.05 ) , 0.8709 ( 0.03 ) , 0.7075 ( 0.04 ) 0.4669 ( 0.07 ) , 0.8873 ( 0.02 ) , 0.6086 ( 0.06 ) 0.1022 ( 0.03 ) , 0.0531 ( 0.01 ) 0.0699 ( 0.02 ) 0.0655 ( 0.01 ) , 0.1534 ( 0.02 ) 0.0918 ( 0.02 )
Deviation ) 0.9471 ( 0.04 ) , 0.7883 ( 0.04 ) , 0.8594 ( 0.03 ) 0.9552 ( 0.02 ) , 0.7723 ( 0.05 ) , 0.8530 ( 0.03 ) 0.9584 ( 0.03 ) , 0.7670 ( 0.06 ) , 0.8505 ( 0.04 ) 0.9622 ( 0.02 ) , 0.8057 ( 0.05 ) , 0.8761 ( 0.03 ) 0.1514 ( 0.03 ) , 0.1608 ( 0.04 ) 0.1560 ( 0.03 ) ) 0.4570 ( 0.05 ) , 0.3294 ( 0.05 ) , 0.3828 ( 0,05 )
Deviation ) 0.7839 ( 0.06 ) , 0.9610 ( 0.04 ) , 0.8620 ( 0.04 ) 0.8536 ( 0.06 ) , 0.8937 ( 0.09 ) , 0.8702 ( 0.06 ) 0.8554 ( 0.08 ) , 0.8994 ( 0.12 ) , 0.8710 ( 0.09 ) 0.8613 ( 0.06 ) , 0.9329 ( 0.06 ) , 0.8940 ( 0.04 ) 0.0737 ( 0.02 ) , 0.3237 ( 0.10 ) 0.1201 ( 0.07 ) 0.8619 ( 0.16 ) , 0.3516 ( 0.13 ) 0.4995 ( 0.19 )
Different to shower , washer loads were disaggregated with very high recall ( 89~96% ) , and relatively low precision ( 78~86% ) . Generally , cloth washer is the heaviest and meanwhile the least frequent activity on water consumption in a household . Based on the specifications and settings of a washer , its water consumption is usually consistent . That ’s the reason why almost all of the washer instances can be learned and identified . On the other hand , a washer usage usually crosses multiple intervals . This usage pattern may be similar to certain combinations of other consumption . Therefore , some other consumption was classified as washer by the disaggregation approaches . In overall , SVM GMM achieved the best overall performance , and HMM got the highest recall .
Detecting toilet flushes is the most difficult task comparing to shower and washer . Because toilet usage typically happens very frequently and costs a small amount of water , it is hard to be distinguished from sink usage in 15 minute interval , or be identified when combined with heavy activities such as a shower or a washer load . All the four approaches had F measure between 61 % and 78 % . HMM was the only approach with precision higher than recall . KNN GMM performed the best in terms of F measure .
Due to the small number of training data ( <= 4 days per house ) , GMM based approaches failed to disaggregate consumption on the
246 volunteer households . As shown in Table 4 , HMM perfectly identified the washer usage , and disaggregated showers with high scores . The F measure for toilet disaggregation with HMM only achieved 55 % , although still much better than the baselines .
Table 4 . Precision , Recall , and F measure on Volunteers . Precision , Recall , F measure HMM
Mean ( Standard
Mean ( Standard
Deviation )
Deviation )
Washer
Mean ( Standard
Deviation )
Toilet
Shower
0831(0138 ) , 0.818 ( 0.144 ) , 0.8244 ( 0.14 ) 0.08 ( 0.09 ) , 0.19 ( 0.16 ) 0.1126 ( 0.17 ) 0.52 ( 0.34 ) , 0.47 ( 0.16 ) 0.4937 ( 0.25 )
1 ( 0 ) , 1 ( 0 ) 1 ( 0 ) 0.07 ( 0.09 ) , 0.29 ( 0.34 ) 0.1128 ( 0.27 ) 0.44 ( 0.52 ) , 0.23 ( 0.27 ) 0.3021 ( 0.39 )
Random Pick
Knapsack
0.516 ( 0.27 ) , 0.597 ( 0.17 ) 0.5536 ( 0.22 ) 0.20 ( 0.18 ) , 0.19 ( 0.08 ) 0.1949 ( 0.13 ) 0.20 ( 0.10 ) , 0.904 ( 0.01 ) 0.3275 ( 0.05 )
5.4 Impact of Sample Rate Choosing an appropriate sample rate for smart meter deployment is a very important decision that may affect hardware and maintenance cost . This set of experiments can provide practical suggestions from the requirement of activity analysis . Reading intervals of the simulation datasets were varied from 15 min to 3 hours in this set of experiments to evaluate its impact on the accuracy of disaggregation results . Both HMM and GMM methods were evaluated in this set of experiments . SVM GMM was selected to represent GMM , because it had shown practically good accuracy and efficiency in previous experiments . As suggested in Figure 5 , both 15 and 30 min intervals provide acceptable results . 1 hour interval supports fair disaggregation of washer and shower , but cannot identify more than half of toilet flushes .
100 e r u s a e m F
80
60
40
20
0
Toilet_HMM Shower_HMM Washer_HMM Toilet_SVM Shower_SVM Washer_SVM
15min
30min
1hr
1.5hr
2.0hr
3.0hr
Figure 5 . Impact of Interval Length .
5.5 Disaggregation for Pilot Households a ) Pilot Households b ) Single Adult c ) Two Adults d ) Households with Kids e ) Households with Toddlers
Figure 6 . Distribution vs . Demographic Info .
The proposed HMM based approach has been applied on 300+ pilot households with 15 minute meter readings . Hidden Markov models were constructed for each household , and water consumption since August 2010 was disaggregated into activities to provide insights to residents and the city management team . Some interesting usage patterns discovered from the disaggregation results are illustrated in the following paragraphs .
By combining with demographic survey results , we first summarize the consumption distribution of different types of households in pie charts as shown in Figure 6 . Each pie chart shows the portion of water each activity used by a given group of households . The consumption that cannot be disaggregated is included in category ‘others’ . The consumption distribution of all the pilot households is illustrated in Figure 6 a ) , where toilet and shower used about 30 % each , and washer used about 25 % . Households with single occupant ( Figure 6 b ) ) showed different usage pattern , where shower only consumed 21 % of the overall usage and washer reduced to 22 % . Figure 6 c ) shows the pie chart for households with two adults only . Compared to the single adult households , households of two adults consumed significantly higher in shower . On the other hands , kids in general caused more washer usage . As shown in Figure 6 d ) and e ) , households with kids brought washer usage to 28 % , and more specifically , households with toddlers had increased washer usage further to 30 % . By comparison , a resident can easily figure out on which activity his or her household needs more efforts to conserve water . Temporal patterns of washer and shower usage have been identified from the disaggregation results . As shown in Figure 7 , the pilot households preferred to use washer in weekends , and each weekday there was about 0.9 load per household in average . Not only the number of loads , but also the size of each load increased in weekends . Figure 7 b ) illustrates that each load on Saturday used 9 % more water than a load on Tuesday or Wednesday . This is reasonable because usually heavy laundry is saved to weekends .
1.5
1
0.5
0 r e p s e c n e r r u c c O d l o h e s u o H
50
48
46
44
42
40 d a o L r e p s n o l l a G
Sun Mon Tue Wed Thu Fri Sat
Day of Week
Sun Mon Tue Wed Thu Fri Sat
Day of Week a ) Daily Occurrences b ) Gallons per Load
Figure 7 . Washer Usage vs . Day of Week .
Similar to washer , as can be seen in Figure 8 a ) , more showers happened during the days in weekends . However , interestingly , an average shower on Sunday used the least water in a week , which was 10 % less than one on Saturday . Furthermore , a shower on Friday consumed the highest amount of water in a week . It seemed that people wanted to relax and enjoyed longer showers on Friday , while the stress from work arrived early on Sunday . r e p s e c n e r r u c c O d l o h e s u o H
4
3
2
1
0
14 d a o L r e p s n o l l a G
13.8
13.6
13.4
13.2
13
Sun Mon Tue Wed Thu Fri Sat
Day of Week
Sun Mon Tue Wed Thu Fri Sat
Day of Week a ) Daily Occurrences b ) Gallons per Load
Figure 8 . Shower vs . Day of Week .
Figure 9 demonstrates the time of day distributions of shower and washer across the pilot households . As expected , the peaks of showers happened during 8~9 am and 6~7 pm in a day , which are before and after work . Washer usage showed a similar distribution in b ) , although the pm peak was not significant . That consistency could be explained as that many washer loads occurred right after a shower to handle the changed clothes .
247 150
100
50
0 d l o h e s u o H r e p s n o l l a G
200
150
100
50
0 d l o h e s u o H r e p s n o l l a G
0 2 4 6 8 10 12 14 16 18 20 22
Hour of Day
0 2 4 6 8 10 12 14 16 18 20 22
Hour of Day a ) Shower b ) Washer Usage Figure 9 . Shower/Washer vs . Time of Day .
6 . RELATED WORK Non intrusive load monitoring has been proposed based on analyzing steady state change and transient state change . So far most of the research effort has been focused on electricity load disaggregation with high sample rate [ 7 13 ] . A power meter with high sample rate ( >= 1Hz ) can identify most of the state changes of multiple metrics ( eg , power , reactive power , voltage , and harmonics ) caused by individual appliances in a real world home . Based on state change of current and voltage , a non intrusive load monitoring approach [ 7 ] was proposed to determine power consumption of individual appliances . An electrical noise sensor has been used to disaggregate consumption by running SVM on transient noise of turning on and off appliances [ 8 ] . By measuring voltage of each outlet in a house , one approach [ 12 ] applied kNN and SVM to classify appliances . This approach collected peak , average , and RMS of voltage of a single target with 4kHz sample rate , and achieved best results using an NN classifier . An NNbased disaggregation approach has been proposed to identify appliances with 90 % accuracy using only the main power meter [ 9 , 13 ] . The features it used consist of power , reactive power , voltage RMS , and harmonics for state transition . RECAP has recently been proposed using artificial neural network ( ANN ) to disaggregate electricity usage [ 11 ] . Features including power factor , peak and RMS of voltage and current were aggregated every minute and analyzed in a 3 layer ANN . To extract better features , Matrix Pencil [ 10 ] has been proposed to model each signal as complex plan , and use residues and poles as features for disaggregation . Improved disaggregation results have been demonstrated . Compared with electricity disaggregation , residential water disaggregation has attracted much less research effort . To the best of our knowledge , there has not been any design that can disaggregate water consumption either using a single water meter or from a sample rate lower than 500Hz . Microphone based sensors were applied on major water pipes ( cold inlet , hot inlet , and sewing ) the timestamps that these microphones detect noise , the authors identified most of the water usages . However , this approach has difficulties to disaggregate concurrent activities and cannot determine water volume . Integration of a water meter and a network of accelerometers [ 15 ] has been proposed to estimate the flow rates based on pipe vibration . This approach has been applied in laboratory environments to disaggregate water usage . To avoid accessing water pipes , an approach using pressure sensor on main source [ 16 ] was proposed to identify fixtures . This approach applies hierarchical classifiers to first detect valve open and close events , and then label fixtures . Due to the 1 kHz sample rate , it can clearly capture on and off signals of fixtures from water pressure . 7 . CONCLUSION This paper describes a design and deployment of activity disaggregation using low sample rate smart water meters in Dubuque , IA . In the proposed general disaggregation framework , fixture activity to recognize usage activities [ 14 ] . Combining characteristics , household behavior , and improve correlations are modeled to disaggregate water consumption . Implementations based on Hidden Markov Model and Gaussian Mixture Model have been developed accordingly to provide insights for helping residents their behavior and supporting utility manager ’s decision making . Evaluation on both real and simulation datasets have demonstrated the effectiveness of the disaggregation approaches , and revealed some interesting patterns from pilot households . Future efforts may include providing user annotation interface to support learning from feedback ; and expanding the disaggregation service to electricity smart meters . 8 . ACKNOWLEDGEMENTS The authors would like to gratefully acknowledge the collaboration from the Information Services Department of City of Dubuque on smart meter data transmission ; and the support from Dubuque 2.0 , an NGO , for engaging the volunteer households . 9 . REFERENCES [ 1 ] Dubuque2.0 , "Inspiring Sustainability," 2010 . [ 2 ]
T . Woody , "Smart Water Meters Catch On in Iowa," in The New York Times New York City , 2010 .
[ 3 ] NeptuneTechnologyGroup , "R900 RF Wall or Pit MIU Product
Sheet," 2009 .
[ 4 ] S . J . Roberts , "Novelty Detection using Extreme Value Statistics," IEE VISP , vol . 146 , pp . 124 129 , Jun . 1999 .
[ 5 ] H . Rue , "Fast Sampling of Gaussian Markov Random Fields,"
JRSS : Series B , vol . 63 , pp . 325 338 , 2001 .
[ 6 ] C . C . Chang and C . J . Lin , "LIBSVM : a library for support vector machines," 2001 .
[ 7 ] G . W . Hart , "Nonintrusive Appliance Load Monitoring,"
Proceedings of the IEEE , vol . 80 , pp . 1870 1891 , Dec . 1992 . [ 8 ] S . N . Patel , T . Robertson , J . A . Kientz , M . S . Reynolds , and G . D . Abowd , "At the Flick of a Switch : Detecting and Classifying Unique Electrical Events on the Residential Power Line," in ACM ICUC , Innsbruck , Austria , 2007 , pp . 271 288 .
[ 9 ] M . Berges , E . Goldman , H . S . Matthews , and L . Soibelman , "Learning Systems for Electric Consumption of Buildings," in ASCE International Workshop on Computing in Civil Engineering , Austin , TX , 2009 , pp . 1 10 .
[ 10 ] H . Najmeddine , K . E . K . Drissi , C . Pasquier , C . Faure , K .
Kerroum , T . Jouannet , M . Michou , and A . Diop , "Smart metering by using “ Matrix Pencil ” ," in IEEE EEEIC , Prague , Czech Republic , 2010 , pp . 238 241 .
[ 11 ] A . G . Ruzzelli , C . Nicolas , A . Schoofs , and G . M . P . O'Hare ,
"Real Time Recognition and Profiling of Appliances through a Single Electricity Sensor," in IEEE SECON , Boston , MA , 2010 , pp . 1 9 .
[ 12 ] T . Saitoh , T . Osaki , R . Konishi , and K . Sugahara , "Current
Sensor Based Home Appliance and State of Appliance Recognition," SICE JCMSI , vol . 3 , pp . 86 93 , Mar . 2010 .
[ 13 ] M . Berges , E . Goldman , H . S . Matthews , and L . Soibelman ,
"Enhancing Electricity Audits in Residential Buildings with Nonintrusive Load Monitoring," Journal of Industrial Ecology , vol . 14 , pp . 844 858 , Oct . 2010 .
[ 14 ] J . Fogarty , C . Au , and S . E . Hudson , "Sensing from the
Basement : A Feasibility Study of Unobtrusive and Low Cost Home Activity Recognition," in ACM UIST , Montreux , Switzerland , 2006 , pp . 91 100 .
[ 15 ] Y . Kim , T . Schmid , Z . M . Charbiwala , J . Friedman , and M . B .
Srivastava , "NAWMS : Nonintrusive Autonomous Water Monitoring System," in ACM SenSys , Raleigh , NC , 2008 , pp . 309 322 .
[ 16 ] J . Froehlich , E . Larson , T . Campbell , C . Haggerty , J . Fogarty , and S . N . Patel , "HydroSense : Infrastructure Mediated SinglePoint Sensing of Whole Home Water Activity," in ACM ICUC , Orlando , FL , 2009 , pp . 235 244 .
248
