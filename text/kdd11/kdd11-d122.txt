Ranking Based Classification of Heterogeneous
Information Networks
Ming Ji
Jiawei Han
Department of Computer
Department of Computer
Science
University of Illinois at Urbana Champaign
Urbana , IL , USA mingji1@illinois.edu
Science
University of Illinois at Urbana Champaign
Urbana , IL , USA hanj@illinois.edu
Marina Danilevsky
Department of Computer
Science
University of Illinois at Urbana Champaign
Urbana , IL , USA danilev1@illinois.edu
ABSTRACT
1 .
INTRODUCTION
It has been recently recognized that heterogeneous information networks composed of multiple types of nodes and links are prevalent in the real world . Both classification and ranking of the nodes ( or data objects ) in such networks are essential for network analysis . However , so far these approaches have generally been performed separately . In this paper , we combine ranking and classification in order to perform more accurate analysis of a heterogeneous information network . Our intuition is that highly ranked objects within a class should play more important roles in classification . On the other hand , class membership information is important for determining a quality ranking over a dataset . We believe it is therefore beneficial to integrate classification and ranking in a simultaneous , mutually enhancing process , and to this end , propose a novel ranking based iterative classification framework , called RankClass . Specifically , we build a graph based ranking model to iteratively compute the ranking distribution of the objects within each class . At each iteration , according to the current ranking results , the graph structure used in the ranking algorithm is adjusted so that the subnetwork corresponding to the specific class is emphasized , while the rest of the network is weakened . As our experiments show , integrating ranking with classification not only generates more accurate classes than the state of art classification methods on networked data , but also provides meaningful ranking of objects within each class , serving as a more informative view of the data than traditional classification .
Categories and Subject Descriptors
H28 [ Database Management ] : Database Applications—Data Mining
General Terms
Algorithms
Keywords heterogeneous information network , ranking , classification
Information networks have been found to play increasingly important roles in real life applications . Examples include friendship networks in Facebook1 , co author networks extracted from bibliographic data , and webpages interconnected by hyperlinks on the Web . Networks and feature vectors are two alternatives to represent the data , and the former is often more natural than the latter in many data sets [ 8 ] . Even if the data is naturally represented in a feature space , it is usually helpful to transform the data into a network , or graph structure ( for example , by constructing a nearest neighbor graph ) to better exploit the intrinsic characteristics of the data . Therefore , learning on networked data is receiving growing attention in recent years [ 9 , 22 , 1 , 24 , 6 ] . Most of the existing studies [ 19 , 16 , 2 , 12 ] about information networks mainly work with homogeneous networks , ie , networks composed of a single type of object , as mentioned above . However , heterogeneous networks composed of multiple types of objects are more general and prevalent in many real world applications [ 21 , 11 , 3 ] . For example , beyond co author networks , bibliographic data actually forms a heterogeneous information network consisting of multi typed objects , such as papers , authors , venues and terms .
Example 1 . Bibliographic Information Network . A bibliographic information network generally contains four types of objects : papers , authors , venues ( conferences and journals ) and terms . Papers and authors are linked by the relation of “ written by ” and “ write ” . Papers and venues are linked by “ published in ” and “ publish ” . Papers and terms are linked by “ contain ” and “ contained in ” . '
In this paper , we study the analysis of heterogeneous information networks . Classification and ranking are two of the most fundamental analytical techniques . When label information is available for some of the data objects , classification makes use of the labeled data as well as the network structure to predict the class membership of the unlabeled data [ 19 , 16 ] . On the other hand , ranking gives a partial ordering to objects in the network by evaluating the node/link properties using some ranking scheme , such as PageRank [ 2 ] or HITS [ 12 ] . Both classification and ranking have been widely studied and found to be applicable in a wide range of problems .
Traditionally , classification and ranking are regarded as orthogonal approaches , computed independently . However , adhering to such a strict dichotomy has serious downsides . Consider , for instance , an information network of bibliographic data , consisting of some combination of published papers , authors , and conferences . As a concrete example , suppose we wish to classify the conferences in Table 1 into two research areas . We wish to minimize the chance
1http://wwwfacebookcom/
Table 1 : Conferences from two research areas
Database
Information Retrieval
SIGMOD , VLDB ,
ICDE , EDBT , PODS ,
SIGIR , ECIR ,
CIKM , WWW , WSDM ,
Table 2 : Top 5 ranked conferences in different settings
Rank Global Ranking Within DB Within IR
1 2 3 4 5
VLDB SIGIR
SIGMOD
ICDE ECIR
VLDB
SIGMOD
ICDE PODS EDBT
SIGIR ECIR WWW CIKM WSDM that the top conferences are misclassified , not only to improve our classification results overall , but also because misclassifying a top conference is very likely to increase errors on many other objects that link to that conference , and are therefore greatly influenced by its label . We would thus like to more heavily penalize classification mistakes made on highly ranked conferences , relative to a workshop of little influence . Providing a ranking of all conferences within a research area can give users a clearer understanding of that field , rather than simply grouping conferences into classes without noting their relative importance . On the other hand , the class membership of each conference is very valuable for characterizing that conference . Ranking all conferences globally without considering any class information can often lead to meaningless results and apples to oranges comparisons . For instance , ranking database and information retrieval conferences together may not make much sense since the top conferences in these two fields cannot be reasonably compared , as shown in the second column of Table 2 . These kinds of nonsensical ranking results are not caused by the specific ranking approach , but are rather due to the inherent incomparability between the two classes of conferences . Thus we suppose that combining classification with ranking may generate more informative results . The third and fourth columns in Table 2 illustrate this combined approach , showing the more meaningful conference ranking within each class .
In this study , we propose RankClass , a new framework that groups objects into several pre specified classes , while generating the ranking information for each type of object within each class simultaneously in a heterogeneous information network . More accurate classification of objects increases the quality of the ranking within each class , since there is a higher guarantee that the ranking algorithm used will be comparing only objects of the same class . On the other hand , better ranking scores improve the performance of the classifier , by correctly identifying which objects are more important , and should therefore have a higher influence on the classifier ’s decisions . We use the ranking distribution of objects to characterize each class , and we treat each object ’s label information as a prior . By building a graph based ranking model , different types of objects are ranked simultaneously within each class . Based on these ranking results , we estimate the relative importance or visibility of different parts of the network with regard to each class . In order to generate better within class ranking , the network structure employed by the ranking model is adjusted so that the sub network composed of objects ranked high in each specific class is emphasized , while the sub network of the rest of the class is gradually weakened . Thus , as the network structure of each class becomes clearer , the ranking quality improves . Finally , the posterior probability of each object belonging to each class is estimated to determine each object ’s optimal class membership . Instead of performing ranking after classification , as facet ranking does [ 4 , 23 ] , RankClass essentially integrates ranking and classification , allow ing both approaches to mutually enhance each other . RankClass iterates over this process until converging to a stable state . Experimental results show that RankClass both boosts the overall classification accuracy and constructs within class rankings , which may be interpreted as meaningful summaries of each class .
The rest of this paper is organized as follows . We briefly review the related work in Section 2 . We introduce related concepts and formally define our problem in Section 3 . Our ranking based classification algorithm , RankClass , is introduced in Section 4 . Section 5 presents the experimental results , and we conclude this work in Section 6 .
2 . RELATED WORK
As data sets with inherent network structures become increasingly prevalent , ranking networked objects has received substantial interest in recent years . Two important representative algorithms are PageRank [ 2 ] and HITS [ 12 ] , both of which propagate information throughout the network to compute the ranking score of each object , using different propagation methods corresponding to different ranking rules . These methods mainly work on homogeneous information networks . Recently , PopRank [ 18 ] was proposed to rank the popularity of heterogeneous web objects via knowledge propagation throughout the heterogeneous network of web objects . This approach considers that different types of links in a network have different propagation factors , which are trained according to partial ranks given by experts . In contrast , we rank objects according to their importance within each class , rather than within the global set of all objects , and the ranking results in turn facilitate more accurate classification .
Classification is an essential tool in analyzing information networks when some object label information is available [ 25 , 20 ] . Collective classification [ 14 , 19 , 17 ] has been proposed to employ both the network structure and the feature representation of objects in the classification task . Since local features may not be always available , Macskassy et al . [ 15 ] develop a relational neighbor classifier to classify network only data by iteratively assigning an object to the majority class of its neighbors . This idea is similar to the label propagation scheme in graph based classification [ 26 ] . However , existing algorithms mainly work on homogeneous networks and graphs , and therefore cannot easily distinguish between the type differences among objects in a heterogeneous information network . Recently , the graph based classification framework has been extended to work on heterogeneous information networks [ 11 ] . In this paper , we build on this approach by providing within class ranking for objects in the information network , which can improve classification results by providing informative summaries of each class .
To enhance the quality of classification , boosting , bagging and ensemble methods have been explored in various studies [ 10 ] . In particular , boosting methods such as AdaBoost [ 5 ] iteratively learn from their classification mistakes by assigning higher weights to objects which are misclassified in each previous round , until a stable classification state is reached . Like boosting , RankClass also adjusts the relative importance of objects in various rounds of classification . However , RankClass uses within class ranking to measure the importance of each object with regard to each class , in contrast to boosting , which estimates the global importance of each object based on classification mistakes .
Another relevant algorithm is the newly proposed NetClus [ 21 ] method , which uses a ranking clustering mutual enhancement methodology to cluster objects in heterogeneous information networks . Although this method effectively provides a ranking within each cluster , it has some limitations : ( 1 ) it can only work on heteroge neous information networks with a star schema ; and ( 2 ) it requires a prior distribution specified by several labeled representative objects of each cluster , and does not work well with arbitrary labeled objects , which may not be representative . Thus , if we do not know which objects are representative in a data set , NetClus cannot be used . However , for heterogeneous information networks with arbitrary network schema , our proposed RankClass algorithm can make full use of label information available for any data objects to generate accurate classification results and informative rankings .
3 . PROBLEM FORMALIZATION
In this section , we introduce several related concepts and nota tions , and then formally define the problem .
Definition 1 . Heterogeneous information network . Given m types of data objects , denoted by X1 = {x11 , . . . , x1n1 } , . . . , Xm = {xm1 , . . . , xmnm } , a graph G = hV , E , Wi is called a heterogei=1 Xi and m ≥ 2 . E is the set of links between any two data objects of V , and W is the set of weight values on the links . When m = 1 , G reduces to a homogeneous information network . ' neous information network if V = Sm
In the following sections , for convenience , we use Xi to denote both the set of objects belonging to the i th type and the type name . We let Wxipxjq denote the weight of the link between any two objects xip and xjq , which is represented by hxip , xjqi .
In a heterogeneous information network , each type of link relationship between two types of data objects Xi and Xj can be represented by a relation graph Gij , i , j ∈ {1 , . . . , m} . Note that it is possible for i = j . Let Rij be an ni × nj relation matrix corresponding to graph Gij . The element at the p th row and q th column of Rij is denoted as Rij,pq , representing the weight on link hxip , xjqi . There are many ways to define the weights on the links , which can also incorporate domain knowledge . A simple definition is as follows :
Rij,pq =fl 1
0 if data objects xip and xjq are linked together otherwise .
Here we consider undirected relation graphs such that Rij = RT ji . In this way , each heterogeneous network G can be mathematically represented by a set of relation matrices G = {Rij}m i,j=1 .
To naturally generalize classification in homogeneous network data , we define a class in a heterogeneous information network to be a group of multi typed objects sharing a common topic . For instance , a research community in a bibliographic information network contains not only authors , but also papers , venues and terms belonging to the same research area . Other examples include movie networks in which movies , directors , actors and keywords are tagged with the same genre , and E commerce networks where sellers , customers , items and tags belong to the same shopping category . The formal definition of a class is given below : work G = hV , E , Wi , V = Sm
Definition 2 . Class . Given a heterogeneous information neti=1 Xi , a class is defined as G′ = hV ′ , E ′ , W ′i , where V ′ ⊆ V , E ′ ⊆ E . ∀e = hxip , xjqi ∈ E ′ , where xip ∈ V ′ and xjq ∈ V ′ , we have W ′ xipxjq = Wxipxjq . Note here , V ′ also consists of multiple types of objects from X1 to Xm . ' classes , we also aim to generate the ranking distribution of objects within each class k , which can be denoted as P ( x|T ( x ) , k ) , k = 1 , . . . , K . T ( x ) denotes the type of object x . Note that different types of objects cannot be compared in a ranking . For example , it is not meaningful to create a ranking of conferences and authors together in a bibliographic information network . Therefore , each ranking distribution is restricted to a single object type , p=1 P ( xip|Xi , k ) = 1 . ie,Pni objects V ′ ⊆ V = Sm
Now our problem can be formalized as follows : given a heterogeneous information network G = hV , E , Wi , a subset of data i=1 Xi , which are labeled with values Y denoting which of the K pre specified classes each object belongs to , predict the class labels for all the unlabeled objects V−V ′ as well as the ranking distribution of objects within each class , P ( x|T ( x ) , k ) , x ∈ V , k = 1 , . . . , K .
4 . THE RANKCLASS ALGORITHM
In this section we introduce our ranking based iterative classification method , RankClass . There are two major challenges when working with heterogeneous information networks : ( 1 ) how to exploit the links representing the dependency relationships between data objects ; and ( 2 ) how to model the type differences among objects and links . The intuition behind RankClass is to build a graphbased ranking model that ranks multi typed objects simultaneously , according to the relative importance of objects within each class . The initial ranking distribution of each class is determined by the labeled data . During each iteration , the ranking results are used to modify the network structure to allow the ranking model to generate higher quality within class ranking .
4.1 The Framework of RankClass
We first introduce the general framework of RankClass . We will explain each part of the algorithm in detail in the following subsections .
• Step 0 : Initialize the ranking distribution within each class according to the labeled data , ie , {P ( x|T ( x ) , k)0}K k=1 . Initialize the set of network structures employed in the ranking model , {G0 k = G , k = 1 , . . . , K . Initialize t = 1 . k=1 , as G0 k}K
• Step 1 : Using the graph based ranking model and the current }K k=1 , update the ranking dis set of network structures {Gt−1 tribution within each class k , ie , {P ( x|T ( x ) , k)t}K k k=1 .
• Step 2 : Based on {P ( x|T ( x ) , k)t}K k=1 , adjust the network structure to favor within class ranking , ie , {Gt k}K k=1 .
• Step 3 : Repeat steps 1 and 2 , setting t = t + 1 until converk=1 = {P ( x|T ( x ) , k)t}K gence , ie , until {P ( x|T ( x ) , k)∗}K do not change much for all x ∈ V . k=1
• Step 4 : Based on {P ( x|T ( x ) , k)∗}K terior probability for each object , ie , {P ( k|x , T ( x))}K Assign the class label to object x as : k=1 , calculate the posk=1 .
C(x ) = arg max 1≤k≤K
P ( k|x , T ( x ) )
4.2 Graph based Ranking
Definition 2 follows [ 21 ] and [ 11 ] . Notice that a class in a heterogeneous information network is actually a sub network containing multi typed objects that are closely related to each other . In addition to grouping multi typed objects into the pre specified K
Ranking is often used to evaluate the relative importance of objects in a collection . In this paper , we propose to rank objects within their own type and within a specific class . The higher an object x is ranked within class k , the more important x is for class k , and the more likely it is that x will be visited in class k . Clearly , withinclass ranking is quite different from global ranking , and will vary throughout different classes .
The intuitive idea of our ranking scheme is authority propagation throughout the information network . Taking the bibliographic information network as an example , in a specific research area , it is natural to observe the following ranking rules [ 21 ] :
1 . Highly ranked conferences publish many high quality papers .
2 . High quality papers are often written by highly ranked au thors .
3 . High quality papers often contain keywords that are highly representative of the papers’ areas .
The above authority ranking rules can be summarized as follows : objects which are linked together in a network are more likely to share similar ranking scores . Therefore , the ranking of each object can be iteratively updated by looking at the rankings of its neighbors . The initial ranking distribution within a class k can be specified by the user . When data objects are labeled without ranking information in a general classification scenario , we can initialize the ranking as a uniform distribution over only the labeled data objects :
P ( xip|Xi , k)0 =fl 1/lik
0 if xip is labeled to class k otherwise . where lik denotes the total number of objects of type Xi labeled to class k . k = {Rij }m
Suppose the current network structure used to estimate the ranking within class k is mathematically represented by the set of relation matrices : Gt−1 i,j=1 . For each relation matrix Rij , we define a diagonal matrix Dij of size ni × ni . The ( p , p) th element of Dij is the sum of the p th row of Rij . Instead of using the original relation matrices in the authority propagation , we construct the normalized form of the relation matrices as follows :
Sij = D(−1/2 ) ij
RijD(−1/2 ) ji
, i , j ∈ {1 , . . . , m}
( 1 )
This normalization technique is adopted in traditional graph based learning [ 26 ] in order to reduce the impact of node popularity . In other words , we can suppress popular nodes to some extent , to keep them from completely dominating the authority propagation . Notice that the normalization is applied separately to each relation matrix corresponding to each type of link , rather than the whole network . In this way , the type differences between objects and links are well preserved [ 11 ] . At the t th iteration , the ranking distribution of object xip with regard to class k is updated as follows :
P ( xip|Xi , k)t j=1 λijSij,pqP ( xjq|Xj , k)t−1 + αiP ( xip|Xi , k)0
( 2 )
∝ Pm j=1 λij + αi
Pm
The first term of Equation ( 2 ) updates the ranking score of object xip by the summation of the ranking scores of its neighbors xjq , weighted by the link strength Sij,pq . The relative importance of neighbors of different types is controlled by λij ∈ [ 0 , 1 ] . The larger the value of λij , the more value is placed on the relationship between object types Xi and Xj . For example , in a bibliographic information network , if a user believes that the links between authors and papers are more trustworthy and influential than the links between conferences and papers , then the λij corresponding to the author paper relationship should be set larger than that of conference paper . As a result , the rank of a paper will rely more on the ranks of its authors than the rank of its publication venue .
The parameters λij can also be thought of as performing feature selection in the heterogeneous information network , ie , selecting which types of links are important in the ranking process .
The second term learns from the initial ranking distribution encoded in the labels , whose contribution is weighted by αi ∈ [ 0 , 1 ] . A similar strategy has been adopted in [ 13 , 11 ] to control the weights between different types of relations and objects . After each iterap=1 P ( xip|Xi , k)t = 1 , ∀i = 1 , . . . , m , k = 1 , . . . , K , in order to stay consistent with the mathematical definition of a ranking distribution . tion , P ( xip|Xi , k)t is normalized such thatPni
We employ the authority propagation scheme in Equation ( 2 ) to estimate the ranking distribution instead of other simple measures computed according to the network topology ( eg , the degree of each object ) . This choice was made since we aim to rank objects with regard to each class by utilizing the current soft classification results . Therefore , if the ranking of an object were merely based on the network topology , it would be the same for all classes . By learning from the label information in the graph based authority propagation method , the ranking of each object within different classes will be computed differently , which is more suitable for our setting .
Following a similar analysis to [ 11 ] and [ 27 ] , the updating scheme in Equation ( 2 ) can be proven to converge to the closed form solution of minimizing the following objective function :
J(P ( xip|Xi , k ) ) nj m ni
=
λij
Xi,j=1 Xi=1
+ m
Sij,pq ( P ( xip|Xi , k ) − P ( xjq|Xj , k))2
Xq=1
( P ( xip|Xi , k ) − P ( xip|Xi , k)0)2
( 3 ) ni
Xp=1 Xp=1
αi which shares a similar theoretical foundation with the graph based regularization framework on heterogeneous information networks [ 11 ] that preserves consistency over each relation graph corresponding separately to each link type . However , we extend the graphbased regularization framework to rank objects within each class , which is conceptually different from [ 11 ] .
4.3 Adjusting the Network
Although graph based ranking considers class information by incorporating the labeled data , it still ranks all object types in the global network . Instead , a within class ranking should be performed over the sub network corresponding to each specific class . The cleaner the network structure , the higher our ranking quality . Therefore , the ranking within each class should be performed over a different sub network , rather than employing the same global network for every class . The network structure is mathematically represented by the weight values on the links . Thus , extracting the subnetwork belonging to class k is equivalent to increasing the weight on the links within the corresponding sub network , and decreasing the weight on the links in the rest of the network . It is straightforward to verify that multiplying Rij by any positive constant c will not change the value of Sij . So increasing the weights on the links within a sub network should be performed relative to the weight on the links of other parts of the network . In other words , we can increase or decrease the absolute values of the weights on the links in the whole network , as long as the weights on the links of the sub network belonging to class k are larger than those on the links belonging to the rest of the network . Let Gt i,j=1 . We propose a simple scheme to update the network structure so as to favor the ranking within each class k , given the current ranking k = {Rt ij ( k)}m distribution P ( x|T ( x ) , k)t :
Rt ij,pq(k ) = Rij,pq × r(t ) +s P ( xip|Xi , k)t maxp P ( xip|Xi , k)t
P ( xjq|Xj , k)t maxq P ( xjq|Xj , k)t!(4 )
Recall that Rij is the relation matrix corresponding to the links between object types Xi and Xj in the original network . Using the above updating scheme , the weight of each link hxip , xjqi is increased in proportion to the geometric mean of the ranking scores of xip and xjq , which are scaled to the interval of [ 0 , 1 ] . The higher the rankings of xip and xjq , the more important the link between them hxip , xjqi is in class k . The weight on that link should therefore be increased . Note that instead of creating hard partitions of the original network into classes , we simply increase the weights on the links that are important to classes k . This is because at any time in the iteration , the current classes represented by the ranking distributions are not very accurate , and the results will be more stable if we consider both the global network structure and the current ranking results . By gently increasing the weights of links in the sub network of class k , we gradually extract the correct subnetwork from the global network , since the weights of links in the rest of the network will decrease to very low values . Note that this adjustment of the network structure still respects the differences among the various types of objects and links . r(t ) is a positive parameter that does not allow the weights of links to drop to 0 in the first several iterations , when the authority scores have not propagated very far throughout the network and P ( x|T ( x ) , k)t are close to 0 in value for many objects . As discussed above , multiplying Rij by any positive constant will not change the value of Sij . Therefore , it is essentially the ratio bemaxq P ( xjq |k)t that determines how much the original network structure and the current ranking distribution , respectively , contribute to the adjusted network Gt k . Since we hope to progressively extract the sub network belonging to each class k , and we want to gradually reduce the weights of links that do not belong to class k down to 0 , we decrease r(t ) exponentially by setting r(t ) = 1 2t . tween r(t ) andq P ( xip|k)t maxp P ( xip|k)t × P ( xjq |k)t
P ( xip|k)t
Equation ( 4 ) is not the only way to gradually increase the weights of links between highly ranked objects in class k . For instance , the geometric mean of maxq P ( xjq |k)t can be replaced by the arithmetic mean , and r(t ) can be any positive function that decreases with t . We will show in Section 5 that even such simple adjustments as shown above can boost both the classification and ranking performance of RankClass . maxp P ( xip|k)t and
P ( xjq |k)t
4.4 Posterior Probability Calculation
Once the ranking distribution of each class has been computed by the iterative algorithm , we can calculate the posterior probability of each object of type Xi belonging to class k simply by Bayes’ rule :
By employing the EM algorithm , P ( k|Xi ) can be iteratively es timated using the following two equations :
P ( k|xip , Xi)t ∝ P ( xip|Xi , k)P ( k|Xi)t
P ( k|Xi)t = ni
Xp=1
P ( k|xip , Xi)t/ni where P ( k|Xi ) is initialized uniformly as P ( k|Xi)0 = 1/K .
4.5 Computational Complexity Analysis
In this subsection , we analyze the computational complexity of the proposed RankClass algorithm . Let K denote the number of classes , |V | denote the total number of objects , and |E| denote the total number of links in the information network . It takes O(K|V | ) time to initialize the ranking distribution in step 0 . At each iteration of step 1 , we need to process each link twice to update the ranking distribution , once for each object at each end of the link . We also need O(K|V | ) time to learn from the initial ranking distribution . So the total time complexity for step 1 at each iteration is O(K(|E| + |V |) ) . In step 2 , we need O(K|E| ) time to adjust the network structure at each iteration . After the ranking distribution is computed , we need O(K|V | ) time at each iteration of the EM algorithm to calculate the posterior probability . Finally , it takes O(K|V | ) time to generate the final class prediction in step 4 . Hence the total time complexity of the RankClass algorithm is
O,N1K(|E| + |V | ) + N2K|V | , where N1 is the number of iter ations in the computation of the ranking distribution , and N2 is the number of iterations in the EM algorithm . We will experimentally demonstrate that this algorithm converges in a few iterations . And since the number of classes K is constant , the computational complexity is generally linear in the number of links and objects in the network .
5 . EXPERIMENTS
In this section , we apply our proposed ranking based classification scheme , RankClass , to a real heterogeneous information network extracted from the DBLP2 database . We try to classify the bibliographic data into research communities , each of which consists of multi typed objects closely related to the same area . All of the experiments were conducted on a PC with 3.00GHz CPU and 8GB memory . The following five classification methods on information networks are compared :
• Our proposed RankClass algorithm ( RankClass ) .
• Graph based regularization framework for transductive classification in heterogeneous information networks ( GNetMine ) [ 11 ] .
• Learning with Local and Global Consistency ( LLGC ) [ 26 ] .
• Weighted vote Relational Neighbor Classifier ( wvRN ) [ 15 ,
P ( k|xip , Xi ) ∝ P ( xip|Xi , k)P ( k|Xi )
16 ] . where P ( xip|Xi , k ) = P ( xip|Xi , k)∗ , and P ( k|Xi ) represents the relative size of class k among type Xi , which should also be estimated . We choose the P ( k|Xi ) that maximizes the likelihood of generating the set of objects of type Xi : ni log L(xi1 , . . . , xini |Xi ) = log P ( xip|Xi )
Xp=1
= ni
Xp=1 log K Xk=1
P ( xip|Xi , k)P ( k|Xi)!
( 5 )
• Network only Link based Classification ( nLB ) [ 19 , 16 ] .
LLGC is a graph based transductive classification algorithm for homogeneous networks , while GNetMine is its extension , which works on heterogeneous information networks . Weighted vote relational neighbor classifier and link based classification are two popular classification methods for networked data . Since a feature representation of nodes is not available for our problem , we use the network only derivative of the link based classifier ( nLB ) [ 16 ] ,
2http://wwwinformatikuni trierde/~ley/db/
( a % , p % ) of authors and papers labeled
( 0.1 % , 0.1 % ) ( 0.2 % , 0.2 % ) ( 0.3 % , 0.3 % ) ( 0.4 % , 0.4 % ) ( 0.5 % , 0.5 % ) nLB wvRN
( A C P T )
Table 3 : Comparison of classification accuracy on authors ( % ) nLB ( A A ) 25.4 28.3 28.4 30.7 29.8
LLGC ( A A ) 41.4 44.7 48.8 48.7 50.6 wvRN ( A A ) 40.8 46.0 48.6 46.3 49.0
26.0 26.0 27.4 26.7 27.3
34.1 41.2 42.5 45.6 51.4
61.3 62.2 65.7 66.0 68.9
( A C P T )
( A C P T )
LLGC average
28.5
26.7
46.3
43.0
46.8
64.8
( a % , p % ) of authors and papers labeled
( 0.1 % , 0.1 % ) ( 0.2 % , 0.2 % ) ( 0.3 % , 0.3 % ) ( 0.4 % , 0.4 % ) ( 0.5 % , 0.5 % ) nLB wvRN
( A C P T )
Table 4 : Comparison of classification accuracy on papers ( % ) nLB ( P P ) 49.8 73.1 77.9 79.1 80.7
LLGC ( P P ) 67.2 72.8 76.8 77.9 79.0 wvRN ( P P ) 62.0 71.7 77.9 78.1 77.9
62.7 65.5 66.6 70.5 73.5
42.0 49.7 54.3 54.4 53.5
31.5 40.3 35.4 38.6 39.3
( A C P T )
( A C P T )
LLGC average
72.1
37.0
73.5
50.8
74.7
67.8
GNetMine ( A C P T )
RankClass ( A C P T )
82.9 83.4 86.7 87.2 87.5
85.5
85.4 88.0 88.5 88.4 89.2
87.9
GNetMine ( A C P T )
RankClass ( A C P T )
79.2 83.5 83.2 83.7 84.1
82.7
77.7 83.0 83.6 84.7 84.8
82.8
Table 5 : Comparison of classification accuracy on conferences ( % )
( a % , p % ) of authors and papers labeled nLB wvRN
LLGC
( A C P T )
( A C P T )
( A C P T )
GNetMine ( A C P T )
RankClass ( A C P T )
( 0.1 % , 0.1 % ) ( 0.2 % , 0.2 % ) ( 0.3 % , 0.3 % ) ( 0.4 % , 0.4 % ) ( 0.5 % , 0.5 % ) average
25.5 22.5 25.0 25.0 25.0
24.6
43.5 56.0 59.0 57.0 68.0
56.7
79.0 83.5 87.0 86.5 90.0
85.2
81.0 85.0 87.0 89.5 94.0
87.3
85.0 85.5 90.0 92.0 95.0
89.5 which creates a feature vector for each node based on neighboring information . Note that LLGC , wvRN and nLB are classifiers which work with homogeneous networks , and cannot be directly applied to heterogeneous information networks . In order to compare all of the above algorithms , we can transform the heterogeneous DBLP network into a homogeneous network in two ways ( see Section 5.2 ) : ( 1 ) disregard the type differences between objects and treat all objects as the same type ; or ( 2 ) extract a homogeneous sub network on one single type of object , if that object type is partially labeled . We try both approaches in the accuracy study . The open source implementation of NetKit SRL3 [ 16 ] is employed in our experiments .
5.1 Data Preparation
We extracted a connected sub network of the DBLP data set on four research areas : database , data mining , information retrieval and artificial intelligence , which naturally form four classes . As previously discussed , this heterogeneous information network is composed of four types of objects : paper , conference , author and term . Among the four types of objects , we have three types of link relationships : paper conference , paper author , and paper term . The data set we used contains 14376 papers , 20 conferences , 14475 authors and 8920 terms , with a total number of 170794 links4 .
For accuracy evaluation , we use a labeled data set of 4057 authors , 100 papers and all 20 conferences . For more details about the labeled data set , please refer to [ 7 , 21 ] . In the following sections , we randomly choose a subset of labeled objects and use their
3http://wwwresearchrutgersedu/~sofmac/ NetKit.html 4The data set is available at wwwcsillinoisedu/homes/ mingji1/DBLP_four_area.zip for sharing and experiment repeatability . label information in the learning process . The classification accuracy is evaluated by comparing with manually labeled results on the rest of the labeled objects . Since terms are difficult to label even manually , as many terms may belong to multiple areas , we do not evaluate the accuracy on terms here .
5.2 Accuracy Study
In order to address the label scarcity problem in real life , we randomly choose ( a % , p % ) = [ (0.1 % , 0.1% ) , ( 0.2 % , 0.2% ) , . . . , ( 0.5 % , 0.5% ) ] of authors and papers , and use their label information in the classification task . For each ( a % , p% ) , we average the performance scores over 10 random selections of the labeled set . We set the parameters of LLGC and GNetMine to optimal values , which were determined experimentally . For our proposed RankClass method , as discussed above , the parameters λij are used to select which types of links are important in the ranking process . We consider all types of objects and links to be important in the DBLP network , so we follow [ 11 ] and set αi = 0.1 , λij = 0.2 , ∀i , j ∈ {1 , . . . , m} . This may not be the optimal choice , but it is good enough to demonstrate the effectiveness of our algorithm . Since labels are given for selected authors and papers , the results on conferences of wvRN , nLB and LLGC can only be obtained by mining the original heterogeneous information network ( denoted by A C P T ) and disregarding the type differences between objects and links . While classifying authors and papers , we also tried constructing homogeneous author author ( A A ) and paper paper ( P P ) sub networks in various ways , where the best results reported for authors are given by the co author network , and the best results for papers are generated by linking two papers if they are published in the same conference . Note that there is no label information given for conferences , so we cannot build a conference conference ( C C ) sub network for classification . We show the classification accuracy
1
0.8
0.6
0.4
0.2 i t h g e w k n i l e g a r e v A
0
0
G in
G out
10
20
30
40
50
Number of iterations
1
0.8
0.6
0.4
0.2 i t h g e w k n i l e g a r e v A
0
0
G in
G out
10
20
30
40
50
Number of iterations
1
0.8
0.6
0.4
0.2 i t h g e w k n i l e g a r e v A
0
0
G in
G out
10
20
30
40
50
Number of iterations
( a ) Links connected to authors
( b ) Links connected to conferences
( c ) Links connected to papers
Figure 1 : Link weight change in 50 iterations on authors , papers and conferences in Tables 3 , 4 and 5 , respectively . The last row of each table records the average classification accuracy while varying the percentage of labeled data .
RankClass outperforms all other algorithms when classifying authors , papers and conferences . Note that even though the number of authors is much higher than the number of conferences , RankClass achieves comparable accuracy for both of these types of objects . While classifying authors and papers , it is interesting to note that wvRN and nLB perform better on the author author and paperpaper sub networks than on the whole heterogeneous information network . We observe a similar result when we use LLGC to classify papers . These results serve to verify that homogeneous classifiers like wvRN , nLB and LLGC are more suitable for working with homogeneous data . However , transforming the heterogeneous information network into homogeneous sub networks inevitably results in information loss . For example , in the author author subnetwork , the conferences where each author often publishes papers , and the terms that each author likes to use , are no longer known . Overall , GNetMine performs the second best by explicitly respecting the type differences in links and objects and thus encoding the typed information in the heterogeneous network in an organized way . Compared to GNetMine , RankClass achieves 16.6 % , 0.58 % and 17.3 % relative error reduction in the average classification accuracy when classifying authors , papers and conferences , respectively . Although RankClass has a knowledge propagation framework similar to that of GNetMine , RankClass aims to compute the within class ranking distribution to characterize each class , and further employs the ranking results to iteratively extract the sub network corresponding to each specific class . Therefore , the knowledge propagation for each class is more accurate .
We randomly select objects to obtain label information in our experiments . Similar to [ 21 ] , we observe that if we choose some representative ( or highly ranked ) objects ( eg , famous authors ) to label , the classification performance will be generally slightly better than when using labels of low quality ( eg , authors closely related to multiple fields , or with few publications ) . However , the difference is not significant . In other words , the initial choice of labeled data does not drastically affect the quality of ranking and classification . This is because our graph based ranking model in Equation ( 3 ) is a summation of two terms , where the first depends on the initial ranking , and the second depends on the network structure which ensures the smoothness of the learner . Even if the quality of the initial ranking distribution is not very high , RankClass can still generate a reasonable ranking distribution and label predictions . This is because RankClass exploits the relationships among objects in the network , iteratively propagating information through out the network ( see the first term of Equation ( 3) ) . Therefore , our algorithm is theoretically robust when working with random labels .
5.3 Convergence Study
Since our proposed RankClass algorithm iteratively adjusts the network structure to facilitate within class ranking , we further explore the changes of the link weights within the network . According to ground truth for each class k , all of the links connected to object type Xi can be divided into two groups : one contains the links that connect to at least one object of class k ( denoted as Gin ) , while the other group does not involve any objects of class k ( denoted as Gout ) . Links in Gin compose the sub network corresponding to class k , while links in Gout form the sub network excluding class k . In Figure 1 , we show the average weight of the links in Gin and Gout ( averaged over the four classes ) connected to authors , conferences and papers , along with the number of iterations , when ( 0.5 % , 0.5 % ) authors and papers are labeled . The link weight changes of Gin and Gout for each individual class are very similar to Figure 1 , and are omitted due to space limitation .
From Figure 1 , it can be observed that the average link weight of Gin and Gout are the same at first , and then decrease at various rates over iterations . During the first several iterations , the ranking scores have not propagated very far throughout the network and are close to 0 in value for many objects . Therefore , the weight of many links decreases almost exponentially as a result of multiplying by r(t ) . Then the ranking scores of objects within each class k gradually increase , making the average link weight in Gin decrease more slowly than that in Gout . Within a few iterations , the average link weights in Gin and Gout converge to relatively stable values . There is also a clear gap between the average link weights of Gin and Gout ( the former being much larger than the latter ) . Thus , the sub network corresponding to each class k is well separated from the rest of the network , and the within class ranking can be accurately performed within the sub network , rather than the global network . When the network structure stabilizes , the graph based ranking scheme can be proven to converge , following a similar analysis to [ 26 , 11 ] .
5.4 Case Study
In this section , we present a simple case study by listing the top ranked data objects within each class . Recall that GNetMine performs the second best in the classification accuracy , and can generate a confidence score for each object related to each class [ 11 ] . Thus , we can also rank data objects according to the confidence scores related to each class as the within class ranking . In Tables 6 and 7 , we show the comparison of the ranking lists of confer
Table 6 : Top 5 conferences related to each research area generated by different algorithms
RankClass
GNetMine
Database Data Mining
AI
IR
VLDB
SIGMOD
ICDE PODS EDBT
KDD SDM ICDM PKDD PAKDD
SIGIR ECIR CIKM SIGMOD
IJCAI AAAI ICML CVPR WWW ECML WSDM
PODS CIKM
SDM KDD ICDM PAKDD PKDD
Database Data Mining VLDB ICDE
AI
IR
SIGIR IJCAI ECIR AAAI CIKM ICML IJCAI CVPR ECML CVPR
Table 7 : Top 5 terms related to each research area generated by different algorithms
RankClass
GNetMine
Database Data Mining
AI
IR
Database
Data Mining data database query system xml mining data clustering frequent classification learning knowledge reasoning logic model retrieval information interlocking deindexing search web text seed bitemporal debugging rare extreme scan mining
AI failing interleaved cognition literals
IR helps specificity sponsored relevance information associations configuration y c a r u c c a n o i t a c i f i s s a C l
0.95
0.9
0.85
0.8
0.75
RankClass GNetMine
−1
10
0 10
−3
10
−2
10
α a
( a ) Varying αa y c a r u c c a n o i t a c i f i s s a C l
0.95
0.9
RankClass GNetMine
0.85
−3
10
−2
10
α p
−1
10
0 10
( b ) Varying αp y c a r u c c a n o i t a c i f i s s a C l
0.95
0.9
0.85
0.8
0.75
RankClass GNetMine
−4
10
−3
10
−2
10
−1
10
0 10
λ pa
( c ) Varying λpa
Figure 2 : Model Selection when ( 0.5 % , 0.5 % ) of authors and papers are labeled ences and terms generated by RankClass and GNetMine , respectively , with ( 0.5 % , 0.5 % ) authors and papers labeled .
From comparing the ranking lists of the two types of objects , we can see that RankClass generates more meaningful ranking results than GNetMine . There is a high degree of consensus between the ranking list of conferences generated by RankClass and the top conferences in each research area . Similarly , the highly ranked terms generated by RankClass are in high agreement with the most representative keywords in each field . The reason why GNetMine fails to generate meaningful ranking lists is that the portions of labeled authors and papers are too limited to capture the distribution of the confidence score with regard to each class . In contrast , RankClass boosts the ranking performance by iteratively obtaining the clean sub network corresponding to each class , which favors the within class ranking .
5.5 Model Selection
In the graph based ranking scheme in Equation ( 2 ) , the αi ’s and λij ’s are essential parameters which control the relative importance of different types of information . In the previous experiments , we empirically set αi ’s as 0.1 , and λij ’s as 0.2 , ∀i , j ∈ {1 , . . . , m} . In this subsection , we study the impact of parameters on the performance of RankClass . Since only several authors and papers are labeled , the αi associated with authors ( denoted by αa ) and papers ( denoted by αp ) , as well as the λij associated with the authorpaper relationship ( denoted by λpa ) are empirically more important than other parameters . Therefore we fix all other parameters and let αa , αp and λpa vary . As GNetMine performs the second best in the classification task , and has been proven to be robust over a large range of parameters [ 11 ] , we only compare RankClass with GNetMine in this experiment . Note that we also change the corresponding parameters αa , αp and λpa in GNetMine . We show the average classification accuracy on three types of objects ( author , paper , conference ) as a function of the parameters in Figure 2 , with ( a % , p % ) = ( 0.5 % , 0.5 % ) authors and papers labeled .
We observe that over a large range of parameters , RankClass achieves better performance than GNetMine [ 11 ] . Since the graphbased ranking scheme in RankClass has a knowledge propagation framework similar to that of GNetMine , the changes in accuracy of the two algorithms over different parameters trend in a similar fashion . However , RankClass generates more accurate and robust results by employing the ranking results to iteratively extract the sub network corresponding to each class . We therefore conclude that the performance of the RankClass algorithm is generally not very sensitive to the setting of its parameters .
5.6 Time Complexity Study
In this section , we vary the size of the database by randomly selecting connected sub networks from the original network , and then test the running time of our algorithm . The size of the database is measured by the number of nodes in the network . As can be seen in Figure 3 , the time complexity of our method is generally linear with respect to the size of the database , which is consistent with our analysis in Section 45
4 x 10
2.5
) c e s ( e m i t i g n n n u R
2
1.5
1
0.5
1
1.5
2
2.5
3
3.5
Size of the database
4 x 10
Figure 3 : Running time wrt database size
6 . CONCLUSIONS
In this paper , we investigate a new problem of classifying data objects in a heterogeneous information network , while simultaneously ranking each object according to its importance within each class , in order to provide informative class summaries . A novel ranking based classification algorithm called RankClass is proposed to iteratively solve this problem . During each iteration , we calculate the ranking distribution over the nodes of the network by authority propagation . The ranking results are then used to modify the network structure to allow the ranking model to improve the within class ranking . Thus , we gradually extract the sub network corresponding to each specific class from the global network . Finally , we calculate the posterior probability of each object belonging to each class to determine each object ’s optimal class membership .
In the future , we plan to more thoroughly analyze the theoretical foundation behind the ranking based classification framework to further justify its ability to enhance both classification and ranking . It would also be interesting to study integrating ranking and classification when working with non networked data .
7 . ACKNOWLEDGEMENTS
The work was supported in part by US National Science Foundation grants IIS 0905215 , IIS 1017362 , and the US Army Research Laboratory under Cooperative Agreement No . W911NF09 2 0053 ( NS CTA ) . The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies , either expressed or implied , of the Army Research Laboratory or the US Government . The US Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on .
8 . REFERENCES [ 1 ] W . Bian and D . Tao . Manifold regularization for sir with rate root n convergence . In NIPS 22 , pages 117–125 . 2009 .
[ 2 ] S . Brin and L . Page . The anatomy of a large scale hypertextual web search engine . Computer Networks , 30(1 7):107–117 , 1998 .
[ 3 ] B . Cao , N . N . Liu , and Q . Yang . Transfer learning for collective link prediction in multiple heterogeneous domains . In ICML , pages 159–166 , 2010 .
[ 4 ] D . R . Cutting , J . O . Pedersen , D . R . Karger , and J . W . Tukey .
Scatter/gather : A cluster based approach to browsing large document collections . In SIGIR , pages 318–329 , 1992 .
[ 5 ] Y . Freund and R . E . Schapire . A decision theoretic generalization of on line learning and an application to boosting . J . Computer and System Sciences , 55:119–139 , 1997 .
[ 6 ] B . Gao , T Y Liu , Z . Ma , T . Wang , and H . Li . A general markov framework for page importance computation . In CIKM , pages 1835–1838 , 2009 .
[ 7 ] J . Gao , F . Liang , W . Fan , Y . Sun , and J . Han . Graph based consensus maximization among multiple supervised and unsupervised models . In NIPS 22 , pages 585–593 , 2009 .
[ 8 ] A . Guillory and J . Bilmes . Label selection on graphs . In
NIPS 22 , 2009 .
[ 9 ] S . Hanneke and E . P . Xing . Network completion and survey sampling . In AISTAT , 2009 .
[ 10 ] T . Hastie , R . Tibshirani , and J . Friedman . The Elements of
Statistical Learning : Data Mining , Inference , and Prediction ( 2nd ed ) Springer Verlag , 2009 .
[ 11 ] M . Ji , Y . Sun , M . Danilevsky , J . Han , and J . Gao . Graph regularized transductive classification on heterogeneous information networks . In ECML/PKDD ( 1 ) , pages 570–586 , 2010 .
[ 12 ] J . M . Kleinberg . Authoritative sources in a hyperlinked environment . J . ACM , 46(5):604–632 , 1999 .
[ 13 ] B . Long , Z . M . Zhang , X . Wu , and P . S . Yu . Spectral clustering for multi type relational data . In ICML , pages 585–592 , 2006 .
[ 14 ] Q . Lu and L . Getoor . Link based classification . In ICML ,
2003 .
[ 15 ] S . A . Macskassy and F . Provost . A simple relational classifier . In MRDM at KDD , pages 64–76 , 2003 .
[ 16 ] S . A . Macskassy and F . Provost . Classification in networked data : A toolkit and a univariate case study . J . Mach . Learn . Res . , 8:935–983 , 2007 .
[ 17 ] J . Neville and D . Jensen . Relational dependency networks . J .
Mach . Learn . Res . , 8:653–692 , 2007 .
[ 18 ] Z . Nie , Y . Zhang , J R Wen , and W Y Ma . Object level ranking : bringing order to web objects . In WWW , pages 567–574 , 2005 .
[ 19 ] P . Sen and L . Getoor . Link based classification . Technical
Report CS TR 4858 , University of Maryland , February 2007 .
[ 20 ] L . Sun , S . Ji , and J . Ye . Hypergraph spectral learning for multi label classification . In KDD , pages 668–676 , 2008 .
[ 21 ] Y . Sun , Y . Yu , and J . Han . Ranking based clustering of heterogeneous information networks with star network schema . In KDD , pages 797–806 , 2009 .
[ 22 ] T . Yang , R . Jin , Y . Chi , and S . Zhu . Combining link and content for community detection : a discriminative approach . In KDD , pages 927–936 , 2009 .
[ 23 ] O . Zamir and O . Etzioni . Grouper : A dynamic clustering interface to web search results . Computer Networks , 31(11 16):1361–1374 , 1999 .
[ 24 ] B . Zhang , H . Li , Y . Liu , L . Ji , W . Xi , W . Fan , Z . Chen , and
W Y Ma . Improving web search results using affinity graph . In SIGIR , pages 504–511 , 2005 .
[ 25 ] Y . Zhang and Z H Zhou . Non metric label propagation . In
IJCAI , pages 1357–1362 , 2009 .
[ 26 ] D . Zhou , O . Bousquet , T . N . Lal , J . Weston , and
B . Schölkopf . Learning with local and global consistency . In NIPS 16 , 2003 .
[ 27 ] D . Zhou , J . Weston , A . Gretton , O . Bousquet , and
B . Schölkopf . Ranking on data manifolds . In NIPS 16 , 2003 .
