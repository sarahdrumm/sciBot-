Meta Optimization and its Application to Portfolio Selection
Puja Das
Dept of Computer Science & Engg
Univ of Minnesota , Twin Cities pdas@csumnedu
Arindam Banerjee
Dept of Computer Science & Engg
Univ of Minnesota , Twin Cities banerjee@csumnedu
ABSTRACT Several data mining algorithms use iterative optimization methods for learning predictive models . It is not easy to determine upfront which optimization method will perform best or converge fast for such tasks . In this paper , we analyze Meta Algorithms ( MAs ) which work by adaptively combining iterates from a pool of base optimization algorithms . We show that the performance of MAs are competitive with the best convex combination of the iterates from the base algorithms for online as well as batch convex optimization problems . We illustrate the effectiveness of MAs on the problem of portfolio selection in the stock market and use several existing ideas for portfolio selection as base algorithms . Using daily S&P500 data for the past 21 years and a benchmark NYSE dataset , we show that MAs outperform existing portfolio selection algorithms with provable guarantees by several orders of magnitude , and match the performance of the best heuristics in the pool .
Categories and Subject Descriptors H28 [ Database Management ] : Database Applications—Data mining
General Terms Algorithms , Theory
Keywords Meta Optimization , Online Learning , Portfolio Selection
1 .
INTRODUCTION
Several data mining algorithms use iterative update methods for learning predictive models . Typically , there are several choices for iterative update methods including gradient based or Newton step based optimization routines , stochastic gradient descent algorithms , domain specific methods , evolutionary and genetic algorithms , or plain heuristics . It is not easy to determine upfront which method will converge fast or perform the best .
While multiple iterative update methods can be run in an embarrassingly parallel manner , it is unclear if iterates from multiple algorithms for the same problem can be meaningfully combined to guarantee good optimization performance . Ideally , one would like the combined iterates to outperform the best algorithm in the pool , noting that the best algorithm may be different for different problem settings and domains . Such a desideratum is related to ensemble methods for prediction problems , where one expects the ensemble prediction to outperform the single best predictor in the pool [ 13 , 6 , 7 ] . In this paper , we investigate a related question in the contest of iterative optimization : Can iterates from multiple iterative update algorithms for the same problem be combined in a way so as to outperform the single best algorithm in the pool in terms of optimization performance ? Related questions have been investigated in certain other contexts , including online learning [ 9 , 22 ] and genetic programming [ 24 , 27 ] . t = Pk
The setting we consider is fairly general : Given a canonical convex optimization problem minx∈P φ(x ) and a set of k different base algorithms which generate an iterate xt,h ∈ P , 1 ≤ h ≤ k in every iteration , can we form an adaptive convex combination of the iterates xwt h=1 wt,hxt,h whose performance is at least as good as the best single algorithm . There is no requirement from the base algorithms other than producing a feasible xt,h ∈ P in every iteration . In particular , the base algorithms need not guarantee monotonic improvements in the objective function , and may be based on a heuristic without any guarantees . To make our analysis general , we even allow the convex function to change over time . Using advances in online learning and online convex optimization [ 8 , 22 , 20 , 9 , 15 ] , we develop two algorithms for adaptively combining iterates which are guaranteed to be as good as the best convex combination of iterates , and hence the best algorithm . We extensively evaluate the proposed methodology in an important problem in financial data mining—portfolio selection [ 23 , 10 , 16 , 1 ] . The goal is to adaptively update a portfolio over a set of stocks so that the returns over time are maximized . The problem can be posed as an online convex optimization problem , where the convex function gets determined by market movements on each day [ 1 , 16 , 10 ] . Due to its importance , the portfolio selection problem has been widely studied for six decades [ 23 , 19 , 10 , 9 ] , and numerous algorithms and heuristics exist on how to pick the next days portfolio which forms the iterate xt,h in our setting . We use a pool of these existing algorithms for portfolio selection , and focus on creating a portfolio by adaptively combining the portfolios suggested by the base algorithms . Through our analysis and algorithms , we establish theoretical results and illustrate strong empirical performance . In particular , we show that the meta algorithms for portfolio selection will be universal , ie , competitive with the best constant rebalanced portfolio ( CRP ) chosen in hindsight [ 10 , 18 , 4 ] , if any base algorithm in the pool is universal . Note that universal portfolios are guaranteed to be as good as the best stock
1163 even in adversarial settings . Our experiments show that the meta algorithms outperform all existing universal algorithms by orders of magnitude , by suitably leveraging good heuristics in the pool . For example , trading on S&P500 stocks over the past 21 years ( 1990 2010 ) , the meta algorithms multiply the starting wealth by 103 times even with two major financial meltdowns . Further , the proposed meta algorithms clearly outperform other simplistic approaches to combining portfolios .
The rest of the paper is organized as follows . We present a general framework and two algorithms for meta optimization in Section 2 . In Section 3 , we specialize the analysis and algorithms to the problem of portfolio selection . We present comprehensive experimental results in Section 4 , and conclude in Section 5 .
2 . ONLINE META OPTIMIZATION
Consider the following generic convex optimization problem which shows up while building models for a variety of data mining tasks [ 25 ] :
φ(x ) , min x∈P
( 1 ) where φ is a convex function and P ∈ Rd determines the convex feasible set . For the meta optimization setting , we assume access to k different iterative algorithms A1 , . . . , Ak , referred to as base algorithms , which attempt to solve the above problem . In particular , Ah is assumed to generate a feasible xt,h ∈ P at every iteration . The analysis we present does not depend on any other properties of the base algorithms or the iterates . The iterates may be coming from a iterative convex optimization routines based on gradient or Newton methods , from domain specific heuristics , or even entirely arbitrary guesses . The proposed meta algorithm picks a suitable iterate from the convex hull of the iterates at any time , given by :
Co(Xt ) = whxt,h wh = 1 , wh ≥ 0
,
)
˛˛˛˛˛ kX h=1 where Xt = [ xt,1 ··· xt,k ] ∈ Rd×k is the matrix of iterates . Let ∆k denote the k dimensional simplex . Then , it is easy to see that h whxt,h ∈ Co(Xt ) will always the best point xw achieve a lower ( better ) objective function value than any of the ! individual iterates , ie , min w∈∆k
φ h=1 whxt,h
≤ φ(xt,h ) , ∀h .
In general , the best point xw
Figure 1 shows examples to illustrate the above point . In Figure 1(a ) , the best point in the convex hull of the iterates achieves the global minimum of the function ; in Figure 1(b ) , it is nearest to the global minimum ; and in Figure 1(c ) , the best point in the convex hull is an iterate itself , ie , a corner of the hull . t = Xtw ∈ Co(Xt ) inside the convex hull or equivalently the best convex combination w ∈ ∆k cannot be obtained in closed form . One can design optimization algorithms to find the best point inside the convex hull . Note that such computations have to be repeated at every iteration , since corners of the hull , determined by Xt , changes in every iteration . In this section , we develop algorithms which adaptively pick wt ∈ ∆k based on Xt−1 , and show that the iterates xwt h wt,hxt,h of the meta algorithm are competitive with any fixed convex combination w ∈ ∆k used over iterations , ie , ∀w ∈ ∆k we have t = Xtwt =P
( h=1
Xtw = kX t = Xtw = P kX
TX
φ(Xtwt ) ≤ TX t=1 t=1
φ ( Xtw ) + o(T ) .
( 2 )
( a )
( b )
( c )
Figure 1 : The best convex combination xw t of the iterates from the base algorithms is always better than individual iterates xt,h(the red dot is the global minimum and the green dot is the best point in the convex hull of iterates ) : ( a ) xw t achieves the global minimum , ( b ) xw is on an edge of the hull , and ( c ) xw t t overlaps with the best iterate .
In particular , if any w∗ ∈ ∆k achieves the global minimum , the adaptive approach will find the global minimum as well . Indeed , instead of simply being competitive with the single best iterate , the adaptive xwt t will be competitive with any convex combinations of them ( Figure 1 ) . To present our analysis in its full generality , we consider the online convex optimization ( OCO ) setting [ 28 ] , where the convex function itself can change over time . We denote the convex function at time t to be φt . Note that we can recover the batch case analysis for a fixed φ as a special case by simply setting φt = φ,∀t . In the OCO setting , we intend to get a set of such that the following form of regret bounds adaptive iterates xwt t are satisfied :
φt(Xtwt ) ≤ min w∈∆k
φt ( Xtwt ) + o(T ) .
( 3 )
TX t=1
TX t=1
2.1 Online Gradient Updates
Our meta algorithm and analysis for Online Gradient Updates ( OGU ) involves suitably reducing the Online Meta Optimization ( OMO ) problem to an online learning problem over k experts [ 22 , 9 ] , where each expert corresponds to a corner for meta optimization . We start by recalling a standard result from the online learning literature [ 22 , 12 , 3 ] : Lemma 1 Let t ∈ [ 0 , 1]k , t = 1 , . . . , T , be an arbitrary sequence of loss vectors over the k experts . If one maintains an adaptive distribution over the experts using multiplicative updates given by pt+1(h ) = pt(h ) exp(−ηt(h))/Zt , where η > 0 and Zt is the partition function , then for any w ∈ ∆k , the following inequality holds : t t ≤ ηPT pT
TX t=1 t=1 wT t + log k 1 − exp(−η )
.
( 4 )
Variants of the above result form the basis of much work in online learning , boosting , game theory , and numerous other developments in the past two decades [ 22 , 12 , 11 , 2 , 3 , 9 ] . We now outline a transformation of the OMO problem to the above online learning setting . For our analysis , we assume that the sequence of convex functions φt can be arbitrary , but satisfies ∇φt(x)∞ ≤ g∞ for x ∈ P . Further , we assume x ∈ P satisfies x1 ≤ c . For the portfolio selection application in Section 3 , we will obtain specific values for g∞ and c . Let ft(w ) = φt ( Xtw ) .
( 5 )
1164 o
Algorithm 2 Online Newton Update ( ONU ) for Meta Optimization 1 : Initialize w1 ∈ ∆k 2 : Let β = min 3 : For t = 1 , . . . , T 4 : 5 : 6 : 7 :
Receive Xt = [ xt,1 ··· xt,k ] from base algorithms Compute xwt Receive convex function φt from nature Update distribution h=1 wt,hxt,h
8cg∞ , α n 1 t =Pk YAt where At andQAt wt − 2 β t ∇ft −1 A are as in ( 9 ) and ( 10 ) . wt+1,h =
„
«
∆k
,
∆k
∆k . Adding over all t and using ( 8 ) , we have
TX ft(wt ) − TX ft(w ) ≤ 2cg∞
TX “ p2T log k + log k t=1
”
. t ( wt − w ) T
Noting that the above inequality holds for any w ∈ ∆k completes the proof .
2T log k + log k´ = o(T ) , we have a desired
Since 2cg∞`√ form of the bound . Further , assuming φt = φ gives the corresponding bound for the batch optimization case . 2.2 Online Newton Updates
Our analysis for Online Newton Updates ( ONU ) build on recent advances in Online Convex Optimization ( OCO ) [ 15 , 1 ] . The analysis of ONU differs from the standard analysis of online Newton step [ 15 ] due to two reasons : first , our analysis focuses on the derived convex function ft : ∆k → R instead of the original convex function φt : P → R , and second , our bounds are based on the L∞ norm of φt instead of the L2 norm , which can be substantially larger for high dimensional problems . Following [ 15 ] , we consider convex functions φt which satisfy the α exp concavity property : there is a α > 0 such that for x ∈ P , exp(−αφt(x ) ) is a concave function . Note that α exp concave functions φt are more general than ones which have bounded gradients and Hessians which are strictly bounded away from 0 , ie , ∇2φt HI for some constant H > 0 . As before , we assume that L∞ norm of the gradient of φt are bounded above , ie , ∇φt∞ ≤ g∞ .
With these assumptions , Algorithm 2 presents the Online Newton Update ( ONU ) algorithm for Online Meta Optimization [ 15 ] . In essence , the algorithm takes a Newton like step from the current iterate wt , and then projects the vector to the feasible set ∆k to obtain wt+1 . Note that the algorithm does not use the actual Hessian of ft , but a matrix based on the outer product of the gradients defined as :
∇ft∇f T t + I ,
( 9 )
Algorithm 1 Online Gradient Update ( OGU ) for Meta Optimization 1 : Initialize w1,h = 1 2 : For t = 1 , . . . , T 3 : 4 : 5 : 6 :
Receive Xt = [ xt,1 ··· xt,k ] from base algorithms Compute xwt Receive convex function φt from nature Update distribution t =Pk k , h = 1 , . . . , k h=1 wt,hxt,h wt+1,h = wt,h exp(−ηt(h))/Zt where t(h ) is as in ( 6 ) and Zt is the partition function .
Since φt : P → R , where P ⊆ Rd , is a convex function , the function ft : ∆k → R is also convex . To see this , first note that the Hessian ∇2ft(w ) = X T t ∇2φt(Xtw)Xt . Since φt is convex , ∇2φ(Xtw ) is positive semi definite . Hence , ∇2ft(w ) is positive semi definite , implying convexity of ft . Define loss vector
„∇ft(wt ) cg∞ t =
1 2
« where e is the all ones vector . Based on this definition of loss , Algorithm 1 presents an adaptive algorithm for Online gradient update for meta optimization . We establish the following regret bound for OGO for this algorithm :
Theorem 1 For any sequence of convex functions φt such that ∇φt(x)∞ ≤ g∞ , and any sequence of iterates Xt = [ xt,1 ··· ··· xt,k ] such that xt,h1 ≤ c , for η = log in Algorithm 1 , we have q 2 log k
1 +
T
„
«
TX t=1
TX ft(wt ) − min w∈∆k ft(w )
“ p2T log k + log k t=1
”
.
( 7 )
≤ 2cg∞
PROOF . Since ∇ft(wt ) = X T t ∇φt(Xtwt ) , ∇ft(wt)∞ = t,h∇φt(xwt t )| . From Hölder ’s inequality [ 26 , 14 , 21 ] , maxh |xT t,h∇φt(Xtwt)| ≤ xt,h1∇φt(Xtwt)∞ ≤ cg∞ . |xT cg∞ ∈ [ −1 , 1]k , so that t ∈ [ 0 , 1]k . From Lemma 1 , Hence ∇ft(wt ) Algorithm 1 will satisfy ( 4 ) . Let = 1 − exp(−η ) so that from TX Lemma 1 we have t t − TX wT t ≤ T + log k , wT
1 where we have usedPt t=1 a direct calculation shows t=1 t=1 wT t ≤ T . Choosing = t ( wt − w ) ≤p2T log k + log k .
T
TX
√
√
√ 2 log k 2 log k+
,
T t=1
Now , since ft is convex , we have ft(wt ) − ft(w ) ≤ ∇ft(wt)T ( wt − w ) = 2cg∞T t ( wt − w ) , where the last equality follows since eT ( wt − w ) = 0 as wt , w ∈
∈ Rk ,
( 6 ) t=1 t=1
≤ 2cg∞
+ e
At = tX β2c2 . FurtherQAt YAt
τ =1
( ˜w ) = argmin w∈∆k
∆k
( 8 ) where = k Mahalanobis distance induced by At , ie ,
∆k is the projection onto ∆k using the
( w − ˜w)T A t ( w − ˜w ) . −1
( 10 )
We start our analysis by showing that if φt is α exp concave for x ∈ P , then ft is α exp concave for w ∈ ∆k for the same ( set of ) α .
1165 Since ∇ft ≤ √ TX we have ∇T t A k∇ft∞ ≤ √ „ kc2g2∞T t ∇t ≤ k log −1 t=1
« kcg∞ , from Lemma 11 in [ 15 ] ,
«
„ T
2a
+ 1
≤ k log
+ 1
, where we have used = k T ≥ 2a , T
8cg∞ , and a = 32g∞ c2 a . Plugging everything back , we have
. For
2a + 1 ≤ T TX
β2c2 , β ≤ 1 « „ 
+ 1
T a log ff 8cg∞ , α} , we have
Rt ≤ k β
= t=1
Since β = min{ 1 k β log eT a
.
1 α Plugging this upper bound back completes the proof .
≤ 8cg∞ +
8cg∞ ,
= max
1 α
1 β
.
3 . META OPTIMIZATION FOR PORTFO
LIO SELECTION
We consider a stock market consisting of n stocks {s1 , . . . , sn} over a span of T periods . For ease of exposition , we will consider a period to be a day , but the analysis presented in the paper holds for any valid definition of a ‘period,’ such as an hour or a month . Let rt(i ) denote the price relative of stock si in day t , ie , the multiplicative factor by which the price of si changes in day t . Hence , rt(i ) > 1 implies a gain , rt(i ) < 1 implies a loss , and rt(i ) = 1 implies the price remained unchanged . We assume rt(i ) > 0 for all i , t . Let rt = rt(1 ) , . . . , rt(n ) denote the vector of price relatives for day t , and let r1:t denote the collection of such price relative vectors upto and including day t . A portfolio xt = xt(1 ) , . . . , xt(n ) on day t can be viewed as a probability distribution over the stocks that prescribes investing xt(i ) fraction of the current wealth in stock st(i ) . Note that the portfolio xt has to be decided before knowing rt which will be revealed only at the end of the day . The multiplicative gain in wealth at the end of day t , is then simply rT i=1 rt(i)xt(i ) . Given a sequence of price relatives r1:t−1 = {r1 , . . . , rt−1} upto day ( t − 1 ) , the sequential portfolio selection problem in day t is to determine a portfolio xt based on past performance of the stocks . At the end of day t , rt is revealed and the actual performance of xt gets determined by rT t xt . Over a period of T days , for a sequence of portfolios x1:T = {x1 , . . . , xt} , the multiplicative gain in wealth is then t xt = Pn
”
TY
“ t=1
TX
φt(xt ) = − TX
The above problem can be viewed as an Online Convex Optimization ( OCO ) , where the convex function φt(xt ) = − log(rT t xt ) , and the cumulative loss over T iterations is log(rT t xt ) = − log S(x1:T , r1:T ) .
( 14 ) t=1 t=1
There are numerous algorithms in the literature for picking the portfolio xt on a given day based on past information r1:(t−1 ) [ 10 , 16 , 9 , 1 , 5 ] . Instead of proposing new algorithms for the task , we focus on meta optimization to combine the portfolios from a pool of base algorithms from the literature . We now specialize the general case results and algorithms of Section 2 to the task of portfolio selection . Consider k base algorithms {A1 , . . . , Ak} for portfolio selection where algorithm Ah generates a portfolio xt,h ∈ ∆n based on the past information r1:(t−1 ) . Recall that our analysis does ft(wt ) − min w∈∆k ft(w ) ≤ k
8cg∞ +
1 α log eT a
. ( 12 )
S(x1:T , r1:T ) = rT t xt
.
( 13 )
Lemma 2 If φt is α exp concave for some α > 0 , then ft as defined in ( 5 ) is also α exp concave .
PROOF . Let ht(w ) = exp(−αft(w) ) . The Hessian is given by
∇2ht(w ) = [ α2(∇ft)(∇ft)T − α∇2ft]ht(w )
= X T t [ α2(∇φt)(∇φt)T − α∇2φt]Xtht(w )
Let ψt(x ) = exp(−αφt(x) ) . Since φt is α exp concave , the Hessian ∇2ψt 0 , so that
[ α2(∇φt)(∇φt)T − α∇2φt]ψt(x ) 0 .
Let Bt = [ α2(∇φt)(∇φt)T − α∇2φt ] . Since ψt(x ) ≥ 0 , we have
Bt 0 ⇒ X T t BtXt 0 , so that ∇2ht 0 since ht(w ) ≥ 0 , implying ht is α exp concave .
We now establish a result , similar to Lemma 3 in [ 15 ] , but using the L∞ bound g∞ and the fact that x1 ≤ c for x ∈ P . Lemma 3 For β ≤ min{ 1
8cg∞ , α} , for any w , wt ∈ ∆k , we have ft(w ) ≥ ft(wt ) + ∇ft(wt)T ( w − wt )
( w − wt)T∇ft(wt)∇ft(wt)T ( w − wt ) .
+
β 4
( 11 )
PROOF . Since β ≤ α , following the proof of Lemma 3 in [ 15 ] we have log[1 − β∇ft(wt)T ( w − wt ) ] . ft(w ) ≥ ft(wt ) − 1 β Now , by Hölder ’s inequality , |β∇ft(wt)T ( w−wt)| ≤ β∇ft(wt)∞w−wt1 ≤ 2βcg∞ ≤ 1 4 Since − log(1 − z ) ≥ z + 1 4 , using it for z = β∇ft(wt)T ( w − wt ) completes the proof .
4 z2 for |z| ≤ 1
.
We now present the main result for ONU :
Theorem 2 For any sequence of α exp concave functions φt such that ∇φt∞ ≤ g∞ for x ∈ P where x1 ≤ c , for T ≥ 2a where a = 32g∞ c2
, we have the following regret bound :
„
«
TX t=1 t=1 we have
∇T t A
TX t ∇t+ −1
Rt ≤ 1 β
PROOF . Using Lemma 3 and using the proof of Theorem 2 in [ 15 ] ,
( wt−w)T ( A1−∇1∇T
TX At = Pt τ =1 ∇τ∇T 2 ≤ 4c2 , and = k TX
1 )(w1−w ) , where Rt = ft(wt ) − ft(w ) for any w ∈ ∆k , ∇t = ∇ft , and 1 = I , w1 − w2
τ + I as in ( 9 ) . Since A1 − ∇1∇T
β2c2 , we have
β 4 t=1
∇T t A t ∇t + −1
Rt ≤ 1 β t=1 w1 − w2
2
.
β 4 k β
≤ 1 β
∇T t A t ∇t + −1
TX t=1
TX TX t=1 t=1
1166 not impose any other constraints on the base algorithms and so they can be based on theoretically well grounded ideas [ 10 , 16 , 1 ] or good heuristics [ 5 ] . Given the set of base portfolios Xt = [ xt,1 ··· xt,k ] , the goal of the meta algorithm is to choose wt ∈ ∆k to construct the portfolio xwt t = Xtwt and subsequently incur loss ft(wt ) = φt(xwt t Xtwt ) . Since a portfolio x ∈ ∆n , we have c = x1 = 1 . Among all price relatives over all stocks , let rmin = mini,t rt(i ) > 0 and let , ∇φt(x)∞ ≤ rmax = maxi,t rt(i ) . Since ∇φt(x ) = − rt rT t x = g∞ . For convenience , we use ¯u = rmax . For our subsermin t ) = − log(rT t ) = − log(rT rmax rmin quent analysis , we note that t xwt
∇ft(wt ) = − X T t rt rT t Xtwt
( 15 ) Gradient Updates : Since ∇φt(x ) for portfolio selection is a positive vector , one can define the loss vector for OGU in Algorithm 1 as follows :
. t =
∇ft(wt ) cg∞
= − 1 2¯u
X T t rt rT t Xtwt
+ e .
( 16 )
With this modification , the OGU in Algorithm 1 has the following guarantee :
Corollary 1 For any sequence of price relatives r1:T and any sequence of base portfolios X1:T , the log wealth accumulated by Algorithm 1 choosing adaptive wt satisfies the following regret bound :
TX max w∈∆k log(rT t=1
≤ ¯u t Xtw ) − TX “ p2T log k + log k t=1 log(rT
”
. t Xtwt )
( 17 )
The proof follows from a direct application of Theorem 1 . We briefly discuss the implication of the fact that the wealth accumulated by the adaptive meta algorithm will be competitive with any fixed combination strategy chosen in hindsight . If one of the base algorithms is universal [ 10 , 16 , 4 , 17 , 9 ] , ie , competitive with best constant rebalanced portfolio ( CRP ) [ 10 , 4 ] in hindsight so that
TX max x∈∆n t x ) − TX t=1 t=1 log(rT log(rT t xt ) = o(T ) ,
( 18 ) then our meta algorithm will also be universal . Also , since the best CRP would outperform the best stock , having an universal algorithm in the pool is sufficient to ensure the meta algorithm will be competitive with the single best stock in hindsight . More generally , the meta algorithm will be competitive with the best convex combination of the base algorithms , which is guaranteed to be better than the best base algorithm in the pool ( Figure 1 ) .
Newton Updates : We start our analysis with the following result :
Lemma 4 φt(x ) = − log(rT α ∈ ( 0 , 1 ] . t x ) is a α exp concave function for
PROOF . Let ψt(x ) = exp(−αφt(x ) ) = ( rT t x)α . A direct cal culation shows the Hessian to be
As a result , Algorithm 2 can be applied as a meta algorithm for the portfolio selection problem . As before , c = 1 , g∞ = ¯u . Choos≥ 1 . Hence , ing α = 1 , β = min{ 1 e ≤ 12¯u . Usβ = 8¯u . Further , a = 32g∞ 1 ing the above values in Algorithm 2 , from Theorem 2 we have the following result :
8¯u since ¯u = rmax rmin c2 = 32¯u , so that a
8¯u , α} = 1
Corollary 2 For any sequence of price relatives r1:T and any sequence of base portfolios X1:t , the log wealth accumulated by Algorithm 2 choosing adaptive wt satisfies the following regret bound :
TX t Xtw ) − TX max w∈∆k log(rT t=1 t=1 log(rT t Xtwt ) ≤ 8k¯u log
T 12¯u
.
( 19 )
As before , the proof follows from a direct application of Theorem 2 . The bound has the same optimality properties as discussed √ In fact , the worst case regret of in the context of OGU above . T ) for OGU . The ONU grows as O(log T ) as opposed to O( bound for OGU can in fact be sharpened in this setting by suitably modifying the OGU algorithm and analysis using the fact that the Hessian ∇2ft is bounded away from 0 under the assumption mini,t ri,t > 0 .
4 . EXPERIMENTAL RESULTS
We conducted extensive experiments on two financial data sets to establish how effective Online Meta Optimization can be carried out by OGU and ONU . In this section , we describe the datasets that were chosen for the experiments , the algorithms , the parameter choices and most importantly the results of our experiments . Datasets : The experiments were conducted on two major datasets : the New York Stock Exchange dataset ( NYSE ) [ 10 ] and a Standard & Poor ’s 500 ( S&P 500 ) dataset . The NYSE dataset consists of 36 stocks with data accumulated over a period of 22 years from July 3 , 1962 to Dec 31 1984 . The dataset captures the bear market that lasted between January 1973 and December 1974 . However , all of the 36 stocks increase in value in the 22 year run .
The S&P500 dataset that we used for our experiments consists of 263 stocks which were present in the S&P500 index in December 2010 and were alive since January 1990 . This period of 21 years from 1990 to 2010 covers bear and bull markets of recent times . Methodology : We ran a pool of base portfolio selection algorithms and the Meta Algorithms on the datasets ( NYSE and S&P500 ) . For our experiments , this pool included universal and non universal algorithms . We start by briefly describing the base algorithms and the Meta Algorithms . 4.1 Base Algorithms
Of the base algorithms that we used for our experiments UP , EG and ONS are universal while Anticor and its variant are heuristics . Universal Portfolios ( UP):The key idea behind Cover ’s [ 10 ] UP is to maintain a distribution over all Constant Rebalanced Portfolios ( CRPs ) and perform a Bayesian update after observing every rt . Each CRP q is a distribution over n stocks and hence lies in the n simplex , one uses a distribution µ(q ) over the n simplex . The universal portfolio xt is defined as : q q(i)St−1(q , r1:t−1)µ(q)dq q St−1(q , r1:t−1)µ(q)dq
.
( 20 )
∇2ψt(x ) = α(α − 1 ) rtrT t rT t x
ψt(x ) , xt(i ) = which is negative semi definite for α > 0 if α ∈ ( 0 , 1 ] .
UP has a regret of O(log T ) with respect to the best CRP in hindsight . However , the updates for UP are computationally prohibitive .
R
R
1167 ( a ) Monetary returns on NYSE .
( b ) Monetary returns on S&P500 .
Figure 2 : Monetary returns of the Meta Algorithms , MA EG and MA ON S for $1 investment , is competitive with the best performing base algorithm ONS in this case(best viewed in color ) .
( a ) Monetary returns on NYSE .
( b ) Monetary returns on S&P500 .
Figure 3 : Monetary returns of the meta algorithms(MAEG , MAON S ) when Anticor30 is added to the pool of base algorithms . Anticor30 performs best and particularly MAEG is able to track Anticor30 ( best viewed in color ) .
Exponentiated Gradient ( EG ) : Exponentiated Gradient ( EG ) [ 16 ] scales linearly with the number of stocks but is weaker in regret than UP . The EG investment strategy was introduced and analyzed by [ 16 ] . At the start of day t , the algorithm computes its new portfolio vector xt such that it stays close to xt−1 and does well on the price relatives rt−1 for the previous day . The updated portfolio turns out to be xt(i ) = xt−1(i ) exp(ηrt−1(i)/xT i=1 xt−1(i ) exp(ηrt−1(i)/xT t−1rt−1 ) t−1rt−1 )
.
( 21 )
Pn where η > 0 is a parameter called the learning rate . Online Newton Step ( ONS ) : ONS uses a Newton step based method to compute the portfolio for the next iteration [ 1 ] . The Online Newton Step method can be shown to achieve sublinear regret and hence is an universal strategy .
The ONS algorithm uses following portfolio update method for round t > 1 :
„ YAt−1 where ∇t = ∇[log(xt · rt) ] , At =Pt negative constant , andQAt−1n xt =
∆n
A t−1∇t−1 −1 xt−1 − 1 ( 22 ) β τ =1 ∇τ∇τ + I , β is a nonis the projection onto the n simplex
∆n . Anticor : Anticor is a heuristic based method which does not confirm to the universal property for portfolio selection algorithms [ 5 ] . Here learning the best stocks ( to invest money in ) is done by exploiting the volatility of the market and the statistical relationship between the stocks . It implements the ‘reversal to the mean’ market
« phenomenon rather aggressively . One of the most important parameters for Anticor is the window length win . The version of Anticor implemented , works with two most recent windows of length win . The strategy is to move money from a stock i to stock j if the growth rate of stock i is greater than the growth rate of j in the most recent window . An additional condition that requires to be satisfied is the existence of a positive correlation between stock i in the second last window and stock j in the last window . For more details on the Anticor algorithm please refer to [ 5 ] . The experiments with different variations of the Anticor algorithm in [ 5 ] , brought to the fore the exceptional empirical performance improvement that this heuristic based approach can achieve over theoretically motivated approaches .
The performance of Anticor is sensitive to the window size win [ 5 ] .
One way to address this issue is to adaptively learn the weights and invest in a weighted version of all Anticorwins where win W . We consider a variant BAH(AnticorW ) , which maintains a uniform buy and hold investment on the Anticorwin , win ∈ [ 2 , W ] . 4.2 Meta Algorithms
Meta Algorithms ( MAs ) are constructed by combining a pool of base algorithms . Meta algorithm MAEG uses the gradient updates and this follows from OGU in Algorithm 1 and Meta Algorithm MAON S uses Newton updates and follows from ONU in Algorithm 2 . Meta Algorithms MAEG and MAON S are universal if at least one of the base algorithms in their pool is universal .
Additionaly , we used two other versions of Meta Algorithms for our experiments : MAAnticor and MABAH . MAAnticor is a Meta Algorithm version of Anticor . Like Anticor it works with differ
’62’64’66’68’70’72’74’76’78’80’82’8410−1100101102103YearLogarithmic Wealth GrowthMonetary returns on the NYSE dataset UPEGONSUCRPMAEGMAONS‘90‘91‘92‘93‘94‘95‘96‘97‘98‘99‘00‘01‘02‘03‘04‘05‘06‘07‘08‘09‘1010−1100101102103104YearLogarithmic Wealth GrowthMonetary returns on the S&P500 dataset UPEGONSUCRPMAEGMAONS’62’64’66’68’70’72’74’76’78’80’82’8410−2100102104106YearLogarithmic Wealth GrowthMonetary returns on the NYSE dataset UPEGONSAnticor30UCRPMAEGMAONS‘90‘91‘92‘93‘94‘95‘96‘97‘98‘99‘00‘01‘02‘03‘04‘05‘06‘07‘08‘09‘1010−1100101102103104YearLogarithmic Wealth GrowthMonetary returns on the S&P500 dataset UPEGONSAnticor30UCRPMAEGMAONS1168 ( a ) Monetary returns on NYSE .
( b ) Monetary returns on S&P500 .
Figure 4 : Monetary returns of the meta algorithms(MAEG , MAON S ) . BAH(Anticor30)is added to the pool of base algorithms . The Meta Algorithms continue to track the best algorithm in the pool.(best viewed in color ) .
( a ) Monetary returns on NYSE .
( b ) Monetary returns on S&P500 .
Figure 5 : Monetary returns of the meta algorithms(MAEG , MAON S , MAAnticor , MABAH ) . MAEG performs best while MAAnticor doesn’t fare well.(best viewed in color ) . ent window lengths over the pool of base algorithms . MABAH does a uniform buy and hold over the base algorithms and does not move money between the algorithms . Unlike MAEG and MAON S , MAAnticor and MABAH have no performance guarantees . 4.3 Results
The experimental setup can be broadly categorized into three subcategories : ( a ) Universal Pool , ( b ) Mixed Pool 1 and ( c ) Mixed Pool 2 based on the pool of base algorithms that were used by the MAs . Universal Pool : In the Universal Pool setup , the MAs worked with universal base algorithms UP , EG , and ONS . Figure 2 shows the wealth accumulated by the universal base algorithms on the NYSE and S&P500 datasets . We see that ONS performs best , followed by EG and UP . Figure 2 also shows that the two Meta Algorithms MAEG and MAON S are able to catch up with the performance of ONS , the best performing algorithm in the pool . Mixed Pool 1 : The Mixed Pool 1 is formed by adding Anticor to the Universal Pool of base algorithms . In Figure 3 , we see that there is a stark difference in the wealth garnered by Anticor as compared to the Universal Pool of base algorithms . While for the NYSE dataset , Anticor ’s wealth is of the order of 106 ( almost 104 times the wealth gathered by ONS ) , for S&P500 , the wealth reaches the order of 103 . MAEG is able to catch up with the performance of Anticor for both the datasets . MAON S is very slightly behind Anticor and MAEG on the NYSE dataset . On S&P500 , the base algorithm ONS outperforms MAON S ( which is still better than UP and EG by a sybstantial margin ) . Mixed Pool 2 : To further emphasize the strength of the MAs we formed Mixed Pool 2 of base algorithms by adding BAH(AnticorW ) to Mixed Pool 1 . BAH(AnticorW ) outperforms Anticorwin ( for win W ) , EG , UP , and ONS . Figure 4 shows that the wealth achieved by MAEG and MAON S with BAH(AnticorW ) in the pool , is almost as much as BAH(AnticorW ) itself . Thus we see that Meta Algorithms , MAEG and MAON S are competitive with the best base algorithm in all the three experimental setups .
Figure 5 , shows the performance of MAAnticor and MABAH with the Mixed Pool 2 of base algorithms . The performance of the MAAnticor is inferior than both MAEG and MAON S . We could attribute this inferior performance to the inherent nature of Anticor which will tend to move money away from the base algorithms which are performing well . With a buy and hold version of MA called MABAH , the wealth gained is more than Anticorw , but less than that of BAH(AnticorW ) and MAEG and MAON S . Parameter choices : Parameter choices had to be made for the universal as well as non universal base algorithms . For EG , we experimented with different learning rate ( η ) values and found η = 0.05 to be a good choice , validating the observations in [ 16 ] . For ONS , β value was chosen as 1 . This gave better results than when β was chosen as a function of the market variability ( refer to [ 1 ] for details ) .
The window size w for Anticorwin was taken to be 30 . The performance of Anticorwin is a function of win as demonstrated in [ 5 ] . BAH(AnticorW ) combines multiple Anticorwin algorithms , win ∈ [ 2 , W ] to harness the strength of these different versions . We choose W = 30 for our experiments which might not be the optimal value for the NYSE and S&P500 datasets . Hoever , it is observed that BAH(Anticor30 ) surpasses all the base universal algo
’62’64’66’68’70’72’74’76’78’80’82’8410−2100102104106108YearLogarithmic Wealth GrowthMonetary returns on the NYSE dataset UPEGONSAnticor30BAH(Anticor30)UCRPMAEGMAONS‘90‘91‘92‘93‘94‘95‘96‘97‘98‘99‘00‘01‘02‘03‘04‘05‘06‘07‘08‘09‘1010−2100102104106YearLogarithmic Wealth GrowthMonetary returns on the S&P500 dataset UPEGONSAnticor30BAH(Anticor30)UCRP’62’64’66’68’70’72’74’76’78’80’82’8410−2100102104106108YearLogarithmic Wealth GrowthMonetary returns on the NYSE dataset UPEGONSAC30BAH(Anticor30)UCRPMAEGMAONSMAAC5MABAH‘90‘91‘92‘93‘94‘95‘96‘97‘98‘99‘00‘01‘02‘03‘04‘05‘06‘07‘08‘09‘1010−2100102104106YearLogarithmic Wealth GrowthMonetary returns on the SP500 dataset UPEGONSAnticor30BAH(Anticor30)UCRPMAEGMAONSMAAnticor5MABAH1169 ( a ) NYSE : weights of MAEG with η=05
( b ) S&P500 : weights of MAEG with η=1 .
Figure 6 : Traces the weights maintained by MAEG on the base algorithms EG , ONS and AC for NYSE and S&P500 with η values 0.5 and 1 respectively(best viewed in color ) . rithms and Anticor30 in terms of empirical performance and helps us establish that MAEG and MAON S can always manage to track the best strategy even if it is a heuristic .
The rate at which MAEG caught up with Anticor in terms of wealth increased as we increased the value of η . However , for very high values of η ( η 50 ) , the increase in the wealth gathered by MAEG changed by a small amount . For MAON S , the β value was chosen according to Lemma 3 . MAAnticor was run with different window lengths . We plotted the results with a window length of 5 , as this version was observed to perform reasonably well . It was observed that the performance of MAAnticor decreased as the window length was increased beyond 10 days . APY and Volatility : Table 1 presents the monetary returns in dollars , APY and volatility of the universal and non universal algorithms on the two datasets .
The wealth for the algorithms has been expressed as the final return on an initial investment of $1 . The values given for MAEG and MAON S are with Mixed Pool 2 of base algorithms . The top three final returns appear in bold face . APY : The Annual Percentage Yield ( APY ) of the algorithms were calculated based on the following formula : i × 100
1
Tyears − 1 h
APY =
( Final/Initial ) where Final and Initial are the final return and initial investment respectively for Tyears . BAH(Anticor30 , MAEG and MAON S have the top three ( in the order mentioned ) APY for both the datasets . Volatility : Volatility of the Algorithms were calculated by taking the standard deviation of the sequence of daily wealth relatives ( xt T rt ) over Tyears . Anticor30 and BAH(Anticor30 ) have more than twice the volatility of the base universal algorithms . MAEG and MAON S have almost the same volatility as BAH(Anticor30 ) . This could be explained by the fact that the MAs try to track BAH(Anticor30 ) .
Figure 6 renders the path traced by MAEG as a weighted combination of EG , ONS , and Anticor . Our experiments show that Anticor outperforms EG and ONS in terms of accumulated wealth by an overwhelming margin . Hence , we see that MAEG converges towards the Anticor corner and the rate of convergence depends on the learning rate η . We also conducted experiments where we interchanged the weights of AC and ONS ( switched corners ) once every was taken to be 500 , 1000 and 2000 days t for our experiments . Even after switching , MAEG quickly learned that Anticor is the best performing strategy . This led MAEG to automatically adjust its weight distribution over the base algoothms . MAEG is sensitive to the volatility . Our experiments show that days . The value of t
Table 1 : Monetary returns in dollars ( per $1 investment ) , APY and volatility of universal and non universal algorithms
Algorithm UP
EG
ONS
Anticor30
BAH(Anticor30 )
MAEG
MAON S wealth APY volatility wealth APY volatility wealth APY volatility wealth APY volatility wealth APY volatility wealth APY volatility wealth APY volatility
NYSE 18.56 14.20 0.0089 27.10 16.18 0.0085 109.17 23.78 0.0113 617754.61 83.32 0.0284 77626129.46 128.37 0.0195 68381688.71 127.06 0.0194 61119978.64 125.90 0.0194
SP500 17.42 15.36 0.0139 26.83 17.88 0.0116 1217.39 42.65 0.0201 4769.39 52.73 0.0191 58591.86 73.14 0.03296 41678.69 70.21 0.0287 37667.41 69.36 0.0286
MAEG might prefer ONS earlier on due to its low volatility ( See Figure 6 ( b) ) . But as the wealth accumulated by Anticor increases , it shifts its weight from ONS to Anticor .
5 . CONCLUSIONS
In this paper , we have presented the idea of designing new Meta Algorithms which work with a pool of base algorithms for optimization . We have shown that solutions from multiple iterative algorithms can be combined by Meta Algorithms to outperform the single best base algorithm . We demonstrate the efficacy of the Meta Algorithms in the domain of Online Portfolio Selection . Detailed experiments over the NYSE and S&P500 datasets show that the Meta Algorithms MAEG and MAON S beat the universal algorithms in terms of empirical performance but are still competitive with the best CRP in hindsight .
Although , the Meta Algorithms have exceptional performance ,
12/198406/197406/1966Weights by MAEG on EG , ONS and AC with η=0.507/196207/1970EGONSAC01/200512/200112/199712/2010Weights of MAEG on EG , ONS and AC with η=112/199301/1990ACEGONS1170 Online portfolio setection using multiplicative weights . Mathematical Finance , 8(4):325–347 , 1998 .
[ 17 ] A . Kalai and S . Vempala . Efficient algorithms for universal portfolios . Journal of Machine Learning Research , 3(3):423–440 , 2002 .
[ 18 ] A . Kalai and S . Vempala . Efficient algorithms for on line optimization . Journal of Computer and System Sciences , 713:291–307 , 2005 .
[ 19 ] J . L . Kelly . A new interpretation of information rate . Bell
Systems Technical Journal , 35:917–926 , 1956 .
[ 20 ] J . Kivinen and M . Warmuth . Exponentiated gradient versus gradient descent for linear predictors . Information and Computation , 132(1):1–64 , 1997 .
[ 21 ] O . Knill . Probability . Course notes from Caltech , 1994 . [ 22 ] N . Littlestone and M . Warmuth . The weighted majority algorithm . Information and Computation , 108:212–261 , 1994 .
[ 23 ] H . Markowitz . Portfolio selection . Journal of Finance ,
7:77–91 , 1952 .
[ 24 ] T . Soule . Voting teams : A cooperative approach to non typical problems . Proceedings of the Genetic and Evolutionary Computation Conference , pages 916–922 , 1999 .
[ 25 ] P . Tan , M . Steinbach , and V . Kumar . Introduction to Data
Mining , ( First Edition ) . 2005 .
[ 26 ] D . Williams . Probability with Martingales . Cambridge
University Press , 1991 .
[ 27 ] W . Yan , M . Sewell , and C . D . Clack . Learning to optimize profits beats predicting returns – comparing techniques for financial portfolio optimisation . Proceedings of the Genetic and Evolutionary Computation Conference , pages 1681–1688 , 2008 .
[ 28 ] Martin Zinkevich . Online convex programming and generalized infinitesimal gradient ascent . Proceedings of the 20th International Conference on Machine Learning , 2003 . they do not take into account the commission one has to pay while trading . This is also a shortcoming with the existing universal and non universal portfolio selection algorithms [ 10 ] [ 16 ] [ 1 ] [ 5 ] . Most of these algorithms trade every stock every day which is not practical as one can incur huge amount of commission costs . As part of our future work , we would like to investigate if a sparse version of the meta algorithm can take care of commissions and yet achieve good empirical performance . Also , the current models for on line portfolio selection do not model risk . Modeling risk and taking account of volatility of stocks is an interesting direction for our future work . Acknowledgements : The research was supported by NSF CAREER award IIS 0953274 , and NSF grants IIS 0916750 , IIS 0812183 , IIS 1029711 , and NetSE 1017647 . The authors also wish to thank Huahua Wang and Padmanabhan Balasubramanian for their help .
6 . REFERENCES [ 1 ] A . Agarwal , E . Hazan , S . Kale , and R . Schapire . Algorithms for portfolio management based on the newton method . Proceedings of the 23rd International Conference on Machine Learning , pages 9–16 , 2006 .
[ 2 ] S . Arora , E . Hazan , and S . Kale . The multiplicative update algorithm : A meta algorithm and applications . Technical report , Dept of Computer Science , Princeton University , 2005 .
[ 3 ] A . Banerjee . On Bayesian bounds . In Proceedings of the
23rd International Conference on Machine Learning , 2006 . [ 4 ] A . Blum and A . Kalai . Universal portfolios with and without transaction costs . In Proceedings of the 10th Annual Conference on Learning Theory , 1997 .
[ 5 ] A . Borodin , R . El Yaniv , and V . Gogan . Can we learn to beat the best stock . Journal of Artificial Intelligence Research , 21:579–594 , 2004 .
[ 6 ] L . Breiman . Bagging predictors . Machine Learning ,
24:123–140 , 1996 .
[ 7 ] L . Breiman . Random forests . Machine Learning , 45:5–32 ,
2001 .
[ 8 ] N . Cesa Bianchi , Y . Freund , D . P . Helmbold , D . Haussler ,
R . Schapire , and M . K . Warmuth . How to use expert advice . Journal of the ACM , 44(3):427–485 , 1997 .
[ 9 ] N . Cesa Bianchi and G . Lugosi . Prediction , Learning , and
Games . Cambridge University Press , 2006 .
[ 10 ] T . Cover . Universal portfolios . Mathematical Finance ,
1:1–29 , 1991 .
[ 11 ] Y . Freund and R . Schapire . Adaptive game playing using multiplicative weights . Games and Economic Behavior , 29:79–103 , 1999 .
[ 12 ] Y . Freund and R . E . Schapire . A decision theoretic generalization of on line learning and an application to boosting . Journal of Computer and System Sciences , 55(1):119–139 , 1997 .
[ 13 ] J . Friedman , T . Hastie , and R . Tibshirani . Additive logistic regression : A statistical view of boosting . Annals of Statistics , 2000 .
[ 14 ] B . Fristedt and L . Gray . A Modern Approach to Probability
Theory . Birkhauser Verlag , 1997 .
[ 15 ] E . Hazan , A . Agarwal , and S . Kale . Logarithmic regret algorithms for online convex optimization . Machine Learning , 69(2 3):169–192 , 2007 .
[ 16 ] D . Helmbold , E . Scahpire , Y . Singer , and M . Warmuth .
1171
