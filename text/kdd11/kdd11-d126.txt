Revisiting Sequential Pattern Hiding to Enhance Utility
Aris Gkoulalas Divanis Information Analytics Lab IBM Research – Zurich Rüschlikon , Switzerland agd@zurichibmcom
Grigorios Loukides
Health Information Privacy Lab
Vanderbilt University
Nashville , Tennessee , USA gloukides@vanderbiltedu
ABSTRACT Sequence datasets are encountered in a plethora of applications spanning from web usage analysis to healthcare studies and ubiquitous computing . Disseminating such datasets offers remarkable opportunities for discovering interesting knowledge patterns , but may lead to serious privacy violations if sensitive patterns , such as business secrets , are disclosed . In this work , we consider how to sanitize data to prevent the disclosure of sensitive patterns during sequential pattern mining , while ensuring that the nonsensitive patterns can still be discovered . First , we re define the problem of sequential pattern hiding to capture the information loss incurred by sanitization in terms of both events’ modification ( distortion ) and lost nonsensitive knowledge patterns ( side effects ) . Second , we model sequences as graphs and propose two algorithms to solve the problem by operating on the graphs . The first algorithm attempts to sanitize data with minimal distortion , whereas the second focuses on reducing the side effects . Extensive experiments show that our algorithms outperform the existing solution in terms of data distortion and side effects and are more efficient .
Categories and Subject Descriptors H28 [ Database Management ] : Database Applications— Data Mining
General Terms Algorithms , Security , Performance
Keywords Data privacy , Knowledge hiding , Sequential pattern hiding
1 .
INTRODUCTION
Sequential data are increasingly collected to support numerous applications in which the sequentiality of events is of primary interest . Examples of such data are web usage logs , which record web page accesses , or mobility data that capture the location of mobile devices at different moments in time [ 16 ] . Clearly , sequential data offer remarkable opportunities for discovering interesting behavioral patterns that can be beneficial to a broad community of people . For example , mining user mobility data can reveal interesting patterns that aid traffic engineers and environmentalists in their decisions . Publishing sequential data for data mining purposes , however , may lead to serious privacy violations , if sensitive knowledge patterns are discovered . For instance , the mining of knowledge patterns from mobility datasets may enable intrusive inferences regarding the habits of a portion of the population , or provide the means for unsolicited advertisement and user profiling . Similar concerns have also been raised related to medical data sharing [ 13 , 21 ] .
To address these concerns , knowledge hiding methods [ 5 ] are necessary . These methods conceal sensitive patterns that can otherwise be mined from published data , without seriously affecting the data and the nonsensitive interesting patterns . Clifton and Marks [ 12 ] , following D . E . O’Leary [ 24 ] who firstly pointed out the privacy breaches that originate from data mining algorithms , indicated the need to consider data mining approaches under the prism of privacy preservation . Since then , several methods emerged to hide knowledge that appears in the form of frequent itemsets and related association rules [ 19 , 27 , 29 ] , or classification rules [ 11 , 23 ] .
Unlike these works , this paper considers the problem of hiding sensitive knowledge that appears in the form of frequent sequences and can be disclosed through sequence pattern mining algorithms [ 6 , 9 ] . Sequential pattern hiding is a challenging problem , because sequences have more complex semantics than itemsets , and calls for efficient solutions that offer high utility . To our knowledge , only the work of [ 3 , 4 ] attempts to address this problem , but it may fail to identify high quality hiding solutions , as we discuss in Section 2 .
Our work makes the following contributions : • We re define the problem of sequential pattern hiding to capture the utility of released data by considering both the side effects and the distortion introduced by the hiding process . This allows the production of more useful data for the task they are disseminated for .
• We design two novel sequence hiding algorithms . The first algorithm aims to minimize data distortion , whereas the second focuses on ensuring that the nonsensitive interesting knowledge can still be discovered . • We extensively evaluate our algorithms , demonstrating that they significantly outperform the existing solution
1316 tid events
1 2 3 4 5 6 7 8 9 a b c c d e a b c e a c e b c a b d f g h h d h b d f h h h c d f g f d h f g ( a )
Nonsensitive seq . n1 =< a ; b > n2 =< a ; c > n3 =< a ; e > n4 =< c ; e > n5 =< d ; f > n6 =< d ; g > n7 =< f ; g > n8 =< h >
( c ) tid events tid events tid events
1 2 3 4 5 6 7 8 9
* b c c d e * b c e * c e b c a b d f g h h * h b d f h h h c * f g * * h f g ( d )
1 2 3 4 5 6 7 8 9
* b c c d e a b c e a c e b c a b * * g h h * h b d f h h h c * f g f d h f g ( e )
1 2 3 4 5 6 7 8 9 a b c c d e * b c e a c e b c a b d f g h h * h b d f * * * c * f g f d h f g ( f )
Sensitive seq . s1 =< a ; c ; e > s2 =< d ; f ; g > s3 =< d ; h > s4 =< f ; h >
( b )
Figure 1 : Example of ( a ) original data , ( b ) sensitive sequences , ( c ) nonsensitive sequences ( maximal ) , ( d ) HHA output [ 4 ] , ( e ) DBSH output , and ( f ) SBSH output ( * denotes a suppressed event , = 3 ) . in terms of reducing data distortion and side effects , while being an order of magnitude more efficient .
The rest of the paper is organized as follows . Related work is in Section 2 , where we also discuss the limitations of existing approaches . Section 3 provides the background . In Section 4 , we present the hiding strategies used by our algorithms , which are given in Section 5 . Section 6 contains the experimental evaluation and Section 7 concludes the paper . 2 . RELATED WORK
Approaches for privacy preserving data sharing fall into two general categories [ 5 ] . The first category of approaches attempt to protect the privacy of individuals , whose information is contained in the data , by preventing the disclosure of individuals’ identity [ 28 ] or sensitive information [ 8,10,15 ] . The second category , referred to as knowledge hiding , aims to prevent sensitive patterns from being mined from the data , and it is the one our work is related to .
Several hiding algorithms have been proposed with most of the research being conducted along the lines of protecting sensitive association and classification rules . In particular , association rule hiding evolved from efficient heuristic approaches [ 7 , 25 , 29 ] , to border based approaches [ 27 ] and , more recently , to exact hiding approaches that offer stronger quality guarantees at the expense of high computational cost [ 17,18,22 ] . Classification rule hiding , on the other hand , evolved around perturbation based techniques [ 11 ] that reduce the confidence of sensitive rules by modifying the values of attributes that support these rules , and reconstructionbased approaches [ 23 ] that reconstruct the dataset by using only records supporting nonsensitive rules .
The problem of sequential pattern hiding was recently investigated in [ 4 ] , where the focus was on hiding the sensitive knowledge in a way that minimally affects the support of the rest of the sequences in the database . The authors proposed HHA , a sanitization algorithm that operates as follows . First , for each sequence s of the original database , this algorithm computes the different ways ( called matchings ) in ′ which s supports any sensitive sequence s . Then , the original sequences are sorted in ascending order with respect to the number of matchings that they contribute to , and the top sequences are selected for sanitization , based on a userspecified disclosure threshold . The sanitization operation eliminates all matches of the sensitive sequences in the sequence s by marking selected events with a special symbol ∆ . To sanitize the sequence s , HHA finds , for each event e in s , the number of matchings ffi(e ) to which e contributes , and marks the events that contribute to most matches , until s no longer supports sensitive sequences . The approach of [ 4 ] has three limitations , which we address in this work .
First , the problem formulation adopted by [ 4 ] does not focus on side effects that may be introduced by the hiding process to nonsensitive frequent sequences . As a result , a large number of potentially interesting sequences may be lost in the sanitized dataset . Since the main reason behind publishing sequential data for data mining purposes is to enable the discovery of nonsensitive frequent sequences , the problem formulation of [ 4 ] may lead to producing solutions of low data utility . As can be seen in Fig 1(d ) , which shows the result of applying the HHA algorithm [ 4 ] with = 3 to the dataset of Fig 1(a ) , the nonsensitive frequent sequences n1 ; n2 ; n3 ; n5 and n6 are lost . This , however , can be avoided for n1 and n5 , as shown in Fig 1(f ) .
Second , the ( global ) selection criterion , used by HHA to identify sequences for sanitization , often selects sequences that incur high distortion when sanitized . That is , it may mark more events than necessary with ∆ . Consider , for ′ example , a sensitive sequence s = < a ; b ; c > and the sequences s1 = < a ; a ; a ; b ; c ; c ; c > and s2 = < a ; a ; b ; b ; c ; c > . ′ Both s1 and s2 contain ( ie , support ) s , but s1 does so with 9 matchings , s2 with only 8 . As a result , HHA chooses to sanitize s2 instead of s1 , assuming that this would incur less distortion . Notice , however , that s1 should be sanitized instead , since the minimum number of events that should be marked with ∆ to sanitize s1 is 1 ( ie , b should be marked with ∆ ) , whereas 2 events need to be marked with ∆ to sanitize s2 ( ie , both a ’s , or both b ’s , or both c ’s ) .
Third , HHA needs to compute ffi(e ) for each event e in every sequence s . As we discuss in Section 521 , our algorithms avoid this costly operation to improve efficiency .
3 . BACKGROUND
In this section , we provide the background for the sequence hiding problem and derive the problem statement . Without loss of generality , we follow the work of [ 4 ] in that we consider patterns that are simple sequences of symbols ( or events ) . As we discuss in Section 524 , our algorithms can easily be extended to support sequential patterns that follow the classical definition proposed in [ 6 ] . Let Σ = {e1 ; e2 ; : : : ; eM} be a set of literals ei , called symbols or events , where M denotes the cardinality of the set . A sequence s is an ordered list of events from Σ and is represented as s = < e1 ; e2 ; : : : ; em > , where ei ∈ Σ ; ∀i ∈ {1 ; : : : ; m} . A transaction T is an ordered pair ( tid ; s ) , where s is a sequence and tid a unique identifier used to distinguish among transactions that correspond to the same sequence . Furthermore , a sequence database D is a set of N transactions , carrying different identifiers . We define the length or size of a sequence s ( and denote it by |s| ) to be the number of events that the sequence contains . Moreover ,
1317 ( a )
( b )
( c )
( d )
( e )
Figure 2 : Example of ( a ) constructing graphs for s ; s and T , ( c ) an original dataset , ( d ) applying Annotate , ( e ) avoiding side effects .
′ and a transaction T , ( b ) constructing a single graph for fs ; s
′g if s
′ A transaction T = ( tid ; s ) supports a sequence s we say that a sequence s1 over Σ is contained in ( or , equivalently , is a subsequence of ) a sequence s2 over Σ , if s1 can be obtained by deleting ( |s2| |s1| ) events from sequence s2 . We use the symbol “ ⊑ ” to denote this type of relationship between two sequences , ie s1 ⊑ s2 . ′ ⊑ s . The support of a sequence s in database D is denoted by sup(s;D ) , and it is the number of transactions in D that support s . These transactions are called the supporting transactions of sequence s . The sequence s is called large or frequent in database D , if and only if its support in D is at least equal to a minimum support threshold , ie iff sup(s;D)≥ . Otherwise , s is called infrequent in D . The problem of mining sequential patterns requires , given a sequence database D and a minimum support threshold , to compute the set of all sequences that are supported by at least transactions in D , which is denoted with FD ; . We also formally define the sequence hiding problem below :
Problem 31 ( Sequence Hiding Problem ) Given a sequence database D , a minimum support threshold , and a set of sensitive sequences S ( selected by data owners among the frequent ones ) , construct a new , sanitized database D′ from D such that : ( 1 ) sup(s;D′ ) < , for each sensitive sequence s ∈ S , ( 2 ) FD′ ; = FD ; − S∗ ∗ ∈ FD ; |s ⊑ s ∗ ) , the number of events from D that are sanitized in D′
; s ∈ S} and ( 3 ) distance(D;D′
, where S∗ is minimum1 .
= {s
The sequence hiding problem requires sanitizing the database D so that ( 1 ) no sensitive sequence can be mined from D′ at a support threshold of or higher , ( 2 ) no sideeffects are introduced by the hiding process to D′ in terms of that are infrequent in D′ ( a ) sequences in FD ; − S∗ or ( b ) infrequent sequences in D appearing as frequent in D′ ( ghost sequences ) , and ( 3 ) the least number of events in sequences supported in D is sanitized ( marked or deleted ) to derive D′ , which implies that D′ should be kept as similar as possible to D . If symbols are marked with ∆ when sanitized , then distance(D;D′
) is equal to the number of ∆s in D′
.
As is proved in [ 4 ] , the problem of sanitizing a sequence by introducing the least distance is NP hard . In addition , it is important to observe that the three goals in Problem 3.1 are not of the same importance . That is , a sequence hiding algorithm has to accomplish the first goal to protect 1Following related work in frequent itemset hiding [ 19 ] , we in FD ; that con∗ do not consider the loss of a sequence s tains a sensitive sequence s ∈ S as side effect , as s will be inevitably hidden when we hide s .
∗ all the sensitive knowledge , but needs to prioritize between the second and the third goals , when generating a sanitized database . As we will see shortly , the two algorithms we propose guarantee that the first goal will be satisfied , but each focuses on one of the two other goals . Our first algorithm aims to minimize distance(D;D′ ) to incur low distortion , while the second algorithm favors fewer side effects instead of a smaller distance , a choice adopted by related work in association rule hiding [ 19 ] . We also apply only deletions of events to sanitize the sensitive sequences . Thus , no ghost sequences can be introduced by our approach and the second goal can be re stated as “ minimize the number of nonsensitive frequent sequences that are lost in D′ ” . Moreover , distance(D;D′ ∀T =(tid;s′)∈D′ |s ′| .
∀T =(tid;s)∈D |s| −∑
∑
) =
4 . HIDING STRATEGIES
In this section , we explain how to represent the matchings between sensitive sequences and transactions using multipartite graphs ( Section 4.1 ) and how to hide sequences guided by these graphs ( Section 42 ) Strategies to perform these operations in a way that reduces distance and helps prevent side effects are also discussed ( Section 43 ) 4.1 Graph based sequence representation Let S be the set of sensitive sequences from D , DS the transactions in D that support at least one sensitive sequence , and D ~S = D−DS . A nonsensitive frequent sequence is any sequence in FD′ ; , as defined in Problem 31 Given a transaction T , we use TS to refer to the set of sensitive sequences S ∈ S that T supports in D , and TN to refer to the set of nonsensitive frequent sequences that T supports in D . Given a sequence s = < e1 ; e2 ; : : : ; em > , we define the position of an event in the sequence : the first event ( e1 ) is in position 0 , : : : , the last event ( em ) is in position ( m− 1 ) . For notational convenience , we refer to a transaction T = ( tid ; s ) as Ttid = s .
Definition 41 Given a transaction T ∈ D and a sensitive sequence s , we define the matching graph Gs;T to be a multi partite graph with the following properties : ( a ) each position i of s corresponds to a different part ( or layer ) i in the graph that carries the symbol of s in this position as a label – the layers are positioned consecutively in Gs;T in the same order as the symbols of s , ( b ) for each position in T , a node lies in each layer of the graph that has the same label as the corresponding symbol in T – the node carries a label equal to the position of the corresponding symbol in T ,
0236 0 1 2 3 4 5 6T=<b,b,a,c,a,a,c> 0 1 2 3s=<b,c,a,c>14563b ( 0 ) c ( 1 ) a ( 2 ) c ( 3)0245b ( 0 ) a ( 1)0 0 1s'=<b,a>Gs,TGs',T1{s,s'}={<b,c,a,c>,<b,a>}456b c a c2G{s,s'},T 0 1 2 3 4 5 6T=<b,b,a,c,a,a,c> 0 1 2 3 0 101s's453tidevents1dfgg2da3dfg0223 d f g 01 T1=<d,f,g,g>Gs,T1Gs,T1 s=<d,f,g> n1=<d> 3n2=<f> 2n3=<g> 2n4=<d,f> 2n5=<d,g> 2n6=<f,g> 2022301 d f g nonsen . sequen . sup.ψ=1ψ=2024 c d f h 23 s=<c,d,f,h> T=<c,c,d,f,h,h,>10Gs,T65r=1r=2C SA(3,Gs,T,1)={4,5,6}C PA(3,Gs,T,1)={ }C PA(3,Gs,T,2)={0,1}Replace(3,Gs,T,2)={0,1}1318 ( c ) an edge between two nodes u ; v exists in the graph only if ( i ) u ; v are in adjacent layers , with u preceding v in the graph , and ( ii ) u ; v belong to a path defined as a sequence of nodes u1 ; u2 ; : : : ; u|s| ( based on the corresponding sequence of events in T ) for which each node ui is in the i th layer of the graph and label(u1 ) < label(u2 ) < : : : < label(u|s| ) – this is called a complete path2 , and ( d ) isolated nodes are removed from Gs;T .
Definition 4.1 assumes that |s| > 1 ( when |s| = 1 , Gs;T contains one node that has a self loop , forming a complete path by itself ) . Figure 2(a ) presents an example of constructing the matching graph for a transaction T and a sensitive sequence s . Observe that if we assume that , when visited , a node “ emits ” the symbol of the label of the layer , then traversing a complete path in Gs;T corresponds to one occurrence of the sensitive sequence in T . Likewise , the number of complete paths in Gs;T represents the different ways that the sensitive sequence is “ produced ” by T . To sanitize T , all these different matchings have to be removed , which is equivalent to cutting all complete paths in Gs;T . However , computing the complete paths in the matching graph incurs significant cost [ 4 ] . Our algorithms avoid this cost by requiring only the computation of complete paths that pass through a small number of selected nodes , as we show in Section 5 . Next , we discuss a graph merging operation that is useful when hiding many sensitive sequences .
Definition 42 Given a transaction T ∈ D , a set of sensitive sequences S ⊆ S and the matching graph Gsi;T , for each si ∈ S , we construct a matching graph GS;T for S and T by ( a ) identifying the largest set of nodes V that comprise a single layer in each Gsi;T ( breaking ties arbitrarily ) , ( b ) for each node in V , constructing a node in GS;T that has the same label , ( c ) for each node that is not contained in V , constructing a new node in GS;T that has the same label , and ( d ) for each edge ( u ; v ) in each Gsi;T , creating the edge ( u ; v ) in GS;T and annotating it with the identifier i of si .
Constructing the matching graph for a set of sensitive sequences allows our algorithms to find solutions of high quality , as we discuss later . Consider that we want to construct a ′} and the transacmatching graph GS;T for the set S = {s ; s tion T in Fig 2(a ) . The largest set of nodes , which comprise a single layer ( ie , nodes that are contained in a single layer that does not have any other nodes ) in both Gs;T and Gs′;T , contains the nodes labeled 0 and 1 . Thus , for each of the latter nodes , we construct a node in G{s;s′};T ( ie , we merge these nodes in Gs;T and Gs′;T ) . Next , we construct a node in G{s;s′};T , for each node that is not labeled 0 or 1 and is contained in Gs;T or Gs′;T , and copy the label of the latter node to the new one . For the edge ( 0 ; 5 ) in Gs′;T , we create an edge ( 0 ; 5 ) in G{s;s′};T and annotate this edge as corre′ sponding to s . Last , we perform the same for each other edge in Gs;T and also for Gs′;T to obtain the matching graph GS;T of Fig 2(b ) . 4.2 Sequence hiding
Matching graphs allow tackling the problem of sequence hiding based on a series of graph operations that guide the 2We use “ < ” , interpreted as “ less than ” , when comparing the labels of two nodes in the graph . In Fig 2(a ) , for instance , label(1 ) < label(3 ) , since b in the first position of T appears before c in the third position . sanitization of the transactions of D . Specifically , given one transaction T and a set of sensitive sequences S , the sanitization task for T becomes equivalent to applying the minimum number of node deletions in graph GS;T , so that all complete paths for the sensitive sequences si ∈ S are cut . As an example , consider the case of sanitizing T so that it no longer supports the sensitive sequence s , shown in Fig 2(a ) . This can be achieved by deleting nodes 0 and 1 , or 3 , or 4 and 5 , or 6 . Assuming that the criterion we want to optimize is distance ( goal 3 in Problem 3.1 ) , deleting any of nodes 3 , or 6 will achieve that with a cost of 1 .
An important observation follows if we want to sanitize T so that it no longer supports both sensitive sequences , s and ′ . If the sanitization is performed separately for s and for s ′ s , the hiding algorithm may choose to delete node 3 first , so that s is unsupported by T , and then nodes 0 and 1 , so that ′ s is unsupported by T . This leads to a total distance of 3 , and can be avoided if the hiding algorithm operates on the combined graph G{s;s′};T , shown in Fig 2(b ) . In this case , nodes 0 and 1 participate in all complete paths for both s ′ and s , and their removal can lead to the sanitization of T incurring a distance of 2 instead of 3 .
Another issue that needs to be addressed is the update of the matching graph after a delete operation . This is accomplished through a function Update paths which , given the transaction Ttid = s and the position p in s in which the symbol to be deleted lies , removes the corresponding node from the matching graph and then traverses the graph to delete any edges and nodes that belong to incomplete paths . 4.3 Utility considerations The hiding of sensitive sequences in D should be performed in a way that preserves the utility of the database D′ to the highest possible extent . Thus , in this section , we discuss novel strategies that are used by our hiding algorithms to tackle objectives ( 2 ) and ( 3 ) of Problem 31 Minimizing distance Minimizing distance requires finding the minimum number of events that need to be deleted from a transaction , but this is NP hard [ 4 ] . To deal with this problem , we present Cost , which is explained in Algorithm 1 . Cost begins by iterating over all distinct events contained in at least one sequence in TS ( step 1 ) . For each distinct event e , it constructs the set of sensitive sequences Se that contain e and assigns the number of occurrences of e to we ( steps 2 3 ) . Then , Cost computes the number of events that need to be deleted from T to sanitize it ( steps 4 9 ) . Specifically , it greedily selects the event e with the smallest ratio between we and |Se| , and assigns its weight to w ( step 7 ) . Next , Cost adds w to sc , which is used to count the number of events to be deleted , and Se to a set S ( steps 8 9 ) . This process is repeated until S contains all sequences in TS . Observe that deleting all occurrences of the selected events from T guarantees that T will be sanitized , because eventually S = TS . Despite its simplicity , Cost obtains a tight approximation error of O(ln(|TS|) ) , as proved in [ 14 ] . Example 1 . Consider applying Cost on T7 of Fig 1(a ) , which supports s3 and s4 of Fig 1(b ) . Cost begins by computing Sd = {s3} ; wd = 1 , Sf = {s4} ; wf = 1 , and Sh = {s3 ; s4} ; wh = 3 . Next , it assigns wd and then wf to w as wd|Sd| = wf|Sf | = 1 < wh|Sh| = 3
2 , and returns sc = 2 .
Minimizing side effects We present a mechanism that detects events whose deletion does not lead to side effects .
1319 Algorithm 1 Cost(T ; TS ) 1 . 2 . 3 . 4 . 5 . sc 0 S ∅ for each ( distinct event e in a sequence in TS ) Se the sequences in TS that contain e we the number of occurrences of e in T
6 . while ( there is a sensitive sequence s 2 TS n S ) w find the weight we of the event e with min( we|Se| ) sc sc + w S S [ Se
7 . 8 . 9 . 10 . return sc
Before doing so , we classify positions of T as follows . A position p is annotated as ( i ) black , if side effects are not introduced by removing the p th event of T , ( ii ) red if removing p generates side effects , or ( iii ) gray , if we cannot be certain whether the removal of p will lead to side effects .
The annotation of p is performed by Annotate , explained in Algorithm 2 . After assigning the sequences in TN that contain the p th event of T to TN p , Annotate checks whether these sequences have a support different than in D , and , in this case , annotates p as black ( steps 1 3 ) . If there exist sequences with a support of , Annotate iterates over them and annotates p as red , if at least one of them becomes infrequent after deleting the p the event from T ( steps 5 7 ) . If p has not been marked red after examining all sequences in TN p , Annotate marks it as gray and returns ( step 8 ) .
Example 2 . Consider applying Annotate to the position 0 of T1 in Fig 2(c ) using = 1 . Observe in Fig 2(d ) that the node labeled 0 in Gs;T1 , where s = < d ; f ; g > , is annotated black , because the sequences n1 to n6 are supported by at least 2 transactions . Had we used = 2 instead , this position would be annotated red , since the sequences n2 to n6 have a support of 2 , and n4 ; n5 , and n6 will be lost if the 0 th event is deleted from T1 .
As explained above , nonsensitive frequent sequences that contain the p th event of a transaction T will be lost if a red position p is deleted . However , this can be avoided if we locate a set of positions in the graph GS;T such that ( i ) they are all annotated black , and ( ii ) each complete path in GS;T that contains the node labeled p also contains a node labeled with at least one of these positions . We are interested in sets containing positions that appear either before or after p in T . These types of sets are referred to as PA ( Preceding Alternatives ) and SA ( Succeeding Alternatives ) , respectively . Unfortunately , finding such sets for a position p incurs significant computational overhead , as it may require examining a very large number of positions . To cope with this overhead , we restrict ourselves to considering positions that are reachable from p by following at most r edges in
GS;T , where ( radius ) r ∈ [ 1 ; maxj=1;:::;|S| |sj| ] is a parameter that controls the part of GS;T to be searched .
Specifically , we find a set PA using C PA(p ; GS;T ; r ) , a function that traverses GS;T to find a set of positions that satisfy properties ( i ) and ( ii ) mentioned above , lie in layers that appear before the layer of node p in GS;T , and are reachable from p by traversing at most r edges . C PA starts with positions that are reachable from p by following one edge in GS;T and increases the number of edges that are followed by one in each subsequent iteration . This function stops the first time a set P A is found or when the number of edges that are followed exceeds r . A set SA for p is found using a function similar to C PA , called C SA .
To find sets of positions in a way that helps reduce both distance and side effects , we use Replace , a function that , given a position p of T , the matching graph GS;T , and a specified r , utilizes C PA and C SA and returns the smallest of the sets constructed by them .
Example 3 . Consider position 3 in T , shown in Fig 2(e ) , which corresponds to the node labeled 3 in the matching graph Gs;T , and is annotated red . Applying Replace to this position using r = 1 yields {4 ; 5 ; 6} , which implies that the 4 th , 5 th , and 6 th events of T can be deleted instead of the 3 rd one . Observe that these positions are annotated black and s is hidden if their corresponding events are deleted . Using r = 2 instead yields {0 ; 1} , since the nodes with these labels are reachable from the node labeled 3 by following two edges , and the positions they correspond to are fewer than those returned by C SA(3 ; GS;T ; 2 ) .
Algorithm 2 Annotate(p ; D ; TN ; ) 1 .
TN p the nonsensitive frequent sequences in TN if ( no sequence nj 2 TN p has sup(nj ; D ) = ) that contain the p th event of T return black else for each ( nj 2 TN p such that sup(nj ; D ) = ) if ( sup(nj ; D ) < after deleting the p th event of T ) return red return gray
2 . 3 . 4 . 5 . 6 . 7 . 8 .
5 . ALGORITHMS
Sequence hiding involves selecting a number of transactions to sanitize and then deciding which events need to be deleted to perform the sanitization . In this section , we discuss our strategies for these steps and present two novel algorithms to perform the hiding task . 5.1 Selecting transactions to sanitize
As our goal is to release a database D′ in which all sensitive sequences are hidden , we first need to select the transactions from D that will be sanitized . Clearly , all transactions that do not support any sensitive sequence in S can safely be disclosed and will be part of D′ . Among the transactions supporting sensitive sequences , a set of transactions can be chosen to be part of D′ without being sanitized , as long as the support of each sensitive sequence in D′ remains below . This allows the selection of transactions that support sensitive sequences and incur low distortion when sanitized . To achieve this , we propose Exclude , a function that is used by our sanitization algorithms and described in Algorithm 3 . Exclude begins by computing the number of deletions required to sanitize each transaction in DS using Cost , and then sorts these transactions in descending order with respect to this cost ( steps 1 3 ) . Next , it iterates over each transaction T in DS and moves the transaction to D′ without sanitizing it only if every sensitive sequence supported by T has been encountered fewer than ( − 1 ) times . The remaining transactions in DS are subsequently sanitized . 5.2 Sanitizing sequences
In what follows , we introduce DBSH , an algorithm that employs Exclude and Cost to minimize distance , and SBSH which reduces side effects by utilizing Replace . The differences between these two algorithms and their extension to support itemset sequences , are also discussed .
1320 that , in step 4 , SBSH uses a variant of Annotate , which annotates every position corresponding to an event contained in a sensitive sequence s ∈ TS and stores the result for each position into an array A . In steps 7 37 , SBSH retrieves the element P [ i ] of P and selects a set of events that can be deleted to sanitize T in such a way that side effects are prevented . Note that the support of sequences in TN will not reflect whether a side effect has occurred if a red position is marked for deletion but has not yet been deleted from T . To detect side effects accurately , we compute supports as if the marked nodes had been removed and use a function Max updated support in step 7 , which returns the maximum support of sequences in TS . Algorithm 5 SBSH ( DS ; ; r;DN )
DS Exclude SBSH ( DS ; ) for each ( transaction T in DS ) fP ; Hg Candidates SBSH ( T ; TS ) A Annotate T ( T ; D ; TN ; ) R ∅ i 0 while(Max updated support(T ; TS ) )
positions of events to delete from T if ( A[P [ i ] ] is black )
R R [ P [ i ] Update paths(P [ i ] ; T ) if(P [ i ] = ∅ ) P [ i ] is not a valid position break i i + 1 ′ ∅ for each ( Sj H(j ) )
alternative positions to P [ i ]
R else if ( A[P [ i ] ] is red ) if ( GSj ;T has a path that contains only P [ i ] )
′ [ Replace(P [ i ] ; GSj ;T ; r ) break else ′ R R = ∅ ) if ( R
′ R R [ P [ i ] Update paths(P [ i ] ; T ) if(P [ i ] = ∅ ) break i i + 1 else
′ for each ( p
′ 2 R ) R R [ fp ′g ′ Update paths(p
; T )
R R [ P [ i ] Update paths(P [ i ] ; T ) if(P [ i ] = ∅ ) break i i + 1 else if ( Annotate(P [ i ] ; D ; TN ; ) is gray )
521 Distance Based Sequence Hiding ( DBSH ) DBSH is applied to DS and its pseudocode is provided in Algorithm 4 . It first uses Exclude to create a potentially smaller set of transactions , sorted in terms of sanitization cost and assigned to DS ( step 1 ) , and then selects a transaction T from DS to sanitize ( step 2 ) . In step 3 , DBSH uses a function Candidates to find an approximately minimal set of positions of T corresponding to events that need to be deleted to sanitize T . This function is similar to Cost except that it returns a set {P ; H} , where P is a 2D array and H a hashtable . Each element P [ j ] of P contains the positions of T that need to be deleted to hide a subset Sj ∈ TS , comprised of sequences that share at least one event , and it is associated to Sj using H . In addition , P is sorted in descending order of the size of the subsets of sequences its elements correspond to . Next , in steps 4 5 , DBSH retrieves the element P [ j ] of P and the subset Sj ∈ TS corresponding to P [ j ] , using H . Following that , it iteratively deletes events from the positions of T that are retrieved from P [ j ] as we increment i by 1 , if P [ j][i ] corresponds to a valid position , until T no longer supports Sj ( steps 7 13 ) . This process is repeated for each Sj ∈ TS and all transactions of DS . Algorithm 3 Exclude(DS ; ) for each ( transaction T in DS ) sort transactions in DS in descending order of cost for each ( transaction T in DS ) M a hashtable associating each s 2 TS with 0 if ( M ( s ) < ( , 1 ) , for each s 2 TS ) compute Cost(T ; TS )
DS DS n T for each ( s 2 TS ) increase M ( s ) by 1
1 . 2 . 3 . 4 . 5 . 6 . 7 . 8 . 9 . for each ( transaction T in DS ) fP ; Hg Candidates(T ; TS ) for each ( element P [ j ] 2 P ) delete the event in the P [ j][i] th position of T Update paths(p ; T ) if ( T supports Sj ) if(P [ j][i ] = ∅ ) P [ j][i ] is not a valid position break i i + 1
Sj H(j ) the subset of TS corresponding to P [ j ] i 0 while ( T supports Sj )
Algorithm 4 DBSH ( DS ; ) 1 . DS Exclude(DS ; ) 2 . 3 . 4 . 5 . 6 . 7 . 8 . 9 . 10 . 11 . 12 . 13 . 14 . return DS Cost analysis DBSH needs O(|D| × |T|2 × |s| ) time in the worst case when all transactions in D support at least one sequence in S , sensitive sequences do not share events , and = 1 , where |s| is the length of the largest sequence in S . The bottleneck of DBSH is Update paths , which takes O(|T| × |s| ) time [ 4 ] . 522 Side effect Based Sequence Hiding ( SBSH ) SBSH is explained in Algorithm 5 . This algorithm begins by calling Exclude SBSH , a variant of Algorithm 3 that removes the transaction that supports the largest number of sensitive sequences from DS , breaking ties arbitrarily if many transactions have the same sanitization cost . This choice can significantly reduce the number of sideeffects incurred by sanitization , as our experiments confirm . Then , SBSH considers the first transaction in DS and uses Candidates SBSH , which is similar to Candidates except that it creates an 1D array P containing positions that correspond to all sequences of TS ( steps 2 3 ) . After
1 . 2 . 3 . 4 . 5 . 6 . 7 . 8 . 9 . 10 . 11 . 12 . 13 . 14 . 15 . 16 . 17 . 18 . 19 . 20 . 21 . 22 . 23 . 24 . 25 . 26 . 27 . 28 . 29 . 30 . 31 . 32 . 33 . 34 . 35 . 36 . 37 . 38 . 39 . 40 . for each ( p 2 R ) delete p th event of T return DS
Contrary to DBSH , the SBSH algorithm detects the events to delete based on the annotation of their positions . If event P [ i ] is annotated black , the P [ i] th event of T can be deleted from T without introducing a side effect . Thus , we mark P [ i ] as a position of an event to be deleted by adding it into R , update GSj ;T using Update paths to reflect this marking , and increment i by 1 , if P [ i ] corresponds to a valid position ( steps 9 13 ) . If P [ i ] is annotated red , we first iterate over each subset of sequences Sj ∈ TS to identify alternative positions for P [ i ] ( steps 15 20 ) . Such positions are found by applying Replace with the specified radius r , and they are added to R , only if GSj ;T contains a path that has P [ i ] and at least another node , as P [ i ] needs to be removed from T in any other case . Note that we replace a single position p at a time and use r to restrict the part of GSj ;T we consider . Although these heuristics focus on efficiency , they allow SBSH to significantly outperform DBSH in terms of reducing side effects , as we experimentally verify . If no po
′
1321 ( a )
( b )
( c )
Figure 3 : Side effects ( % ) for hiding various patterns in ( a ) MSN , ( b ) BMS , and ( c ) TRUCKS . sitions are found , we cannot avoid deleting the P [ i] th event of T , so we treat position P [ i ] as if it were annotated black ( steps 21 26 ) . Otherwise , we add each of the positions found by Replace to R and reflect their marking ( steps 27 30 ) . If P [ i ] has been annotated as gray , we apply Annotate to it again ( step 32 ) . This is required because the initial annotation of P [ i ] may be incorrect owing to the marking of other positions and subsequent calls of Update paths . If P [ i ] is annotated as gray again , we treat it as if it were annotated black ( steps 23 37 ) . When this loop terminates , SBSH iterates over R and deletes the event of all of the positions in R from T , one at a time ( steps 38 39 ) . Finally , after considering all transactions of DS , SBSH returns the sanitized dataset ( step 40 ) . Cost analysis SBSH needs O(|D| × |T|2 × |s| + |D| × |T| × |TN p| ) time in the worst case when all transactions in D support at least one sequence in S , sensitive sequences do not share events , and = 1 , where |s| is the length of the largest sequence in S . The bottleneck of DBSH are steps 32 and 34 , which take O(|TN p| ) time and O(|T| × |s| ) time , respectively . Although DBSH needs more time than HHA [ 4 ] in the worst case , it is more efficient in practice , because complete paths in the graph are typically computed for only a small number of nodes .
Algor .
DBSH
HHA
SBSH dist .
Side effects
5
7
6
< a ; c >,< a ; e > , < d ; f >,< d ; g > < f ; g > < a >,< a ; b > < a ; c >,< a ; e > < d ; f >,< d ; g > < a ; c >,< a ; e > < d ; g >
( a )
( b )
Figure 4 : ( a ) Effectiveness of DBSH , HHA , and SBSH , and ( b ) Gs1;T 1 and Gs1;T 2 for the data of Fig 1(a ) and sensitive sequences of Fig 1(b ) .
523 DBSH and SBSH through an example Consider applying DBSH and SBSH to the data of Fig 1(a ) and the sensitive sequences of Fig 1(b ) using = 3 and , for SBSH , r = 3 . The sanitized datasets are shown in Figs . 1(e ) and 1(f ) , respectively . Observe that DBSH removed the 0 th event of T1 , while SBSH removed the 0 th event of T2 . Although both T1 and T2 have a sanitization cost of 1 , as can be seen in Fig 4(a ) , T2 supports fewer nonsensitive frequent sequences . Since this implies potentially fewer side effects , SBSH selects this transaction instead of T1 . Similarly , DBSH sanitizes T5 , while SBSH chooses to
Supporting itemset sequences sanitize T7 instead . Note that , due to these choices , SBSH can produce a significantly less distorted sanitized database than both HHA and DBSH with respect to distance and side effects , as shown in Fig 4(b ) . 524 Our algorithms can easily be extended to operate on itemset sequences [ 6 ] , where each event e is an itemset instead of a symbol ( item ) . In this case , to construct the matching graph for a transaction T and a sensitive sequence s , instead of applying equality tests between the events of T ( ei ) and s ( ej ) , we apply set inclusion tests ( ie , ej ⊆ ei ) . Moreover , to sanitize an event ei in T , we choose to delete the subset of items in ei that affect most of the complete paths in Gs;T .
( a )
( b )
( c )
Figure 5 : Side effects ( % ) for hiding patterns with varying ( a ) length using all methods , ( b ) number using SBSH with min and max r , and ( c ) length using SBSH with min and max r ( TRUCKS ) .
6 . EXPERIMENTAL EVALUATION
We compare DBSH and SBSH against HHA [ 4 ] , in terms of data utility and efficiency . We capture utility by measuring distance and number of side effects . For this purpose , we mined sequential patterns using PrefixSpan [ 26 ] with different support thresholds and considered a varying number of sensitive sequences of different lengths . We use the notation n to refer to n sequences of length l . To ensure a fair l comparison , we configured SBSH with r = 1 , unless stated otherwise . We used three real world datasets : MSNBC ( MSN ) [ 20 ] , BMS WebView 1 ( BMS ) [ 1 ] , and TRUCKS [ 2 ] , which have been used in evaluating relevant works [ 3,4 ] . The characteristics of these datasets and the minimum support thresholds used to both mine and sanitize them are shown in Table 1 ( default values appear in bold ) .
Dataset MSN BMS TRUCKS Table 1 : Characteristics of datasets and values used min . sup . threshold 3711,4949,9898,19796 59 15,20,30,40
N 989818 59602 273 jIj Avg . jTj 17 497 100
5.7 2.5 20.1
0253 a c e 02 T1=<a,b,c,c,d,e>Gs1,T1Gs1,T2 T2=<a,b,c,e> s1=<a,c,e>02302 a c e ψ=331322 ( a )
( b )
( c )
Figure 6 : Distance ( % ) for hiding various patterns in ( a ) MSN , ( b ) BMS , and ( c ) TRUCKS .
( a )
( b )
( c )
Figure 7 : Runtime ( sec ) for sanitizing ( a ) MSN , ( b ) BMS , and ( c ) patterns of varying support in MSN .
6.1 Side effects
We first demonstrate that our hiding algorithms allow potentially interesting nonsensitive patterns to be discovered . The results with respect to the percentage of side effects incurred when hiding increasingly larger sets of patterns of varying length are illustrated in Fig 3 . Observe that SBSH produced sanitized data that permit the mining of at least 12 % and up to 23:5 % more nonsensitive patterns than HHA , which incurred 26:4 times more side effects on average . DBSH outperformed HHA but not SBSH , since it does not attempt to reduce side effects . To illustrate the effect of varying the length of sensitive patterns more clearly , we provide Fig 5(a ) . Observe that our methods consistently outperformed HHA , which incurred at least 2 times more side effects than SBSH .
Next , we show that SBSH can reduce side effects when applied with a large r . For space reasons , we report results only for the TRUCKS dataset , which is the most difficult to sanitize owing to its large density , and for two configurations of SBSH , with the minimum and maximum r . Figure 5(b ) demonstrates a scenario in which an increasing number of sensitive sequences need to be hidden . Using a large r helps avoid side effects , reducing their number by 27 on average . This is also observed in Fig 5(c ) , which shows the impact of hiding sensitive patterns that vary in length . Also , increasing r helps hide large numbers of sensitive patterns because SBSH operates on larger graphs . 6.2 Distance
We examined the impact of hiding patterns of varying number and length on distance . Figure 6 reports the percentage of events deleted by each of the methods tested . Note that HHA removed 14 and 15.4 times more events than SBSH and DBSH on average , and SBSH was only slightly worse than DBSH , although focuses on side effects . We also provide Fig 8(a ) , which shows that our algorithms outperformed HHA when long patterns need to be hidden .
We then studied the impact of r on distance by executing
( a )
( b )
( c )
Figure 8 : Distance ( % ) for hiding patterns with varying ( a ) length using all methods , ( b ) number using SBSH with min and max r , and ( c ) length using SBSH with min and max r ( TRUCKS ) .
SBSH with the minimum and the maximum r value . Figure 8(b ) shows the result when an increasing number of patterns are hidden , and Fig 8(c ) when the sensitive patterns vary in length . We observed that r had little impact on distance , which implies that SBSH can find solutions with fewer sideeffects without overly distorting data .
( a )
( b )
( c )
( d )
( e )
( f )
Figure 9 : Runtime ( sec ) for sanitizing patterns of varying ( a ) number , ( b ) length , and ( c ) support in MSN . ( d ) , ( e ) , ( f ) are the corresponding results for TRUCKS ) .
1323 6.3 Efficiency
We also tested the time each method needs to conceal the sensitive patterns . Figure 7(a ) reports this for the case of hiding various patterns in MSN . Observe that our algorithms were at least an order of magnitude faster than HHA , scaling linearly with the number of sensitive patterns , and not exponentially as HHA did . SBSH was slower than DBSH by 44 % on average , owing to the overhead that processing nonsensitive patterns incurs . Similar results were observed for BMS , as can be seen in Fig 7(b ) .
We then measured runtime as a function of the minimum support thresholds . For consistency , the patterns were mined and hidden using the same , which varied from 3711 ( 0:375 % ) to 19796 ( 2% ) . The result for hiding 50 patterns of length 3 from MSN is shown in Fig 7(c ) . All algorithms needed more time when was smaller , because there are more nonsensitive sequences that need to be dealt with . However , DBSH and SBSH remained faster than HHA by at least 5:5 and 4:6 times , respectively .
Last , we investigated the effect of using a larger r in SBSH on the runtime . Figures 9(a ) , 9(b ) , and 9(c ) show that SBSH remained efficient , even when it ran on MSN with the maximum r value . In fact , SBSH needed less than 13 % more time on average to search a larger part of the matching graphs . The runtime of SBSH was also no more than 41 % larger ( on average ) when it ran on the denser TRUCKS dataset , as shown in Figs . 9(d ) , 9(e ) , and 9(f ) .
7 . CONCLUSIONS
In this paper , we revisited the problem of sequential pattern hiding and proposed a new definition that takes into account both the side effects and the distortion incurred by sanitization . We also developed two heuristic algorithms for sequence hiding , which are guided by graph based strategies . Extensive experiments verified that our algorithms incur significantly fewer side effects and less data distortion than the existing method , while being more efficient . We believe that the graph based representation can be used to solve other privacy problems related to sequential and trajectory data .
8 . REFERENCES [ 1 ] Frequent itemset mining repository , http://fimicshelsinkifi/
[ 2 ] R tree portal , http://wwwrtreeportalorg [ 3 ] O . Abul , M . Atzori , F . Bonchi , and F . Giannotti .
Hiding sequences . In ICDM Workshops , pages 147–156 , 2007 .
[ 4 ] O . Abul , F . Bonchi , and F . Giannotti . Hiding sequential and spatiotemporal patterns . IEEE TKDE , 22(12):1709–1723 , 2010 .
[ 5 ] C . C . Aggarwal and P . S . Yu . Privacy Preserving Data
Mining : Models and Algorithms . Springer , 2008 .
[ 6 ] R . Agrawal and R . Srikant . Mining sequential patterns . In ICDE , pages 3–14 , 1995 .
[ 7 ] M . Atallah , E . Bertino , A . Elmagarmid , M . Ibrahim , and V . S . Verykios . Disclosure limitation of sensitive rules . In KDEX , pages 45–52 , 1999 .
[ 8 ] M . Atzori , F . Bonchi , F . Giannotti , and D . Pedreschi .
Anonymity preserving pattern discovery . VLDBJ , 17(4):703–727 , 2008 .
[ 9 ] J . Ayres , J . Flannick , J . Gehrke , and T . Yiu .
Sequential pattern mining using a bitmap representation . In KDD , pages 429–435 , 2002 .
[ 10 ] J . Cao , P . Karras , C . Ra¨ıssi , and K . Tan . fl uncertainty : Inference proof transaction anonymization . PVLDB , 3(1):1033–1044 , 2010 .
[ 11 ] K . Chen and L . Liu . Privacy preserving data classification with rotation perturbation . In ICDM , pages 589–592 , 2005 .
[ 12 ] C . W . Clifton and D . Marks . Security and privacy implications of data mining . In SIGMOD , pages 15–19 , 1996 .
[ 13 ] G . Das and N . Zhang . Privacy risks in health databases from aggregate disclosure . In PETRA , pages 1–4 , 2009 .
[ 14 ] U . Feige . A threshold of ln n for approximating set cover . J . ACM , 45(4):634–652 , 1998 .
[ 15 ] G . Ghinita , P . Kalnis , and Y . Tao . Anonymous publication of sensitive transactional data . IEEE TDKE , 23:161–174 , 2011 .
[ 16 ] F . Giannotti and D . Pedreschi . Mobility , Data Mining and Privacy : Geographic Knowledge Discovery . Springer , 2008 .
[ 17 ] A . Gkoulalas Divanis and V . S . Verykios . An integer programming approach for frequent itemset hiding . In CIKM , pages 748–757 , 2006 .
[ 18 ] A . Gkoulalas Divanis and V . S . Verykios . Hiding sensitive knowledge without side effects . Knowledge and Information Systems , 20(3):263–299 , 2009 .
[ 19 ] A . Gkoulalas Divanis and V . S . Verykios . Association
Rule Hiding for Data Mining . Springer , 2010 .
[ 20 ] S . Hettich and C . Merz . UCI Repository of machine learning databases . 1998 .
[ 21 ] G . Loukides , A . Gkoulalas Divanis , and B . Malin .
Anonymization of electronic medical records for validating genome wide association studies . PNAS , 107(17):7898–7903 , 2010 .
[ 22 ] S . Menon , S . Sarkar , and S . Mukherjee . Maximizing accuracy of shared databases when concealing sensitive patterns . Information Systems Research , 16(3):256–270 , 2005 .
[ 23 ] J . Natwichai , X . Li , and M . Orlowska . Hiding classification rules for data sharing with privacy preservation . In DAWAK , pages 468–477 , 2005 .
[ 24 ] D . E . O’Leary . Knowledge discovery as a threat to database security . In KDD , pages 507–516 , 1991 .
[ 25 ] S . R . M . Oliveira and O . R . Za¨ıane . Protecting sensitive knowledge by data sanitization . In ICDM , pages 211–218 , 2003 .
[ 26 ] J . Pei , J.Han , B . Mortazavi Asl , H . Pinto , Q . Chen ,
U . Dayal , and M . Hsu . PrefixSpan : Mining sequential patterns by prefix projected growth . In ICDE , pages 215–224 , 2001 .
[ 27 ] X . Sun and P . S . Yu . Hiding sensitive frequent itemsets by a border–based approach . Computing Science and Engineering , 1(1):74–94 , 2007 . [ 28 ] M . Terrovitis , N . Mamoulis , and P . Kalnis .
Privacy preserving anonymization of set valued data . PVLDB , 1(1):115–125 , 2008 .
[ 29 ] V . S . Verykios , A . K . Emagarmid , E . Bertino ,
Y . Saygin , and E . Dasseni . Association rule hiding . IEEE TKDE , 16(4):434–447 , 2004 .
1324
