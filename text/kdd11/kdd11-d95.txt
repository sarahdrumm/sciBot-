Mining Partially Annotated Images
Zhongang Qi , Ming Yang , and Zhongfei
( Mark ) Zhang
Zhejiang Provincial Key Lab of Information
Network Technology
Dept . of ISEE , Zhejiang University , China
{zhongangqi , cauchym , zhongfei}@zjueducn
Zhengyou Zhang Microsoft Research
One Microsoft Way , Redmond , WA , USA zhang@microsoft.com
ABSTRACT In this paper , we study the problem of mining partially annotated images . We first define what the problem of mining partially annotated images is , and argue that in many real world applications annotated images are typically partially annotated and thus that the problem of mining partially annotated images exists in many situations . We then propose an effective solution to this problem based on a statistical model we have developed called the SemiSupervised Correspondence Hierarchical Dirichlet Process ( SSCHDP ) . The main idea of this model lies in exploiting the information pertaining to partially annotated images or even unannotated images to achieve semi supervised learning under the HDP structure . We apply this model to completing the annotations appropriately for partially annotated images in the training data and then to predicting the annotations appropriately and completely for all the unannotated images either in the training data or in any unseen data beyond the training process . Experiments show that SSC HDP is superior to the peer models from the recent literature when they are applied to solving the problem of mining partially annotated images . Categories and Subject Descriptors H28 [ Database Management ] : Database Applications—Data mining , Image databases ; H33 [ Information Storage and Retrieval ] : Information Search and Retrieval—Retrieval models ; I51 [ Pattern Recognition ] : Models—Structural General Terms Algorithms , experimentation Keywords Semi supervised learning , Partially annotated training set , Image annotation completion and prediction
1 .
INTRODUCTION
With the development of technologies to acquire , store , and transmit massive amounts of data , recent years have witnessed an ex plosive growth in the size of digital image collections . Efficient methods for image classification and retrieval play an important role in discovering useful information from large scale and diverse image collections . It is noted that the majority of the existing image annotation methods , based on either supervised learning or semisupervised learning , assume that either the images in the training data are completely annotated appropriately or the given annotations in the training data can be updated through transductive learning . We argue that in reality it is difficult , if not impossible , and also unnecessary and impractical to have this assumption . Figure 1 is a typical example of a given annotated image in the training data in the literature of image annotation . Here the given ground truth annotations of this image are just person , bottle , and TVmonitor whereas it is clear that there are many other objects in this image that should also be given as part of the ground truth annotation labels such as the microphone , sofa , door , telephone , and books but they are actually not included in the ground truth annotation labels . In many existing image annotation methods , the given annotation label set is presumably assumed to be appropriate and complete . However , it is clear from this example that the given annotation labeling is typically far away from being actually complete in many such applications in the real world . It is well understood that while image annotation is laborious and time consuming , completely annotated images are hard to acquire . Even with the laborious effort of manually annotating images , labels may still be missing due to the subjectivity , different foci , lack of patience to complete the annotations to every detail or even ignorance of certain details for human perception . In this case , these annotated images are actually partially annotated instead of completely annotated and the assumption that the given annotations are complete would certainly mislead the learning . While there are label propagation learning methods proposed in the recent literature to update the given annotations to a certain degree during the learning process , all these methods are transductive learning in the sense that they are unable to predict the appropriate and complete annotation labels for any out of sample images after the learning .
Consequently , we argue that partially annotated or completely unannotated images typically exist in many situations . This paper thus studies this practical problem — mining partially annotated images , in which we develop a solution to complete the given partial annotations of the images in the training dataset and to generate and complete the annotations for all unannotated images in the testing dataset . We have the following two assumptions for the partially annotated image training set : 1 ) Every label of an image in the training set is correct and appropriate ; 2 ) Whether or not an image in the training set is annotated completely is unknown , which means that there may exist images lacking appropriate labels , or even images completely unannotated at all .
1199 Figure 1 : An example of an annotated image with the given ground truth annotations as person , bottle , and TVmonitor while many other objects in the image are not labeled at all .
We highlight the contributions of this work as follows . • We argue that the partially annotated images exist in many applications and thus it is necessary and desirable to study the problem of mining partially annotated images .
• We develop an effective solution to the problem of mining partially annotated images based on a statistical model we have developed called the Semi Supervised Correspondence Hierarchical Dirichlet Process ( SSC HDP ) .
• We demonstrate through extensive evaluations utilizing real datasets that the SSC HDP model performs well in comparison with the peer methods in the literature as an effective and promising solution to the problem of mining partially annotated images .
This paper is organized as follows . Section 2 briefly reviews the related work in the area of image annotation and retrieval . Section 3 describes the data representation and symbols used in this work . In Section 4 , we introduce the proposed SSC HDP model , and present an efficient algorithm to estimate the parameters of the model . We present experimental results for SSC HDP , and compare them with those of the peer methods in the literature in Section 5 . Finally , we conclude this study in Section 6 .
2 . RELATED WORK
Various approaches have been proposed in the area of image annotation and retrieval in the past years [ 7 ] . Basically , these approaches can be classified into various categories from different views . One way of the classification is to reduce the problem into “ one vs all ” ( OVA ) mode , or to introduce a set of bridge variables . The image annotation and retrieval problem has been cast as a multi label learning problem . In semantic scene classification [ 5 ] , an image is considered as one instance , which may belong to more than one conceptual class . Boutell et al . [ 5 ] introduce several transformation methods that map the multi label learning problem into the single label classification problem . A more complicated situation is when an image is represented as a bag of instances , and belongs to a bag of classes . Hence , the original annotation problem becomes a multi instance and multi label learning problem . Zhou and Zhang [ 29 ] solve this problem by mapping it into a singleinstance and multi label learning problem . All of the above methods are finally reduced to the solution of training several binary classifiers in the OVA mode , each of which is used for one class .
Different from the above approaches , another paradigm for image annotation is to introduce a set of latent variables as a bridge ,
Figure 2 : Example of Positive and Unlabeled Data . The asterisks are labeled data from the positive class , while the circles are unlabeled data from both classes . where each variable has joint distributions not only with the semantic labels , but also with the image feature descriptors . Barnard et al . [ 2 ] propose two classes of models , the multi modal hierarchical aspect models using clusters as the bridge variables and the mixture of multi modal LDA ( MoM LDA ) model extending the Latent Dirichlet Allocation ( LDA ) [ 4 ] to learning the joint distribution of words and images . Compared with MoM LDA , Blei and Jordan [ 3 ] propose the correspondence LDA ( Corr LDA ) model under which each label shares a latent variable with a randomly selected image feature descriptor in one image . In [ 9 , 12 , 13 ] , the annotated images in the training set are used as the connection variables to compute the joint probability of labels and image regions . Zhang et al . [ 28 ] propose a probabilistic semantic model using a hidden concept layer to exploit the synergy among the modalities . Li and Fei Fei [ 14 ] propose an integrative model , somewhat similar to MoM LDA , to classify the types of the events and object components of images . In order to adapt to the number of the latent variables based on the training data , the multi modal HDP ( MoMHDP ) model based on a Hierarchical Dirichlet Process ( HDP ) [ 25 ] is proposed by Yakhnenko and Honavar [ 26 ] . Yang et al . [ 27 ] propose a generative model , called Dirichlet Bernoulli Alignment , to describe the multi class multi label multi instance corpora .
From the aspect of the type of the training set , the approaches in this area can also be categorized into supervised learning and semi supervised learning . Most of the previous work uses datasets of completely annotated images as the training set . There has been work on semi supervised image annotation by adding a large amount of additional unannotated images into the training set . In [ 15 , 23 ] , the co training framework is applied to utilize the unlabeled data to improve the performance of the algorithm . Loeff et al . [ 19 ] use manifold regularization to incorporate the information from the unlabeled data . The work in [ 19 , 24 ] is the most relevant to ours in the sense that they can also formulate the problem we proposed as an inductive learning problem , though their methods are completely different from ours .
This problem of mining partially annotated images , which is demonstrated as the Weak Label problem in [ 24 ] , is also related to the graph label propagation problem , specifically the graph label propagation problem in the context of image annotation . Solutions are developed [ 16 ] to iteratively update the given annotation labels in the training data and to predict the annotation labels for the initially unlabeled images in the dataset . However , all these methods for the graph label propagation problem are transductive learning in nature and consequently , are unable to predict the annotation labels for any new , out of sample images after the learning .
In this paper , we introduce the Semi Supervised Correspondence Hierarchical Dirichlet Process ( SSC HDP ) , a statistical model using partially annotated images as the training set . Compared with
1200 α
πi zil bil i = 1 , . . . , D
Ni yij wij
α i = 1 , . . . , D
Ni yij wij
β
πi zil bil
α
β1
α
β2
α
β3 i = 1 , . . . , D yij1 wij1
Ni1
πi1 zil1 bil1 i = D + 1 , . . . , D + U i = 1 , . . . , D + U bil1 l = 1 , . . . , Ni1 yij2 wij2
Ni2
πi2 zil2 bil2 i = 1 , . . . , D + U yij3 wij3
Ni3
πi3 zil3 bil3
. . .
. . . j = 1 , . . . , Mi l = 1 , . . . , Ni j = 1 , . . . , Mi l = 1 , . . . , Ni j = 1 , . . . , Mi1 l = 1 , . . . , Ni1 j = 1 , . . . , Mi2 l = 1 , . . . , Ni2 j = 1 , . . . , Mi3 l = 1 , . . . , Ni3
φw z
φb z
K
( a )
φw z
φb z
∞
( b )
φw z
φb z
∞
( c )
Figure 3 : Graphical Model for ( a ) Corr LDA , ( b ) Corr HDP , and ( c ) SSC HDP ( The dashed line indicates the initial assignment ) .
MoM HDP , SSC HDP considers the correspondence between the latent variables which respectively generate the image descriptors and their labels in each image . Compared with Corr LDA , SSCHDP adapts to the number of latent variables based on the training set . More importantly , the major difference between SSC HDP and MoM HDP , Corr LDA , as well as other image annotation models , is that SSC HDP can train partially annotated images , and complete the annotation for partially annotated images through the training process . In addition , as an inductive learning approach , new unannotated images can be predicted with appropriate annotation labels and can be added seamlessly as part of the training data to further improve the performance of the SSC HDP model .
3 . DATA REPRESENTATION AND SYMBOLS
We denote an image set as I , the visual word vocabulary as V , and the label vocabulary as L . We follow the notations in a bag ofwords representation for both images and annotations . For each im age Ii ∈ I , let an N dimensional vector bi = ( bi,1 , bi,2 , . . . , bi,N ) be the visual word representation for Ii , where bi,j is the count of the jth visual word Vj ∈ V appeared in Ii . Let an M dimensional be the label representation vector wi = ( wi,1 , wi,2 , . . . , wi,M ) for Ii , where wi,j ∈ {0 , 1} , 0 ≤ j ≤ M represents the occurrence of the jth label Lj ∈ L . If Ii is fully annotated or partially annotated , Ii is represented as a pair ( bi , wi ) . Otherwise , Ii is unannotated and represented as bi . Consequently , a partially annotated training set of D images is denoted as D = {Id}D d=1 = {(bd , wd)}D d=1 , and an unannotated set of U images is denoted as U = {Iu}U u=1 = {b1 , b2 , . . . , bU} . 4 . MODEL FORMULATION
The main idea of this work is based on achieving semi supervised learning under the HDP structure . We begin with describing semisupervised learning with positive and unlabeled data , then propose the correspondence HDP ( Corr HDP ) , which is an extension of the Corr LDA model using a hierarchical Dirichlet process instead . Finally we introduce the SSC HDP model and give the parameter estimation procedure . 4.1 Semi Supervised Learning with Positive and
Unlabeled Data
In many practical applications of the binary classification problem , we encounter such a situation that only one class of labeled data is available , and the unlabeled data may contain both classes . As shown in Figure 2 , all the information we have is that the asterisk points are from the positive class , and we do not know which class each of the unlabeled data points ( circles ) belongs to . The labeled data form the positive data set P , while the unlabeled data form the mixed data set S . Consequently , the dataset which consists of P and S is a partially labeled dataset .
Zhu [ 30 ] reviews the problem of learning with positive and unlabeled data . Liu et al . [ 18 ] theoretically analyze the binary classification problem using positive and unlabeled data . Given the partially labeled dataset ( T , C ) , where C ∈ {0 , 1} , and a function f as the classifier , the probability of the classification error is :
Pr[f ( T ) = C ] =Pr[f ( T ) = 1 ∧ C = 0 ] + Pr[f ( T ) = 0 ∧ C = 1 ] =Pr[f ( T ) = 1 ] − Pr[C = 1]+ 2Pr[f ( T ) = 0|C = 1]Pr[C = 1 ] .
( 1 ) Since Pr[C = 1 ] is a constant , the method to minimize the classification error is to hold Pr[f ( T ) = 0|C = 1 ] small while minimizing Pr[f ( T ) = 1 ] , which is approximately the same as minimizing PrS[f ( T ) = 1 ] while holding PrP [ f ( T ) = 1 ] ≥ 1 − r when sufficient data in P and S are available [ 18 ] . Here PrS[f ( T ) = 1 ] denotes the probability of f ( T ) = 1 in the mixed data set S , PrP [ f ( T ) = 1 ] denotes the probability of f ( T ) = 1 in the positive data set P , and r is a recall . Liu et al . [ 18 ] prove that accurate classifiers can be built with a high probability when P and S are large enough .
The image annotation and retrieval problem has been cast as a multi label learning problem , which can be solved as M binary classification problems , where M is the total number of the labels . By inference , an accurate model can be built using a large amount of partially annotated images to complete the missing annotations of the training images and to predict the annotations of the new , unannotated images precisely . 4.2 Correspondence HDP Model
We extend the Corr LDA model introduced by Blei and Jordan [ 3 ] to the Corr HDP model . The graphical models of Corr LDA and Corr HDP are shown in Figure 3(a ) and ( b ) . The difference between the two models is that in Corr HDP the prior β is drawn from a stick breaking distribution , while in Corr LDA the prior is drawn from a finite Dirichlet distribution . The advantage of Corr HDP is that it adapts to the number of the latent variables dynamically based on the training set instead of setting the number of the latent variables as a prior .
From the graphical model of Corr HDP we see that visual words b and labels w are both associated with the assignment variable z which is multinomially distributed with the parameter π . The cluster mixing variable π is sampled from a global distribution G0 with
1201 the parameter β . Using the notation of stick breaking theory , which is an efficient method to establish the Dirichlet process [ 22 ] , we denote that β ∼ Stick(α ) and π ∼ DP ( απ , β ) . For the observed nodes , we set a random variable y ∼ U nif orm(1 , . . . , Ni ) which correlates labels with visual words in the same image . Given an image i , we first generate Ni visual words bi,l , bi,l ∼ p(bi,l|z , φb z ) , which is a multinomial distribution with parameter φb z . Then for each of the Mi labels , we use y to select one of the Ni visual words randomly , and draw the corresponding label wi,j conditioned on the latent variable z which generates the selected visual word , wij ∼ p(wi,j|yi,j , z , φw z ) , which is a multinomial distribution with parameter φw z . The generative process of the Corr HDP Model is described in Algorithm 1 . algorithm is described in Algorithm 2 . Through updating the likelihood of the labels , the model progressively enhances the correspondence between the labels and the visual words , which ultimately makes the annotations precise and complete .
Algorithm 2 : SSC HDP algorithm Initialize wi,j foreach Lj ∈ L do wi,j ← 1 ; wi,j ← 0 ; foreach Ii ∈ Pj do foreach Ii ∈ Sj do
Algorithm 1 : Generative process of Corr HDP draw β ∼ Stick(α ) for cluster z = 1 , 2 , . . . do draw φb draw φw z ∼ Dir(η ) z ∼ Dir(ω ) for image i = 1 , . . . , D do draw πi ∼ DP ( απ , β ) for visual word l = 1 , . . . , Ni do for label j = 1 , . . . , Mi do bi,l zi,l , zi,l ) draw zi,l ∼ M ult(πi ) draw bi,l ∼ M ult(φ draw yi,j ∼ U nif ( 1 , . . . , Ni ) draw wi,j ∼ M ult(φ wi,j zi,j , yi,j , zi· )
In practice , we need to truncate β at K to make the parameter estimation feasible [ 11 ] . Thus , π ∼ DP ( απ , β ) is approximated as π ∼ Dirichlet(απβ1 , . . . απβK ) . Note that truncating β at K in the HDP is not equivalent to using a Corr LDA model with a fixed number of K topics . Using the truncated HDP as a prior adapts to any number of latent variables within K ( as the maximum number of the latent variables ) based on the training set , while using LDA as a prior would fix the number of latent variables as exactly K . 4.3 SSC HDP
We now apply the semi supervised learning scheme with positive and unlabeled data to the Corr HDP model . Given a partially annotated image training set D , for each label Lj ∈ L , there exists a pair set Pj × Sj , where Pj ⊂ D denotes a positive set and Sj ⊂ D denotes a mixed set ; ∀Ii ∈ D , we claim the following relationship : wi,j = 1 =⇒ Ii ∈ Pj , wi,j = 0 =⇒ Ii ∈ Sj
Consequently , the training set D can be represented as a set pair Pj × Sj for each j ∈ {1 , 2 , . . . , M} . Since the training set D is partially labeled , we note that
Ii ∈ Pj⇒Pr[wi,j = 1|bi ] = 1 Ii ∈ Sj ⇒Pr[wi,j = 1|bi ] = 0
∀Ii ∈ Sj , a more reasonable assumption is that Pr[wi,j = 1|bi ] can take any random value in [ 0 , 1 ] . The graphical model of SSC HDP is shown in Figure 3(c ) . Based on the theoretical analysis described in Section 4.1 , the main idea of semi supervised learning here is to update the likelihood Pr[wk,j = 1|bk ] for Ik ∈ Sj(1 ≤ j ≤ M ) , while holding Pr[wi,j = 1|bi ] = 1 for Ii ∈ Pj(1 ≤ j ≤ M ) under the Corr HDP structure . The
Build the first Corr HDP model using the initial wi,j while parameters of Corr HDP change do foreach Lj ∈ L do foreach Ik ∈ Sj do foreach Ii ∈ Pj do
Compute Pr[wk,j = 1|bk ] through Corr HDP ; wk,j ← Pr[wk,j = 1|bk ] ∈ [ 0 , 1 ] ; Pr[wi,j = 1|bi ] ← 1 ; wi,j ← 1 ; foreach Ig ∈ D do if wg,j ≤ e or wg,j in the bottom t % in Sj then foreach Lj ∈ L do wg,j ← 0 ;
Update the parameters of Corr HDP model by wg,j
Note that even a completely annotated image may only contain a few labels in the whole label vocabulary . We see that wg is actually a sparse vector for a given Ig , and most elements of wg are zero . Thus , as Algorithm 2 shows , after each element of wg for Ig is updated in each iteration , we reserve element wg,j if wg,j ≥ e , and set other elements to zero . Here e is a threshold , which is selected appropriately to ensure that not only wg is a sparse vector , but also the information of the annotations for Ig is lost as least as possible . What is more , in order to avoid adding a large number of labels of one kind into the training set , we also set wg,j = 0 if it is in the bottom t % in the mixed set Sj for each kind of labels .
From Figure 3(c ) we note that the information of the unlabeled data can be added seamlessly into the algorithm . After the initial Corr HDP model is built , we exploit parameters of this initial model to compute the likelihood for each label of each image in the unannotated set U , and allocate all the unannotated images into the mixed set Sj(1 ≤ j ≤ M ) . Consequently , the unlabeled data are merged into the mixed set , and are utilized to update the Corr HDP model in the subsequent iteration .
4.4 Parameter Estimation
In order to maximize the likelihood of the training data for a precise prediction , we adopt the Expectation Maximization ( EM ) algorithm under the variational framework to learn the parameters of SSC HDP . Before we list explicitly the estimation steps , the prerequisite knowledge on variational inference is introduced below . The main idea of variational inference is to select an auxiliary distribution q to approximate the original distribution p through minimizing the KL divergence D(qν ( H)||p(H|x , θ ) ) in the meanfield framework iteratively and updating the parameters of the la
1202 ( 3 )
Eq[log q(zn|φn ) ] =
φn,i log φn,i + const
( 7 )
( 8 )
( 9 )
( 11 )
( 12 )
( 13 ) tent variables :
Eq[log p(x|θ ) ] ≥ Eq[log p(H , x|θ ) ] − Eq[log qν ( H) ] .
( 2 ) where H is the set of latent variables , x is the set of observed variables , θ is the set of hyperparameters , and ν is the parameter set of the auxiliary distribution . Herein , x = {w , b} , H = {β , π , z , y} , θ = {φw z , φb z} , and ν = {γ , φn , λm} . We aim to estimate Eq[log p(w , b|φw z) ] . According to ( 2 ) we decompose its lower bound Eq[log p(β , π , z , y , w , b|φw into the algebraic combination of the following ten items and denote this lower bound as R : z , φb z , φb z)]−Eq[log qν ( β , π , z , y ) ]
+ n=1
Eq[log p(zn|π ) ] +
R Eq[log p(β|α ) ] + Eq[log p(π|β ) ] Nd Eq[log p(bn|zn , φb Md Md
− Eq[log q(β ) ] − Eq[log q(π|γ ) ]
Nd Md Nd
Eq[log p(ym|Nd ) ] + m=1 m=1 n=1
+
− n=1
Eq[log q(zn|φn ) ] − m=1
Eq[log q(ym|λm ) ] zn ) ]
Eq[log p(wm|ym , z , φw zym ) ]
We claim the following relationships of the real distribution p and the auxiliary distribution q :
β|α ∼pStick(α ) π|β ∼pDP ( απ , β ) zn|π ∼pM ult(π ) zn ∼pM ult(φb zn ) ym|Nd ∼pU nif ( Nd ) bn|zn , φb
π|γ ∼qDir(γ ) zn|φn ∼qM ult(φn ) ym|λm ∼qM ult(λm ) zym ) z , φb zym ∼pM ult(z , ym , φw wm|ym , z , φw As described before , we formulate the estimation steps in four parts . Firstly , in the E step we derive the updating formulas for parameters γ , φn , λm in the auxiliary distribution q . Secondly , in the Mstep we maximize the hyperparameters φw z under the smooth and normalization constraints . Thirdly , we update the top level parameter β since there does not exist an analytical form in the above EM steps . Finally , we append the labels to the partially annotated and completely unannotated images based on the likelihood ’s prediction . After this step , the prior for word wd in the next epoch has also been generated . Moreover , we truncate β at K as described in Section 4.2 to make parameter estimation feasible . Thus , π ∼ DP ( απ , β ) is approximated as π ∼ Dirichlet(απβ1 , . . . απβK ) . 441 Updating the parameters γ , φn , λm in q ( E step ) We denote q(zn = i ) φn,i and q(ym = n ) λm,n . Note that omitting Eq[log p(β|α ) ] and Eq[log q(β ) ] in ( 3 ) does not influence the updating of γ , φn , λm , and the term Eq[log p(ym|Nd ) ] in the real distribution p is a constant ; therefore , we only estimate the other seven items in ( 3 ) : Eq[log p(π|β ) ]
( απβi − 1)Eq[log πi ] + log
K
Γ(Σαπβi ) i=1 Γ(απβi )
( απβi − 1)[Ψ(γi ) − Ψ(Σγi ) ] + const
( 4 )
K K i=1 i=1
=
=
The second equation in ( 4 ) is due to the logarithm of sufficient statistics being equal to its natural statistics’ negative derivative . Ψ(· ) is the Digamma function , which is the logarithmic derivative of the gamma function . The following expectation formulas in R are expanded as formula ( 4 ) :
Eq[log p(zn|π ) ] =
φn,i[Ψ(γi ) − Ψ(Σγi ) ] + const
( 5 )
φn,i log p(bn|zn = i , φb zn )
( 6 ) zn ) ] =
K
Eq[log p(bn|zn , φb Md Eq[log p(wm|ym , z , φw K
Eq[log q(π|γ ) ] m=1 i=1
=
=
φn,iλm,n log p(wm|zn = i , ym = n , φw zym )
( γi − 1)[Ψ(γi ) − Ψ(Σγi ) ] + log i=1
K
Γ(Σγi ) i=1 Γ(γi )
K i=1
K i=1 zym ) ]
K Md i=1 m=1
Eq[log q(ym|λm ) ] =
λm,n log λm,n + const
( 10 )
Now R can be expressed by ( 4)∼(10 ) . We have found that ( 4 ) , ( 5 ) , and ( 8 ) are associated with γ . Taking derivative with each γi and setting ∂R = 0 , we obtain an estimation of γi . Similarly , ∂γi setting ∂R = 0 , we obtain the estimation of ∂φn,i φn,i and λm,n :
= 0 and
∂λm,n
∂R
Nd n=1
γi = απβi +
φn,i
φn,i ∝ p(bn|zn = i , φb zn=i ) exp [ Ψ(γi ) − Ψ(Σγi)]·
[ p(wm|zn = i , ym = n , φw zym )]λm,n
λm,n ∝
[ p(wm|zn = i , ym = n , φw zym )]φn,i
Md K m=1 i=1 z , φw z ( M step ) z , φw
442 Updating the parameters φb In the given training set D , we consider φb z as multinomial vector parameters of visual words and labels respectively for K latent variables z . In order to avoid overfitting , we smooth the parameters φb z by appending the conjugate priors Dir(η , , η ) and Dir(ω , , ω ) for the two parameters respectively . We modify R in ( 3 ) by appending normalization constraints on φb zn=i and φw zym =i . Applying the method of Lagrange multipliers , we obtain z and φw
D D d=1
Nd Nd n=1
Md q(φ bj i |ηj i ) ∝ exp{
φn,i1[bd,n → j ] log φ bj i } · p(φ bj i |η ) ( 14 ) i q(φwk
|ωk i ) ∝ exp{ p(φwk
φn,iλm,n1[wd,m → k ] log φwk i }· ( 15 ) Where bd,n → j means that bd,n chooses the jth visual word in
|ω ) m=1 n=1 d=1 i
1203 V , wd,m → k means that wd,m chooses the kth label in L , ηj ωk i are the updating parameters for φb Thus , through updating the parameters ηj updating of φb zym =i . We obtain : i and zym =i respectively . i , we achieve the zn=i and φw i and ωk zn=i and φw
ηj i = η +
ωk i = ω +
φn,i1[bd,n → j ]
φn,iλm,n1[wd,m → k ]
( 16 )
( 17 ) k ] with
Now that we have assumed that wd,m = Pr[wd,m = 1|bd ] is a probability value instead of a Boolean value , we replace 1[wd,m → wd,m→k wd,m in ( 17 ) and obtain
D D d=1
Nd Nd n=1
Md d=1 n=1 m=1
D
Nd
Md
N
K n=1 m=1
K i=1
ωk i = ω +
φn,iλm,n wd,m
( 18 ) d=1 n=1 wd,m→k 443 Updating the top level parameter β We obtain a target function Lβ from R with the normalization m=1 constraint :
Lβ = Eq[log GEM ( β ; α ) ] + Eq[log Dir(π ; απβ ) ]
+ λ(
βi − 1 )
( 19 ) where λ is a Lagrange multiplier . Similar to [ 17 ] , we compute ∂Lβ ∂βi and use the gradient projection method [ 21 ] to find the optimal β . 444 Updating priors and making predictions We utilize the updated Corr HDP model to compute the likelihood and update wd , which can be considered as a prior of the next iteration and can also be used to make predictions of a new , completely unannotated image after the iteration converges and the SSC HDP model is established . wd,j = Pr[wd,j = 1|bd ] ≈ p(wd,j|zm)q(zm|bd,n )
( 20 )
5 . EXPERIMENTS 5.1 Data and Parameter Setting
We compare our model with both MoM HDP and Corr LDA using the partially annotated images as the training set on three standard datasets : VOC 2010 challenge data [ 8 ] , NUS WIDE [ 6 ] , and the Berkley Drosophila embryo image database [ 1 ] . Figure 4 shows examples of the images in the three databases to demonstrate the variety of the images and the complexity of the experiments .
The VOC 2010 database contains 11 , 321 images in 20 categories ( labels ) . For each image in the database , we rescale it for the maximum height of 256 pixels , then slide a window with a 16pixel interval to divide the image into 16 × 16 patches . We use the 128 dim SIFT descriptor [ 20 ] to extract the features of each patch . Consequently , each image in the database is represented as a collection of SIFT descriptors . Given the collection of SIFT descriptors of each image from the whole database , we cluster them into 400 categories by performing k means algorithm to learn the visual word vocabulary . Therefore , each image from the database is represented as a bag of visual words and a bag of labels . Each category in the VOC 2010 database contains a different number of
VOC 2010
NUS WIDE
BDE
Figure 4 : Image examples from the three databases : VOC 2010 , NUS WIDE , and BDE . images . To keep most of the categories with roughly similar numbers of images and similar frequency distributions , we select 3 , 876 images as the partially annotated training set , 1 , 987 images as the unlabeled training set , and 2 , 124 images as the testing set . Hence , 7 , 987 images from the VOC 2010 database are used in the experiment . We consider the original database as the completely annotated data as the ground truth . We randomly remove 30 % of the ground truth labels from the images to form the partially annotated training set with the remaining images as the unlabeled data .
The NUS WIDE database includes 269 , 648 web images and 81 concepts as the ground truth labels . We choose the top 24 concepts from the database as the annotation words and have randomly sampled 10 , 000 images for the experiments with 3 , 500 images as the partially labeled training set , 4 , 500 images as the unlabeled training set , and 2 , 000 images as the testing set . In the experiments , we use the 500 D bag of words based on SIFT descriptions provided by the database and randomly remove 30 % of the ground truth labels from the images to form the partially labeled training set .
The Berkeley Drosophila embryo ( BDE ) image database contains 36 , 628 embryo images classified into different embryo development stages with 227 words as annotations to those images . The images are archived in six different folders with each folder containing images of two to four neighboring development stages . We use one of the folders which contains 5 , 496 images and 75 annotation words as the experiment database to evaluate the performance of our model . After removing the low frequency words in the folder , we keep 53 words and 5 , 494 images with 3 , 846 images as the partially labeled training set and 1 , 648 images as the testing set . There is no unlabeled training set in this database . Following the work in [ 10 ] , we partition the images into blocks , compute the feature vector for each block , and cluster the feature vectors into 150 categories by k means . In the experiments we randomly remove 30 % of the ground truth labels from the images to form the partially labeled training set . 5.2 Results and Discussions
In order to measure the quality of image annotation by the models , we follow the work in [ 26 ] by using the accuracy of the annotations as the performance measure on the annotation prediction and using the completeness of the annotations as the performance measure on the annotation completion . Let Wt be the predicted label set of a given image dataset . Let Wr be the ground truth label set of the given dataset . The accuracy of the predicted annotations . Let Wi be the initial partial label is defined as Acc = set of the given dataset , which is ∅ for an unlabeled set . The com
|Wt∩Wr|
|Wt|
1204 Table 1 : The accuracy and completeness for the testing sets of the three databases using MoM HDP , Corr LDA , Corr HDP , and SSC HDP , respectively . M.1 represents MoM HDP , M.2 represents Corr LDA , M.3 represents Corr HDP , M.4 represents SSC HDP without the unlabeled data , M.5 represents SSC HDP with the unlabeled data ; M.1 − M.5 use the partially labeled training set , and M.6 represents Corr HDP using the completely labeled training set .
V OC2010
N U S − W IDE
BDE n = 3 n = 3 n = 3 n = 4 n = 2 n = 4 n = 2 n = 4 n = 2 29.6 % 22.7 % 19.2 % 20.7 % 19.5 % 19.0 % 31.9 % 27.3 % 23.5 % 30.9 % 23.8 % 20.2 % 21.5 % 20.4 % 19.9 % 32.6 % 28.5 % 24.7 % 31.7 % 24.7 % 20.9 % 32.9 % 28.9 % 25.1 % 21.9 % 20.9 % 20.5 % 33.0 % 25.4 % 21.4 % 33.5 % 29.4 % 25.7 % 22.1 % 21.3 % 20.8 % — 33.0 % 25.7 % 21.8 % 33.7 % 29.8 % 26.1 % 34.5 % 27.8 % 24.1 % 35.1 % 31.1 % 27.9 % 22.8 % 22.4 % 21.9 % 11.7 % 16.5 % 21.4 % 36.6 % 42.0 % 47.4 % 36.4 % 46.7 % 53.7 % 12.1 % 17.3 % 22.5 % 38.2 % 44.1 % 50.0 % 37.2 % 48.8 % 56.4 % 39.2 % 45.7 % 51.6 % 12.4 % 17.7 % 23.1 % 37.5 % 49.5 % 57.4 % 38.2 % 50.3 % 58.7 % 12.5 % 18.0 % 23.5 % 40.8 % 47.0 % 52.7 % — 40.8 % 47.5 % 53.8 % 38.4 % 51.0 % 59.6 % 42.6 % 51.4 % 59.4 % 40.0 % 53.2 % 63.8 % 12.9 % 19.0 % 24.7 %
—
—
—
—
M.1 M.2 ACC M.3 M.4 M.5 M.6 M.1 M.2 COM M.3 M.4 M.5 M.6 s s e n e t e l p m o C
0.8 0.79 0.78 0.77 0.76 0.75 0.74 0.73 0.72 0.71 0.7 0.69 0.68
0
1
SSC HDP without the unlabeled data for VOC 2010 SSC HDP with the unlabeled data for VOC 2010 SSC HDP without the unlabeled data for NUS WIDE SSC HDP with the unlabeled for NUS WIDE SSC HDP without the unlabeled data for BDE
2
3
Iteration Numbers
4
5
Figure 5 : The completeness of the annotations for the partially labeled training set using SSC HDP .
|Wr|
|(Wt∪Wi)∩Wr| . pleteness of the annotations is defined as Com = For each label , we evaluate the performance of the model on the annotation prediction using the standard performance measures of precision and recall . The precision of a label is the fraction of the images which actually have the predicted label out of all the images predicted with the label . The recall of a label is the fraction of the images which are assigned a given label out of all the images which actually have the label . For the testing set , we choose the predicted label as the new label of a given image if it is within the top n predicted labels .
We describe the completeness of the annotations for the partially annotated training sets of the three databases using SSC HDP as a function of the iteration in Figure 5 . In Table 1 , we summarize the prediction accuracy and completeness for the testing sets of the three databases when n is selected as 2 , 3 , 4 using MoM HDP , Corr LDA , Corr HDP , and SSC HDP , respectively . The numbers of the mixture components for the VOC 2010 , the NUS WIDE , and the BDE image databases in Table 1 are chosen as KV = 20 , KN = 30 , and KB = 8 .
We observe from Figure 5 that the completeness increases after the iteration progresses , and the performance of SSC HDP with the unlabeled data is better than that without the unlabeled data , which shows that the unlabeled data are helpful to improve the perfor
Figure 6 : The accuracy for the testing set using MoM HDP , Corr LDA , Corr HDP , and SSC HDP with the partially labeled training set when n = 3 for the BDE image database . mance of the model and that the semi supervised learning scheme is effective in completing the missing labels of the training set and at the same time in improving the predicted accuracy of the testing set . The curves for the completeness of SSC HDP in Figure 5 all exhibit their major elevation between the first two iterations , then level off during the subsequent iterations and quickly converge , indicating that SSC HDP converges fast . Because of the iterations , the complexity of SSC HDP is four to five times of those of MoMHDP , Corr LDA , and Corr HDP . Although SSC HDP spends more time in the off line training process , it is as fast as the other three models when predicting annotations of any new , unannotated image on line .
From Table 1 , we see that our proposed models including CorrHDP and SSC HDP perform better than MoM HDP and Corr LDA . The performance of SSC HDP is the closest to that of Corr HDP using the completely labeled training set which is the baseline , and is better than those of MoM HDP , Corr LDA and Corr HDP using the partially labeled training set , because MoM HDP , Corr LDA , and Corr HDP using the partially labeled training set all consider the training set as the completely labeled set and ignore the missing labels . Corr HDP using the completely labeled training set as the baseline performs the best , because there is the clearest and the most complete information of the distribution of labels in its train
Table1:TheaccuracyandcompletenessforthetestingsetusingMoM HDP,Corr LDA,Corr HDP,andSSC HDP,respectivelyM1representsMoM HDP,M2representsCorr LDA,M3representsCorr HDP,M4representsSSC HDPwithouttheunlabeleddata,M5representsSSC HDPwiththeunlabeleddata;M1−M5usethepartiallylabeledtrainingset,andM6representsCorr HDPusingthecompletelylabeledtrainingsetVOC2010NUS−WIDEBDEn=2n=3n=4n=2n=3n=4n=2n=3n=4M1296%227%192%319%273%235%207%195%190%M2309%238%202%326%285%247%215%204%199%ACCM3317%247%209%329%289%251%219%209%205%M4330%254%213%335%294%257%221%213%208%M5330%257%218%337%298%261%———M6345%278%240%351%311%279%228%224%219%M1366%420%474%364%467%537%117%165%214%M2382%441%500%372%488%564%121%173%225%COMM3392%457%516%375%495%574%124%177%231%M4408%469%527%382%503%587%125%180%235%M5408%475%538%384%510%596%———M6426%514%594%400%532%638%129%190%247%0123450680690707107207307407507607707807908IterationNumbersCompletenessSSC HDPwithouttheunlabeleddataforVOC2010SSC HDPwiththeunlabeleddataforVOC2010SSC HDPwithouttheunlabeleddataforNUS WIDESSC HDPwiththeunlabeledforNUS WIDESSC HDPwithouttheunlabeleddataforBDEFigure5:ThecompletenessoftheannotationsforthepartiallylabeledtrainingsetForeachlabel,weevaluatetheperformanceofthemodelontheannotationpredictionusingthestandardperformancemeasuresofprecisionandrecallTheprecisionofalabelisthefractionoftheimageswhichactuallyhavethepredictedlabeloutofalltheim agespredictedwiththelabelTherecallofalabelisthefractionoftheimageswhichareassignedagivenlabeloutofalltheimageswhichactuallyhavethelabelForthetestingset,wechoosethepredictedlabelasthenewlabelofagivenimageifitiswithinthetopnpredictedlabelsWedescribethecompletenessoftheannotationsforthepartiallyannotatedtrainingsetsofthethreedatabasesusingSSC HDPasafunctionoftheiterationinFigure5InTable1,wesumma rizethepredictionaccuracyandcompletenessforthetestingsetsofthethreedatabaseswhennisselectedas2,3,4usingMoM HDP,Corr LDA,Corr HDP,andSSC HDP,respectivelyThenumbersofthemixturecomponentsfortheVOC2010,theNUS WIDE,andtheBDEimagedatabasesinTable1arechosenasKV=20,KN=30,andKB=8WeobservethatthecompletenessincreasesaftertheiterationprogressesinFigure5,andtheperformanceofSSC HDPwiththeunlabeleddataisbetterthanthatwithouttheunlabeleddata,whichshowsthattheunlabeleddataarehelpfultoimprovetheperfor Table1:TheaccuracyandcompletenessforthetestingsetusingMoM HDP,Corr LDA,Corr HDP,andSSC HDP,respectivelyM1representsMoM HDP,M2representsCorr LDA,M3representsCorr HDP,M4representsSSC HDPwithouttheunlabeleddata,M5representsSSC HDPwiththeunlabeleddata;M1−M5usethepartiallylabeledtrainingset,andM6representsCorr HDPusingthecompletelylabeledtrainingsetVOC2010NUS−WIDEBDEn=2n=3n=4n=2n=3n=4n=2n=3n=4M1296%227%192%319%273%235%207%195%190%M2309%238%202%326%285%247%215%204%199%ACCM3317%247%209%329%289%251%219%209%205%M4330%254%213%335%294%257%221%213%208%M5330%257%218%337%298%261%———M6345%278%240%351%311%279%228%224%219%M1366%420%474%364%467%537%117%165%214%M2382%441%500%372%488%564%121%173%225%COMM3392%457%516%375%495%574%124%177%231%M4408%469%527%382%503%587%125%180%235%M5408%475%538%384%510%596%———M6426%514%594%400%532%638%129%190%247%ingset,and2,000imagesasthetestingsetIntheexperiments,weusethe500 DbagofwordsbasedonSIFTdescriptionsprovidedbythedatabaseandrandomlyremove30%ofthegroundtruthla belsfromtheimagestoformthepartiallylabeledtrainingsetThenumberofthemixturecomponentsischosenasK=3052ResultsanddiscussionInordertomeasurethequalityofimageannotationbythemod els,wefollowtheworkin[23]byusingtheaccuracyofthean notationsastheperformancemeasureontheannotationpredictionandusingthecompletenessoftheannotationsastheperformancemeasureontheannotationcompletionLetWtbethepredictedlabelsetofagivendatasetLetWrbethegroundtruthlabelsetofthegivendatasetTheaccuracyofthepredictedannotationsisdefinedasAcc=|Wt∩Wr||Wt|LetWibetheinitialpartiallabelsetofthegivendataset,whichis∅foranunlabeledsetThecom pletenessoftheannotationsisdefinedasCom=|(Wt∪Wi)∩Wr||Wr|Foreachlabel,weevaluatetheperformanceofthemodelontheannotationpredictionusingthestandardperformancemeasuresofprecisionandrecallTheprecisionofalabelisthefractionoftheimageswhichactuallyhavethepredictedlabeloutofalltheim agespredictedwiththelabelTherecallofalabelisthefractionoftheimageswhichareassignedagivenlabeloutofalltheimageswhichactuallyhavethelabelForthetestingset,wechoosethepredictedlabelasthenewlabelofagivenimageifitiswithinthetopnpredictedlabelsWedescribethecompletenessoftheannotationsforthepartiallyannotatedtrainingsetsofthethreedatabasesusingSSC HDPasafunctionoftheiterationinFigure4InTable1,wesumma rizethepredictionaccuracyandcompletenessforthetestingsetsofthethreedatabaseswhennisselectedas2,3,4usingMoM HDP,Corr LDA,Corr HDP,andSSC HDP,respectivelyThenumberofthemixturecomponentsfortheBDEimagedatabaseinTable1ischosenasK=8WeobservethatthecompletenessincreasesaftertheiterationprogressesinFigure4,andtheperformanceofSSC HDPwiththeunlabeleddataisbetterthanthatwithouttheunlabeleddata,whichshowsthattheunlabeleddataarehelpfultoimprovetheperfor manceofthemodelandthesemi supervisedlearningschemeiseffectiveincompletingthemissinglabelsofthetrainingsetatthesametimeinpromotingthepredictedaccuracyofthetestingset6789101112185191952020521215ThenumberofthemixturecomponentsKAccuracy(%)MoM HDPCorr LDACorr HDPSSC HDPFigure5:TheaccuracyforthetestingsetusingMoM HDP,Corr LDA,Corr HDP,andSSC HDPwiththepartiallylabeledtrainingsetfortheBDEimagedatabasepersondogcarchaircatbirdbottleaeroplanesofadiningtabletvmonitorpottedplantbicyclemotorbiketrainboathorsebussheepcow0020406081Precision/RecallPrecisionRecallFigure6:Theprecision/recallofthe20labelsforSSC HDPwithunlabeleddatawhenn=3fortheVOC2010databaseFigure6:TheaccuracyforthetestingsetusingMoM HDP,Corr LDA,Corr HDP,andSSC HDPwiththepartiallylabeledtrainingsetfortheBDEimagedatabase6789101112185191952020521215ThenumberofthemixturecomponentsKBAccuracy(%)MoM HDPCorr LDACorr HDPSSC HDPFigure7:TheaccuracyforthetestingsetusingMoM HDP,Corr LDA,Corr HDP,andSSC HDPwiththepartiallylabeledtrainingsetfortheBDEimagedatabase1205 Figure 8 : Image examples in the six categories in the VOC 2010 database : aeroplane , sheep , bus , bottle , diningtable , and tvmonitor ( from left column to right column ) .
1
0.8
0.6 l l a c e R / n o i s i c e r P
0.4
0.2
0 person
Precision Recall dog car chair cat aeroplane bottle bird bicycle diningtable pottedplant train motorbike sofa tvmonitor boat horse sheep bus cow
Figure 7 : The precision/recall of the 20 labels for SSC HDP with unlabeled data when n = 3 for the VOC 2010 database . ing set . Since the performance of SSC HDP is already close ( about 1 % to 2 % ) to that of the baseline which is the best and “ ideal ” case , the improvement of SSC HDP over the other models , though small ( about 1 % to 3% ) , is still significant . The reason why the baseline has a relatively low performance is related to the fact that the given ground truth labels are far away from being actually complete ; this can be seen clearly from the example shown in Figure 1 where the given ground truth , ie the “ complete ” annotation set , only includes person , bottle , and TVmonitor , while many other labels should have been given as part of the ground truth such as microphone and door . This fact further demonstrates the necessity to develop an inductive learning image annotation method based on partially given labels such as SSC HDP . Also from Table 1 it is further verified that the unlabeled data contribute to the improvement of the SSC HDP performance . From another perspective , the unlabeled data are considered as the partially annotated data from which 100 % of the labels are removed . Although the unlabeled data contain no information about labels , they are useful to make the structure of the distribution of the visual words clearer .
In Figure 6 we describe the accuracy of the predicted annotations when n = 3 for the testing set of the BDE image database as a function of the mixture components KB using MoM HDP , CorrLDA , Corr HDP , and SSC HDP with the partially labeled training set , respectively . From Figure 6 , we see that the performance of Corr LDA is more sensitive when the number of KB increases than those of MoM HDP , Corr HDP , and SSC HDP , for the latter three models use the truncated HDP as a prior which adapts to the number of the mixture components dynamically based on the training set . Similar results exist for the other two databases .
Figure 7 shows the precision/recall plots on each label for SSCHDP with the unlabeled dataset when n = 3 for the VOC 2010 database . Since the label person occurs most frequently and is contained in 4639 images in the VOC 2010 database , though we try to keep most of the categories roughly the same number of images , the occurrence number of the label person is larger than those of other labels . Consequently , most of the visual words establish links to the label person during the training process and in Figure 7 the recall and precision of the label person are high . Except for the label person , labels with the top three highest recalls and precisions are aeroplane , sheep , and bus , and labels with the top three lowest recalls and precisions are bottle , diningtable , and tvmonitor . Figure 8 shows examples of the images in these six categories in the VOC 2010 database , which further reveals an intuitive verification of the SSC HDP performance that an image with simple semantics results in a high precision and recall .
Further as a case study to demonstrate the superiority of the SSCHDP performance , Figure 1 is one of the partially labeled training images in the training data of the VOC 2010 database with the given partial labels as bottle and TVmonitor , and the given ground truth labels to this image as person , bottle , and TVmonitor . After the learning with SSC HDP , two extra labels are identified and added : one is the missing label person ; the other is an appropriate label sofa , which was even not originally given in the ground truth of the image . This shows that SSC HDP is an effective inductive learning method to complete all the missing labels in annotations , even in completing the missing labels of the ground truth , as long as those missing labels are in the label vocabulary . Since in the database the given label vocabulary is not actually complete in the ground truth , SSC HDP is unable to pick up those missing labels that appear in the image of Figure 1 such as microphone and door that are not even included in the label vocabulary .
6 . CONCLUSION
This paper studies an important problem in image data mining — mining partially annotated images . We have argued that this problem exists in many real world applications . We have then presented an effective and promising solution to this problem based on a statistical model we have developed called Semi Supervised Correspondence Hierarchical Dirichlet Process ( SSC HDP ) . The novelty of this model is that it uses partially annotated images as the training set to develop an inductive semi supervised learning statistical model to complete all the missing labels in the given partially labeled training annotations and to predict all the missing labels for the unlabeled and any new , unseen data . We evaluate SSC HDP on several standard datasets from the related literature in comparison with peer models from the recent literature . Experimental results demonstrate the effectiveness and promise of SSC HDP as a solution to the problem of mining partially annotated images . The partially labeled problem can be generalized from the image annotation to other multi label learning problems , and consequently , has a wide range of applications .
1206 using multi correlation probabilistic matrix factorization . In Proceedings of ACM international conference on Multimedia , pages 1187–1190 , 2010 .
[ 17 ] P . Liang , Petrov , M . I . Jordan , and D . Klein . The infinite pcfg using hierarchical dirichlet processes . In Proceedings of Empirical Methods in Natural Language Processing , pages 688–697 , 2007 .
[ 18 ] B . Liu , W . S . Lee , P . S . Yu , and X . Li . Partially supervised classification of text documents . In Proceedings of the 19th International Conference on Machine Learning , pages 387–394 , 2002 .
[ 19 ] N . Loeff , A . Farhadi , I . Endres , and D . A . Forsyth . Unlabeled data improves word prediction . In Proceedings of International Conference Computer Vision , 2009 .
[ 20 ] D . G . Lowe . Distinctive image features from scale invariant keypoints . International Journal of Computer Vision , 60(2):91–110 , 2004 .
[ 21 ] D . G . Luenberger and Y . Ye . Linear and Nonlinear
Programming . Springer , third edition , 2008 .
[ 22 ] J . Sethuraman . A constructive definition of dirichlet priors .
Statistica Sinica , 4:639–650 , 1994 .
[ 23 ] A . Sharma , G . Hua , Z . Liu , and Z . Zhang . Meta tag propagation by co training an ensemble classifier for improving image search relevance . In Computer Vision and Pattern Recognition Workshop , pages 1–6 , 2008 .
[ 24 ] Y Y Sun , Y . Zhang , and Z H Zhou . Multi label learning with weak label . In Proceedings of Association for the Advancement of Artificial Intelligence , pages 593–598 , 2010 .
[ 25 ] Y . W . Teh , M . I . Jordan , M . J . Beal , and D . M . Blei .
Hierarchical dirichlet processes . Journal of the American Statistical Association , 101:1566–1581 , 2004 .
[ 26 ] O . Yakhnenko and V . Honavar . Annotating images and image objects using a hierarchical dirichlet process model . In Proceedings of the 9th International Workshop on Multimedia Data Mining , pages 1–7 , 2008 .
[ 27 ] S H Yang , H . Zha , and B G Hu . Dirichlet bernoulli alignment : A generative model for multi class multi label multi instance corpora . In Proceedings of Neural Information Processing Systems , pages 2143–2150 , 2009 . [ 28 ] R . Zhang , Z . Zhang , M . Li , W Y Ma , and H J Zhang . A probabilistic semantic model for image annotation and multi modal image retrieval . In Proceedings of International Conference Computer Vision , pages 846–851 , 2005 .
[ 29 ] Z H Zhou and M L Zhang . Multi instance multilabel learning with application to scene classification . In Proccedings of Neural Information Processing Systems , pages 1609–1616 , 2007 .
[ 30 ] X . Zhu . Semi supervised learning literature survey .
Technical report , Computer Sciences TR 1530 , University of Wisconsin Madison , 2005 .
7 . ACKNOWLEDGMENTS
Zhongfei Zhang is on leave from SUNY Binghamton , USA , and is supported in part by US NSF through grants IIS 0812114 and CCF 1017828 . Any opinions , findings , and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the National Science Foundation .
8 . REFERENCES [ 1 ] http://wwwfruitflyorg/ [ 2 ] K . Barnard , P . Duygulu , D . Forsyth , N . de Freitas , D . M .
Blei , and M . I . Jordan . Matching words and pictures . Journal of Machine Learning Research , 3:1107–1135 , 2003 .
[ 3 ] D . M . Blei and M . I . Jordan . Modeling annotated data . In
Proceedings of the 26th International ACM SIGIR Conference , 2003 .
[ 4 ] D . M . Blei , A . Y . Ng , and M . I . Jordan . Latent dirichlet allocation . Journal of Machine Learning Research , 3:993–1022 , 2003 .
[ 5 ] M . R . Boutell , J . Luo , X . Shen , and C . M . Brown . Learning multi label scene classification . Pattern Recognition , 37(9):1757–1771 , 2004 .
[ 6 ] T . S . Chua , J . Tang , R . Hong , H . Li , Z . Luo , and Y . Zheng . Nus wide : a real world web image database from national university of singapore . In Proceedings of the ACM International Conference on Image and Video Retrieval , pages 1–9 , 2009 .
[ 7 ] R . Datta , D . Joshi , J . Li , and J . Z . Wang . Image retrieval :
Ideas , influences , and trends of the new age . ACM Computing Surveys , 40:1–60 , 2008 .
[ 8 ] M . Everingham , L . V . Gool , C . Williams , C . K . I . , J . Winn , and A . Zisserman . The pascal visual object classes ( voc ) challenge . International Journal of Computer Vision , 88(2):303–338 , 2010 .
[ 9 ] S . Feng , R . Manmatha , and V . Lavrenko . Multiple bernoulli relevance models for image and video annotation . In Proceedings of International Conference on Computer Vision and Pattern Recognition , pages 1002–1009 , 2004 . [ 10 ] Z . Guo , Z . Zhang , E . P . Xing , and C . Faloutsos . Enhanced max margin learning on multimodal data mining in a multimedia database . In Proceedings of 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , 2007 .
[ 11 ] H . Ishwaran and L . F . James . Gibbs sampling methods for stick breaking priors . Journal of the American Statistical Association , 96(453):161–173 , 2001 .
[ 12 ] J . Jeon , V . Lavrenko , and R . Manmatha . Automatic image annotation and retrieval using cross media relevance models . In Proceedings of ACM Special Interest Group on Information Retrieval , pages 119–126 , 2003 .
[ 13 ] V . Lavrenko , R . Manmatha , and J . Jeon . A model for learning the semantics of pictures . In Proceedings of Neural Information Processing Systems , 2003 .
[ 14 ] L J Li and L . Fei Fei . What , where and who ? classifying events by scene and object recognition . In Proceedings of International Conference Computer Vision , 2007 .
[ 15 ] W . Li and M . Sun . Semi supervised learning for image annotation based on conditional random fields . In Proceedings of ACM International Conference on Image and Video Retrieval , pages 463–472 , 2006 .
[ 16 ] Z . Li , J . Liu , X . Zhu , T . Liu , and H . Lu . Image annotation
1207
