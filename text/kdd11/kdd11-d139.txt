Stackelberg Games for Adversarial Prediction Problems
Michael Brückner
Department of Computer Science University of Potsdam , Germany mibrueck@csuni potsdamde
ABSTRACT The standard assumption of identically distributed training and test data is violated when test data are generated in response to a predictive model . This becomes apparent , for example , in the context of email spam filtering , where an email service provider employs a spam filter and the spam sender can take this filter into account when generating new emails . We model the interaction between learner and data generator as a Stackelberg competition in which the learner plays the role of the leader and the data generator may react on the leader ’s move . We derive an optimization problem to determine the solution of this game and present several instances of the Stackelberg prediction game . We show that the Stackelberg prediction game generalizes existing prediction models . Finally , we explore properties of the discussed models empirically in the context of email spam filtering .
Categories and Subject Descriptors I51 [ Pattern Recognition ] : Models—statistical ; H43 [ Information System Applications ] : Communications Applications—electronic mail
General Terms Theory , Algorithms
Keywords Adversarial Classification , Stackelberg Competition , Prediction Game , Spam Filtering
1 .
INTRODUCTION
A common assumption on which most learning algorithms are based is that training and test data are governed by identical distributions . However , in a variety of applications , the distribution that governs data at application time may be influenced by an adversary whose interests conflict those of the learner . Consider , for instance , the following three scenarios . In computer and network security , scripts that control
Tobias Scheffer
Department of Computer Science University of Potsdam , Germany scheffer@csuni potsdamde attacks are engineered with botnet and intrusion detection systems in mind . Credit card fraudsters adapt their unauthorized use of credit cards—in particular , amounts charged per transactions and per day and the type of businesses that amounts are charged from—such as not to trigger alerting mechanisms employed by credit card companies . Email spam senders design message templates that are instantiated by nodes of botnets ; templates are specifically designed to produce a low spam score with current spam filters . The domain of email spam filtering will serve as a running example throughout the paper . In all of these applications , assailants factor information about countermeasures that are being employed into the process of data generation .
The interaction between learner and data generators can be modeled as a game in which one player controls the predictive model whereas another exercises some control over the process of data generation . The adversary ’s influence on the generation of the data can be mathematically modeled as a transformation that is imposed on the distribution that governs the data at training time . The transformed distribution then governs the data at application time . The optimization criterion of either player takes as arguments both , the predictive model chosen by the learner and the transformation carried out by the adversary .
Typically , this problem is modeled under the worst case assumption that the adversary desires to impose the highest possible costs on the learner . This amounts to a zero sum game in which the loss of one player is the gain of the other . In this setting , both players can maximize their expected outcome by following a minimax strategy . El Ghaoui et al . [ 5 ] derive a minimax model for input data that are known to lie within some hyper rectangles around the training instances . Their solution minimizes the worst case loss over all possible choices of the data in these intervals . Lanckriet et al . [ 10 ] study the minimax probability machine . This classifier minimizes the maximal probability of misclassifying new instances for a given mean and covariance matrix of each class . Geometrically , this solution corresponds to a minimax strategy with hyper ellipsoids around the training instances , rather than hyper rectangles . Similarly , worstcase solutions to classification games in which the adversary deletes input features or performs arbitrary feature transformation have been studied [ 3 , 6 , 7 , 14 , 4 ] .
Several applications motivate problem settings in which the goals of the learner and the data generator , while still conflicting , are not necessarily entirely antagonistic . For instance , a fraudster ’s goal of maximizing the profit made from exploiting phished account information is not the inverse of an email service provider ’s goal of achieving a high spam recognition rate at close to zero false positives . When playing a minimax strategy , one often makes overly pessimistic assumptions about the adversary ’s behavior and may not necessarily obtain an optimal outcome .
For games that do not exhibit the zero sum property , a game theoretic model has been studied that assumes both players to commit to their actions simultaneously [ 1 ] ; that is , without information about the opponent ’s course of action . When the parameter space of the learner ’s model and the adversary ’s transformation and both players’ loss functions satisfy specific criteria ( eg , the loss functions have to be monotonic with distinct monotonicity and twice differentiable ) , then the prediction game has a unique Nash equilibrium that can be found by solving a compact optimization problem [ 1 ] . The Nash equilibrium is a combination of parameters for the predictive model and the adversary ’s transformation which has the property that neither player benefits by unilaterally deviating from it . For the learner , playing the Nash equilibrium instead of the minimax strategy is an optimal course of action under the following sufficient conditions : First , the adversary has to be trusted to behave rationally in the sense of maximizing their profit by playing a Nash strategy , too . If the learner plays the Nash equilibrium but the adversary deviates from that equilibrium , then both players may fare arbitrarily poorly . Secondly , a unique equilibrium needs to exist , since a combination of actions from two distinct equilibria may lead to an arbitrarily poor outcome for either player . Thirdly , the adversary must not have any information about the predictive model that the learner commits to before generating the data . In practice , this assumption can be violated when the adversary is able to probe the predictive model . If the adversary violates either of the above three conditions , no guarantees on the optimality can be given and , consequently , a learner may be ill advised to play the Nash equilibrium .
In practice , a spam sender may follow heuristics derived from past experience and experiments with the filter . Such a setting in which both players act non simultaneously can be modeled as a Stackelberg competition which allows one player—the follower—to be potentially fully informed about the move of the other player—the leader . We model adversarial learning as a Stackelberg competition in which the learner acts as leader by committing to a predictive model in the first step . The model is then disclosed to the follower— the data generator—who then gets to transform the input distribution .
Some authors [ 9 , 12 ] study the case in which the data generator acts as leader and the learner as follower . This reflects a setting in which the adversary discloses how the future distribution will differ from the current distribution before the learner has to commit to a model , which contradicts the intuition of an adversarial model building problem . When the data generator acts as leader and discloses the data transformation , the learner only has to solve a simple optimization problem in order to minimize the risk on the transformed data points .
The rest of this paper is organized as follows . Section 2 introduces the problem setting . We formalize the Stackelberg prediction game , derive an optimization problem to determine the Stackelberg equilibrium , and show how to employ kernel functions in Section 3 . In Section 4 , we present three instances of the SPG and discuss their relation to existing prediction models . We report on experiments on email spam filtering in Section 5 ; Section 6 concludes .
2 . PROBLEM SETTING We study prediction games between two players : The learner ( v = −1 ) and an adversary , the data generator ( v = +1 ) . In our running example of email spam filtering , we study the competition between recipient and senders , not competition among senders . To this end , v = −1 refers to the recipient whereas v = +1 models the entirety of all legitimate and abusive email senders as a single , amalgamated player . In the past , the data generator v = +1 produced a sample D = {(xi , yi)}n i=1 of n training instances xi ∈ X with corresponding class labels yi ∈ Y = {−1 , +1} . These object class pairs are drawn according to a training distribution with density function p(x , y ) . By contrast , future object class pairs , produced by the data generator at application time , are drawn from some test distribution with density ˙p(x , y ) which may differ from p(x , y ) . The task of the learner v = −1 is to select the parameters w ∈ R m of a predictive model h(x ) = sign fw(x ) implemented in terms of a generalized linear decision function fw : X → R with fw(x ) = wTφ(x ) and feature mapping φ : X → R m . The learner ’s theoretical costs at application time are given by fi
.
Y
X
θ−1(w , ˙p ) = c−1(x , y)'−1(fw(x ) , y ) ˙p(x , y)dx , where weighting function c−1 : X × Y → R and loss : R × Y → R detail the weighted loss function '−1 c−1(x , y)'−1(fw(x ) , y ) that the learner incurs when the predictive model classifies instance x as h(x ) = sign fw(x ) while the true label is y . The positive class and instance specific weighting factors c−1(x , y ) with E[c−1(X , Y ) ] = 1 specify the importance of minimizing the loss '−1(fw(x ) , y ) for the corresponding object class pair ( x , y ) . For instance , in spam filtering , the correct classification of non spam messages can be business critical for email service providers while failing to detect spam messages runs up processing and storage costs , depending on the size of the message .
The data generator v = +1 can modify the data generation process for future instances . In practice , spam senders update their campaign templates which are disseminated to the nodes of botnets . Formally , the data generator transforms the training distribution with density p to the test distribution with density ˙p . The data generator incurs transformation costs by modifying the data generation process which is quantified by Ω+1(p , ˙p ) . This term acts as a regularizer on the transformation and may implicitly constrain the shift that can be imposed on the distribution , depending on the nature of the application that is to be modeled . For instance , the email sender may not be allowed to alter the training distribution for non spam messages , or to modify the nature of the messages by changing the label from spam to non spam or vice versa . Additionally , changing the training distribution for spam messages may run up costs depending on the extent of distortion inflicted on the informational payload .
The theoretical costs of the data generator at application time are the sum of the expected prediction costs and the transformation costs , fi
.
θ+1(w , ˙p ) =
Y
X c+1(x , y)'+1(fw(x ) , y ) ˙p(x , y)dx
+ Ω+1(p , ˙p ) .
In analogy to the learner ’s costs , c+1(x , y)'+1(fw(x ) , y ) quantifies the loss that the data generator incurs when instance x is labeled as h(x ) = sign fw(x ) while the true label is y . The weighting factors c+1(x , y ) with E[c+1(X , Y ) ] = 1 express the significance of ( x , y ) from the perspective of the data generator . In our example scenario , this allows to reflect that costs of correctly or incorrectly classified instances may vary greatly across different physical senders that are aggregated into the amalgamated player .
Since the theoretical costs of both players depend on the test distribution , they can , for all practical purposes , not be calculated . Hence , we focus on a regularized , empirical counterpart of the theoretical costs based on the training sample D . The empirical counterpart ˆΩ+1(D , ˙D ) of the data generator ’s regularizer Ω+1(p , ˙p ) penalizes the divergence between training sample D = {(xi , yi)}n i=1 and a perturbated training sample ˙D = {( ˙xi , yi)}n i=1 that would be the outcome of applying the transformation that translates p into ˙p to sample D . The learner ’s cost function , instead of integrating over ˙p , sums over the elements of the perturbated training sample ˙D . The players’ empirical cost functions can still only be evaluated after the learner has committed to parameters w and the data generator to a transformation from training to test density function , but this transformation need only be represented in terms of the effects that it will have on the training sample D . The transformed training sample ˙D must not be mistaken for test data ; test data will be generated under ˙p at application time after the players have committed to their actions .
The empirical costs incurred by the predictive model h with parameters w and the shift from p to ˙p amount to
' where we have replaced the weighting terms 1 n cv( ˙xi , yi ) by constant cost factors cv,i > 0 with i cv,i = 1 . The learner ’s regularizer ˆΩ−1(w ) in ( 1 ) accounts for the fact that ˙D does not constitute the test data itself , but is merely a training sample transformed to reflect the test distribution and then used to learn the model parameters w . The tradeoff between the empirical loss and the regularizer is controlled by each player ’s regularization parameter ρv > 0 for v ∈ {−1 , +1} .
In our analysis , we estimate the transformation costs by the average squared l2 distance between xi and ˙xi in feature space ,
ˆΩ+1( ˙D , D ) =
1 n
'φ( ˙xi ) − φ(xi)'2 .
1 2
( 3 ) n . i=1
The learner ’s regularizer ˆΩ−1 penalizes the complexity of the predictive model h(x ) = sign fw(x ) . For our analysis , we consider Tikhonov regularization which , for linear decision functions fw , reduces to the squared l2 norm of w ,
ˆΩ−1(w ) =
'w'2 .
1 2
( 4 )
Note that either player ’s empirical costs ˆθv(w , ˙D ) depend on both players’ actions . The concept of an optimal choice of model parameters w regardless of the adversary ’s choice of a data transformation is therefore not well defined . In the following section , we will refer to the Stackelberg model which identifies the concept of an optimal move of the leader which minimizes ˆθ−1 over w under the assumption that the follower will react by minimizing ˆθ+1 over ˙D given the parameters w chosen by the leader .
3 . STACKELBERG PREDICTION GAME
We model the prediction game as a Stackelberg competition ; we refer to the resulting model as the Stackelberg prediction game ( SPG ) . A Stackelberg game is one of the simplest dynamic games : In the first stage , the leader —in our case , the learner—decides on a predictive model h(x ) = sign fw(x ) with parameters w . In the second stage , the data generator , who plays the part of the follower , observes the leader ’s decision and chooses a transformation that changes the distribution of past instances into the distribution of future instances . In this scenario , the learner has to commit to a set of parameters unilaterally whereas the data generator can take the model parameters w into account when preparing the data transformation .
The optimality of a Stackelberg equilibrium which we will now introduce rests on the assumption that the follower— the data generator—will act rationally in the sense of choosing a transformation that minimizes the resulting costs ˆθ+1 given the disclosed w . To reach minimal costs given w , the data generator has to identify a sample ˙D that constitutes a global minimum of the cost function ˆθ+1(w , ˙D ) . There may be several global minima with identical values of the cost function ; in general , the data generator has to identify any element ˙D from the set of optimal responses to w ,
ˆθ+1 w,{( ˙x i , yi)}n fi i=1
(
. i=1 : { ˙xi}n i=1 ∈ argmin . n∈X 1 , , ˙x .
˙x
Identifying an element ˙D ∈ ˙Dw amounts to solving a regular optimization problem because w can be observed before ˙D has to be chosen . A Stackelberg equilibrium is now identified by backward induction . Assuming that the data generator will decide for any ˙D ∈ ˙Dw , the learner has to choose model that minimize the learner ’s cost function ˆθ−1 parameters w for any of the possible reactions ˙D ∈ ˙Dw that are optimal for the data generator :
∗ w
∗ ∈ argmin w∈Rm max ˙D∈ ˙Dw
ˆθ−1(w , ˙D ) .
( 5 )
∗
An action w that minimizes the learner ’s costs and a corresponding optimal action ˙D ∈ ˙Dw∗ of the data generator are called a Stackelberg equilibrium . The Stackelberg equilibrium is a special case of a subgame perfect equilibrium which is an extension of the Nash equilibrium for games that are played non simultaneously . n . n . i=1 i=1
ˆθ−1(w , ˙D ) =
ˆθ+1(w , ˙D ) = c−1,i'−1(fw( ˙xi ) , yi ) + ρ−1 ˆΩ−1(w ) ,
( 1 ) c+1,i'+1(fw( ˙xi ) , yi ) + ρ+1 ˆΩ+1(D , ˙D ) , ( 2 )
˙Dw =ff {( ˙xi , yi)}n
3.1 Finding a Stackelberg Equilibrium
Equation 5 establishes a hierarchical mathematical program—specifically , a bilevel optimization problem—with upper level objective ˆθ−1 and lower level objective ˆθ+1 . w∈Rm max min ∀i : ˙xi∈X st
ˆθ−1(w , {( ˙xi , yi)}n i=1 ) { ˙xi}n i=1 ∈ argmin . n∈X 1 , , ˙x .
˙x
( 6 )
ˆθ+1(w,{( ˙x i , yi)}n fi i=1 ) ( 7 )
Bilevel programs are intrinsically hard to solve . Even the simplest instance in which all constraints and objectives are linear is known to be NP hard [ 8 ] . The main difficulties arise i ∈ X of the lower level optimization fi from the constraints ˙x problem which generally render constraint ( 7 ) of the upperlevel optimization problem to be non differentiable in w , fi even if ˆθ+1 is continuously differentiable in w and ˙x i for i = 1 , . . . , n .
Numerous approaches that address bilevel programs have been studied , for instance , based on gradient descent , penalty function , and trust region methods ; see , for instance , [ 2 ] for a detailed survey . Commonly , these methods reformulate the optimization problem into a mathematical program with equilibrium constraints . In this , the lower level optimization problem is replaced by its Karush Kuhn Tucker ( KKT ) conditions . The resulting optimization problem with equilibrium constraints can be solved approximately by relaxing the complementary conditions [ 15 ] . However these methods do not necessarily converge to a ( local ) optimum and are applicable to small problems only .
That is why we focus on a special case of the above bilevel program . The following theorem reformulates the lowerlevel optimization problem into an unconstrained problem such that constraint ( 7 ) becomes continuously differentiable in w . This requires the feature space induced by mapping φ , but not necessarily the input space X , to be unrestricted and the data generator ’s loss function '+1(z , y ) to be convex and continuously differentiable in z ∈ R .
Theorem 1 . Let the leader ’s cost function ˆθ−1 and the follower ’s cost function ˆθ+1 be defined as in ( 1 ) and ( 2 ) with regularizers ˆΩ−1 and ˆΩ+1 defined as in ( 4 ) and ( 3 ) , respectively . Let feature mapping φ : X → R m be surjective , let the data generator ’s loss function '+1(z , y ) be convex and continuously differentiable with respect to z ∈ R for any fixed y ∈ Y . Now let weight vector w m and factors ∗ 1 , . . . , τ τ fw(xi ) + τi'w'2 , yi n ∈ R be a solution of the optimization problem ∗ n . 'w'2 fw(xi ) + τi'w'2 , yi c−1,i'−1 ∀i : 0 = τi +
∗ ∈ R min w,∀i : τi st
( 8 )
.
ρ−1 2 c+1,i' i=1
+ fi +1 n ρ+1
Then the Stackelberg prediction game in Equation 6 attains i ∈ ∗ ∗ , ˙D an equilibrium at ( w { ˙x ∈ X : φ( ˙x ) = φ(xi ) + τ
) with ˙D ∗} . ∗ i w i , yi)}n ∗
= {( ˙x i=1 and ˙x
∗
∗ n .
Proof . Constraint 7 says that { ˙x i }n ∗ of the restricted optimization problem i=1 has to be a solution min
∀i : ˙xi∈X i=1 c+1,i'+1(w
T
φ( ˙xi ) , yi)+
ρ+1 n
'φ( ˙xi)−φ(xi)'2 .
1 2
As the objective as well as the constraints are entirely de∗ fined in terms of ˙x i ) , this condition is equivalent to
∗ i = φ( ˙x n . i=1 enforcing { ˙x i }n ∗ n . mization problem min
∀i : ˙xi∈Rm i=1 c+1,i'+1(w i=1 to be a solution of the unrestricted opti
T
˙xi , yi)+
ρ+1 n
' ˙xi−φ(xi)'2 . ( 9 )
1 2 n . i=1
∗ i ∈ R ∗ m , the set
˙X i w = { ˙x
This solution is uniquely defined for any fixed w as loss function '+1(z , y ) is required to be convex in z , and consequently in ˙xi , and the term ' ˙xi−φ(xi)'2 is quadratic in ˙xi and therefore strictly convex for any fixed φ(xi ) . Given w ∈ R m and ∗ ∈ X : φ( ˙x i} ∗ ∗ minimizer ˙x contains all instances ˙x which correspond to the optimally ∗ transformed instance in feature space ˙x i . Since φ is surjec˙X i tive , w is guaranteed to be non empty , and consequently , for any solution { ˙x i }n ∗ i=1 , there exist at least one correspondi }n ing set of instances { ˙x ∗ i=1 . As φ is not required to be a bijective mapping , there may exist multiple instances ˙x ∈ ˙X i w which are optimal in the sense of minimizing the data generator ’s loss . However , since all of these instances share the ∗ same feature representation ˙x i , the inner maximization of the upper level optimization problem in ( 6 ) vanishes ,
) = ˙x
+
ρ−1 2
'w'2 ,
( 10 ) w∈Rm max min ∀i : ˙xi∈ ˙X i w
ˆθ−1(w,{( ˙xi , yi)}n n .
) c−1,i'−1
T ˙x w
∗ i , yi i=1 ) = min w∈Rm i }n ∗ i=1 where {x i=1 is the solution of Optimization Problem 9 . Since 9 is convex , this constraint can be replaced by its complementary conditions which are given by ∇ ˙xi ˆθ+1(w , ˙D ) = 0 for i = 1 , . . . , n where
∇ ˙xi fi ˆθ+1(w , ˙D ) = c+1,i' +1(w ∗ i that satisfies the i th complemen
( ˙xi − φ(xi) ) .
∗ i , yi)w +
ρ+1 n
˙x
T
The mapped instance ˙x tary condition is given by
∗ i = φ(xi ) + τiw
˙x
( 11 )
,
T
T
˙x w with c+1,i' c+1,i'
∗ i , yi fi +1 fi +1 fi +1
) ) w w , yi fw(xi ) + τi'w'2 , yi
τi = − n ρ+1 = − n ρ+1 = − n ρ+1 ∗ When replacing ˙x i by ( 11 ) in the upper level Optimization Problem 10 and enforcing Equation 12 , Optimization Problem 8 follows . Hence , a solution w of ( 8 ) with corresponding τ X : φ( ˙x ) = φ(xi ) + τ
∗ n is also a solution of ( 6 ) with ˙x w∗ = { ˙x ∈
∗ 1 , . . . , τ i ∈ ˙X i ∗
φ(xi ) + τiw c+1,i'
∗ i w
∗} .
( 12 )
∗
T
,
.
The objective as well as the constraints of the optimization problem in Theorem 1 are generally not jointly convex in w and τ1 , . . . , τn . However , under the assumptions of the following proposition , a locally optimal solution can still be found efficiently by standard SQP solvers .
Proposition 1 . Let loss function '−1(z , y ) be twice continuously differentiable and loss function '+1(z , y ) be convex and thrice continuously differentiable with respect to z ∈ R for any fixed y ∈ Y . Then , a point satisfying the KKT conditions of the optimization problem in Equation ( 8 ) can be obtained by sequential quadratic programming ( SQP ) methods .
The objective as well as the constraints in ( 8 ) are twice continuously differentiable with respect to w and τi for i = 1 , . . . , n . Hence , the corresponding complementary conditions are continuously differentiable which is a sufficient condition to apply SQP methods ; this proves Proposition 1 .
3.2 Applying Kernels Theorem 1 states that a Stackelberg equilibrium with parameter vector w ∈ R m can be obtained by solving the optimization problem in ( 8 ) which requires an explicit feature representation φ(xi ) of the training instances . However , in some applications , such a feature mapping is unwieldy or even not existing . Instead , one is often equipped with a kernel function k : X × X → R which measures the similarity between two instances . Generally , kernel function k is assumed to be a positive semidefinite kernel such that it can be stated in terms of a scalar product in the corresponding reproducing kernel Hilbert space ; ie , ∃φ with k(x , x ) . Making use of the representer theorem [ 13 ] , we can now express weight vector w as a linear combination of the mapped training instances ; that is ,
) = φ(x )Tφ(x fi fi n . w =
αiφ(xi ) i=1
( 13 ) where feature mapping φ is implicitly defined by kernel k . When substituting w in ( 8 ) by ( 13 ) , the squared norm of w and decision function fw can be completely expressed in terms of the kernel ,
'w'2 =
αjαkk(xj , xk ) , fw(xi ) =
αj k(xi , xj ) . j=1 n . n . j,k=1
( 14 )
( 15 )
Hence , the optimization problem in ( 8 ) can be reformulated into an optimization problem over τ1 , . . . , τn ∈ R and the dual weights α1 , . . . , αn ∈ R without the need of an explicit feature mapping φ . However , inferring an optimal transformed sample ˙D still requires the knowledge of an explicit −1 . Of course , this is not a mapping φ and its inverse φ restriction as we are interested in the predictive model fw rather than the transformed sample ˙D
∗
∗
.
Note that for computational reasons , it may be advisable to first construct an explicit feature mapping from the kernel matrix and then to train the Stackelberg model in the primal . For instance , we can employ the kernel PCA map1
φ : x ( → K
− 1
T 2 [ k(x , x1 ) , . . . , k(x , xn ) ]
,
( 16 ) where K denotes the kernel matrix with Kij = k(xi , xj ) . Within our experiments ( presented in Chapter 5 ) where we use linear kernels , we study all three variants : Computing the model in input space , computing the kernelized version , and computing the PCA map induced variant . Even though all variants yield the same solution , using an explicit PCA mapping is generally fastest for reasonable n .
− 1
1Matrix K 2 can be computed directly from the eigenvalue decomposition of the kernel matrix K ; in case it is singular we use the pseudo inverse of K
1 2 .
4 .
INSTANCES OF THE SPG
By the choice of 'v , distinct instances of the Stackelberg prediction game ( SPG ) can be identified which , to some extent , generalize existing prediction models such as the SVM for invariances [ 14 ] and the SVM with uneven margins [ 11 ] . 4.1 SPG with Worst Case Loss
The SPG with worst case loss is an instance of the Stackelberg prediction game that is characterized by an antagonicity of the ( weighted ) empirical costs of learner and data generator ; that is , the data generator employs the loss function
+1(z , y ) = −'−1(z , y ) 'wc and cost factors c+1,i = c−1,i . Loss functions 'wc +1 and '−1 cannot both be convex at the same time—except for an inappropriate linear function—and so the requirements of either Theorem 1 or Proposition 1 are violated . As we cannot apply Theorem 1 , we consider the original optimization problem ( Equations 6 7 ) . We substitute 'wc +1 and c+1,i in the objective ( Equation 2 ) of the lower level optimization problem 'φ( ˙xi ) − φ(xi)'2
+1 ( fw( ˙xi ) , yi ) + n . n . c+1,i'wc
ρ+1 n
1 2 i=1 min
∀i : ˙xi∈X i=1 which decouples into n maximization problems
˙xi∈X c−1,i'−1(fw( ˙xi ) , yi ) − ρ+1 max n
'φ( ˙xi ) − φ(xi)'2 .
( 17 )
1 2
An equivalent formulation of ( 17 ) is given by
'−1(fw( ˙xi ) , yi ) max ˙xi∈X . i
( 18 )
ρ . +1 n
1 2 i = { ˙x ∈ X : c−1,i = where X fi 'φ( ˙x ) − φ(xi)'2} are feasible sets of transformed instances . The difference between both formulations is that in ( 18 ) , regularization pafi rameter ρ +1 explicitly restricts the amount of transformation of each instance xi . As now the inner maximization of the upper level optimization problem in ( 6 ) can be stated in terms of the solution of the lower level optimization prob∗ lem , '−1(fw( ˙x i ) , yi ) , the entire bilevel optimization problem reduces to the following constrained minimization problem . n . i=1 min w,∀i : ξi st c−1,iξi + ρ−1
'w'2
( 19 )
1 2
∀i : ξi ≥ 0 , ξi ≥ max ˙xi∈X . i
'−1(fw( ˙xi ) , yi )
( 20 )
If the lower level maximization problem ( 20 ) has a unique solution for any fixed w ∈ R m , then the above optimization problem can be solved by gradient descent where in each iteration the maximization problem in ( 20 ) has to be solved for the current iterate wk ( see , eg , [ 14] ) . In case the learner choses the hinge loss ,
'h−1(z , y ) = max(0 , 1 − yz ) ,
( 21 ) the SPG with worst case loss reduces to an instance of the SVM for invariances [ 14 ] . 4.2 SPG with Linear Loss
A second instance of the Stackelberg prediction game is the SPG with linear loss in which the data generator employs a linear loss function , 'lin +1(z , y ) = z , which penalizes high decision values z independently of the class . This choice is appropriate , for instance , in email spam filtering where the data generator is purely interested in the delivery of an email x which becomes unlikely for large values of z , independently of the corresponding true class y .
For the linear loss that is continuously differentiable and convex , the constraints in ( 8 ) reduce to
τi = − n ρ+1 c+1,i
( 22 ) for i = 1 , . . . , n . When choosing the hinge loss ( 21 ) for the learner and replacing τi in ( 8 ) by ( 22 ) we arrive at the following minimization problem . 'w'2 ff c−1,iξi + ρ−1 min w,∀i : ξi n . fi
1 2 i=1 st
∀i : ξi ≥ 0 , ξi ≥ 1 − yi
T w
φ(xi ) − n ρ+1 c+1,i'w'2
The latter constraints can be reformulated to
T yiw
φ(xi ) ≥ 1 + yiκi − ξi n ρ+1 which amounts to the constraints of the SVM with uneven margins [ 11 ] . The only syntactic distinction is that κi = c+1,i'w'2 is indirectly defined by ρ+1 and c+1,i ; however , for each choice of κi ≥ 0 in the SVM with uneven margins , there exist appropriate parameters ρ+1 and c+1,i of an equivalent SPG with linear loss and vice versa .
Consider the special case of equal factors c+1,i = c+1,j , and consequently κ = κi = κj , for all i , j = 1 , . . . , n . Then the margin of negative instances becomes 1 − κ whereas the margin of positive instances is 1+κ . In our example of spam filtering , this goes with the intuition that the margin of spam instances that vary greatly has to be larger than the margin of non spam instances that remain almost unmodified . This effect is stronger when the data generator ’s regularization parameter ρ+1 is small . By contrast , if ρ+1 goes to infinity , and consequently κ attains zero , then the SPG with linear loss reduces to the regular SVM . 4.3 SPG with Logistic Loss
Finally , this section introduces the SPG with logistic loss . This instantiation meets the preconditions of Theorem 1 and Proposition 1 , and the resulting optimization criterion can be solved with standard tools . The learner may use any loss function that is convex and twice continuously differentiable ( Equation 23 details the loss function used in our experiments ) while the data generator uses the logistic loss
'log +1(z , y ) = log ( 1 + e z
) which again penalizes large decision values z . The rationale behind this loss function is that the data generator experiences costs when the learner blocks an event , ie , produces a high decision function value for an instance . For instance , a legitimate sender experiences costs when a legitimate email is erroneously blocked just like an abusive sender , also amalgamated into the data generator , experiences costs when spam messages are blocked . Cost function 'log +1 approaches zero for small values of the decision function . Now , the constraints in ( 8 ) resolve to gi(w , τi ) = 0 for i = 1 , . . . , n with
) gi(w , τi ) = τi
1 + e
−fw ( xi)−τiw2
+ n ρ+1 c+1,i .
Functions gi(w , τi ) are not jointly convex in w and τi . However , as they are smooth ( ie , infinitely differentiable ) in both arguments , their roots can be obtained efficiently and , consequently , the resulting optimization problem fw(xi ) + τi'w'2 , yi
+
'w'2
ρ−1 2 n . min w,∀i : τi st c−1,i'−1 i=1
∀i : 0 = gi(w , τi ) can be solved by standard SQP solvers .
5 . EXPERIMENTAL EVALUATION
The goal of this section is to explore the relative strengths and weaknesses of the discussed instances of Stackelberg prediction games and existing baseline methods in the context of email spam filtering . We compare a regular support vector machine ( SVM ) , logistic regression ( LogReg ) , the SVM for invariances with feature scaling ( Invar SVM , [ 14] ) , Nash logistic regression ( Nash , [ 1] ) , and the Stackelberg instances SPG with worst case loss ( SPGwc , cf . Section 4.1 ) , SPG with linear loss ( SPGlin , cf . Section 4.2 ) , and the SPG with logistic loss ( SPGlog , cf . Section 43 ) For all Stackelberg instances we choose the logistic loss function
−yz
'log−1(z , y ) = log
1 + e
( 23 ) for the learner which is convex and smooth , and consequently satisfies Proposition 1 . In the absence of prior knowledge on the instance specific costs , we set cv,i = 1 n for all v ∈ {−1 , +1} , i = 1 , . . . , n and train all methods in the PCA map induced feature space . To solve the nonlinear program of the SPG with logistic loss we use the Ipopt solver [ 16 ] .
We use four email corpora detailed in Table 1 : The first data set contains emails of an email service provider ( ESP ) collected between 2007 and 2010 . The second ( Mailinglist ) is a collection of emails from publicly available mailing lists augmented by spam emails from Bruce Guenter ’s spam trap of the same time period . The third corpus ( Private ) contains newsletters and spam and non spam emails of the authors . The last corpus is the NIST TREC 2007 spam corpus . All emails are tokenized , converted into binary bag of word vectors , and sorted chronologically .
Table 1 : Data sets used in the experiments . data set
ESP
Mailinglist
Private
TREC 2007 instances 169,612 128,117 108,178 75,496 features 541,713 266,378 582,100 214,839 delivery period
01/06/2007 27/04/2010 01/04/1999 31/05/2006 01/08/2005 31/03/2010 04/08/2007 07/06/2007
Our evaluation protocol is as follows . We use the 4,000 oldest emails as training portion and set the remaining emails aside as test instances . We use the F measure—that is , the harmonic mean of precision and recall—as evaluation measure and train all methods 20 times on a stratified subset of 200 spam and 200 non spam messages sampled from the training portion . In order to tune the regularization parameters we perform a 5 fold cross validation on the training sample within each repetition of an experiment and for each method separately .
In the first experiment , we evaluate all methods into the future by processing the test set in chronological order . Each test sample is split into 20 disjoint subsets . We average
Performance on ESP corpus
Performance on Mailinglist corpus
0.98 e r u s a e m F
0.96
0.94
0.92
Oct07
Jul08
Apr09
Jan10
Aug01
Jan03
Jun04
Nov05
Performance on Private corpus
Performance on TREC 2007 corpus
0.9
0.99
0.98 e r u s a e m F
0.97
0.96
0.95
0.9 e r u s a e m F
0.85
0.8
0.75
0.95
0.9 e r u s a e m F
0.85
0.8
0.75
0.7
0.95
Mar06
May07
Aug08
Oct09
Apr07
May07
Jun07
SVM
LogReg
Invar−SVM
Nash
SPGwc
SPGlin
SPGlog
Figure 1 : F measure of predictive models . Error bars indicate standard errors . the F measure on each of those subsets over the 20 models ( trained on different samples drawn from the training portion ) for each method and perform a paired t test .
Figure 1 shows that , for all data sets , the Stackelberg prediction games with linear loss and with logistic loss outperform the regular SVM and logistic regression that do not explicitly factor the adversary into the optimization criterion . On the ESP corpus , the SPG with linear loss is slightly better than the SPG with logistic loss whereas for the Mailinglist corpus the SPG with logistic loss outperforms the SPG with linear loss . On the TREC 2007 data set , most of the methods behave comparably with a slight advantage for the Nash logistic regression and the SPG instances with logistic loss and linear loss . The period over which the TREC 2007 data have been collected is very short ; therefore we believe that the training and test instances are governed by nearly identical distributions . Consequently the gametheoretic models do not gain a significant advantage over logistic regression that assumes iid samples . For the other three data sets , the game theoretical models outperform the iid baselines .
Table 2 shows aggregated results over all four data sets . For each point in each of the diagrams of Figure 1 , we conduct a pairwise comparison of all methods based on a paired t test at a confidence level of α = 005 When a difference is significant , we count this as a win for the method that achieves a higher F measure . Each line of Table 2 details the wins and , set in italics , the losses of one method against all other methods . The Stackelberg prediction game with logistic loss has more wins than it has losses against each of the other methods . The Stackelberg prediction game with linear loss has more wins than losses against each of the other methods except for the SPG with logistic loss and the Nash logistic regression . The ranking continues with the InvarSVM , the SPG with worst case loss , logistic regression , and the regular SVM which loses more frequently than it wins against all other methods .
To study the predictive performance as well as running time behavior with respect to the size of the data set , we train the baselines and the three SPG instances for a varying number of training examples . We report on the results for the representative ESP data set in Figure 2 . Except for SPGwc , the game models significantly outperform the trivial baseline methods SVM and logistic regression , especially for small corpus sizes . However , this comes at the price of considerably higher computational cost . For the game models , the Stackelberg instance SPGlin clearly outperforms all reference methods with respect to efficiency . Though , the larger the size of the data set , the stronger the computational differences , where at the same time the discrepancy of the predictive performance diminishes .
The data generator ’s regularizer that we use in the experiments does not distinguish between modifications of spam and non spam messages . In reality , most senders of legitimate messages do not deliberately change their writing behavior such as to bypass spam filters , perhaps with the exception of senders of legitimate newsletters who must be careful not to trigger filtering mechanisms . In a final exper
Performance on ESP corpus
Execution time on ESP corpus
103 c e s
0.9
0.85
0.8 e r u s a e m F
0.75
0.7
50
100
200
400 number of training emails
800
101 n i e m i t
10−1
1600
3200
50
100
200
400 number of training emails
800
1600
3200
SVM
LogReg
Invar−SVM
Nash
SPGwc
SPGlin
SPGlog
Figure 2 : Predictive performance ( left ) and execution time ( right ) for varying sizes of the training data set .
Table 2 : Results of paired t test over all corpora : Number of trials in which each method ( row ) has significantly outperformed each other method ( column ) vs . number of times it was outperformed . method vs . method
SVM
LogReg
Invar SVM
Nash SPGwc SPGlin SPGlog
SVM LogReg 6:44 0:0 44:6 0:0 41:3 64:2 72:0 72:0 29:0 50:8 48:6 54:6 69:6 57:5
Invar SVM Nash 0:72 0:72 6:40 0:0 2:57 17:33 16:14
2:64 3:41 0:0 40:6 10:39 23:20 30:18
SPGwc 8:50 0:29 39:10 57:2 0:0
46:17 48:9
SPGlin 6:54 6:48 20:23 33:17 17:46
0:0
23:10
SPGlog 6:69 5:57 18:30 14:16 9:48 10:23
0:0 iment , we want to study whether the Stackelberg model reflects this aspect of reality . Table 3 shows the average number of modifications—ie , word additions and deletions— performed by the sender per spam and per non spam email depending on the sender ’s regularization parameter ρ+1 for fixed ρ−1 .
Table 3 : Average number of word additions and deletions per instance for SPGlog .
ρ+1
4 16 64 256 1024 non spam spam additions deletions additions deletions
1.4 0.3 0.0 0.0 0.0
1.6 0.3 0.0 0.0 0.0
14.6 9.9 7.1 2.4 0.8
17.6 11.6 8.7 2.8 0.9
As expected , the number of transformations increases inversely proportional to the regularization parameter . Even for equal cost factors cv,i , non spam messages are rarely modified because the interests of sender and recipient are coherent for legitimate messages .
6 . CONCLUSIONS
We model adversarial prediction problems as a game in which a learner has to commit to a predictive model using past data whereas the data generator may choose a transformation function after the predictive model has been disclosed which then defines the test distribution . This model reflects applications such as the detection of network attacks and spam filtering in which an assailant can probe the filter . The cost functions of learner and data generator are generally conflicting but are not constrained to be perfectly antagonistic . Playing the Stackelberg equilibrium instead of a worst case strategy based on a zero sum model is advisable when the data generator can be assumed to behave rational in the sense of minimizing a cost function . However , in contrast to the Nash strategy , the Stackelberg model does not rely on the existence of a unique equilibrium and the assumptions that the adversary has no information about the predictive model and is able to identify and follow the equilibrial strategy .
We derived a compact optimization problem that determines the solution of the resulting Stackelberg prediction game . We showed that the Stackelberg model generalizes existing prediction models such as SVM with uneven margins and SVM for invariances . We evaluated spam filters resulting from a regular SVM , logistic regression , existing game theoretical models , and three instances of the Stackelberg game on several spam filtering data sets . The relative performance of the distinct game theoretic models varies , but we observe that when compared to any other model , the Stackelberg model with logistic loss has more wins than it has losses against each of the baseline methods .
Acknowledgments This work was supported by the German Science Foundation DFG under grant SCHE 540/12 1 and by STRATO AG .
7 . REFERENCES [ 1 ] M . Br¨uckner and T . Scheffer . Nash equilibria of static prediction games . In Advances in Neural Information Processing Systems . MIT Press , 2009 .
[ 2 ] B . Colson , P . Marcotte , and G . Savard . An overview of bilevel optimization . Annals of Operations Research , 153(1):235–256 , 2007 .
[ 3 ] O . Dekel and O . Shamir . Learning to classify with missing and corrupted features . In Proceedings of the International Conference on Machine Learning , pages 216–223 . ACM , 2008 .
[ 4 ] O . Dekel , O . Shamir , and L . Xiao . Learning to classify with missing and corrupted features . Machine Learning , 81(2):149–178 , 2010 .
[ 5 ] L . E . Ghaoui , G . R . G . Lanckriet , and G . Natsoulis .
Robust classification with interval data . Technical Report UCB/CSD 03 1279 , EECS Department , University of California , Berkeley , 2003 .
[ 6 ] A . Globerson and S . T . Roweis . Nightmare at test time : robust learning by feature deletion . In Proceedings of the International Conference on Machine Learning . ACM , 2006 .
[ 7 ] A . Globerson , C . H . Teo , A . J . Smola , and S . T .
Roweis . Dataset Shift in Machine Learning , chapter An adversarial view of covariate shift and a minimax approach , pages 179–198 . MIT Press , 2009 .
[ 8 ] R . Jeroslow . The polynomial hierarchy and a simple model for competitive analysis . Mathematical Programming , 32:146–164 , 1985 .
[ 9 ] M . Kantarcioglu , B . Xi , and C . Clifton . Classifier evaluation and attribute selection against active adversaries . Data Mining and Knowledge Discovery , 22(1 2):291–335 , 2011 .
[ 10 ] G . R . G . Lanckriet , L . E . Ghaoui , C . Bhattacharyya , and M . I . Jordan . A robust minimax approach to classification . Journal of Machine Learning Research , 3:555–582 , 2002 .
[ 11 ] Y . Li and J . Shawe Taylor . The SVM with uneven margins and chinese document categorization . In Proceedings of the Pacific Asia Conference on Language , Information and Computation , pages 216–227 , 2003 .
[ 12 ] W . Liu and S . Chawla . A game theoretical model for adversarial learning . In ICDM Workshops , pages 25–30 . IEEE Computer Society , 2009 .
[ 13 ] B . Sch¨olkopf , R . Herbrich , and A . J . Smola . A generalized representer theorem . In COLT : Proceedings of the Workshop on Computational Learning Theory , Morgan Kaufmann Publishers , 2001 .
[ 14 ] C . H . Teo , A . Globerson , S . T . Roweis , and A . J .
Smola . Convex learning with invariances . In Advances in Neural Information Processing Systems . MIT Press , 2007 .
[ 15 ] S . Veelken . A New Relaxation Scheme for
Mathematical Programs with Equilibrium Constraints : Theory an Numerical Experience . PhD thesis , Technische Universit¨at M¨unchen , 2009 .
[ 16 ] A . W¨achter and L . T . Biegler . On the implementation of an interior point filter line search algorithm for large scale nonlinear programming . Mathematical Programming , 106:25–57 , 2006 .
