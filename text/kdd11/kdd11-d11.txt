An Effective Evaluation Measure for Clustering on Evolving Data Streams
Hardy Kremer , Philipp Kranen , Timm Jansen , Thomas Seidl RWTH Aachen University , Germany lastname@csrwth aachende
ABSTRACT Due to the ever growing presence of data streams , there has been a considerable amount of research on stream mining algorithms . While many algorithms have been introduced that tackle the problem of clustering on evolving data streams , hardly any attention has been paid to appropriate evaluation measures . Measures developed for static scenarios , namely structural measures and ground truth based measures , cannot correctly reflect errors attributable to emerging , splitting , or moving clusters . These situations are inherent to the streaming context due to the dynamic changes in the data distribution .
In this paper we develop a novel evaluation measure for stream clustering called Cluster Mapping Measure ( CMM ) . CMM effectively indicates different types of errors by taking the important properties of evolving data streams into account . We show in extensive experiments on real and synthetic data that CMM is a robust measure for stream clustering evaluation . Categories and Subject Descriptors H28 [ Database Management ] : Database Applications— Data Mining ; I53 [ Pattern Recognition ] : Clustering General Terms Measurement , Experimentation 1 .
INTRODUCTION
Mining patterns from data streams is constantly gaining importance in many applications . Streams consist of data tuples that need to be processed as they arrive , and mining these streams is challenging since the data distribution underlying a stream can evolve significantly over time . Stream mining tasks are , for example , classification [ 4 ] , association rule mining [ 30 ] , or clustering [ 1 , 8 , 23 ] . In stream clustering , a clustering is constantly adapted to reflect changes in the observed stream . Besides dealing with evolving distributions , stream clustering algorithms have to meet several
Albert Bifet , Geoff Holmes ,
Bernhard Pfahringer
University of Waikato Hamilton , New Zealand
{abifet,geoff,bernhard}@cswaikatoacnz technical requirements , including limited time , limited memory , and processing the stream in a single pass . A multitude of stream clustering algorithms has been proposed in the literature that satisfy these requirements .
Of major importance is the quality of the resulting clusterings , which can be measured by evaluation measures , also termed criteria , indices , validation measures , or validation indices . Research on evaluation measures for static datasets , ie traditional clustering without the streaming context , looks back at a history of more than thirty years . While clustering itself is commonly accepted as a difficult and subjective task [ 21 ] , the validation of clustering results is even described as the most difficult and frustrating part of cluster analysis [ 20 ] . This holds for evaluation no matter whether or not a ground truth is available against which to compare the clustering result . The usage of a ground truth can strictly categorize the proposed measures into internal and external measures [ 7 , 25 , 38 , 41 ] : Internal measures consider only the structure and properties of the clusters , eg their compactness or the distance between them . External measures compare the resulting clustering against a ground truth , eg punishing an algorithm for putting objects from different ground truth clusters into a single cluster .
The MOA Framework [ 5 , 24 , 29 ] is an open source benchmarking software for data stream mining , which contains a set of stream clustering algorithms from the literature as well as an extensive collection of evaluation measures . The experience from implementing and using MOA showed two major disadvantages of existing evaluation measures : First , none can properly handle the peculiarities of evolving data streams such as overlapping due to merging or drifting clusters or noisy data streams . As a consequence the measures cannot effectively reflect the occurring errors . Second , the vast majority of evaluation measures achieve suboptimal results even if the ground truth clustering is tested . The Cluster Mapping Measure ( CMM ) proposed in this paper overcomes these shortcomings and enables effective evaluation of clustering results on evolving streams .
2 . RELATED WORK
We first review existing work on evaluation measures for clustering on static data sets . After that we discuss related work on stream clustering algorithms and identify the evaluation measures employed in the individual approaches .
As mentioned in Sec 1 , evaluation measures can be categorized into internal and external measures , depending on whether or not they employ a ground truth clustering for comparison . A different categorization additionally identi
868 fies so called relative measures , comparing the single partitions within a clustering result . However , this group is less recognized and solutions are often specialized to a specific domain [ 36 , 42 ] ; we focus on internal and external measures . Table 1 lists ( without claiming completeness ) a collection of internal and external measures from the literature with references to formulae and more detailed description . Apart from these , other measures exist that deal with fuzzy clustering [ 6 ] or focus on finding the best number of clusters [ 37 , 40 ] . For readability and space reasons we reduced the amount of measures used in our experiments to the ones highlighted in gray . Our choice of internal measures is based on a study of thirty measures in [ 28 ] ; the external measures resulted as best choices in three recent studies [ 7 , 38 , 41 ] .
External measures Rand statistic [ 41 , 32 ] Jaccard coefficient [ 12 ] Folkes and Mallow Index [ 12 ] Hubert Γ statistics [ 17 ] Minkowski score [ 7 ] Purity [ 43 ] van Dongen criterion [ 39 ] V measure [ 35 ] Completeness [ 35 ] Homogeneity [ 35 ] Variation of information [ 26 ]
Internal measures Gamma [ 2 ] C Index [ 18 ] Point Biserial [ 27 ] Log Likelihood [ 16 ] Dunn ’s Index [ 11 ] Tau [ 34 ] Tau A [ 18 ] Tau C [ 18 ] CDbw [ 14 ] Ratio of Repetition [ 18 ] Sum squared dists SSQ [ 15 ] Adj . Ratio of Clustering [ 18 ] Mutual information [ 10 ] Class based entropy [ 38 ] Fagan ’s Index [ 18 ] Cluster based entropy [ 43 ] Deviation Index [ 18 ] Z Score Index [ 18 ] Precision [ 33 ] Recall [ 33 ] D Index [ 18 ] Silhouette coefficient [ 22 ] F measure [ 33 ]
Table 1 : Internal and external evaluation measures .
Stream clustering algorithms can be categorized from different perspectives , eg whether convex or arbitrary shapes are found . Convex stream clustering approaches are based on a k center clustering [ 1 , 23 , 31 ] . Approaches for arbitrary shaped clusters use kernels [ 19 ] , fractal dimensions [ 3 ] , or density based methods [ 8 , 9 ] . In the evaluation of these papers , the used measures are those for static data sets , most often Entropy ( Purity ) , Precision , or the F measure . In convex approaches , which are the most prevalent in the literature , often also the sum of squared distances is used ( eg , [ 1 , 31] ) , ie the compactness of spherical clusters is measured , which does not testify the quality of a clustering . Most stream clustering algorithms use an internal representation , called micro clustering , that is constantly updated . Only when required , the output ( macro ) clusterings are generated by an offline component , eg k means .
In summary , we find that despite the amount of work on developing evaluation measures as well as developing stream clustering algorithms , no attempt has been made to meet the requirements of both tasks .
3 . PRELIMINARIES
In this section we provide formal definitions used throughout the paper . We concentrate on spherical clusters , which constitute the most prevalent model . It is eg also used in the online components of density based algorithm [ 9 ] .
An object arriving on a data stream is represented by a tuple of attribute values . We define a stream as follows :
Definition 1 . Stream . A streamS = {o1 , o2 , . . .} is an infinite sequence of objects oi , where each object is a d dim . tuple of attribute values oi = ( oi1 , . . . , oid ) with oij ∈ R .
.
Definition 2 . Weight .
In order to give more influence to recent data , objects are assigned an age depending weight . We exemplarily define the weight using an exponential decay function as in [ 1 ] . Other weighting functions assign a binary weight ( sliding window ) using either the age or the cardinality for thresholding . Let tnow be the current time and to the arrival time of objecto with to ≤ tnow . Then the weight of o is w(o ) = β−λ·(tnow−to ) The parameters β and λ control the form of the aging function , eg if β = 2 then 1/λ is the half life of o . Apart from the complete stream S we often only consider a subset of the most recent objects that we call horizon . Definition 3 . Horizon . The horizon H for a stream S and threshold ξ is defined as H = {o ∈ S|w(o ) ≥ ξ} . To employ a consistent terminology we also formally define clustering and ground truth . Definition 4 . Clustering . A clustering algorithm takes a set O = {o1 , . . . , on} of objects as input and returns a cluster set C = {C1 , . . . , Ck , C∅} . o ∈ Ci implies that o lies within the cluster boundary of Ci and C∅ contains all unassigned objects . Objects may fall into several clusters .
Definition 5 . Ground truth .
.l
= O ∪ Clnoise .
= CL ∪ {Clnoise} and O+
For a given object set O = {o1 , . . . , on} a ground truth CL = {Cl1 , . . . , Cll} is a partitioning of O with ∀i = j : Cli∩ Clj = ∅ and i=1 Cli = O . The partitions Cli are called classes and Cl(o ) is the class of o . In the presence of noise Clnoise is the noise class , CL+ We define the ground truth cluster Cl◦ i as the smallest cluster that contains all objects from Cli within its boundary : ∀o ∈ Cli : o ∈ Cl◦ i . The ground truth cluster resulting from a class may contain i ⊇ Cli , and two points from other classes as well , ie Cl◦ clusters resulting from two different ground truth classes can overlap , ie they are not necessarily disjoint since objects may fall into the boundaries of other classes .
4 . CLUSTER MAPPING MEASURE
In stream processing , data mining algorithms have to take the special properties of the scenario into account . Likewise , for a reasonable comparison of the algorithms , evaluation measures should also consider these special circumstances :
1 . Aging / decay Dealing with this property is probably the simplest task , because faults caused by a clustering algorithm can be weighted by the influence of the corresponding points ( cf . Def . 2 ) .
2 . Missed points Moving clusters yield errors for missed points . These errors should reflect the seriousness , eg how close the point is to its actual cluster .
3 . Misplaced points Evolution , merging , and splitting of clusters yield overlapping clusters and thereby easily misplaced points . A measure that punishes these misplaced points equally to misplaced points laying outside of any overlapping region does not account for the special circumstances of evolving streams .
4 . Noise Including noise in a found cluster is often inevitable in the model of the clustering algorithm and should be accounted for by an effective measure .
869 . ff .
fi fffi
' ff'
Figure 1 : Point connectivity in clusters . p1 and p3 have stronger connections to their clusters than p2 .
Figure 2 : The errors due to misplaced points ( blue circles ) is less severe in the right example .
Summarizing these properties , three fault cases can be identified that have to be considered in depth , namely missed points , misplaced points , and noise inclusion . The penalty for such errors of stream clustering algorithms should reflect their seriousness and take the age of the points as well as the clustering model into account . CMM is a normalized sum of the penalties for occurring errors that accounts for all aspects mentioned above . Two important prerequisites for the computation are a notion of how well an object fits into a cluster and a mapping from found clusters to ground truth classes . We introduce these prerequisites and CMM in the following section and analyze its behavior in the fault scenarios in Sec 5 . 4.1 Connectivity
A central concept used throughout CMM is the connectivity between points and clusters . This connectivity states how well the point is connected to the cluster , ie how it fits the distribution of the cluster in comparison to the other points . We define the connectivity as a distance based concept that ranges from 0 to 1 , where 0 indicates no connectivity and 1 indicates a strong connectivity . As a prerequisite we define the average k neighborhood distance for points and clusters . k is a locality parameter , and we show in Sec 6 that it has only marginal influence on CMM effectiveness .
Definition 6 . average k neighborhood distance . The k neighborhood ( knh ) of a point p in a cluster Ci are the k closest points , ie knh(p , Ci ) ⊆ Ci \ p with |knh(p , Ci)| ≤ k , and for objects oin ∈ knh(p , Ci ) and oout ∈ Ci \ knh(p , Ci ) it holds ∀oin∀oout : dist(p , oout ) ≥ dist(p , oin ) . The average distance of p to its k neighbors in Ci is then fi fi p∈Ci knhDist(p , Ci ) =
1 k dist(p , o ) o∈knh(p,Ci ) and the average distance for a Cluster Ci is knhDist(Ci ) =
1|Ci| knhDist(p , Ci )
Based on this distance we define connectivity as follows :
Definition 7 . Point connectivity . The connectivity of a point p to a ClusterC i is defined as con(p , Ci ) = if knhDist(p , Ci ) < knhDist(Ci ) if Ci = ∅
0 knhDist(Ci ) knhDist(p,Ci ) else
⎧⎪⎨ ⎪⎩1
Fig 1 shows examples for connectivity scenarios for spherical clusters using k = 3 . In the left case the points are densely and rather equally distributed within the cluster . Point p1 has a strong connectivity to cluster C1 , since its average neighborhood distance is similar to that of C1 . In C2 , the points are not equally distributed . Point p2 is not strongly connected , since its average neighborhood distance is larger than the average of C2 . In the right example , p3 also has a comparably large average neighborhood distance , but it is still strongly connected to C3 , becauseC 3 is less dense .
Fig 2 illustrates the connectivity of points from the gray cluster ( blue circles ) to the black cluster . Misplacing gray points in the black cluster seems more severe in the left example , since they are strongly connected to their own ( gray ) cluster and hardly connected to the black cluster ( cf . blue circles ) . In contrast , on the right they have a stronger connection to the black cluster making the misplacement error intuitively less severe . 4.2 Cluster mapping
To decide whether a point is misplaced we need a mapping from the clusters returned by a stream clustering algorithm to ground truth classes . Before we give a formal definition of the employed mapping we will discuss an example .
As described in Sec 3 clusters Cl◦
1 and Cl◦ j resulting from the ground truth classes ( cf . Def . 5 ) may overlap . Fig 3(a ) shows an example . The gray points belong to class Cl1 , the black points to class Cl2 . The solid circles are the cluster boundaries resulting from a spherical clustering model , ie Cl◦ 2 , and there are black points that fall into the boundary of the gray cluster and vice versa . The figure demonstrates that on evolving data streams a simple majority voting for mapping found clusters to ground truth clusters is not feasible . The core problem are clusters of different densities , frequently occurring in streaming scenarios due to novelty or disappearance of clusters . In the figure , the black cluster is dense and the gray cluster is still emerging , ie there are only 10 objects present in the gray concept . The overlapping due to the convex model yields a majority of the black class even in the ground truth cluster Cl◦ 1 of the gray class , ie a majority voting would map both C1 and Cl◦ 1 to the wrong ( black ) class due to the dominance of the black objects . A majority voting cannot obtain a correct mapping in these scenarios because its decision is based on a single class ’s objects in a cluster , ignoring the other classes’ information that often indicate novel or fading clusters . To solve this issue we map clusters Ci to ground truth classes Clj according to the similarity of Ci ’s and Cl◦ j ’s class distributions , ie we take the clustering model into account . We define these distributions of classes inside a cluster as frequency histograms . Definition 8 . Class distribution . For a given clustering C = {C1 , . . . , Ck} and ground truth CL = {Cl1 , . . . , Cll} , the histogram of the class distribution in cluster Ci is
ρ(Ci ) = ( |Ci ∩ Cl1| , . . . ,|C i ∩ Cll| )
ρ(Ci)a is the a th component of ρ(Ci ) representing the frequency of class Cla in cluster Ci . Def . 8 analogously applies to ground truth clusters Cl◦ j that result from classes Clj . The right part of Fig 3 illustrates the class distributions for the shown clusters .
870 a)figroundfitruthficlusters
( cid:1233 )
Cl2
( cid:1233 )
Cl1 b)fifoundficlusters
C1
( cid:1233 )
( cid:85)(Cl1)fi=fi(10,fi11 )
( cid:1233 )
( cid:85)(Cl2)fi=fi(1,fi50 )
( C1,fiCl1)fi=fi
( cid:1233 )
0fi+fi1fi=fi1
( C1,fiCl2)fi=fi
( cid:1233 )
7fi+fi0fi=fi7
( cid:85)(C1)fi=fi(8,fi12 )
Figure 3 : Mapping from found clusters to ground truth clusters is based on class distributions . Mapping clusters based on majority voting cannot recognize emerging or disappearing clusters .
We map clusters based on class distribution similarity . Concretely , we map a cluster Ci to the ground truth class Clj , whose ground truth cluster Cl◦ j covers the majority of Ci ’s class frequencies . Definition 9 . Cluster mapping . For a given clustering C = {C1 , . . . , Ck , C∅} and ground truth CL = {Cl1 , . . . , Cll} ,
Δ(Ci , Cl◦ j ) = max{0 , ρ(Ci)a − ρ(Cl◦ j )a} lfi a=1 is the total surplus of objects from classes Cl1 , . . . , Cll in Ci compared to Cl◦ j , where the surplus is the number of class objects from Cli not covered by the class distribution of the ground truth cluster Cl◦ j . Ci is then mapped to the class j )} if ∀Clj : Δ(Ci , Cl◦ j ) > 0 map(Ci)= if Ci = C∅ j|} else
⎧⎪⎪⎪⎪⎪⎪⎨ ⎪⎪⎪⎪⎪⎪⎩ argmin {Δ(Ci , Cl◦ Clj∈CL ∅ argmax {|Ci ∩ Cl◦ Clj∈CL Δ(Ci,Cl◦ j )=0
The first and most important case ensures that for a set of ground truth clusters , Ci is mapped to the ground truth class that induces the least surplus on class frequencies . If we would also consider negative differences , as eg in Lp norms , micro clusters would always be mapped to the smallest ground truth class . Employing a majority voting is not generally feasible in the streaming context as explained above . The second case ensures that the unassigned object set C∅ is not mapped to any class , enabling a correct penalty for missed non noise points ( cf . the analysis in Sec 51 ) The third case arises if Ci completely fits into one or more ground truth clusters ; in this special case , a majority voting is applied . If a ground truth cluster Cl◦ i falls completely into another cluster Cl◦ j )a , Ci is mapped to the larger cluster ’s class ; such clusters are inseparable , as we discuss in Sec 53 If we use this mapping in Fig 3 , the found cluster C1 in ( b ) as well as the ground truth clusters Cl◦ 4.3 Cluster Mapping Measure With the mapping from found clusters to ground truth classes , we can now determine the set F ⊆ O+ of points that cause faults , ie missed points , misplaced points , or included noise points . j , ie ∀a : ρ(Cl◦ i in ( a ) are correctly mapped . i )a ≤ ρ(Cl◦
Definition 10 . Fault set .
CL+ objects mapped to a false class is
= O ∪ Clnoise , = CL ∪ {Clnoise} , and C = {C1 , . . . , Ck , C∅} , the set of F = {o ∈ O+|∃Ci : o ∈ Ci ∧ map(Ci ) = Cl(o)}
For O+
Obviously , a single point o can cause several faults . The set of clusters in which o causes a fault is f aultClu(o ) = {Ci ∈ C|o ∈ Ci ∧ map(Ci ) = Cl(o)}
The penalty for a fault point depends on the connectivity to both its true class and the assigned class . fault set and Ci ∈ f aultClu(o ) . The penalty for o is pen(o , Ci ) = con(o , Cl(o ) ) · ( 1 − con(o , map(Ci) ) )
Definition 11 . Penalty . Let o be an object from the
The overall penalty for a fault point o wrt all found clusters Ci ∈ C is defined as pen(o,C ) = maxCi∈f aultClu(o){pen(o , Ci)}
The single penalty function can handle all three fault types , and we detail on this in Sec 51 To sustain comparability between points , we only count a fault point ’s most serious fault in the overall penalty .
Now we can define the CMM , which indicates how different a given clustering is from a given ground truth . CMM is a normalized sum of the penalties : if no fault occurs CMM will be 1 and 0 indicates maximal error . Definition 12 . CMM . Given = O ∪ Clnoise , a ground truth CL+ an set = CL ∪ {Clnoise} , O+ a clustering C = {C1 , . . . , Ck , C∅} , and the fault set , the Cluster Mapping Measure between C and F ⊆ O+ CL+ is defined using the point weight w(o ) and the overall penalty from Def . 11 as CMM(C,CL ) = 1 −
( ( o∈F w(o ) · pen(o,C ) o∈F w(o ) · con(o , Cl(o ) ) object and if F = ∅ , then CMM(C,CL ) = 1 . 5 . ANALYSIS & REFINEMENT
In this section we first analyze how CMM handles different fault types caused by evolving streams . In Sec 5.2 we refine CMM such that it is robust against errors occurring due to the clustering model and that it can measure how well a clustering reflects the ground truth ’s main concepts . Sec 5.3 introduces a structure analysis for data sets . 5.1 Missed , Misplaced , and Noise inclusion
In this section we discuss how the penalties differ for the three fault types and why these faults are correctly reflected . An object o ∈ CL is missed if it is unassigned and is not a noise object , ie o ∈ C∅ ∧ o /∈ CLnoise . The set of these objects is called Fmissed . The connectivity of o to its class Cl(o ) gives an idea of how severe it is if an algorithm excludes o from a cluster mapped to Cl(o ) . More precisely , if o is hardly connected to Cl(o ) then the exclusion of o is not as severe as an exclusion of a highly connected object . This is expressed by the first term in the penalty definition . The second term equals to 1 according to Def . 7 , ie fi o ∈ Fmissed ⇒ pen(o , C∅ ) = con(o , Cl(o ) ) · ( 1 − con(o,∅ ) ) ff
)
=1
871 If a noise object onoise is assigned to a cluster Ci , this noise inclusion is considered a fault , and the corresponding set is called Fnoise . We want to penalize noise inclusion according to the connection between onoise and map(Ci ) , ie if con(onoise , map(Ci ) ) has a high value then we want to assign a low error and vice versa . This is expressed by the second term in the penalty definition , the first term is close to 1 due the random distribution of noise , ie o ∈ Fnoise ⇒ pen(o , Ci ) = con(o , Clnoise )
·(1 − con(o , map(Ci) ) )
) ff
≈1 for noise fi
For a misplacement error assume an object o from class Cl(o ) is assigned to cluster Ci and Ci is mapped to another class , ie map(Ci ) = Cl(o ) . Misplaced objects are summarized in Fmisplaced . In this case we want to consider both the connection of o to its true class Cl(o ) and its connection to the wrongly assigned class map(Ci ) . More precisely , a high value for con(o , Cl(o ) ) yields a high error and a low value for con(o , map(Ci ) ) yields a high error as well . The penalty in CMM combines both aspects by multiplication .
A better understanding of clusterings and their evaluation can be achieved by constraining CMM ( cf . Def . 12 ) to one of the subsets Fmissed , Fnoise , orF misplaced ( cf . Sec 6 ) . 5.2 Model error and concept detection
If one wants to evaluate the goodness of a given clustering algorithm , the corresponding approach , ie its underlying clustering model , is of importance . For example , given the data sets from Fig 2 or 3 , a spherical clustering algorithm can never reach a perfect result , since even the ground truth clusters contain objects from different classes yielding misplacement errors . How meaningful is a measure that tells you an algorithm has 70 % performance if you don’t know whether it ’s model even allows it to perform better ?
CMM shall measure how well an algorithm solved the clustering task with respect to its approach . To this end it is checked for each object , whether it causes an error in the corresponding ground truth clusters Cl◦ j ( cf . Def . 5 ) . If an error occurs also in the ground truth , it is called an error by model and the object is added to the set Fmodel . These errors by model are then excluded in the CMM computation . This way the ground truth always yields a perfect result and so can an algorithm .
Any stream clustering algorithm has to adhere to memory constraints for its internal representation , ie the total number of clusters or micro clusters is limited . Due to aging of objects , drifting clusters , and newly emerging clusters the algorithm constantly has to update its representation and decide on the position and size of its clusters . It is more important to reflect the main concepts of the current data distribution rather than spending limited resources to represent some concepts very detailed and missing other concepts in exchange . In other words , for two given clusterings with equally many missed objects , the one that better covers the concepts is preferable ( cf . Fig 4 ) . To operationalize this aspect we decrease the penalty for missed points with respect to the severity of the fault . Formally , we redefine the overall penalty for this fault type . For an object o ∈ Fmissed we test for all clusters Ci with map(Ci ) = Cl(o ) the relative dis
Figure 4 : The concept is better recognized on the left .
fi'ff ('.ff tance of o to the cluster boundary of Ci , ie o ∈ Fmissed ⇒ − minDist(o,Ci ) maxDist(o,Ci ) } pen(o,C ) = con(o , Cl(o ) ) ·
{1 − e max Ci∈C map(Ci)=Cl(o )
The second term simplifies to 1 − e− d−r d+r for spherical clusters , where d is the distance of o to Ci ’s center and r its radius . 5.3 Structure analysis
To analyze the structure of a given data set , we define the connectivity between two classes , which is based on the same concept as Def . 7 . Intuitively , the connection from class Cli to class Clj is high , if several points that have a strong connection within Cli show a strong connection to Clj at the same time . The definition below uses the same locality parameter k as Def . 6 .
Definition 13 . Class connectivity . For a locality pa rameter k the connectivity from class Cli to class Clj is con(p , Cli ) · con(p , Clj ) ffi
. fl fi
1 k p∈KM conCli→Clj = max KM⊆Cli |KM|=k
The symmetric connectivity between two classes is then con(Cli , Clj ) = min{conCli→Clj , conClj→Cli}
The above definition considers the k points within Cli that maximize the product of connectivity to both classes . The blue objects in Fig 2 illustrate the connectivity between the two classes gray and black . In both cases the two classes are not strongly connected .
If two ground truth classes have a strong connectivity , the two classes are difficult to separate from each other . To avoid misplacement penalties between such classes , we merge classes who ’s connectivity according to Def . 13 exceeds a threshold τ and assign their points the same label . Analyzing the structure of a given ground truth CL = {Cl1 , . . . , Cll} hence yields a reduced set of classes CL = h} with h ≤ l . As an indicator of how well the {Cl classes in a given ground truth CL+ are separable we define : Separability(CL+
1 , . . . , Cl
) = h/l
In Fig 5 we demonstrate for different horizons how the
Separability is influenced by different τ values .
Figure 5 : Evaluation of different τ values . y t i l i b a r a p e S
1
0.8
0.6
0.4
0.2
0 horizonfi[points ] fi100 fi4,000 fi1,000 fi10,000
0
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
Thresholdfi(cid:655 )
For the structure analysis in the experiments in Sec 6 , we use τ = 05 To complete the structure analysis we define a second indicator , counting the percentage of objects represented redundantly , ie covered by several ground truth clusters Cl◦ i : Red(CL+ j ∧ i = j}|/|O+| ) =|{o ∈ O+|o ∈ Cl◦ This indicator allows for a more in depth analysis of the different measures’ behavior in the empirical evaluation . i ∧ o ∈ Cl◦
872 1
0.8
0.6
0.4
0.2
Purityfi(Median ) Purity CMfifififififififififififififififififififififififififififififififififififififififififiCfi(Median ) VarInformation
VarInformationfi(Median )
0 5,000
255,000
505,000 positionfiinfiForestfiCoverfiTypefistreamfi[points ] ( a ) CluStream clustering
1
0.8
0.6
0.4
0.2
0 fi100
CMM Separability Redundancy fi250
1(cid:882)SilhCoeff 1(cid:882)CfiIndex SSQ
1
0.8
0.6
0.4
0.2 fi500 fi1,000 horizonfi[points ] fi5,000 fi10,000
0 fi100 fi250 fi1,000 fi5,000 fi10,000 fi500 horizonfi[points ]
0 0 0 3
0 0 0 2
0 0 0 1
0
Q S S
Norm.fiRand F(cid:882)Measure vanfiDongen
Purity V(cid:882)Measure VarInformation
1
0.8
0.6
0.4
0.2
0 fi100 fi250 fi500 fi1,000 horizonfi[points ] fi5,000 fi10,000
( b ) CMM & structure analysis
( c ) internal measures
( d ) external measures
Figure 6 : 10 dim . Forest Cover Type stream : ( a ) : Illustration of the individual evaluations for a real stream clustering and the resulting medians . ( b d ) : Varying horizon on ground truth clusterings .
6 . EXPERIMENTS
We evaluate CMM in comparison to evaluation measures introduced in Sec 2 . For repeatability , we integrated CMM into MOA ( cf . Sec 7 ) . First of all , we describe our evaluation framework .
Stream generator . The generator ’s output is a stream of data points that have class labels and weights reflecting a point ’s age , depending on the used horizon . Since clusters move , a larger horizon yields more tail like clusters ; a small horizon yields more sphere like clusters . Technically , the data points are obtained by generating clusters , which have a center and a maximal radius and which move through a unit cube ( [0 , 1 ] ) into a random direction . At the cube boundaries , the clusters bounce off . At specific intervals all cluster centers are shifted by 0.01 in their corresponding direction and points are equally drawn from each generating cluster . On average , the number of points in each cluster is equal . Our stream generator has the following parameters : the number of clusters moving through the dataspace , the number of generated points , the shift interval , the cluster radius , the dimensionality , and the noise degree . d
Real world data streams . We use the 10 continuous , consisting of 581,012 obattributes of Forest Cover Type jects and 7 classes , and we use the 34 continuous attributes , consisting of 4,898,431 objects and 5 of Network Intrusion classes . This variant was also used in [ 1 , 8 ] .
1
2
Cluster generator . We evaluate measures in specific clustering error scenarios , which are obtained by generating clusterings out of the synthetic stream that reflect a desired error level . We create cluster join , radius decrease , and cluster remove errors and the cluster boundaries are determined by a technique from [ 13 ] . The cluster join error simulates that two classes are covered by a single cluster by joining pairs of nearby , non overlapping clusters ; eg , an error level of 0.4 indicates that all pairwise clusters are joint whose minimal boundary distance is below 40 % of the minimum of their cluster radii . By this , we achieve a more realistic scenario without joining of far apart clusters . The radius decrease error states that the generated clusters have a radius that is smaller than the radius of the corresponding ground truth cluster . An error level of 1 states that the radius of the error cluster is 0 ; for an error level of 0 the two radii are equal . The cluster remove error denotes how many clusters are missed by a clustering ; for an error level of 0.4 , 40 % of the clusters are removed from the error free clustering .
Setup . We compare CMM and its variants ( cf . Sec 5.1 ) with internal and external measures from the literature ( cf . Sec 2 ) . In selected experiments , we provide the structural
1
2 http://archiveicsuciedu/ml/datasets/Covertype http://kddicsuciedu/databases/kddcup99/kddcup99html measures Separability and Redundancy ( cf . Sec 53 ) All measures , besides the Sum of Squared distances ( SSQ ) , are normalized to [ 0 , 1 ] . For some measures the best value corresponds to 0 ; we reverse them and indicate this by ” 1 ” in the plots . The values of SSQ are plotted on a secondary yaxis . By using clusterings from the cluster generator , we ensure an evaluation unbiased by possible incorrect outcomes of stream clustering algorithms . Moreover , we evaluate real clusterings of CluStream [ 1 ] and DenStream [ 8 ] using CMM . The CMM parameter k was preliminary fixed to 2 ; the choice of k only has marginal influence on CMM effectiveness , as we will later illustrate . Synthetic data is generated with the following settings : the dimensionality is 2 , the number of points is 200 , 000 , the cluster number is 6 , the cluster radius is 0.075 , the shift interval is 100 points , and noise is equally distributed and fixed at 10 % . The horizon is defined by the number of included points , ie h = |H| , and the evaluation frequency is the horizon . The values in all plots are the medians over all evaluations of the analyzed stream , as illustrated in Fig 6(a ) for three measures on CluStream clusterings of Forest Cover Type .
Varying horizon on real data . Fig 6 shows experiments where we analyze the robustness of the measures under a varying horizon . We use error free Forest Cover Type clusterings , ie the ground truth . By a varying horizon this ground truth changes ; with greater horizons the cluster tails become longer , increasing the probability of overlapping clusters . This is confirmed by the two structural measures in Fig 6(b ) : Redundancy rises while Separability ( of clusters ) drops . The comparison of CMM with the competing measures shows a clear picture : CMM ( in Fig 6(b ) ) achieves perfect quality that is stable over all settings . In contrast , both internal ( Fig 6(c ) ) and external measures ( Fig 6(d ) ) degrade with increasing horizons , showing that they cannot cope with higher redundancy and the worsened separability that occurs with larger horizons . More surprisingly , however , is that they also deliver low qualities for small horizons , indicating their general inability to express that the analyzed clusterings are error free .
Error level . We analyze how good the measures can reflect the errors in generated clusterings .
We start with the internal measures in Fig 7 , where each graph corresponds to one error type . Comparing an external measure like CMM with internal measures is inherently unfair ; however , since internal measures are often used in practice , we think a general overview of their performance in error scenarios is of interest . From the three plots , we can conclude the following : The C Index shows nearly no reaction ; only extreme cases ( error → 1 ) for radius decrease and cluster remove errors are indicated through quality drops . The Silhouette Coefficient reflects the cluster join error , but can
873 1
0.8
0.6
0.4
0.2
0
CM 1(cid:882)SilhCoeff 1(cid:882)CfiIndex SSQ
80
60
40
Q S S
20
0
1
0.8
0.6
0.4
0.2
0
CM 1(cid:882)SilhCoeff 1(cid:882)CfiIndex SSQ
0
0.2
0.4
0.6
0.8
1
0 clusterfijoinfi[errorfilevel ]
0.2 clusterfiradiusfidecreasefi[errorfilevel ]
0.4
0.8
0.6
80
60
40
Q S S
20
0
1
1
0.8
0.6
0.4
0.2
0
0
CM 1(cid:882)SilhCoeff 1(cid:882)CfiIndex SSQ
0 0 0 0 1
Q S S
0 0 1
1
0.8
0.6
0.4
0.2
0.2
0.4
0.8 clusterfiremovefi[errorfilevel ]
0.6
1
1
0 fi100
( a ) Cluster Join Error
( b ) Radius Decrease Error
( c ) Cluster Remove Error
Separability
Redundancy
1
0.8
0.6
0.4
0.2
Network Intrusion
ForestfiCoverfiType
0 fi100 fi500 fi5,000 horizonfi[points ] horizonfi[points ] ( d ) Structure analysis fi500 fi5,000
Figure 7 : ( a c ) : CMM & internal measures under different error types with h = 5 , 000 ; ( d ) : Structure analysis . not reflect the other errors , where the corresponding values even rise . The SSQ , which is used in many stream clustering publications [ 1 , 9 ] , shows a good reaction on the cluster join and the cluster remove error ; however , if we look at the corresponding maximal values ( 60 and 10,000 ) a practical use is questionable due to its unnormalized nature . CMM shows a very good performance on all scenarios , and a deeper analysis will be included in the next paragraph .
In Fig 9 we compare CMM with the external measures using horizons of 5,000 and 10,000 . We start with cluster join errors . Note that due to the technique used for creating this error ( only nearby clusters are joined ) , the error level 1 does not indicate that all clusters are joined into a single cluster . Fig 9(a ) and 9(b ) show that CMM reflects this error well , ie with an increasing number of joined clusters the quality constantly drops . We expect this to be caused by misplaced points , ie points that are assigned to wrong clusters , which is confirmed by CMMmisplaced . CMMnoise illustrates that when clusters are joined the resulting clusters tend to absorb noise points due to their larger sizes . The external measures in Fig 9(c ) also reflect the errors . However , a general problem of these measures are error free settings ( error=0 ) in which they show lower qualities ( 08 06 ) We suspect this to be caused by cluster overlap and it worsens with a larger horizon , as illustrated in Fig 9(d ) . Considering that these measures are normalized to [ 0 , 1 ] , this is a severe problem . In contrast , CMM shows maximal quality in error free settings for both horizons and this also holds for the other error types in Fig 9 . The cluster radius decrease error is analyzed for CMM in Fig 9(e ) and 9(f ) . This error mostly results in missed points , which is shown by CMMmissed and thus by CMM . Here we also demonstrate the influence of the CMM refinement that better measures how well the main concepts of the data are reflected by a clustering ( cf . Sec 52 ) The figure shows that at lower error levels , CMM does not decrease as rapidly as the variants without refinement ( green lines ) . This is intended , since the main concepts of the data are well represented at this stage and only close points are missed . From the six measures in Fig 9(g ) , four can basically reflect the error ; however , for lower error levels ( ≤ 0.4 ) three of the measures go up and the negative effects of larger horizons on all competing measures are again obvious in Fig 9(h ) . Especially the bad performance of Purity is mentionable , a measure which is the main evaluation method in many stream clustering publications [ 8 , 19 ] . The cluster remove error is analyzed in Fig 9(i) 9(l ) . This error corresponds to removal of complete clusters and thus concepts ; accordingly and in contrast to the radius decrease error this loss of concepts should be reflected by a constant decrease of the measured quality . This is achieved by CMM . A comparison to its variant without refinement shows that for this error type the refinement has no undesired effects ; this refinement only affects the measurement of radius decrease errors . The external measures show a similar behavior as for the radius decrease error : only three reflect the error at all and their expressiveness strongly decreases for larger horizons .
Summarized , CMM can precisely reflect all errors . Most of the internal measures cannot reflect the errors at all , while some of the external measures reflect the errors but have serious problems in settings without errors or larger horizons . CMM locality parameter k . In Fig 8 we analyze the influence of k ( cf . Sec 41 ) We simulate a more realistic evaluation scenario by using synthetic clusterings with embedded errors ( error level=05 ) For each error type , we tried 10 different ks ( k ∈ {1 , , 10} ) with 4 different horizons . On the left we plot the standard deviation of the CMM results wrt the choice of k : CMM values for two of the error types are influenced by k for very small horizons ; however , considering the value range of the CMM and the small standard deviations ( < 0.009 ) , these effects are negligible . This is also illustrated on the right , where we plot the exact CMM values with a horizon of 10 , 000 for the individual ks on the range [ 0.8 , 098 ] Both figures show that k has only marginal influence for very small horizons and does not affect CMM for larger horizons . clusterfijoin clusterfiremove clusterfiradiusfidecrease
0.009 k fi fi . t . r . fi w M M C fi f o V D T S fi
0.006
0.003
0
100
M M C
0.98
0.92
0.86
0.8 horizon=10,000
500 1,000 horizonfi[points ]
10,000
1
3
7
9
5 k
Figure 8 : Marginal effects ( std . deviation < 0.009 ) of varying k .
Real data and stream clustering algorithms . Finally , we analyze the measures in real application scenarios , in which real world data streams are clustered by actual stream clustering algorithms , as in this case CluStream [ 1 ] and DenStream [ 8 ] . In Fig 10 , we distinguish between macro clusterings , ie the output of the algorithms , and micro clusterings , ie the underlying internal representations constantly adapted by the algorithms . The macro clusterings are produced from the micro clusterings by an offline component . Comparability is ensured by using CluStream ’s offline component in CluStream and DenStream . We apply an horizon of 1,000 . A structure analysis of the real world streams is shown in Fig 7(d ) : Forest Cover Type has high redundancy and low separability ; Network Intrusion has no redundancy and high separability , making the clusters easier to find .
We start with Network Intrusion . The results obtained by DenStream for the macro clustering in Fig 10(a ) confirm
874 1
0.8
0.6
0.4
0.2
0
Norm.fiRand Purity F(cid:882)Measure V(cid:882)Measure vanfiDongen VarInformation
1
0.8
0.6
0.4
0.2
0
Norm.fiRand Purity F(cid:882)Measure V(cid:882)Measure vanfiDongen VarInformation
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1 clusterfijoinfi[errorfilevel ] clusterfijoinfi[errorfilevel ]
( c ) ext . measures ; h = 5 , 000 1
( d ) ext . measures ; h = 10 , 000
1
0.8
0.6
0.4
0.2
0
Norm.fiRand Purity F(cid:882)Measure V(cid:882)Measure vanfiDongen VarInformation
CM CMfiMisplaced CMfiNoise
0
0.2
0.4
0.6
0.8
1 clusterfijoinfi[errorfilevel ]
( b ) CMM ; h = 10 , 000
CM CMfiMisse(cid:282 ) CMfiw/ofiRe(cid:296)(cid:349)n . CMfiMiss(cid:286)(cid:282)fiw/ofiRef(cid:349)n .
0.2 0.8 clusterfiradiusfidecreasefi[errorfilevel ]
0.4
0.6
0.8
0.6
0.4
0.2
0
0
1
Norm.fiRand Purity F(cid:882)Measure V(cid:882)Measure vanfiDongen VarInformation
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
1
0.8
0.6
0.4
0.2
0
CM CMfiMisplaced CMfiNoise
0
0.2
0.4
0.6
0.8
1 clusterfijoinfi[errorfilevel ]
( a ) CMM ; h = 5 , 000
C CMfiMiss(cid:286)(cid:282 ) CMfiw/ofiRe(cid:296)(cid:349)n . CMfiMiss(cid:286)(cid:282)fiw/ofiRef(cid:349)n .
0
0.6
0.4
0.2 0.8 clusterfiradiusfidecreasefi[errorfilevel ] ( e ) CMM ; h = 5 , 000
CM CMfiMissed CMfiw/ofiRefin . CMfiMissedfiw/oRefin .
1
0
1
0.8
0.6
0.4
0.2
0
( f ) CMM ; h = 10 , 000
( g ) ext . measures ; h = 5 , 000 1
( h ) ext . measures ; h = 10 , 000 1
0.2 0.8 clusterfiradiusfidecreasefi[errorfilevel ]
0.4
0.6
1
0
0.2 0.8 clusterfiradiusfidecreasefi[errorfilevel ]
0.4
0.6
1
C CMfiMissed CMfiw/ofiRefin . CMfiMissedfiw/ofiRefin .
0.8
0.6
0.4
0.2
0
Norm.fiRand Purity F(cid:882)Measure V(cid:882)Measure vanfiDongen VarInformation
0.8
0.6
0.4
0.2
0
Norm.fiRand Purity F(cid:882)Measure V(cid:882)Measure vanfiDongen VarInformation
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1 clusterfiremovefi[errorfilevel ] clusterfiremovefi[errorfilevel ]
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1 clusterfiremovefi[errorfilevel]fi clusterfiremovefi[errorfilevel ]
( i ) CMM ; h = 5 , 000
( j ) CMM ; h = 10 , 000
( k ) ext . measures ; h = 5 , 000
( l ) ext . measures ; h = 10 , 000
Figure 9 : Evaluating CMM and external measures under different error types .
1 0.8 0.6 0.4 0.2 0
M M C d e s s i
M
CluStream
DenStream e s i o N d e c a p s i l
M f f e o C h l i
S ( cid:882 ) 1 x e d n
I fi
C ( cid:882 ) 1 e r u s a e M ( cid:882 ) V e r u s a e M ( cid:882 ) F d n a R fi . m r o N
1 0.8 0.6 0.4 0.2 0
M M C d e s s i
M y t i r u P n e g n o D n a v fi n o i t a m r o f n I r a V
CluStream
DenStream e s i o N d e c a p s i l
M f f e o C h l i
S ( cid:882 ) 1 x e d n
I fi
C ( cid:882 ) 1 e r u s a e M ( cid:882 ) V e r u s a e M ( cid:882 ) F d n a R fi . m r o N
1 0.8 0.6 0.4 0.2 0
M M C d e s s i
M y t i r u P n e g n o D n a v fi n o i t a m r o f n I r a V
CluStream
DenStream e s i o N d e c a p s i l
M f f e o C h l i
S ( cid:882 ) 1 x e d n
I fi
C ( cid:882 ) 1 e r u s a e M ( cid:882 ) V e r u s a e M ( cid:882 ) F d n a R fi . m r o N
1 0.8 0.6 0.4 0.2 0
M M C d e s s i
M y t i r u P n e g n o D n a v fi n o i t a m r o f n I r a V
CluStream
DenStream e s i o N d e c a p s i l
M f f e o C h l i
S ( cid:882 ) 1 x e d n
I fi
C ( cid:882 ) 1 e r u s a e M ( cid:882 ) V e r u s a e M ( cid:882 ) F d n a R fi . m r o N y t i r u P n e g n o D n a v fi n o i t a m r o f n I r a V
CMM internal external
CMM internal external
CMM internal external
CMM internal external
( a ) Macro clusterings of Network Intrusion data .
( b ) Macro clusterings of Forest Cover Type data .
( c ) Micro clusterings of Network Intrusion data .
( d ) Micro clusterings of Forest Cover Type data .
Figure 10 : Evaluation of CluStream and DenStream on real world data streams . the conclusions from the structural analysis : nearly all evaluation measures indicate that high quality clusterings are generated . For CluStream , however , we can make a surprising conclusion . CMM and most of the other measures indicate that the found clusterings are of low quality . This is mostly caused by missed points , as CMMM issed shows . In contrast , the evaluation of micro clusterings used by CluStream in Fig 10(c ) shows another picture : the micro clusterings are of high quality . We can conclude that CluStream correctly identifies the concepts in the data , but the used offline method that generates the macro clusters from the micro clusters is ineffective for this data type .
For Forest Cover Type in Fig 10(b ) and 10(d ) , we can conclude by CMMM issed that DenStream covers nearly all of the concepts in the macro clusterings . CluStream , however , seems to miss more concepts of the data . For this dataset , the macro clusterings of both CluStream and DenStream are of higher quality than the micro clusterings .
Summarized , CMM is an effective measure for evaluation on real data streams and clusterings generated by stream clustering algorithms , and its variants help in understanding why an analyzed clustering is of a specific quality .
7 . CONCLUSION
Evaluation of clustering results on static data sets received a lot of research attention for several decades . Many recent publications deal with the important task of clustering on evolving data streams . However , despite the amount of work on evaluation measures and on stream clustering algorithms , no effort has been made to meet the requirements of both tasks . In this paper we proposed a novel and effective evaluation measure for clustering on evolving data streams called CMM . It is the first measure that takes the important properties of the streaming context into account . It is based on a novel mapping component that can handle emerging and disappearing clusters correctly . We included CMM into the open source MOA framework [ 29 ] and showed in extensive experiments on real and synthetic data that it is a robust measure precisely reflecting errors in data stream scenarios .
Acknowledgments . This work has been supported by the UMIC Research Centre , RWTH Aachen University , Germany . Special thanks go to Marc Wichterich for his valuable comments and thorough reviewing of the paper .
875 8 . REFERENCES [ 1 ] C . C . Aggarwal , J . Han , J . Wang , and P . S . Yu . A framework for clustering evolving data streams . In VLDB , pages 81–92 , 2003 .
[ 2 ] F . B . Baker and L . J . Hubert . Measuring the power of hierarchical cluster analysis . Journal of the American Statistical Association ( JASA ) , 70(349):31–38 , 1975 . [ 3 ] D . Barbar´a and P . Chen . Using the fractal dimension to cluster datasets . In ACM SIGKDD , pages 260–264 , 2000 .
[ 4 ] A . Bifet , G . Holmes , B . Pfahringer , R . Kirkby , and
R . Gavald`a . New ensemble methods for evolving data streams . In ACM SIGKDD , pages 139–148 , 2009 .
[ 5 ] A . Bifet , G . Holmes , B . Pfahringer , P . Kranen ,
H . Kremer , T . Jansen , and T . Seidl . MOA : Massive online analysis , a framework for stream classification and clustering . In JMLR , 2010 .
[ 6 ] M . Bouguessa , S . Wang , and H . Sun . An objective approach to cluster validation . Pattern Recognition Letters , 27(13):1419–1430 , 2006 .
[ 7 ] M . Brun , C . Sima , J . Hua , J . Lowey , B . Carroll ,
E . Suh , and E . R . Dougherty . Model based evaluation of clustering validation measures . Pattern Recognition , 40(3):807–824 , 2007 .
[ 8 ] F . Cao , M . Ester , W . Qian , and A . Zhou .
Density based clustering over an evolving data stream with noise . In SIAM SDM , pages 328–339 , 2006 . [ 9 ] Y . Chen and L . Tu . Density based clustering for real time stream data . In ACM SIGKDD , pages 133–142 , 2007 .
[ 10 ] T . Cover and J . Thomas . Elements of Information
Theory ( 2nd Edition ) . Wiley Interscience , 2006 .
[ 11 ] J . Dunn . Well separated clusters and optimal fuzzy partitions . Journal of Cybernetics , 4:95–104 , 1974 .
[ 12 ] E . Folkes and C . Mallows . A method for comparing two hierarchical clusterings . JASA , 78:553–569 , 1983 . [ 13 ] B . Gartner . Fast and robust smallest enclosing balls .
In ESA , pages 325–338 . Springer , 1999 .
[ 14 ] M . Halkidi and M . Vazirgiannis . A density based cluster validity approach using multi representatives . Pattern Recognition Letters , 29(6):773–786 , 2008 .
[ 15 ] J . Han and M . Kamber . Data Mining : Concepts and
Techniques . Morgan Kaufmann , 2001 .
[ 16 ] J . A . Hartigan . Clustering Algorithms . Wiley , 1975 . [ 17 ] L . Hubert and P . Arabie . Comparing partitions .
Journal of Classification , 2:193–218 , 1985 .
[ 18 ] L . J . Hubert and J . R . Levin . A general statistical framework for assessing categorical clustering in free recall . Psychological Bulletin , 83(6):1072–1080 , 1976 .
[ 19 ] A . Jain , Z . Zhang , and E . Y . Chang . Adaptive non linear clustering in data streams . In ACM CIKM , pages 122–131 , 2006 .
[ 20 ] A . K . Jain and R . C . Dubes . Algorithms for Clustering
Data . Prentice Hall , 1988 .
[ 21 ] A . K . Jain , M . N . Murty , and P . J . Flynn . Data clustering : A review . ACM CS , 31(3):264–323 , 1999 . [ 22 ] L . Kaufmann and P . Rousseeuw . Finding Groups in
Data : an Introduct . to Cluster Analysis . Wiley , 1990 . [ 23 ] P . Kranen , I . Assent , C . Baldauf , and T . Seidl . Selfadaptive anytime stream clustering . In IEEE ICDM , pages 249–258 , 2009 .
[ 24 ] P . Kranen , H . Kremer , T . Jansen , T . Seidl , A . Bifet ,
G . Holmes , and B . Pfahringer . Clustering performance on evolving data streams : Assessing algorithms and evaluation measures within MOA . In IEEE ICDMW , pages 1400–1403 , 2010 .
[ 25 ] Y . Liu , Z . Li , H . Xiong , X . Gao , and J . Wu .
Understanding of internal clustering validation measures . In IEEE ICDM , pages 911–916 , 2010 .
[ 26 ] M . Meila . Comparing clusterings : an axiomatic view .
In ICML , pages 577–584 , 2005 .
[ 27 ] G . W . Milligan . An examination of the effect of six types of error perturbation on fifteen clustering algorithms . Psychometrika , 45(3):325–342 , 1980 .
[ 28 ] G . W . Milligan . A monte carlo study of thirty internal criterion measures for cluster analysis . Psychometrika , 46(2):187–199 , 1981 .
[ 29 ] MOA project . http://moacswaikatoacnz [ 30 ] S . G . Mojaveri , E . Mirzaeian , Z . Bornaee , and
S . Ayat . New approach in data stream association rule mining based on graph structure . In IEEE ICDM , pages 158–164 , 2010 .
[ 31 ] L . O’Callaghan , A . Meyerson , R . Motwani , N . Mishra , and S . Guha . Streaming data algorithms for high quality clustering . In ICDE , pages 685–694 , 2002 .
[ 32 ] W . Rand . Objective criteria for the evaluation of clustering methods . JASA , 66:846–850 , 1971 .
[ 33 ] C . Rijsbergen . Information Retrieval ( 2nd Edition ) .
Butterworths , London , 1979 .
[ 34 ] F . J . Rohlf . Methods for comparing classifications .
Annual Review of Ecology and Sys . , 5:101–113 , 1974 .
[ 35 ] A . Rosenberg and J . Hirschberg . V measure : A conditional entropy based external cluster evaluation measure . In EMNLP CoNLL , pages 410–420 , 2007 .
[ 36 ] V . Roth , M . L . Braun , T . Lange , and J . M . Buhmann .
Stability based model order selection in clustering with applications to gene expression data . In ICANN , pages 633–640 . Springer , 2002 .
[ 37 ] S . Saitta , B . Raphael , and I . F . C . Smith . A comprehensive validity index for clustering . Intell . Data Anal . ( IDA ) , 12(6):529–548 , 2008 .
[ 38 ] M . J . Song and L . Zhang . Comparison of cluster representations from partial second to full fourth order cross moments for data stream clustering . In IEEE ICDM , pages 560–569 , 2008 .
[ 39 ] S . Van Dongen . Performance criteria for graph clustering and markov cluster experiments . Report Information systems , ( 12):1–36 , 2000 .
[ 40 ] L . Wang , U . T . V . Nguyen , J . C . Bezdek , C . Leckie , and K . Ramamohanarao . iVAT and aVAT : Enhanced visual analysis for cluster tendency assessment . In PAKDD ( 1 ) , pages 16–27 . Springer , 2010 .
[ 41 ] J . Wu , H . Xiong , and J . Chen . Adapting the right measures for k means clustering . In ACM SIGKDD , pages 877–886 , 2009 .
[ 42 ] K . Y . Yeung , D . R . Haynor , and W . L . Ruzzo . Validating clustering for gene expression data . Bioinformatics , 17(4):309–318 , 2001 .
[ 43 ] Y . Zhao and G . Karypis . Empirical and theoretical comparisons of selected criterion functions for document clustering . ML , 55(3):311–331 , 2004 .
876
