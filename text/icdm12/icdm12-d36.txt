2012 IEEE 12th International Conference on Data Mining 2012 IEEE 12th International Conference on Data Mining
Inferring the Underlying Structure of Information Cascades
Bo Zong , Yinghui Wu , Ambuj K . Singh , and Xifeng Yan
University of California at Santa Barbara {bzong , yinghui , ambuj , xyan}@csucsbedu
Abstract—In social networks , information and influence diffuse among users as cascades . While the importance of studying cascades has been recognized in various applications , it is difficult to observe the complete structure of cascades in practice . In this paper we study the cascade inference problem following the independent cascade model , and provide a full treatment from complexity to algorithms : ( a ) We propose the idea of consistent trees as the inferred structures for cascades ; these trees connect source nodes and observed nodes with paths satisfying the constraints from the observed temporal information . ( b ) We introduce metrics to measure the likelihood of consistent trees as inferred cascades , as well as several optimization problems for finding them . ( c ) We show that the decision problems for consistent trees are in general NPcomplete , and that the optimization problems are hard to approximate . ( d ) We provide approximation algorithms with performance guarantees on the quality of the inferred cascades , as well as heuristics . We experimentally verify the efficiency and effectiveness of our inference algorithms , using real and synthetic data .
Keywords information diffusion ; cascade prediction .
I . INTRODUCTION
In various real life networks , users frequently exchange information and influence each other . The information ( eg , messages , articles , recommendation links ) is typically created by a user and spreads via links among users , leaving a trace of its propagation . Such traces are typically represented as trees , namely , information cascades , where ( a ) each node in a cascade is associated with the time step at which it receives the information , and ( b ) an edge from a node to another indicates that a user propagates the information to and influences its neighbor [ 3 ] , [ 10 ] , [ 15 ] .
A comprehensive understanding and analysis of cascades benefits various emerging applications in social networks [ 5 ] , [ 11 ] , viral marketing [ 1 ] , [ 18 ] , and recommendation networks [ 16 ] . In order to model the propagation of information , various cascade models have been developed [ 8 ] , [ 22 ] , [ 24 ] . Among the most widely used models is the independent cascade model [ 11 ] , where each node has only one chance to influence its inactive neighbors , and each node is influenced by at most one of its neighbors independently . Nevertheless , it is typically difficult to observe entire cascades in practice , due to the noisy graphs with missing data , or data privacy policies [ 20 ] . This calls for techniques that can infer the cascades using partial information . Although cascade models and a set of related problems , eg , influence maximization , have been widely studied , much less is known on how to infer the cascade structures based on partial information , including complexity bounds and approximation algorithms .
In this paper we investigate the cascade inference problem , where cascades follow the widely used independent cascade model . The paper is organized as follows . In Section II , we introduce the notions of ( perfect and bounded ) consistent trees to capture the missing structures of partial cascades , as well as a measure for their quality . We investigate the problems of identifying perfect and bounded consistent trees , given partial observations , in Section III and Section IV , respectively . We show that these problems are all NP complete , and hard to approximate . Nevertheless , we provide heuristics for these problems . We experimentally verify the effectiveness and efficiency of our inference algorithms in Section V .
Related work . There has been recent work on cascade prediction and inference , with the emphasis on global properties ( eg , cascade nodes , width , size ) [ 4 ] , [ 7 ] , [ 9 ] , [ 14 ] , [ 20 ] , [ 22 ] , [ 24 ] . All the above works focus on predicting the nodes and their behavior in cascades . In contrast , we propose approaches to infer both the nodes and the topology of the cascades in the graph time domain . Closer to our work is the work by Sadikov et al . [ 20 ] that considers cascade prediction on k trees . In contrast , we model cascades as general trees , and infer the nodes as well as topology of the cascades only from a set of nodes and their activation time , using much less available information . In addition , the temporal information in the partial observations is not considered in [ 20 ] . More related work is discussed in [ 26 ] .
II . CONSISTENT TREES
We start by introducing several notions .
Diffusion graph . We denote a social network as a directed graph G = ( V , E , f ) , where ( a ) V is a finite set of nodes , and each node u ∈ V denotes a user ; ( b ) E ⊆ V × V is a finite set of edges , where each edge ( u , v ) ∈ E denotes a social connection via which the information may diffuse from u to v ; and ( c ) a diffusion function f : E → R+ which assigns for each edge ( u , v ) ∈ E a value f ( u , v ) ∈ [ 0 , 1 ] , as the probability that node u influences v .
Cascades . We first cascade model [ 11 ] . We say a cascade unfolds over a graph G review the independent
1550 4786 2012 1550 4786 2012 US Government Work Not Protected by US Copyright US Government Work Not Protected by US Copyright DOI 101109/ICDM2012100 DOI 101109/ICDM2012100
1218 709 following the independent cascade model if ( a ) at any time step , each node in G is exactly one of the three states {active , newly active , inactive} ; ( b ) a cascade starts from a source node s being newly active at time step 0 ; ( c ) a newly active node u at time step t has only one chance to influence its inactive neighbors , such that at time t + 1 , ( i ) if v is an inactive neighbor of u , v becomes newly active with probability f ( u , v ) ; and ( ii ) the state of u changes from newly active to active , and cannot influence any neighbors afterwards ; and ( d ) each inactive node v can be influenced by at most one of its newly active neighbors independently , and the neighbors’ attempts are sequenced in an arbitrary order . Once a node is active , it cannot change its state .
Based on the independent cascade model , we define a cascade C over graph G = ( V , E , f ) as a directed tree ( Vc , Ec , s , T ) where ( a ) Vc ⊆ V , Ec ⊆ E ; ( b ) s ∈ Vc is the source node from which the information starts to propagate ; and ( c ) function T assigns for each node vi ∈ Vc a time step ti , which represents that vi is newly active at time step ti . Intuitively , a cascade is a tree representation of the “ trace ” of the information propagation from a source node s to a set of influenced nodes . Indeed , one may verify that any cascade from s following the model is a tree rooted at s .
Partial observation . Given a cascade C = ( Vc , Ec , s , T ) , a pair ( vi , ti ) is an observation point , if vi ∈ V is known ( observed ) to be newly active at or by time step ti . A partial observation X is a set of observation points . Specifically , X is a complete observation if for any v ∈ Vc , there is an observation point ( v , t ) ∈ X . To simplify the discussion , we also assume that pair ( s , 0 ) ∈ X where s is the source node . The techniques developed in this paper can be adapted to the case where the source node is unknown .
We are now ready to introduce the idea of consistent trees .
A . Consistent trees
, ETs
Given a partial observation X of a graph G = ( V , E , f ) , a bounded consistent tree Ts = ( VTs , s ) wrt X is a directed subtree of G with root s ∈ V , such that for every ( vi , ti ) ∈ X , vi ∈ VTs , and s reaches vi by ti hops , ie , there exists a path of length at most ti from s to vi . Specifically , we say a consistent tree is a perfect consistent tree if for every ( vi , ti ) ∈ X and vi ∈ VTs , there is a path of length exactly ti from s to vi .
Intuitively , consistent trees represent possible cascades which conform to the independent cascade model , as well as the partial observation . Note the following : ( a ) the path from the root s to a node vi in a bounded consistent tree Ts is not necessarily a shortest path from s to vi in G , as observed in [ 13 ] ; ( b ) perfect consistent trees model cascades when the partial observation is accurate , ie , each time ti in an observation point ( vi , ti ) is exactly the time when vi is newly active ; in contrast , in bounded consistent trees , an observation point ( vi , ti ) indicates that node vi is newly active at the time step ti information propagation , as observed in [ 5 ] .
. ≤ ti , due to possible delays during
B . Cascade inference problem
We now introduce the general cascade inference problem . Given a social graph G and a partial observation X , the cascade inference problem is to determine whether there exists a consistent tree T wrt X in G .
There may be multiple consistent trees for a partial observation , so one often wants to identify the best consistent tree . We next provide two quantitative metrics to measure the quality of the inferred cascades . Let G = ( V , E , f ) be a social graph , and X be a partial observation .
Minimum weighted consistent trees . In practice , one often wants to identify consistent trees that are close to the actual that each edge ( u , v ) ∈ E in a given cascades . Recall network G carries a value assigned by a diffusion function f ( u , v ) , which indicates the probability that u influences v . Based on f ( u , v ) , we introduce a likelihood function as a quantitative metric for consistent trees . Likelihood function . Given a graph G = ( V , E , f ) , a partial observation X and a consistent tree Ts = ( VTs , s ) , the , ETs likelihood of Ts , denoted as LX ( Ts ) , is defined as : f ( u , v ) .
LX ( Ts ) = P(X | Ts ) =
.
( 1 )
( u,v)∈ETs
Following common practice , we opt to use the log likelihood metric , where LX ( Ts ) = fi log f ( u , v )
( u,v)∈ETs
Given G and X , a natural problem is to find the consistent tree with maximum likelihood . Using log likelihood , the minimum weighted consistent tree problem is to identify the consistent tree Ts with the minimum −LX ( Ts ) .
Minimum consistent trees . In some cases , one may simply want to find the minimum structure that represents a cascade [ 17 ] . The minimum consistent tree , as a special case of the minimum weighted consistent tree , depicts the smallest cascades with the fewest communication steps to pass the information to all the observed nodes . In other words , this metric favors consistent trees with the fewest edges .
Given G and X , the minimum consistent tree problem is to find the minimum consistent trees in G wrt X .
In the following sections , we investigate the cascade inference problem , and their optimization problems .
III . CASCADES AS PERFECT TREES
As remarked earlier , when the partial observation X is accurate , one may want to infer the cascade structure via trees . The minimum ( resp . weighted ) perfect consistent perfect consistent tree problem , denoted as PCT min ( resp .
7101219
PCT w ) is to find the perfect consistent trees with minimum size ( resp . maximum log likelihood ) as the quality metric . w problems can be solved in polynomial time . Nevertheless , the following result shows that these problems are nontrivial .
It is desirable that the PCT min and PCT
Proposition 1 : Given a graph G and a partial observation X , ( a ) it is NP complete to determine whether there is a perfect consistent tree wrt X in G ; and ( b ) the PCT and PCT w problems are NP complete and APX hard . min
One may verify Proposition 1(a ) by a reduction from the Hamiltonian path problem [ 23 ] . We prove Proposition 1(b ) by constructing an approximation preserving reduction ( AFP reduction ) [ 23 ] from the minimum directed steiner tree ( MST ) problem to PCT min . The APX hard problems are APX problems to which every APX problem can be reduced [ 23 ] . A . Bottom up searching algorithm
Given the above intractability and approximation hardness result , we introduce a heuristic WPCT for PCT w problem . The idea is to ( a ) generate a “ backbone network ” Gb of G which contains all the nodes and edges that are possible to form a perfect consistent tree , using a set of pruning rules , and also rank the observed nodes in Gb with the descending order of their time step in X , and ( b ) perform a bottom up evaluation for each time step in Gb using a local optimal strategy , following the descending order of the time step .
Backbone network . We consider pruning strategies to reduce the nodes and the edges that are not possible to be in any perfect consistent trees , given a graph G = ( V , E , f ) and a partial observation X = {(v1 , t1 ) , . . . , ( vk , tk)} . We define a backbone network Gb = ( Vb , Eb ) , where
• Vb =
{vj|dist(s , vj ) + dist(vj , vi ) ≤ ti} for each
'
( vi , ti ) ∈ X ; and
• Eb = {(v . , v)|v . ∈ Vb , v ∈ Vb , ( v . , v ) ∈ E} Intuitively , Gb includes all the possible nodes and edges that may appear in a perfect consistent tree for a given partial observation . In order to construct Gb , a set of pruning rules can be developed as follows : for a node v . in G , if every observed node v in a cascade with time step t has dist(s , v . ) + dist(v . , v ) > t , then v . and all the edges connected to v . can be safely pruned .
Algorithm . Algorithm WPCT is as shown in Fig 1 . It starts by initializing a tree T ( line 1 ) , by inserting all the observation points into T . Each node v in T is assigned with a level l(v ) equal to its time step as in X . The edge set is set to empty . It then constructs a backbone network Gb with the pruning rules ( lines 2 9 ) . It initializes a node set Vb within tmax hop of the source node s , where tmax is the maximum time step in X ( line 2 ) . If there exists some node v ∈ X that is not in Vb , the algorithm returns ∅ , since there is no path from s reaching v with t steps for ( v , t ) ∈ X ( line 3 ) .
7111220
2 . 3 . 4 . 5 . 6 .
Input : graph G and partial observation X . Output : a perfect consistent tree T in G . 1 . tree T = ( VT , ET ) , where VT := {v|(v , t ) ∈ X} , set level l(v):= t for each ( v , t ) ∈ X , E := ∅ ; set Vb := {vb|dist(s , vb ) ≤ tmax} ; if there is a node v in X and v /∈ Vb then return ∅ ; set Eb := {(v . , v)|(v . , v ) ∈ E , v . ∈ Vb , v ∈ Vb)} ; for each v ∈ Vb do if there is no ( vi , ti ) ∈ X that dist(s , v)+dist(v , vi ) ≤ ti then Vb = Vb \ {v} ; Eb = Eb \ {(v1 , v2)} where v1 = v or v2 = v ;
7 . 8 . 9 . graph Gb := ( Vb , Eb ) ; 10 . list L := {(v1 , t1 ) , . . . , ( vk , tk)} where ti ≤ ti+1 , ( vi , ti ) ∈ X , i ∈ [ 1 , k − 1 ] ;
11 . for each i ∈ [ 1 , tmax ] following descending order do 12 . Vt:= V1 ∪ V2 ∪ V3 , V1 := {vi|(v , ti ) ∈ X} ;
V2 := {v|v ∈ VT , l(v ) = ti} ; V3 := {v|(v , v ) ∈ Eb , v ∈ V1 ∪ V2 , v . /∈ VT } ; construct Gt = ( Vt , Et ) ; T := T ∪ PCTl(Gt , V1 ∪ V2 , V3 , i ) ;
13 . Et := {(v . , v)|v . ∈ V3 , v ∈ V1 ∪ V2 , ( v . , v ) ∈ Eb} ; 14 . 15 . 16 . if T is a tree then return T ; 17 . return ∅ ;
Figure 1 : Algorithm WPCT : pruning and local searching
It further removes the redundant nodes and edges that are not in any perfect trees , using the pruning rules ( lines 58 ) . The network Gb is then constructed ( line 9 ) . The partial observation X is also sorted wrt the time step ( line 10 ) .
Following a bottom up greedy strategy , WPCT then processes each observation point ( lines 11 17 ) . For each i in [ 1 , tmax ] , it generates a ( bipartite ) graph Gt . ( a ) It initializes a node set Vt as the union of three sets of nodes V1 , V2 and V3 ( line 12 ) , where ( i ) V1 is the nodes in X with time step ti , ( ii ) V2 is the nodes v in the current perfect consistent tree T with level l(v ) = ti , and ( iii ) V3 is the set of possible parents for the nodes in V1 and V2 . ( b ) It constructs an edge set Et which consists of the edges from V3 to V1 and V2 . ( c ) It then generates Gt with Vt and the edge set Et , which is a bipartite graph . After Gt is constructed , the algorithm WPCT invokes l to compute a “ part ” of the perfect tree T , procedure PCT which is an optimal solution for Gt , a part of the graph Gb which contains all the observed nodes with time step ti . It expands T with the returned partial tree ( line 15 ) . The above process ( lines 11 15 ) repeats for each i ∈ [ 1 , tmax ] until all the nodes in X are processed . Algorithm WPCT then checks if the constructed T is a tree . If so , it returns T as a perfect tree ; otherwise , it returns ∅ ( line 17 ) . l . Given a ( bipartite ) graph Gt , and two sets Procedure PCT of nodes V and Vs in Gt , the procedure PCT l [ 26 ] computes for Gt a set of trees Tt = {T1 , . . . , TL} with the minimum total weight , where ( a ) each Ti is a 2 level tree with a root in Vs and leaves in V , ( b ) the leaves of any two trees in Tt are disjoint , and ( c ) the trees cover all the nodes in V . The weight of Ti consists of the edge weights , and the root weight which is estimated by the minimum cost path from the cascade root s to Ti ’s root . For each Ti , PCT l assigns its root r in Vs a level l(r ) = ti − 1 . Tt is then returned as a part of the entire perfect consistent tree . In practice , we may either employ linear programming , or an algorithm for MST problem ( eg , [ 19 ] ) to compute Tt .
Discussion . The algorithm WPCT either returns ∅ , or correctly computes a perfect consistent tree wrt the partial observation X . Indeed , one may verify that ( a ) the pruning rules only remove the nodes and edges that are not in any perfect consistent tree wrt X , and ( b ) WPCT has the loop invariant that at each iteration i ( lines 11 15 ) , it always constructs a part of a perfect tree as a forest . One may further verify that WPCT runs in time O(|V ||E|+|X|2+tmax∗A ) , where tmax is the maximum time step in X , and A is the time complexity of procedure PCT l . The bottomup construction runs in O(|tmax ∗ A| ) , which is further bounded by O(|tmax ∗ |V |3 ) if an approximable algorithm is used [ 19 ] . In our experimental study , we utilize efficient linear programming to compute the optimal steiner forest .
The algorithm WPCT can easily be adapted for PCT min problem for minimum perfect consistent trees , treating the weight on each edge as unit weight .
Perfect consistent SP trees . The independent cascade model may be an overkill for real life applications , as observed in [ 6 ] , [ 12 ] . Instead , one may identify the consistent trees which follow the shortest path model [ 12 ] , where cascades propagate following shortest paths . We define a perfect shortest path ( sp ) tree rooted at a given source node s as a perfect consistent tree , such that for each observation point ( v , t ) ∈ X of the tree , t = dist(s , v ) ; in other word , the path from s to v in the tree is a shortest path in G . The PCT w ( resp . PCT min ) problem for sp trees is to identify the sp trees with the maximum likelihood ( resp . minimum size ) . min and PCT
Proposition 2 : Given a graph G and a partial observation X , ( a ) it is in PTIME to find a sp tree wrt X ; ( b ) the PCT w problems for perfect sp trees are NPhard and APX hard ; ( c ) the PCT w problem is approximable within O(d ∗ log fmin log fmax ) , where d is the diameter of G , and fmax ( resp . fmin ) is the maximum ( resp . minimum ) value defined by the diffusion function f . the algorithm , denoted as WPCT
We next provide an approximation algorithm for the w problem on sp trees . Given a graph G and a partial PCT observation X , sp ( not shown ) , first constructs the backbone graph Gb as in the algorithm WPCT . It then constructs node sets Vr = {v|(v , t ) ∈ X} , and Vs = V \ Vr . Treating Vr as required nodes , Vs as steiner nodes , and the log likelihood function as the weight function , WPCT sp approximately computes an undirected minimum steiner tree T . If the directed counterpart T . of T sp transforms T . to a tree : for in Gb is not a tree , WPCT each node v in T . with more than one parent , it ( a ) connects s and v via a shortest path , and ( b ) removes redundant edges
Input : graph G and partial observation X . Output : a bounded consistent tree T in G . 1 . 2 . 3 . 4 . 5 . 6 . tree T = ( Vt , Et ) , where Vt := {s|(s , 0 ) ∈ X} , Et := ∅ ; compute tk bounded BFS DAG Gd of s in G ; for each ti ∈ [ t1 , tk ] do for each node v where ( v , ti ) ∈ X and l(v ) = i do if i > ti then return ∅ ; find a path ρ from s to v with the minimum weight w(ρ ) = −Σ log f ( e ) for each e ∈ ρ ; T = T ∪ ρ ; return T as a bounded consistent tree ;
7 . 8 .
Figure 2 : Algorithm WBCT attached to v . It then returns T . as an sp tree .
One may verify that ( a ) T . is a perfect sp tree wrt X , ( b ) the weight −LX ( T . ) is bounded by O(d ∗ log fmin log fmax ) times of the optimal weight , and ( c ) the algorithm runs in O(|V 3| ) time , leveraging the approximation algorithm for the steiner tree problem [ 23 ] . Moreover , WPCT sp can be used for min for sp trees , where each edge in G has the problem PCT the same weight . This achieves an approximation ratio of d .
IV . CASCADES AS BOUNDED TREES
In this section , we investigate the cascade inference problems for bounded consistent trees . In contrast to the intractable counterpart in Proposition 1(a ) , the problem of finding a bounded consistent tree for a given graph and a partial observation is in PTIME .
Proposition 3 : For a given graph G and a partial observation X , there is a bounded consistent tree in G wrt X if and only if for each ( v , t ) ∈ X , dist(s , v ) ≤ t , where dist(s , v ) is the distance from s to v in G . w , is to identify the bounded consistent tree T ∗
Given a graph G and a partial observation X , the minimum weighted bounded consistent tree problem , denoted as s wrt X BCT with the maximum likelihood LX ( T ∗ s ) . Using log likelihood measurement , the BCT s with the minimum − log LX ( T ∗ w problem is to identify T ∗ s ) ( see Section II ) .
Theorem 1 : Given a graph G and a partial observation w problem is
X , the BCT ( a ) NP complete and APX hard ; and ( b ) approximable within O(|X| ∗ log fmin log fmax ) , where fmax ( resp . fmin ) is the maximum ( resp . minimum ) value defined by the diffusion function f over G .
One may show the hardness result in Theorem 1(a ) by constructing ( 1 ) a polynomial time reduction from the exact 3 cover problem ( X3C ) , and ( 2 ) an AFP reduction from the minimum directed steiner tree ( MST ) problem . We next provide an algorithm for the BCT w problem , which runs in linear time wrt the size of G , and with performance guarantee as in Theorem 1(b ) .
Algorithm . The algorithm , denoted as WBCT , is illustrated in Fig 2 . Given a graph G and a partial observation X , the algorithm first initializes a tree T = ( Vt , Et ) with the single
7121221 source node s ( line 1 ) . It then computes the tk bounded BFS directed acyclic graph ( DAG ) [ 2 ] Gd of the source node s , where tk is the maximum time step of the observation points in X , and Gd is a DAG induced by the nodes and edges visited by a BFS traversal of G from s ( line 2 ) . Following a top down strategy , for each node v of ( v , t ) ∈ X , WBCT then ( a ) selects a path ρ with the minimum −Σ log f ( e ) from s to v , and ( b ) extends the current tree T with the path ρ ( lines 3 7 ) . If for some observation point ( v , t ) ∈ T , dist(s , v ) > t , then WBCT returns ∅ ( line 5 ) . Otherwise , the tree T is returned ( line 8 ) . Correctness and complexity . One may verify that algorithm WBCT either correctly computes a bounded consistent tree T , or returns ∅ . The algorithm runs in time O(|E| ) , since it visits each edges at most once following a BFS traversal . We next show the approximation ratio in Theorem 1(b ) . Observe that for a single node v in X , ( a ) the total weight of the path w from s to v is no greater than |w| log fmin , where |w| is the length of w ; and ( b ) the weight of the counterpart of w in T ∗ , denoted as w . , is no less than |w∗| log fmax . Also observe that |w| ≤ |w∗| . Thus , w/w∗ ≤ log fmin log fmax . As there are in total |X| such nodes , LX ( T )/LX ( T ∗ ) ≤ |X| w ≤ |X| log fmin log fmax
. Theorem 1(b ) thus follows . w∗
Minimum bounded consistent tree . As remarked earlier , one may simply want to identify a bounded consistent tree with minimum total number of nodes and edges . Given a social graph G and a partial observation X , the minimum bounded consistent tree problem , denoted as BCT min , is to identify such a tree in G wrt X .
The BCT min problem is a special case of BCT w . We summarize the main result as follows .
Proposition 4 : The BCT min problem is ( a ) NP complete ,
( b ) APX hard , and ( c ) approximable within O(|X| ) .
V . EXPERIMENTS
We next present an experimental study to evaluate the effectiveness and efficiency of the proposed algorithms .
Experimental setting . We used both real life and synthetic datasets . For real life data we used ( 1 ) the Enron email cascades1 , a social graph of 86 , 808 users and 660 , 642 edges as email forwarding relation , and ( 2 ) Retweet cascades ( RT)2 [ 25 ] . For Enron dataset , We tracked the forwarded messages of the same subjects and obtained 260 cascades of depth no less than 3 with more than 8 nodes . For Retweet dataset , we obtained 321 cascades of depth more than 4 , with node size ranging from 10 to 81 , by extracting the retweet cascades of the identified hashtags [ 25 ] . We used the EM algorithm from [ 21 ] to estimate the diffusion function . We also randomly generated a set of synthetic cascades
1http://wwwcscmuedu/∼enron 2http://snapstanfordedu/data/twitter7html unfolding in an anonymous Facebook social graph3 . For all the datasets , we define uncertainty of a cascade T as σ = 1 − |X| |VT | , where |VT | is the node number in T , and |X| is the size of the partial observation X . We remove the nodes from the given cascades until the uncertainty is satisfied , and collect the remaining nodes and their time steps as X .
We have implemented the following in C++ : ( i ) al r and BCT lp ( resp . BCT lp , where PCT gorithms WPCT , and WBCT ; ( ii ) two algorithms PCT lp and BCT lp ) identifies the optimal weighted bounded ( resp . perfect ) consistent trees using linear programming , respectively ; ( iii ) two randomized algorithms PCT r is similar to WPCT except for randomly selecting the steiner forest at each level ( see Section III ) ; as WBCT does , BCT r runs on bounded BFS directed acyclic graphs , but randomly selects edges ; and ( iv ) an algorithm PCT g which uses a greedy strategy to select the steiner forest at each level ( see Section III ) . We used a machine powered by an Intel(R ) Core 2.8GHz CPU and 8GB of RAM , using Ubuntu 1010 r , where PCT
\VX )|
Σ(|VTi
Σ(|VTi fi \VX )|
Experimental results . We next present our findings . Effectiveness of consistent trees . Given a set of real life cascade T = {T1 , . . . , Tk} , for each cascade Ti = ( VTi , ETi ) ∈ . = ( VTi fi , ETi T , we computed an inferred cascade Ti fi ) according to a partial observation with uncertainty σ . Denote the nodes in the partial observation as VX . We evaluated the precision as prec = Σ(|(VTi fi ∩VTi )\VX | ) , and rec = Σ(|(VTi fi ∩VTi )\VX | )
Using the same setting , both BCT
. For Enron dataset , we found that WPCT g and PCT r on both prec and rec , as shown outperforms PCT in Fig 3(a ) and Fig 3(b ) , respectively . When the uncertainty increases , both the prec and rec of the three algorithms decrease . In particular , WPCT successfully infers cascade nodes with prec no less than 70 % and rec no less than 25 % even when 85 % of the nodes in the cascades are removed . lp and WBCT outr , and their prec and rec decrease while the perform BCT uncertainty increases , as shown in Fig 3(c ) and Fig 3(d ) , respectively . The performance of these algorithms over retweet cascades [ 26 ] verifies our observations . Efficiency . In all the tests over real life datasets , PCT r , g and WBCT take less than 1 second . BCT BCT lp and PCT lp do not scale for these datasets . In our tests , the efficiency of all the algorithms are not sensitive wrt the changes to σ . The results over synthetic data also verify the effectiveness and scalability of our methods . r , PCT
In summary , our inference algorithms can infer cascades effectively based on partial observation , and scale well with the sizes of the cascades . For more details , please refer to [ 26 ] .
VI . CONCLUSION
In this paper , we investigated cascade inference problem based on partial observation . We proposed consistent trees
3http://currentcsucsbedu/socialnets
7131222 i i n o s c e r P
1
0.8
0.6
0.4
0.2
0
0.6
0.5
0.4
0.3
0.2
0.1
0
WPCT PCTr PCTg l l a c e R
0.4
0.3 0.8 The uncertainty of the observation ( σ )
0.5
0.6
0.7
WPCT PCTr PCTg
0.4
0.3 0.8 The uncertainty of the observation ( σ )
0.5
0.6
0.7 i i n o s c e r P
1
0.8
0.6
0.4
0.2
0
WBCT BCTr BCTlp
0.4
0.3 0.8 The uncertainty of the observation ( σ )
0.5
0.6
0.7 l l a c e R
1
0.8
0.6
0.4
0.2
0
WBCT BCTr BCTlp
0.4
0.3 0.8 The uncertainty of the observation ( σ )
0.6
0.5
0.7
( a ) PCT@Enron : prec
( b ) PCT@Enron : rec
( c ) BCT@Enron : prec
( d ) BCT@Enron : rec
Figure 3 : The precision and recall of the inference algorithms over Enron cascades
Complexity
Approximation
Problem
BCTmin BCTw
PCTmin ( sp tree ) PCTw ( sp tree )
PCTmin PCTw
NP c , APX hard NP c,APX hard NP c , APX hard NP c , APX hard
NP c , APX hard NP c , APX hard
|X|
|X| ∗ log fmax log fmin d d ∗ log fmax log fmin time
O(|E| ) O(|E| ) )
|V 3| |V 3|
– –
O(|tmax ∗ |V |3 ) O(|tmax ∗ |V |3 )
Table I . Summary of the results as well as quantitative metrics for capturing the inferred cascades . We have established the hardness results for the optimization problems as summarized in Table I . Despite the hardness , we provide heuristics for these problems , with performance guarantees on inference quality . Experimental results show that our methods are able to efficiently and effectively infer partially observed cascades .
Acknowledgment . This research was sponsored in part by the US National Science Foundation under grant IIS1219254 and by the Army Research Laboratory under cooperative agreement W911NF 09 2 0053 ( NS CTA ) . The views and conclusions contained herein are those of the authors and should not be interpreted as representing the official policies , either expressed or implied , of the Army Research Laboratory or the US Government . The US Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notice herein .
REFERENCES
[ 1 ] D . Arthur , R . Motwani , A . Sharma , and Y . Xu . Pricing Internet strategies for viral marketing on social networks . and Network Economics , pages 101–112 , 2009 .
[ 2 ] J . Bang Jensen and G . Z . Gutin . Digraphs : Theory , Algo rithms and Applications . Springer , 2008 .
[ 3 ] S . Bikhchandani , D . Hirshleifer , and I . Welch . A theory of fads , fashion , custom , and cultural change as informational cascades . Journal of political Economy , pages 992–1026 , 1992 .
[ 4 ] C . Budak , D . Agrawal , and A . El Abbadi . Limiting the spread of misinformation in social networks . In WWW , 2011 .
[ 5 ] M . Cha , F . Benevenuto , Y Y Ahn , and P . K . Gummadi . Delayed information cascades in flickr : Measurement , analysis , and modeling . Computer Networks , 56(3):1066–1076 , 2012 . [ 6 ] W . Chen , C . Wang , and Y . Wang . Scalable influence maximization for prevalent viral marketing in large scale social networks . In KDD , 2010 .
[ 7 ] F . Chierichetti , J . M . Kleinberg , and D . Liben Nowell . Reconstructing patterns of information diffusion from incomplete observations . In NIPS , pages 792–800 , 2011 .
7141223
[ 8 ] K . Dave , R . Bhatt , and V . Varma . Modelling action cascades in social networks . In AAAI , 2011 .
[ 9 ] H . Fei , R . Jiang , Y . Yang , B . Luo , and J . Huan . Content based social behavior prediction : a multi task learning approach . In CIKM , 2011 .
[ 10 ] J . Goldenberg , B . Libai , and E . Muller . Talk of the network : A complex systems look at the underlying process of wordof mouth . Marketing Letters , pages 211–223 , August 2001 . [ 11 ] D . Kempe , J . Kleinberg , and E . Tardos . Maximizing the spread of influence through a social network . In KDD , 2003 . [ 12 ] M . Kimura and K . Saito . Tractable models for information diffusion in social networks . PKDD , pages 259–271 , 2006 . [ 13 ] G . Kossinets , J . Kleinberg , and D . Watts . The structure of information pathways in a social communication network . In SIGKDD , 2008 .
[ 14 ] T . Lappas , E . Terzi , D . Gunopulos , and H . Mannila . Finding effectors in social networks . In KDD , pages 1059–1068 , 2010 . [ 15 ] J . Leskovec , M . McGlohon , C . Faloutsos , N . S . Glance , and M . Hurst . Patterns of cascading behavior in large blog graphs . In SDM , 2007 .
[ 16 ] J . Leskovec , A . Singh , and J . Kleinberg . Patterns of influence Advances in Knowledge in a recommendation network . Discovery and Data Mining , pages 380–389 , 2006 .
[ 17 ] M . Mathioudakis , F . Bonchi , C . Castillo , A . Gionis , and In
Sparsification of influence networks .
A . Ukkonen . SIGKDD , pages 529–537 , 2011 .
[ 18 ] M . Richardson and P . Domingos . Mining knowledge sharing sites for viral marketing . In SIGKDD , 2002 .
[ 19 ] G . Robins and A . Zelikovsky . Tighter bounds for graph steiner tree approximation . SIAM J . Discrete Math . , 19(1 ) , 2005 .
[ 20 ] E . Sadikov , M . Medina , J . Leskovec , and H . Garcia Molina . In
Correcting for missing data in information cascades . WSDM , 2011 .
[ 21 ] K . Saito , R . Nakano , and M . Kimura . Prediction of information diffusion probabilities for independent cascade model . In KES , 2008 .
[ 22 ] X . Song , Y . Chi , K . Hino , and B . L . Tseng . Information flow modeling based on diffusion rate for prediction and ranking . In WWW , 2007 .
[ 23 ] V . V . Vazirani . Approximation Algorithms . 2001 . [ 24 ] F . Wang , H . Wang , and K . Xu . Diffusive Logistic Model Towards Predicting Information Diffusion in Online Social Networks . ArXiv e prints , 2011 .
[ 25 ] J . Yang and J . Leskovec . Patterns of temporal variation in online media . In Proceedings of the fourth ACM international conference on Web search and data mining , WSDM , 2011 . Inferring the underlying structure of information cascades . arXiv preprint arXiv:1210.3587 , 2012 .
[ 26 ] B . Zong , Y . Wu , A . K . Singh , and X . Yan .
