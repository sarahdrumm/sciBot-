2012 IEEE 12th International Conference on Data Mining 2012 IEEE 12th International Conference on Data Mining
Student t based Robust Spatio Temporal Prediction
Yang Chen∗ , Feng Chen∗ , Jing Dai† , T . Charles Clancy‡ and Yao Jan Wu§
∗Department of Computer Science , Virginia Tech , VA 22043
†Google Inc . New York , NY 10011
§Department of Civil Engineering , Saint Louis University , St . Louis , MO 63103
‡Bradley Electrical and Computer Engineering , Virginia Tech , VA 22203 {yangc10∗ , chenf∗ , tcc‡}@vt.edu , jddai@google.com† , yaojan@slu.edu§
Abstract—This paper describes an efficient and effective design of Robust Spatio Temporal Prediction based on Student ’s t distribution , namely , St RSTP , to provide estimations based on observations over spatio temporal neighbors . The proposed St RSTP is more resilient to outliers or other small departures from model assumptions than its ancestor , the Spatio Temporal Random Effects ( STRE ) model . STRE is a state of the art statistical model with linear order complexity for large scale processing . However , it assumes Gaussian observations , which has the well known limitation of non robustness . In our StRSTP design , the measurement error follows Student ’s t distribution , instead of a traditional Gaussian distribution . This design reduces the influence of outliers , improves prediction quality , and keeps the problem analytically intractable . We propose a novel approximate inference approach , which approximates the model into the form that separates the high dimensional latent variables into groups , and then estimates the posterior distributions of different groups of variables separately in the framework of Expectation Propagation . As a good property , our approximate approach degeneralizes to the standard STRE based prediction , when the degree of freedom of the Student ’s t distribution is set to infinite . Extensive experimental evaluations based on both simulation and real life data sets demonstrated the robustness and the efficiency of our Student t prediction model . The proposed approach provides critical functionality for stochastic processes on spatio temporal data .
Keywords Spatio Temporal Process ; Expectation Propaga tion ; Student ’s t Distribution .
I . INTRODUCTION
Predicting spatial and temporal data is an essential component in many emerging applications in geographical information systems , medical imaging , urban planning , economy study , and climate forecasting . In the real world , most physical , biological , or social processes involve some degree of spatial and temporal variability [ 1 ] . It is suggested that any application that requires dynamic and stochastic process as a component should take spatial and temporal dependencies into account [ 2 ] . In these processes , an efficient and robust spatiotemporal prediction approach helps identify the causalities due to environmental effects , and forecast the impact of changes . Applications of such an approach include predicting traffic of an unsensored road segment using nearby traffic sensors , and estimating average income using known samples in similar geographic locations .
1550 4786/12 $26.00 © 2012 IEEE 1550 4786/12 $26.00 © 2012 IEEE DOI 101109/ICDM2012135 DOI 101109/ICDM2012135
308 151
There have been two paradigms for spatio temporal prediction , Kriging based and dynamical ( mechanic or probabilistic ) specification based . The Kriging based paradigm basically extends spatial dimensions ( d ) with an extra time dimension and focuses on the modeling of the variance covariance structure between the observations in the ( d + 1) dimensional space . The dynamic specification based paradigm considers spatio temporal processes through a dynamical statistical ( or state space based ) framework . In this framework the observations in the current state are dependent on its previous states through dynamic mechanical ( or probabilistic ) relationships . Our work focuses on the dynamic statistical paradigm , which can be explicitly specified based on the knowledge of the phenomenon under study . It always leads to a valid variance covariance structure , and allows fast filtering , smoothing , and forecasting [ 3 ] .
One emerging research challenge for spatio temporal prediction is to efficiently model massive spatio temporal data that have been collected by using advanced remote sensing technologies . For example , NASA collects data on the order of 100,000 observations per day from satellites . Big data challenges from smartphone usages have recently attracted a lot of research efforts [ 4 ] . Given the large data volume , most traditional spatio temporal statistical models fail to process in either memory space or execution time , even in supercomputing environments . Although recent progresses have been made [ 5 ] , the preceding works are still unable to achieve near real time performance and thus not suitable for processing massive streaming spatial data .
As the most recent advancement , [ 2 ] presents a spatiotemporal random effects ( STRE ) model that reduces the problem into a fixed dimension problem and makes it possible to do fast filtering , smoothing , and forecasting with a linear order time complexity . The STRE model assumes that 1 ) the spatial dependence can be captured by a predefined set of basis functions ; 2 ) the temporal dependence can be modeled by a latent first order Gaussian autoregressive process ; and 3 ) the measurement error can be modeled by a Gaussian distribution . These assumptions make the STRE model mainly applicable to linear dynamic environments
However , the spatio temporal dynamics of real applications are usually nonlinear , and some of the STRE ’s distribution assumptions are often violated . For example , the data may have a number of outliers , such as random hardware failures in digital control systems [ 6 ] , sensor faults in aerospace applications [ 7 ] , cochannel fading and interference in wireless communications [ 4 ] , and traffic incidents and malfunctioning detectors in urban traffic networks [ 17 ] . This paper presents a robust spatio temporal prediction approach for applications in nonlinear dynamic environments where some of the STRE assumptions are violated .
In recent years , robust methods have received much attention for a variety of learning problems(eg , [ 8 ] , [ 9 ] , [ 10 ] , [ 11 ] , [ 6 ] , [ 12] ) . The majority of these methods can be summarized using a probabilistic framework [ 8 ] in which the measurement error is modeled by a heavy tailed distribution , instead of the traditional Gaussian distribution . However , employing heavy tailed distributions makes the prediction process analytically intractable . Although stochastic simulation methods have been applied to estimate an approximate posterior distribution , for example via MCMC or particle filtering [ 9 ] , they are very computationally intensive . An efficient expectation propagation algorithm [ 10 ] was presented for robust Gaussian process regression based on the Student ’s t distribution . Similar efforts include a variational inference approach [ 11 ] for robust Student ’s t mixture clustering , a robust Kalman filter [ 6 ] based on the Huber distribution , and a Kalman smoother [ 12 ] based on the Laplace distribution .
This paper focuses on robust prediction in a probabilistic framework . We propose an observation model for spatiotemporal prediction based on Student ’s t . Because of its good robustness properties , the Student ’s t can be altered continuously from a very heavy tailed distribution to the Gaussian model with the degrees of freedom parameter . Further more , this work resolves the main challenge of the student t based model , which is the analytically intractable inference of high dimensional latent variables . The main contributions of our study can be summarized as follows . • We formalize an innovative robust prediction model for spatio temporal data in a systematical framework ;
• We approximate the robust prediction model such that the high dimensional latent variables can be separated into groups that can be optimized iteratively .
• We present novel implementations of Expectation Propagation ( EP ) in order to efficiently estimate the posterior distributions of latent variables .
• We validate the robustness and the efficiency of the proposed St RSTP model compared with the regular STRE model by an extensive simulation study and experiments on two real data sets .
The rest of the paper is organized as follows . Preliminaries on the formulation and inference algorithms of the regular STRE model is reviewed in Section II . Section III presents the robust spatio temporal prediction model , StRSTP , followed by the detailed approximation prediction techniques based on EP in Section IV . Simulation study and evaluation of our proposed robust smoothing algorithm on
309152 two real world data sets are illustrated in Section V . Finally , we conclude our work in Section VI .
II . THEORETICAL BACKGROUNDS
This section reviews the Spatio Temporal Random Effects ( STRE ) model and STRE based spatio temporal prediction . A . Spatio Temporal Random Effects Model
The STRE model is a recently proposed statistical model for processing large spatio temporal data in linear order time complexity [ 2 ] . The STRE model is used to model a spatial random process that evolves over time , {Yt(s ) ∈ fi : s ∈ D ⊂ fi2 , t = 1 , 2,···} , where D is the spatial domain under study , and Yt(s ) is the nonspatial measurement ( eg , temperature ) at location s and time t .
A discretized version of the process can be represented as
{Y1 , Y2,··· , Yt , Yt+1,···} ,
( 1 ) where Yt = [ Yt(s1,t ) , Yt(s2,t),··· , Yt(smt,t)]T . The sample locations {s1,t , s2,t,··· , smt,t} can be different spatial locations at different time t . Observations Zt and latent observations Ytare given by the data process , Zt = OtYt + εt , t = 1 , 2,··· ,
( 2 ) where Zt is an nt dimenstional vector ( nt ≤ mt ) , Ot is an nt×mt incidence matrix , used to handle missing values that are related to locations where no observations are available , and εt = [ εt(s1,t),··· , εt(snt,t)]T ∼ Nnt ( 0 , σ2 ε,tVε,t ) is a vector of white noise Gaussian processes , with Vε,t = diag(vε,t(s1,t),··· , vε,t(snt,t) ) . Particularly , var(εt(s ) ) = σ2 ε,tv(s ) > 0 , σ2 is a parameter to be estimated , and ε,t v(s ) is known . The white noise assumption implies that cov(εt(s ) , εu(r ) ) = 0 , for t = u and s = r .
The vector Yt is given by the spatial process :
Yt = Xtβt + νt , t = 1 , 2,··· ,
( 3 ) where Xt = [ xt(s1,t),··· , xt(smt,t)]T , xt(si,t ) ∈ fip , 1 ≤ i ≤ mt , represents a vector of covariates , and the coefficients βt = ( β1,t,··· , βp,t)T are general unknown . The random process νt captures the small scale variations . For traditional spatio temporal Kalman filtering models , a large number of parameters need to be estimated with high computational costs due to the high data dimensionality during the filtering , smoothing , and forecasting processes . As a key advantage of the STRE model , it models the small scale variation νt as a vector of spatial random effects ( SRE ) processes t ηt + ξt , t = 1 , 2,··· ,
νt = ST
( 4 ) where St = [ St(s1,t),··· , St(smt,t) ] , St(si,t ) = [ S1,t(si,t),··· , Sr,t(si,t)]T , 1 ≤ i ≤ mt , is a vector of r predefined spatial basis functions , such as wavelet and bisquare basis functions , and ηt is an r dimensional zeromean Gaussian random vector with an r × r covaraince matrix given by Kt . The first component in Equation ( 4 ) denotes a smoothed small scale variation at time t , captured by the set of basis functions St .
The second component in Equation ( 4 ) captures the microscale variability similar to the nugget effect as defined in geostatistics [ 2 ] . It is assumed that ξt ∼ Nmt(0 , σ2 ξ,tVξ,t ) , Vξ,t = diag(vξ,t(s1,t),··· , vξ,t(smt,t) ) , and vξ,t(· ) describes the variance of the micro scale variation and is typically considered known . Note that the component ξt is important , since it can be used to capture the extra uncertainty due to the dimension reduction in replacing νt by ST t ηt . The coefficient vector ηt is assumed to follow a vector autoregressive process of order one ,
ηt = Htηt−1 + ζt , t = 1 , 2,··· ,
( 5 ) where Ht refers to the so called propagator matrix , ζt ∼ N ( 0 , Ut ) is an r dimensional innovation vector , and Ut is named as the innovation matrix . The initial state η0 ∼ Nr(0 , K0 ) and K0 is in general unknown .
Combining Equations ( 2 ) , ( 3 ) , and ( 4 ) , the ( discretized ) data process can be represented as
Zt = Otμt + OtST t ηt + Otξt + εt , t = 1 , 2,··· ,
( 6 ) where μt = Xtβt is deterministic and the other components are stochastic .
B . STRE based Spatio Temporal Prediction
Given a set of observations {Z1,··· , ZT} , the spatiothe latent ( or temporal prediction problem is to predict de noised ) values {Y1,··· , Yt} . As discussed in Subsection II A , the incidence matrix Ot allows for the specification of missing observations , which makes it possible to concurrently predict the latent Y values for both observed and unobserved locations . This is a smoothing problem if t < T ; and a filtering problem if t = T ; and a forecasting problem if t > T . Readers are referred to [ 2 ] for the detailed STRE based prediction equations .
III . PROBLEM FORMULATION
This section introduces the new Robust Spatio Temporal Prediction model based on Student ’s t , St RSTP , and describes the problem of estimating the posterior distributions p(Yt|Z1:t ) and p(Yt|Z1:T ) for spatial prediction .
A . Robust Spatio Temporal Prediction Model the measurement error ,
The Robust Spatio Temporal Prediction model based on Student t ( St RSTP ) considers Student ’s t distribution to model instead of the traditional Gaussian distribution . Student ’s t distribution has a heavier tail than Gaussian distribution . The tail heaviness is controlled by setting the degrees of freedom ( ν ) . When the degree of freedom approaches infinity , Student ’s t distribution becomes equivalent to Gaussian distribution . Student ’s t distribution has been used in a number of statistical models , and has been shown effective for a variety of robust processes [ 1 ] , [ 10 ] .
We use the same symbols and definitions as in subsection
II A . The St RSTP model can be formalized as
Zt = OtYt + εt , Yt = Xtβt + ST ηt = Htηt−1 + ζt . t ηt + ξt ,
( 7 ) ( 8 ) ( 9 )
As a key difference from the STRE model , the measurement error εtn now follows a Student ’s t distribution Studentt(0 , ν , σ ) with the probability density function as 2 − 1 2 , p(εtn ) =
2 ( 1 +
( 10 )
1
)
− ν
)
Γ( ν+1 2 ) Γ( ν 2 )
(
1
πνσ
ε2 tn νσ where ν is the degrees of freedom and σ is the scale parameter . B . Problem Formulation for Robust Prediction Given the observations {Z1,··· , ZT} , the predictive process is to estimate the latent variables {Y1,··· , Yt} at sampled and unsampled locations , where t = 1 , 2,··· The estimation of Y variables at unsampled locations is realized by using the incidence matrix Ot in the St RSTP model , where Ot ∈ Rnt×mt , nt refers to the number of observations at sampled locations , and mt − nt refers to the number of unsampled locations that are of interest for prediction .
The objective of this paper is to estimate the expectation and variance covariance of the posterior distributions p(Yt|Z1:T ) , t = 1 , 2,··· , denoted as Yt|T and Σt|T , respectively . Yt|T will be regarded as the prediction values , and Σt|T will be applied to estimate confidence intervals . Specifically , the predictive process is called smoothing ; if t = T , the predictive process is called filtering ; and if t = T + k , k > 0 , the predictive process is called k step forecasting . if t < T ,
According to the STRE model decomposition as shown in Equation 6 , we can first estimate the mean and variancecovaraince matrix of the joint posterior p(ηt , ξt|Z1:T ) . The components Yt|T and Σt|T can then be estimated by linear transformations . However , the total dimension of ηt and ξt is “ r + mt ” . This high dimensionality makes the estimation process computationally expensive even using advanced convex optimization techniques . IV . APPROXIMATE SPATIO TEMPORAL PREDICTION In this section , we first present an approximate St RSTP model , such that the posterior distributions of latent variables {ηt , ξt}T t=1 can be estimated iteratively . EP based approximate algorithms are then designed in order to efficiently infer the posterior distributions p(ηt|Z1:T ) and p(ξt|Z1:T ) . A . Approximate St RSTP Model Let ηt|T ≡ E[p(ηt|Z1:T ) ] , Pt|T ≡ V ar[p(ηt|Z1:T ) ] , ξt|T ≡ E[p(ξt|Z1:T ) ] , and Rt|T ≡ V ar[p(ξt|Z1:T ) ] . It follows that
Yt|T = Xtβt + ST t ηt|T + ξt|T , .
310153
In order to efficiently estimate the variance covariance matrix Σt|T , we make the approximation as
Σt|T ≈ ST t Pt|T St + Rt|T .
( 11 )
Based on the above strategy , the major task is to conduct
Gaussian approximations to p(ηt|Z1:T ) and p(ξt|Z1:T ) : p(ηt|Z1:T ) ∼G N ( ηt|T , Pt|T ) p(ξt|Z1:T ) ∼G N ( ξt|T , Rt|T ) .
( 12 ) ( 13 )
A popular strategy is to calculate the maximum aposterior ( MAP ) estimations of the above posteriors using numerical optimization techniques ( eg , gradient decent , interior point algorithms ) , and then calculate the corresponding Hessian matrices at the MAP locations . However , there exist no analytical forms of the posteriors
Based on the above approximate St RSTP model , the subsequent subsection ( IV B ) presents an efficient EP based algorithm to conduct Gaussian approximation of p(ηt|Z1:T ) . Phase II : Approximate Estimation of ξt|T and Rt|T In order to estimate ξt|T and Rt|T , we need to first conduct Gaussian approximation of the posterior p(ξt|Z1:t ) . The joint posterior distribution p(ξt , ηt|Z1:t ) = p(ξt , ηt , Zt|Z1:t−1 )
= p(Zt|ηt , ξt)p(ξt|ηt)p(ηt|Z1:t−1 ) .
Given ˆp(ηt−1|Z1:t−1 ) ∼ N ( ηt−1|t−1 , Pt−1|t−1 ) estimat ed in Phase I , it follows that
ˆp(ηt|Z1:t−1 ) ∼ N ( ηt|t−1 , Pt|t−1 ) , where ηt|t−1 = Htηt−1|t−1 , p(ηt|Z1:T ) = p(ξt|Z1:T ) = p(ξt , ηt|ZT )dξt , p(ξt , ηt|ZT )dηt ,
( 14 )
( 15 )
Pt|t−1 = HtPt−1|t−1HT t + Ut . The posterior p(ξt , ηt|Z1:t ) can be approximated as ˆp(ξt , ηt|Z1:t ) = p(Zt|ηt , ξt)p(ξt)ˆp(ηt|Z1:t−1 ) .
( 22 )
( 23 )
( 24 )
. . and the application of numerical optimizations is difficult , because no analytical forms of gradient and Hessian matrix can be calculated . The following presents several approximations to make the estimation of the posteriors tractable .
Phase I : Approximate Estimation of ηt|T and Pt|T The St RSTP model can be reformulated as follows
Zt = OtXtβt + OtST ηt = Htηt−1 + ζt t ηt + Otξt + εt ,
( 16 ) ( 17 )
The component ξtn captures a micro scale variation and is modeled by a white noise Gaussian process with mean . zero and variance var(ξ(s ; t ) ) = σ2 t(s ) . The component ξ v εtn is a Student ’s t process with mean zero and variance var(ε(s ; t ) ) = σ2
ε vt(s ) . An approximation is made as
˜ξt = Otξt + εt , ˜ξtn ∼ Student t(0 , ν , ˜σ ) .
( 18 ) ( 19 )
The approximate St RSTP model can be reformulated as
Zt = OtXtβt + OtST ηt = Htηt−1 + ζt . t ηt + ˜ξt ,
( 20 ) ( 21 )
Figure 1 shows the graph model representation about the statistical relationships between observation Zt and latent variables ηt and ξt .
Figure 1 : Approximate St RSTP Graphic Model
311154
. . .
Integrating out ηt , we obtain p(ξt|Z1:t ) = ≈ ≈ p(ξt , ηt|Zt)dηt p(Zt|ηt , ξt)p(ξt)ˆp(ηt|Z1:t−1)dηt ˆp(ξt , ηt|Z1:t)dηt .
( 25 ) Notice that the components p(ξt ) and ˆp(ηt|Z1:t−1 ) are Gaussian . By applying Gaussian approximation to p(Zt|ηt , ξt ) , the posterior ˆp(ξt , ηt|Z1:t ) is hence approximated as Gaussian as well , and the analytical form of the above integration ( 25 ) can be obtained . An efficient EP based algorithm is presented in subsection IV C . Note that in Phase I and Phase II , it is required that t ≤ T . That means , the results are only suitable for smoothing and filtering . Given the filtering estimations ηt|T and Pt|T by Phase I , the forecasting estimations ηt|T , Pt|T , ξt|T , and Rt|T , where t = T + k and k > 0 , can be obtained based on the regular STRE model [ 2 ] , because it is unnecessary to consider outliers in future “ observations ” .
Hi
ηt|T , fi i=T +1
T +k' ⎧⎪⎨ T +k−1 ⎪⎩ fi T +k' i=T +1 ff ⎛ ⎝ T +k' ff j=i+1
⎛ ⎞ ⎝ T +k' ⎠ Ui ffT fi T +k' j=i+1
Hj
⎞ ⎠T
( 26 )
⎫⎪⎬ ⎪⎭ +
Hj
+ UT +k ,
Hi
PT|T
Hi
ηT +k|T =
PT +k|T = i=T +1 i=T +1
ξT +k|T = 0 , RT +k|T = 0 . Theorem 1 . the Student ’s t distribution used in the St RSTP model is set the degree of freedom parameter of
If to infinite , then the estimation results of p(ηt|Z1:T ) and p(ξt|Z1:T ) by Phase I and II , as well as the prediction results by Equations ( 10 ) and ( 11 ) , are equivalent to the exact estimation and prediction results of the standard STRE model .
Proof : The proof is removed due to space limit .
The above theorem presents a pleasant theoretical property of our proposed St RSTP model . It shows that the standard STRE is a special case of our robust model .
Figure 2 : Factor Graph Presentation of St RSTP
B . EP Based Estimation of ηt|T and Pt|T
In order to apply EP to the estimation problem , we first present the factor graph [ 13 ] representation in the framework of dynamic Bayesian networks as shown in Figure 2 . From Figure 2 , the joint distribution of latent variables and observations , forward and backward message passing components α(· ) and β(· ) can be derived from literature [ 14 ] , as showed below : p(η1:T , Z1:T ) = p(η1)p(Z1|η1 )
αt(ηt ) = p(Zt|ηt )
.
T'
. p(ηt|ηt−1)p(Zt|ηt ) , p(ηt|ηt−1)αt−1(ηt−1)dηt−1 , t=2
βt−1(ηt−1 ) = p(ηt|ηt−1)p(Zt|ηt)βt(ηt)dηt .
( 27 )
The posterior distribution of latent variable can be re formalized as the production of factor functions : p(η1:T|Z1:T ) ∝
Ωt(ηt−1 , ηt ) ,
( 28 )
' where each factor function is represented as t
Ωt(ηt−1 , ηt ) := p(ηt|ηt−1)p(Zt|ηt ) , and Ωt(η0 , η1 ) := p(η1)p(Z1|η1 ) , when t = 1 .
Recall that p(Zt|ηt ) follows a Student ’s t distribution , the estimation of Equation ( 27 ) is intractable . It can be further approximated as the following factorized form qt(ηt−1 , ηt ) ∝
ˆΩ(ηt−1 , ηt ) ,
( 29 )
' q(η ) = t
' t where ˆ indicates an approximation of the corresponding symbol .
312155
Combining Equations ( 27 ) and ( 28 ) , the smoothing latent variable can be estimated by p(ηt|Z1:T ) ≈ qt(ηt ) ∝ ˆαt(ηt ) ˆβt(ηt ) p(ηt−1 , ηt|Z1:T ) ≈ ˆpt(ηt−1 , ηt ) ,
( 30 ) ( 31 ) ∝ ˆαt−1(ηt−1)p(ηt|ηt−1)p(Zt|ηt ) ˆβt(ηt ) = ˆαt−1(ηt−1)Ωt(ηt−1 , ηt ) ˆβt(ηt ) .
Furthermore , given that from the factorial form ,
ˆpt(ηt−1 , ηt ) = qt−1(ηt−1)qt(ηt ) ,
( 32 ) plugging Equations ( 29 ) , ( 30 ) , ( 31 ) into Equation ( 32 ) leads to the simplified approximation form :
ˆΩt(ηt−1 , ηt ) = ˆβt−1(ηt−1)ˆαt(ηt ) .
( 33 ) t
( ηt−1 , ηt ) , we need to estimate ˆβnew
The EP algorithm refines the approximate posterior q(η ) iteratively by recomputing passing messages . As indicated in order to estimate the approximate in Equation ( 33 ) , t−1 ( ηt−1 ) and factor ˆΩnew ˆαnew ( ηt ) . One slice posterior distribution can be acquired t by integrating one latent variable from two slice posterior distribution . When we compute the one slice posterior , the corresponding message can be calculated by Equation ( 30 ) . Hence , by combining Equations ( 31 ) and ( 32 ) , these two messages can be obtained by following two steps : 1 ) approximating ˆpt(ηt−1 , ηt ) ∝ ˆαt−1(ηt−1)p(ηt|ηt−1)p(Zt|ηt ) ˆβt(ηt ) as a Gaussian distribution by Laplace Approximation
ˆpt(ηt−1 , ηt ) ≈LA N ( ηt−1 , ηt | μ , Σ ) ,
( 34 ) where μ and Σ match the first and second moments of ˆpt(ηt−1 , ηt ) ; 2 ) integrating out ηt−1 ( or ηt ) to obtain ˆαnew t
( ηt ) ( or ˆβnew t−1 ( ηt−1) ) : ( ηt ) ∝ ˆα t−1 ( ηt−1 ) ∝ new ˆβ new t
N ( ηt−1 , ηt | μ , Σ)dηt−1 N ( ηt−1 , ηt | μ , Σ)dηt
ˆβt(ηt )
ˆαt−1(ηt−1 )
,
( 35 )
( 36 )
.
The above strategy outputs the estimated messages ˆαt(ηt ) and ˆβt(ηt ) , t = 1,··· , T , each of which follows a Gaussian distribution , with known parameters . The posterior distributions of p(ηt|Z1:t ) , p(ηt|Z1:T ) can be estimated as
ˆp(ηt|Z1:t ) = ˆp(ηt|Z1:T ) =
1Z1:t 1Z1:T
ˆαt(ηt ) ,
ˆαt(ηt ) ˆβt(ηt ) ,
( 37 ) where Z1:t and Z1:T are the normalization factors . The mean and variance covariance matrix ηt|T and Pt|T can be estimated readily from ( 37 ) . C . EP Based Estimation of ξt|T and Rt|T As illustrated in the above Phase II , this subsection focuses on the EP based Gaussian approximation of the posterior p(ξt|Z1:t ) : p(ξt|Z1:t ) ∼G N ( ξt|t , Rt|t ) .
( 38 )
Based on the above Gaussian approximation , as well as the Gaussian approximations p(ηt|Z1:t ) ∼G N ( ηt|t , Pt|t ) and p(ηt|Z1:T ) ∼G N ( ηt|T , Pt|T ) conducted in the subsection IV B , the parameters ξt|T and Rt|T can be conveniently estimated by the regular STRE model as shown in [ 2 ] . The joint distribution ˆp(ξt , ηt|Z1:t ) comprises a product of factors in the form
Nt' n=1
ˆp(ξt , ηt|Z1:t ) = {p(Ztn|ηt , ξtn)p(ξtn)} ˆp(ηt|Z1:t−1 ) . ( 39 ) We approximate ˆp(ξt , ηt|Z1:t ) as a product of factors
Nt' qn(ξtn , ηt|ˆμtn , ˆΣtn)p(ξtn )
ˆp(ηt|Z1:t−1 ) , ( 40 ) q(ξt , ηt ) = n=1 where p(Ztn|ηt , ξtn ) is approximated by the Gaussian function qn(ξtn , ηt|ˆμtn , ˆΣtn ) ∼ N ( ˆμtn , ˆΣtn ) ,
( 41 ) and ˆμtn and ˆΣtn are unknown parameters to be estimated . Notice that , given the estimated ˆp(ηt|Z1:t−1 ) , Equation ( 24 ) indicates that the sets of variables {ξt , ηt} and {ξs , ηs} are independent when t = s . Different from the EP algorithm in Section IV B , which needs to propagate the messages backward and forward to the variables at different time stamps , the EP algorithm for estimating ˆq(ξt , ηt ) can be conducted separately for different time stamps . The detailed EP algorithm for estimating p(ξt , ηt|Z1:t ) can be described as follows : 1 ) Estimate the approximate factors ˆp(ηt−1|Z1:t−1 ) by the EP algorithm proposed in Section IV B . Estimate ˆp(ηt|Z1:t−1 ) by Equation ( 23 ) . 2 ) Initialize the factors qn(ξtn , ηt|ˆμtn , ˆΣtn ) , n = 1,··· , Nt , by setting ˆμtn = [ 0 ] and −ST 1 −Stn StnST
σ
ˆΣtn =
2 ξ . tn tn
3 ) Until convergence ( iterate on n = 1,··· , Nt ) : a ) Remove the factor qn(ξtn , ηt|ˆμtn , ˆΣtn ) from q(ξt , ηt ) by division
\n
( ξt , ηt ) ∝ q q(ξt , ηt ) qn(ξtn , ηt|ˆμtn , ˆΣtn )
.
( 42 ) b ) Estimate the new posterior qnew(ξt , ηt ) by matching the first and second moments of
\n q
( ξt , ηt)p(Ztn|ηt , ξtn ) . c ) Update the new factor new q
( ξtn , ηt|ˆμtn , ˆΣtn ) = qnew(ξt , ηt ) \n(ξt , ηt ) q
.
( 43 )
Evaluating the above EP algorithm , the number of required iterations is greater than Nt , which is the size of locations at it needs to evaluate the new posterior qnew(ξt , ηt ) by setting the time stamp t . For each iteration ,
313156 first and second order moments of qnew(ξt , ηt ) equal to \n(ξt , ηt)p(Ztn|ηt , ξtn ) . An efficient strategy is those of q to explore the special structure of the factorized forms ( 39 ) and ( 40 ) . The dependency between ξtn and {ξts , s = n} is realized only through ηt , and the joint distribution of ηt and {ξts , s = n} is Gaussian . Hence , we are able to obtain the analytical form ( ˜qn(ξtn , ηt ) ) by marginalization over {ξts , s = n} . The factor ˜q(ξtn , ηt ) can be efficiently approximated as a Gaussian form ˜f ( ξtn , ηt ) by matching the first and second order moments using iterative reweighted least squares ( IRLS ) [ 15 ] .
V . EXPERIMENTS
This section evaluates the effectiveness and efficiency of our proposed St RSTP prediction algorithms based on a simulation study and comprehensive experiments on two real data sets , including an Aerosol Optical Depth ( AOD ) data set collected by NASA and a region wide traffic volume ( TV ) data set collected in the City of Bellevue , WA . A . Experiment Design
Given the raw data , we first conducted a preprocess to generate original observations Z1:T by cleaning the data set , converting the observations into a close to symmetric distribution , and selecting a study region . The second step was to estimate model parameters based on the clean data set by applying the EM estimation method proposed by [ 16 ] . The third step was to run the STRE smoothing on the clean data set to obtain the set of smoothed values ˆY1:T as the ground truth for evaluation . The fourth step was to randomly add isolated or region ( cluster of ) outliers into the clean data to obtain the contaminated data set ˜Z1:T ( except for TV ) . The fifth step was to apply the STRE prediction algorithm and the proposed St RSTP prediction algorithm to estimate Y(s ) 1:T , respectively . The final step was to calculate the mean absolute percentage error ( MAPE ) and root mean squared error ( RMSE ) by comparing Y(s ) 1:T with Y1:T .
1:T and Y(sr )
1:T and Y(sr )
The superscripts ( sr ) and ( s ) of MAPE and RMSE refer to the St RSTP processing and the STRE processing , respectively . If MAPE(s ) ( or RMSE(s ) ) is larger than MAPE(sr ) ( or RMSE(sr) ) , we can conclude that our proposed algorithm is more robust than the STRE algorithm . B . Simulation Study
This section presents a simulation study on the robustness of the proposed St RSTP prediction algorithm , compared with that of the STRE algorithm . In this work , we considered the same simulation model as employed in recent STRE related papers [ 2 ] , [ 16 ] , to generate spatio temporal simulation data . The spatial domain was designed as one dimension and had the observation locations , D = {s : s = 1,··· , 256} . The temporal domain had the observation timestamps t = 1 , 2,··· , 50 . We assumed that the trend component μ(s ; t ) was zero and simulated the processes Y ( s ; t ) and Z(s ; t ) according to Equations ( 2 ) and ( 3 ) . The small scale ( autoregressive ) process {ηt} was generated by the matrix parameters H and U . The spatial basis functions S were defined by 30 W wavelets from the first four resolutions .
We considered two types of outliers , isolated outliers and regional ( cluster of ) outliers . For isolated outliers , we randomly picked locations and timestamps , and then shifted the observation to a larger value 5 . We generated cases with 5 , 15 , and 35 random outliers . For regional outliers , we fixed the center of the region and set region sizes ( number of outliers ) to 5 , 15 , and 35 . The temporal dimension of the region was fixed to a 6 units window . Note that , other combinations of the time and spatial locations had also been tested and similar patterns were observed .
Observation Z
Contaminated Z
St−RSTP Ysr
STRE Ys
6
4
2
0
−2
−4
0
6
4
2
0
−2
−4
0
6
4
2
0
−2
−4
0
50
100 s
150
200
250
( a ) t = 4 , 5 regional outliers
50
100 s
150
200
250
( b ) t = 7 , 35 regional outliers
50
100 s
150
( c ) t = 44 , 35 isolated outliers
200
250
Figure 3 : STRE vs . St RSTP using simulation data
1 ) Simulation Results : We conducted both St RSTP and STRE smoothing , filtering , and forecasting in a variety of simulated scenarios with isolated and regional outliers . Several case studies are discussed as follows . Figure 3 illustrates the impacts of isolated and regional outliers on the filtering algorithms at three different timestamps with various number of outliers . Each sub figure has four curves that are related to the original observations Zt , the contaminated observations ˜Zt , the filtered values Y(s ) via the regular STRE algorithm , and the filtered values Y(sr ) via our proposed St RSTP algorithm , respectively . The X axis
314157 refers to location index , with totally 256 distinct locations . The Y axis denotes the Z values . The symbol t refers to time stamp . As shown in the figures , with the increasing number of outliers , the STRE curve was clearly distorted at an increasing degree . On the contrary , our proposed robust filtering algorithm demonstrated strong resilience to outlier effects . Even in the situation of high rate contaminations ( 35 isolated outliers , around 13 % percentage in Figure 3(c) ) , our proposed algorithm could still recover the latent random variables Yt very well .
Figure 3 ( a ) and ( b ) illustrates the impacts of regional outliers on the two filtering algorithms with different outlier region size . When the outlier region size was small ( 5 adjacent outliers ) , our proposed robust filtering algorithm performed very well , whereas the STRE filtering algorithm was already misguided by the outliers and the filtered curve segment around the outlier region was clearly distorted . On the other hand , outside the outlier region , the filtered curve generated by St RSTP was almost identical to the filtered curve generated from the STRE filtering algorithm . This indicates that when there are no outliers , our algorithm performs similarly as the regular STRE model , but when outliers appeared , our algorithm tends to be more resilient to the outliers .
However , we also observed that large region outliers have significant impacts on both the STRE and St RSTP , in Figure 3 ( b ) . When we increased the region size to 35 , both StRSTP and STRE filtering algorithms were misguided and the filtered values around the outlier region were close to outlier values . This could be interpreted by the STRE model assumptions ( See Section II A ) that define spatio temporal dependencies between Z(si ; u ) and Z(sj ; t ) , with i = j or u = t . Particularly , the STRE model assumes a Markov Gaussian process to model spatial dependencies between Z(si ; t ) and Z(sj ; t ) , i = j . Observations will have a high spatial correlation if they are spatially close . For temporal dependency , the STRE model assumes a first order Markov process . That is , except for the dependence on the other locations at the current time t , Z(s ; t ) is also dependent on its previous time stamp observations Zt−1 . To conclude , the STRE model considers spatial Gaussian process , log 1 temporal autocorrelation , and white noise ( Gaussian distribution ) to model the whole data variation . Spatiotemporal outliers can be interpreted as the observations that have low correlations with their spatio temporal neighbors and can not be regarded as the normal measurement error ( white noise ) . When a data set has outliers , for the standard STRE model the additional variations due to outliers will be captured by distorting the spatio temporal dependencies . The white noise component can not handle large deviations due to the non heavy tail distribution characteristics . This explains the distorted STRE curves as shown in Figures 3 . A specific spatio temporal autocorrelation pattern is associated with certain degree of sharpness of the resulting filtered curves . In comparison , our St RSTP model uses Student ’s
Table I : Model Robustness Comparison using Different Simulation Settings
Outlier Size MAPE(sr ) MAPE(s ) RMSE(sr ) RMSE(s ) MAPE(sr ) MAPE(s ) RMSE(sr ) RMSE(s ) Type
5 Isolated 15 Outliers 35 Regional 5 Outliers 35
( O ) 1.2554 1.3436 1.6939 2.1965 132.14
( O ) 2.1253 4.8988 7.7223 14.047 138.94
( O ) 0.3534 0.3313 0.3497 0.5454 4.5852
( O ) 0.7105 0.8400 1.2457 3.4465 4.7571
( R ) 6.5712 6.6204 6.7262 6.6423 7.2288
( R ) 10.656 20.061 11.337 11.050 10.824
( R ) 0.2468 0.2466 0.2498 0.2536 0.2537
( R ) 0.3341 0.3575 0.4085 0.3938 0.3301
Table II : Model Robustness Comparison use the AOD Data
MAPE MAPE MAPE RMSE RMSE RMSE
( O )
( R )
( A )
( O )
( R )
( A )
3.3475 3.9940 3.9682 0.4309 0.3799 0.3821 STRE St RSTP 2.2176 2.1619 2.1641 0.3322 0.3244 0.3247 improve 33.8 % 45.9 % 45.5 % 22.9 % 14.6 % 15.0 % t distributions to model white noise ( or the measurement error ) . When outliers appear , our St RSTP model directly captures the additional large variations due to outliers as white noise . When the outlier region becomes large , however , it becomes possible to directly use the spatio temporal autocorrelations to capture the outlier variations . Intuitively , we are able to use a smooth curve to fit the observations well . This potentially explains why the St RSTP model could not recover the true Y values around the outlier region , when the outlier region size was large .
Table I illustrates the robustness of the filtering algorithms based on different settings of outliers . In this table , ( O ) refers to outliers , and ( R ) refers to non outliers . It can be observed that St RSTP algorithm always outperformed the STRE filtering algorithm in all the scenarios we have experimented . Although we observed the similar results for 1 step forecasting , we only present the forecasting results for the real data sets due to the space limit .
C . Aerosol Optical Depth Data Experiments
The AOD data set was collected by NASA ’s Terra satellite with MISR ( Multi angle Imaging Spectro Radiometer ) on board . Because the AOD data are heavily right skewed , we applied log transformation log(AOD ) to convert the 40day level 3 data ( with spatial resolution ( 05◦×05◦ ) and temporal resolution ( 1 day ) ) into a close to symmetric distribution . Each time unit is defined as an exclusive eight day period . We focus on the data collected in a rectangle region ◦ and between latitudes D between longitudes 14 ◦ , as shown in Figure 4(a ) . The number of level14 3 observations ( pixels ) in the region is 32 × 64 = 2048 . Other geographical regions had also been studied and similar patterns were obtained .
◦ and 46
◦ and 30
In order to evaluate the robustness of different filtering and forecasting algorithms on the AOD data , we randomly set 5 % locations in every timestamp and replaced the observations with value 5 , which is outside the normal range of the observations ( −0.0843 ± 04958 )
315158
A similar STRE model specification as used in [ 2 ] was applied in this simulation . We detrended the observations Zt by the residuals Zt − Xtβ to Zt . After this process , the observations Z no longer had trend components and could be called as detrended observations . The unknown parameters ε , K1 , and {Ht , Ut} , t = 1,··· , 5 , in basis functions σ2 S were estimated by using the EM estimation algorithm proposed by [ 16 ] .
Figures 4 illustrate the robustness of our St RSTP filtering and forecasting algorithms compared with that of the regular STRE algorithms at timestamp t = 5 . Figure 4(a ) shows our study region , which was within the white box on the map . Figure 4(b ) shows the heatmap of the detrended observations Zt=5 . Figure 4(c ) displays the contaminated observations ˜Zt=5 , in which we injected an red color outlier dots in the image . Figure 4(d ) shows the STRE filtering results on the clean detrended observations Zt=5 , and Figure 4(e ) displays the STRE filtering results on the contaminated observations ˜Zt=5 . Figure 4(f ) shows the St RSTP filtering results on ˜Zt=5 . By comparing Figure 4(e ) and ( f ) with the original filtering results shown in Figure 4(d ) , we can observe that the regular STRE filtering results were clearly distorted by the region outliers round the neighborhood area . However , our St RSTP filtering results in Figure 4(f ) were still very close to the original filtering results in Figure 4(e ) . Similarly , the 1 step forecasting results in Figure 4(g ) and 4(h ) showed that the St RSTP produced more accurate prediction than the STRE .
To demonstrate the results in a more comprehensive way , Table II presents the average results on all the five time units , where ( O ) refers to outlier region , ( R ) refers to non outlier region , and ( A ) refers to all the region . It can be clearly observed that the St RSTP achieved much lower MAPE and RMSE than the STRE filtering algorithm in both outlier and nonoutlier regions .
D . Case Study on Traffic Volume Data
The traffic volume data were collected in the City of Bellevue , WA . The data was managed by the Smart Transportation Application and Research Laboratory ( STAR Lab ) at the University of Washington , Seattle . In this set of experiments , 17 detectors located in NE 8th Ave was selected as the test route because it ’s a major city corridor , with annual average weekday traffic of 37,700 ( veh/day ) . Weekday data ( Tuesday , Wednesday and Thursday ) collected from first two weeks of July , 2007 were used for training and the last two e d u t i t a L
10
20
30
40
50
60
70
80
90
100 e d u t i t a L
5
10
15
20
25
30 e d u t i t a L
5
10
15
20
25
30
20
40
60
80
100
Longitude
120
140
160
180
10
20
30 Longitude
40
50
60
1.5
1
0.5
0
−0.5
−1
−1.5
( a ) Study Region
( b ) Detrended Observation Zt=5
1.5
1
0.5
0
−0.5
−1
−1.5 e d u t i t a L
5
10
15
20
25
30
1.5
1
0.5
0
−0.5
−1
−1.5
10
20
30 Longitude
40
50
60
( f ) St RSTP Filter on ˜Zt=5
10
20
30 Longitude
40
50
60
( e ) STRE Filter on ˜Zt=5 e d u t i t a L e d u t i t a L
5
10
15
20
25
30
5
10
15
20
25
30
10
20
30 Longitude
40
50
60
( c ) Contaminated ˜Zt=5
10
20
30 Longitude
40
50
60
( g ) STRE Forecast on ˜Zt=5
1.5
1
0.5
0
−0.5
−1
−1.5
1.5
1
0.5
0
−0.5
−1
−1.5
Figure 4 : STRE vs . St RSTP on AOD data sets at time unit 5
10
20
30 Longitude
40
50
60
( d ) STRE on Zt=5 e d u t i t a L
5
10
15
20
25
30 e d u t i t a L
5
10
15
20
25
30
10
20
30 Longitude
40
50
60
( h ) St RSTP Forecast on ˜Zt=5
1.5
1
0.5
0
−0.5
−1
−1.5
1.5
1
0.5
0
−0.5
−1
−1.5 weeks of June , 2007 were used for cross validation . The verification data were collected during the first week of July in 2008 . In this study , all data were aggregated into 5 minute intervals to reduce the effect of random noise . In total , the detector data collected on on 17 detectors within 5376 time intervals were evaluated .
Observation Z St−RSTP Forecast St−RSTP Filter STRE Forecast STRE Filter e m u o V l
2000
1500
1000
500
0 5 AM
7 AM
9 AM
11 AM
1 PM Time
3 PM
5 PM
7 PM
9 PM
( a ) t = 5th day , detector #3
600
500
400
300
200
100
0 e m u o V l
Observation Z St−RSTP Forecast St−RSTP Filter STRE Forecast STRE Filter
5 AM
7 AM
9 AM
11 AM
1 PM Time
3 PM
5 PM
7 PM
9 PM
( b ) t = 5th day , detector #16
Figure 5 : STRE vs . St RSTP using the TV data on 5th day
Figure 5 shows the comparison results on two detectors with different real world outlier rates . The X axis refers to the 192 timestamps from 5 am to 9 pm , and the Y axis
316159 refers to the traffic volume , aggregated at 5 minute intervals . Figure 5(a ) shows the traffic volume from detector #3 with one significant spike reached 1900 around 9 am , which was probably caused by malfunctioning . On this detector , the STRE filtering algorithm had a spike over 500 triggered by the outlier , and its 1 step forecasting had a even higher spike right after the real one . On the other hand , the St RSTP smoothed the spike to around 300 , which is closer to their spatial neighbors . The St RSTP 1 step prediction produced the volumes very similar to its smoothed curve . Figure 5(b ) shows the results on detector 16 with vibrating volumes throughout the day . Because this detector was located close to detector #3 on the same route , the outlier on detector #3 affected the STRE process on detector #16 . As can be observed from the figure , the STRE approach had a significant spike on the filtering curve at exactly the same time when the outlier appeared on detector #3 ; and a higher spike on the forecasting curve right after the outlier appeared . On the contrary , although the St RSTP did filtering and forecasting by considering spatial and temporal neighbors as well , its process successfully resisted the impact from the spatially neighboring outlier . Besides that , one can also notice that the St RSTP handled the vibrations on the original volume more smoothly than the STRE . More specifically , the St RSTP forecasting gave smoother volumes than its filtering . This suggested that both St RSTP filtering and forecasting are robust on the temporal domain . These patterns are consistent with what we observed from the simulation study and the AOD results .
E . Time Cost
Table III presents the execution time comparisons between our St RSTP model and regular STRE model . The comparisons are under Windows 7 Professional 64 bit operating system , Intel core i7 Q740 , 1.73GHz ( CPU ) , 8.00 GB ( RAM ) . We compare all the scenarios in simulation data and the whole set in AOD data . The result shows that the St RSTP can reach ten times in execution time comparing to that of STRE algorithms under all tested simulation data scenarios . But in the AOD dataset , St RSTP outperformed demonstrated in extensive experiments evaluations based on both simulation and real life data sets . The proposed approach provides critical functionality for stochastic processes on spatio temporal data .
ACKNOWLEDGMENT
The authors would like to thank the City of Bellevue , Washington for providing arterial traffic data . The authors are also grateful to the STAR Lab for maintaining the arterial database and providing the online portal to access the data .
REFERENCES
[ 1 ] N . Cressie and C . Wikle , Statistics for Spatio Temporal Data .
Wiley , 2011 , iSBN 978 0471692744 .
[ 2 ] N . Cressie , T . Shi , and E . L.Kang , “ Fixed rank filtering for spatial temporal data , ” Journal of Computational and Graphical Statistics , vol . 19 , no . 3 , pp . 724–745 , 2010 .
[ 3 ] R . H . Shumway and D . S . Stoffer , Time Series Analysis and
Its Applications With R Examples . Springer , 2006 .
[ 4 ] I . A . J . B . Juha K . Laurila , Daniel Gatica Perez and O . Bornet , “ The mobile data challenge : Big data for mobile computing research , ” In Proc . Mobile Data Challenge by Nokia Workshop , in conj . with Int . Conf on Pervasive Computing , 2012 . [ 5 ] N . Cressie and C . Wikle , “ Space time kalman filter , ” Ency clopedia of Environmetrics , vol . 4 , pp . 2045–2049 , 2002 .
[ 6 ] M . Gandhi and L . Mili , “ Robust kalman filter based on a generalized maximum likelihood type estimator , ” IEEE Transactions on Signal Processing , vol . 58 , pp . 2509–2520 , 2010 .
[ 7 ] Y . Ruan and P . Willett , “ Practical fusion of quantized measurements via particle filtering , ” IEEE Aerosp . Conf . , 2003 . [ 8 ] R . Maronna , R . Martin , and V . Yohai , Robust Statistics :
Theory and Methods .
John Wiley Sons , Ltd , 2006 .
[ 9 ] J . Durbin and S . J . Koopman , “ Monte carlo maximum likelihood estimation for non gaussian state space models , ” Biometrika , , vol . 84 , pp . 669–684 , 1997 .
[ 10 ] P . Jylanki , J . Vanhatalo , and A . Vehtari , “ Gaussian process regression with a student t likelihood , ” Journal of Machine Learning Research , p . Accept for Publication , 2011 .
[ 11 ] C . M . Bishop and M . Svensen , “ Robust bayesian mixture modelling , ” Neurocomputing , vol . 64 , pp . 235–252 , 2005 .
[ 12 ] A . Y . Aravkin , B . M . Bell , J . V . Burke , and G . Pillonetto , “ An 1 laplace robust kalman smoother . ” IEEE Trans . Automat . Contr . , vol . 56 , no . 12 , pp . 2898–2911 , 2011 .
[ 13 ] C . M . Bishop , Pattern Recognition and Machine Learning . Secaucus , NJ , USA : Springer Verlag New York , Inc . , 2006 . [ 14 ] A . Ypma and T . Heskes , “ Novel approximations for inference in nonlinear dynamical systems using expectation propagation . ” Neurocomputing , vol . 69 , pp . 85–99 , 2005 .
[ 15 ] P . J . Green , “ Iteratively Reweighted Least Squares for Maximum Likelihood Estimation , and some Robust and Resistant Alternatives , ” J ROY STAT SOC B , vol . 46 , no . 2 , 1984 .
[ 16 ] M . Katzfuss and N . Cressie , “ Spatio temporal smoothing and em estimation for massive remote sensing data sets , ” Journal of Time Series Analysis , vol . 32 , no . 4 , pp . 430–446 , 2010 . [ 17 ] V J . Hodge and J . Austin , “ A survey of outlier detection methodologies , ” Artificial Intelligence Review , vol . 22 , 2004 . the regular STRE algorithms in the all 5 time units . Our St RSTP algorithm estimated small scale and micro scale variation separately . The estimation went through all the timestamps one by one , so it would cost less time and outperform STRE in a dataset with fewer timestamps .
Table III : Comparison of Time Cost using the Simulated and AOD Data
Dataset
Outliers ( # ) STRE ( Sec ) St RSTP ( Sec ) a t a D n o i t a l u m S i
Isolated Outliers
Regional Outliers
AOD Data
5 15 35 5 15 35 5 %
2.95 3.03 3.14 2.72 2.87 2.88 69.07
29.10 29.19 29.64 28.28 28.54 28.28 26.58
Note : The simulated data has 256 locations and 50 time units . The AOD data has 2048 locations and 5 time units .
On the other hand , time costs of St RSTP and STRE on the simulation data with various location sizes are illustrated in Figure 6 , where the X axis shows the number of locations in log scale , and the Y axis represents the execution time in seconds . As can be clearly observed , both St RSTP and STRE had increased time costs when the number of locations grew up . Although the St RSTP took longer to execute when the number of locations changed from 32 to 1024 , the St RSTP has shown better scalability than the STRE as the time differences reduced from tens of times to about 30 % .
STRE St−RSTP
180
160
140
120
100
80
60
40
20 s d n o c e S
0 32
64
128 Number of Locations
256
512
1024
Figure 6 : Time Cost vs . Number of Locations
VI . CONCLUSION
This paper proposes a robust and effective design of spatio temporal prediction based on Student ’s t distribution , St RSTP . This prediction model inherits the ability of processing large scale spatio temporal data with linear time complexity from STRE , and provides enhanced tolerance to outliers or other small departures . An approximate inference approach in the framework of Expectation Propagation is proposed to support the analytical intractable inference of Student ’s t model in near linear time . The robustness and the efficiency of our Student t based prediction model have been
317160
