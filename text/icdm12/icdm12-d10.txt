Diffusion of Information in Social Networks : Is It All Local ?
Ceren Budak , Divyakant Agrawal , Amr El Abbadi
Department of Computer Science , UCSB
Santa Barbara , USA cbudak,agrawal,amr@csucsbedu
Abstract— Recent studies on the diffusion of information in social networks have largely focused on models based on the influence of local friends . In this paper , we challenge the generalizability of this approach and revive theories introduced by social scientists in the context of diffusion of innovations to model user behavior . To this end , we study various diffusion models in two different online social networks ; Digg and Twitter . We first evaluate the applicability of two representative local influence models and show that the behavior of most social networks users are not captured by these local models . Next , driven by theories introduced in the diffusion of innovations research , we introduce a novel diffusion model called Gaussian Logit Curve Model ( GLCM ) that models user behavior with respect to the behavior of the general population . Our analysis shows that GLCM captures user behavior significantly better than local models , especially in the context of Digg . Aiming to capture both the local and global signals , we introduce various hybrid models and evaluate them through statistical methods . Our methodology models each user separately , automatically determining which users are driven by their local relations and which users are better defined through adopter categories , therefore capturing the complexity of human behavior .
Keywords social networks ; diffusion models ; diffusion of innovations ; gaussian logit curve ; firth logistic regression
I . INTRODUCTION
The advent of online social networks has generated an ever increasing interest in understanding how and why people share information online . Such an understanding can help devise methods to maximize [ 1 ] or control [ 2 ] the reach of an information item or even build social networks that provide the right tools for sharing information . Various models have been introduced to tackle this problem [ 3 ] , [ 1 ] , [ 4 ] , [ 5 ] , [ 6 ] , [ 7 ] , [ 8 ] . All these models aim to explain the behavior of a given user by the behavior of his/her friends . This entails making the simplification of modeling users as being aware of only their immediate surrounding .
The goal of building models of diffusion is hardly new , however . Social scientists have long been building models to study the diffusion of innovations . Although the theory of diffusion of innovations brings up the importance of friendship relations , it reaches beyond that and identifies various other characteristics of human behavior that are vital to this process . For instance , it categorizes people into one of five categories , innovators , early adopters , early majority , late majority and the laggards , based on their innovativeness . This categorization is done on the basis of how early/late a person adopts an innovation with respect to the rest of the population . Therefore , adoption behavior is explained not solely based on friend behavior but based on the behavior of the entire population . One of the most interesting findings of this research [ 9 ] , is that users belong to one of the five adopter categories irrespective of the innovation . This means that an innovator will lead and not follow an innovation no matter what the nature of the innovation is . Similarly a laggard is intrinsically reluctant to adopt an idea before a large population has done so .
With the advent of online social networks , researchers largely moved away from this point of view and moved on to local models where the behavior of users are explained by the events in their local neighborhood . In this paper , we question the generalizability of this approach and make a case for the re integration of global characteristics for better understanding user behavior . To this end , we first study two representative local models [ 3 ] , [ 10 ] in two different online social networks ; Digg and Twitter and show that such models are inadequate in capturing user behavior . Driven by the lack of fit of the local models and inspired by research in the diffusion of innovations , we propose a novel diffusion model called Gaussian Logit Curve Model ( GLCM ) that models user behavior with respect to the entire population and captures the innovativeness of a given user based on its actions . We test the fit of GLCM in Twitter and Digg and show a better fit compared to the local models , especially in the case of Digg . To bridge the gap between the two perspectives , we introduce various hybrid models that incorporate the social effect as well as the global awareness . Through the use of various statistical methods and prediction , we show that the hybrid models perform significantly better than the local models while performing slightly better than GLCM . For instance in Twitter , prediction results show that the two local models have a value of at least 0.8 AUC ( which corresponds to good prediction ) for only 11 % and 8 % of the users respectively while this number is 76 % for GLCM , and around 84 % for the hybrid models . With a per user modeling technique where each user is captured by the best model that fits them , this number reaches 92 % .
We envision modeling as capturing the characteristics of each user rather than aiming to find one parameter , or even one model , to capture all users . Through a per user modeling approach , our methods are able to capture the behavior of every user with the model that best fits them rather than applying a one model fits all technique . Overall , our approach , which uses a cross social networks analysis methodology , challenges the current single model approach and thus the generality of many commonly used social influence models . Through testing of various models on different networks , we believe our work takes the first step for creating a general and practical framework to evaluate diffusion models .
II . RELATED WORK
Here we give an overview of the diffusion of information research , focusing on two distinct high level approaches :
Diffusion of Information and the use of local models In recent studies , diffusion in social networks is generally modeled with local models , ie models in which the decision of adoption for a given user is a function of adoptions in its local neighborhood . One such model defines the odds of adoption for a given user as a linear function of the number of friends that have already adopted the information [ 3 ] . Details about this model are given in Section IV . The independent cascade model ( ICM ) is another well studied diffusion model that has been used in various studies [ 1 ] . In this model , different from [ 3 ] the probability of adoption at a given time is dependent on only the friends that have newly adopted the information rather than all friends that have so far adopted it . This model has been extended to consider various notions such as time [ 4 ] , [ 5 ] , [ 6 ] or exogeneity [ 11 ] . Watts et al . study a similar model and argue for the value of critical mass of easily influenced people [ 12 ] . Other local models include , but are not limited to epidemiological models [ 13 ] and markov chain models [ 7 ] .
Diffusion of Innovations and the use of global models As sophisticated and diverse as the local influence models became , these models still capture users as beings that interact with and are aware of only their local neighborhood . This clearly is not the case in real world where people are exposed to information through channels outside their social networks friends . Not only is it that people have channels to get information about the innovations spreading through the general crowd , their behavior in adoption can vary wrt the behavior of the general crowd . This notion has been captured by the diffusion of innovations theory introduced by Rogers [ 9 ] that seeks to explain how , why , and at what rate new ideas and technology spread through cultures . For this purpose , the notion of rate of adoption has been introduced which can be seen as the relative speed at which people adopt new adoptions . The population is categorized into 5 adopter categories , namely innovators , early adopters , early majority , late majority and laggards . As introduced by Rogers and later analyzed in various contexts [ 14 ] , [ 15 ] , this categorical behavior is an innate property . For instance an innovator will act as an innovator no matter what the innovation , whereas a laggard will be late in adopting innovations in general . The diffusion process explained by Rogers was later defined in a mathematical way in the Bass model [ 16 ] and expanded to study innovations of different nature in a large number of follow up works [ 14 ] , [ 15 ] . Mansfield introduced deterministic and stochastic models similar to the Bass model [ 17 ] . Compared to the Bass model , Mansfield captures a larger pool of characteristics such as profitability and investment size . Unlike these models , our work models user behavior rather than simply capturing the number of adopters for an item .
III . DATA SETS
The process through which information diffuses can differ based on the network the information is propagating on . Therefore , we believe a clear understanding of diffusion behavior can only be captured through a cross network study . Our work takes the first step in this direction by studying two networks of different characteristics ; a study we aim to extend by analyzing more networks as future work . Here we will give an overview of the two networks studied in this paper .
Digg : Digg is a social news aggregator . It provides means for its users to submit stories and vote on them . Of those stories , it promotes the ones that receive many votes to the front page . In addition to providing means for users to share stories , Digg also allows users to create social networks by adding other users as friends . Using the friends interface , a user can see the stories her friends recently voted for or submitted . In our experiments we used 3553 stories promoted to the front page in June 2009 as well as the social connections between the Digg users [ 18 ] . Each story in this data set contains a list of voters as well as the time of the vote . Since the models we examine are discrete time models , the data should be fragmented into time frames . A large number of digg stories take about a day to receive a large population of the votes[19 ] . Therefore , we choose hourly time frames to model this network . Adoption in the context of Digg is defined as voting on a story .
Twitter : We use a Twitter data set [ 20 ] of 467 million tweets from 20 million users spanning a 7 month period as well as the social network graph [ 21 ] which provides the connections between the users sharing these tweets . Adoption in this work is defined as using a hashtag for the first time . There are approximately 10 million distinct hashtags in the Twitter data set . Since the goal is to identify the first time a hashtag is used , hashtags that were used in the first 7 days in our data set were eliminated from the analysis to eliminate hashtags that might have been introduced before the start date of our data collection , including hashtags with weekly patterns ( such as #followfriday ) . Of those , we evaluate 1326 hashtags that have been adopted by at least 500 users . Over 1.3 million users used at least one of those hashtags . The lifespan of a hashtag is much longer than the life span of stories in the context of Digg , therefore daily time frames were selected for Twitter . the probability p(xl f m ) of activation for an agent with xl f m already active friends can be defined as [ 3 ] :
IV . LOCAL MODELS
We study the problem of progressive diffusion where the users who adopt an item become active and do not become inactive again . We denote users who have adopted an item i as being active in i . Our goal in this section is to study the models that assign a probability of adoption for each user given the actions of their friends . Although we believe that it is a worthwhile practice to create a platform in which all local models can be tested and compared , this task is outside the scope of our paper . Instead , we choose two representative models that have been used to study various networks [ 3 ] , [ 10 ] . Unlike related work [ 3 ] , we develop and test models for each user rather than each information item since the understanding achieved for a given information item cannot be generalized and applied to a new item . In fact , related work in Flickr [ 3 ] , as well as our preliminary per item analysis , show that social correlation can vary significantly across different information items . Therefore , the benefits of per item modeling fall short . However , identifying per user characteristics can help make better predictions for future information items . Therefore , in this paper we focus our efforts on per user modeling .
A . Model Definitions
Linear Friendship Model ( LFM ) : Influence of friends are generally modeled to be additive . For instance , the independent cascade model ( ICM ) states that a node with a active friends has a independent chances of becoming active [ 1 ] . This additive property is also captured in the Linear Threshold Model ( LTM ) , where a node v is influenced by each neighbor w according to a weight bv,w [ 1 ] . The model given in Equation 2 , captures this additive effect while not restricting the node activation to only the time steps with newly activated friends [ 3 ] . For ease of reference , we call this model Linear Friendship Model ( LFM ) . LFM defines the odds of adoption as a linear function of the number of already active friends the agent has . Logistic regression is a natural candidate for fitting such a linear explanatory function to a probability value between 0 and 1 . Transformation of the output of a linear regression with k explanatory variables x1 , x2 , , xk to a value in the range of [ 0,1 ] can be performed using a logit link function as follows : logit p = log
= β0 + β1x1 + β2x2 + + βkxk
( 1 ) p 1− p
For real valued explanatory variable xi , βi reflects the log odds of improvement for one unit of increase in the value of xi . The inverse of the logit function is the logistic function ( if logit(p ) = z , then p = ez 1+ez ) . Since the Linear Friendship Model uses the number of active friends as an explanatory variable , its logit can be defined as : αl f m ∗ xl f m + β where xl f m is the number of currently active friends . Therefore , p(xl f m ) = eαl f m∗xl f m+β
1 + eαl f m∗xl f m+β
( 2 ) i,m,t i,m,t and SI
The coefficient αl f m measures social correlation : a large value of αl f m indicates a large degree of correlation . The values for β and αl f m can be estimated as follows : Consider a user ui . Let SA i,m,t be the active item set for ui at time t for m friends . An item item j ∈ SA if and only if ui has not adopted item j by time step t − 1 , m of friends of ui have already adopted item j by this time step and ui became active in item j at time step t . Similarly , an item itemk is in the inactive set SI i,m,t if and only if ui has not adopted itemk by time step t − 1 , m of friends of ui have already adopted itemk by this time step and ui became still did not become active in itemk at time step t . Let Ai,m,t and Ii,m,t be the number of elements in sets SA i,m,t respectively . We aggregate these values to compute Ai,m = ∑t Ai,m,t and Ii,m = ∑t Ii,m,t . Given Ai,m and Ii,m values for all possible active friend counts m for ui , our goal is to find β and αl f m values that maximize ∏m(p(m)Am(1− p(m)Im) ) .
Friend Saturation Model ( FSM ) : The notion of additive influence of friends was challenged in a recent study [ 10 ] which claims that multiple exposures to a Digg story only marginally increase the probability of voting for it . In fact , the effect of multiple recommendations by friends quickly saturates and is approximated as constant . The Friend Saturation Model [ 10 ] , which addresses this notion , can be formulated as another logistic regression with one categorical explanatory variable x f sm ( x f sm = 0 for no active friends and x f sm = 1 for at least one active friend ) . Here α f sm captures the log odds improvement of having at least one active friend in the activation of a given node .
In this section we test the validity of these two local influence models on Twitter and Digg data sets .
B . Methodology : Firth Logistic Regression
Logistic regression can be performed in a number of ways . Exact logistic regression [ 22 ] is not commonly used due to its complexity . Instead , researchers mostly turn to maximum likelihood logistic regression that proceeds in iterations to minimize the deviance of the resultant model . This technique has been used to model the social correlation of tags in Flickr [ 3 ] . However , modeling user behavior in social networks and capturing social correlation introduces new challenges that maximum likelihood logistic regression fails to address . For one , adoption behavior per user is fairly sparse in social networks and it has been shown that with small to medium sized data sets there can be cases where the maximum likelihood logistic regression converges , while at least one parameter estimate is infinite . This occurs when the responses ( y= 1 ) and non responses ( y=0 ) can be perfectly separated by one of the explanatory variables or by a nontrivial linear combination of a subset of the variables [ 23 ] . There are two types of separation problems ; complete and quasi complete separation . While complete separation is not a problem for LFM and FSM , our analysis shows that the maximum likelihood approach for LFM suffers from quasicomplete separation problems for 3279 users ( ≈ 8 % ) in Digg while this number is 253(≈ 1.4 % ) in Twitter . Similarly , maximum likelihood for FSM fails for 3624 users in Digg and 289 users in Twitter . This issue occurs when there exists some coefficient βi such that βixi ≥ 0 whenever yi = 1 , and βixi ≤ 0 whenever yi = 0 , and equality holds for at least one case in each category of the dependent variable . There are a number of ways to approach a separation problem in logistic regression . One solution is to eliminate the problematic explanatory variable . Unfortunately this is not a feasible option for LFM or FSM since they have only one explanatory variable . Another approach is to use exact logistic regression . However , this solution is not feasible either due to its time complexity . Instead , we apply Firth ( bias reduced ) logistic regression which was originally developed to reduce the bias of maximum likelihood estimates [ 23 ] .
The maximum likelihood estimates of each regression parameter β j in a parameter vector β are obtained by solving the score function ∂ log L/∂β j ≡ S(βi ) = 0 where L is the likelihood function . Let Y be a vector of m observations is the ith observation in a given dataset . Let where yi X be a mxk matrix where xi , j denotes the value of the jth explanatory variable for the ith observation . Using the logistic regression model the probability of yi values can be defined as : P(yi = 1|xi , β ) = pi = e where β is xi , j β j xi j β j the parameter vector . The score equation used by maximum likelihood logistic regression to calculate such values can be given as S(β j ) = ∑m i=1(yi − pi)xi , j . In contrast , Firth logistic regression replaces the scoring function with [ 23 ] :
∑k j=1 ∑k j=1
1+e
S(β j)′ = m
∑ i=1
( yi − pi + hi(
1 2 − pi))∗ xi , j where hi are the ith diagonal elements of the matrix H = W 1/2X(X TW X)−1X T W 1/2 and W = diag(pi(1− pi) ) . Given this scoring function , the β estimates can still be obtained using an iterative method . In addition to providing a solution for separation problems by giving estimates ( and corresponding standard errors ) that are always finite , Firth logistic regression is also second order unbiased and has smaller variance than the maximum likelihood estimator . Give these advantages , next we present analysis results for local models using Firth logistic regression . Due to space limitations , we omit the results obtain by traditional maximum likelihood logistic regression which results in a poorer fit in general .
Evaluating the goodness of fit through the likelihood ratio test : Given the results of logistic regression , its statis tical significance can be evaluated through the likelihood ratio test . The deviance D of a model can be used to achieve this goal . In particular , to test a model M with k explanatory variables , the deviance with just the intercept or the null model ( Dnull ) is compared to the deviance of model M ( DM ) . The difference between these two deviance values can be captured as G = χ2 = Dnull − DM where D(M ) = −2 log p(y|M ) for observed values y and model M . The value of G and d f = k ( degrees of freedom ) can be used to obtain the p value of M by a simple table look up . If this value is smaller than 0.05 , the null hypothesis can be rejected , meaning that model M is statistically significant .
C . Regression Results
Regression Results for LFM and FSM in Digg : Bias reduced logistic regression is applied to extract αl f m and α f sm values for 41348 users who have voted on at least 10 stories . The regression task was performed to evaluate LFM with both the number of active friends m and the log of this measure log(m + 1 ) as the explanatory variable . The results were similar but log(m + 1 ) provided a better fit in general and therefore we focus on this case . LFM has statistical significance for 8257 users while this number is 7711 for FSM . The histogram of the αl f m values for the 8257 users that fit LFM are given in Figure 1(a ) . The results point out an interesting trend . Even though a large portion of users ( 5786 out of 8257 ) have positive social correlation , there is a group that has negative social correlation instead . These users are less likely to vote for stories that their friends have already voted for . Due to Space limitations we omit the graph for FSM that shows similar trends .
Regression Results for LFM and FSM in Twitter : For the 19666 users that used at least 20 distinct hashtags , 12028 had a good fit for LFM while this number is 12184 for FSM . This ratio of approximately 3/5 is a more significant result compared to the results obtained for Digg data set . The αl f m values users that pass the likelihood ratio test are given in Figure 1(b ) where most of the values are greater than 1 . The results overall indicate that the social effect is higher in Twitter compared to Digg . However , the behavior of 2/5 of the users still is not captured by the local models . In addition , it is still an open question if the fit can be outperformed by capturing other aspects , such as the possible effect of the actions of the rest of the population .
Due to a large number of users whose behavior is not explained by either LF M or FSM , next we investigate a global model and show its value on Digg and Twitter .
V . GLOBAL MODELS
In his influential book “ Diffusion of
Innovations ” , Rogers [ 9 ] introduces various influential theories including his introduction of 5 categories of adopters : the innovator , early adopter , early majority , late majority and the laggard . The categorization of people into one of these 5 categories p(xglcm ) , the probability of adopting an idea as a function of an environmental variable xglcm that captures the user ’s response to the behavior of the general crowd . For this purpose , we introduce the Gaussian Logit Curve Model ( GLCM ) , in which the logit transform of probability [ 25 ] is a quadratic function as follows : log( p(xglcm ) 1− p(xglcm )
) = b0 + b1xglcm + b2x2 glcm = a−
1
2
( xglcm − µ)2
σ2
( 3 ) where xglcm is the natural logarithm of the total number of people that adopted the idea so far , µ is the optimum point in the innovation curve , defined by the current number of adopters in the entire network , for the given user to adopt the innovation . Tolerance of a user , ie how much the user varies from his/her mean behavior is captured by σ . A low sigma value means that the probability of adoption changes quickly as the current number of adopters in the network moves further from the mean ( µ ) of the given user . The parameter a is related to the maximum value of p(xglcm ) . We choose xglcm as the logarithm of the number of adopters since the number of adopters can be a noisy parameter as it varies largely for different stories . When this maximum value of p(xglcm ) is small the shape of p(xglcm ) is almost identical to that of a Gaussian curve ; when it is close to 1 , the Gaussian logit curve is flatter near the optimum . Since social network adoption data is mostly sparse , the maximum p(xglcm ) value tends to be small hence the use of a quadratic curve fits our goal of classifying user behavior under normal distribution around a mean that determines its adopter category . Using the quadratic model , the optimum mean and deviation values can be extracted from the b values as follows :
µ = b1/(2b2 )
1
σ = p(− 2b2 ) pmax = p(µ ) =
( 4 )
( 5 )
( 6 )
1
1 + exp(−b0 − b1µ− b2µ2 )
These formulas assume that b2 < 0 . For the cases where b2 > 0 the curve has a minimum instead of maximum . These cases model users that have a global minimum instead of a maximum , ie a point in the adoption curve that the user is least likely to adopt an item . We give examples of the fit of global maximum and minimum in Figure 2 . The circles in both the figures represent data points and the curves are the fits for those hypothetical data points . In Figure 2(a ) where b2 < 0 , the user has a global optimum time when e4 others in the network have adopted the idea . On the contrary , Figure 2(b ) shows the odds of adopting an idea for a user who has a global minimum , ie a least likely point in the adoption curve to adopt an idea . Fitting a user to either one of those categories and identifying the global optimum ( or minimum ) can help understand the behavior of a user .
( a ) Digg
( b ) Twitter
Figure 1 . Social Correlation Per User in Digg and Twitter is done based on how innovative they are compared to the rest of the community , defining the behavior of a user in terms of where they lie in the innovation curve .
Before exploring models to capture this notion , we performed a preliminary analysis in which the consistency in user adoption times are evaluated in both Digg and Twitter . For a user ui and item j they adopted , the innovativeness of ui for item j is defined as the percentage of the final number of users to adopt item j by the time ui adopted it . We denote this percentage as ρi , j . Next all such ρi , j values for ui are aggregated and the level of consistency in this set is analyzed . Mean absolute deviation ( MAD ) , a technique that is robust to outliers , is used to evaluate this consistency . For the set ρi,1 , ρi,2 , , ρi,k MAD is defined as the mean of the absolute deviations from the data ’s median . Our analysis shows that for a large population ( 70% ) , MAD is in fact reasonable ( within 20 % ) in Digg while being slightly higher for Twitter . Given that there is consistency in innovativeness of social networks users , next we introduce and evaluate a novel diffusion model that captures this notion .
A . Model Definition
Consider the plot given in Figure 2(a ) which depicts the odds of adoption for a given user as a function of the size of the adoption , ie number of people that have already adopted it . Each circle is a data point giving the fraction of the times the user adopted an item with the given number of adopters . This plot shows that the user has an optimum mean value point in the adoption from which it diverges according to the variance of a normal distribution . Such modeling for each user can help determine their optimum time to adopt an idea therefore capturing the adopter category they belong to in the community . In order to test a fit of such a model for each user , our goal is to identify a technique similar to logistic regression . Unfortunately , it is not possible to use logistic regression as is since it is suited for a linear fit while our goal is to investigate a gaussian distribution fit . In order to approximate the fit of a gaussian distribution for the odds of adoption , we use a technique that has been used in ecology to model species response curves to presence absence data [ 24 ] . Similar to how species are modeled to respond to an ecological variable , we model
This indicates that there are no consistent innovators in our dataset . Instead , there are a large number of laggards that follow others in various hashtags . This can be attributed to the characteristics of Twitter where trending hashtags are reported . Due to space limitations we omit the graph for b2 > 0 which also supports this finding . For b2 > 0 , there are a large number of users with small µ . Such users are unlikely to start an adoption but can lie in various categories that follow the innovators .
VI . ANALYSIS OF GLOBAL AND LOCAL MODELS
Given the outcomes of the regression analysis , we now provide a deeper analysis on the users that have a significant fit to either one of the two local and global models . We first analyzed the tolerance of users modeled by GLCM . The results are presented in Figure 4(a ) for Digg and in Figure 4(b ) for Twitter . Each data point corresponds to a user for whom GLCM was found statistically significant . The Xvalue for a given point is the µ value for that given user while the Y value is the tolerance σ . Digg results show that the tolerance has a multi scaling property . For the µ values between 0 5 there is a general decreasing trend in tolerance measures while for values 5 10 there is an increasing trend . On both ends of the spectrum , there are a large number of users with high tolerance , ie users willing to deviate from their optimum means while users in the middle have little variance . This group can be captured as those users that do not start cascades and yet are not laggards and therefore will not participate in an adoption very late . Twitter users do not exhibit the multi scaling characteristic . There is a consistent increasing trend in tolerance with increasing mean values . There are a large number of Twitter users that could be categorized as laggards but also have a high tolerance value .
( a ) Digg
( b ) Twitter
Figure 4 . Optimum mean vs . tolerance values for GLCM
In order to study the patterns in social connection of different types of adopters , we study the social network graph and analyze the friend relations of users with different µ values . We restrict the analysis here to users for whom the GLCM model is statistically significant and b2 < 0 . The correlation between the global behavior and degree distribution is presented in Figure 5 where each data point with a plus ( + ) marker gives the µ of a specific user ( x value )
( a ) b2 < 0
( b ) b2 > 0
Figure 2 . Global Response Curves
Figure 3 . Distribution of µ∗ as modeled by GLCM for Digg and Twitter
B . Regression Results
GLCM in Digg : The results of Firth logistic regression show that the behavior of a much larger population can be described by the global model ( = 25050 ) compared to LF M ( =8257 ) or FSM ( =7711 ) . This result suggests that the users in Digg have consistent adopter behaviors , ie the timing users choose to vote on a topic wrt the votes from the general crowd is largely independent of the story and mostly a function of intrinsic characteristics of the user itself . The dashed line in Figure 3 represents the cumulative distribution function ( CDF ) of µ values for Digg users for whom GLCM is statistically significant and b2 < 0 . This shows that in Digg there are a large number of innovators that consistently vote on stories early on and a notable number of laggards that are consistently late in voting on stories . The near flat area between µ values 4 6 indicates that there is only a small group whose global optimum is centered in this area .
GLCM in Twitter : A large fraction the population ( 19484 out of 19666 users ) has a good fit for GLCM and of those 11421 users have a µ value between 0 15 . We limit our analysis to only the users with estimated µ values between 0 15 . A user with µ > 15 , has an optimum adoption time when more than e15 users have adopted an item . Since our dataset consists of items whose adoption size is smaller than this value , as a conservative approach , we only count users with µ between 0 15 as a successful fit . The solid line in Figure 3 shows the CDF of µ values for 8846 of such Twitter users with b2 < 0 . There are no users with optimum mean value ≤ 4 , ie there are no users whose highest probability of adoption for an item is when there are ≤ e4 adopters .
Figure 5 . Correlation between in and out degrees of Digg users and their global behaviors versus its in degree ( y value ) . The asterisk ( * ) markers provide for each user the correlation between µ and its outdegree . The distribution of the in degree values show that the innovators early adopters ( users with small µ values ) have a relatively high in degree . This finding is in line with research in diffusion of innovations [ 9 ] . A more interesting pattern is observed for the distribution of out degrees which is largely uniform across different µ values , ( except for µ > 11 with a drop off ) . Since the out degree is the number of people a user follows , which captures potential local influence , the result indicates that the timing of adoption cannot merely be explained by local behavior . Instead , it can be an intrinsic characteristic of users , thus supporting the global model .
Given the interplay between the static friend relations and GLCM , next we explore the correlation between the social correlation ( αl f m ) and global characteristics ( µ ) . Each data point in Figure 6(a ) provides results for a user with a good fit for both LFM and GLCM in Digg . We limit the data points to those with b2 < 0 . The X axis gives the µ value as defined in Equation 4 while the Y axis represents the αl f m values . The larger the global optimum value of a user is , the more they seem to be effected by their friends . Even more interestingly a large fraction of users with small global optimum values , the so called innovators in the context of Digg , have a negative social correlation . The innovators in Digg are likely not to vote on stories that have already been voted on by their friends . We performed the same analysis in the context of Twitter , the results are presented in Figure 6(b ) and indicate that the social correlation measure is mostly positive and strong across different global values .
Nature of Diffusion : Recently , the term “ diffusion ” has been used by the computer science research community to refer to information flowing through friend relations in a social graph . In reality however , diffusion is not restricted to inter network edges . Instead , information can flow from news media or simple offline connections that are not captured in the online world . Defining diffusion through pure local models can result in a myopic depiction of the nature
( a ) Digg
( b ) Twitter
Figure 6 . Correlation between the local and global values of diffusion . Graph properties such as density have been used in recent research to capture the nature of diffusion in different networks [ 26 ] . Therefore we performed a series of experiments in which the mean clustering coefficient and graph density metrics are used to evaluate how well the local and global models capture the nature of information . Since the two metrics provided similar outcomes , we focus on mean clustering coefficient results . The mean clustering coefficient ( ¯C ) of a graph is defined as the average clustering coefficient ( Cu ) of all its nodes . The clustering coefficient Cu for a node u with degree ku in graph G = ( V , E ) is Cu = |{(v,w)|(u,v),(u,w),(v,w)∈E}| . Considering subgraph of nodes that adopted an information item ( story or hashtag ) and the edges between these nodes , this measure gives an indication about the true structure of the diffusion . ku(ku−1 )
In order to evaluate how well LFM , FSM and GLCM capture ¯C , we performed experiments in Digg for which we have access to the full graph . Firstly , the data is divided into training and test data sets where a story is assigned to the training set with 0.8 probability and to the test set otherwise . The models are trained using the training data . Next , for each test story , a thousand simulations were performed given the activity in the first k hours of the story . Each simulation is terminated when there are m number of inactive time steps where no user becomes newly activated . The value of m is learned from the training set . For each such simulation , ¯C of the subgraph of users that are predicted to have adopted the story is computed . The average of such ¯C values for a given story is reported as its predicted mean clustering coefficient . The results of experiments with k = 2 are presented in Figure 7 where each point gives the relation between the actual ¯C ( x axis ) and the predicted ¯C ( y axis ) of a particular story in our test data set . Points with asterisk shaped markers give the results for LFM while the points with a plus sign give the results for GLCM . The 45 degree line provides a reference point for perfect prediction where the actual and the predicted values are the same . For ease of viewing we omit FSM and note that its results were similar to LFM . The results show that local models largely overestimate the clustering coefficient of diffusions while GLCM provides a much better fit . In fact , the normalized root mean square
1√(−2(b2+b3 ) )
III . GLIM ( Global Local Interaction Model ) Models III assume independence between local and global effects . However , when a user has friends that have adopted an item , its µ , σ and pmax values can vary accordingly . For instance , a user with more active friends can have a larger tolerance(σ ) and maximum probability of adoption ( pmax ) values . In order to capture such a case , we introduce GLIM ( Global Local Interaction Model ) where logit(p ) = b0 + b1xglcm + b2x2 glcm + b3x f smx2 glcm . For instance , in this model when a user has no active friends the tolerance can be defined as σ∗ = 1√(−2b2 ) similar to the global model . However , if a user has at least one friend the tolerance is σ∗ = . 13991 Digg users and 13667 Twitter users pass the likelihood ratio test for this model . IV . GausGLM ( Gaussian Global Local Model ) The goal of this model is to capture users who observe the behavior of its friends as well as the global network as a single entity and responds to a combination of these two variables as a gaussian . In this case , the optimal conditions to adopt a campaign is redefined to capture both the local and global signals . The logit of this model can be given as logit(p ) = d + b1xGausGLM + b2x2 GausGLM where xGausGLM = xgclm + xl f m . 24826 Digg users and 19564 Twitter users pass the likelihood ratio test for this model . V . GausGLM2 ( Gaussian Global Local Model 2 ) Similar to GausGLM but uses logit(p ) = d + b1xGausGLM2 + b2x2 GausGLM2 where xGausGLM2 = xgclm + x f sm . This model is statistically significant for 25143 Digg and 19572 Twitter users . Compared to GausGLM , this model puts less importance in the friend effect as the value of x f sm is restricted to values of 0 and 1 while xl f m is practically unbounded .
VIII . MODEL EVALUATION
Model evaluation is a non trivial task . Choosing the best model for predicting future behavior of users among a group of arbitrary models requires more complex methods than simple null hypothesis testing . Our goal is to automate this process that ordinarily requires statistical expert input and scale it to perform model selection per user . We aim to identify the best out of the 8 models studied in this paper for each user . To compare two models where one is a subset of the other , one could use the likelihood ratio test defined in Section IV . Unfortunately , not all of the 8 models are a subset of another ( for instance LFM and GLCM ) . Information theoretic approaches such as Akaike Information Criterion ( AIC ) that incorporate the complexity and the deviance of a given model in deciding the best among various models [ 27 ] can be used to compare arbitrary models . However , these techniques , being restricted to evaluating a given model based on the data set it has been trained with , can still suffer from over fitting . In fact , our analysis in both Twitter and Digg showed that these metrics do not choose the best predictive model in a large number of cases .
Figure 7 . Correlation between the predicted and actual mean clustering coefficient values of Digg stories error ( NRMSE ) for LFM,FSM and GLCM are 0.8 , 0.9 , 0.14 respectively . This shows that the idea that information diffuses through the edges of a social graph does not capture the real nature of information .
VII . HYBRID MODELS
Our analysis of the local and global models indicates that the actions of the local neighborhood and the entire community can have different levels of effect in the adoption behavior of a given user . However , exactly how these two notions interact is not clear . Therefore , in this section , we introduce a number of hybrid models that represent different interactions between the local and global signals . These models are also tested through likelihood ratio tests for the 41348 Digg and 19666 Twitter users . I . LFMorGLCM Consider a user who adopts items either when there are a large number of people in the network that have adopted the item or when there is enough social pressure from its local neighborhood . Such a user can be captured by an additive model where the probability of adoption depends on both the global and the local signals . To this end , we introduce LFMorGLCM : with logit(p ) = b0 + b1xglcm + b2x2 glcm + b3xl f m where xl f m is the natural logarithm of the number of active friends and xglcm is the logarithm of the total number of active users . This model captures users as independently reacting to their local neighborhood and global signals . Our analysis shows that 13990 Digg users pass the likelihood ratio test for this model while this number is 13672 for Twitter . II . FSMorGLCM Since recent research claims that the friendship effect saturates quickly , we also test a different version of the additive model that is a hybrid of FSM and GLCM instead . The logit of this model , named FSMorGLCM , can be given as logit(p ) = b0 + b1xglcm + b2x2 glcm + b3x f sm where x f sm is a categorical value that has value of 0 when there are no active friends and 1 otherwise . 11586 Digg users and 12995 Twitter users pass the likelihood ratio test for this model showing that FSMorGLCM mostly performs worse than LFMorGLCM .
In order to capture the predictiveness of the models , we perform 20 different experiments for each user where the data is randomly divided into test and training sets . Training data consists of 80 % of the data points while the rest is marked as test data . Since a user adopting an item is a rare event , simple methods such as precision are not applicable as an evaluation metric . Therefore , the receiver operating characteristic ( ROC ) is used to evaluate the models . This measure provides a way to trade off sensitivity ( no false negatives ) with specificity ( no false positives ) . The result of ROC analysis can be summarized in one value ; the area under the ROC ( AUC ) . AUC measures the probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one . An AUC value between 05 06 , 06 07 , 07 08 , 08 09 and 0.9 1 can be evaluated as fail , poor , fair , good and excellent respectively .
( a ) Digg
( b ) Twitter
Figure 8 . Area under ROC results for cross validation
The results for Digg and Twitter are provided in Figure 8 . Each curve in this figure corresponds to the CDF distribution of AUC values for a given model across all the users . For instance a point ( x,y ) on a given curve means that y fraction of users have AUC value of less than or equal to x for that given model . For instance in Figure 8(a ) , the intersection point of each curve with the vertical line at x = 0.7 gives the fraction of users for whom the prediction results for the given model performed worse than fair . Therefore , a curve that is closer to the x axis is preferred . Comparing Figures 8(a ) and 8(b ) , it can be seen that the prediction performance for all models are better in Twitter . This is not surprising since the percentage of users with a good fit to one of the models is much higher in Twitter compared to Digg . Also it is obvious that the local models LFM and FSM consistently perform worse than the global and the hybrid models . Of the hybrid models , FSMorGLCM performs the worse while the others have comparable performance . For Digg , GLCM performs very similar to the hybrid models while in Twitter we see some improvement in performance by using one of the hybrid models ( except for FSMorGLCM ) . These results indicate that a hybrid model alone can provide “ some ” added value but the difference is not drastic .
Capturing the “ best ” model through user centric modeling : One of the advantages of performing user centric modeling is that it is not necessary to find one model to fit all users . Instead each user can be captured and tagged with the model that best describes the user . If for each user , the best model is chosen based on their AUC values , the fit can be improved as given by the curves named allmodel in Figures 8(a ) and 8(b ) . For instance , consider the performance of the models in the context of Twitter . The vertical line at x = 0.8 shows that the fraction of users for which the models LFM , FSM , GLCM , LFMorGLCM , FSMorGLCM , GausGLM , GausGLM2 and GLIM perform at least good ( x=0.8 ) on average are 0.1107 , 0.0828 , 0.7680 , 0.8568 , 0.6009 , 0.8393 , 0.8354 and 0.8309 respectively . However , if there is no restriction to use one model to fit all users and rather choose the best model per user , this value reaches 0.9294 as given in the curve named all model . These results demonstrate the importance of capturing each user as a separate entity with distinct intrinsic characteristics .
IX . CONCLUSION
In this paper we studied the diffusion of information in two different networks , Digg and Twitter and investigated the validity of commonly used local influence models . We studied two different local models to address this question . The results indicate that Digg users show little social correlation while Twitter has overall more social correlation . Due to the large number of users whose behavior is not captured by the local model , we introduced a novel diffusion model called Gaussian Logit Curve Model that is inspired by the research in the theory of diffusion of innovations . GLCM captures a user ’s global behavior , ie how fast or slow they vote on stories in Digg or they use hashtags in Twitter compared to the rest of the social network community . GLCM provides significant improvement over the local models for Digg while the results for Twitter , although still impressive , are not as strong as the results for Digg . In order to capture both the local and the global signals we introduce a number of hybrid models . Prediction results show that the hybrid models provide a great improvement over the local models while the improvement is not as pronounced for GLCM .
The results presented in this paper also raise the higher level question for our research community : “ How generalizable are the social influence models that have been used in the area of social networks ? Are we , as a community , too eager to look for social effects in any online tool that simply has a friend button ? ” Given the outcomes of this study , there are various future research directions . As future work , we aim to investigate the effectiveness of maximization of diffusion techniques introduced in the context of purely local models and to construct optimal methods for the per user modeling technique . It is also important to investigate new and efficient techniques for predicting the future popularity of information items based on the new models . Finally , through a cross network , cross model evaluation framework our work takes the first step for a general framework to study models of diffusion . However , as we demonstrated in this study , how well local or global signals reflect user behavior is also a function of the social network studied . Therefore , we believe it is important to enrich this framework by studying other social networks and diffusion models .
ACKNOWLEDGMENT
This work is partially supported by NSF Grant IIS1135389 . The authors would also like to thank ICB at UCSB for access to computing resources .
REFERENCES
[ 1 ] D . Kempe , J . M . Kleinberg , and ´E . Tardos , “ Maximizing the spread of influence through a social network , ” in KDD , 2003 , pp . 137–146 .
[ 2 ] C . Budak , D . Agrawal , and A . El Abbadi , “ Limiting the spread of misinformation in social networks , ” in WWW , 2011 , pp . 665–674 .
[ 3 ] A . Anagnostopoulos , R . Kumar , and M . Mahdian , “ Influence and correlation in social networks , ” in KDD , 2008 , pp . 7–15 .
[ 10 ] G . V . Steeg , R . Ghosh , and K . Lerman , “ What stops social epidemics ? ” in ICWSM , 2011 .
[ 11 ] R . Crane and D . Sornette , “ Robust dynamic classes revealed by measuring the response function of a social system , ” Proceedings of the National Academy of Science , vol . 105 , pp . 15 649–15 653 , Oct . 2008 .
[ 12 ] D . J . Watts and P . S . Dodds , “ Influentials , networks , and public opinion formation , ” Journal of Consumer Research , vol . 34 , no . 4 , pp . 441–458 , 2007 .
[ 13 ] N . Bailey , The Mathematical Theory of Infectious Diseases and its Applications . London : Griffin , 1975 .
[ 14 ] V . Mahajan , E . Muller , and R . K . Srivastava , “ Determination of adopter categories by using innovation diffusion models , ” Journal of Marketing Research , vol . 27 , no . 1 , pp . 37–50 , 1990 .
[ 15 ] V . Mahajan , E . Muller , and F . M . Bass , “ Diffusion of new products : Empirical generalizations and managerial uses , ” Marketing Science , vol . 14 , no . 3 , pp . G79–G88 , 1995 .
[ 16 ] F . M . Bass , “ A new product growth for model consumer durables , ” Manage . Sci . , vol . 50 , pp . 1825–1832 , Dec . 2004 .
[ 17 ] E . Mansfield , “ Technical change and the rate of imitation , ”
Econometrica , vol . 29 , no . 4 , pp . 741–766 , 1961 .
[ 18 ] K . Lerman and R . Ghosh , “ Information contagion : an empirical study of spread of news on digg and twitter social networks , ” in ICWSM , May 2010 .
[ 19 ] G . Szabo and B . A . Huberman , “ Predicting the popularity of online content , ” Commun . ACM , vol . 53 , pp . 80–88 , Aug . 2010 .
[ 20 ] “ Snap : Network datasets : 476 million twitter tweets , ” http :
//snapstanfordedu/data/twitter7html
[ 21 ] H . Kwak , C . Lee , H . Park , and S . Moon , “ What is Twitter , a social network or a news media ? ” in WWW , 2010 , pp . 591– 600 .
[ 4 ] A . Goyal , F . Bonchi , and L . V . S . Lakshmanan , “ Learning influence probabilities in social networks , ” in WSDM , 2010 , pp . 241–250 .
[ 22 ] C . R . Mehta and N . R . Patel , “ Exact logistic regression : theory and examples . ” Statistics in Medicine , vol . 14 , no . 19 , pp . 2143–2160 , 1995 .
[ 5 ] R . Kumar , M . Mahdian , and M . McGlohon , “ Dynamics of conversations , ” in KDD , 2010 , pp . 553–562 .
[ 6 ] G . Kossinets , J . M . Kleinberg , and D . J . Watts , “ The structure of information pathways in a social communication network , ” in KDD , 2008 , pp . 435–443 .
[ 7 ] X . Song , Y . Chi , K . Hino , and B . L . Tseng , “ Information flow modeling based on diffusion rate for prediction and ranking , ” in WWW , 2007 , pp . 191–200 .
[ 8 ] S . Liu , L . Ying , and S . Shakkottai , “ Influence maximization in social networks : An ising model based approach , ” in Allerton , 29 2010 oct . 1 2010 , pp . 570 –576 .
[ 9 ] E . M . Rogers , Diffusion of innovations ( 5 . ed ) Free Press ,
2003 .
[ 23 ] G . Heinze and M . Schemper , “ A solution to the problem of separation in logistic regression . ” Statistics in Medicine , vol . 21 , no . 16 , pp . 2409–2419 , 2002 .
[ 24 ] C . J . F . Ter Braak and C . W . N . Looman , “ Weighted averaging , logistic regression and the gaussian response model , ” Vegetatio , vol . 65 , no . 1 , pp . 3–11 , 1986 .
[ 25 ] D . Cox and E . Snell , Analysis of binary data . Chapman &
Hall/CRC , 1989 , vol . 32 .
[ 26 ] J . Yang and S . Counts , “ Comparing information diffusion structure in weblogs and microblogs , ” in ICWSM , 2010 .
[ 27 ] K . Burnham and D . Anderson , Model selection and multimodel inference : a practical information theoretic approach , 2nd ed . Springer , Jul . 2002 .
