Cost Sensitive Online Classification
Jialei Wang , Peilin Zhao , Steven CH Hoi
School of Computer Engineering , Nanyang Technological University , Singapore 639798
Email : {jl.wang , zhao0106 , chhoi}@ntuedusg
Abstract—Both cost sensitive classification and online learning have been studied extensively in data mining and machine learning communities , respectively . It is a bit surprising that there was very limited comprehensive study for addressing an important intersecting problem , that is , cost sensitive online classification . In this paper , we formally study this problem , and propose a new framework for cost sensitive online classification by exploiting the idea of online gradient descent techniques . Based on the framework , we propose a family of cost sensitive online classification algorithms , which are designed to directly optimize two well known cost sensitive measures : ( i ) maximization of weighted sum of sensitivity and specificity , and ( ii ) minimization of weighted misclassification cost . We analyze the theoretical bounds of the cost sensitive measures made by the proposed algorithms , and extensively examine their empirical performance on a variety of cost sensitive online classification tasks .
Keywords cost sensitive learning , online learning , classifica tion
I . INTRODUCTION
Online learning represents a family of efficient and scalable machine learning methods , which has been extensively studied in machine learning and data mining literature [ 5 ] , [ 15 ] , [ 21 ] , [ 25 ] , [ 27 ] , [ 29 ] . In general , the goal of online learning is to incrementally learn some prediction models to make correct predictions on a stream of examples that arrive sequentially . Online learning is advantageous for its high efficiency and scalability for large scale applications , and has been applied to solve online classification tasks in a variety of real world data mining applications .
Despite being studied extensively in machine learning , most existing online learning techniques are unsuitable and potentially would not be effective enough to solve a cost sensitive classification task , an important data mining problem which takes the misclassification costs into consideration [ 10 ] , [ 7 ] . This is because most existing online learning studies often concern the performance of an online classification algorithm in terms of prediction mistake rate or accuracy , which is obviously cost insensitive and thus inappropriate for many real applications in data mining , especially for cost sensitive classification tasks where datasets are often class imbalanced and the misclassification costs of instances from different classes can be very different [ 24 ] , [ 4 ] , [ 9 ] , [ 20 ] .
To address the above challenge of cost sensitive classification , researchers especially in data mining literature have proposed more meaningful metrics , such as the weighted sum of sensitivity and specificity [ 13 ] , [ 3 ] and the weighted misclassification cost [ 10 ] , [ 1 ] . Over the past decades , substantial research efforts have been devoted to developing batch classification algorithms to improve the cost sensitive measures , including the weighted sum of sensitivity and specificity and the weighted misclassification cost metrics [ 10 ] , [ 1 ] . However , these batch classification algorithms often suffer from low efficiency and poor scalability when solving large scale problems , making them unsuitable for online classification applications .
Although both cost sensitive classification and online learning have been studied extensively in data mining and machine learning communities , respectively , there were very few comprehensive studies on cost sensitive online classification in both data mining and machine learning literature . In this paper , we formally investigate this problem by attempting to develop cost sensitive algorithms for solving an online cost sensitive classification task . As the first comprehensive study , in this paper , we propose a new framework of CostSensitive Online Classification to resolve this challenging open problem . The key challenge of our framework is how to develop an effective cost sensitive online algorithm which can directly optimize a predefined cost sensitive measure ( eg , balanced accuracy or weighted misclassification cost ) for an online classification task , and further offer theoretical guarantee of the proposed algorithm .
To this end , we summarize the major contributions in this work as follows : ( i ) we propose a family of costsensitive online algorithms using online gradient descent learning technique to tackle the online optimization task of maximizing the weighted sum or minimizing the weighted misclassification cost ; ( ii ) we theoretically analyze the costsensitive measure bounds of the proposed algorithms , and extensively examine their empirical performance of costsensitive online classification tasks .
The rest of the paper is organized as follows . Section II briefs the related works . Section III formulates the problem and presents the proposed algorithms . Section IV theoretically analyzes the bounds of the proposed algorithms . Section V discusses our experimental results , and finally Section VI concludes this work .
II . RELATED WORK
Our work is mainly related to two groups of research in data mining and machine learning : ( i ) cost sensitive classification in data mining literature , and ( ii ) online learning in machine learning literature .
Cost sensitive classification has been extensively studied in data mining and machine learning [ 18 ] , [ 26 ] , [ 30 ] . To address this problem , researchers have proposed a variety of cost sensitive metrics . The well known examples include the weighted sum of sensitivity and specificity [ 13 ] , [ 3 ] , and the weighted misclassification cost that takes cost into consideration when measuring classification performance [ 10 ] , [ 1 ] . As a special case , when the weights are both equal to 0.5 , the weighted sum of sensitivity and specificity is reduced to the well known balanced accuracy [ 3 ] . Over the past decades , various batch learning algorithms have been proposed for cost sensitive classification in literature [ 22 ] , [ 23 ] , [ 7 ] , [ 10 ] , [ 19 ] , [ 17 ] , [ 20 ] .
Online learning has been extensively studied in machine learning community . Various online learning methods have been actively proposed in literature [ 21 ] , [ 15 ] , [ 5 ] . Examples include the well known Perceptron algorithm [ 21 ] , [ 11 ] , the recent Passive aggressive ( PA ) learning [ 5 ] , and many other recently proposed algorithms , many of which usually follow the principle of large margin learning [ 6 ] , [ 12 ] , [ 14 ] , [ 8 ] . Most online learning algorithms are cost insensitive , except the prediction based PA algorithm ( ’CPAP B’ ) [ 5 ] and the perceptron algorithm with uneven margin ( ’PAUM’ ) [ 16 ] . However , to the best of our knowledge , no existing work in this area had attempted to directly optimize the two costsensitive metrics in an online learning setting . Finally , we note that our work is very different from another recent online learning study [ 28 ] , which aims to optimize AUC , but cannot be guaranteed to optimize the cost sensitive measures in our study .
III . COST SENSITIVE ONLINE CLASSIFICATION
A . Problem Formulation
Without loss of generality , let us consider an online binary classification problem . At each learning round , the learner receives an instance and predicts its class label as “ +1 ” or “ 1 ” . After making the prediction , the learner receives the true label of the instance and suffers a loss if the prediction is incorrect . At the end of each round , the learner makes use of the received training example and it class label to update the prediction model .
Formally , let us denote by xt ∈ Rn the instance received at the t th learning step , and wt ∈ Rn a linear prediction model learned from the previous t − 1 training examples . We also denote the prediction for the t th instance as ˆyt = sign(wt · xt ) , while the value |wt · xt| , known as the “ margin ” , is used as the confidence of the learner on the prediction . The true label for instance xt is denoted as yt ∈ {−1 , +1} . If ˆyt 6= yt , the learner made a mistake ; otherwise it made a correct prediction .
For binary classification , the result of each prediction for an instance can be classified into four cases : ( 1 ) True Positive ( TP ) if ˆyt = yt = +1 ; ( 2 ) False Positive ( FP ) if ˆyt = +1 and yt = −1 ; ( 3 ) True Negative ( TN ) if ˆyt = yt = −1 ; and ( 4 ) False Negative ( FN ) if ˆyt = −1 and yt = +1 .
We now consider a sequence of training examples ( x1 , y1 ) , . . . , ( xT , yT ) for online learning . Then , for convenience , we denote by M the set of indexes that correspond to the trials of misclassification :
M = {t |yt 6= sign(wt · xt ) , ∀t ∈ [ T ]} where [ T ] = {1 , . . . , T } . Similarly , we denote by Mp = {t |t ∈ M and yt = +1} the set of indexes for false negatives , and Mn = {t |t ∈ M and yt = −1} the set of indexes for false positives .
Further , we introduce notation M = |M| to denote the number of mistakes , Mp = |Mp| to denote the number of false negatives , and Mn = |Mn| to denote the number of false positives . Also we use notation I p T = {i ∈ [ T ]|yi = +1} to denote the set of indexes of the positive examples , T = {i ∈ [ T ]|yi = −1} to denote the set of indexes I n of negative examples , Tp = |I p T | to denote the number of positive examples , and Tn = |I n T | to denote the number of negative examples .
For performance metrics , sensitivity is defined as the ratio between the number of true positives Tp − Mp and the number of positive examples ; specificity is defined as the ratio between Tn−Mn and the number of negative examples ; and accuracy is defined as the ratio between the number of correctly classified examples and the total number of examples . These can be summarized as : sensitivity = specif icity = accuracy =
Tp − Mp
Tp
,
Tn − Mn
Tn T − M
,
T
Consider an online binary classification task , without loss of generality , we assume positive class is the rare class , ie , Tp ≤ Tn , the number of positive examples is smaller than the number of negative examples . For simplicity , we also assume that kxtk ≤ 1 . For traditional online learning , the performance is measured by the prediction accuracy ( or mistake rate equivalently ) over the sequence of examples . This is inappropriate for imbalanced data because a trivial learner that simply classifies any example as negative could achieve a quite high accuracy for a highly imbalanced dataset . Thus , a more appropriate metric is to measure the sum of weighted sensitivity and specificity , ie , sum = ηp × sensitivity + ηn × specif icity
( 1 ) where ηp + ηn = 1 and 0 ≤ ηp , ηn ≤ 1 are two parameters to trade off between sensitivity and specificity . Notably , when ηp = ηn = 0.5 , the corresponding sum is the well known balanced accuracy . In general , the higher the sum value , the better the classification performance . Besides , another approach is to measure the total misclassification cost suffered by the algorithm , which is defined as : cost = cp × Mp + cn × Mn
( 2 ) where cp + cn = 1 and 0 ≤ cp , cn ≤ 1 are the misclassification cost parameters for positive and negative classes , respectively . The lower the cost value , the better the classification performance .
B . Algorithms
In this section , we propose a framework of Cost Sensitive Online Classification for cost sensitive classification by optimizing two cost sensitive measures . Before presenting our algorithms , we first prove the following important proposition that motivates our solution .
Proposition 1 : Consider a cost sensitive classification problem , the goal of maximizing the weighted sum in ( 1 ) or minimizing the weighted cost in ( 2 ) is equivalent to minimizing the following objective :
Xyt=+1
ρI(ytw·xt<0 ) + Xyt=−1
I(ytw·xt<0 )
( 3 ) where ρ = ηpTn ηnTp sum , and ρ = cp cn misclassification cost . for the maximization of the weighted for the minimization of the weighted
Proposition 1 gives the explicit objective function for optimization , but the indicator function is not convex . To facilitate the online optimization task , we replace the indicator function by its convex surrogate , ie , either one of the following modified hinge loss functions :
ℓI(w ; ( x , y ) ) = max(0 , ( ρ ∗ I(y=1 ) + I(y=−1 ) ) − y(w · x ) ) ( 4 ) ℓII(w ; ( x , y ) ) = ( ρ ∗ I(y=1)+I(y=−1))∗max(0 , 1 − y(w · x ) ) ( 5 )
As a result , we can formulate the optimization problem for cost sensitive classification as follows :
F ∗
T ( w ) =
1 2 kwk2 + C
T
Xt=1
ℓ∗(w ; ( xt , yt ) ) ∗ ∈ {I , II} ( 6 ) where kwk2 is introduced to regularize the complexity of the linear classifier and C is a positive penalty parameter of the cumulative loss . The idea of the above formulation is somewhat similar to the biased formulation of batch SVM for learning with imbalanced datasets [ 1 ] .
Now our goal is to find an online learning solution to tackle the above convex optimization ( 6 ) . To this end , we propose to solve the problem using the online gradient descent approach [ 31 ] , [ 2 ] , that is , wt+1 = wt − λ∇ℓt(wt ) where λ is a learning rate parameter and ℓt(w ) = ℓ∗(w ; ( xt , yt) ) , ∀∗ ∈ {I , II} . Specifically , when using the loss function ( 4 ) , the update rule can be expressed as : wt+1 = fl wt + λytxt wt if ℓt(wt ) > 0 otherwise
We refer to the above resulting cost sensitive online classification algorithm as “ CSOGD I ” for short .
When using the loss function ( 5 ) , the update rule can be expressed as : wt+1 = fl wt + λρtytxt wt if ℓt(wt ) > 0 otherwise where ρt = ρ ∗ I(yt=1 ) + I(yt=−1 ) . We refer to the above resulting algorithm as “ CSOGD II ” for short .
Finally , Algorithm 1 summarizes the two proposed
CSOGD algorithms .
Algorithm 1 The proposed CSOGD algorithms .
INPUT : learning rate λ ; bias parameter ρ = ηpTn ηnTp “ sum ” and ρ = cp for “ cost ” cn INITIALIZATION : w1 = 0 . for t = 1 , . . . , T do for receive instance : xt ∈ Rn ; predict : ˆyt = sign(wt · xt ) ; receive correct label : yt ∈ {−1 , +1} ; suffer loss ℓt(wt ) = ℓ∗(wt ; ( xt , yt) ) ; ∗ ∈ {I , II} if ( ℓt(wt ) > 0 ) update classifier : wt+1 = wt − λ∇ℓt(wt ) ; end if end for OUTPUT : wT +1 .
Remark . In Algorithm 1 , one practical concern is about setting the value of ρ when the goal is to optimize the weighted sum performance . In the algorithm , ρ is formally defined as ρ = ηpTn . However , the values of Tn and Tp ηnTp might be unknown in a real world online learning task . In practice , one could try to approximate the ratio Tn according Tp to the distribution of online received training data instances over the past sequence , and adaptively update this ratio during the online learning process .
IV . ANALYSIS OF COST SENSITIVE MEASURE BOUNDS Although the above proposed algorithm is simple , very limited existing study has formally investigated it for online learning tasks . Below we theoretically analyze its performance for classification tasks in terms of two types of costsensitive measures .
To ease our discussion , we denote by S the set of indexes that correspond to the trials when a margin error happens , S = {t |ℓt(wt ) > 0} . Similarly , we denote by Sp = {t |ℓt(wt ) > 0 and yt = +1} , Sn = {t |ℓt(wt ) > 0 and yt = −1} , Sp = |Sp| , and Sn = |Sn| .
Firstly , we will prove the following lemma , which gives the loss regret bound achieved by the online learning algorithm , and will facilitate later theoretical analysis .
Lemma 1 : Let ( x1 , y1 ) , . . . , ( xT , yT ) be a sequence of examples , where xt ∈ Rn , yt ∈ {−1 , +1} and kxtk ≤ 1 for all t . Then for any w ∈ Rn , for CSOGD I :
T
Xt=1
ℓt(wt ) ≤
T
Xt=1
ℓt(w ) + kwkpSp + Sn and for CSOGD II :
T
Xt=1
ℓt(wt ) ≤
T
Xt=1
ℓt(w ) + kwkqρ2Sp + Sn
Thus , by our proposed method , we can guarantee the following bound on the sum of ηp × sensitive + ηn × specif icity , where ηp + ηn = 1 and ηp , ηn > 0 .
Theorem 1 : Let ( x1 , y1 ) , . . . , ( xT , yT ) be a sequence of examples , where xt ∈ Rn , yt ∈ {−1 , +1} and kxtk ≤ 1 for all t . By setting ρ = ηpTn , for any w ∈ Rn , we then have ηnTp the bounds of the proposed algorithms : sum of CSOGDI ≥ 1− sum of CSOGDII ≥ 1−
ηn Tn
ηn Tn
(
(
T
Xt=1 Xt=1
T
ℓt(w ) + kwkpSp + Sn ) ℓt(w ) + kwkqρ2Sp + Sn )
One limitation of the above algorithm is that for a real online learning task , we may not know the ratio Tn in adTp vance . To address this issue , an alternative way is to consider the cost of the algorithm for performance evaluation , which in advance . Specifically , does not need to know the ratio Tn Tp , we propose to set ρ = cp instead of setting ρ = ηp Tn , cn ηnTp where cp and cn are the cost of false negative and the cost of false positive , respectively . We assume cp + cn = 1 , and cn , cp > 0 . Finally , the following theorem gives the cost bound of the proposed cost based algorithm .
Theorem 2 : Let ( x1 , y1 ) , . . . , ( xT , yT ) be a sequence of examples , where xt ∈ Rn , yt ∈ {−1 , +1} and kxtk ≤ 1 for all t . By setting ρ = cp , for any w ∈ Rn , we then have the cn bounds of the proposed algorithms : cost of CSOGDI ≤ cnh cost of CSOGDII ≤ cnh
T
Xt=1 Xt=1
T
ℓt(w ) + kwkpSp + Sni ℓt(w ) + kwkqρ2Sp + Sni
V . EXPERIMENTS OF COST SENSITIVE ONLINE
CLASSIFICATION
This section is to evaluate the empirical performance of the two proposed algorithms ( CSOGD I and CSOGD II ) . To ease our discussions , we denote by CSOLsum the proposed
CSOL algorithm that aims to maximize the weighted sum of sensitivity and specificity , and CSOLcos the proposed CSOL algorithm that aims to minimize the overall misclassification cost .
A . Experimental Testbed and Setup
We compare two CSOGD algorithms with a number of state of the art online learning algorithms , including Perceptron , “ ROMMA ” and its aggressive version “ agg ROMMA ” , and two versions of the Passive Aggressive algorithms ( “ PA ” ) [ 5 ] , ie , PA I and PA II . Besides , we also compare with the existing cost sensitive online algorithms : predictionbased PA algorithm ( ’CPAP B’ ) [ 5 ] and the perceptron algorithm with uneven margin ( ’PAUM’ ) [ 16 ] .
To examine the performance , we test all the algorithms on a number of benchmark datasets from web machine learning repositories . All of them can be downloaded from LIBSVM website 1 . For space limitation , we randomly choose some of them for our following discussions , which are listed in Table 1 .
Table I
#Examples
LIST OF BINARY DATASETS IN OUR EXPERIMENTS . #Pos:#Neg dataset 1:1 covtype 1:2.3 german w8a 1:32.5
581012 1000 64700
54 24 300
#Features
To make a fair comparison , all algorithms adopt the same experimental setup . In particular , for all the compared algorithms , the penalty parameter C was set to 10 ; for the proposed CSOLsum algorithms , we set ηp = ηn = 1/2 for all cases , while for CSOLcos , we set cp = 0.95 and cn = 0.05 ; for PAUM , the uneven margin was set to ρ ; for PB CPA , ρ(−1 , 1 ) was set to 1 and ρ(1 , −1 ) was set to ρ . The learning rate λ of CSOGD I was set to 0.2 , and the learning rate λ of CSOGD II was set to 01 The value of ρ was set to cp for CSOLsum , cn respectively . We also evaluate the parameter sensitivity about the cost sensitive weights in our experiments . for CSOLcos and ηpTn ηnTp
All the experiments were conducted over 20 random permutations for each dataset . The results are reported by averaging over these 20 runs . We evaluate the online classification performance by several metrics : sensitivity , specificity , the weighted sum of sensitivity and specificity , and the weighted cost .
B . Evaluation of Weighted Sum Performance
We first evaluate the weighted sum performance . The first three columns of Table 2 summarize the results of the algorithms . Some observations can be drawn below .
First of all , by examining the sum results , we found that CSOGD always achieves the best among all the datasets , which significantly outperforms all the online algorithms ,
1http://wwwcsientuedutw/∼cjlin/libsvmtools/datasets/
EVALUATION OF THE COST SENSITIVE CLASSIFICATION PERFORMANCE OF CSOGD AND OTHER EXISTING ALGORITHMS .
Table II
Algorithm
Perceptron ROMMA agg ROMMA PA I PA II PAUM CPAP B CSOGD I CSOGD II
Algorithm
Perceptron ROMMA agg ROMMA PA I PA II PAUM CPAP B CSOGD I CSOGD II Algorithm
Perceptron ROMMA agg ROMMA PA I PA II PAUM CPAP B CSOGD I CSOGD II
Sum( % )
66.149 ± 0.034 63.799 ± 0.562 64.833 ± 0.628 65.880 ± 0.044 66.103 ± 0.043 69.867 ± 0.035 65.891 ± 0.044 74.947 ± 0.022 75.526 ± 0.018
Sum( % )
62.001 ± 1.259 60.504 ± 1.496 61.012 ± 1.386 61.654 ± 1.495 61.893 ± 1.467 65.019 ± 1.144 61.850 ± 1.601 70.690 ± 0.846 70.619 ± 0.824
Sum( % )
79.011 ± 0.319 78.559 ± 0.267 79.090 ± 0.191 79.703 ± 0.300 79.998 ± 0.312 80.849 ± 0.344 80.933 ± 0.304 83.159 ± 0.258 85.619 ± 0.254
“ sum ” on covtype
Sensitivity( % ) 66.771 ± 0.056 66.266 ± 2.963 68.768 ± 2.936 66.263 ± 0.045 66.550 ± 0.047 69.825 ± 0.050 66.484 ± 0.046 77.543 ± 0.051 78.960 ± 0.041
“ sum ” on german
Sensitivity( % ) 64.967 ± 2.229 64.400 ± 2.588 65.517 ± 3.012 65.000 ± 2.372 65.300 ± 2.420 52.367 ± 2.173 65.500 ± 2.218 77.367 ± 1.284 77.667 ± 1.475 “ sum ” on w8a
Sensitivity( % ) 65.717 ± 0.614 62.230 ± 0.440 61.094 ± 0.381 63.621 ± 0.596 64.307 ± 0.633 63.011 ± 0.694 70.998 ± 0.613 71.128 ± 0.533 89.289 ± 0.330
Specificity ( % ) 65.528 ± 0.051 61.332 ± 4.064 60.897 ± 4.113 65.498 ± 0.057 65.656 ± 0.055 69.908 ± 0.048 65.298 ± 0.056 72.351 ± 0.052 72.091 ± 0.048
Specificity ( % ) 59.036 ± 1.483 56.607 ± 2.202 56.507 ± 2.156 58.307 ± 1.472 58.486 ± 1.390 77.671 ± 0.980 58.200 ± 1.858 64.014 ± 1.039 63.571 ± 0.703
Specificity ( % ) 92.305 ± 0.079 94.888 ± 0.204 97.086 ± 0.115 95.785 ± 0.100 95.689 ± 0.099 98.686 ± 0.024 90.868 ± 0.183 95.191 ± 0.058 81.949 ± 0.355 including two cost sensitive online algorithms ( PAUM and CPA ) . This shows that it is important to study effective costsensitive algorithms .
Second , by examining both sensitivity and specificity metrics , we found that CSOGD is not only guaranteed to achieve the best sensitivity for all cases , but also can produce a fairly good specificity performance for most cases . This shows that the proposed approach for CSOGD is effective in improving the accuracy of predicting the examples from the rare class .
Third , similar to the previous results , the two CSOGD algorithms in general achieved comparable sum performance , in which CSOGD I tends to perform slightly better than CSOGD II .
C . Evaluation of Weighted Cost Performance
We further evaluate the performance of the CSOLcos algorithm in terms of the cost metric . The last three columns of Table 2 summarize the results of total cost evaluation . From the experimental results , we can also draw several observations .
First of all , we found that the two existing cost sensitive algorithms ( PAUM and CPAP B ) usually outperform the other cost insensitive algorithms , in which PAUM seems to be more effective than CPAP B for most cases .
Cost
94563.580 ± 150.542 96545.407 ± 7371.897 89876.875 ± 7293.558 95934.380 ± 125.245 95137.125 ± 130.178 33239.145 ± 85.815 72060.113 ± 129.526 35544.630 ± 80.287 14752.020 ± 31.166
Cost
114.182 ± 6.309 116.647 ± 7.239 113.500 ± 8.260 114.342 ± 6.863 113.425 ± 6.974 102.045 ± 6.052 112.612 ± 7.229 77.313 ± 3.514 84.747 ± 4.635
Cost
871.072 ± 12.103 854.022 ± 11.630 805.900 ± 7.383 800.330 ± 11.264 790.747 ± 11.521 723.015 ± 11.433 798.985 ± 11.668 681.158 ± 9.100 652.142 ± 8.337
“ cost ” on covtype Sensitivity( % ) 66.771 ± 0.056 66.266 ± 2.963 68.768 ± 2.936 66.263 ± 0.045 66.550 ± 0.047 90.414 ± 0.031 75.765 ± 0.047 89.366 ± 0.030 99.245 ± 0.010 “ cost ” on german Sensitivity( % ) 64.967 ± 2.229 64.400 ± 2.588 65.517 ± 3.012 65.000 ± 2.372 65.300 ± 2.420 68.367 ± 2.171 65.650 ± 2.514 77.283 ± 1.244 75.067 ± 1.603
“ cost ” on w8a Sensitivity( % ) 65.717 ± 0.614 62.230 ± 0.440 61.094 ± 0.381 63.621 ± 0.596 64.307 ± 0.633 62.646 ± 0.632 70.031 ± 0.601 71.136 ± 0.525 85.331 ± 0.429
Specificity ( % ) 65.528 ± 0.051 61.332 ± 4.064 60.897 ± 4.113 65.498 ± 0.057 65.656 ± 0.055 50.013 ± 0.022 54.081 ± 0.064 53.475 ± 0.034 14.547 ± 0.074
Specificity ( % ) 59.036 ± 1.483 56.607 ± 2.202 56.507 ± 2.156 58.307 ± 1.472 58.486 ± 1.390 66.029 ± 1.243 57.957 ± 1.338 64.086 ± 1.068 60.893 ± 1.278
Specificity ( % ) 92.305 ± 0.079 94.888 ± 0.204 97.086 ± 0.115 95.785 ± 0.100 95.689 ± 0.099 98.819 ± 0.021 92.077 ± 0.150 95.185 ± 0.059 87.803 ± 0.285
Second , among all the algorithms , we found that the proposed CSOGD algorithms achieve significantly less total misclassification cost than the other algorithms for most cases . For example , on the dataset “ w8a ” , the total misclassification cost of CSOGD II is about 20 % less than that of PA algorithms , and about 10 % less than that of PAUM . Further , by examining both sensitivity and specificity metrics , we found that CSOGD often achieves the best sensitivity result , but does not always guarantee the best results for specificity . Finally , by examining the two CSOGD algorithms themselves , we found that CSOGD II tends to perform sightly better than CSOGD I ( except on the dataset “ german ” ) .
VI . CONCLUSION to fill
As an attempt the gap between cost sensitive classification and online learning in machine learning and data mining , this paper investigated a new framework of Cost Sensitive Online Classification , which aims to directly optimize cost sensitive measures for online classification tasks . We proposed a family of effective algorithms based on online gradient descent , theoretically analyzed their costsensitive bounds , and finally examined their empirical performance extensively . Our encouraging results show that the proposed algorithms considerably outperform the traditional online learning algorithms for cost sensitive online classification tasks . Through this study , we hope to inspire researchers in both data mining and machine learning to further explore in depth theory of cost sensitive online classification and the application of new cost sensitive online learning techniques to tackle a variety of emerging challenges in real world data mining applications .
ACKNOWLEDGMENTS
This work was supported by Singapore MOE tier 1 project
( RG33/11 ) and Microsoft Research project ( M4060936 ) .
REFERENCES
[ 1 ] R . Akbani , S . Kwek , and N . Japkowicz . Applying support In ECML , pages vector machines to imbalanced datasets . 39–50 , 2004 .
[ 2 ] P . L . Bartlett , E . Hazan , and A . Rakhlin . Adaptive online gradient descent . In NIPS , 2007 .
[ 3 ] K . H . Brodersen , C . S . Ong , K . E . Stephan , and J . M . Buhmann . The balanced accuracy and its posterior distribution . In ICPR , pages 3121–3124 , 2010 .
[ 4 ] N . V . Chawla , K . W . Bowyer , L . O . Hall , and W . P . Kegelmeyer . Smote : Synthetic minority over sampling technique . JAIR , 16:321–357 , 2002 .
[ 5 ] K . Crammer , O . Dekel , J . Keshet , S . Shalev Shwartz , and JMLR ,
Y . Singer . Online passive aggressive algorithms . 7:551–585 , 2006 .
[ 6 ] K . Crammer and Y . Singer . Ultraconservative online algo rithms for multiclass problems . JMLR , 3:951–991 , 2003 .
[ 7 ] P . Domingos . Metacost : a general method for making classifiers cost sensitive . In KDD’99 , pages 155–164 , San Diego , CA , USA , 1999 . ACM .
[ 8 ] M . Dredze , K . Crammer , and F . Pereira . Confidence weighted linear classification . In ICML , pages 264–271 , 2008 .
[ 9 ] C . Drummond and R . C . Holte . C4.5 , class imbalance , and cost sensitivity : Why under sampling beats over sampling . In ICML’03 Workshop on Learning from Imbalanced Data Sets , pages 1–8 , 2003 .
[ 15 ] Y . Li and P . M . Long . The relaxed online maximum margin algorithm . In NIPS , pages 498–504 , 1999 .
[ 16 ] Y . Li , H . Zaragoza , R . Herbrich , J . Shawe Taylor , and J . S . Kandola . The perceptron algorithm with uneven margins . In ICML , pages 379–386 , 2002 .
[ 17 ] Y F Li , J . T . Kwok , and Z H Zhou . Cost sensitive semi supervised support vector machine . In AAAI , 2010 .
[ 18 ] X Y Liu and Z H Zhou . The influence of class imbalance on cost sensitive learning : An empirical study . In Proceedings of the Sixth International Conference on Data Mining ( ICDM’06 ) , pages 970–974 . IEEE Computer Society , 2006 .
[ 19 ] A . C . Lozano and N . Abe . Multi class cost sensitive boosting with p norm loss functions . In KDD’08 , pages 506–514 , Las Vegas , Nevada , USA , 2008 . ACM .
[ 20 ] H . Masnadi Shirazi and N . Vasconcelos . Risk minimization , In ICML , probability elicitation , and cost sensitive svms . pages 759–766 , 2010 .
[ 21 ] F . Rosenblatt . The perceptron : A probabilistic model for information storage and organization in the brain . Psychological Review , 65:386–407 , 1958 .
[ 22 ] M . Tan . Cost sensitive learning of classification knowledge and its applications in robotics . Mach . Learn . , 13(1):7–33 , Oct . 1993 .
[ 23 ] P . D . Turney . Cost sensitive classification : Empirical evaluation of a hybrid genetic decision tree induction algorithm . JAIR , 2:369–409 , 1995 .
[ 24 ] K . Veropoulos , C . Campbell , and N . Cristianini . Controlling the sensitivity of support vector machines . In IJCAI , pages 55–60 , 1999 .
[ 25 ] J . Wang , P . Zhao , and S . C . Hoi . Exact soft confidence weighted learning . In ICML , 2012 .
[ 26 ] B . Zadrozny , J . Langford , and N . Abe . Cost sensitive learning by cost proportionate example weighting . In Proceedings of the Third IEEE International Conference on Data Mining ( ICDM’03 ) , pages 435– , Washington , DC , USA , 2003 .
[ 27 ] P . Zhao , S . C . H . Hoi , and R . Jin . Double updating online learning . Journal of Machine Learning Research , 12:1587– 1615 , 2011 .
[ 10 ] C . Elkan . The foundations of cost sensitive learning .
IJCAI , pages 973–978 , 2001 .
In
[ 28 ] P . Zhao , S . C . H . Hoi , R . Jin , and T . Yang . Online auc maximization . In ICML , pages 233–240 , 2011 .
[ 11 ] Y . Freund and R . E . Schapire . Large margin classification using the perceptron algorithm . Mach . Learn . , 37(3):277– 296 , 1999 .
[ 29 ] P . Zhao , J . Wang , P . Wu , R . Jin , and S . C . Hoi . Fast bounded online gradient descent algorithms for scalable kernel based online learning . In ICML , 2012 .
[ 12 ] C . Gentile . A new approximate maximal margin classification algorithm . JMLR , 2:213–242 , 2001 .
[ 13 ] J . Han and M . Kamber . Data Mining : Concepts and Tech niques . Morgan Kaufmann , 2000 .
[ 14 ] J . Kivinen , A . J . Smola , and R . C . Williamson . Online learning with kernels . In NIPS , pages 785–792 , 2001 .
[ 30 ] X . Zhu and X . Wu . Class noise handling for effective cost sensitive learning by cost guided iterative classification filtering . IEEE Trans . on Knowl . and Data Eng . , 18(10):1435– 1440 , Oct . 2006 .
[ 31 ] M . Zinkevich . Online convex programming and generalized In T . Fawcett and N . Mishra , infinitesimal gradient ascent . editors , ICML , volume 20 , 2003 .
