Structured Learning for Non Smooth Ranking Losses Chiru Bhattacharyya Soumen Chakrabarti
Rajiv Khanna
IIT Bombay
IIT Bombay
Uma Sawant
IIT Bombay
IISc Bangalore soumen@cseiitbacin rajivk@cseiitbacin uma@cseiitbacin chiru@csaiiscernetin
ABSTRACT Learning to rank from relevance judgment is an active research area . Itemwise score regression , pairwise preference satisfaction , and listwise structured learning are the major techniques in use . Listwise structured learning has been applied recently to optimize important non decomposable ranking criteria like AUC ( area under ROC curve ) and MAP ( mean average precision ) . We propose new , almost lineartime algorithms to optimize for two other criteria widely used to evaluate search systems : MRR ( mean reciprocal rank ) and NDCG ( normalized discounted cumulative gain ) in the max margin structured learning framework . We also demonstrate that , for different ranking criteria , one may need to use different feature maps . Search applications should not be optimized in favor of a single criterion , because they need to cater to a variety of queries . Eg , MRR is best for navigational queries , while NDCG is best for informational queries . A key contribution of this paper is to fold multiple ranking loss functions into a multi criteria max margin optimization . The result is a single , robust ranking model that is close to the best accuracy of learners trained on individual criteria . In fact , experiments over the popular LETOR and TREC data sets show that , contrary to conventional wisdom , a test criterion is often not best served by training with the same individual criterion . Categories and Subject Descriptors : I26 [ Computing Methodologies ] : Artifical Intelligence — Learning ; H33 [ Information Systems ] : Information Storage and Retrieval — Information Search and Retrieval . General Terms : Algorithms , Experimentation . Keywords : Max margin structured learning to rank , Nondecomposable loss functions . 1 . INTRODUCTION
Learning to rank is an active research area where supervised learning is increasingly used [ 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ] . The main challenge in adapting supervised learning is that for ranking problems , the evaluation criterion or “ loss function ” is usually defined over the permutation induced by the scoring function over response instances ( see Section 2.2 ) , and hence the loss function is not decomposable over instances as in regular Support Vector Machines ( SVMs ) [ 11 ] . Moreover , common ways to formulate learning with these loss functions result in intrinsically non convex and “ rough ” optimization problems . This is a central challenge in learning to rank . 1.1 Existing algorithms Algorithms for learning to rank may view instances Itemwise [ 10 ] and regress them to scores , then sort the instances by decreasing score .
Pairwise [ 2 , 3 ] , which is highly suited for clickthrough data , and leads to a simple loss function decomposable over
1 preference pairs ; however , it is thereby not sensitive to absolute ranks .
Listwise [ 4 , 9 ] , and use structured learning [ 12 ] algorithms , which is our focus here .
The large margin structured learning framework [ 12 ] fits a model to minimize the loss of a whole permutation , not individual or pairs of items . This approach has been used to optimize non decomposable ranking criteria , like the area under the ROC curve ( AUC ) [ 4 ] and mean average precision ( MAP ) [ 9 ] . However , other widely used criteria in Information Retrieval and Web search , such as mean reciprocal rank ( MRR ) [ 13 ] or normalized discounted cumulative gain ( NDCG ) [ 14 ] , had no efficient direct optimizers .
The advantage of the structured learning approach is that it helps break down the difficult non convex ranking loss optimization problem into a convex quadratic program and a combinatorial optimization problem which , as we shall see , is often tractable and simple for ranking applications .
The second framework approximates the non convex and discontinuous ranking loss function with a somewhat more benign ( but often still non convex ) surrogate , which is then optimized using gradient descent and neural networks [ 3 , 7 , 8 , 15 ] . A very interesting variant is LambdaRank [ 6 ] which models only the gradient , with an unmaterialized objective . A potential problem with this family is that non convex optimization behavior is tricky to replicate accurately in general , requiring many bells and whistles to tide over local optima . In fact , a recent approach using boosted ordinal regression trees ( McRank ) [ 10 ] has proved surprisingly competitive to gradient methods and put itemwise approaches back in the race . In this paper we will not focus on this family , except to compare the best structured learning approaches with McRank , to show that listwise structured learning remains very competitive . 1.2 Our contributions
Our first contribution is to augment the class of nonsmooth ranking loss functions that can be directly and efficiently ( in near linear time ) optimized for listwise structured learning . Specifically , we propose new , almost linear time algorithms , SVMndcg for NDCG ( Section 3.4 ) and SVMmrr for MRR ( Section 36 ) Therefore , now we can optimize efficiently for AUC , MAP , NDCG and MRR within the structured ranking framework .
Structured ranking requires us to design a feature map φ(x , y ) over documents x and a proposed ranking y . Our second contribution is a close look ( Section 3.1 ) at feature map design and feature scaling : all important but somewhat neglected aspects of structured ranking . Specifically , our feature maps for MRR and NDCG are different , and this affects accuracy ( Section 43 ) It also greatly affects the numerical behavior of the optimizer ( Section 42 ) We give some guidelines on how to check if a feature map , in conjunction with a loss function , is healthy for the optimizer .
We perform a thorough comparison , using standard public data sets ( see Figures 1 , 9 ) , of test accuracies in terms of MAP , MRR , and NDCG when trained with structured rank learners that are optimizing for each of these loss functions separately . Conventional wisdom suggests that a system q = |Gq| and n−
For evaluation , suppose the exact sets of relevant and irrelevant documents , Gq and Bq , are known for every query q . For simplicity these can be coded as zqi = 1 if the ith document is relevant or “ good ” for query q , and 0 otherwise , ie , q = |Bq| . We the document is “ bad ” . Let n+ will drop q when clear from context . 221 Pair preference and AUC For every query q , every good document xqi and every bad document xqj , we want xqi to rank higher than xqj , denoted “ xqi xqj ” and satisfied if w>xqi > w>xqj . Pair preferences can be asserted even when absolute relevance values are unknown or unreliable , as with clickthrough data . Usually , learning algorithms [ 1 , 2 ] seek to maximize over w ( a smooth approximation to ) the number of pair preferences satisfied . The number of satisfied pairs is closely related to the area under the receiver operating characteristic ( ROC ) curve [ 4 ] .
A long standing criticism of pair preference satisfaction is that all violations are not equal [ 19 ] ; flipping the documents at ranks 2 and 11 is vastly more serious than flipping #100 and #150 . This has led to several global criteria defined on the total order returned by the search engine . 222 Mean reciprocal rank ( MRR ) In a navigational query , the user wants to quickly locate a URL that is guaranteed to satisfy her information need . In question answering ( QA ) , many questions have definite answers , any one correct answer is adequate . MRR is wellsuited to such occasions [ 13 ] . Suppose , in the document list ordered by decreasing w>xqi , the topmost rank at which an answer to q is found is rq . ( Note : For consistency with code all our ranks begin at zero , not one . ) The reciprocal rank for a query q is 1/(1 + rq ) . Averaging over q , we get MRR = 1|Q| where Q is the set of all queries . Often a cutoff of k is used :
P q∈Q
1+rq
1
MRR = 1|Q| q∈Q
1/(1 + rq ) , 0 , rq < k rq ≥ k
( MRR )
(
P
The ideal ranking ensures an MRR of 1 ( assuming there is at least one relevant document for every query ) . 223 Normalized discounted cumulative gain ( NDCG ) Of recent interest in Information Retrieval and Machine Learning communities is NDCG , which , unlike MRR , does accumulate credit for second and subsequent relevant documents , but discounts them with increasing rank . The DCG for a specific query q and document order is DCG(q ) = 0≤i<k G(q , i)D(i ) where G(q , i ) is the gain or relevance of document i for query q and D(i ) is the discount factor given by [ 14 ]
P
D(i ) =
( Discount ) trained to optimize MAP should be best for test MAP , a system optimized for MRR should be best for test MRR , etc . Surprisingly , across five data sets , we see very little evidence of this . Often , the best test loss of a certain type is obtained by training with a different loss function . We conjecture that this is because conventional feature maps for ranking are not well matched to commonly used ranking loss functions ( Section 42 )
Web search users have diverse needs . Even if we could , it would be undesirable to ultra optimize in favor of one criterion . MRR is best for navigational queries ( “ IBM ” ) and factual questions ( “ giraffe height ” ) , where only the first URL ( http://wwwibmcom ) or answer ( 18 feet ) matter . In contrast , NDCG is best for collecting information about a topic .
Our third contribution is a robust max margin optimization ( SVMcombo ) of a combined loss function ( Section 37 ) We show that SVMcombo ’s test performance on any criterion ( MAP , MRR , NDCG ) is close to that of the best components of the combination ( Section 45 )
We also report on running time and scalability comparisons between structured rank learners and a prominent recent contender in accuracy ( McRank—boosted regression trees ) and find , on the public LETOR data set [ 16 ] , that structured learners are considerably faster ( Section 3.8 ) while also being more accurate in two out of three data sets . 2 . BACKGROUND 2.1 Testbed and data sets
Figure 1 summarizes the leading algorithms and data sets on which they have been evaluated . RankSVM [ 2 ] , StructSVM [ 12 ] , and SVMmap [ 9 ] codes are in the public domain . Implementations of ranking using gradient descent and boosting are not public .
From Figure 1 it is evident that many of the data sets are proprietary , and many implementations are not readily available . As a result , there are hardly any data sets over which many algorithms have been compared directly . We have implemented SVMauc [ 4 ] , SVMmap [ 9 ] , DORM [ 18 ] , McRank [ 10 ] , as well as our new proposals SVMmrr and SVMndcg , in a common open source Java testbed ( http : //wwwcseiitbacin/soumen/doc/StructRank/ )
We ran all the algorithms on the well known LETOR benchmark [ 16 ] that is now widely used in research on learning to rank . We also ran all algorithms but one on TREC 2000 and 2001 data prepared by Yue et al . [ 9 ] . More details are in Section 41 In many cases , the behavior of different algorithms differed on the three data sets . This highlights the importance of shared , standardized data to avoid potentially biased conclusions . 2.2 Ranking evaluation criteria
Suppose q is a query from a query set Q . For each document xi in the corpus , we use q together with xi to compute a feature vector we call xqi ∈ Rd whose elements encode various match and quality indicators . Eg , one element of xqi may encode the extent of match between q and the page title , while another element may be the PageRank of the node corresponding to the ith document in the Web graph . Collectively , these feature vectors over all documents , for fixed query q , is called xq . Learning a ranking model amounts to estimating a weight vector w ∈ Rd . The score of a test document x is w>x . Documents are ranked by decreasing score .
0 ≤ i ≤ 1 1/ log2(1 + i ) 2 ≤ i < k 0 k ≤ i
8><>:1 ( q ) =Pmin{n+ P i=0
∗
DCG(q ) DCG∗(q )
=
Note the cutoff at k . Suppose there are n+ for query q , then the ideal DCG is q good documents
DCG q ,k}−1
G(q , i)D(i ) , pushing all the relevant documents to the top . Now define
0≤i<k zqiD(i ) DCG∗(q )
( NDCG )
NDCG(q ) =
2
Algorithm RankSVM , public , reimplemented here [ 2 ] SVMauc , public , reimplemented here [ 4 ] SVMmap , public , reimplemented here [ 9 ] SVMmrr , proposed here SVMndcg , proposed here DORM , not public , reimplemented here RankNet , not public [ 3 ] LambdaRank , not public [ 6 ] SoftRank , not public [ 8 , 15 ] McRank , not public , reimplemented here [ 10 ]
Public
Not public
D E M U S H O
•[15 , 17 ] • • • • •[17 ]
0 0 0 2 C E R T
1 0 0 2 C E R T
• [ 9 ] • [ 9 ] • • •
• [ 9 ] • [ 9 ] • • •
3 0 0 2 D T
• • • • • •
4 0 0 2 D T
• • • • • •
[ 15 ] •
•
•
◦
◦
1 b e W S M
2 b e W S M
3 b e W S M
[ 6 ] [ 6 , 10 ]
[ 10 ]
[ 10 ]
[ 10 ]
[ 10 ]
[ 10 ]
4 b e W S M [ 18 ] [ 18 ]
1 b e W
!
Y [ 17 ]
2 b e W
!
Y [ 17 ]
[ 18 ]
[ 17 ]
[ 17 ]
Figure 1 : Algorithms for learning to rank and data sets where they have been evaluated . “ MS Web ” data is from Microsoft , “ Y! Web ” data is from Yahoo . “ • ” means the evaluation is reported here . “ ◦ ” means the RAM/CPU requirements prevented evaluation . [ 2 , 3 , 4 , 5 ] predate OHSUMED , TD2003 , TD2004 . and average NDCG(q ) over queries . G(q , i ) is usually defined as 2zqi − 1 . Because we focus on zqi ∈ {0 , 1} , we can simply write G(q , i ) = zqi . 224 Mean average precision ( MAP ) For query q , let the ith ( counting from zero ) relevant or ‘good’ document be placed at rank rqi ( again , counting from zero ) . Then the precision ( fraction of good documents ) up to rank rqi is ( 1 + i)/(1 + rqi ) . Average these over all good documents for a query :
AP(q ) =P i:zqi=1
1+i 1+rqi
P and define MAP = 1|Q| q∈Q AP(q )
( MAP )
The ideal ranking pushes all good documents to the top and ensures a MAP of 1 . 2.3 Structured ranking basics
In structured ranking , the input is the set of documents xq and the output is a total or partial order y over all the documents .
Ranking is achieved through two devices : a feature map φ(xq , y ) and a model weight vector w . The score of a ranking y wrt xq , φ and w is w>φ(xq , y ) . The intention is , given a trained model w and documents xq , to return the best ranking arg maxy w>φ(xq , y ) . φ(x , y ) is usually chosen so that , given w , this maximization amounts to sorting documents by decreasing w>xqi .
The ideal ranking for query q is called y∗ q . It places all good documents in Gq at top ranks and all bad documents Bq after that . The third component of structured learning is q , y ) ≥ a loss function : Any order y incurs a ranking loss ∆(y∗ 0 . ∆(y∗ q , y∗ q ) = 0 and the worse the ranking y , larger the value of ∆(y∗ q , y ) .
In structured rank learning the goal is to estimate a scoring model w via this generic StructSVM optimization [ 12 ] :
X q arg min w;ξ≥~0 >
>
1 2 w w + C|Q| q ) ≥ w ∗
>
ξq st
( 1 )
∗ q : w
∀q,∀y 6= y Intuitively , if y is a poor ranking , ∆(y∗
φ(xq , y
φ(xq , y ) + ∆(y we want w to indicate that , ie , we want w>φ(xq , y∗ w>φ(xq , y ) in that case . If not , w needs to be refined . q , y ) − ξq . ∗ q , y ) is large and q ) * w and current set of slack variables ξq , and we wish to find a violator ( ˆq , ˆy 6= y∗
ˆq ) such that
> w
φ(xˆq , y
∗ ˆq ) + < w
>
φ(xˆq , ˆy ) + ∆(y
ˆq , ˆy ) − ξˆq , ∗ where > 0 is a tolerance parameter , and then add the ˆq , ˆy ) − ξq ” to constraint “ w>(φ(xˆq , y∗ the working set . This means we need to find , for each q ,
ˆq ) − w>φ(xˆq , ˆy ) ) ≥ ∆(y∗ arg max y6=y∗ q
H(y ; x , w ) = arg max y6=y∗ q
> w
φ(xq , y ) + ∆(y
∗ q , y )
( 2 )
If w were “ perfect ” , maximizing w>φ(xq , y ) would give us an ideal y with very small ∆ . Intuitively , the maximization ( 2 ) finds weaknesses in w where a large w>φ(xq , y ) can coexist with a large ∆(yq , y ) . Then the next step of the cutting plane algorithm proceeds to improve w and adjust ξ suitably . Applying StructSVM to a problem [ 9 , 18 ] amounts to designing φ(x , y ) and giving an efficient algorithm for ( 2 ) . The critical property of the cutting plane algorithm is that , for any fixed , a constant number of violators are considered before convergence . Therefore , if each invocation of ( 2 ) takes linear time , the overall training algorithm is also linear time . The details , which are now standard , can be found in [ 12 , 4 , 5 ] . 3 . ALGORITHMS AND ANALYSIS 3.1 Feature map design
The representation of xqi as a feature vector comes from domain knowledge , but the design of the feature map φ(x , y ) is an integral part of learning to rank . Here we review two known feature maps and propose one . 311 Partial order φpo For pair preferences and AUC , the partial order feature map is a natural choice . If y encodes a partial order , it is indexed as yij where zqi = 1 and zqj = 0 . yij = 1 if the partial order places xqi before xqj . yij = −1 if the partial order ( mistakenly ) places xqi after xqj . If yij = 0 , xqi and xqj are incomparable in the partial order . Note that y∗ ij = 1 for all i , j . With this coding of y , a common feature function used by Joachims and others [ 4 , 9 ] is
φpo(xq , y ) = 1 − + q n q n g∈Gq ,b∈Bq ygb(xqg − xqb )
( 3 )
P
At any step in the execution of a cutting plane algorithm [ 12 ] , there is a working set of constraints , a current model where g indexes a good document and b indexes a bad document .
3 q n−
In practice , the pair averaging scale factor 1/(n+ q ) is absolutely critical for any learnability of w ; without it , we get almost zero accuracy of all kinds ( AUC , NDCG , MAP , MRR ) . Therefore , proper scaling across queries is also an integral part of feature map design . 312 New insights and feature map φmrr With φpo defined as above , consider
∗
δφx(y
, y ) = φ(x , y
∗
) − φ(x , y ) .
Note that the optimization ( 1 ) sees only δφx(y∗ , y ) , never φ(x , y∗ ) or φ(x , y ) separately . Fact 31 δφx(y∗ , y ) can be written as
P
P b:bg(xg − xb ) ,
1 − + q n q
2
( 4 ) where “ b g ” means that y places the bad document indexed by b before the good document indexed by g . n g
Proof . Consider a good document ( index ) g with two bad documents , b1 g and g b2 , in partial order y . Using ( 3 ) , φ(x , y ) will include terms xb1 − xg and xg − xb2 . In y∗ we will have g b1 and g b2 , so φ(x , y∗ ) will include terms xg − xb1 and xg − xb2 .
This shows that , despite the global “ all pairs ” feel to ( 3 ) , φpo carries no information to the optimizer from documents lower than the lowest ranked good document . We can use ( 4 ) to define an equivalent feature map that exposes the local nature of φpo :
P g
P b:bg(xb − xg ) .
ψ(x , y ) = 2
1 − + q n q n
Note that
ψ(x , y
∗
) = ~0 , ∵6 ∃b g in y
∗
, and therefore δψx(y∗ , y ) = δφx(y∗ , y ) .
φmrr(x , y ) =P
Now consider MRR . ∆MRR depends not on all g , but only the top ranking good document g0(y ) . So the sum over all g seems out of place . Accordingly , we will define b:bg0(y)(xb − xg0(y) ) .
( 5 ) Again , φmrr(x , y∗ ) = ~0 . There is no need to scale down by n+ q , because only one good document is contributing to the sum . We are just soft counting the number of bad documents ahead of g0(y ) , so there is also no need to scale down by n− q . 313 Permutation feature map φdorm Instead of expressing a partial order involving good bad pairs , y may also encode a total order . A natural encoding of a total order is to set y(i ) to the rank of xqi , where y(i ) ∈ {0 , . . . , nq − 1} . Given xq and a permutation y , the feature function is
φdorm(xq , y ) =P
0≤i<n A(y(i))xqi
( 6 ) where A(r ) is a heuristically designed decay profile [ 18 ] . Eg , the ranking evaluation measures we study here pay more attention to the documents in the top ranks . For NDCG and MRR , our attention is limited to the top k documents . √ To embed this knowledge in the feature function , one can set A(r ) to various decay functions , like 1/ r + 1 . Thus , φdorm(xq , y ) increases the representation of top ranked documents . Unfortunately , there is no theoretical guidance to design A . It is naturally of interest to see how φpo , φmrr , φdorm perform at various tasks ; to our knowledge such comparisons have not been done before .
4
3.2 Loss functions It is easy to translate the ranking criteria reviewed in Section 2.2 into loss functions . ∆AUC(y∗ , y ) is the fraction of pair preferences that are violated by y ( y∗ violates none ) . This can be written as
∆AUC(y
∗
, y ) = 1 2 g,b(1 − ygb )
( 7 ) n+ n−P
1
Next we consider MRR , NDCG and MAP . For any y , MRR is a number between 0 and 1 ; ∆MRR(y∗ , y ) is simply one minus the MRR of y . Note that the MRR of y∗ is 1 if there is at least one good document for every query , which we will assume . ∆NDCG(y∗ , y ) and ∆MAP(y∗ , y ) are defined similarly . 3.3 Review of SVMauc and SVMmap
Consider optimization ( 2 ) using φpo and ∆AUC [ 4 ] . For the current fixed w in a cutting plane algorithm , let us shorthand the current score sqi = w>xqi , and omit q when fixed or clear from context . Then observe that
> w arg max y
φpo(xq , y ) + ∆AUC(y
P
∗ q , y )
`sg − sb − 1
´ .
1 − + q n q
2 n g,b ygb
= arg maxy
( 8 ) In this case the best choice of y is obvious : ygb = sign(sg − sb − 1 2 ) , and therefore the elements ygb can be optimized independently . Other ranking criteria , such as MAP , MRR and NDCG lead to more non trivial optimizations .
SVMauc with φpo and ∆AUC admits a very efficient optimization of ( 2 ) . Learning for MAP with φpo and ∆MAP is not as simple , but the following insight can be exploited to design a greedy algorithm [ 9 ] . Fact 32 There is an optimal total order y for ( 2 ) with φpo and ∆ = ∆MAP such that the scores ( wrt the current w ) of good documents are in non increasing order , and the scores of bad documents are in non increasing order . The proof is via a swap argument . The SVMmap algorithm of Yue et al . [ 9 ] greedily percolates score ordered bad documents into the score ordered sequence of good documents , and this is proved to be correct . 3.4 New algorithm SVMndcg
For φpo and ∆NDCG , we present a solution to optimizatime , where nq = tion ( 2 ) that takes O q + n− n+ q . It can be verified that Fact 3.2 holds for φpo and ∆NDCG as well . However , the details of merging good and documents are slightly different from SVMmap . q(nq log nq + k2 )
Fix a query q and consider the good documents in a list G = x0 , . . . , xg , . . . , xn+−1 sorted by decreasing current score wrt the current w . Also let B = x0 , . . . , xb , . . . , xn−1−1 be the bad documents sorted likewise . We will insert good documents , in decreasing score order , into B ( the opposite also works ) . Initially , it will be easiest to visualize this as a dynamic programming table , shown in Figure 2 .
Cell [ g , b ] in the table will store a solution up to the placement of good document xg just before bad document xb , which means its rank in the merged list is g + b ( counting from 0 ) . The contribution of the cell [ g , b ] to the objective H comes in two parts : CellScore(g , b ) from w>φpo is
“ P
”
Pb−1 ‘=0(sb‘ − sg ) +Pn−−1
‘=b
− q n q n+
( sg − sb‘ )
; this can be found in O(1 ) time by precomputing prefix and suffix sums of B . CellLoss(g , b ) is −D(g + b)/ DCG∗(q ) : this is the negated contribution of the gth good document to the NDCG ( Discount ) . After the last row , we will add up ( negative ) loss contributions from each row and add to 1 to get ∆NDCG . b → . . . . . .
S
0 k − 1 ≥ k
. . .
( n− − 1 )
◦
◦
• ◦
[ g , b ] for b = 0 , 1 , . . . , n− − 1 do
0 . . . g k − 1 . n+ − 1 1 : obtain sorted good list G and bad list B 2 : initialize objective matrix S to zeros 3 : for g = 0 , 1 , . . . , n+ − 1 do 4 : 5 : 6 : 7 : 8 : 9 : 10 : 11 : 12 : 13 : 14 : 15 : 16 : 17 : 18 :
{first good doc} S[g , b ] ← cellValue {several good docs before first bad} S[g , b ] ← S[g − 1 , 0 ] + cellValue {general recurrence with g , b > 0} p∗ ← arg max0≤p≤b S[g , b ] ← S[g − 1 , p∗ ] + cellValue
{g good and b bad before xg} find cellLoss ← CellLoss(g , b ) ( see text ) find cellScore ← CellScore(g , b ) ( see text ) cellValue ← cellLoss + cellScore if g = 0 then else if g > 0 and b = 0 then else
˘S[g − 1 , p ] + cellValue¯
Figure 2 : Generic SVMndcg pseudocode .
For clarity , Figure 2 shows a generic procedure that may also be useful for other loss functions . For the specific case of NDCG , the following observations simplify and speed up the algorithm considerably . Fact 33 The optimal solution can be found using a reduced table of size min{n+ , k}×(k +1 ) instead of the n+×n− table shown . Proof . We keep the first k columns 0 , . . . , k − 1 as is , but columns k through n− can be folded into a single column representing the best solution in row g for ‘b ≥ k’ . This is possible because , right of column k , cellLoss becomes zero , so the best cellValue is the best cellScore , which can be obtained by binary searching bad documents bk , . . . , bn−−1 with key sg . This reduces our table size to n+ × ( k + 1 ) . However , there is also no benefit to considering more than k good documents , so we can further trim the number of rows to k if k < n+ .
Fact 34 Instead of the general recurrence
˘S[g − 1 , p ] + cellValue¯ ,
S[g , b ] ← max 0≤p≤b which takes Θ(k2 ) time per cell and O(k3 ) time overall , we can first find the best column for the previous row g − 1 : S[g − 1 , b ] ,
∗ g−1 = arg max
∗ g−1 = max
S[g − 1 , b ] ,
S b b b and then set S[g , b ] = max b∗ g−1≤b
˘S g−1 + cellValue(g , b)¯ ,
∗ which will take k2 time overall .
Proof . This involves a swap argument similar to Yue et al . [ 9 , Lemma 1 ] to show that b∗ g , ie , even though the optimal column in each row is being found greedily , these columns will monotonically increase with g . This follows the same argument as Yue et al . [ 9 ] and is omitted . g−1 ≤ b∗ timeP
Therefore , we can execute each ‘argmax’ step of SVMndcg in O(k2 + n log n ) time , using φpo and ∆NDCG . The initial sorting of good and bad documents by their current scores sqi dominates the time . q n− q O(n+
Because MAP needs to optimize over the location of all good documents , the ‘argmax’ ( 2 ) step in SVMmap took q + nq log nq ) . Because NDCG is clipped at rank k , SVMndcg can be faster , although , in practice , the O(nq log nq ) term tends to be the dominating term . Not clipping at k : Comparing ( MRR ) , ( NDCG ) and ( MAP ) , we see that in case of MRR and NDCG , no credit accrues for placing a good document after rank k , whereas in case of MAP , a good document will fetch some credit no matter where it is placed . This means that SVMmrr and SVMndcg get no signal when if improves the position of good documents placed beyond rank k . We can give SVMndcg the same benefit by effectively setting k = ∞ . The dynamic programming or greedy algorithms can be adapted , like SVMmap , to run in O q + nq log nq ) time . We will call this option SVMndcg nc , for “ no clip ” . 3.5 Review of the DORM algorithm
“ P q n− q(n+
”
A different feature encoding , φdorm described in Section 313 , was used very recently by Le et al . [ 17 , 18 ] to perform a Direct Optimization of Ranking Measures ( DORM ) . In this case , optimization ( 2 ) takes the form arg maxy
= arg maxy
P P i A(y(i))(w>xi ) −P i A(y(i))(w>xi ) + ∆NDCG(y∗ , y ) D(y(i ) ) DCG∗ zi P i,j πij(siA(j ) − zidj ) . i arg maxπ
This is equivalent to filling in a permutation matrix ( a square 0/1 matrix with exactly one 1 in each row and column ) π to optimize an assignment problem [ 20 ] of the form
The Kuhn Munkres assignment algorithm takes O(n3 ) time in the worst case , which is much larger than the time taken by SVMndcg . The time can be reduced by making A very sparse . Eg , we might force A(r ) = 0 for r > k , but the √ resulting accuracy is inferior to a smooth decay such as A(r ) = 1/
1 + r [ 18 ] , which needs O(n3 ) time .
An important limitation of DORM , thanks to using the assignment paradigm , is that it cannot “ count good documents to the left of a position ” , and so cannot deal with MAP or MRR at all .
As we shall see in Section 4.4 , SVMndcg is substantially faster than DORM while having quite comparable accuracy . 3.6 New algorithm SVMmrr
Because of the change in feature map from φpo to φmrr , we have to redesign the ‘argmax’ routine . The pseudocode for solving ( 2 ) in SVMmrr is shown in Figure 3 . Below we explain how it works .
5
B = b0 , . . . , bn−−1
1 : inputs : current w , x1 , . . . , xn , clip rank k 2 : obtain sorted good list G = g0 , . . . , gn+−1 and bad list 3 : maxObj ← −∞ , argMaxOrder ← null 4 : for r = 0 , 1 , . . . , k − 1 do 5 : 6 : 7 : merge br , . . . , bn−−1 and g0 , . . . , gn+−2 in decreasing initialize empty output sequence o append b0 , . . . , br−1 ; gn+−1 to o
1+r + w>φmrr(x , o ) score order to o obj ( o ) ← 1 − 1 if obj ( o ) > maxObj then maxObj ← obj ( o ) argMaxOrder ← o
8 : 9 : 10 : 11 : 12 : build remaining output sequence o with r ≥ k and 13 : if obj ( o ) = 1 + w>φmrr(x , o ) > maxObj then 14 : maxObj ← obj ( o ) argMaxOrder ← o 15 : 16 : return optimal order o for generating new constraint
∆MRR = 1 as described in text
Figure 3 : SVMmrr pseudocode for one query . In an implementation we do not need to materialize o .
Fact 35 With φmrr and ∆MRR , ( 2 ) can be solved for a query q in time O(nq log nq + k2 + k log nq ) .
Proof . With φmrr and ∆MRR , instead of using Fact 3.2 , we collect all solutions y for the objective w>φmrr(x , y ) + ∆MRR(y∗ , y ) into clusters , each having a common value of ∆MRR(y∗ , y ) . Note that ∆MRR(y∗ , y ) can only take values from the set {0 , 1/k , 2/k , . . . , 1} , so we can afford to first optimize the objective within each cluster and take the best of these k + 1 solutions . Consider all solutions y with ∆MRR(y∗ , y ) = 1− 1/(1 + r ) , ie , the MRR of ordering y is 1/(1 + r ) ( 0 ≤ r < k ) because the first good document is at position r ( beginning at 0 ) . Inspecting φmrr in ( 5 ) , it is easy to see that within this cluster of solutions , the y that maximizes w>φmrr(x , y ) is the one that fills ranks 0 , . . . , r − 1 with bad documents having the largest scores , and then places the good document with the smallest score at rank r . What documents are placed after the first good document is immaterial to φmrr , and therefore we can save the effort . The last cluster of orderings is where there is no good document in any of ranks 0 , . . . , k− 1 and the MRR is 0 and ∆MRR = 1 . In this case , clearly the k bad documents with the largest scores should occupy ranks 0 , . . . , k−1 . Now consider the good document xg with the smallest score sg . We should now place all bad documents with score larger than sg , after which we place xg . Again , how other documents are placed after xg does not matter . 3.7 SVMcombo : Multicriteria ranking
Conventional wisdom underlying much work on learning to rank is that it is better to train for the loss function on which the system will be evaluated . As we have argued in Section 1.2 , search systems typically face a heterogeneous workload . It may not be advisable to ultra optimize a ranking system toward one criterion . Moreover , our experiments ( Section 4.5 ) suggest that a test criterion is not reliably optimized by training with the associated loss function .
A related question of theoretical interest is , must one necessarily sacrifice accuracy on one criterion to gain accuracy in another , or are the major criteria ( AUC , MAP , MRR and NDCG ) sufficiently related that there can be a common model serving them all reasonably well ? Once a model w is trained by optimizing ( 1 ) , during testing , given xq we return f ( xq , w ) = arg maxy w>φ(xq , y ) . DeP fine the following empirical risk as q ∆(y∗
R(w , ∆ ) = 1|Q| q , f ( w , xq) ) .
In presence of multiple kinds of loss functions ∆l , l = 1 , . . . , L , we can modify learning problem ( 1 ) in at least two ways . Shared slacks : We define an aggregate loss ∆(y , y0 ) = maxl ∆l(y , y0 ) , and then assert the same constraint as in ( 1 ) . This is done by simply asserting more constraints , on behalf of each ∆l : ∀l,∀q,∀y 6= y
P q ξq ≥ R(w , maxl ∆l ) . At optimality , we can see that Separate slacks : The other option is to aggregate the eml R(w , ∆l ) , in which case , we have to declare separate slacks ξl q for each query q and loss type l . These slacks have different “ units ” and should be combined q . For simplicity we set all Cl = C ; pirical risk , as P as ( 1/|Q|)P P q , y ) ≥ ∆l(y ∗ 1|Q| q , y ) − ξq . ∗
∗ q : w
δφxq ( y
> q ξl l Cl learning Cls is left for future work .
X
X
>
1 w + C|Q| 2 w arg min w;ξ≥~0 q , y ; xq ) ≥ ∆l(y ∗
δφ(y
> l q q , y ) − ξl ∗ q .
ξl q st q ≥ R(w , ∆l ) , therel R(w , ∆l ) . Because maxl ∆l(y , y0 ) ≤ q ξl
1|Q|
P
As before , we can see that
∀l , q,∀y 6= y
∗ q : w
P q ≥P foreP P l ∆l(y , y0 ) , we haveP q ξl
1|Q| l l R(w , ∆l ) ≥ R(w , maxl ∆l ) .
Therefore , if there is a mix of queries that benefit from different loss functions , such as some navigational queries that are served well by MRR and some exploratory queries served better by NDCG , separate slacks may perform better , which is indeed what we found in experiments . 3.8 Review of McRank
For completeness , we compare the structured learning ap
McRank assigns a scoreP proaches ( SVMauc , SVMmap , SVMmrr , SVMndcg , DORM , SVMcombo ) against McRank , which is among the best of the lower half of Figure 1 . Li et al . [ 10 ] have found McRank to be generally better than LambdaRank [ 6 ] and FRank [ 21 ] ; SoftRank is comparable to LambdaRank [ 8 ] and both are generally better than RankNet [ 3 ] . McRank uses a boosted ensemble of regression trees [ 22 ] to learn a non linear itemwise model for Pr(z|xqi ) , ie , the probability of falling into each relevance bucket ( in this paper we have mostly considered z ∈ {0 , 1} ) . The interesting twist is that , instead of assigning relevance arg maxz Pr(z|xqi ) , z z Pr(z|xqi ) to the ith document responding to query q , and then sorts the documents by decreasing score . Note that McRank has no direct hold on true loss functions like MAP , MRR or NDCG . We implemented the boosting code in Java , taking advantage of the WEKA [ 23 ] REPTree implementation . 4 . EXPERIMENTS 4.1 Data preparation
Inside the LETOR distribution [ 16 ] there are three data sets , OHSUMED ( 106 queries , 11303 bad documents , 4837
6 good documents ) , TD2003 ( 50 queries , 48655 bad documents , 516 good documents ) and TD2004 ( 75 queries , 73726 bad documents , 444 good documents ) . Each document has about 25–45 numeric attributes . These are scaled to [ 0 , 1 ] within each query as specified in the LETOR distribution . We observed that LETOR has many queries for which the same feature vector is marked as both good and bad . In addition there are feature vectors with all elements exactly equal to zero . A robust training algorithm is expected to take these in stride , but test accuracy falls prey to breaking score ties arbitrary . This can give very unstable results especially given the modest size of LETOR . Therefore we eliminated all zero feature vectors and good and bad vectors whose cosine similarity was above 099 Although this further reduced the number of queries , the comparisons became much more reliable . In our other data set obtained from Yue et al . [ 9 ] , TREC 2000 has 50 queries , 218766 bad documents and 2120 good documents . TREC 2001 has 50 queries , 203507 bad documents and 2892 good documents . 4.2 φ , ∆ and ease of optimization rithms , the value of ( 1/|Q|)P
Obviously , formulating a structured learning approach to ranking does not guarantee healthy optimization . The purpose of this section is to highlight that structured ranking algorithms suffer from various degrees of distress during training , and offer some analysis . Average slack vs . C : Figure 4 shows , for different algoq ξq ( an upper bound on the training loss ) when the optimizer terminates , against C . DORM , SVMmrr , and SVMauc show the most robust reduction in average slack with increasing C . Note that DORM and SVMmrr use custom feature maps . Also , φpo is ideally suited for ∆AUC . When constraints are added in SVMauc , each term ( 1/n+n−)ygb(sg − sb ) on the lhs w>δφ is matched to one term ( 1/n+n−)(1− ygb ) on the rhs ∆AUC .
Figure 4 : Different behavior of ( 1/|Q|)P mination for different algorithms as C increases . q ξq at ter
SVMmap and SVMndcg have a harder time . We conjec ture that this is caused by a mismatch between ∆MAP , ∆NDCG , and φpo . The lhs of constraints now consist of sums of ( variable numbers of ) score differences , while the rhs have a much more granular loss ∆ not sufficiently sensitive to the variation on the lhs . Training objective : Let obj(w = ~0 ) be the value of the objective in ( 1 ) for w = ~0 , and obj be the optimized training objective . For C = 0 , w = ~0 is the optimum . A plot of obj/obj(w = ~0 ) against C ( Figure 5 ) is an indication of how well w is adapting to increasing C . The results are related
7 to Figure 4 : DORM , SVMauc and SVMmrr adapt best , while SVMmap and SVMndcg stay close to w = ~0 , but , luckily , not quite at w = ~0—see Figure 6 .
Figure 5 : obj/obj(w = ~0 ) for different algorithms as C increases .
Figure 6 : Different behavior of |w| at termination for different algorithms as C increases . Rightmost point arbitrarily scaled to 1 for comparison .
4.3 SVMmrr evaluation
Indirect support for our conjecture comes from Figure 7 . It shows the benefits of using φmrr instead of φpo for optimizing MRR . Over all data sets , there is a consistent large gain in MRR when φmrr is used , compared to φpo . However , from Figure 9 , we see that training with some criterion other than MRR is almost always best for test MRR scores . Specifically , SVMcombo almost always beats SVMmrr . Similar to Taylor et al . [ 8 ] , we conjecture that this is because the “ true ” loss function ∆MRR and φMRR are losing information from multiple good documents . SVMcombo “ hedges the bet ” in a principled manner . 4.4 SVMndcg scalability and accuracy
The three data sets inside the LETOR distribution have different sizes , which makes it easy to do scaling experiments . OHSUMED has a total of 16140 documents , TD2003 has 49171 , and TD2004 has 74170 ; this is roughly 1:3:46 OHSUMED has 106 queries , TD2003 has 50 and TD2004 has 75 . In these experiments we gave DORM the benefit of a sparse A(· ) decay function decaying to zero after rank 30 , which was what was required to approach or match the accuracy of SVMndcg . From Figure 8 we see that the total time taken by DORM is substantially larger than SVMndcg , and scales much more steeply than 1:3:4.6 , which is expected from the nature of the assignment problem .
In contrast , the total time taken by SVMndcg is much smaller . For TD2004 , SVMndcg took only 19 seconds while
002040608100101110100svmCavgXiDORMSVMmapSVMmrrSVMndcgSVMauc02040608100101110100svmCobj/obj(w=0)DORMSVMmapSVMmrrSVMndcgSVMauc1E 81E 61E 41E 21E+01E 21E+01E+21E+4svmC|w|^2DORMSVMmapSVMmrrSVMndcgSVMauc approximation to ∆NDCG .
• Often , SVMmap does not give the best test MAP . • SVMcombo ( using MAP , NDCG , NDCG NC , and MRR components variously ) is most consistently among the top two performers in each column . Sometimes SVMcombo ’s accuracy is greater than any of its constituents . • Despite spending O(n3 ) time in optimization ( 2 ) , DORM • Similarly , McRank rarely wins over SVMcombo and never tops the chart in any column .
SVMmap ( two of nine columns ) . 4.6 Comparison with McRank
Figure 7 : Comparison of φmrr against φpo for the MRR criterion .
Figure 8 : Breakdown of DORM time into assignment [ 20 ] and quadratic optimization ; compared with breakdown of SVMndcg time into time taken by the ‘argmax’ calculations ( Figure 2 ) and quadratic optimization .
DORM needed 283 seconds . Obviously the gap will only grow with increasing data sizes . Proprietary training data mentioned in the literature [ 10 ] have millions of documents . Also noteworthy is the very small time taken in the QP optimizer ( invisible for DORM , barely visible for SVMndcg ) . We used a very recent and fast implementation of LaRank [ 24 ] . This shows that solving the ‘argmax’ problem ( 2 ) quickly for large data sets is important , because the QP solver is not the bottleneck .
Figure 9 compares test NDCG at rank 10 for different training criteria . SVMndcg and DORM come out about even , but SVMndcg nc is consistently better than DORM . 4.5 SVMcombo evaluation
At this point , it is of interest to complete a table where each row corresponds to a training criterion , and each column is a test criterion . Conventional wisdom suggests that the trainer that gives the best test NDCG will be the one that uses ∆NDCG and so on . Figure 9 shows that this is rarely the case! Specifically ,
• ∆MRR is never best for test MRR . • SVMndcg , which uses the “ true ” ∆NDCG loss , consistently loses to SVMndcg nc , which uses only an
8
We finally consider the training speed and test accuracy of McRank . Our WEKA based implementation exceeded 2 GB of RAM for each of TREC 2000 and TREC 2001 , and was unreasonably slow . So we limit our study to the LETOR data . In only two of the nine columns pertaining to LETOR does McRank show substantial advantage ; in the remaining seven , one of the list wise structured learning approaches is better .
McRank ’s occasional lead comes at a steep RAM and CPU cost . The CPU time is dominated by the time to induce CART [ 22 ] style regression trees . The number of rounds of boosting was set between 1500 and 2000 by Li et al . [ 10 ] ; we found this too slow ( corroborated elsewhere [ 19 ] ) and also unnecessary for accuracy . On LETOR more than 30–40 rounds sometimes hurt accuracy , so we set the number of boosting rounds to 30 ; this only tips the scales against us wrt performance . Even so , we find in Figure 10 that McRank can be computationally more expensive that structured learners by two orders of magnitude . 5 . CONCLUSION
Using the structured learning framework , we proposed novel , efficient algorithms for learning to rank under the MRR and NDCG criteria . The new algorithms are comparable to known techniques in terms of accuracy but are much faster . We then presented SVMcombo , a technique to optimize for multiple ranking criteria . SVMcombo may be preferable for real life search systems that serve a heterogeneous mix of queries . Our exploration revealed that structured ranking often suffers from a mismatch between the feature map φ(x , y ) and the loss function ∆(y , y0 ) . Designing loss specific feature maps for better training optimization remains a central problem that merits further investigation . Acknowledgment : Thanks to Thorsten Joachims and Yisong Yue for the TREC 2000 and TREC 2001 data , to Sundar Vishwanathan for discussions , and to Sunita Sarawagi for discussions and the LARank implementation . e e r t k n a R c M Dataset OHSUMED 1034 9730 TD2003 8760 TD2004 t s o o b k n a R c M 67 383 548 l a t o t k n a R c M 1102 10113 9308 g c d n M V S 4.8 14.9 19.1 r r m M V S 30.6 125 148
Figure 10 : Break up of McRank running time and comparison with SVMndcg and SVMmrr ( times in seconds ) .
0304050607080123456789kMRRTD2004 phi_poTD2004 phi_mrrTD2003 phi_poTD2003 phi_mrrOHSUMED phi_poOHSUMED phi_mrr050000100000150000200000250000300000OHSUMEDTD2003TD2004OHSUMEDTD2003TD2004DORMSVMndcgAlgos,DataSetsTime(ms) >QPArgMax Figure 9 : Test accuracy vs . training loss function used . Contrary to conventional wisdom , the best test accuracy on a given loss function may be the result of training on some other loss function . SVMcombo and SVMmap are among the most robust trainers . 6 . REFERENCES [ 1 ] R . Herbrich , T . Graepel , and K . Obermayer , “ Support vector learning for ordinal regression , ” in International Conference on Artificial Neural Networks , 1999 , pp . 97–102 . http://wwwresearchmicrosoftcom/∼rherb/paper s/hergraeober99bpsgz retrieving highly relevant documents , ” in SIGIR Conference , 2000 , pp . 41–48 . http://wwwinfoutafi/tutk imus/fire/archive/KJJKSIGIR00.pdf
42–51 . http://trecnistgov/pubs/trec10/t10 proceedings.html
[ 14 ] K . J¨arvelin and J . Kek¨al¨ainen , “ IR evaluation methods for
[ 2 ] T . Joachims , “ Optimizing search engines using clickthrough data , ” in SIGKDD Conference . ACM , 2002 . http://www . cscornelledu/People/tj/publications/joachims 02c.pdf
[ 3 ] C . Burges , T . Shaked , E . Renshaw , A . Lazier , M . Deeds , N . Hamilton , and G . Hullender , “ Learning to rank using gradient descent , ” in ICML , 2005 . http://research.microso ft.com/∼cburges/papers/ICML ranking.pdf
[ 4 ] T . Joachims , “ A support vector method for multivariate performance measures , ” in ICML , 2005 , pp . 377–384 . http://wwwmachinelearningorg/proceedings/icml2005/pa pers/048 ASupport Joachims.pdf
[ 5 ] —— , “ Training linear SVMs in linear time , ” in SIGKDD
Conference , 2006 , pp . 217–226 . http://wwwcscornelledu /people/tj/publications/joachims 06a.pdf
[ 6 ] C . J . C . Burges , R . Ragno , and Q . V . Le , “ Learning to rank with nonsmooth cost functions , ” in NIPS , 2006 . http://re searchmicrosoftcom/∼cburges/papers/LambdaRankpdf
[ 7 ] Z . Cao , T . Qin , T Y Liu , M F Tsai , and H . Li , “ Learning to rank : From pairwise approach to listwise approach , ” in ICML , 2007 , pp . 129–136 . http://wwwmachinelearningor g/proceedings/icml2007/papers/139.pdf
[ 8 ] M . Taylor , J . Guiver , S . Robertson , and T . Minka ,
“ SoftRank : Optimising non smooth rank metrics , ” in WSDM . ACM , 2008 . http://researchmicrosoftcom/∼jog uiver/sigir07LetorSoftRankCam.pdf
[ 15 ] E . Snelson and J . Guiver , “ SoftRank with gaussian processes , ” in NIPS 2007 Workshop on Machine Learning for Web Search , 2007 . http://researchmicrosoftcom /CONFERENCES/NIPS07/papers/gprank.pdf
[ 16 ] T Y Liu , T . Qin , J . Xu , W . Xiong , and H . Li , “ LETOR :
Benchmark dataset for research on learning to rank for information retrieval , ” in LR4IR Workshop , 2007 . http://researchmicrosoftcom/users/LETOR/
[ 17 ] O . Chapelle , Q . Le , and A . Smola , “ Large margin optimization of ranking measures , ” in NIPS 2007 Workshop on Machine Learning for Web Search , 2007 . http://researchmicrosoftcom/CONFERENCES/NIPS07/ papers/ranking.pdf
[ 18 ] Q . V . Le and A . J . Smola , “ Direct optimization of ranking measures , ” Feb . 2008 , arXiv:07043359v1 http://arxivorg/pdf/07043359
[ 19 ] C . Burges , “ Learning to rank for Web search : Some new directions , ” Keynote talk at SIGIR Ranking Workshop , July 2007 . http://researchmicrosoftcom/users /LR4IR 2007/LearningToRankKeynote Burges.pdf
[ 20 ] R . Ahuja , T . Magnanti , and J . Orlin , Network Flows .
Prentice Hall , 1993 .
[ 21 ] M F Tsai , T Y Liu , T . Qin , H H Chen , and W Y Ma ,
“ FRank : A ranking method with fidelity loss , ” in SIGIR Conference , 2007 , pp . 383–390 . http : //portalacmorg/ft gateway.cfm?id=1277808&type=pdf
[ 9 ] Y . Yue , T . Finley , F . Radlinski , and T . Joachims , “ A
[ 22 ] L . Breiman , J . H . Friedman , R . A . Olshen , and C . J . Stone ,
Classification and Regression Trees . Wadsworth & Brooks/Cole , 1984 , iSBN : 0 534 98054 6 .
[ 23 ] I . H . Witten and E . Frank , Data Mining : Practical machine learning tools and techniques , 2nd ed . San Francisco : Morgan Kaufmann , 2005 . http://wwwcswaikatoacnz/ml/weka/
[ 24 ] A . Bordes , L . Bottou , P . Gallinari , and J . Weston , “ Solving multiclass support vector machines with LaRank , ” in ICML . ACM , 2007 , pp . 89–96 . http://www.machinelearn ingorg/proceedings/icml2007/papers/381pdf support vector method for optimizing average precision , ” in SIGIR Conference , 2007 . http://wwwcscornelledu/Peop le/tj/publications/yue etal 07a.pdf
[ 10 ] P . Li , C . J . C . Burges , and Q . Wu , “ McRank : Learning to rank using multiple classification and gradient boosting , ” in NIPS , 2007 , pp . 845–852 . http : //booksnipscc/papers/files/nips20/NIPS2007 0845.pdf
[ 11 ] V . Vapnik , S . Golowich , and A . J . Smola , “ Support vector method for function approximation , regression estimation , and signal processing , ” in Advances in Neural Information Processing Systems . MIT Press , 1996 .
[ 12 ] I . Tsochantaridis , T . Joachims , T . Hofmann , and Y . Altun , “ Large margin methods for structured and interdependent output variables , ” JMLR , vol . 6 , no . Sep , pp . 1453–1484 , 2005 . http : //tticuchicagoedu/∼altun/pubs/TsoJoaHofAlt JMLRpdf
[ 13 ] E . Voorhees , “ Overview of the TREC 2001 question answering track , ” in The Tenth Text REtrieval Conference , ser . NIST Special Publication , vol . 500 250 , 2001 , pp .
9
MRR10NDCG10MAPMRR10NDCG10MAPMRR10NDCG10MAPMRR10NDCG10MAPMRR10NDCG10MAPAUC799635582510349256639501420607448267632441264MAP808642586618411314614496412696469277636450272NDCG790636581587372302631457374517323175608356171NDCG NC818640582595404306611486404685455265624443264MRR795623570628405330629441383670410244643426230COMBO813635578667434345647458384695465277647449272DORM807637583587362290474340297662413243621435250McRank701565527650403232588529453TREC2001OHSUMEDTD2003TD2004TREC2000
