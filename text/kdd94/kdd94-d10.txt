From : AAAI Technical Report WS 94 03 . Compilation copyright © 1994 , AAAI ( wwwaaaiorg ) All rights reserved .
Knowledge Discovery
Dealing with Uncertainties in Large Image Databases : in Ground Truth
Smytht , Michael C . Burl iS , Usama M . Fayyad~ , t Jet Propulsion Laboratory
~
~ Electrical Engineering and Pietro
Perona
Padhraie
California Institute of Technology MS 525 3660 ~ Pasadena , CA 91109
{pj s , fayyad}@aig , jpl . nasa . gov
California Institute of Technology MS 116 81 Pasadena , CA 91125 {burl , perona}@syst,~s . ¢al~ech . edu
Abstract
This paper discusses the problem of knowledge discovery in image databases with particular focus on the issues which arise when absolute ground truth is not available . The problem of searching the Magellan image data set in order to automatically locate and catalog small volcanoes on the planet Venus is used as a case study . In the absence of calibrated ground truth , planetary scientists provide subjective estimates of ground truth based on visual inspection of Magellan images . The paper discusses issues which arise in terms of elicitation of subjective probabilistic opinion , learning from probabilistic labels , and effective evaluation of both scientist and algorithm performance in the absence of ground truth . Data from the Magellan volcano detection project is used to illustrate the various techniques which we have developed to handle these issues . The primary conclusion of the paper is that knowledge discovery methodologies can be modified to handle lack of absolute ground truth provided the sources of uncertainty in the data are carefully handled .
1
I.ntroduction in image databases . This paper tackles
At last year ’s KDD workshop we presented initial results on building an automated system for locating and cataloging small volcanoes on the surface of Venus , using radar images returned by the Magellan spacecraft [ Fayy93 ] . In particular we discussed some of the issues which are unique to the problem of knowledge discovery the problem of developing and evaluating knowledge discovery systems for image databases when ground truth is not available . Remote sensing image analysis problems where there is a complete absence of ground truth are increasingly common : the Magellan volcano detection project example . Indeed , the problem is not unique to image analysis in certain medical diagnosis applications where absolute diagnoses are never applications , known with certainty [ Henk90 ] . In general , one cannot be sure that class labels ( or values of the "dependent in some cases , this uncertainty in variable" ) are noise free . The core issue addressed in this paper is that , class labels , or "lack of ground truth" , must be dealt with explicitly : it needs to be estimated and then it needs to be accounted for by the learning algorithms employed . is used as an illustrative it also arises
The phrase "lack of ground truth" requires some comment : what is typically available is not a complete lack of ground truth , but rather , subjective estimates of ground truth . In other words , a domain expert ( or group of same ) examines the available data ( an image ) and provides a subjective estimate of the class labels locations within the image . Hence , there is an additional source of noise in the data , namely for particular that this noise source be modeled and calibrated as far the nois~ e~timGtes from the ezpert . It is critical as possible . The alternative is to ignore the noisy nature of the labelling process , assume that the labels are correct , and condition all algorithm design , parameter estimation , and performance evaluation on this premise . If the labelling process is not very noisy this is often the practical approach .
In this paper we focus on the case where there is considerable visual ambiguity in the images , such that there will be significant differences on the same data between the labels of the same expert at different times and between different experts . Ignoring this source of noise is likely to lead to a significantly miscalibrated
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 109 system . For example , in the volcano detection problem , the local density of volcanoes in a given planetary region is a parameter of significant geological relevance . Ignoring the subjective uncertainty in the labelling would lead to a systematic bias in terms of over estimating local volcano densities .
The paper is structured in the following manner : first the general background to the problem is described , namely the Magellan mission and the scientific importance and relevance of investigating volcanism on Venus . We then review our overall philosophy behind developing "user trainable" tools for knowledge discovery in databases , focusing in particular on the development of machine learning and pattern recognition tools which allow a scientist to train a search algorithm based on sample objects of interest . This sets the stage for the main discussion of the paper : the modeling and treatment of subjective label information . We outline the experimental methodology and basic principles of subjective elicitation , using data obtained from the participating scientists as examples . The following issues are then discussed in some detail : noise models to relate probabilistic labels to ground truth , performance evaluation metrics which incorporate probabilistic labels , and learning algorithm modifications . We note that previous work in the pattern recognition literature has dealt with some of the general theoretical aspects of this problem [ Lug92 , SilverS0 ] ; the originality of the work described here lies in the handling of the ground truth ambiguity problem in the context of a large scale , real world , image analysis problem .
2 . Background : Automated Detection of Volcanoes in Radar Im ages of Venus
Both in planetary science and astronomy , image analysis is often a strictly manual process and much investigative work is carried out using hardcopy photographs . However , due to the sheer enormity of the image databases currently being acquired , simple manual cataloging is no longer a practical consideration if aU of the available data is to be utilized . The Magellan Venus data set is a typical instance of the now familiar data glut situation in scientific , medical , industrial and defense contexts .
The background to this work is the notion of a trainable image analysis system ; a scientist trains the system to find certain geological features by giving it examples of features to be located . The scientist can thus customize the tool to search for one type of feature versus another simply by providing positive and negative examples . In addition to automating laborious and visually intensive tasks , the system provides an object~e , examinable , and repeatable process for detecting and classifying objects in images . This allows scientists to base their analysis results on uniformly consistent data , free from subjective variations that invariably creep in when a visually exhausting task requiting many months or years is undertaken .
The Magellan spacecraft transmitted back to earth a data set consisting of over 30,000 high resolution synthetic aperture radar ( SAR ) images of the Venusian surface . This data set is greater than that gathered all previous planetary missions combined planetary scientists are literally swamped by data [ Fayy94 ] . The study of volcanic processes is essential to an understanding of the geological evolution of the planet [ Guest92 ] . Central to volcanic studies is the cataloging of each volcano location and its size and characteristics . There are estimated to be on the order of 10e visible volcanoes scattered throughout the 30,000 images [ Aubele90 ] . Furthermore , it has been estimated that manually locating all of these volcanoes would require on the order of 10 man years of a planetary geologist ’s time to carry out .
Empirical results using spatial eigenrepresentations ( combined with supervised classification algorithms ) have demonstrated that a trainable image analysis system can be roughly competitive with humans in terms of classification accuracy [ Bur194 , Fayy94 ] . The system uses a matched filter ( for example , the mean of locally windowed training examples of volcanoes ) to initially focus attention on local regions of interest . The detected local regions are projected into a subspace consisting of significant principal components of the training data . Although the full covariance matrix of the data ( whose . largest eigenvectors correspond to principal components ) cannot be computed given the available sample sizes , the approximate eigenvectors can be computed using the singular value decomposition ( SVD ) technique [ Bur194 ] . Supervised learning is used to produce a model which can discriminate between volcano and non volcano local regions in the projected subspace . A simple maximum likelihood multi dimensional Gaussian classifier with full covariance matrices has been found to perform as well as alternative non parametric methods such as neural networks and decision trees for the problem of discriminative learning in the projected eigenspace [ Bur194 ] .
Page 110
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94
Knowledge Discovery
Dealing with Uncertainties in Large Image Databases : in Ground Truth
Padhralc Smytht , Michael C . Burlt$ , Usama M . Fayyad* , and Pietro Perona$ t Jet Propulsion Laboratory
~ Electrical Engineering
California Institute of Technology MS 525 3660 Pasadena , CA 91109
{pj s , fayyad}@aig , jpl . nasa . gov
California Institute of Technology MS 116 81 p Pasadena , CA 91125 {burl , perona}@systems , caltech , edu
Abstract
This paper discusses the problem of knowledge discovery in image databases with particular focus on the issues which arise when absolute ground truth is not available . The problem of searching the Magellan image data set in order to automatically locate and catalog small volcanoes on the planet Venus is used as a case study . In the absence of calibrated ground truth , planetary scientists provide subjective estimates of ground truth based on visual inspection of Magellan images . The paper discusses issues which arise in terms of elicitation of subjective probabilistic opinion , learning from probabilistic labels , and effective evaluation of both scientist and algorithm performance in the absence of ground truth . Data from the Magellan volcano detection project is used to illustrate the various techniques which we have developed to handle these issues . The primary conclusion of the paper is that knowledge discovery methodologies can be modified to handle lack of absolute ground truth provided the sources of uncertainty in the data are carefully handled .
1
I.ntroduction a in image databases . This paper tackles
At last year ’s KDD workshop we presented initial results on building an automated system for locating and cataloging small volcanoes on the surface of Venus , using radar images returned by the Magellan spacecraft [ Fayy93 ] . In particular we discussed some of the issues which are unique to the problem of knowledge discovery the problem of developing and evaluating knowledge discovery systems for image databases when ground truth is not available . Remote sensing image analysis problems where there is a complete absence of ground truth are increasingly common : the Magellan volcano detection project example . Indeed , the problem is not unique to image analysis applications , in certain medical diagnosis applications where absolute diagnoses are never known with certainty [ Henk90 ] . In general , one cannot be sure that class labels ( or values of the "dependent in some cases , this uncertainty in variable" ) are noise free . The core issue addressed in this paper is that , class labels , or "lack of ground truth" , must be dealt with explicitly : it needs to be estimated and then it needs to be accounted for by the learning algorithms employed . is used as an illustrative it also arises
The phrase "lack of ground truth" requires some comment : what is typically available is not a complete lack of ground truth , but rather , subjective estimates of ground truth . In other words , a domain expert ( or group of same ) examines the available data ( an image ) and provides a subjective estimate of the class labels locations within the image . Hence , there is an additional source of noise in the data , namely for particular the noisll e~timates from the expert . It is critical that this noise source be modeled and calibrated as far as possible . The alternative is to ignore the noisy nature of the labelling process , assume that the labels are correct , and condition all algorithm design , parameter estimation , and performance evaluation on this premise . If the labelling process is not very noisy this is often the practical approach .
In this paper we focus on the case where there is considerable visual ambiguity in the images , such that there will be significant differences on the same data between the labels of the same expert at different times and between different experts . Ignoring this source of noise is likely to lead to a significantly miscalibrated
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 109 system . For example , in the volcano detection problem , the local density of volcanoes in a given planetary region is a parameter of significant geological relevance . Ignoring the subjective uncertainty in the labelling would lead to a systematic bias in terms of over estimating local volcano densities .
The paper is structured in the following manner : first the general background to the problem is described , namely the Magellan mission and the scientific importance and relevance of investigating volcanism on Venus . We then review our overall philosophy behind developing "user trainable" tools for knowledge discovery in databases , focusing in particular on the development of machine learning and pattern recognition tools which allow a scientist to train a search algorithm based on sample objects of interest . This sets the stage for the main discussion of the paper : the modeling and treatment of subjective label information . We outline the experimental methodology and basic principles of subjective elicitation , using data obtained from the participating scientists as examples . The following issues are then discussed in some detail : noise models to relate probabilistic labels to ground truth , performance evaluation metrics which incorporate probabilistic labels , and learning algorithm modifications . We note that previous work in the pattern recognition literature has dealt with some of the general theoretical aspects of this problem [ Lug92 , Silver80 ] ; the originality of the work described here lies in the handling of the ground truth ambiguity problem in the context of a large scale , real world , image analysis problem .
2 Background : Automated Detection of Volcanoes in Radar Im ages of Venus
Both in planetary science and astronomy , image analysis is often a strictly manual process and much investigative work is carried out using hardcopy photographs . However , due to the sheer enormity of the image databases currently being acquired , simple manual cataloging is no longer a practical consideration i/all of the available data is to be utilized . The Magellan Venus data set is a typical instance of the now familiar data glut situation in scientific , medical , industrial and defense contexts .
The background to this work is the notion of a trainable the system to find certain geological features by giving it examples of features to be located . The scientist can thus customize the tool to search for one type of feature versus another simply by providing positive and negative examples . In addition to automating laborious and visually intensive tasks , the system provides an examinable , and repeatable process for detecting and classifying objects in images . This allows object’.rve , scientists that invariably creep in when a visually exhausting task requiring many months or years is undertaken . to base their analysis results on uniformly consistent data , free from subjective variations image analysis system ; a scientist trains
The Magellan spacecraft transmitted back to earth a data set consisting of over 30,000 high resolution synthetic aperture radar ( SAR ) images of the Venusian surface . This data set is greater than that gathered all previous planetary missions combined planetary scientists are literally swamped by data [ Fayy94 ] . The study of volcanic processes is essential to an understanding of the geological evolution of the planet [ Guest92 ] . Central to volcanic studies is the cataloging of each volcano location and its size and characteristics . There are estimated to be on the order of 10~ visible volcanoes scattered throughout the 30,000 images [ Aubeleg0 ] . Furthermore , it has been estimated that manually locating all of these volcanoes would require on the order of 10 man years of a planetary geologist ’s time to carry out . accuracy [ Bur194 , Fayy94 ] . The system uses a matched filter
Empirical results using spatial eigenrepresentations ( combined with supervised classification algorithms ) have demonstrated that a trainable image analysis system can be roughly competitive with humans in terms ( for example , the mean of of classification locally windowed training examples of volcanoes ) to initially focus attention on local regions of interest . The detected local regions are projected into a subspace consisting of significant principal components of the training data . Although the full covariance matrix of the data ( whose largest eigenvectors correspond to principal components ) cannot be computed given the available sample sizes , the approximate eigenvectors can be computed using the singular value decomposition ( SVD ) technique [ Bur194 ] . Supervised learning is used to produce a model which can discriminate between volcano and non volcano local regions in the projected subspace . A simple maximum likelihood multi dimensional Gaussian classifier with full covariance matrices has been found to perform as well as alternative non parametric methods such as neural networks and decision trees for the problem of discriminative learning in the projected eigenspace [ Bur194 ] .
Page 110
AAAI.94 Workshop on Knowledge Discovery in Databases
KDD 94
Category 4 :
Figure 1 : A small selection of volcanoes from four categories as labeled by the geologists .
3 Eliciting Ground Truth Estimates from Scientists real ground truth data does not In the volcano location problem , as in many remote sensing applications , exist . No one has ever actually been to the surface of Venus ( apart from a Russian robotic lander which melted within a few minutes ) , and despite the fact that the Magellan data is the best imagery ever obtained of Venus , scientists is indeed a volcano . cannot always determine with 100 % certainty whether a particular image feature
In principle , for a given local region of interest , a scientist can provide a subjective probability that a is preferable to forcing a "yes/no" decision . In particular , labels provide more information about the underlying Bayes optimal discrimination volcano exists at that point given the local intensity values . It can been shown [ Smyth94 ] that eliciting subjective probabilities ple size , probabilistic labels will converge boundary than "hard decision" is conditioned on the assumption that the more quickly as the sample size increases . However , this result It is well known that accurate scientists elicitation of subjective probabilities from humans is quite difficult and subject to various calibration errors and biases [ Kahn82 ] . are providing perfect unbiased subjective probability estimates . labels hence , learning methods based on probabilistic for a fixed training sam of Volcanoes
3.1 Defining Sub Categories A more effective approach in practice is to have the scientists label training examples into quantized probability bins , where the probability bins correspond to visually distinguishable sub categories of volcanoes . In particular , we have used 5 bins : ( i ) summit pits , bright dark radar pair , and apparent topographic slope , all clearly visible , probability 0.98 , ( ii ) only 2 of the 3 criteria in category ( i ) are visible , probability 0.80 , ( iii ) no summit pit visible , evidence of flanks or circular outline , probability 0.60 , ( iv ) only a summit visible , probability 0.50 , ( v ) no volcano like features visible , probability 00 The probabilities correspond to the mean probability location given that it has been identified as belonging to a particular bin . These probabilities were elicited based on considerable discussions with the participating planetary geologists . How we use these probabilities for both training and evaluation will be discussed in more detail in the next few sections . that a volcano exists at a particular
Figure 1 shows some typical volcanoes from.each category . The use of quantized probability bins to is not new : the same approach is routinely used in attach levels of certainty the evaluation of radiographic image displays to generate subjective ROC ( receiver operating characteristic ) curves [ Chest92 ] . However , this paper extends the basic approach by defining the notion of probabilistic ROC curves ( see Section 5 ) . to subjective image labels
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 111
Figure 2 : Magellan SAR image of Venus with consensus ground truth showing size and locations of small volcanoes .
3.2 Methodologies for Collecting Subjective Label Information
Participating in the development of the detection algorithm are planetary geologists from the Department of Geological Sciences at Brown University . We are fortunate to have direct collaboration with members of this group who have extensive experience in studying both earth based and planetary volcanism and have published some of the standard reference works on Venus volcanism [ Aubeleg0 , Guest92 ] . Hence , their collective subjective opinion is ( roughly speaking ) about as expert as one can find given the available data and our current state of knowledge about the planet Venus .
It is an important point that , in the absence of absolute ground truth , the goal of our work is to be as comparable in performance as possible to the scientists in terms of labelling accuracy . Absolute accuracy is not measurable for this problem . Hence , the best the algorithm can do is to emulate the scientist ’s performance this point will become clearer when we discuss performance metrics later in the paper .
A standard Magellan image consists of 1000 × 1000 pixels , where the pixels are 75m in resolution for the results referred to in this paper . Small volcano diameters are typically in the 2 3kin range , ie , 30 to 50 pixels wide . Volcanoes are often spatially clustered in volcano fields . As a consequence , most of the volcanoes are expected to be found in about 10 20 % of the total number of images , and within these images there may number as many as 100 or more volcanoes , although typically the number is in the 10 50 range .
The standard manner in which we obtain labels is to have a labeller interact with a special X windows interface implemented as part of the JARtool ( 3PL Adaptive Recognition Tool ) software package tool being developed for use by scientists in analyzing the magellan data set . The user mouse clicks locations of candidate volcanoes . Starting with a new image , the labeller proceeds to sequentially click on the estimated centers of the volcanoes and is then prompted to provide a subjective label estimate from a choice of categories 1 4 as described above . By default , locations which are not labeled are considered to have label "0" ( non
Page 112
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94 volcano ) . Clearly it is possible that based on the visual evidence , for the same local image patch , the same label may not be provided by different labellers , or indeed by the same labeller at different times . In addition to labels , the labeller can also provide a fitted diameter estimate by fitting a circle to the feature . Figure 2 shows a typical image labelled in this manner .
After completing the labelling , the result is an annotation of that image which can be stored in standard database format the unique key to the image is a label event , which corresponds to a particular tude/longitude ( to the resolution of the pixels ) for a particular labeller at a particular time ( since the same labeller may relabel an image multiple times ) . It is this database which provides the basic reference framework for deriving estimates of geologic parameters , training data for the learning algorithms , and reference data for performance evaluation . A simple form of spatial clustering is used to determine which label events ( from different labellers ) actually correspond to the same geologic feature ( volcano ) . It is fortunate that canoes tend not to overlap each other spatially and thus maintain a separation of at least a few kilometers , tend to be quite consistent in their centering of the mouse clicks mean and also that different scientists differences of about 2.5 pixels ( Euclidean distance ) have been found in cross comparisons of label data from different scientists , which is reasonable considering the precision one can expect from mouse location on a screen . lati
Table 1 : Confusion Matrix of Scientist A Vs . Scientist B .
Label 1 Label 2 Label 3 Label4 Not Detected
Scientist A
Scientist B Label 1 Label 2 Label 3 Label 4 Not Detected
19 9 13 1 4
8 8 12 4 8
4 6 18 5 29
1 5 1 24 16
3 5 37 15 0
Table 1 shows the confusion matrix between two geologists for a set of 4 images . The ( i,j)th element the co~sion matrix counts the number of label events which corresponded to labeller A generating label i and labeller B generating label j , where both labels were considered to belong to the same visual feature , ie , were within a few pixels of each other . The ( i , 0 ) entries count the instances where labeller A provided label i , but labeller B did not provide any label entry ( 0,0 ) is defined to be zero . Ideally , the confusion matrix would have all of its entries on the diagonal if both labellers agreed completely on all events . Clearly , however there is Substantial disagreement , as judged by the number of off diagonal counts in the matrix . For example , label 3’S are particularly noisy , in both "directions." Label 3 ’s are noisier than label 4 ’s because there is less variability in the appearance of 4 ’s compared to 3 ’s ( 4 ’s are simple pits , 3 ’s are less well defined ) . On the order of 50%of the label 3 ’s detected by either labeller are not detected at all by the other labeller . On the other hand only on the order of 10 % of the label l ’s of either matrix underlines the importance of modeling probabilistic labeller are missed by the other . The labels for this particular problem .
4 Relating Probabilistic
Labels to Ground Truth step is to determine what it means when a scientist
The first label : what is the that a volcano actually exists given a label ? We will use the shorthand v and v to denote probability the events "volcano present" and "volcano not present" , label , 0 _< ! _< lm~x ( /m~ = 4 for the labelling problem ) . Let V be a binary random variable taking values v and and let L be another discrete random variable taking values l , 1 < l < lmax . The shorthand notation of "v" for "V v," etc . , will be used . Note that we assume that labelling is stochastic rather than deterministic image region , a scientist may not always in the sense that presented multiple provide the same label . The relevant probabilities we are interested in are conditional probabilities of the in determining these probabilities lies in the fact that form p(volcanollabel ) = p(vll ) . Note that the difficulty and I to denote a particular times with the same local provides a particular respectively ,
KDD 94
AAA1 94 Workshop on Knowledge Discovery in Databases
Page 113 the V is a hidden variable and cannot be observed directly .
V
J
"
L
Figure 3 : Causal Model 1 of Volcano Labelling Process .
Consider Figure 3 which identifies a simple causal model : volcanoes are mapped to an image intensity i , which in turn is mapped to a label by the scientists . There is an implicit conditionalization on local pixel regions of fixed size , ie , treated as a series of decisions on such local regions . From Figure 3 we are ultimately interested in determining the probability of a volcano given i . To train and evaluate our models we need to estimate terms such as p(vIl ) . If we expand this out , we have to condition on all possible realizations of the image intensity i ; the labelling process is effectively
P(Vll ) = ~P(Vl~ , l)p(~ll ) i
( 1 )
Given the dimensionality of i ( all possible intensities of a local region ) , this method of estimating p(vll ) is clearly impractical . Note that the above equation can be rewritten as : p(vlZ ) = ~p(vl~)p(ill ) i
( 2 ) since by the causal model of Figure 3 , V is conditionally independent of L .
It is convenient to assume that the volcanoes correspond to visually distinguishable categories , namely "types." In addition , "type 0" will be used to identify all local images not covered by the "well distinguished" types ( ie , non volcanoes in general ) . "Type" will be treated as another random variable T , taking values 1 < t < tmax , where tmax " lmax typically . Conceptually it is useful to imagine that there is an Oracle who information ; the main point is that we do not have access can unambiguously identify to such an Oracle , but rather have access only to fallible scientists who provide labels , noisy estimates of types . In other words , T is an unobserved , hidden variable , while L is observed directly . " L types given intensity
I
V
" T r
Figure 4 : Causal Model 2 of Volcano Labelling Process : volcanoes to types to labels .
To circumvent the problems of estimating probabilities simplification of the model is proposed : replace the high dimensional intensity in the causal model . T can be considered a quantization of the intensity map . The effect dependency on intensity values in the model , which can now be written as conditioned on intensity values the following i with the low dimensional T is to remove any p( lt ) = p(vlt)pCtlt ) t
( 3 )
The dependence of types on volcanoes will be assumed given by the scientists as a general piece of prior information in particular , p(vtt ) , for t = 1 , 2 , 3 , 4 are the subjective probabilities we have elicited from the scientists which described the mean probability location , given that it type ( Section 31 ) These subjective probabilities are not conditioned on labels per belongs to a particular se , but on the types , ie , p(vlt ) E {098,080,060,05,00},t E {1,2,3,4,0} . that a volcano exists at a particular
The p(tll ) terms in Equation ( 3 ) represent from the fact that scientists are unable to specify , with 100 % certainty , "type" of a volcano . Determination of these is rendered non trivial by the fact that the true types t are never directly observed , and thus probabilities their dependence . some assumptions about the relationship between T and L must be made in order to infer At this point in time , estimating the p(tll ) terms from multiple labellings of the same data represents work in progress a particular method is outlined in Appendix 1 . Note that the overall effect of the above models the estimation noise resulting the particular
Page 114
AAM 94 Workshop on Knowledge Discovery in Databases
KDD 94 will be to reduce our confidence that a typical local region is a volcano , given some labelling information this has direct implications for estimating the overall numbers of volcanoes in a particular region , and so forth . For example local regions which which produce label disagreements between experts will be down weighted compared to volcanoes which receive unanimous labels .
5
Performance Evaluation : Analysis
Probabilistic
Free Response
ROC cannot classify each object with 100 % confidence , how can we assess how well our Given that the scientists the idea of "consensus ground truth" : a consensus based algorithms are performing ? We have investigated probabilistic labelling is generated by multiple scientists working together on labelling images . The individual labellings and the results of the automated detection system described earlier are then evaluated in terms of performance relative compared to consensus ground truth , an implicit assumption that the consensus process is "fair" in the sense that the results reflect expertise of each member and is not biased by factors such as personality traits , the volcano application we believe that the consensus is reasonably fair in this sense . if , its performance is as good as that of an individual scientist . There is to the consensus . The performance of an algorithm is considered to be satisfactory the measured seniority , and so forth . For
As a performance evaluation tool we use a variation of the well known receiver operator characteristic the complete range of performance of
( ROC ) methodology . The purpose of the ROC is decision system in terms of its estimated detection rate versus false alarm rate . Consider a binary hypothesis testing problem ( equivalently a binary classification or discrimination problem ) : the 2 mutually exclusive and exhaustive hypotheses are denoted as 0)1 and c#2 . Let x_ . denote the observed data . to determine
Standard Bayesian decision theory [ VanTrees68 ] shows that the optimal decision rule ( in terms of mini mum cost ) must be of the form :
If P(0)l li~ ) > t then choose 0)1 , else choose c#2
( 4 ) where t , 0 < t < oo , is a particular decision threshold ( related to the various types of misclassification costs ) . Hence~as t is varied one obtains different decision rules . Consider what happens whenever the rule chooses 0)1 . If 1:he true state of nature is actually o)1 then detection occurs , whereas ifthetruestateof natureis 0)2 then a false alarm occurs : the probabilities the respective probabilities the rule becomes more conservative : more liberal : more detections , but also more false alarms . of detection , pal(t ) , and false alarm , p/,(t ) , are thus defined as that a detection or false alarm occurs given that the rule chooses 0)1 . As t ~ o¢ fewer detections , but also fewer false alarms . As t ¢ 0 the rule becomes
When the conditional densities p(0)1[x ) and p(w21x ) are known exactly one can determine pd(t ) as function of pf,(t ) ; this plot is known as the ROC and provides the characteristic signature of a decision System over the entire range of possible detection/false alarm operating points . The utility of this framework is that one can evaluate the performance of a particular decision rule over a range of possible operating values for t and thus determine a useful operating point , eg , fix the false alarm rate at ( say ) 20 % .
Since in practical applications p(0)xlx ) and p(0)5[x ) are unknown , the ROC must be estimated directly from data . This is straightforward provided the decision system is producing either a direct estimate of the ratio r = , or some monotonic function of r . The estimation procedure is to vary r ( or a monotonic function of same ) as a decision threshold on a labeled training data set and count the resultant numbers of detections and false alarms for each value of r . A training set of size N produces N + 1 operating points ( including the end points of ( 00,00 ) and ( 1.0 , 10 ) ) One converts the number of detections and number false alarms to probabilities by dividing by the total number of training examples of class 0)1 and class 0)5 respectively . Thus , one can plot an empirical ROC , the estimated probability of detection versus estimated probability of false alarm .
For the volcano detection problem , the reference labels are taken from the consensus labelling , this is in effect treated as ground truth . Class c#1 corresponds to volcanoes , class c#2 to non volcanoes . False alarms correspond to label events which are categorized by the detection system as being of class volcano , when the consensus labelling indicates a non volcano event , ie , a local region which was not labeled . There ie ,
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 115 is a problem in defining the probability of false alarm , since it is di~cult to define the prior probability of class w2 . For example , should the prior probability be proportional in the image sense , since it would be which were not labeled as volcanoes ? This definition does not make much intuitive a function of the number of pixels to changes in such parameters ) and also since it would result in an astronomically high prior in favour of non volcanoes . in a g!ven image ( one wants the ROC to be invariant to the number of pixels
Hence , we use detection rate versus false alarms per total number of detections this normalized false alarm rate is a much more useful parameter since it is invariant to the size and resolution of the images used to determine the ROC . This plot is no longer directly as a standard ROC since the false alarm rate axis can now run from 0~ to some arbitrary percentage greater there may have been more false alarms detected than true detections in total for some threshold operating points . This slightly modified ROC methodology is essentially radiology display systems [ Bunch78 , Chakrag0 ] . the same as the free response ROC ( FROC ) used in evaluation than 100~ , ie , interpretable
Furthermore , are determined with reference to the consensus labelling : standard ROC and FROC approaches assume that ground truth is known . When ground truth is known only in probabilistic form as described earlier , one must allow for the fact that each detected local region is only a detection with probability p : there is an associated probability of 1 p of it being for example , a false alarm . These probabilities for a given threshold value , if the detection system being evaluated detects a particular local region which has been labeled by the consensus as category 2 ( probability of volcano = 0.8 ) , is to drag the non probabilistic ROC ( where 0.8 of a detection and 0.2 of a false alarm . The overall effect no allowance is made to for the probabilistic towards the "center" of the plot , away from the ideal "false alarm rate 0.0 , detection rate 1.0" operating point . Furthermore , the ideal "perfect" operating point is no longer achievable by any system , since the reference data is itself probabilistic . Hence , an effective optimal ROC is defined by exactly matching the probabilistic better . We denote the probabilistic method with the normalized false alarm rate as the probabilistic FROC ( PFROC ) ( in [ Henk90 ] a similar concept to the PFROC is defined for the special case of multivariate normal distributions ) . predictions of the consensus one can do no is counted then this effect )
Within this framework , the performance of a human labeller can only be determined within the resolution of the quantized probabilistic bins used in the subjective labelling process . With k bins , one can determine the location of k operating points on the PFROC , including the ( 0.0 , 0.0 ) point .
Figure 5 shows a PFROC curve for four images , comparing the performance of 4 planetary geologists and the current version of the detection algorithm . A consensus of 2 planetary geologists was used as reference . The consensus labelling was determined some time after from the same scientists . in [ Bur194 ] ) and was evaluated in crossThe algorithm was as described in Section 2 ( and in more detail the validation mode ( trained on 3 Of the images , and tested on the fouth , repeated four times ) . In total , consensus labelling produced 163 volcanoes , which correspond to the 100 % point on the y axis : as described above , the false alarm rates are determined relative to the 163 "true" detections . the individual labellings
The top curve is that which is obtained if one ignored the probabilistic nature of the labels completely upper operating points are and just treated all samples with labels {1,2,3,4} as volcanoes . The scientist ’s at about 80 % detection and 30 % false alarm rates , with the algorithm begin competitive in performance for the 5 20 % range of false alarms .
The other two curves were determined using the PFROC described above : the center plot corresponds to assuming no estimation noise ( p(t[l ) = 1.0 , t = l ) , whereas the lower plot contains an estimation noise model . The estimation noise probability matrix was estimated as described in the Appendix . For each curve , the relative weightings assigned to each detection or false alarm were equal to the estimated p(vll ) , where I is the label attached to each test example according to the consensus labelling . is
The upper curve in each plot ( "Optimal" ) or algorithm could do if they matched the consensus labelling exactly . The other curves largely parallel this curve but are 10 to 50 % less accurate in terms of detection rate at a fixed false alarm rate . The effect of introducing probabilistic labels is to induce a dramatic shift ( to the right ) in terms of increased false alarm rate , ie , compared to the top plot , the scientist ’s upper operating point is now at 80 90 % false alarms for about an 80 % detection rate . This is a direct consequence of the fact that many of the volcanoes which are being detected only have a 60 % chance of actually being a volcano . the upper bound reflecting how well a scientist
Furthermore , the curve for the algorithm is now further away from those of the scientists . be explained by the fact that the detection algorithm has a relatively poor ability
This can to accurately determine
Page 116
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94
Mean
Detection Rate [ eA ]
Mean
Detection Rate [ % ]
Mean
Detection Rate [ e~ ]
100
80
60
40
20
0
100
SO so
4o
2o o
1SO
SO so
4o
2o
Model 1 : Deterministic Labels , No Estimation Noise
: :
; ! .
, , ::[ ! i :
:::::::::::::::::::: : :
/,’" :": ’"":’~’""~’"! ~ :
i"=’"’! i ~ "i "i’"i"!
"~ 4 o scientist c t ’i"i"’i ; .~ :
" : r ~"’"’T’"’~’"’,"’"~"~"’’~ , : ~’"’"’i ,:’"":’"’i’"~’","~ " : 1 ~ 1 ::::::::::::::: i i ’: ~ i i i ~: i~ ~
"1 a, Scientist B I. : ’ ; j o Scientist D ! ! ± : ’ ’ " ~,T,t~ J’ ~ ScentstAl "’ ¯ ’ ,
i ;~ ~ ; ; ~ ; ~. ! ~ ;
: : , : J Algorithm S’"!’"~"’," I"’’~’’’’’’~ ,~iiii!i!i!!!!!!i!!!!i!!!ii!!i!!!i!!i!!!!!!!!!! :
~~ i / ~~[i : ~ : :
o
. ~,::’~~ ";" " : :’; L;’L~ ;:;, ’, , . ~ ; ~" r : ~ ~ "’"":’"’"’ "T"I i ! ! ’,’ "~’"~’"",’"!’" ;
_, _, :~: ~’ ~ .; ~,,~ ":~’""~’~:~’"’:’":’"’" , "’"i’"’’"’’"~’ "" ~,_,:;~’" , ~$;’~~~’~ ~ " ~ " ~ i ::’~i " ; ,~’""?’"’!’"’V"~’" :’"~ ! ! ! !’"’*’ ""!""!""!"! ~ , ~ ~ : ,,~ ~ ~ f,~~a,F~ ;
~ ~ ~ ~~~~~~
~’: " " : ". ’ ’: ~
~ i i i i i :’ i ~
~ i i ~ ~ ~
::::::::::::::::::::: : :
:
~
: i~ ~
; ; ; ;
: : :
; ; ; I
~ r
; : ."
; :
: :
,~ :
:
:~ i !
;
:
;
;
;
;
;
;
10
Mean False Alarm Rate
( expressed as % of total number of volcanoes )
100
~:::~
~cientlslA
Model 2 : Probabilistic Labels , No Estimation Noise ,r :’ ~. ~ : T r
I .e ,~cientlst C I"~’"""~""
I~ : i .i ~ ~ :’ : ~ Algorithm ~ : :~’~ : : ~
,’ ~ , I T’""C"’?’"T"’:’’~ , ~ , i ~ ~ ÷"" ""~ "’",""~,"" "’~ " ~ :’""~’"’!’"’!’"P’÷"~ " : "’i"~<’’"’"÷’"’!’";~’"i’~"’’~ ~ ~ Scientl~l B ,,’ ~ ~ , : ~ : , ~ ~’ ~ "~, " ’ ~" , ~ Opum= I ~’"’"l ::::::::::::::::::::::::::: : : i ~’:):ii’ :::::::::::::::::::::::: : :
, ! !’"’÷’"~’"’:’"’>~ : "’:’~’"Y’~" " , ~ i . ~ ~.~ ~"~,"’~ : i i: ~ ,~ "~~,~"!"~ ,
~ l : :, r :, ~~:~::,~::::::::::~____
~~:: : ::::~ i " ~ i’"’"i’"ii"~"=:"i
;~
~::’’’::: : :
: ’ ~=~=~ ’ , ~ar~a~___ ,
~
~
:’" ’;’"’:’"’;’":’"~" ;
:
:
:, y, ",. ’ :i : ~ L ’: ’ ~
;
;
;
;
;
; i
;
;
i I 10
; ;
; ;
;
;
I 100
Mean False Alarm Rate
( expressed as % of total number of volcanoes )
Model 3 : Probabilistic Labels with Estimation Noise
; I . sc,,m~c
: : ; ~ ~ ~;~ ~~ i i ~ ’ ~ii~ i ~ ~ ; ; ~ ~~;~ ~ i ~ , l~ ’ i " ,~ ; ~ S01enttet B i:: : : ’ ~__ . i o s=,,,0t o I, : . ~ .i : .~ ~_~i ~~~L~~ ~’ : /,i~ L ~ : ~ .’ ~; ~ ~ ~ ~~~’~:~~’~ : ’~ ~ ! ~ "~"’"~ ,’ ~ ~ ~ ~~~~;~~ ~ ~ ~ i ~ ~ ~~
i .~ Scientist A |~~ ~i : i::."~:’""’~’" ~ ;;~ : x::: ’ :~:~ , w, ~ ~ :
: t ~"",’":" : ~"
: Algorithm I~’":’"~"]" "
! i ~ ~ i
~ Optimal
~ ~ :
[
:
:
~ : ,’~
~ ’ ~_~:~~_~~ ~::::"::: : : ; : : :’:~ ":: ’F : ’ : :" , , ~:::::::: : :
~ , ~, ~’", ~:~ i" ~
; ¢ "~ ~ ~
,~i
: . : ~o:::’~::i::~
10
Mean False Alarm Rate
~ ~ ~ ~ ~ ~ ~ ~
~ : ; ~ ~ ,: i ; ; ~
100
( expressed as % of total number of volcanoes )
Figure 5 : ( i ) standard FROC , ( ii ) probabilistic FROC ( PFROC ) with estimation noise , ( iii ) PFROC with estimation noise
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 117 posterior class probabilities , in that a class 3 volcano might be estimated to have posterior probability 0.9 , whereas a class 1 volcano might only be given a probability of 06 This distinction is penalized by the probabilistic ROC method , whereas it is not penalized by the conventional approach ( top plot ) . Thus , the PFROC provides more information to the algorithm designer in terms of evaluating how well the algorithm performance matches that of the scientists . We note that the probabilistic nature of the labels ( the center plot ) has the major effect : adding estimation noise ( lower plot ) only causes a slight deterioration inestimated performance .
The PFROC clearly demonstrates that both the scientists inaccurate at detecting volcanoes . Nevertheless , we feel these results provide a true picture of the relative accuracy with which volcanoes can be detected in the Magellan images . This underlying ambiguity in volcano detectability should be recognized and factored into any scientific inferences made based upon labellings by individuals or machine algorithms . and the algorithm are relatively
6
Other Aspects of Probabilistic
Labels impacts on overall image labels in the labelling can have other significant in [ Smyth94 ] and [ Bur194 ] , the matched filter leads to improved performance in theory [ Smyth94 ] , in our experiments to date we learning procedures can all be modified to account labels . The general approach is based on the notion of assigning fractions of a training label weight : for example , a category 2 volcano
The acknowledgment of uncertainty analysis methodologies . For example , as described in detail generation , SVD subspace generation , and discriminant for probabilistic data sample to each class in proportion to the subjective might be treated as 0.8 of a sample for the volcano class and 0.2 of a sample for the non volcano class . When the estimation noise can be calibrated and there are labels from multiple experts , the methods of the Appendix can be used to determine more accurate relative class weighting . While this weighted treatment of probabilistic have found no improvement in performance by learning from probabilistic labels as compared to the default approach of treating all labelled items as examples of class volcano . Investigation of the data revealed that the subspace projection structure which existed in the data at the level of the intensity maps , ie , category l ’s , 2 ’s , 3 ’s and 4 ’s were all being projected into the same region of feature space ( as revealed by 2 d scatterplots of various feature pairs ) and completely overlapped each other without any structure . structure had been preserved , one would expect to see the l ’s eto be further away from the non volcano class than the 2 ’s and so forth . This is an example of a learning algorithm dealing with a feature space ( SVD filter than that on which the labelling is performed ( local intensity maps ) , with the result that the probabilistic labels do not relate any useful way to the space in which learning is taking place . As a consequence , a detection algorithm based only on SVD filter responses cannot reproduce accurate posterior probability estimates which match those of the scientists is to seek projections which preserve the probabilistic subjective labels . A current direction of investigation label information , which in turn should result technique was destroying any probabilistic responses ) which is different
If the probabilistic in better PFROC performance .
Estimation of various spatial statistics can also be conditioned on the probabilistic nature of the labels for example , non parametric kernel density estimates of the volcano diameters ( an important geological labels into account as described in [ Smyth94 ] . Densities "signature" ) can be modified to take probabilistic which are not unimodal are particularly treatment of the labels sensitive can lead to oversmoothing of real modes , or the introduction of spurious ones . Once again , the actual values of the probabilistic labels are a function of the particular noise model one chooses to use as described in the Appendix . Estimation of spatial statistics in this manner is a topic of current investigation . to probabilistic incorrect labels :
7
Conclusion
The major focus of this paper is the treatment of uncertainty in the training data when designing and evaluating knowledge discovery systems for image databases . The net effect of ground truth ambiguity is to propagate an extra level of subjective noise into processes such as training learning algorithms , performance evaluation methodologies , and estimation of spatial statistics of science interest . Handling this uncertainty requires the introduction of special techniques such as the probabilistic free response ROC ( PFROC ) methodology . The proposed techniques provide a framework for more accurate estimation and evaluation of basic
Page 118
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94 image quantities are becoming increasingly well calibrated of interest for applications where absolute ground truth common as remote sensing platforms is not available .
Such applications provide orders of magnitude more data and ground truth constitutes a tiny ( and perhaps even zero ) fraction of the overall data set .
The Magellan volcano detection problem provides a clear example of this problem in a realistic setting . The problem of lack of ground truth remote sensing , medical diagnosis , is fairly pervasive and is applicable and large corporate and financial database analysis . in training data ( or examples of patterns and to a wide range large scale knowledge discovery problem , uncertainties need to be treated and approximated explicitly .
Ignoring this labels are absolute is likely to result in a miscalibrated information , system . This paper also discusses as is often done , by in measuring the performance of the learning system in this context . large scale of domains covering In a typical of interest ) assuming class issues that arise
Acknowledgments in this to thank our collaborating
The research described Institute like assistance and analyzing and Joe Roden for work on developing by by NASA OACT Code CD . in labelling of Technology , under contract with the National Aeronautics and Space Administration . We would report has been carried out by the Jet Propulsion Laboratory , California geologists :
Jayne Aubele and Larry Crumpler of Brown University the Magellan data . We thank Maureen Burl , the software and user interfaces their John Loch , Jennifer Yu , of JARtool . This work is sponsored for
References
[ Agresti92 ]
[ Aubeleg0 ]
[ ChakragO ]
[ Bunch78 ]
[ Bur1947
[ Chest92 ]
[ Fayy93 ]
[ Fayy94 ]
[ Guest92 ]
[ Henk90 ]
[ Kahn82 ]
[ Lug92 ] [ Science91 ] [ Silver80 ]
[ Smyth94 ]
[ Ueber93 ] in Earth , and origins,"
50/51,493 532 . of radiographic observer
"A Free Response performance," J . Appl .
Agresti , A . , ( 1992 ) , "Modelling patterns of agreement and disagreement," Statistical Methods in Medical Research , vol.1 , pp201 218 Aubele , J . C . and Slyuta , E . N . ( 1990 ) , "Small domes on Venus : characteristics Moon and Planets , Chakraborty , D . P . , and Winter , L . H . L . ( 1990 ) , " Free Response methodology : alternate analysis and a new observer performance experiment," Radiology , 174 , 873 881 . Bunch , P . C . , Hamilton , J . F . , Sanderson . G . K . , and Simmons , A . H . , ( 1978 ) , approach to the measurement and characterization Photo . Eng . , vol.4 , no . 4 , pp166 171 Burl , MC , Fayyad , UM , Perona , P . , Smyth , P . , and Burl , MP ( 1994 ) , "Automating the hunt for volcanoes on Venus," in CVPR 9J : Proceedings of the 1994 Computer Vision and Pattern Recognition Conference , to appear . Chesters , M . S . , ( 1992 ) , "Human visual perception and ROC methodology in medical imaging," Phys . Med . Biol . , vol.37 , no.7 , pp1433 1476 Fayyad , U . M . , and Smyth , P . , ( 1993 ) "Image database exploration : progress and challenges," Proceedings of the 1993 AAAI Workshop on Knowledge Discovery Fayyad , U . M . , P . Smyth , N . Weir , and S . Djorgovski ( 1994 ) , "Automated analysis and exploration large image databases : results , progress , and challenges , " Journal of Intelligent in press . Guest , J . E . et al . ( 1992 ) . "Small volcanic edifices and volcanism in the plains of Venus," Journal of Geophysical Research , vol.97 , no.E10 , pp15949 66 Henkelman , R . M . , Kay , I . , and Bronskill , M . J . ( 1990 ) "Receiver operator characteristic without ground truth," Medical Decision Making , vol.10 , no.l , pp24 29 Kahneman , D . , Slovic , P . , and Tversky , A . ( eds . ) Bias~ , Cambridge University Press . Lugosi , G . , ( 1992 ) "Learning with an unreliable teacher," Pattern Recognition , vol . 25 , no.l , pp79 87 Science , special issue on Magellan data , April 12 , 1991 . Silverman , B . , ( 1980 ) , "Some asymptotic properties of the probabilistic Theory , IT 26 , no.2 , pp246 249 Smyth , P . , ( 1994 ) , "Learning with probabilistic in Computational Learning Theory and Natural Learning Systems 3 , T . Petsche , M . Kearns , S . Hanson , R . Rivest ( eds ) , Cambridge , MA : MIT Press , to appear . Uebersax , J . S . , ( 1993 ) , "Statistical modeling of expert ratings on medical treatment appropriateness," J . Amsr . Statist . Assoc . , vol.88 , no.422 , pp421 427
( 1982 ) , Judgement under Uncertainty : Heuristics and
Information Systems ,
IEEE Trans . Info .
( ROC ) analysis in Databases . supervision," teacher,"
KDD 94
AAA1 94 Workshop on Knowledge Discovery in Databases
Page 119
[ VtmTrees68 ] Van Trees , H . L . , ( 1968 ) , Detection , Estimation , and Modulation Theory : Part 1 , John Wiley and Sons ,
New York , pp23 31 the p(tll )
Appendix : Estimating Consider that we have a database of N labelled times , either by rn different of same ( the extension labellers or groups of labellers been labelled as one of the 4 labels 1/2/3/4 by at least one of the rrt terms from multiple local regions . Assume that each local region has been examined rrt scientists or groups of same , or the same scientist multiple times , or some combination to the case where some subsets of local regions have been examined by different numbers of and will be omitted to keep notation simple ) . Hence , each local region has labellings is trivial labellers .
For each label event assign a "vote" of 1/m to each label 1/2/3/4 each time that a labeller assigns that label , and is and are not dealt with as the probability that a "vote" of 1/m to the label 0 if a labeller did not label it at all . being weighted equally extensions to the case of non equal weighting are straightforward here . We can interpret labellers ) local intensity i will be assigned label I . More formally , we define the estimator
Implicit here is an assumption that each labeller the sum of the votes for a particular label ( from different
~(tli )
1 k I where 5(x,y ) : 0 unless x y , and vk(_/ ) is the label provided by the kth labeUer for the local intensity map
We can now estimate the marginal probability that an arbitrary labeller will assign label I to a local region , by summing over all intensities :
N j 1
N ~ ) T) ~ ~(lli j 1
( 6 ) where j is an index over the N local estimate p(t , l ) . The following estimator is defined : regions in the database . To estimate p(ttl
) by Bayes’ rule we first need to
#(t,l ) = ~"#(t,i,l ) ~ ’~$(tlZ , i)$(lli)p(i ) =
¯
,2
N
,_’
~
N j=l t l
1 ~$(tlt,,_j)#CLlij
) J=! since the type t is independent of the label l given the local intensity the same as for ~(lli and can be estimated directly i . If we define the estimator for/3(t[~ j ) to be j ) ( as in Equation 6 above ) , the process is complete , since all necessary terms are now defined from the database . Finally , we have that
As an example , this method was applied to two labellings of the same 9 images with the following results :
~(tl 0 = ~(t , l ) ~(l )
( 7 )
$(T llL 1 ) = 0.80 , 0.68 , lfi(T= 2IL=2 ) /~(T 3[L a ) 0.70 , Labelling of 1 ’s and 4 ’s appears to be the most accurate ,
~6(L i ) 0.11 /~(L=2)=0.22 /~(L 3 ) = 0.29 estimated that 16 % of the local regions identified images ) are truly non volcanoes .
/3(T=41L=4 ) ~(r = OIL = o ) = 0.5 , r3(L = O ) = 0.16
/~(L=4)=0.22
= 0.78 ,
( out of 330 which were labelled by at least one labeller labellings of 2 ’s and 3 ’s less so . Furthermore , it is in the
The replacement of/~(tl/j ) by fi(lli_ j ) above is a provably biased approximation but the method appears to yield in practice . The properties of this estimator are currently under investigation as are alternative eg , methods based on maximum likelihood estimation techniques using parametric models of hidden reasonable results estimators , ( latent ) traits In addition
[ Ueber93 , Agresti92 ] . it should be noted that the method described above implicitly assumes that all experts are treated equally in the sense that a single average estimation matrix is derived for all . A more sophisticated approach would be to produce estimation noise models for each individual expert . Although there are some subtleties to this aspect of the problem , in principle it is solvable by the same techniques as described above .
Page 120
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94
