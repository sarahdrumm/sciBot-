From : AAAI Technical Report WS 94 03 . Compilation copyright © 1994 , AAAI ( wwwaaaiorg ) All rights reserved .
Toward the Integration of Exploration and Modeling in a Planning Framework
Robert St . Amant and Paul R . Cohen
Computer Science Dept . , LGRC
University of Massachusetts
Box 34610
Amherst , MA 01003 4610 stamant@csumassedu , cohenQcsumassedu
Abstract
Statistical operations are often facilitated by other operations . We can facilitate modeling operations by testing their input for irregularities and removing problems wherever possible . A planning representation is well suited to this task . We describe the representation used in Igor , a system for exploratory data analysis , and its integration with two modeling systems , Pearl ’s IC and Cohen ’s FBD . We show that introducing outliers into the inputs of the algorithms can influence their performance . We demonstrate that a planning representation offers a flexible way of integrating outlier detection and removal into the modeling process , taking account of specific characteristics of the modeling operations involved .
Keywords : statistics , statistical modeling , data exploration
1
Ihtroduction in exploring data : The techniques of exploratory data analysis ( EDA ) rely on two general strategies one generates simplifying descriptions of data , the other extends and refines surface descriptions of data . EDA techniques simplify data by constructing partial descriptions and models that capture particular characteristics of the data . They make descriptions more effective by looking beyond surface descriptions at what is left unexplained . Exploratory strategies generate increasingly detailed , complementary descriptions of data .
Causal modeling is one approach to describing data . Like many other statistical procedures , input data . causal modeling algorithms often make strong assumptions about properties of their ( eg , nonlinearity , We can facilitate modeling operations by testing their input for irregularities outliers ) to the input of an operation to ensure that it corresponds to the requirements of the operation and to improve the quality of its results . and removing problems wherever possible .
In general , we apply transformations
Igor is a knowledge based system designed for exploratory statistical and environments [ 1 ] . Igor uses a script based planning representation statistical on information acquired during the exploration and modeling process . operations . In Igor models of data are built incrementally and opportunistically , analysis of complex systems to guide application of relying
In this paper we describe a limited integration.of exploration and modeling in Igor . We focus on in linear relationships , and two modeling a specific exploration operation , the detection of outliers algorithms , Pearl ’s IC [ 11 ] and Cohen ’s FBD [ 3 ] . We demonstrate that a planning representation
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 49 o
°
° o
¯
".oO
,oo
¯o¯
¯0
( a ) Quadratic
( b ) Outlier
( c ) Partitions
Figure 1 : Examples offers a promising way of integrating exploration into the modeling process . Though the integration is limited in terms of the range of exploration and modeling operations performed , it shows that the combination can be profitable : modeling operations can provide context for exploratory actions ; exploration can test assumptions made by the modeling algorithm .
2 Motivation
A central element of some well known causal modeling algorithms independence [ 11 ] . If X , Y , and Z are disjoint sets of variables , conditionally independent given Z , iff is the notion of conditional then X and Y are said to be
I(X,Z,Y ) iff P(x , yJz ) = P(xlz)P(ylz
) .
Informally , if holding Z constant renders X and Y independent , then there can be no direct influence between X and Y .
Conditional independence is defined on probabilities , or probability distributions . The partial correlation statistic provides a straightforward way to operationalize the test :
Partial(X , YJZ ) < Threshold ~ I(X , Z ,
If the partial correlation of X and Y with Z held constant falls below a threshold , Y are conditionally a covariance matrix as input and base their conditional correlations derived from the matrix . then X and take independence inferences on the partial independent . Thus some implementations of causal modeling algorithms the correlation of Y and X is zero , but clearly after an appropriate
Recall that the correlation coefficient ( and by extension the partial correlation coefficient ) measures the degree of linear association between variables . Consider the three cases in Figure 1 . In Figure l(a ) transformation In Figure l(b ) the correlation between Y and X is moderate the correlation would be perfect . high , but would be near zero after filtering the single outlier . Figure l(c ) shows a strong relationship between Y and X , but the positive correlation would change to a negative correlation after partitioning on a third variable .
Each of these cases demonstrates that the correlation statistic may not capture thedesired to calcurelationship between two variables . late conditional independence , then the validity of its results depends on properties of the input variables in particular , that these sorts of irregularities are not present in the data , either obscuring existing relationships or inducing spurious relationships .
If a modeling algorithm uses partial correlations
Page 50
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94
This discussion should not be taken as criticism of the modeling algorithms ; these considerations lie outside their domain . It is rather recognition of the limits of their applicability . By integrating data exploration with modeling operations we extend these limits .
3 Igor
Elsewhere [ 1 ] we draw an analogy between the process of EDA and planning . Briefly :
¯ Exploratory strategies are plans consisting of sequences of statistical operations ; these oper ations are actions that transform data relationships .
¯ As in planning , primitive exploratory operations can be combined in different ways for dif ferent effects . For example , in considering a relationship between two variables , a difference whether we remove outliers before or after applying a transformation relationship . it makes to the
¯ Conversely , abstract statistical into more primitive operations , just as in hierarchical plan decomposition . For example , the abstract operation of fitting a robust line to a relationship may expand to partitioning the relationship , calculating medians , and combining the results . operations often decompose naturally
¯ Selection of the most effective exploratory strategy is akin to selection of an appropriate plan to satisfy a given goal . We must often evaluate different paths to find the most effective one . for adequate results . Retrying an operation is analogous to retrying an action as a part of plan failure recovery . Selecting a different , more promising strategy corresponds to replanning .
¯ Just as plans fail and require repair , an exploratory operation may require iteration
Igor uses a script based planning representation , based on the RESUN signal interpretation system [ 2 ] , to guide application of statistical are combined for complex effect . Results are derived incrementally and opportunistically , constructing and revising plans according to information acquired during the process . operations . In Igor , sequences of simple operations based on
Th~ data structures manipulated at the lowest level in the planning representation are frames .
A variable is a simple frame ; a linear relationship between two variables is a slightly more complex hierarchy of frames ; an annotated causal model is a highly interconnected hierarchy of frames . We call frames and hierarchies of all types structures .
The primitive operations provided by the representation are called actions . An action is a data transformation or decomposition of an input structure to an output structure . A log transform is a simple example of an action ; it applies a log function to each element in a sequence and collects the results . More complex transformations include smoothing , outlier removal , and fit operations . Each action has an associated goal form and may be triggered by the establishment of a matching goal .
Actions are combined in scripts . A script is a sequence of subgoals whose associated acinto a more concise , better parametrized , more descriptive structure . tions transform one structure Scripts , like actions , have associated goal forms , and thus may be combined hierarchically to satisfy the goals of other scripts . Combination of subgoals in a script is governed by the specification of the script . A script specification defines how its subgoals must be satisfied in order for the top level goal to be satisfied . Specification constructs allow sequential combination of subgoals , iteration over sets of subgoals , conditionalization on tests of variable values , and activation of subgoals in parallel .
In the example script in Figure 2 , the :sequence directive orders the goals simple linear regression , generate residuals , and standardize . The result of this script is a sequence containing the standardized residuals from a linear regression between two variables .
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 51
( define plan generate standardized residuals plan
:goal
( standardized residuals
?y variable ?x variable ?residuals )
:input :internal :output :grammar
( y variable x variable ) ( slope intercept ) ( residuals ) ( :sequence simple linear regression generate residuals standardize ) )
Figure 2 : Example Script
Scripts and actions control procedural execution in the representation , managed flexibly by goal establishment . These constructs still do not provide the degree of opportunism and context specific control we associate with exploration , however . For this we rely on two mechanisms that depend on context , monitoring and focusing .
A strictly goal driven system can find it difficult to take new structures under consideration during the search process . A monitor is a goal , active in parallel with the execution of a script , and matching scripts , which test intermediate results produced . Monitors evaluate the ’interestingness’ of results , taking context information into account , to initiate new directions in the exploration .
Focusing heuristics guide and constrain the exploration process based on local context information . Focusing heuristics are activated whenever there is a choice between which goals to pursue and which scripts to apply ; they evaluate the precedence of active goals and the relevance of matching scripts when deciding which scripts should be activated and which ignored . We use focusing heuristics is free to prune the goals or scripts it takes as input , temporarily or permanently . As with monitors , a focusing heuristic may take advantage of domain specific knowledge in its processing . to evaluate the cost of pursuing particular search paths . A focusing heuristic
4
Integration and Evaluation
We begin by describing the datasets we used for the evaluation . For each algorithm we then describe
. the modeling algorithm itself , e outlier detection techniques suited to its operation , . the plan form of the integrated operations , . how the integration affects performance .
We generated 60 sets of linear structural equations of varying size . For each set of equations we generated a dataset of 50 tuples . Exogenous variables were sampled from normal distributions . Endogenous variables were derived according to the structural equations . Error was added to each variable , sampled from independent normal distributions . By following these procedures we ensured that the datasets we generated accurately reflected the structural equations .
We then perturbed each dataset by adding a single outlier to the 50 tuples . Here an outlier is a tuple in which each element has been independently sampled from a normal distribution . We generated outliers at three standard deviation settings : 2.0 , 3.0 , and 40 As this value increases ,
Page 52
AAAI.94 Workshop on Knowledge Discovery in Databases
KDD 94
0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1
0.9 0.8 " 0.7 " 0.6 " 0.5 0.4 " 0.3 " 0.2 0.1
0.9 0.8 " 0.7 0.6 0.5 0.4 " 0.3 0.2 " 0.1 "
~
( a ) Perturbation 2.0
0.5 0.6 0.7 0.8 0.9 ( b ) Perturbation 3.0
1
0.5
0,6 0,7
0.8 0.9
( c ) Perturbation 4.0
Figure 3 : IC : Effect of perturbation on correct link ratio we say that the perturbation plausibly be attributed
Our evaluation considered level of the dataset increases . In the real world such outliers might to measurement error or anomalous experimental conditions . two algorithms , Pearl ’s
IC and Cohen ’s FBD . We ran the same procedure on both algorithms . We first applied the algorithm to each original dataset to generate levels and evaluated a nominal model . We then generated models for each of the perturbation the outlier data models with respect to the nominal model . Note that we are not evaluating the algorithms with respect to some true model , but rather only how they are affected by the outliers . the modeling algorithm with specific outlier detection operations in Igor . the filtered data models , with respect to the nominal and outlier data
We then integrated
We evaluated the results , models .
4.1
IC
The IC algorithm generates a causal model in the form of a DAG in which nodes represent variindicating genuine ables , ~dges causal influences . Linl~s are identified as marked unidirectional , causation , unmarked unidirectional , indicating spuriindicating an undetermined relationship . Two models are said to ous association , and undirected , be identical if they have the same links ( edges without regard to direction ) and the same uncoupled head to head nodes ( converging arrows emanating from non adjacent nodes , such as a + c + b . ) A much more complete description indicating potential causation , bidirectional , is given in [ 11 ] .
In our evaluation we evaluated the effects of perturbation on a model M by means of links in M and the nominal model ,
¯ ¯ uncoupled head to head nodes in M and the nominal model , and ¯ edges denoted genuine in M and the nominal model .
Running IC on the perturbed datasets 1 we produced models which we summarize in Figure 3 . The histograms show the cumulative distribution of the ratio of correct links in a model with respect to the nominal model . In other words , we counted the number of links shared between each model and its nominal model and divided by the total number of links in the nominal model , giving us one number per model . Thus each bin in the histogram measures the proportion of models with a correct link ratio equal to or lower than the value on the x axis .
Ideally each distribution should be as right skewed as possible , with all cases achieving high correct link ratios . We see by the clustering around 1.0 on the x axis that the outlier data models
1We fixed the separating set size at 1 , the partial threshold at 0.1
KDD 94
AAA1 94 Workshop on Knowledge Discovery in Databases
Page 53 do tend to be very similar to the nominal models . As the perturbation grows greater , however , the central location of the distribution decreases while spread increases outlier data models are found farther and farther away from their nominal models . The distributions for other measures behave similarly . the outliers
We can redress these problems by identifying in the data . The detection procedure treats variables pairwise . It runs a linear regression and examines the residuals , looking for those cases which exert undue leverage on the linear relationship between the variables . Such leverage is indicated by outliers in the standardized residuals . The normal test counts an element ( x , y ) as an outlier in the relationship ( X , Y ) if its standardized residual falls outside [ 2.7 , +27 ] The fourth spread test [ 7 ] ( similar to a quantile test ) counts an an element ( x , y ) as an outlier residual the spread itself . These tests give similar results for our data . falls more than 3~2dR below or above the fourth spread boundaries , where dF measures if
The combination of outlier removal and model construction the to the IC algorithm in a script , generate model plan A . We make the input exploration and call transformation phase explicit by satisfying the goal explore input before proceeding with model construction . The goal explore input is not specific to outlier detection , so that other exploration operations also apply . Note that the goal representation allows us to use either algorithm , IC or FBD , in the model building phase , the selection managed by a simple focusing heuristic . is managed by incorporating
( define plan generate model plan A ( top level build model
:goal
?domain ?variables ?relationships ?context )
( domain variables context )
:input :output ( relationships ) :grammar ( :sequence explore input build model ) )
( define plan explore remove outliers plan
( explore input ?variables ?transformed variables )
:goal :input ( x variable y variable ) :internal ( relationships ) :output ( outliers ) :grammar ( :sequence generate relationships ( :in parallel ( relationships ) mark outliers ) transpose variables remove marked tuples transpose tuples ) )
In this arrangement control is of the form ExamineInput ~ ConstructModel . Igor acts strictly as a preprocessor for the IC algorithm , in that outlier detection is managed by a test phase entirely before the modeling begins . In effect we consider exploration a simple extension of the modeling operation .
Summaries of our evaluation measures are shown in Table 1 . Each pair of rows contains measurements of outlier data and filtered data models for each level of perturbation . Correct % is the mean percentage of correct links , per model , with the total number of correct links in parentheses . W/C is the ratio of correct links . C ratio measures the overlap in uncoupled links to incorrect
Page 54
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94
Condition Outlier Filtered Outlier Filtered Outlier Filtered
Pert 2.0
3.0
4.0
Correct % ( N ) w/c 0.87 ( 31.97 ) 0.22 0.80 ( 28.78 ) 0.29 0.81 ( 29.37 ) 0.29 0.26 0.81 ( 29.47 ) 0.75 ( 27.63 ) 0.38 0.82 ( 29.55 ) 0.24
C ratio G Same G Diff 0.60 0.80 0.66 0.64 1.40 0.72
0.40 0.42 0.31 0.48 0.19 0.46
0.73 0.57 0.59 0.60 0.44 0.62
Table 1 : IC : Degradation by perturbation level
°10.8
,,4
’1
¯
0.6
0.5
0.4
0.3
0.2
|
¯
!
( a ) correct link ratio
( b ) genuine edge ratio
Figure 4 : IC : Effect of perturbation head t0 head nodes between a outlier data the overlap and difference between genuine edges in the models . and filtered data model . G Same and G Diff measure
In Figure 4 we see a more detailed comparison for Correct % ( a ) and G Same ( b ) . Along x axis we have increasing perturbation level , along the y axis the appropriate measurement level . The lines correspond to the measures for outlier data models and filtered data models , with .90 confidence intervals . In both cases the downward sloping line belongs to the outlier data models . There is a clear degradation for outlier data models as perturbation increases , while the filtereddata models remain relatively as well . insensitive . These results are roughly the same for the other measures
At the initial perturbation level , the outlier data models are unexpectedly closer to the nominal models than the filtered data models , sometimes even outperforming the filtered data models . We attribute this to the small size of the datasets : single outliers , both those we have introduced and those potentially already present in the data , can have a relatively between variables . 2 Thus removing small numbers of outliers may induce new relationships remove existing ones . As perturbation Outlier detection improves all measurements with further increase in perturbation level . large effect on the correlation or increases , however , outliers become easier to distinguish¯
~This indicates that we should examine larger datasets as well . It does not lead us to dismiss these preliminary the effect of a single outlier , but large single outliers or groups of calculations . It also may be that larger samples are simply not available .
Tesults . A larger sample size naturally dilutes smaller outliers can still In any case , exploration is required to test our assumptions . influence statistical
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 55
4.2
FBD the strength of relationships .
The FBD algorithm , in addition to building qualitative timates considers a single variable and a set of candidate predictors for it . Filters are applied sequentially to prune the predictor set . When the filtering is completed , the algorithm selects another variable to predict . Here the essential aspects are that ( 1 ) FBD proceeds incrementally and ( 2 ) FBD ’s decisions are dependent upon the same assumptions made by linear regression . causal descriptions of relationships ,
FBD constructs a model iteratively" at each stage FBD es
We can measure how much effect perturbations have on a model M by measuring
¯ finks in M and the nominal model , ¯ the difference ¯ the difference in predictive power in M and the nominal model ( AR2 ) , in estimated correlations in M and the nominal model ( At ) .
If we perform the data exploration/transformation process entirely before running FBD , as we the results with did with the IC algorithm , we see improvement in most measures . We can better a closer integration of model building and exploration . In the IC example we detect outliers with respect between pairs of in choosing the detection mechanism was the nature of the variables . One of our considerations In general the notion of "outlier" depends on the operation to be partial correlation performed . In the case of FBD we can detect outliers by examining the effect of removing presumed outliers on prediction parameters of the partially constructed model . to linear relationships statistic .
The diagnostic measure vii ( also known as hii ) can be used to detect outliers in the predictors in a regression , vii is the diagonal of the matrix V , where
V " x(xTx) Ix
T and Y Y = ( I
V)Y .
Each row of V corresponds to a tuple in the dataset . The matrix V is often called the hatmatrb¢ , because it gives us a way of calculating Y , the predicted value of the dependent variable , from Y , the actual value . A larger entry in the diagonal of V indicates a larger contribution of that tuple to the predicted value of the dependent variable , and thus greater influence on the regression model . ( A full discussion of vii is beyond the scope of this paper , but see [ 4] . ) We use vii to identify high leverage cases , those most likely to bias the predictors of a variable in a model .
Rather than running the test on the entire dataset before running FBD , as we did with IC , we can take advantage of FBD ’s incremental construction . We can apply the vii test most effectively by including only legal predictors of a given variable , as determined by the modeling filters , rather than all variables in the dataset . Thus during the predictor selection process the vii test checks the set of candidate predictors to see whether any cases might exert undue influence on the regression . If so , these cases are removed and FBD continues with its selection . The procedure is repeated for each predicted variable .
To do this we reimplement the top level control of the FBD algorithm in plan form . Two loops are involved , the outer loop over predicted variables , the inner loop over filters on each variable ’s potential predictors . The :iterate directive continues until its condition clause evaluates to nil . Focusing heuristics can control the order in which predicted variables and filters are selected , in a fixed order . We manage outlier detection and removal by a but currently defining a new filter it execute with the others . When the inner loop completes , the variable is considered predicted and the next variable is selected . Incremental construction gives us a completed model when the plan is finished . Again the goal representation and model building makes few assumptions about the particular modeling algorithm or heuristics they are selected and letting for filters involved .
Page 56
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94
Condition Outlier Preprocessed Interleaved Outlier Preprocessed Interleaved Outlier Preprocessed Interleaved
Pert 2.0
3.0
4.0
AR2 Correct % ( N ) w/c 0.47 0.09 0.75 ( 13.12 ) 0.53 0.09 0.72 ( 12.42 ) 0.08 0.47 0.74 ( 13.15 ) 0.73 ( 12.98 ) 0.47 0.11 0.76 ( 13.08 ) 0.45 0.09 0.78 ( 13.68 ) 0.38 0.09 0.65 ( n.58 ) 0.13 0.64 0.76 ( 13.10 ) 0.44 0.09 0.78 ( 13.71 ) 0.40 0.08
Ar 11.81 12.88 11.24 13.28 15.72 11.53 14.78 13.33 13.09
Table 2 : FBD : Degradation by perturbation level
( define plan generate model plan B ( top level build model
:goal
?domain ?variables ?relationships ?context )
( domain variables context )
:input :internal ( filter predicted variable ) :output :Er~mmar
( relationships ) ( :iterate ( )
( serf predicted variable
( select predicted variable ) )
( :sequence ( :iterate ( ) o
( serf filter
( select filter ) ) apply filter ) incremental build model ) )
In this arrangement we see a different view of the process : we no longer have a monolithic removal operation preceding an atomic modeling operation , but rather an incremental outlier Transform ~ Construct plemented as a filter , merges seamlessly into the model construction process .
Transform + Construct
The outlier detection function ,
im
Application of outlier removal to FBD gives results similar to those for IC . The summarized results are shown in Table 2 . The Condition column specifies whether the outlier data model was used ( Outlier ) , the model built using the pairwise detection algorithm ( Preprocessed ) , or the model built interleaving construction with the vii test ( Interleaved ) . W/C is again the ratio of wrong links for the model and the to correct nominal model , per predicted variable . Ar is similarly in correlation between the model and the nominal model . For both measures , lower values are better . links . AR2 measures the difference between the R2 calculated the difference
Figure 5 shows a more detailed comparison between the three conditions for the Correct % mealevel , along the y axis the measurement sure . Along the x axis we have increasing perturbation level . The lines correspond to the measures for outlier data models , filtered data ( interleaved ) models , with .90 confidence intervals . Here again the downmodels , and filtered data ward sloping line belongs to the outlier data models , and the approximately parallel lines to the filtered data models . The highest performance is achieved in the interleaved case . In summary , we
( preprocessed )
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 57
0.8
0.7
Figure 5 : Effect of perturbations on link ratio find that applying outlier detection as a preprocessing phase improves FBD ’s performance as perturbation increases . Incremental application improves results yet further , and reduces degradation for the low perturbation setting .
5 Conclusions
We have approached the integration of statistical modeling with transformation operations from the viewpoint of exploratory data analysis [ 5 , 8 , 12 ] , with strong influences from work in the machine learning and knowledge discovery in databases literature [ 10 ] . We have shown preliminary evidence that the integration of exploration and model building can be profitable . We can automate parts of the data exploration phase necessarily associated with application of a modeling algorithm .
The purpose of this work is not to describe well known statistical techniques , but rather to show how their application can be managed in the planning representation , exploration and modeling . Lansky has noted that planning meshes well with iterative modeling because both processes are essentially constructive [ 9 ] . Igor ’s planning representation lets us tailor the combination of transformation operations with modeling operations takes advantage of the characteristics of the operations . and how control interleaves in a way that
One issue we have not addressed is the selection of facilitation operations for particular modeling is just a single example . Realistically we will transform operations . Outlier detection/removal highly skewed variables , test whether relationships are approximately linear , ensure that cases in each variable are independent , and run a variety of domain dependent tests as well . While we have mechanisms in place , focusing heuristics , to decide among potentially applicable actions , we have only begun to examine the knowledge required to make the correct decisions .
There are larger issues we will address in further work , in particular the notion of statistical
[ 6 ] in exploration . We hope to incorporate more complex interactions strategies and modeling process . Domain specific knowledge plays a strong role in the work of real statisticians ; our work has left issues in representation so far unaddressed . into the exploration
References
[ 1 ] Robert St . Amant and Paul R . Cohen . A planning representation data analysis . gence Systems in Aerospace and Industry Proc . SPIE 22~ , 1994 .
In D . H . Fisher and Wray Buntine , editors , Knowledge Based Artificial for automated exploratory Intelli
Page 58
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94
[ 2 ] Norman Carver and Victor Lesser . A planner for the control of problem solving systems . IEEE Transactions on Systems , Man , and Cybernetics , special issue on Planning , Scheduling , and Control , 23(6 ) , November 1993 .
[ 3 ] Paul R . Cohen , Lisa Ballesteros , Dawn Gregory , and Robert St . Amant . Regression can build predictive causal models . 1994 .
[ 4 ] R . Dennis Cook and Sanford Weisberg . Residuals and Influence in Regression . Chapman and
Hall , 1982 .
[ 5 ] A . P . Dempster . Purposes and limitations of data analysis .
In G . E . P . Box , T . Leonard , and
C F Wu , editors , Scientific
Inference , Data Analysis , and Robustness . Academic , 1983 .
[ 6 ] DJ Hand . Patterns in statistical strategy .
In WA Gale , editor , Artificial
Intelligence and
Statistics
I , pages 355 387 . Addison Wesley , 1986 .
[ 7 ] David C . Hoaglin , Frederick Mosteller , and John W . Tukey . Understanding robust and ex ploratory data analysis . Wiley , 1983 .
[ 8 ] David C . Hoaglin , Frederick Mosteller , and John W . Tukey . Exploring Data Tables , Trends , and Shapes . Wiley , 1985 .
[ 9 ] Amy L . Lansky and Andrew G . Philpot . Ai based planning for data analysis
Expert , 1993 . forthcoming . tasks .
IEEE
[ 10 ] Christopher
J . Matheus , Philip K . Chan , and Gregory Piatetsky Shapiro .
Systems for issue on Learning and Discovery in knowledge discovery Knowledge Based Databases , 1993 . forthcoming . in databases .
IEEE TKDE special
[ 11 ] JPearl and T . Verma . A theory of inferred causation . In Proceedings of Principles of Knowl edge Representation and Reasoning , 1991 .
[ 12 ] John W . Tukey . Exploratory Data Analysis . Addison Wesley , 1977 .
KDD 94
AAAI 94 Workshop on Knowledge Discovery in Databases
Page 59
Page 60
AAAI 94 Workshop on Knowledge Discovery in Databases
KDD 94
