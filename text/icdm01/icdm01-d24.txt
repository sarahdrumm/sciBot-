MEASURING REAL TIME PREDICTIVE MODELS
SAMUEL STEINGOLD , RICHARD WHERRY , AND GREGORY
PIATETSKY SHAPIRO
ABSTRACT In this paper we examine the problem of comparing real time predictive models and propose a number of measures for selecting the best model , based on a combination of accuracy , timeliness , and cost . We apply the measure to the real time attrition problem .
1 . Introduction
Comparing quality of different models is an important practical task . When the model deals with static data , this is a well established area with many known model measures , like Lift , Response Ratio , L quality etc ( see [ 1 ] , [ 2 ] and [ 3] ) .
Recently data miners have begun to deal with dynamic and realtime data . We can use the latest transactions to predict how likely the customer is to buy this product , click on that link , or disconnect the service . When using real time data , in addition to traditional dimensions of accuracy and cost , we also have to compare models on the time dimension . If model A makes the same correct prediction as model B , but earlier , then model A should be preferred .
We have recently conducted extensive experiments with building real time attrition models and in this paper we summarize our experiences .
Suppose a company has a set C of customers and a continuous transaction stream X which , possibly together with historical data , is used to predict attrition of the customers . The model should be trained using the data up to the 1st day of the test period ( usually a month ) , and then run daily on the set of transactions up to that day ( and , possibly , on all the other historical data accumulated so far ) . The model should return the probability that the customer will attrite before the end of the period .
Date : June 15 , 2001 . Key words and phrases . Real time , Database marketing , measurement , predic tive models .
1
2
STEINGOLD , WHERRY , AND PIATETSKY SHAPIRO
The difference from the usual setup is that it is important to identify the potential attritors as early as possible , so that some actions can be taken to retain the customer .
2 . Desirable Properties of the Measure
A model M ( c , t ) is a function of two arguments : the customer c ∈ C and time t ∈ [ 0 ; T ] , which means that the actual model scoring algorithm gets all the historical and demographical data for c as well as all transactions x ∈ X up to time t . M returns ( an estimate of ) the probability p ∈ [ 0 ; 1 ] of the predicted event ( “ attrition ” ) by the end of the time period ( say , a month , in which case T = 30 ) . M ( t ) is the model at time t . The boolean value A(c ) says whether the customer c will actually attrite by the end of the month .
As specified in the Introduction , the model which identifies the potential attritors early is better , thus , the model quality Q(M ) should satisfy the following property : if M1 is “ better ” than M2 in the following sense : for all t
( 1 ) if A(c ) = 1 then M1(c , t ) ≥ M2(c , t ) if A(c ) = 0 then M1(c , t ) ≤ M2(c , t ) then Q(M1 ) ≥ Q(M2 ) . In other words , if the model M1 predicts true attritors earlier and non attritors later than model M2 , then it is “ better ” .
L(M1 , t ) ≥ L(M2 , t ) , so a simple measure like Q(M ) := P
One of the simplest measures would be the L quality , as defined in [ 3 ] . If we define L(M , t ) := L quality(M ( t ) ) to be the L quality of the model M as run at time t , one can easily see that if the model M1 is better than the model M2 in the sense of 1 , then for all t we have t L(M , t ) would satisfy the requirement . Unfortunately , this measure does not capture the notion of how much earlier one model identifies the attritors than the other .
Thus , we need to generalize the current model quality measure to take the time aspect into account . While ultimately the cost/benefit matrix of the ( in ) correct prediction should be the deciding factor , in many cases it is not known , or subject to change . Thus we start with considering the value free measures , based on time and accuracy , and will add the value consideration later .
REAL TIME MODELS
3
3 . Value Free Measures
31 Derivation . For a customer c ∈ C who is an attritor ( A(c ) = 1 ) , consider the following measure :
( 2 )
Q0(c ) =
2 T 2
M ( c , t)(T − t)dt
When the model stably predicted that this customer would attrite ( ie , M ( c , t ) = 1 for all t ) , we have Q0(c ) = 1 , and if the model never predicted attrition ( M ( c , t ) = 0 for all t ) , then Q0(c ) = 0 . If the model started to predict attrition at time 0 < τ < T , ie , fl 0 when t ≤ τ
1 when t > τ
M 1
τ ( c , t ) =
Z T
0
( 3 ) then
( 4 )
( 5 )
( 6 ) then
Thus Q0 measures how much time the company would have to contact the potential attritor . Note that , since T − t ≥ 0 when t ∈ [ 0 ; T ] , this measure satisfies the requirement 1 . For a customer c ∈ C who is not an attritor ( A(c ) = 0 ) , we can write to charge a penalty for falsely predicting attrition . If the model stopped predicting attrition at time 0 < τ < T , ie ,
Q0(c ) = 1 − τ T
M ( c , t)dt
Z T fl 1 when t ≤ τ
0
0 when t > τ
Q0(c ) = − 1 T
M 0
τ ( c , t ) =
Q0(c ) = − τ T
( 7 ) Thus , for an “ always positive ” model Q0(c ) = −1 , while for an “ always negative ” one Q0(c ) = 0 . Therefore Q0 measures how long the model gave a false prediction , ie , the chances the company had to contact the non attritor . Note that this measure satisfies the requirement 1 . Combining formulas 2 and 5 using A and 1 − A as a partition of unity , we arrive at
Q0(c ) =
M ( c , t )
A(c)(T − t ) − ( 1 − A(c ) )
T 2 ) − ( 1 − A(c ) ) dt dt
2 T 2
Z T Z T
0
0
=
1 T
M ( c , t )
2A(c)(1 − t T
STEINGOLD , WHERRY , AND PIATETSKY SHAPIRO
Z T
0
Z T
X c∈C
0
4 or
( 8 )
Q0(c ) :=
1 T
M ( c , t )
3A(c ) − 1 − A(c )
2t T dt
It only remains to average Q0 over all customers to arrive at a real time model quality measure :
( 9 )
Q0(M ) :=
1 N T
M ( c , t )
3A(c ) − 1 − A(c )
2t T dt where N = #C is the total number of customers .
Since both 2 and 5 satisfy the requirement 1 , this combined measure satisfies it too .
32 Rationale . We want the quality of the similar models 3 and 6 to look similar , namely like 4 and 7 respectively , and formulas 2 and 5 are the only solutions .
Formulas 4 and 7 let us interpret Q0 as the mean “ good time ” ( the advance warning the model gives us for the true attritors ) minus mean “ bad time ” ( the advance warning the model gives us for the non attritors ) .
Note that we did not consider false positives ( M 1
τ when A(c ) = 0 ) and false negatives ( M 0 τ when A(c ) = 1 ) . The reason is that both of these situations are highly unlikely in reality : usually the quality of prediction improves with time , ie , we expect that |M − A| decreases with time . A more realistic examples of false positives are M 1 τ when A(c ) = 1 , and false negatives are M 0 τ when A(c ) = 0 , but τ is close to T , ie , the correct prediction comes too late .
33 Examples . Let us compute this measure for some specific models . 331 “ Always Negative ” Model . If M ( c , t ) = 0 for all c ∈ C and t ∈ [ 0 ; T ] , then obviously Q0(M ) = 0 . 332 “ Always Positive ” Model . If M ( c , t ) = 1 for all c ∈ C and t ∈ [ 0 ; T ] , then let Na = #{c : A(c ) = 1} be the number of attritors and b = Na
N be the base rate , and compute
Q0(M ) =
1 N T
( 2 − 2t T
)dt +
Z T
X
( A(c)=1
0
= b − ( 1 − b ) = 2b − 1
Z T
X
A(c)=0
0
( −1)dt )
REAL TIME MODELS
5
333 “ Perfect ” Model . If M ( c , t ) = A(c ) for all c ∈ C and t ∈ [ 0 ; T ] , then
Z T
X
A(c)=1
0
( 2 − 2t T
)dt
Q0(M ) =
1 N T
= b
334 “ Random ” Model . If M ( c , t ) = b , where b is the base rate , as above , for all c ∈ C and t ∈ [ 0 ; T ] , then this is just a multiple of the “ always positive ” model and Q0(M ) = b(2b − 1 ) .
335 Summary . Here is the summary for the four models :
Always Positive Always Negative
Perfect Random
2b − 1
0 b b(2b − 1 )
34 Discussion . Figure 1 shows that the “ Perfect ” model is the best , and its advantage is the highest when the base rate is 1 2 . When the base rate is 1 , “ Perfect ” , “ Random ” and “ Always Positive ” models are identical , and , indeed , their Q0 is the same – one . When the base rate is 0 , “ Perfect ” , “ Random ” and “ Always Negative ” models are identical , and , indeed , there Q0 is the same – zero .
As expected , the “ Random ” model ’s quality is between that of “ Always Positive ” and “ Always Negative ” ones , and “ Always Positive ” wins when the base rate b > 1
2 and loses when b < 1 2 .
It is better to normalize Q0 so that the “ Perfect ” model always has
Q = 1 , while the “ Random ” model has Q = 0 , ie ,
Q(M ) = Qn(M ) =
Q(M ) − b(2b − 1 ) b − b(2b − 1 )
This means
( 10 )
Q(M ) :=
1
2N T b(1 − b )
Z T
0
X c∈C
( M ( c , t ) − b )
3A(c ) − 1 − A(c )
2t T dt
Since the original measure 9 satisfies the requirement 1 , this measure satisfies it too .
Then we would have
6
STEINGOLD , WHERRY , AND PIATETSKY SHAPIRO
Figure 1 . Comparison of Q0 for various models
Always Positive Always Negative ( 1 − 2b)/2(1 − b )
( 2b − 1)/2b
Perfect Random
1 0
Note that the graphs on figure 2 are symmetric .
4 . Value Based Measures
Business practice has shown that any data mining effort should take the customer value into account , otherwise valuable resources would be wasted on retaining an unprofitable customer whose probably of attrition is high , while no effort would be made to retain a profitable customer with low attrition probability .
1 08 06 04 02002040608100102030405060708091Q qualitybase ratealways negativealways positiverandomperfect REAL TIME MODELS
7
Figure 2 . Comparison of Q = Qn for various models , normalized
Thus we must ascribe a customer a value V ( c ) , take it into account during model training and evaluate the model using
( M ( c , t ) − b ) V ( c )
3A(c ) − 1 − A(c )
2t T dt
Actually V ( c ) should be not the past value of the customer , but his
Again , this measure satisfies the requirement 1 when the value V is
( 11 )
Q(M ) :=
1
2N T b(1 − b )
Z T
X c∈C
0 projected total future value . non negative , since
V ( c )
V ( c )
3A(c ) − 1 − A(c )
3A(c ) − 1 − A(c )
2t T 2t T
≥ 0 when A(c ) = 1
≤ 0 when A(c ) = 0
1 08 06 04 02002040608100102030405060708091normalized Q qualitybase ratealways negativealways positiverandomperfect 8
STEINGOLD , WHERRY , AND PIATETSKY SHAPIRO
5 . Real World Examples of Real Time models
51 Problem Description . In this section , we will evaluate the performance of two models . The goal of each is to identify those customers that exhibit behavior that leads to attrition . Once these customers are identified , action should be taken on behalf of the institution to prevent attrition . This usually takes the form of a marketing offer .
It is assumed the attrition models will be part of a data mining system that operates on transactions in real time ( eg , customers are scored at each transaction ) . It is desirable to make such a system adaptive to transactions as they happen in real time . Such a system should have a method of measuring the effectiveness of a deployed model . One way to do this is using the usual lift , accuracy , or l quality . However , these measures are static and do not capture the dynamic nature of the production environment . Model quality , developed in the previous sections , provides an excellent measure for such a system .
52 Data . The data that we use is a combination of historical and transaction banking data . We have two months of historical data ( January and February ) and one month ( March ) of transaction data . We are trying to predict attrition in the months of March and April . We will compare two models and judge their performance against each other and to that of a random model using the model quality measure developed in the section 3 .
The data is split at the customer level into a training and held out datasets so that all transactions belonging to a certain customer are in either the training dataset or all transactions for that customer are in the held out dataset .
The training takes place over the entire period of the 31 days of March . The held out data is divided into 5 day increments ( March 0105 , March 06 10 , March 11 15 , March 16 20 , March 21 25 , and March 26 31 ) . This will allow us to estimate Q(M ) .
53 Estimating Model Quality . To estimate Q(M ) , we use the held out set Ch of customers , which was not used in training the model , and change the order of summation and integration in the equation 10 . We also replace the integral with a sum , computed for t1 being March 5 , t2 – March 10 , t3 – March 15 , t4 – March 20 , t5 – March 25 , and t6 – March 31 . In addition , we split the sum over customers in 10 into a sum for attritors and a sum for non attritors . This will lead to an efficient computation of Q(M ) with the assumption that the number
REAL TIME MODELS
9
Q0(M )
Qn(M )
Period Model 1 0.0555 Model 2 0.0013 Random 0.0282
( Normalized )
0.8712 0.0526
0.0
Table 1 . The quality measures for the experimental models of non attritors is much greater than the number of attritors . We get the following expression :
( 12 )
Q(M )
:= t=6X
[
X
2NhT b(1 − b )
1
X c∈Ch,A(c)=1 t=1 c∈Ch,A(c)=0
2(M ( c , t ) − b )
1 − t T
( b − M ( c , t ) ) +
]
Here Nh = #Ch is the number of customers in the held out set , and M ( c , t ) is the model score computed for the transactions of the customer c up to the time t plus his historical and demographical data ( if the model uses it ) . If the model uses only the transaction data and the customer had none in [ 0 ; t ] , then the base rate M = b is used ( which is obviously equivalent to ignoring such customers ) . Note that b is the global base rate across the whole customer set C , which should be the same as the base rate in the held out set Ch .
Unfortunately , the inner sums in equation 12 , do not make much sense in themselves , in particular , they do not estimate Q(M ) restricted to [ 0 ; t ] ( instead of [ 0 ; T ] ) .
54 Results . Both models were trained using the same dataset and are evaluated on the same held out dataset . The training dataset consists of transactions for 6,814 customers . The held out dataset consists of transactions for 3,440 customers . The average number of transactions per customer is approximately 18 . The held out data transactions were divided into each of the six periods ( t = 5 , 10 , 15 , 20 , 15 , 31 ) . For the first period , March 1 5 , there were 1,865 customer that performed transactions . By the end of March 3,440 customers had performed transactions .
Table 1 summarizes the results . With a base rate of 0.03 , both models perform poorly . Notice that for both Model 1 and Model 2 , Q0(M ) < 0 . This tells us that for both
10
STEINGOLD , WHERRY , AND PIATETSKY SHAPIRO models , the mean “ bad time ” is greater than the mean “ good time ” . Accordingly , both models are giving more weighted advanced warnings for non attritors than for attritors . The fact that Q0(M ) < 0 is not necessarily bad . In fact , Qn(M1 ) > 0 indicates that Model 1 performs better than the random model .
55 Real Time Environment . We have evaluated the models on the held out dataset . Model 1 performs better than Model 2 , so we choose to deploy Model 1 to a real time environment . Once the model is deployed , it will be monitored . The model quality , Q(M ) developed in the previous sections provide an excellent way to measure the performance of the model .
However , in order to use Q(M ) to measure the performance , we need to choose T , the period over which the model will be evaluated , and select the held out subset of customers whose transactions will be used to estimate Q(M ) .
If the deployed model begins to perform below certain level , we can re build and re deploy the model . Alternatively , if the learning algorithm supports it , we can adapt the model to the new information .
6 . Discussion
61 Cross Sell Models . The models developed in section 5 were attrition models where the goal was to identify attritors as early as possible . In a cross sell model , the goal is to identify which product , if any , is the best sell for the current customer , based on their behavior and likeness with customers that currently own the product . For example , a bank may wish to sell certificates of deposits ( CD ) to its current base of customers . It may be desirable to identify these potential customers as early as possible . Continuing with the CD example , a customer may be gradually building up a balance in their savings or checking , along with other indicative behavior . The bank may want to intervene as early as identifiably possible in this process and make an offer of a CD to the customer . As in the case of attrition , a static measure will measure which model is better at time t , but not provide you with enough information as to which model made the correct prediction earliest . Model quality , Q(M ) , can be used is this situation .
62 Customer Value . It bears repeating the dictum of section 4 that the reason for data mining in the business setting is to increase the value of the customer to the company and vice versa . Therefore it is
REAL TIME MODELS
11 crucial to use the ( reasonable estimate of the ) customer value in the formula 11 if at all possible .
References
[ 1 ] Foster Provost , Tom Fawcett “ Analysis and Visualization of Classifier Performance : Comparison under Imprecise Class and Cost Distributions ” , Proceedings of KDD 97 , pp . 43 48 , AAAI Press , 1997 .
[ 2 ] Gregory Piatetsky Shapiro , Brij Masand “ Estimating Campaign Benefits and
Modeling Lift ” , Proceedings of KDD 99 , pp . 185 193 , ACM Press , 1999 .
[ 3 ] Gregory Piatetsky Shapiro , Sam Steingold , “ Measuring Lift Quality in Data base Marketing ” , SIGKDD Explorations , Vol . 2:2 , ( 2000 ) , 81 86
Samuel Steingold , Xchange Inc , ( 617 ) 790 2522 E mail address : sds@xchange.com
Richard Wherry , Xchange Inc , ( 617) 790 2542 E mail address : rwherry@xchange.com
Gregory Piatetsky Shapiro , Xchange Inc & KDNuggets , ( 617 ) 232
7512
E mail address : gps@kdnuggets.com
