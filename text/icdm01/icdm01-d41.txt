Hierarchical Text Classification and Evaluation
Aixin Sun and Ee Peng Lim
Center for Advanced Information Systems
Nanyang Technological University
Nanyang Avenue , Singapore 639798 , Singapore sunaixin@pmailntuedusg aseplim@ntuedusg
Abstract
Hierarchical Classification refers to assigning of one or more suitable categories from a hierarchical category space to a document . While previous work in hierarchical classification focused on virtual category trees where documents are assigned only to the leaf categories , we propose a topdown level based classification method that can classify documents to both leaf and internal categories . As the standard performance measures assume independence between categories , they have not considered the documents incorrectly classified into categories that are similar or not far from the correct ones in the category tree . We therefore propose the Category Similarity Measures and DistanceBased Measures to consider the degree of misclassification in measuring the classification performance . An experiment has been carried out to measure the performance of our proposed hierarchical classification method . The results showed that our method performs well for Reuters text collection when enough training documents are given and the new measures have indeed considered the contributions of misclassified documents .
1 . Introduction
Text classification ( TC ) or text categorization is the process of automatically assigning one or more predefined categories to text documents . In TC research , most of the studies have focused on flat classification where the predefined categories are treated in isolation and there is no structure defining the relationships among them [ 1 , 19 ] . Such categories are also known as flat categories . However , when the number of categories grows to a significantly large number , it will become much more difficult to browse and search the categories . One way to solve this problem is to organize the categories into a hierarchy like the one developed by Yahoo! [ 18 ] .
Hierarchical classification allows us to address a large classification problem using a divide and conquer approach . At the root level in the category hierarchy , a document can be first classified into one or more sub categories using some flat classification method(s ) . The classification can be repeated on the document in each of the subcategories until the document reaches some leaf categories or cannot be further classified into any sub categories . A few hierarchical classification methods have been proposed recently [ 1 , 2 , 10 , 13 , 15 , 17 ] . In most of the hierarchical classification methods , the categories are organized in treelike structures . On the whole , we can identify four distinct category structures for text classification . They are :
1 . Virtual category tree : In this category structure , categories are organized as a tree . Each category can belong to at most one parent category and documents can only be assigned to the leaf categories [ 2 ] .
2 . Category tree : This is an extension of the virtual category tree that allows documents to be assigned into both internal and leaf categories [ 15 ] .
3 . Virtual directed acyclic category graph : In this category structure , categories are organized as a Directed Acyclic Graph ( DAG ) . Similar to the virtual category tree , documents can only be assigned to leaf categories .
4 . Directed acyclic category graph : This is perhaps the most commonly used structure in the popular web directory services such as Yahoo! [ 18 ] and Open Directory Project [ 11 ] . Documents can be assigned to both internal and leaf categories .
In this paper , we will only focus on hierarchical classification that involves category trees .
To compare different hierarchical classification methods , experiments involving training and test data sets have to be conducted , and some performance measures are used to determine the effectiveness of the methods . In flat classification , performance measures such as precision and recall have been widely used [ 14 , 19 ] . The same performance measures have also been used to measure the performance of hierarchical classification methods . In this paper , we argue that these performance measures are not adequate as they have largely ignored the parent child and sibling relationships between categories in a hierarchy . By not considering the “ closeness ” of categories , the performance of hierarchical classification may not be accurately captured . In general , the categories from the same subtree share more domain knowledge than the ones from different subtrees , that is , the categories from the same subtree are semantically closer to one another . With the standard precision and recall measures , all these relationships among categories are not accounted for . In this paper , we will present several performance measures applicable to hierarchical classification . Among them are the category similarity measures and distance based measures .
In this paper , we aim to establish a framework to evaluate the performance of hierarchical classification . There are two main contributions :
1 . We define a new set of performance measures that consider the semantic relationships and parent child relationships among categories in a hierarchy . The intuition is that when a document is wrongly classified , one has to examine how different is the incorrect category from the correct category .
2 . We develop a top down level based hierarchical classification method for category tree using Support Vector Machine ( SVM ) classifiers . By conducting experiments using the Reuters text collection and the new performance measures , we illustrate how the performance of hierarchical classification can be more accurately determined .
This paper is organized as follows . We first give an overview of the related hierarchical classification work in Section 2 . In Section 3 , we present several new performance measures for hierarchical classification . The experiment on our proposed hierarchical classification method will be described in Section 5 . The results of both standard performance measures and the new performance measures are presented in this section . Finally , we conclude our work in Section 6 .
2 . Related work
The existing hierarchical classification methods have mostly assumed a virtual category tree structure [ 2 , 13 ] . Furthermore , these methods have often been evaluated using the performance measures developed for flat classification . There are basically two approaches adopted by the existing hierarchical classification methods , namely , the bigbang approach and the top down level based approach .
In the big bang approach , only a single classifier is used in the classification process . Given a document , the classifier assigns it to one or more categories in the category tree . The assigned categories can be internal or leaf categories depending on the category structure supported by the methods . The big bang approach has been achieved with Rocchio like classifier [ 7 ] , rule based classifier [ 13 ] and methods built upon association rule mining [ 15 ] . The performance measures used in these experiments have been very much based on simple empirical observations of the number of correctly classified documents or the percentage of incorrectly classified documents .
In the top down level based approach , one or more classifiers are constructed at each level of the category tree and each classifier works as a flat classifier at that level . A document will first be classified by the classifier at the root level into one or more lower level categories . It will then be further classified by the classifier(s ) of the lower level category(ies ) until it reaches a final category which could be a leaf category or an internal category . The top down levelbased classification has been implemented with ACTION ( for Automatic Classification for Full Text Documents ) algorithm in [ 1 ] , multiple Bayesian classifiers in [ 6 ] and Support Vector Machine classifiers in [ 2 ] . Three performance measures , ie , precision , recall and F measure have been used in these experiments .
Compared to the top down level based approach , the big bang approach can only use the information carried by the category structure during the training phase but not the classification phase . As discriminative features ( eg , terms ) at a parent category may not be discriminative at the child categories , it is usually very difficult for a classification method using big bang approach to exploit different sets of features at different category levels . Another issue in the big bang approach is that the classifier constructed may not be flexible enough to cater for changes to the category structure . The classifier needs to be retrained once the category structure is changed .
On the other hand , the top down level based classification approach is not problem free . One of its obvious problems is that a misclassification at a parent ( ancestor ) category may force a document to be excluded from the child categories before it could be examined by the classifiers of the child categories . Classification methods based on topdown approach also require more training examples since multiple classifiers have to be constructed and each requires a different training set . Without adequate training examples , the performance of these classifiers may suffer .
3 . Performance measures
To evaluate a hierarchical classification method , one can directly apply the standard precision and recall for flat clas
Category
 
Classifier YES Judgments NO
Expert Judgments YES
NO
Table 1 . Contingency table for category   sification on each category of the entire category space .
Most hierarchical classification methods that involve virtual category trees often exclude the internal categories from the performance measurement as they are virtual categories and there are no documents under them . In a category tree , however , all categories have to be considered . In addition , categories are connected with parent child and sibling relationships . Two categories can be similar when they share many common documents . For example , the Programming and Software Engineering categories may have several common features allowing documents to be classified under both of them . Therefore , if a document is not classified to the correct category , one should consider the degree of wrong classification . In other words , wrongly classifying a document into a parent or child category is considered better than classifying it into categories that are far away from the correct category .
31 Measures for flat classification
The performance of text classification methods can be measured in several ways . In this paper , we are interested in measuring the accuracy of the final classification results , ie , the correctness of assigning categories to a set of documents . According to the text classification survey by Sebastiani [ 14 ] , the most commonly used performance measures in flat classification are the classic information retrieval ( IR ) notions of Precision and Recall . Precision for a category in this paper . The contingency table for a par
  , denoted as , measures the percentage of correct assignments among all the documents assigned to   . The gives the percentage of correct assignments in Recall   among all the documents that should be assigned to   . are also known as the standard precision and and recall for       ticular category   from the category space be the set of documents coris shown in Table 1 . Let be the set of docrectly classified into category   ; uments wrongly classified ; be the set of documents be the set of documents correctly wrongly rejected and rejected . The standard precision and recall are defined as follows1 :
 !
1In all the formulas presented in this paper , elements in set #
.
( 1 )
#$" gives the number of
%
 !
( 2 )
Based on the standard precision and recall for each category , the overall precision and recall for the whole category space , ie , ways , namely , Micro Average and Macro Average . MicroAverage gives equal importance to each document , while Macro Average gives equal importance to each category [ 19 ] :
    , can be obtained in two
1 . Micro Average :
( ' '
2 . Macro Average :
*+
*+
 !
 !
*+ ( , *+ ( ,
( . .
*+ *+
0
( 3 )
( 4 )
( 5 )
( 6 )
Neither precision nor recall can effectively measure classification performance in isolation [ 14 ] . Therefore , the performance of the text classification has often been measured by the combination of the two measures . The popular combinations are listed below :
1 . Break Even Point(BEP ) : BEP , proposed by Lewis [ 8 ] , defines the point at which precision and recall are equal . However , in some cases , BEP can never be obtained . For example , if there are only a few positive test documents compared to a large number of negative ones , the recall value can be so high that the precision can never reach .
2 .
$1 Measure : $1 measure was proposed by Rijsbergen
[ 12 ] . It is a single score computed from precision and recall values according to the user defined importance is used [ 19 ] . The formula is :
( ie , 2 ) of precision and recall . Normally , 2 $15
43
276 where 2;:=<
@ ?
( 7 )
9
+8 +0
+0
9
3 . Average 11 Point Precision : The precision values are interpolated at 11 points at which the recall values are 0.0 , 0.1 , . . . , 10 This measure is mostly used in the situation when the classification method ranks documents according to their appropriateness to a category or similarly ranks categories to a document [ 14 ] .

 
 " 
 

&
)

 )

 &
)

 )

 &
)
/ &
)
/ ,  3 8 2 6 8  > Besides precision and recall , other commonly used performance measures include Accuracy and Error [ 14 , 6 ] , de and noted by  
 
3 for category   respectively .
 !  !  !  !
 !  !
 !  !  
32 Measures based on category similarity
( 8 )
( 9 ) documents into categories similar to the correct categories , , that misclassifies the documents into totally unrelated categories . We therefore extend the standard precision and recall defi
Intuitively , if a classification method   misclassifies it is considered better than another method , say nitions to distinguish the performance of   and The Category Similarity between two categories   and   , denoted by  
, can be computed in several ways . In our work , we have chosen to adopt cosine distance between the feature vectors of two categories . It is suggested that the feature vector for a category should be derived by summation of the feature vectors of all training documents under it . The feature vectors of documents are the ones used to build the classifiers . From the category similarities , one can define the Average Category Similarity
 
 
.
( ACS ) . The formulas for   and  
     
 
 
  are :
*+
@*$   ; ’s are index terms , where sponding term weights .
*+
( 10 )
*+ *+    
  + ’s and ’s are the corre
( 11 )
, !
Based on the category similarity , we can now measure is counted as 1 in computation of precision the degree of correctness of the assigned categories   of document while its labelled categories are . In is assigned to   correctly , ie , the simplest case where ! and recall for   , similar to flat classification . However , if ) , we should is wrongly assigned to   ( ie , ! ! consider whether the ’s labelled categories are similar to   ; that is , how much can contribute to   when we compute the precision and recall values for   . In this case , the #"%$ "%$ to   , denoted by   670
&)"%$ of !
 98     defined as follows :
)+* ,/.1032 4
 
3
 
 
 '(
 
( 12 )
!
%&
"%$ is to   depends on the category simi is wrongly rejected from   , say , ! : Similarly , if !  '( &)"%$ of ! the #"%$ larities between   and the assigned categories of .  
( 13 )
%&
* ,/.1032 4
: ;#0
 
3
 98    
 
"%$
!
,
 
C>ED!F
 '( %&
%& "%$   is defined as follows :
The contribution of a document can be positive or negative depending on how similar its labelled and assigned categories are in comparison with the average category similar . Note that a document can belong to or be assigned to more than one category . To prevent one document from ity  being over shined or over punished , the #"%$ each document 3#< . Therefore , the !=(&7$$ % 3 range of < denoted by "%$ 3     "%$ "%$ ! For all the documents that belong to butions G
&)"%$ of to category   should be restricted to the  '( &)"%$  
?>A@ will be : + IH "%$
! , the total contri 
"%$ and similarly , the total contributions "%$ *TS
"%$ The extended category   based on category similarity are defined as fol
+ NH 032 . J % O&QPR&)"%$
! and %
032 . JLK M
"%$   is :
UV
( 16 )
( 15 )
( 14 )
G
*TS for
!
"%$ lows :
G "%$   "%$
   !
G "%$   "%$
G
   ! can be negative ,  and "%$ can be negative . Therefore , a /  , when  "%$
G
; "%$
"%$ "%$
"%$
1W
( 17 )
( 18 )
  1W YX
*TS *TS
>ED!F
>ED!F
Since both G G "%$ YX 0 . As G "%$ > , the numerator / *TS and *TS applicable to
"%$
"%$
. function is applied to the numerator to make it not less than can be treated as 0 in this case . The same rule is
The Micro Average and Macro Average can be extended to consider category similarity . We give the extended definitions as follows :
Micro Average :
[ \ ] ^`_ba  O ] ^`_ba
)?c egf#h/ikj#l`hnm oRp egf#hQp egf#h/ikj#l`hnm oRp )?c egfOhQp
)+c p rtsvuxwzyR{ p r~p p rtsvuxwzyR{ pOrp s  r|s {(wzyR{ d } pOr|s {(wzyR{ d })} r|s {(wzyR{ d } pOr|svuxwzyR{ d })}
( 19 )
( 20 )

 


 

,
6
6
6
6
,
)
,
)
6
)
6
 
)
)
, /
, /
3
: :
,   ,
5 , ,
   
  ,
) , ,
   
 
  ,
  , B , 3 , ,
   
  , $  
$  
M
  ,
, >

 

$  

$  
, >

 

$  

 
  $  
 

$     

 
$   , >

   

$  
>
Z d q [ d d ) c d q [ d s [ d Z d q [ d d d q [ d d Macro Average :
^`_ ^`_
*+ *+
*TS *TS
( 21 )
( 22 )
Similar to the extended precision and recall , the extended accuracy and error for category   can be defined based on document contribution :
*TS *TS
 
 !  !
 !  !
G  
 ! = G
 !
"%$ "%$
 ! =  !
"%$ "%$
( 23 )
( 24 )
Note that the sum of extended accuracy and error is 1 which is the same as the original definitions .
As we have discussed in Section 3.1 , it is not sufficient to evaluate a classification method using only precision or recall . Instead , they have to be considered together . The performance measures that combine both precision and re call are the Break Even Point ( BEP ) , 71 and Average 11Point Precision . Among them , 71 can be easily computed using the extended precision and recall . BEP can be applied to classification methods that can rank documents for each category . In hierarchical classification using the bigbang approach , BEP and Average 11 Point Precision can be computed for classification methods that can rank all documents in the test set for each category . On the other hand , for those classification methods using top down level based approach , the test documents available for classification at a level are determined by the parent classifier as the latter may reject documents before they reach the child classifier(s ) . With such restriction , it is difficult to compute the BEP and Average 11 Point Precision for each category . Hence , we argue that the above two performance measures are less applicable to the hierarchical classification methods .
33 Measures based on category distance
Instead of using category similarity , we can define performance measures based on the distances between categories in a category tree . The distance between two cate gories   and   , denoted by , is defined to be the number of the links between   and   . Intuitively , the shorter the length , the closer the two categories .
 
 
&QP
The distance between categories was first proposed to measure misclassification in [ 16 ] . Nevertheless , the work did not define performance measures based on category dis tance . To define the #"%$ ments , an acceptable distance , denoted as be specified by the user . example , if
&)"%$ of misclassified docu3 , a misclassification of document that
, must first must be greater than 0 . For
&QP
 '( %& &QP
&QP
 '( involves the labelled and assigned categories at more than 1 link apart will yield negative contribution , but zero con
670
&QP
 
%&
( 25 )
.1032 4
 98 &QP defined as follows :
&)"%$ of a to category   based on category distance is :   tribution at 1 link apart . Formally , the #"%$ document ! If ! : "%$ If ! : "%$
: ;#0 * ,/.1032 4 &)"%$ needs to be refined For the same reason , the #"%$ %& 3#< . With this new definition for 3 to be in the range of < egory distance , denoted by and larly , Micro Average , Macro Average , +1 contribution , the extended precision and recall based on cat , can be defined using the formulae ( 17 ) and ( 18 ) respectively . Simi , accuracy and er
!
:   !
 98 &QP
 '(
( 26 )
 
&QP ror can be extended .
4 . Hierarchical classification method
In this section , we propose a hierarchical classification method for category tree structure based on top down levelbased approach . All the classifiers involved in this method are binary classifiers . Binary classifiers normally need to be trained with both positive and negative training documents . In the hierarchical classification method , a binary classifier is built for each category . These classifiers that determine whether a document should belong to the corresponding categories are known as the local classifiers . However , an additional binary classifier is built for each internal category to determine whether a document should be given to the classifiers of its sub categories . This special classifier is known as the subtree classifier since it decides whether a document should belong to a subtree . This separation of local and subtree classifiers distinguishes our method from that proposed by Dumais and Chen [ 2 ] . To build binary classifiers in hierarchical classification , special consideration must be given to the selection of training documents for each classifier . in the hierarchy shown in Figure 1 Tree ( a ) , in a given category is the set of categories of a category   tree , denoted by   " % including   . For that belongs to the subtree rooted at   Q
. For any doc" %
&7$ &7$ is true if and only if belongs ument ! ,   to category   ; ! " % if ! belongs to any of the categories in     .
  1 @ is true if and only
#" %$
The   example ,
 
!
" %
" %
& .
)
/ & .
)
0 /

 

$  



  
$  

 ,
  ,
H * , 5 , 3
>
, &
  ,
H , 3
>
, &
,  
,
: :  
,
, Hier1
Hier2 grain crude livestock veg oil corn wheat ship nat gas carcass hog
( a ) oil seed ( b ) palm oil barley
Hier3 meal feed rice cocoa strategic metal tin copper
( c ) iron steel
Figure 1 . Category trees from Reuters collection
.
%
  returns the parent category of category   . Let $ denote a set of training documents . The posi tive and negative training documents are selected differently for each type of classifier given below2 where +ve and ve refer to positive and negative training documents respec
:
% tively and ! : Subtree classifier of a root category   0
– +ve : All ! such that ! : . " %
– ve : All ! or Equal number ( to positive documents ) of random selected such that !
" % selected and the method of selection are classification methods dependent for this subtree classifier .
0
0
. The number of Subtree classifier of an internal category   :  
Local classifier of an internal category   :
– +ve : All ! such that ! : – ve : All ! such that !
  ! : $ " %
– +ve : All ! such that ! :
" %
" % .   . !
Local classifier of a leaf category  
– ve : All such that
!  
.
" %
5 :
– ve : All
– +ve : All ! such that ! : 5 . !
. such that
!
" %
$
5 . Experiments with SVM classifier
;
Joachims [ 4 ] . our experiment is SVM 5 category tree . In the experiments , we compared the classification performance indicated by both the standard and extended precision and recall . The SVM classifier used in Version 3.50 implemented by In our experiment , Reuters 21578 collection3 was used . To conduct our experiment , category trees need to be manually derived from the 135 categories . Kohler and Sahami extracted three category trees from the Reuters 22173 collection by identifying the category labels that suggest parentchild relationships [ 6 ] . Three slightly different category trees are derived from the Reuters 21578 collection using a similar approach ( see Figure 1 ) . Note that the roots of the three category trees are virtual categories .
Almost all documents in Reuters collection come with title , dateline and text body . We obtained the index terms from only the title and text body after stopword removal and stemming . The stopwords and the stemming algorithms have been taken directly from the BOW library [ 9 ] . A binary term vector is obtained for each document without applying any feature selection . In our experiment , we used Lewis Split provided by Reuters collection to obtain training documents and test documents .
All the test documents that belong to one or more category in a category tree are used as its positive test documents . The same number of test documents that do not belong to the category tree are randomly selected to be the negative test documents . The statistics about our training and test documents are shown in Table 2 . For Category
  ,   :P and   : refer to the subtree classifier and localclassifier for   respectively . In the table ,  and
  refer to number of positive training , negative training and positive test documents respectively . The category similarity matrix for Tree(a ) is shown in Table 3 . As
, only the lower half of the ma trix is shown . The ones for Tree(b ) and Tree ( c ) can be computed in a similar way .
,
 
 
 
 
 
The results of our experiment are shown in Tables 4 , 5 and 6 for the three category trees . We computed the stan dard Precision and Recall , the precision recall sion
*TS and *TS based on category similarity ; and the preciand recall based on category distance for
3http://wwwresearchattcom/˜lewis/reuters21578html
.  
and
  and !
5 and ! % :
Support Vector Machine ( SVM ) classifiers have been shown to be fast and effective in text classification [ 3 , 5 ] . Dumais and Chen have shown that SVM works well for virtual category tree but they did not consider category tree in their work [ 2 ] . The purpose of this experiment is to explore the use of SVM classifiers in classifying documents into a
2As normally there is no document directly under the root category , the local classifier for the root category is not constructed .
   
   
       
   
   
,
 
,   :  
,    
, :  
,  
,
, : :  
,   :    
,
,   5
 ,
, Category Hier1 crude:s crude:l grain:s grain:l nat gas ship corn wheat
Tree ( a ) +   981 574 391 437 434 75 198 182 212
  981 435 183 544 3 499 376 255 225
+   394
189
149 30 89 56 71
Category Hier2 livestock:s livestock:l veg oil:s veg oil:l carcass hog oil seed palm oil
Tree ( b ) +   270 83 75 191 87 50 16 124 30
  270 188 8 81 104 33 67 67 161
+   104 24 37 18 6 47 10
Category Hier3 meal feed:s meal feed:l str metal:s str metal:l barley rice cocoa copper iron steel tin
Tree ( c ) +   271 153 30 119 16 37 55 35 47 40 18
  271 119 123 153 103 116 98 118 72 79 101
+   123 19 11 14 18 24 18 14 12
Table 2 . Number of training and test documents for Trees
Category crude grain nat gas crude 1.000 0.523 0.602 0.574 0.487 0.497
1.000 0.453 0.556 0.791 0.815 Average Category Similarity ship corn wheat grain nat gas ship corn wheat
1.000 0.432 0.463 0.472
1.000 0.510 0.513
1.000 0.699
0.559
1.000
Table 3 . Category similarity matrix for Tree ( a )
Category crude grain nat gas ship corn wheat Micro Ave Macro Ave
0.846 0.869 0.818 0.879 0.888 0.886 0.864 0.864
0.962 0.939 0.600 0.820 0.857 0.986 0.909 0.860
0.849 0.869 0.833 0.879 0.944 0.976 0.883 0.892
0.963 0.938 0.614 0.821 0.939 0.993 0.919 0.878
0.890 0.868 0.900 0.888 0.929 0.942 0.892 0.903
0.964 0.932 0.714 0.843 0.913 0.980 0.922 0.891
Table 4 . Testing results for Tree ( a ) each category . The &QP
. We also computed the Micro Averages and
Macro Averages for the three definitions of precision and recall . and are computed with
From Table 2 , Tree ( a ) receives the largest number of training and test documents . Most of the precision and recall ( both the standard and extended ) values for Tree ( a ) are good . This is consistent with the experimental results given by Koller and Sahami in [ 6 ] although slightly different collections are used . The extended precision and recall based on category similarity are better than the standard ones in most cases ( ie , except the category grain ) . From the category similarity matrix shown in Table 3 , we observe that the categories within one subtree are more similar to each other compared to the categories across the two subtrees . In top down level based approach , most of the misclassification will occur in the subtrees , unless the document is wrongly rejected at the level grain and crude . Therefore ,
Category livestock veg oil carcass hog oil seed palm oil Micro Ave Macro Ave
0.629 0.878 0.611 1.000 0.646 1.000 0.710 0.794
0.708 0.783 0.611 0.333 0.893 0.700 0.760 0.671
0.816 0.906 0.778 1.000 0.688 1.000 0.789 0.864
0.771 0.845 0.734 0.287 0.919 0.799 0.815 0.726
0.734 0.904 0.600 1.000 0.625 1.000 0.734 0.810
Table 5 . Testing results for Tree ( b )
Category meal feed str metal barley rice cocoa copper iron steel tin Micro Ave Macro Ave
1.000 0.000 0.923 1.000 1.000 0.937 0.500 1.000 0.896 0.795
0.315 0.000 0.857 0.833 0.500 0.833 0.428 0.250 0.530 0.502
1.000 0.000 0.923 1.000 1.000 0.937 0.500 1.000 0.896 0.795
0.332 0.000 0.857 0.833 0.505 0.833 0.428 0.249 0.534 0.505
1.000 0.000 0.923 1.000 1.000 0.937 0.500 1.000 0.896 0.795
Table 6 . Testing results for Tree ( c )
0.654 0.880 0.473 0.416 0.901 0.918 0.769 0.695
0.368 0.000 0.857 0.833 0.520 0.833 0.428 0.166 0.534 0.501 the documents misclassified within the subtrees should contribute positively to the extended precision and recall based on category similarity . Therefore , it is reasonable for our extended precision and recall to be better than the standard ones .
The same observation holds for the extended precision and recall based on category distance , ie , most of the extended precision and recall values are higher than the standard ones . Since the acceptable error distance is 2 , the documents misclassified within the subtrees contributed positively to the extended precision and recall .
For Trees ( b ) and ( c ) , there are several categories ( ie , hog , tin and strategic metal ) trained with documents fewer than 20 . Since SVM classifiers require about 20 training documents to yield stable performance [ 2 ] , the performance result may not be representative enough for analysis . Al
[ 4 ] T .
Joachims . tion of Support Vector Machines http://aisgmdde/˜thorsten/svm light/ .
 
, an ( SVMs ) implementain C .
[ 5 ] T . Joachims . Text categorization with support vector machines : learning with many relevant features . In Proc . of the 10th European Conf . on Machine Learning , pages 137–142 , Chemnitz , DE , 1998 .
[ 6 ] D . Koller and M . Sahami . Hierarchically classifying documents using very few words . In Proc . of the 14th Int . Conf . on Machine Learning , 1997 .
[ 7 ] Y . Labrou and T . W . Finin . Yahoo! as an ontology : Using Yahoo! categories to describe documents . In Proc . of the 8th Int . Conf . on Information Knowledge Management , pages 180–187 , Kansas City , MO , 1999 .
[ 8 ] D . D . Lewis . An evaluation of phrasal and clustered representations on a text categorization task . In Proc . of the 15th Annual Int . ACM SIGIR Conf . on Research and Development in Information Retrieval , pages 37–50 , 1992 .
[ 9 ] A . K . McCallum . Bow : A toolkit for statistical language modeling , text retrieval , classification and clustering . http://wwwcscmuedu/ mccallum/bow , 1996 .
[ 10 ] D . Mladenic . Turning yahoo to automatic web page classifier . In Proc . of the European Conf . on Artificial Intelligence , pages 473–474 , 1998 .
[ 11 ] ODP Open Directory Project . http://dmozorg/ [ 12 ] C . J . V . Rijsbergen . Information Retrievel . London : Butter worths , 2nd edition , 1979 .
[ 13 ] M . Sasaki and K . Kita . Rule based text categorization using hierarchical categories . In Proc . of the IEEE Int . Conf . on Systems , Man , and Cybernetics , pages 2827–2830 , La Jolla , US , 1998 .
[ 14 ] F . Sebastiani . Machine learning in automated text categorisation : a survey . Technical Report IEI B4 31 1999 , Istituto di Elaborazione dell’Informazione , Consiglio Nazionale delle Ricerche , Pisa , IT , 1999 . Revised version , 2001 .
[ 15 ] K . Wang , S . Zhou , and Y . He . Hierarchical classification of real life documents . In Proc . of the 1st SIAM Int . Conf . on Data Mining , Chicago , 2001 .
[ 16 ] K . Wang , S . Zhou , and S . C . Liew . Building hierarchical classifiers using class proximity . In Proc . of the 25th Int . Conf . on Very Large Data Bases , pages 363–374 , Edinburgh , UK , 1999 .
[ 17 ] A . S . Weigend , E . D . Wiener , and J . O . Pedersen . Exploiting hierarchy in text categorization . Information Retrieval , 1(3):193–216 , 1999 .
[ 18 ] Yahoo! http://wwwyahoocom [ 19 ] Y . Yang . An evaluation of statistical approaches to text cat egorization . Information Retrieval , 1(1 2):69–90 , 1999 . though the extended precision and recall based on either category similarity or category distance give different values compared to the standard precision and recall , it is not clear enough to conclude the performance of our method for Tree(b ) and ( c ) .
In summary , our method performed reasonably well for the Reuters collection when given enough training documents . The extended measures have indeed considered contributions of wrongly classified documents .
6 . Conclusions
In this paper , we give an overview of hierarchical classification problem and its solutions . While the commonlyused performance measures are the ones for flat classification , the relationships among the categories in category tree are not accounted for . We propose some novel approaches to include the contributions of wrongly classified documents towards performance measures . We have also developed a top down level based classification method using binary classifiers ( such as SVM ) and evaluated the method using the Reuters collection . The results show that our method works well and the extended precision and recall can be feasibly implemented .
In our future work , we are going to evaluate the hierarchical classification method using classifiers other than SVM to compare their performance using the extended measures . Since we use category similarity and distance to measure the classification results , we plan to design a new hierarchical classification method that makes use of such information . In the top down level based approach , the error made at the parent category is not recoverable at the child category . We will also try to design a more tolerant hierarchical classification method with which the child classifiers are able to recover the errors made by the parent classifier(s ) .
References
[ 1 ] S . D’Alessio , K . Murray , R . Schiaffino , and A . Kershenbaum . The effect of using hierarchical classifiers in text categorization . In Proc . of the 6th Int . Conf . “ Recherche d’Information Assistee par Ordinateur ” , pages 302–313 , Paris , FR , 2000 .
[ 2 ] S . Dumais and H . Chen . Hierarchical classification of Web content . In Proc . of the 23rd ACM Int . Conf . on Research and Development in Information Retrieval , pages 256–263 , Athens , GR , 2000 .
[ 3 ] S . Dumais , J . Platt , D . Heckerman , and M . Sahami . Inductive learning algorithms and representations for text categorization . In Proc . of the 7th Int . Conf . on Information and Knowledge Management , pages 148–155 , 1998 . d
