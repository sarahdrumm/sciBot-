Anchor Text Mining for Translation of Web Queries : A Transitive Translation Approach
WEN HSIANG LU Academia Sinica and National Chiao Tung University LEE FENG CHIEN Academia Sinica and HSI JIAN LEE National Chiao Tung University ________________________________________________________________________
To discover translation knowledge in diverse data resources on the Web , this paper proposes an effective approach to finding translation equivalents of query terms and constructing multilingual lexicons through the mining of Web anchor texts and link structures . Although Web anchor texts are wide scoped hypertext resources , not every particular pair of languages contains sufficient anchor texts for effective extraction of translations for Web queries . For more generalized applications , the approach is designed based on a transitive translation model . The translation equivalents of a query term can be extracted via its translation in an intermediate language . To reduce interference from translation errors , the approach further integrates a competitive linking algorithm into the process of determining the most probable translation . A series of experiments has been conducted , including performance tests on term translation extraction , cross language information retrieval , and translation suggestions for practical Web search services , respectively . The obtained experimental results have shown that the proposed approach is effective in extracting translations of unknown queries , is easy to combine with the probabilistic retrieval model to improve the cross language retrieval performance , and is very useful when the considered language pairs lack a sufficient number of anchor texts . Based on the approach , an experimental system called LiveTrans has been developed for English Chinese cross language Web search .
Categories and Subject Descriptors : H24 [ Database Management ] : Systems – Textual databases ; H28 [ Database Management ] : Database Applications – Data mining ; H33 [ Information Storage and Retrieval ] : Information Search and Retrieval ; I72 [ Document and Text Processing ] Document Preparation – Hypertext/hypermedia General Terms : Algorithms , Experimentation , Performance Additional Key Words and Phrases : Multilingual translation , anchor text mining , cross language information retrieval , cross language Web search , competitive linking algorithm ________________________________________________________________________
1 . INTRODUCTION
The Web is becoming the largest data repository in the world . How to discover knowledge in diverse data resources on the Web and benefit Web information systems is
________________________________________________________________________
Authors' addresses : Wen Hsiang Lu , Institute of Information Science , Academia Sinica , Nangang 115 , Taiwan ; and Department of Computer Science and Information Engineering , National Chiao Tung University , Hsinchu 300 , Taiwan ; email : whlu@iissinicaedutw ; Lee Feng Chien , Institute of Information Science , Academia Sinica , Nangang 115 , Taiwan ; email : lfchien@iissinicaedutw ; Hsi Jian Lee , Department of Computer Science and Information Engineering , National Chiao Tung University , Hsinchu 300 , Taiwan ; email : hjlee@csienctuedutw Permission to make digital/hard copy of part of this work for personal or classroom use is granted without fee provided that the copies are not made or distributed for profit or commercial advantage , the copyright notice , the title of the publication , and its date of appear , and notice is given that copying is by permission of the ACM , Inc . To copy otherwise , to republish , to post on servers , or to redistribute to lists , requires prior specific permission and/or a fee . © 2003 ACM 1073 0516/01/0300 0034 $5.00
Germany
Yahoo englische version
Yahoo's Suchseite
Yahoo! ( États Unis )
Yahoo! ( répertoire et moteur de cherche )
美国雅虎
야후 USA
대중적인 야후
アメリカの Yahoo!
米国 Yahoo!
Korea
雅虎搜尋引擎
Yahoo! America http://wwwyahoocom
France
Yahoo 搜索引擎
Yahoo Search Engine
美國Yahoo網際網路WWW站
Japan
China
Taiwan
Fig 1 . An illustration showing various anchor texts in multiple languages linking to site Yahoo! from all over the world [ Lu et al . 2002a ] . being studied in almost every intelligent information processing area . Multilingual terminological resources , such as multilingual lexicons or thesauri , are valuable for conducting academic researches or developing applications , such as machine translation
[ Brown et al . 1993 ; Knight 1997 ] , cross language information retrieval ( CLIR ) [ Dumais et al . 1996 ; Oard and Diekema 1998 ] , or even information exchange in electronic commerce [ Silverman et al . 2001 ] . However , manual lexicography is time consuming and not cost effective . It is worthwhile to automatically construct multilingual lexicons or even thesauri via mining the Web content , which consists of huge amounts of multilingual and wide scoped hypertext resources .
To deal with the above problem , we have proposed a preliminary approach to extracting translations of Web queries through the mining of Web anchor texts and link structures [ Lu et al . 2001 , 2002a ] . This novel approach exploits Web anchor texts as bilingual corpora to alleviate the existing difficulties of cross language Web search , and has been proven particularly effective for extracting multilingual translation equivalents of query terms1 containing proper names or new terminology . For example , Fig 1 shows
1 In our collected query logs , most of the user queries contain only one or two words , so we use query term , query or term interchangeably in this paper . a typical example , in which there are a variety of anchor texts in multiple languages linking to the URL at http://wwwyahoocom/ from all over the world . Such a bundle of anchor texts pointing together to the same page is called as an anchor text set ( refer to
Subsection 31 ) It is not difficult to find some of Yahoo ’s regional aliases in this anchor text set . In fact , Web anchor text sets may contain similar description texts ( or concepts ) in multiple languages . It is likely that a number of word ( or phrase ) translations and synonyms can be extracted from them .
Discovering useful knowledge in Web anchor texts has not been fully explored .
According to our previous experiments , the extracted translation equivalents might not be reliable when a query term ’s corresponding translations either appear infrequently in the same anchor text sets or even do not appear together . In addition , the translation process will be inapplicable if there is a lack of sufficient anchor texts for a particular language pair . Although Web anchor texts undoubtedly are multilingual resources , not every particular pair of languages contains sufficient anchor texts . To deal with the above problems , this paper extends the previous anchor text based approach by adding a phase consisting of indirect translation via an intermediate language . For a query term which can not be translated , our idea is to translate it into a set of translation candidates in an intermediate language , and then to seek the most likely translation from the candidates that are translated from the intermediate language into the target language . We therefore propose a transitive translation approach to further exploit anchor text mining for translating Web queries [ Lu et al . , 2002b ] .
To reduce interference from translation errors , the proposed transitive translation model further integrates a competitive linking algorithm into the process of determining the most likely translation [ Melamed 2000 ] . The algorithm is designed based on an approximation of the maximum a posteriori matching for all considered translation pairs .
The overall approach is composed of several techniques , including anchor text mining , the probabilistic inference model , the transitive translation model , and the competitive linking algorithm . A series of experiments has been conducted , including performance tests on term translation extraction , cross language information retrieval , and translation suggestions for practical Web search services , respectively . The obtained experimental results on term translation extraction show that the transitive translation model is very useful when the considered language pairs lack a sufficient number of anchor texts . In addition , the competitive linking algorithm is effective in reducing the number of indirect association errors , ie , erroneous translations caused by highly relevant source terms . To determine the performance of the proposed approach when applied to CLIR , we conducted some experiments on the NCTIR 2 English Chinese IR task using both CL
LSI and the probabilistic retrieval model . The proposed approach was found to be effective in extracting translations of unknown queries , and easy to combine with the probabilistic retrieval model to improve the retrieval performance . On the other hand , although the proposed approach can not be integrated into the CL LSI model in a straightforward manner , we found that it could augment the translation lexicon and aid the retrieval process . Based on the proposed approach , an experimental system , called
LiveTrans , has been developed for English Chinese cross language Web search .
2 . RELATED WORK
2.1 Translation Extraction and CLIR
Cross language information retrieval ( CLIR ) , which enables users to query in one language and retrieve relevant documents written or indexed in another language , has become an important topic in recent research on information retrieval [ Ballesteros and
Croft 1998 ] . However , this presents a number of challenges , especially the problem of query translation . To make query translation possible , existing IR systems mostly rely on bilingual dictionaries for cross lingual retrieval . In these systems , queries submitted in a source language normally have to be translated into a target language by means of simple dictionary lookup . These techniques are limited in real world applications since queries given by users often contain proper nouns that do not exist in general purpose bilingual dictionaries . Another popular approach to dealing with query translation is based on corpus based techniques . A number of related researches on natural language processing have used a parallel corpus , containing aligned sentences whose translation pairs correspond to each other , to extract translation equivalents [ Brown et al . 1993 ; Dagan et al . 1993 ; Smadja et al . 1996 ] . In addition , an alternative approach using comparable or unrelated text corpora was presented by Rapp [ 1999 ] and Fung et al . [ 1998 ] .
On the other hand , many research works have been focused on the development of cross language retrieval models to improve retrieval performance . Some of them were based on probabilistic retrieval models [ Xu et al . 2001 ; Hiemstra and de Jong 1999 ;
Lavrenko et al . 2002 ] . For example , Lavrenko et al . developed a formal probabilistic model for integrating query expansion into the relevance estimation of documents . In addition , some other works were based on cross language latent semantic indexing ( CL
LSI ) , which uses the Singular Value Decomposition ( SVD ) to discover important associative relationships among source query terms and target documents without the need for query translation [ Dumais et al . 1996 , 1997 ; Furnas et al . 1988 ] .
Practical cross language Web search services have not lived up to expectations , since they suffer from a major bottleneck due to the fact that up to date bilingual lexicons containing the translations of popular query terms such as proper nouns are lacking
[ Kwok 2001 ; Hull and Grefenstette 1997 ] . Web query terms are often diverse and dynamic . Only a certain set of the translations of a query term can be extracted using corpora with limited domains . Different from previous works , Nie et al . [ 1999 ] developed an efficient method for extracting parallel text corpora from bilingual Web sites instantly , based on use of the Web ’s multilingual nature and a wide range of hypertext resources to collect bilingual corpora . Similar to utilizing parallel texts extracted from the Web ,
Resnik et al . [ 2001 ] proposed a backoff translation technique that combines evidence from dictionary based and corpus based approaches , and improves the coverage and accuracy of translation lexicons .
2.2 Transitive Translation via a Third Language
For CLIR , transitive translation via an extra language might be necessary and beneficial for query translation if the direct query translation is unreliable or even unavailable due to the lack of sufficient parallel ( comparable ) corpora or a bilingual dictionary . Borin [ 2000 ] tried to use various sources of information to improve the alignment of word translation and proposed the pivot alignment , which combines direct translation and indirect translation via a third language . The method increases the recall rate without lowering precision .
In general , using an intermediate language for transitive translation doubles the number of translations and thus increases the likelihood of translation errors due to incorrect identification of ambiguous words . Gollins and Sanderson [ 2001 ] proposed a feasible approach of translating in parallel across multiple intermediate languages and fusing the results . Such a technique eliminates errors and raises the effectiveness of retrieval . In addition , Simard [ 2000 ] developed an approach to exploiting the transitive properties of translations to improve quality of multilingual text alignment .
2.3 Text Mining
Text mining , also known as text data mining [ Hearst 1999 ] , concerns the discovery of knowledge in huge amounts of unstructured textual data . It is a relatively new research area in data mining in which most researchers have focused on knowledge discovery in structured databases [ Fayyad et al . 1996 ; Deogun et al . 1997 ] . Feldman and Dagan [ 1995 ] created the Knoweledge Discovery in Texts ( KDT ) system , the precursor to the text mining , to find patterns between concept distributions in textual data . A variety of related studies have focused on different subjects , such as automatic extraction of terms or phrases [ Feldman et al . 1997 ; Ahonen et al.1999 ] , the discovery of rules for the extraction of specific information patterns [ Soderland 1997 ] , and ontology construction
[ Fensel 2001 ] .
On the other hand , some recent works have proposed practical algorithms , such as
HITS [ Kleinberg 1998 ] and PageRank [ Brin and Page 1998 ] , for modeling Web topology or exploring authoritative or popular pages in Web search based on link structures and their related content information [ Chakrabarti et al . 1998 ] . Amitay and Paris [ 2001 ] also applied both hyperlink structures and the contexts of their associated anchor texts to automatically summarize Web pages and sites . Unlike the previous researches , we exploit
Web anchor texts and link structures as multilingual corpora to incrementally discover knowledge for extracting multilingual translations of query terms .
3 . TRANSLATION EXTRACTION
The proposed transitive translation approach is designed mainly to find exact translation equivalents of query terms via anchor text mining . The overall approach incorporates several techniques , including anchor text mining , the probabilistic inference model , the transitive translation model , and the competitive linking algorithm . In this section , the basic concepts behind the probabilistic inference model and the transitive translation model will be introduced .
3.1 Anchor Text Set
An anchor text is the descriptive part of an out link of a Web page to represent a brief description of the linked Web page . The anchor text set of a Web page ( or URL ) ui is defined as all of the anchor text of the links , ie , ui's in links , pointing to ui . In general , the anchor text set records ui's alternative concepts and textual expressions , such as titles and headings , which are cited by other Web pages . With different preferences , conventions and levels of language competence , the anchor text set can be composed of multilingual phrases , short texts , acronyms , or even ui's URL . For a query term appearing in an anchor text set , it is likely that its corresponding translations will also appear together . A collection of anchor text sets can be considered as composing a comparable corpus of translated texts , from the viewpoint of translation extraction .
Conventional statistical translation models perform estimation mostly based on a parallel corpus . These models have a fundamental problem in that they are not able to efficiently deal with the translation of semantically close or opposite terms in CLIR applications . That is because semantically close or opposite terms have a lower chance of occurring together with the source term in the same sentences ; as a result , their translations cannot be extracted through co occurrence with the source term in a parallel corpus . A collection of anchor text sets can be considered as being composed of a comparable corpus of translated texts . According to our observations , there is a higher chance of finding semantically close translations for a source word from anchor text sets containing it . The above drawback can be to some degree improved by using anchor text sets as the corpus if a proper translation model can be employed .
3.2 Probabilistic Inference
Different from conventional statistical translation models or rule induction used in data mining , our proposed probabilistic model uses the symmetric similarity estimation function P(s ↔ t ) to replace the conditional estimation function P(s → t ) and takes into account the significance of the authority of Web pages linked by other related pages .
To determine the most probable target translation t for source query term s , we have developed a probabilistic inference model [ Wong et al . 1995 ] . This model is used to estimate the probability value between a source query and all the translation candidates that co occur in the same anchor text sets . The estimation assumes that anchor texts linking to the same pages may contain similar terms with analogous concepts . Therefore , a candidate translation has a higher chance of being an effective translation if it is written in the target language and frequently co occurs with the source query term in the same anchor text sets . In addition , in the field of Web research , it has been proven that link structures can be used effectively to estimate the authority of Web pages [ Kleinberg 1998 ;
Chakrabarti et al . 1998 ] . Our model further assumes that the translation candidates in the anchor text sets of the pages with higher authority may be more reliable . The similarity estimation function based on the probabilistic inference model is defined below :
( sP
=↔ t
)
( sP ( sP
∩ ∪ t t
) )
= n ∑ ( sP = 1 i n ∑ = 1 i
( ( sP
∩∩ t u i
)
∩∪ t
) u i
)
=
∩
∪ n ∑ ( sP = 1 i n ∑ ( sP = 1 i
| ( ) uPut i i
)
| ( ) uPut i i
)
.
( 1 )
The above measure is adopted to estimate the degree of similarity between source term s and target translation t . The measure is estimated based on their co occurrence in the anchor text sets of the concerned Web pages U = {u1 , u2 , un} , in which ui is a page of concern and P(ui ) is the probability value used to measure the authority of page ui . By considering the link structures and concept space of Web pages , P(ui ) is estimated along with the probability of ui being linked , and its estimation is defined as follows : P(ui)= L(ui)/Σj=1,n L(uj ) , where L(uj ) indicates the number of in links of page uj . This estimation is simplified from the HITS algorithm [ Kleinberg 1998 ] .
In addition , we assume that s and t are independent given ui ; then , the joint probability P(s∩t|ui ) is equal to the product of P(s|ui ) and P(t|ui ) , and the similarity measure becomes
( sP
≈↔ ) t n ∑ |([ usP i = 1 i
)
|(
( uPutPusP i
|( )
) ] i i
.
( 2 )
) i
|(
|( ) n ∑ ( ) uPutPusP i = 1 i +
− i
|( utP i
)
)
The values of P(s|ui ) and P(t|ui ) are estimated by calculating the fractions of the numbers of ui ’s in links containing s and t over L(ui ) , respectively . Therefore , a candidate translation has a higher confidence value for being an effective translation if it frequently co occurs with the source term in the anchor text sets of the pages having higher authority .
In our previous work , we showed that the link structure and page authority information are useful for improving the translation accuracy [ Lu et al . 2002a ] . We found that text expressions associated with the links of pages with higher authority are usually more reliable and professional . This phenomenon is especially obvious in the case of the
Chinese Web , where bilingual pages are often provided by organizations with higher authority . In fact , using the probabilistic inference model , we found it easier to consider the characteristics of anchor texts and to integrate the model with other techniques to improve the translation accuracy . Also , as will be shown in Section 621 the model could be integrated with the probabilistic retrieval model to improve the performance of cross lingual retrieval , especially for queries with unknown query terms . For further information about the probabilistic inference model , readers may refer to our previous works [ Lu et al . 2001 , 2002a ] .
3.3 Direct Translation
For each source term , the probabilistic inference model extracts the most probable translation that maximizes the estimation . The estimation process based on the model was developed to extract term translations through the mining of real world anchor text sets .
The process contains three major computational modules : anchor text extraction , term extraction and term translation extraction . The anchor text extraction module was constructed to collect pages from the Web and build up a corpus of anchor text sets . The
Algorithm 1 : Direct_Translation ( s , U , Vt )
Input : source term s , Web pages of concern U , translation vocabulary set Vt . Output : target translation set R . 1 . Extract translation candidate set T .
11 Let ATs be the anchor text sets of the pages in U containing s . Use Vt as the translation vocabulary set to segment terms appearing in ATs and take them as translation candidates .
2 . For each translation candidate t in T , perform the following sub steps :
21 Extract the page set U{s}∪{t} that contains either s or t in its anchor text sets ( pages containing neither s nor t in their anchor text sets have no effect for the estimation in Step 22 )
22 Calculate Pdirect ( s , t ) based on Equation ( 2 ) and page set U{s}∪{t} .
3 . Select up to k most probable translations from T as the target translation set R and return R .
Fig 2 . Algorithm for the estimation of direct translation . coverage and corresponding domains of the collected Web pages U determine the reliability of the estimation process . In fact , the proposed approach can be extended to the extraction of domain specific term translations if the module focuses on collecting domain specific documents on the Web .
On the other hand , for each given source term s , the term extraction module extracts key terms as the translation candidate set T from the anchor text sets of the pages containing s , ie , ATs . The effectiveness of the adopted term extraction methods greatly affects performance in extracting correct translations . Three different methods have been tested : the PAT tree based , query set based and tagger based methods [ Lu et al . 2002a ] .
Among them , the query set based method has been strongly recommended because it can avoid some problems with term segmentation . The method uses a query log in the target language as the translation vocabulary set Vt to segment key terms in ATs . The precondition for using this method is that the coverage of the query set should be high . Last , the term translation extraction module extracts the translation that maximizes the similarity estimation . To reduce the computational cost , the similarity estimation between source term s and each translation candidate t is estimated based only on the page set
U{s}∪{t} that contains either s or t in ATs or ATt . To distinguish it from the translation process that uses an intermediate language , the above process is called direct translation , s
新力
( Traditional
Chinese )
Direct
Translation
Indirect
Translation t
索尼
( Simplified Chinese ) m m
Sony
( English ) s : source term t : target translation m : intermediate translation
Fig 3 . An abstract diagram showing the concepts of direct translation and indirect translation . and the adopted model will be called the direct translation model hereafter . Meanwhile , we use function Pdirect in Equation ( 3 ) for the estimation of the direct translation :
Pdirect
),( ts
↔=
( sP t
)
( 3 )
The direct translation process is designed to extract the top k most probable translations as the output . Its major operations are summarized in Algorithm 1 ( see Fig 2 ) .
3.4 Transitive Translation
As mentioned above , for those query terms whose corresponding translations either appear infrequently in the same anchor text sets or do not appear together , the estimation obtained using Equation ( 2 ) is basically unreliable . To increase the possibility of translation extraction , especially for source terms whose corresponding translations do not co occur , we add an indirect translation phase using an intermediate language . For example , as shown in Fig 3 , our idea is to obtain the corresponding target translation “ 索
尼 ” in simplified Chinese by translating the source term “ 新力 ” in traditional Chinese into an intermediate term “ Sony ” in English , and then trying to translate “ Sony ” into a target term “ 索尼 ” in simplified Chinese . For both the source query and the target translation , we assume that their translations in the intermediate language are the same and can be found .
The above assumption is actually not unrealistic . For example , it is possible to find the Chinese translation of the name of a Japanese movie star by submitting his/her
English name to a search engine and browsing the retrieved Chinese pages containing the
English name . Based on this assumption , we extend the probabilistic inference model and propose an indirect translation model as shown in the following formula :
P indirect
),( ts
=
≈
∑ m ∑ m
↔
( sP mm
,
↔
) mPt
(
)
( sP
×↔ mPm
(
)
×↔ t
) mP
(
) ,
( 4 ) where m is one of the top k most probable intermediate translations of s in the intermediate language , and P(m ) is the confidence value of m ’s accuracy , which can be estimated based on m ’s probability of occurring in the corpus . In addition , P(s ↔ m ) and P(m ↔ t ) are the probability values , which can be obtained by using the direct translation model and calculated using Equation ( 2 ) .
The transitive translation model combines both the direct and indirect translation models . By combining Equation ( 3 ) and ( 4 ) , the transitive translation model can be defined as follows :
P trans
),( ts
=
  
P direct P indirect
,( if ) , ts ,( ) , ts
P s,t direct otherwise ,
(
>
θ )
( 5 ) where θ is a predefined threshold value . The transitive translation model can be used to enhance the ability of the proposed approach to deal with the translation of a language pair when an adequate corpus is lacking . Under this circumstance , the direct translation process is normally not reliable enough . Via translation into an intermediate language , the possibility of translation extraction can be increased . However , the indirect translation process might unavoidably result in more errors in some cases . For a language pair with an adequate corpus , the importance of indirect translation in the estimation process can be reduced .
4 . ROBUST ESTIMATION USING THE COMPETITIVE LINKING ALGORITHM
4.1 Indirect Association Problem
As mentioned above , the estimation obtained using the proposed models is not reliable if the translation of the source term appears infrequently in the same anchor text sets . A so called indirect association problem might arise [ Melamed 2000 ] . An illustration in Fig 4 shows this problem . Assume that t is s ’s corresponding translation but appears infrequently with s . An indirect association error might arise when t1 , the translation of s ’s highly relevant term s1 , co occurs often with s . To reduce such translation errors and enhance the reliability of the estimation , a competitive linking ( CL ) algorithm which is s
思科 ( Cisco )
Cisco t s1
系統 ( system ) system t1
Fig 4 . An illustration showing the indirect association problem , in which the dashed arrows indicate possible indirect association errors . extended from Melamed ’s work is developed and integrated into the process of determining the most probable translation [ Melamed 2000 ] .
4.2 Concept of CL Algorithm
Let A be a one to one mapping between a set of source terms S and a set of possible target translations T , and let the mapping for a source term to be associated with a translation be called an assignment . The competitive linking algorithm determines the most probable translation pairs for the two term sets . The algorithm can be viewed as a heuristic search for the most likely assignment in the space of all possible assignments .
For the convenience of discussion , we use a bipartite graph to show the concept . The bipartite graph can be defined as G = ( S∪T , E ) , in which all the considered source terms and target translations are vertices ( the vertices on one side correspond to unique source terms , and the vertices on the other side to unique target terms ) , and the edges are weighted with the similarity values of the corresponding source terms and target translations . Let eij = <si , tj , wij> indicate the edge from the vertex of source term si to the vertex of target term tj and its weight wij . wij can be Pdirect(si , tj ) or Pindirect(si , tj ) , depending on the model employed .
Let A be the set of all possible assignments between S and T . The CL algorithm is a heuristic search that proceeds using an iterative process of assignment elimination . In the first search iteration , all the assignments that do not contain the most likely edges ( links ) are discarded . In the second iteration , all the assignments that do not contain the second most likely link are discarded , and so on until only one assignment remains . The algorithm greedily selects the most likely edges first , and then selects less likely edges only if they do not conflict with previous selections . The algorithm is based on the one to one assumption : each source term is translated into at most one term .
For the example shown in Fig 4 , s , s1 can be taken as source vertices , and t , t1 as target vertices . Based on the one to one assumption , the example conceptually constitutes two possible assignments ( graphs ) , ie , G1 = ( {s , s1}∪{t , t1} , {<s , t> , <s1 , t1>} ) , and G2 = ( {s , s1}∪{t , t1} , {<s , t1> , <s1 , t>} ) . Assume that <s1 , t1> is the most likely edge , ie , ws1t1 is the highest weight . In the first search iteration , assignment G2 is discarded immediately . Therefore , assignment G1 is the remaining one , and s ’s translation is , thus , determined as t . For the sake of efficiency in implementation , all of the possible graphs can be merged into one , ie , G3 = ( {s , s1}∪{t , t1} , {<s , t> , <s1 , t1> , <s , t1> , <s1 , t>} ) . The above search process is then modified and re interpreted as follows . In the first search iteration , the edge <s1 , t1> whose weight is the highest will be selected , and all other edges linking to either s1 or t1 ( ie , <s , t1> and <s1 , t> ) will be discarded . Therefore , the weights of the remaining edges will be re estimated and the second iteration performed . However , in our case , edge <s , t> is the only remaining edge after the first iteration , and no further iterations are necessary .
4.3 Problems of Using CL Algorithm
Before the above algorithm can be used in real applications , there are some problems which need to be further investigated . The CL algorithm is designed based on an approximation of the maximum a posteriori matching for the term pairs in S and T .
According to Melamed [ 2000 ] , the employed one one mapping assumption is not as restrictive as it may appear . As the experimental results presented in Section 5.4 will demonstrate , the CL algorithm is effective in reducing the number of indirect association errors and useful in dealing with the translation of language pairs when an adequate corpus is not available .
On the other hand , the computing time is another possible drawback . Let a bipartite graph G = ( S∪T , E ) with v = |S∪T| and e = |E| ; the lowest currently known upper bound on the computational complexity of this problem is O(ve+v2logv ) . The Web is live , and users’ query terms are dynamic and huge in number . Although this upper bound is polynomial , it is still too high for typical Web query sets . To reduce the computation cost , the number of vertices ( the number of considered source terms and translation candidates ) should be limited .
To extract the most likely translation of each given source term , it is not realistic to consider matching with all of the source terms and their possible translations in the corpus . We , therefore , develop a method to determine a proper set of candidate terms for
Algorithm 2 : Bipartite_Graph_Construction ( s , U , Vt )
Input : source query term s , Web pages of concern U , translation vocabulary set Vt . Output : bipartite graph G for s . 1 . Based on translation vocabulary set Vt , extract a set of s ’s possible translations T = {t1 , t2 , … , tn} from ATs , the anchor text sets of the pages in U containing s . 2 . For each ti in T , find a set of possible translations Sti which appear in both ATti and ATs . Let ST = St1∪St2∪ ∪Stn , and S = {s}∪ST .
3 . Construct a bipartite graph G = ( V1∪V2 , E ) , where V1 =S and V2 = T , and E contains the edges from every vertex in V1 to vertex in V2 .
Fig 5 . Algorithm for bipartite graph construction . system
Cisco t1 t2 s
思科 ( Cisco )
St1
St2
系統 ( system )
資訊 ( information )
網路 ( network )
電腦 ( computer )
Fig 6 . An illustration showing a bipartite graph generated by using Algorithm 2 . the estimation . Algorithm 2 shown in Fig 5 is a method designed for both direct and indirect translations , in which s ’s translation set T = {t1 , , tn} contains only the candidates extracted from ATs , ie , the anchor text sets of the pages in U containing s . In addition to source term s , the source term set contains additional source terms ST = St1∪ ∪Stn , which is the union of all translation sets of s ’s translation candidates that appear in Ts . These source terms are assumed to be likely to cause indirect associations and should be included when constructing a bipartite graph for further estimation . Following the previous example , Fig 6 shows an example graph which might be generated using
Algorithm 2 .
Algorithm 3 : Direct_Translation_with_CL ( s , U , Vt )
Input : source term s , Web pages of concern U , translation vocabulary set Vt . Output : target translation set R . 1 . Call Bipartite_Graph_Construction ( s , U , Vt ) to construct bipartite graph G =
( S∪T , E ) for source term s and its possible translations in Vt .
2 . For each edge eij in E , compute the translation probability Pdirect ( si , tj ) as its initial weight wij . The probability estimation is based on the anchor text sets of the pages in U containing at least one term in S∪T , rather than all of the collected pages .
3 . Sort all wij from highest to lowest . 4 . Let ei*j* be the edge with the highest weight . If si* = s , let R = R ∪{tj*} .
Return R if |R| = k .
5 .
If si* ≠ s , remove all edges linking to either vertex si* or vertex tj* . Re
6 . estimate wij for each remaining edge eij . The probability estimation is based on the original anchor text sets but excluding sets that contain either si* or tj* . If si* = s , remove all edges linking to vertex tj* . Re estimate wij for each remaining edge eij . The probability estimation is based on the original anchortext sets but excluding sets that contain tj* . 7 . Repeat beginning with Step 3 until | E | = 0 . 8 . Return R as the output .
Fig 7 . Algorithm for the estimation of direct translation using the CL algorithm .
4.4 Integration with the CL Algorithm
The CL algorithm can be implemented based on the bipartite graph constructed by
Algorithm 2 . Algorithm 3 shown in Fig 7 , which is an extension of Algorithm 1 , describes the operations for estimating direct translation using the CL algorithm . Note that the algorithm extracts up to the k most probable translations as the output .
In addition , Algorithm 4 shown in Fig 8 describes the operations for estimating indirect translation using the CL algorithm , which is an approximation considering the high computational cost that the CL algorithm might cause . The algorithm divides the estimation process into two stages . In the first stage , it extracts up to the k most probable intermediate translations . It constructs a bipartite graph containing the source term , the possible intermediate translations and their source translations . With these intermediate
Algorithm 4 : Indirect_Translation_with_CL ( s , U , Vt , Vm )
Input : source term s , Web pages of concern U , target translation vocabulary set Vt , and transitive translation vocabulary set Vm . Output : target translation set R . 1 . Call Direct_Translation_with_CL ( s , U , Vm ) to extract the most probable intermediate translation set M = {m*} for s .
2 . For each m* , Call Direct_Translation_with_CL ( m* , U , Vt ) to extract the most probable target translation set TR = {t**} .
3 . For each t** , calculate Pindirect ( s , t** ) based on Equation ( 4 ) and page set
U{s}∪{t**}∪{m*} .
4 . Select up to the k most probable target translations from all t** as the output set
R and return R .
Fig 8 . Algorithm for the estimation of indirect translation using the CL algorithm . translations , it extracts the most probable target translations in the second stage . For each intermediate translation , an additional bipartite graph needs to be constructed . The graph consists of the intermediate translation , its possible target translations and their translations in the intermediate language . It calls Algorithm 3 to extract a set of the most probable target translation candidates . For each target translation candidate generated by the intermediate translations , it uses the function Pindirect in Equation ( 4 ) to estimate the similarity value between the source term and the target translation candidate . The top k most probable target translations will be selected as the output . A drawback of the above estimation process is that the most probable target translations are determined without considering all the possible intermediate translations of the source term . This is , however , a tradeoff .
With the above three algorithms , estimation with the transitive translation model using the CL algorithm is straightforward . Algorithm 5 ( see Fig 9 ) shows the process .
5 . EXPERIMENTAL RESULTS
5.1 Analysis of Anchor Text Sets and Query Logs
In the initial experiments , we took traditional Chinese and simplified Chinese as the source and target language , respectively , and used English as the intermediate language .
We had collected 1,980,816 traditional Chinese Web pages in Taiwan . Among these pages , 109,416 pages whose anchor text sets contained both traditional Chinese and
Algorithm 5 : Transitive_Translation_with_CL ( s , U , Vt , Vm )
Input : source term s , Web pages of concern U , target translation vocabulary set Vt , and intermediate translation vocabulary set Vm . Output : target translation set R . 1 . Call Direct_Translation_with_CL ( s , U , Vt ) to obtain the most probable target translation set R1 .
2 . Select up to k most probable translations {t1*} from R1 , where Pdirect ( s , t* ) is larger than the threshold . Let R = {t1*} , and return R if |R| = k .
3 . Call Indirect_Translation_with_CL ( s , U , Vt , Vm ) to obtain up to the k |R| most probable target translations {t2*} . Let R = R ∪{t2*} and return R .
Fig 9 . Algorithm for the estimation of transitive translation using the CL algorithm .
English terms were taken as the anchor text set corpus . We had also collected 2,179,171 simplified Chinese Web pages in China and extracted 157,786 pages whose anchor text sets contained both simplified Chinese and English terms . In addition , after merging the two Web page collections into a larger one , we extracted only 4,516 pages whose anchor text sets contained both traditional and simplified Chinese terms . The three comparable corpora provided a potential resource of translation pairs for some Web queries . In order to realize the feasibility of translating query terms via transitive translation , we aimed to find out the corresponding simplified Chinese translations of traditional Chinese query terms using English as the intermediate language .
We also collected popular query terms with the logs from two real world Chinese search engines in Taiwan , ie , Dreamer and GAIS2 . The Dreamer log contained 228,566 unique query terms from a period of over 3 months in 1998 , and the GAIS log contained
114,182 unique query terms from a period of two weeks in 1999 . There were 9,709 most popular query terms whose frequencies were above 10 in both logs , and 1,230 of them were English terms . After filtering out the terms used locally in Taiwan , we obtained 513 terms , and 430 of which had Chinese translations that appeared together in the logs . For retrieving the desired pages , these terms are supposed to be useful in cross language search . We randomly selected 258 terms from them and took their corresponding Chinese translations from the logs , which were determined manually , as the source query set in the following experiments . Table I lists some examples of the test query terms , which
2 Both search engines are second tier portals in Taiwan , whose logs contain queries that are popular in Chinese communities , and whose URL ’s are as follows : http://wwwdreamercomtw/ and http://gaiscscuedutw/
Table I . Some examples of test queries .
Type
Number
Examples of test queries
Dic
96
OOV
162
銀行 ( bank ) 亞洲 ( Asia ) 愛滋病 ( AIDS ) 書店 ( bookstore ) 照相機 ( camera ) 電子商務 ( e commerce ) 地理資訊系統 ( GIS ) 雅虎 ( Yahoo ) 美國職籃 ( NBA ) 喬丹 ( Jordan ) 威而剛 ( viagra ) were divided into two types , where type Dic ( the terms existing in dictionary ) made up about 37 % ( 96/258 ) of the test queries , and type OOV ( out of vocabulary ; the terms not in the dictionary ) made up about 63 % ( 162/258 ) . The dictionary used for the experiments was complied with the CEDICT3 Chinese English electronic dictionary , which contains
23,948 word/phrase entries with the translations in traditional Chinese , simplified
Chinese and English .
To evaluate the performance of translation extraction , we used the average top n inclusion rate as a metric . For a set of test query terms , its top n inclusion rate was defined as the percentage of query terms whose effective translation(s ) could be found in the top n extracted translations . Normally , the determination of whether or not extracted translations are effective is based on whether the translations can be used to perform similar search requests in the target language , which needs to be judged manually . There is a major difference between query term translation in Web search and common term translation in machine translation . Query terms usually indicate certain information requests . Their translated terms should be effective for the same requests . In the experiments , three volunteers with library information service backgrounds helped prepare effective translations .
In our previous work [ Lu et . al . 2002a ] , we performed a number of experiments to determine the performance of the approach based on the direct translation model . We showed that the link structure and page authority information can be used to improve translation accuracy . Also , three different term extraction methods were compared , and it was found that the query set based method could achieve better performance than either the PAT tree or POS tagger based methods . Nevertheless , since we had not yet collected any query logs in simplified Chinese , in the following experiments , we adopted the PAT tree based keyword extraction method , which is an efficient statistics based approach that can automatically extract repeated text patterns from documents indexed with a PAT tree data structure [ Chien 1997 ] .
5.2 Performance of the Direct Translation Model
In order to determine the feasibility of the transitive translation model , we carried out experiments based on the direct translation models and three different anchor text set corpora in the first step . Table II shows the results of the obtained top 5 inclusion rates , where the terms “ TC , ” “ SC ” and “ ENG ” represent traditional Chinese , simplified
Chinese and English terms , respectively . The performance of translating TC into SC was worse than that of using the other two corpora since the size of the anchor text set corpus containing both TC and SC was relatively small in comparison with the others . This is why we combined direct translation with indirect translation via a third language .
However , the performance of direct translation from TC to SC was used as a reference for comparison with our proposed models in the following experiments .
5.3 Performance of the Indirect and Transitive Translation Models
To determine the improvement obtained using the transitive translation model , we conducted further experiments . As shown in Table III , the indirect and transitive translation models outperformed the direct translation model . As mentioned above , the size of the anchor text corpus that contained both TC and SC was small . The indirect translation model was , therefore , helpful for finding corresponding translations for some terms with low frequency values in the corpora . For example , the traditional Chinese term “ 西門子 , ” we found its corresponding translation equivalent “ 西门子 ” in simplified
Chinese via the intermediate translation “ Siemens , ” which could not be found using only direct translation .
The use of multiple intermediate translations was found to improve the translation accuracy of both the indirect and transitive translation models . The top 1 inclusion rates ranged from 44.2 % when the indirect translation model was used with only one intermediate translation ( k=1 ) to 50.0 % when the transitive translation model was used
3 http://wwwmandarintoolscom/cedicthtml
Table II . Top n inclusion rates obtained with the direct translation model and the three specific language pairs corpora .
Type
TC => SC TC => ENG ENG => SC
Top2
Top4
Top3
Top1 Top5 35.7 % 43.0 % 46.9 % 49.6 % 51.2 % 68.6 % 82.2 % 85.7 % 88.0 % 88.8 % 45.3 % 55.8 % 59.3 % 61.6 % 64.0 %
Table III . Top n inclusion rates obtained with different models for translating traditional Chinese into simplified Chinese .
Model
Direct Indirect ( k=1 ) Indirect ( k=3 ) Transitive ( k=1 ) Transitive ( k=3 )
Top4
Top3
Top2
Top1 Top5 35.7 % 43.0 % 46.9 % 49.6 % 51.2 % 44.2 % 55.1 % 58.0 % 59.7 % 60.5 % 46.5 % 57.0 % 60.4 % 62.0 % 62.8 % 49.2 % 58.1 % 60.9 % 61.6 % 62.0 % 50.0 % 60.1 % 62.8 % 63.9 % 64.3 %
Table IV . Top n inclusion rates obtained with the transitive translation model and the approach integrating the CL algorithm .
Model
Direct + CL Indirect + CL ( k=1 ) Indirect + CL ( k=3 ) Transitive + CL ( k=1 ) Transitive + CL ( k=3 )
Top4
Top2
Top3
Top5 Top1 38.0 % 43.8 % 47.3 % 49.6 % 51.2 % 48.0 % 57.0 % 59.4 % 60.1 % 60.9 % 48.7 % 58.1 % 60.8 % 62.0 % 63.1 % 52.7 % 60.1 % 62.5 % 63.1 % 63.9 % 52.7 % 61.6 % 63.9 % 64.3 % 65.1 % with at most three intermediate translation candidates ( k=3 ) . Table V shows some examples of the translations extracted using the transitive translation model .
5.4 Performance of the Models Using the CL Algorithm
The competitive linking algorithm was integrated into the transitive translation model to deal with the indirect association problem to increase the accuracy rate . An additional experiment was also conducted to compare the models without use of the CL algorithm .
Table IV shows that the top 1 inclusion rate achieved using the CL algorithm was slightly better at 527 % Detailed analysis of the procedure for processing test queries shows that the CL algorithm is actually helpful in removing some indirect association errors based on correct translation pairs with reliably high co occurrence frequency . For example , as shown in Table V , the simplified Chinese “ 蓝鸟 ” could reach the first rank from the third rank of the translation candidates after the CL algorithm was used since the correct high frequency pairs ( focus , 视点 ) and ( movie , 电影 ) could be chosen first , then
Table V . Two examples of extracted target translations by the three different models . ( The asterisk indicates correct translations . )
Source terms ( Traditional
Chinese )
藍鳥 ( Bluebird )
迪士尼 ( Disney )
Top 5 extracted target translations ( Simplified Chinese )
Direct
Transitive
Transitive with CL
Not available
乐园(amusement park ) 迪士尼(Disney)* 狮子王(Lion King ) 狄斯尼(Disney)* 世界(world )
视点(focus ) 电影(movie ) 蓝鸟(Bluebird)* 试点(test point ) 快车(express ) 乐园(amusement park ) 迪士尼(Disney)* 狮子王(Lion King ) 狄斯尼(Disney)* 世界(world )
蓝鸟(Bluebird)* 视点(focus ) 电影(movie ) 试点(test point ) 快车(express ) 迪士尼(Disney)* 乐园(amusement park ) 狄斯尼(Disney)* 世界(world ) 动画(anime ) the error pairs of indirect association ( Bluebird , 视点 ) and ( Bluebird , 电影 ) could be removed , and finally the correct translation pair ( Bluebird , 蓝鸟 ) could be found as the best pair . As a result , for the traditional Chinese term “ 藍 鳥 , ” its corresponding translation “ 蓝 鸟 ” in simplified Chinese could be obtained using the intermediate translation “ Bluebird . ”
5.5 Discussion
To realize the abilities of transitive translation model , we further took traditional Chinese and Japanese as the source and target language , respectively , and used English as the intermediate language . We had also collected 801,091 Japanese Web pages and extracted
183,582 pages whose anchor text sets contained both Japanese and English terms were taken as the Japanese English anchor text set corpus . In addition , after merging both collections of 801,091 Japanese pages and 1,980,816 traditional Chinese pages ( see
Subsection 6.1 ) , we extracted only 1,371 pages whose anchor text sets contained both traditional Chinese and Japanese terms as the Chinese Japanese anchor text set corpus .
We continued to use the same 258 traditional Chinese query terms as the test set and the
109,416 Chinese English anchor text set corpus to make the following experiments as shown in Table VI . Considering the shortage of a sufficiently large Chinese Japanese anchor text corpus on the Web , the performance using both the indirect and transitive models actually surpassed our expectations . Some of multilingual translations of the test
Table VI . Top n inclusion rates obtained with different models for translating traditional Chinese queries into Japanese .
Model
Direct Indirect Transitive
Top2
Top3
Top4
Top1 Top5 10.5 % 12.8 % 14.3 % 15.1 % 15.1 % 40.2 % 49.4 % 56.6 % 58.6 % 59.6 % 42.9 % 51.4 % 58.6 % 61.3 % 61.9 %
Table VII . Selected source query terms in traditional Chinese and their translations in English , simplified Chinese and Japanese respectively , which were extracted by our transitive translation model .
Source terms
( Traditional Chinese )
English
新力 耐吉 史丹佛 雪梨 網際網路 網路 首頁 電腦 資料庫 資訊
Sony Nike Stanford Sydney internet network homepage computer database information
索尼 耐克 斯坦福 悉尼 互联网 网络 主页 计算机 数据库 信息
Extracted target translations
Simplified Chinese
Japanese
ソニー ナイキ スタンフォード シドニー インターネット ネットワーク ホームページ コンピューター データベース インフォメーション queries , including Japanese , extracted by using our transitive translation model are shown in Table VII .
It is important to understand what kinds of queries are suitable when the proposed approach is used to find translations . In fact , the correct translations of a source term are hard to be found when their frequencies are low in the anchor text sets . This implies that the correct translations of popular terms might more easily appear in the anchor text sets and be extracted . However , many proper names , such as company names and personal names , have bilingual translations on the Web . If there are no other noisy translations with higher frequencies in the anchor text sets containing the terms , then their correct translations can be also extracted even though these are not popular terms employed by typical users . In our additional test of the top 19,124 terms , which occupied 80 % of the query requests in the Dreamer log , it was found about one third of the test queries could obtain effective target translations in the top 10 candidates .
On the other hand , it will also be important to determine the performance of the proposed approach when the corpus size changes . A large anchor text corpus can improve the coverage rates of translation candidates , but it might result in more noises as well . This problem will be further investigated in our future research .
6 . CLIR APPLICATION
In this section , we will investigate the performance achieved when the proposed transitive translation approach is applied to CLIR . We conducted experiments with the
NTCIR 2 English Chinese task of retrieving Chinese documents using English queries .
The test collection contained 132,173 traditional Chinese news documents ( 200MB ) and
50 English query topics [ Chen and Chen 2001 ] . There were four types of tests designed based on different combinations of descriptive sections of query topics , including “ Long
Query ” ( all the sections in a topic were used ) , “ Short Query ” ( titles , queries and concepts ) , “ Very Short Query ” ( titles and concepts ) and “ Title Query ” ( title sections only ) . Our experiments focused on testing the title queries because the average length of the title queries was 3.8 English words ( after removing stop words ) , which is close to the length of real Web queries . Previous analysis revealed that the average length of Web queries was about 2.3 words [ Silverstein 1998 ] . Table VIII lists several examples of test title queries .
In previous research [ Kwok 2001 ] , the obtained retrieval results for “ title ” only queries were not good enough , reaching only about 55 % of the monolingual MAP ( mean average precision ) value . According to Kwok , the results demonstrated that users will be disappointed if they use short queries for CLIR . We were interested in finding out whether the proposed approach could help with the retrieval of such short queries , including the extraction of translations of unknown queries , and improve retrieval performance .
6.1 Translation Extraction
There were a total of 178 unique query terms in the 50 test English title queries , and 22 of them were not included in the LDC4 English to Chinese lexicon with about 120K entries .
The 178 English query terms were tested by using the proposed approach to extract their traditional Chinese translations . The approach was based on Algorithm 5 ( k=1 ) . We used simplified Chinese as the intermediate language , and the three anchor text corpora mentioned in Section 5.1 as the test corpora . Table IX shows the achieved translation
4 The LDC English to Chinese lexicon ( http://wwwldcupennedu/Projects/Chinese ) was adopted since it was also employed in related works [ Kwok 2001 ] .
Table VIII . Examples of title queries in NTCIR 2 .
English title query
Kosovar refugees Michael Jordan's retirement Disneyland Cutting down the timber of Chinese cypress in Chilan Black faced Spoonbill in Taiwan El Nino and infectious diseases Side effects of Viagra Chunghwa NO . 1 Satellite ( ROCSAT 1 ) CIH computer virus Cloud Gate Dance Theatre of Taiwan Ma Yo yo cello recital Jin Yong kung fu novels
Q06 Q12 Q23 Q28 Q29 Q30 Q34 Q38 Q43 Q45 Q46 Q47
Chinese title query 科索沃難民潮 麥可喬登退休 迪士尼樂園 棲蘭檜木砍伐 台灣黑面琵鷺 聖嬰現象與傳染病 威而鋼之副作用 中華衛星一號 ＣＩＨ電腦病毒 雲門舞集 馬友友演奏會 金庸武俠小說
Table IX . Top n inclusion rates obtained with the proposed approach for extracting the traditional Chinese translations of the 178 unique English title query terms .
Type
Number Top1
Terms existing in LDC Terms not included in LDC Total
156 22 178
Top4
Top3
Top2
Top5 56.4 % 62.8 % 66.7 % 67.9 % 68.6 % 63.6 % 68.1 % 72.7 % 77.3 % 77.3 % 57.3 % 63.5 % 67.4 % 69.1 % 69.7 % accuracy . The proposed approach was found to be effective in extracting translations of the test queries , especially the unknown query terms . The obtained inclusion rates for the unknown query terms were even higher than those for the existing query terms . However , the results also revealed that the proposed approach might not be reliable enough when used to extract translations of common terms .
6.2 Retrieval Performance
Both the probabilistic retrieval model [ Lavrenko et al . 2002 ; Xu et al . 2001 ] and CL LSI model [ Dumais et al . 1996 , 1997 ; Furnas et al . 1988 ] are major approaches to CLIR . We tried to investigate whether the proposed transitive translation approach could be effectively integrated with these models and applied to CLIR .
621 The Probabilistic Retrieval Model . We first combined the proposed approach with the probabilistic retrieval model . Referring to Xu et al . ’s work [ Xu et al . 2001 ;
Hiemstra and de Jong 1999 ] , the following model was adopted in our experiment :
DQP
(
|
=
)
DeP
(
|
∏ ∈ Qe
=
)
∏ ∈ Qe
λ )( eP
[
λ ∑−+ 1( ) c
DcpceP
(
(
|
|
)
, ] )
( 6 ) where Q is a query , D is a document , e is a composed English query term of Q , c is a target translation of e in traditional Chinese and λ represents a smoothing parameter . In addition , P(e ) is the background probability of e , which can be estimated based on e ’s occurrence in the anchor text set corpus . P(c|D ) is the probability of c appearing in document D . P(e|c ) is the translation probability of e given c , which was estimated using three different estimation methods listed below :
( cid:121 ) The transitive translation model : we used Equation ( 5 ) to estimate the translation probability , ie , P(e|c ) = Ptrans(e , c ) .
( cid:121 ) The dictionary based method : we used the LDC lexicon to look up the translations of e . For each translation candidate c , its translation probability P(e|c ) is defined as
P(e|c ) = Pdic(e|c ) = 1/ne , where ne is the number of possible translations of c . P(e|c ) will become zero if ne is 0 .
( cid:121 ) The combined method : this approach was designed based on a linear combination of the above methods , ie , P(e|c ) = [ Ptrans(e , c)+ Pdic(e|c)]/2 .
We used mean average precision ( MAP ) values to evaluate the retrieval performance .
Table X shows the obtained results . The transitive translation approach performed slightly better than the dictionary based approach , but the combined approach achieved the best performance . However , the achieved MAP values still can be improved . In
Kwok ’s work , the best MAP value obtained was 0.316 [ Kwok 2001 ] . In fact , our experiment was conducted to check the possibility of combining the probabilistic retrieval model with the proposed approach for CLIR applications . To realize the performance of the proposed approach clearly , we did not employ advanced techniques as reported in Kwok ’s work to deal with the difficult retrieval task . Although the overall retrieval performance was not obviously improved , the proposed approach was found to benefit some queries through the correct translations of unknown query terms ; eg , the
MAP value of the query “ Ma Yo yo cello recital ” ( Q46 ) increased from 0.205 to 0.446 due to the correct translation ” 馬友友演奏會 ” .
622 The CL LSI based Model . As described in Section 2.1 , the CL LSI model can automatically construct a multilingual semantic space using latent semantic indexing ( LSI ) from a collection of multilingual documents . The following formula was adopted to rank documents related to queries [ Furnas et al . 1988 ; Yang et al . 1997 ] :
M
=  
 A Σ= B  DQSim
=
)
(
, t t VUVU kk k
Σ
≈
( 7 ) cos(
DUQU
,
)
( 8 ) t k t k
Table X . The MAP values obtained by applying three different translation probability estimation methods to the NTCIR 2 English Chinese retrieval task .
Method
Transitive translation model Dictionary lookup method Combined method
Mean average precision
0.155 0.143 0.235
Table XI . The MAP values obtained using three different CL LSI based methods for the NTCIR 2 English Chinese retrieval task .
Method
Mean average precision
CL LSI using the anchor text set corpus CL LSI using the pseudo parallel corpus CL LSI using the pseudo parallel corpus plus the augmented lexicon
0.090 0.192 0.219
M is an input bilingual term document matrix constituted by A and B , where A is a term document matrix for the training documents in the source language , and B is a termdocument matrix for the training documents in the target language . In addition , ΣK , UK and VK are the matrices computed using singular value decomposition of M .
We used the program las2 in SVDPACKD [ Berry et al . 1993 ] to perform singular value decomposition [ Mori et al . 2001 ] and obtained a 400 dimension CL LSI space .
Actually , it was not straightforward how the CL LSI model could be integrated into the proposed transitive translation approach . There were two ways to proceed : ( 1 ) using only anchor text sets as the training corpus to construct the CL LSI model , and ( 2 ) augmenting the translation lexicon using the proposed transitive translation approach . To evaluate them , three CL LSI based methods were , therefore , developed :
( cid:121 ) The first method used the anchor text sets as the corpus : Conventional CL LSI models are normally trained via parallel texts , but the anchor text set corpus was a comparable corpus . It was necessary to determine whether it was appropriate for constructing CL LSI models .
( cid:121 ) The second method used pseudo parallel texts as the corpus : To compare this method with the previous method , we randomly selected 33,043 ( about 25 % ) documents from the NTCIR 2 Chinese collection and created a pseudo parallel corpus by translating these documents into English .
( cid:121 ) The third method used the pseudo parallel corpus plus an augmented lexicon : In addition to using the pseudo parallel corpus , this method also employed an augmented lexicon , which consisted of the top 5 translations of unknown query terms obtained using the proposed transitive translation approach .
The first two methods employed the LDC lexicon as the word list to segment the
Chinese documents into words and generate the term document matrix in the target language . The third method employed both the LDC lexicon and the augmented lexicon as the word list . Table XI shows the obtained retrieval performance . The obtained MAP values were not good enough . It is obvious that the anchor text set corpus was not suitable for training CL LSI models due to its non parallel text property . But the proposed transitive translation approach might be useful for performing text segmentation and augmenting the translation lexicon , which is useful for Oriental languages . However , the above experiments revealed that the proposed approach is more effective in combination with the probabilistic retrieval model to improve the retrieval performance .
7 . AN APPLICATION : TRANSLATION SUGGESTION FOR CROSSLANGUAGE WEB SEARCH
As mentioned above , the need among real users for cross language Web search is increasing . We have developed a cross language Web search ( CLWS ) system called
LiveTrans5 based on the proposed approach . The LiveTrans system is a prototype of a meta search engine that provides English Chinese query translations for the retrieval of both Web pages and images in the greater China area . For example , as shown in Fig 10 , for the user query “ national palace museum , ” three effective Chinese translations which were not included in general purpose bilingual lexicons could be automatically extracted , ie , “ 國立故宮博物院 ” ( National Palace Museum ) “ 故宫 ” ( an abbreviation of National
Palace Museum ) and “ 故宮博物院 ” ( Palace Museum ) .
Since real Web queries are often short , it was not easy to adopt conventional cross language retrieval models for use in the system . The system , therefore , combines the proposed approach with dictionary lookup and produces translation suggestions in response to input queries . For each translation t of source query s , the system assigns a weight , W(t ) , and only a certain number of the translations with higher weights are sent to the backend search engines for search . The weighting value is obtained by using the weighted sum of the inverse values of the ranks obtained using anchor text mining and dictionary lookup , respectively . The function W(t ) is defined below :
5 http://livetransiissinicaedutw/lthtml
Fig 10 . An example showing the search results retrieved by the LiveTrans system , where the given query was “ national palace museum ” and its translations extracted were “ 國立故宮博物院 ” ( National Palace Museum ) , “ 故宮 ” ( an abbreviation of National Palace Museum ) , “ 故宮博物院 ” ( Palace Museum ) , etc .
)( tW
=
−
α )(
1(
− + 1
α (
AR t
)
DR t
)
−
1 where 0 ≤ α ≤ 1 .
,
( 9 )
ARt is basically the rank of t in the set of all possible translations of s that are extracted through the mining of the anchor text sets containing s . The rank is obtained by sorting the similarity values of the translations with s . The estimation of the values is obtained using Algorithm 5 ( k=1 ) as described in Section 44 ARt is the default value if t cannot be found using the proposed approach .
On the other hand , DRt is the rank of t in the set of all possible translations of s that are extracted through dictionary lookup . The rank is obtained by sorting the weights of these translations with s . DRt will be the default value if t cannot be found using dictionary lookup . Since the used translation dictionary has no predefined rank for each of the translations , the method used to determine the ranks of the translations is based on their approximate frequencies on the Web .
A preliminary experiment , as shown in Table XII , was also conducted to compare the performance of anchor text mining , dictionary lookup and the combined approach in translating traditional Chinese into simplified Chinese , respectively . The dictionary
Table XII . Top n inclusion rates obtained with different approaches .
Top1 Top2 Top3 Top4 Top5 Method 12.4 % 20.2 % 23.3 % 28.7 % 30.2 % Dictionary lookup Anchor text mining 49.2 % 58.1 % 60.9 % 61.6 % 62.0 % Anchor text mining plus CL 52.7 % 60.1 % 62.5 % 63.1 % 63.9 % Combined approach 55.8 % 60.8 % 64.0 % 65.9 % 67.8 % Combined plus CL approach 59.7 % 63.2 % 66.0 % 68.2 % 70.1 % mentioned in Section 5.1 was used . By examining the top 1 translations for the 258 test queries introduced in Section 5.1 , it was found that the inclusion rates ranged from 12.4 % for dictionary lookup to 59.7 % for the combined approach plus the use of the CL algorithm . The achieved performance shows that anchor text mining approach is really more suitable for practical Web search than dictionary lookup . Of course , combining these techniques could be the best choice .
8 . CONCLUSION
In this paper , we have proposed a transitive translation approach to extracting multilingual translations of Web queries through the mining of Web anchor texts and link structures . The translation equivalents of a query term can be extracted via its translations in an intermediate language . To reduce interference due to translation errors , the approach further integrates a competitive linking algorithm into the process of determining the most probable translation . This approach is particularly useful when the considered language pair lacks a sufficient number of anchor texts .
Preliminary experimental results show the feasibility of the proposed approach for term translation extraction . To determine the performance of the proposed approach when applied to CLIR , some experiments were conducted on the NCTIR 2 English Chinese IR task using both CL LSI and the probabilistic retrieval model . The proposed translation extraction approach was found to be effective in extracting translations of unknown queries , and it was easy to combine with the probabilistic retrieval model to improve the retrieval performance . In addition , we found that it could augment the translation lexicon and aid construction of a CL LSI model for Oriental languages . Furthermore , with our novel combination of the anchor text mining technique and bilingual dictionary lookup , the prototype CLWS system has been shown to be able to generate effective translation suggestions for popular queries . However , there are still some problems that need to be further investigated ; for example , the performance of the proposed approach when the corpus size changes needs to be studied . In addition , there are large amounts of multilingual information embedded in other Web resources , such as bilingual and multilingual Web pages , search results from search engines , etc . Finding ways to exploit these resources is one of our future research directions .
ACKNOWLEDGMENTS
This research was partially supported by a research grant under contract NSC91 2219 E
001 010 from the National Science Council , Republic of China . The authors would like to thank Prof . Mark Sanderson and the anonymous reviewers for their valuable comments and suggestions . Many thanks are given to Mr . Jin Shea Kuo , Shui Lung Chuang , Shih
Jui Lin , Jei Wen Teng and Chien Chung Huang for their very helpful discussions and supports in preparing the experiments .
REFERENCES
Ahonen , H . , Heinonen , O . , Klemettinen , M . , Verkamo , A . 1999 . Finding Co occurring Text Phrases by Combining Sequence and Frequent Set Discovery . In Proceedings of IJCAI’99 Workshop on Text Mining : Foundations , Techniques and Applications , 1 9 .
Amitay , E . , Paris , C . 2001 . Automatically Summarising Web Sites Is There A Way Around It ? In Proceedings of ACM 9th International Conference on Information and Knowledge Management , 173 179 .
Ballesteros , L . and Croft , W . B . 1998 . Resolving Ambiguity for Cross Language Retrieval . In Proceedings of
ACM SIGIR ’98 , 64 71 .
Berry , M . , Do , T . , O’Brien , G . , Krishna , Varadhan , S . 1993 . SVDPACKC ( Version 1.0 ) User ’s Guide ,
Computer Science Department , University Tennessee .
Borin , L . 2000 . You’ll Take the High Road and I’ll Take the Low Road : Using a Third Language to Improve
Bilingual Word Alignment . In Proceedings of the 18th COLING , 97 103 .
Brin , S . and Page , L . 1998 . The Anatomy of a Large Scale Hypertextual Web Search Engine . In Proceedings of the 7th International World Wide Web Conference , 107 117 .
Brown , P . , Pietra , S . A . D . , Pietra , V . D . J . , Mercer , R . L . 1993 . The Mathematics of Machine Translation .
Computational Linguistics , 19 , 2 , 263 312 .
Chakrabarti , S . , Dom , B . , Gibson , D . , Kleinberg , J . , Raghavan , P . , Rajagopalan , S . 1998 . Automatic Resource List Compilation by Analysing Hyperlink Structure and Associated Text . In Proceedings of the 7th World Wide Web Conference/Computer Networks and ISDN Systems , 30 , 65 74 .
Chen , K . H . and Chen , H . H . 2001 . The Chinese Text Retrieval Tasks of NTCIR Workshop 2 , In Proceedings of the Second NTCIR Workshop Meeting on Evaluation of Chinese & Japanese Text Retrieval and Text Summarization .
Chien , L . F . 1997 . PAT Tree Based Keyword Extraction for Chinese Information Retrieval . In Proceedings of
ACM SIGIR ’97 , 50 59 .
Dagan , I . , Church , K . W . , Gale , W . A 1993 . Robust Bilingual Word Alignment for Machine Aided Translation .
In Proceedings of the Workshop on Very Large Corpora , 1 8 .
Deogun , J . S . , Raghavan V . V . , Server , H . 1997 . Data Mining : Research Trends , Challenges , and Applications .
In Rough Sets and Data Mining : Analysis of Imprecise Data . Kluwer Academic Publishers , 9 45 .
Dumais , S . T . , Landauer , T . K . , Littman , M . L . 1996 . Automatic Cross Linguistic Information Retrieval Using Latent Semantic Indexing . In Proceedings of ACM SIGIR’96 Workshop on Cross Linguistic Information Retrieval , 16 24 .
Dumais , S . T . , Letsche , A . , Littman , M . L . , Landauer , T . K . 1997 . Automatic Cross Linguistic Retrieval Using Latent Semantic Indexing . In AAAI Spring Symposium on Cross Language Text and Speech Retrieval , 1521 .
Fayyad , U . M . , Piatetsky Shapiro , G . , Smyth , P . , and Uthurusamy , R . 1996 . Advances in Knowledge Discovery and Data Mining . AAAI Press .
Feldman , R . and Dagan , I . 1995 . KDT Knowledge Discovery in Texts . In Proceedings of the 1st International
Conference on Knowledge Discovery and Data Mining , 112 117 .
Feldman , R . , Aumann , Y . , Amir , A . , Kloesgen , W . , and Zilberstien , A . 1997 . Maximal Association Rules : a New Tool for Mining for Keyword co occurrences in Document Collections . In Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining , 167 170 .
Fensel , D . 2001 . Ontologies : Silver Bullet for Knowledge Management and Electronic Commerce . Springer
Verlag .
Fung , P . and Yee , L . Y . 1998 . An IR Approach for Translating New Words from Nonparallel , Comparable Texts . In Proceedings of the 36th Annual Conference of the Association for Computational Linguistics , 414 420 .
Furnas , G . W . , Deerwester , S . , Dumais , S . T . , Landauer , T . K . , Harshman , R . A . , Lochbaum , K . E . 1988 . Information Retrieval Using a Singular Value Decomposition model of Latent Semantic structure . In Proceedings of ACM SIGIR’88,465 480
Gollins , T . , Sanderson , M . 2001 . Improving Cross Language Information with Triangulated Translation . In
Proceedings of ACM SIGIR200 , 90 95 .
Hearst , M . 1999 . Untangling Text Data Mining . In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics , 3 10 .
Hiemstra , D . and de Jong , F . 1999 . Disambiguation Strategies for Cross language Information Retrieval . In Proceedings of the Third European Conference on Research and Advanced Technology for Digital Libraries , 274 293 .
Hull , D . A . and Grefenstette , G . 1996 . Querying across Languages : A Dictionary based Approach to
Multilingual Information Retrieval . In Proceedings of the ACM SIGIR’96 , 49 57 .
Kleinberg , J . 1998 . Authoritative Sources in a Hyperlinked Environment . In Proceedings of the 9th ACM SIAM
Symposium on Discrete Algorithms , 668 677 .
Knight , K . 1997 . Automating Knowledge Acquisition for Machine Translation , AI Magazine,18(4 ) . Kwok , K . L . 2001 . NTCIR 2 Chinese , Cross Language Retrieval Experiments Using PIRCS . In Proceedings of the Second NTCIR Workshop Meeting on Evaluation of Chinese & Japanese Text Retrieval and Text Summarization .
Lu , W . H . , Chien , L . F . , Lee , H . J . 2001 . Anchor Text Mining for Translation of Web Queries . In Proceedings of the 2001 IEEE International Conference on Data Mining , 401 408 .
Lu , W . H . , Chien , L . F . , Lee , H . J . 2002a . Translation of Web Queries using Anchor Text Mining . ACM
Transactions on Asian Language Information Processing , 159 172 .
Lu , W . H . , Chien , L . F . , Lee , H . J . 2002b . A Transitive Model for Extracting Translation Equivalents of Web Queries through Anchor Text Mining . In Proceedings of the 19th International Conference on Computational Linguistics ( COLING2002 ) , 584 590 .
Lavrenko , V . , Choquette , M . , Croft , W . B . 2002 . Cross lingual Relevance Model . In Proceedings of ACM
SIGIR 2002 , 175 182 .
Melamed , I . D . 2000 . Models of Translational Equivalence among Words . Computational Linguistics , 26 , 2 ,
221 249 .
Mori , T . , Kokubu , T . , Tanaka , T . 2001 . Cross Lingual Information Retrieval based on LSI with Multiple Word Spaces . In Proceedings of the Second NTCIR Workshop Meeting on Evaluation of Chinese & Japanese Text Retrieval and Text Summarization .
Nie , J . Y . , Isabelle , P . , Simard , M . , and Durand , R . 1999 . Cross language Information Retrieval Based on Parallel Texts and Automatic Mining of Parallel Texts from the Web . In Proceedings of ACM SIGIR’99 , 74 81 .
Oard , D . and Diekema , A . 1998 . Cross Language Information Retrieval . Annual Review of Information Science and Technology , 33 , 223 256 .
Rapp , R . 1999 . Automatic Identification of Word Translations from Unrelated English and German Corpora . In
Proceedings of the 37th Annual Conference of the Association for Computational Linguistics , 519 526 .
Resnik , P . , Oard , D . , Levow , G . 2001 . Improved Cross Language Retrieval using Backoff Translation . In
Proceedings of First International Conference on Human Language Technology Research .
Silverman , B . G . , Bachann , M . , Akharas , K . 2001 . Do What I Mean : Online Shopping with a Natural Language
Search Agent . IEEE Intelligent Systems , Jul/Aug , 2001 , 48 53 .
Silverstein , C . , Henzinger , M . , Marais , J . , Moricz , M . 1998 . Analysis of a Very Large AltaVista Query Log .
Technical Report 1998 014 , Digital Systems Research Center .
Simard , M . 2000 . Multilingual Text Alignment . In Parallel Text Processing , J . Veronis , Eds . Kluwer Academic
Publishers , Printed in the Netherlands , 49 67 .
Smadja , F . , McKeown , K . , Hatzivassiloglou , V . 1996 . Translating Collocations for Bilingual Lexicons : A
Statistical Approach . Computational Linguistics , 22 , 1 , 1 38 .
Soderland , S . 1997 . Learning to Extract Text based Information from the World Wide Web . In Proceedings of the 3rd International Conference on Knowledge Discovery and Data Mining , 251 254 .
Wong , S . K . M . , Yao Y . Y . 1995 . On Modeling Information Retrieval with Probabilistic Inference . ACM
Transactions on Information Systems , 13 , 38 68 .
Xu , J . , Weischedel , R . , Nguyen , C . 2001 Evaluating a Probabilistic Model for Cross lingual Information
Retrieval . In Proceedings of ACM SIGIR 2001 , 105 110 .
Yang , Y . , Carbonell , J . G . , Brown , R . D . , Frederking , R . E . 1997 . Translingual Information Retrieval : Learning from Bilingual Corpora . Artifical Intelligence Journal , 103 , 323 345 .
Received August 2002 ; revised April 2003 ; accepted August 2003 .
