Submitted to the Seventeenth International Joint Conference on Artificial Intelligence , August 4th 10th , 2001 , Seattle , Washington . University of Pittsburgh Department of Computer Science Technical Report ISL 01 02 . Closing the Loop : an Agenda and Justification Based Framework for Selecting the
Next Discovery Task to Perform
Gary R . Livingston
202 Mineral Industries Building
University of Pittsburgh Pittsburgh , PA 15260 gary@cspittedu
John M . Rosenberg
312 Clapp Hall
University of Pittsburgh Pittsburgh , PA 15260 jmr@jmr3xtalpittedu
Bruce G . Buchanan
206 Mineral Industries Building
University of Pittsburgh Pittsburgh , PA 15260 buchanan@cspittedu
Content areas : machine learning , autonomous agents , data mining , AI architectures
Abstract
We propose and evaluate an agenda and justificationbased architecture for discovery systems that contains a mechanism for selecting the next task to perform . This framework has many desirable properties : ( 1 ) its use of heuristics to perform and propose tasks facilitates the use of general discovery strategies that are able to use a variety of background knowledge , ( 2 ) through the use of justifications its mechanism for selecting the next task to perform is able to reason about tasks being considered , and ( 3 ) its mechanism for selecting the next task to perform also considers the users interests , allowing a discovery program to tailor its behavior toward them . the appropriateness of the
We evaluate the extent to which both reasons and estimates of interestingness contribute to performance in the domain of protein crystallization . With both aspects contributing to task selection , a high fraction of discoveries by the HAMB prototype were judged interesting by an expert ( 21 % interesting and novel ; 45 % interesting but rediscoveries ) .
1 . Introduction The rapid growth of data available for knowledge discovery argues for fully autonomous machine learning and knowledge discovery in databases ( KDD ) systems . Autonomous discovery systems will save time and eliminate human error , and they will examine orders of magnitude more hypotheses in the search for interesting discoveries . However , because the space of possible hypotheses is immense , an autonomous discovery system must have strong heuristics to focus on tasks and goals that are more likely to be interesting [ Zytkow , 1993 ] .
The research presented here evaluates a mechanism for deciding which task to perform within an agenda and justification based framework for discovery .
1.1 The Agenda and Justification Based Framework The agenda and justification based framework consists of an agenda of tasks prioritized by their plausibility , where a task ’s plausibility is calculated as a function of strengths of justifications ( called reasons ) given for performing the task and estimates of the interestingness of the items it operates upon . Each task is an operation upon zero or more items . The the the strengths are theoretical support and corresponding quantitative representations . By making this theoretical support and framework facilitates reasoning about the appropriateness of tasks . reasons are qualitative representations of fit explicit , fit , and the
Tasks are performed using heuristics that create new items for further exploration and place new tasks on the agenda . When putting a new task on the agenda , a heuristic must also provide reasons and corresponding strengths for performing the task . New reasons given for performing a task already on the agenda are attached to the existing task , thus increasing its plausibility . The framework is derived from that of AM [ Lenat , 1982 ] .
1.2 Plausibility Function is : The particular plausibility function we evaluated Plausibility(T ) = ( S Interestingness(IT ) ) , where {RT} is the set of the ratings of T ’s reasons and {Interestingness(IT)} estimated interestingness of T ’s items .
RT ) * ( S represents the
This plausibility function has three properties that may be necessary for appropriate task selection [ Lenat , 1982 ] : • The plausibility of a task is a monotonically increasing function of each of its reason‘s ratings . If a new supporting reason is found , the task ’s value is increased . The better that new reason , the bigger the increase .
• If an already known supporting reason is re proposed , the plausibility of the associated task is not increased .
• The plausibiliy of a task involving an item C should be a monotonically increasing function of the worth of C . Two similar tasks dealing with two different concepts , each supported by the same list of reasons and strengths of reasons , should be ordered by the worth of those two concepts .
1.3 Evaluation of the Framework We implemented the framework in a program , HAMB ( pronounced HamBEE ) , and used HAMB to make
1 . Compute the plausibilities of the tasks on the agenda using the strengths of the reasons given for performing the them and the interestingness of the items involved in the tasks .
2 . Select and remove from the agenda the task with the greatest plausibility . 3 . Perform the task using heuristics , resulting in one or more of : i . Proposing new tasks ii . Evaluating items iii . Creating new items iv . Examining relationships among the items
4 . Check the stopping criterion , and if it is met , stop the discovery process , otherwise loop back to 1 .
Figure 1 . Sketch of HAMB's top level control from data discoveries the domain of macromolecule crystallization . Our evaluation of HAMB ’s discoveries and behavior revealed that using reasons and interestingness to select tasks is better than either alone . taken from
2 . The HAMB Program To evaluate the proposed agenda and justification based discovery framework we implemented it in a prototype discovery program called HAMB . HAMB uses rule induction as its primary method for discovering patterns and uses the rule induction program RL [ Provost and Buchanan , 1995 ] , a descendant of Meta DENDRAL [ Buchanan and Mitchell , 1978 ] . RL is efficient , flexible , robust with respect to incomplete or noisy data , and can use a variety of domain knowledge [ Clearwater and Provost , 1990 ; Provost and Buchanan , 1995 ] . Figure 1 sketches HAMB ’s top level control and Figure 2 presents an overview of the types of tasks HAMB performs .
HAMB ’s stopping condition is that either : ( 1 ) the plausibility of all tasks on the agenda falls below a userspecified threshold ( ie , no task is interesting enough ) or ( 2 ) the number of cycles that have been executed exceeds a user defined maximum discovery cycles threshold .
2.1 HAMB ’s Discoveries Because HAMB uses rule induction to perform empirical discovery , HAMB ’s items are instances and sets of instances of concepts that are used while performing rule induction—attributes , examples , rule conjuncts , and rules . HAMB ’s discoveries are items with interesting properties or relationships .
3 . Evaluation Several experiments with HAMB in the domain of macromolecule crystallization were performed . Those related to task selection are reported here .
3.1 Macromolecule Crystallization Data The macromolecule crystallization data consists of experiments for growing crystals of proteins , nucleic acids , or larger complexes , such as proteins bound to DNA , for X ray diffraction and subsequent determination of threedimensional structure [ Hennessy , Buchanan , et al . , 2000 ] . These data have been problematic for standard KDD techniques such as rule learning and clustering for a variety of reasons : no clear target attribute , a high level of redundancy in the data , heterogeneous data ( eg , nucleic acids crystallize under a very different set of conditions than proteins ) , and a high degree of noisy and incomplete data [ Hennessy , Gopalakrishnan , et al . , 1994 ] . The database consists of 2,225 examples of crystallization experiments , each with 225 attributes . The attributes include : • macromolecular properties—macromolecule name , macromolecule class name , and molecular weight ;
• experimental conditions—pH , temperature , crystallization method , macromolecular concentration , and concentrations of chemical additives in the growth medium ;
• and characteristics of the grown crystal ( if any)— descriptors of the crystal ’s shape and its diffractionlimit , which is a measure of how well the crystal diffracts .
These data were supplemented with additional chemical information : macromolecule type , the “ perceived role ” of the additives in the experiment ( eg , precipitant , buffer ) , what ions the additives break down into , the net charge of the ions , the buffering capacity of the growth medium , and so on [ Hennessy , Buchanan , et al . , 2000 ] .
3.2 Evaluation of HAMB ’s Behavior Figure 3 presents narrative descriptions of four excerpts from a run of HAMB upon the data that illustrate HAMB ’s ability to tailor its tasks to the data . The first excerpt , shown at discovery cycle 5 , illustrates a heuristic opportunistically identifying a potential rule induction target . The second excerpt , shown at cycle 1,029 , shows HAMB assigning low strengths to a task its heuristics suggest would not lead to a promising line of investigation : When a selected training set ’s size is small , HAMB ’s heuristics , encoding the rule of thumb that inducing a “ good ” rule set is more likely with larger training sets , cause HAMB to assign low strengths to the reasons given for selecting a feature set for the CRFORM . Finally , the excerpt at cycle 1,202 , shows HAMB performing a task because it has determined that ADD IRON [II] CITRATE may be an “ easy ” rule induction target ( not shown are the many reasons HAMB found for doing so ) , not because examine item(item ) select training set(target ) examine relationships with item(item ) select feature set(target , training set ) examine r relationships with(item , rel ) examine relationship(item1 , item2 , itemn , rel ) select bias(target , training set , feature set ) induce rule set(target , training set , feature set , bias ) create exception set(rule set , target , training set )
Figure 2 . An overview of HAMB ’s task types . The task types on the left side of the figure are the task types for examining items , the task types on the right side are the task types for creating items . The arrows indicate which task types are proposed by other tasktypes .
ADD IRON [II] CITRATE is especially interesting to the user .
3.3 Evaluation of HAMB ’s Discoveries After semimanual removal of redundant discoveries from the discoveries HAMB made from the crystal growing database , 431 discoveries were presented to Dr . Rosenberg for categorization of their significance and novelty . His categorizations are presented in Table 1 .
3.4 Lesion Studies of the Plausibility Function Given an expert ’s assessment of the degree of interest of over 400 discoveries , we performed lesion studies to further evaluate the plausibility function . To perform this experiment , we used three versions of HAMB : • HAMB • Reasons Only HAMB , which computes the plausibility of a task as the sum of the strengths of the task ’s reasons • Interestingness Only HAMB , which computes a task ’s the the estimates of plausibility as interestingness of the items involved in the task Figure 4 presents a graph of the interestingness of the discoveries reported by the three versions of HAMB during periodic reports of their discoveries versus the discovery cycle that followed the generation of the reports . Differences are significant between HAMB and Reasons Only HAMB ( p value is 0.003 ) and between HAMB and Interestingness OnlyHAMB ( p value is 0049)1 the sum of the sum of
We also tested a version of HAMB that selected tasks randomly . It starts inducing rules earlier than HAMB but after 1,400 cycles the total interestingness of HAMB exceeds that of Random HAMB , and that difference is statistically significant ( p value is 0007 )
1 Significance level for rejecting H0 is p £
005
3.5 Evaluating HAMB ’s Assignment of Reasons and Strengths to Tasks Inducing Rule Sets HAMB ’s heuristics are designed to use the results of performing one phase of inducing a rule set , such as selecting a reasons and corresponding strengths to the task for the next phase , such as selecting a feature set . By doing so , the reasons and strengths should allow HAMB to tailor its behavior to the data and be opportunistic by deciding to induce rule sets for target attributes that may have better test accuracies , ceteris paribus . to assign training set ,
To evaluate the effectiveness of HAMB ’s heuristics in assigning reasons and corresponding strengths to achieve this behavior , I examined the strengths of the reasons assigned for the tasks HAMB performs to induce rule sets at three points in the process of inducing a rule set : • before performing select training set tasks , when the ratings reflect the predictiveness of attributes toward target attributes . Regressing a line between the strengths of the reasons given for performing the tasks and the accuracy of the induced rule sets on the test database yielded a correlation of determination of 00241 However , visual examination of a plot of the data , not shown to conserve space , indicates that there are two groups of datapoints , those for which the ratings are suggestive of the test accuracy of the induced rule set , and those for which the test accuracy is zero . If those datapoints with a test accuracy of zero are removed from the line , the coefficient of determination goes up to 03704 regression of
• after selecting a training set , when the strengths have been adjusted to account for the size of the selected training set . A plot of the sizes of the training sets to the test accuracy of the induced rules shows a very weak trend with a slope of 0.22 and a coefficient of determination of 0.0151 for a line linearly regressed from these data . However , very few rule sets induced from smaller than approximately 300 examples ) had accuracies on the testdatabase greater than 03 Therefore , while large training training sets
( containing less the
Cycle 5 : HAMB examines the predictivity of other attributes toward CRFORM , discovering two predictors of CRFORM , and also examines CRFORM ’s predictivity of the other attributes , discovering that CRFORM is predictive of several others . One of HAMB ’s heuristics suggests that it is easier to induce good rules for a target attribute with many good predictors , causing HAMB to propose a task to select a training set for inducing rules predicting CRFORM each time HAMB discovers a good predictor of CRFORM . And each time HAMB discovers that CRFORM is a good predictor of another attribute , HAMB proposes a task to select a training set for the attribute . HAMB ’s identification of “ easier ” rule induction targets illustrates how heuristics may be used to identify opportunities and propose tasks accordingly .
Cycle 1,029 : Primarily because CRFORM has the greatest a priori interest to the user , but also because HAMB has discovered many good predictors of CRFORM , HAMB selects a training set for inducing rules predicting CRFORM before doing so for other attributes . HAMB creates the training set from the discovery database ’s examples that do not have uninformative values for CRFORM ( eg , missing values , or “ miscellaneous ” ) , avoiding the induction of many uninteresting rules . After selecting the training set , HAMB notices that the selected training set is small , containing only 164 out of 1,482 possible examples . Because HAMB believes that it is harder to induce good rules using a small training set , HAMB postpones performing the next step of inducing rules for CRFORM—selecting a feature set—until task 11,172 . Note that when HAMB finally does induce a rule set for CRFORM the accuracy of the induced rule set on the testing database is 002
Cycle : 1,123 : HAMB selects a training set for inducing rules to predict the attribute SPGRPS DESC , again using domain knowledge to exclude examples that would cause the induction of uninformative rules , and then proposes a task for selecting a feature set from which rules predicting SPGRPS DESC may be induced . The selected training set is fairly large , containing 1,305 examples .
Cycle 1,202 : HAMB selects a training set for inducing rules predicting ADD IRON [II] CITRATE , not becuase ADD IRON [II]CITRATE is especially interesting , but because HAMB found many reasons for performing this task . The selected training set contains 1,482 out of 1,482 possible examples .
Figure 3 . Excerpts taken from a run of HAMB upon the macromolecule crystal growing data illustrating HAMB ’s ability to be opportunistic as well as to postpone less promising tasks in favor of more promising ones . After 33,204 discovery cycles HAMB finished its discovery process , at which time HAMB reported approximately 700 discoveries it considered interesting . set size may be insufficient for predicting a high accuracy for an induced rule set , small training set size may be useful for predicting low accuracy on the testdatabase , allowing HAMB to identify less promising rule induction tasks . A line regressed between the strength of the reasons provided for the next step in inducing a rule set , selecting a feature set , and the accuracies of the induced rule sets yields a coefficient of determination of determination is a slight increase over the coefficient of determination derived from the strengths of the reasons given before performing selecting training set tasks , indicating that HAMB ’s adjustment of the strengths to account for the size of the training set is helpful .
00168 This coefficient of
• after selecting the parametric bias . A plot of the strengths of the reasons given for the last task performed when inducing rule sets , the actual induction of the rule set , to the accuracies of the induced rule sets on the test database shows a strong correlation , with a coefficient of determination of 08563 the results of
These results , and lesion study demonstrate how HAMB is able to assign reasons and corresponding strengths to adapt its behavior to fit the data , in this case allowing HAMB to achieve the desired behavior of inducing rules with greater test accuracies first . the
4 . Discussion Our experiments with HAMB demonstrate that HAMB was able to tailor its tasks to the data , being opportunistic by identifying better rule induction targets and postponing less promising lines of investigation in favor of more promising ones . HAMB also demonstrated that it considered the user ’s interests when deciding which task to perform . Finally , HAMB demonstrated that it could use knowledge about performing discovery , which in HAMB ’s heuristics , to propose tasks and to provide reasons and corresponding strengths for performing those tasks . Other experiments ( reported in [ Anonymous , 2001 ] ) also suggest that HAMB and the framework are general , thus easily adapted to make discoveries from datasets taken from new domains . is contained
4.1 Related Systems The agenda and justification based framework presented in this thesis was adapted from the framework used in Lenat ’s AM ( Automatic Mathematician ) and EURISCO discovery programs [ Lenat , 1982 ; Lenat and Brown , 1984 ] . AM is “ one of the best known artificial intelligence programs of the 1970s , ” 2 and discovers concepts in the domain of number theory and geometry .
While many systems have been created for various phases of the empirical discovery process , no published system combines all phases into a complete system , although KDD planning systems , such as GLS [ Zhong , Liu , et al . , 1997 ] and the framework presented in [ Engels , 1996 ] , perform sequences of tasks for a discovery goal provided by a user . Similarly , multistrategy systems
2 [ Dietterich and Shavlik , 1990 ] , page 337 .
Table 1 . Categories used by an expert to assess the interestingness of 531 discoveries using HAMB .
Category
IV
III
II I 0
Significance Individually , these discoveries could be the basis of a publication in the crystallography literature , being both novel and extremely significant to the crystallography literature In groups of about a dozen , these discoveries could form the core of research papers in the crystallography literature These discoveries are about as significant as Category III , but are not novel These discoveries are not as interesting as Category II or III , but still are of some interest These discoveries are any discovery that are not Category I , II , III , or IV
Number 0 / 431
Percent 0
92 / 431
192 / 431 51 / 431 96 / 431
21
45 12 22
[ Nordhausen and Langley , 1993 ; Michalski and Tecuci , 1994 ; Klosgen , 1996 ] perform multiple discovery operations ; but again , the discovery goals are provided by a user . Evaluation of the discovered patterns is also left to the user . Therefore , while these systems have an increase in autonomy over traditional KDD systems , they do not run autonomously .
The most closely related program is AIDE [ St . Amant , 1996 ; St . Amant and Cohen , 1997a ; St . Amant and Cohen , 1997b ; St . Amant and Cohen , 1998 ] , an intelligent assistant for performing exploratory data analysis ( EDA ) . AIDE provides low level support for examining relationships Given a relation to examine , AIDE uses encoded strategic knowledge to suggest tasks to examine the relation . AIDE autonomously performs some of the simpler tasks it suggests , but usually relies upon the user to select a task to perform.3 When AIDE performs a task , it looks for indications in the data which may suggest additional tasks to perform . This process repeats until the user wishes to stop or AIDE cannot devise any new tasks to perform . AIDE was designed only to aid the user by using its knowledge of EDA to suggest new tasks , not to run autonomously . Moreover , AIDE did not attempt to evaluate the interestingness of its discoveries ; that too was left to the user . AIDE ’s inability to use domain specific knowledge was a design choice . However , AIDE ’s architecture would have to be modified to allow an estimate of the user ’s interest to be considered when prioritizing tasks .
5 . Conclusions We believe the agenda and justification based framework provides a sufficient mechanism for selecting the next task to perform for implementing fully autonomous discovery systems . Our experiments suggest that heuristics may be sufficient vehicles for suggesting new tasks to perform and providing them . Our experiments also suggest that both the strengths of reasons for performing the the
3 The rules AIDE uses to determine which tasks to perform autonomously are never stated in [ St . Amant , 1996 ; St . Amant and Cohen , 1997a ; St . Amant and Cohen , 1997b ; St . Amant and Cohen , 1998 ] . for performing justifications tasks and estimates of interestingness of the tasks’ items are useful in selecting the next task to perform . for
6 . Acknowledgments We thank John Aronis , Tom Fawcett , David Jensen , and Foster Provost their numerous discussions and suggestions . This work was funded in part by grants from the National Library of Medicine ( 1 G08 LM006625 01 , the the National Center for Research Resources to Pittsburgh Supercomputing Center ( 005011 ) , and the National Science Foundation ( 9412549 ) .
References [ St . Amant , 1996 ] Robert St . Amant . A Mixed Initiative Planning Approach to Exploratory Data Analysis . PhD Dissertation , Department of Computer Science , University of Massachusetts , 1996 .
[ St . Amant and Cohen , 1997a ] Robert St . Amant and Paul R . Cohen . Evaluation of a Semi Autonomous Assistant for Exploratory Data Analysis . In Proceedings of the First International Conference on Autonomous Agents , pages 355 362 , Marina Del Rey , California , 1997 . ACM Press .
[ St . Amant and Cohen , 1997b ] Robert St . Amant and Paul R . Cohen . Interaction with a Mixed Initiative System for Exploratory Data Analysis . In Proceedings of the Third International Conference on Intelligent User Interfaces , pages 15 22 , Orlando , Florida , 1997 . ACM Press .
[ St . Amant and Cohen , 1998 ] Robert St . Amant and Paul R . Cohen . Intelligent Support for Exploratory Data Analysis . Journal of Computational and Graphical Statistics , 7(4):545 558 , 1998 .
[ Anonymous , 2001 ] Anonymous . A Framework for Autonomous Knowledge Discovery from Databases . PhD Dissertation . Department of Computer Science , Anonymous University , 2001 .
[ Buchanan and Mitchell , 1978 ] Bruce G . Buchanan and Tom Mitchell . Model directed Learning of Production Rules . In D . A . Waterman and F . Hayes Roth , Eds . , s s e n g n i t s e r e t n
I
200 180 160 140 120 100 80 60 40 20 0
0
500
1,000
1,500
2,000
2,500
3,000
3,500
4,000
4,500
5,000
Discovery Cycle
HAMB
Strengths Only HAMB
Interestingness Only HAMB
Figure 4 . Plot of the total interestingness of reported discoveries versus the discovery cycle for each of the four versions of HAMB . Interestingness is the sum of the category numbers assigned by Dr . Rosenberg ) to the discoveries reported by the four versions of HAMB . Discovery cycle is the discovery cycle before which the discoveries are reported .
Pattern Directed Inference Systems , pages 297 312 , Academic Press , New York , 1978 .
Intelligent Systems for Molecular Biology , pages 179187 , Stanford , CA , 1994 . AAAI Press .
[ Clearwater and Provost , 1990 ] Scott Clearwater and Foster Provost . RL4 : A Tool for Knowledge Based Induction . In Proceedings of the Second International IEEE Conference on Tools for Artificial Intelligence , pages 24 30 , Los Alamitos , California , 1990 . IEEE CS . Press .
[ Klosgen , 1996 ] Willi Klosgen . Explora : A Multipattern and Multistrategy Discovery Assistant . In U . Fayyad , G . Piatetsky Shapiro , P . Smyth , and R . Uthurusamy , Eds . , Advances in Knowledge Discovery and Data Mining , pages 249 271 , The AAAI Press , Menlo Park , California , 1996 .
[ Dietterich and Shavlik , 1990 ] Thomas G . Dietterich and Jude W . Shavlik . Discovery . In J . W . Shavlik and T . G . Dietterich , Eds . , Readings in Machine Learning , pages 337 340 , Morgan Kaufmann Publishers , San Mateo , California , 1990 .
[ Engels , 1996 ] Robert Engels . Planning Tasks for Knowledge Discovery in Databases ; Performing TaskOriented User Guidance . In The Second International Conference on Knowledge Discovery and Data Mining , pages 170 175 , Portland , Oregon , 1996 . AAAI Press .
[ Hennessy , et al . , 2000 ] Daniel Hennessy , Bruce G . Buchanan , Devika Subramanian , Patricia Wilkosz , and the John M . Rosenberg . Statistical Methods for Objective Design of Screening Procedures for Macromolecule Crystallization . Acta Crystallographica Section D , 2000 .
[ Hennessy , et al . , 1994 ] Daniel Hennessy , Vanathi Gopalakrishnan , Bruce G . Buchanan , John M . Rosenberg , and Devika Subramanian . Induction of Rules for Biological Macromolecule Crystallization . In Proceedings of the Second International Conference on
[ Lenat , 1982 ] Douglas B . Lenat . AM : Discovery in Mathematics as Heuristic Search . In Knowledge Based Systems in Artificial Intelligence , pages 3 225 , McGrawHill , New York , New York , 1982 .
[ Lenat and Brown , 1984 ] Douglas B . Lenat and John S . to Work .
Brown . Why AM and Eurisko Appear Artificial Intelligence , 23:269 294 , 1984 .
[ Michalski and Tecuci , 1994 ] Ryszard Michalski and Gheorghe Tecuci , Eds . Machine Learning IV : A Multistrategy Approach , Morgan Kaufmann Publishers , San Francisco , California , 1994 .
[ Nordhausen and Langley , 1993 ] Bernd Nordhausen and Pat Langley . An Integrated Framework for Empirical Discovery . Machine Learning , 12:17 47 , 1993 .
[ Provost and Buchanan , 1995 ] Foster John Provost and Bruce G . Buchanan . Inductive Policy : The Pragmatics of Bias Selection . Machine Learning , 20(1):35 61 , 1995 .
[ Zhong et al , 1997 ] Ning Zhong , Chunnian Liu , Yoshitsugu Kakemoto , and Setsuo Ohsuga . KDD Process Planning .
In Third International Conference on Knowledge Discovery and Data Mining , pages 291 294 , Newport Beach , California , 1997 . AAAI Press .
[ Zytkow , 1993 ] Jan M . Zytkow . Introduction : Cognitive Autonomy in Machine Discovery . Machine Learning , 12:7 16 , 1993 .
