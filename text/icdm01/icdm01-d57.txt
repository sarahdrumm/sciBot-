Livingston , G . R . , Rosenberg , J . M . , and Buchanan , B . G . 2001 . “ Closing the Loop : Heuristics for Autonomous Discovery . ” In Proceedings of the 2001 IEEE International Conference on Data Mining , November 29–December 2 , 2001 , San Jose , CA . IEEE Computer Society Press , pp . 393 400 .
Closing the Loop : Heuristics for Autonomous Discovery
Gary R . Livingston
202 Mineral Industries Building
Univ . of Pittsburgh Pittsburgh , PA 15260 gary@cspittedu
John M . Rosenberg
312 Clapp Hall
Univ . of Pittsburgh Pittsburgh , PA 15260 jmr@jmr3xtalpittedu
Bruce G . Buchanan
206 Mineral Industries Building
Univ . of Pittsburgh Pittsburgh , PA 15260 buchanan@cspittedu
Abstract
Autonomous discovery systems will be able to peruse very large databases more thoroughly than people can . In a companion paper [ 1 ] , we describe a general framework for autonomous systems . We present and evaluate heuristics for use in this framework . Although these heuristics were designed for a prototype system , we believe they provide good initial solutions to problems encountered when implementing fully autonomous discovery systems . As such , these heuristics may be used as the starting point for future research into fully autonomous discovery systems .
1 . Introduction
Autonomous discovery systems will be able to peruse very large databases more thoroughly than people can , will be able to free a considerable amount of a dataminer ’s time , and may be more easily used . In a companion paper [ 1 ] , we describe a general agenda and justification based framework for implementing autonomous systems . Because the space of possible hypotheses is immense , an autonomous discovery system must have strong heuristics to focus on tasks and goals that are more likely to be interesting [ 2 ] .
The research presented here evaluates domainindependent heuristics for use in autonomous discovery systems implementing the agenda and justificationbased framework . These heuristics ( 1 ) keep an item ’s properties and relationships sufficiently up to date , allowing a discovery system to select appropriate tasks without needlessly re examining these properties and relationships after every task , ( 2 ) select rule induction targets and other goals worth pursuing , and ( 3 ) use domain specific knowledge to improve the quality of reported discoveries .
11 The agenda and justification based framework
The framework , discussed in [ 1 ] , consists of an agenda of tasks prioritized by their plausibility , where a task ’s plausibility is calculated as a function of strengths of justifications ( called reasons ) given for performing the task and estimates of the interestingness of the items it operates upon . An item is an instance of the space being searched for discoveries ( eg , rules or subsets of the data ) . Each task is an operation upon zero or more items . Tasks are performed using heuristics that create new items for further exploration and that place new tasks on the agenda . When proposing a new task to be put onto the agenda , a heuristic must also provide reasons and corresponding strengths for performing the task . New reasons given for performing a task already on the agenda are attached to the existing task , thus increasing its plausibility .
12 Evaluation
We evaluated our heuristics by implementing them in a prototype , HAMB ( pronounced HamBEE ) , and using it to make discoveries from data taken from two domains : macromolecule crystallization and patient rehabilitation . Our evaluations suggest that the heuristics are useful in guiding the discovery process and in using background knowledge . A study of HAMB ’s generality shows that the heuristics are domain independent .
Because the results of our experiments with HAMB provide support for both the agenda and justificationbased framework and our heuristics , we use many of them in [ 1 ] to support the framework and in this report to support our heuristics . We also present in this report the results of a study not reported in [ 1 ] .
2 . An example
Figure 1 presents an example designed to show the basic operation of the framework and its use of heuristics both to propose new tasks and to provide strengths of reasons for performing tasks ( which are used to tailor a discovery system ’s behavior to the data ) . To keep the example simple , it is concocted rather than taken from an actual trace of HAMB , but it is closely patterned after actual traces generated by HAMB .
DISCOVERY CYCLE 101 Agenda : Task–100 Examine relationship ( age , pneumonia , predictivity )
Reason : Need to examine age ’s predictivity of pneumonia
Task–30 : Examine item ( weight ) Reason : Never been examined
Task–40 : Induce rule set ( pneumonia )
Reason : Pneumonia is a target attribute
Performing Task–100 : examine relationship ( age , pneumonia , predictivity )
Reasons :
Haven’t examined age ’s predictivity of pneumonia
Applicable heuristics : general examine relationship Performing general examine item heuristic :
Calculating predictivity of age for pneumonia Predictivity ( age , pneumonia ) is 0.306 ; age may be a predictor of pneumonia Proposing new task : Induce rule set ( pneumonia )
Age may be a predictor of pneumonia ( predictivity : 0.306 )
Proposing new task : Examine item ( age )
Predictivity ( age , pneumonia ) has changed from NIL to 0.8
Proposing new task : Examine item ( pneumonia )
Predictivity ( age , pneumonia ) has changed from NIL to 0.8
DISCOVERY CYCLE 102 Agenda : Task–40 : Induce rule set ( pneumonia )
Reason : Pneumonia is a target attribute Reason : Age may be a predictor of pneumonia ( predictivity : 0.306 )
Task–30 : Examine item ( weight ) Reason : Never been examined
Task–131 : Examine item ( pneumonia )
Reason : Predictivity ( age , pneumonia ) has changed from NIL to 0.8
Task–132 : Examine item ( age )
Reason : Predictivity ( age , pneumonia ) has changed from NIL to 0.8
Strength : 100
Strength : 80
Strength : 50
Strength : 100
Strength : 61
Strength : 40
Strength : 40
Strength : 50 Strength : 61
Strength : 85
Strength : 40
Strength : 40
Item interestingness : 70 , 100 Plausibility :
17,000
Item interestingness : 120 Plausibility :
9,600
Item interestingness : 100 Plausibility :
5,000
Plausibility :
17,000
Item interestingness : 100 Plausibility :
11,100
Item interestingness : 120 Plausibility :
10,200
Item interestingness : 100 Plausibility :
4,000
Item interestingness : 70
Plausibility :
2,800
Figure 1 . An artificial example illustrating the use of reasons to prioritize tasks and the effects of performing a task . Each task is put on the agenda by a heuristic . Task 100 is to examine a predictive relationship from age to pneumonia and was suggested because predictivity is an interesting relationship and both the variables age and pneumonia are interesting . Examine item tasks are proposed to examine age and pneumonia in cycle 102 because the value of their predictivity relationship has changed .
3 . The HAMB program
As described in [ 1 ] , HAMB uses rule induction as its primary method for discovering patterns and uses the rule induction program RL [ 3 ] , derived from MetaDENDRAL [ 4 ] . Because HAMB mainly uses rule induction to perform discovery , HAMB ’s items are attributes , examples , rule conjuncts , and rules , plus sets of these . HAMB ’s discoveries are items with interesting properties or relationships .
HAMB estimates the interestingness of its items and discoveries using a hierarchical weighted sum of their properties , with the weights forming a simple model of the user ’s interestingness function . Interested readers are directed to [ 5 ] for details of HAMB ’s estimation of interestingness .
HAMB ’s stopping condition is : ( 1 ) the agenda is empty , ( 2 ) the plausibility of all tasks on the agenda falls below a user specified threshold ( ie , no task is interesting enough ) , or ( 3 ) the number of completed discovery cycles exceeds a user defined threshold .
HAMB ’s input is a database of cases from which discoveries are to be made , an optional testing database of cases , and a domain theory which contains domainspecific information , such as known relationships among the attributes .
HAMB reports as discoveries those items with interesting relationships or properties . A property or relationship is interesting if its value exceeds a threshold provided for each relationship or property . HAMB creates a report for each relationship or property , where the items having values for that property or relationship greater than or equal to the threshold are listed in decreasing order .
The types of tasks HAMB performs and its heuristics for performing them are presented in Table 1 , and they are divided into two groups based upon function : those examining items and those creating new items . The tasktypes and heuristics for creating items may be further divided into two subgroups , those creating new items using rule induction and those creating new items using a deductive heuristic ( creating exception sets ) . Due to space limitations , we could only briefly discuss these
2
Table 1 . An overview of HAMB ’s task types and heuristics . Tasks indicates the type of task and summary of heuristics provides a brief description of the heuristics performing the tasks . Not shown is that examine item tasks are proposed during initialization .
Tasks Tasks items Examine item ( item ) examining
Examine relationshipswith ( item )
Examine r relationships ( item , R )
Examine relationship ( item1 , item2 , itemn , R )
Summary of heuristics
Check item ’s membership in item groups , evaluate item ’s properties , and estimate its interestingness . Propose examine relationships with ( item ) If item is an attribute and this is the first time item has been examined , then propose select training set ( item ) For each type of relationship R defined to hold with item :
Propose an examine relationships with task to examine all possible R relationships involving item
Assign a strength to the reason given for the task that is proportional to the utility of the relationship
For each possible relationship of type R that could hold with item :
If the relationship may be evaluated quickly , then do so using a function given in the definition of R for evaluating R relationships1
Propose examine item tasks to examine any items in relationships whose values have changed
Assign strengths to the reasons given for performing the tasks which are proportional to the change in the relationships’ values
Otherwise propose an examine relationship task to examine that relationship Assign a strength to the reason given for performing the task that is proportional to the utility of the relationship
Evaluate the R relationship among item1 , item2 , itemn If the relationship ’s value has changed , propose examine item tasks for item1 , item2 , itemn
1
Assign strengths to the reasons given for performing the tasks which are proportional to the change in the relationships’ values
Tasks creating new items Select training set ( target attribute )
Select a training set from which rules predicting target attribute will be induced . Omit from the training set cases with missing values for target attribute Propose a select feature set task for target attribute
Select feature set attribute , training set )
( target
Select bias ( target attribute , training set , feature set )
Induce rule set attribute , feature set , bias ) training
( target set ,
Assign a strength to the reason given for performing the task that is proportional to the size of the selected training set
Select a feature set from which rules predicting target attribute will be formed
Omit from the feature set the following attributes :
Attributes which are known or discovered to be a synonym to the target attribute Attributes which are known to be or are definitionally related to target attribute Attributes that have information gains with the target attribute which are in the lower n percentile
If the feature set is not empty , propose a select bias task for target attribute
Assign to the newly proposed task the reasons and strengths associated with the current task
Select a bias for inducing rules predicting target attribute using hill climbing . Use cross validation upon training set to evaluate the biases
Propose an examine item task for each newly induced rule set Propose an examine item task for each newly induced rule Propose an examine item task for each attribute , rule conjunct , or rule used in a newly induced rule set Propose an induce rule set task for target attribute
Assign a strength to the reason given for performing the newly proposed induce rule set task that is proportional to the score of the selected bias
Induce a rule set predicting target attribute using the selected training set , feature set , and bias
Propose an examine item task for the induced rule set Propose an examine item task for each newly induced rule Propose an examine item task for each attribute , rule conjunct , or rule used in the induced rule set
Propose a create exception set task to create an exception set for the induced rule set
Create exception set ( rule set , training set )
Assign a strength to the reason given for performing the newly proposed create exception set that is proportional to the testaccuracy of the induced rule set Create an exception set for rule set . If the exception set is smaller than training set , then propose a select feature set task to begin the process of inducing a rule set from the exception set to “ fill in the gaps ” of the theory encoded in the rule set
Assign a strength to the reason given for performing the task that is proportional to the size of the exception set and the testaccuracy of the rule set
————— 1 The function given for examining predictivity relationships contains a heuristic that proposes a select training set task for a target attribute whenever a predictor is found for that attribute . The strength of the reason given for the newly proposed task is proportional to the strength of the predictivity relationship .
3 heuristics in this paper . Readers are directed to [ 5 ] for full details of these heuristics .
31 Heuristics for examining items
Heuristics for examining items create tasks on the agenda that , essentially , look at what is known ( given in the domain theory or discovered by HAMB ) about the named item(s ) and determine whether some properties or relationships are interesting .
HAMB ’s heuristics for examining items solve a novel problem for fully autonomous discovery systems : keeping the values of an item ’s properties , relationships , and interestingness up to date without recalculating their values after every discovery cycle . HAMB ’s heuristics use satisficing to solve this problem : whenever a heuristic indicates that some aspect ( property , relationship , or interestingness ) of an item may have changed , a task is ( re)proposed for reexamining the item . As HAMB ’s heuristics notice that more and more aspects of the item may have changed , more and more reasons accumulate for the task of examining the item , eventually causing the sum of the strengths of those reasons to become great enough to cause HAMB to examine the item .
32 Heuristics for inducing rule sets
When HAMB determines that an attribute of a set of objects might make an interesting target variable , heuristics propose a task for inducing rules predicting the value of that variable .
We decomposed the induction of rule sets into four subtasks : selecting a training set , selecting a feature set , selecting a parametric bias , and calling an induction program ( RL ) with the selected training set , feature set , and bias to actually induce the rule set . Each of these subtasks corresponds to one of HAMB ’s task types : select training set , select feature set , select bias , and induce rule set , respectively . After the completion of one of these tasks , the next task in the sequence is proposed , ensuring that HAMB performs the tasks in the order given above .
When proposing the next task in the sequence , the results of the current task are often used to determine the strengths of the reason given for performing the next task , allowing HAMB to factor the results of the current task into its decision about when to perform the next task in the sequence , if at all . For example , the heuristic for selecting a training set proposes a task for selecting a feature set , with the strengths of the reasons given for the proposed task being proportional to the size of the training set ( encoding the rule of thumb that inducing a rule set from a small training set may result in a rule set with poor performance on future cases ) .
HAMB proposes select training set tasks , the first in the series of tasks given above , when it examines an at tribute that is a possible target attribute or when it discovers a potentially good predictor of a possible target attribute ( ie , detecting opportunities for inducing rule sets ) .
33 Heuristics for creating exception sets
HAMB creates exception sets for rule sets in order to induce rule sets from these exception sets , hopefully filling in the gaps of the “ theory ” formed by the initial rule set . An exception set is created for a rule set by selecting the rule set ’s counter examples from the training set . After creating the exception set , HAMB proposes an examine item task to examine the set and a selectfeature set task which will begin the process of inducing rules from the exception set .
4 . Evaluation
Several experiments with HAMB using data taken from the domain of macromolecule crystallization were performed . We report here the results of our evaluations of HAMB ’s heuristics . The reader is directed to [ 1 ] and [ 5 ] for details of our examination of the framework ’s task selection mechanism .
The studies presented in this paper are :
• Evaluation of HAMB ’s behavior to see if the heuristics allow it to adapt its behavior to the data .
• Evaluation of HAMB ’s discoveries to study the effi cacy of the heuristics .
• Evaluation of the heuristics’ assignment of reasons and strengths .
• Evaluation of the ability of the heuristics—which are domain independent—to use domain specific knowledge , allowing HAMB to achieve domain specific behavior using domain independent heuristics .
• Evaluation of HAMB ’s generality to determine the generality of the heuristics .
41 Macromolecule crystallization data
The macromolecule crystallization dataset consists of reports of experiments for growing crystals of proteins , nucleic acids , or larger complexes , such as proteins bound to DNA , for X ray diffraction and subsequent determination of three dimensional structure [ 6 ] . As described in [ 1 ] this dataset is a good test for autonomous discovery because it is relatively unexplored .
The database consists of 2,225 examples of crystallization experiments , each with 225 attributes . The attributes include : • macromolecular properties—macromolecule name , macromolecule class name , and molecular weight ;
• experimental conditions—pH , temperature , crystallization method , macromolecular concentration , and
4
Cycle 5 : HAMB examines the predictivity of other attributes toward CRFORM , discovering two predictors of CRFORM , and also examines CRFORM ’s predictivity of the other attributes , discovering that CRFORM is predictive of several others . One of HAMB ’s heuristics suggests that it is easier to induce good rules for a target attribute with many good predictors , causing HAMB to propose a task to select a training set for inducing rules predicting CRFORM each time HAMB discovers a good predictor of CRFORM . And each time HAMB discovers that CRFORM is a good predictor of another attribute , HAMB proposes a task to select a training set for the attribute . HAMB ’s identification of “ easier ” rule induction targets illustrates how heuristics may be used to identify opportunities and propose tasks accordingly . Cycle 1,029 : Primarily because CRFORM has the greatest a priori interest to the user , but also because HAMB has discovered many good predictors of CRFORM , HAMB selects a training set for inducing rules predicting CRFORM before doing so for other attributes . HAMB creates the training set from the discovery database ’s examples that do not have uninformative values for CRFORM ( eg , missing values , or “ miscellaneous ” ) , avoiding the induction of many uninteresting rules . After selecting the training set , HAMB notices that the selected training set is small , containing only 164 out of 1,482 possible examples . Because HAMB believes that it is harder to induce good rules using a small training set , HAMB postpones performing the next step of inducing rules for CRFORM—selecting a feature set—until task 11,172 . Note that when HAMB finally does induce a rule set for CRFORM the accuracy of the induced rule set on the testing database is 002 Cycle : 1,123 : HAMB selects a training set for inducing rules to predict the attribute SPGRPS DESC , again using domain knowledge to exclude examples that would cause the induction of uninformative rules , and then proposes a task for selecting a feature set from which rules predicting SPGRPSDESC may be induced . The selected training set is fairly large , containing 1,305 examples . Cycle 1,202 : HAMB selects a training set for inducing rules predicting ADD IRON [II] CITRATE , not because ADD IRON [II] CITRATE is especially interesting , but because HAMB found many reasons for performing this task . The selected training set contains 1,482 out of 1,482 possible examples .
Figure 2 . Excerpts taken from a run of HAMB with the macromolecule crystal growing data illustrating HAMB ’s ability to be opportunistic as well as to postpone less promising tasks . After 33,204 discovery cycles HAMB finished its discovery process , at which time HAMB reported approximately 575 discoveries it considered interesting . concentrations of chemical additives in the growth medium ;
• characteristics of the grown crystal
( if any)— descriptors of the crystal ’s shape ( eg , crform , and spgrps desc ) and its diffraction limit , which measures how well the crystal diffracts .
42 Evaluation of HAMB ’s behavior
We evaluated HAMB ’s ability to respond opportunistically to the data by examining traces showing its choices . In particular we asked about the program ’s abilities to ( a ) propose new tasks , ( b ) reason about the appropriateness of the tasks , and ( c ) direct its behavior toward tasks more likely to produce interesting discoveries . identifying a potential
Figure 2 presents narrative descriptions of four excerpts from a run of HAMB upon the data that illustrate HAMB ’s ability to tailor its tasks to the data . The first excerpt , shown at discovery cycle 5 , illustrates a heuristic opportunistically ruleinduction target . The second excerpt , shown at cycle 1,029 , shows HAMB assigning low strengths to a task its heuristics suggest would not lead to a promising line of investigation : When a selected training set ’s size is small , HAMB ’s heuristics , encoding the rule of thumb that inducing a “ good ” rule set is more likely with larger training sets , cause HAMB to assign low strengths to the reasons given for selecting a feature set for the attribute crform . Finally , the excerpt at cycle 1,202 shows HAMB performing a task because it has determined that addiron [II] citrate may be an “ easy ” rule induction target
5
( not shown are the many reasons HAMB found for doing so ) , not because it had reason to believe that add iron[II] citrate is especially interesting to the user .
43 Evaluation of HAMB ’s discoveries
After semi manual removal of redundant discoveries HAMB made from the crystal growing database , 431 discoveries were presented to one of the authors ( JMR , a crystallographer ) for categorization of their significance and novelty . His categorizations are presented in Table 2 . The redundant rules removed during the semi manual filtering ( approximately 144 ) are counted as Category 0 discoveries ( uninteresing ) in the table . One Category II discovery that caught Dr . Rosenberg ’s interest is an improving rule specialization relationship between two rules in which the first rule is specialized by the second and the positive predictive value ( PPV ) of the specialization is greater than that of the first . The first rule matches 63 examples correctly and 97 examples incorrectly ( PPV= 0.39 ) :
Rule 1 : An organic amine is present ( cid:222 ) molecule being crystallized is a nucleic acid . The second rule of the relationship intensionally spe the macro cializes the first :
Rule 2 : An organic amine is present AND ammonium is not present ( cid:222 ) the macromolecule being crystallized is a nucleic acid , refining the general domain knowledge represented by Rule 1 . This rule matches 62 examples correctly and 25 examples incorrectly ( PPV= 071 )
Table 2 . Categories used by an expert to assess the interestingness of 531 discoveries made by HAMB from the macromolecule crystallization domain . The redundant rules removed during the semi manual filtering ( approximately 144 ) are counted as Category 0 discoveries .
Category Significance
IV
III II I 0
Individually , these discoveries could be the basis of a publication in the crystallography literature , being both novel and extremely significant to the crystallography literature In groups of about a dozen , these discoveries could form the core of research papers in the crystallography literature These discoveries are about as significant as Category III , but are not novel These discoveries are not as interesting as Category II or III , but still are of some interest These discoveries are any discoveries that are not Category I , II , III , or IV
Number 0 / 575
Percent 0
92 / 575 192 / 575 51 / 575 240/ 575
16 33 9 42
Rule 1 captures the general but imprecise domain knowledge that “ Organic amines tend to promote the growth of nucleic acid crystals but are less likely to be of use in the crystallization of proteins . ” Rule 2 refines this general knowledge by adding the condition “ ammonium is not present , ” which eliminated 72 incorrect predictions of the first rule while eliminating only one correct prediction .
44 Evaluation of HAMB ’s assignment of reasons and strengths to tasks inducing rule sets
HAMB ’s heuristics use the results of performing one phase of inducing a rule set , such as selecting a training set , to assign reasons and corresponding strengths to the task for the next phase , such as selecting a feature set . By doing so , the reasons and their strengths should help HAMB tailor its behavior to the data and induce rule sets for target attributes that may have better test accuracies . ( We preferred this behavior because we reasoned that more accurate rule sets would yield more interesting discoveries . )
To evaluate the effectiveness of the heuristics in assigning reasons and corresponding strengths , we examined the strengths of the reasons at three points in the process of inducing a rule set ( to conserve space , plots of the data , which are referred to in the following paragraphs , are not shown ; these plots may be found in [ 5] ) : • before performing select training set tasks , when the strengths of reasons given for selecting a training set reflect the predictiveness of attributes toward target attributes . Regressing a line between the strengths of the reasons given for performing the tasks and the accuracy of the induced rule sets on the test database revealed little correlation ( a coefficient of determination of 002 ) However , visual examination of a plot of the data indicates that there are two groups of datapoints : those for which the strengths of the reasons are suggestive of the test accuracy of the induced rule set and those for which the test accuracy is zero . If those datapoints with a test accuracy of zero are removed , the coefficient of determination goes up to 037
• after selecting a training set , when the strengths have been adjusted to account for the size of the selected training set . A plot of the sizes of the training sets to the test accuracy of the induced rule sets shows little correlation with a coefficient of determination of 002 However , very few rule sets induced from smaller training sets ( containing fewer than approximately 300 examples ) had accuracies on the test database greater than 03 Therefore , while large training set size may be insufficient for predicting a high accuracy for an induced rule set , small training set size may be useful for predicting low accuracy on the test database , allowing HAMB ruleinduction tasks . less promising
• after selecting the parametric bias . A plot of the strengths of the reasons given for the last task performed when inducing rule sets—the actual induction of the rule set—to the accuracies of the induced rule sets on the test database indicates a strong correlation , with a coefficient of determination of 086 These results demonstrate how HAMB ’s heuristics allow it to assign reasons and corresponding strengths and to adapt its behavior to fit the data , in this case allowing HAMB to achieve the desired behavior of inducing rules with greater test accuracies first . to identify
45 Evaluation of HAMB ’s use of domainspecific knowledge
We performed a lesion study to evaluate the effectiveness of some of HAMB ’s heuristics that use domainspecific knowledge . To perform this study , we used 500 cases randomly selected from the macromolecule crystallization data .
The unmodified version of HAMB with the complete domain theory was also run on this set of cases , as was a version of HAMB which used no domain knowledge . In the study described below , the latter version is called nodomain knowledge .
The heuristics tested during this study are :
• heuristics reducing redundancy by eliminating synonyms . If an attribute is found in the feature set that is synonymous ( as either discovered by HAMB or stated in the domain theory ) with another attribute in the feature set , the attribute with the lesser estimated interestingness is removed from the feature set . A base
6 line version of HAMB omitted these heuristics and did not eliminate synonyms . It allowed the creation of 40 ( 19 % ) more redundant rules than did HAMB . This was surprising , because the data contain many similar attributes . However , HAMB ’s definition of redundancy is very strict , requiring either intensional or extensional equivalence ; therefore only a few pairs of attributes met its strict criterion of similarity .
• heuristics reducing the number of uninteresting discoveries . The domain theory may contain knowledge about attributes and values which are uninteresting or meaningless to the user . HAMB ’s heuristics use this knowledge to avoid inducing rules containing ( either in the left hand side or right hand side of a rule ) uninteresting features . A baseline version of HAMB omitted this heuristic and allowed the generation of 300 ( 141 % ) additional uninteresting rules .
• heuristics reducing the number of non novel discoveries . HAMB uses domain knowledge to remove attributes that are known to be associated ( by causation , definition , association , etc . ) with the current target attribute . It also removes attributes that are discovered to be extensionally equivalent to the target attribute . The baseline version of HAMB used to test these heuristics omitted this use of domain knowledge and allowed the generation of 2,897 ( 1,367 % ) additional non novel rules . The regular version of HAMB induced 212 rules , whereas the baseline no domain knowledge version induced 3,936 rules , most of them uninteresting . Thus , HAMB was able to use domain knowledge to avoid the creation of 3,724 uninteresting rules . In addition HAMB only required 5,030 discovery cycles to finish , while the baseline no domain knowledge version required approximately 45,000 cycles .
46 Evaluation of generality
To evaluate the generality of the system , we used HAMB to perform discovery from a second database : 930 cases of patients in rehabilitation after a medical disability , such as stroke or amputation . There are 11 attributes in the database , ranging from demographic data to admission and discharge scores of the patients’ functional independence . Thus , this database represents a domain that is dissimilar to the macromolecule crystallization domain .
After running HAMB with these data , we presented HAMB ’s discoveries to the physician who provided us with the data , Dr . Louis Penrod of the University of Pittsburgh Medical Center . He decided that there were 26 ( 9 % ) Category III discoveries ( novel and significant ) , of which 2 were bordering on Category IV ( revolutionary ) , 5 ( 2 % ) were Category II discoveries ( non novel , but significant ) , 53 ( 18 % ) were Category I
7 discoveries ( novel and marginally interesting ) , and 215 ( 71 % ) were uninteresting . Note that because of the smaller number of attributes , we were able to represent almost all of the known relationships among the attributes , which HAMB ’s heuristics were able to use to greatly reduce the number of Category II ( non novel , but significant ) discoveries .
Our conclusion from this study is that the heuristics are general enough to make significant discoveries from two dissimilar domains .
5 . Discussion
Our experiments with HAMB demonstrate that the heuristics allowed HAMB to tailor its tasks to the data , such as being opportunistic by identifying better ruleinduction targets and postponing less promising lines of investigation in favor of more promising ones . The heuristics allowed HAMB to perform significantly better than randomly selecting tasks from the agenda . We also showed that our heuristics for inducing rule sets were able to use a variety of domain specific knowledge to avoid reporting a large proportion of uninteresting discoveries . Our evaluation of the generality of HAMB suggests that our heuristics are general .
51 Related work
When viewed along the spectrum of autonomy , “ single shot ” learning programs , such as linear regression , neural networks , or rule learning systems , have the least autonomy , followed by programs that automatically select their bias , such as COMBS and CLIMBS [ 7 ] , and multistrategy and KDD planning systems that may perform more than one task but require a user to examine their results and select new discovery goals . Then come intelligent assistant programs , such as Shen ’s assistant for defining metapatterns [ 8 ] , AIDE [ 9 ] , and IDEA [ 10 ] , which propose new tasks but still require a user to choose the next task and to select top level goals . Toward the end of this spectrum lies HAMB , which autonomously performs the entire discovery process ( after the datasets have been collected and verified ) .
52 Scaling up and future work
Future work involves devising more heuristics for autonomous discovery . Additional heuristics are needed to better take advantage of an autonomous discovery system ’s ability to perform more than one task , such as being able to use more than one task to evaluate its discoveries or to identify patterns that may be found by examining the results of more than one task , such as a group of cases that unexplicably behave differently for a variety of tasks . Sources of heuristics may be found in the KDD and machine learning literature , and additional ference Systems , 297 312 . New York , NY : Academic Press .
[ 5 ] Livingston , G . R . 2001 . A Framework for Autonomous Knowledge Discovery from Databases . PhD Diss . , Dept . of Computer Science , Univ . of Pittsburgh , Pittsburgh , PA .
[ 6 ] Hennessy , D . , Buchanan , B . , Subramanian , D . , Wilkosz , P . , and Rosenberg , J . 2000 . Statistical Methods for the Objective Design of Screening Procedures for Macromolecule Crystallization . Acta Crystallographica Section D : 817 827 .
[ 7 ] Provost , F . J . 1992 . Policies for the Selection of Bias in Inductive Machine Learning . PhD Diss . , Dept . of Computer Science , Univ . of Pittsburgh , Pittsburgh , PA .
[ 8 ] Shen , W M and Leng , B . 1996 . A MetapatternBased Automated Discovery Loop for Integrated Data Mining . IEEE Trans . on Knowledge and Data Engineering 8(6 ) : 898 910 .
[ 9 ] Amant , R . S . and Cohen , P . R . 1997a . Evaluation of a Semi Autonomous Assistant for Exploratory Data Analysis . In Proc . of the First Intl . Conf . on Autonomous Agents , 355 362 , Marina Del Rey , CA , Feb . 58 . ACM Press .
[ 10 ] Bernstein , A . and Provost , F . 2001 . An Intelligent Assistant for the Knowledge Discovery Process . In Proc . of the IJCAI 01 Workshop on Wrappers for Performance Enhancement in KDD , Seattle , WA , Aug . 4 . Morgan Kaufmann .
[ 11 ] Darden , L . 1991 . Theory Change in Science . Ox ford : Oxford Univ . Press . sources may be found in the writings of philosophers of science , such as [ 11 ] , who have studied discovery for hundreds of years .
6 . Conclusions
Our experiments suggest that heuristics are sufficiently powerful and flexible for suggesting new tasks to perform and for providing reasons and the strengths of those reasons for performing them .
We presented heuristics for keeping the values of the properties and relationships of the items sufficiently upto date and heuristics for choosing rule induction targets ; these heuristics allow the identification of targets for which rule sets with better or worse generalization scores on a test database may be induced . We also presented heuristics for use in fully autonomous discovery programs for proposing the next task to perform and providing justifications for performing those tasks . Finally , we presented heuristics for inducing rule sets which are able to use a variety of domain specific knowledge to avoid inducing a large proportion of uninteresting rules . Our evaluations of these heuristics suggest that they are valid and general . We believe that these heuristics may be used as the starting point for further research into heuristics for autonomous discovery systems .
7 . Acknowledgments
We thank John Aronis , Tom Fawcett , David Jensen , Foster Provost , and anonymous reviewers for their numerous discussions and suggestions . This work was funded in part by grants from the National Library of Medicine ( 1 G08 LM006625 01 , the National Center for Research Resources ( RR14477–2 ) , and the National Science Foundation ( 9412549 ) .
References
[ 1 ] Livingston , G . R . , Rosenberg , J . M . , and Buchanan , B . G . 2001 . Closing the Loop : An Agenda and Justification Based Framework for Selecting the Next Discovery Task to Perform . To appear in Proc . of the 2001 IEEE Intl . Conf . on Data Mining , San Jose , CA . IEEE Computer Society Press .
[ 2 ] Zytkow , J . M . 1993 . Introduction : Cognitive Autonomy in Machine Discovery . Machine Learning 12 : 716 .
[ 3 ] Provost , F . J . and Buchanan , B . G . 1995 . Inductive Policy : The Pragmatics of Bias Selection . Machine Learning 20(1 ) : 35 61 .
[ 4 ] Buchanan , B . G . and Mitchell , T . 1978 . ModelDirected Learning of Production Rules . In Waterman , D . A . and Hayes Roth , F . , Eds . , Pattern Directed In
8
