QMapper : A Tool for SQL Optimization on Hive Using
Query Rewriting
Yingzhong Xu1,2,3 xuyingzhong@ictaccn
Songlin Hu2,3 husonglin@ictaccn
1University of Chinese Academy of Sciences , China
2Institute of Computing Technology , Chinese Academy of Sciences , China 3State Key Laboratory of Software Engineering , Wuhan University , China
ABSTRACT Although HiveQL offers similar features with SQL , it is still difficult to map complex SQL queries into HiveQL and manual translation often leads to poor performance . A tool named QMapper is developed to address this problem by utilizing query rewriting rules and cost based MapReduce flow evaluation on the basis of column statistics . Evaluation demonstrates that while assuring the correctness , QMapper improves the performance up to 42 % in terms of execution time .
Categories and Subject Descriptors H24 [ Database Management ] : Systems—Parallel databases , Query processing
Keywords SQL ; Hive ; MapReduce ; Query Rewriting
1 .
INTRODUCTION
MapReduce provides a highly simplified programming model , allowing users to run their programs distributedly by implementing Mapper and Reducer functions without caring about the data placement and task scheduling . Hive was in turn developed to provide HiveQL as a high level language interface and automatically translate it into MapReduce workflows . Both of them are very popular in emerging applications and have been widely used in Internet companies to deal with big data problem [ 3 ] . However , when engineers seek to utilize Hive to accelerate analysis applications that previously implemented in RDBMS , they will face the difficulties of migrating current SQL to HiveQL , which is time consuming and neither the correctness nor the performance of the results could be easily guaranteed .
Automatic translation and optimization of SQL to MapReduce mapping attracts lots of attentions from both industry and academia . Current works either adopt a rule based approach to guide the mapping procedure as done by Google Tenzing or optimized the translation by merging MapReduce jobs to reduce the number of jobs [ 3 ] . Both of them focus on optimization at MapReduce level , while ignoring the varieties of the SQL query and their influences on query performance . In this paper , we design a query rewrite based tool
Copyright is held by the author/owner(s ) . WWW 2013 Companion May 13–17 , 2013 , Rio de Janeiro , Brazil . ACM 978 1 4503 2038 2/13/05 . which applies a series of rewriting rules to SQL/HiveQL to guide SQL to HiveQL translation and provides a cost based plan evaluator to choose the optimized equivalent one .
2 . METHODOLOGY
SQL s
G
A n D
R P la
M
End User
HiveQL
HiveQL Queries
Table Statistics
Query Graph Model
We divide the process of QMapper into three phases . For QMapper a given SQL query , it is firstly parsed by SQL Interpreter into Query Graph Model ( QGM ) . Then , Query Rewriter applies two series of rules ( S H and H H ) to the QGM to generate equivalent queries . S H rules are applied to transforFigure 1 : Architecture m the unsupported operators such as ( NOT ) EXISTS to acceptable form of Hive . Followed by H H rules that are adopted to generate equivalent HiveQL queries , for instance , exchanging join orders and marking the joining on small tables as map join . Finally , these HiveQL queries generated from the adjusted QGMs are compiled into MapReduce DAGs ( direct Direct acyclic graph consists of a set of MapReduce jobs ) by Query Compiler . A Plan Evaluator is utilized for estimating these DAGs , so as to identify the best equivalent one . 2.1 Query Rewriting
Query rewriting aims at generating more equivalent candidate HiveQL queries and increasing the probability of triggering more optimization mapping rules . The more candidates are available , the more chances to find the optimal solution . In QMapper , many well studied rules [ 1 ] were leveraged for translation , and the rewriting rule itself is pluggable to make it easy to extend . Moreover , since query rewriting is performed outside Hive , it can also work together with MapReduce level optimizers .
Consider the following example which retrieves all Shipments information of the P arts stored in Rio or provided by Suppliers in the same city .
SELECT * FROM Shipments SP WHERE EXISTS ( SELECT 1 FROM Suppliers S WHERE SSNO=SPSNO AND S.city = ’Rio’ ) OR EXISTS ( SELECT 1 FROM Parts P Where SPPNO=PPNO AND P.city=’Rio’ )
QMapper will generate a variety of versions of HiveQL that can yield the same results . One version is to divide the two disjunctive predicates into separate SEMI JOIN and then perform an UNION ALL . Another version is to transform
211 the EXISTS to LEFT OUTER JOIN and replace itself with joinkey IS NOT NULL . The first one uses SEMI JOIN so that it can remove unnecessary tuples earlier than OUTER JOIN . However , a tuple may satisfy two predicates at same time , and this might bring about duplicates after UNION ALL . Thus , an additional operation is added by QMapper to eliminate the duplicates .
These two execution plans vary a lot and lead to different performance , but it is difficult to intuitively judge which version is cheaper . In order to find the best choice , cost estimation and automatic selection is supported in QMapper . 2.2 Cost Estimation
It is known that the cost formula used in centralized database is not suitable for Hive[2 ] . Particularly , the intermediate data between Mapper and Reducer or among individual jobs is materialized to disk and transferred via network , and should be considered as a key aspect of cost in IO intensive Hive . Besides , Hive .a´rs optimizer will seek for the chances to merge jobs , eg joining 3 tables within a single job when they join on the same key , which also need new cost model . QMapper estimator is thus implemented to estimate the cost of MapReduce DAGs . i i i
} . I M|R represents the output data of M RM|R
= {I M|R represents the input data of M RM|R . P M|R
A MapReduce DAG consists of a set of MapReduce jobs as nodes , the directed edge between jobs indicates the data flow . A job is composed of Map and Reduce . Each Map and Reduce is considered as a tuple . M RM|R , P M|R , i OM|R , and OM|R is also a DAG representing the internal operators of Map and Reduce . In order to calculate the cost , we define a profile for each M RM|R and P M|R to describe the data set being processed . The input or output data profile of an operation is } where noted as P rof ileM|R|P ctM|R|P I|Oi repre
I|Oi = {ctM|R|P I|Oi
, P rof ileM|R|P I|Oicol(x ) is the number of tuples and P rof ileM|R|P I|Oicol(x ) i i i i i i i sents the profile of columns in the data . Besides the columnlevel metrics mentioned in [ 2 ] , we add ab(Average bytes ) for estimating data volumes and quartile value for predicating selectivity . The P rof ileM Ii of the Maps that use hive tables as input is initialized with table statistics which is collected periodically at background or while loading data . In order to propagate P rof ileM|R|P which is the profile of output data generated by map , reduce or internal operations based on P rof ileM Ii , we extend the work in [ 4 ] to apply profile estimation to the operators within Map and Reduce .
Oi
Cost(M R ) = m . i=1
( ctM Ii
× y . x=1 abM
Iicol(x )
+ ctR Ii
× y . x=1 abR
Iicol(x )
)
After the calculation of all profiles of Map and Reduce , QMapper measures the amount of intermediate data generated between Maps and Reduces as well as that produced among different jobs . The best solution with minimize cost is finally selected .
3 . EXPERIMENTS
We evaluated our system on a cluster consisting of 13 nodes , each of them has 8 cores and 16GB RAM . All nodes use CentOS 6.2 , Java 160 22 and hadoop101 The latest Hive 0100 was deployed and 15GB TPC H data set was generated as workload . We choose relatively complex queries : Q2 ,
Q18 and Q10 from TPC H , which provide opportunities to generate more equivalent queries to verify the effectiveness of QMapper .
Figure 2 : Execution time Figure 3 : Cost estimation
We compared the execution time of 3 SQL queries translated manually in the most direct way with that translated by our tool and YSmart respectively . Figure 2 shows that an average performance improvement of 20.2 % is gained by QMapper , while YSmart is not able to optimize these queries . Figure 3 indicates the total cost estimation of optimized queries and the original ones . As shown in Figure 3 , the intermediate data generated between each job is reduced by 89.7 % for query Q2 , and that is why 41.7 % of execution time is saved . For Q8 and Q10 , their performance are improved by 8.9 % and 10.2 % respectively , in that their structures have been already close to the optimized queries and the input tables are too big compared to the intermediate data set , thus a saving on intermediate data does not help much .
4 . CONCLUSION AND FUTURE WORK
A tool for translating SQL queries to optimized HiveQL is introduced together with its two key components : Query Rewriter and Plan Evaluator . We are extending the Rewriter to support more rules and enhancing the estimator to involve the parallelism of multiple SQL blocks , data compression and the difference of cost effect between Map and Reduce to provide a more fine grained cost model . SQL Optimization of HiveQL compatible system , like Shark , is also our future work .
5 . ACKNOWLEDGMENTS
For the completion of this research , we would like to thank the National Natural Science Foundation of China under Grant No.61070027 , 61020106002 , 611611605 . This work is also supported by State Key Laboratory of Software Engineering ( SKLSE2012 09 02 ) .
6 . REFERENCES [ 1 ] U . Dayal . Of nests and trees : A unified approach to processing queries that contain nested subqueries , aggregates , and quantifiers . In Proc . VLDB . Morgan Kaufmann Publishers Inc . , 1987 .
[ 2 ] A . Gruenheid , E . Omiecinski , and L . Mark . Query optimization using column statistics in hive . In Proc . IDEAS . ACM , 2011 .
[ 3 ] R . Lee , T . Luo , Y . Huai , F . Wang , Y . He , and
X . Zhang . Ysmart : Yet another sql to mapreduce translator . In Proc . ICDCS , pages 25–36 . IEEE , 2011 .
[ 4 ] M . V . Mannino , P . Chu , and T . Sager . Statistical profile estimation in database systems . ACM Comput . Surv . , 20(3):191–221 , Sept . 1988 .
212
