Estimating Clustering Coefficients and Size of Social
Networks via Random Walk
Stephen J . Hardiman∗ Capital Fund Management ,
France hardimas@tcd.ie
ABSTRACT Online social networks have become a major force in today ’s society and economy . The largest of today ’s social networks may have hundreds of millions to more than a billion users . Such networks are too large to be downloaded or stored locally , even if terms of use and privacy policies were to permit doing so . This limitation complicates even simple computational tasks . One such task is computing the clustering coefficient of a network . Another task is to compute the network size ( number of registered users ) or a subpopulation size . The clustering coefficient , a classic measure of network connectivity , comes in two flavors , global and network average . In this work , we provide efficient algorithms for estimating these measures which ( 1 ) assume no prior knowledge about the network ; and ( 2 ) access the network using only the publicly available interface . More precisely , this work provides three new estimation algorithms ( a ) the first external access algorithm for estimating the global clustering coefficient ; ( b ) an external access algorithm that improves on the accuracy of previous network average clustering coefficient estimation algorithms ; and ( c ) an improved external access network size estimation algorithm .
The main insight offered by this work is that only a relatively small number of public interface calls are required to allow our algorithms to achieve a high accuracy estimation . Our approach is to view a social network as an undirected graph and use the public interface to retrieve a random walk . To estimate the clustering coefficient , the connectivity of each node in the random walk sequence is tested in turn . We show that the error of this estimation drops exponentially in the number of random walk steps . Another insight of this work is the fact that , although the proposed algorithms can be used to estimate the clustering coefficient of any undirected graph , they are particularly efficient on social network like graphs . To improve the network size prior art estimation algorithms , we count node collision one step before they actually occur . In our experiments we validate our algorithms on several publicly available social network datasets . Our results validate the theoretical claims and demonstrate the effectiveness of our algorithms .
∗
Research was conducted while the author was unaffiliated .
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author ’s site if the Material is used in electronic media . WWW2013 , May . 13 17 , Rio de Janeiro , Brazil ACM 978 1 4503 2035 1/13/05 .
Liran Katzir
Advanced Technology Labs , Microsoft Research , Israel lirank@microsoft.com
Categories and Subject Descriptors F22 [ Theory of Computing ] : Analysis of Algorithms and Problem Complexity—Nonnumerical Algorithms and Problems General Terms Algorithms Keywords Estimation , Sampling , Clustering Coefficient , Social Network
1 .
INTRODUCTION
The popularity of online social networks has grown enormously in recent years . Users of the most popular social network , FacebookTM , now number greater than a billion1 . This popularity has increased interest in analyzing the properties of these networks . In [ 2 , 13 , 21 ] the authors investigate structural measures of online social networks , including degree distribution and clustering coefficient .
Large social networks , as well as search engines , provide a public interface as part of their service . Estimating structural measures of the network using only these public interfaces is a research question that has received much attention in recent studies . Search engine public interfaces have been used in [ 6 , 8 ] to estimate corpus size , index freshness , and density of duplicates , and in [ 7 ] estimate the impressionrank of a webpage . Online social network public interfaces have been used in [ 13 , 14 , 25 ] to estimate the assortativity coefficient , degree distribution , and clustering coefficients of online social networks , as well as in [ 14 , 15 ] to estimate the number of registered users .
In practical scenarios , the underlying social network may be available only through a public interface . The public interface of most social networks provides the ability to retrieve a list of a user ’s connections ( “ friends ” ) . By applying this function iteratively to a random member of the connection list one can effectively perform a random walk on the network . Although the public interface allows us to store the social network locally , this practice is considered impractical due to high time/space/communication cost and often violates the terms of use agreement . In light of this , in this paper we proceed under the assumption that ( 1 ) only external access to the social network is available ; and ( 2 ) only a small number of users/nodes can be sampled . The main
1http://newsroomfbcom/News/457/One Billion Peopleon Facebook
539 insight offered by this work is that , even under these limitations , our algorithms achieve a good estimation accuracy of the network ’s structural measures .
This work focuses on two particular structural measures . The first measure is called the clustering coefficient . The second measure is the size of the network . Namely , the number of registered users in the network2 .
The clustering coefficient comes in two main flavors , ( 1 ) the network average clustering coefficient [ 12 ] ; and ( 2 ) the global clustering coefficient [ 12 ] . Both measures are important for the understanding of the network structure . First , we introduce the local clustering coefficient of a node in a graph as the ratio of the number of edges between its neighbors to the maximal possible number of such edges . The network average clustering coefficient of a graph is the local clustering coefficient averaged over the set of nodes in the graph . The global clustering coefficient of a graph is the ratio of the number of triangles ( ordered triples of different nodes in which are all nodes connected ) to the number of connected triplets ( ordered triples of different nodes in which consecutive nodes are connected ) .
The size of the network is one of the basic structural measures . The network size can determine the worth of a network ( for business development ) . For certain applications in business development and advertisement , the size of a social network subpopulation is extremely important . For example , the number of users of an online product or the number of potential users for a product . The subpopulation fraction ( which can also be estimated efficiently [ 15 ] ) and the network size can determine the size of the subpopulation . Although some networks report their size periodically , the difference between consecutive reports can be more than ten percent . Moreover , even if this number is reported every day , an unbiased independent estimate would be beneficial . This work contains three main contributions . The first and principal contribution is the first external access estimator for the global clustering coefficient . The second contribution is an improved external access estimator for the network average clustering coefficient . The third contribution is an improved external access estimator for the network size .
The rest of this paper is organized as follows . Section 2 surveys related work . Section 3 provided preliminaries and notations . Section 4 details our clustering coefficient estimators . Section 5 details our network size estimator . Section 6 reports our experimental results . We conclude the paper in Section 7 .
2 . BACKGROUND AND PRIOR WORK
We consider the social network as an undirected graph where nodes and edges are represented by users and friendship connections . Although the algorithms presented in this paper are correct for general graphs , the structure of social networks renders them even more effective .
Both the network average and the global clustering coefficient ( also known as transitivity ) are a long studied classical computer science problem . The running time of the naive algorithm for computing them is O(n3 ) for dense graphs ( where n is the number of nodes in the graph ) , and it is considered impractical for large graphs . For the global cluster
2Technically , the algorithm estimates the size of the largest connected component and isolated users are neglected . ing coefficient , the most challenging part of the computation is counting the total number of triangles , since computing the number of connected triplets is done in linear time . To this end , the computation of global clustering coefficient and the computation of the number of triangles is equivalent .
We provide references for a partial list ( most recent ) for several directions for estimating the number of triangles . Alon et al . [ 3 ] provided an exact algorithm for the counting the number of triangles . The running time of this al2ω ω+1 ) = O(E1.41 ) , where ω < 2.376 is the gorithm is O(E exponent of matrix multiplication . Avron [ 4 ] provided an estimator based on numerical matrix vector multiplication using O(log2 n ) samples , each of which requires O(|E| ) time ( where E is the set of nodes in the graph ) . Both these algorithm access the entire graph .
Buriol et al . [ 10 ] provided an approximate solution to the global clustering coefficient in the streaming model . The streaming models allows the algorithm to have a single pass on the input while ( 1 ) reading the edges in arbitrary/vertex ordered appearance ( different algorithms ) and ( 2 ) use constant amount of space . Becchetti et al . [ 9 ] provided an algorithm for the network average clustering coefficient in the streaming model . In contrast to [ 3 , 4 ] these works assume there is no random access to the graph . However , the streaming algorithms access each edge at least once .
Schank et al . [ 27 ] , provided estimators for both the global and network average clustering coefficient which only uses a sample of the nodes . However , unlike our work , the algorithms assume there is an efficient way to sample nodes with distribution that is tailored to the clustering coefficient . Specifically , for the network average clustering coefficient the sampling distribution is the uniform distribution and for the global clustering coefficient each node vi with degree di is sampled proportionally to di(di − 1 ) . In contrast , the algorithms provided in this work do not even assume the number of nodes is known and does not require a tailored sampling distribution .
Another research direction [ 13 , 25 ] addresses the problem of estimating the local clustering coefficient with external access3 . In these papers , the graph can only be accessed via the exploration of nodes that lie on the frontier of previously explored nodes . Ribeiro et al [ 25 ] explored the graph using a random walk . Gjoka et al . [ 13 ] explored the graph using Metropolis Hastings random walk that generates uniform samples from the nodes set . In both these papers , the computation requires augmenting the set of explored nodes , S , with further exploration of S ’s ego network . An ego network of a set of users S , is the set of users Sfi that contains all the users in S and all their ( immediate ) friends [ 13 , 28 ] . In this work , we perform a random walk but remove the requirement of exploring the ego network . This difference is illustrated in Figure 1 . The random walk contains three nodes v1 , v2 , v3 . Our approach requires the exploration of the nodes v1 , v2 , v3 ( marked by a thick circle ) , the ego network approach requires additional exploration of the nodes v4 , v5 , v6 . In total the ego network requires exploration of all the nodes v1 , v2 , . . . , v6 ( marked by solid fill ) . In section 6 , we show that the algorithm provided in this paper
3Ref [ 25 ] mistakenly refers to the global clustering coefficient , but provides an accurate definition of the network average clustering coefficient .
540 va vb vc in random walk in ego network visible by random walk and ego network visible by ego network only beyond reach visible by neither v3 v5 v7 v1 v2 v9 v4 v6 v8 number of samples needed to guarantee convergence for a fixed accuracy is O(n1/4 log n ) [ 15 ] .
In some applications the size of a subpopulation needs to be estimated . This subpopulation is defined by a property of the user ’s profile . For example , the number of registered users who use a specified online product . Estimating the size of a subpopulation requires multiplying the total size of the network by the ratio the target nodes to the total nodes which could also be estimated by the random walk [ 15 ] . In this work , we improve the network size estimation algorithms by using not only the visited node ids , but also the adjacency list of each of the visited nodes . This is done by counting node collision one step before they actually occur . Namely , two nodes on the random walk ( enough nodes apart ) that share a connection . We call this collision a neighbor collision .
Figure 1 : An example of a random walk with its corresponding ego network augmentation . outperform competing approaches [ 25 , 13 ] on all the social networks we study .
Another method for estimating the clustering coefficient from a random walk was presented in [ 14 ] . This algorithm uses only the ids of nodes visited by a random walk and does not assume any prior information . In contrast , the algorithms in this paper assume not only the node ids are visible , but also their list of friends ( adjacency list ) . Practically , if this assumption holds , it renders [ 14 ] uncompetitive . In this work , two estimators are provided for the clustering coefficient . The first for the network average clustering coefficient and the second for the global clustering coefficient . Both estimators use samples taken from a random walk on the graph . Namely , not only that the algorithms do not access the entire graph , they do not even have random access to the graph ’s nodes and edges . The only assumption is that a random walk can be performed via the public interface , and the visited node ids along with their list of friends ( adjacency list ) . This is the case for many social networks . Indeed , the act of performing a random walk at all in an online social network typically necessitates having access to this information .
Both [ 14 , 15 ] provide estimators for the total number of registered users in the network . These algorithms use only the node ids visited on the random walk and do not assume any prior information on the graph . The underlying idea in both papers is to count node collision , a pair of indices ( k , l ) such that the same node appears in the kth and lth location of the random walk . Nodes on the random walk are highly correlated when their index distances ( |k − l| ) are short , which increases the probability of a node collision . To ensure a unified probability of collision across all node pairs , a collision is counted only if the nodes appear a significant number of steps apart . These works differ in the way they select these pairs . In [ 15 ] the estimator chooses all pairs in which both k and l are a multiple of a parameter m , while [ 14 ] chooses all pairs in which m ≤ |k − l| . Choosing all pairs [ 14 ] is practically better , but harder to analyze . The convergence of social network like graphs is very fast and depends on the degree distribution . For example , if the node degrees are distributed according to a Zipfian distribution n and parameter α = 2 , then the with maximum degree of
√
3 . PRELIMINARIES AND NOTATIONS We denote by G(V , E ) the social network ’s underlying undirected graph , where V = {v1 , v2 , . . . , vn} is the set of nodes ( users ) and E is the set of edges ( friendship connections ) . Additionally , we denote by di the degree of node i=1 di = 2|E| . The vi and the sum of degrees by D = maximum degree of a node in the graph is noted by dmax = i=1 di . maxn We denote by an n× n matrix A the adjacency matrix for graph G . Namely , Ai,k = Ak,i = 1 if node vi is connected by an edge to node vk and 0 otherwise . We assume no self loops , thus Ai,i = 0 for all i .
. n
Definition 1 . A triplet of nodes ( vj , vi , vk ) is called connected if vj is connected to vi , vi is connected to vk , and j < k . Formally , if Aj,i = 1 , Ai,k = 1 , and j < k .
Definition 2 . A triangle is a connected triplet ( vj , vi , vk ) in which vj and vk are connected . Formally , if Aj,k = 1 .
.
.
Following these definitions , a triplet of nodes is connected if j < k and Aj,iAi,k = 1 and it is a triangle if j < k and Ai,jAi,kAj,k = 1 . For a specific node vi , the number of connected triplets ( vj , vi , vk ) is thus Aj,iAi,k . Note Aj,iAi,k = di(di−1)/2 since there are di(di−1)/2 that choices for j < k in which both Aj,i = 1 and Ai,k = 1 . For a specific node vi , the number of ( vj , vi , vk ) triangles is denoted by li = Ai,j Ai,kAj,k ( it is also the number of edges between neighbors of vi ) .
. j<k j<k j<k
Definition 3 . The local clustering coefficient [ 12 ] for node vi , denoted by ci , is defined as the ratio of the number of ( vj , vi , vk ) triangles to the number of ( vj , vi , vk ) connected triplets . Formally , ci =
2li di(di − 1 )
Note that ci ∈ [ 0 , 1 ] . In the case where di = 1 or di = 0 , we have ci = 0 .
Definition 4 . The network average clustering coefficient
[ 12 ] , denoted by cl , is defined by nfi cl =
1 n ci i=1
541 Definition 5 . The global clustering coefficient [ 12 ] , denoted by cg , is defined as the ratio of the total number of triangles to the total number of connected triplets . Formally ,
.
. i=1 li i=1 di(di − 1 )
2 n n cg =
Note that a set of three nodes {vj , vi , vk} forms three different triangles4 one is counted in lj , a second in li , and a third in lk .
The first step of the estimation algorithms is to generate a random walk . A random walk with r steps on G , denote by R = ( x1 , x2 , . . . , xr ) , is defined as follows : start from an arbitrary starting node vx1 , then move to one of the neighboring nodes uniformly at random ( with probability 1 ) and repeat r − 1 times . We use Pr [ A ] to denote the probdxi ability that event A occurred . We denote the distribution induced by R , as
πR = ( Pr [ xr = 1 ] , Pr [ xr = 2 ] , . . . ,Pr [ xr = n ] ) .
The probability Pr [ xr = i ] after many random walk steps converges to pi . di/D and the vector π = ( p1 , p2 , . . . , pn ) is called the stationary distribution of G .
In our estimators , we assume that x1 is drawn from the stationary distribution5 . This assumption is valid because we can always perform an initial random walk from an arbitrary node to draw a starting node from the stationary distribution .
The actual number of steps needed to converge to the stationary distribution depends on the mixing time of G . There are several definitions of mixing time , many of which are known to be equivalent up to constant factors . All definitions take an parameter to measure the distance between the stationary and the induced distribution . Both the book [ 17 ] and the survey [ 19 ] provide excellent overview on random walks and mixing times . We denote the mixing time of graph G by τ ( ) or τ ( is assumed to be a small constant ) . We use the following definition :
Definition 6 . Let R = ( x1 , x2 , . . . , xr ) be a random walk . Then , let the distance between π and πR be the maximum difference between the probability of drawing a specific node xr over all possible choices of nodes x1 and xr . Namely , d(r ) = n n max x1=1 max i=1
|pi − Pr [ xr = i]| .
We have τ ( ) = min {r | d(r ) ≤ } . be r = log2 n for the Facebook network , r = 3 log2 n for the DBLP and youtube networks , and r = 10 log2 n for the Live Journal network . Both the low mixing time and the relatively high value of the clustering coefficients enable the clustering coefficient estimation algorithms in this paper to provide accurate result with relatively low number of samples . Notations are summarized in Table 1 .
G n A vi di D r xk pi π li cl cg ˆcl ˆcg ˆn τ ( ) dmax underlying undirected graph number of nodes in the graph adjacency matrix for G . degree of node vi the sum all nodes degrees node in G n i=1 di total number of steps in the random walk the index of kth node in the random walk p(xk = i ) = di D the stationary distribution ( p1 , p2 , . . . , pn ) number of edges between neighbors of vi network average ( local ) clustering coefficient global clustering coefficient cl estimation cg estimation n estimation mixing time i=1 di maxn
Table 1 : Summary of notations
4 . CLUSTERING COEFFICIENT ESTIMA
TION
We now present the main observation used in both network average and global clustering coefficient estimators . Given a random walk ( x1 , x2 , . . . , xr ) , we define a new variable φk = Axk−1,xk+1 for every 2 ≤ k ≤ r − 1 . For any function f ( xk ) the following holds6 :
E [ φkf ( xk ) ] =
=
= i=1 nfi nfi nfi i=1 i=1 piE [ φkf ( xk)|xk = i ] di D
1 D
2li d2 i
2li di f ( vi ) f ( vi ) .
( 1 )
Social network graphs are known to have low mixing times and constant clustering coefficients ( which are not extremely small ) . Recently , Addario Berry et al [ 1 ] proved rigorously that the mixing time of Newman Watts [ 23 , 24 ] small world networks is Θ(log2 n ) . Mohaisen et al . [ 22 ] provide numerical evaluation of the mixing time of several networks . The authors claim that “ the mixing time is much larger than anticipated ” . However , Table 1 and Figure 2 in their paper show that to have d(r ) ≈ 0 , the number of steps should 4In some references a triangle is defined by an unordered set of three nodes , in which case cg is defined by three times the ratio of the total number of triangles to the total number of connected triplets . 5This is not necessary in practice . However , the running time bound is tighter with this assumption .
The first equality holds due to the law of total expectation . The second equality holds because there are d2 i equal probability combinations of ( xk−1 , vi , xk+1 ) out of which only 2li form a triangle ( vj , vi , vk ) or a reverse triangle ( vk , vi , vj ) . Notice that in a triangle or a reverse triangle vj is connected to vk ( Aj,k = 1 ) . The third equality holds due to algebraic manipulation . 4.1 Network average clustering coefficient
To estimate cl , we introduce two variables . First , we de1 fine Φl as a weighted sum of φjs , Φl = 1 −1 . r−2 dxk Second , we define Ψl as the sum of the sampled nodes reciprocal degrees , Ψl = 1 r 6We choose f ( vi ) = 1/ ( di − 1 ) for the network average clustering and f ( vi ) = di for the global clustering estimator . r−1 k=2 φk
.
1 dxk r k=1
.
.
542 Using linearity of expectation and Eq ( 1 ) it is easy to
' ' compute Φl and Ψl expectation . ff nfi
E [ Φl ] = E
E [ Ψl ] = E
φk
1 − 1 ff dxk nfi
1 dxk
= i=1
1 D
2li di(di − 1 ) n D
= i=1 di D
1 di
= nfi i=1 ci
=
1 D
From the above equations we can isolate cl and get that : nfi i=1 cl =
1 n ci =
E [ Φl ] E [ Ψl ]
Intuitively , both Φl and Ψl converge to their expected values and the estimator Φl/Ψl converges to cl as well .
Definition 7 . Let ˆcl be the estimator for cl , defined as follows :
ˆcl . Φl Ψl
.
Lemma 1 . For any ≤ 1/8 and δ ≤ 1 we have :
Pr[cl(1 − ) ≤ ˆcl ≤ cl(1 + ) ] ≥ 1 − δ when the number of samples , r , satisfies : r ≥ rl ∈ O
D ncl
τ ( )
.
Proof . The proof first finds the number of step , rl , which guarantees both Φl and Ψl be within /3 approximations to their expected values with probability at least 1 − δ/2 . See Appendix A for more details . Since the probability of Φl or Ψl deviating from their expected value is at most δ/2 , the probability of either Φl or Ψl deviating is at most δ ( using the union bound ) . Then , we use the fact that
( 1− )cl ≤ ( 1 −
3 ) ( 1 + 3 )
E [ Φl ] E [ Ψl ]
≤ Φl Ψl
≤ ( 1 + 3 ) ( 1 − 3 )
E [ Φl ] E [ Ψl ]
≤ ( 1 + )cl to complete the proof .
Note that for social network like graph the mixing time is assumed to be relatively low ( for Newman Watts networks τ ( ) = O(log2 n ) [ 1] ) , D = O(n ) and cl is a small constant . Thus , the number of steps needed is linear in the mixing time , τ ( ) . 4.2 Global Clustering Coefficient
To estimate cg , we introduce two variables . First , we der−1 fine Φg as a weighted sum of φjs , Φg = 1 k=2 φkdxk . r−2 Second , we define Ψg as the sum of the sampled nodes degrees minus one , Ψg = 1 r k=1 dxk
− 1 .
.
Using linearity of expectation and Eq ( 1 ) it is easy to r
. compute Φg and Ψg expectation .
E [ Φg ] = E [ φkdxk ] =
E [ Ψg ] = E [ dxk
− 1 ] = nfi nfi i=1
1 D i=1 nfi i=1
1 D di =
2li di D ( di − 1 ) = di
2li nfi i=1 di(di − 1 )
1 D
From the above equations we can isolate cg and get that : cg =
1 . i=1 di(di − 1 ) n nfi i=1
2li =
E [ Φg ] E [ Ψg ]
.
Intuitively , both Φg and Ψg converge to their expected values and the estimator Φg/Ψg converges to cl as well .
Definition 8 . Let ˆcg be the estimator for cg , defined as follows :
ˆcg . Φg Ψg
.
Lemma 2 . For any ≤ 1/8 and δ ≤ 1 we have :
Pr[cg(1 − ) ≤ ˆcg ≤ cg(1 + ) ] ≥ 1 − δ when the number of samples , r , satisfies : Ddmax i=1 di(di − 1 ) n r ≥ rg ∈ O
. cg
τ ( )
.
The proof is similar to the proof of Lemma 1 , except the number of steps rg that guarantees convergences for Φg and Ψg is different . See Appendix B for more details .
Both estimators presented in this section are consistent . Formally , as the number of samples , r , grows the estimators converge to the true value . This also implies the estimators are asymptotically unbiased .
5 . NETWORK SIZE ESTIMATION
In this section we present an estimator for the graph size ( number of nodes ) . The estimator uses observations of node pairs which are “ far away ” from each other in the random walk ( as in Ref [ 14] ) . This assumption is needed to ensure both nodes in a pair are ( approximately ) uncorrelated : each drawn from the stationary distribution7 . Specifically , the estimator examines node pairs whose index distance is greater than a threshold m . Formally ,
I = {(k , l ) | m ≤ |k − l| ∧ 1 ≤ k , l ≤ r} .
The estimator counts weighted neighbor collisions . A neigh bor collision is a pair of indices ( k , l ) such that vxk and vxl share a common neighbor . Formally , let Ai be the set of vertices adjacent to vi . Thus , Ai ∩ Aj is the set of nodes neighboring both vi and vj . Given a random walk ( x1 , x2 , . . . , xr ) , | . Note that if we define a new variable φk,l = |Axk ( k , l ) ∈ I , then 2 ff '
∩ Axl di D dj D
|Ai ∩ Aj| 1 didj
= dj D
. nfi j=1 nfi j=1 nfi . i=1
E
φk,l
1 dxl dxk .
= n i=1 n j=1 |Ai ∩ Aj| = n
To see why j consider the following combinatorial proof . For a node vk , the number of connected triplets ( vi , vk , vj ) with no restrictions on i and . j is d2 k . Thus , the total number of connected triplets is k=1 d2 k . Alternatively , for nodes vi and vj the number of connected triplets ( vi , vk , vj ) is |Ai ∩ Aj| . Thus , the to . . tal number of connected triplets can also be expressed by n i=1 Next , we define Φn to be the averaged value of φk,l j=1 |Ai ∩ Aj| . over all possible choices of ( k , l ) ∈ I . Namely ,
1 dxk dxl n
. j=1 d2 n fi ( k,l)∈I
Φn =
1|I|
φk,l
1 dxl dxk
.
7The larger the value of m , the smaller the bias in the estimate introduced by this correlation , but increasing m means fewer observations of node pairs and a larger estimator variance . However , note that we again benefit from the fastmixing nature of social graphs , and m need only be of the order O(log2 n ) .
543 Let Ψn be the averaged sum of of ( k , l ) ∈ I . Formally , over all possible choices
Ψn =
1|I|
.
|I| Ψn =
. be efficiently computed for every k in O(1 ) , using a cumuk=1 dxk , lative sum precomputation . Specifically , if Bq = then q rfi l=1
1 dxl
Br − B(l+m)+ + B(l−m)− ff
.
To compute Φn one must first construct an inverted index of neighboring nodes . In document term view , each node is a document containing adjacent nodes as terms . Specifically if vj is a neighbor of xk then k is a term in vj . The running time of creating an inverted index is linear in the 2 d number of terms ( O(rdmax ) worst case and O(r . D ) exi pected ) . Then , the entry for vj holds a list Lj of all indices in which vj is a neighbor . Thus , |I| Φn = j=1 Cj , where . . To efficiently compute Cj Cj = in O(|Lj| ) , a precomputation Bq(j ) = should be used ( similarly to the computation of Ψn ) .
. ( k,l)∈I|k∈Lj∧l∈Lj
1 dxk dxl q≥k∈Lj
.
1 dxk n i=1 n
6 . EXPERIMENTAL EVALUATION
6.1 Networks with public dataset
We demonstrate the effectiveness of the estimators by experimenting with social networks with known structure . Datasets statistics are enclosed in Table 2 .
Network DBLP Orkut Flickr
Live Journal n
977,987 3,072,448 2,173,370 4,843,953
D/n 8.457 76.28 20.92 17.69 cl
0.7231 0.1704 0.3616 0.3508 cg
0.1868 0.0413 0.1076 0.1179
Table 2 : Networks statistics
In all our datasets we perform the following : ( 1 ) if the original network is directed , the direction is removed ( the edge is made undirected ) ; ( 2 ) only the network ’s largest connected component is retained and the rest of the nodes/users are dropped . All the datasets we use are publicly available9 .
DBLP In the “ Digital Bibliography and Library Project ” ( DBLP[18 ] ) dataset each entry is a reference to a paper which contains a title and a list of authors . In the corresponding network each node is an author and an edge between two authors represent co authorship of one or more papers . We used a snapshot taken Oct 01 , 2012 .
Orkut Orkut is a general purpose social network . The dataset contains a partial snapshot ( 11.3 % of the nodes ) taken during 2006 by [ 21 ] . In this social network the friendship connections ( edges ) are undirected .
Flickr Flickr is an online social network with focus on photo sharing . The dataset contains a partial snapshot taken during 2006–2007 by [ 20 ] . In this social network the friendship connections ( edges ) are directed .
9The DBLP , Orkut , Flickr , and LiveJournal are publicly and http://konectuni koblenzde/networks/{orkut links,flickrgrowth,soc LiveJournal1} [ 16 ] , respectivly . http://dblpuni trierde/xml/ available at dxk dxl fi ( k,l)∈I nfi ff dxk dxl dj D
2
' '
Due to linearity of expectation , we have
E [ Φn ] = E
E [ Ψn ] = E
φk,l dxk dxl
1 dxl dxk ff nfi
= nfi
= i=1 j=1 j=1 di D
2 nfi j=1 dj D dj D dj di
= n
Notice that n = E [ Ψn]/E [ Φn ] . Intuitively , both Ψn and
Φn converge to their expected values and the estimator Ψn/Φn converges to n as well .
Definition 9 . Let ˆn be the estimator for n , defined as follows :
ˆn . Ψn Φn
.
Prior art algorithm [ 14 , 15 ] count the number of node collisions , C , and estimates n by Ψn/C . A node collision is a pair of indices ( k , l ) such that such that xk = xl . In contrast Φn counts neighbor collision and estimates n by Ψn/Φn .
Lemma 3 . The neighbor collision estimator , ˆn ( definition 9 ) , has confidence intervals tighter than the node collision estimator .
Proof . Formally , C = 1|I|
( k,l)∈I 1xk=xl where 1xk=xl is 1 if xk = xl and 0 otherwise . The key observation is that )
(
1xk+1=xl+1 | xk , xl
E
= φk,l
1 dxl dxk
.
.
This stems from the combinatorial argument that ( a ) there are dxk dxl equally likely joint node transitions from xk and | of xl to xk+1 and xl+1 ; and ( b ) in only φk,l = |Axk them xk+1 = xl+1 holds . Note that , xk is uncorrelated with xl when ( k , l ) ∈ I . Using this observation we have , )
∩ Axl
(
1xk+1=xl+1 | xk , xl
.
E
Φn =
1|I| fi ( k,l)∈I
This is the Conditional Monte Carlo estimator8 of C , which guarantees Var [ C ] ≥ Var [ Φn ] [ 26](Section 54 ) 5.1 Implementation notes n i=1
.
2 d D ) . i
The straight forward computation of Ψn and Φn running time is O(r2 ) and O(r2d2 max ) respectively . However , a careful implementation can reduce this complexity to O(r ) and O(rdmax ) respectively . For Φn the expected running can be reduced to O(r First , we define ( l+m)+ to be min {r , l + m} and ( l−m ) − to be max {l − m , 1} . For the computation of Ψn instead of .(l+m)+ multiplying the value of 1 by each dxk separately , it is muldxl k=(l−m)− dxk . The sum in turn , can tiplied by the sum of 8Note that if ( k , l ) ∈ I , then ( k − 1 , l − 1 ) ∈ I except for k = 1 which holds only for a negligible fraction of the pairs .
544 LiveJournal LiveJournal is an on line social network with focus on journals and blogs . The dataset contains a partial snapshot of the nodes taken by [ 5 ] . In this social network the friendship connections ( edges ) are directed .
The x axis in our figures is the percentage of mined nodes ( number of mined nodes over the total number of network nodes ) . The y axis is the relative estimated value ( estimate value over the true value ) . We display [ 5 % , 95%]confidence intervals for all figures . A [ 5 % , 95%] confidence interval of random variable z , is defined as the interval [ L , U ] such that Pr [ z ≤ L ] = 0.05 and Pr [ z ≤ U ] = 095 Thus , Pr [ z ∈ [ L , U ] ] = 09 To estimate the confidence interval , each simulation was run independently 100,000 times . The values L and U are estimated by the 5th and 95th percentile values respectively .
In subsections 6.2 and 6.3 we compare the prior art algorithms method with the random walk approach described in this work . For comparison we consider the following approaches : ( 1 ) the estimator based on random walk combined with ego network exploration described in [ 25 ] ( labeled RW Ego network ) ; and ( 2 ) the estimator based on MetropolisHastings sampling with ego network exploration described in [ 13 ] ( labeled MH Ego Network ) . The estimator described in subsection 4.1 is labeled random walk . In the random walk estimator ( our approach ) the number of mined nodes is exactly the random walk ’s length , while in the Ego network algorithms ( prior art ) the mined nodes include the ( sampled ) walk nodes as well as their neighbors .
In subsection 6.4 we compare prior art node collision estimator [ 14 , 15 ] ( labeled node collision ) with the new proposed neighbor collision estimator ( labeled neighbor collision ) . 6.2 Network average clustering coefficient
Figure 2 displays confidence intervals for all algorithms and datasets . The proposed random walk estimator significantly outperforms ego network estimators . Specifically , using only 1 % of the network size , the confidence intervals of the random walk estimator are about fifty percent tighter for the DBLP network and four times as tight for the Orkut , Flickr , and LiveJournal networks . The exact numbers are enclosed in Table 3 .
Network DBLP Orkut Flickr LiveJ random walk [ 0.967 , 1.033 ] [ 0.916 , 1.085 ] [ 0.891 , 1.111 ] [ 0.951 , 1.054 ]
MH Ego
RW Ego
[ 0.942 , 1.051 ] [ 0.583 , 1.468 ] [ 0.557 , 1.415 ] [ 0.816 , 1.200 ]
[ 0.910 , 1.073 ] [ 0.426 , 1.658 ] [ 0.064 , 2.023 ] [ 0.645 , 1.329 ]
Table 3 : Network average clustering [ 5%,95%]confidence interval for 1 % mined nodes .
6.3 Global clustering coefficient
In this subsection there is no prior art algorithm for comparison . To have a baseline , we retrofit the ego network estimator for computing the global clustering coefficient . The global clustering coefficient can be viewed as a weighted sum of local clustering coefficients . The ego network sampling es− 1 ) timators multiplies each observed cxk by wk = dxk ( dxk and divide the total by the sum W =
.
Figure 3 displays confidence intervals for all algorithms and datasets . The proposed random walk estimator sig wk . k nificantly outperforms ego network estimators by an even greater margin when compared with the network average clustering coefficient estimators . The curve for metropolis hasting ego network in missing in the Flickr graph because all the values are greater than 8 , which demonstrate the estimator ’s inefficiency . In the LiveJournal graph , one can see the upper 95 % curves are even increasing . These curves converge only after 5 % of the network is sampled . Using only 1 % of the network size , the confidence intervals of the random walk estimator are about three times tighter for the DBLP network and ten times tighter for the Orkut network . The ego network estimators for the Flickr and LiveJournal networks are extremely inaccurate in the [ 0.1 % , 2 % ] range . The exact numbers are enclosed in Table 4 .
Network DBLP Orkut Flickr LiveJ random walk [ 0.869 , 1.180 ] [ 0.892 , 1.130 ] [ 0.922 , 1.078 ] [ 0.620 , 1.523 ]
MH Ego
RW Ego
[ 0.659 , 1.919 ] [ 0.424 , 2.711 ] [ 0.212 , 10.07 ] [ 0.235 , 4.275 ]
[ 0.609 , 1.485 ] [ 0.317 , 3.068 ] [ 0.176 , 1.588 ] [ 0.246 , 3.051 ]
Table 4 : Global clustering [ 5%,95%] confidence interval for 1 % mined nodes .
6.4 Network size
In this subsection we compare the node collision and neighbor collision estimators . In all estimators the number of mined nodes is exactly the random walk ’s length . We used m = 2.5%r as the separation parameter for all estimators . Namely , we used about 95 % of the maximum number of ( k , l ) pairs ( |I| ≈ 095r2 ) In Figure 4 we see that the neighbor collision estimator outperforms the node collision estimator . The node collision estimator and neighbor collision estimator are Ψn/C and Ψn/Φn respectively . The performance of the estimators depend on the variance of Ψn , C , and Φn . The performance of the neighbor collision reduces the variance of one factor , but retains the variance of Ψn . Therefore , we see a different performance impact on these ≈ 1∓x+x2∓·· ·+x2k datasets . Moreover , the fact that explains why the neighbor collision estimator has a greater impact on performance in the early stages of convergence when r is small .
1 1±x
Using only 1 % of the network size , there was a significant accuracy improvement in the DBLP network , a noticeable improvement for the Orkut network , and negligible improvement for the Flickr and LiveJ networks . The exact number are enclosed in Table 5 . The second column is prior art node collision estimator ; the third column is the proposed new neighbor collision estimator ; and the fourth column is the confidence bound improvement10 .
7 . CONCLUSIONS
We presented algorithms for estimating the ( 1 ) network average clustering coefficient ; ( 2 ) global clustering coefficient ; and ( 3 ) the number of registered users . These algorithms use the information collected by random walk , namely , the ids of the visited nodes along with their adjacency list .
10In the DBLP network the change from 1.384 to 1.221 in the 95 % confidence implies a ( 0384−0221)/0384 improvement and the change in the 5 % confidence from 0.752 to 0.815 implies a ( 0.815 − 0.752)/(1 − 0.752 ) improvement .
545 e u l a v n o i t a m i t s e e v i t a l e R e u l a v n o i t a m i t s e e v i t a l e R
1.3
1.2
1.1
1
0.9
0.8
0.7
3
2.5
2
1.5
1
0.5
0
DBLP network
RW Ego network MH Ego network Random walk
0
0.2 0.4 0.6 0.8
1
1.2 1.4 1.6 1.8
2
Percentage of mined nodes
Flickr network
RW Ego network MH Ego network Random walk
0
0.2 0.4 0.6 0.8
1
1.2 1.4 1.6 1.8
2
Percentage of mined nodes e u l a v n o i t a m i t s e e v i t a l e R e u l a v n o i t a m i t s e e v i t a l e R
2.5
2
1.5
1
0.5
0
2
1.5
1
0.5
0
Orkut network
RW Ego network MH Ego network Random walk
0
0.2 0.4 0.6 0.8
1
1.2 1.4 1.6 1.8
2
Percentage of mined nodes
LiveJournal network
RW Ego network MH Ego network Random walk
0
0.2 0.4 0.6 0.8
1
1.2 1.4 1.6 1.8
2
Percentage of mined nodes
Figure 2 : Estimation of the network average clustering coefficient confidence interval vs . the percentage of mined nodes .
Network DBLP Orkut Flickr LiveJ
Node
[ 0.752 , 1.384 ] [ 0.849 , 1.187 ] [ 0.846 , 1.203 ] [ 0.780 , 1.232 ]
Neighbor
[ 0.815 , 1.221 ] [ 0.860 , 1.161 ] [ 0.843 , 1.208 ] [ 0.785 , 1.218 ] improvement [ 25.4 % , 42.5 % ] [ 7.30 % , 13.9 % ] [ 1.91 % , 2.40 % ] [ 2.27 % , 6.03 % ]
Table 5 : Network size [ 5%,95%] confidence interval for 1 % mined nodes .
For the clustering coefficients algorithms we showed that ( 1 ) for social network like graphs these algorithms considerably outperform prior art ( sampling the ego network of each sampled node ) ; and ( 2 ) an analytic bound on the number of steps required for convergence . For the number of registered users algorithm we showed , both analytically and experimentally , that the new suggested algorithm is strictly more accurate than prior art node collision algorithms .
Ego network algorithms sample all the adjacency lists of nodes in the random walk , while the random walk estimator samples only two nodes from this list ( previous and next node of the random walk ) . Investigating between these two extremes might give rise to further improvement .
8 . REFERENCES [ 1 ] L . Addario Berry and T . Lei . The mixing time of the newman–watts small world . In SODA , pages 1661–1668 , 2012 .
[ 2 ] Y Y Ahn , S . Han , H . Kwak , S . B . Moon , and
H . Jeong . Analysis of topological characteristics of huge online social networking services . In WWW , pages 835–844 , 2007 .
[ 3 ] N . Alon , R . Yuster , and U . Zwick . Finding and counting given length cycles . Algorithmica , 17(3):209–223 , 1997 .
[ 4 ] H . Avron . Counting triangles in large graphs using randomized matrix trace estimation . In Large Scale Data Mining : Theory and Applications ( KDD Workshop ) , 2010 .
[ 5 ] L . Backstrom , D . P . Huttenlocher , J . M . Kleinberg , and X . Lan . Group formation in large social networks : membership , growth , and evolution . In KDD , pages 44–54 , 2006 .
[ 6 ] Z . Bar Yossef and M . Gurevich . Random sampling from a search engine ’s index . J . ACM , 55(5 ) , 2008 .
[ 7 ] Z . Bar Yossef and M . Gurevich . Estimating the impressionrank of web pages . In WWW , pages 41–50 , 2009 .
[ 8 ] Z . Bar Yossef and M . Gurevich . Efficient search engine measurements . TWEB , 5(4):18 , 2011 .
546 e u l a v n o i t a m i t s e e v i t a l e R e u l a v n o i t a m i t s e e v i t a l e R
3
2.5
2
1.5
1
0.5
2.5
2
1.5
1
0.5
0
DBLP network
MH Ego network RW Ego network Random walk
0
0.2 0.4 0.6 0.8
1
1.2 1.4 1.6 1.8
2
Percentage of mined nodes
Flickr network
RW Ego network MH Ego network Random walk
0
0.2 0.4 0.6 0.8
1
1.2 1.4 1.6 1.8
2
Percentage of mined nodes e u l a v n o i t a m i t s e e v i t a l e R e u l a v n o i t a m i t s e e v i t a l e R
5
4
3
2
1
0
6
5
4
3
2
1
0
Orkut network
RW Ego network MH Ego network Random walk
0
0.2 0.4 0.6 0.8
1
1.2 1.4 1.6 1.8
2
Percentage of mined nodes
LiveJournal network
RW Ego network MH Ego network Random walk
0
0.2 0.4 0.6 0.8
1
1.2 1.4 1.6 1.8
2
Percentage of mined nodes
Figure 3 : Estimation of the global clustering coefficient confidence interval vs . the percentage of mined nodes .
[ 9 ] L . Becchetti , P . Boldi , C . Castillo , and A . Gionis .
[ 16 ] J . Kunegis . KONECT – the Koblenz Network
Efficient algorithms for large scale local triangle counting . TKDD , 4(3 ) , 2010 .
[ 10 ] L . S . Buriol , G . Frahling , S . Leonardi ,
A . Marchetti Spaccamela , and C . Sohler . Counting triangles in data streams . In PODS , pages 253–262 , 2006 .
[ 11 ] K M Chung , H . Lam , Z . Liu , and M . Mitzenmacher .
Chernoff hoeffding bounds for markov chains : Generalized and simplified . In STACS , pages 124–135 , 2012 .
[ 12 ] L . F . Costa , F . A . Rodriguez , G . Travieso , and
P . R . V . Boas . Characterization of complex networks : A survey of measurements . Advances in Physics , 56(1):167–242 , Aug . 2006 .
[ 13 ] M . Gjoka , M . Kurant , C . T . Butts , and
A . Markopoulou . Walking in facebook : A case study of unbiased sampling of OSNs . Proceedings of IEEE INFOCOM 2010 , pages 1–9 , 2010 .
[ 14 ] S . J . Hardiman , P . Richmond , and S . Hutzler .
Calculating statistics of complex networks through random walks with an application to the on line social network bebo . European Physics Journal B , 71(4):611–622 , 2009 .
[ 15 ] L . Katzir , E . Liberty , and O . Somekh . Estimating sizes of social networks via biased sampling . In WWW , pages 597–606 , 2011 .
Collection . http://konectuni koblenzde/ , 2012 .
[ 17 ] D . A . Levin , Y . Peres , and E . L . Wilmer . Markov
Chains and Mixing Times . American Mathematical Society , 2008 .
[ 18 ] M . Ley . The DBLP computer science bibliography :
Evolution , research issues , perspectives . In Proc . Int . Symp . on String Processing and Information Retrieval , pages 1–10 , 2002 .
[ 19 ] L . Lov´asz and P . Winkler . Mixing times . microsurveys in discrete . In DimacsWorkshop , 1998 .
[ 20 ] A . Mislove , H . S . Koppula , K . P . Gummadi ,
P . Druschel , and B . Bhattacharjee . Growth of the flickr social network . In Proceedings of the 1st ACM SIGCOMM Workshop on Social Networks ( WOSN’08 ) , August 2008 .
[ 21 ] A . Mislove , M . Marcon , P . K . Gummadi , P . Druschel , and B . Bhattacharjee . Measurement and analysis of online social networks . In Internet Measurement Comference , pages 29–42 , 2007 .
[ 22 ] A . Mohaisen , A . Yun , and Y . Kim . Measuring the mixing time of social graphs . In Internet Measurement Conference , pages 383–389 , 2010 .
[ 23 ] M . Newman and D . Watts . Renormalization group analysis of the small world network model . Physics Letters A , 263:341–346 , 1999 .
547 Orkut network
Node Collision Neighbor Collision
2.6 2.4 2.2 2 1.8 1.6 1.4 1.2 1 0.8 0.6 0.4 e u l a v n o i t a m i t s e e v i t a l e R e u l a v n o i t a m i t s e e v i t a l e R
2.2
2
1.8
1.6
1.4
1.2
1
0.8
0.6
2.6 2.4 2.2 2 1.8 1.6 1.4 1.2 1 0.8 0.6 0.4
DBLP network
Node Collision Neighbor Collision
0.5
1
1.5
2
2.5
Percentage of mined nodes
Flickr network
Node Collision Neighbor Collision
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
Percentage of mined nodes e u l a v n o i t a m i t s e e v i t a l e R e u l a v n o i t a m i t s e e v i t a l e R
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9
1
Percentage of mined nodes
LiveJournal network
Node Collision Neighbor Collision
0.4
0.6
0.8
1
1.2
1.4
1.6
Percentage of mined nodes
2.2
2
1.8
1.6
1.4
1.2
1
0.8
0.6
0.2
Figure 4 : Estimation of the network size confidence interval vs . the percentage of mined nodes .
[ 24 ] M . Newman and D . Watts . Scaling and percolation in the small world network model . Physical Review E , 60:7332–7342 , 1999 .
[ 25 ] B . F . Ribeiro and D . F . Towsley . Estimating and sampling graphs with multidimensional random walks . In Internet Measurement Conference , pages 390–403 , 2010 .
[ 26 ] R . Y . Rubinstein and D . P . Kroese . Simulation and the Monte Carlo Method . Wiley Series in Probability and Statistics , 2 edition , 2007 .
[ 27 ] T . Schank and D . Wagner . Approximating clustering coefficient and transitivity . J . Graph Algorithms Appl . , 9(2):265–275 , 2005 .
[ 28 ] S . Wasserman and K . Faust . Social Network Analysis :
Methods and Applications . Cambridge University Press , 1994 .
APPENDIX A . CONCENTRATION OF ΨL AND ΦL
In the proof of Lemma 1 we required that the variables Ψl and Φl give an /3 approximation to their expected values with probability at least 1 − δ/2 .
To prove both Ψl or Φl are concentrated we first restate a theorem from Chung et al . [ 11 ] :
Theorem 4
Let M be an ergodic Markov chain with state space [ n ] and stationary dis
( Theorem 3.1 [ 11] ) .
π =
. tribution π . Let τ = τ ( ) be its mixing time for ≤ 1 8 . Let ( x1 , x2 , . . . , xr ) denote an r step random walk on M starting from an initial distribution ϕ on [ n ] , ie , x1 ← ϕ . Let ffϕff . For every k ∈ [ r ] , let fk : [ n ] → [ 0 , 1 ] be a weight function at step k such that the expected weight . Ev←π[fk(xk ) ] = μ for all k . Define the total weight of the walk ( x1 , x2 , . . . , xr ) by Z . k=1 fk(xk ) . There exists some constant c ( which is independent of μ , δ and ) such that for 0 < δ <1 n i=1
2 ϕ i πi r
Pr [ |Z − μr| > μr ] ≤ cffϕff e−
2
μr/72τ ,
π or equivalently
'fifififi Z r
Pr fifififi > μ ff
− μ
≤ cffϕff
π e−
2
μr/72τ .
Lemma 5 . There is a constant value , ξ , such that if r ≥ rΨl = ξ D n
τ ( ) , we have
' |Ψl − E [ Ψl]| ≤ E [ Ψl ] ff
Pr
≥ 1 − δ 2
. We assume that fl ffi
1 dxk
= n D .
3 ffi
Proof . Let fk(xk ) = f ( xk ) = 1 dxk
π = 1 . We have , E [ Ψl ] = E
ϕ ≈ π , and thus ffϕff From Theorem 4 , fl |Ψl − E [ Ψl]| >
Pr
3
E [ Ψl ]
≤ ce−
2 nr/9·72·τ D
548 ≤ τ ( ) . Since and δ are constants , this ends the nr/9·72·τ D , we have rΨl
2 = ce−
2
Extracting rΨl for which δ ˜ξ log(δ ) 1 2 proof .
D n
Lemma 6 . There is a constant value , ξ , such that if r ≥ rΦl = ξ D ncl
τ ( ) , we have
' ff
Pr
|Φl − E [ Φl]| ≤ E [ Φl ]
3
≥ 1 − δ 2 dxk
Axk ,xk+2 −1
Proof . For this bounds , we cannot apply Therorem 4 directly since fj depends on previously visited node . However , since only depends on a 3 nodes history , we observe a related Markov chain that remembers the last three visited nodes . To this end , ˜M has ˜n = n × n × n nodes , and ( x1 , x2 , x3 ) ← ( x2 , x3 , x4 ) with the same transiAxk−1,xk+1 tion probability of x3 to x4 in M . Let fk(˜xk ) = . We assume that ϕ ≈ π , and thus ffϕff . π = 1 . We have , i=1 ci = n cl . From TheoE [ Φl ] = E ffi rem 4 , fl φk
1 −1 dxk
= 1 D dxk
−1 ffi
D n fl |Φl − E [ Φl]| >
Pr
≤ ce−
2 ncl(r−2)/9·72·˜τ D
2
2
D ncl
Extracting rΦl for which δ rΦl the proof . ncl ( r−2)/9·72·˜τ D , we have ≤ ˜ξ log(δ ) 1 ˜τ . Since and δ are constants , this ends Note that ˜τ ( ) ≤ τ ( ) . To see this , in the true stationary distribution the probability of drawing xk−1 , xk , xk+1 is dxk−1 . After τ ( ) steps , the probability of drawing xk−1 is at most distance away . Therefore , probability of drawing xk−1 , xk , xk+1 is , and thus D the difference is bounded by 1 dxk
±
≤ . dxk−1
1 dxk
1 dxk dxk+1 dxk+1 dxk+1 ffl
D
1
1
1
3
E [ Φl ] 2 = ce−
To conclude we combine Lemma 5 and 6 , and choose rl = max {rΨl B . CONCENTRATION OF ΨG AND ΦG
, rΦl
} .
In the proof of Lemma 2 we require that the variables Ψg and Φg give an /3 approximation to their expected values with probability at least 1 − δ/2 .
Lemma 7 . There is a constant value , ξ , such that if r ≥ n
.
Pr ff
Ddmax rΨg = ξ
τ ( ) , we have i=1 di(di−1 )
' |Ψg − E [ Ψg]| ≤ E [ Ψg ] −1 dxk dmax ( all values in [ 0 , 1] ) . We assume that ϕ ≈ π , and thus ffϕff . π = 1 . We have , i=1 di(di − 1 ) . From dmax E [ Ψg ] = E Theorem 4 ,
Proof . Let fk(xk ) = f ( xk ) =
≥ 1 − δ 2
−1 dxk dmax
Ddmax fl
=
3 n
1
1 ffi fifififi >
'fifififi Ψg dmax
Pr
− E [ Ψg ] dmax ff
E [ Ψl ] dmax 3 2 = ce− i=1 di(di−1 )
Ddmax
2 . n
≤ ce
−
2 . n i=1 di 9·72·τ Ddmax
( di
−1)r n i=1 di(di−1)r/9·72·τ Ddmax , τ ( ) . Since and δ are
Extracting rΨg for which δ ≤ ˜ξ log(δ ) 1 we have rΨg . constants , this ends the proof .
2
Lemma 8 . There is a constant value , ξ , such that if r ≥ rΦg = ξ
. cg
Ddmax n
τ ( ) , we have ' i=1 di(di−1 ) |Φg − E [ Φg]| ≤ E [ Φg ]
Pr ff
≥ 1 − δ 2
3
Proof . The proof combines the division by dmax of lemma 7 and the the 3 node history markov chain ˜M of lemma 6 .
549
