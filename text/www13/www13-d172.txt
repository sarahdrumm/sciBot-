Spectral analysis of communication networks using Dirichlet eigenvalues
Alexander Tsiatas1 , Iraj Saniee∗2 , Onuttom Narayan3 , and Matthew Andrews2
1Department of Computer Science and Engineering , University of California , San
Diego , 9500 Gilman Drive , La Jolla , CA 92093 0404
2Mathematics of Networks , Bell Laboratories , Alcatel Lucent , 600 Mountain
3Department of Physics , University of California , Santa Cruz , CA 95064
Avenue , Murray Hill , NJ 07974
1 1 0 2 b e F 7 1
.
] P S h t a m
[
1 v 2 2 7 3
.
2 0 1 1 : v i X r a
Abstract
We study spectral characteristics of networks that represent the IP layer connectivity of communication systems as measured and documented by previous researchers . Our goal is to understand the behavior of these networks as truncated samples of infinite graphs . As such , the existence of a spectral gap and positive Cheeger constant in the extrapolated infinite variety would provide insight into their basic geometry . We apply Dirichlet boundary conditions to the computation of the eigenvalues to show that unlike standard spectral techniques , the gap and the Cheeger constant of finite truncations of regular trees provide accurate estimates of the corresponding parameters for the infinite tree . Having shown the effectiveness of the Dirichlet spectrum for trees , we compute spectral decompositions via Dirichlet eigenvectors for the communication networks . We show that Dirichlet eigenvectors provide a strong means to separate clusters and conclude that the said networks exhibit characteristics common in hyperbolic networks .
1 Introduction
The study of large networks is an important field filled with many applications , important problems , and open questions . Amongst the key characteristics of large networks are bottlenecks , capacity , and reliability . These related properties are critical in the design and analysis of any data network : information must be able to flow freely from any part of the network to any other , and no small segment can be so critical as to undermine the network upon failure .
One well studied technique that captures these structural properties is spectral graph theory , examining the eigenvalues and eigenvectors of graph theoretic matrices ( see [ 6 ]
∗This work was supported by AFOSR Grant No . FA 9550 08 2 0064 .
1 for a survey ) . Through relationships such as the Cheeger inequality , one can see that there are direct connections between the spectral gap and sparse cuts or bottlenecks in networks . When a network has a bottleneck , overall capacity and reliability suffer degradations .
Many real world networks are incredibly vast , encompassing topologies with millions or billions of nodes and edges . Networks this large are often treated as infinite , as evidenced by network generation models [ 1 , 10 , 27 ] that exhibit unique convergence properties ( to power law degree distributions or otherwise ) as the size of the network grows to infinity . Furthermore , with large scale networks , computation may be feasible only on smaller portions of the overall structure . In this case , it is advantageous to study these portions not as separate networks , but as subsets of infinite topologies .
To see how infinite networks provide good fundamental models for large scale networks , one can take the tree as an example . Regular trees are usually thought to be excellent expanders due to exponential growth radiating from the root as the tree gets deeper . This is reflected in the spectrum of the infinite tree : it has a finite spectral gap [ 4 , 8 , 12 ] . But with finite truncations , it is not hard to see that the spectral gap tends to zero as the tree gets larger , masking the inherent expansion properties of trees . The same phenomenon exists when considering the isoperimetric or Cheeger constant .
Much work on the study of large networks has concerned properties such as smallworld phenomena [ 27 ] and power law degree distributions [ 1 , 2 , 3 , 11 ] . One more recent development is the study of global network curvature in the geodesic sense [ 15 , 19 , 21 ] . For example , infinite regular trees and regular hyperbolic grids Hpq [ 22 ] have natural embeddings on negatively curved surfaces . Even though it is possible to define a local measure of curvature for a large graph via the clustering coefficient [ 9 , 27 ] , the more natural measure for network curvature is in the large scale , as defined by Gromov ’s δ hyperbolicity [ 13 ] as applied to analysis of complex networks [ 15 , 19 ] . There is evidence of negative curvature in real world networks with structural ramifications : the existence of a core bottleneck with quadratically scaling load assuming unit traffic between every pair of nodes along shortest paths [ 19 ] . This quadratic scaling is asymptotically worse than O(n1.5 ) load scaling for flat networks such as the regular Euclidean grid [ 19 ] . These examples also indicate a connection between negative curvature and expansion . The negatively curved infinite trees and hyperbolic grids are good expanders , while the flat Euclidean grid is not . Our goal is to determine to what extent spectral techniques , suitably modified to eliminate distortions due to boundaries , can take advantage of large scale negative curvature and identify structural properties such as clustering .
The rest of this paper is structured as follows : in Section 2 , we use the infinite tree as a prototype and motivation for using Dirichlet eigenvalues [ 5 ] rather than the traditional spectral gap for finite portions of infinite graphs , showing that the Dirichlet spectral gap can be a better indicator for true expansion in large graphs . We then apply this mathematical tool in Section 3 to real , publicly determined network topologies [ 25 ] that represent smaller portions of the wider telecommunications grid , with an emphasis on investigating bottlenecks , expansion , and large scale network curvature as discussed in Section 4 . In Section 5 , we use well known graph partitioning algorithms , modified to use Dirichlet eigenvalues , to produce graph partitions that are often more indicative of bottlenecks in the network core
2 rather than the fringes .
2 Spectrum of Finite Trees
Throughout this paper , we analyze general undirected connected graphs G by using the normalized graph Laplacian L , defined as in [ 6 ] . For two vertices x and y , the corresponding matrix entry is :

Lxy =
1 − 1√ 0 dxdy if x = y , if x and y are adjacent , and otherwise , where dx and dy are the degrees of x and y . We denote by λ the spectral gap , which is simply the smallest nonzero eigenvalue of L . For any graph G and subgraph S ⊂ G , the Cheeger ratio h(S ) is a measure of the cut induced by S : h(S ) = e(S , ¯S ) min(vol(S ) , vol( ¯S ) )
.
We use e(S , ¯S ) to denote the number of edges crossing from S to its complement , and the volume vol(S ) is simply the sum of the degrees of all nodes in S . The Cheeger constant h is the minimum h(S ) over all subsets S . The Cheeger constant and spectral gap are related by the following Cheeger inequality [ 6 ] :
2h ≥ λ ≥ h2 2
.
Both λ and h are often used to characterize expansion or bottlenecks in graphs . This inequality shows that they are both good candidates and gives the ability to estimate one based on the other . been analytically determined [ 12 , 18 ] . Using L , the spectral gap is
For the infinite d regular tree , the spectral gap and Cheeger constant have both
√ d − 1 ,
λ = 1 − 2 d
( 1 ) and the Cheeger constant is h = d−2 [ 14 ] . Both of these values are nonzero , indicating good expansion . However , the Cheeger ratio for truncated d regular trees ( T dT ) – those with all branches of the infinite tree cut off beyond some radius r from the center – approaches zero as the tree gets deeper . By cutting off any one subtree S from the root , there is only one edge connecting S to ¯S , and as the tree gets deeper , this ratio gets arbitrarily small . Using the Cheeger inequality , it follows that the λT dT → 0 as r → ∞ . Thus , the standard spectral properties of finite trees do not approach the infinite case as they get larger ; in fact , they suggest the opposite . This is problematic when making qualitative observations about networks and their expansion , necessitating another tool for spectral analysis of networks .
3
The main reason why the traditional spectral gap does not capture expansion well in large , finite trees is the existence of a boundary . This is also problematic in network partitioning algorithms ; often times the “ best ” partition is a bag of whiskers or combination of several smaller cuts near the boundary [ 17 ] . In this paper , we will use Dirichlet eigenvalues to eliminate this problem .
Dirichlet eigenvalues are the eigenvalues of a truncated matrix , eliminating the rows and columns that are associated with nodes on the graph boundary . We will use a truncated normalized graph Laplacian , LD , a submatrix of L . This is different from simply taking the Laplacian of an induced subgraph , as the edges leading to the boundary nodes are still taken into account ; it is only the boundary nodes themselves that are ignored . Using LD , we define the Dirichlet spectral gap to be the smallest eigenvalue .
Using Dirichlet eigenvalues , we also have a local Cheeger inequality [ 5 ] for a set of nodes T . We define the local Cheeger ratio for T as in [ 5 ] :
H(T ) = e(T , ¯T ) vol(T )
, and the local Cheeger constant hS for a set S is the minimum local Cheeger ratio over all T ⊂ S . The local Cheeger inequality is hS ≥ λS ≥ h2 S 2
, where λS is the Dirichlet eigenvalue of the Laplacian restricted to the rows and columns corresponding to nodes in S . This inequality indicates a relationship between local expansion and bottlenecks .
We shall be primarily interested in the case where S excludes the boundary of a graph . In the particular case of finite trees , by selecting ¯S to be the boundary , we eliminate the possibility of cutting whole branches off and thus bring the local Cheeger ratio and Dirichlet spectral gap closer to the asymptotic values . We note that the use of Dirichlet eigenvalues requires the definition of such a graph boundary . For trees this is simple : the leaf nodes are a natural choice . We shall see that for the Rocketfuel data as well as any finite truncation of a much larger network , the boundary can also be defined naturally .
We first use Dirichlet eigenvalues on d regular trees as prototypical evidence for their effectiveness in capturing true spectral properties on real world networks . There is empirical evidence in Figure 1 , showing that the Dirichlet spectral gap for 3 regular trees indeed converges to a nonzero value as tree depth increases , contrasting with the traditional spectral gap which converges to zero . This is made rigorous in the following theorem :
Theorem 1 . For finite d regular trees of depth L , the Dirichlet spectral gap converges to the true spectral gap ( 1 ) of the infinite tree as L approaches infinity .
Proof . To derive the Dirichlet spectral gap for finite trees using the leaves as the boundary , we will solve a recurrence that arises from the tree structure and the standard eigenvalue equation
Ldx = λx .
( 2 )
4
Figure 1 : Dirichlet spectral gap for successively larger 3 regular trees , showing convergence to a nonzero value .
Let T be a d regular tree of depth L + 1 ; the ( L + 1)st level is the boundary . We will make the assumption that the eigenvector x has the same value at every node at the same depth within T ; these eigenvectors are azimuthally symmetric , and it can be shown that all other eigenvectors can be written as linear combinations of azimuthally symmetric eigenvectors with the same eigenvalue . Thus , we can represent each eigenvector x as a sequence of values ( x0 , x1 , . . . , xL ) , where xi is the uniform value at all nodes at depth i , similar to the analysis of the infinite tree spectral gap appearing in [ 12 ] . Using this eigenvector form for x in ( 2 ) leads to the recurrence : xi − 1 d xi−1 − d − 1 d xi+1 = λxi , 2 ≤ i ≤ L .
At the leaves of the tree , we have the Dirichlet boundary condition : xL+1 = 0 .
We can solve ( 3 ) using the characteristic equation : d − 1 d r2 − ( 1 − λ)r +
1 d
= 0 , whose roots can be written as r1,2 = γe±iα .
5
( 3 )
( 4 )
( 5 )
It follows that γ = 1√ d−1 and
√
λ = 1 − 2 d d − 1 cos α .
( 6 )
Substituting the the boundary condition ( 4 ) yields a solution to ( 3 ) with the form xn = Ark
1 ( rn−k
1 − rn−k
2
) ,
( 7 ) for some constant A and r1,2 given in ( 5 ) . There are two ways that we can proceed .
One possibility is that the eigenvector has all xi = 0 . This could be the trivial case where the individual components of the eigenvector are all zero at every layer ( which we ignore ) , but it could also be the case that the components are strictly non zero until a certain layer . In this case , the individual components all become zero after that critical layer , and every layer still averages to zero , corresponding with the assumption that xi = 0 . Suppose that n∗ is the first layer with components = 0 . Then , using the boundary condition xn∗−1 = 0 and ( 7 ) , we derive
α = mπ
L − n∗ + 2
, 1 ≤ n∗ ≤ L , 1 ≤ m ≤ L − n + 1 .
( 8 )
Alternatively , if there is no all zero layer in x , then we simply enforce ( 2 ) at the root to derive the second boundary condition x0 − x1 = λx0 . Imposing this condition on ( 7 ) implies that the values for α are the solutions to tan α tan(L + 1)α
= − 1 3
.
( 9 )
It is not hard to see ( via counting ) that ( 8 ) and ( 9 ) furnish all the nontrivial eigenvalues and eigenvectors of ( 2 ) . In any case , we are interested in finding the smallest eigenvalue λ . This occurs when cos α is closest to 1 , or α is closest to zero , since there are no imaginary roots to ( 9 ) . One can see that in both ( 8 ) and ( 9 ) , as L gets larger , the smallest α approaches 0 , showing that ( 6 ) does indeed converge to the true spectral gap ( 1 ) of the infinite tree as the depth approaches infinity .
This derivation shows that Dirichlet eigenvalues capture the expansion properties of trees much better than the traditional spectral gap which has been shown to be bounded away from zero for large finite trees . This behavior on trees suggests that Dirichlet eigenvalues are a good candidate for use in analyzing real world networks . Such analysis appears in Section 3 .
3 Spectrum of Rocketfuel Networks
Our research is motivated by a series of datasets representing portions of network topologies using Rocketfuel [ 25 ] . Rocketfuel datasets are publicly available , created using traceroute and other networking tools to determine portions of network topology corresponding to individual Internet service providers . Even though like most measured datasets , the Rocketfuel
6
Dataset ID Nodes Edges Traditional spectral gap Dirichlet spectral gap
1221 1239 1755 2914 3257 3356 3967 4755 6461 7018
2998 8341 605 7102 855 3447 895 121 2720 10152
3806 14025 1035 12291 1173 9390 2070 228 3824 14319
0.00386 0.01593 0.00896 0.00118 0.01045 0.00449 0.00799 0.03570 0.00639 0.00029
0.07616 0.03585 0.09585 0.04621 0.04738 0.05083 0.03365 0.06300 0.11036 0.09531
Table 1 : Structural and spectral properties of Rocketfuel datasets . networks are not free of errors ( see for example [ 26] ) , they provide valuable connectivity information at the IP layer of service provider networks across the globe .
Because the datasets were created in this manner , they represent only subsets of the vast Internet ; it becomes impossible to determine network topology at certain points . For example , corporate intranets , home networks , other ISP ’s , and network address translation cannot be explored . The networks used range in size from 121 to 10,152 nodes .
Because of the method of data collection , the Rocketfuel datasets contain many degree 1 nodes that appear at the edge of the topology . In actuality , the network extends beyond this point , but the datasets are limited to one ISP at a time . As such , it makes sense to view these degree 1 nodes as the boundary of a finite subset of a much larger network , similar to our treatment of the boundary of finite trees . This idea can be extended to general large scale graphs : starting from one or more centers of mass , one can take the subset of the network within distance r as a smaller , more manageable subset , for larger and larger r . ( Finding centers of mass can be done in many ways ; see [ 7 ] for one method . ) Using Dirichlet eigenvalues has been shown in Section 2 to be a promising technique for preserving the limiting behavior in the spectral analysis of such structures .
To show how the methodology of Section 2 can be applied to the IP layer connectivity graphs , we compute the Dirichlet spectral gaps of the these graphs and compare with their standard counterparts . The numeric data is in Table 1 , and one can see a visual comparison in Figure 2 .
Included for comparison with the Rocketfuel data in Figure 2 are the traditional and Dirichlet spectral gaps for the two dimensional Euclidean grid . It is apparent that the Dirichlet spectral gaps are all much larger than the traditional spectral gaps for the Rocketfuel data , and the spectral gap for the Euclidean grid is very small . The grid is known to be a poor expander , and the spectral gap reflects this . For the Rocketfuel data , using traditional spectral gaps imply that the expansion is also quite poor . But as we saw using successively larger finite trees , the Dirichlet eigenvalues provide a better characterization of the expansion properties of the Rocketfuel data , implying a higher degree of expansion and
7
Figure 2 : Comparison of traditional and Dirichlet spectral gaps in Rocketfuel data as well as the 2 dimensional Euclidean grid . the presence of bottlenecks at the core of the network .
4 Relationship to Geometry
In addition to the relationships involving the spectral gap , Cheeger constant , and expansion , global network curvature is a related phenomenon gaining attention [ 15 , 16 , 19 ] . Negative curvature can arise when graphs are embedded on a surface using geodesic distances . For some graphs , such as the Euclidean grid , this results in a flat , planar embedding , but for many graphs the natural embedding involves negatively curved surfaces ( see [ 21] ) .
Determining an exact natural graph embedding on a surface can be computationally very hard . However , we can more efficiently use the notion of large scale curvature captured by the δ thin triangle condition [ 13 ] . For any three nodes x , y , z , the geodesic triangle is drawn between them . If D(w , xyz ) is the distance between any fourth node w and the geodesic triangle xyz , then
δ = max xyz min w
D(w , xyz ) .
In a negatively curved graph , δ is small , leading to “ thin ” geodesic triangles .
Direct measurement of δ [ 19 ] has shown evidence of negative curvature or hyperbolicity in the Rocketfuel datasets [ 25 ] , hyperbolic grids Hpq [ 22 ] , Barab´asi Albert graphs generated via preferential attachment [ 1 ] , and trees ; such curvature does not empirically exist in other models such as Watts Strogatz “ small world ” generated graphs [ 27 ] , Euclidean grids , and Erd¨os R´enyi random graphs [ 10 ] .
8
Global negative curvature has many implications in networks . It has been shown that negatively curved graphs exhibit congestion and sparse bottlenecks [ 19 , 21 ] . This is illustrated when analyzing network load at the core , assuming unit traffic between every pair of nodes , using shortest path routing . For δ hyperbolic graphs , the load at the network core scales as O(n2 ) , where n is the number of nodes in the networks . For flat networks , the network core load scales better : O(n15 ) This difference represents extra network congestion that is occuring at a central bottleneck for negatively curved graphs . Direct measurement of δ and core congestion in the Rocketfuel data has shown this phenomenon explicitly [ 19 ] . Clear evidence of a mathematical connection between negative curvature , bottlenecks , and expansion can be seen in regular hyperbolic grids Hpq [ 22 ] . In these grids , each vertex has degree q , the edges form regular p gons , and they exhibit constant negative curvature when ( p − 2)(q − 2 ) > 4 . Note that when ( p − 2)(q − 2 ) = 4 , this is a flat Euclidean grid , and when p approaches infinity , the grid becomes tree like . It has been shown [ 14 ] that Hpq has a nonzero Cheeger constant of hp,q = h(Hpq ) = q − 2 q
1 −
4
( p − 2)(q − 2 )
.
( 10 )
The spectral gap of hyperbolic grid is not yet known exactly , but we may approximate it as follows . Replace the ( p , q) grid with an equivalent dp,q regular tree , where dp,q is the average number of edges leading from a node to the next layer away from the center . For p > 3 , this average degree must equal the growth rate of the ( p , q) grid which is given by ( see , for example , [ 22 ] ) dp,q =
1 2
( p − 2)(q − 2 ) − 1 +
( p − 2)(q − 2 ) − 1
1
2
2 − 1 .
Now , if this equivalent tree is to approximate the ( p , q) grid , its spectral gap must satisfy the Cheeger inequality with hp,q as in ( 10 ) . That is , we must have hp,q > λdp,q > h2 p,q 2 where
λdp,q = 1 − 2 dp,q dp,q − 1 .
After some algebra we see that when ( p − 2)(q − 2 ) > 4 these inequalities do hold strictly , as shown in Figure 3 .
We have shown previously that the Dirichlet spectral gap remains nonzero for successively larger d regular trees , for any d . This shows the approximation for the spectral gap of the ( p , q) grid is likely very close to its true value , further evidence of connections between global negative curvature , expansion , and bottlenecks .
9
Figure 3 : Comparison of the Cheeger ratio for ( p , q) grid with the spectral gap of tree with equivalent degree dp,q .
5 Spectral Decomposition
One important application of the eigendecomposition of a graph is spectral clustering or partitioning [ 20 , 24 ] . The problem is to group the nodes into partitions , clusters , or communities that are inherently well connected within themselves , with sparser connections between clusters . This is closely related to finding bottlenecks ; if a graph has a bottleneck , then a good partition is often found by dividing the graph at the bottleneck . See [ 23 ] for a general survey of graph clustering .
It is often desirable for a network partition to be balanced , and finding bottlenecks near the core or center of mass of a network is often more useful than simply clipping small subsets of nodes near the boundary . But according to [ 17 ] , using the Cheeger ratio as a metric on real world data , the “ best ” cuts larger than a certain critical size are actually “ bags of whiskers ” or combinations of numerous smaller cuts . Because many graph clustering algorithms , including spectral clustering , try to optimize for this metric , the resulting partitions often slice numerous smaller cuts off the graph , which is not always useful . For our Rocketfuel data , we know that the boundary of the network is imposed by the method of data collection . Thus , by eliminating the boundary from graph clustering , we can more easily find partitions that are more evenly balanced , and bottlenecks that are closer to the core of the network .
To do this , we use standard spectral clustering techniques from [ 20 ] , but instead
10 of using the normalized graph Laplacian L , we use the truncated Dirichlet version LD . The eigenvectors used for clustering will therefore not include components for the degree 1 boundary nodes , but we can assign them to the same side of the partition as their nonboundary neighbor nodes . Specifically , we compute the first two eigenvectors of LD and cluster the nodes based on their components in these eigenvectors using k means . For each node , we compute the distance to both centers and sort the nodes based on the difference . For a partition of size k , we take the top k nodes .
We follow the experiments of Leskovec et al . in [ 17 ] by using both traditional spectral clustering and Dirichlet spectral clustering to find cuts of different sizes . Specifically , we find Dirichlet cuts of all possible sizes , and then we find cuts using traditional spectral clustering for those same sizes after adding boundary nodes back in . Thus , for each network of N nodes , we calculate N − B cuts , where B is the number of boundary nodes .
For each cut , we measure the Cheeger ratio h and the number of components c . Ideally , a logical cut would split the network into exactly c = 2 components , but as Leskovec et al . demonstrated , as cut size increases , spectral clustering and other algorithms that optimize for h yield cuts with many components . This is precisely the problem we are trying to avoid using Dirichlet clustering , and our results show that Dirichlet clustering is effective in finding cuts with fewer components . Furthermore , even though our algorithm is not specifically optimizing for h , it does not find cuts that have significantly worse values for h while finding cuts with far fewer components .
Number of cuts in each category : cD > cT hD ≤ hT
5 11 37 24 13 0 0 cD > cT Average Average hD − hT hD > hT 0.0437 0.0066 0.0246 0.0402 0.0773 0.0341 0.0156 cD − cT 21.8020 4.9197 7.3013 97.1599 1.8038 9.1273 25.7487
48 31 68 128 229 11 0 cD ≤ cT Dataset hD ≤ hT 1221 1755 3257 3356 3967 4755 6461
89 124 121 509 98 23 350 cD ≤ cT hD > hT
362 107 75 420 245 20 415
Table 2 : Aggregate data comparing Dirichlet spectral clustering with traditional spectral clustering for several Rocketfuel datasets . For each dataset , we compute Dirichlet cuts of all possible sizes , and compare them with traditional spectral cuts with the same sizes . Smaller values of c and h are better . We classify the cuts into four categories , counting the number in each , and we also give the average difference in h and c between Dirichlet and traditional spectral clustering . The data shows that Dirichlet clustering finds cuts with many fewer components without significant adverse effects on the Cheeger ratio .
We outline some aggregate data in Table 2 . For several datasets , we count the number of cuts in four different categories , comparing the Dirichlet Cheeger ratio and number of components ( hD and cD ) with traditional spectral clustering ( hT and cT ) . It is
11 evident that Dirichlet clustering finds cuts with fewer components than traditional spectral clustering ( cD ≤ cT ) for most cut sizes , indicating that while spectral clustering optimizes for Cheeger ratio , it often “ cheats ” by collecting whiskers as one cut . In addition , despite the use of Cheeger ratio optimization , Dirichlet clustering sometimes finds cuts with better Cheeger ratio as well . In the last two columns for each dataset , we give the difference in h and c averaged out over all cut sizes . It turns out that the Cheeger ratios , on average , are not drastically different between the two methods , and Dirichlet clustering gives cuts with far fewer components .
Along with our aggregate data , we illustrate each individual cut for our Rocketfuel datasets in Fig 4 . For each cut size , we plot a point corresponding to the difference in Cheeger ratio h and the number of components c between Dirichlet and traditional spectral clustering . It should be clear that for the majority of cut sizes , Dirichlet clustering finds cuts with far fewer components , but there is generally little change in Cheeger ratio . This can be seen in the large variation on the c axis with much smaller discrepancies on the h axis . In other words , Dirichlet clustering avoids finding “ bags of whiskers ” while still maintaining good separation in terms of h , despite not explicitly optimizing for h .
It is clear that using Dirichlet eigenvalues improves the partition by ignoring the boundary , alleviating the tendency to find “ bags of whiskers ” without drastically changing the Cheeger ratio . Although traditional spectral clustering does not always fail , there is clear evidence that Dirichlet spectral properties are an important tool in the analysis of real world networks .
The spectral decomposition using Dirichlet eigenvalues also suggests a further connection to large scale negative curvature in the Rocketfuel data . Traditional negativelycurved graphs such as trees and hyperbolic grids generally exhibit poor connectivity and core congestion . Standard clustering often yields combinations of smaller cuts , but using Dirichlet clustering , we can see that there tend to be bad larger scale cuts as well in the Rocketfuel datasets . The presence of these larger scale cuts is a hallmark of negative curvature or hyperbolicity , suggesting the possibility of this property in the Rocketfuel data .
6 Discussion
Our results show evidence that Dirichlet eigenvalues can provide rich analytical information about real world networks , based on rigorous analysis using infinite d regular trees . While regular trees exhibit properties such as expansion , bottlenecks , and global negative curvature , the hyperbolic grids Hpq are the next logical candidate for study in this manner . Many properties such as the spectral gap remain open questions .
We saw that the Dirichlet spectral gap of successively larger trees in fact converges to the true spectral gap for infinite trees . It is possible to use similar techniques for realworld data : growing the network by increasing the radius from one or more centers of mass , and looking at the behavior of the Dirichlet spectral gap as the radius gets larger . Perhaps the Dirichlet spectral gap also converges as the radius gets larger , indicating a true spectral gap of an infinite version of the network .
With such evidence of a connection between global negative curvature , the spectral
12 gap , and expansion , it would be interesting to empirically compare the hyperbolicity δ , the Cheeger constant h , and the traditional and Dirichlet spectral gaps of Rocketfuel and other real world networks as well as well known network models . From this , it could be possible to classify various networks based on these properties .
References
[ 1 ] A L Barab´asi and R . Albert , Emergence of scaling in random networks . Science 286
( 1999 ) , 509–512 .
[ 2 ] A L Barab´asi , R . Albert and H . Jeong , Scale free characteristics of random networks : the topology of the World Wide Web . Physica A 281 ( 2000 ) , 69–77 .
[ 3 ] A . Broder , R . Kumar , F . Maghoul , P . Raghavan , S . Rajagopalan , R . Stata , A . Tomkins and J . Wiener , Graph structure in the Web . Computer Networks 33 ( 2000 ) , 1–6 .
[ 4 ] P . Cartier , Fonctions harmoniques sur un arbre . Symposia Mathematica 9 ( 1972 ) , 203–
270 .
[ 5 ] F . Chung , Random walks and local cuts in graphs . Linear Algebra and its Applications
423 ( 2007 ) , 22–32 .
[ 6 ] F . Chung , Spectral Graph Theory . Providence , RI : American Mathematical Society ,
1997 .
[ 7 ] F . Chung and A . Tsiatas , Finding and visualizing graph clusters using PageRank optimization . Proceedings of the Workshop on Algorithms and Models for the Web Graph ( WAW 2010 ) , Lecture Notes in Computer Science 6516 , 86 97 .
[ 8 ] J . Dodziuk and L . Karp , Spectral and function theory for combinatorial Laplacians ,
Geometry of Random Motion , Contemporary Mathematics 73 ( 1988 ) , 25–40 .
[ 9 ] J P Eckmann and E . Moses , Curvature of co links uncovers hidden thematic layers in the World Wide Web . Proceedings of the National Academy of Sciences 99 ( 2002 ) , 5825–5829 .
[ 10 ] P . Erd¨os and A . R´enyi , On the evolution of random graphs . Publications of the Math ematical Institute of the Hungarian Academy of Sciences 5 ( 1960 ) , 17–61 .
[ 11 ] M . Faloutsos , P . Faloutsos and C . Faloutsos , On power law relationships of the Internet topology . Proceedings of the Conference on Applications , Technologies , Architectures , and Protocols for Computer Communication ( SIGCOMM 1999 ) , 251–262 .
[ 12 ] J . Friedman , The spectra of infinite hypertrees . SIAM Journal on Computing 20 ( 1991 ) ,
951–961 .
[ 13 ] M . Gromov , Essays in Group Theory . Mathematical Sciences Research Institute Publi cations 8 ( 1987 ) , 75 .
13
[ 14 ] O . H¨aggstr¨om , J . Jonasson and R . Lyons , Explicit isoperimetric constants and phase transitions in the random cluster model . Annals of Probability 30 ( 2002 ) , 443–473 .
[ 15 ] E . Jonckheere , P . Lohsoonthorn and F . Banahon , Scaled Gromov hyperbolic graphs .
Journal of Graph Theory 57 ( 2008 ) , 157–180 .
[ 16 ] E . Jonckheere , M . Lou , F . Bonahon and Y . Baryshnikov , Euclidean versus hyperbolic congestion in idealized versus experimental networks . ArXiv e print 0911.2538 , 2009 .
[ 17 ] J . Leskovec , K . Lang , A . Dasgupta and M . Mahoney , Statistical properties of community structure in large social and information networks . Proceedings of the 17th International Conference on the World Wide Web ( WWW 2008 ) , 695–704 .
[ 18 ] B . McKay , The Expected Eigenvalue Distribution of a Large Regular Graph , Linear
Algebra and Applications , 40 ( 1981 ) , 203–216 .
[ 19 ] O . Narayan and I . Saniee , The large scale curvature of networks . ArXiv e print
0907.1478 , 2009 .
[ 20 ] A . Ng , M . Jordan and Y . Weiss , On spectral clustering : analysis and an algorithm .
Advances in Neural Information Processing Systems 14 ( 2002 ) , 849–856 .
[ 21 ] F . Papadopoulos , D . Krioukov , M . Boguna and A . Vahdat , Greedy forwarding in dynamic scale free networks embedded in hyperbolic metric spaces . Proceedings of the 29th Conference on Information Communications ( INFOCOM 2010 ) , 2973–2981 .
[ 22 ] R . Reitman , B . Nienhuis and J . Oitmaa , The Ising model on hyperlattices . Journal of
Physics A 25 ( 1992 ) , 6577–6592 .
[ 23 ] S . E . Schaeffer , Graph clustering . Computer Science Review 1 ( 2007 ) , 27–64 .
[ 24 ] J . Shi and J . Malik , Normalized cuts and image segmentation . IEEE Transactions on
Pattern Analysis and Machine Intelligence 22 ( 2000 ) , 888–905 .
[ 25 ] N . Spring , R . Mahajan and D . Wetherall , Measuring ISP topologies with Rocketfuel .
Proceedings of the 2002 SIGCOMM Conference , 133–145 .
[ 26 ] R . Teixeira , K . Marzullo , S . Savage and G . M . Voelker , In search of path diversity in
ISP networks . Proceedings of the 2003 SIGCOMM Conference , 2003 .
[ 27 ] D . Watts and S . Strogatz , Collective dynamics of ‘small world’ networks . Nature 393
( 1998 ) , 440–442 .
14
( a ) Dataset 1221
( b ) Dataset 1755
( c ) Dataset 3257
( d ) Dataset 3356
( e ) Dataset 3967
( f ) Dataset 6461
Figure 4 : Comparison of Cheeger ratio h and number of components c for cuts for various datasets using Dirichlet ( D ) and traditional ( T ) spectral clustering . Each point represents one possible cut size ; in general , Dirichlet clustering yields many fewer components without sacrificing much in Cheeger ratio .
15
