Mining Collective Intelligence in Diverse Groups
Guo Jun Qi† , Charu C . Aggarwal‡ , Jiawei Han† , Thomas Huang†
†University of Illinois at Urbana Champaign
{qi4 , hanj , t huang1}@illinois.edu ‡IBM TJ Watson Research Center charu@usibmcom
ABSTRACT Collective intelligence , which aggregates the shared information from large crowds , is often negatively impacted by unreliable information sources with the low quality data . This becomes a barrier to the effective use of collective intelligence in a variety of applications . In order to address this issue , we propose a probabilistic model to jointly assess the reliability of sources and find the true data . We observe that different sources are often not independent of each other . Instead , sources are prone to be mutually influenced , which makes them dependent when sharing information with each other . High dependency between sources makes collective intelligence vulnerable to the overuse of redundant ( and possibly incorrect ) information from the dependent sources . Thus , we reveal the latent group structure among dependent sources , and aggregate the information at the group level rather than from individual sources directly . This can prevent the collective intelligence from being inappropriately dominated by dependent sources . We will also explicitly reveal the reliability of groups , and minimize the negative impacts of unreliable groups . Experimental results on real world data sets show the effectiveness of the proposed approach with respect to existing algorithms .
Categories and Subject Descriptors H28 [ Database applications ] : Data mining ; Statistical databases
Keywords Collective intelligence ; Crowdsourcing ; Robust classifier
1 .
INTRODUCTION
Collective intelligence aggregates contributions from multiple sources in order to collect data for a variety of tasks . For example , voluntary participants collaborate with each other to create a fairly extensive set of entries in Wikipedia , or a crowd of paid persons may perform image and news article annotations in Amazon Mechanical Turk . These crowdsourced tasks usually involve multiple objects , such as Wikipedia entries and images to be annotated . The participating sources collaborate to claim their own observations , such as facts and labels , on these objects . Our goal is to aggregate these collective observations to infer the true values ( eg , the true fact and image label ) for the different objects [ 18 , 14 , 5 ] .
We note that an important property of collective intelligence is that different sources are typically not independent of one another .
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author ’s site if the Material is used in electronic media . WWW 2013 , May 13–17 , 2013 , Rio de Janeiro , Brazil . ACM 978 1 4503 2035 1/13/05 .
For example , in the same social community , people often influence each other , where their judgments and opinions are not independent . In addition , task participants may obtain their data and knowledge from the same external information source , and their contributed information will be dependent . Thus , it may not be advisable to treat sources independently and directly aggregate the information from individual sources , when the aggregation process is clearly impacted by such dependencies . In this paper , we will infer the source dependency by revealing latent group structures among involved sources . Dependent sources will be grouped , and their reliability is analyzed at the group level . The incorporation of such dependency analysis in group structures can reduce the risk of overusing the observations made by the dependent sources in the same group , especially when these observations are unreliable . This helps prevent dependent sources from inappropriately dominating collective intelligence especially when these sources are not reliable .
Moreover , we note that groups are not equally reliable , and they may provide incorrect observations which conflict with each other , either unintentionally or maliciously . Thus , it is important to reveal the reliability of each group , and minimize the negative impact of the unreliable groups . For this purpose , we study the general reliability of each group , as well as its specific reliability on each individual object . These two types of reliability are closely related . General reliability measures the overall performance of a group by aggregating each individual reliability over the entire set of objects . On the other hand , although each object specific reliability is distinct , it can be better estimated with a prior that a generally reliable group is likely to be reliable on an individual object and vice versa . Such prior can reduce the overfitting risk of estimating each object specific reliability , especially considering that we need to determine the true value of each object at the same time [ 11 , 1 ] . The remainder of this paper is organized as follows . We review the related work in Section 2 . Our problem and notations are formally defined in Section 3 . The probabilistic model for the problem is developed in Section 4 , followed by a running example that illustrates the impact of group dependency on the model in Section 5 . Section 6 presents the model inference and parameter estimation algorithms . Then Section 7 presents the application of the developed model to training classifiers from noisy crowdsourced data . We evaluate the model in Section 8 on real data sets , and summarize the paper with the conclusion in Section 9 .
2 . RELATED WORK
Aggregating crowdsourced knowledge and information has attracted a lot of research efforts , and yields many insightful discoveries . For example , [ 16 ] proposed an iterative truth finder algorithm by simultaneously accessing the trustworthiness of each source and the correctness of claimed facts . [ 1 ] developed a probabilistic graphical model by jointly modeling the abilities of participants and the correct answers to questions in an aptitude testing setting . The work in [ 18 ] developed a latent truth model to infer the source quality and correct claims by modeling two types of false positive and false negative errors of each source . All of these algorithms estimate the performances of data sources and the impacts on the credibility of their claimed facts .
However , sources are not independent of each other in real world . Instead , their contributions are typically dependent . [ 16 ] noted this problem and used a dampening factor to compensate for excessively high confidence due to the copied content between sources . But this method did not explicitly model the dependency between sources , and how the dampening factor can reduce the dependency effect is not clear . On the other hand , [ 4 ] studied the relation between the content claimed by sources , and developed a separate weighted voting algorithm by considering the copied content between each other . However , the accuracies are accessed independently on the source level , which can make the accuracy of a data source overestimated if many other dependent sources repeat the same false facts .
Moreover , existing models [ 4 , 2 , 9 , 6 ] only consider the pairwise relations between sources to their dependency , which completely ignores the higher order dependency among sources . In contrast , we explicitly group the dependent sources to capture arbitrary orders of dependency among sources . We find that high order dependency prevails in many real cases , and it is more effective to model them directly rather than decomposing them into separate pairwise relations . For example , sources which obtain the content from the same resource will be assigned to the same group to reflect the high order dependency among them . This yields a more compact representation to jointly assess the reliability of data sources and the correctness of the claimed facts . Moreover , we will see based on the group level dependency , independent sources from different groups will play more important role than dependent ones in the same group in inferring the true facts . This is a desired property which can properly aggregate collective knowledge in many real world tasks .
Modeling the group dependency can be analogized to the community discovery in social networks . Community structure has been considered as a more effective data structure to capture the social relations among people than the links between pairs of persons [ 7 ] . With the similar spirit , the groups can also be more effective than pairwise dependency , and provide deeper insight into the property of high order dependency among sources and how such property affects the aggregation of collective knowledge . However , it is worth pointing out that the groups defined in our model differ from the communities [ 3 ] in social networks . Communities are usually defined as a set of people densely linked in social networks . However , two linked people may not necessarily be influenced by one another when they report the facts and knowledge . Two close friends can express different opinions and claim conflicting truths . Therefore , we will directly investigate the data contributed by sources to find the group structure characterizing their mutual dependency that directly affects the source reliability in our collective intelligence model .
Finally , our model is motivated to explore the objective facts and knowledge . This is in contrast to the inference of individual ’s preference , which aims to recommend products and services based on user ’s ratings and opinions [ 12 ] . Instead , in this paper we aim at aggregation of collective knowledge to automatically extract the true facts , such as correct answers to questions and true categories for
Figure 1 : An example illustrating a set of five sources with their observations on four objects . web pages , which do not depend on the variability of user ’s subjectivity .
3 . PROBLEM DEFINITIONS
We formally define the following Multi Source Sensing ( MSS ) model which abstracts the description of collective intelligence . Suppose that we have a set S := {S1 , S2,··· , SN} of N sources , and a set O := {O1 , O2,··· , OM} of M objects . Each object Om takes a value tm from a domain Xm which describes one of its attributes . Each source Sn in S reports its observation yn,m ∈ Xm on an object Om . Then the goal of the MSS model is to infer the true value tm of each object Om from the observations made by sources . We introduce some notations , which will be used consistently in this paper . We will use n , m , l and k in the subscript to index sources , objects , groups and values in an object domain , respectively . The variables y , t , u and r denote the observations , true values , group reliability and object specific reliability respectively . In this paper , we are particularly interested in categorical domain Xm = {1,··· , Km} with discrete values . For example , in many crowdsourcing applications , we focus on the ( binary valued ) assertion correctness in hypothesis test and ( multi valued ) categories in classification problem . However , the MSS model can be extended to continuous domain with some effort by adopting the corresponding continuous distributions . Due to the space limitation , we leave this extension in the full version of this paper .
Figure 1 illustrates an example , where five sources make their observations on four objects . An object can be an image or a biological molecule , and an annotator or a biochemical expert ( as a source ) may claim the category ( as the value ) for each object . Alternatively , an object can be a book , and a book seller web site ( as a source ) claims the identity of its authors ( as the values ) . In a broader sense , objects are even not concrete objects . They can refer to any crowdsourced tasks , such as questions ( eg , “ is Peter a musician?" ) and assertions ( eg , “ George Washington was born on February 22 , 1732." and “ an animal is present in an image," ) , and the observations by sources are the answers to the questions , or binary valued positive or negative claims on these assertions . It is worth noting that each source does not need to claim the observations on all objects in O . In many tasks , sources make claims only on small subsets of objects of interest . Thus , for notational convenience , we denote all claimed observations by y in bold , and use I = {(n , m)|∃ yn,m ∈ y} to denote all the indices in y . We use the notations In,· = {m|∃ ( n , m ) ∈ I} and
S1S2S3S4O1O2O3S5y1,1y2,2y3,1y3,3y4,2y4,3y5,3y5,4ObservationsG2G1Latent Groupsg1g2g3g4g5O4SourcesObjectsS5y5,4g5O4 I·,m = {n|∃ ( n , m ) ∈ I} to denote the subset of indices that are consistent with the corresponding subscripts n and m . Meanwhile , in order to model the dependency among sources , we assume that there are a set of latent groups {G1 , G2,···} , and each source Sn is assigned to one group Ggn where gn ∈ {1 , 2,···} is a random variable indicating its membership . For example , as illustrated in Figure 1 , the five sources are inherently drawn from two latent groups , where each source is linked to the corresponding group by dotted lines . Each latent group contains a set of sources which are influenced by each other and tend to make similar observations on objects . The unseen variables of group membership will be inferred mathematically from the underlying observations . Here , we do not assume any prior knowledge on the number of groups . The composition of these latent groups will be determined with the use of a Bayesian nonparametric approach by stickbreaking construction [ 15 ] , as to be presented in the next section .
To minimize the negative impact of unreliable groups , we will explicitly model the group level reliability . Specifically , for each group Gl , we define a group reliability score ul ∈ [ 0 , 1 ] in unit interval . This value measures the general reliability of the group over the entire set of objects . A higher value of ul indicates the greater reliability of the group . Meanwhile , we also specify the reliability rl,m ∈ {0 , 1} of each group Gl on each particular object Om . When rl,m = 1 , group Gl will have reliable performance on Om , and otherwise it will be unreliable . The reason that we distinguish between reliability ul and object specific reliability rl,m is as follows . While a generally reliable group with a larger value of ul , provides very useful evidence about the members of the group on a generic basis , there are likely to be natural variations within the group itself . Thus , in our model , a group reliability ul only measures how likely it will be reliable on object set , and whether it will have a reliable performance on a particular object is given by rl,m . In the next section , we will clarify the relationship between general reliability ul and object specific reliability rl,m .
4 . MULTI SOURCE SENSING MODEL
In this section , we present a generative process for the multisource sensing problem . The output of this model will contain the following three aspects : ( 1 ) the group membership of sources which describes their dependency when claiming their observations on a set of objects . ( 2 ) the reliability ul associated with each group and its specific reliability rl,m on each object . ( 3 ) the true values tm for each object . Our goal is to reveal the connections between these three aspects , especially how the collective observations made by sources can be explained by the latent groups and their reliability in a unified probabilistic framework .
First we define the following generative model for multi source sensing ( MSS ) process below , the details of which will be explained shortly .
1 . Draw λ ∼ GEM(κ ) ( ie , stick breaking construction with concentration κ ) .
2 . For each source Sn ,
21 Draw its group assignment gn|λ ∼ Discrete(λ ) ;
3 . For each object Om ,
31 Draw its true value tm ∼ Uniform(Xm ) ;
4 . For each group Gl :
41 Draw its group reliability ul ∼ Beta(b1 , b0 ) ;
Figure 2 : The graphical model for multi source sensing . The three plates represent group reliability ul with l = 1 , 2,··· , , the true values tm for each object Om with m = 1,··· , M , and the group assignment gn of each source with n = 1,··· , N , respectively .
5 . For each pair of group Gl and object Om :
51 Draw reliability indicator rl,m ∼ Bernoulli(ul ) ; 52 Draw the observation model parameter
πl,m|rl,m , tm = z ∼ Hrl;m ( tm ) for group Gl on object Om ;
6 . For each ( n , m ) ∈ I :
61 Draw observation yn,m|πl,m , gn ∼ F ( πgn,m ) ;
Here , gn|λ ∼ Discrete(λ ) denotes a discrete distribution , which generates the value gn = l with probability λl ; H and F are a pair of conjugate distributions which are determined by the type of data values on objects . For categorical values , these are Dirichlet and Multinomial distributions , respectively . Figure 2 illustrates the generative process in a graphical representation . We will explain the details later .
In Step 1 , we adopt the stick breaking construction GEM(κ ) ( named after Griffiths , Engen and McCloskey ) with concentration parameter κ ∈ R+ to define the prior distribution of assigning each source Sn to a latent group Ggn [ 15 ] . Specifically , in GEM(κ ) , a set of random variables ρ = {ρ1 , ρ2,···} are independently drawn from the Beta distribution ρi ∼ Beta(1 , κ ) . They define the mixing weights λ of the group membership component such that i=1 ( 1 − ρi ) . By the aforementioned p(gn = l|ρ ) = λl = ρl l−1 stick breaking process , we do not need the prior knowledge of the number of groups . This number will be determined by capturing the degree of dependency between sources .
∏
Clearly , we can see that the parameter κ in the above GEM construction plays the vital role of determining a priori the degree of dependency between sources . According to the GEM construction , we can verify that the probability of two sources Sn and Sm being assigned to the same group is given by the following :
+∞∑ +∞∑ l=1
P ( gn = gm ) =
+∞∑
= l=1
2 l =
E λl
E
P ( gn = ljλ)P ( gm = ljλ ) )
( l−1
2
( 1 + )(2 + )
2 + l=1
( 1 )
=
1
1 +
It is evident that when κ is smaller , sources are more likely to be assigned to the same group where they are dependent and share the tmyn,mπl,mm=1,…,Mgeneral reliabilityrl,mul,()lmrmHttrue value object specificreliabilityl=1,…,+∞n=1,…,Ngnn,mgroupassignment same observation model . This will yield higher degree of dependency between sources . As κ increases , the probability that any two sources belong to the same group will decrease . In the extreme case , as κ → +∞ , this probability approaches zero . In this case , all sources will be assigned to distinctive groups , yielding complete independence between sources . This shows that the model can flexibly capture the various degrees of dependency between sources by setting an appropriate value of κ . In Step 3 , we adopt the uniform distribution as the prior on the true value tm of each object over its domain Xm . The uniform distribution sets an unbiased prior so that true values will be completely determined a posteriori given observations in the model inference . In Section 7 , we will show how to set a more informative prior when more knowledge about objects is available .
In Step 4 , we define a Beta distribution Beta(b1 , b0 ) on the group reliability score ul , where b1 and b0 are the soft counts which specify whether a group is reliable or not a priori , respectively . Then , in Step 5.1 , object specific reliability rl,m ∈ {0 , 1} is sampled from the Bernoulli distribution Bern(ul ) to specify the group reliability on a particular object Om . The higher the general reliability ul , the more likely Gl is reliable on a particular object Om with rl,m being sampled to be 1 . This suggests that a generally more reliable group is more likely to be reliable on a particular object . In this sense , the general reliability serves as a prior to reduce the over fitting risk of estimating object specific reliability in the MSS model .
In Step 5.2 , the model parameter πl,m for each group on a particular object is drawn from the conjugate prior Hrl;m ( tm ) , which depends on the true value tm and the object specific group reliability rl,m . Then , given the group membership gn , each source Sn generates its observation yn,m according to the corresponding group observation model F ( πgn,m ) in Step 6 . In the next subsection , we will detail the specification of Hrl;m ( tm ) and F ( πl,m ) in categorical domain .
4.1 Group Observation Models
In this subsection , we discuss the specification of group observation distribution F ( πl,m ) and its conjugate distribution Hrl;m ( tm ) for categorical values on each object . Here the group observation model on each object depends on two factors : ( 1 ) the specific reliability rl,m on this object , which aims to reveal the differences between reliable and unreliable observations on an object , and ( 2 ) the true value tm for the object .
It is worth noting that although we distinguish each group observation into reliable and unreliable cases in this subsection , it does not mean that two groups are enough to capture the source dependency . These two cases are used to model the performance at the object level . However , given more objects , there are many possible combinations of these two cases on different objects . This is why we need more groups to capture the source dependency based on their observations on different objects . In the following , we will discuss the group observations models on each object .
In categorical domains , for each group , we choose the multinomial distribution as its observation model to generate each observation yn,m for its member sources on each object Om . Thus , Step 6 in the generative process of MSS model becomes the following : yn,m|πl,m , gn ∼ F ( πgn,m ) ∆= Multinomial(πgn,m ) where πl,m is the parameter of multinomial distribution for group Gl on object Om . Here , all member sources in the same group share the same observation model to capture their dependency .
The model parameter πl,m is generated by the following :
πl,m|rl,m , tm = z ∼ Hrl;m ( tm ) {z } ∆= Dir(θ(rl;m),···
, η(rl;m )
|
↓
,··· , θ(rl;m ) ) z−1 zth entry where Dir denotes Dirchlet distribution , and θ(rl;m ) and η(rl;m ) are its soft counts for sampling the false and true values under different settings of rl,m .
If group Gl has reliable observations for object Om ( ie , rl,m = 1 ) , it should be more likely to sample the true value tm = z as its observation than sampling any other false value . Thus , we should set a larger value for η(rl;m ) than for θ(rl;m ) .
On the other hand , if group Gl has unreliable observations for object Om , ie , rl,m = 0 , it should not be more likely to claim the true value for the object than claiming the false values . Therefore , the group observation model should have η(0 ) no larger than θ(0 ) , ie , η(0 ) ≤ θ(0 ) . Specifically , the mathematical model can distinguish between uninformative and malicious observations on the target object :
I . Uninformative observation : When η(0 ) = θ(0 ) , sources in group Gl make uninformative observations on object Om , since false values are equally likely to be claimed as the true value . This can be caused when these sources either carelessly claim their observations at random , or lack the knowledge about the target object .
II . Malicious observation : When η(0 ) < θ(0 ) , it suggests that the group Gl contains malicious sources which tend to claim false values for object Om . Compared with uninformative observations , these malicious observations can even provide us with some information about the target object by interpreting the observations in a reverse manner . Actually , with θ(0 ) > η(0 ) , the model gives the unclaimed observation larger weight to be evaluated as the true value .
In summary , depending on rl,m , the sources in group Gl make either reliable ( when rl,m = 1 ) or unreliable ( when rl,m = 0 ) observations on a particular object Om . Accordingly , the corresponding parameters η(rl;m ) and θ(rl;m ) are constrained in different ways . When rl,m = 1 , we impose a strict inequality η(1 ) > θ(1 ) to enforce that group Gl is more likely to claim the true value . On the contrary , when rl,m = 0 , we have θ(0 ) ≥ η(0 ) , representing that Gl will be unreliable in terms of claiming the true value for Om . In Section 6 , we will see how these parameters can be estimated by maximizing the observation likelihood of the MSS model subject to these constraints .
By putting together these different pieces , the MSS defines a p(ul|b1 , b0)p(rl,m|ul )
M∏
L,M∏ l=1,m=1 complete distribution p(y , g , r , u , t , π| . ) = p(tm ) ∏ ×p(πl,m|rl,m , tm , η(rl;m ) , θ(rl;m ) ) m=1
× N∏ p(gn|κ ) n=1
( n,m)∈I p(yn,m|gn , πgn,m ) over g = {gn} , r = {rl,m} , u = {ul} , t = {tm} , π = {πl,m} and the source observations y with model parameters . = {η(0 ) , θ(0 ) , η(1 ) , θ(1 ) , b1 , b0 , κ} . In Section 6 , we will present how to infer ( 1 ) the true values tm for each object , ( 2 ) group assignment gn of each source , and ( 3 ) the general reliability ul of each group and its specific reliability rl,m on each object from the MSS model a posteriori given the observations y .
( a ) An running example
( b ) Likelihoods of two hypotheses
( c ) Minimal number of independent sources to overturn the claims by S dependent sources ( solid blue curve ) .
Figure 3 : ( a ) A running example with S dependent sources in the same group and T independent sources . ( b ) Comparison of the likelihoods of two hypotheses ( in Y axis ) versus varying number T of independent sources ( in X axis ) . The number of dependent sources in the group is fixed to S = 20 . ( c ) The minimal number of independent sources ( in Y axis ) to overturn the claims made by varying number of dependent sources ( in X axis ) . The results are obtained with η(1 ) = 10 , θ(1 ) = 5 , and η(0 ) = θ(0 ) = 10 .
4.2 Multiple Attributes
In some cases , an object might have multiple attributes . There are many such examples as follows .
• A person can have many attributes . For example , she/he has a hobby of playing piano and takes “ software engineer" as her/his vocation . We can consider hobby and vocation as two attributes for each person , and define their values on two different domain sets such as {playing piano , hiking , swimming , traveling ··· } and {software engineer , stock trader , university faculty , ··· } in MSS model , respectively .
• An image can be labeled as “ tiger" as well as “ forest" . We can consider the presence of these two nonexclusive labels as two different attributes , and their values are boolean {Present , Not Present} for an image . In this way , we can allow an image has multiple labels simultaneously .
• A movie can have multiple actors/actresses . We can treat each actor/actress as an attribute , and use a binary value {1,0} to denote whether an actor/actress participates in a particular movie or not .
We can see in these examples , our MSS model is much flexible to handle multiple attributes associated with each object . Moreover , we note that different attributes often correlate with each other . For example , image labels “ tiger" and “ forest" often co occur in an image , and some actors/actresses may tend to co star a movie . Exploring these attributes together can improve the accuracy of inferring their true values .
5 . DEPENDENCE VS . INDEPENDENCE :
A RUNNING EXAMPLE
In this section , we show a running example that demonstrates how group reliability structure captures the dependency between sources when it infers the true value for an object . In Figure 3(a ) , we show a group of S sources and T independent sources . We consider an ideal case where the S sources in the group make an unanimous claim of the value 0 for an object , while the T independent sources unanimously claims the opposite value 1 for the same object . While the dependent sources in the group and the independent sources claim the different values in this example , we can investigate different values of information contributed by these sources . Especially , we wonder whether independent sources play more important roles than dependent ones in finding the true value for each object in the MSS model .
For this purpose , we test the following two hypotheses : • H0 : The true value for the object is 0 , versus • H1 : The true value for the object is 1 . To decide which hypothesis is true , we compare the observation likelihoods given these two hypotheses in the MSS model . Figure 3(b ) compares the two likelihoods with varying number T of independent sources . The number of dependent sources is fixed to S = 20 . We can see with more than T = 14 independent sources , H1 has a larger likelihood than H0 . In this case , the claims made by independent sources become more credible than that made by dependent sources . This example shows fewer independent sources can overturn the claim made by more dependent sources . This suggests that each dependent source contains less information about the true claim as compared with each independent source . To make this point more clear , Figure 3(c ) illustrates the minimum number of independent sources to ensure p(y|H1 ) > p(y|H0 ) under varying number of dependent sources S in the group . We can see that usually fewer independent sources is needed to have its claim accepted compared with the same number of dependent sources . This shows that independent sources are more valuable than dependent sources in determining the true value for each object . This is a desired property in our model , since we would like to de emphasize the excessive impacts of dependent sources in a group .
Of courses , in the real world , sources may not be ideally split into dependent ones in a group , and completely independent ones . The independent sources may not make unanimous claims as in this case . However , this intuitive running example explains how
000001111ST14204060−50−40−30−20−100Number of Independent Sources T logP(y|H0)logP(y|H1)10203040500101420304050Group Size S the dependency encoded in group structure will affect the inference of true value on an object , and illustrates the independent claims are generally more valuable than dependent claims in the MSS model .
6 . MODEL INFERENCE AND PARAMETER
ESTIMATION
In this section , we present the inference and learning processes . We wish to infer the tractable posterior p(g , r , u , t , π|y ) with a parametric family of variational distributions in the factorized form :
∏ q(tm|νm ) n
∏ q(gn|φn )
∏ q(πl,m|αl,m ) l,m q(rl,m|τ l,m )
∏ q(g , r , u , t , π ) = q(ul|βl )
∏ l m l,m with parameters φn , τ l,m , βl , νm and αl,m for these factors . The distribution and the parameter for each factor can be determined by the variational approach [ 10 ] . Specifically , we aim to maximize the lower bound of the log likelihood log p(y ) , ie , log p(y ) ≥ E q log p(g , r , u , t , π , y)−E q
( log q(g , r , u , t , π ) ) ∆= L(q )
This can obtain the optimal factorized distribution . The lower bound can be maximized over one factor while the others are fixed . This is an approach which is similar to coordinate descent . In each iteration , all the factors are updated sequentially over steps by finding the fixed point solutions until convergence . The details of these updating steps are provided in Appendix A .
We analyze the computational complexity in one loop of updating all factors . Suppose that we are given N sources , M objects , and obtain L groups by the stick breaking construction . We also denote by Kmax the maximum size of the domain sets among all objects . Then by investigating the updating steps in Appendix A , we can find that the computational complexity is O(N M LKmax ) for one loop .
On the other hand , the model parameters . can be estimated by maximizing the observation likelihood . This can be done by the EM algorithm : E Step : Given the current parameters in . , apply variational inference to obtain the factorization q and their variational parameters ; M Step : Given the factorization q , maximize the lower bound L(q ) of the log likelihood and obtain a new model parameter ( Details of this Maximization step are given in Appendix B . )
These two steps are iterated until convergence . We obtain the variational approximation and the maximum likelihood parameter estimation results simultaneously .
7 . CLASSIFICATION PROBLEMS
We are often of particular interest in the classification problem where each object takes a class as its value from a K class domain X = {1 , 2,··· , K} . Moreover , we might be able to access the feature representations for the objects in O . For example , if the objects are genetic sequences or text documents , we can extract their feature descriptors to describe the genetic structure and document content . Therefore , we wish to impose a more informative prior that aggregates these features into the prior distribution . For this purpose , given a feature vector xm for an object , the prior on tm becomes a conditional distribution on xm . For greater modeling flexibility , we choose a distribution for this prior . For example , we
}
{
K∑ can choose an exponential distribution p(tm|xm , W ) : Exp(W ) := p(tm|xm , W ) =
δ [ [tm = k]]⟨wk , x⟩ ( 2 ) where each coefficient vector is taken from the parameters W = {wk|k ∈ X} , ⟨wk , x⟩ denotes the inner product between two vectors , and Z is the normalization factor to ensure that the above exponential distribution integrates to unit value .
1 Z exp
Accordingly , the model inference in Step A.4 in Appendix A should be changed . Each updated factor q(tm ) in model inference becomes an exponential distribution : k=1
δ [ [tm = k ] ] νm;k}
( 3 ) with the parameter νm defined as follows : q(tm|νm ) := exp{ K∑ ∑ ∑
∑ k=1 rl l
νm;k = ⟨wk , x⟩ + × E ln πl,m;k + q(l;m ) k′̸=k q(rl){(η(rl ) − 1 ) ( θ(rl ) − 1 ) E q(l;m ) ln πl,m;k′}
The other updating steps for the model inference in Appendix A stay the same . Besides the inference , we need to learn the parameter W in p(tm|xm , W ) . Here , we adopt the variational EM ( ExpectationMaximization ) algorithm . In each iteration , the E step ( expectation ) involves computing the tractable posterior distributions as in the inference step . Then , the maximization step will update W by maximizing the expected log likelihood over q as follows :
Eq(tm|m ) log p(tm|xm , W )
( 4 )
M∑ max
W m=1
We can adopt any off the shelf optimization algorithms to solve the above problem . The learned parameterized model p(tm|x , W ) , as a byproduct , is a classifier conditional on the input feature vector x . This provides us with a way to train a robust classification model with the noisy crowdsourced labels , compared with typical classifiers trained with the clean labels . On the other hand , the learned classifier enhances the MSS model by providing a more discriminative prior of the labeling information on objects through their feature representations . This regularizes the true classes of objects in the feature space , especially when the classes claimed by different sources on an object are too scarce or too inconsistent to make robust estimation of the true classes . In this case , the imposed prior plays a nontrivial role in determining the true class of the object .
8 . EXPERIMENTAL RESULTS
In this section , we compare our approach with other existing algorithms and demonstrate its effectiveness for inferring source reliability together with the true values of objects . The comparison is performed on a book author data set from online book stores , and a user tagging data set from the online image sharing web site Flickrcom 8.1 Online Book Store Data Set
The first data set is the book author data set prepared in [ 16 ] . The data set is obtained by crawling 1 , 263 computer science books on AbeBookscom For each book , AbeBooks.com returns the book information extracted from a set of online book stores . This data set contains a total of 877 book stores ( sources ) , and 24 , 364 listings of books ( objects ) and their author lists ( object values ) reported by these book stores . Note that each book has a different categorical domain that contains all the authors claimed by sources . Our goal is to predict the true authors for each book .
Author names are normalized by preserving the first and last names , and ignoring the middle name of each author . For evaluation purposes , the authors of 100 books are manually collected from scanned book covers [ 16 ] . We compare the returned results of each model with the ground truth author lists on this test set and report the accuracy .
We compare the proposed algorithm MSS with the following baselines : ( 1 ) the naive voting algorithm which counts the top voted author list for each book as the truth ; ( 2 ) TruthFinder [ 16 ] ; ( 3 ) Accu [ 4 ] which considers the dependency between sources ; ( 4 ) 2Estimates as described in [ 5 ] with the highest accuracy among all the models in [ 5 ] .
Table 3 compares the results of the different algorithms on the book author data set in terms of the accuracy . The MSS model achieves the best accuracy among all the compared models . We note that the proposed MSS model is an unsupervised algorithm which does not involve any training data . In other words , we do not use any true values in the MSS algorithm in order to produce the reliability ranking as well as other true values . Even compared with the accuracy of 0.91 of the Semi Supervised Truth Finder ( SSTF ) [ 17 ] using extra training data with known true values on some objects , the MSS model still achieves the highest accuracy of 095 Figure 4(a ) illustrates the scatter plot between the predicted reliability ul for each group and its test accuracy . From this figure , it is evident that the group reliability obtained from the MSS model is a good predictor of the true accuracy for each group . Meanwhile , we also report three example groups in Table 1 . It is evident that within each group , the member sources have much consistent reliability as they make dependent claims . Therefore , by accurately predicting reliability of groups , the proposed MSS model can appropriately aggregate the contributions from differen groups based on their performances and gain the competitive accuracy as shown above .
Moreover , to compare the reliability between sources , we can define the reliability of each source Sn by the expected reliability score of its assigned groups as follows :
∑
Reliability(Sn ) = where l q(gn = l ) E q(ul|fil )
[ ul ]
E q(ul|fil )
[ ul ] =
βl,1
βl,1 + βl,2
Then , sources can be ranked based on such source reliability . In Table 2 , we rank the top 10 and bottom 10 book stores in this way . In order to show the extent to which this ranking list is consistent with the real source reliability , we provide the accuracy of these bookstores on test data sets . Note that each individual bookstore may only claim on a subset of books in the test set , and the accuracy is computed based on the claimed books . From the table , we can see that the obtained rank of data sources is consistent with the rank of their accuracies on the test set . On the contrary , the accuracy of the bottom 10 bookstores is much worse compared to that of the top 10 book stores on the test set . This also partially explains the better performance of the MSS model .
Since κ influences the dependency modeling between sources , we study the sensitivity of the model accuracy versus κ in Figure 3 . We know that when κ = 0 , all sources are completely dependent , and assigned to the same group . At this point , the model has a much
Table 4 : The rounds used before convergence and computing time for each model .
Model
Voting 2 Estimates TruthFinder Accu MSS
Bookstore
Rounds Time(s ) 1 29 8 22 9
0.2 21.2 11.6 185.8 10.3
User Tagging
Rounds Time ( s ) 1 32 11 23 12
0.5 628.1 435.0 3339.7 366.2
( a ) Book author data set
( b ) Flickr data set
Figure 4 : Scatter plots on two data sets . The horizontal axis represents the predicted group reliability by ul and the vertical axis represents the average accuracy of the member sources on the test set . The slope of each red line in the scatter is the correlation coefficient which shows the statistical correlation between ul and the average accuracy . lower accuracy , since all sources are tied to the same level of reliability within a single group . As κ increases , the accuracy achieves the peak at κ = 50 After that point , it deteriorates as the model gradually stops capturing the source dependency with increased κ . This demonstrates the importance of modeling the source dependency , and the capability of the MSS model in capturing such dependencies with κ . 8.2 Flickr Image Tagging Data Set
We also evaluate the algorithm on a user tagging data set from an online image sharing web site Flickrcom This data set contains 13 , 528 users ( data sources ) who annotate 36 , 280 images ( data objects ) with their own tags . We consider 12 tags “ balloon," “ bird," “ box," “ car," “ cat," “ child," “ dog," “ flower," “ snow leopard," “ waterfall," “ guitar," “ pumpkin" for evaluation purposes . Each tag is associated with a binary value 1/0 to represent its presence or not in an image . This forms a multi attribute model with these 12 tags to find whether they are present on each image as described in Section 42 Different from the book author data set , we apply the extended classification model in Section 7 , where the visual content of each image is represented by a 8 , 000 dimensional hierarchical gaussian [ 19 ] feature vector .
Figure 4 illustrates some image examples in this data set and the tags annotated by users . It is evident that some images are wrongly tagged by users . The MSS model aims to correct these errors and yield accurate annotations on these images . To test accuracy , we manually annotate these 12 tags on a subset of 1 , 816 images .
We follow the same experimental setup as on the book author data set . For the sake of fair comparison , we adopt the variants in [ 8 ] to incorporate visual features to enhance the original algorithms for comparison by inferring the true values based on object clusters in
00204060810020406081Predicted group reliabilityAverage accuracy on test setcorrelation coefficient = 0906300204060810020406081Predicted group reliabilityAverage Accuracy on test setcorrelation coefficient = 0.8676 Table 1 : Three example groups among all 33 groups discovered by the MSS model on book author data set . The parenthesis after the name of each bookstore is its accuracy on test set .
Group I FREE US AIR SHIPPING ( 0.3750 ) TheBookCom ( 0.3556 ) Browns Books ( 0.3438 ) Mellon ’s Books ( 0.4000 )
Group III
Group II The Book Depository ( 0.3043 ) DVD Legacy ( 0.5833 ) textbookxdotcom ( 0.4444 ) Caiman ( 0.3855 ) Bobs Books ( 0.4615 ) Books Down Under ( 0.4750 ) Limelight Bookshop ( 0.3896 ) Powell ’s Books ( 0.3810 )
Englishbookservice.com ( 0.5500 ) Henry ’s Biz Books ( 0.6000 ) Blackwell Online ( 0.6579 ) Morgenstundt Buch & Kunst ( 0.6207 )
Table 2 : Top 10 and bottom 10 book stores ranked by their posterior probability of belonging to a reliable group . We also report the accuracy of these bookstores on the test set . top 10 bookstore International Books happybook eCampus.com COBU GmbH & Co . KG HTBOOK AlphaCraze.com Cobain LLC Book Lovers USA Versandantiquariat Robert A . Mueller THESAINTBOOKSTORE accuracy 1 1 0.9375 0.875 1 0.8462 1 0.8667 0.8158 0.8214 accuracy bottom 10 bookstore 0.0476 textbooksNow Gunter Koppon 0.225 wwwtextbooksruscom 0.3333 0.2308 Gunars Store 0.3846 Indoo.com Bobs Books 0.4615 0 OPOE ABE Books 0.3043 The Book Depository 0.3896 Limelight Bookshop textbookxdotcom 0.4444
( a ) balloon
( b ) snow leopard
( c ) guitar
( d ) pumpkin
Figure 5 : Parametric Sensitivity : model accuracy versus different κ on book author data set .
Figure 6 : Examples of image and the associated user tags in Flickr data set . In each subfigure the left image is correctly tagged by users , while the right one is wrongly tagged . the feature space . It has shown better accuracy compared with the original algorithms [ 8 ] . Table 3 shows the average precision and recall on the 12 tags by the compared algorithms . We can see that MSS still performs the best among these compared algorithms . The Figure 4(b ) illustrates the scatter plot between the predicted reliability of each group and the average accuracy of its member sources on the test set . It is evident that the obtained group reliability is still a good predictor of the true accuracy with strong correlation coefficient 08676 This guarantees a competitive performance of the MSS model on this Flickr data set as on the book author data set .
We also compare the computational time used by different algorithms in Table 4 . The experiments are conducted on a personal computer with Intel Core i7 2600 3.40 GHz CPU , 8 GB physical memory and Windows 7 operating system . We can see that compared with most of other algorithms , MSS model can converge in fewer rounds with less computational cost .
9 . CONCLUSION
In this paper , we propose an integrated true value inference and group reliability approach . Dependent sources which are grouped together , and their ( general and specific ) reliability is assessed at the group level . The true data values are extracted from the reliable groups so that the risk of overusing the observations from dependent sources can be minimized . The overall approach is described by a probabilistic multi source sensing model , based on which we jointly infer group reliability as well as the true values for objects a posterior given the observations from sources . The key to the success of this model is to capture the dependency between sources , and aggregate the collective knowledge at the group granularity . We present experimental results on two real data sets , which demonstrate the effectiveness of the proposed model over other existing algorithms .
Acknowledgements Research was sponsored by the Army Research Laboratory and National Science Foundation and was accomplished under Cooperative Agreement Number W911NF 09 2 0053 and Grant IIS 1144111 . The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies , either expressed or implied , of the Army Research Laboratory or the US Government . The US Government is au
0650707508085090951005125810121520Accuracyκ Table 3 : Comparison of different algorithms on book author and Flickr data set . On book author data set , the algorithms are compared by their accuracies . On Flickr data set , the algorithms are compared by their average precisions and recalls on 12 tags .
Model book author data set accuracy
Voting[4 ] 2 Estimates[5 ] TruthFinder[17 ] Accu[4 ] MSS
0.71 0.73 0.83 0.87 0.95
Flickr data set precision 0.8499 0.8545 0.8637 0.8731 0.9176 recall 0.8511 0.8602 0.8649 0.8743 0.9212 thorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on . The first author was also in part supported by an IBM Fellowship and National Natural Science Foundation of China under Grant 61272214 . Appendix A : Model Inference In this Appendix , we derive the variational inference for the proposed MSS model , and give the detail steps to update the variational parameters in each factor . A.1 : Update each factor q(πl,m|αl,m ) for the group observation parameter πl,m .
By variational approach , we can verify that the optimal q(πl,m|αl,m ) has the form
∑ q(πl,m|αl,m ) ∝ exp{ ∏
+ n∈I·;m q(rl;m),q(tm ) ln p(πl,m|rl,m , tm )
E ln p(yn,m|πl,m , gn)}
E q(gn )
αl;m;k−1
πl,m;k k∈X
It still has Dirichlet distribution with the parameters q(gn = l)δ [ [yn,m = k ] ]
∝
∑ ∑ n∈I·;m
αl,m;k =
+ q(rl,m)[(η(rl;m ) − 1)q(tm = k )
E q(l;m )
It is evident that the above updated parameter sums up the posterior reliability q1(rl,m ) and q0(rl,m ) over all objects . This corresponds to the intuition that the general reliability is the sum of the reliability on individual objects . A.3 : Update each factor q(rl,m|τ l,m ) for the object specific reliability rl,m of group Gl on Om : E ln p(rl,m|ul ) ln p(πl,m|rl,m , tm ) ln q(rl,m|τ l,m ) ∝ q(tm),q(l;m )
( 5 )
+ E q(ul )
Thus , we have
∑ ln q(rl,m|τ l,m ) ∝ k∈Xm
+ ( θ(rl;m ) − 1 )
∑ j̸=k q(tm = k)[(η(rl;m ) − 1 ) E q(l;m ) ln πl,m;k
( 6 )
E q(l;m ) ln πl,m;j ]
+ rl,m E q(ul ) for rl,m ∈ {0 , 1} , respectively . Here we compute the expectation of the logarithmic Dirichlet variable as q(ul ) ln ul + ( 1 − rl,m ) E ln(1 − ul ) ∑ ln πl,m;k = ψ(αl,m;k ) − ψ(
αl,m;i ) with the digamma function ψ(· ) ; the expectation of the logarithmic Beta variables i
Eq(ul)ln ul = ψ(βl;1 ) − ψ(βl;1 + βl;2 ) and
Eq(ul)ln(1 − ul ) = ψ(βl;2 ) − ψ(βl;1 + βl;2 ) .
Finally , the updated values of q(rl,m ) are normalized to be valid probabilities .
The last line of Eq ( 6 ) reflects how the general reliability ul affects the estimation of the object specific reliability . This embodies the idea that a generally reliable group is likely to be reliable on a particular object and vice versa . This can reduce the overfitting risk of estimating rl,m especially considering that q(tm ) in the second line also needs to be estimated simultaneously in the MSS model as in the next step . A.4 : Update each factor q(tm|νm ) for the true value . rl;m∈{0,1}
+ ( θ(rl;m ) − 1)(1 − q(tm = k) ) ] + 1 for each k ∈ Xm , where δ [ [A ] ] is the indicator function which outputs 1 if A holds , and 0 otherwise . Here we index the element in αl,m and πl,m by k after the colon . We will follow this notation convention to index the element in vectors in this paper . A.2 : Update each factor q(ul|βl ) for general group reliability ul . We have ln q(ul|βl ) ∝ ln p(rl,m|ul ) + ln p(ul|b1 , b0 ) q(rl;m )
E q1(rl,m ) + b1 − 1 ) ln ul q0(rl,m ) + b0 − 1 ) ln(1 − ul )
∑ ∑ ∑ m m
= (
+ ( m
∑ where qi(rl,m ) is short for q(rl,m = i ) for i = 0 , 1 , respectively . It is evident the posterior of ul still has Beta distribution as Beta(βl ) with parameter
∑
βl = [ q1(rl,m ) + b1 , q0(rl,m ) + b0 ] . m m
∑ We have ln q(tm = k|νm ) ∝ ln p(tm = k ) + q(rl,m ) E
∑ rl;m∈{0,1} l q(l;m ) ln p(πl,m|tm = k , rl,m )
This suggests that
∑
∑ ln q(tm = k|νm ) ∝ ∑ rl;m l q(rl,m){(η(rl;m ) − 1 ) E ln πl,m;k q(l;m )
( θ(rl;m ) − 1 ) E ln πl,m;k′} q(l;m )
+ k′̸=k
All q(tm = k ) , k ∈ Xm are normalized to ensure they are validate probabilities . A.5 : Update each factor q(gn|φn ) for the group assignment of each source . We can derive ln q(gn = ljφn ) / E ln p(yn,mjl,m ; gn = l ) ln p(gn = ljρ ) +
E q(fl )
= E q(fl ) ln p(gn = ljρ ) + q(l;m )
E q(l;m ) ln l,m;yn;m
∑ ∑ m∈In;· m∈In;·
This shows that q(gn = l|φn ) is a multinomial distribution with its parameter as
∞∑ φn;l = q(gn = l|φn ) = ∑ ln p(gn = l|ρ ) + l=1 where
Un,l = E q(fl ) exp(Un,l ) exp(Un,l )
( 7 )
E ln πl,m;yn;m m∈In;· q(l;m )
As in [ 13 ] , we truncate after L groups : the posterior distribution q(ρi ) after the level L is set to be its prior p(ρi ) from Beta(1 , κ ) ; and all the expectations ln πl,m;k after L are set to :
E q(l;m )
Eq(l;m ) ln πl,m;k =
E q(tm),p(rl;m )
{ E[ln πl,m;k|rl,m , tm ] } with the prior distribution p(rl,m ) defined as Section 4 for all l > L , respectively . The inner conditional expectation in the above is taken with respect to the probability of πl,m conditional on rl,m and tm . Similar to the family of nested Dirichlet process mixture in [ 13 ] , this will form a family of nested priors indexed by L for the MSS model . Thus , we can compute the infinite sum in the denominator of Eq ( 7 ) as :
∞∑ exp(Un,l ) = l=L+1
1 − exp( exp(Un,L+1 ) ρi∼Beta(1,κ )
E ln(1 − ρi ) )
A.6 : Update q(ρi ) in GEM construction .
Before the truncation level L , the posterior distribution q(ρi ) ∼
Beta(ϕi,1 , ϕi,2 ) is updated as
N∑
∞∑
N∑
ϕi,1 = 1 + q(gn = i ) , ϕi,2 = κ + q(gn = j ) n=1 n=1 j=i+1
Appendix B : Parameter Estimation The model parameters . = {η(0 ) , θ(0 ) , η(1 ) , θ(1 ) , b1 , b0 , κ} can be estimated by maximizing the log likelihood log L(q ) by the obtained factorization q with the constraints η(1 ) > θ(1 ) and η(0 ) ≤ θ(0 ) . Since we require η(1 ) > θ(1 ) strictly holds , we usually impose η(1 ) ≥ ( 1+ϵ)θ(1 ) with a positive value of ϵ , ie , η(1 ) is larger than θ(1 ) with a margin ϵ . This ensures the strict inequality and improves numerical stability . In the algorithm , we set ϵ = 05 Then , the parameter estimation problem becomes the following :
L(q )
.⋆ = arg max st , 0 ≤ η(0 ) ≤ θ(0 ) , η(1 ) ≥ ( 1 + ε)θ(1 ) ≥ 0 , b1 , b0 , κ ≥ 0
Θ i
= k∈Xm
∑
This constrained optimization problem can be solved by many offthe shelf gradient based constrained optimization solvers with the following gradients :
{ψ(η(r ) + ( Km − 1 ) θ(r ) ) − ( Km − 1)ψ(θ(r ) )
∑ ∑ ∂L {ψ(η(r ) + ( Km − 1)θ(r ) ) − ψ(η(r ) ) l,m,k∈Xm ∂η(r ) αl,m;i)} +ψ(αl,m;k ) − ψ( ∑ ∑ ∂L ∂θ(r ) = ψ(αl,m;k′ ) − ( Km − 1)ψ( + for r ∈ {0 , 1} . ∑ ∑ ψ(b1 + b0 ) − ψ(b0 ) + ψ(βl,2 ) − ψ(βl,1 + βl,2 ) ∑
ψ(b1 + b0 ) − ψ(b1 ) + ψ(βl,1 ) − ψ(βl,1 + βl,2 )
αl,m;i)}
ψ(1 + κ ) − ψ(κ ) + ψ(ϕi,1 + ϕi,2 ) − ψ(ϕi,2 )
∂L ∂b1 ∂L ∂b0 ∂L ∂κ k′
=
= i l l
= i
10 . REFERENCES [ 1 ] Y . Bachrach , T . Minka , J . Guiver , and T . Graepel . How to grade a test without knowing the answers a bayesian graphical model for adaptive crowdsourcing and aptitude testing . In Proc . of International Conference on Machine Learning , 2012 .
[ 2 ] M . Bilgic , G . Namata , and L . Getoor . Combining collective classification and link prediction . In Workshop on Mining Graphs and Complex Structures ( at ICDM ) , 2007 .
[ 3 ] A . Clauset , M . E . J . Newman , and C . Moore . Finding community structure in very large networks . Physical Review E , 70:066111 , 2004 .
[ 4 ] X . L . Dong , L . Berti Equille , and D . Srivastava . Integrating conflicting data : The role of source dependence . In Proc . of International Conference on Very Large Databases , August 2009 .
[ 5 ] A . Galland , S . Abiteboul , A . Marian , and P . Senellart .
Corroborating information from disagreeing views . In Proc . of ACM International Conference on Web Search and Data Mining , February 2010 .
[ 6 ] L . Getoor , N . Friedman , D . Koller , and B . Taskar . Learning probabilistic models of link structure . Journal of Machine Learning Research , ( 3):679–707 , 2002 .
[ 7 ] M . Girvan and M . Newman . Community structure in social and biological networks . Proceedings of the National Academy of Sciences , 99(12):7821–7826 , June 2002 .
[ 8 ] M . Gupta , Y . Sun , and J . Han . Trust analysis with clustering . In Proc . of International World Wide Web Conference , April 2011 .
[ 9 ] O . Hassanzadeh and et al . A framework for semantic link discovery over relational data . In CIKM , 2009 .
[ 10 ] M . Jordan , Z . Ghahramani , T . Jaakkola , and L . Saul .
Introduction to variational methods for graphical models . Machine Learning , 37:183–233 , 1999 .
[ 11 ] G . Kasneci , J . V . Gael , D . Stern , and T . Graepel . Cobayes :
Bayesian knowledge corroboration with assessors of unknown areas of expertise . In Proc . of ACM International Conference on Web Search and Data Mining , 2011 .
[ 12 ] Y . Koren , R . Bell , and C . Volinsky . Matrix factorization techniques for recommender systems . Computer , 42(8):30–37 , August 2009 .
[ 13 ] K . Kurihara , M . Welling , and N . Vlassis . Accelerated variational dirichlet process mixtures . In NIPS , 2006 .
[ 14 ] J . Pasternack and D . Roth . Knowing what to believe ( when you already know something ) . In Proc . of International Conference on Computational Linguistics , August 2010 .
[ 15 ] J . Sethuraman . A constructive definition of dirichlet priors .
Statistica Sinica , 4:639–650 , 1994 .
[ 16 ] X . Yin , J . Han , and P . S . Yu . Truth discovery with multiple conflicting information providers on the web . In Proc . of ACM SIGKDD conference on Knowledge Discovery and Data Mining , August 2007 .
[ 17 ] X . Yin and W . Tan . Semi supervised truth discovery . In Proc . of International World Wide Web Conference , March 28 April 1 2011 .
[ 18 ] B . Zhao , B . I . P . Rubinstein , J . Gemmell , and J . Han . A bayesian approach to discovering truth from conflicting sources for data integration . In Proc . of International Conference on Very Large Databases , 2012 .
[ 19 ] X . Zhou , N . Cui , Z . Li , F . Liang , and T . Huang . Hierarchical gaussianization for image classification , 2009 .
