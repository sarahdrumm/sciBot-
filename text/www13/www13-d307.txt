Personalized Recommendation via Cross Domain Triadic Factorization
Liang Hu
Department of CSE
Jian Cao*
Department of CSE
Shanghai Jiaotong University
Shanghai Jiaotong University lianghu@sjtueducn cao jian@sjtueducn
Guandong Xu
Advanced Analytics Institute
University Technology Sydney guandongxu@utseduau
Longbing Cao
Advanced Analytics Institute
University Technology Sydney longbingcao@utseduau
Zhiping Gu
Can Zhu
Department of Electrical Engineering
Department of CSE
Shanghai Technical Institute of
Electronics & Information guzhiping@stieieducn
Shanghai Jiaotong University 0627wshhg@sjtueducn
ABSTRACT Collaborative filtering ( CF ) is a major technique in recommender systems to help users find their potentially desired items . Since the data sparsity problem is quite commonly encountered in real world scenarios , Cross Domain Collaborative Filtering ( CDCF ) hence is becoming an emerging research topic in recent years . However , due to the lack of sufficient dense explicit feedbacks and even no feedback available in users’ uninvolved domains , current CDCF approaches may not perform satisfactorily in user preference prediction . In this paper , we propose a generalized Cross Domain Triadic Factorization ( CDTF ) model over the triadic relation useritem domain , which can better capture the interactions between domain specific user factors and item factors . In particular , we devise two CDTF algorithms to leverage user explicit and implicit feedbacks respectively , along with a genetic algorithm based weight parameters tuning algorithm to trade off influence among domains optimally . Finally , we conduct experiments to evaluate our models and compare with other state of the art models by using two real world datasets . The results show the superiority of our models against other comparative models .
Categories and Subject Descriptors H33 [ Information Search and Retrieval ] : Information Filtering ; I26 [ Artificial Intelligence ] : Parameter Learning
General Terms Algorithms , Performance , Experimentation , Human Factors
Keywords Recommender System , Cross Domain Collaborative Filtering , Triadic Factorization
1 . INTRODUCTION ACM 978 1 4503 2035 1 /13/05.The huge and ever fast increasing amount of information on the Internet has penetrated every corner of our life . However , we become more easily overwhelmed by so ________________________
*Jian Cao is the corresponding author
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . IW3C2 reserves the right to provide a hyperlink to the author's site if the Material is used in electronic media . WWW 2013 , May 13 17 , 2013 , Rio de Janiero , Brazil . ACM 978 1 4503 2035 1 /13/05 . much information and unable to find what we really desire . When we follow events on Facebook , buy books on Amazon or add apps into a smartphone , systems may record our feedbacks , eg , a rating assigned to a book . Based on such observed feedbacks ( or ratings ) collected from like minded users , collaborative filtering ( CF ) in recommender systems can predict personalized preferences to unconsumed items . In general , CF methods can be sub divided into neighborhood based and model based approaches [ 5 ; 22 ; 26 ] . Therein , latent factor model based on matrix factorization ( MF ) [ 6 ; 9 ] has gained the dominance in recent years .
The essence to success in CF is highly dependent on the feedback data . However , users are not always willing to provide feedbacks due to various personal reasons . Even some applications possess the data sparsity problem in nature , for instance , users who has bought a new car recently may not have a new car purchase plan in next five years . Thus most CF methods , including MF , suffer from the data sparsity [ 26 ] and cold start [ 9 ; 23 ] issues . The lack of reliable feedback data has become a major barrier for CF methods .
To deal with the sparsity issue , Cross Domain Collaborative Filtering ( CDCF ) , which leverages the information from multiple related domains , is an emerging research topic in recent years . Some CDCF algorithms have been proposed in literatures [ 11 ] , where the basic idea is based on the assumption of the existence of multiple related domains and the user preference learned from one dense domain , eg movies , can be re used to make prediction in a sparse domain , eg books ( ie cross domain learning ) [ 12 ; 18 ] . An early neighborhood based CDCF ( N CDCF ) was mentioned in [ 1 ] , but it can only provide a very local optimum solution as done by neighborhood based CF models ( further analysis provided in the next section ) . Recently , some cross domain matrix factorization ( CDMF ) models [ 18 ; 24 ] have been proposed to overcome the local optimum problem of N CDCF . The underlying idea of CDMF can be illustrated using Figure 1 ( b ) , where user factor matrix U serves as the bridge to transfer knowledge from auxiliary domain ( A ) to target domain ( T ) .
Most CDMF models assume the auxiliary data is relative dense for all users or items [ 18 ] . However , we argue that this assumption is not always true in real world . In general , our argument is based on the well known power law , as illustrated in Figure 1(a ) , only the minority of users are rating frequently while the majority of users are quite inactive in providing feedback . This observation might impact the hypothesis of traditional CDCF approaches , therefore resulting in the deterioration of recommendation performance .
595 Figure 1 : ( a ) Due to the power law , the feedbacks over majority of users are sparse in each domain , so the unacquainted world phenomenon are ubiquitous in CDCF ; ( b ) The demonstration of unacquainted world issue in CDMF ; ( c ) More accurate triadic factor analysis over CDCF .
Furthermore , due to the diversity of user interests a user is usually active in a few domains that she/he is really interested in , but silent in other domains hardly involved . Given a set of domains , we call those user ’s uninvolved domains as unacquainted world . Since each user has different domains of interest , the unacquainted world phenomenon is common in CDCF problem , shown in Figure 1 ( a ) . Moreover , the ubiquitous unacquainted world phenomenon may negatively impact the recommendation performance of CDMF models in heterogeneous domain settings . Consider the example depicted in Figure 1 ( b ) , CDMF aims to improve recommendation in the target domain T by utilizing the transferred knowledge ( ie the user factor matrix U ) from the auxiliary domain A . More specifically , this transferred user factor matrix U should be updated by taking into account users’ feedbacks from T before serving as the user factor matrix U for target domain T [ 18 ; 24 ] . Now the problem occurs : no feedback is available for the last two users in T ( ie the unacquainted world , marked with dashed red box ) to adjust the transferred user factor vector u , but the prediction of preference to an item in T is purely determined by the operation of uTw , which may yield an inaccurate result due to the unadjusted u and the heterogeneity of item factors between the heterogeneous domains A and T ( eg the heterogeneity between v and w ) . Therefore , it results in unreliable prediction completely based on the preference learned from a heterogeneous domain . Thus this raises a demand to devise a new cross domain learning model by jointly leveraging the complementary data from multiple domains rather than simply relying on some dense feedback domain .
The major reason caused the above concerns is that CDMF deals with a set of user item data over multiple domains in a flat manner but it does not consider the attribute of domain factor . The absence of domain specific information in factorization process leads CDMF to suffering from the unacquainted world issue . We argue that domain factors is an essential element in cross “ domain ” problem , so cross domain learning should take into consideration the full triadic relation user item domain to reveal the user preference on items within various domains in depth , rather than the dyadic relation user item modeled by CDMF .
To learn such triadic factors from data , intuitively a tensor factorization ( TF ) could be introduced . However , a standard TF model requires that the slice of each domain should be the same size . Obviously , overlying all domain slices ( differ in the number of items ) in Figure 1 ( c ) cannot form a cubical tensor . Inspired by PARAFAC2 [ 7 ] , a special TF model , we propose Cross Domain Triadic Factorization ( CDTF ) to relax the constraint that the same item factor matrix is employed for all domains . As illustrated in Figure 1 ( c ) , CDTF allows an exclusive item factor matrix for each domain to express heterogeneities . In addition , user factor matrix U in CDTF is used to model the general users concerns over all domains and the domain factor matrix D carries the information to express the traits of each domain . Hence each observation can be viewed as the result of triadic interaction among user , item and domain factors . Further , we can interpret that the domain specific user factors is generated by the interaction between domain factors and general user factors as shown in Figure 1 ( c ) . Obviously , such triadic factor model avoids the unacquainted world issue in CDMF .
In real world scenarios , another difficulty is that the user explicit feedback data ( eg , ratings ) are sometimes hardly available . How to alleviate this kind of problems becomes a new research direction in CF and more and more studies attempt to make use of implicit feedbacks ( here implicit feedback means the intention conveyed by user activities , such as purchase history or browsing behavior ) [ 6 ; 20 ] . Accordingly , we further extend CDTF model to accommodate implicit feedbacks , namely CDTF IF , which can effectively deal with the one class implicit feedback data that CDTF cannot handle . Moreover , in cross domain learning problems , tuning the trade off parameters over domains is an essential step to achieve better performance [ 16 ; 24 ] . Therefore , in this work we also investigate an automated and robust trade off parameters determination approach for our models based on genetic algorithm ( GA ) .
The contributions of this paper can be summarized as follows :
 We address the CDCF problem by formulating a generalized triadic relation user item domain .
 We devise a cross domain triadic factorization ( CDTF ) model to learn the triadic factors for user , item and domain , where the item dimensionality varies with domains .
 To alleviate the absence of explicit feedbacks , we extend our proposed CDTF model to be able to utilize the implicit feedbacks that CDTF cannot handle .
 We study an automated optimal weight parameter estimation algorithm based on genetic algorithm .
 We perform experiments on two real world datasets to evaluate our models and make comparisons with other state of the art models .
2 . CDCF FROM CLASSICAL CF VIEWS Neighborhood and MF based methods are two kinds of dominant approaches in CF . Although such classical CF methods can be applied to CDCF , they have disadvantages in nature . Notations : 𝑫 = {𝐷1 , 𝐷2 , ⋯ , 𝐷𝐾} denotes all the domains for modeling , 𝑼 = {𝑢1 , 𝑢2 , ⋯ , 𝑢𝑁} denotes the users in 𝑫 and 𝑷𝐷𝑘 = {𝑝1
𝐷𝑘} denotes items belonging to the domain 𝐷𝑘 .
𝐷𝑘 , 𝑝2
𝐷𝑘 , ⋯ , 𝑝𝑀
N CDCF : Neighborhood based CF compute similarity between users or items , which can be sub divided into two types : user based nearest neighbor and item based nearest neighbor [ 26 ] .
For a user based CDCF algorithm , we first calculate the similarity , 𝑤𝑢,𝑣 , between the users 𝑢 and 𝑣 who have co rated the same set of items . The similarity can be measured by the Pearson correlation :
( c)(b)(a)5?4?5?4?1?3?2???5?1???2?53?41?A2??5?2??3?4?4???????TuUwvWVTransferitem factor vectoru'w?=w unacquainted world phenomenonuuser factorvectorwWVuUTAw?=Userduu=u'w?= f(du)domain specific user factors:*3235345232521513522452BookMusicUserPower Law596 𝑤𝑢,𝑣 =
∑
𝑝∈𝒑𝑢,𝑣
( 𝑟𝑢,𝑝 − 𝑟̅𝑢)(𝑟𝑣,𝑝 − 𝑟̅𝑣 )
( 1 )
√∑
𝑝∈𝒑𝑢,𝑣
( 𝑟𝑢,𝑝 − 𝑟̅𝑢 )
2
∑
𝑝∈𝒑𝑢,𝑣
( 𝑟𝑣,𝑝 − 𝑟̅𝑣 )
2 for different domains may quite heterogeneous so MF CDCF fails to express them . Furthermore , such model absolutely loses the information to model domain factors for CDCF problem .
𝑑 𝒑𝑢
𝑑∈𝑫
, 𝒑𝑣 = ⋃ where 𝒑𝑢,𝑣 = 𝒑𝑢 ∩ 𝒑𝑣 ( 𝒑𝑢 = ⋃ ) denotes the items over all domains 𝑫 co rated by 𝑢 and 𝑣 ; 𝑟𝑢,𝑝 and 𝑟𝑣,𝑝 are the ratings on item 𝑝 given by users 𝑢 and 𝑣 respectively ; 𝑟̅𝑢 is the average rating of user 𝑢 for all the items rated . Then , the predicted rating of an item 𝑝 for user 𝑢 can be calculated by a weighted average strategy [ 22 ] :
𝑑∈𝑫
𝑑 𝒑𝒗
𝑟̂𝑢,𝑝 = 𝑟̅𝑢 +
∑
𝒌
𝑣∈𝑼𝑢,𝑝 ∑
𝑤𝑢,𝑣
( 𝑟𝑣,𝑝 − 𝑟̅𝑣 )
𝒌
𝑣∈𝑼𝑢,𝑝
|𝑤𝑢,𝑣|
( 2 )
𝒌 denotes the set of top 𝑘 users ( 𝑘 neighbors ) that are where 𝑼𝑢,𝑝 most similar to user 𝑢 who rated item 𝑝 .
Similar to user based algorithm , the item based CDCF needs to compute the similarity , 𝑤𝑝,𝑞 , between item pair 𝑝 and 𝑞 . Given corated cases 𝑈𝑝,𝑞 over 𝑝 and 𝑞 , ie each case is that a user rated both 𝑝 and 𝑞 , the Pearson correlation is given by :
𝑤𝑝,𝑞 =
∑
𝑢∈𝑈𝑝,𝑞
( 𝑟𝑢,𝑝 − 𝑟̅𝑝)(𝑟𝑢,𝑞 − 𝑟̅𝑞 )
( 3 )
√∑
𝑢∈𝑈𝑝,𝑞
( 𝑟𝑢,𝑝 − 𝑟̅𝑝 )
2
∑
𝑢∈𝑈𝑝,𝑞
( 𝑟𝑢,𝑞 − 𝑟̅𝑞 )
2
Then , the predicted value , 𝑟̂𝑢,𝑝 , is taken as a weighted average of 𝑘 . the ratings for neighboring 𝑘 items rated by 𝑢 , denoted 𝑷𝑢,𝑝
𝑟̂𝑢,𝑝 = 𝑟̅𝑝 +
∑
𝑘 : 𝑞∈𝑷𝑢,𝑝 ∑
𝑤𝑝,𝑞
( 𝑟𝑢,𝑞 − 𝑟̅𝑞 )
𝒌
𝑣∈𝑼𝑢,𝑝
|𝑤𝑝,𝑞|
( 4 )
MF CDCF : The method to perform MF on a CDCF problem is straightforward . We can construct a matrix 𝑴𝐷𝑘 that takes all users 𝑼 as the rows and all items 𝑷𝐷𝑘 in domain 𝐷𝑘 as the columns . Thus , we easily obtain 𝐾 matrices 𝑴𝐷1 , 𝑴𝐷2 , ⋯ , 𝑴𝐷𝐾 for 𝐾 domains . Then , an augmented matrix , 𝑴𝑫 , can be built by horizontally concatenating all matrices as shown in Figure 2 .
Figure 2 : Horizontal concatenation of matrices for all domains
With the matrix 𝑴𝑫 in hand , we can exploit any classical MF algorithm , eg the frequently used stochastic gradient descent ( SGD ) method [ 9 ] , to construct user factor matrix and item factor matrix . These factor matrices are used for prediction .
Disadvantage : Neighborhood based models are most effective at detecting much localized relationships and unable to capture the totality of weak signals encompassed in all of a user ’s ratings . For example , 𝑢1 rated items {𝑝1 , 𝑝2} , 𝑢2 rated items {𝑝3 , 𝑝4} and 𝑢3 rated items {𝑝2 , 𝑝3} . The direct correlation between 𝑢1 and 𝑢2 is zero . In fact , 𝑢1 is correlated with 𝑢3 by 𝑝2 and 𝑢2 is correlated with 𝑢3 by 𝑝3 , so 𝑢1 is transitively correlated with 𝑢2 instead of zeros . It proves that N CDCF cannot obtain a global optimal solution , especially when the data is very sparse .
MF CDCF accommodates items from all domains into a single matrix so as to employ single domain MF . However , single domain model assumes the homogeneity of items . Obviously , item factors
3 . OUR MODELS 3.1 Preliminary Before clarifying our model , we firstly introduce some basic notations , operations and algorithms for TF models . There are different TF models in literatures , such as Tucker model , CP model ( canonical decomposition/parallel factor analysis ( PARAFAC ) ) [ 8 ; 15 ] . Here , we mainly focus on CP model because our model is an extension of PARAFAC2 which needs to cope with CP .
311 Notations and Operations The order of a tensor is the number of dimensions , also known as ways or modes . In this paper , tensors are denoted by boldface script letter , eg 𝓧 . Matrices are denoted by boldface capital letters , eg 𝐗 . Vectors are denoted by boldface lowercase letters , eg 𝐱 . Entries are denoted lowercase letters with subscripts eg 𝑥𝑖,𝑗,𝑘 . In addition , we denote the 𝑖𝑡ℎ row of a matrix 𝐗 as 𝐗𝑖,∙ , the 𝑗𝑡ℎ column as 𝐗∙,𝑗 and 𝐗𝑖,𝑗 for the entry ( 𝑖 , 𝑗 ) .
The 𝑛𝑡ℎ mode matricizing operation maps a tensor into a matrix , 𝐽×𝐼𝐾 eg , 𝐗(2 ) represents the mapping 𝓧𝐼×𝐽×𝐾 → 𝐗(2 ) [ 8 ; 15 ] . ⊗ denotes the Kronecker product and ⊙ denotes the Khatri Rao product , eg 𝐗 ⊙ 𝐘 = [ 𝐗∙,1 ⊗ 𝐘∙,1 𝐗∙,2 ⊗ 𝐘∙,2 ⋯ 𝐗∙,𝑅 ⊗ 𝐘∙,𝑅 ] . ⊛ is the element wise product while ⊘ is the element wise division . 〈𝓧 ⊛ 𝓨〉 = ∑ denotes the inner product and the norm of a tensor is , ‖𝓧‖ = √〈𝓧 ⊛ 𝓧〉 .
𝑥𝑖,𝑗,𝑘𝑦𝑖,𝑗,𝑘
𝑖,𝑗,𝑘
Figure 3 : The CP factorization of a three order tensor
312 CP Model CP model decomposes a tensor into a sum of rank one components as illustrated in Figure 3 . For instance , given a three order tensor 𝑅 𝓧 , the factorization can be writtern as 𝓧 = ⟦𝐀 , 𝐁 , 𝐂⟧ = ∑ 𝐀∙,𝑟 ∘ 𝑟=1 𝐁∙,𝑟 ∘ 𝐂∙,𝑟 , where 𝐀 , 𝐁 , 𝐂 are R component factor matrices and ∘ denotes the outer product , ie the entries are computed 𝑥𝑖,𝑗,𝑘 = 𝑅 ∑ . Let 𝓧 be a three order tensor with the size 𝐼 × 𝑟=1 𝐽 × 𝐾 . We can formulate the problem of fitting 𝓧 as a least squares optimization problem [ 8 ] :
𝐀𝑖,𝑟𝐁𝑗,𝑟𝐂𝑘,𝑟 min 𝑓(𝐀 , 𝐁 , 𝐂 ) =
‖𝓧 − ⟦𝐀 , 𝐁 , 𝐂⟧‖2 +
1 2 2 + ‖𝐀‖𝐹
𝜆𝐴 2
𝜆𝐵 2
‖𝐁‖𝐹
2 +
𝜆𝐶 2
‖𝐂‖𝐹
2 ( 5 ) where regularization terms are added to avoid overfitting,‖∙‖𝐹 is the Frobenius norm and 𝜆𝐴 , 𝜆𝐵 , 𝜆𝐶 are regularization parameters .
It is easy to prove that the partial derivative of the objective function ( 5 ) wrt 𝐀 is given by :
∂𝑓 ∂𝐀
= ( 𝐗(1 ) − 𝐘(1))(𝐂 ⊙ 𝐁 ) + 𝜆𝐴𝐀 where 𝐘 = ⟦𝐀 , 𝐁 , 𝐂⟧ . Setting the above equation equal to zero and the property of pseudo inverse of Khatri Rao product [ 27 ] yields :
𝐀 = 𝐗(1)(𝐂 ⊙ 𝐁)(𝐁T𝐁 ⊛ 𝐂T𝐂 + 𝜆𝐴𝐈)† ( 6 )
32351324523325152154525132522452BookDVDMusicUserb1b2bRX=+++a1c1c2a2aRcR597 Similarly , the optimal solutions wrt 𝐁 and 𝐂 are given by :
𝐁 = 𝐗(2)(𝐂 ⊙ 𝐀)(𝐀T𝐀 ⊛ 𝐂T𝐂 + 𝜆𝐵𝐈)† ( 7 )
𝐂 = 𝐗(3)(𝐁 ⊙ 𝐀)(𝐁T𝐁 ⊛ 𝐀T𝐀 + 𝜆𝐶𝐈)† ( 8 )
Above derivation corresponds to a regularized alternative least square algorithm , CP ALS R , given by Algorithm 1 . The complexity for this algorithm is proportional to 𝐼𝐽𝐾𝑅 + ( 𝐼 + 𝐽 + 𝐾)𝑅2 , per iteration . Since we normally have 𝐼𝐽𝐾 ≫ ( 𝐼 + 𝐽 + 𝐾 ) , the computational complexity is O(𝐼𝐽𝐾𝑅 ) .
Algorithm 1 : [ 𝐀 , 𝐁 , 𝐂 ] = CP ALS R(𝓧 , 𝜆𝐴 , 𝜆𝐵 , 𝜆𝐶 ) Input : 𝓧 the tensor for factorization ,
𝜆𝐴 , 𝜆𝐵 , 𝜆𝐶 the regularization paramters
Initialize 𝐀 , 𝐁 , 𝐂
Output : 𝐀 , 𝐁 , 𝐂 the factor matrices Begin : 1 : 2 : Fix 𝐁 , 𝐂 : Update 𝐀 by Equation ( 6 ) 3 : Fix 𝐀 , 𝐂 : Update 𝐁 by Equation ( 7 ) 4 : Fix 𝐀 , 𝐁 : Update 𝐂 by Equation ( 8 ) 5 : Repeat 2 – 4 until convergence 6 : Return 𝐀 , 𝐁 , 𝐂 End
3.2 Cross Domain Triadic Factorization We have discussed the weaknesses of traditional CDCF approaches in the previous section , where items from all domains are mixed together , so the item latent factors cannot be well learned due to the heterogeneity between domains . In addition , all those approaches discard the most important domain specific information .
321 Model A straightforward method to capture the 3 way interaction between user item domain is to model this triadic relation by a cube , ie a three order tensor , where each frontal slice in this cube corresponds to a rating matrix for each domain . Unfortunately , the inconsistent number of items for each domain , as illustrated in the left part of Figure 4 , cannot form a standard tensor . PARAFAC2 [ 8 ; 15 ] relaxes CP ’s constraints that apply the same factors across a parallel set of matrices . Inspired by this idea , we propose the cross domain triadic factorization ( CDTF ) model , which can be applied to a collection of rating matrices for domains that are equivalent in the User dimension but vary in the Item dimensions over domains .
Figure 4 : Slices of domain specific matrices with heterogeneous items are transformed into a cubical tensor containing virtual items with identical length .
The standard CP model presented previously can be written as the factorization form wrt each slices , 𝐘𝑘 , for k=1 to K
𝐘𝑘 = 𝐀𝚺𝑘𝐁T + 𝚬𝑘 ( 9 ) where 𝐀 , 𝐁 are the factor matrices as given in previous section , 𝚺𝑘 = diag(𝐂𝑘,∙ ) is an 𝑅 × 𝑅 diagonal matrix of weights for the slice 𝐘𝑘 , and 𝚬𝑘 denotes the residuals [ 11 ; 27 ] . Therefore , we can rewrite the objective function ( 5 ) wrt the slices 𝐘𝑘 for k=1 to K min 𝑓(𝐀 , 𝐁 , 𝐂 ) =
1 2
∑ ‖𝐘𝑘 − 𝐀𝚺𝑘𝐁T‖
2
+
𝐾
𝑘=1 𝜆𝐵 2
𝜆𝐴 2
‖𝐀‖𝐹
2 +
‖𝐁‖𝐹
2 +
𝜆𝐶 2
‖𝐂‖𝐹
2 ( 10 )
Let us denote 𝐗𝑫 = {𝐗1 , 𝐗2 , ⋯ , 𝐗𝐾} to be the rating matrices for domains , where each matrix , 𝐗𝑘 , has the size 𝑁 × 𝑀𝑘 , 𝑁 is the number of users and 𝑀𝑘 is the number of items in the kth domain . We apply a PARAFAC2 like modeling strategy to the collection of rating matrices , 𝐗𝑫 , with varying sizes in Item mode ( see Figure 4 ) . Analogous to Eq ( 9 ) for CP model , we can write the similar form of factorization wrt the rating matrix of each domain .
𝐗𝑘 = 𝐔𝚺𝑘𝐕𝑘
T + 𝚬𝑘 ( 11 ) where 𝐔 denotes the 𝑁 × 𝑅 factor matrix ( it refers to user factors in our model ) , 𝐕𝑘 is the 𝑀𝑘 × 𝑅 factor matrix ( it refers to item factors in our model ) for the slice 𝐗𝑘 and 𝚺𝑘 is an 𝑅 × 𝑅 diagonal matrix ( it refers to domain factor in our model ) for slice 𝐗𝑘 . Then , we easily obtain the objective function with the same form as Eq ( 12 ) . However , such PARAFAC2 like factorization is not unique without additional constraints [ 11 ; 27 ] . To improve the uniqueness property , Harshman [ 4 ] imposed a constraint that the cross product T𝐕𝑘 for k=1 , … , K . 𝐕𝑘 Thus , Eq ( 11 ) can be written as :
T𝐕𝑘 is a invariant matrix over k , ie , 𝚽 = 𝐕𝑘
𝐗𝑘 = 𝐔𝚺𝑘(𝐏𝑘𝐕)T + 𝚬𝑘 ( 12 ) where 𝐔 , 𝚺𝑘 are defined as usual , 𝐏𝑘 is a column wise orthonormal T𝐏𝑘 = 𝐈 ) of size 𝑀𝑘 × 𝑅 and 𝐕 is an 𝑅 × 𝑅 matrix matrix ( ie 𝐏𝑘 that does not vary by slice . The cross product constraint is enforced implicitly since
𝐕𝑘
T𝐕𝑘 = ( 𝐏𝑘𝐕)T(𝐏𝑘𝐕 ) = 𝐕T𝐕 = 𝚽
Then , the objective function can be given according to Eq ( 12 ) min 𝑓(𝐔 , 𝐕 , 𝐂 , 𝐏𝑘 ) =
1 2
2 ∑ ‖𝐗𝑘 − 𝐔𝚺𝑘(𝐏𝑘𝐕)T‖
( 13 )
𝐾
𝑘=1
Weights over Slices : In our model , the user factor matrix 𝐔 is shared across all domains ( see Eq ( 13) ) , ie learning 𝐔 is affected by the loss on each slice . Some domain may have a lot of items and feedbacks ( heavy slice ) while other domain may only have a few of items and a few feedbacks ( light slice ) . If the loss from a heavy slice overwhelms the loss from light slices , 𝐔 is fully determined by the heavy slice . On the other hand , the scale of ratings on each slice may be different , eg the ratings on some slices are in the range of 1 5 and others may be 1 100 , so the larger scaled rating slice tends to account for more loss . More importantly , sometimes we deliberately require that the learning of 𝐔 is mainly determined by feedbacks from target domain so as to perform better prediction .
Consequently , we add the weight parameter , 𝑤𝑘 , to the objective function ( 13 ) to adjust the penalty of loss on each slice as given by Eq ( 14 ) . If we assign a large weight to some domain slice , then factor matrix 𝐔 is mainly learned from the factorization over this slice . Note that the change of 𝐔 will update other factor matrices 𝐕 , 𝐂 , 𝐏𝑘 in turn during the process of factorization . Therefore , we can control the learning result of all factor matrices by tuning the weight assigned to each slice . min 𝑓(𝐔 , 𝐕 , 𝐂 , 𝐏𝑘 ) =
1 2
2 ∑ ‖𝑤𝑘(𝐗𝑘 − 𝐔𝚺𝑘(𝐏𝑘𝐕)T)‖
( 14 )
𝐾
𝑘=1
X3X2BookMusicMovieVideoX1Y1UserVirtual Item598 Minimizing Eq ( 14 ) is obviously equivalent to minimizing following objective function [ 7 ] . min 𝑓(𝐔 , 𝐕 , 𝐂 , 𝐏𝑘 ) =
1 2
2 ∑ ‖𝑤𝑘𝐗𝑘𝐏𝑘 − 𝑤𝑘𝐔𝚺𝑘𝐕T‖
( 15 )
𝐾
𝑘=1
Let 𝐘𝑘 = 𝑤𝑘𝐗𝑘𝐏𝑘 , 𝚺̅𝑘 = 𝑤𝑘𝚺𝑘 = 𝑤𝑘diag(𝐂𝑘,∙ ) , it is easy to see Eq ( 15 ) corresponds to a 𝑁 × 𝑅 × 𝐾 cubical tensor as illustrated in the right part of Figure 4 , where each slice 𝐘𝑘 has the identical size 𝑁 × 𝑅 ( N users and R virtual items ) . Finally , we can obtain the full objective function for CDTF by appending the regularization terms as given by Eq ( 16 ) . min 𝑓(𝐔 , 𝐕 , 𝐂 , 𝐏𝑘 ) =
+
𝐾
𝑘=1
1 2 ∑ ‖𝑤𝑘𝐗𝑘𝐏𝑘 − 𝐔(𝑤𝑘𝚺𝑘)𝐕T‖ 2 𝜆𝑈 2
‖𝐔‖𝐹
‖𝐕‖𝐹
‖𝐂‖𝐹
𝜆𝑉 2
𝜆𝐶 2
2 +
2 +
2 ( 16 )
322 Algorithm We need to reconstruct all missing values for prediction but the standard fitting algorithm for PARAFAC2 is based on the complete data [ 7 ] . Therefore , we need to design a new fitting algorithm which allows dealing with missing data . Thus , we apply an Expectation Maximization ( EM ) [ 25 ; 27 ] sub procedure into the fitting algorithm to handle the incomplete data by iteratively imputation after each full cycle of updates .
𝑘
𝑘
𝐗̅
( 𝑡+1 ) = 𝐌𝑘 ⊛ 𝐗̅
( 𝑡 ) + ( 𝟏 − 𝐌𝑘 ) ⊛ 𝐔𝚺̅𝑘𝐕T ( 17 ) ( 0 ) = 𝑤𝑘𝐗𝑘 can be pre computed and 𝐌𝑘 is an indicator where 𝐗̅ matrix whose entry ( 𝑖 , 𝑗 ) is one if 𝐗𝑘(𝑖 , 𝑗 ) has been rated ( for observed values ) and zero otherwise ( for missing values ) , 𝟏 is an all ones matrix that has the same size as 𝐌𝑘 .
𝑘
So far we have described the detail of CDTF model and the EM algorithm for missing data handling . In summary , Algorithm 2 gives the whole factorization scheme for CDTF extending from the direct fitting algorithm for PARAFAC2 [ 2 ; 7 ] . In this algorithm , the computational complexity is mainly dependent on the internal sub procedure CP . Here , we use the CP ALS R so the complexity is O(𝑁𝑅𝐾𝑅 ) . Since the 𝐾 ( the number of domains ) and the 𝑅 ( dimensionality of factor ) are small , the generated tensor 𝓨 can be decomposed very efficiently .
323 Recommendation Given the estimated factor matrices 𝐔 , 𝐕 , 𝐂 , 𝐏𝑡 , the prediction of user 𝑢 ’s rating of item 𝑖 of target domain 𝑡 is given by :
𝐗̂𝑡(𝑢 , 𝑖 ) ≈ 𝐩T𝐪 where 𝐩T = 𝐔𝑢,∙ ⊛ 𝐂𝑡,∙ is the domain specific user factors of 𝑢 and 𝐪T = 𝐏𝑡(𝑖,∙)𝐕 is the item factors of 𝑖 . As a whole , the reconstructed rating matrix of target domain 𝑡 is given by 𝐗̂𝑡 ≈ 𝐔𝚺𝑡(𝐏𝑡𝐕)T . Let 𝒊 denote the set of 𝑢 ’s all unrated items , then we can obtain the personalized recommendation ranking over 𝒊 by sorting 𝐗̂𝑡(𝑢 , 𝒊 ) in a descending order .
3.3 Implicit Feedback based CDTF In real applications , the explicit feedbacks are not always available but implicit feedbacks are easily gained from user behavior history . For example , a user may not give ratings ( explicit feedbacks ) to the books she/he has bought but his purchase history can be considered as an implicit feedback . Consequently , some single domain CF methods have been proposed to exploit the more abundant implicit feedbacks [ 6 ; 20 ; 21 ] . However , even implicit feedback based CF models still suffer from data sparsity and cold start issues .
Algorithm 2 : [ 𝐔 , 𝐕 , 𝐂 , 𝐏𝑘 ] = CDTF(𝐗𝑘 , 𝐰𝑘 , 𝐌𝑘 , 𝜆𝑈 , 𝜆𝑉 , 𝜆𝐶 ) Input : 𝐗𝑘 the rating matrices for each domain
𝐰𝑘 the weights for each domain 𝐌𝑘 the indicator matrices for each slice 𝜆𝑈 , 𝜆𝑉 , 𝜆𝐶 the regularization parameters
Output : 𝐔 the factor matrix for users 𝐂 the factor matrix for domains 𝐕 , 𝐏𝑘 the factor matrices for items Begin :
Initialization :
1 : 𝐗̅𝑘 ← 𝑤𝑘𝐗𝑘 , 𝐕 ← 𝐈 , 𝚺̅𝑘 ← 𝑤𝑘𝐈 k=1,…,K 2 :
𝐾 Initialize 𝐔 principal eigenvectors ∑ 𝑘=1 by SVD
T𝐗̅𝑘 𝑘
𝐗̅
EM Steps : 3 : 𝐐𝑘 ← 𝐗̅
T𝐔𝚺̅𝑘𝐕T k=1,…,K 𝑘
𝟏 4 : 𝐏𝑘 ← 𝐐𝑘(𝐐𝑘 𝟐 k=1,…,K 5 : Generate tensor 𝓨 whose slices are 𝐘𝑘 ← 𝐗̅𝑘𝐏𝑘 k=1,…,K 6 : Update 𝐔 , 𝐕 , 𝐂 by one iteration CP ALS R ( Algorithm 1 ) :
− T𝐐𝑘 )
[ 𝐔 , 𝐕 , 𝐂 ] =CP ALS R(𝓨 , 𝜆𝑈 , 𝜆𝑉 , 𝜆𝐶 )
7 : 𝚺̅𝑘 ← diag(𝐂𝑘,∙ ) k=1,…,K 8 : 𝐗̅𝑘 ← 𝐌𝑘 ⊛ 𝐗̅𝑘 + ( 𝟏 − 𝐌𝑘 ) ⊛ 𝐔𝚺̅𝑘𝐕T k=1,…,K 9 : Repeat 3 –8 until convergence
Post Steps :
𝐂𝑘,∙ , ie rescale back 𝚺̅𝑘 k=1,…,K 10 : Rescale 𝐂𝑘,∙ ← 11 : Return 𝐔 , 𝐕 , 𝐂 , 𝐏𝑘 k=1,…,K End
𝟏 𝑤𝑘
In particular , one class implicit feedback is dominant in real world . For example , a one class purchase record matrix marks entries with 1 to indicate the buy and the rest of data on this matrix are unknown . Since such one class data is purely indiscriminate , most explicit feedback based MF/TF methods , including CDTF , cannot work well . Hence , we devised an implicit feedback enhanced CDTF ( CDTF IF ) model to deal with one class feedbacks via confidence modeling .
331 Confidence Level In fact , implicit feedbacks can indirectly reflect opinions through user behavior because users may deliberately choose to access which items [ 17 ] . Given an observation matrix 𝐑 of some domain , let us introduce a binary matrix 𝚫 , where its element , 𝛿𝑢,𝑝 , indicates whether the entry 𝐑𝑢,𝑝 has an observed value . Note that the matrix 𝐑 can be rating based like above , or simply all ones to indicate observed entries for one class implicit feedbacks .
𝛿𝑢,𝑝 = {
1 𝐑𝑢,𝑝 has a value
0 𝐑𝑢,𝑝 is missing
𝛿𝑢,𝑝 = 1 can be interpreted that 𝑢 shows some explicit like to item 𝑝 whereas 𝛿𝑢,𝑝 = 0 indicates 𝑢 never consumed 𝑝 , which implies 𝑢 , to some extent , implicitly dislikes 𝑝 . However , such implicit dislike can stem from many other reasons beyond real dislike . For example , the user might be unaware of the existence of the item , or unable to consume it due to its price [ 6 ] . Therefore , we can use varying confidence levels to represent the degree of users’ like or dislike over each item .
The confidence level of user preference is proportional to the value of given rating . That is , the higher the rating is given by a user , the more the confidence indicates that the user indeed likes the item . For example , if a user rates an item with 5 ( the highest score ) , it indicates she/he likes this item very much so we can assign a high
599 confidence level to signify the like . On the contrary , if a user rates an item with 1 ( the lowest score ) , it implies that she/he has much dissatisfaction with this item so a low confidence level is assigned to identify the dislike . On the other hand , to model the confidences of users’ dislike over unrated items ( missing values in 𝐑 ) , a very low confidence level is associated with these entries since we have no evidence to prove the users’ explicit dislike .
According to the above analysis , we can construct a confidence matrix 𝛀 to indicate the level of users’ like/dislike over each item :
𝛀𝑢,𝑝 = {
1
𝛿𝑢,𝑝 = 0 𝛼𝐑𝑢,𝑝 𝛿𝑢,𝑝 = 1
( 18 ) where 𝛼 ≫ 1 is a constant to scale confidence according to the rating of items . For missing value ( 𝑢 , 𝑝 ) , a small constant 1 is assigned to denote the minimal confidence of dislike .
Then , we can add the confidence matrix 𝛀𝑘 into Eq 14 and replace the rating matrix 𝐗𝑘 with indicative matrix 𝚫𝑘 for each domain . Immediately , we obtain the following objective function . min 𝑓(𝐔 , 𝐕𝑘 , 𝚺𝑘 ) =
1 2
𝐾
𝑘=1
∑ ‖𝑤𝑘[𝛀𝑘 ⊛ ( 𝚫𝑘 − 𝐔𝚺𝑘𝐕𝑘
2 T)]‖
( 19 ) where 𝑤𝑘 is the weight as discussed in CDTF and 𝛀𝑘 is the confidence matrix over each domain .
332 Algorithm Similar to the derivation of CDTF , it is possible to transform Eq ( 19 ) into a cube based TF model by variables substitution as follows . Let 𝐗𝑘 = ( 𝑤𝑘𝛀𝑘 ) ⊛ 𝚫𝑘 be the observation matrix and 𝐗̂𝑘 = T ) be the approximate matrix , and then we ( 𝑤𝑘𝛀𝑘 ) ⊛ ( 𝐔𝚺𝑘𝐕𝑘 substitute the variable 𝐗̂𝑘 with the factorization form 𝐔̅𝚺̅𝑘(𝐏̅𝑘𝐕̅)T . So Eq ( 19 ) can be rewritten in the form of Eq ( 20 ) with the regularization terms appended . min 𝑓(𝐔̅ , 𝐕̅ , 𝐂̅ , 𝐏̅𝑘 ) =
+
1 2 𝜆𝑈̅ 2
𝑘=1 ‖𝐔̅‖𝐹
2 +
𝐾
2 ∑ ‖𝐗𝑘 − 𝐔̅𝚺̅𝑘(𝐏̅𝑘𝐕̅)T‖
𝜆𝑉̅ 2
‖𝐕̅‖𝐹
2 +
𝜆𝐶̅ 2
‖𝐂̅‖𝐹
2 ( 20 ) where 𝐏̅𝑘 satisfies the column wise orthonormal constraint as previously . Accordingly , the whole factorization algorithm wrt factor matrices 𝐔̅ , 𝐕̅ , 𝐂̅ , 𝐏̅𝑘 is given by Algorithm 3 .
333 Recommendation According to Eq ( 19 ) , the ranking score matrix for target domain 𝑡 is computed by 𝚫̂𝑡 = 𝐔𝚺𝑡𝐕𝑡 T . So the recommendation ranking over user 𝑢 ’s unrated items 𝒊 can be generated by descendingly sorting the 𝚫̂𝑡(𝑢 , 𝒊 ) . Here , the ranking score matrix 𝚫̂𝑡 can be computed by the back substitution :
𝚫̂𝑡 = 𝐔𝚺𝑡𝐕𝑡
T = [ 𝐔̅𝚺̅𝑡(𝐏̅𝑡𝐕̅)T ] ⊘ ( 𝑤𝑡𝛀𝑡 ) .
However , such back substitution is not necessary because 𝑤𝑡 and 𝛀𝑡(𝑢,𝑝 ) = 1 are constant for all unrated items . Therefore , we can directly sort each row of 𝚫̅𝑡 = 𝐔̅𝚺̅𝑡(𝐏̅𝑡𝐕̅)T in a descending order to rank the items for each user .
3.4 Optimal Weights Assignment Weight parameters are also quite valuable to be discussed because they play an important role in CF models [ 16 ; 24 ] to control the amount of impact from auxiliary data . It has been reported in many literatures that imposing both too much and too little influence will degenerate the performance [ 16 ; 24 ] . So finding well tuned weight parameters is an inevitable step to achieve better performance .
Algorithm 3 : [ 𝐔̅ , 𝐕̅ , 𝐂̅ , 𝐏̅𝑘 ] = CDTF IF(𝚫𝑘 , 𝐰𝑘 , 𝛀𝑘 , 𝜆𝑈 , 𝜆𝑉 , 𝜆𝐶 ) Input : 𝚫𝑘 is the indicative matrices for each domain
𝐰𝑘 is the weight for each domain 𝛀𝑘 is the confidence matrix for each slice 𝜆𝑈̅ , 𝜆𝑉̅ , 𝜆𝐶̅ are the regularization parameters
Output : 𝐔̅ is the factor matrix for users 𝐂̅ is the factor matrix for domains 𝐕̅ , 𝐏̅𝑘 is the factor matrices for items Begin :
Initialization :
1 : 𝐗𝑘 = ( 𝑤𝑘𝛀𝑘 ) ⊛ 𝚫𝑘 , 𝐕 ← 𝐈 , 𝚺̅𝑘 ← 𝐈 k=1,…,K 2 : by SVD
Initialize 𝐔̅ principal eigenvectors ∑ 𝐾 𝑘=1 Iteration : 3 : 𝐐𝑘 ← 𝐗𝑘
T𝐔̅𝚺̅𝑘𝐕̅T k=1,…,K
𝐗𝑘
T𝐗𝑘
𝟏 4 : 𝐏𝑘 ← 𝐐𝑘(𝐐𝑘 𝟐 k=1,…,K 5 : Construct tensor 𝓨 whose slices are 𝐘𝑘 ← 𝐗𝑘𝐏𝑘 k=1,…,K 6 : Update 𝐔̅ , 𝐕̅ , 𝐂̅ by one iteration CP ALS R ( Algorithm 1 ) :
− T𝐐𝑘 )
[ 𝐔̅ , 𝐕̅ , 𝐂̅ ] =CP ALS R(𝓨 , 𝜆𝑈̅ , 𝜆𝑉̅ , 𝜆𝐶̅ )
7 : 𝚺̅𝑘 ← diag(𝐂̅𝑘,∙ ) k=1,…,K
Repeat 3 –7 until convergence
8 : Return 𝐔̅ , 𝐕̅ , 𝐂̅ , 𝐏̅𝑘 k=1,…,K End
The same holds true for CDTF and CDTF IF , where the weights assigned on each domain exactly act as such trade off parameters . Too large weights assigned to auxiliary domains may overwhelm the information from target domain while too small weights may fail to transfer enough knowledge to target domain .
Most of current CF methods [ 16 ; 24 ] usually only involve one or two auxiliary relations so a common way to find an optimal model is to select the best setting from a group of manually given values via cross validation . However , the CDCF problem often involve several domains and the number of possible weights assignments grows with the number of domains exponentially . For example , if we have four domains and the weight on each domain has five possible values {0.01 , 0.1 , 1 , 10 , 100} , then the possible number of combinations of weights is 54 . Obviously , it will be a painful process to find the optimal weights assignment in semi manual way by cross validation . Moreover , such heuristically pre given values do not guarantee to cover real optimal values . Hence , we need a more robust and automated method to find the best weights assignment .
Figure 5 : Searching optimal weights assignment by crossover and mutation operators using GA
Here , we employ the genetic algorithm ( GA ) [ 3 ] to find such optimal weights assignment . We fix the weight on target domain to be 1 so various weights assignments on auxiliary domains act as the individuals in the population . In GA the crossover operator combines a part of elements in each parent to form children for the next generation , so it enables the automatic search for the best combination of weights as depicted in Figure 5(a ) . And the w1w2w3w4w1w2w3w4w1w2w3w4w1w2w3w4w1w2w3w4w1w2w3w4w ~ N(w,σ2)(a ) Crossover(b ) MutationCurrent GenerationNext Generation600 mutation operator applies random changes to a single individual in the current generation to create a child . As illustrated in Figure 5(b ) , the weights in each generation are automatically adjusted by mutation .
Since the range of weight is large , a uniformly randomized initial population will take too long time to converge . So we take the following strategy to initialize the individuals with exponential growth , where 𝛼 ∈ ( 0,1 ] is a constant to scale weight , 𝛽 and 𝛾 are integers to control the range of weight , 𝟏 is an all one vector with the length equal to the number of auxiliary domains .
𝛼 = ( 𝛼 × 10𝑖 ) × 𝟏 for 𝑖 = 𝛽 , ⋯ , 𝛾
𝒘𝑖
Taking an example , we initialize the population as 𝒘 = {𝒘0.5 , 𝒘1} , with 𝛽 = −2 and 𝛾 = 2 , and then we obtain 10 weight vectors ( ie individuals ) ranging from 0.005 to 100 .
Accordingly , the change caused by mutation should match with the order of weight instead of fluctuating in the entire range , so we set up the following mutation rule to generate the child weight 𝑤(𝑔+1 ) , where 𝐺 specifies the maximum number of generations and 𝒩(∙ ) denotes a normal distribution with the mean 𝑤(𝑔 ) and the standard deviation 𝜎 shrinking as generations go by .
𝑤(𝑔+1 ) ~ 𝒩 ( 𝑤(𝑔)|(𝑤(𝑔)𝜎(𝑔+1 ) )
2
) , 𝑠 . 𝑡 . 𝑤(𝑔+1 ) > 0
𝜎(𝑔+1 ) = 1 −
( 𝑔 + 1 )
𝐺
Following the above initial strategy and mutation rule , we can run the GA given any fitness function , eg the MAE ( mean absolute error ) over the testing dataset using CDTF .
4 . EXPERIMENTS The experiments are conducted on two real world datasets , namely the ratings of Amazon products and the follow records of a social networking site . In the following experiments , we evaluated the performance of the rating and ranking prediction by a set of metrics and compared our models with other state of the art approaches .
4.1 Amazon Data Amazon 1 is the most famous e business website to sell diverse products , such as books , DVDs , shoes , etc . The dataset [ 10 ] was crawled from Amazon website and it contains 1,555,170 users and 1 5 scaled ratings over 548,552 different products covering four domains : 393,558 books , 103,144 music CDs , 19,828 DVDs and 26,132 VHS video tapes . Obviously , the users’ preferences are dependent across these domains , so it is very suitable to test CDCF algorithms over this dataset .
Data Preparation : In this experiment , we selected Book and Music CD as the target domain to evaluate respectively . We filtered out users who have rated at least 50 books or 30 music CDs so that there are enough observations to be split in various proportions of training and testing data for our evaluation . Finally , 2,505 users were selected , and in addition we retrieved all items rated by these users in these four domains and set aside top K rated items for each domain respectively . Table 1 shows the statistics of the data for evaluation . Then , we constructed rating matrices over filtered out data for each domain .
 Sparse Data Case : To simulate the sparse data problem , we constructed two sparse training sets , TR20 and TR75 , by
1 http://wwwamazoncom/ respectively holding out 80 % and 25 % data from the target domain Book , ie the remaining data of target domain for training is 20 % and 75 % . The hold out data servers as ground truth for testing . Likewise , we also construct two other training sets TR20 and TR75 when choosing Music as the target domain .
 Unacquainted World Case : We randomly select half users and hold out all their data from target domain to simulate the unacquainted world phenominon . The training set used for this case is denoted as TRuw .
Table 1 . Statistics of amazon data for evaluation
Domain
Items
Book Music DVD VHS
6000 5000 3000 3000
Avg . # ratings for each item
Avg . # ratings for each user
24 15 30 29
57 30 37 35
Density
0.0097 0.0062 0.0124 0.0117
Methods : In all following experiments , a group of state of the art methods are evaluated for comparison , including our models . When running the evaluation using each compared method , we set the dimensionality of factors and other hyper parameters by cross validation .
 MF SGD : It is a single domain based MF model to minimize the squared error by stochastic gradient descent [ 9 ] . It directly takes the rating matrix of the target domain as input and cannot handle the cold start problem .
 N CDCF U : A user based neighborhood CDCF model uses Eq ( 1 ) for prediction . In this experiment , we use k=10 closest users .
 N CDCF I : An item based neighborhood CDCF model uses Eq ( 3 ) for prediction . In this experiment , we use k=10 closest items .
 MF CDCF : A MF model , described in Section 2 , takes the long concatenated rating matrix as input .
 CMF : Collective matrix factorization [ 24 ] is a CDMF which couples rating matrices for all domains on the User dimension so as to transfer knowledge through the common user factor matrix
 CDTF : Our model , which is described in Section 3.2 , takes one of the above domains as target domain to perform prediction and others as auxiliary domains to borrow knowledge .
 PF2 CDCF : The main difference of PARAFAC2 [ 4 ] from our CDTF is that it does not have the mechanism to adjust the amount of knowledge contributed by each domain .
Metrics : we used the most widely used evaluation metric for CF problem , namely Mean Absolute Error ( MAE ) [ 26 ] , to measure the rating prediction quality .
MAE = ∑
𝑎𝑏𝑠(𝑟𝑢,𝑝 − 𝑟̂𝑢,𝑝 )
𝑁
𝑟𝑢,𝑝∈𝑻𝑺 where 𝑟𝑢,𝑝 denotes the true rating user 𝑢 gave to item 𝑝 , 𝑟̂𝑢,𝑝 is the predicted rating , and 𝑁 denotes the number of ratings in testing set .
Comparison : We evaluated the prediction performance using three differently sparse training sets , namely TR75 , TR20 and TRuw constructed above . Table 2 reports the evaluation results with setting Book and Music CD as target domains respectively .
601 Table 2 . MAE ( the smaller the better ) of comparative models with different training sets
CMF
MF SGD
Models
TR20 TRuw
TR75 0.749 N CDCF U 0.488 0.776 0.843 0.701 0.728 0.850 0.826 0.776 N CDCF I 0.503 0.753 0.855 0.715 0.452 0.764 0.821 0.686 PF2 CDCF 0.507 0.765 0.800 0.709 0.327 0.672 0.757 0.664 CDTF
Target Domain : Book Target Domain : Music TRuw TR75 0.597 0.833 0.907 0.873 0.879 0.848 0.839 0.776
TR20 0.942 0.906 1.062 0.832 0817 0.827 0.751
MF CDCF
From Table 2 , we can find that most CDCF models achieve much better performance than single domain CF model . Therein , our model , CDTF , significantly outperforms all other comparative CDCF methods over all testing sets . Especially , more than 35 % improvement is achieved in the case of TR75 training sets , which illustrates that CDTF can better capture personalized factors for each domain when users’ feedbacks are relatively sufficient . NCDCF U also achieves a not bad performance when the data is relative dense , ie TR75 , but the performance decreases very fast when the data becomes sparser . As analyzed in Section 2 , such neighborhood based method usually fails to find global similarity among users when the data is sparse . The typical CDMF model , CMF , overall outperforms MF CDCF . It is because that CMF provides a more effective way to transfer knowledge between domains instead of ignoring the heterogeneity between domains and integrating all data into a single matrix as MF CDCF .
Not surprisingly , CDTF achieves the best performance again in the unacquainted world cases , ie using the training sets TRuw , which can be mainly attributed to the triadic relation modeling over useritem domain so CDTF can better recover the domain specific user preferences than other models . In comparison , CMF lags much behind CDTF . The reason is that CMF only models a couple of dyadic relations over users and items like traditional MF models so , for the unacquainted world cases , it cannot learn the domainspecific user factors due to the absence of domain factors . Specially , PF2 CDCF cannot achieve a good performance though it is also a TF model based on triadic relation . The main reason is that it does not provide a mechanism to trade off the amount of influence contributed from each domain . Next , we will demonstrate impact of weights assignment on the prediction results .
Impact of Weights : CDTF offers a flexible mechanism to balance the amount of influence among auxiliary domains by tuning the weight assigned to each domain . For example , we selected Book as the target domain and varied the weight on all other auxiliary domains from 0.01 to 100 exponentially and report the MAEs over TR20 in Figure 6 ( a ) . We can find that the performance is quite different with different weights assignments . To find the optimal weights assignment , we ran the GA with initial population 𝒘 = {𝒘0.33 , 𝒘0.66 , 𝒘1} and 𝛽 = −2 , 𝛾 = 2 , ie there are totally 15 initial individuals with different scale . The rightmost bar in Figure 6 ( a ) shows the optimal result through GA . Obviously , it performs much better than those results with heuristically setting weights . Figure 6 ( b ) depicts the MAEs changing with iterations , and we can find that it converges very fast and reaches the optimal result within 10 generations .
2 http://wwwkddcup2012org/c/kddcup2012 track1
Figure 6 : ( a ) Comparison of weights assignment optimized by GA to the weights settings varying from 0.01 to 100 ; ( b ) The converging status over generations for searching the optimal weights assignment .
Table 3 reports the results of optimal weights assignments learned through GA . These results prove an obvious truth that the target domain needs only a little information transferred from auxiliary domains ( relative small weights on auxiliary domains ) if there are sufficient data on it , but it needs to leverage more and more information from auxiliary domains ( relative large weights on auxiliary domains ) when the data become sparser .
Table 3 . Optimal weights assignments found through GA over six different training sets
Weight wBook wMusic wDVD wVHS
Target Domain : Book Target Domain : Music TRuw TR75 1.444
TR75 0.012
TR20 0.336
TR20 TRuw
1
1
1
0.001 0.012 13.64 0.002 0.019 3.940 0.001 0.009 0.135 1.875 0.020
1
1
1
0.891 0.459
0.923 0.030
4.2 CDCF in Social Networking Site Social networking sites ( SNS ) may be the most successful product in the age of Web 20 People share videos , blogs , games , movies reviews and all kinds of things on SNS but most people only focus their interests on very a few domains . Finding possible attractive items in people ’s unacquainted domains cannot only improve user experience but bring more profits . In a SNS , we often only know what items users explicitly like , eg the applications added or the groups followed , but no information about what they explicitly dislike . Therefore , it is suggested to perform the implicit feedback CDCF algorithm .
In this experiment , we use the SNS dataset provided by KDD Cup2 , where the dataset provides the profile for each user about the items she/he has followed . These items are categorized into different domains with anonymous names which may be interpreted as game , sports , entertainment , etc . Hence , we ran CDCF methods over this dataset to evaluate the performance of item ranking .
000101110100GA060650707508weights assinged to auxiliary domainsMAE(a ) w = 0.01w = 0.1w = 1w = 10w = 100w = GA012345678910111206706806907071072073GenerationMAE(b ) Best fitnessMean fitness602 Data Preparation : Four domains accounted for most data from the dataset , namely A , B , C and D , are selected for evaluation . We filtered out 7,000 users who have followed at least 10 items in domain A and B . Then , we obtain a dataset that contains about one million follow records over above four selected domains . These follow records are representing one class valued matrix for each domain , that is , the entry with value 1 denotes a user has followed this item . Table 4 illustrates the statistics of this dataset .
Table 4 . Statistics of SNS data for evaluation
Domain
Items
Avg . # users
Avg . # items following an item a user
Density following
A B C D
859 313 863 329
144 287 487 251
17 12 60 11
0.0206 0.0407 0.0681 0.0360
In this experiment , domain A and B are chosen as the target domains for evaluation respectively . For each target domain , we apply the same strategy to construct two training sets TR25 and TRuw as done in the first experiment to evaluate the sparse data and unacquainted world case respectively . All the hold out data are used as ground truths for testing .
Methods : Some models in the first experiment do not support implicit feedbacks , so they cannot handle this dataset consisting of one class values . We provide some other methods instead .
 Most Pop : It is a most widely used strategy to rank item by its popularity ( measured by the number of users following ) .
 N CDCF U : Given a user , the similarity with other users is computed by cosine similarity over all items ( using binary ratings ) . Then , the ranking score is computed as a weighted average rating over all other users . In this experiment , we use k=10 closest neighbors .
 MF CDCF IF : The concatenated matrix based CDCF model described in Section 2 , taking advantage of implicit feedback [ 6 ] .
 CDTF IF : Our cross domain factorization model using implicit feedback , described in Section 33
 PF2 IF : We extend the original PARAFAC2 [ 4 ] to support implicit feedbacks as applying to CDTF IF . The main difference from CDTF IF is that PF2 IF does not have weight parameters to trade off the influence from each domain .
Metrics : We use two frequently used metrics , recall and AUC [ 21 ; 26 ] , to evaluate the quality of ranking for recommendation over TSu , ie the positively followed items for each user in testing set .
 recall@N considers the positively followed items within the top
N , a high recall with lower N will be a better system :
𝑟𝑒𝑐𝑎𝑙𝑙@𝑁 =
#ℎ𝑖𝑡𝑠@𝑁
|𝑻𝑺𝒖|
 AUC ( Area under the ROC curve ) measures the probability that a system ranks a positive instance higher than a negative one .
∑
𝑖∈𝑻𝑺𝒖
𝐴𝑈𝐶 =
∑
𝛿(𝑟𝑘(𝑖 ) < 𝑟𝑘(𝑘 ) )
𝑘∈𝑰\𝑻𝑺𝒖 |𝑻𝑺𝒖| ∙ |𝑰\𝑻𝑺𝒖| where 𝑰 denotes all items in the target domain , 𝑟𝑘(𝑖 ) retrieve the rank of item 𝑖 created by some model and 𝛿(𝑟𝑘(𝑖 ) < 𝑟𝑘(𝑘 ) ) is the delta function returning 1 if 𝑟𝑘(𝑖 ) < 𝑟𝑘(𝑘 ) and 0 otherwise .
Below we report the results using the average recall and AUC from all testing users .
Comparison : The performance of prediction is evaluated using two training sets TR25 , TRuw with setting domain A and B as the target domain respectively . For our model CDTF IF , the scaling constant in Eq 18 is set as 𝛼 = 10 and the weight parameters are automatically optimized by GA . Table 5 reports the results of all comparative methods using the metric AUC .
Table 5 . AUC ( the larger the better ) of comparative models over different training sets
Model
Most Pop N CDCF U MF CDCF IF PF2 IF CDTF IF
Target Domain : A Target Domain : B
TR25 0.8391 0.5015 0.8388 0.8205 0.8365
TRuw 0.9317 0.8112 0.9103 0.6832 0.9570
TR25 0.8015 0.6210 0.7980 0.7276 0.8069
TRuw 0.9389 0.8122 0.9276 0.7358 0.9533
A little surprisingly , the Most Pop method performs better than all other models except CDTF IF . Through a further consideration , we concluded it reveals a general fact that the hot events , music , movies , tweets , etc . are usually listed on the home pages of SNS so users will actively or passively keep their eyes on these popular items and share them with their friends . Such “ rich get richer ” phenomenon over items is ubiquitous on SNS so it leads to a high AUC . The neighborhood based method , N CDCF U , does not perform very well due to the inherent weakness of finding the closest users over the sparse data . CDTF IF surpassing Most Pop proves that CDTF IF not only concerns popular items but also better captures personalized preferences .
The metric recall@k can effectively check if a recommender system can successfully retrieve the items that user has shown positive preference by comparing the top k recommended items from its returned list . Hence we evaluate recall@5~100 over all comparative methods . Figure 7 reports the results over four different training sets . Most Pop does not achieve a high recall@k when k is relative small , which illustrates that apart from some most popular items people tend to follow much more personalized favorite items . Similar to Most Pop , N CDCF U also depends on other users’ preferences so its performance is close to Most Pop . In particular , PF2 IF lags behind CDTF IF due to the lack of adjusting the appropriate amount of influence among target domain and auxiliary domains . Obviously , as illustrated in all four figures , the plots of CDTF IF are consistently above those of all other models , so we can conclude that CDTF IF can better capture the domainspecific personalized preference than other models .
5 . RELATED WORK Most state of the art CDCF models are extended from singledomain MF models , where knowledge from auxiliary domains are transferred into target matrix by some shared factor matrices .
Codebook Transfer [ 12 ] assumes some cluster level rating patterns , which are represented by a codebook , can be found between the rating matrices in two related domains . Rating Matrix Generative Model [ 13 ] extends this idea with a probabilistic model to solve collective transfer learning problems . In reality , there are many cold start users for most domains . Therefore , it is always out of the question to find common patterns when the user data is absent in some domain , ie the unacquainted world case . Dual Transfer Learning ( DTL ) [ 14 ] exploits the duality between by matrix trifactorization , which mainly aims to solve the clustering or
603 classification problems . Given observed features of source and target domains , the marginal distribution corresponds to common latent features learned from the data over all domains , and the conditional distributions corresponds to domain specific latent features . However , the explicit features are commonly not available in collaborative filtering so DTL is not applicable to the CDCF problems as studied in this paper .
Since the user preference is not exclusive in a single domain , a more straightforward way is to transfer knowledge through the userfactor matrix . Collective matrix factorization ( CMF ) [ 24 ] couples target matrix and all auxiliary matrices on User dimension to share the user factor matrix across all domains . Similar to our model , CMF assigns a weight to the loss of fitting each matrix so that it can control the amount of influence from each domain on the user factor matrix . However , CMF does not provide a mechanism to find an optimal weights assignment . Coordinate System Transfer ( CST ) [ 19 ] learns the user factor matrix 𝐔A from an auxiliary rating matrix in the first step , and then generates the user factor matrix 𝐔T for the target domain based on 𝐔A , with the regularization of penalizing the divergence between 𝐔A and 𝐔T . As pointed at the beginning , CST cannot be applied to the multiple domains ( more than two ) scenarios as studied in this paper . Furthermore , all above models inevitably suffer from the unacquainted world issue , which may lead to very poor recommendations .
Hu et al . [ 6 ] presented an implicit feedback based MF model , where they used a similar strategy with us to assign a small confidence to unrated items to represent implicit dislike . Bayesian personalized ranking ( BPR ) [ 20 ] treats explicit rated item as positive class and unrated item as negative class and it uses those classified items to represent the preference ordering between each pair of items . However , it degenerates into a one class feedbacks problem ( all negative items ) for cold start users . Hence , no single domain model can work . It will lead to a typical unacquainted world problem if we resolve such cold start implicit feedback problem using CDMF models . To the best our knowledge , we are the first to introduce implicit feedbacks into the CDCF problem .
In summary , current CDMF methods generally cannot address the unacquainted world issue because they only model the user and item factors but absolutely ignore the domain factors , whereas our CDTF models introduce the triadic interaction among user , item and domain factors so as to overcome the unacquainted world issue .
6 . CONCLUSION In this paper , we have discussed the requirements of CDCF in current web era and limitations of current CDCF methods in an unacquainted world . Our triadic relational CDCF solution , namely CDTF and CDTF IF , is proposed . The experiments have evaluated the performance of rating and ranking prediction in terms of various metrics using our models and other comparative methods . The evidence from all results has shown that our cross domain factorization models significantly outperform all other state of theart methods , especially for cold start cases . It is because our tensor based models can better capture the triadic relation between users , items and domains than only the dyadic relation between users and items modeled by other methods , which lose the domain specific information . The experiments also proved the efficiency of our GA algorithm to find an optimal weights assignment , which can achieve a much better prediction than PARAFAC2 .
In the future , we may extend our model to be a time varying CF model , since the number of items is always changing over time and users can give feedbacks to the same item multiple times . Therefore , we can create a feedback matrix for each time stamp so as to construct a TF model like CDTF . Such model can better capture the temporal factors and the shift of item factors over time .
7 . ACKNOWLEGEMENTS This work is partially supported by China National Science Foundation ( Granted Number 61073021 and 61272438 ) , Research Funds of Science and Technology Commission of Shanghai Municipality ( Granted Number 11511500102 and 12511502704 ) and Cross Research Fund of Biomedical Engineering of Shanghai Jiaotong University ( YG2011MS38 ) .
Figure 7 : Comparison of CDTF IF to Most Pop , N CDCF U , MF CDCF IF and PF2 IF using the metrics recall@5~100 : ( a ) T25 wrt Target Domain A ; ( b ) Tuw wrt Target Domain A ; ( c ) T25 wrt Target Domain B ; ( d ) Tuw wrt Target Domain B .
0102030405060708090100000501015020250303504045krecall(a ) T25 : Target Domain A Most PopN CDCF UMF CDCF IFPF2 IFCDTF IF01020304050607080901000102030405060708091krecall(b ) Tuw : Target Domain A Most PopN CDCF UMF CDCF IFPF2 IFCDTF IF01020304050607080901000102030405060708krecall(c ) T25 : Target Domain B Most PopN CDCF UMF CDCF IFPF2 IFCDTF IF01020304050607080901000102030405060708091krecall(d ) Tuw Target Domain B Most PopN CDCF UMF CDCF IFPF2 IFCDTF IF604 8 . REFERENCES
[ 1 ] Berkovsky , S . , Kuflik , T . , and Ricci , F . , 2007 . Cross Domain
Mediation in Collaborative Filtering . In Proceedings of the 11th international conference on User Modeling SpringerVerlag , Corfu , Greece , 355 359 .
[ 2 ] Bro , R . , 1998 . Multi way analysis in the food industry : models , algorithms , and applications University of Amsterdam
[ 3 ] Goldberg , D . , 1989 . Genetic Algorithms in Search ,
Optimization , and Machine Learning . Addison Wesley Professional .
[ 4 ] Harshman , RA , 1972 . PARAFAC2 : Mathematical and technical notes . UCLA Working Papers in Phonetics 22 , 30 44 .
[ 5 ] Hofmann , T . , 2004 . Latent semantic models for collaborative filtering . ACM Trans . Inf . Syst . 22 , 1 , 89 115 .
[ 6 ] Hu , Y . , Koren , Y . , and Volinsky , C . , 2008 . Collaborative filtering for implicit feedback datasets IEEE , 263 272 .
[ 7 ] Kiers , HAL , ten Berge , JMF , and Bro , R . , 1999 .
PARAFAC2—Part I . A direct fitting algorithm for the PARAFAC2 model . Journal of Chemometrics 13 , 3 4 , 275294 .
[ 8 ] Kolda , TG and Bader , BW , 2009 . Tensor decompositions and applications . SIAM review 51 , 3 , 455 500 .
[ 9 ] Koren , Y . , Bell , R . , and Volinsky , C . , 2009 . Matrix factorization techniques for recommender systems . Computer 42 , 8 , 30 37 .
[ 10 ] Leskovec , J . , Adamic , LA , and Huberman , BA , 2007 . The dynamics of viral marketing . ACM Trans . Web 1 , 1 , 5 .
[ 11 ] Li , B . , 2011 . Cross Domain Collaborative Filtering : A Brief Survey . In Proceedings of the 2011 IEEE 23rd International Conference on Tools with Artificial Intelligence IEEE Computer Society , 1085 1086 .
[ 12 ] Li , B . , Yang , Q . , and Xue , X . , 2009 . Can movies and books collaborate ? cross domain collaborative filtering for sparsity reduction . In IJCAI Morgan Kaufmann Publishers Inc . , 20522057 .
[ 13 ] Li , B . , Yang , Q . , and Xue , X . , 2009 . Transfer learning for collaborative filtering via a rating matrix generative model . In Proceedings of the 26th Annual International Conference on Machine Learning ACM , Montreal , Quebec , Canada , 617 624 .
[ 16 ] Ma , H . , Yang , H . , Lyu , MR , and King , I . , 2008 . SoRec : social recommendation using probabilistic matrix factorization . In Proceeding of the 17th ACM conference on Information and knowledge management ACM , Napa Valley , California , USA , 931 940 .
[ 17 ] Marlin , BM , Zemel , RS , Roweis , S . , and Slaney , M . , 2007 .
Collaborative filtering and the missing at random assumption . In Proceeding 23rd Conference on Uncertainty in Artificial Intelligence
[ 18 ] Pan , W . , Xiang , EW , Liu , NN , and Yang , Q . , 2010 . Transfer learning in collaborative filtering for sparsity reduction . In AAAI
[ 19 ] Pan , W . , Xiang , EW , Liu , NN , and Yang , Q . , 2010 . Transfer learning in collaborative filtering for sparsity reduction . In Proceedings of the 24th AAAI Conference on Artificial Intelligence
[ 20 ] Rendle , S . , Freudenthaler , C . , Gantner , Z . , and Schmidt
Thieme , L . , 2009 . BPR : Bayesian personalized ranking from implicit feedback . In Proceedings of the Twenty Fifth Conference on Uncertainty in Artificial Intelligence AUAI Press , Montreal , Quebec , Canada , 452 461 .
[ 21 ] Rendle , S . , Freudenthaler , C . , and Schmidt Thieme , L . , 2010 .
Factorizing personalized Markov chains for next basket recommendation . In Proceedings of the 19th international conference on World wide web ACM , Raleigh , North Carolina , USA , 811 820 .
[ 22 ] Resnick , P . , Iacovou , N . , Suchak , M . , Bergstrom , P . , and
Riedl , J . , 1994 . GroupLens : an open architecture for collaborative filtering of netnews . In Proceedings of the 1994 ACM conference on Computer supported cooperative work ACM , Chapel Hill , North Carolina , United States , 175 186 .
[ 23 ] Schein , AI , Popescul , A . , Ungar , LH , and Pennock , DM , 2002 . Methods and metrics for cold start recommendations . In Proceedings of the 25th annual international ACM SIGIR conference on Research and development in information retrieval ACM , Tampere , Finland , 253 260 .
[ 24 ] Singh , AP and Gordon , GJ , 2008 . Relational learning via collective matrix factorization . In Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining ACM , Las Vegas , Nevada , USA , 650 658 .
[ 25 ] Srebro , N . and Jaakkola , T . , 2003 . Weighted low rank approximations . In Proceedings of the Twentieth International Conference on Machine Learning , Washington DC , 720 .
[ 14 ] Long , M . , Wang , J . , Ding , G . , Cheng , W . , Zhang , X . , and Wang , W . , 2012 . Dual transfer learning . In Proceedings of the 12th SIAM International Conference on Data Mining
[ 26 ] Su , X . and Khoshgoftaar , TM , 2009 . A survey of collaborative filtering techniques . Adv . in Artif . Intell . 2009 , 2 2 .
[ 15 ] Mørup , M . , 2011 . Applications of tensor ( multiway array )
[ 27 ] Tomasi , G . and Bro , R . , 2005 . PARAFAC and missing factorizations and decompositions in data mining . Wiley Interdisciplinary Reviews : Data Mining and Knowledge Discovery 1 , 1 , 24 40 . values . Chemometrics and Intelligent Laboratory Systems 75 , 2 , 163 180 .
605
