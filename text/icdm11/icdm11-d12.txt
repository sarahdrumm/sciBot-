Multi Task Learning with Task Relations
Zhao Xu and Kristian Kersting
Fraunhofer IAIS
Sankt Augustin , Germany ffirstnamelastnameg@iaisfraunhoferde
Abstract—Multi task and relational learning with Gaussian processes are two active but also orthogonal areas of research . So far , there has been few attempt at exploring relational information within multi task Gaussian processes . While existing relational Gaussian process methods have focused on relations among entities and in turn could be employed within an individual task , we develop a class of Gaussian process models which incorporates relational information across multiple tasks . As we will show , inference and learning within the resulting class of models , called relational multi task Gaussian processes , can be realized via a variational EM algorithm . Experimental results on synthetic and real world datasets verify the usefulness of this approach : The observed relational knowledge at the level of tasks can indeed reveal additional pairwise correlations between tasks of interest and , in turn , improve prediction performance .
Keywords Relational Learning ; Multi task Learning ; Link based Analysis ; Nonparametric Bayesian Models
I . INTRODUCTION
Multi task learning , see eg [ 4 ] , [ 7 ] , [ 12 ] , [ 1 ] , [ 2 ] , is a natural and widely successful setting to collaboratively solve a set of related learning tasks . Intuitively , by learning a joint model for all tasks , the method has to fit the observed data from all tasks simultaneously . This allows for information between different tasks to be shared and can significantly alleviate problems associated with sparse training data such as overfitting and unstable search and in turn often result in significant performance gains compared to single task models . For instance , within preference elicitation , an important subtask of many recommendation systems , we can share information from modeling the preferences of different users , ie , learning the preference of one user is viewed as a task .
This sharing of information between related tasks is close in spirit to statistical relational learning , see e.g [ 9 ] , [ 14 ] , that combines aspects of relational logic and statistical reasoning and learning . For example , when eliciting preferences of users , it is often helpful to consider the social network among them . If two users A and B are friends , their preferences are likely to be similar . They would give similar ratings on an item more likely than users without social relations . Known preference of a user can provide useful information about unknown preferences of related users . Thus the observable relations also allow for information between entities ( users ) to be shared and to improve performance .
Despite these commonalities , there are some fundamental differences among existing multi task and relational learning approaches . Most existing multi task learning methods leverage common latent relations between high level entities , namely tasks , whereas relational learning methods focus on the observed relations between low level entities such as items . Consequently , it is natural to ask the questions
• How do we explicitly employ observed relations among tasks within multi task learning ?
• Can observed relational knowledge reveal additional correlations between tasks of interest ?
An investigation of these questions was the seed that grew into our main contribution : relational multi task Gaussian processes ( RMTGPs ) .
Specifically , relational multi task Gaussian processes introduce for each task one latent function f q , on which we condition the observations . These latent functions are drawn from a common Gaussian process prior for all tasks . However , in contrast to multi task Gaussian processes ( MTGPs ) , the latent functions in RMTGPs are not independent of each other given the shared prior but coupled by the observable task relations . Technically , we introduce an additional random variable rq;q′ representing a relation between ′ . Its value ( true / false ) is conditioned on tasks q and q the latent functions f q and f q . Intuitively , tasks with a true relation between them will have more similar latent functions than those false relations . Viewing functions as nodes in a graphical model , this establishes a network of inter linked tasks so that information of individual tasks can propagate through the whole network . Consequently , RMTGPs not only leverage common latent relations across tasks , but also make use of observed relations between tasks to reveal additional correlations between the tasks of interest1 .
′
The rest of the paper is organized as follows . We start off by touching upon related work in Sec II . Then we introduce the relational multi task models in Sec III and Sec IV . We develop the corresponding inference , learning , and ( transductive ) prediction methods in Sec V . Before concluding , we present our experimental evaluation in Sec VI .
1For the sake of simplicity , we do not model relations among low level entities . This can easily be accomplished by applying relational hierarchical Gaussian process framework to relational GPs instead of GPs .
II . RELATED WORK
III . RELATIONAL LINEAR MULTI TASK MODELS
The relational multi task Gaussian process model unifies two lines of research within the Gaussian process community , namely relational and multi task learning .
[ 9 ] ,
[ 14 ] relational
Statistical learning , see eg for overviews , investigates how to employ relations among entities within probabilistic models . This is mainly motivated by the growing need in analyzing data that is best represented as a graph , such as the World Wide Web , social networks , social media , biological networks , communication networks , and physical network systems . To incorporate links and relations into probabilistic kernel methods such as Gaussian processes ( GPs ) , there are essentially two approaches . One is encoding relations as random variables conditioned on the latent function values of entities involved in relations [ 8 ] , [ 28 ] , [ 26 ] . The other is to encode relations in the covariance matrixes [ 32 ] , [ 23 ] . Intuitively , this represents relational information as hidden common causes and condition the outputs on the relations .
Multi task learning [ 24 ] , [ 7 ] , [ 3 ] , [ 1 ] , [ 31 ] is to collaboratively learn a set of related tasks such that prediction about one query can leverage information from all other queries . Lawrence and Platt [ 19 ] first leveraged Gaussian process in multi task learning , where the covariance matrix is task specific block diagonal structure , the covariances between different tasks are zero . Yu et al . [ 29 ] introduced a hierarchical GP model , where the information is transferred by a “ informed prior ” that is learned from the individual tasks . One recent extension is proposed by Birlutiu et al . [ 5 ] . Additionally , Bonilla et al . [ 6 ] introduced a GP model for multi task learning , which generalized over task attributes with a Kronecker product based method . Most recently , Deshpande et al . [ 10 ] and Landwehr et al . [ 18 ] considered multi task learning in relational domains . In contrast to the present paper , they employed relations within tasks and not across tasks . Besides Gaussian processes , other techniques are employed for multi task learning , eg , the task clustering approaches [ 25 ] , [ 3 ] , [ 27 ] , the regularization methods [ 12 ] , [ 2 ] , and neural networks [ 7 ] . Several relational approaches have been explored . For example , Evgeniou et al . proposed a regularization methods for multi task learning with task relations [ 11 ] . Kato et al . introduced a similar method with a different penalization term [ 17 ] . Sheldon extended their works to incorporate non linear kernels [ 22 ] . In contrast to the regularization based methods , this paper proposes a novel approach which models the prediction uncertainty in multi task learning and incorporates the observable task relations into a flexible probabilistic model . The method encodes both latent and observed relations between tasks within a relational GP framework . The knowledge propagation between tasks is based on the relational likelihood distributions . The proposed framework can also naturally be applied to model multi relational tasks .
Let us start with a simple linear regression model for the relational multi task learning , then extend it to a more flexible Gaussian process model . Assume that there are ( 1 ) a set of n items E = fe1 ; : : : ; eng with attributes X = fxi : xi 2 RD ; i = 1 ; : : : ; ng , and ( 2 ) a set of Q tasks with relations R = frq;q′ : q ; q ′ 2 1 ; : : : ; Qg , as well as ( 3 ) real valued observations on the items for each task q , y q = fyq A . Linear Model for Single task Learning
2 R ; i = 1 ; : : : ; ng . i : yq i
In Bayesian analysis , a linear regression model for a single task can be represented as :
!j ; K N ( ; K ) f ( xi ) = xT yijf ( xi ) ; 2 N ( f ( xi ) ; 2 ) : i = 1 ; : : : ; n i ! ;
( 1 )
The observations yi are modeled as noisy linear combination of attributes with a D dimensional weight ! , which is drawn from a Gaussian with mean and covariance matrix K . f ( xi ) denotes the true value of the data point i . 2 is variance of the noise .
B . Linear Model for Multi task Learning
In multi task learning , there is an underlying assumption that the tasks are distinct , but related with each other . One task can borrow strength from the information extracted from another tasks . In Bayesian framework , it can be modeled with hierarchical method : !qj ; K N ( ; K ) ; f q(xi ) = xT jf q(xi ) ; 2 N ( f q(xi ) ; 2 ) : yq i q = 1 ; : : : ; Q i = 1 ; : : : ; n i !q ;
( 2 )
There is one distinct weight vector !q for each task q , but they are drawn from a common prior N ( ; K ) . The shared prior parameters and K model the common properties in the different tasks . In the hierarchical Bayesian framework , each task is distinguished via personalized parameters , but closely connected with the common prior .
C . Linear Model for Relational Multi task Learning
Most existing multi task learning approaches do not consider observable relations among tasks . However , link and relational information in general have been proved to be a promising way to improve performance . For example , in a social media website , songs are entities , users are tasks . Ratings of users on songs are observations . Additionally we have the social relations between users ( tasks ) . Users being friends would give similar rating values on a song more likely than users with no social relations . Knowing such kinds of relational information will reduce the uncertainty on learning and prediction . To explicitly incorporate the information into the hierarchical linear model , we introduce techniques , and in turn offer the relational multi task Gaussian process model ( RMTGP ) .
The RMTGP model is graphically represented in Fig 1 . For each task , we introduce a random function f q , and assume that all functions are drawn from a Gaussian process ( GP ) , which is a distribution over functions . Additionally the functions are not independent of each other given the GP prior , instead , they are linked together due to some relations . The tasks having relations between them will likely have similar functions . To model these dependencies , we again introduce for each relation rq;q′ an additional random likelihood P ( rq;q′jf q ; f q variable with the conditional ) . are , the Intuitively , the more similar functions f q and f q ′ . more likely there is a relation between the tasks q and q Let us now introduce the prior distributions , the likelihood function for task relations , and the generative process of the RMTGP model .
′
′
A . Prior Distributions
We define a GP prior over the attribute wise latent functions , shared by all tasks . Specifically , for a random function f q( ) of a task q , the function values ff q(x1 ) ; f q(x2 ) ; : : :g at an infinite number of data points can be represented as an infinite dimensional vector , ie , the i’th dimension is the function value f q(xi ) ( shortened as f q i ) . We assume that the infinite dimensional random vector follows a Gaussian process prior with mean function m(xi ) and covariance function k(xi ; xj ) . In turn , any finite set of function values ff q i : i = 1 ; : : : ; ng has a multivariate Gaussian distribution with mean and covariance matrix K defined in terms of the mean and covariance functions of the GP [ 20 ] . Formally , the prior distribution over functions of item attributes is defined as follows : P ( f qj ; K ) = N ( ; K )
(
=
1
( 2)njKj 1
2 exp
, 1 2
( f q , )T K
−1(f q , )
)
;
( 5 ) where f q denotes the function values ( f q items for the task q . K is the n . n covariance matrix .
1 ; : : : ; f q n ) of the
One is tempted to use some covariance function with a finite number of hyperparameters to compute K . However the parameterized kernel function limits the flexibility of the model as eg Yu et al . pointed out [ 29 ] . Therefore , we assume that the prior parameters and K are directly drawn from a conjugate hyperprior , ie Normal Inverse Wishart ( NIW ) distribution [ 13 ] :
P ( ; Kj0 ; 0 ; 0 ; fi0 ) / jKj− 0+n+2 ( , 0)T K tr(fi0K
−1 ) , 0 2 v = , 1 2
2 exp ( v ) ;
−1( , 0 ) :
( 6 )
The parameters 0 > n and 0 > 0 are the degrees of freedom for K and the number of prior measurements
Figure 1 . The RMTGP model for a simple example with two tasks and two items . f 1 and f 2 are random functions drawn from a GP prior , one for each task . The mean and covariance matrix of the GP is drawn from a Normal Inverse Wishart distribution with parameters 0 , 0 , 0 and fi0 . The two functions are coupled with the relation r1;2 between tasks . x1 and x2 are attributes of the two items . an additional random variable rq;q′ for each relation between ′ . The variable rq;q′ is conditioned on !q and tasks q and q !q
′ with the probability P ( rq;q′j!q ; !q
′
; ) = exp(,(!q , !q
′
)T ( !q , !q
′
) ) ;
( 3 ) where > 0 is the rate parameter . The probability naturally captures the property in relational multi task learning . The less the difference between weight vectors of the two tasks , the more likely there are relations between them . In the social media example , the weight vector !q represents intrinsic preference of a user on songs . If two users are friends , then they likely have similar preferences ( ie weights !q ) , and vice versa . The complete linear multi task model with observable task relations is defined as
!qj ; K N ( ; K ) ; rq;q′j!q ; !q
′ q = 1 ; : : : ; Q ; exp(,(!q , !q = 1 ; : : : ; Q q ; q
′
′ i !q ; f q(xi ) = xT jf q(xi ) ; 2 N ( f q(xi ) ; 2 ) : yq i i = 1 ; : : : ; n
)T ( !q , !q
′
) )
( 4 )
IV . RELATIONAL NON LINEAR MULTI TASK MODELS
WITH GAUSSIAN PROCESSES
So far , we have assumed that the latent functions are linear . Each function is characterized by its weight vector . The parameterization of functions limits the flexibility of the model , since the mathematic form of functions is not necessarily linear , there exists uncertainty . To overcome the limitation , we extend the linear case with nonparametric
∑D d for . fi0 represents our prior belief on the covariance matrix before seeing any observations fyqg . For that we can use any Mercer kernel function . A typical choice is the squared exponential covariance function with isotropic distance measure : k(xi ; xj ) = 2 exp( , fl2
2
( xi;d , xj;d)2 )
( 7 ) where and fl are parameters of the covariance function , and xi;d denotes the d th dimension of the attribute vector xi . Now and K are samples of a NIW distribution , they are flexible enough to reflect any possible covariance structure shared among all tasks . By the two parameters and K , the latent correlations between tasks are represented in an elegant way .
B . Likelihood for Task Relations
We now define the likelihood distribution for the observable task relations . As already argued earlier , the related tasks generally show similar intrinsic properties , ie , their functions are likely to be close to each other . We extend the likelihood definition in linear model , and have ) = exp(,d(f q ; f q
P ( rq;q′j ; f q ; f q
( 8 )
) ) ;
′
′
′ where d(f q ; f q ) denotes the distance between two functions . This encodes the natural assumption : The less the , the more likely difference between the functions f q and f q ′ . There are is it that the task q is related/linked to the task q many choices for the distance function used . The typical ones include the L1 and L2 norm . In this paper , we leverage the L1 norm :
′
′ d(f q ; f q
∑ ) = jjf q , f q jf q =
′jj1 , f q i i
′ j :
( 9 )
C . The Generative Model i
Finally we complete the relational multi task GP model with the generative procedure . Give the hyperparameters = f0 ; 0 ; 0 ; fi0 ; 2 ; g , the data is generated as follows :
Kj0 ; fi0 IW0(fi −1 0 ) ; j0 ; K ; 0 N ( 0 ; 1 0 f qj ; K N ( ; K ) ; jf q i ; 2 N ( f q yq i rq;q′j ; f q ; f q i ; 2 ) ;
K ) q = 1 ; : : : ; Q i = 1 ; : : : ; n
′ exp(,jjf q , f q
′jj1 ) :
( 10 )
Where IW0(fi0 ) denotes the Inv Wishart distribution with freedom degree 0 . Generating a matrix from the InvWishart distribution amounts to the following two steps :
• Sampling 0 vectors from a Gaussian distribution fftjfi0 N ( 0 ; fi0 ) ; for t = 1 ; : : : ; 0
• Compute the covariance matrix with
(
0∑
)−1
K = t=1 fftffT t
:
V . INFERENCE AND LEARNING
The key inferential problem in the relational nonparametric hierarchical model is to compute the joint posterior distribution of the unknown variables given the multitask observations Y = fyqgQ q=1 and the relations between tasks R = frq;q′gQ q;q′=1 , as well as the entity attributes X = fxign i=1 . The unknown variables in the model are the latent functions f = ff qgQ q=1 , one for each task . Thus the ∏ posterior is proportional to : ∏
P ( fjY ; R ; X ; ) / P ( KjX ; 0 ; fi
P ( f qj ; K)P ( Y qjf q ; 2I ) P ( rq;q′jf q ; f q
0 ) P ( j0 ; K ; 0 ) −1
( 11 )
.
.
) q
′ q;q′ the model , = where denotes hyperparameters of −1 0 ; 0 ; ; 2 ) . It is clear that the equation is in(0 ; 0 ; fi tractable , since unknown functions are coupled together by the task relations R . To address the problem , we consider to decouple the dependencies with a variational approximation algorithm [ 15 ] . In particular , we expect to find a variational distribution ^P ( f ) to approximate the true posterior P ( fjY ; R ; X ; ) as close as possible . For computational efficiency , a family of fully factorized distributions are assumed ,
^P ( f 1 ; : : : ; f Q ) =
^P ( f q ) ;
( 12 )
Q∏ q=1 and for each f q , the variational distribution is defined as a Gaussian :
^P ( f q ) = N ( f qj^q ; ^K q ) ;
( 13 ) where ^q and ^K q are the mean and covariance matrix of the variational distribution . The difference between the variational distribution and the true posterior distribution is measured via Kullback Leibler ( KL ) divergence , ie , KL( ^PjjP ) = E ^P [ log ^P ( f ) ] , E ^P [ log P ( Y ; R ; fjX ; ) ]
+ log P ( Y ; Rj ) :
Permuting the equation , we get an inequality about the loglikelihood of the data : logP ( Y ; Rj )
= E ^P [ log P ( Y ; R ; fjX ; ) ] , E ^P [ log ^P ( f ) ] + KL( ^PjjP ) E ^P [ log P ( Y ; R ; fjX ; ) ] , E ^P [ log ^P ( f ) ] : ( 14 )
The right terms define a lower bound of the log likelihood of the data . It can also be derived from Jensen ’s inequality . The
−1 0 )
( 15 )
0 = q′
@L @ ^q = K , 2 = , 1 Q∑ 2 Q∑
@L @ ^K q @L @ @L @K q=1
=
K
K q=1
=
1 2 , Q 2 0 2 1 24
+
0 =
0 =
0 =
0 = difference between the lower bound and the log likelihood is the KL divergence . The larger the lower bound is , the smaller the divergence is , and the closer the variational distribution approximates the true posterior . Thus the probabilistic inference problem is now converted into an optimization problem : maximize the lower bound of the log likelihood with respect to the variational parameters . In details , the lower bound is written as :
; ) ]
L =
′
+ q;q′
E ^P [ log P ( rq;q′jf q ; f q E ^P [ log P ( yqjf q ; 2 ) ] E ^P [ log P ( f qj ; K ) ]
∑ ∑ ∑ ∑ + log P ( ; KjX ; 0 ; 0 ; 0 ; fi ,
E ^P [ log ^P ( f q) ] :
+ q q q
= ,
= , 1 2
= , 1 2 , 1 2
= , 1 2
The first two terms are about the expectations of likelihoods : task relations and observations per tasks . The third term is related to the expectation of the prior . The fourth term is about the mean and covariance matrix of the prior . The last term is the entropy of the variational distribution . Since the variational distributions ^P ( f q ) are factorized and defined as Gaussian , the computation of ( 15 ) is relatively straightforward , and we have E ^P [ log P ( rq;q′jf q ; f q
; ) ]
′
′
′
)
]
)T ( ^q , ^q
[ tr( ^K q + ^K q ) + ( ^q , ^q [ n log 2 + tr( ^K q ) + ( yq , ^q)T ( yq , ^q ) [ log det(K ) + tr(K ( ^q , )T ( ^q , )
−1 ^K q )
]
]
E ^P [ log P ( yqjf q ; 2 ) ]
E ^P [ log P ( f qj ; K ) ]
E ^P [ log ^P ( f q ) ] log det( ^K q ) logP ( ; KjX ; 0 ; 0 ; 0 ; fi
−1 0 )
−1 )
= , 1 2 + 0( , 0)T K
[ (0 + n + 2 ) log det(K ) + tr(fi0K
−1( , 0) ] :
( 16 ) Where tr( ) and det( ) denote the trace and determinant of a matrix respectively . Note that the constant terms ( eg log 2 ) do not appear in the equations . Now we learn the variational parameters f^q ; ^K qg by maximizing the lower bound . Since the prior mean and covariance matrix K are unknown as well , we leverage variational EM algorithm to learn the two sets of parameters together . In the E step , we maximize the lower bound with respect to the variational parameters f^q ; ^K qg . The step actually optimizes the variational distribution to approximate the true posterior distribution given the current prior parameters . In the M step , we maximize the lower bound with respect to the prior parameters and K . In each step , we use coordinate ascent to solve the optimization problem . Specifically , we take the derivative with respect to ^q ( resp . ^K q , , and K ) , set it to zero , and solve the equation , then get the update formula for E and M steps . The partial derivative equations are defined as follows 1
∑ −1( , ^q ) + ( ^q , ^q
′
)
2 ( yq , ^q )
−1 , 1
22 I , QqI + −1(^q , ) + 0K
−1
( ^K q )
1 2
−1(0 , )
−1[ ^K q + ( ^q , )(^q , )T ]K
−1
K
2
K
K
K
−1
1 K 2 −1
−1fi0K
−1 , 0 + n + 2 −1 + Q∑ −1( , 0)( , 0)T K [ tr( ^K q ) + ( yq , ^q)T ( yq , ^q ) ] , nQ 22 : ( 17 ) ′ denotes tasks which have relations with the task q=1
@L @2 =
Where q q . Qq is the number of related tasks of q .
Putting everything together , the variational EM method consists of : • E step :
• M step :
∑
−1
−2 + 2Qq)K ) −2Kyq + 2K
−1 + ( q′ −2 + 2Qq)I )
) ;
′
^q −1 :
^q = ( I + ( . ( + ∑
^K q = ( K b ^q ; q
= a 0 + ∑ K = c [ fi0 + 0( , 0)( , 0)T ∑ ^K q + ( ^q , )(^q , )T ] ; tr( ^K q ) + ( yq , ^q)T ( yq , ^q ) q 2 = d
+ q where a,b,c and d are coefficients : a = 0=(Q + 0 ) , b = 1=(Q + 0 ) , c = 1=(Q + 0 + n + 2 ) , and d = 1=nQ .
Iteratively run the E and M steps until convergence , then we can get the approximate posterior distribution N ( ^q ; ^K q ) for each task q and the common prior N ( ; K ) shared by all tasks . The convergence can be monitored by tracing the difference of the optimized parameters ( eg and K ) between two iterations . The procedure can be initialized with = 0 and K = fi0 .
From the E step , we can obviously observe how the tasks are mixed by observed task relations . Updating the variational mean ^q for the task q takes into account three components :
1 ) the prior information K 2 ) the observations within the task 1=2yq , 3 ) the variational means ^q
′ of the tasks having relations
−1 , with q .
In updating variational covariance matrix ^K q , the term QqI comes from the related tasks as well . The M step is similar to that in non relational multi task learning . It is reasonable , since the prior parameters ( and K ) are independent of task relations given the latent functions ( ^q and ^K q ) . A . Transductive Prediction
The prediction inference in multi task learning is to predict values of unobserved entities . In this section we consider the predictive inference in a transductive setting , ie there is no new entity introduced in prediction . It can also be viewed as a learning problem with missing values [ 30 ] . In particular , we still use the variational EM method to address the problem , but the E step is modified such that it learns not only the variational parameters , but also the expectation of unseen values for each task . Let I and U denote the indexes of entities with and without observations . Then the new E step is as follows :
^q = ( I + . ( +
^K q = ( K
−1
∑
1 2 KI + 2QqK ) 1 2 KIyqI + 2K −1 + q′ 1 2 II + 2QqI )
′
^q
) ;
−1 ;
( 18 )
( 19 ) where KI denotes the prior covariance matrix K , but only keeping the columns I , all others being zeros . In comparison with the E step in the last section , updating variational mean and covariance matrix for each task will only consider the data points having observations . ^qU will be the expectation of the missing values , which computation depends on the observations within the same tasks , and the observations from the relational tasks .
In the M step , the update of and K remain unchanged , since the two parameters are independent of observations given the latent functions . Only 2 is updated differently :
] tr( ^K qI ) + ( yqI , ^qI )T ( yqI , ^qI )
∑
;
( 20 )
2 =
[
1 nq q where nq is the number of observations in the task q . 2 is the “ variance ” averaged over all observed data points .
Here we introduce transductive prediction , the proposed model can also work on inductive setting . In the inductive setting , the covariance between the new entities and the known ones can be computed via the nystr¨om method [ 21 ] or similarity matching [ 33 ] .
VI . EMPIRICAL ANALYSIS
Our intention in the empirical analysis is to investigate the following questions :
• ( Q1 ) Does RMTGP perform better than single task GPs and multi task Gaussian processes ( MTGP ) without relations ?
• ( Q2 ) Is its performance more stable for smaller number of observed training examples ?
• ( Q3 ) How does its performance depend on the infor mativeness of the task relations provided ?
To this aim , we implemented RMTGPs as well as singletask GPs and MTGPs within Python and evaluated them on two datasets , a synthetic dataset and Kamishima ’s Sushi data [ 16 ] . For ( R)MTGP , we conducted the experiments within a transductive setting and measured performance using three commonly used metrics :
• the mean absolute error
M AE =
• the root mean squared error
1 n
√ i
∑ jyi , fij ; ∑ ( yi , fi)2 ; )2 i
1 n i(yi , y)(fi , f ) ( n , 1)yf
:
• the coefficient of determination
RM SE =
( ∑
R2 =
Where MAE and RMSE measure the difference between predicted and real values , ie , the smaller , the better , the coefficient of determination R2 measures the generalization performance of a model , the better . For all experiments , we randomly selected 10 % ( 20%,,70 % ) observations of each task for training and the rest for testing . For each setting ( 10%,,70% ) , the selection was repeated 10 times to get the average performance . the larger , ie ,
A . Data Description
The synthetic dataset is generated using the generative procedure described earlier . That is , we uniformly sample n = 100 data points with 1 dimensional attributes xi 2 ( ,15 ; +15 ) . The hyperparameters 0 are computed assuming 0 = cos(x ) and fi0 using a squared exponential kernel . Then , we draw and K from the NIW distribution with parameters 0 , fi0 , 0 = n + 10 , and 0 = 2 .
( a )
( b )
( c )
( d )
( e )
( f )
Figure 2 . Experimental results on the synthetic ( left ) and Sushi ( right ) datasets averaged over 10 random reruns , each on predicting unseen values given different percentages of observations . MAE ( top ) and RMSE ( middle ) ; the lower the two measures , the better the performance . R2 ( bottom ) ; the larger , the better . The results show that exploiting relations among tasks can reveal additional correlations and in turn improve the prediction performance .
10%20%30%40%50%60%70%Training Data1416182022242628MAEsingle GPMTGPRMTGP10%20%30%40%50%60%70%Training Data10152025303540455055MAEsingle GPMTGPRMTGP with uninf . rel.RMTGP with inf . rel.10%20%30%40%50%60%70%Training Data2025303540RMSEsingle GPMTGPRMTGP10%20%30%40%50%60%70%Training Data1234567RMSEsingle GPMTGPRMTGP with uninf . rel.RMTGP with inf . rel.10%20%30%40%50%60%70%Training Data 04 0200020406R2single GPMTGPRMTGP10%20%30%40%50%60%70%Training Data00020406081012141618R2single GPMTGPRMTGP with uninf . rel.RMTGP with inf . rel . Next , 10 functions are sampled from N ( ; K ) , and we add some Gaussian noise with 2 = 0:01 . Finally , the relations between tasks are sampled based on the L1 norm .
The Sushi dataset was collected by Kamishima [ 16 ] . It is about preferences of users on 10 different sushi variants : ebi , anago , maguro , ika , uni , sake , tamago , toro , tekka maki , and kappa maki . Each sushi type is described in terms of the following attributes : style , major group , minor group , heaviness/oiliness , consumption frequency , normalized price , and sell frequency . In total , there are 5000 users , and we randomly select 1000 users for our experiments . Each user provides a full ordering of the ten sushi types according to her preference . The ratings range from 1 to 10 where the most preferred sushi gets the rating 10 . Additionally , each user is described in terms of attributes : gender , age , and others that compile regional information . As there are no task relations ( ie relations between users ) in the sushi dataset , we computed artificial relations with two methods . ( 1 ) We established informative relations using the averaged L1 norm of user ratings thresholded at 03 ( 2 ) We computed un informative relations using the cosine similarities of user attributes thresholded at 0:8 ( ie there is a relation between two users only if they have the same age , gender , living region in early life and living region currently ) . The latter relations are un informative since users with the same attributes do not necessarily have the same preferences on sushi . We further note that , although informed relations are based on ratings , they do not provide much information about the test set since the resulting relations ( exist/nonexist ) only compile whether the preferences of users are similar or not , no more information . In turn , it is still sensible to compare performance between RMTGP and ( MT)GP . Moreover , informative relations are not transitive : u1 and u2 respectively u2 and u3 linked does not imply u1 and u3 linked .
B . Experimental Results
Fig 2 ( left ) summarizes the results on the synthetic dataset . As one can see , in all cases ( different percentages of known observations for each task ) , RMTGPs outperform non relational MTGPs and single task GPs . A Wilcoxon rank sum test ( p value 0:01 ) shows that this difference is significant . Moreover , we see that the RMTGP model performs particularly well when the number of known observations is small . Overall , the RMTGP improved prediction performance between 5.10 % and 1172 % Furthermore , the variability of RMTGP ’s performance across multiple tasks is substantially smaller than for non relational MTGP .
The experimental results on the Sushi dataset are shown in Fig 2 ( right ) . When the relations between users are informative , RMTGPs outperform non relational MTGPs and single task GPs , especially for low percentages of known observations . Furthermore , RMTGPs also achieve good performance if the relations are not informative . The results
( a )
( b )
( c )
Experimental results about
Figure 3 . the impact of relations being informative on the overall performance . The analysis is conducted with the Sushi datasets where task relations are computed with the ratings on 2 ( 4 , 6 , 8 , 10 ) sushi types . MAE ( top ) and RMSE ( middle ) ; the lower the two measures , the better the performance . R2 ( bottom ) ; the larger , the better .
10%20%30%40%50%60%70%Training Data1015202530354045MAERMTGP with inf.10 rel.RMTGP with inf.8 rel.RMTGP with inf.6 rel.RMTGP with inf.4 rel.RMTGP with inf.2 rel.MTGP10%20%30%40%50%60%70%Training Data152025303540455055RMSERMTGP with inf.10 rel.RMTGP with inf.8 rel.RMTGP with inf.6 rel.RMTGP with inf.4 rel.RMTGP with inf.2 rel.MTGP10%20%30%40%50%60%70%Training Data00020406081012141618R2RMTGP with inf.10 rel.RMTGP with inf.8 rel.RMTGP with inf.6 rel.RMTGP with inf.4 rel.RMTGP with inf.2 rel.MTGP are very similar but still slightly better than non relational MTGPs and substantially better than single task GPs . What is the reason that RMTGPs did not substantially outperform MTGP when considering less informative relations ? We find that the L1 norm of the preference differences averaged over all users is 0:5709 . The norm averaged over users having the un informative relations only is 0:5660 . So , there is a difference but not a significant one . In other words , users linked with such relations do not necessarily have similar sushi preferences . Therefore , the benefit of employing these relations within RMTGPs is low and RMTGP essentially coincides with MTGP without task relations . In other words , RMTGPs are a proper generalization of MTGPs and automatically balance between explicit task relations and latent dependencies across tasks learned from observations : if the task relations are uninformative , RMTGP employs just the latent dependencies ; if the task relations are informative , RMTGP employs the revealed additional correlations to improve the predictive performance .
To further investigate the impact of relations being informative on the overall performance , we ran the same experiment with relations of different informativeness levels , namely relations computed using the ratings on the first 2 ( 4 , 6 , 8 , 10 ) sushi types only . Fig 3 summarizes the experimental results . In all cases RMTGPs perform significantly better than MTGPs . Already using the L1 norm on the first two of the ten sushi preferences to establish task relations results in significantly better performance .
To summarize , the experimental results clearly show that all questions ( Q1) (Q3 ) can be answered affirmatively : exploiting relations among tasks can reveal additional correlations and in turn improve the prediction performance .
VII . CONCLUSION
Most existing multi task Gaussian process approaches treat all tasks a priori the same : fully related or totally irrelevant , the Gaussian process has to figure this out by learning . In reality , however , observable relations among tasks fall everywhere along this spectrum and we may know this a priori . In this work , we have shown how to incorporate relations among tasks within a Gaussian process framework . The observed relations among tasks reveal additional correlations that in turn can result in performance gains . Specifically , we have developed a Bayesian framework to multi task learning based on Gaussian processes that exploits observed relations among tasks . On synthetic and real world datasets , we have shown that the resulting class of nonparametric models can yield significantly better predictive performance than single and multi task Gaussian processes . While this paper has focused on regression , the proposed relational multi task Gaussian process framework can be used for classification as well as for preference learning . Furthermore it can be generalized for directed relations as well as multiple classes of relations . These are promising avenues for future work .
ACKNOWLEDGMENTS
This work was funded by the Fraunhofer ATTRACT Fellowship ” Statistical Relational Activity Mining ” ( STREAM ) , and by the European Commission under contract number FP7 248258 First MM , as well as by the German Federal Ministry of Economy and Technology ( BMWi ) under the THESEUS project .
REFERENCES
[ 1 ] R . K . Ando , T . Zhang , and P . Bartlett . A framework for learning predictive structures from multiple tasks and unlabeled data . Journal of Machine Learning Research , 6:1817–1853 , 2005 .
[ 2 ] A . Argyriou , T . Evgeniou , and M . Pontil . Multi task feature learning . In B . Sch¨olkopf , J . Platt , and T . Hofmann , editors , Advances in Neural Information Processing Systems 19 , pages 41–48 . MIT Press , 2007 .
[ 3 ] B . Bakker and T . Heskes . Task clustering and gating for bayesian multitask learning . Journal of Machine Learning Research , 4 , 2003 .
[ 4 ] J . Baxter . A bayesian/information theoretic model of learning to learn via multiple task sampling . Machine Learning , pages 7–39 , 1997 .
[ 5 ] A . Birlutiu , P . Groot , and T . Heskes . Multi task preference learning with an application to hearing aid personalization . Neurocomputing , 73(7 9):1177–1185 , 2010 .
[ 6 ] E . V . Bonilla , K . M . A . Chai , and C . K . I . Williams . Multitask Gaussian process prediction . In JC Platt , D . Koller , Y . Singer , and S . Roweis , editors , Advances in Neural Information Processing Systems 20 . MIT Press , 2008 .
[ 7 ] R . Caruana . Multitask learning . Machine Learning , 28:41–75 ,
1997 .
[ 8 ] W . Chu , V . Sindhwani , Z . Ghahramani , and S . Keerthi . Relational learning with gaussian processes . In B . Sch¨olkopf , J . Platt , and T . Hofmann , editors , Advances in Neural Information Processing Systems 19 , pages 289–296 . MIT Press , 2007 .
[ 9 ] L . De Raedt . Logical and Relational Learning . Springer ,
2008 .
[ 10 ] A . Deshpande , B . Milch , L . S . Zettlemoyer , and L . P . Kaelbling . Learning probabilistic relational dynamics for multiple tasks . In Proceedings of the Twenty Third Conference Annual Conference on Uncertainty in Artificial Intelligence ( UAI 07 ) , pages 83–92 . AUAI Press , 2007 .
[ 11 ] T . Evgeniou , C . A . Micchelli , and M . Pontil . Learning Journal of Machine multiple tasks with kernel methods . Learning Research , 2005 .
[ 27 ] Y . Xue , X . Liao , L . Carin , and B . Krishnapuram . Multitask learning for classification with dirichlet process priors . Journal of Machine Learning Research , 8:35–63 , 2007 .
[ 28 ] K . Yu , W . Chu , S . Yu , V . Tresp , and Z . Xu .
StochasIn tic relational models for discriminative link prediction . B . Sch¨olkopf , J . Platt , and T . Hofmann , editors , Advances in Neural Information Processing Systems 19 , pages 1553–1560 . MIT Press , 2007 .
[ 29 ] K . Yu , V . Tresp , and A . Schwaighofer . Learning gaussian In Proceedings of the 22nd processes from multiple tasks . International Conference on Machine learning ( ICML ’05 ) , pages 1012–1019 , 2005 .
[ 30 ] S . Yu , V . Tresp , and K . Yu . Robust multi task learning In Proceedings of the 24th International with t processes . Conference on Machine learning ( ICML ’07 ) , pages 1103– 1110 , 2007 .
[ 31 ] Y . Zhang and D Y Yeung . Multi task learning using generalized t process . In Y . W . Teh and M . Titterington , editors , Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics ( AISTATS ’10 ) , pages 964–971 , 2010 .
[ 32 ] X . Zhu , J . Kandola , J . Lafferty , and Z . Ghahramani . Graph kernels by spectral transforms . In O . Chapelle , B . Schoelkopf , and A . Zien , editors , Semi Supervised Learning . MIT Press , 2005 .
[ 33 ] X . Zhu , J . Lafferty , and Z . Ghahramani . Semi supervised learning : From gaussian fields to gaussian processes . Technical report , Technical Report CMU CS 03 175 , 2003 .
[ 12 ] T . Evgeniou and M . Pontil . Regularized multi–task learning . In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ( KDD ’04 ) , pages 109–117 . ACM , 2004 .
[ 13 ] A . Gelman , J . B . Carlin , H . S . Stern , and D . B . Rubin .
Bayesian Data Analysis . CRC Press , 2004 .
[ 14 ] L . Getoor and B . Taskar , editors . An Introduction to Statistical
Relational Learning . MIT Press , 2007 .
[ 15 ] M . I . Jordan , Z . Ghahramani , T . Jaakkola , and L . K . Saul . An introduction to variational methods for graphical models . Machine Learning , 37(2):183–233 , 1999 .
[ 16 ] T . Kamishima . Nantonac collaborative filtering : recommenthe dation based on order responses . Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ( KDD ’03 ) , pages 583–588 . ACM , 2003 .
In Proceedings of
[ 17 ] T . Kato , H . Kashima , M . Sugiyama , and K . Asai . Multitask learning via conic programming . In JC Platt , D . Koller , Y . Singer , and S . Roweis , editors , Advances in Neural Information Processing Systems 20 . MIT Press , 2008 .
[ 18 ] N . Landwehr , A . Passerini , L . De Raedt , and P . Frasconi . Fast learning of relational kernels . Machine Learning , 78(3):305– 342 , 2010 .
[ 19 ] N . D . Lawrence and J . C . Platt . Learning to learn with the In Proceedings of the Twentyinformative vector machine . First International Conference on Machine learning ( ICML ’04 ) , 2004 .
[ 20 ] C . E . Rasmussen and C . K . I . Williams . Gaussian Processes for Machine Learning . The MIT Press , 2006 .
[ 21 ] A . Schwaighofer , V . Tresp , and K . Yu . Learning gaussian process kernels via hierarchical bayes . In L . K . Saul , Y . Weiss , and L . Bottou , editors , Advances in Neural Information Processing Systems 17 . MIT Press , 2005 .
[ 22 ] D . Sheldon . Graphical multi task learning .
In NIPS 2008 Workshop on Structured Input and Structured Output , 2008 .
[ 23 ] R . Silva , W . Chu , and Z . Ghahramani . Hidden common cause relations in relational learning . In JC Platt , D . Koller , Y . Singer , and S . Roweis , editors , Advances in Neural Information Processing Systems 20 . MIT Press , 2008 .
[ 24 ] S . Thrun . Is learning the n th thing any easier than learning the first ? In D . S . Touretzky , M . Mozer , and M . E . Hasselmo , editors , Advances in Neural Information Processing Systems 8 , pages 640–646 . MIT Press , 1996 .
[ 25 ] S . Thrun and J . O’Sullivan . Discovering structure in multiple learning tasks : The TC algorithm . In L . Saitta , editor , Proceedings of the 13th International Conference on Machine Learning ( ICML ’96 ) . Morgen Kaufmann , 1996 .
[ 26 ] Z . Xu , K . Kersting , and V . Tresp . Multi relational learning with gaussian processes . In C . Boutilier , editor , Proceedings of the International Joint Conference on Artificial Intelligence ( IJCAI–09 ) , Pasadena , CA , USA , July 11–17 2009 .
