2011 11th IEEE International Conference on Data Mining
Incremental Elliptical Boundary Estimation for Anomaly Detection in
Wireless Sensor Networks
Masud Moshtaghi
∗
∗ , Christopher Leckie
∗ , Shanika Karunasekera
Sutharshan Rajasegarar‡ and Marimuthu Palaniswami‡
∗
NICTA Victoria Research Laboratories
, James C . Bezdek† ,
Department of Computer Science and Software Engineering , The University of Melbourne , Australia
†Department of Computer Science and Software Engineering
The University of Melbourne , Australia
‡Department of Electrical and Electronic Engineering
The University of Melbourne , Australia
I . ABSTRACT
Wireless Sensor Networks ( WSNs ) provide a low cost option for gathering spatially dense data from different environments . However , WSNs have limited energy resources that hinder the dissemination of the raw data over the network to a central location . This has stimulated research into efficient data mining approaches , which can exploit the restricted computational capabilities of the sensors to model their normal behavior . Having a normal model of the network , sensors can then forward anomalous measurements to the base station . Most of the current data modeling approaches proposed for WSNs require a fixed offline training period and use batch training in contrast to the real streaming nature of data in these networks . In addition they usually work in stationary environments . In this paper we present an efficient online model construction algorithm that captures the normal behavior of the system . Our model is capable of tracking changes in the data distribution in the monitored environment . We illustrate the proposed algorithm with numerical results on both real life and simulated data sets , which demonstrate the efficiency and accuracy of our approach compared to existing methods . Keywords Anomaly Detection ; Streaming Data Analysis ; Incremental Elliptical Boundary Estimation ; IDCAD ;
II . INTRODUCTION
A Wireless Sensor Network ( WSN ) consists of a set of nodes each equipped with a set of sensing devices . WSNs provide a cost effective platform for monitoring and data collection in environments where the deployment of wired sensing infrastructure is too expensive or impractical [ 1 ] . The different sensing elements installed on each node , for example temperature and humidity sensors , enable the WSN to collect a large volume of multidimensional and correlated samples . An important challenge for WSNs is to detect unusual measurements , which are caused by either events of interest in the surrounding environment or faults in the nodes . Detection of anomalous measurements at the nodes allows us to conserve limited resources of the wireless nodes by reducing the communication of raw data over the network . In order to detect anomalies we need a well defined notion of the normal behavior of the nodes .
Various data mining approaches have been proposed to build a model of the normal behavior of the nodes . In a decentralized approach , each node in WSNs builds a local model of its own normal behavior . The parameters of the local models are forwarded to the base station or the cluster head where a global model is calculated based on the local models . Many different data modeling methods using this approach have been proposed recently . However , most of these models are static models and cannot adapt to changes in the environment [ 2 ] , [ 3 ] , [ 4 ] , [ 5 ] , [ 6 ] , [ 7 ] , [ 8 ] . Moreover , their accuracy depends on proper selection of the initial training period . If the initial training period is not a good representative of future measurements , the model fails . An open research issue is how to continuously learn models of normal behavior in non stationary environments . The focus of this paper is on efficient anomaly detection techniques suitable for resource constrained wireless sensor nodes to detect unusual events in non stationary environments .
While anomaly detection is an active research topic in WSNs , a critical issue for the practical use of anomaly detection techniques is how to generalize their use to online data streams with temporal changes . There are well known batch techniques for anomaly detection in multidimensional data which use Mahalanobis distance for anomaly detection ( [9 ] and [ 10] ) . In particular , the authors of [ 5 ] proposed a hyperellipsoidal boundary using Mahalanobis distance called Data Capture Anomaly Detection ( DCAD ) to compute a local model of the normal data in WSNs . In this paper , we build on the static model of [ 5 ] to propose an iterative approximation of the Mahalanobis distance and the hyperellipsoidal boundary in data streaming environments .
This paper offers three contributions : ( 1 ) introduction of an iterative formula for the estimation of an ellipsoidal boundary , iterative DCAD ( IDCAD ) ; ( 2 ) introduction of a forgetting factor method to increase the tracking capabilities of the model in non stationary environments ; and ( 3 ) an
1550 4786/11 $26.00 © 2011 IEEE DOI 101109/ICDM201180
467 the sensor nodes , empirical evaluation of the performance of the proposed approaches on three real life and two synthetic datasets . Our results demonstrate that the new approach , by adapting to changes in the environment , can achieve higher accuracy than an existing batch approach in non stationary environments which makes it more suitable for use in practical applications . In contrast to the batch approach , our iterative approach does not require all previous raw data to be buffered at thus reducing memory overhead . We also show that in the evaluation datasets , the proposed iterative formula without the forgetting factor terminates at the same ellipsoid as the batch approach . The next section summarizes related work . In Section IV we present the notation used in this paper . In Section V we derive the formulas for iterative adjustment of the hyperellipsoidal boundary . Section VI develops the method that adds tracking capability to the IDCAD . In Section VII we evaluate our method on five datasets . A summary and conclusions are given in Section VIII .
III . BACKGROUND AND RELATED WORK
An important challenge in monitoring systems is to detect unexpected events or unusual behavior . Therefore , anomaly detection techniques are an important part of automated monitoring systems . In WSNs , anomaly detection techniques have been applied in a variety of applications [ 11 ] , including intrusion detection [ 12 ] , event detection [ 13 ] and quality assurance [ 14 ] , [ 15 ] . Numerous factors affect the use of anomaly detection in these applications , such as mobility in sensors , the condition of the environment ( benign or adverse ) [ 16 ] , the dynamics of the environment , and energy constraints . In order to detect anomalies in the data we need to separate them from normal observations . The most common way to perform this task is by modeling the normal data and then identifying deviations from the model . ie , all
The authors of [ 17 ] proposed one class support vector machine models to find anomalies in WSN data . The main assumption in this approach is that all the training data is available at the sensors , and the training can be done in batch mode , the measurements collected are processed as a single batch . Although these methods often provide a good decision boundary for the normal data , they impose a computational overhead of O(n3 ) on each sensor . The authors of [ 18 ] proposed a Discrete Wavelet Transform ( DWT ) combined with a self organizing map ( SOM ) technique to detect anomalies . The DWT encoded the measurements at the nodes , and the SOM was used at the base station to detect unusual sets of wavelet coefficients . The main drawbacks of this method are firstly , SOM training is sensitive to noise in the data and secondly , it is hard to understand what triggered the reported anomaly . The alarms generated by the anomaly detection systems usually require further verification by more expensive measures such as human operators or fault diagnostic systems . Accepted alarms can then be used as a trigger for other tasks such as waking up more sensors in the field , or increasing the sampling rate of the sensors to gather more data . Therefore , it the output of an anomaly detection technique be easy to interpret . is important that
In [ 3 ] , [ 5 ] hyperellipsoidal boundaries are used to model the normal behavior of the system with batch training . This method tolerates noise in the training data and individual anomalies are reported to users . However , the hyperellipsoidal boundaries are calculated over a training period . The methods in [ 3 ] , [ 5 ] require the nodes to keep measurements in the memory during the training period , and further , at the end of training all measurements are processed in batch mode . These methods are computationally efficient , but their inability to adapt to changes in the environment and the problem of choosing a proper training period render them somewhat impractical .
The authors of [ 14 ] demonstrated a need for adaptive modeling for anomaly detection in WSN . They used a dynamic Bayesian network that maps to the network structure for data quality control by using spatial and temporal relationships between the sensors . In [ 19 ] , the authors proposed an adaptive way of updating the normal model of the sensor data . However , the support vector machine ( SVM ) based model advocated in [ 19 ] is computationally demanding to train and update in wireless nodes .
There are a set of approaches which look at the data stream and build a regression model or assume a data distribution model for the data in the stream and use likelihood ratio or cumulative sum ( CUSUM ) test to detect changes in the data model . The authors of [ 20 ] proposed a multi class CUSUM algorithm to detect network anomalies . CUSUMbased algorithms for anomaly detection are computationally efficient ; however their threshold based detection mechanisms usually cannot model normal behavior accurately . Ross et al . [ 21 ] proposed an iterative estimation of an autoregressive model of the data stream and used CUSUM for online detection of anomalies .
In this paper , we propose an iterative approach ( IDCAD ) to create hyperellipsoidal decision boundaries . Each node adjusts its hyperellipsoidal model based on the measurements up to the current time . When changes in the parameters of the boundary become small the IDCAD algorithm terminates , and the final hyperellipsoidal boundary is similar to that found by the batch approach in [ 5 ] . An analogy for the difference between the iterative formulation and the work proposed in [ 5 ] is the difference between Least Squares Estimation ( LS ) and Recursive Least Squares ( RLS ) . In the literature , the term recursive is often , rather loosely , used instead of iterative . We sidestep this semantic argument by calling our method iterative . Further , we introduce a forgetting factor in the iterative estimation algorithm to allow the model to track non stationary behavior in the sampled data distribution .
468
IV . DEFINITIONS AND NOTATIONS
We begin by presenting the definitions that are needed for describing the hyperellipsoidal model for anomaly detection . Let Xk = {x1 , x2 , . . . ,xk} be the first k samples at times {t1,t2 , . . . ,tk} in a node in a WSN where each sample is a d × 1 vector in ℜd . Each element in the vector represents an attribute of interest measured by the node , for example temperature and relative humidity . The sample mean mk of Xk can be calculated using the formula in Eq 1 . The sample covariance Sk can be calculated using the formula in Eq 2 . mk = 1 k k∑ j=1 x j
( 1 )
( 2 ) fi fi
;t ) =
;t ) = k∑ j=1
( x− mk ) ≤ t2
( x j − mk)(x j − mk)T
The hyperellipsoid of effective radius t centered at mk
Sk = 1 k− 1 . with covariance matrix Sk is defined as x ∈ ℜd|(x− mk)T S −1 −1 ek(mk , S ( 3 ) k k Remark 1 : ( x−mk)T S ( x−mk ) is the Mahalonobis distance −1 −1 k from x to mk and S is the characteristic matrix of ek . . k x ∈ ℜd|(x− mk)T S
The boundary of hyperellipsoid ek is defined as −1 δek ( mk , S k Remark 2 : Using t2 = ( χ2 d
( ie , the inverse of the chisquared statistic with d degrees of freedom ) with p = 0.98 results in a hyperellipsoidal boundary that covers at least 98 % of the data under the assumption that the data has a normal distribution [ 22 ] . We use this value for t2 throughout this paper . Definition 1 We define a single point first order anomaly with respect to ek as any data vector x ∈ ℜd that is outside it : x is anomalous for ek ⇔ ( x− mk)T S −1 k
( x− mk ) > t2
( x− mk ) = t2
)−1 p
−1 k
( 4 )
( 5 )
V . ITERATIVE ELLIPTICAL BOUNDARY ESTIMATION Now we are ready to process the next sample at the node . At tk+1 we record the measurement vector xk+1 ∈ ℜd . First we test xk+1 using Eq 5 and then use it to increment ek . If xk+1 /∈ ek we declare it to be an anomaly and send it to the base station for further processing .
( xk+1 − mk ) mk+1 = mk + 1 k + 1 ' I −
−1 S k+1
−1 = kS k k− 1
( xk+1 − mk)(xk+1 − mk)T S + ( xk+1 − mk)T S
( xk+1 − mk )
−1 k
−1 k k2−1 k
( 6 ) ff
( 7 )
469
These formulas for iterative updates of the characteristic matrix and center of ek can be found in [ 23 ] ( pp150151 ) We call this scheme the iterative ellipsoidal boundary estimation ( IDCAD ) method . Instead of using an estimate obtained from the first couple of samples to initialize the −1 = I where I is the identity iterative method we use S matrix ( because the first few samples often result in a singular sample covariance matrix ) . The identity matrix corresponds to a hypersphere . An initial hypersphere with a small radius increases the speed of the convergence of IDCAD . In this paper we do not investigate the effects of the initial radius on the convergence of IDCAD .
−1 ek(mk , S k
The formula in Eq 7 is similar to iterative formulas used in RLS . We use both normal and anomalous measurements to increment ek under the assumption that a large majority of the data is normal and hence , will cancel any undesired effects of updating with anomalous measurements . However , we can imagine more sophisticated approaches that handle anomalies differently . Such approaches should consider whether anomalies are a normal change ( drift ) in the environment or not . This type of analysis would require additional inputs to determine the type of anomaly . Let Xn = {x1 , x2 , . . . ,xn} be a sequence of observations ;t)|1 ≤ k ≤ n at a node . The IDCAD ellipsoids If ( m , S ) are the sample mean and are well defined . −1;t ) is the ellipsoid used by the batch cov(Xn ) , ens(m , S static ( DCAD ) method in [ 5 ] where subscript s indicates static . When every input at the node is used to update n ;t ) ∼= ens(m , S −1 −1;t ) . That is , the IDCAD ellipsoid , en(mn , S the sequence {ek} should terminate very close to the static ellipsoid ens . We will discuss the asymptotic case shortly . Fig 1 contains two graphs that study the behavior of {ek} as k → n . The data underlying these views is the set of n = 818 ( temperature , humidity ) pairs scatter plotted in Fig 1(a ) from the IBRL dataset described in Section VII A . Fig 1(c ) shows several of the IDCAD ellipses in the sequence {ek : 1 ≤ k ≤ 818} . The dashed ellipse is the terminal ellipse in the sequence , and the convergence of {ek} → e818 , is clearly evident . Fig 1(b ) graphs the two as k → n = 818 . The eigenvalues −1 eigenvalues of S 818s are {αM,818 = 11.88,αM,818s = 12.09} and −1 k of S {αm,818 = 0.39,αm,818s = 039} Fig 1(b ) shows that the −1 reaches its terminal value at smaller eigenvalue of S −1 k k = 75 , while the larger eigenvalue of S experiences a very k large deviation from αM,818s which maximizes at k = 327 where |αM,818s − αM,818| = 18941 The points to the left of the vertical line in Fig 1(a ) correspond to the first 320 samples which result in very narrow ellipses initially in IDCAD as shown by high values for the larger eigenvalue in Fig 1(b ) . Fig 1(b ) suggests that the sequence {ek} begins to approximate e818s at about k = 600 , roughly 75 % of the input samples . Does this hold ( roughly ) for other datasets ? If yes , this might yield an effective rule of thumb for the size of training window used in [ 5 ] . If not , we will want
∼= S
−1 818
42
41
40
39
38
37
36
35
34
)
%
( i y t i d m u H
First 320 samples
250
200
1 − S k
201.5
α m α M l f o s e u a v n e g E i
150
100
50
( b )
( c )
( a )
42
41
40
39
38
37
36
35
34
)
%
( i y t i d m u H
33
20
21
22
23 25 Temperature ( C° )
24
26
27
28
( a ) n = 818 points from the IBRL data
0
0
75
200
327 400
# Samples
−1 ( b ) Eigenvalues of S k as k → n e(c ) es=e818 e(a ) e(b )
23 25 Temperature ( C° )
24
26
27
28
600
800
33
20
21
22
( c ) Some IDCAD ellipses
Figure 1 . Convergence of IDCAD sequence ek to its terminal state e818 = es more information on the rate of convergence of {ek} → ens . ( ( → Now we briefly discuss the limiting case . As k → ∞ in Eq 6 and 7 , ( mk+1 − mk( → 0 and likewise , 0 . The factor k2−1 in the denominator in Eq 7 slows the convergence as k → ∞ . Since we always deal with a finite set of observations , the rate of convergence will be of more interest than the limit .
( (S
−1 k+1
− S
−1 k k
VI . TRACKING CAPABILITY
To enable the iterative algorithm to track data variation in the monitored environment , we introduce a forgetting factor for the older measurements . We define the weighted sample covariance over a period of k samples by introducing the forgetting factor 0 < λ < 1 which gives a weight of λj to the measurement from j samples ago . This type of forgetting factor with exponential forgetting is widely used in the estimation literature [ 24 ] . An Exponential Moving Average ( EMA ) shown in Eq 8 can be used to update the sample mean for k > 2 . mk+1,λ = λmkλ+ ( 1− λ)xk+1
( 8 )
The weighted sample covariance with exponential forget ting factor λ for k samples is shown in Eq 9 .
Skλ = 1 k− 1 k∑ j=1
( x j − mkλ)(x j − mkλ)T λk− j .
( 9 )
We start by finding a formula for the iterative covariance matrix updates considering the forgetting factor and then derive an iterative update formula for the characteristic matrix . By re arranging the formula in Eq 9 , we can write the update formula for the covariance matrix at time k + 1 based on the covariance matrix of the previous step plus an update value . Eq 10 shows the one step update for the covariance matrix . λ(k− 1 )
Skλ+ 1 k
( xk+1 − mk+1,λ)(xk+1 − mk+1,λ)T ( 10 )
Sk+1,λ = k
We can replace mk+1 in the above formula with its value from Eq 8 to obtain
Sk+1,λ =
λ(k− 1 ) k
Skλ+
λ2 k
( xk+1 − mkλ)(xk+1 − mkλ)T
( 11 ) In order to calculate the direct update formula for the characteristic matrix , we use the matrix inverse lemma Eq 12 for the inverse of the sum of two matrices . The assumption in this equation is that E is invertible and B is a square matrix . Note that in our case E is a number and C and D are vectors . By applying this lemma to Eq 11 and after some re arrangements we obtain the formula in Eq 13 .
( B +CED)−1 = B
−1 − B
−1C(E
−1 + DB
−1C)−1DB
−1 ( 12 )
×
−1 ' −1 k+1,λ = kS kλ λ(k− 1 ) S ( xk+1 − mkλ)(xk+1 − mkλ)T S −1 I − kλ ( k−1 ) λ + ( xk+1 − mkλ)T S kλ(xk+1 − mkλ ) −1 ff ( 13 )
We call the sequence of updates to ek using Eq 8 and 13 the forgetting factor IDCAD ( FFIDCAD ) .
The forgetting factor λ should be close to one . The suggested range for λ in the estimation theory literature is [ 0.9 099 ] Throughout this paper we use λ= 0.99 and suggest that the range for λ for FFIDCAD be [ 0.99 , 0999 ] This method increases the significance of the current measurement compared to previous measurements , but for very large k the iterative algorithm becomes unstable . Fig 2 shows this effect on the real life dataset Grand Saint Bernard ( GSB ) ( see Section VII A for more details about the GSB dataset ) . As k → ∞ the value in the brackets of ( 13 ) approaches I , thus −1 the characteristic matrix updates approach S kλ λ . Therefore , as k grows large the effects of the new measurement becomes −1 small and S kλ λ controls the change in the characteristic matrix . As the volume of a hyperellipsoid is proportional to
470 the inverse of the square root of the determinant of its characteristic matrix , this update gradually reduces the volume of the hyperellipsoidal boundary . To deal with this issue , we limit the growth of k by introducing a sliding window based benchmark approach and an approximation for it with lower computational complexity called the Effective N approach .
Discarded samples at tk
… . k n 1 k n k n+1
…… k 1 k k+1 k+2
Time=tk
Benchmark :
Sliding window of n samples
Time=tk+1 e u l a v n e g E i
12000
10000
8000
6000
4000
2000
0 0
Plot of Eigenvalues of the Characteristic Matrix
GSB Dataset
5000
10000
Samples
15000
Figure 2 . The eigenvalues of the characteristic matrix after each update using FFIDCAD . After sample 5000 the larger eigenvalue is very unstable .
A . Benchmark Estimation
To limit the growth of k in the update formulas of FFIDCAD , we can use FFIDCAD over a sliding window of size w . To provide a benchmark for comparison we recalculate our overall estimate from the beginning of the window to get the exact FFIDCAD ellipsoid after each input . This approach is computationally inefficient for an online algorithm , but it provides the exact value of the hyperellipsoidal boundary using the active measurements , ie , the measurements in the sliding window , and is used as the benchmark for comparison of the proposed approach for limiting the effect of large k in our calculations .
B . Effective N
In this approach , to deal with the issue of large k for instead of k in tracking , we simply use a constant neff Eq 13 when k ≥ neff . The idea is that after k ≥ neff weights assigned to data samples approach zero , ie , λk ∼= 0 , so the corresponding samples have been ( almost ) forgotten completely . We suggest neff = 3τ in this paper , where τ = 1 1−λ is known as the memory horizon of the iterative algorithm with an exponential forgetting factor λ . A view of the benchmark and the Effective N tracking approaches is shown in Fig 3 . The boxes show the samples that have been considered in the calculation of the ellipsoidal boundary . In the Effective N approach the weight of older samples decreases exponentially , but no cut off is defined .
471
Absorbed into with weight 
1 λkS − , 0≅effn λ neff at time=tk+1
… . k n 1 k n k n+1
…… k 1 k k+1 k+2 neff at time=tk Effective N approach
Figure 3 . A view of the benchmark and the Effective N approaches at samples k and k + 1
VII . EVALUATION
We start this section by introducing the datasets used in our evaluation of the different methods . Then we show that IDCAD terminates at the batch approach using all the datasets . We continue by comparing the proposed Effective N approach with the benchmark approach for FFIDCAD . Detection and false alarm rates of the two methods for FFIDCAD on the synthetic datasets are used for comparison . In the synthetic datasets a uniform noise from [ −10 10 ] is added randomly to 1 % of the samples and these samples are labelled anomalies while the rest are considered normal . Another comparison approach is introduced based on deviation from the proposed benchmark approach , which does not require a labelled dataset and hence , allows us to use real life datasets for comparison . Next , we check the effects of FFIDCAD on anomaly detection compared to IDCAD . Finally , we compare our proposed FFIDCAD with Effective N with a change detection technique proposed in [ 21 ] .
A . Datasets
We use three real life datasets to evaluate our iterative model for anomaly detection and compare it with existing methods . The first dataset ( IBRL ) consists of measurements collected by 54 sensors from the Intel Berkeley Research Lab [ 25 ] . In this paper , we used the data from epochs 25000 to 30000 of node 18 . Fig 1(a ) shows the first 818 samples in this data . The second dataset ( GSB ) was gathered in 2007 from 23 sensors deployed at the Grand St Bernard pass between Switzerland and Italy [ 26 ] . We extracted the data gathered during October by station 10 . The third dataset is the Le Genepi dataset , gathered in 2007 from 16 sensing stations deployed on the rock glacier located at Le Genepi above Martigny in Switzerland . The data from Station 10 in a twelve days collection period starting at October 10th is used in this paper .
45
40
35
30
25
)
%
( i y t i d m u H
20
20
30
IBRL Dataset
100
Grand St . Bernard ( GSB )
)
%
( i y t i d m u H
90
80
70
60
50
40
30
20
10
60
70
0 −15
−10
−5
0
Temperature ( C° )
5
10
15
40
Temperature ( C° )
50
)
%
( i y t i d m u H
90
80
70
60
50
40
30
20
10
0 −15
Le Genepi
−10
−5
0
Temperature ( C° )
5
10
15
Figure 4 . Scatter plots of the datasets used for evaluation ( IBRL left , GSB middle and Le Genepi right )
30
25
20
15
10
5
0
−5
−5
Normal Data Noisy Data
M1
50
40
30
20
10
0
2 1
3 2
4 3
5 4
6 5
7 6
8 7
9 8
9 1
1
1
M2
0
5
10
15
20
25
30
−10
M2 0
1 2 2
1 2 2 1
M1
3
4 5
5 6
6
6 7
7 8
7
8 9
9 10
1
1 10 1112 1
Normal Data Noisy Data
10
20
30
40
50
60
Figure 5 . Scatter plots of synthetic datasets used for evaluation ( S1 Left and S2 right )
The synthetic datasets ( shown in Fig 5 ) , are generated by considering two modes , M1 and M2 , with different normal distributions N(Σ1 , μ1 ) and N(Σ2 , μ2 ) and 9 intermediate modes . The parameter values of the modes M1 and M2 are shown in Table I . M1 is the initial mode , and M2 is the final mode . M1 is transformed as follows .
)
S1
0.6797 0.1669
Σ1 =
0.1669 0.7891
)
Σ1 =
S2
10.0246 1.2790
1.2790 2.1630
μ1 = ( 20,20 ) )
Σ2 =
0.7089 0.1575
0.1575 0.8472
μ1 = ( 45,42 ) )
Σ2 =
7.6909 0.6646
0.6646 2.1624
M1
M2
μ2 = ( 5,5 )
μ2 = ( 5,5 )
PARAMETERS OF THE TWO NORMAL DISTRIBUTIONS USED TO
GENERATE SYNTHETIC DATASETS
Table I
First , 500 samples {k = 1 . . .500} are drawn from M1 . Sampling continues as each individual value in the covariance matrix and the mean is changed in 10 equal steps . After the first step , 200 samples {k = 501 . . .700} are taken
472 from the new normal distribution . After each new step 200 more samples are added to the dataset . The final step ends at mode M2 . In the first dataset , S1 , the steps are much smaller than the second dataset , S2 . In this way , we can examine how the size of the steps affects the tracking methods . In )−1 Fig 5 , ellipses with t2 = ( χ2 0.98 are shown at M1 and M2 . d The dots are the data samples . The stars show 1 % of the samples at each normal distribution which are perturbed by a uniform noise from [ −10 , 10 ] . These samples are labelled real anomalies , while the rest of the samples are labelled normal . This labelling is used to calculate detection and false alarm rates for these data sets .
B . IDCAD Convergence
We ran the IDCAD method proposed in Section V and compared it to the batch DCAD approach of calculating the covariance matrix and the mean for the dataset as a whole . We use focal distance , a measure of the distance between two ellipsoids [ 27 ] , to check how close the final elliptical boundary of IDCAD is to the DCAD . The focal distance considers both the shape and location of two ellipsoids . The final result of the iterative and batch algorithms is very similar and the focal distances between the final ellipsoids , ie , FD(en , ens ) , are very small ( BRL=0.0016 , SGB=0.0014 and Le Genepi=00024 ) These small distances do not provide a visually apparent effect on the final boundaries shown in Fig 6 . The dotted line ellipsoids in Fig 6 show the final ellipsoid obtained from IDCAD and the black solid ellipsoids are calculated using the batch approach .
C . Comparison of Tracking
To compare the proposed tracking methods , first we used our synthetic data to compare the accuracy of the proposed methods for anomaly detection . A window size of 300 samples is considered for the benchmark algorithm . Similarly neff is set to 300 samples . Table II shows the detection and false alarm rates for the proposed approaches . The Effective N approach has accuracy comparable to the benchmark approach . This shows that the Effective N approach is a good approximation of the benchmark approach and neff can replace k in the iterative formula for tracking to solve the instability problem when k becomes large .
Dataset
S1 S2
Benchmark FA 2.4 % 2.6 %
DR 96 % 81 %
Effective N FA 3.1 % 3.3 %
DR 96 % 85 %
COMPARISON OF DIFFERENT TRACKING METHODS ON SYNTHETIC
DATASETS ( DR : DETECTION RATE , FA : FALSE ALARM RATE )
Table II
We use a measure of deviation from the benchmark for evaluation of the Effective N approach on unlabeled data . The deviation can be calculated as the distance between two entities , ie , elliptical boundaries . We use the focal distance [ 27 ] to calculate the distance between pairs of elliptical boundaries , calculated after each new sample ( beginning from sample number 300 ) where the different forgetting factors result in different elliptical boundaries . Fig 7 shows the focal distance between the elliptical boundaries of Effective N and the benchmark . The hyperellipsoidal boundaries calculated by the Effective N approach are very similar to the benchmark algorithm and mostly have values near zero for the focal distance ( two ellipsoids with a focal distance of less than 2 in the temperature humidity input space can be considered very similar ) . There are only a few values of focal distance in the GSB dataset that are considered large . They occur when there appears to be a sudden fault in the humidity sensor of the node ( see the Ushaped structure at the bottom of the GSB scatter plot in Fig 4 ) . The reason for this difference is that the Effective N approach lags behind the benchmark , since it does not completely forget the samples beyond neff . Hence when there is a sudden change in the data stream , initially there will be some difference between the elliptical boundaries produced by the two approaches . Table III shows the average focal distance for different approaches in each dataset . Fig 7 and Table III support our assertion that the Effective N method is a good approximation of the benchmark approach for these datasets .
Dataset
Effective N
S1 0.13 ± 0.00
S2 0.28 ± 0.00
IBRL 0.11 ± 0.00
GSB 0.65 ± 0.01
Le Genepi 0.57 ± 0.00
Table III
AVERAGE FOCAL DISTANCE BETWEEN HYPERELLIPSOIDAL
BOUNDARIES CALCULATED USING EFFECTIVE N AND THE BENCHMARK
TRACKING METHODS .
Fig 8 shows the snapshots of the Effective N approach taken at 300 sample intervals in the synthetic datasets . We can see that the elliptical boundary tracks changes in the synthetic datasets from mode M1 to M2 .
D . Comparison of Sequential and Batch Anomaly Detection We compare FFIDCAD using the Effective N approach to the DCAD approach proposed in [ 5 ] using the two synthetic datasets . The detection rate and false alarm rates are shown in Table IV . The FFIDCAD with Effective N approach achieves much better accuracy than the batch DCAD method in these datasets which represent non stationary environments . This is because the data used for batch learning does not come from a single distribution , so the assumption of normality is a weak one that results in the inability of the model to detect anomalies .
Dataset
DCAD
S1 S2
DR 55 % 29 %
FA 2.1 % 1 %
Table IV
FFIDCAD FA 3.1 % 3.3 %
DR 96 % 85 %
COMPARISON OF THE ANOMALY DETECTION CAPABILITY OF DCAD VS FFIDCAD WITH EFFECTIVE N APPROACH ( DR : DETECTION RATE , FA :
FALSE ALARM RATE )
E . Change Detection in Data Streams
In this section , we compare the usage of our proposed method for online anomaly detection in data streams with the approach in [ 21 ] . In data streaming analysis it is very common to use a dynamic prediction model and use residual analysis such as CUSUM to detect change or anomalies in the data stream . We use a typical model of this kind and compare with our FFIDCAD with Effective N . Similar to [ 21 ] , we iteratively build an ARX model of order np = 4 for temperature prediction with humidity as the input ( stimulus signal ) using Recursive Least Squares ( RLS ) , and apply CUSUM on its residual to find changes in the data stream . FFIDCAD is defined to find single point anomalies and can be easily modified to detect change points . The FFIDCAD model can simply signal a change when it sees na consecutive single point anomalies in the data stream .
473
IBRL − FD(e ,e n ns
) =0.0016
55
50
45
40
35
30
25
)
%
( i y t i d m u H
GSB − FD(e ,e n ns
) =0.0014
140
120
100
80
60
40
20
)
%
( i y t i d m u H
120
100
80
60
40
20
)
%
( i y t i d m u H
Le Genepi − FD(e ,e n ns
) =0.0024
800
10
15
20 0
10
20
30
40
Temperature ( C° )
800
50
60
70
0 −15
−10
−5
0
5
Temperature ( C° )
10
15
20
0 −15
−10
−5
5 Temperature ( C° )
0
Figure 6 . Terminal elliptical boundaries calculated using the IDCAD ( dotted line ) and EBE approaches ( solid line ) with corresponding focal distances e c n a t s D i l a c o F
5
4.5
4
3.5
3
2.5
2
1.5
1
0.5
0
0
Start of shift
S2 S1
7
6
5
4
3
2
1 e c n a t s D i l a c o F
GSB IBRL Le Genepi
500
1000
Samples
1500
2000
0
0
2000
4000
6000
8000 10000 12000 14000 16000 Samples
Figure 7 . The focal distance between the Benchmark and Effective N methods on synthetic datasets ( left ) and real datasets ( right )
30
25
20
15
10
5
0
−5 −5
Snapshots of Effective N on S1 e initial e terminal
0
5
10
15
20
25
30
50
45
40
35
30
25
20
15
10
5
0
−5
Snapshots of Effective N on S2 e initial e terminal
0
10
20
30
40
50
Figure 8 . Snapshots of the Effective N approach at different stages of the algorithm on synthetic datasets
The lack of a ground truth in real datasets makes it hard to interpret the change points . Here , we only use IBRL and the two synthetic datasets to compare the results of the two approaches . Both ARX/RLS and FFIDCAD are considered to be inaccurate at their initial state , therefore , we delay using these models for anomaly detection for the first nd = 50 samples after their initialization . Also note that after each change point the model is reset back to its initial state .
Fig 9 shows the results of the ARX/RLS method and FFIDCAD method for change detection . The red plus symbols indicate the change point in these figures . The performance of FFIDCAD and ARX/RLS is comparable in the IBRL dataset , with more change points detected using FFIDCAD . In the S1 dataset ARX/RLS could not find the change points between the modes , while FFIDCAD detects three change points . In S2 , FFIDCAD detects all the mode changes while ARX/RLS detects only one . Note that FFIDCAD can also be used to detect single point anomalies , as discussed in the previous part of this section .
F . Discussion
In terms of computational complexity , DCAD , IDCAD and FFIDCAD require one pass over the data , so they all grow linearly with n and they all have an asymptotic
474
S1
0
5
10
15
20
25
30
S2
0
10
20
30
40
50
60
IBRL
30
25
20
15
10
5
0
−5 −5
50
40
30
20
10
0
−10
−10 45
)
%
( y t i d m u H i
40
35
30
25
S1
0
5
10
15
20
25
30
S2
0
10
20
30
40
50
60
IBRL
30
25
20
15
10
5
0
−5 −5 50
40
30
20
10
0
−10
−10
45
40
)
%
( y t i d m u H i
35
30
25
20
20
30
40 50 Temperature ( C° )
60
70
20
20
30
40 50 Temperature ( C° )
60
70
Figure 9 . Comparison of ARX/RLS(left ) with FFIDCAD with Effective N approach(right ) for data streaming analysis and change point detection ( red ’+’ ) . computational complexity of O(nd2 ) . The computational complexity of the ARX/RLS model discussed earlier also grows linearly with n but has a slightly higher asymptotic p ) . The iterative approaches ( IDCAD , complexity of O(nd2n2 FFIDCAD and ARX/RLS ) process data in an online manner and have a constant memory complexity , while the memory requirement of the DCAD approach grows linearly with n . The accuracy and efficiency of FFIDCAD with Effective N makes it suitable for online streaming data analysis , especially in WSNs .
VIII . CONCLUSION
In this paper , we have proposed an iterative model that closely approximates its batch counterpart and its iterative nature makes it more suitable for streaming data analysis . Further , we introduce a forgetting factor into the iterative model to make it suitable for non stationary environments and our evaluation has shown that this method can closely follow changes in the environment and achieve much better accuracy in non stationary environments than the batch method . We have also shown that in anomaly detection in data streams , our proposed FFIDCAD with forgetting factor can better detect changes in the environment with less computational complexity than a state of the art approach . Our future work includes consideration of a better way of handling anomalies as discussed briefly in Section V . Another worthwhile endeavor is the study of tracking multiple elliptical boundaries .
ACKNOWLEDGMENT
NICTA is funded by the Australian Government as represented by the Department of Broadband , Communications and the Digital Economy and the Australian Research Council through the ICT Centre of Excellence program .
475
REFERENCES
[ 1 ] A . Willig , “ Recent and emerging topics in wireless industrial communications : A selection , ” IEEE Transactions on Industrial Informatics , vol . 4 , pp . 102 – 124 , 2008 .
[ 2 ] V . Bhuse and A . Gupta , “ Anomaly intrusion detection in wireless sensor networks , ” Journal of High Speed Networks , vol . 15 , pp . 33–51 , 2006 .
[ 3 ] M . Moshtaghi , S . Rajasegarar , C . Leckie , and S . Karunasekera , “ Anomaly detection by clustering ellipsoids in wireless sensor networks , ” in Fifth International Conference on Intelligent Sensors , Sensor Networks and Information Processing ( ISSNIP 09 ) , December 2009 .
[ 4 ] I . Onat and A . Miri , “ An intrusion detection system for wireless sensor networks , ” in Proc . IEEE International Conference on Wireless and Mobile Computing , Networking And Communications , August 2005 , pp . 253–259 .
[ 5 ] S . Rajasegarar , J . C . Bezdek , C . Leckie , and M . Palaniswami , “ Elliptical anomalies in wireless sensor networks , ” ACM Transactions on Sensor Networks ( ACM TOSN ) , vol . 6 , no . 1 , 2009 .
[ 6 ] S . Rajasegarar , C . Leckie , M . Palaniswami , and J . Bezdek , “ Quarter sphere based distributed anomaly detection in wireless sensor networks , ” in Proc . IEEE International Conference on Communication Systems , June 2007 , pp . 3864–3869 .
[ 7 ] S . Rajasegarar , A . Shilton , C . Leckie , R . Kotagiri , and M . Palaniswami , “ Distributed training of multiclass conicsegmentation support vector machines on communication constrained networks , ” in Sixth International Conference on Intelligent Sensors , Sensor Networks and Information Processing ( ISSNIP ) , December 2010 , pp . 211 –216 .
[ 8 ] B . Sheng , Q . Li , W . Mao , and W . Jin , “ Outlier detection in sensor networks , ” in MobiHoc ’07 : Proceedings of the 8th ACM International Symposium on Mobile Ad Hoc Networking and Computing , 2007 , pp . 219–228 .
[ 9 ] V . Hodge and J . Austin , “ A survey of outlier detection methodologies , ” Artif . Intell . Rev . , vol . 22 , no . 2 , pp . 85–126 , 2004 .
[ 10 ] S . Rajasegarar , C . Leckie , and M . Palaniswami , “ Anomaly detection in wireless sensor networks , ” IEEE Wireless Communications , vol . 15 , no . 4 , pp . 34–40 , 2008 .
[ 11 ] V . Chandola , A . Banerjee , and V . Kumar , “ Anomaly detection : A survey , ” ACM Comput . Surv . , vol . 41 , pp . 15:1–15:58 , July 2009 .
[ 12 ] D . Djenouri , L . Khelladi , and A . Badache , “ A survey of security issues in mobile ad hoc and sensor networks , ” IEEE Comm . Surveys & Tutorials , vol . 7 , no . 4 , pp . 2– 28 , 2005 .
[ 13 ] S . Subramaniam , T . Palpanas , D . Papadopoulos , V . Kalogeraki , and D . Gunopulos , “ Online outlier detection in sensor data using nonparametric models , ” in 32nd International Conference on Very Large Data Bases , September 2006 , pp . 187–198 .
[ 14 ] E . W . Dereszynski and T . G . Dietterich , “ Spatiotemporal models for data anomaly detection in dynamic environmental monitoring campaigns , ” ACM Transactions on Sensor Networks , In Press .
[ 15 ] S . Rajasegarar , C . Leckie , and M . Palaniswami , “ Detecting data anomalies in wireless sensor networks , ” in Security in Ad hoc and Sensor Networks , July 2009 , pp . 231–260 .
[ 16 ] C . Chong and S . Kumar , “ Sensor networks : Evolution , opportunities , and challenges , ” in Proceedings of IEEE , vol . 91 , August 2003 , pp . 1247–1256 .
[ 17 ] S . Rajasegarar , C . Leckie , J . Bezdek , and M . Palaniswami , “ Centered hyperspherical and hyperellipsoidal one class support vector machines for anomaly detection in sensor networks , ” IEEE Transactions on Information Forensics and Security , vol . 5 , no . 3 , pp . 518 –533 , September 2010 .
[ 18 ] S . Siripanadorn , W . Hattagam , and N . Teaumroong , “ Anomaly detection using self organizing map and wavelets in wireless sensor networks , ” in Proceedings of the 10th WSEAS International Conference on Applied Computer Science , ser . ACS’10 , 2010 , pp . 291–297 .
[ 19 ] Y . Zhang , N . Meratnia , and P . Havinga , “ Adaptive and online one class support vector machine based outlier detection techniques for wireless sensor networks , ” International Conference on Advanced Information Networking and Applications Workshops , vol . 0 , pp . 990–995 , 2009 .
[ 20 ] H M Lee and C H Mao , “ Finding abnormal events in home sensor network environment using correlation graph , ” in Proceedings of the 2009 IEEE International Conference on Systems , Man and Cybernetics . IEEE Press , 2009 , pp . 1852–1856 .
[ 21 ] G . J . Ross , D . K . Tasoulis , and N . M . Adams , “ Online annotation and prediction for regime switching data streams , ” in Proceedings of the 2009 ACM Symposium on Applied Computing . ACM , 2009 , pp . 1501–1505 .
[ 22 ] D . M . Tax and R . P . Duin , “ Data description in subspaces , ” International Conference on Pattern Recognition , vol . 2 , p . 2672 , 2000 .
[ 23 ] R . O . Duda , P . E . Hart , and D . G . Stork , Pattern Classification ( 2nd Edition ) , 2nd ed . Wiley Interscience , November 2000 .
[ 24 ] L . Ljung , System Identification : Theory for the User . Prentice
Hall PTR , 1999 .
[ 25 ] “ IBRL Web , ” 2006 . [ Online ] . Available : http://dblcsmitedu/ labdata/labdata.html
[ 26 ] “ SensorScope
Web , ”
Available : http://sensorscopeepflch/indexphp/Grand St Bernard\ Deployment
[ Online ] .
2007 .
[ 27 ] M . Moshtaghi , T . C . Havens , J . C . Bezdek , L . Park , C . Leckie , S . Rajasegarar , J . M . Keller , and M . Palaniswami , “ Clustering ellipses for anomaly detection , ” Pattern Recognition , vol . 44 , pp . 55–69 , January 2011 .
476
