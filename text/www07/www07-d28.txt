A Content Driven Reputation System for the Wikipedia
B . Thomas Adler
Computer Science Dept . University of California
Luca de Alfaro
Computer Engineering Dept .
University of California
1156 High St . , Santa Cruz , CA 95064 , USA
1156 High St . , Santa Cruz , CA 95064 , USA
November 21 , 2006
Technical Report ucsc crl 06 18
School of Engineering
University of California , Santa Cruz
Abstract
On line forums for the collaborative creation of bodies of information are a phenomenon of rising importance ; the Wikipedia is one of the best known examples . The open nature of such forums could benefit from a notion of reputation for its authors . Author reputation could be used to flag new contributions from low reputation authors , and it could be used to allow only authors with good reputation to contribute to controversial or critical pages . A reputation system for the Wikipedia would also provide an incentive to give high quality contributions . We present in this paper a novel type of contentdriven reputation system for Wikipedia authors . In our system , authors gain reputation when the edits and text additions they perform to Wikipedia articles are longlived , and they lose reputation when their changes are undone in short order . We have implemented the proposed system , and we have used it to analyze the entire Italian and French Wikipedias , consisting of a total of 691,551 pages and 5,587,523 revisions . Our results show that our notion of reputation has good predictive value : changes performed by low reputation authors have a significantly larger than average probability of having poor quality , and of being undone .
1
Introduction
The collaborative , web based creation of bodies of knowledge and information is a phenomenon of rising importance . Arguably the most successful example of collaborative content creation , as well as one of the oldest , is the Wikipedia.1 The Wikipedia is a set of en
1wwwwikipediacom cyclopedias , each in a different language , that cover a very wide swath of knowledge , from history to geography , from math to politics , from pop culture to archeology . Anyone can contribute to the Wikipedia : when an article is displayed , the reader can click on an \edit" button , and is thus able to modify the content of the article . Subsequent users can improve on the contribution , or revert the article to its previous form . An important feature of the Wikipedia is that for each article , all revisions are kept . This makes it easier to undo edits than to perform them : in particular , it makes it easy for good users to undo the improper edits performed by rogue users . Since good users outnumber rogue ones , a fundamental insight behind wiki development was that good content would predominate [ CL01 ] .
In spite of the self policing character of the Wikipedia , its notoriety has attracted many rogue contributors , who have defaced or inserted false or inappropriate material . While this material is quickly removed , it was felt that this was enough of a problem that many articles dealing with high visibility or controversial topics have been \protected" : only authors who have contributed to the Wikipedia for some time may edit them.2 The length of time for which a user has contributed to the Wikipedia is , of course , a basic form of reputation . Another criticism leveraged at the Wikipedia is that , since contributions are not signed with the real names of the authors , a user lacks an easy way of assessing the reliability of the text in an article ; this problem received much attention in the press ( see eg [ Str06 , HR06] ) . While the average quality of Wikipedia articles is high [ Gil05 ] , it may be useful to know which text was inserted by experienced authors ,
2http://enwikipediaorg/wiki/Wikipedia:Semi protection policy
1 and lasted through many edits , and which text has been just inserted by authors who have a poor track record : in other words , it may be useful to know the reputation of the users who contributed , and vetted , the text . In this paper , we present a reputation system for Wikipedia authors that may help fulfill this need . Although we do not advocate , in this paper , a particular application of author reputation over another , we mention below some of the most obvious possibilities : ffl Reputation based text coloring . Each article could display a button labeled \check text reputation" : upon clicking the button , a user would be led to a copy of the page , where the text background color reflects the reputation of the author of each portion of text , as well as the reputation of authors who vetted the text , editing the page while leaving the text in place [ Cro06 ] . The appeal of this method is that reputation is displayed in an anonymous way , associated to the article text . This avoids placing blame or praise directly on the authors : the impersonal character of this feedback could be well suited to a collaborative forum such as the Wikipedia . ffl Restricting edits . Highly controversial articles could be protected , so that only authors with sufficiently high reputation are able to edit them . ffl Alerting editors about low reputation edits . Wikipedia Editors keep a watchful eye on most controversial articles , and in fact , on a large portion of the Wikipedia , improving content and undoing poor quality revisions . A reputation system could be used to alert them whenever a crucial or controversial article is modified by a low reputation author . ffl Provide an incentive for high quality contributions . A reputation system could provide an additional incentive for authors to provide highquality contributions to the Wikipedia .
1.1 A Content Driven Reputation Sys tem
Most reputation systems are user driven : they are based on users rating each other ’s contributions or behavior [ RZFK00 , Del03 ] . A famous example is the rating system of Ebay , where buyers and sellers rate each other after performing transactions . In contrast , the reputation system we propose requires no user input : rather , Wikipedia authors are evaluated on the basis of how their contribution to the Wikipedia fares . More precisely , suppose that an author A contributes to a Wikipedia article by editing it . When another author
B subsequently revises the same article , she may choose to preserve some of the edits performed by A . By preserving them , B provides her vote of confidence in these edits , and in author A . Our reputation system will increase the reputation of A in a manner that depends on the amount of preserved edits , as well as on the reputation of B .
We call such a reputation system , based on content evolution , rather than on user input , a content driven reputation system . A content driven reputation system ensures that an author ’s reputation depends only on how the author ’s contributions fare in the Wikipedia : as such , it has an intrinsic objectivity advantage over user driven reputation systems . In order to badmouth ( damage the reputation of ) author B , an author A cannot simply give a negative rating to a contribution by B . Rather , to discredit B , A needs to undo some contribution of B , thus running the risk that if subsequent authors restore B ’s contribution , it will be A ’s reputation , rather than B ’s , to suffer . Likewise , authors cannot simply praise each other ’s contributions to enhance their reputations : their contributions must actually withstand the test of time .
Admittedly , a content driven reputation system can be less accurate than a user driven one . Author contributions can be deleted for a variety of reasons , including reorganizations and thorough rewrites of the articles . Our reputation system copes with this in two ways . First , the way we assign reputation is able to distinguish between edits that are later reverted , and edits that are later further refined . The reputations of authors of reverted edits suffer ; the reputations of authors of further refined edits do not . Hence , spammers , whose contributions are reverted , suffer , while contributors to initial versions of articles , which will be extensively rewritten , do not , even though both kinds of contributions do not survive in the long term . Second , contributions that are appropriate , but that can be improved , tend to last longer than inappropriate contributions , thus receiving at least partial credit .
While it could be arguably interesting to explore combinations of user generated and content driven reputation , in this paper we focus on content driven reputation alone . The computational nature of content driven reputation enables us to evaluate its effectiveness directly on the Wikipedia : building a separate ( and , inevitably , small scale and low traffic ) test wiki to experiment with the ideas is not necessary . We will present extensive data on the accuracy and performance of our contentdriven reputation system , by applying it to the revision history of the Italian and French Wikipedias . The data will show that the value of content driven reputation can be used to predict the quality of author ’s contributions .
2
1.2 Prescriptive , Descriptive , and Pre dictive Reputation unless there is some statistical reason to believe that the edits will need to be undone ?
Reputation is most commonly used for its prescriptive and descriptive value :
1.3 Summary of the Results ffl Prescriptive value . Reputation systems specify the way in which users can gain reputation , and thus define , and prescribe , what constitutes \good behavior" on the users’ part . Users are strongly encouraged to follow the prescribed behavior , lest their reputation | and their ability to use the system | suffers . ffl Descriptive value . Reputation systems can be used to classify users , and their contributions , on the basis of their reputation , making it easier to spot high quality users or contributions , and flagging contributions or users with low reputation .
Ebay ’s reputation system is an example of a system that has both prescriptive , and descriptive , value . Users are strongly encouraged to accumulate positive feedback : it has been documented that positive feedback increases the probability of closing a transaction , and in the case of sellers , is connected to higher selling price for goods [ LRBPR99 ] . The original PageRank algorithm [ PBMW98 ] constitutes a reputation system for web pages with descriptive intent .
Our reputation system for the Wikipedia has prescriptive and descriptive value . Reputation is built by contributing lasting content ; by flagging author reputation , we encourage such contributions . The reputation we compute also has descriptive value : Wikipedia visitors can use the author ’s reputation as a guide to the trustworthiness of freshly contributed text .
In addition to prescriptive and descriptive values , we argue that a reputation system that is truly useful for the Wikipedia must also have predictive value : an author ’s reputation should be statistically related to the quality of the author ’s future contributions . To a Wikipedia visitor , it is not generally very useful to know the reputation of an author who made a long past contribution to an article . If the contribution survived for a long time , its quality is essentially proven : all subsequent editors to the same page have already implicitly voted on the contribution by leaving it in place . Reputation in the Wikipedia is most useful as a guide to the value of fresh contributions , which have not yet been vetted by other authors . Reputation is most useful if it can predict how well these fresh contributions will fare ; whether they are likely to be long lasting , or whether they are likely to be reverted in short order . Furthermore , when reputation is used to grant or deny the ability to edit a page , it is its predictive value that matters : after all , why deny the ability to edit a page ,
In order to measure the predictive value of the proposed reputation , we implemented our reputation system , and we used it to analyze all edits done to the Italian Wikipedia from its inception to October 31 , 2005 ( 154,621 pages , 714,280 versions ) , and all edits done to the French Wikipedia from its inception , to July 30 , 2006 ( 536,930 pages , 4,837,243 versions).3 We then measured the statistical correlation between the author ’s reputation at the time an edit was done , and the subsequent lifespan of the edit . This is a valid statistical test , in the sense that the two variables of the study are computed in independent ways : the reputation of an author at the time of the edit is computed from the behavior of the author before the edit , while the lifespan of the edit is determined by events after the edit . To summarize the results , we introduce the following informal terminology ; we will make the terms fully precise in the following sections : ffl Short lived edit is an edit whose effect is undone in the next couple of revisions ; ffl Short lived text is text that is almost immediately removed ( each successive revision removes , on average , 4/5 of such text ) . ffl Low reputation author is an author whose reputation falls in the bottom 20 % of the reputation scale .
When measuring the quantity of text , or edits , our unit of measurement is a word ( white space delimited string ) : this provides a uniform unit of measurement , and ensures that splitting changes in two or more revisions does not affect the results . This also explains why the percentages of text and edits done by low reputation authors are slightly different . Our results for the French Wikipedia indicate that the fact that an author ’s reputation is low at the time a contribution is made is statistically correlated with the contribution being undone : ffl 7.7 % of the edits are performed by low reputation authors ; these 7.7 % edits account for 32 % of the short lived edits . Edits by low reputation authors are 4.2 times more likely than average to be shortlived . ffl 8.4 % of the contributed text comes from lowreputation authors ; this 8.4 % text accounts for 38 %
3These numbers reflect the fact that we consider only the last among consecutive versions by the same author , as explained later .
3 of the short lived text . Text contributed by lowreputation users is 4.5 times more likely than average to be short lived .
Using search terminology , the recall provided by low reputation is 32 % for short lived edits and 38 % for short lived text . The precision is as follows : ffl 24 % of the edits done by low reputation authors are short lived . or even worse , to perform a multitude of gratuitous edits . Indeed , if edit count were used as reputation , it would most likely induce undesirable behaviors by the Wikipedia users . We will show that the predictive value of such a reputation is also inferior to the one we compute , although the difference is not large , and we will discuss why we believe this is the case . ffl 5.8 % of the text inserted by low reputation authors is short lived .
1.4 Related Work
The difference in these two precision figures indicates that most edits performed by low reputation authors that are short lived do not correspond to much insertion of new text ( they may involve text removal or displacement , instead ) . While we use search terminology to report these results , we stress that these results are about the reputation ’s ability to predict the longevity of future contributions by an author .
The above results may underestimate the recall of our content driven reputation . We asked a group of volunteers to decide , of the short lived contributions to the Italian Wikipedia , which ones were of poor quality . The results indicated that short lived contributions by lowreputation authors were markedly more likely to be of poor quality , compared to similarly short lived contributions by high reputation authors . This allowed us to calculate that the recall for bad quality , short lived edits is 49 % , and the recall for bad quality short lived text is 79 % .
We are unsure of the extent with which prediction precision can be increased . Many authors with low reputation are good , but novice , contributors , who have not had time yet to accumulate reputation . Indeed , an unfortunate effect of the ease with which users can register anew to the Wikipedia is that we cannot trust novices any more than confirmed bad contributors | if we trusted novices more , bad contributors would simply re register . Furthermore , even authors who contribute short lived text and edits , and who therefore have low reputation , do not do so consistently , interjecting good contributions among the bad ones .
A basic form of reputation , currently used to screen contributors to controversial pages , is the length of time for which users have been registered to the Wikipedia . We did not have access to this temporal information in our study.4 As a proxy , we considered the number of edits performed by a user . This is a form of reputation that has no prescriptive value : all it does is encouraging users to split their contributions in multiple , small ones ,
4Wikipedia makes only a limited amount of user information available for download .
The work most closely related to ours is [ ZAD+06 ] , where the revision history of a Wikipedia article is used to compute a trust value for the article ; dynamic Bayesian networks are used to model the evolution of trust level over the versions . At each revision , the inputs to the network are a priori models of trust of authors ( determined by their Wikipedia ranks ) , and the amount of added and deleted text . The paper shows that this approach can be used to predict the quality of an article ; for instance , it can be used to predict when an article in a test set can be used as a featured article . Differently from the current work , author trustworthiness is taken as input ; we compute author reputation as output . Furthermore , the work tracks the amount of added and deleted text at each revision , but does not track whose text it is , nor does it track text across revisions . Thus , it cannot be used to infer the trustworthiness of authors . A simpler approach to text trust , based solely on text age , is described in [ Cro06 ] . In many ways , estimating text trust , and author reputation , are complementary approaches . Text trust works best for text that has been part of an article for some time ; author reputation is most useful as an indicator of quality for fresh text .
Reputation systems in e commerce and social networks have been extensively studied ( see , eg , [ Kle99 , RZFK00 , Del03 , KSGM03] ) ; the reputation in those systems is generally user driven , rather than contentdriven as in our case . Related is also work on trust in social networks ( see , eg , [ GKRT04 , Gol05] ) .
The history flow of text contributed by Wikipedia authors has been studied with flow visualization methods in [ VWD04 ] ; the results have been used to analyze a number of interesting patterns in the content evolution of Wikipedia articles . Work on mining software revision logs ( see , eg , [ LZ05 ] ) is similar in its emphasis of indepth analysis of revision logs ; the aim , however , is to find revision patterns and indicators that point to software defects , rather than to develop a notion of author reputation .
4
2 Content Driven Reputation
Reputation systems can be classified into two broad categories : chronological , where the reputation is computed from the chronological sequence of ratings a user receives , and fixpoint , where the reputation is computed via a fixpoint calculation performed over the graph of feedbacks . The Ebay reputation system is an example of a chronological system , while the PageRank and HITS algorithms are examples of fixpoint algorithms [ PBMW98 , Kle99 ] . We chose to follow the chronological approach to develop our content driven reputation for the Wikipedia . The chief advantage of a chronological approach is that it is computationally lightweight . When an author revises a Wikipedia article , we can efficiently compute the feedback to authors of previous revisions to the same article , and we can modify their reputation in real time , with little impact on server response time .
2.1 Notation
The following notation will be used throughout the paper . We assume that we have n > 0 versions v0 ; v1 ; v2 ; : : : ; vn of a document ; version v0 is empty , and version vi , for 1 i n , is obtained by author ai performing a revision ri : vi,1 vi . We refer to the change set corresponding to ri : vi,1 vi as the edit performed at ri : the edit consists of the text insertions , deletions , displacements , and replacements that led from vi,1 to vi . When editing a versioned documents , authors commonly save several versions in a short time frame , in order to avoid losing their work in case of computer or network problems . To ensure that such behavior does not affect reputations , we filter the versions , keeping only the last of consecutive versions by the same author ; we assume thus that for 1 i < n we have ai 6= ai+1 . Every version vi , for 0 i n , consists of a sequence [ wi mi ] of words , where mi is the number of words of vi ; we have m0 = 0 . For us , a word is a whitespace delimited sequence of characters in the Wiki markup language that produces a Wikipedia article : we work at the level of such markup language , rather than at the level of the HTML produced by the wiki engine . Given a series of versions v0 ; v1 ; : : : ; vn of a text document , we assume that we can compute the following quantities :
1 ; : : : ; wi ffl txt(i ; j ) , for 0 < i j n , is the amount of text ( measured in number of words ) that is introduced by ri in vi , and that is still present ( and due to the same author ai ) in vj . In particular , txt(i ; i ) is the amount of new text added by ri . ffl d(vi ; vj ) , for 0 < i < j n , is the edit distance between vi and vj , and measures how much change ( word additions , deletions , replacements , displacements , etc . ) there has been in going from vi to vj .
We will describe in the next section how these quantities can be computed from the series of versions v0 ; : : : ; vn .
2.2 Content Driven Reputation in a
Versioned Document
We propose the following method for computing content driven reputation in a versioned document . Consider a revision ri : vi,1 vi , performed by user ai , for some 0 < i n . Each of the subsequent authors ai+1 ; ai+2 ; : : : can either retain , or remove , the edits performed by ai at ri ; in particular , they can either keep , or discard , the text introduced by ri . We then examine later versions vj of the document , for i < j n , and we increase ( or decrease ) the reputation of ai according to how much of the new text , and edits , introduced in ri have survived until vj . In the evaluation , we also take into account the reputation of author aj of vj , who acts as the judge . This will ensure that high reputation authors do not risk much of their reputation while fighting revision wars against very low reputation authors , such as anonymous authors . If this were not the case , highreputation authors would be wary of undoing damage done by such low reputation authors , including spammers , for fear of reprisal .
We use two criteria to award reputation : the survival of text , and the survival of edits . Text survival is perhaps the most obvious criterion . Adding new text to a Wikipedia article is a fundamental way of contributing | it is how new knowledge is added | and it seems reasonable to take into account the amount of text added , and its longevity , when computing author reputation . However , text survival alone fails to capture many ways in which authors contribute to the Wikipedia . If a user rearranges the content of an article without introducing new text , the contribution cannot be captured by text survival . The act of restoring an article to a previous , good version after an act of vandalism does not result in the addition of new text ; thus , if we based reputation on text survival alone , authors who undo damage and restore articles would not gain any reputation from their actions . This , in spite of the fact that such repairs are fundamental to the quality of an open wiki . Edit survival captures how long the re arrangements performed by an author last in the history of a Wikipedia article , and captures all of the above ways of contributing .
We use a parameter ctext 2 [ 0 ; 1 ] to determine how much weight should be given to text versus edit survival . We have determined the parameter ctext , along
5 with other parameters used in the calculation , via an optimization process aimed at producing reputation functions of high predictive value ; the optimization process is described later in Section 4 .
2.3 Accounting for Text Survival
If text introduced by ri is still present in vj , for 0 < i < j n , this indicates that author aj , who performed the revision rj : vj,1 vj , agrees that the text is valuable . To reflect this , we increase the reputation of ai , in a manner that is proportional to the amount of residual text , and to the reputation of author ai . Precisely , the rule we have chosen is as follows .
Rule 1 ( update due to text survival ) When the revision rj occurs , for all 0 < i < j such that j , i 10 and aj 6= ai , we add to the reputation of ai the amount : cscale ctext txt(i ; j ) txt(i ; i )
( txt(i ; i))clen log(1 + R(aj ; rj) ) ; where cscale > 0 , ctext 2 [ 0 ; 1 ] , and clen 2 [ 0 ; 1 ] are parameters , and where R(aj ; rj ) is the reputation of aj at the time rj is performed .
The rule can be understood as follows . txt(i ; j)=txt(i ; i ) is the fraction of text introduced at version vi that is still present in version vj ; this is a measure of the \quality" of ri . The quantity log(1 + R(aj ; rj ) ) is the \weight" of the reputation of aj , that is , how much the reputation of aj lends credibility to the judgements of aj . We chose to adopt a logarithmic notion of weight , because in our reputation systems , the reputations of most regular contributors , who rarely perform low quality edits , quickly soar to very high values compared to the reputations of beginners ( this will be evident from the experimental results we present later ) . Using a logarithmic weight for reputations limits the power of established authors , preventing them from entirely overriding feedback coming from newer members . The parameters cscale , ctext and clen will be determined experimentally via an optimization process , as described later . Their meaning is as follows : ffl The parameter clen 2 [ 0 ; 1 ] is an exponent that specifies how to take into account the length of the original contribution : if clen = 1 , then the increment is proportional to the length of the original contribution ; if clen = 0 , then the increment does not depend on the length of the original contribution . ffl The parameter cscale specifies how much the reputation should vary in response to an individual feedback . vi d(vi ; vj ) d(vi,1 ; vi ) vj vi,1 d(vi,1 ; vj )
Figure 1 : Distances involved in the computation of ELong(i ; j ) . ffl The parameter ctext specifies how much the feedback should depends on residual text ( Rule 1 ) or residual edit ( Rule 2 , presented later ) .
In the rule , only the 10 most recent versions of an article are considered . This ensures that contributors to articles that have a natural , slow rate of change get roughly the same feedback of contributors to articles that reach a steady , or even frozen , state . We considered basing the limit on time , rather than number of versions , but each Wikipedia article has its own rate of change , dictated in part by the popularity of the article , so we believe that the number of versions is a more uniform criterion .
2.4 Accounting for Edit Survival
To judge the revision ri : vi,1 vi from the vantage point of vj , for 0 < i < j n , we reason as follows . We wish to rate ri higher , if ri made the article more similar to vj . In particular , the revision ri changed the article by an amount d(vi,1 ; vi ) ; we wish to credit ai in proportion to how much of this change is directed towards vj . This suggests using the formula :
ELong(i ; j ) = d(vi,1 ; vj ) , d(vi ; vj ) d(vi,1 ; vi )
:
( 1 )
Figure 1 depicts the distances involved in the computation of ELong(i ; j ) . If d satisfies the triangular inequality ( as our edit distance does , to a high degree of accuracy ) , then ELong(i ; j ) 2 [ ,1 ; 1 ] . For two consecutive edits ri , ri+1 , if ri is completely undone in ri+1 ( as is common when ri consists in the introduction of spam or inappropriate material ) , then ELong(i ; i + 1 ) = ,1 ; if ri+1 entirely preserves ri , then ELong(i ; i + 1 ) = +1 . For more distant edits , ELong(i ; j ) is a measure of how much of the edit performed during ri is undone ( value ,1 ) or preserved ( value +1 ) before rj . The rule we use for updating the reputation is as follows .
Rule 2 ( update due to edit survival ) When the revision rj occurs , for all 0 < i < j such that j , i 3 , we add to the reputation of ai an amount q determined as follows . If aj = ai or d(vi,1 ; vi ) = 0 , then q = 0 ; otherwise , q is determined by the following algorithm .
6 q := cslack d(vi,1 ; vj ) , d(vi ; vj ) d(vi,1 ; vi ) if q < 0 then q := q cpunish endif q := q cscale ( 1 , ctext ) ,d(vi,1 ; vi) clen
log,1 + R(aj ; rj )
In the algorithm , cpunish 1 , cslack 1 , cscale > 0 , ctext 2 [ 0 ; 1 ] , and clen 2 [ 0 ; 1 ] are parameters , and R(aj ; rj ) is the reputation of aj at the time rj is performed .
The rule adopts a modified version of ( 1 ) : the parameter cslack > 1 is used to allow revision ri : vi,1 vi to be slightly counterproductive , without causing punishment for ai . On the other hand , when punishment is incurred , the parameter cpunish is used to amplify its magnitude , compared to the amount of positive reputation gained from good edits . Amplifying punishment is instrumental to make the threat a credible one . Without amplification , a rogue contributor could use the reputation gained in one part of the Wikipedia to constantly destroy a small set of articles elsewhere . Amplification makes this harder to achieve . The parameters cslack and cpunish , as well as cscale , ctext and clen , will be determined via an optimization process , as mentioned before . To assign edit feedback , we have chosen consider only the 3 previous versions of an article . This approach proved adequate for analyzing an already existing wiki , in which authors could not modify their behavior using knowledge of this threshold . If the proposed contentdriven reputation were to be used on a live Wiki , it would be advisable to replace this hard threshold by a scheme in which the feedback of vj on ri is weighed by a gradually decreasing function of j , i ( such as exp(c ( i , j ) ) for some c > 0 ) .
2.5 Computation of Content Driven
Reputation
We compute the reputation for Wikipedia authors as follows . We examine all revisions in chronological order | thus simulating the same order in which they were submitted to the Wikipedia servers . We initialize the reputations of all authors to the value 0.1 ; the reputation of anonymous authors is fixed to 01 As the revisions are processed , we use Rules 1 and 2 to update the reputations of authors in the system . When updating reputations , we ensure that they never become negative , and that they never grow beyond a bound cmaxrep > 0 . The bound cmaxrep is used to prevent frequent contributors from accumulating unbounded amounts of reputation , and becoming essentially immune to negative feedback . The value of cmaxrep will be once again determined via optimization techniques .
Wikipedia allows users to register , and create a author identity , whenever they wish . As a consequence , we need to make the initial reputation of new authors very low , close to the minimum possible ( in our case , 0 ) . If we made the initial reputation of new authors any higher , then rogue authors , after committing revisions that damage their reputation , would simply re register as new users to gain the higher value . An unfortunate side effect of allowing people to obtain new identities at will is that we cannot presume that people are innocent until proven otherwise : we have to assign to newcomers the same reputation as proven offenders . This is a contributing factor to our reputation having low precision : many authors who have low reputation still perform very good quality revisions , as they are simply new authors , rather than proven offenders . We conjecture that content driven reputation systems for the Wikipedia would have better predictive value if creating a new author identity was not free , either monetarily , or in some other sense .
3 Text Longevity and Edit Distance in Versioned Documents
In this section , we describe in more detail how we tracked text authorship , and how we computed edit distances , in versioned documents . We developed our algorithms starting from standard text difference algorithms , and in particular , those of [ Tic84 , Mye86 , BL97 ] . However , we adapted the algorithms in several places , to enable them to better cope with the versioned nature of the Wikipedia , and with the kind of edits that authors perform .
3.1 Tracking Text Authorship
Given a sequence of versions v0 ; v1 ; : : : ; vn , we describe an algorithm for computing txt(i ; j ) for 0 < i j n . Superficially , it might seem that to compute txt(i ; j ) , we need to consider only three versions of the document : vi,1 , vi , and vj . From vi,1 and vi we can derive the text that is added at revision ri : vi,1 vi , and we can then check how much of it survives until vj . This approach , however , is not appropriate for a versioned document like a wiki page , where authors are allowed to inspect| and restore | text from any previous version of a document . For example , consider the case in which revision ri,1 : vi,2 vi,1 is the work of a spammer , who erases entirely the text of vi,2 , and replaces it with spurious material ; such spam insertions are a common occurrence in open wikis . When author ai views the
7 page , she realizes that it has been damaged , and she reverts it to the previous version , so that vi = vi,2 . If we derived the text added by ri by considering vi,1 and vi only , it would appear to us that ai is the original author of all the text in vi , but this is clearly not the case : she simply restored pre existing text . To compute the text added at a revision ri : vi,1 vi , we keep track of both the text that is in vi,1 , and of the text that used to be present in previous versions , and that has subsequently been deleted .
0 ; ci
Our algorithm proceeds as follows . We call a chunk a list c = [ (w1 ; q1 ) ; : : : ; ( wk ; qk) ] , where for 1 j k , wj is a word , and qj 2 f1 ; : : : ; ng is a version number . A chunk represents a list of contiguous words , each labeled with the version where it originates . The algorithm computes , for each version vi , 1 i n , its chunk list Ci = [ ci 0 is the live chunk , and it consists of the text of vi , with each word labeled with the version where the word 1 ; : : : ; wi was introduced ; thus , if vi = [ wi mi ] , we have ci 0 = [ (w1 ; q1 ) ; : : : ; ( wmi ; qmi) ] , for some q1 ; : : : ; qmi . The chunks ci k are dead chunks , and they represent contiguous portions of text that used to be present in some version of the document prior to i . Given the chunk list Ci = [ ci 0 ; ci k ] for document vi , we can compute txt(j ; i ) via k ] . The chunk ci
1 ; : : : ; ci
1 ; : : : ; ci
1 ; : : : ; ci txt(j ; i ) = fifi((u ; j ) fifi 9u:(u ; j ) 2 ci
0)fifi ; for 1 i j n .
( 2 )
0
1 ; : : : ; ci
1 ; 1 ) ; ( w1 for all versions
To compute Ci
For 2 ; 1 ) ; : : : ; ( w1 i of a document , we propose an algorithm that proceeds as the initial version , we let C1 = follows . [ [(w1 m1 ; 1)] ] . For 1 i < n , the al0 ; ci gorithm computes Ci+1 from Ci = [ ci k ] and vi+1 . To compute the live chunk ci+1 , we match contiguous portions of text in vi+1 with contiguous text in any of the chunks in Ci ; the matching words in vi+1 are labeled with the version index that labels them in Ci , and represent words that were introduced prior to version vi+1 . Any words of vi+1 that cannot be thus matched are considered new in vi+1 , and are labeled with version index i+1 . The dead chunks ci+1 ; : : : ; ci+1 of Ci+1 are then obtained as the portions of the chunks in Ci that were not matched by any text in vi+1 . We allow the same text in Ci to be matched multiple timed in vi+1 : if a contributor copies multiple times text present in vi or in prior versions in order to obtain vi+1 , the replicated text should not be counted as new in vi+1 . Considering replicated text as new would open the door to a duplication attack , whereby an attacker duplicates text in a revision ri , and then removes the original text in a revision rk : vk,1 vk with k > i . From version vk onwards , the text would be attributed to the attacker rather than to the original author .
1 l
Matching vi+1 with Ci is a matter of finding matches between text strings , and several algorithms have been presented in the literature to accomplish this in an efficient manner ( see , eg , [ HM75 , Hir77 , Tic84 , Mye86 , BL97] ) . We experimented extensively , and the algorithm that gave the best combination of efficiency and accuracy was a variation of a standard greedy algorithm . In standard greedy algorithms , such as [ Hir77 , Mye86 , BL97 ] , longest matches are determined first ; in our algorithm , we define a notion of match quality , and we determine first matches of highest quality . To define match quality , we let mi+1 be the length of vi+1 , and we let m0 be the length of the chunk of Ci where the match is found ( all length and indices are measured in number of words ) . Let l be the length of the match , and assume that the match begins at word k0 m0 in the chunk , and at word ki+1 mi+1 in vi+1 . We define match quality as follows : ffl If the match occurs between vi+1 and the live chunk , then the quality is : l min(mi+1 ; m0 )
, 0:3 fifififi k0 m0 , ki+1 mi+1
: fifififi ffl If the match occurs between vi+1 and a dead chunk , then the quality is 0 if l < 4 , and is l=min(mi+1 ; m0 ) , 0:4 otherwise . this corresponds to the fact that ,
Thus , the quality of a match is the higher , the longer the match is . If the match is with the live chunk , a match has higher quality if the text appears in the same relative position in vi+1 and in vi . Matches with dead chunks have somewhat lower quality than matches with the live chunk : if some text can be traced both to the previous version ( the live chunk ) , and to some text that was previously deleted , the most likely match is with the text of the previous version . Moreover , matches with dead chunks have to be at least of length 4 : this avoids misclassifying common words in new text as re introductions of previously deleted text . The coefficients in the above definition of quality have been determined experimentally , comparing human judgements of authorship to the algorithmically computed ones for many pages of the Italian Wikipedia . The text survival algorithm we developed is efficient : the main bottleneck , when computing text authorship , is not the running time of the algorithm , but rather , the time required to retrieve all versions of a page from the MySQL database in which Wikipedia pages are stored.5
5The measurement was done on a PC with AMD Athlon 64 3000+ CPU , two hard drives configured in RAID 1 ( mirroring ) , and 1 GB of memory .
8
3.2 Computing Edit Distances
For two versions v , v 0 , the edit distance d(v ; v0 ) is a measure of how many word insertions , deletions , replacements , and displacements are required to change v into v0 . Wikipedia pages contain markup , and possibly the most accurate way to measure edit distance would treat page versions as structured documents , and apply algorithms for the edit distance of structured documents [ ZS89 , CGM97 , CAM02 ] . We opted however for using a standard notion of edit distance for flat files [ Tic84 ] . In order to compute the edit distance between two versions v and v0 , we use the same greedy algorithm for text matching that we used for text survival , except that each portion of text in v ( resp . v 0 ) can be matched at most once with a portion of text in v 0 ( resp . v ) . Thus , text duplication is captured as an edit . The output of the greedy matching is modified , as is standard in measurements of edit distance , so that it outputs a list L of elements that describe how v 0 can be obtained from v : ffl I(j ; k ) : k words are inserted at position j ; ffl D(j ; k ) : k words are deleted at position j ; ffl M ( j ; h ; k ) : k words are moved from position j in v to position h in v0 .
We compute the total amount Itot of inserted text by summing , for each I(j ; k ) 2 L , the length k ; similarly , we obtain the total amount Dtot of deleted text by summing , for each D(j ; k ) 2 L , the length k . We take into account insertions and deletions via the formula Itot + Dtot , 1 2 min(Itot ; Dtot ) : thus , every word that is inserted or removed contributes 1 to the distance , and every word that is replaced contributes 1 2 . The motivation for this treatment of replacements is as follows . Suppose that author ai edits vi,1 adding a new paragraph consisting of k words , obtaining vi , and suppose that author ai+1 then rewrites completely the paragraph ( keeping it of equal length ) , obtaining vi+1 . If we accounted for insertion and deletions via Itot + Dtot , then d(vi+1 ; vi ) = 2k , while d(vi+1 ; vi,1 ) = k : the edit performed by author ai would thus be considered highly counterproductive . With our formula , we have instead d(vi+1 ; vi ) = k=2 and d(vi+1 ; vi,1 ) = k , so that the contribution of author ai is positive : experiments we performed showed that , on average , this is in better agreement with a human perception of the contribution of author ai .
We account for text moves between versions v and v0 as follows . Let l , l0 be the lengths ( in words ) of v and v0 , respectively . Each time a block of text of length k1 exchanges position with a block of text of length k2 , we count this as k1 k2= max(l ; l0 ) . Thus , a word that moves across k other words contributes k= max(l ; l 0 ) to the distance : the contribution approaches 1 as the word is moved across the whole document . The total contribution Mtot of all moves can be computed by adding k k0 , for all pairs of moves M ( j ; h ; k ) 2 L and M ( j 0 ; h0 ; k0 ) 2 L such that j < j 0 and h > h0 ( this ensures that every crossing is counted once ) . We finally define : d(r ; r0 ) = Itot + Dtot + Mtot , 1
2 min(Itot ; Dtot ) :
Due to the nature of the greedy algorithms used for text matching , and of the definitions above , our edit distance is not guaranteed to satisfy the triangular inequality . However , we found experimentally that the proposed edit distance , on Wikipedia pages , satisfies the triangular inequality within approximately one unit ( one word ) for well over 99 % of triples of versions of the same page .
4 Evaluation and Optimization
Metrics
We now develop quantitative measures of the ability of our content driven reputation to predict the quality of future revisions . For a revision ri : vi,1 vi in a sequence v0 ; v1 ; : : : ; vn of versions , let flt(ri ) = txt(i ; i ) be the new text introduced at ri , and fle(ri ) = d(vi,1 ; vi ) be the amount of editing involved in ri . We define edit and text longevity as follows : ffl The edit longevity ffe(ri ) 2 [ ,1 ; 1 ] of ri is the av erage of ELong(i ; j ) for i < j min(i + 3 ; n ) . ffl The text longevity fft(ri ) 2 [ 0 ; 1 ] of ri is the solution to the following equation : n
X j=i txt(i ; j ) = txt(i ; i ) n
X j=1
( fft(ri))j,i :
( 3 )
Thus , fft(ri ) is the coefficient of exponential decay of the text introduced by ri : on average , after k revisions , only a fraction ( fft(ri))k of the introduced text survives . As all quantities in ( 3 ) except fft(ri ) are known , we can solve for fft(ri ) using standard numerical methods . We also indicate by rep(ri ) the reputation of the author ai of ri at the time ri was performed . We note that rep(ri ) is computed from the history of the Wikipedia before ri , while ffe(ri ) and fft(ri ) depend only on events after ri . Moreover , ffe(ri ) and fft(ri ) can be computed independently of reputations .
Let R be the set of all revisions in the Wikipedia ( of all articles ) . We view revisions as a probabilistic process , with R as the set of outcomes . Since some revisions change very little , while others affect many words ,
9 we normalize revisions by the number of words they affect . This ensures that the metrics are not affected if revisions by the same author are combined or split in multiple steps . Since we keep only the last among consecutive revisions by the same user , a \revision" is a rather arbitrary unit of measurement , while a \revision amount" provides a better metric .
Thus , when studying edit longevity , we associate with each r 2 R a probability mass proportional to fle(r ) , giving rise to the probability measure Pre . Similarly , when studying text longevity , we associate with each r 2 R a probability mass proportional to flt(r ) , giving rise to the probability measure Prt .
In order to develop figures of merit for our reputation , we define the following terminology ( used already in the introduction in informal fashion ) : ffl We say that the edit performed in r is short lived if ffe(r ) ,0:8 . ffl We say that the new text added in r is short lived if fft(r ) 0:2 , indicating that at most 20 % of it , on average , survives from one version to the next . ffl We say that a revision r is low reputation if log(1+ rep(r ) ) log(1 + cmaxrep)=5 , indicating that the reputation , after logarithmic scaling , falls in the lowest 20 % of the range .
Correspondingly , we define three random variables Se ; St ; L : R 7! f0 ; 1g as follows , for all r 2 R : ffl Se(r ) = 1 if ffe(r ) ,0:8 , and Se(r ) = 0 otherwise . ffl St(r ) = 1 if ffe(r ) 0:2 , and St(r ) = 0 otherwise . ffl L(r ) = 1 if log(1 + rep(r ) ) log(1 + cmaxrep)=5 , and L(r ) = 0 otherwise .
The precision prec t and recall rec t for short lived text , and the precision prec e and recall rece for short lived edits , are defined as : prec t = Prt(St=1 j L=1 ) prec e = Pre(Se=1 j L=1 ) rec t = Prt(L=1 j St=1 ) rec e = Pre(L=1 j Se=1 ) :
These quantities can be computed as usual ; for instance ,
Pre(Se = 1 j L = 1 ) = Pr2R Se(r ) L(r ) fle(r )
Pr2R L(r ) fle(r )
( noting that it is unnecessary in these expressions to renormalize all probability masses via 1= Pr2R fle(r) ) . We also define : boost e = boost t =
Pre(Se=1 j L=1 )
Pre(Se=1 )
Prt(St=1 j L=1 )
Prt(St=1 )
=
=
Pre(Se=1 ; L=1 )
Pre(Se=1 ) Pre(L=1 )
Prt(St=1 ; L=1 )
Prt(St=1 ) Prt(L=1 )
Reputation
Judged bad
Judged good
Short lived edits :
Low [ 00{02 ] Normal [ 02{10 ]
Short lived text :
Low [ 00{02 ] Normal [ 02{10 ]
66 % 16 %
74 % 14 %
19 % 68 %
13 % 85 %
Table 2 : User ranking of short lived edits and text , as a function of author reputation . In square brackets , we give the interval where the normalized value log(1 + r)= log(1 + cmaxrep ) of a reputation r falls . The precentages do not add to 100 % , because users could also rank a change as \neutral" .
Intuitively , boost e indicates how much more likely than average it is that edits produced by low reputation authors are short lived . The quantity boost t has a similar meaning . Our last indicator of quality are the coefficients of constraint e = Ie(Se ; L)=He(L ) t = It(St ; L)=Ht(L ) ; where Ie is the mutual information of Se and L , computed with respect to Pre , and He is the entropy of L , computed with respect to Pre [ CT91 ] ; similarly for It(St ; L ) and Ht(L ) . The quantity e is the fraction of the entropy of the edit longevity which can be explained by the reputation of the author ; this is an informationtheoretic measure of correlation . The quantity t has an analogous meaning .
To assign a value to the coefficients cscale , cslack , cpunish , ctext , clen , and cmaxrep , we implemented a search procedure , whose goal was to find values for the parameters that maximized a given objective function . We applied the search procedure to the Italian Wikipedia , reserving the French Wikipedia for validation , once the coefficients were determined . We experimented with both e and prec e rece as objective functions , and they both gave very similar results .
5 Experimental Results
To evaluate our content driven reputation , we considered two Wikipedias : ffl The Italian Wikipedia , consisting of 154,621 articles and 714,280 filtered revisions ; we used a snapshot dated December 11 , 2005 . ffl The French Wikipedia , consisting of 536,930 articles and 4,837,243 filtered revisions ; we used a snapshot dated October 14 , 2006 .
10
Precision
Recall
Boost
Edit prec e 14.15 23.92
Text prec t 3.94 5.85
Edit rece 19.39 32.24
Text rect 38.69 37.80
Edit boost e 4.03 4.21
Text boost t 5.83 4.51
Italian Wikipedia French Wikipedia
Text
Coeff . of constr . Edit e 3.35 7.33 t 7.17 6.29
Table 1 : Summary of the performance of content driven reputation over the Italian and French Wikipedias . All data are expressed as percentages .
Of both wikipedias , we studied only \NS MAIN" pages , which correspond to ordinary articles ( other pages are used as comment pages , or have other specialized purposes ) . Moreover , to allow for the more accurate computation of edit longevity , we used only revisions that occurred before October 31 , 2005 for the Italian Wikipedia , and before July 31 , 2006 for the French one . Our algorithms for computing content driven reputation depend on the value of six parameters , as mentioned earlier . We determined values for these parameters by searching the parameter space to optimize the coefficient of constraint , using the Italian Wikipedia as a training set ; the values we determined are : cscale = 13:08 cslack = 2:20 cpunish = 19:09 ctext = 0:60 clen = 0:60 cmaxrep = 22026
We then analyzed the Italian and French Wikipedias using the above values . The results are summarized in Table 1 . The results are better for the larger French Wikipedia ; in particular , the reputation ’s ability to predict short lived edits is better on the French than on the Italian Wikipedias . We are not sure whether this depends on different dynamics in the two Wikipedias , or whether it is due to the greater age ( and size ) of the French Wikipedia ; we plan to study this in further work . We see that edits performed by low reputation authors are four times as likely as the average to be short lived . To investigate how many of the edits had a short life due to bad quality , we asked a group of 7 volunteers to rate revisions performed to the Italian Wikipedia . We selected the revisions to be ranked so that they contained representatives of all 4 combinations of high/low reputation author , and high/low longevity . We asked the volunteers to rate the revisions with +1 ( good ) , 0 ( neutral ) , and ,1 ( bad ) ; in total , 680 revisions were ranked . The results , summarized in Table 2 , are striking . Of the short lived edits performed by lowreputation users , fully 75 % were judged bad . On the other hand , less than 9.2 % of the short lived edits performed by high reputation users were judged bad . We analyzed in detail the relationship between user reputation , and the percentage of short lived text and edits that users considered bad . Using these results , we computed the approximate recall factors on the Italian Wikipedia of content driven reputation for bad edits , as judged by users , rather than short lived ones : ffl The recall for short lived edits that are judged to be bad is over 49 % . ffl The recall for short lived text that is judged to be bad is over 79 % .
These results clearly indicate that our content driven reputation is a very effective tool for spotting , at the moment they are introduced , bad contributions that will later be undone . There is some margin of error in this data , as our basis for evaluation is a small number of manually rated revisions , and human judgement on the same revisions often contained discrepancies . We note that we do not have data on the recall for contributions that are bad quality , but are not short lived . We focused on short lived contributions , since we assumed that any truly poor quality contribution would be undone in short order . It would be of interest to study the relationship between author reputation , and the quality of their contributions ( short lived or not ) as perceived by human subjects .
The fact that so few of the short lived edits performed by high reputation authors were judged to be of bad quality points to the fact that edits can be undone for reasons unrelated to quality . Many Wikipedia articles deal with current events ; edits to those articles are undone regularly , even though they may be of good quality . Our algorithms do not treat in any special way current events pages . Other Wikipedia edits are administrative in nature , flagging pages that need work or formatting ; when these flags are removed , we classify it as text deletion . Furthermore , our algorithms do not track text across articles , so that when text is moved from one article to another , they classify it as deleted from the source article .
From Table 1 , we note that the precision is low , by search standards . Our problem , however , is a prediction problem , not a retrieval problem , and thus it is intrinsically different . The group of authors with low reputation includes many authors who are who are good
11 i s n o s v e R i f o t n e c r e P
60
50
40
30
20
10
0
0
Population Distribution per Reputation
Italian Wp , edits Italian Wp , text French Wp , edits French Wp , text
1
2
3
4
5
6
7
8
9 log(1 + Reputation )
Figure 2 : Percentage of text and edit that originated from authors of a certain reputation , in the Italian and French Wikipedias . contributors , but who are new to the Wikipedia , so that they have not had time yet to build up their reputation . Figure 2 provides a breakdown of the amount of edits and text additions performed , according to the reputation of the author , for the French and Italian Wikipedias .
Table 3 provides a more in depth look at the relationship between author reputation and edit longevity on the French Wikipedia . The table shows that , the higher an author ’s reputation , the higher the longevity of the edits is . Specifically , as author reputation increases , the percentage of edits that have longevities below specified thresholds decreases . For instance , while 25.63 % of the edits performed by authors in the lowest reputation bin ( log(1 + rep ) < 1 ) have ffe < ,0:8 , only 3.17 % of the edits performed by authors in the highest reputation bin ( log(1 + rep ) 9 ) do . The corresponding data for the Italian Wikipedia is given in Table 4 .
Tables 5 and 6 provide another look at the data , by plotting how the edits in each longevity range were distributed according to author reputation . Each column includes longevity values from the number heading the column , to the number immediately to its right : for instance , the column labeled \0.4" corresponds to the longevity range ffe 2 [ 0:4 ; 0:6 ) . The rightmost column corresponds to the edit longevity value ffe = ,1 . From Table 5 we see that fully 47.74 % of the edits which were immediately reversed ( ffe = ,1 ) were performed by authors of reputation in the lowest bin . Many columns ( see , eg , those for ffe = ,1 or ffe = ,0:8 ) show an increase in the number of short longevity edits , as the reputation increases past the first bin . This is not due to the fact that authors of greater reputation are
12 more likely to produce short longevity edits ; indeed , Table 3 showed the opposite to be true . The proportion of short longevity edits , for bins greater than the first , increases with the reputation , because the number of such edits increases even faster ( see column \%data" ) . For instance , 2.68 % of the edits with ffe = ,0:6 fall in reputation bin 2 , which accounts for 1.55 % of the edits , while 36.19 % of the edits with ffe = ,0:6 fall in reputation bin 9 , which accounts for 45.39 % of the edits . This means that authors in reputation bin 2 are ( 2:68=1:55)=(36:19=45:39 ) = 2:17 times as likely to perform an edit with ffe = ,0:6 than authors in reputation bin 9 .
The corresponding tables for text longevity are Tables 7 , 8 , 9 , and 10 , and they tell a very similar story .
5.1 Comparison with Edit Count Repu tation
We compared the performance of our content driven reputation to another basic form of reputation : edit count . It is commonly believed that , as Wikipedia authors gain experience ( through revision comments , talk pages , and reading articles on Wikipedia standards ) , the quality of their submissions goes up . Hence , it is reasonable to take edit count , that is , the number of edits performed , as a form of reputation . We compare the performance of edit count , and of content driven reputation , in Table 11 . As we can see , according to our metrics , content driven reputation performs slightly better than edit count reputation on both the Italian and French Wikipedias .
We believe that one reason edit count based reputation performs well in our measurements is that authors , after performing edits that are often criticized and reverted , commonly either give up their identity in favor of a \fresh" one , thus zeroing their edit count reputation ( thus \punishing" themselves ) , or stop contributing to the Wikipedia . However , we believe that the good performance of edit count is an artifact , due to the fact that edit count is applied to an already existing history of contributions . Were it announced that edit count is the chosen notion of reputation , authors would most likely modify their behavior in a way that both rendered edit count useless , and damaged the Wikipedia . For instance , it is likely that , were edit count the measure of reputation , authors would adopt strategies ( and automated robots ) for performing very many unneeded edits to the Wikipedia , causing instability and damage . In other words , edit count as reputation measure has very little prescriptive value . In contrast , we believe our content driven reputation , by prizing long lasting edits and content , would encourage constructive behavior on the part of the authors .
Cumulative Distribution of Content Driven Reputation over Edit Longevity
Rep %data 1:0 0:8 0:6 0:4 0:2 0:0 ,0:2 ,0:4 ,0:6 ,0:8 =,1:0 16.19 0.0 4.21 1.0 3.67 2.0 3.0 2.92 1.84 4.0 1.92 5.0 1.85 6.0 7.0 1.33 1.32 8.0 9.0 0.83
27.34 12.16 11.19 8.14 6.84 7.28 5.91 6.42 5.61 4.39
27.81 12.68 11.91 8.82 7.45 7.77 6.44 7.04 6.22 4.91
28.47 13.30 12.72 9.58 8.14 8.32 7.06 7.71 6.88 5.60
34.87 20.42 20.18 17.44 16.30 15.09 14.35 14.69 13.51 12.04
31.51 17.00 16.63 13.28 12.27 11.46 10.81 11.18 10.22 8.89
28.99 13.81 13.31 10.26 8.91 9.00 7.82 8.36 7.52 6.24
26.43 11.21 10.43 7.17 6.00 6.54 5.06 5.48 4.71 3.52
25.63 10.35 9.66 6.65 5.45 6.14 4.58 5.02 4.25 3.17
6.80 0.86 1.55 2.47 3.66 6.06 7.68 11.53 14.01 45.39
29.85 14.94 14.35 11.31 10.05 9.85 8.85 9.34 8.49 7.27
100 100 100 100 100 100 100 100 100 100
Table 3 : French Wikipedia : Cumulative distribution of revisions over edit longevity , grouped by reputation . The Rep column is the scaled reputation blog(1 + rep)c , where rep is the author reputation . Each row shows how much of the total editing was done by authors of each reputation range ( the \%data" column ) , and how those edits were distributed with respect to edit longevity .
Cumulative Distribution of Content Driven Reputation over Edit Longevity
Rep %data 1:0 0:8 0:6 0:4 0:2 0:0 ,0:2 ,0:4 ,0:6 ,0:8 =,1:0 6.00 0.0 1.0 5.63 0.85 2.0 1.54 3.0 0.77 4.0 5.0 0.53 0.46 6.0 0.39 7.0 0.82 8.0 9.0 0.53
21.29 18.09 6.85 6.28 4.58 5.46 4.70 3.88 5.31 6.37
22.11 18.62 7.26 7.31 4.91 5.99 5.33 4.38 5.90 6.90
22.31 18.93 7.87 8.01 5.85 6.60 5.73 5.08 6.50 7.38
36.22 21.09 11.63 10.52 8.33 8.94 7.08 8.18 11.15 10.00
38.94 25.94 16.08 15.11 11.94 11.85 9.85 11.29 15.10 12.84
14.12 17.08 3.78 4.28 2.45 2.23 3.10 1.92 3.93 4.81
21.00 17.90 5.34 5.15 4.07 4.62 4.24 3.21 4.94 5.79
13.82 16.78 3.33 3.87 2.09 2.02 2.43 1.22 3.50 3.42
4.27 0.54 0.99 1.67 3.09 5.36 10.46 9.97 11.59 52.05
23.09 19.64 8.68 8.74 6.53 7.29 6.12 6.26 7.37 8.27
100 100 100 100 100 100 100 100 100 100
Table 4 : Italian Wikipedia : cumulative distribution of revisions over edit longevity , grouped by reputation . The Rep column is the scaled reputation blog(1 + rep)c , where rep is the author reputation . Each row shows how much of the total editing was done by authors of each reputation range ( the \%data" column ) , and how those edits were distributed with respect to edit longevity .
13
Rep %data 6.80 0.0 0.86 1.0 1.55 2.0 3.0 2.47 3.66 4.0 6.06 5.0 7.68 6.0 7.0 11.53 14.01 8.0 9.0 45.39
1:0 5.21 0.80 1.45 2.40 3.60 6.05 7.74 11.57 14.25 46.95
Distribution of Edit Longevity over Content Driven Reputation 0:8 6.80 0.87 1.64 3.07 4.40 6.57 8.11 12.09 13.77 42.67
0:0 ,0:2 ,0:4 ,0:6 ,0:8 ,1:0 47.74 1.57 2.46 3.13 2.92 5.04 6.17 6.67 8.03 16.28
0:2 5.44 0.67 1.43 2.57 4.37 6.28 8.93 11.50 13.89 44.93
0:4 5.80 0.97 1.60 2.60 4.16 5.19 7.94 11.32 13.58 46.86
0:6 6.52 1.01 2.03 2.80 4.70 5.61 8.67 12.21 13.92 42.53
12.18 1.66 2.68 2.86 4.44 5.50 8.31 11.70 14.48 36.19
7.03 0.92 1.34 2.72 3.51 5.12 7.45 12.47 14.42 45.02
19.01 1.55 2.74 2.73 3.92 7.57 6.22 12.61 12.15 31.49
5.88 0.81 2.02 3.05 4.05 5.42 7.37 12.95 15.61 42.84
6.74 0.80 1.86 2.82 3.79 4.98 7.18 11.54 13.79 46.51
Table 5 : French Wikipedia : distribution of revisions over reputation , grouped by edit longevity . The Rep column is the scaled reputation blog(1 + rep)c , where rep is the author reputation . The first column ( \%data" ) shows the amount of editing that was performed by authors in each reputation range . The other columns show , as percentages , how revisions of a specific edit longevity fall into reputation ranges , and therefore add to 100 % .
Rep %data 4.27 0.0 1.0 0.54 0.99 2.0 1.67 3.0 3.09 4.0 5.0 5.36 10.46 6.0 9.97 7.0 11.59 8.0 9.0 52.05
1:0 3.03 0.46 0.97 1.64 3.15 5.49 10.94 10.26 11.42 52.64
0:8 3.79 0.85 1.44 2.50 3.63 5.09 9.47 10.13 14.94 48.17
Distribution of Edit Longevity over Reputation 0:6 23.33 0.33 1.22 1.24 2.32 3.68 4.17 7.93 18.19 37.61
0:0 ,0:2 ,0:4 ,0:6 ,0:8 ,1:0 30.78 3.64 1.01 3.09 2.86 3.44 5.80 4.64 11.34 33.43
0:2 1.68 0.32 1.15 2.23 5.49 6.24 7.93 13.22 13.37 48.37
0:4 3.96 0.46 0.96 1.45 2.51 4.42 4.86 14.20 12.12 55.06
21.30 0.32 1.12 1.04 3.62 9.29 8.61 9.26 8.47 36.96
2.14 0.18 2.66 3.34 2.79 7.98 8.49 11.91 7.61 52.91
12.48 2.24 0.92 1.45 1.52 2.98 7.68 3.09 11.61 56.03
6.29 0.51 0.74 3.08 1.86 5.09 11.97 8.95 12.22 49.30
1.32 0.17 0.47 0.72 1.15 1.16 7.30 7.28 5.18 75.26
Table 6 : Italian Wikipedia : distribution of revisions over reputation , grouped by edit longevity . The Rep column is the scaled reputation blog(1 + rep)c , where rep is the author reputation . The first column ( \%data" ) shows the amount of editing that was performed by authors in each reputation range . The other columns show , as percentages , how revisions of a specific edit longevity fall into reputation ranges , and therefore add to 100 % .
14
Cumulative Distribution over Text Longevity Rep %data 1:0 0:8 0:6 0:4 0:2 0:0 4.10 0.00 1.85 1.00 1.26 2.00 3.00 1.38 0.81 4.00 1.05 5.00 0.67 6.00 0.58 7.00 8.00 0.52 0.58 9.00
7.30 1.08 1.97 3.02 4.51 6.35 9.30 11.68 14.32 40.47
14.00 8.01 8.70 7.49 6.55 5.49 4.62 5.43 4.06 3.96
6.36 2.40 2.30 2.05 1.37 1.19 1.04 0.75 0.65 0.70
9.71 4.23 4.37 3.84 3.17 2.43 1.95 1.76 1.55 1.67
6.83 3.10 2.55 2.30 1.64 1.33 1.16 0.88 0.78 0.83
100 100 100 100 100 100 100 100 100 100
Table 7 : French Wikipedia : Cumulative distribution of revisions over text longevity , grouped by reputation . The Rep column is the scaled reputation blog(1 + rep)c , where rep is the author reputation . Each row shows how much of the total text was contributed by authors of each reputation range ( the \%data" column ) , and how the text was distributed with respect to text longevity .
Cumulative Distribution over Text Longevity Rep %data 1:0 0:8 0:6 0:4 0:2 0:0 3.17 0.00 1.00 0.93 1.03 2.00 0.45 3.00 0.44 4.00 0.34 5.00 6.00 0.24 0.26 7.00 0.29 8.00 9.00 0.34
6.01 0.63 1.49 2.55 4.07 7.92 11.69 12.40 16.85 36.40
11.48 5.70 7.82 5.32 7.27 7.14 8.44 5.81 6.77 10.81
5.23 2.03 2.39 1.78 1.73 1.26 1.06 1.62 1.34 1.81
4.33 1.25 1.22 1.04 0.98 0.55 0.41 0.56 0.47 0.58
4.23 1.18 1.13 0.51 0.75 0.44 0.36 0.42 0.39 0.44
100 100 100 100 100 100 100 100 100 100
Table 8 : Italian Wikipedia : cumulative distribution of revisions over text longevity , grouped by reputation . The Rep column is the scaled reputation blog(1 + rep)c , where rep is the author reputation . Each row shows how much of the total text was contributed by authors of each reputation range ( the \%data" column ) , and how the text was distributed with respect to text longevity .
Rep %data 0.00 7.30 1.08 1.00 1.97 2.00 3.02 3.00 4.00 4.51 6.35 5.00 9.30 6.00 11.68 7.00 8.00 14.32 40.47 9.00
Distribution of Text Longevity over Reputation 0:0 32.22 2.15 2.67 4.50 3.91 7.20 6.67 7.23 8.02 25.44
0:2 44.85 1.62 5.57 5.50 6.97 2.44 9.45 5.56 5.12 12.92
0:8 10.97 1.43 2.99 3.86 5.33 6.79 8.68 15.00 12.55 32.40
0:6 19.60 1.14 3.33 4.36 6.45 6.56 6.88 9.52 10.29 31.88
0:4 20.25 4.41 2.94 4.30 6.93 4.96 6.37 9.12 11.03 29.70
1:0 6.64 1.05 1.90 2.95 4.45 6.35 9.38 11.68 14.52 41.09
Table 9 : French Wikipedia : distribution of revisions over reputation , grouped by text longevity . The Rep column is the scaled reputation blog(1 + rep)c , where rep is the author reputation . Columns show , as percentages , how revisions of a specific text longevity fall into reputation ranges , and therefore add to 100 % .
15
Rep %data 6.01 0.00 0.63 1.00 2.00 1.49 2.55 3.00 4.07 4.00 7.92 5.00 6.00 11.69 12.40 7.00 16.85 8.00 9.00 36.40
Distribution of Text Longevity over Reputation 0:0 37.97 1.18 3.07 2.30 3.55 5.32 5.50 6.45 9.85 24.82
0:2 36.49 0.89 0.82 0.91 7.37 4.56 7.99 11.44 9.64 19.89
0:4 4.79 0.35 1.01 10.49 7.22 6.81 5.25 13.21 10.30 40.58
1:0 5.82 0.65 1.50 2.65 4.13 8.04 11.71 12.78 17.19 35.52
0:8 5.50 0.34 1.18 1.32 3.30 6.81 12.61 7.60 13.41 47.93
0:6 5.48 0.50 1.78 1.92 3.08 5.77 7.73 13.44 14.81 45.48
Table 10 : Italian Wikipedia : distribution of revisions over reputation , grouped by text longevity . The Rep column is the scaled reputation blog(1 + rep)c , where rep is the author reputation . Columns show , as percentages , how revisions of a specific text longevity fall into reputation ranges , and therefore add to 100 % .
Precision
Edit prec e
Text prec t
Recall
Boost
Edit rece
Text rect
Edit boost e
Text boost t
Coeff . of constr . Edit e
Text t
Italian Wikipedia :
Content driven reputation Edit count as reputation
14.15 11.50
French Wikipedia :
Content driven reputation Edit count as reputation
23.92 21.62
3.94 3.32
5.85 5.63
19.39 19.09
38.69 39.52
32.24 28.30
37.80 37.92
4.03 3.27
4.21 3.81
5.83 4.91
4.51 4.34
3.35 2.53
7.33 5.61
7.17 6.35
6.29 6.08
Table 11 : Summary of the performance of content driven reputation over the Italian and French Wikipedias . All data are expressed as percentages .
16
5.2 Text Age and Author Reputation as
Trust Criteria
The age of text in the Wikipedia is often considered as an indicator of text trustworthiness , the idea being that text that has been part of an article for a longer time has been vetted by more contributors , and thus , it is more likely to be correct [ Cro06 ] . We were interested in testing the hypothesis that author reputation , in addition to text age , can be a useful indicator of trustworthiness , especially for text that has just been added to a page , and thus that has not yet been vetted by other contributors . Let fresh text be the text that has just been inserted in a Wikipedia article . We considered all text that is fresh in all the Italian Wikipedia , and we measured that 3.87 % of this fresh text is deleted in the next revision . In other words , Pr(deleted j fresh ) = 0:0387 . We then repeated the measurement for text that is both fresh , and is due to a low reputation author : 6.36 % of it was deleted in the next revision , or Pr(deleted j fresh and low reputation ) = 0:0636 . This indicates that author reputation is a useful factor in predicting the survival probability of fresh text , if not directly its trustworthiness . Indeed , as remarked above , since text can be deleted for a number of reasons aside from bad quality , author reputation is most likely a better indicator of trustworthiness than these figures indicate .
6 Conclusions
After comparing edit and text longevity values with user quality ratings for revisions , we believe that the largest residual source of error in our content driven reputation lies in the fact that our text analysis does not include specific knowledge of the Wikipedia markup language and Wikipedia conventions . We plan to make the text analysis more precise in future work .
It is occasionally claimed that the reputation of Wikipedia authors should be domain specific , so that a good reputation for writing about mathematics does not automatically translate to a good reputation for writing about history . We are not sure domain specific reputation has more prediction value than generic reputation , such as the one we build in this paper . We suspect that a sense of one ’s own abilities and limitations , and a knowledge of Wikipedia customs , may play a more important role than domain specific knowledge in determining the average quality of an author ’s contributions . The techniques developed for this paper enable us to easily measure the contributions of authors to various categories of the Wikipedia , so we plan to study the usefulness of domain specific reputation from an experimental point of view in future work .
Acknowledgements We thank Marco Faella for helping organize the manual rating of revisions to the Italian Wikipedia .
References
[ BL97 ] RC Burns and DDE Long . A linear time , constant space differencing algorithm . In Performance , Computing , and Communication Conference ( IPCCC ) , pages 429{436 . IEEE International , 1997 .
[ CAM02 ] G . Cobena , S . Abiteboul , and A . Marian . Detecting changes in XML documents . In Proc . of the 18th Intl . Conf . on Data Engineering ( ICDE ) . IEEE Computer Society Press , 2002 .
[ CGM97 ] S . Chawate and H . Garcia Molina . Meaningful change detection in structured data . In Proc . of the ACM SIGMOD Conference on Management of Data , pages 26{37 . ACM Press , 1997 .
[ CL01 ] W . Cunningham and B . Leuf . The Wiki Way . Quick Collaboration on the Web . AddisonWesley , 2001 .
[ Cro06 ] T . Cross . Puppy smoothies : Improving the reliability of open , collaborative wikis . First Monday , 11(9 ) , September 2006 .
[ CT91 ] TM Cover and JA Thomas . Elements of In formation Theory . J . Wiley & Sons , 1991 .
[ Del03 ] C . Dellarocas . The digitization of word ofmouth : Promises and challenges of online reputation systems . Management Science , October 2003 .
[ Gil05 ] J . Giles .
Internet encyclopaedias go head to head . Nature , pages 900{901 , December 2005 .
[ GKRT04 ] R . Guha , R . Kumar , P . Raghavan , and A . Tomkins . Propagation of trust and distrust . In Proc . of the 13th Intl . Conf . on World Wide Web , pages 403{412 . ACM Press , 2004 .
[ Gol05 ] JA Golbeck . Computing and Applying Trust in Web Based Social Networks . PhD thesis , University of Maryland , 2005 .
[ Hir77 ] DS Hirschberg . Algorithms for the longest J . ACM , common subsequence problem . 24(4):664{675 , 1977 .
[ HM75 ] JW Hunt and MD McIlroy . An algorithm for differential file comparison . Computer Science Technical Report 41 , Bell Laboratories , 1975 .
17
[ HR06 ] M . Hickman and G . Roberts . Wikipedia | separating fact from fiction . The New Zealand Herald , Feb . 13 2006 .
[ Kle99 ] JM Kleinberg . Authoritative sources in a hyperlinked environment . J . ACM , 46(5):604{632 , 1999 .
[ ZS89 ] K . Zhang and D . Shasha . Simple fast algorithms for the editing distance between trees and related problems . SIAM Journal on Computing , 18(6 ) , 1989 .
[ KSGM03 ] SD Kamvar , MT The
Schlosser , and eigentrust algoH . Garcia Molina . in p2p rithm for networks . In Proc . of the 12th Intl . Conf . on World Wide Web , pages 640{651 . ACM Press , 2003 . reputation management
[ LRBPR99 ] D . Lucking Reiley , D . Bryan , N . Prasad , and D . Reeves . Pennies from Ebay : The determinants of price in online auctions . Working paper , Vanderbilt University , 1999 .
[ LZ05 ] VB Livshits and T . Zimmerman . Dynamine : Finding common error patterns by mining software revision histories . In ESEC/FSE , pages 296{305 , 2005 .
[ Mye86 ] EW Myers . An o(ND ) difference algorithm and its variations . Algorithmica , 1(2):251{266 , 1986 .
[ PBMW98 ] L . Page , S . Brin , R . Motwani , and T . Winograd . The PageRank citation ranking : Bringing order to the web . Technical report , Stanford Digital Library Technologies Project , 1998 .
[ RZFK00 ] P . Resnick , R . Zeckhauser , E . Friedman , and K . Kiwabara . Reputation systems . Comm . ACM , 43(12):45{48 , 2000 .
[ Str06 ] R . Stross . Anonymous source is not the same as open source . The New York Times , Mar . 12 2006 .
[ Tic84 ] WF Tichy . The string to string correction problem with block move . ACM Transactions on Computer Systems , 2(4 ) , 1984 .
[ VWD04 ] F . Viegas , M . Wattenberg , and K . Dave . Studying cooperation and conflict between authors with history flow visualizations . In Proc . of the SIGCHI Conf . on Human Factors in Computing Systems , pages 575{582 , 2004 .
[ ZAD+06 ] H . Zeng , MA Alhoussaini , L . Ding , R . Fikes , and DL McGuinness . Computing trust from revision history . In Intl . Conf . on Privacy , Security and Trust , 2006 .
18
