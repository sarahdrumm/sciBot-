Fast and Cost efficient Bid Estimation for Contextual Ads
Ye Chen , Pavel Berkhin , Jie Li , Sharon Wan , Tak W . Yan
Microsoft Corporation
1065 La Avenida , Mountain View , CA 94043
{yec,pavelbe,lijie,xiawa,takyan}@microsoft.com
ABSTRACT We study the problem of estimating the value of a contextual ad impression , and based upon which an ad network bids on an exchange . The ad impression opportunity would materialize into revenue only if the ad network wins the impression and a user clicks on the ads , both as a rare event especially in an open exchange for contextual ads . Given a low revenue expectation and the elusive nature of predicting weak signal click through rates , the computational cost incurred by bid estimation shall be cautiously justified . We developed and deployed a novel impression valuation model , which is expected to reduce the computational cost by 95 % and hence more than double the profit . Our approach is highly economized through a fast implementation of kNN regression that primarily leverages low dimensional sell side data ( user and publisher ) . We also address the cold start problem or the exploration vs . exploitation requirement by Bayesian smoothing using a beta prior , and adapt to the temporal dynamics using an autoregressive model .
Categories and Subject Descriptors I51 [ Models ] : Statistical
General Terms Algorithms , Theory , Experimentation
Keywords Computational advertising , nonparametric models , exchange
1 .
INTRODUCTION
We study the problem of estimating the value of a contextual ad impression , with the goal of returning a sufficiently accurate valuebased bid to an ad exchange in a cost efficient manner to optimize profit or return on investment ( ROI ) for an ad network . An ad exchange sends a request for bid ( RFB ) for an ad impression to an ad network or more generally a bidder . The bidder then returns a bid based upon the value of the impression or the revenue opportunity through winning the auction and user clicking on the served ads . The value based bid estimation or simply impression valuation incurs the computational cost to bid ( CTB ) . If the bidder wins the impression , she pays the next highest bid ( second price auction ) as the traffic acquisition cost ( TAC ) . The ad network then runs an internal generalized second price auction ( GSP ) to select which advertisers’ ads to serve , along with their ranking and pricing , in
Copyright is held by the author/owner(s ) . WWW 2012 Companion , April 16–20 , 2012 , Lyon , France . ACM 978 1 4503 1230 1/12/04 . response to the request for payload ( RFP ) from the exchange and incurring the computational cost to serve ( CTS ) . If the served ads are clicked , the advertisers pay the ad network the click through rate ( CTR ) adjusted next highest cost per click ( CPC ) bid , as in standard GSP pricing [ 1 ] . We will focus on impression valuation in response to a RFB in this work .
Impression valuation plays a central role in bidding for performance based ads , yet is a difficult task involving estimating rates of very rare events , ie , click through of contextual ads . Given a contextual ad call impression or block i , the expected revenue is
E(yi ) = wi bi,k+1pi,k+1 ,
( 1 ) m k=1 m where wi is the auction winning rate , k indexes m positional ranks contained in the ad impression block , bi,k+1 and pi,k+1 are the CPC bid and the estimated CTR , respectively , of the ad ranked k+1 via a GSP . The expected payoff is then
E(ui ) = wi bi,k+1pi,k+1 − cTAC i − cCTS i
− cCTB i
,
( 2 ) k=1 i i i
, cCTS and cCTB where cTAC are the TAC , CTS and CTB terms , respectively . CTB is primarily incurred by bid estimation and would sink regardless of winning an auction or not ( wi ) , nor depends upon the CTR ( pi,k ) ; hence more difficult to justify under a competitive exchange for low response impression opportunities . A typical value of wi in an open exchange is 10 % , and pi,k ’s of contextual ads are very low , eg , 03 % A full fledged valuation would scan hundreds of campaigns for a best match to realize the impression value thus costly in terms of CTB ; while only relying on the sellside data of the impression , ie , user and publisher , may already give an accurate enough estimate with a substantially lower CTB .
2 . AN EFFICIENT KNN REGRESSION
The expected revenue given a won impression is referred to as the true value of the impression , as shown in Eq 1 excluding the winning probability . We wish to estimate the true value using a predictive model of the general form y = f ( x ) . This is a regression problem involving two stochastic processes : ( 1 ) a GSP mechanism , and ( 2 ) the click through thereupon . With economical computation as one design goal , x is an input vector encoding only the sell side features of the impression , which are known and unique from the RFB at run time , eg , user geolocation , publisher , page URL , and ad placement . We use a k nearest neighbor ( kNN ) regression to memorize an aggregated view of history , to implicitly capture the best match with the buy side data , eg , advertiser and ad . Formally , given a dataset of historical impression valuation D = {xi , yi}n i=1 ,
WWW 2012 – Poster PresentationApril 16–20 , 2012 , Lyon , France477 the offline training involves building a mapping : f : x → ( nx =
1 , sx = yi ) ,
( 3 ) i:xi=x i:xi=x where x denotes a point in feature space . In online prediction , given an ad impression x , the MLE of the value is given by the first moment yMLE ← sx/nx sz(x)/nz(x ) if x = x , otherwise .
( 4 )
Here z(x ) is a mapping function from x to an aggregated level z , eg , the publisher placement pair , nz and sz are accumulated accordingly .
Since kNN is a nonparametric model , it will bravely predict zero for x without any historical clicks . This behavior is desirable when sufficient impressions have been seen . However , at the beginning of launching a model on a new traffic source , eg , a new page , some form of exploration vs . exploitation needs to be built in . One way to approach this is to impose a beta prior on y , derived from an aggregated level z naturally available from domain hierarchy and typically with much denser data , as follows yx ∼ Beta(λyz(x ) + 1 , λ(1 − yz(x ) ) + 1 ) ,
( 5 ) where yz = sz/nz and λ is the smoothing factor . The MAP estimate of the value of impression x is x ← sx + λyz(x ) yMAP nx + λ
.
( 6 )
The Bayesian interpretation is that we have a priori observed λyz(x ) revenue from λ impressions with feature vector x before we see any real x . λ controls the smoothing strength , and we wish to have a reasonably strong smoothing for those x ’s with zero revenue sx = 0 , while being conservative with the x ’s with sufficient positive feedbacks , especially for sx * 0 . One data driven approach is λ ← mode(nx : sx = 0 ) . This ensures that for most zero revenue x ’s , the MAP estimate is half its back off estimate yz(x ) .
The kNN estimator derived thus far assumes that the expected value yx stays static temporarily . In practice , however , the system is dynamic , especially in an exchange environment due to supply ( inventory mix ) or demand ( user and campaign concept drift ) changes . To adapt to the temporal dynamics , we apply an autoregressive model to decay the importance of old data , as follows
T T x ← yDyn t=1(st x + λyt z(x ) ) exp(γt ) t=1(nt x + λ ) exp(γt )
,
( 7 ) where t indexes 1 : T training days , γ is an exponential decay parameter fitted into the latest training day T using least squares and updated daily . The existence of temporal dynamics and the effectiveness of our approach are quite evident empirically , as shown in Figure 1 .
We now comment on the rationale behind our choice of kNN . Clicking on contextual ads is not only a very rare event , with more than 95 % ads getting no response ; but also a very random event , with about 90 % variance of revenue cannot be explained by any single feature available . It is known that kNN classifier is universally Bayes consistent under the following sufficient condition [ 3 ] : if n → ∞ , then k → ∞ and k/n → 0 . Our implementation approaches this condition by controlling the feature dimentionality . Most features in ad domain are categorical , and we use binary encoding , ie , each feature value is a dimension . For each feature , we first select values by document frequency and use a minority bin to hold rare ones . By such feature value selection , we ensure a desired
Figure 1 : Static and dynamic prediction vs . actual . overall dimensionality d , and the number of kNN keys is upper bounded by 2d . Consequently , if n → ∞ , then k ≈ n/2d → ∞ and k/n = 1/2d → 0 . Empirically , we have tried linear regression and decision tree , and both yielded suboptimal results . 3 . EXPERIMENTAL RESULTS tion error rate :
We conducted a two week period online A/B testing on MSN web traffic , to compare the kNN valuation model with the current production model , which is a probit regression full evaluation model [ 2 ] . The evaluation metrics are primarily ( 1 ) sum of predici yi , and ( 2 ) profit as in Eq 2 . The results are reported in dollars per thousand impressions ( CPM ) as shown in Table 1 . i ( yi − yi)/
Table 1 : Online Testing Results
Model Test week Win rate Actual CPM Predicted CPM Error rate TAC and CTS CTB Profit kNN
Week 1 12 % 1.35 1.07
Probit regression Week 2 Week 1 Week 2 9 % 4 % 7.7 % 1.43 1.65 1.00 1.32 1.15 1.09 −8 % −34 % −21 % 15.30 % 0.14 0.15 0.12 0.05 0.89 2.00 0.40 −0.50 0.83
0.13 0.03 1.18
The results show that kNN reduces the computational cost of impression valuation ( CTB ) by 95 % , hence yields more than twice profit , compared with the current model . We also observe that kNN tends to have higher auction winning rate , which suggests that the nonpamametric approach yields better calibrated estimates and in turn further increases ROI . 4 . REFERENCES [ 1 ] B . Edelman , M . Ostrovsky , and M . Schwarz . Internet advertising and the generalized second price auction : Selling billions of dollars worth in keywords . American Economic Review , 97:242–259 , 2007 .
[ 2 ] T . Graepel , J . Q . Candela , T . Borchert , and R . Herbrich .
Web scale Bayesian click through rate prediction for sponsored search advertising in Microsoft ’s Bing search engine . ICML 2010 .
[ 3 ] C . J . Stone . Consistent nonparametric regression ( with discussion ) . Annals of Statistics , 5:595–645 , 1977 .
12345678910111213141516081121416182Prediction dayValue in CPM ( $ per thousand impressions ) static CPMdynamic CPMactual CPMWWW 2012 – Poster PresentationApril 16–20 , 2012 , Lyon , France478
