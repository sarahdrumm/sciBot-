You’ve got Mail , and Here is What you Could do With It! Analyzing and Predicting Actions on Email Messages
Dotan Di Castro
Yahoo Labs
Haifa 31905 , Israel lianeleytan@yahoocom
Haifa 31905 , Israel dot@yahoo inc.com Liane Lewin Eytan
Yahoo Labs
Zohar Karnin
Yahoo Labs
Haifa 31905 , Israel zkarnin@ymail.com
Yoelle Maarek
Yahoo Labs
Haifa 31905 , Israel yoelle@ymail.com
ABSTRACT With email traffic increasing , leading Web mail services have started to offer features that assist users in reading and processing their inboxes . One approach is to identify “ important ” messages , while a complementary one is to bundle messages , especially machinegenerated ones , in pre defined categories . We rather propose here to go back to the task at hand and consider what actions the users might conduct on received messages . We thoroughly studied , in a privacy preserving manner , the actions of a large number of users in Yahoo mail , and found out that the most frequent actions are typically read , reply , delete and a sub type of delete , delete withoutread . We devised a learning framework for predicting these four actions , for users with various levels of activity per action . Our framework leverages both vertical learning for personalization and horizontal learning for regularization purposes . In order to verify the quality of our predictions , we conducted a large scale experiment involving users who had previously agreed to participate in such research studies . Our results show that , for recall values of 90 % , we can predict important actions such as read or reply at precision levels up to 40 % for active users , which we consider pretty encouraging for an assistance task . For less active users , we show that our regularization achieves an increase in AUC of close to 50 % . To the best of our knowledge , our work is the first to provide a unified framework of this scale for predicting multiple actions on Web email , which hopefully provides a new ground for inventing new user experiences to help users process their inboxes .
1 .
INTRODUCTION
The nature of email traffic has greatly changed in the last decade . Some recent studies have shown that more than 90 % of non spam Web email is now machine generated , with messages of various importance , from critical etickets or invoices , to hotel newsletters , [ 2 , 18 ] . Several mail clients have identified this evolution and have started to offer some organizational means to help users process their constantly growing inboxes . Thus AOL mail was one of the first mail services to provide high level stacks such as Daily Deals , Social Notifications or Photos and Attachments , [ 25 ] . Yahoo mail offers Smart views , which provide search facets for messages , such as People , Social , Travel , Shopping and Finance , as detailed in [ 18 ] . Gmail has also been offering various ways for users to scan their inboxes , first with its Priority Inbox [ 1 ] , then with its Smart Labels and Inbox Tabs1 and more recently with its Inbox for Gmail [ 15 ] experience , which supports automatic sorting into four semantic Bundles ( Travel , Purchases , Finance and Social . )
All of these systems apply some classification scheme on messages , but typically ignore the end game , namely what action the user will take on them . In this paper , our goal is to study mail actions in details and explore a novel approach to predict them . More specifically , we first propose to conduct a large scale study of the actions conducted by real users in Yahoo mail , identify the most popular actions , such as read , reply , delete , and forward , and verify how predictable they are . Other actions , such as moving messages into folders , are of less interest since they are quite rare . Indeed , it has been shown that 70 % of Web mail users never ever defined a single folder , [ 23 ] . The delete action is given special consideration . We distinguish between two delete behaviors . The first , referred to as delete with read , covers the case in which the message is first open , and we assume read even if not in depth , and then deleted . The second , delete without read , covers the case in which the message header , typically including the sender , subject line and possibly a short snippet of the body , are sufficient for the user to decide that s/he does not need to open it , let alone read it . We believe that these two actions are conceptually very different . The first carries some level of interest : its header is intriguing enough for the user to open ( and most probably read ) it . The second indicates a lesser level of interest : either the header brings sufficient information that the user does not need to read more , or more frequently , the header is sufficient for the user to decide that s/he has no interest whatsoever in the message , which is quite common with mass mailing . Note that we do not claim here is that a message that is only read is less important in essence that a message that was replied to or forwarded . It could be that by the simple nature of the message ( an answer to a critical question for instance in personal communication , or a confirmation of shipment delivery in a machine generated message ) , it does not require further action . This is one of the reasons for which we do not attempt to predict the importance of the email , which we believe is not only difficult but probably not useful per se , but prefer to try predicting each action independently . 1https://supportgooglecom/mail/answer/3055016?hl=en&p= inboxtabs&rd=1
307 Some messages should by their simple nature only be read , as for instance Direct Answers or OneBoxes such as Weather or Stock Prices in Web Search , while others will demand further action .
Our task is thus to predict the most probable actions , from the list of sufficiently frequent actions , for any user and any incoming message . This task is inherently difficult , since as we will show , most Web mail users , unlike enterprise mail users who are out of the scope of this work , are quite passive . One major challenge is thus to support all Web mail users , across all levels of usage . To do so , we examine case specific methods of regularization aimed to apply data learned vertically , from the collective of users , on a single user with a low usage level .
As mentioned earlier , in our context of Web email , with its huge amount of machine generated messages , it is to be expected that a majority of messages will remain action less . One simple but key result of our study is that we have verified that over 85 % of the messages in an average inbox are never read . Consequently , identifying messages that have a non negligible chance to be acted upon should already bring value to the user . The task is obviously challenging due to the diversity of messages , users and users’ behaviors . However , like in any suggestion framework , the user will always have a choice of ignoring the suggestion . Our goal here is to offer a decent level of precision and a high level of recall for reasonably active users .
An additional motivation for this work , is to hopefully offer novel assistance features to mail users beyond suggestions . While discussing them is out of the scope of this paper , one can easily imagine various user experiences for ranking suggested actions in Smart phones mail clients , or dedicating a special view to messages that will probably be deleted without being fully opened . Note that this would be significantly different from some Gmail tabs such as “ Social ” or “ Promotions ” , which still require the user to isolate the rare actionable message ( for instance an interesting promotion that the user would wish to forward to a friend ) in a long list of messages that will most probably be deleted without being read . Another direct application of our framework is mail search or alerting systems . For instance , a message that has little chance to be read should not be returned at a high rank in search results , as users will typically search only for “ stuff they have seen ” to paraphrase the work by Dumais et al . [ 16 ] .
The contributions of our paper are three fold :
1 . We provide , to the best of our knowledge , the first large scale study of users’ actions in a major Web mail service .
2 . We formalize the task of “ actionable email prediction ” , leveraging both local features representing an individual inbox , and global features representing the overall mail traffic , as well as introduce a novel learning method that supports all types of users , according to their levels of activity per action . We apply “ vertical ” learning for personalization over a single inbox and “ horizontal ” learning for regularization , especially needed for action specific light users .
3 . We describe a full system that was implemented and evaluated on Yahoo mail and detail a large scale experiment that was done on users who had agreed to participate in such studies .
The paper is organized as follows . Section 2 provides some key insights on how Web mail users act today on their messages , reporting results of a large scale study we conducted on Yahoo mail . Section 3 formalizes the task of predicting users’ actions on delivered messages . Section 4 provides an exhaustive list of the mailspecific features we use . Section 5 describes in details our learning methodology , that relies on “ vertical ” learning for personalization and “ horizontal ” learning for regularization . Section 6 reports on the large scale experiments we conducted . We review related work in Section 7 and present our conclusions in Section 8 .
2 . STUDYING USERS’ ACTIONS 2.1 Popular Actions
One important validation exercise before we address the task of predicting actions , is to verify whether users do act on their inbox . We examined the log of the actions performed by Yahoo mail users , and considered the number of users who performed at least one action over a period of two months , thus ignoring “ dormant ” users . We observed that about 35 % of the entire non dormant population perform at least one action on a daily basis , which we believe is sufficient for motivating the task of predicting actions . Table 1 lists the most common actions over a period of two months . One interesting observation is that while read is obviously the most frequent action , conducted by 98 % of users , for 44 % of users it is , maybe surprisingly , the only action . This type of behavior reflects the evolution of Web mail traffic and a recent trend in Web mail usage . For more and more users , Web mail becomes more often used for bookkeeping of important messages ( such as purchase receipts , or itineraries ) of for getting updates from subscribed mailing lists , rather than communicating with friends or family . In that sense , Web mail becomes more and more similar in nature to traditional snail mail .
Action read reply forward delete
Percentage of Users
98 % 29 % 28 % 18 %
Table 1 : Percentage of users performing an action at least once over two months
We further explored the reply action . While reply is intuitively a popular action , its coverage over the total volume of messages is very low . Indeed , we verified that it is performed on only 2 % of incoming messages . For each message , we counted the number of users it was sent to . Note that we counted only once a single message that was sent separately to multiple users . This pattern is mostly observed in machine generated email as human senders will typically use the CC field instead . The count of recipients per message was then aggregated by sender to compute the average number of users receiving an email from each sender during a period of two weeks . As it turns out , most of the senders do not send messages to many different users . However , the vast majority of email traffic is sent as expected by mass senders , that send messages to many different users . This result is again consistent with our previous observations that Web mail is used less and less for personal communications and that , 90 % of Web mail messages are now machine generated , and as such do not expect a reply .
The graphs shown in Figure 1 provide more details on these counts . The lower graph gives the ratio of the messages triggering a reply action , with respect to their number of recipients . Clearly , the ratio is higher when the number of recipients is smaller ( indicating a personal correspondence ) , thus explaining the overall low reply ratio , when considering the overall traffic .
Note that all other actions , such as moving into a folder , report as spam ( or ham ) , starring a message etc . are significantly less frequent . Consequently we did not consider them in this work , as they are too rare to be of interest .
308 tion a , we consider three sets of users , depending on their levels of activity represented by the number of actions of type a that they performed over our 120 days period . Users performing at least one action , users performing more than 70 actions , and users performing more than 200 actions . For each user set and each action , we computed the percentage of messages on which the action was performed , averaged over all users in the set . Note that as the total count of actions increases , so does the percentage per message . This means that users who perform many actions of a certain type do not do so simply because they receive more mail but rather because they are more active : they act more often on each message . This phenomenon is stronger in the actions of forward , reply and delete with read , where the percentage per message demonstrates a huge increases when considering active vs . non active users . The varying percentage rates motivate a personalized approach to the action prediction task as it indicates that different recipients exhibit different behavior patterns .
Action # actions > 0 > 70 > 200
Read
Reply
Fwd
Deletewith Read
15.3 % 1.27 % 0.36 % 0.76 % 17.5 % 5.54 % 3.98 % 3.15 % 20.2 % 9.52 % 7.32 % 4.94 %
Delete without Read 10.43 % 16.47 % 19.76 %
Table 2 : Percentages of messages on which an action was performed according to various users’ activity levels
We continue our analysis of the selected five actions , while pivoting our focus on the percentage of users rather than on the percentage of messages . Specifically , for each action a , Table 3 presents the percentage of users who perform an action of type a over at least x % of the messages in their inbox , for various values of x .
Action msg ratio ≥ 0.5 % ≥ 1 % ≥ 2 % ≥ 5 % ≥ 10 % ≥ 25 %
Read
Reply
Fwd
Deletewith Read
94.3 % 30.2 % 9.53 % 9.77 % 91 % 19.1 % 4.31 % 6.2 % 83.8 % 10.1 % 1.58 % 3.48 % 63.3 % 2.9 % 0.25 % 1.12 % 39.8 % 0.58 % 0.04 % 0.29 % 11.7 % 0 %
0 %
0 %
Delete without Read 40.3 % 36.61 % 32.6 % 25.71 % 19.35 % 8.66 %
Table 3 : Percentages of users performing an action over different ratios of their messages
After analyzing the delete operations in our dataset , we discovered that 89.5 % of the delete actions are not preceded by any read operation , which confirms our intuition that delete without read is a common behavior that was worth isolating . This is also sustained by the statistics presented in Table 2 , where one can observe the large gap between the percentages of messages that are associated with a delete with read action and those associated with a deletewithout read action . The difference between these two actions is also demonstrated in Figure 2 and Table 3 , where the relative infrequency of delete with read is shown this time in terms of percentage of users who apply this action . We have verified that , as expected , the delete without read actions are in a huge majority conducted on machine generated messages as opposed to personal communications . Note that this does not imply that all machinegenerated messages will immediately be deleted by users , as it is clear that some of them are highly valuable and will be kept for future reference .
From both Tables 2 and 3 , read naturally emerges as the most popular action , with delete without read as an intriguing runnerup . After our initial surprise , we realized that this behavior does
Figure 1 : Senders , Messages and Reply Stats
2.2 Analyzing the Actions of Active Users
Following the global analysis on non dormant users described above , we conducted a more thorough analysis of the actions of more active users . To this effect , we defined as active any user who performed at least one spam vote during a time period of 120 days . Since spam vote is a rare action , this is a convenient proxy for identifying regularly active users . Given this definition , we generated a dataset covering the actions of more than 110 , 000 of such active users over this time period of 120 days . This dataset includes over 500M inbound messages and over 10M outbound messages , as well as their associated actions . More specifically , we considered the read , reply , forward and delete actions previously mentioned , as well as two specific sub types of delete , namely delete with read and delete without read . Note that we did not access any data pertaining to an individual message or user , and considered only aggregated data over actions , for obvious privacy reasons . The same dataset was used for our action prediction experiments as reported in Section 6 .
Figure 2 presents for each action , the percentage of users performing the action at least x times a day , on average . The plots are presented in log scale to account for the wide range of values . Clearly , the read action ( top blue curve ) is the most frequent one , performed on a daily basis by most users . The next two actions are delete without read and reply , that are performed daily by over 30 % and 10 % of active users , respectively .
Figure 2 : Daily Actions , taken over 120 days
Table 2 provides additional information on action coverage for messages according to the users’ levels of activity . For each ac
309 make sense , given the new nature of Web mail traffic that we previously discussed . One the other end of the spectrum forward and delete with read are clearly much less frequent actions . As seen in Figure 2 , even our active users do not perform either of these actions on daily basis . They are not only of limited interest to active users but will also be significantly more difficult to predict considering the sparsity of data . Consequently in our prediction task , we will deliberately ignore forward among the top four atomic actions and focus on read , reply and delete . In addition , given the high popularity of delete without read , we will also give it dedicated attention and attempt to predict it .
3 . PREDICTING USER’S ACTIONS
We motivate and define below some of the concepts that are key to our task of predicting actions on any given message received by any given user . 3.1 Model & Features
Given a user i , we note mi j ∈ M i a message received by user i in his/her inbox M i . The function y(i , j , a ) takes as value 1 , if user i conducted action a on message mi j , and 0 otherwise . We define the task of actionable email prediction as predicting the value of j and for any action a , with a ˆy(i , j , a ) , for any new message mi value 1 for predicting action a , and a value of 0 for a non action . As discussed in Section 2 , the actions we consider further are read , reply , delete and delete without read .
Each message mi j within the inbox is translated into a vector of features . We abuse notations and denote by mi j both the message and its associated feature vector . The extracted features range from “ local ” features , that is , features computed locally over a specific inbox , to “ global ” features computed over the entire mail dataset . Local features cover both features derived from the message content and header and features that reflect the behavioral pattern of the specific user over similar past messages . In contrast , global features refer to the entire dataset , typically referring to large senders . Examples include the overall number of messages sent by this specific sender , or the number of actions triggered by the sender across all users , etc . The exhaustive list of features we are using is detailed in Section 4 . We regularly update our model as follows . When a j , or does not perform user i performs an action a on message mi this action on mi j over the predefined time period , we record the corresponding value of y(i , j , a ) , and feed it as a labelled example to our model , the example being respectively positive or negative . 3.2 Horizontal vs Vertical Learning
Following [ 23 ] , we propose to use a “ vertical ” view of email data , which focuses on each user ’s individual inbox and supports personalization , as well as a “ horizontal" view of email across a very large number of email recipients , which leverages some type of “ wisdom of crowds ” . In our vertical learning process , we learn from the historical data derived from a given inbox , considering both local and global features in order to predict actions on a new message . The quality of the prediction is therefore highly dependent on the availability of historical inbox data . However , we have observed in Section 2 , that many users , even with large inboxes , are mostly passive and take very few actions . Even active users might focus on one type of action only . It is therefore critical to compensate for this lack of information by extrapolating from other users . To this effect we apply a complementary horizontal learning approach and apply regularization techniques as described next . We pause to mention that the concept of integrating between horizontal and vertical learning is not new and has been done in the past for tasks involving several types of data , including email ( see eg
[ 1] ) . Our novelty is the exact method for incorporating the horizontal learning , specially tailored for the task at hand ( see also Section 53 )
We consider two methods of regularization depending on the availability of historical data for a given user . The first method is applied to users who exhibit a very small amount of actions of a specific type in their inbox , and for whom the vertical learning model will probably perform poorly due to lack of data . In order to compensate for such sparse data , we compute , for each action , an average user model . We then add a specialized regularization term pulling the personalized model towards it , as detailed in Section 5.2 , equation 2 .
The second method is reserved to more active users , with respect to a given action . These users are defined as exhibiting a sufficient ( above some action specific threshold ) number of positive examples . Our intuition here is that these users could benefit from the information derived from other users who somehow resemble them with respect to this action . It is clear that users exhibit various types of behavior on their email , yet the differences in behavior can be quite fine grained . Note that we are not trying to infer highlevel type of inboxes ( eg , work from home , family , bookkeeping , etc. ) , but rather focus on behavioral patterns for each action . To this effect , we propose to identify latent user types with respect to each action . The rationale here is that each sufficiently active user will be somehow close to one of these latent types and could benefit from data learned on users who exhibit similar behavior for this action . To this effect we consider users with a rich dataset for a given action , and derive from them a relatively small number of latent user types . Note that , like in traditional collaborative filtering , we do not attempt to label or interpret these latent types as our goal is to exploit them solely for regularization . We explain in Section 5.2 how we identify a set of latent user types for each action , and how we leverage them for regularization purposes . We mention that this form of regularization , to the best of our knowledge , has not been suggested in the past , possibly due to its unique setting where the task involves learning multiple regressors ( per user ) that are assumed to have an underlying cluster like structure ( each cluster corresponds to a latent user type ) .
4 . MAIL FEATURES
Given a user ’s inbox , we generate for each message a feature vector . Then for each possible action on a message , we assign to the corresponding feature vector a binary label that indicates whether the message triggered the respective action or not . We detail below how these feature vectors are generated .
The naive feature space of the predictor is quite large , given the numerous fields of the current Internet Message Format [ 28 ] . These features are derived from the message header ( covering header fields such as sender including domain and associated IP , cc , “ subject ” , etc. ) , from the message body and also additional meta data fields provided by the mail service such as URLs included in the body . Potentially , the number of feature values that can be derived , especially from textual fields such as subject or body , can be quite large . One method to handle this , is to limit the scope of feature values as described later . For each message m , we denote the set of fields associated with m by F = {f1 , . . . , fk} , where k is the total number of fields . We define a function φ(· ) that maps the set of fields F into features x1 , . . . , xn , where n is the total number of features .
As mentioned in Section 3 , we distinguish between local features and global features . Local features represent the messages forming an individual user ’s inbox as well as the way the user reacted to similar messages in the past . In this context , similarity is
310 defined with respect to the different fields from which the features are generated . Global features relate to the message sender , and characterize the way by which all users , as a collective , react to messages sent by the same sender .
Local features pertain to the different fields of a message m , and can be divided into the two following types :
• Action independent : Each such feature is based on a specific field fj ∈ m , and indicates whether the user previously received messages with a similar ( identical ) value of fj . We keep both a binary and scalar version of this feature . The binary feature holds a 0/1 value that reflects whether or not the user received such a message in the past , while the value of the scalar feature holds the count of messages ( received over a certain period of time ) that have a similar field value for fj . For example , consider the sender field , and assume message mi t was sent to user i from info@twittercom Then , the binary feature associated with the sender field for t indicates whether messages from info@twitter.com mi were received by user i in the past , while the scalar feature reflects the count of messages received from this sender . Table 4 details the different fields on which this type of features are based . • Action dependent : Each such feature is based on a specific field fj ∈ m and a given action az ∈ A that might be performed on m . Consider a message mi t received at time t by user i , and sent by a sender s . Then , for each action az ∈ A , we generate a feature that indicates whether user i ever performed this specific action az over messages sent by the same sender . Like in the previous case , we keep both binary and scalar versions of these features . Note that the total number of this type of features is a cross product of the number of fields we consider ( namely k ) and the number of actions considered
Global features pertain to senders over the entire mail dataset and are also divided into types , as detailed below :
• General traffic sender features : These features cover absolute and relative counts of messages exchanged between a given sender and the recipient population in our dataset . They include :
– Traffic features : These features provide absolute and relative counts of messages both sent and received by the sender .
– Reply traffic features : These features provide relative counts ( expressed as percentages ) of messages sent as reply messages , either by or to the sender . We also keep a feature indicating the ratio between the number of messages that the sender sent to users , and the number of messages it received from the mail users of our service .
• Conditioned sender traffic features : These features represent various types of sender traffic information , conditioned by certain attributes . They include :
– Sender traffic , conditioned by action : Given a sender , this feature provides the total and relative counts ( across the entire dataset ) of sent messages that triggered a specific action .
– Sender traffic , conditioned by textual content : Given a sender , this feature provides the total and relative counts of sent messages that include some specific words in their body . Examples of such words are "unsubscribe" ,
"free" , "delivered" , etc , which are with high probability indicators of message types such as newsletters , promotions , purchases etc . These terms were manually chosen as the 50 most frequent words in the sender ’s messages ( stop words not included ) .
– Sender mass traffic : Given a sender , this feature provides the total and relative counts of the messages sent by the sender to more than one recipient .
– Sender burst traffic : Given a sender , this feature provides the relative count of messages sent by the sender in a burst . A burst corresponds to messages with identical subject , send over a small time interval . We have observed that bursts are quite frequent among mass senders of machine generated email ( for promotion campaigns for instance ) .
Finally , we add for every sender a global semantic feature , that we refer to as the sender latent category feature . This feature builds upon the work of Grbovic et al . [ 18 ] , which identifies for any message or sender a high level category out of the 6 latent categories that were identified on a large mail dataset . These 6 latent categories are : finance , shopping , social , travel , career , and personal communication . We compute for each sender the latent category using the classification approach described in this work , and associate either one the 6 values or a nil value , if the category cannot be inferred .
5 . VERTICAL HORIZONTAL LEARNING In Sections 3,4 , we described how we generate for each message a vector of features , which later becomes a labelled example , referred to as a sample , with respect to each action . More specifically , for each message mj received by user i , and each monitored action a , we generate either a new positive sample for an observed value y(i , j , a ) = 1 or a negative one for an observed valued y(i , j , a ) = 0 , as per the formalism introduced in Section 3 . Thus , the stream of messages received by the user is transformed into a stream of samples , ordered by time , each sample being created after some time interval . In order to run the learning process efficiently , we divide the stream of samples into small batches , the latest batch comprising the most recent samples . Upon creation of a new batch ( eg , a batch of samples aggregated on a daily basis ) , the learning model is retrained , based on the whole set of samples ( including the samples of the latest batch ) . In the most extreme case , a batch consists of a single message only . This mechanism allows us to support an online learning process ( see [ 30 ] and references therein ) . We build 4 types of predictors , one for each of the actions considered : read , reply , delete , and delete without read . We describe next the vertical and horizontal learning processes , that we have introduced and motivated in Section 3 . 5.1 Vertical Learning
Vertical learning is by definition highly personalized and provides the best results , when enough historical data is available . For each user , the available data varies between the different actions . For example , a user with a heavy personal correspondence performs many replies , but might delete rarely . We thus define the level of activity of each user with respect to each action . Specifically , for a user i and action a , we define ni,a as the number of observed actions of type a performed by the user during the training period . We later demonstrate that unsurprisingly , for users with a large ni,a value , the vertical learning based model performs well and does not have much to gain from the horizontal learning techniques mentioned below . We define “ active users" for action a , as
311 Field Local , ActionIndependent Local , ActionDependent Global , ActionIndependent
Global , ActionDependent
Sender s
# of inbox msg from similar sender s as above , cross action
traffic sent/received by s reply traffic sent to/from s ratio between traffic sent & received by s sender latent category cross action : sender traffic triggering a specific action
Recipients
Sender Domain/IP # of inbox msg from # of inbox msg w/ similar domain/IP as above , cross action − similar recipients as above , cross action sender traffic with similar # of recipients
−
−
Table 4 : Global & Local Features
Subject
Body
# of inbox msg w/ similar subject as above , cross action
# of inbox msg w/ similar body words as above , cross action
sender traffic with similar subject words sender traffic sent as burst − sender traffic with similar body words
− users whose ni,a value is above some action specific threshold , as detailed in Section 52
Vertical learning is performed as follows . For each inbox the model is trained solely based on messages and actions performed by the particular user . Formally , the vertical learning of the model for user i is done by training only on samples associated with the training set of user i . We note that this process is not purely vertical as some of the features ( such as the rate of reply to message sent by a sender ) are global and contain data obtained from different inboxes . For each user and action , we train a personal predictor , by using both positive and negative examples for action a from the user train set . We note that in this model , the labels of the examples corresponding to an action are skewed , since applying an action on a message is much less frequent than not applying the action . One way to address this is to take into consideration the frequency of the action . For each user and action , we use standard logistic regression to train our model , and conduct cross validation [ 19 ] on the models for users with at least 10 positive and 10 negative examples , optimizing for the AUC measure [ 24 ] .
Although vertical learning may suffice for users with sufficient observed history , there will always be a non negligible number of less active users with only a few actions . These include new users with small inboxes , more passive users with a usage rate below the required usage rate mentioned above , and also more active users , who do not equally favor all actions as mentioned in Section 3 . In order to properly handle such users , we introduce a “ horizontal ” learning method . 5.2 Horizontal Learning
The horizontal learning approach is critical to our ability to predict actions for “ all ” users , including those with few samples . We refer to these users as “ light users ” , that is , users with a ni,a value below some threshold . We described below how we derive information horizontally from all users across all inboxes . “ Average User" Horizontal Model .
For each action , we train a model with samples from many different inboxes , so as to be able to model an “ average user ” . Using the entire set of message across these multiple users , we create for each action an average inbox based on a set of examples . Each such inbox is created using a set of samples counting about 10 , 000 positive and 10 , 000 negative examples , respectively representing messages that did or did not trigger the action . The examples are created by first applying a uniform sampling over the users , and then applying a uniform sampling over their messages . An average user predictor is then trained for each action , based on the average inbox of the considered action . "Latent User type" Horizontal Model .
The idea here to cluster users into a small number of latent types . This is done by computing the personal predictors of all users having a rich dataset for the considered action , and clustering these predictors according to their coefficient vectors . More specifically , for each action a , we choose about 2 , 500 users who have more than 100 positive and 100 negative examples in their dataset ( see Section 22 ) We train a personal predictor for each user i and each action a using vertical learning , getting as output the coefficient vector wi a . Then , we cluster these coefficient vectors using the k means++ implementation [ 4 ] , with standard methods for model selection , resulting in 8 clusters . For each cluster , a latent type predictor is computed , with a coefficient vector equal to the center of the corresponding cluster . The assumption is that the personal predictor of a user will typically be close to the predictor of its corresponding latent type . This way , a prior is learned for each type of user , later to be used in the regularization process . Regularization .
A classic regularization process in the context of linear classifiers can be described as follows : We learn a coefficient vector w while minimizing
Ex,y [ Loss(w , x , y ) ] + λw
Here , Loss(w , x , y ) describes the loss inferred by choosing a vector w for example x with label y , w describes the norm of w ( can be set to L1 or L2 ) and λ is a regularization parameter . In the specific case of Logistic regression we have ( for y ∈ {−1 , 1} ) Loss(w , x , y ) = log
1 + eyw,x
.
We apply two types of regularization depending on the type of users .
1 . A user i is said to be active with respect to action a if ni,a , the number of observed examples of the action in the corresponding training set not less than some threshold τ . A global optimization using a grid search over the user pool led us to set τ = 23 . For active users , we define their latent type according to the cluster to which they belong with respect to k means ( determined by the minimum distance between the coefficient vector of their personal predictor and the coefficient vector of the latent type predictor ) . The regularization is performed using their distance from the latent type predictor . That is , the optimization function in the training process is set to
Ex,y [ Loss(w , x , y ) ] + min w0∈C
λ(ni,a)w − w0 .
( 1 )
Here , C is the set of coefficient vectors corresponding to latent predictors , and the norm used is the L2 norm . The regularization coefficient λ was set as λ(ni,a ) = α · n −β i,a where α , β are hyper parameters . An optimization for α , β via a grid search over the training data yielded α = 5 , β = −04 Notice that the weight of the regularization term decreases with the number of positive examples in the training set .
2 . For light users , ie users with ni,a < τ , we do not have enough data to compute their latent types , thus regularization
312 is performed using the average user predictor only . Specifically , the optimization target in the training phase is defined as
( ni,a)w − wAvg ,
Ex,y [ Loss(w , x , y ) ] + λ
( 2 ) where wAvg is the coefficient vector of the average user predictor . For the regularization coefficient λ , we use the same −β technique of setting λ(ni,a ) = α · n i,a . The optimization of α , β yielded α = 6 , β = −05
5.3 Relation with Transfer Learning
There are several pieces of work that relate to the learning framework we suggest , mainly with respect to horizontal learning , which transfers actions behavior across users . The umbrella area is called transfer learning [ 27 ] , and focuses on problems , for which a solution in one domain can be exploited in another domain . More precisely , a source dataset XS , yS and a target dataset XT , yT are being considered . The sets XS and XT contain feature vectors drawn from distribution DS,DT , respectively . The labels distribution of yS and yT are assumed to be dominated by p(y|x , λS ) and p(y|x , λT ) respectively , where some connection between λT , λS exists .
Several subproblems are defined in the context of transfer learning . In the covariate shift problem [ 31 ] , it is assumed that λT = λS but the distributions generating XS and XT are different . This is not a reasonable assumption in our case as it translates to the assumption that all users demonstrate the same behavior for the same inbox . The works of [ 10 , 17 ] discuss cases in which λT = λS . The assumptions we are familiar with can be split into two types . The first type assumes that λS and λT are sufficiently close , hence using a regularization that pulls towards λS can benefit the learning process in the target data2 . The second type assumes that despite the different distributions , there exists a single classifier achieving a sufficiently good performance on both the source and destination datasets .
Our application can be considered as an extension to the first type of assumption . We do not have a single source dataset , but rather many ( eg , all the users other than the one being handled ) , and we assume that all of the λ ’s are close in the sense that they are all drawn iid from a distribution of distributions . Our assumption regarding the process for generating the different λ coefficients is the following . First , since we use a linear model , we assume that for each user i and sample x , y is a Bernoulli random variable ( assuming labels in {0 , 1} ) whose expected value is determined by wi , x , where wi is some unknown vector associated with user i . The iid assumption regarding the λi ’s translates to assuming that all wi are drawn iid according to some unknown distribution D . Our assumption of having a handful of latent user types translates into assuming that D is ( close to ) a mixed gaussian distribution . Keeping this assumption in mind , one can imagine two possible scenarios when learning a model for user i . In one setting , user i has a light activity level and it is not possible to predict , with sufficiently high confidence , the component of the mixture distribution from which it is derived . In this case , we perform a regularization using the average user predictor . On the other hand , when user i has a sufficient number of observed examples , it is possible to determine its associated component with high probability , hence we regularize the learning process with the latent user predictor .
The benefits of this approach is demonstrated in Figure 3 . The figure depicts two examples of users i and k . User i is a light user , for whom we do not have many examples . Therefore , for user i , our 2We note that using a custom made regularization is not the only method to exploit the fact that λS , λT are close
Figure 3 : Average User & Latent User type Regularizations estimation wi of w∗ i ( the true linear function associated with user i ) is too far in order to determine its latent type ( ie , component in the mixture distribution ) . For that reason , a regularization according to the average predictor , ie using ˆwi , yields better results then those obtained by performing a regularization using the latent type . For user k however , the number of observed examples is larger , and our approximation wk of w∗ k is more precise . We are able to determine the latent type of user k , and use it for regularization in order to yield better results , as will be verified in our experiments .
6 . EXPERIMENTS
In this section we describe the large scale experiments we carried on Yahoo mail data . The dataset we used for the experiments is described in Section 2 , and we describe here the models we ran , as well as the results we achieved .
As described in Section 5 , we divided each inbox in our dataset into a train and a test dataset , based on time . We evaluated 4 action predictors introduced in Section 5 : read , reply , delete , and deletewithout read , separately . For every user i , and action a we learned 3 different predictors : ( 1 ) a personal predictor , ( 2 ) an average user predictor , and ( 3 ) a latent type predictor . Predictor ( 1 ) ignores the horizontal learning part and is trained solely based on the samples of user i . Predictor ( 2 ) uses regularization according to the average user model . Predictor ( 3 ) is built from the model described in Section 5 , choosing the regularization method according to the number of observed samples for user i and action a .
For each predictor , action and user , we computed precision and recall values , using as ground truth the actual actions taken by the user in the test set . We then averaged them over all users . Formally , for user i , predictor type t ( with t indicating the previously defined predictor type ) , action a , and recall value R ( R ∈ [ 0 , . . . , 100] ) , we compute the precision at R for the predictor of type t , action a and user i , and denote it as P ( R , t , a , i ) . We set the precision at R score of predictor type t and action type a as Ei[P ( R , t , a , i) ] , the expected value over all users . The area under the curve ( AUC ) score associated to an action type a and predictor t is formally defined the average ( over recall values ) precision of the action wrt the predictor ( Ei,R[P ( R , t , a , i)] ) .
In order to best demonstrate the effectiveness of the regularization methods , for each action we consider only users with a low activity level . Specifically , users with fewer than 70 actions observed in the training period . We recall here that users with such low activity are not at all rare , even for the more common actions ( see Section 2 , Figure 2 ) . The reason is that with over 70 actions ,
313 all 3 predictors performed similarly ; this is due to the ( somewhat unsurprising ) fact that with a rich training set the regularization has a smaller impact . A comparison of the prediction types is given in Table 5 . It lists the AUC score associated with every pair of predictor t and action a , where the users being considered are those with the above defined low activity level .
For these users , we can see the benefit of the regularization techniques ( average user based , latent user type based ) . Although the regularizations did not provide a substantial improvement for all action types ( for example , the delete and delete without read are insignificant ) , we see that for some actions the improvement is quite significant . For the reply action , we observe a lift of 32 % using the average user based regularization , and a lift of 48 % for the latent user type regularization ( such an improvement could have a significant impact on these users specifically , pointing out their small set of “ actionable" messages ) . For the read action , the lift is not as substantial but is significant nevertheless .
Action
Read
Reply
Delete
Vertical Avg . User Latent Type
0.228 0.236 0.248
0.204 0.269 0.302
0.121 0.127 0.13
Delete without Read 0.104 0.103 0.104
Table 5 : AUC values per operation per model , averaged over users with a low activity level
To realize the effect of the activity level of a user on the performance of the prediction task we measured the AUC value for different levels of high activity ; the results are given in Figure 4 . For every action type , we measured the AUC score for users with at least X observed actions in the training period for X taking several possible values . Since we focused on relatively large values for X ( X ≥ 70 ) we do not present 3 different predictors as they all demonstrate practically the same performance . One can see that at X = 200 , all action AUC score are ( almost ) completely stabilized . ply action , we achieve a precision score of roughly 36 % at recall 90 % . As mentioned in Section 1 , given the inherent difficulty of the task , this result is quite encouraging . Indeed , one could imagine a new mail feature that would put in a same view messages that should be replied to . In such a view , the reply link would achieve a CTR value of 30 % , as compared to the 9.52 % CTR that can be observed in an average inbox of such users today , as reported in Table 2 . This shows an improvement of 200 % for the reply action for users with more than 200 actions . In any case , we stress that CTR or other types of measures should be applied in accordance to the specific use case and user experience considered . We provide here the “ backend system" for analyzing and predicting users’ actions , which would enable the support of such experiences .
The full list of precision values for a recall of 90 % is reported in Table 6 . We use as baseline the average success of a constant predictor , predicting that the action will always be performed ( 100 % recall ) . This is in fact a naive baseline when targeting a high recall , which corresponds to Table 2 . Using this baseline over users with more than 200 actions , the increase achieved for our actions can be seen in Table 6 . For read , which is another notable action , we demonstrated an increase from 20.2 % to 379 %
Figure 5 : Precision Recall active users . For each action , the precision recall curve is averaged over users with more than 200 observed positive samples
Action
Read
Reply
Delete
Delete without Read
Baseline Prec@90 %
20.2 % 9.52 % 20.29 % 19.76 % 37.9 % 37 % 41.6 %
36.3 %
Table 6 : Comparison with baseline for users with more than 200 actions
Figure 4 : Area Under the Curve vs . minimum observed samples in the training set . The x axis is a minimum threshold for the number of observed positive samples in the training set . The y axis is the AUC score for each action , averaged over all users with at least x observed positive samples in their training set .
We paid special attention to highly active users , with more than 200 observed positive samples in the training set ( ni,a ≥ 200 ) , since they would benefit most from predicting actions . Figure 5 shows several precision/recall plots for them . As stated before , we are interested in the case of high recall . We see that for the re
7 . RELATED WORK
The problem of studying user ’s actions on messages is not new . It was traditionally conducted in a relative small scope , either leveraging the Enron corpus [ 21 ] , a small set of monitored users , or users’ studies , surveys , etc . The Enron corpus was used by numerous researchers as the basis for learning and predicting reply actions , by leveraging various email exchange features [ 11 , 5 , 26 , 29 ] . Another approach was to track the actions of a small number of users . Thus in [ 9 ] , the inboxes of 6 enterprise mail users were monitored in order to investigate the characteristics of an email message likely to be discarded . Dabbish et al . [ 8 ] investigated the more general task of predicting actions , as we do here , but their work
314 was solely based on data obtained from the answers of a survey they conducted over 124 college students . The latter voluntarily reported data pertaining to message content , sender characteristics , communication frequency , etc . Using the same approach of considering few inboxes but focusing on different features ( eg , user profile , identity of recipients and sender , different natures of content ) , Dredze et al . [ 13 , 14 ] developed a predictor for reply action , evaluating their results on 2 4 inboxes of graduate students . Tyler et al . [ 33 ] identified several factors that may influence the likelihood of response using an empirical study generally based on interviews . The replying behavior of users was investigated by Kooti et al . [ 22 ] . They focused on the various factors affecting reply time and length , on the influence of email overload , as well as on the synchronization of these reply characteristics in threads . The work presented in [ 22 ] is specific to the reply behavior only , which is deeply investigated . Users however are not differed with respect to their activity level , nor are other operations considered . To the best of our knowledge , the only piece of work that studied a wide range of actions over Web mail , as we do , is the work by Aberdeen et al . [ 1 ] on Gmail priority inbox . The distinction between enterprise or small organization email prediction and Web email is critical since , as mentioned before , they drastically differ , not only in size , but in nature of traffic and behavior . In Gmail priority inbox , the notion of importance is based on the probability that a user will perform an action on a message , where the set of actions include actions such as reply , open , forward etc . We significantly differ from this work , as we intentionally ignore inferred importance and focus on predicting actions as the task at hand . Another distinction between our work and that of [ 1 ] is in the mix of the vertical and horizontal learning . In [ 1 ] , a standard approach in which the vertical learning learns the difference between the user ’s model from the global model , learned separately in a horizontal learning phase . Here we use a problem specific approach , exploiting a hidden cluster like structure of the users’ behavioral patterns in order to best incorporate the weights learned horizontally to those learned vertically , as detailed in Section 5 .
Less directly related to our work here is the large amount of literature around spam classification , such as [ 6 , 34 , 32 ] ) or email organization , tagging or classification . In the area of spam classification , two pieces of work are worth noting . One is the early work by Taylor [ 32 ] , who described how sender reputation has been leveraged in Gmail antispam filter . Like in our case , Taylor described methods that that are highly scalable and deal with mass senders . Another is the work by Bickel et al . [ 6 ] , who applied as we do transfer learning on email , but for a different task namely spam filtering . The authors assume that each user ’s inbox is parameterized by a single ( numeric ) parameter coming from a different distribution . Given this parameter , the model of the label ( ie , p(y|x ) where x ∈ X represents the message and y represents the label namely , spam or ham ) is common to all inboxes .
In the area of mail organization , various classification methods have been proposed in different contexts . Klimt et al . [ 21 ] learned from individual inboxes in order to automatically assign messages to user defined folders . Other methods for organizing a user ’s inbox , too numerous to exhaustively cite here , leveraged rule based , information retrieval or machine learning methods , see as examples [ 3 , 7 , 12 , 20 ] . Two pieces of work ( co authored by some of the authors on this paper ) worth noting in this area , are the studies by Koren et al . [ 23 ] , and Grbovic et al . [ 18 ] on Yahoo mail data . The first [ 23 ] , proposed a classification method based on learning the most popular folders from the entire set of users , and introduced the notion of horizontal and vertical learning for email , which we endorse her . The other [ 18 ] , described an approach for distinguishing between personal and machine generated email , and for classifying messages into latent categories , which also influenced this work . 8 . CONCLUSION
Based on a thorough study of users actions in Yahoo mail , we presented here a novel approach for predicting users’ actions on newly received messages . Unlike some recent work that attempted to infer the message importance from user ’s activities , we intentionally decided to go back to the basics and focus on the actions themselves . We considered the most frequent actions , namely read , reply , delete , and a sub type of delete , delete without read . We formalized the task of “ actionable email prediction ” , and defined a learning framework that takes advantage of the size and nature of large scale Web mail . More specifically we introduced both local ( ie , inbox specific ) and global ( ie , at the mail population level ) features to represent messages , and devised “ vertical ” and “ horizontal ” methods to train and predict actions for all types of users . We verified that the quality of our vertical learning for action prediction on an individual inbox was highly dependent on the level of activity of the user for this action . Consequently , we complemented our vertical learning with horizontal learning for regularization purposes . To this effect , we defined two majors action specific types of users according to their activity level for this action , namely “ light ” and “ active ” users . For light users , we applied a regularization method based on an “ average user ” horizontal model for each action . For more active users , our regularization method leveraged a “ latent user type ” horizontal model , which allows to model the behavior of a representative user of the same latent type . One clear benefit of this hybrid approach is that it allows to predict actions for all types of users , across numerous types of behavior , i.e , users who read and delete a lot but don’t reply much , or users who reply a lot but never delete , etc .
We conducted a large scale experiment on data from Yahoo mail , building predictors for each type of action . Each predictor was trained both for active and light users . As expected the best performance was obtained on more active users , yet we showed that horizontal learning could compensate for the lack of data . For users with a high level of activity , we showed that for recall values of 90 % we can predict important actions such as read or reply at precision levels of close to 40 % . A possible exploitation of our results would be to offer for instance a view of the messages a user should reply to . In this view , the reply link would achieve a CTR value of 30 % , as compared to the 9.52 % CTR that can be observed in an average inbox of such users today , leading to an improvement of 200 % . For users with a low activity level , we showed that our horizontal based regularization methods achieve a significant increase in the AUC measure for most types of operations : the reply operation for example reached a lift of up to 48 % .
To the best of our knowledge , our work is the first to provide a unified framework of this scale for predicting multiple actions on Web email , which hopefully provides a new ground for inventing new user experiences to help users process their inboxes . 9 . REFERENCES [ 1 ] D . Aberdeen , O . Pacovsky , and A . Slater . The learning behind gmail priority inbox . In LCCC : NIPS 2010 Workshop on Learning on Cores , Clusters and Clouds . Elsevier , 2010 . [ 2 ] N . Ailon , Z . Karnin , E . Liberty , and Y . Maarek . Threading machine generated email . In Proceedings of WSDM’2013 , pages 405–414 , New York , NY , USA , 2013 .
[ 3 ] I . Alberts and D . Forest . Email pragmatics and automatic classification : A study in the organizational context . JASIST , 63(5):904–922 , 2012 .
315 [ 4 ] D . Arthur and S . Vassilvitskii . k means++ : The advantages of careful seeding . In Proceedings of SODA’2007 , New Orleans , LA , Jan 2007 .
[ 5 ] T . Ayodele and S . Zhou . Applying machine learning techniques for e mail management : solution with intelligent e mail reply prediction . Journal of Engineering and Technology Research , 1(7):143–151 , 2009 .
[ 6 ] S . Bickel and T . Scheffer . Dirichlet enhanced spam filtering based on biased samples . Advances in neural information processing systems , 19:161 , 2007 .
[ 7 ] W . Cohen . Learning rules that classify e mail . In AAAI Spring Symposium on Machine Learning in Information Access , pages 18–25 , 1996 .
[ 8 ] L . Dabbish , R . Kraut , S . Fussell , and S . Kiesler .
Understanding email use : predicting action on a message . In Proceedings of CHI’2005 , Portland,OR , Apr 2005 .
[ 9 ] L . A . Dabbish , G . Venolia , and JJ Cadiz . Marked for deletion : An analysis of email data . In Proceedings of CHI’2003 , Fort Lauderdale , FL , Apr 2003 .
[ 10 ] H . Daumé III . Frustratingly easy domain adaptation . arXiv preprint arXiv:0907.1815 , 2009 .
[ 11 ] P . Deepak , D . Garg , and V . Varshney . Analysis of enron email threads and quantification of employee responsiveness . In Workshop on Text Mining and Link Analysis , 2007 .
[ 12 ] Y . Diao , H . Lu , and D . Wu . A comparative study of classification based personal e mail filtering . In Proceedings of PAKDD’2000 , Kyoto , Japan , Apr 2000 .
[ 13 ] M . Dredze , J . Blitzer , and F . Pereira . Reply expectation prediction for email management . In Proceedings of CEAS’2005 , Stanford , CA , Jul 2005 .
[ 14 ] M . Dredze , T . Brooks , J . Carroll , J . Magarick , J . Blitzer , and
F . Pereira . Intelligent email : Reply and attachment prediction . In Proceedings of IUI’2008 , Canary Islands , Spain , Jan 2008 .
[ 15 ] J . Duffy . Google inbox for gmail ( for iphone ) . PC Magazine ,
Oct 2014 .
[ 16 ] S . Dumais , E . Cutrell , JJ . Cadiz , G . Jancke , R . Sarin , and
DC . Robbins . Stuff I’ve seen : A system for personal information retrieval and re use . In Proceedings of SIGIR , pages 72–79 , Toronto , Canada , 2003 .
[ 17 ] T . Evgeniou and M . Pontil . Regularized multi–task learning .
In Proceedings of KDD’2004 , Seattle , WA , Aug 2004 .
[ 18 ] M . Grbovic , G . Halawi , Z . Karnin , and Y . Maarek . How many folders do you really need ? classifying email into a handful of categories . In Proceedings of CIKM’2014 , 2014 .
[ 19 ] T . Hastie , J . Friedman , and R . Tibshirani . The elements of statistical learning : Data Mining , Inference , Prediction , volume 2 . Springer , 2009 .
[ 20 ] S . Kiritchenko and S . Matwin . Email classification with co training . In Proceedings of the 2011 Conference of the Center for Advanced Studies on Collaborative Research , pages 301–312 , 2011 .
[ 21 ] B . Klimt and Y . Yang . The enron corpus : A new dataset for email classification research . In Proceedings of ECML’2004 , Pisa , Italy , Sep 2004 .
[ 22 ] F . Kooti , LM Aiello , M . Grbovic , K . Lerman , and
A . Mantrach . Evolution of conversations in the age of email overload . In Proceedings of the 24th International Conference on World Wide Web , WWW ’15 , pages 603–613 , 2015 .
[ 23 ] Y . Koren , E . Liberty , Y . Maarek , and R . Sandler .
Automatically tagging email by leveraging other users’ folders . In Proceedings of KDD’2011 , San Diego , CA , Aug 2011 .
[ 24 ] CD Manning , P . Raghavan , and H . Schütze . Introduction to information retrieval , volume 1 . Cambridge university press Cambridge , 2008 .
[ 25 ] Derek Mead . Aol ’s new alto client is visual email , and you don’t need a new address . MotherBoard , Oct 2012 . [ 26 ] B . On , E . Lim , A . Purandare , and L . Teow . Mining interaction behaviors for email reply order prediction . In Proceedings of ASONAM’2010 , pages 306–310 , 2010 .
[ 27 ] SJ Pan and Q . Yang . A survey on transfer learning . IEEE
Transactions on Knowledge and Data Engineering , 22(10):1345–1359 , 2010 .
[ 28 ] P . Resnick . Internet message format , rfc 5322 , October 2008 . [ 29 ] M . Sappelli , S . Verberne , and W . Kraaij . Combining textual and non textual features for e mail importance estimation . In Proceedings of the 25th Benelux Conference on Artificial Intelligence , 2013 .
[ 30 ] S . Shalev Shwartz . Online learning and online convex optimization . Foundations and Trends in Machine Learning , 4(2):107–194 , 2011 .
[ 31 ] H . Shimodaira . Improving predictive inference under covariate shift by weighting the log likelihood function . Journal of statistical planning and inference , 90(2 ) , 2000 . [ 32 ] B . Taylor . Sender reputation in a large webmail service . In Proceedings of CEAS’2006 , Mountain View , CA , Jul 2006 .
[ 33 ] J . Tyler and J . Tang . When can i expect an email response ? a study of rhythms in email usage . In Proceedings of ECSCW’2003 , pages 239–258 , Helsinki , Finland , Sep 2003 .
[ 34 ] WT Yih , R . McCann , and A . Kolcz . Improving spam filtering by detecting gray mail . In Proceedings of CEAS’2007 , Mountain View , CA , Aug 2007 .
316
