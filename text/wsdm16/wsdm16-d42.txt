Collaborative Denoising Auto Encoders for Top N Recommender Systems
Yao Wu
Simon Fraser University Burnaby , BC , Canada wuyaow@sfu.ca
Christopher DuBois
Dato Inc .
Seattle , WA , USA chris@dato.com
Alice X . Zheng
Dato Inc .
Seattle , WA , USA alicez@dato.com
Martin Ester
Simon Fraser University Burnaby , BC , Canada ester@cssfuca
ABSTRACT Most real world recommender services measure their performance based on the top N results shown to the end users . Thus , advances in top N recommendation have far ranging consequences in practical applications . In this paper , we present a novel method , called Collaborative Denoising Auto Encoder ( CDAE ) , for top N recommendation that utilizes the idea of Denoising Auto Encoders . We demonstrate that the proposed model is a generalization of several well known collaborative filtering models but with more flexible components . Thorough experiments are conducted to understand the performance of CDAE under various component settings . Furthermore , experimental results on several public datasets demonstrate that CDAE consistently outperforms state of the art top N recommendation methods on a variety of common evaluation metrics .
Categories and Subject Descriptors H33 [ Information Search and Retrieval ] : Information Filtering
Keywords Recommender Systems ; Collaborative Filtering ; Denoising AutoEncoders
1 .
INTRODUCTION
In recent years , recommender systems have become widely utilized by businesses across industries . Given a set of users , items , and observed user item interactions , these systems can recommend other items that the users might like . Personalized recommendation is one of the key applications of machine learning in e commerce and beyond . Many recommendation systems use Collaborative Filtering ( CF ) methods to make recommendations . In production , recommender systems are often evaluated based on the performance of the top N recommendations , since typically only a few recommendations are shown to the user each time . Thus , top N recommendation methods are of particular interest .
In this paper , we present a new model based collaborative filtering ( CF ) method for top N recommendation called Collaborative
Denoising Auto Encoder ( CDAE ) . CDAE assumes that whatever user item interactions are observed are a corrupted version of the user ’s full preference set . The model learns latent representations of corrupted user item preferences that can best reconstruct the full input.1 In other words , during training , we feed the model a subset of a user ’s item set and train the model to recover the whole item set ; at prediction time , the model recommends new items to the user given the existing preference set as input . Training on corrupted data effectively recovers co preference patterns . We show that this is an effective approach for collaborative filtering .
Learning from intentionally corrupted input has been widely studied . For instance , Denoising Auto Encoders [ 24 ] train a one hiddenlayer neural network to reconstruct a data point from the latent representation of its partially corrupted version . However , to our best knowledge , no previous work has explored applying the idea to recommender systems .
CDAE generalizes several previously proposed , state of the art collaborative filtering models ( see Section 32 ) But its structure is much more flexible . For instance , it is easy to incorporate nonlinearities into the model to achieves better top N recommendation results . We investigate the effects of various choices for model components and compare their performance against prior approaches on three real world data sets . Experimental results show that CDAE consistently outperforms state of the art top N recommendation methods by a significant margin on a number of common evaluation metrics .
Our contributions can be summarized as follows : • We propose a new model CDAE , which formulates the topN recommendation problem using the Auto Encoder framework and learns from corrupted inputs . Compared to related methods , CDAE is novel in both model definition and objective function .
• We demonstrate that CDAE is a generalization of several state of the art methods but with a more flexible structure . • We conduct thorough experiments studying the impact of the choices of different components in CDAE , and show that CDAE outperforms state of the art methods on three real world data sets .
The rest of the paper is organized as follows . Section 2 provides the problem definition , background , and useful notations . Section 3 describes our proposed model and learning algorithm in detail . We
1 We follow the typical top N recommendation setup and consider only user item interaction data in this paper . Handling of additional data , such as user/item features and contextual information , is left as future work .
153 discuss related work on applying neural network methods to recommender systems in Section 4 . Experimental results for the components analysis and performance comparisons are presented in Section 5 . We conclude with a summary of this work and discussion of future work in Section 6 .
2 . PROBLEM DEFINITION Given a set of users U = {u = 1 , , U} , a set of items I = {i = 1 , , I} , and a log of the users’ past preferences of items O = ( u , i , yui ) , our goal is to recommend to each user u a list of items that will maximize her/his satisfaction . In many cases , the log contains only implicit feedback where all the yui are 1 ; the rest of the triples are assumed missing . We use ¯O to denote the set of unobserved , missing triples , and O an augmented user item pairs dataset that includes some data sampled from ¯O . ( We discuss O in more detail in the subsection on objective functions . ) Let Ou denote the set of item preferences in the training set for a particular user u , and ¯Ou the unobserved preferences of user u . Items in ¯Ou are the candidates to be recommended to user u . The goal of the recommender is to pick for each user u a subset of items from the candidate set , the predicted values of which are most likely to be 1 . In some cases , yui are numeric ratings in the range of , say , [ 1 , 5 ] or binary values {0 , 1} . For simplicity , we only consider the case of implicit feedback in this paper . Numeric ratings can be handled with slight modifications to our method .
In the rest of the paper , we use u to index a user , and i and j to index items . Vectors and matrices are denoted by bold symbols , where symbols in lower case ( eg , x ) represent vectors and symbols in upper case ( eg , X ) represent matrices . Unless stated differently , xi also represents a vector where i is used to distinguish different vectors . We denote the i th row of matrix X by Xi and its ( i , j) th element by Xij . 2.1 Overview of Model based Recommenders Most machine learning models can be specified through two components : model definition and objective function during training . The model definition formulates the relationship between the input ( eg , user ids , item ids , interactions , other features , etc . ) and output ( ratings or implicit feedback of items ) . The objective function is what the training process optimizes to find the best model parameters . Recommender Models In general , recommender models are defined as
ˆyui = Fθ(u , i ) ,
( 1 ) where ˆyui is the predicted preference of user u on item i , and θ denotes the model parameters we need to learn from training data . Different choices of the function Fθ correspond to different assumptions about how the output depends on the input . Here we review 4 common recommender models . Latent Factor Model ( LFM ) . LFM models the preference ˆyui as the dot product of latent factor vectors vu and vi , representing the user and the item , respectively [ 9 , 17 ] . 2
ˆyui = F LF M v
( u , i ) = v u vi
( 2 )
In addition , hierarchical latent factor models [ 1 , 32 ] and the factorization machine [ 14 ] can model interactions between user or item side features . 2To simplify notation , we assume that the latent factors are padded with a constant to model the bias .
 j∈Ou\{i}
 j∈Ou\{i}


Similarity Model ( SM ) . The Similarity model [ 8 ] models the user ’s preference for item i as a weighted combination of the user ’s preference for item j and the item similarity between i and j . It is a natural extension of an item based nearest neighbor model . The difference is that SM does not use predefined forms of item similarity ( eg , Jaccard , Cosine ) . Instead , it learns a similarity matrix from data [ 12 ] .
ˆyui = F SM
S ( u , i ) = yuj · Sji
( 3 ) j∈Ou\{i}
Factorized Similarity Model ( FSM ) . The problem with the Similarity Model is that the number of parameters is quadratic in the number of items , which is usually impractical . A straightforward solution is to factorize the similarity matrix into two low rank matrices [ 8 , 7 ] .
ˆyui = F F SM p,q
( u , i ) = yuj · pj qi
( 4 )
LFSM ( LFM+FSM ) . The above models can also be combined . For example , combining LFM and FSM results in the model SVD++ [ 8 ] , which proved to be one of the best single models for the Netflix Prize .
ˆyui = F LF SM p,q
( u , i ) = yuj · pj + pu qi
( 5 )
Objective Functions for Recommenders Objective functions for training recommender models can be roughly grouped into two groups : point wise and pair wise.3 Pair wise objectives approximates ranking loss by considering the relative order of the predictions for pairs of items . Point wise objectives , on the other hand , only depend on the accuracy of the prediction of individual preferences . Pair wise functions are usually considered to be more suitable for optimizing top N recommendation performance . However , as we demonstrate in our experiments , this is not necessarily the case for all data sets .
Regardless of the choice of a pair wise or point wise objective function , it is critical to properly take into account unobserved feedback within the model . Models that only consider the observed feedback fail to account for the fact that ratings are not missing at random . These models are not suitable for top N recommenders [ 13 , 23 ] . Let ( · ) denote a loss function and Ω(θ ) a regularization term that controls model complexity and encodes any prior information such as sparsity , non negativity , or graph regularization . We can write the general forms of objective functions for recommender training as follows . Point wise objective function . point(yui , ˆyui ) + λΩ(θ ) .
( 6 )
( u,i)∈O
Here O denotes an augmented dataset that includes unobserved user item pairs . The problem with using only observed user item pairs is that , when users provide only implicit “ like ” s without explicit ratings , all the observed values yui are equal to 1 . In this case , directly optimizing the point wise objective function over O leads 3Some models use list wise objective functions [ 28 , 22 ] , but they are not as widely adopted as point wise and pair wise objectives .
154 Table 1 : Overview of related model based recommenders .
Name MF [ 9 ] / PMF [ 17 ] SVD++ [ 8 ] MMMF [ 16 ] WSABIE [ 29 ] BPR MF [ 15 ] SLIM [ 12 ] FISM [ 7 ] WRMF [ 6 ] COFI [ 28 ] CLIMF [ 21 ]
Model Objective Function LFM SL point LFSM SL point LFM HL point LFM HL pair LFM LL pair SM SL point FSM point , SL SL pair weighted SL LFM LFM NDCG loss MRR loss LFM point to a trivial model that predicts all the ratings as 1.4 A common solution is to augment O with a subset of negative user item pairs5 from the unobserved set ¯O = {U × I} \ O , and train the model on the augmented set O . Several strategies for sampling negative user item pairs are discussed in [ 13 ] . O can also include duplicate samples to simulate weighted feedback ( eg , [ 6] ) . Pair wise objective function . pair(yuij , ˆyuij ) + λΩ(θ ) ,
( 7 )
( u,i,j)∈P where yuij = yui − yuj , ˆyuij = ˆyui − ˆyuj , and P is a set of triplets sampled from O , each of which includes a user u and a pair of items i and j , where usually i is a positive item and j is a negative item .
For both pair wise and point wise objective functions , the choice of the loss function ( · ) is important . Here we list a few commonly used loss functions for both point wise and pair wise objectives :
2 ( y − ˆy)2 ;
• SQUARE LOSS : SL(y , ˆy ) = 1 • LOG LOSS : LL(y , ˆy ) = log(1 + exp(−y · ˆy) ) ; • HINGE LOSS : HL(y , ˆy ) = max(0 , 1 − y · ˆy ) ; • CROSS ENTROPY LOSS : CE(y , ˆy ) = −y log(p ) − ( 1 − y ) log(1 − p ) , where p = σ(ˆy ) = 1/(1 + exp(−ˆy) ) .
Note that , for LOG and HINGE losses , the value y for the negative examples should be −1 instead of 0 .
Table 1 summarizes recent models for top n recommendation that fit this framework . For explicit feedback , the loss function can be slightly different ( eg,[11 ] ) Also , several recent papers study position aware pair wise loss functions ( eg , WARP [ 29 , 30 ] , CLiMF [ 21] ) . For this paper , we do not propose any new objective functions . Any objective function that fits the described framework can be used with our model .
To summarize , the two key components of designing modelbased recommenders are : 1 ) a suitable way to represent the relations between inputs and outputs . 2 ) a proper objective function and a proper way to deal with the relationship between observed and unobserved feedback . 2.2 Denoising Auto Encoders A classical auto encoder [ 2 ] is typically implemented as a onehidden layer neural network that takes a vector x ∈ RD as input 4For explicit feedback data , only modeling observed feedback is also insufficient to make good top N recommendations [ 13 , 23 ] . 5Here we use the term negative to denote missing feedback . and maps it to a hidden representation z ∈ RK through a mapping function z = h ( x ) = σ
W x + b
, where W is a D × K weight matrix and b ∈ K is an offset vector . The resulting latent representation is then mapped back to a reconstructed vector ˆx ∈ RD through
ˆx = σ,W
. z + b
The reverse mapping may optionally be constrained by tied weights , where W = W .
The parameters of this model are trained to minimize the average reconstruction error : n i=1 arg min W ,W ,b,b
1 n
( xi , ˆxi ) ,
( 8 ) where is a loss function such as the square loss or the cross entropy loss mentioned in the previous subsection .
The Denoising Auto encoder ( DAE ) [ 24 ] extends the classical auto encoder by training to reconstruct each data point x from its ( partially ) corrupted version ˜x . The goal of DAE is to force the hidden layer to discover more robust features and to prevent it from simply learning the identity function [ 24 ] . The corrupted input ˜x is typically drawn from a conditional distribution p( ˜x|x ) . Common corruption choices are the additive Gaussian noise and the multiplicative mask out/drop out noise . Under mask out/drop out corruption , one randomly overwrites each of the dimensions of x with 0 with a probability of q :
P ( ˜xd = δxd ) = 1 − q
P ( ˜xd = 0 ) = q
( 9 )
To make the corruption unbiased , one sets the uncorrupted values to δ = 1/(1 − q ) times their original value .
3 . PROPOSED METHODOLOGY
In this section , we introduce a new model–Collaborative Denoising Auto Encoder ( CDAE ) . The model learns correlations between the user ’s item preference by training on a corrupted version of the known preference set . A preference set is binary , ie , containing only information about whether an item is preferred or not . Therefore , as we will see , CDAE is uniquely suitable for top N preference recommendations . 3.1 Collaborative Denoising Auto Encoder
Similar to the standard Denoising Auto Encoder , CDAE is also represented as a one hidden layer neural network . The key difference is that the input also encodes a latent vector for the user , which allows CDAE to be a much better recommender model , as we see in section 5 . Figure 1 shows a sample structure of CDAE . CDAE consists of 3 layers , including the input layer , the hidden layer and the output layer .
In the input layer , there are in total I + 1 nodes , where each of the first I nodes corresponds to an item , and the last node is a userspecific node ( the red node in the figure ) , which means the node and its associated weights are unique for each user u ∈ U in the data . We refer to the first I nodes as item input nodes , and the last node as user input node . Given the historical feedback O by users on the item set I , we can transform O into the training set containing U instances {y1 , y2 , , yU} , where yu = {yu1 , yu2 , , yuI} is the I dimensional feedback vector of user u on all the item in I . yu is a sparse binary vector that only has |Ou| non zero values : yui = 1 if i is in the set Ou , otherwise , yui = 0 .
155 Algorithm 1 Learning algorithm for CDAE
Initialize parameters with random values . iter ← 0
3 : while iter < maxIter or error on validation set decreases do for all u ∈ U do
Sample ˜yu ∼ p( ˜yu|yu ) using Equation 9 . Compute zu using Equation 10 . Sample negative samples Su ⊂ ¯Ou . for all i ∈ Ou ∪ Su do
Update W i and b i using Equation 14 , 15 and 20 . end for Compute ∂ for all j ∈ {j|j ∈ I and ˜yuj > 0} do ∂zu Update Wj using Equation 17 and 20 . using Equation 16 . end for Update Vu using Equation 18 and 20 . Update b using Equation 19 and 20 . end for iter ← iter + 1 end while
6 :
9 :
12 :
15 :
18 : put value ˆyui for node i is computed as follows : i zu + b i
W
ˆyui = f
( 11 ) where W ∈ RI×K and b are the weight matrix and the offset vector for the output layer , respectively . f ( · ) is also a mapping function .
,
We learn the parameters of CDAE by minimizing the average reconstruction error : arg min
1 U
U
Ep( ˜yu|yu ) [ ( ˜yu , ˆyu)]+R,W , W
,
, V , b , b u=1
W ,W ,V ,b,b ( 12 ) where R is the regularization term to control the model complexity . In this paper we use the squared L2 Norm . 2 2 + V 2
,W2
( 13 )
2 + b2
2 + W
R ( · ) =
2 + b
2
2
λ 2
We apply Stochastic Gradient Descent ( SGD ) to learn the parameters . Algorithm 1 provides the detailed procedure . Because the number of output nodes equals the number of items , the time complexity of one iteration over all users is O(U IK ) , which is impractical when the number of users and the number of items are large . Instead of computing the gradients on all the outputs , we only sample a subset of the negative items Su from ¯Ou and compute the gradients on the items in Ou ∪ Su . The size of Su is proportional to the size of Ou . So the overall complexity of the learning algorithm is linear in the size of O and the number of latent dimensions K . A similar method has been discussed in [ 5 ] . An alternative solution is to build a Hierarchical Softmax tree on the output layer [ 10 ] , but it requires the loss function on the output layer to be softmax loss .
The gradients for the parameters are as follows :
Figure 1 : A sample CDAE illustration for a user u . The links between nodes are associated with different weights . The links with red color are user specific . Other weights are shared across all the users .
There are K nodes in the hidden layer and these nodes are fully connected to the nodes of the input layer . Here K is a predefined constant which is usually much smaller than the size of the input vectors . The hidden layer also has an additional node to model the bias effects ( the pink node in the figure ) . We use W ∈ RI×K to denote the weight matrix between the item input nodes and the nodes in the hidden layer , and Vu ∈ RK to denote the weight vector for the user input node . Note that Vu is a user specific vector , ie , for each of the users we have one unique vector . From another point of view , Wi and Vu can be seen as the distributed representations of item i and user u respectively .
In the output layer , there are I nodes representing reconstructions of the input vector yu . The nodes in the output layer are fully connected with nodes in the hidden layer . The weight matrix is denoted by W ∈ RI×K . We denote the weight vector for the bias node in the hidden layer by b ∈ RI . Formally , the inputs of CDAE are the corrupted feedback vector ˜yu which is generated from p( ˜yu|yu ) as stated in Equation 9 . Intuitively , the non zero values in yu are randomly dropped out independently with probability q . The resulting vector ˜yu is still a sparse vector , where the indexes of the non zero values are a subset of those of the original vector .
CDAE first maps the input to a latent representations zu , which is computed as follows:6
,
W zu = h
˜yu + Vu + b
( 10 ) where h(· ) is an element wise mapping function ( eg , identity function h(x ) = x or sigmoid function h(x ) = σ(x ) = 1/(1 + e−x) ) , and b ∈ RK is the offset vector .
At the output layer , the latent representation is then mapped back to the original input space to reconstruct the input vector . The out
6 Here we compute the hidden representation using the sum of the weight vectors . Other choices such as concatenation and max pooling are also possible .
∂ ∂zu
=
∂ ∂ ˆyui
∂ ˆyui ∂zu
+ λzu
∂ ∂W i
=
∂ ∂ ˆyui
∂ ˆyui ∂W i
+ λW i
∂ ∂b i
∂ ∂ ˆyui
+ λb i
∂ ˆyui ∂b i
= i∈Ou∪Su
( 14 )
( 15 )
( 16 )
˜yu1˜yu2˜yu3˜yu4˜yu5UserNodeBiasNodeyu1yu2yu3yu4yu5HiddenLayerInputLayerOutputLayer156 Table 2 : Sample Mapping Functions . Note that all the operations in this table are element wise .
Identity Sigmoid
Tanh h(x ) x
σ(x ) tanh(x )
Gradient ∂h ∂x
1
σ(x)(1 − σ(x ) )
1 − tan2(x )
∂ ∂Wj
=
∂ ∂zu
∂zu ∂Wj
+ λWj
∂ ∂Vu
∂ ∂b
=
=
∂ ∂zu
∂zu ∂Vu
∂ ∂zu
∂zu ∂b
+ λVu
+ λb
( 17 )
( 18 )
( 19 )
We apply AdaGrad [ 4 ] to automatically adapt the step size during the learning procedure . The update formula is as follows :
θ(t+1 ) = θ(t ) −
,
( 20 )
β +t
ηg(t ) θ s=1 g(s )
θ is its gradient at step t . where θ(t ) is the value of the parameter θ at the t th SGD step and g(t ) θ Recommendation . At prediction time , CDAE takes user u ’s existing reference set ( without corruption ) as input , and the items from the candidate set ¯Ou that have largest prediction values on the output layer are recommended to him/her . 3.2 Discussion Components . CDAE is very flexible in that the mapping function h(· ) , point wise or pair wise objectives , the loss function ( · ) , and the corruption probability q can all be chosen to suit the application . Table 2 lists mapping function choices explored in this paper . As for the loss function , all the choices discussed in Section 2.1 , both point wise and pair wise , can be used . Different choices of these functions result in different variants of the model with different representation capabilities . Our experiments show that no single variant always produces the best results . One benefit of the proposed general framework is that one can try several variants and find the one that best fits the task .
It ’s worth noting that pair wise objective does not perform much better than point wise objective for CDAE , at least in our experiments . Similar results have also been reported in [ 7 ] . This may be a characteristic of implicit feedback data . See section 5.4 for more details . Generalization of other models . CDAE is a generalization of latent factor models . The representations mentioned in Section 2.1 can all be interpreted as special cases of this framework .
Specifically , if we choose the identity mapping function for both h(x ) and f ( x ) and not add noise to the inputs , the output value of ˆyui in Equation 11 becomes : i zu + b
ˆyui = f i
W i h
W j∈Ou
= W
∼= W i
˜yu + Vu + b i
+ b
( 21 )
˜yuiWj + Vu
.
In the last step we omit the bias term to make the comparison clearer . We can see that the representation in Equation 21 is equivalent to that in Equation 5 , ie , the LFSM model .
If we set the corruption level q to 1 , all the non zero values in the input vector would be dropped out . We get the following prediction : i Vu ,
ˆyui = W
( 22 ) which is equivalent to the representation in Equation 2 , ie , the LFM model . Alternatively , if we remove the user input node and its associated weights , the resulting model is equivalent to FSM in Equation 4 :
ˆyui = W i
˜yuiWj
.
( 23 ) j∈Ou
Another possible mapping function is the linear function h(x ) = Ux , where U is a K × K transform matrix . If we use a userspecific matrix Uu ∈ RK×K on the hidden layer , the representation becomes
ˆyui = W i u
U
˜yuiWj
,
( 24 ) j∈Ou which is related to the Latent Collaborative Retrieval model proposed in [ 30 ] .
We tried the linear mapping function in our experiments , but found that its performance is not as good as others . One reason is likely that it has many more parameters to estimate , which can easily lead to overfitting . We also experimented with setting Uu to be a diagonal matrix to reduce the number of parameters , but the improvements over the identity were still not significant . With this in mind , we do not include the linear mapping function in Table 2 , nor report the results in the rest of this paper . Summary . CDAE is a flexible framework for top N recommendation . It generalizes several very popular existing methods . The proposed framework is naturally compatible with the denoising trick , which can further improve the results of recommendation , as shown in the next section . 4 . RELATED WORK
An overview of the model based collaborative filter methods has been discussed in Section 21 In this section , we discuss the few related works on neural networks for recommender systems .
Restricted Boltzmann Machines ( RBM ) [ 18 ] is the first work that applies neural network models to recommender systems . However , RBM targets rating prediction , not top N recommendation , and its loss function considers only the observed ratings . It is technically challenging to incorporate negative sampling , which would be required for top N recommendation , into the training of RBM . For this reason , we do not compare with RBM in our experiments , but test several other neural network baselines that work for top N recommendation ( see Section 54 )
We are aware of a concurrent proposal called AutoRec [ 20 ] , which uses the Auto Encoder for rating prediction . The main differences are as follows : 1 ) AutoRec only considers the observed ratings in the loss function , which does not guarantee the performance for top N recommendation . 2 ) They use the vanilla AutoEncoder structure , while we prove that introducing user factors in the model can greatly improve performance . 3 ) AutoRec does not employ the denoising technique , which is a major part of our work . Another related work is [ 27 ] , which also uses the Auto Encoder for recommender systems . This work studies the particular problem of article recommendation , and improves the well known model Collaborative Topic Regression [ 26 ] by replacing its Topic Model component by a Bayesian Auto Encoder , which is used for learning the latent feature representations for the articles . Different from
157 Table 3 : Dataset Statistics
#users 69K 37K 9.6K
#items 8.8K 11K 7K
ML Netflix Yelp
#dyads density( % )
5M 4.8M 243K
0.82 1.18 0.36 this model , our model is a generic model and addresses the general top N recommendation problem , and the inputs are user behaviors instead of item/article features .
5 . EXPERIMENTAL RESULTS
Our experimental evaluation consists of two parts . First , we study the effects of various choices of the components of CDAE . Second , we compare CDAE against other state of the art top N recommendation methods . The source code of CDAE will be available from https://githubcom/jasonyaw/CDAE 5.1 Data Sets and Experimental Setup
We use 3 popular data sets : MovieLens 10M ( ML)7 , Netflix8 and Yelp ( from Yelp Dataset Challenge9 in 2014 ) . For each data set , we keep those with ratings no less than 4 stars and treat all other ratings as missing entries . Those ratings that are retained are converted to a yui score of 1 . This processing method is widely used in previous work on recommendation with implicit feedback ( eg , [ 15 , 31 , 7] ) . We iteratively remove users and items with fewer than 5 ratings . For each user , we randomly hold 20 % of the ratings in the test set , and put the other ratings in the training set . The statistics of the resulting data sets are shown in Table 3 . 5.2 Implementation Details
We perform 5 fold cross validation on the training data sets to select the best hyperparameters for all the models , and then use the best hyperparameters to train models on the whole training data sets .
We use Stochastic Gradient Decent ( SGD ) to learn the parameters for both the proposed method and comparison partners . AdaGrad [ 4 ] is used to automatically adapt the step size during the learning procedures . We set β = 1 and try different step sizes η ∈ {1 , 0.1 , 0.01 , 0.001} and report the best result for each model . For negative sampling , we experiment with different numbers of negative samples and find that N S = 5 consistently produces good results . This means that , for each user , the number of negative samples is 5 times the number of observed ratings of this user . 5.3 Evaluation Metrics
In the case of top N recommender systems , we present each user with N items that have the highest predicted values but are not adopted by the user in the training data . We evaluate different approaches based on which of the items are actually adopted by the user in the test data . Precision and Recall . Given a top N recommendation list CN,rec , precision and recall are defined as
( cid:84 ) Cadopted| ( cid:84 ) Cadopted|
N
,
|Cadopted|
( 25 )
Precision@N =
Recall@N =
|CN,rec |CN,rec
7http://grouplens.org/datasets/movielens 8http://wwwnetflixprizecom 9http://wwwyelpcom/dataset_challenge where Cadopted are the items that a user has adopted in the test data . The precision and recall for the entire recommender system are computed by averaging the precision and recall over all the users , respectively . Mean Average Precision ( MAP ) . Average precision ( AP ) is a ranked precision metric that gives larger credit to correctly recommended items in top ranks . AP@N is defined as the average of precisions N computed at all positions with an adopted item , namely , k=1 Precision@k × rel(k ) min{N,|Cadopted|}
AP@N =
( 26 )
, where Precision(k ) is the precision at cut off k in the top N list CN,rec , and rel(k ) is an indicator function equaling 1 if the item at rank k is adopted , otherwise zero . Finally , Mean Average Precision ( MAP@N ) is defined as the mean of the AP scores for all users .
Usually , these metrics are consistent with each other , ie , if a model performs better than another model on one metric , it is more likely that it will also produce better results on another metric . Due to space limits , we mainly show the results of MAP@N with N = {1 , 5 , 10} on several evaluation tasks since it takes the positions into consideration . 5.4 Analysis of CDAE Components
The main components of the proposed CDAE model include the types of the mapping functions , the loss function and the level of corruption . Different choices of these components result in different variants of the model that make different top N recommendations . In this subsection , we study these variants on the 3 data sets . For the mapping function , we show results for the identity function and sigmoid function on the hidden layer and the output layer . ( Results for the tanh function are similar to those of the sigmoid function and hence omitted . ) There are 23 = 8 total combinations of choices for the mapping functions ( on both layers ) and the loss function . Among them , the logistic loss function requires ˆy to be a value between 0 and 1 , so it must be associated with a sigmoid function on the output layer . Note that the combination of the sigmoid function and the logistic loss is equivalent to the cross entropy loss discussed in Section 21 Therefore , we study 4 variants10 of our model in this subsection . Table 4 describes the function choices for each variant .
Table 4 : Four sample variants of the CDAE model . Hidden Layer Output Layer Loss Function
M1 M2 M3 M4
Identity Identity Sigmoid Sigmoid
Identity Sigmoid Identity Sigmoid
Square Logistic Square Logistic
In our extensive experiments , we observed that the pair wise objective function did not perform much better than point wise objectives for CDAE . One possible cause is that for the implicit feedback with binary ratings , point wise loss functions are sufficient for separating those items preferred by the user and those not preferred . In other words , a well designed point wise loss can be discriminating enough to model the user ’s preference in these datasets , and the pair wise loss is not needed . For this reason , results on pair wise objective functions are omitted in the rest of this paper . On a related note , as we show in section 5.5 , the BPR model , which uses pairwise loss , does not perform better than MF , which uses point wise 10We omit the results of another 2 variants ( replacing the loss functions of M2 and M4 with square loss ) since their performances are similar to those of M2 and M4 respectively .
158 ( a ) MAP@1
( b ) MAP@5
( a ) MAP@1
( b ) MAP@5
( c ) MAP@10
( c ) MAP@10
Figure 2 : Model performance comparison on Yelp data .
Figure 3 : Model performance comparison on Netflix data . loss . Similar results have also been reported in [ 7 ] . This might be due to the same reason as for CDAE . Moreover , BPR is designed to optimize for the AUC , not top N metrics such as precision , recall , or MAP . Hence , for multiple models for top N recommendation , pair wise loss functions may not be necessary for all data sets . We train each of the four variants under varying corruption levels ( q in Equation 9 ) from {0 , 0.2 , 0.4 , 0.6 , 0.8 , 1} . The number of latent dimensions K is set to 50 unless otherwise stated . The results on the three data sets are shown in Figure 2 , 3 and 4 respectively .
( a ) MAP@1
( b ) MAP@5
( c ) MAP@10
Figure 4 : Model performance comparison on MovieLens data .
Table 5 : Comparison with DAE on the Yelp data .
MAP@1
MAP@5
MAP@10
DAE 0.0275 0.0369 0.0443 0.0529
CDAE 0.0327 0.0420 0.0460 0.0528
DAE 0.0164 0.0225 0.0270 0.0315
CDAE 0.0201 0.0241 0.0285 0.0319
DAE 0.0172 0.0236 0.0289 0.0329
CDAE 0.0210 0.0254 0.0303 0.0334
Model M1 M2 M3 M4
Table 6 : Comparison with DAE on the MovieLens data .
MAP@1
MAP@5
MAP@10
DAE 0.2807 0.3134 0.3270 0.3625
CDAE 0.2933 0.3368 0.3494 0.3860
DAE 0.1619 0.1785 0.1953 0.2123
CDAE 0.1730 0.1900 0.2099 0.2252
DAE 0.1278 0.1408 0.1579 0.1684
CDAE 0.1402 0.1509 0.1722 0.1797
Model M1 M2 M3 M4 sets , and get relatively similar results . We show the results on the Yelp data and on the MovieLens data in Table 5 and 6 respectively . We can see that for models M1 and M2 , using user specific vectors greatly improves the results on the Yelp data . As the performances of the models get better for M3 and M4 , the gain becomes relatively smaller . For the MovieLens data , using user specific vectors consistently outperforms the alternative choice .
The general observation is that the best model depends on the data set . No single variant of CDAE always produces the best results . So one should choose the components ( mapping function , objective function , loss function , and corruption level ) depending on the data . Consider the two different extremes of corruption level : q = 0 ( no input corruption ) and q = 1 ( complete input corruption ) . For variant M1 , the results of q = 0 are much worse than those of q = 1 . This indicates that simply summing up all the input vectors ( q = 0 ) is insufficient for learning good representations , and is in fact worse than dropping out all of them ( q = 1 ) . Note that introducing non linear functions can largely alleviate the problem , as evidenced in the results for the other three variants with q = 0 . Adding noise on the input can also prevent this problem ( see the results of M1 with various corruption levels ) , which means that the denoising technique can help with learning more robust representations .
The denoising technique appears beneficial especially for variants M1 and M2 . On the Yelp data set , all four variants can be improved by adding relatively higher levels of noise ( eg , q = 08 ) Variant M2 is the best model for the Netflix data set , and setting q = 0.2 and q = 0.4 can slightly improve the results . On MovieLens data , setting q = 0.8 makes M2 almost as good as M4 , the best model . However , in some cases , the best results are those without any input corruption ( q = 0 ) .
In general , M4 produces relatively better results on all three data sets . In particular , it achieves the best MAP scores on Yelp and MovieLens . This indicates that non linear functions help to increase the representation capability of the model , thus improving the recommendations . Comparison with DAE . A main difference between CDAE and classical DAE is the user specific input between the input layer and the hidden layer , namely , the vector Vu . We study two cases here – with the user specific vectors ( CDAE ) and without the userspecific vectors ( DAE ) . We conduct experiments on the three data
159 Table 7 : Effects of using tied weights on MovieLens data . “ TW ” means using tied weights , while “ NTW ” means no tied weights .
MAP@1
MAP@5
MAP@10
TW 0.1739 0.3707 0.3482 0.3530
NTW 0.2933 0.3368 0.3494 0.3860
TW 0.0983 0.2086 0.2044 0.2007
NTW 0.1730 0.1901 0.2099 0.2252
TW 0.0763 0.1643 0.1669 0.1609
NTW 0.1402 0.1509 0.1722 0.1797
Model M1 M2 M3 M4
Table 8 : Effects of using tied weights on Netflix data . “ TW ” means using tied weights , while “ NTW ” means no tied weights .
MAP@1
MAP@5
MAP@10
TW 0.1172 0.2567 0.1172 0.2287
NTW 0.1301 0.2608 0.2000 0.2474
TW 0.0551 0.1418 0.0551 0.1260
NTW 0.0695 0.1431 0.1162 0.1370
TW 0.0428 0.1177 0.0428 0.1066
NTW 0.0571 0.1199 0.1011 0.1143
Model M1 M2 M3 M4
( a ) Results on Yelp data .
( b ) Results on Netflix data .
Figure 5 : The effects of the number of latent dimensions .
Tied weights . We study the effects of using tied weights ( TW ) for the weight matrices , where we force W = W . Results on MovieLens and Netflix data sets are shown in Table 7 and 8 , respectively . We refer to the cases of “ no tied weights ” as NTW . The results on Yelp data are similar to those on Netflix data , so we omit them here . Other than variant M2 on MovieLens data , the results of NTW are much better than TW . On Netflix data , NTW consistently outperforms TW by at least 10 % . On both data sets , the best MAP scores are from models with NTW ( M4+NTW in Table 7 and M2+NTW in Table 8 , respectively ) . Thus we do not recommended using tied weights for CDAE . The number of latent dimensions . We study the effects of the number of latent dimensions K . Results on Yelp data and Netflix data are shown in Figure 5 . From the figures , we can see that the performance increases with larger K , but only up to a point . When K becomes large enough , the performance no longer improves and can in fact decrease due to overfitting . 5.5 Experimental Comparisons with Previous
Models
In this section , we compare CDAE with a number of popular top N recommendation methods . Note that comparisons against
Denoising Auto Encoder ( DAE ) and its non denoising variant ( when q = 0 ) are already discussed in Section 54
These baseline methods are : • POP : Items are recommended based on how many users have rated them .
• ITEMCF [ 19 ] : We use Jaccard similarity measure and set the number of nearest neighbor to 50 .
• MF ( with negative sampling ) [ 9 ] : We train the Latent Factor Model with point wise objective functions ( with square , log , hinge and cross entropy losses ) and negative sampling11 , and report the best results .
• BPR [ 15 ] : BPR is the state of the art method for recommendation based on implicit feedback . As discussed in Section 2.1 , BPR MF is a Latent Factor Model with the pair wise log loss function . In addition to the log loss used in the original paper [ 15 ] , we also experiment with square and hinge loss functions and report the best results .
• FISM [ 7 ] : FISM is a variant of FSM with point wise square loss function12 . We also test log loss and hinge loss and report the best results .
For all the baseline methods , we carefully choose the hyperparameters by cross validation to ensure fair comparisons . We train the 4 variants of CDAE discussed in Table 4 with different corruption levels , and report the best results . For all the latent factor models ( including MF , BPR , FISM and CDAE ) , we set the number of latent dimensions to 50 and use an additional dimension to model the bias . Other implementation details are as discussed in Section 52
Figure 6 , 7 and 8 show the MAP@N scores of all models on Yelp , MovieLens and Netflix , respectively . Since Recall is another widely used metric for comparing top N recommendation models , we also include plots of the Recall scores on the three data sets in Figure 9 , 10 and 11 .
In general , the results of MAP and Recall are consistent , ie , the performance orderings of models are almost the same . One exception is on the Yelp data , where MF gets better MAP@N scores than BPR , but BPR has better Recall@N scores .
According to the results of MAP@10 and Recall@10 , CDAE consistently outperforms other compared methods . On the Yelp data , CDAE outperforms the other methods with a large margin on all the evaluation metrics . The MAP@10 score and Recall@10 score of CDAE are at least 15 % better than those of the second best model MF . For the Netflix data set , ITEMCF achieves much better results than other methods such as MF , BPR and FISM , particularly on the metrics MAP@1 and Recall@1 . CDAE is the only model that can beat ITEMCF on metrics MAP@10 and Recall@10 , where CDAE outperforms ITEMCF by around 10 % .
It is surprising to see that BPR and FISM achieve lower MAP scores than MF on Yelp and Netflix data sets . The only data set on which they achieve better results is MovieLens , but the performance gains are not significant . 11We note that , for implicit feedback data , MF with negative sampling has the same objective function with WRMF [ 6 ] – both of them assign high confidence on the observed/positive feedback and low cofidence on the missing/negative feedback . We do not compare with WRMF because its computational speedup trick for ALS only works with squared loss . 12We also tried the pair wise loss functions , but the results are not as good as for the point wise functions . The same observation is reported in the original paper .
160 Figure 6 : MAP scores with different N on the Yelp data set .
Figure 7 : MAP scores with different N on the MovieLens data set .
Figure 8 : MAP scores with different N on the Netflix data set .
Figure 9 : The Recall scores with different N on the Yelp data set .
Figure 10 : The Recall scores with different N on the MovieLens data set .
Figure 11 : The Recall scores with different N on the Netflix data set .
6 . CONCLUSION
In this paper , we presented the Collaborative Denoising AutoEncoder ( CDAE ) for the top N recommendation problem . CDAE learns distributed representations of the users and items via formulating the user item feedback data using a Denoising Auto Encoder structure . Several previous works can be seen as special cases of the proposed model . We conducted a comprehensive set of ex periments on three data sets to study how the choice of the model components impacts the performance . We also compared CDAE against several other state of the art top N recommendation methods and the results show that CDAE outperforms the rest of the methods by a large margin .
The proposed model enables a wide range of future works on applying neural networks to recommender systems . Here we list some potential directions .
161 Deep Neural Network . The neural network structure used in our paper is shallow . A straightforward extension is to stack the model as done in the stacked DAE [ 25 ] . Our preliminary experiments on the stacked CDAE do not show significant improvement over CDAE . We plan to investigate the reason and try to improve it . Also , the idea of marginalized DAE [ 3 ] might be able to speed up the training and improve the performance . It would also be interesting to consider applying other neural network structures such as Convolutional Neural Networks and Recurrent Neural Networks to this framework . Feature aware Recommendation . User and item features can be important for producing semantically meaningful models and dealing with the cold start problem . It is worth exploring how to incorporate user and item features to improve the proposed model . Context aware Recommendation . In many applications , one might benefit from incorporating contextual information ( such as time , location , browser session , etc . ) into the recommendation process in order to recommend items to users in certain circumstances . We leave such extensions as future work .
7 . REFERENCES [ 1 ] D . Agarwal and B . Chen . Regression based latent factor models . In Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 19–28 , 2009 .
[ 2 ] Y . Bengio , P . Lamblin , D . Popovici , and H . Larochelle . Greedy layer wise training of deep networks . In Advances in Neural Information Processing Systems , pages 153–160 , 2006 .
[ 3 ] M . Chen , K . Q . Weinberger , F . Sha , and Y . Bengio . Marginalized denoising auto encoders for nonlinear representations . In Proceedings of the 31st International Conference on Machine Learning ( ICML 14 ) , pages 1476–1484 , 2014 .
[ 4 ] J . Duchi , E . Hazan , and Y . Singer . Adaptive subgradient methods for online learning and stochastic optimization . The Journal of Machine Learning Research , 12:2121–2159 , 2011 .
[ 5 ] X . Glorot , Y . Bengio , and Y . N . Dauphin . Large scale learning of embeddings with reconstruction sampling . In Proceedings of the 28th International Conference on Machine Learning ( ICML 11 ) , pages 945–952 , 201 .
[ 6 ] Y . Hu , Y . Koren , and C . Volinsky . Collaborative filtering for implicit feedback datasets . In Proceedings of the Eighth IEEE International Conference on Data Mining , pages 263–272 , 2008 .
[ 7 ] S . Kabbur , X . Ning , and G . Karypis . FISM : factored item similarity models for top n recommender systems . In Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 659–667 . ACM , 2013 .
[ 8 ] Y . Koren . Factorization meets the neighborhood : a multifaceted collaborative filtering model . In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 426–434 . ACM , 2008 .
[ 9 ] Y . Koren , R . Bell , and C . Volinsky . Matrix factorization techniques for recommender systems . Computer , 42(8):30–37 , 2009 .
[ 10 ] S . Lauly , H . Larochelle , M . Khapra , B . Ravindran , V . C . Raykar , and
A . Saha . An autoencoder approach to learning bilingual word representations . In Advances in Neural Information Processing Systems , pages 1853–1861 , 2014 .
[ 11 ] J . Lee , S . Bengio , S . Kim , G . Lebanon , and Y . Singer . Local collaborative ranking . In Proceedings of the 23rd International Conference on World Wide Web , pages 85–96 . ACM , 2014 .
[ 12 ] X . Ning and G . Karypis . SLIM : Sparse linear methods for top N recommender systems . In Proceedings of the 11th IEEE International Conference on Data Mining , pages 497–506 , 2011 .
[ 13 ] R . Pan , Y . Zhou , B . Cao , N . N . Liu , R . Lukose , M . Scholz , and Q . Yang . One class collaborative filtering . In Proceedings of the Eighth IEEE International Conference on Data Mining , pages 502–511 , 2008 .
[ 14 ] S . Rendle . Factorization machines with libfm . ACM Transactions on
Intelligent Systems and Technology ( TIST ) , 3(3):57 , 2012 .
[ 15 ] S . Rendle , C . Freudenthaler , Z . Gantner , and L . Schmidt Thieme .
Bpr : Bayesian personalized ranking from implicit feedback . In Proceedings of the Twenty Fifth Conference on Uncertainty in Artificial Intelligence ( UAI ) , pages 452–461 , 2009 .
[ 16 ] J . D . Rennie and N . Srebro . Fast maximum margin matrix factorization for collaborative prediction . In Proceedings of the 22nd international conference on Machine learning , pages 713–719 . ACM , 2005 .
[ 17 ] R . Salakhutdinov and A . Mnih . Probabilistic matrix factorization . In
Advances in neural information processing systems , pages 1257–1264 , 2007 .
[ 18 ] R . Salakhutdinov , A . Mnih , and G . Hinton . Restricted boltzmann machines for collaborative filtering . In Proceedings of the 24th international conference on Machine learning , pages 791–798 . ACM , 2007 .
[ 19 ] B . Sarwar , G . Karypis , J . Konstan , and J . Riedl . Item based collaborative filtering recommendation algorithms . In Proceedings of the 10th international conference on World Wide Web , pages 285–295 . ACM , 2001 .
[ 20 ] S . Sedhain , A . K . Menon , S . Sanner , and L . Xie . Autorec :
Autoencoders meet collaborative filtering . In Proceedings of the 24th International Conference on World Wide Web Companion , WWW’15 Companion , pages 111–112 , 2015 .
[ 21 ] Y . Shi , A . Karatzoglou , L . Baltrunas , M . Larson , N . Oliver , and A . Hanjalic . Climf : learning to maximize reciprocal rank with collaborative less is more filtering . In Proceedings of the sixth ACM conference on Recommender systems , pages 139–146 . ACM , 2012 . [ 22 ] Y . Shi , M . Larson , and A . Hanjalic . List wise learning to rank with matrix factorization for collaborative filtering . In Proceedings of the fourth ACM conference on Recommender systems , pages 269–272 . ACM , 2010 .
[ 23 ] H . Steck . Training and testing of recommender systems on data missing not at random . In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 713–722 . ACM , 2010 .
[ 24 ] P . Vincent , H . Larochelle , Y . Bengio , and P A Manzagol . Extracting and composing robust features with denoising autoencoders . In Proceedings of the 25th international conference on Machine learning , pages 1096–1103 . ACM , 2008 .
[ 25 ] P . Vincent , H . Larochelle , I . Lajoie , Y . Bengio , and P A Manzagol .
Stacked denoising autoencoders : Learning useful representations in a deep network with a local denoising criterion . The Journal of Machine Learning Research , 11:3371–3408 , 2010 .
[ 26 ] C . Wang and D . M . Blei . Collaborative topic modeling for recommending scientific articles . In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining , KDD ’11 , pages 448–456 . ACM , 2011 .
[ 27 ] H . Wang , N . Wang , and D Y Yeung . Collaborative deep learning for recommender systems . In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , KDD ’15 , pages 1235–1244 . ACM , 2015 .
[ 28 ] M . Weimer , A . Karatzoglou , Q . V . Le , and A . J . Smola . COFI
RANK maximum margin matrix factorization for collaborative ranking . In Advances in Neural Information Processing Systems , pages 1593–1600 , 2007 .
[ 29 ] J . Weston , S . Bengio , and N . Usunier . WSABIE : scaling up to large vocabulary image annotation . In Proceedings of the 22nd International Joint Conference on Artificial Intelligence ( IJCAI’11 ) , pages 2764–2770 , 2011 .
[ 30 ] J . Weston , C . Wang , R . Weiss , and A . Berenzweig . Latent collaborative retrieval . In Proceedings of the 29th International Conference on Machine Learning ( ICML 12 ) , pages 9–16 , 2012 .
[ 31 ] S H Yang , B . Long , A . J . Smola , H . Zha , and Z . Zheng .
Collaborative competitive filtering : learning recommender using context of user choice . In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval , pages 295–304 . ACM , 2011 .
[ 32 ] L . Zhang , D . Agarwal , and B C Chen . Generalizing matrix factorization through flexible regression priors . In Proceedings of the Fifth ACM Conference on Recommender Systems , RecSys ’11 , pages 13–20 . ACM , 2011 .
162
