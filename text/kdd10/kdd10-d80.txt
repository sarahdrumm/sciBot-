GLS SOD : A Generalized Local Statistical Approach for Spatial Outlier Detection
Feng Chen
Virginia Tech , USA chenf@vt.edu
Department of Computer Science
Department of Computer Science
Chang Tien Lu
Virginia Tech , USA
Arnold P . Boedihardjo
Department of Computer Science
Virginia Tech , USA ctlu@vt.edu
ArnoldPBoedihardjo@vtedu
( GLS )
ABSTRACT Local based approach is a major category of methods for spatial outlier detection ( SOD ) . Currently , there is a lack of systematic analysis on the statistical properties of this framework . For example , most methods assume identical and independent normal distributions ( iid normal ) for the calculated local differences , but no justifications for this critical assumption have been presented . The methods' detection performance on geostatistic data with linear or nonlinear trend is also not well studied . In addition , there is a lack of theoretical connections and empirical comparisons between local and global based SOD approaches . This paper discusses all these fundamental issues under the proposed Generalized Local Statistical framework . Furthermore , robust estimation and outlier detection methods are designed for the new GLS model . Extensive simulations demonstrated that the SOD method based on the GLS model significantly outperformed all existing approaches when the spatial data exhibits a linear or nonlinear trend . Categories and Subject Descriptors D28 [ Database Management ] : Database Applications – data mining . I53 [ Pattern Recognition ] : Outlier Detection . General Terms Algorithms , Theory , and Experimentation Keywords Spatial Outlier Detection , Spatial Gaussian Random Field . 1 . INTRODUCTION The ever increasing volume of spatial data has greatly challenged our ability to extract useful but implicit knowledge from them . As an important branch of spatial data mining , spatial outlier detection aims to discover the objects whose non spatial attribute values are significantly different from the values of their spatial neighbors [ 1 ] . In contrast to traditional outlier detection , spatial outlier detection must differentiate spatial and non spatial attributes , and consider the spatial continuity and autocorrelation between nearby samples . By the first law of geography , "Everything is related to everything else , but nearby things are more related than distant things [ 3]." There are two main classes of spatial outlier detection ( SOD ) methods : local and global based approaches . Local based approaches [ 4 ] first calculate the local difference ( statistic ) for each object which is the difference between the non spatial attribute of the object and the aggregated value ( eg , average ) of its spatial neighbors . By assuming iid normal distributions for these local differences , the local based approaches discover outlier objects by robust estimation of model parameters such as the aggregated values , mean , and standard deviation . Various methods have been presented by using different spatial neighborhood definitions and robust estimation techniques [ 5 9 ] . The second class , global based methods , is to identify outliers using the robust estimator of a global kriging model which is the best linear unbiased estimator for geostatistical data . Particularly , Christensen et al . [ 10 ] proposed diagnostics to detect spatial outliers on the estimation of covariance function . Cerioli and Riani [ 11 ] developed a forward search procedure to identify spatial outliers for an ordinary kriging model . Militino et al . [ 12 ] further generalized the forward search method in [ 11 ] to a universal kriging model . This paper focuses on local based methods , because local based methods can achieve higher computational efficiency with minimal loss of accuracy . This feature of the local based approaches is demonstrated through extensive simulations described in Section 5 . This work is primarily motivated by the current situation where there is no systematic study on the statistical properties of local based SOD methods . For example , existing works assume iid on local differences , but justifications for the assumption have never been proposed . Also their performance on spatial data with linear or nonlinear trends has not been well studied . There is also a lack of research on theoretical connections and empirical comparisons between local and global based SOD methods . To that end , this paper provides a generalized framework for local based SOD methods and theoretically and empirically compares it against global based SOD methods . The proposed framework is cast within the statistical abstraction of a spatial Gaussian random field which is the most popular model for geostatistical data [ 1,2 ] . A major reason for its popularity is that the optimal solution based on the Gaussian random field is equivalent to a best linear unbiased estimator ( BLUE ) for non Gaussian data . It has been shown to provide accurate results in a variety of practical situations [ 1,2 ] . Sections 5.8 , 633 , and 7.4 in [ 2 ] give an in depth discussion on the applicability of Gaussian random field . A spatial Gaussian random field refers to a collection of dependent random variables that are associated with a set of spatial to a continuous fixed region . This family of random variables can be characterized by a joint Gaussian probability density or distribution . In real applications , only partial observations of one realization ( or a partial sample of size one ) are available . In order to make this model operational , the requirements for stationarity and isotropy , such as second order or intrinsic stationarity , are further imposed . Imposing such assumptions helps reduce the number of indexes , ( cid:4668)(cid:1852)(cid:4666)(cid:2201)(cid:4667 ) | ( cid:2201)(cid:1488)(cid:1830)(cid:1599)(cid:1337)(cid:2870)(cid:4669 ) , where ( cid:1830 ) refers the
1069 isotropic , model parameters required to be estimated . When the data is second order stationary and the spatial correlation structure is described by a semivariogram or covariance function , in which the correlations between variables are dependent on their spatial distance . Statistical inferences are then performed by assuming explicit forms of the covariance and mean functions . Our major contributions are as follows : • Design of a generalized local statistical ( GLS ) framework : The general local statistical model is a generalized statistical framework for existing local based SOD methods . It can effectively handle complex situations where the spatial data exhibit a global trend or non negligible dependences between local differences .
• analyze framework : We
• Robust estimation and outlier detection methods based on the the proposed GLS contamination issues that lead to masking and swamping effects . Based on the analysis , two robust algorithms , GLSbackward search and GLS forward search , are proposed to estimate the parameters for the GLS model . In depth study on the connection between different SOD methods : We present theoretical foundations for existing local based SOD methods and discuss the crucial connections between local and global based SOD methods .
• Comprehensive simulations to validate the effectiveness and efficiency of GLS . This is the first work that provides extensive comparisons between existing popular methods through a systematic simulation study . The results showed the proposed GLS SOD approach significantly outperformed all existing methods when the spatial data exhibits a linear or nonlinear trend . spatial statistic [ 4 ] is defined as
( cid:4666)(cid:2201)(cid:4667)(cid:3427)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:1831)(cid:2201)(cid:2191)(cid:1488)(cid:2170)(cid:4666)(cid:2201)(cid:4667)(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439)(cid:3431 ) ,
This paper is organized as follows . Section 2 reviews spatial local statistics and related works . Section 3 introduces the generalized local statistical model and presents a rigorous theoretical treatment of its fundamental statistical properties . In Section 4 , we introduce several robust estimation and outlier detection methods for the GLS model , and analyze the connection between different SOD methods . Section 5 provides the simulations and discussions . Section 6 gives the conclusion . 2 . SPATIAL LOCAL STATISTICS AND RELATED WORKS
Given a set of observations ( cid:4668)(cid:1852)(cid:4666)(cid:2201)(cid:2778)(cid:4667),(cid:1852)(cid:4666)(cid:2201)(cid:2779)(cid:4667),…,(cid:1852)(cid:4666)(cid:2201)(cid:2196)(cid:4667)(cid:4669 ) , a local where ( cid:2163)(cid:4668)(cid:2201),…,(cid:2201)(cid:4669)(cid:1599)(cid:1337)(cid:2870 ) is a set of spatial locations , ( cid:2201)(cid:1488)(cid:2163 ) , ( cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:1488)(cid:1337 ) represents the value of ( cid:1852 ) attribute at location ( cid:2201 ) , ( cid:2170)(cid:4666)(cid:2201)(cid:4667 ) is the set of spatial neighbors of ( cid:2201 ) , and ( cid:1831)(cid:2201)(cid:2191)(cid:1488)(cid:3015)(cid:4666)(cid:2201)(cid:4667)(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439 ) represents the average ( cid:1852 ) attribute value of the neighbors of ( cid:2201 ) . It is assumed that the set of local spatial statistics ( cid:4668)(cid:4666)(cid:2201)(cid:4667),…,(cid:4666)(cid:2201)(cid:4667)(cid:4669 ) are Then the popular ( cid:1852) test [ 4 ] for detecting spatial outliers can be described as follows : Spatial statistic ( cid:1852)(cid:3020)(cid:4666)(cid:2201)(cid:4667)(cid:4698)(cid:3020)(cid:4666)(cid:2201)(cid:4667)(cid:3091)(cid:2201)(cid:3097)(cid:2201 ) ( cid:4698)(cid:3408)Φ(cid:4672)(cid:3080)(cid:2870)(cid:4673 ) , where Φ is the cumulative distribution function ( CDF ) of a standard normal distribution , ( cid:2009 ) refers to a significance level and is usually set to 0.05 , and ( cid:2020)(cid:2201 ) and ( cid:2026)(cid:2201 ) refer to the sample mean and Lu et al . [ 5 ] pointed out that the ( cid:1852) test is susceptible to the independently and identically normally distributed ( iid normal ) . sample standard deviation , respectively . well known masking and swamping effects . When multiple
( 1 ) to to similar outliers exist in the data , the quantities ( cid:1831)(cid:2201)(cid:2191)(cid:1488)(cid:3015)(cid:4666)(cid:2201)(cid:4667)(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439 ) , ( cid:2020)(cid:2201 ) , and ( cid:2026)(cid:2201 ) are biased estimators of the population means and standard deviation . As a result , some true outliers are "masked" as normal objects and some normal objects are "swamped" and misclassified as outliers . The authors proposed an iterative approach that detects outliers by multi iterations . Each iteration identifies only one outlier and then modifies its attribute value so that it will not impact the results of subsequent iterations . Later , Chen et al . [ 6 ] proposed a median based approach that uses median estimator for the quantities ( cid:1831)(cid:2201)(cid:2191)(cid:1488)(cid:3015)(cid:4666)(cid:2201)(cid:4667)(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439 ) and ( cid:2020)(cid:2201 ) , and median absolute deviation ( MAD ) estimator for ( cid:2026)(cid:2201 ) . Hu and Sung [ 7 ] proposed an estimate ( cid:1831)(cid:2201)(cid:2191)(cid:1488)(cid:3015)(cid:4666)(cid:2201)(cid:4667)(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439 ) , instead of the median . Sun and Chawla ( (cid:1840)(cid:4666)(cid:2201)(cid:4667 ) ) and their method is applied to a special case of statistics ( cid:4668)(cid:4666)(cid:2201)(cid:4667),…,(cid:4666)(cid:2201)(cid:4667)(cid:4669 ) are iid normal , but no justifications
[ 8 ] presented a spatial local outlier measure to capture the local behavior of data in their neighborhood . Shekhar et al . [ 9 ] employed a graph based method to define spatial neighborhoods transportation network . Most existing local based methods assume that the set of local
[ 6 ] , but using trimmed mean approach
Symbol for this assumption have ever been proposed . As we will discuss in next sections , this iid assumption is only approximately true in certain scenarios , and the dependencies between different local differences ( statistics ) must be considered when the spatial data exhibit linear or nonlinear trend or the selected neighborhood size for each object is small . As shown in our simulations in Section 5 , the violation of iid assumption can significantly impact the accuracies of the outlier detection methods . 3 . GENERALIZED LOCAL SPATIAL STATISTICS This section first introduces some preliminary background on spatial Gaussian random field , then presents the generalized local statistical ( GLS ) model , and finally discusses the statistical properties of the GLS model . Table 1 summarizes the key notations used in this paper .
Table 1 : Description of Major Symbols Descriptions
( cid:4668)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:4669)(cid:2880 ) A given set of observations , where ( cid:2201)(cid:1488)(cid:1337)(cid:2870 ) is the spatial location and ( cid:1852)(cid:4666)(cid:1668)(cid:4667 ) is the Z attribute value . ( cid:4668)(cid:2206)(cid:4666)(cid:2201)(cid:4667)(cid:4669)(cid:2880 ) ( cid:2206)(cid:4666)(cid:2201)(cid:4667 ) is a vector of covariates of ( cid:2201 ) , such as the bases of spatial coordinates of ( cid:2201 ) . ( cid:1800)(cid:4670)(cid:1852)(cid:4666)(cid:2201)(cid:4667),…,(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:4671)(cid:1794 ) ( cid:1800 ) ( cid:1798)(cid:4670)(cid:2206)(cid:4666)(cid:2201)(cid:4667),…,(cid:2206)(cid:4666)(cid:2201)(cid:4667)(cid:4671)(cid:1794 ) ( cid:1798 ) Neighborhood weight matrix ; See Equation 4 A general definition of spatial neighbors of(cid:1819 ) . ( cid:2170)(cid:4666)(cid:2201)(cid:4667 ) ( cid:2170)(cid:3012)(cid:4666)(cid:2201)(cid:4667 ) K nearest neighbors of ( cid:1819 ) . This paper considers ( cid:2170)(cid:3012)(cid:4666)(cid:2201)(cid:4667 ) as the specification of ( cid:2170)(cid:4666)(cid:1819)(cid:4667 ) . define spatial neighbors ( cid:3435)(cid:2170)(cid:3012)(cid:4666)(cid:2201)(cid:4667)(cid:3439 ) . ( cid:2236),(cid:2026 ) , ( cid:2026 ) Given a spatial Gaussian random field ( cid:4668)(cid:1852)(cid:4666)(cid:2201)(cid:4667),(cid:2201)(cid:1488)(cid:1830)(cid:1599)(cid:1337)(cid:2870)(cid:4669 ) ,
Spatial Outlier Detection Generalized Local Statistics Model The unknown parameters in the GLS model
3.1 Generalized Local Statistic Model ( GLS ) consider the following decomposition of the process [ 1 ]
Neighborhood size . It is the major parameter to
SOD GLS
F
1070 model and exponential model ( see Equations 8 and 11 ) .
( Manhattan distance ) , and graph distance [ 10 ] . There are two variation ω(s ) , we assume that it is an isotropic second order illustrations ) . The nonlinear degree of the trend is dependent on that are partial observations of a particular realization of the spatial Gaussian
( cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:1858)(cid:4666)(cid:2206)(cid:4666)(cid:2201)(cid:4667),(cid:2236)(cid:4667)(cid:3397)(cid:2033)(cid:4666)(cid:2201)(cid:4667)(cid:3397)(cid:2035)(cid:4666)(cid:2201)(cid:4667 ) , ( cid:4666)2(cid:4667 ) where ( cid:1830 ) is a fixed region , ( cid:1858)(cid:4666)(cid:2206)(cid:4666)(cid:2201)(cid:4667),(cid:2236)(cid:4667 ) is the large scale trend ( mean ) of the process , ( cid:2033)(cid:4666)(cid:2201)(cid:4667 ) is the smooth scale variation that is a Gaussian stationary process , and ( cid:2035)(cid:4666)(cid:2201)(cid:4667 ) is the white noise with the variance ( cid:2026)(cid:2870 ) . The large scale trend ( cid:1858)(cid:4666)(cid:2206)(cid:4666)(cid:2201)(cid:4667),(cid:2236)(cid:4667)(cid:2206)(cid:4666)(cid:2201)(cid:4667)(cid:2236 ) , where ( cid:2236 ) is a vector of trend parameters , and ( cid:2206)(cid:4666)(cid:2201)(cid:4667 ) is a vector of covariates that are the basis functions of spatial coordinates of s ( See Section 5.1 for the polynomials of covariates in x(cid:4666)s(cid:4667 ) . For the smooth scale stationary process , in which the covariance Cov(cid:4672)(cid:1852)(cid:4666)(cid:2201)(cid:4667),(cid:1852)(cid:3435)(cid:2201)(cid:3439)(cid:4673 ) is a function of the spatial distance between ( cid:2201 ) and ( cid:2201 ) : ( cid:1829)(cid:3435)(cid:2201 ) ( cid:2201)(cid:1313);(cid:2242 ) ( cid:3439 ) , where ( cid:2242 ) are function parameters . A variety of distance metrics may be selected , such as ( cid:1838)(cid:2870 ) ( Euclidean distance ) , ( cid:1838 ) popular models for the covariance function ( cid:1829 ) , including spherical Given a sample set ( cid:4668)(cid:1852)(cid:4666)(cid:2201)(cid:2778)(cid:4667),…,(cid:1852)(cid:4666)(cid:2201)(cid:2196)(cid:4667 ) ( cid:4669 ) random field , let ( cid:2182)(cid:4670)(cid:1852)(cid:4666)(cid:2201)(cid:2778)(cid:4667),…,(cid:1852)(cid:4666)(cid:2201)(cid:2196)(cid:4667)(cid:4671 ) , ( cid:2187)(cid:4670)(cid:1857)(cid:4666)(cid:2201)(cid:4667),…,(cid:1857)(cid:4666)(cid:2201)(cid:4667)(cid:4671 ) , ( cid:2259)(cid:4670)(cid:2033)(cid:4666)(cid:2201)(cid:4667),…,(cid:2033)(cid:4666)(cid:2201)(cid:4667)(cid:4671 ) , and ( cid:2180)(cid:4670)(cid:2206),…,(cid:2206)(cid:4671 ) . By Equation 2 , the random vector ( cid:2182 ) has the decomposition form as ( cid:2182)(cid:2180)(cid:2236)(cid:3397)(cid:2259)(cid:3397)(cid:2187 ) ~ ( cid:1840)(cid:4666)(cid:2180)(cid:2236),(cid:2737)(cid:3397)(cid:2026)(cid:2870)(cid:2165)(cid:4667 ) , where ( cid:2259 ) ~ ( cid:2170)(cid:4666)(cid:2777)(cid:3400),(cid:2227)(cid:3400)(cid:4667 ) and ( cid:2187 ) ~ ( cid:2170)(cid:4666)(cid:2777)(cid:3400),(cid:2026)(cid:2870)(cid:2165)(cid:3400)(cid:4667 ) . where ( cid:2162)(cid:1488)(cid:1337)(cid:3400 ) is a neighborhood weight matrix with ( cid:1832)1 if ( cid:1861 ) ; ( cid:1832)1/ if ( cid:2201)(cid:1488)(cid:1840)(cid:3012)(cid:4666)(cid:2201)(cid:4667 ) ; and ( cid:1832)0 , otherwise . Recall that ( cid:2227)(cid:1829)(cid:3435)(cid:2201)(cid:2201);(cid:2242 ) ( cid:3439 ) . The GLS model has the including ( cid:4666)|(cid:2236)|(cid:3397)1(cid:3397)|(cid:2242)|(cid:4667 ) unknown components ( cid:2236),(cid:2026),and ( cid:2242 ) , parameters . Because the covariance function ( cid:1829)(cid:4666)(cid:1668)(cid:4667 ) ( eg , spherical model is that the component ( cid:2162)(cid:2227)(cid:2162 ) can be approximated by ( cid:2026)(cid:2777)(cid:2870)(cid:2165 ) . relatively large with ( cid:3410)10 , the component ( cid:2026)(cid:2870)(cid:2162)(cid:2162 ) can be further approximated by ( cid:2026)(cid:2870)(cid:2165 ) . This leads to a simpler form of GLS or exponential model ) is nonlinear and nonconvex , it requires iterative reweighted generalized least squares algorithm to estimate all these parameters which is computationally expensive and can only guarantee a local optimum [ 14 ] . As shown in Section 3.2 , an important property of the GLS
( cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667 ) ~ ( cid:1788)(cid:4666)(cid:2162)(cid:2180)(cid:2236),(cid:2026)(cid:2870)(cid:2165)(cid:3397)(cid:2026)(cid:2870)(cid:2162)(cid:2162)(cid:4667 ) . ( cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667 ) ~ ( cid:1788)(cid:4666)(cid:2162)(cid:2180)(cid:2236),(cid:4666)(cid:2026)(cid:2870)(cid:3397)(cid:2026)(cid:2870)(cid:4667)(cid:2165)(cid:4667 ) .
( 6 ) As discussed in Section 4.1 , the model fitting for the GLS form ( 6 ) is a convex problem and can be efficiently solved . By Section 3.2 Theorem 1 , when the neighborhood size is
( cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667 ) ~ ( cid:1788)(cid:4666)(cid:2162)(cid:2180)(cid:2236),(cid:2162)(cid:2227)(cid:2162)(cid:3397)(cid:2026)(cid:2870)(cid:2162)(cid:2162)(cid:4667 ) .
By Equations 3 and 4 , we can readily derive the generalized local statistical ( GLS ) model as
The vector of local spatial statistics calculated by Equation 1 can be reformulated as the matrix form
( 7 ) Discussion : Local statistics is a popular technique used to reduce the dependence between sample points . However , by employing the decomposition form as indicated in Equations 2 4 , we observe that local statistics help reduce the correlations between sample points caused by smooth scale random variations , but at the same
Hence the GLS form ( 5 ) becomes asymptotically equivalent to
( cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667)(cid:2162)(cid:2182 ) ,
( 3 )
( 4 )
( 5 ) the important information about time it also induces "new" correlations due to the averaging of white noise variations . As discussed in [ 2 ] , correlated data can be expressed as linear combination of uncorrelated data . The approximate GLS form ( 6 ) explicitly models the "new" correlations caused by the averaging of white noises variations . The approximate GLS form ( 7 ) essentially ignores these "new" correlations . The form ( 7 ) may be considered when users expect high efficiency and allow some loss of accuracy . This tradeoff is studied in Section 5 by simulations . 3.2 Theoretical Properties of GLS This sub section studies the properties of two major covariance
( Readers are referred to [ 15 ] for the proof . ) Theorem 1 indicates that when the neighborhood size is relative structure gives related dependence structure ( eg , in correlation implies independence ) . Three related theorems are stated as follows : components ( cid:2026)(cid:2779)(cid:2162)(cid:2162 ) and ( cid:2162)(cid:2227)(cid:2162 ) , and discusses the situations where they can be approximated by ( cid:2026)(cid:2870)(cid:2165 ) and ( cid:2026)(cid:2870)(cid:2165 ) , respectively . As shown in Equation 3 , ( cid:2026)(cid:2779)(cid:2162)(cid:2162 ) and ( cid:2162)(cid:2227)(cid:2162 ) are the covariance matrices of the random vectors ( cid:2187)(cid:1499)(cid:2162)(cid:2187 ) and ( cid:2259)(cid:1499)(cid:2162)(cid:2259 ) , respectively . We focus on the study of their correlation structures . Because ( cid:2187)(cid:1499 ) and ( cid:2259)(cid:1499 ) are both multivariate normally distributed , the correlation Theorem 1 : The random vector ( cid:2187)(cid:1499 ) has two major properties 1 ) The variance ( cid:1848)(cid:1853)(cid:4666)(cid:1857)(cid:1499)(cid:4667)(cid:3012)(cid:3012 ) ( cid:2026)(cid:2870),(cid:1861)1… , 2 ) The correlation ( cid:3627)(cid:2025)(cid:3435)(cid:1857)(cid:1499),(cid:1857)(cid:1499)(cid:3439)(cid:3627 ) ( cid:2870)(cid:3012),(cid:1482)(cid:1861 ) , ( cid:1875)(cid:1861)(cid:1860 ) ( cid:1861)(cid:3405 ) , where ( cid:1857)(cid:1499 ) refers to the i th element in the vector ( cid:2187)(cid:1499 ) . large , the correlations between the components in ( cid:2187)(cid:1499 ) are very low ( eg , smaller than 0.2 when 10 ) and the variance of each component is very close to ( cid:2026)(cid:2870 ) . In this case , ( cid:2026)(cid:2779)(cid:2162)(cid:2162)(cid:3406)(cid:2026)(cid:2779)(cid:2165 ) . ( Section 5 ) , the dependence between the components in ( cid:2187)(cid:1499 ) must The next two theorems are related to the random vector ( cid:2259)(cid:1499 ) . It is difficult to analytically evaluate ( cid:2259)(cid:1499 ) , because it is generated by properties of ( cid:2259)(cid:1499 ) are still not straightforward . For this reason , A1 . If ( cid:2170)(cid:3012)(cid:4666)(cid:2201)(cid:3039)(cid:4667)(cid:1514)(cid:2170)(cid:3012)(cid:4666)(cid:2201)(cid:3031)(cid:4667)(cid:3405)(cid:2740 ) , then , ( cid:1482),,(cid:3047)(cid:1488)(cid:2170)(cid:3012)(cid:4666)(cid:2201)(cid:3039)(cid:4667)(cid:1515 ) ( cid:2170)(cid:3012)(cid:4666)(cid:2201)(cid:3031)(cid:4667 ) , their between spatial distances are approximately equivalent : ( cid:2201)(cid:2201)(cid:3406)(cid:1313)(cid:2201)(cid:3047)(cid:2201)(cid:1313)(cid:3406)(cid:2201)(cid:2201)(cid:3047 ) . A2 . If ( cid:2201)(cid:1488)(cid:2170)(cid:3012)(cid:4666)(cid:2201)(cid:4667),(cid:2201)(cid:3047)(cid:1489)(cid:2170)(cid:3012)(cid:4666)(cid:2201)(cid:4667),(cid:1853)(cid:1856 ) ( cid:2170)(cid:3012)(cid:4666)(cid:2201)(cid:3047)(cid:4667)(cid:1514)(cid:2170)(cid:3012)(cid:4666)(cid:2201)(cid:4667)(cid:2740 ) , then ( cid:1313)(cid:2201)(cid:3047)(cid:2201)(cid:1313)(cid:3406)(cid:2201)(cid:3047)(cid:2201 ) . several additional assumptions need to be considered . The following are three assumptions required for Theorem 2 : an isotropic second order stationary process , and even when the explicit form of the covariance function is known , the statistical
However , for a small neighborhood size , as shown in simulations be considered .
A3 . The distance between any points that are k nearest neighbors is approximately constant everywhere .
The intuition on assumptions A1 and A2 is that , because neighbors are close to each other , they share similar betweendistances and similar distances to points that are not their neighbors . The assumption A3 is valid when the spatial locations follow a uniform distribution or a grid structure . The assumption A3 holds in many practical situations [ 13 ] . The situations where assumptions A1 and A2 are potentially violated will be discussed in Theorem 3 . Theorem 2 : If the above assumptions A1 and A2 hold , then the random vector ( cid:2259)(cid:1499 ) has two major properties
1071 correlation .
1 ) The variance ( cid:1848)(cid:1853)(cid:4666)(cid:2033)(cid:1499)(cid:4667)(cid:3406)(cid:3012)(cid:3012 ) ( cid:3435)(cid:2026)(cid:2870)(cid:1829)(cid:2206)(cid:3284)(cid:3439),(cid:1861)1… 2 ) The correlation ( cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3406)(cid:3012 ) , if ( cid:1488)(cid:1840)(cid:3012)(cid:4666)(cid:4667 ) or ( cid:1488 ) ( cid:1840)(cid:3012)(cid:3435)(cid:3439 ) ; otherwise , ( cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3406)0 , where ( cid:1829)(cid:2201)(cid:3284 ) refers to the average covariance value between ( cid:2201 ) and its K nearest neighbors , and ( cid:2026)(cid:2870)(cid:1829)(cid:4666)0(cid:4667 ) refers to the constant variance for each component of ( cid:2259 ) . Further , if the assumption A3 the variance ( cid:1848)(cid:1853)(cid:4666)(cid:2033)(cid:1499)(cid:4667 ) becomes constant components in ( cid:2259)(cid:1499 ) are mostly zero , except for neighboring points . . The greater the value of K , the less the neighbor points are correlated . However , cannot be arbitrary large ; otherwise , the 200 and 10 , then only about 5 % of pairs are correlated . to 01 As shown in Figure 1 , 0.1 indicates a negligible also holds , everywhere . ( Readers are referred to [ 15 ] for the proof . )
Particularly , the correlations between neighboring points are all negative , and their major impact factor is the neighborhood size
For these correlated components , the correlations are only close assumptions made above will be violated . For example , suppose the correlations between
Theorem 2 indicates then that the are employed : direction of a linear relationship [ 13 ] .
Figure 1 : An example of correlation : it reflects the noise and
B4 . Consider 4 or 12 nearest neighbors as spatial neighbors for it is not directly known how these properties are impacted if assumptions A1 and A2 are violated . The next Theorem 3 will delve deeper into this issue and provide more specific analysis
Theorem 2 states two approximate properties of ( cid:2259)(cid:1499 ) . However , on ( cid:2259)(cid:1499 ) . For Theorem 3 , the following less restrictive assumptions B1 . The spatial locations ( cid:4668),…,(cid:4669 ) follow a grid structure and 2500 ; B2 . The spatial distance is defined by ( cid:1838)(cid:2870 ) ( Euclidean ) distance ; B3 . The covariance function ( cid:1829)(cid:1867)(cid:4672)(cid:1852)(cid:4666)(cid:4667),(cid:1852)(cid:3435)(cid:3439)(cid:4673)(cid:1829)(cid:4666)(cid:1860)(cid:4667 ) , where ( cid:1860)(cid:2870 ) , follows a popular spherical model ; consider a much enlarged range with 2500 , for the purpose ( cid:1829)(cid:4666)(cid:1860);(cid:2242)(cid:4667)(cid:3422)(cid:1854 ) ( cid:1861)(cid:1858 ) ( cid:1860)0 ( cid:1854)(cid:3436)1(cid:2871)(cid:3035)(cid:2870)(cid:3030)(cid:3397)(cid:2870)(cid:4672)(cid:3035)(cid:3030)(cid:4673)(cid:2871)(cid:3440 ) ( cid:1861)(cid:1858 ) 0(cid:1860)(cid:1855 ) 0 ( cid:1861)(cid:1858 ) ( cid:1860)(cid:3408)(cid:1855 ) , where ( cid:2242)(cid:4666)(cid:1854),(cid:1855)(cid:4667),(cid:1854)(cid:3410)0,(cid:1855)(cid:3410)0 . Note that ( cid:1854)(cid:1829)(cid:4666)0;(cid:2242)(cid:4667 ) refers to the constant variance for each object ( cid:2201 ) , and ( cid:1829)(cid:4666)(cid:1860);(cid:2242)(cid:4667 ) is a assumption B4 , is set to 4 or 12 due to the use of the grid decreasing function on the distance h . The reason for using a spherical model as opposed to exponential or Gaussian models is that the spherical model leads to closed form analytical results . The closed form results will provide important insights into its statistical properties . As for
Assumptions B1 and B2 are generic properties that can be readily applied to spatial data in general [ 1 , 2 ] . In many applications , the total number of spatial locations is smaller than 300 [ 1 ] . Here , we of generality . For assumption B3 , a spherical model is defined as each object .
( 8 )
4 ) If b ) c ) d ) a ) b ) c ) structure ( assumption B1 ) . In a grid data , each object has four
Theorem 3 : Under the above four assumptions , the random nearest objects with the same distance , eight next nearest objects with the same distance 2 , and so on , where is the grid cell size . Hence , we can select 4,12,24,… . We select the first two values with 4 and 12 , which are equivalent to defining neighborhoods with radiuses of and 2r , respectively . vector ( cid:2259)(cid:1499 ) has following properties on the correlation structure 1 ) If 4 , then a ) ( cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)0 , ( cid:1861)(cid:1858 ) ( cid:1856)(cid:3435)(cid:2201),(cid:2201)(cid:3439)(cid:3408)(cid:1855)(cid:3397)2 , ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.4 , ( cid:1861)(cid:1858)(cid:1855)2 ( cid:1853)(cid:1856 ) ( cid:1856)(cid:3435)(cid:2201),(cid:2201)(cid:3439)2 , ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.22,(cid:1861)(cid:1858 ) ( cid:1855)(cid:3408)2 ( cid:1853)(cid:1856 ) ( cid:1856)(cid:3435)(cid:2201),(cid:2201)(cid:3439)2 , ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.05,(cid:1861)(cid:1858 ) ( cid:1856)(cid:3435)(cid:2201),(cid:2201)(cid:3439)(cid:3408)2 . 2 ) If 12,(cid:1856)(cid:3435)(cid:2201),(cid:2201)(cid:3439)(cid:3408)(cid:1855)(cid:3397)4 , then ( cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)0 3 ) If 12,(cid:1855)4 , then ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.220,(cid:1861)(cid:1858 ) ( cid:1856)(cid:3435)(cid:2201),(cid:2201)(cid:3439)2 ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.110,(cid:1861)(cid:1858 ) 2(cid:1856)(cid:3435)(cid:2201),(cid:2201)(cid:3439)3 ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.050,(cid:1861)(cid:1858 ) ( cid:1856)(cid:3435)(cid:2201),(cid:2201)(cid:3439)(cid:3408)3 12,(cid:1855)(cid:3410)4 ( cid:1853)(cid:1856 ) ( cid:1867)(cid:1875)(cid:3435)(cid:2201)(cid:3439)(cid:1867)(cid:1875)(cid:4666)(cid:2201)(cid:4667)(cid:4672)(cid:1867 ) ( cid:1855)(cid:1867)(cid:1864)(cid:3435)(cid:2201)(cid:3439 ) ( cid:1855)(cid:1867)(cid:1864)(cid:4666)(cid:2201)(cid:4667)(cid:4673 ) , then a ) ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.4741 .(cid:2875)(cid:2877 ) ( cid:1668 ) ( cid:3030)(cid:3118)/(cid:3045)(cid:3118 ) ( cid:3030)(cid:3118)/(cid:4666)(cid:2870).(cid:2875)(cid:2875)(cid:1668)(cid:3045)(cid:3118)(cid:4667 ) , if ( cid:1856)(cid:3435)(cid:2201),(cid:2201)(cid:3439 ) b ) ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.1203 , if ( cid:1856)(cid:3435)(cid:2201),(cid:2201)(cid:3439)2 c ) ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.1719 .(cid:2873)(cid:2876 ) ( cid:1668 ) ( cid:3035)(cid:3284)(cid:3285)(cid:3118)/(cid:3045)(cid:3118 ) ( cid:3030)(cid:3118)/(cid:4666).(cid:2873)(cid:2875)(cid:2872)(cid:1668)(cid:3045)(cid:3118)(cid:4667 ) , otherwise . 12,(cid:1855)(cid:3410)4,(cid:1867)(cid:1875)(cid:3435)(cid:2201)(cid:3439)(cid:3405)(cid:1867)(cid:1875)(cid:4666)(cid:2201)(cid:4667),(cid:1855)(cid:1867)(cid:1864)(cid:3435)(cid:2201)(cid:3439)(cid:3405)(cid:1855)(cid:1867)(cid:1864)(cid:4666)(cid:2201)(cid:4667 ) , ( cid:1860)(cid:1857 ) ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.1085 .(cid:2870)(cid:2876 ) ( cid:1668 ) ( cid:3035)(cid:3284)(cid:3285)(cid:3118)/(cid:3045)(cid:3118 ) ( cid:3035)(cid:3284)(cid:3285)(cid:3118)/(cid:4666)(cid:2871)(cid:2875).(cid:2874)(cid:2875)(cid:2870)(cid:2871)(cid:1668)(cid:3045)(cid:3118)(cid:4667 ) , where refers to the grid cell size ; ( cid:1867)(cid:1875)(cid:4666)(cid:2201)(cid:4667 ) and ( cid:1855)(cid:1867)(cid:1864)(cid:4666)(cid:2201)(cid:4667 ) refer to the row and column locations of the object ( cid:2201 ) in the grid structure ; ( cid:1860)(cid:1856)(cid:3435)(cid:2201),(cid:2201)(cid:3439 ) is the Euclidean distance between ( cid:2201 ) and ( cid:2201 ) . following discussions , we consider the situation with ( cid:1855)(cid:3410)5 . The situation with ( cid:1855)5 will be discussed separately . By Theorem 3 , if ( cid:1855)(cid:3410)5 , ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.18 when 12 . It indicates small absolute correlation values for different values . The correlation values about ( cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439 ) . All these observations are consistent with the We have a comparison between ( cid:2026)(cid:2779)(cid:2162)(cid:2162 ) and ( cid:2162)(cid:2227)(cid:2162 ) . Consider two typical situations : 4 to represent a small neighborhood ; and 12 to represent a relatively large neighborhood . If
( Readers are referred to [ 15 ] for the proof . ) Theorem 3 implies similar patterns as drawn by Theorem 2 although Theorem 2 provides only approximate properties . Theorem 3 is a further justification of these patterns . In the slightly decreases when K increases . It can also be shown that most correlations are negative and are close or equal to zero . Readers are information
( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.22 when 4 ; for detailed
Theorem 2 . referred
5 ) If then
[ 15 ] and to
1072 increases
K decreases , correlation values ( degrees ) are shown in Figure 1 . Although both
4 , then ( cid:3627)(cid:2025)(cid:3435)(cid:1857)(cid:1499),(cid:1857)(cid:1499)(cid:3439)(cid:3627)0.4 and ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)022 If 12 , then ( cid:3627)(cid:2025)(cid:3435)(cid:1857)(cid:1499),(cid:1857)(cid:1499)(cid:3439)(cid:3627)0.2 and ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)018 The impacts of these ( cid:3627)(cid:2025)(cid:3435)(cid:1857)(cid:1499),(cid:1857)(cid:1499)(cid:3439)(cid:3627 ) and ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627 ) increase when the neighborhood size the absolute correlation ( cid:3627)(cid:2025)(cid:3435)(cid:1857)(cid:1499),(cid:1857)(cid:1499)(cid:3439)(cid:3627 ) drastically . Based on these results , we will approximate ( cid:2162)(cid:2227)(cid:2162 ) by ( cid:2026)(cid:2870)(cid:2165 ) for different settings of , but will only approximate ( cid:2026)(cid:2779)(cid:2162)(cid:2162 ) by ( cid:2026)(cid:2779)(cid:2165 ) , when is relatively large , eg , ( cid:3410)10 . Theorem 3 also indicates that when ( cid:1855 ) is small ( cid:4666)eg,(cid:1855)5(cid:4667 ) , some correlations are relatively high ( eg , ( cid:3627)(cid:2025)(cid:3435)(cid:2033)(cid:1499),(cid:2033)(cid:1499)(cid:3439)(cid:3627)0.4 if 4,(cid:1855)1 , and ( cid:1856)(cid:3435)(cid:2201),(cid:2201)(cid:3439) ) . In this case , an important observation is that the correlation matrix of ( cid:2259)(cid:1499 ) exhibits similar structure as that of ( cid:2187)(cid:1499 ) . Particularly , if ( cid:1855 ) , these two correlation approximate the correlation matrix of ( cid:2259)(cid:1499 ) as identity or unit be recovered while estimating the parameter ( cid:2026 ) for the vector ( cid:2187)(cid:1499 ) , Var(cid:4666)(cid:2259)(cid:1499)(cid:4667 ) and Var(cid:4666)(cid:2187)(cid:1499)(cid:4667 ) . For example , suppose ( cid:1855 ) and the constant variance for each component of ( cid:2187 ) is ( cid:2026)(cid:3032)(cid:2870 ) , then we have Var(cid:4666)(cid:2187)(cid:4667)(cid:2227)(cid:2026)(cid:3032)(cid:2870)(cid:2165 ) , and Var(cid:4666)(cid:2187)(cid:1499)(cid:4667)Var(cid:4666)(cid:2162)(cid:2187)(cid:4667)(cid:2162)(cid:2227)(cid:2162)(cid:2026)(cid:3032)(cid:2870)(cid:2162)(cid:2162 ) . ( cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667 ) ~ ( cid:1788)(cid:4666)(cid:2162)(cid:2180)(cid:2236),(cid:2162)(cid:2227)(cid:2162)(cid:3397)(cid:2026)(cid:2870)(cid:2162)(cid:2162)(cid:4667)(cid:1788)(cid:4666)(cid:2162)(cid:2180)(cid:2236),(cid:4666)(cid:2026)(cid:2870)(cid:3397)(cid:2026)(cid:3032)(cid:2870)(cid:4667)(cid:2162)(cid:2162)(cid:4667 ) . If we approximate ( cid:2162)(cid:2227)(cid:2162 ) as ( cid:2026)(cid:2870)(cid:2165 ) instead , then by Equation 6 the approximate model becomes ( cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667 ) ~ ( cid:1788)(cid:4666)(cid:2162)(cid:2180)(cid:2236),(cid:2026)(cid:2870)(cid:2165)(cid:3397)(cid:2026)(cid:2870)(cid:2162)(cid:2162)(cid:4667 ) . estimated parameters ( cid:2026)(cid:3548)0 and ( cid:2026)(cid:3548)(cid:3493)(cid:2026)(cid:2870)(cid:3397)(cid:2026)(cid:3032)(cid:2870 ) .
Using robust parameter estimation , the approximate model can completely recover the true distribution , eg , by setting the matrix . The lost structure information by this approximation will matrices become identical . In this situation , it is still reasonable to because of the similar structure between the covariance matrices distribution model
Equation true the
By
5 , is :
4 . ESTIMATION AND INFERENCES Spatial outlier detection ( SOD ) is usually coupled with a robust estimation process for the related statistical model . This section presents robust estimation and outlier detection methods to reduce the masking and swamping effects , and then discusses the connection between the proposed GLS SOD methods and existing representative methods , such as kriging based and Z test SOD methods . We are focused on the estimation techniques for the GLS form ( 6 ) that is regarded as the default model . The GLS form ( 7 ) will be explicitly stated when discussing its techniques . 4.1 Generalized Least Squares Regression model . We consider mean squared error ( MSE ) as the score function which is the most popular error function in spatial statistics [ 11 ] . This leads to a generalized least square problem for the GLS form ( 6 ) and can be formulated as :
Given a set of observations ( cid:4668)(cid:1852)(cid:4666)(cid:2201)(cid:2778)(cid:4667),…,(cid:1852)(cid:4666)(cid:2201)(cid:2196)(cid:4667 ) ( cid:4669 ) , the objective is to estimate the parameters ( cid:2236),(cid:2026),and ( cid:2026 ) for the proposed GLS argmin(cid:2962),(cid:2978)(cid:3116),(cid:2978)(cid:4674)(cid:4666)(cid:2162)(cid:2182)(cid:2162)(cid:2180)(cid:2236)(cid:4667)(cid:3435)(cid:2026)(cid:2870)(cid:2165)(cid:3397)(cid:2026)(cid:2779)(cid:2162)(cid:2162)(cid:3439)(cid:4666)(cid:2162)(cid:2182)(cid:2162)(cid:2180)(cid:2236)(cid:4667)(cid:4675 ) , subject to ( cid:2026)(cid:2870)(cid:3397 ) ( cid:2026)(cid:2870)1 and ( cid:2026),(cid:2026)(cid:3410)0 . ( cid:4666)9(cid:4667 ) Note that we scale σ and ( cid:2026 ) by a factor ( cid:1855 ) with ( cid:2026)(cid:1499)(cid:2026)/(cid:1855 ) and ( cid:2026)(cid:1499)(cid:2026)/(cid:1855 ) , such that ( cid:2026)(cid:1499)(cid:2870)(cid:3397 ) ( cid:2026)(cid:1499)(cid:2870)1 . Without this constraint , the setting ( cid:2026)(cid:2026)∞ , and ( cid:2236 ) to any value . For simplicity , we directly use the original symbols ( cid:2026 ) and ( cid:2026 ) , rather than ( cid:2026)(cid:1499 ) and ( cid:2026)(cid:1499 ) . As shown in Theorem 4 , the problem ( cid:4666)9(cid:4667 ) is a convex optimization in ( 9 ) will always be minimized by objective function problem which can be efficiently solved by numerical optimization methods such as interior point method [ 14 ] . Note
( 10 ) outlier detection , it is unnecessary to further derive the explicit
Theorem 4 : The problem ( 9 ) is a convex optimization problem .
Then the problem ( 9 ) reduces to a regular least squares regression problem and an explicit solution that when the neighborhood size is large , the following approximation holds : ( cid:2026)(cid:2870)(cid:2162)(cid:2162)(cid:3406)(cid:2026)(cid:2870)(cid:2165 ) ( see Section 3.2 Equation 7 ) . is available with ( cid:2236 ) ( cid:4666)(cid:2180)(cid:2162)(cid:2162)(cid:2180)(cid:4667)(cid:2180)(cid:2162)(cid:2162)(cid:2182 ) , and ( cid:4666)(cid:2026)(cid:2870)(cid:3397)(cid:2026)(cid:2870)(cid:4667)(cid:1313)(cid:2162)(cid:2180)(cid:2236)(cid:2162)(cid:2182)(cid:1313)(cid:2870)(cid:2870)/(cid:4666 ) ( cid:1868)1(cid:4667 ) , where ( cid:1868 ) is the size of the vector ( cid:2236 ) . For the purpose of forms of ( cid:2026 ) and σ . Proof Sketch : Suppose ( cid:2019 ) and ( cid:2199 ) are the eigenvalues and corresponding ( orthonormal ) eigenvectors of the matrix ( cid:2162)(cid:2162 ) . It argmin(cid:2236),(cid:3097)(cid:3116),(cid:3097)(cid:3428)∑ ( cid:3419)(cid:4666)(cid:2162)(cid:2182)(cid:2162)(cid:2180)(cid:2236)(cid:4667)(cid:3269)(cid:2199)(cid:3284)(cid:3423)(cid:3118 ) ( cid:3432),st ( cid:2026),(cid:2026)(cid:3410)0 ( cid:2880 ) ( cid:3097)(cid:3118)(cid:3097)(cid:3116)(cid:3118)(cid:3090)(cid:3284 ) Let ( cid:1858)(cid:3419)(cid:4666)(cid:2162)(cid:2182)(cid:2162)(cid:2180)(cid:2236)(cid:4667)(cid:3269)(cid:2199)(cid:3284)(cid:3423)(cid:3118 ) , It suffices to prove that ( cid:1858 ) is a convex function , or equivalently ( cid:3105)(cid:3118)(cid:3033)(cid:3284)(cid:3105)(cid:2242)(cid:3118)(cid:1594)0 , ( cid:2242)(cid:4670)(cid:2236),(cid:2026)(cid:2870),(cid:2026)(cid:2870)(cid:4671 ) . ( cid:3097)(cid:3118)(cid:3097)(cid:3116)(cid:3118)(cid:3090)(cid:3284 ) ( cid:3105)(cid:3118)(cid:3033)(cid:3284)(cid:3105)(cid:2242)(cid:3118)(cid:3430)(cid:2180)(cid:2162)(cid:2199)(cid:4666)(cid:2026)(cid:2870)(cid:3397)(cid:2026)(cid:2870)(cid:2019)(cid:4667 ) ( cid:2019)(cid:3435)(cid:2199)(cid:1852)(cid:2199)(cid:2162)(cid:2180)(cid:2236)(cid:3439)(cid:3434)(cid:3430)(cid:2180)(cid:2162)(cid:2199)(cid:4666)(cid:2026)(cid:2870)(cid:3397)(cid:2026)(cid:2870)(cid:2019)(cid:4667 ) ( cid:2019)(cid:3435)(cid:2199)(cid:2182)(cid:2199)(cid:2162)(cid:2180)(cid:2236)(cid:3439)(cid:3434)(cid:1594)0 . , ( cid:3435)(cid:2199)(cid:2182)(cid:2199)(cid:2162)(cid:2180)(cid:2236)(cid:3439 ) ( cid:3435)(cid:2199)(cid:1852)(cid:2199)(cid:2162)(cid:2180)(cid:2236)(cid:3439 ) When the parameters ( cid:2236),(cid:2026),and ( cid:2026 ) are estimated by generalized can be readily shown that the problem ( 9 ) is equivalent to the K nearest neighbor least squares , we can calculate standard residuals and use standard statistic test procedure to identify outliers . This method works well for sample data with small data contamination , but is susceptible to the well known masking and swamping effects when multiple outliers exist . For the GLS model , the masking and swamping effects originate from two phases of the estimation process : 1 ) Phase I contamination occurs in the process of calculating local differences ( cid:2162)(cid:2182 ) . For example , suppose we define neighbors object ( cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3397)(cid:2014 ) , where ( cid:1852)(cid:4666)(cid:2201)(cid:4667 ) is the normal value but it is contaminated by a large error ( cid:2014 ) , and suppose only one of its neighbors is an outlier with ( cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3397)(cid:2014 ) , where ( cid:2014 ) is the local difference diff(cid:3435)(cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667)(cid:3439 ) ( cid:4674)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3012)∑(cid:2201)(cid:2191)(cid:1488)(cid:2170)(cid:4666)(cid:2201)(cid:4667)(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439)(cid:4675)(cid:3397)(cid:2014)(cid:3085)(cid:3012 ) . If ( cid:2014)(cid:1668)(cid:2014 ) , then the outlier object ( cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667 ) which will be identified as a normal object . If ( cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667 ) is a normal object with ζ0 , then the related local difference is contaminated by the error ( cid:2966)K . This leads to the swamping effect where the normal object ( cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667 ) may be misclassified as an outlier . For a relatively large ( eg , 8 ) , it can error is marginalized and we obtain a normal local difference for a contamination error . The rule . Consider be readily shown that Phase I contamination is more significant for a spatial sample with clusters of outliers than a spatial sample with isolated outliers . Another important observation is that the masking and swamping effects will not completely distort the ordering of true outliers . The top ranking outliers are still usually a subset of the true outliers . This observation motivates the backward algorithm presented in Section 43 2 ) Phase II contamination occurs in the generalized regression process , where we regard ( cid:2182)(cid:1499)(cid:2162)(cid:2182 ) as the pseudo "observed" values . The ( eg , ( cid:2236 ) , ( cid:2026 ) , and ( cid:2026 ) ) due to abnormal observations in ( cid:2182)(cid:1499 ) . masking and swamping effects in this phase are the same effects occurred in a general least squares regression process . This is consequence of the biased estimates of the regression parameters outlier by an
1073 the value of K for defining K nearest neighbors , and the
Drawbacks of existing robust estimation techniques : Most existing robust regression techniques are designed to reduce the effect of Phase II contamination . There are two major categories of estimators [ 13 ] . The first category ( also called M estimators ) is to replace the MSE function by more robust score function such as L1 norm and Huber penalty function . The second category is to estimate parameters based on a robustly selected subset of data , such as least median of square ( LMS ) , least trimmed square ( LTS ) , and forward search ( FS ) method . Unfortunately , all these robust techniques cannot be directly applied to address both Phase I and Phase II contaminations concurrently . As with the M estimators , the application of robust penalty function ( eg , L1 ) will lead to a non convex optimization problem where local optimal solution may be found . With the second type of estimators based on subset selection , the estimation results are highly sensitive to the selected objects which can detrimentally impact neighborhood quality . The next sub section will adapt existing robust methods to resolve the problem of concurrently handling Phase I and Phase II contaminations . 4.2 GLS Backward Search Algorithm As discussed above , existing methods only address Phase II contamination . The motivation for our proposed backward search algorithm is to address both Phase I and Phase II contaminations concurrently . The algorithm is described as follows : Algorithm 1 ( Backward search algorithm ) Given a spatial data set ( cid:4668)(cid:1852)(cid:4666)(cid:2201)(cid:4667),…,(cid:1852)(cid:4666)(cid:2201)(cid:4667 ) ( cid:4669 ) , the covariate vectors ( cid:4668)(cid:2206)(cid:4666)(cid:4667),…,(cid:2206)(cid:4666)(cid:2201)(cid:4667)(cid:4669 ) , confidence interval ( cid:2009)(cid:1488)(cid:4666)0,1(cid:4667 ) , 1 . Set ( cid:2175)(cid:3027)(cid:4668)(cid:1852)(cid:4666)(cid:2201)(cid:2778)(cid:4667),…,(cid:1852)(cid:4666)(cid:2201)(cid:2196)(cid:4667 ) ( cid:4669),(cid:2175)(cid:2206)(cid:4668)(cid:2206)(cid:4666)(cid:4667),…,(cid:2206)(cid:4666)(cid:2201)(cid:4667)(cid:4669 ) , and ( cid:3042)(cid:3047)(cid:3043)(cid:3047 ) be an empty set . 2 . Estimate the parameters ( cid:2236),(cid:2026),(cid:2026 ) of the GLS model by solving the generalized least squares regression problem ( cid:4666)9(cid:4667 ) . ( cid:2187)(cid:3427)(cid:1857),…,(cid:1857)|(cid:3020)(cid:3275)|(cid:3431)(cid:3628)(cid:3435)(cid:2026)(cid:2870)(cid:2165)(cid:3397)(cid:2026)(cid:2779)(cid:2162)(cid:2162)(cid:3439)(cid:3117)(cid:3118)(cid:4666)(cid:2162)(cid:2182)(cid:2162)(cid:2180)(cid:2236)(cid:4667)(cid:3628 ) 4 . Set ( cid:1857)(cid:3040)max(cid:4668)(cid:1857)(cid:4669)(cid:2880)|(cid:2175)(cid:3275)| . If ( cid:1857)(cid:3040)(cid:3410)Φ(cid:4666)(cid:2009)/2(cid:4667 ) , where Φ is the CDF of the standard normal distribution , then update ( cid:2175)(cid:3027)(cid:2175)(cid:3027)(cid:4668)(cid:1852)(cid:4666)(cid:2201)(cid:3040)(cid:4667)(cid:4669 ) , ( cid:2175)(cid:2206)(cid:2175)(cid:2206)(cid:4668)(cid:2206)(cid:4666)(cid:2201)(cid:3040)(cid:4667)(cid:4669 ) , and ( cid:2175)(cid:3042)(cid:3047)(cid:3043)(cid:3047)(cid:2175)(cid:3042)(cid:3047)(cid:3043)(cid:3047)(cid:3397)(cid:4668)(cid:1852)(cid:4666)(cid:2201)(cid:3040)(cid:4667)(cid:4669 ) , and Otherwise , stop the algorithm and return ( cid:2175)(cid:3042)(cid:3047)(cid:3043)(cid:3047 ) as the In the above algorithm , the confidence interval ( cid:2009 ) can be set to neighborhood size is large , we may approximate ( cid:2026)(cid:2870)(cid:2162)(cid:2162 ) as ( cid:2026)(cid:2870)(cid:2165 ) . The parameters ( cid:2236),(cid:2026),(cid:2026 ) can be efficiently estimated by least squares regression : ( cid:2236)(cid:4666)(cid:2180)(cid:2162)(cid:2162)(cid:2180)(cid:4667)(cid:2180)(cid:2162)(cid:2162)(cid:2182 ) , and ( cid:4666)(cid:2026)(cid:2870)(cid:3397)(cid:2026)(cid:2870)(cid:4667 ) ( cid:1313)(cid:2162)(cid:2180)(cid:2236)(cid:2162)(cid:2182)(cid:1313)(cid:2870)(cid:2870)/(cid:4666)(cid:1868)1(cid:4667 ) , where ( cid:1868 ) is the size of the vector ( cid:2236 ) . and II contaminations . Suppose a true outlier ( cid:2201 ) is removed after ( cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667 ) is decomposed into two additive components ( cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667 )
This backward search algorithm ’s design is based on the observation that top ranked outliers identified by the least squares techniques are still true outliers ( in most cases ) under both Phase I the first iteration , then both Phase I and Phase II contaminations in the next iteration will be reduced . To illustrate this process , we use the same example in Section 4 . Recall that an outlier object
0.001 , 0.01 , and 005 In step 2 , we apply interior point [ 14 ] method to solve the optimization problem ( 9 ) . When the
3 . Calculate the absolute values of standard estimated residuals ordered set of candidate outliers . go to Step 2 . the local
Then difference
( cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3397)(cid:2014 ) , where ( cid:1852)(cid:4666)(cid:2201)(cid:4667 ) represents the normal value and ( cid:2014 ) represents the contamination error . Suppose ( cid:2201 ) is the only outlier neighbor of an object ( cid:2201 ) that happens to be an outlier as well . diff(cid:3435)(cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667)(cid:3439 ) ( cid:4674)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3012)∑(cid:2201)(cid:2191)(cid:1488)(cid:2170)(cid:4666)(cid:2201)(cid:4667)(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439)(cid:4675)(cid:3397)(cid:2014)(cid:3085)(cid:3012 ) will be marked as normal if ( cid:2014)(cid:1668)(cid:2014 ) . Suppose now that the true outlier ( cid:1852)(cid:4666)(cid:2201)(cid:4667 ) is removed and the newly replaced neighbor for ( cid:2201 ) is normal , then diff(cid:3435)(cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667)(cid:3439)(cid:4674)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3012)∑(cid:2201)(cid:2191)(cid:1488)(cid:2170)(cid:4666)(cid:2201)(cid:4667)(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439)(cid:4675)(cid:3397)(cid:2014 ) . This removed . Similarly , suppose ( cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667 ) is a normal object , then its local difference is contaminated ( swamped ) by the error ( cid:3085)(cid:3012 ) , because of its outlier neighbor ( cid:1852)(cid:4666)(cid:2201)(cid:4667 ) . The removal of ( cid:2201 ) will make ( cid:3085)(cid:3012)0 , thus reducing the swamping effect . For Phase II contamination , the removal of ( cid:1852)(cid:4666)(cid:2201)(cid:4667 ) leads to the removal of an abnormal difference diff(cid:3435)(cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667)(cid:3439 ) . The set of remaining local local difference becomes an abnormal value and the masking effect is differences will therefore have less contamination . The center of the distribution is less attracted by outliers , and the distributional shape becomes less distorted . As a result , outliers tend to be more separated and normal objects tend to be closer together . The masking and swamping effects are therefore reduced . 4.3 GLS Forward Search Algorithm This section adapts the popular Forward Search ( FR ) algorithm [ 13 ] to the GLS parameters estimation problem . There are several restrictions to apply FR here . As discussed in Section 4.1 , FR starts from a robustly selected subset of sample , but GLS is a statistical model based on neighborhood aggregations . will significantly impact the quality of the calculated local differences . To apply FR algorithm , we make the assumption that Phase I contamination is negligible compared to Phase II contamination . As discussed in Section 4.1 , this is reasonable for the case of isolated outliers . Based on this assumption , we pseudo "observations" , and then apply FR algorithm to estimate the model parameters . By simulations , we also noticed that in this case there is no significant difference on accuracy between the GLS forms ( 6 ) and ( 7 ) . For the sake of efficiency , we only consider the GLS form ( 7 ) and apply regular least squares
Considering only a subset of the observations ( cid:4668)(cid:1852)(cid:4666)(cid:4667),…,(cid:1852)(cid:4666)(cid:4667)(cid:4669 ) consider the local differences ( cid:3419)diff(cid:3435)(cid:1852)(cid:4666)(cid:4667)(cid:3439),…,diff(cid:3435)(cid:1852)(cid:4666)(cid:4667)(cid:3439)(cid:3423 ) as regression to estimate the parameters ( cid:2010),(cid:2026 ) , and ( cid:2026 ) . The forward set ( cid:4668)(cid:1852)(cid:4666)(cid:2201)(cid:4667),…,(cid:1852)(cid:4666)(cid:2201)(cid:4667 ) ( cid:4669 ) , the covariate vectors ( cid:4668)(cid:2206)(cid:4666)(cid:4667),…,(cid:2206)(cid:4666)(cid:2201)(cid:4667)(cid:4669 ) , 1 . Calculate the local differences : ( cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667)(cid:2162)(cid:2182 ) , and set ( cid:2175)(cid:3042)(cid:3047)(cid:3043)(cid:3047 ) be an empty set . 2 . Set ( cid:2175)(cid:4668)(cid:2201),,(cid:2201)(cid:4669),(cid:2182)(cid:1499)(cid:4666)(cid:2175)(cid:4667)(cid:4670)(cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667),…,(cid:1852)(cid:1499)(cid:4666)(cid:2201)(cid:4667)(cid:4671)(cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667 ) , and ( cid:2180)(cid:1499)(cid:4666)(cid:2175)(cid:4667)(cid:4670)(cid:2206)(cid:1499)(cid:4666)(cid:2201)(cid:2778)(cid:4667),…,(cid:2206)(cid:1499)(cid:4666)(cid:2201)(cid:4667)(cid:4671 ) = ( cid:2162)(cid:2180 ) as the vector of subset of ( cid:2175 ) , defined as ( cid:2175)(cid:1499 ) , and set ( cid:2175)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) ( cid:1499 ) ( cid:2175)(cid:2175)(cid:1499 ) . The size of the subset ( cid:2175)(cid:1499 ) is ( cid:1729)(cid:4666)(cid:3397)(cid:1868)(cid:3397)1(cid:4667)/2(cid:1730 ) by default . 4 . Estimate the parameter ( cid:2236 ) based on ( cid:2182)(cid:1499)(cid:4666)(cid:2175)(cid:1499)(cid:4667 ) and ( cid:2180)(cid:1499)(cid:4666)(cid:2175)(cid:1499)(cid:4667 ) . Then calculate the absolute standard residuals of ( cid:2175)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) as ( cid:2187 ) ( cid:1499 ) ( cid:3493)(cid:4666)(cid:1868)1(cid:4667)|(cid:2182)(cid:1499)(cid:4666)(cid:2175)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) ( cid:4667)(cid:2236)|/(cid:1313)(cid:2182)(cid:1499)(cid:4666)(cid:2175)(cid:4667)(cid:2180)(cid:1499)(cid:4666)(cid:2175)(cid:4667)(cid:2236)(cid:1313)(cid:2870 ) . ( cid:4667)(cid:2180)(cid:1499)(cid:4666)(cid:2175)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) ( cid:1499 ) ( cid:1499 ) 5 . Find the minimal residual of the test set ( cid:2175)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) ( cid:1499 ) search algorithm is described as follows : Algorithm 2 ( Forward Search algorithm ) Given a spatial data
3 . Apply least trimmed squares ( LTS ) [ 13 ] to identify a robust and the value of K for defining K nearest neighbors , pseudo “ observations ” and pseudo “ covariates ” .
:
1074 . that is not empty , go to step 4 ; otherwise ,
The proposed FR algorithm provides an ordering of objects based on their agreements with the GLS model . To identify outliers , it plots and monitors the change of the minimal residual
( cid:1857)(cid:3040)min(cid:4668)(cid:1857)(cid:4669)(cid:3032)(cid:3284)(cid:1488)(cid:3020)(cid:3295)(cid:3280)(cid:3294)(cid:3295)(cid:1499 ) 6 . Update ( cid:2175)(cid:3042)(cid:3047)(cid:3043)(cid:3047)(cid:2175)(cid:3042)(cid:3047)(cid:3043)(cid:3047)(cid:3397)(cid:4668)(cid:2201)(cid:3040)(cid:4669),(cid:2175)(cid:1499)(cid:2175)(cid:1499)(cid:3397)(cid:4668)(cid:2201)(cid:3040)(cid:4669),(cid:2175)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) ( cid:1499 ) ( cid:1499 ) ( cid:4668)(cid:2201)(cid:3040)(cid:4669 ) . If ( cid:2175)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) ( cid:2175)(cid:3047)(cid:3032)(cid:3046)(cid:3047 ) ( cid:1499 ) output the ordered set ( cid:2175)(cid:3042)(cid:3047)(cid:3043)(cid:3047 ) and terminate the algorithm . with the increasing size of the normal set ( cid:2175)(cid:1499 ) . A drastic drop implies that an outlier was added to ( cid:2175)(cid:1499 ) . This plot could also help ( cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667 ) ~ ( cid:1788)(cid:4666)(cid:2162)(cid:2180)(cid:2236),(cid:2162)(cid:2227)(cid:2162)(cid:3397)(cid:2026)(cid:2870)(cid:2162)(cid:2162)(cid:4667 ) . If we replace the left hand side ( cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667)(cid:2162)(cid:2182 ) by medians or trimmed means , the right side matrix ( cid:2162 ) . The increased bias caused by this inconsistency is much identify masked or swamped objects . Readers are referred to [ 13 ] for details . A direct method for calculating the local differences can be achieved via robust mean functions such as median and trimmed mean . However , as indicated by our simulation study , this direct approach will deteriorate the performance of GLS . Recall the form will remain unchanged and thus still employs the average the statistical model of GLS has larger than the reduction of contamination effects achieved through robust means . 4.4 Connections with Existing Methods This section studies the connection between global ( kriging ) based [ 11 , 12 , 13 ] , local statistics ( LS ) based [ 4 10 ] , and the proposed GLS SOD methods . First , we review the first two approaches : Kriging SOD and LS SOD . Kriging SOD basically applies robust methods to estimate the parameters of a global kriging model . The method then uses the estimated statistical model to predict the ( cid:1852 ) attribute value of each sample location ( cid:2201 ) , denoted as ( cid:1852)(cid:4632)(cid:4666)(cid:2201)(cid:4667 ) , based on the ( cid:1852 ) values of other locations . The standardized residual ( cid:3435)(cid:3627)(cid:1852)(cid:4632)(cid:4666)(cid:2201)(cid:4667)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3627)/(cid:2026)(cid:2201)(cid:3439 ) follows a standard normal distribution , where ( cid:2026)(cid:2201 ) is the estimated standard deviation . If a residual is outside the range ( cid:4670)Φ(cid:4666)(cid:2009)/2(cid:4667),Φ(cid:4666)(cid:2009)/2(cid:4667)(cid:4671 ) , the corresponding object is reported as an outlier , where Φ is the CDF and ( cid:2009 ) is usually set as 005 The LS SOD method assumes that ( cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667 ) ~ ( cid:2170)(cid:4666)(cid:2020)(cid:1668)(cid:2778),(cid:2026)(cid:2870)(cid:2165)(cid:4667 ) . The components in ( cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667 ) can be regarded as iid sample points of a normal distribution ( cid:1840)(cid:4666)(cid:2020),(cid:2026)(cid:2870)(cid:4667 ) . Robust techniques are then designed to estimate ( cid:2020 ) and ( cid:2026 ) . The Theorem 5 : Suppose that ( cid:2162)(cid:2227)(cid:2162)(cid:2026)(cid:2870)(cid:2165 ) and the parameters of remaining steps are similar to Kriging SOD .
Kriging SOD and GLS SOD are correctly calculated by robust estimations , then Kriging SOD and GLS SOD are equivalent . Proof : For Kriging SOD , we consider a universal kriging model [ 1 ] , since other kriging models ( eg , ordinary kriging ) are simply special cases . It suffices to prove that the standardized residuals calculated by Kriging SOD and GLS SOD are identical . Without loss of generality , we test the standardized residual of one particular sample point ( cid:1852)(cid:4666)(cid:2201)(cid:4667 ) . Let ( cid:2182)(cid:1499)(cid:4670)(cid:1852)(cid:4666)(cid:2201)(cid:4667),…,(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:4671 ) and ( cid:2182)(cid:3427)(cid:2182)(cid:1499)(cid:2176),(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3431)T ( cid:2182)~(cid:2170)(cid:4666)(cid:2180)(cid:2236),(cid:2160)(cid:4667 ) , where ( cid:2160)(cid:2737)(cid:3397)(cid:2026)(cid:2870)(cid:2165)(cid:3428)(cid:2737)(cid:1499 ) ( cid:2252 ) ( cid:2252 ) ( cid:2026)(cid:2870)(cid:3432),Var(cid:4666)(cid:2182)(cid:1499)(cid:4667)(cid:2737)(cid:1499 ) , Cov(cid:4666)(cid:1852)(cid:4666)(cid:2201)(cid:4667),(cid:2182)(cid:1499)(cid:4667)(cid:2763 ) , and Var(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439)(cid:2026)(cid:2870 ) . StdRsd(cid:3012)(cid:3045)(cid:3034)(cid:3034)(cid:3020)(cid:3016)(cid:3005)(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439)(cid:3427)(cid:2206)(cid:2236)(cid:3397)(cid:2763)(cid:1794)(cid:2737)(cid:1499)(cid:2778)(cid:4666)(cid:2182)(cid:1499)(cid:2180)(cid:1499)(cid:2236)(cid:4667)(cid:3431 ) ( cid:2026)(cid:2763)(cid:1794)(cid:2737)(cid:1499)(cid:2778)(cid:2252 )
Then , the standard residual by Kriging SOD is
. By Section 3.1 Equation 3 , we have that
The standard residual by LS SOD is
It that
Then , follows
The following will prove that
StdRsd(cid:3008)(cid:3013)(cid:3020)(cid:3020)(cid:3016)(cid:3005)(cid:4672)diff(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439)(cid:4673)(cid:3428)(cid:4666)(cid:2026)(cid:2165)(cid:3397)(cid:2026)(cid:2779)(cid:2162)(cid:2162)(cid:4667)(cid:2870)(cid:4666)(cid:2162)(cid:2182)(cid:2162)(cid:2180)(cid:2236)(cid:4667)(cid:3432 ) StdRsd(cid:3012)(cid:3045)(cid:3034)(cid:3034)(cid:3020)(cid:3016)(cid:3005)(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439)StdRsd(cid:3008)(cid:3013)(cid:3020)(cid:3020)(cid:3016)(cid:3005)(cid:4672)diff(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439)(cid:4673 ) The condition ( cid:2162)(cid:2227)(cid:2162)(cid:2026)(cid:2870)(cid:2165 ) implies(cid:2026)(cid:2870)(cid:2165)(cid:3397)(cid:2026)(cid:2779)(cid:2162)(cid:2162)(cid:2162)(cid:2227)(cid:2162)(cid:3397 ) ( cid:2026)(cid:2779)(cid:2162)(cid:2162)(cid:2162)(cid:2160)(cid:2162),and ( cid:4666)(cid:2026)(cid:2165)(cid:3397)(cid:2026)(cid:2162)(cid:2162)(cid:4667)(cid:3117)(cid:3118)(cid:4666)(cid:2162)(cid:2160)(cid:2162)(cid:4667)(cid:3117)(cid:3118)(cid:4672)(cid:2162)(cid:2160)(cid:3117)(cid:3118)(cid:4673 ) ( cid:4666)(cid:2026)(cid:2165)(cid:3397)(cid:2026)(cid:2162)(cid:2162)(cid:4667)(cid:3117)(cid:3118)(cid:4666)(cid:2162)(cid:2182)(cid:2162)(cid:2180)(cid:2236)(cid:4667 ) ( cid:2160)(cid:3117)(cid:3118)(cid:2162 ) . ( cid:2160)(cid:3117)(cid:3118)(cid:2162)(cid:4666)(cid:2162)(cid:2182)(cid:2162)(cid:2180)(cid:2236)(cid:4667)(cid:2160)(cid:3117)(cid:3118)(cid:4666)(cid:2182)(cid:2180)(cid:2236)(cid:4667 ) . ( cid:2252 ) Further , given that ( cid:2160)(cid:3428)(cid:2737)(cid:1499 ) ( cid:2252 ) ( cid:2026)(cid:3432 ) , it can be readily derived that ( cid:2160)(cid:2870)(cid:1743)(cid:1742)(cid:1742)(cid:1742)(cid:1741)(cid:4680)(cid:2159)(cid:3397)(cid:2159)(cid:2870)(cid:2870)(cid:2737)(cid:1499)(cid:2252)(cid:2252)(cid:2737)(cid:1499)(cid:4681)(cid:2870 ) ( cid:2159)(cid:2779)(cid:2870)(cid:1746)(cid:1745)(cid:1745)(cid:1745)(cid:1744 ) , ( cid:2777 ) ( cid:2252)(cid:2737)(cid:1499)(cid:2159)(cid:2779)(cid:2870 ) where ( cid:2159)(cid:2778)(cid:2737)(cid:1499)(cid:2026)(cid:2252)(cid:2252)(cid:2176 ) and ( cid:2159)(cid:2779)(cid:2026)(cid:2252)(cid:2176)(cid:2737)(cid:1499)(cid:2778)(cid:2252 ) . ( cid:4674)(cid:4666)(cid:2026)(cid:2165)(cid:3397)(cid:2026)(cid:2162)(cid:2162)(cid:4667)(cid:3117)(cid:3118)(cid:4666)(cid:2162)(cid:2182)(cid:2162)(cid:2180)(cid:2236)(cid:4667)(cid:4675)(cid:4674)(cid:2160)(cid:3117)(cid:3118)(cid:4666)(cid:2182)(cid:2180)(cid:2236)(cid:4667)(cid:4675 ) ( cid:4680)(cid:2160)(cid:3117)(cid:3118)(cid:3428)(cid:2180)(cid:1499)(cid:2236)(cid:2206)(cid:2236)(cid:3432)(cid:4681)(cid:2159)(cid:2779)(cid:3117)(cid:3118)(cid:2252)(cid:2737)(cid:1499)(cid:2180)(cid:1499)(cid:2236)(cid:3397)(cid:2159)(cid:2779)(cid:3117)(cid:3118)(cid:2206)(cid:2236)(cid:3419)(cid:2206)(cid:2236)(cid:3397 ) ( cid:2763)(cid:1794)(cid:2737)(cid:1499)(cid:2778)(cid:4666)(cid:2182)(cid:1499)(cid:2180)(cid:1499)(cid:2236)(cid:4667)(cid:3423)/(cid:4666)(cid:2026)(cid:2763)(cid:1794)(cid:2737)(cid:1499)(cid:2778)(cid:2252)(cid:4667 ) . StdRsd(cid:3012)(cid:3045)(cid:3034)(cid:3034)(cid:3020)(cid:3016)(cid:3005)(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439)StdRsd(cid:3008)(cid:3013)(cid:3020)(cid:3020)(cid:3016)(cid:3005)(cid:4672)diff(cid:3435)(cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:3439)(cid:4673 ) , Theorem 6 . If ( cid:2162)(cid:2227)(cid:2162)(cid:2026)(cid:2870)(cid:2165 ) , ( cid:2026)(cid:2870)(cid:2162)(cid:2162)(cid:2026)(cid:2870)(cid:2165 ) , the parameters of ( 1 ) ( cid:2182)(cid:4666)(cid:2201)(cid:4667 ) has a constant trend ( mean ) : ( cid:2180)(cid:2236)c(cid:1783 ) , where c is a ( 2 ) ( cid:2182)(cid:4666)(cid:2201)(cid:4667 ) is a linear trend of spatial coordinates , and each point that ( cid:2162)(cid:2180)(cid:2236)(cid:2777 ) . By conditions ( cid:2162)(cid:2227)(cid:2162)(cid:2026)(cid:2870)(cid:2165 ) and ( cid:2026)(cid:2870)(cid:2162)(cid:2162)(cid:2026)(cid:2870)(cid:2165 ) , we have ( cid:2162)(cid:2182)~(cid:1840)(cid:4666)0,(cid:4666)(cid:2026)(cid:2870)(cid:3397)(cid:2026)(cid:2870)(cid:4667)(cid:2165)(cid:4667 ) which is consistent with the iid SOD . LS SOD assumes Var(cid:3435)(cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667)(cid:3439)(cid:2026)(cid:2779)(cid:2165 ) for some constant ( cid:2026 ) , Section 3.1 discusses the situations where Var(cid:3435)(cid:1804)(cid:1809)(cid:1806)(cid:1806)(cid:4666)(cid:2182)(cid:4667)(cid:3439 ) can be approximated by ( cid:4666)(cid:2026)(cid:2870)(cid:3397)(cid:2026)(cid:2870)(cid:4667)(cid:2165 ) . Furthermore , under the conditions conditions also include "(cid:2162)(cid:2227)(cid:2162)(cid:2026)(cid:2870)(cid:2165)" , then by Theorem 4 we assumption in LS SOD . If we use the same robust methods to estimate the parameters , such as using median and median absolute deviation ( MAD ) to estimate the mean and standard deviation , then GLS SOD becomes equivalent to LS SOD . , Discussion : By Theorem 6 , LS SOD is a special form of GLS
GLS SOD and LS SOD are correctly calculated by robust estimations , and one of the following conditions is true , then GLSSOD becomes equivalent to LS SOD . but no justifications are presented . From this perspective , GLSSOD actually provides a theoretical foundation for LS SOD . of Theorem 6 , LS SOD is equivalent to GLS SOD and since the
Proof : For either condition ( 1 ) or ( 2 ) , it can be readily derived
We conclude that Kriging SOD and GLS SOD are equivalent . , s is the geometric center ( or centroid ) of its neighbors .
The above indicates that constant value . have that GLS SOD is equivalent to Kriging SOD . Therefore , LSSOD becomes equivalent to Kriging SOD in this situation . Hence , it can be seen that the proposed GLS framework can be parameterized to become instances of LS SOD or Kriging SOD . Further study on various outlier detection methods can be greatly enhanced under the lens of this unifying GLS framework .
1075 As discussed in Section 3.1 , ( cid:2162)(cid:2227)(cid:2162 ) can be reasonably approximated by ( cid:2026)(cid:2870)(cid:2165 ) . From Theorem 5 , the major difference impacted . Second , GLS SOD between Kriging SOD and GLS SOD is for which approach the related model parameters can be estimated more accurately and efficiently . From this perspective , GLS SOD is superior to Kriging SOD based on three major reasons : First , GLS SOD has less uncertainty than Kriging SOD , since Kriging SOD needs to further assume a semivariogram model . If the semivariogram model is not selected properly , the performance may be significantly is a convex optimization problem and therefore a global optimal solution exists . However , Kriging SOD is a non convex optimization problem and relies on an iteratively reweighted generalized least square ( IRWGLS ) approach [ 12 ] to determine a local solution . Finally , as shown in Section 5 simulations , GLS SOD runtime performance is superior to Kriging SOD . 5 . SIMULATIONS This section conducts extensive simulations to compare the performance between the proposed GLS based SOD methods and other related SOD methods . The experimental study follows the standard statistical approach for evaluating the performance of spatial outlier detection methods presented in [ 11 , 12 , 1 , 2 ] . 5.1 Simulation Settings Data set : The simulation data are generated based on the following statistical model :
We consider two popular covariogram models : spherical model and exponential model . See Equation 8 in Section 3.2 for the definition of spherical model . The exponential model is defined as
( cid:1852)(cid:4666)(cid:2201)(cid:4667)(cid:2206)(cid:2176)(cid:4666)(cid:2201)(cid:4667)(cid:2236)(cid:3397)(cid:2033)(cid:4666)(cid:2201)(cid:4667)(cid:3397)(cid:2035)(cid:4666)(cid:2201)(cid:4667 ) , ( See Section 3.1 ) where ( cid:2033)(cid:4666)(cid:2201)(cid:4667 ) is a Gaussian random field with covariogram model ( cid:1829)(cid:4666)(cid:1860);(cid:2242)(cid:4667 ) . ( cid:1829)(cid:4666)(cid:1860);(cid:2242)(cid:4667)(cid:3422)(cid:1854 ) ( cid:1861)(cid:1858 ) ( cid:1860)0 ( cid:1854)(cid:4672)1exp(cid:4672)(cid:3035)(cid:3030)(cid:4673)(cid:4673 ) ( cid:1861)(cid:1858 ) 0(cid:1860)(cid:1855 ) 0 ( cid:1861)(cid:1858 ) ( cid:1860)(cid:3408)(cid:1855 ) , These two models have the same parameters ( cid:1854 ) and ( cid:1855 ) . Recall that ( cid:1854 ) is also the constant variance for each ( cid:1852)(cid:4666)(cid:2201)(cid:4667 ) . component ( cid:2206)(cid:2176)(cid:4666)(cid:2201)(cid:4667)(cid:2236 ) , we define ( cid:2206)(cid:4666)(cid:2201)(cid:4667 ) ( cid:4670)1,(cid:1876)(cid:4666)(cid:2201)(cid:4667),(cid:1877)(cid:4666)(cid:2201)(cid:4667),(cid:1876)(cid:4666)(cid:2201)(cid:4667)(cid:1668)(cid:1877)(cid:4666)(cid:2201)(cid:4667),(cid:1876)(cid:4666)(cid:2201)(cid:4667)(cid:2870),(cid:1877)(cid:4666)(cid:2201)(cid:4667)(cid:2870 ) ( cid:4671 ) , where ( cid:1876)(cid:4666)(cid:2201)(cid:4667 ) and ( cid:1877)(cid:4666)(cid:2201)(cid:4667 ) be the X and Y coordinates of the location ( cid:2201 ) . This implies that the trend ( cid:2206)(cid:4666)(cid:2201)(cid:4667)(cid:2236 ) is a polynomial of order two . The nonlinearity of the trend is decided by the regression parameters ( cid:2236 ) . For example , if ( cid:2236)(cid:4670)1,0,0,0,0,0(cid:4671)(cid:2176),then ( cid:2236)(cid:4670)1,1,1,0,0,0(cid:4671)(cid:2176 ) , then the trend is linear . There are three related parameters ( cid:2026),(cid:2026)(cid:3004 ) and ( cid:2009 ) . ( cid:2026)(cid:2870 ) is the variance of a normal white noise , ( cid:2026)(cid:3004)(cid:2870 ) is the variance of contaminated error that generates outliers , and ( cid:2009 ) is used to control ( cid:1840)(cid:4666)0,(cid:2026)(cid:3004)(cid:2870)(cid:4667 ) will also generate some normal white noises . All true random cluster of ( cid:1668)(cid:2009 ) points follow ( cid:1840)(cid:4666)0,(cid:2026)(cid:3004)(cid:2870)(cid:4667 ) . In the simulations ,
( cid:2035)(cid:4666)(cid:2201)(cid:4667)~(cid:1840)(cid:4666)0,(cid:2026)(cid:2870)(cid:4667 ) with probability 1(cid:2009 ) ( cid:1840)(cid:4666)0,(cid:2026)(cid:3004)(cid:2870)(cid:4667 ) with probability ( cid:2009 ) outliers must be only identified based on standard statistical test by calculating the conditional mean and standard deviation for each observation [ 2 ] . We also consider the case of clustered outliers . This can be simulated by constraining that the noises of a the number of outliers . Note that it is possible the distribution
For the white noise component , we employ the standard model : constant ; trend
( 11 )
For the trend the is if we tested several representative settings for each parameter , which are summarized in Table 2 .
Table 2 : Combination of Parameter settings
Variable
( cid:1854),(cid:1855 ) ( cid:2236 ) ( cid:2026),(cid:2026)(cid:3004 ) ( cid:2009 )
Settings
( cid:1488)100,200 . Randomly generate spatial locations ( cid:4668)(cid:2201)(cid:4669)(cid:2880 ) in the range ( cid:4670)0,25(cid:4671)(cid:3400)(cid:4670)0,25(cid:4671 ) . ( cid:1854)5;(cid:1855)5,15,25 For constant trend , ( cid:2010)~(cid:1847)(cid:4666)0,1(cid:4667 ) and(cid:2010)0,(cid:1861 ) 2,…,5 ; For linear trend , ( cid:4668)(cid:2010),(cid:2010)(cid:2870),(cid:2010)(cid:2871)(cid:4669)(cid:1488)(cid:1847)(cid:4666)0,1(cid:4667 ) , ( cid:2010)0 , ( cid:1861)4,5,6 ; For nonlinear trend , ( cid:4668)(cid:2010)(cid:4669)(cid:2880)(cid:2874 ) ( cid:1488 ) ( cid:1847)(cid:4666)0,1(cid:4667 ) . ( cid:2026)(cid:2870)2,10;(cid:2026)(cid:3004)(cid:2870)20 ( cid:2009)005,010,015 4,8
Covariance model
Exponential , spherical
Outlier type
Isolated , Clustered to
Outlier detection methods : We compared our methods with the state of the art local and global based SOD methods , including Ztest [ 4 ] , Median Z test [ 6 ] , Iterative Z test [ 5 ] , trimmed Z test [ 7 ] , SLOM test [ 8 ] , and universal kriging ( UK ) based forward search [ 11,12 ] ( noted as UK forward ) . Our proposed methods are identified as GLS backward G , GLS backward R , and GLSforward R . GLS backward G refers the GLS backward algorithm using generalized least squares regression . GLSbackward R refers to the GLS backward algorithm using regular least square regression ( See Sections 4.2 and 43 ) The implementations of all existing methods are based on their published algorithm descriptions . Performance metric : We tested the performance of all methods for every combination of parameter setting in Table 2 . For each specific combination , we ran the experiments six times and then calculated the mean and standard deviation of accuracy for each method . To compare the accuracies of each method , we used the standard ROC curves . We further collected accuracies of top 10 , 15 , and 20 ranked outlier candidates for each method , and then the counts of winners are shown in Table 3 . To calculate these winning counts , we used as an example the GLS backward R result in the top left cell of table 4 : "47 , 47 , 45" . This column refers to the constant trend cases . If within this particular case , we only consider the true accuracy of the top 10 candidate outliers , then times over all combination of parameters against all other methods . A win is given the highest accuracy . Consequently , if we consider the true accuracy of the top 20 candidate outliers , then the GLS backward R has won 45 times . All the simulations were conducted on a PC with Intel ( R ) Core ( TM ) Duo CPU , CPU 2.80 GHz , and 2.00 GB memory . The development tool is MATLAB 2008 . 5.2 Detection Accuracy We compared the outlier detection accuracies of different methods based on different combinations of parameter settings as shown in Table 2 . Six representative results are displayed in Figure 3 . First we considered the detection performance between the GLS backward R has “ won ” 47 that exhibits the method to
1076 local based methods . For a constant trend , our methods were competitive with existing techniques . For data sets exhibiting linear trends , our GLS algorithms achieved an average 10 % improvement over existing local based methods . However , for data sets with nonlinear trends , our GLS algorithms exhibited more significant improvement ( approximately 50 % increase ) over existing local methods . For the other combination of parameter settings in Table 2 , the winning statistics for each method are displayed in Table 3 . These results further justify the preceding performance results . We also compared our GLS algorithms against the global based method UK forward . Overall , our methods were comparable to UK forward . Particularly , GLS backward G attained better accuracy than UK forward on about half of the data sets . For the remaining data sets , the GLS backward G was still competitive to the UK forward . Additionally , as shown in Section 5.3 , the UKforward incurred a significantly much higher computational cost than the GLS algorithms . As discussed in section 4.1 , when K is small , the effects of ( cid:2026)(cid:2870)(cid:2162)(cid:2162 ) must be considered and a generalized least regression is necessary . The theorems indicate that GLSbackward G should perform better then GLS backward R , this was justified in Figure 3 c ) .
Table 3 : Competition statistics for different combinations of parameter settings . Each cell contains 3 values , representing the win times for the related method on the accuracies of top 10 , 15 , and 20 ranked outlier candidates for all methods . Algorithm
Linear Trend Nonlinear
Constant Trend 47 , 47 , 45 88 , 86 , 89 13 , 11 , 14 47 , 35 , 40 35 , 46 , 63 20 , 23 , 29 15 , 23 , 32 0,0 , 0
GLS backward R GLS backward G GLS forward R Z test Iterative Z test Median Z test Trimmed Z test SLOM test
79 , 72 , 82 114,102,120 22 , 25 , 27 29 , 30 , 13 16 , 20 , 21 1 , 7 , 8 5 , 13 , 13 0 , 0 , 0
Trend 76 , 81 , 77 141,144 , 138 40 , 36 , 47 0 , 0 , 0 0 , 0 , 0 0 , 0 , 0 0 , 0 , 0 0 , 0 , 0
5.3 Computational Cost The comparison on computational cost is shown in Figure 2 . The results indicate that the time cost of UK forward is much higher than other methods . Even the second slowest method GLSbackward G , is still three times faster than UK forward . The other local methods are approximately equal and hence much faster than UK forward . From the comparisons of both the accuracy and computational cost , it can be seen that our proposed GLS SOD algorithms ( especially GLS backward G ) is significantly more accurate than existing local based algorithms when the spatial data exhibits either a linear or nonlinear spatial trend . Our GLS algorithms are comparable to the global based method UK forward on accuracy , but significantly faster than UK forward .
Computational Cost ( Seconds ) trend , isolated outliers , ( cid:2235)(cid:2777).(cid:2778),(cid:2252)(cid:2777)(cid:2779)(cid:2779),(cid:2185)(cid:2778)(cid:2782),(cid:2167)(cid:2785),(cid:2196)(cid:2779)(cid:2777)(cid:2777 ) )
Figure 2 : Comparison on computational cost ( setting : Linear
6 . CONCLUSTION AND FUTURE WORK This paper presents a generalized local statistical ( GLS ) framework for existing local based methods . This generalized statistical framework not only provides theoretical foundations for local based methods , but can also significantly enhance spatial outlier detection methods . This is the first paper to present the theoretical connection between local and global based SOD methods under the GLS framework . As future work we will design other algorithms to further improve the efficiency of the GLS backward and forward methods . 7 . REFERENCES [ 1 ] Cressie , NA 1993 . Statistics for Spatial Data , Wiley . [ 2 ] Schabenberger O . and Gotway C . A . 2005 Statistical
Methods for Spatial Data Analysis . Boca Raton : Chapman and Hall–CRC , Boca Raton , Florida .
[ 3 ] Tobler , W . R . 1979 . Cellular geography , in Philosophy in
Geography , Reidel , Dordrecht , 379–386 .
[ 4 ] Shekhar , S . , Lu , C T and Zhang , P . 2003 . A Unified
Approach to Spatial Outliers Detection , Journal of GeoInformatica , vol . 7 , No.2 , 139 166 .
[ 5 ] Lu , C T , Chen , D . and Kou , Y . 2003 . Algorithms for
Spatial Outlier Detection , In Proceedings of the 3rd IEEE International Conference on Data Mining , 597 600 .
[ 6 ] Lu , C T , Chen , D . and Chen , F . 2008 . On Detecting Spatial
Outliers , Journal of Geoinformatica , vol . 12 , 455 475 .
[ 7 ] Hu , T . and Sung , SY 2004 . A trimmed mean approach to finding spatial outliers , J . Intell Data Anal , vol . 8 , 79 95 . [ 8 ] Sun , P . and Chawla , S . 2004 . On Local Spatial Outliers ,
Proc . 4th IEEE Int’l Conf . on Data Mining , 209–216 .
[ 9 ] S . Shekhar , Lu , C T and Zhang , P . 2001 . Detecting graph based spatial outliers : algorithms and applications ( a summary of results ) . SIGKDD , 365 370 .
[ 10 ] Christensen , R . , Johnson , W . and Pearson , LM , 1993 .
Covariance function diagnostics for spatial linear models . Math . Geol . vol . 25 , 145–160 .
[ 11 ] Cerioli , A . and Riani , M . 1999 . The ordering of spatial data and the detection of multiple outliers . J . Comput . Graphical Statist , vol . 8 , 239–258 .
[ 12 ] Militino , AF , Palacios , MB and Ugarte , MD 2006 .
Outlier detection in multivariate spatial linear models , J . Stat Plann Infer , vol . 136 , 125 146 .
1077 [ 13 ] Atkinson , AC and Riani , M . 2000 . Robust Diagnostics
Regression Analysis . Springer Series in Statistics . Springer . [ 14 ] S . Boyd and L . Vanderberghe . 2004 . Convex Optimization .
Cambridge Univ . Press .
[ 15 ] Chen . F , Lu , C T , and Boedihardjo , Arnold P . , 2010 . GLSSOD : A Generalized Local Statistical Approach for Spatial Outlier Detection . Technical Report TR 10 03 , Computer Science , Virginia Tech . a ) Constant trend , isolated outliers , ( cid:2235)(cid:2777).(cid:2778),(cid:2252)(cid:2777)(cid:2779)(cid:2779),(cid:2185)(cid:2778)(cid:2782),(cid:2167)(cid:2781 ) b ) Linear trend , isolated outliers , ( cid:2235)(cid:2777).(cid:2778),(cid:2252)(cid:2777)(cid:2779)(cid:2779),(cid:2185)(cid:2778)(cid:2782),(cid:2167)(cid:2785 ) c ) Nonlinear trend , isolated outliers , ( cid:2235)(cid:2777).(cid:2778)(cid:2782),(cid:2252)(cid:2777)(cid:2779)(cid:2778)(cid:2777),(cid:2185)(cid:2778)(cid:2782),(cid:2167)(cid:2781 ) d ) Constant trend , cluster outliers , ( cid:2235)(cid:2777).(cid:2778),(cid:2252)(cid:2777)(cid:2779)(cid:2779),(cid:2185)(cid:2779)(cid:2782),(cid:2167)(cid:2781 ) e ) Linear trend , cluster outliers , ( cid:2235)(cid:2777).(cid:2778)(cid:2782),(cid:2252)(cid:2777)(cid:2779)(cid:2779),(cid:2185)(cid:2779)(cid:2782),(cid:2167)(cid:2785 )
Figure 3 : Outlier ROC Curve Comparison ( the same setting : ( cid:2196)(cid:2779)(cid:2777)(cid:2777),(cid:2184)(cid:2782),(cid:2252)(cid:2159)(cid:2779)(cid:2779)(cid:2777 ) ) f ) Nonlinear trend , cluster outliers , ( cid:2235)(cid:2777).(cid:2778)(cid:2782),(cid:2252)(cid:2777)(cid:2779)(cid:2778)(cid:2777),(cid:2185)(cid:2782),(cid:2167)(cid:2785 )
1078
