Frequent Regular Itemset Mining
Dipartimento di Informatica , Università di Pisa
Largo B . Pontecorvo 3 , 56127 Pisa , Italy
Salvatore Ruggieri ruggieri@diunipiit
ABSTRACT Concise representations of frequent itemsets sacrifice readability and direct interpretability by a data analyst of the concise patterns extracted . In this paper , we introduce an extension of itemsets , called regular , with an immediate semantics and interpretability , and a conciseness comparable to closed itemsets . Regular itemsets allow for specifying that an item may or may not be present ; that any subset of an itemset may be present ; and that any non empty subset of an itemset may be present . We devise a procedure , called RegularMine , for mining a set of regular itemsets that is a concise representation of frequent itemsets . The procedure computes a covering , in terms of regular itemsets , of the frequent itemsets in the class of equivalence of a closed one . We report experimental results on several standard dense and sparse datasets that validate the proposed approach .
Categories and Subject Descriptors H28 [ Database Management ] : Database ApplicationsData Mining
General Terms Algorithms
Keywords Concise Representations , Closed and Free Itemsets
1 .
INTRODUCTION
The intended objective of concise representations is to alleviate the problems due to extracting , storing and postprocessing a huge amount of frequent patterns . They sacrifice readability and direct interpretability by a data analyst in favor of a compact , lossless representation , where itemsets whose support is derivable from others are pruned away . Closed itemsets [ 2 ] are a concise representation of frequent itemsets , yet not the only one [ 4 , 5 , 6 , 7 , 12 , 13 , 16 ] , surely tid transaction 1 2 3 4 abcde abcd b ac cover
{1 ; 2} {1 ; 2 ; 3} {1 ; 2 ; 4} closed free d ba abcd bc b a c b ac regular d{abc}⋆ b{ac}+ b {ac}+
Figure 1 : A sample transaction database , the equivalence class of abcd and its covering . the most well known . Let us explain by an example what we intend for “ sacrificing readability ” in the case of closed itemsets . Consider the transaction database in Figure 1 .
For a minimum support of 2 , there is a total of 15 frequent itemsets , but only 3 frequent closed itemsets : C1 = abcd with support 2 ; C2 = b with support 3 ; and C3 = ac with support 3 . Closed itemsets ( and concise representations , in general ) are able to answer frequency queries such as “ is the itemset X frequent ? ” and , if it is , “ what is the support of X ? ” . For instance , for X = abc , we look at closed itemsets that include X . If there is one ( C1 includes it ) , then X is frequent . In such a case , the support of X is the maximal support of the closed itemsets that include it ( only C1 , hence the support of X is 2 ) .
Assume now that a data analyst has focussed her attention on itemsets with support of 2 . Would it be reasonable to prompt her with C1 ? On the one side , it is the only closed itemset with support 2 , hence it concisely represents all itemsets the analyst is interested in . On the other side , however , the conciseness itself is the source of interpretability problems . Once prompted with C1 the data analyst has to figure out which itemsets are represented by C1 , or in other words , what its semantics is . The answer is hardly useful : abcddbabcdacdadbdcdabdbcbacd{abc}*b{ac}+freeclosedfrequent all subsets of C1 except the subsets of closed itemsets whose support is greater than the support of C1 ( technically , the equivalence class of C1 ) . Such an answer highlights that a closed itemset in isolation makes no sense for the analyst , because the itemsets it denotes , its semantics , is undeterminable . The only practical way of presenting the semantics of C1 to the analyst seems then by enumerating the 11 itemsets in its equivalence class , as shown in Figure 1 . But this means loosing the so much acclaimed compactness property of concise representations .
In this paper , we introduce an extension of itemsets , called regular , with an immediate semantics and interpretability , and a conciseness comparable to closed itemsets . Regular itemsets allow for specifying that an item a may or may not be present , using the notation a ? ; that any subset of an itemset may be present , using the notation {a1 ; : : : ; ah}⋆ ; and that any non empty subset of an itemset may be present , using the notation {a1 ; : : : ; ak}+ . We devise a procedure , called RegularMine , for mining a set of regular itemsets that is a concise representation of frequent itemsets . The procedure computes a covering , in terms of disjoint regular itemsets , of the equivalence class of a frequent closed itemset . For the example C1 above , we obtain two regular itemsets , namely b{ac}+ and d{abc}⋆ . They are a cover because every frequent itemset equivalent to C1 belongs to the semantics of one of them . They are disjoint because no frequent itemset belongs to the semantics of both . For the example C2 above , we obtain b ; and for C3 we obtain {ac}+ . We report experimental results on several standard dense and sparse datasets that show how the size of the concise representation using regular itemsets is in most cases very close to the size of closed itemsets .
The paper is organized as follows .
In Section 2 , we set up the notation and recall basic definitions about frequent itemsets , equivalence , closed itemsets , free sets and concise representations . The syntax and semantics of regular itemsets is introduced in Section 3 . In Section 4 we propose the mining procedure RegularMine , which is experimented in Section 5 . Finally , we discuss related work in Section 6 and then summarize the contribution of the paper .
2 . BASIC DEFINITIONS 2.1 Frequent Itemsets Let I be a finite set of literals called items . We use metavariables a ; b ; c ; : : : to denote items . A set X = {a1 ; : : : ; ak} ⊆ I is called an itemset , or a k itemset if it contains k items . X ∪ Y is abbreviated to X ; Y . A transaction over I is a pair T = ( tid ; X ) where tid is a transaction identifier and X is an intemset . A transaction database D over I is a set of transactions over I . From now on , we omit I and D when clear from the context . A transaction T = ( tid ; X ) supports an itemset I if X ⊆ I .
The cover of I is the set of transactions that support I : cover(I ) = {tid | ( tid ; X ) ∈ D ; I ⊆ X} :
The support of I is the number of transactions in its cover : support(I ) = |cover(I)| . An itemset is called frequent if its support is no less than a given minimum threshold minsupp . The set of frequent itemsets is defined as :
F = {X ⊆ I | support(X ) ≥ minsupp} :
2.2 Equivalence , Free and Closed Itemsets
Bastide et al . [ 2 ] introduced the relation between frequent itemsets supported by the same set of transactions , hence equivalent ( and indistinguishable ) with respect to the transaction database . Given two itemsets X and Y , we write XY , and say that X is equivalent to Y , when cover(X ) = cover(Y ) . is an equivalence relation , namely it is reflexive , symmetric and transitive . The class of equivalence of an itemset X consists of all itemsets equivalent to X :
[ X ] = {Y ⊆ I | XY } :
Minimal elements ( with respect to set inclusion ) of a equivalence class are called free itemsets [ 4 ] or generators [ 2 ] . Formally , X is free if X ∈ M in [ X ] , where the mimimal function is defined as : M in S = {X ∈ S | @Y ∈ S:Y ⊂ X} . It turns out that X is free iff there is no Y ⊂ X such that support(Y ) = support(X ) . Another useful property of free itemsets is anti monotonicity [ 2 , 4 ] , namely all subsets of a free itemset are free .
Maximal elements ( with respect to set inclusion ) of a equivalence class are called closed itemsets . Formally , X is closed if X ∈ M ax [ X ] , where the maximal function is defined as : M ax S = {X ∈ S | @Y ∈ S:Y ⊃ X} . It turns out that X is closed iff there is no Y ⊃ X such that support(Y ) = support(X ) . Given Y ∈ [ X ] , it is immediate to observe that the itemset X ; Y belongs to [ X ] . This implies that M ax [ X ] is a singleton , namely there is a bijection between classes of equivalence and closed itemsets . 2.3 Concise Representations
The number of frequent itemsets can be so large that no efficient algorithm exists to enumerate all of them . This case occurs , for instance , for very low minimum support thresholds and for highly correlated data . A concise representation [ 7 , 15 ] of frequent itemsets is a lossless representation , typically consisting in a subset of F , that addresses the problem . By lossless representation , one means that starting from it : ( 1 ) frequent itemsets can be enumerated ; and ( 2 ) given an itemset it can be decided whether it is frequent or not , and , if it is frequent , its support can be derived . The set CS of frequent closed itemsets is a concise representation [ 17 ] . An itemset X is frequent iff there exists Y ∈ CS such that X ⊆ Y . In such a case , the support of X can be calculated as : max{support(Y ) | X ⊆ Y ∧ Y ∈ CS} . The set FS of frequent free itemsets is not a concise representation . The pair of FS and of the free itemsets in the negative border of FS is a concise representation [ 4 , 14 ] . The latter element in the pair is essential to determine whether an itemset X is frequent or not . If frequent , the support of X can be calculated as : min{support(Y ) | X ⊇ Y ∧ Y ∈ FS} .
3 . REGULAR ITEMSETS
In this section , we introduce an extended formulation of itemsets , whose main purpose is to trade off conciseness and interpretability . The basic idea consists of introducing special items that model cases when : an item a may or may not appear , and this will be denoted by a ? ; any subset of items a1 ; : : : ; ah may appear , and this will be denoted by {a1 ; : : : ; ah}⋆ ; any non empty subset of items a1 ; : : : ; ak may appear , and this will be denoted by {a1 ; : : : ; ak}+ .
We start by extending the syntax of items and itemsets along this line .
{a1 ; : : : ; ah}⋆ a1 ? ; : : : ; ah ?
N1
{a}+ a
N2 a ; a ? a
N3 a;{a ; X}+ a ; X ⋆ N4 a?;{a ; X}+ {a ; X}+ N5
( a ) For the normal form of extended itemsets .
−
Y ∩ X ̸= ∅
S1
R ; X ; Y
R ; X ; ( Y \ X ) − a ̸∈ R
R;{a}−
R ; X ; Z ⋆ Z ∩ X ̸= ∅
R ; X ; ( Z \ X)⋆ R;{a ; Y }−
S2
R;∅− fail
S3 a ̸∈ R Y ̸= ∅
R \ {a?}[{a ; X}− → X ⋆ ]
S4
R \ {a?}[{a ; X}− → X ⋆ ] ; Y ⋆ R \ {a?}[{a ; X}− → X
−
] ; a ; Y
− S5
( b ) For splitting non compositional itemsets .
R R ; a
R ; a ?
M1
R R ; Y +
R ; Y ⋆ M2
R ; b ; a ? R ; a R;{a ; b}+ M3
R ; Y + ; a ? R ; a
R;{a ; Y }+ M4
R ; Y + R ; a ; Y ⋆
R;{a ; Y }+ M5
R ; Y + R ; Z + ; Y ⋆
R;{Z ; Y }+ M6
( c ) For merging extended itemsets .
Figure 2 : Rewriting rules . R[X → Y ] means that every extended item matching X in R is replaced by Y .
3.1 Extended Itemsets
An extended item is defined by the following grammar :
E ::= a | a ? | {a1 ; : : : ; ah}⋆ | {a1 ; : : : ; ak}+ where a , ai ’s are items , h ≥ 0 and k > 0 . We use e ; f ; g as meta variables for extended items . Let J be the ( finite ) set of extended items . A extended itemset is a subset R ⊆ J . Example 31 The extended itemset ab{cd}⋆ represents the itemsets where a and b must necessarily appear , while c and d may or may not appear . The intended meaning of ab{cd}⋆ is then the set of itemsets {ab ; abc ; abd ; abcd} . The extended itemset ab?{cd}+ represents the itemsets where a must necessarily appear , b may or may not , and at least one between c and d appears . Its intended meaning is then {ac ; ad ; acd ; abc ; abd ; abcd} .
We now formalize the intuitions underlying the example by providing a semantics mapping an extended item/itemset to the set of itemsets it denotes . The semantics se( ) for extended items is defined as follows : se(a ) = {{a}} se(a ? ) = {{a};∅} se({a1 ; : : : ; ah}⋆ ) = {X | X ⊆ {a1 ; : : : ; ah}} se({a1 ; : : : ; ak}+ ) = {X | X ⊆ {a1 ; : : : ; ak} ; X ̸= ∅} : The semantics s( ) for extended itemsets is defined as follows : s(e1 ; : : : ; en ) = { ∪ i=1nXi | Xi ∈ s(ei ) ; i = 1 : : : n} : ( 1 ) Notice that the semantics s( ) is and compositional , namely s(R1 ; R2 ) = f ( s(R1 ) ; s(R2 ) ) for some function f ( ) ( actually , for f ( S1 ; S2 ) = {X ∪ Y | X ∈ S1 ; Y ∈ S2)} ) . This means that the meaning of an extended itemset can be obtained by looking ( only ) at the meaning of its parts . As discussed in the introduction , closed itemsets and other concise representations do not have such a property . Let us consider now some syntactic issues . Since the following holds : s({a1 ; : : : ; ah}⋆ ) = s(a1 ? ; : : : ; ah? ) ; the ⋆ operator can be seen as syntactic sugar . In this sense , we will not make any further distinction between the ⋆ and the ? operators , eg , when stating that a ? belongs to b{ac}⋆ . Analogously , since s({a}+ ) = s(a ) , we can rewrite singleton itemsets over the + operator into an item .
Example 32 According to the definition of extended itemsets , an item can appear more than once , eg , as in ab{ac}+b ? . However , the following identities : s(a ; a ? ) = s(a ) s(a;{a ; X}+ ) = s(a ; X ⋆ ) s(a?;{a ; X}+ ) = s({a ; X}+ ) allow for removing duplicates . The extended item above is equivalent to abc ? .
The rewriting rules describes so far are reported in Figure 2 ( a ) as rules N 1−N 5 . We say that an extended itemset is in normal form if no rule can further apply . Irrespectively of the order the rules are applied , an extended itemset R can be rewritten in one and only one extended itemset in normal form , which we call the normal form of R . 3.2 Regular Itemsets
The notion of extended itemset does not take into account the cover nor the support of the itemsets in its semantics . Example 33 Consider the transaction database D =
{(1 ; ab ) ; ( 2 ; a)} , and the extended itemset R = ab ? . cover(a ) = {1 ; 2} ̸= {1} = cover(ab ) .
Two itemsets belong to s(R ) , namely a and ab . However ,
Extended itemsets are then relevant to the frequent itemset mining problem only when they denote itemsets with a common cover .
Definition 34 An extended itemset R is said regular if for every X ; Y ∈ s(R ) we have that cover(X ) = cover(Y ) . Using the notation of equivalence classes , R is regular if s(R ) ⊆ [ X ] for some itemset X . An equivalent formulation consists of requiring that all itemsets in the semantics of R have the same support .
Lemma 35 An extended itemset R is regular iff for every
X ; Y ∈ s(R ) we have that support(X ) = support(Y ) .
Proof . The only if part is immediate , since cover(X ) = cover(Y ) implies support(X ) = support(Y ) . Consider the if part . Let C be the itemset obtained from R by replacing a ? with a , and {a1 ; : : : ; ak}+ with a1 ; : : : ; ak . C is the maximal itemset in s(R ) , hence X ⊆ C and Y ⊆ C , and then cover(X ) ⊇ cover(C ) and cover(Y ) ⊇ cover(C ) . Since by hypothesis support(X ) = support(C ) = support(Y ) , we conclude that cover(X ) = cover(C ) = cover(Y ) .
For a regular itemset R , we define cover(R ) = cover(X ) , where X is any itemset in s(R ) . Also , we extend the notion of support as follows : support(R ) = |cover(R)| . Finally , we say that a regular itemset R is frequent if support(R ) ≥ minsupp .
Example 36 Consider the transaction database of Figure 1 . The extended itemset ab{cd}⋆ from Example 3.1 is regular , and its cover is {1 ; 2} . The extended itemset ab?{cd}+ is not regular since , eg , cover(ac ) = {1 ; 2 ; 4} ̸= {1 ; 2} = cover(abc ) . 3.3 Concise Representations
Frequent regular itemsets are natural candidates to be adopted for a concise representation of frequent itemsets . First , a single regular itemset R represents a possibly large set s(R ) of itemsets . Second , the interpretation of an extended item in R is straightforward , even for non technical data analysts : a ? means a may appear ; {a1 ; : : : ; ak}+ means that at least one among a1 ; : : : ; ak must be present . Third , the and compositionality property makes it possible to figure out the semantics s(R ) by looking at extended items in R only . We therefore formalize the notion of concise representation to the case of regular itemsets .
Definition 37 A finite set of regular itemsets R is a concise representation of the set F of frequent itemsets if : ( a ) ∪ R∈Rs(R ) = F , and ( b ) for every pair R1 ̸= R2 ∈ R , s(R1 ) ∩ s(R2 ) = ∅ . Intuitively , given an itemset X : ( a ) means that X is frequent iff X belongs to the semantics of some R ∈ R ; and ( b ) means that if X is frequent , there exists one and only one such an R , hence support(X ) can be obtained as support(R ) . A natural question arise at this stage . How large is a concise representation R ? Since the semantics of a regular itemset is included in the class of equivalence of a closed itemset , we conclude that |CS| ≤ |R| is a lower bound . As for upper bounds , at this stage we cannot draw any conclusion ( apart from the trivial one |R| ≤ |F| ) , but later on we will show that , in practice , there exist concise representations whose size is close to |CS| and abundantly smaller than the number of frequent free sets |FS| .
4 . MINING REGULAR ITEMSETS
We tackle the problem of mining a concise representation by looking for a set of ( pairwise disjoint ) regular itemsets that cover all the itemsets in a equivalence class . We start with a simple observation .
Lemma 41 Let C be a closed itemset , and let M in[C ] = {X1 ; : : : ; Xn} be its free sets . An itemset Y belongs to [ C ] iff there exists i such that Xi ⊆ Y ⊆ C . Proof . The if part follows since Xi ⊆ Y ⊆ C implies cover(Xi ) ⊇ cover(Y ) ⊇ cover(C ) = cover(Xi ) . The onlyif part is immediate .
This result characterizes the equivalence class [ C ] given its maximal ( closed ) itemset and its minimal ( free ) itemsets . As a consequence , [ C ] is equivalent to :
∪i=1n s(Xi(C \ Xi)⋆ ) :
However , while the itemsets X1(C \ X1)⋆ ; : : : ; Xn(C \ Xn)⋆ satisfy condition ( a ) of Definition 3.7 , they do not satisfy condition ( b ) , namely they are not pairwise disjoint .
Example 42 Consider the sample database and the class of equivalence [ abcd ] reported in Figure 1 . Starting from the three free itemsets X1 = d , X2 = ba and X3 = bc , the three regular itemsets R1 = d{abc}⋆ , R2 = ba{cd}⋆ and R3 = bc{ad}⋆ cover all itemsets in the class of equivalence . However , they overlap since s(R1 ) ∩ s(R2 ) = {abd ; abcd} , s(R1 ) ∩ s(R3 ) = {bcd ; abcd} , s(R2 ) ∩ s(R3 ) = {abc ; abcd} . We point out that the overlapping between Ri and Rj starts at the itemset Xi ; Xj , namely the minimal common superset of Xi and Xj .
In the next subsections , we devise a procedure to compute a pairwise disjoint set of regular itemsets . First , we introduce a further extension of items , called non compositional , which serves to divide [ C ] into disjoint sets . Then we transform non compositional itemsets into regular itemsets without the + operator . Finally , we merge pairs of regular itemsets by means of the + operator . 4.1 Non Compositional Itemsets
A non compositional item is defined by the grammar of extended items augmented with the following :
E ::= {a1 ; : : : ; ah}− where h ≥ 0 . Intuitively , {a1 ; : : : ; ah}− represents any subset of {a1 ; : : : ; ah} except for the the maximal one a1 ; : : : ; ah . Formally : se({a1 ; : : : ; ah}− Notice that se({a}− in the semantics , while se({}−
) = {X | X ⊂ {a1 ; : : : ; ah}} : ) = {∅} , ie , only the empty itemset is ) = ∅ , ie , no itemset is in it . Consider now itemsets . A non compositional itemset is a finite set of non compositional items . The semantics s( ) defined as in ( 1 ) does not reflect the intuitive meaning of noncompositional itemsets . Consider , as an example , {ab}−{ac}− . Intuitively , we expect that b ∈ s({ab}− ) and that a ∈ s({ac}− ) . However , their conjunction ab should not be in s({ab}−{ac}− ) since it violates the constraint that a and b should not occur together . In this sense , an and compositional semantics does not exists . Here it is a non compositional one : ( e1 ; : : : ; en ) = {X ∈ s(e1 ; : : : ; en ) | X ∩ Y ⊂ Y −} : for every ei of the form Y
′ s
′
A non compositional itemset R is said regular if cover(X ) = cover(Y ) for every X ; Y ∈ s ( R ) . Similarly , we can extend the notion of concise representation . However , due to the lack of and compositionality , the class of non compositional itemsets is not suitable , in our opinion , to be proposed to a data analyst for direct interpretation . Nevertheless , its is an intermediate representation that is useful for our purposes . The next example clarifies how the equivalence class [ C ] can be easily covered by regular non compositional itemsets .
Example 43 Consider again the class of equivalence [ C ] in Figure 1 , where C = abcd is a closed itemset , and X1 = d , X2 = ba and X3 = bc are the free itemsets in the class . As for X1 , we can define R1 = X1 ; C ⋆ = d{abcd}⋆ to cover all itemsets X such that d ⊆ X ⊆ abcd . As for 1 ; C ⋆ = ba{d}−{abcd}⋆ to cover − X2 , we define R2 = X2 ; X all itemsets X such that ba ⊆ X ⊆ abcd , but such that ( R2 ) = {ba ; bac} . Finally , for X3 d ̸⊆ X . It turns out that s ′ 2 ; C ⋆ = bc{d}−{ba}−{abcd}⋆ to − − we define R3 = X3 ; X 1 ; X cover all itemsets X such that bc ⊆ X ⊆ abcd , but such that d ̸⊆ X and ba ̸⊆ X . It turns out that s ′
( R3 ) = {bc} . Next we formalize the intuitions of the example . Lemma 44 There exists a set R of regular non compositional itemsets with |R| = |FS| that is a concise representation of frequent itemsets . Proof . Let C be a frequent closed itemset , and let M in[C ] = {X1 ; : : : ; Xn} be its free sets . For the regular non compo− i−1 ; C ⋆ , with i = 1 : : : n , sitional itemsets Ni = Xi ; X we have : ( Ni ) = [ C ] . By Lemma 4.1 , X ∈ [ C ] iff for some i ∈ [ 1 ; n ] , Xi ⊆ X ⊆ C . Let k be the minimum of such i ’s . By construction , we have X ∈ s ′ ∅ . − j . We have Nj = Xj ; X 1 ; : : : ; X ( Ni ) then X ⊇ Xi , but since X ′ s ′ s ( Nj ) . 4.2 A Covering Algorithm In this subsection , we devise a covering procedure that , given a non compositional itemset Rin , computes a set Rout of extended itemsets equivalent to Rin and pairwise disjoint , ( Rin ) = ∪R∈Rout s(R ) and such or , formally , such that s that R1 ̸= R2 ∈ Rout implies s(R1 ) ∩ s(R2 ) = ∅ . When applied to the non compositional itemsets whose semantics is the class of equivalence [ C ] , it then provides a covering of [ C ] through regular itemsets . The approach follows the rewriting rules S1 − S5 reported in Figure 2 ( b ) . Let us introduce the intuitions behind them with a few examples .
( Nk ) . ( b ) For every pair Ni ; Nj with i ̸= j , s ′ ( Nj ) = In fact , assume , without loss of generality , that i < If X ∈ is in Nj , we have X ̸∈
( Ni ) ∩ s ′ − j−1 ; C ⋆ .
− i ; : : : ; X − i
( a ) ∪ i=1ns ′
− 1 ; : : : ; X
′
Example 45 Consider Example 43 It is immediate to notice that R1 = d{abcd}⋆ can be simplified to d{abc}⋆ , ie , by removing the item d from {abcd}⋆ , due to the fact that d must necessarily occur . This is the analogous of the simplification rule N 3 from Figure 2 ( a ) for extended itemsets . Similarly , R2 = ba{d}−{cd}⋆ and R3 = bc{d}−{ba}−{ad}⋆ . The general case is stated as rule S2 in Figure 2 ( b ) .
A similar reasoning applies to the extended item {ba}− in R3 . Since b necessarily appear in R3 , it can be removed from {ba}− . Thus , R3 = bc{d}−{a}−{ad}⋆ . In general , we have rule S1 .
X ; Y
− n ; Z ⋆
− 1 ; : : : ; Y itemset Rin of
Algorithm 1 Covering Input : a non compositional the form Output : a set Rout of pairwise disjoint extended itemsets equivalent to Rin , obtained by the splitting rules S1 S5 ; : : : ; ( Yn \ X ) R ← X ; ( Y1 \ X ) ; ( Z \ X)⋆ //rules S1 , S2 − Rout ← ∅ if ∀i:Yi \ X ̸= ∅ then //rule S3
−
R ← {R} while R ̸= ∅ do let R be in R R ← R \ {R} while ∃Y −
− ∈ R do = {a1 ; : : : ; ak}− let Y be in R ′ ← R \ {a1?} R where every {a1 ; X}− R ← R ′ if k > 1 and @{a1}− ∈ R
′ is replaced by X ⋆ //rules S4 , S5 then //rules S5 , S3
′
′′ ← R R R := R ∪ {(a1 ; R where every {a1 ; X}− is replaced by X
)}
′′
− end if end while Rout ← Rout ∪ {R} end while end if
Example 46 Consider R = a{a}− b ? . By rule S1 , R is b ? . As already noted , s(∅− equivalent to a∅− ) is empty , and this is inherited by any itemset containing ∅− . Thus , s(R ) = ∅ . Since any extended itemset has a non empty semantics , this means that no extended itemset is equivalent to R . This motivates rule S3 in Figure 2 ( b ) .
− 1 ; : : : ; X
It is worth noting , however , that a non compositional item− i−1 ; C ⋆ defined in Lemma 4.4 for set Ni = Xi ; X covering a equivalence class has a non empty semantics . In fact , since X1 ; : : : ; Xi are minimal sets , Xi ̸⊇ Xj for j = 1 : : : n , and then Xi ∈ s ′
( Ni ) .
Example 47 Consider R2 = ba{d}−{cd}⋆ from Example 45 The conjunct {d}− implies that the item d must not appear . So , {d}− can be removed together with all d ? in R2 , thus yielding R2 = ba{c}⋆ = bac ? . Analogously , one concludes R3 = bc . In general , we have rule S4 in Figure 2 ( b ) . Let us briefly explain what happens if the hypothesis a ̸∈ R of such a rule is not satisfied , eg , for the non compositional itemset a{a}− . Here , rule S1 applies , so it can be rewritten as a∅− which , by rule S3 , has an empty semantics .
First set : s junct {ab}− ′ Thus , we partition the semantics s
The next example explains rule S5 . Example 48 Consider R = cd{ab}−{ab}⋆ . The conimposes that a and b cannot be both present . ( R ) ∩ {X ⊆ I | a ̸∈ X} . We characterize it by ′ removing any a ? from R , and by replacing every occurrence of the form {Y ; a}− by Y ⋆ . In fact , since a cannot be present , any other subset of Y can appear without violating {Y ; a}− . Summarizing , R1 = cdb ? covers the first set . ( R ) ∩ {X ⊆ I | a ∈ X} . We characterize such a set by adding a to R , by removing any a ? from R , and by replacing {Y ; a}− . In fact , since a is now present ,
′ Second set : s
( R ) in two sets . by Y
− the constraint imposed by any {Y ; a}− becomes equivalent . Summarizing , R2 = cda{b}− to the one imposed by Y b ? covers the second set . By applying rule S4 , we get R2 = cda .
−
−
−
Figure 2 ( b ) summarizes the rewriting rules mentioned in the examples above . They allow for deriving zero , one or two non compositional itemsets that are equivalent to a given one but smaller in the precise sense that at least one item a is removed from extended items of the form Y . As a result , the rewriting process starting from a ( set of ) noncompositional itemset(s ) terminates with an equivalent set of extended itemsets , ie , with no item of the form Y . The only rewriting rule that yields two itemsets is rule S4 . Here , we have to ensure that the two itemsets in the rule consequence are disjoint . This is immediate because one itemset does not contain a ( neither a ? nor {X ; a}− ) whilst the other does contain a . The Covering Algorithm 1 implements the rewriting rules with two optimizations . First , if applied at once , rules S1 and S2 do not need to be re checked , since all other rules remove items a appearing in {Y ; a}− or in {a}− ( preventing rule S1 to fire ) and explicitly remove items a ? ( preventing rule S2 to fire ) . Also , the initial application of S1 and S2 makes it superfluous to check the hypothesis a ̸∈ R in rules S4 and S5 . As a second optimization , if applied at once , rule S3 can only be re checked after rule S5 , where an item ∅− can potentially be introduced . Thus , rule S3 can be folded within rule S5 .
Example 49 The ( size of the ) covering produced may vary with the order in which free sets are considered in the construction of the non compositional itemset . For instance , consider again Example 43 If we reverse the order of free 1 = bc{abcd}⋆ which can be rewritten to ′ sets , we obtain R bc{ad}⋆ , R 2 = ba{bc}−{abcd}⋆ which can be rewritten to ′ 3 = d{bc}−{ba}−{abcd}⋆ = d{bc}−{ba}−{abc}⋆ . ′ bad ? , and R ′ The only rule applicable to R 3 is S5 , which yields two itemsets : d{ac}⋆ ; and db{c}−{a}−{ac}⋆ , which by rule S4 is equivalent to db . Summarizing , the cover obtained includes 4 regular itemsets vs . the 3 regular itemsets obtained in Examples 4.5 , 47
4.3 Merging Extended Itemsets
The Covering procedure yields a set of extended itemsets of the form X ; Y ⋆ , that is , the + operator is not exploited at all . In this subsection , we devise an algorithm to merge two or more extended itemsets by exploiting the rewriting rules M 1 − M 6 reported in Figure 2 ( c ) .
Example 410 With reference to our running example , in Examples 4.5 and 4.7 we derived the regular itemsets R1 = d{abc}⋆ , R2 = bac ? and R3 = bc . Consider R2 and R3 . Their common part is b . The semantics of R2 is that , in addition to b , the item a is present and c may or may not be present . The semantics of R3 is that , in addition to b , the item c is present . The semantics of both R2 and R3 can be rephrased as follows : in addition to b , at least one of a and c must be present . This is precisely the semantics of b{ac}+ which , together with R1 , covers [ abcd ] in Figure 1 . This example is an application of rule M 3 in Figure 2 ( c ) . Rule M 4 is the generalization of M 3 to the case of extended items of the form Y + ( vs . items b ) . Rule M 1 is selfexplicative , and rule M 2 is its generalization to extended items of the form Y + .
Algorithm 2 Merging Input : a set of Rin of pairwise disjoint extended itemsets Output : a set Rout of pairwise disjoint extended itemsets equivalent to Rin , obtained by the merging rules M 1 M 6 R ← Rin Rout ← ∅ while R ̸= ∅ do k ← max{|R ∩ I| | R ∈ R} repeat else if R1 = I and R2 = I ; Y + then //M2 let R1 ; R2 ∈ R such that |R2 ∩ I| = k and |R1 ∩ I| ∈ [ k − 1 ; k ] I ← R1 ∩ R2 if R1 = I and R2 = I ; a then //rule M1 R ← I ; a ? R ← I ; Y ⋆ R ← I;{a ; b}+ R ← I;{a ; Y }+ R ← I;{a ; Y }+ R ← I;{Z ; Y }+ else if R1 = I ; Y + and R2 = I ; Z + ; Y ⋆ then //M6 else if R1 = I ; Y + and R2 = I ; a ; Y ⋆ then //M5 else if R1 = I ; Y + ; a ? and R2 = I ; a then //M4 else if R1 = I ; b ; a ? and R2 = I ; a then //M3 end if if any of the rules M 1 M 6 was applied then
R = R \ {R1 ; R2} ∪ {R} end if until for every R1 ; R2 no rule M 1 M 6 applies K ← {R ∈ R | |R ∩ I| = k} R ← R \ K Rout ← Rout ∪ K end while
Let us show next an example using rule M 5 .
′ 2 and R
1 = bc{ad}⋆ , R ′
3 = d{ac}⋆ and R ′
4 to obtain b{ad}+ . This and R ′
Example 411 Consider the alternative cover of [ abcd ] ′ 2 = reported in Example 49 It consists of R ′ 4 = db . We can apply rule M 3 bad ? , R ′ to R 1 together have the following semantics : in addition to b , if c is present then any of a and d may be present or not ; and if c is not present then at least one of a and d must be present . This is precisely the semantics of b{acd}+ which , together with R ′ 3 represent another cover of size 2 for [ abcd ] . Rule M 5 generalizes the reasoning of this example . of extended items of the form Z + ( vs . items a ) .
Finally , rule M 6 is the generalization of M 5 to the case The rewriting rules M 1 − M 6 allow for merging two extended itemsets into a single one . The rewriting process terminates as soon as no rule can be further applied . However , such a process is inherently non deterministic , in the sense that the order with which rules are applied is left unspecified . The Merging Algorithm 2 implements a top down rewriting strategy , which is motivated by the following observation . For an extended itemset R , let us denote by kR the number of pure ( not extended ) items in R , namely kR = |R ∩ I| . be any rule from M 1 − M 6 . We observe that Let R1 R2 − 1 ; kR2 ] . For instance , for rule M 1 , it turns R3 kR1 ; kR3 out kR = kR,a ? = kR,a − 1 .
∈ [ kR2
Let now k be the maximal kR for R belonging to the set of extended itemsets R under rewriting . The Merging algorithm proceeds top down by considering first rules involving R2 with kR2 = k . By the previous observation , the rationale is to progressively reduce the number of pure items from extended itemsets with large values of kR2 . Once no rule M 1 − M 6 can be further applied to any R2 with kR2 = k , the set K of residual extended itemsets with kR2 = k is removed from R and added to the output . The loop continues while R is not empty .
Example 412 Let C = abcd and a , b , c , and d be the free sets in [ C ] . The Covering procedure returns the following extended itemsets to be merged : a{bcd}⋆ ; b{cd}⋆ ; cd ? ; d . First , a{bcd}⋆ and b{cd}⋆ are merged ( rule M 3 ) to R1 = {ab}+{cd}⋆ ; and cd ? and d are merged ( rule M 3 ) to R2 = {cd}+ . Then , R1 and R2 are merged ( rule M 6 ) to the final answer {abcd}+ . As the last example , assume now that ac , ad , bc , and bd are the free sets in [ C ] . The Covering procedure returns : ac{bd}⋆ ; adb ? ; bcd ? ; bd . First , ac{bd}⋆ and adb ? are merged ( rule M 3 ) to R1 = a{cd}+b ? ; and bcd ? and bd are merged ( rule M 3 ) to R2 = b{cd}+ . Then , R1 and R2 are merged ( rule M 3 ) to the final answer {ab}+{cd}+ . 4.4 Mining through Covering
We are now in the position to devise a procedure for mining a concise representation of frequent itemsets . Starting from a frequent closed itemset and the free sets in its class of equivalence , by Lemma 4.4 we first derive a concise representation of the frequent itemsets in the class in terms of pairwise disjoint non compositional itemsets . Next , by the Covering and the Merging procedures we rewrite the noncompositional itemsets into equivalent pairwise disjoint regular itemsets . The overall procedure , called RegularMine , is reported as Algorithm 3 .
− 1 ; : : : ; X
There are three sources of non determinism in the various components of the procedure . The first one is concerned with the order by which the free itemsets X1 ; : : : ; Xn are considered in building the non compositional itemsets − i−1C ⋆ , for i = 1 : : : n . As shown in ExNi = Xi ; X amples 4.9 and 4.11 , the ( size of the ) covering found may depend on such an order . Intuitively , smaller free itemsets should be arranged first , so that the initial Ni ’s cover as much as possible of the elements in [ C ] . For free sets of the same size , a lexicographic ordering leads to simpler noncompositional itemsets . This is due to the fact that Ni is at ( C \ Xi)⋆ . once rewritten as Xi ; ( X1 \ Xi ) − A total order considering first itemset size and then lexicographic ordering was introduced in [ 8 , 11 ] . It formalizes our intuitions , and it is adopted in the RegularMine algorithm . Definition 413 Let ≼ be a total order over items , and let ≼l be the lexicographic ordering induced by ≼ over itemsets . ≼ is extended to itemsets as follows : X ≼ Y iff |X| < |Y | or , |X| = |Y | and X ≼l Y .
; : : : ; ( Xi−1 \ Xi ) −
The second source of non determinism is in the Covering procedure , which contains two choices ( see Algorithm 1 ) : ( 1 ) which R ∈ R to select ; and ( 2 ) which Y − ∈ R to select . It is readily checked that ( 1 ) does not affect the output , since the splitting rules S1 S5 deal with each non compositional itemset in isolation . On the contrary , the choice ( 2 ) can affect the ( size of the ) output .
Algorithm 3 RegularMine Input : a transactional database D Output : a set Rout of frequent regular itemsets that is a concise representation of frequent itemsets extract frequent closed itemsets CS from D Rout ← ∅ for every C ∈ CS do and , for each C ∈ CS , the free sets in [ C ] let X1 ; : : : ; Xn be the free sets in [ C ] ordered wrt ≼ R = ∪i=1nCovering(Xi ; X Rout ← Rout ∪ M erging(R )
− 1 ; : : : ; X
− i−1 ; C ⋆ ) end for
Example 414 Let C = abcd be a closed itemset and ab , bc and cd be the ( ordered ) free sets in [ C ] . The non compositional itemset for the third free set is R = cd{ab}−{b}−{ab}⋆ . By choosing Y , we apply first rule S5 to obtain cd{b}− b ? , which are further rewritten by rule S4 , to cd and cda . By choosing − Y , we apply rule S4 to obtain cda ? . The latter choice leads to a smaller cover of R . b ? and cda{b}−
= {ab}−
= {b}−
−
Intuitively , rule S4 should be preferred , if possible , over rule S5 – which rewrites a non compositional itemset into two ones . In the actual implementation of the Covering − ∈ R as one of procedure , we achieve that by choosing Y those with the smallest size . The third source of non determinism is in the Merging algorithm , where a pair R1 ; R2 ∈ R of extended itemsets has to be selected . Notice that , since the hypotheses of the rules M 1 M 6 are mutually exclusive , at most one of them applies for a given pair ; thus , the choice of the rule is deterministic once the pair has been selected . The next example shows that the choice of R1 ; R2 can affect the output .
Example 415 Let C = abcdef g be a closed itemset and adf , aef , bdf , bef , cdf , cef , def and df g be the free sets in [ C ] . The Covering procedure returns the following extended itemsets : R1 = adf{bceg}⋆ , R2 = aef{bcg}⋆ , R3 = bdf{ceg}⋆ , R4 = bef{cg}⋆ , R5 = cdf{eg}⋆ , R6 = cef g ? , R7 = def g ? , and R8 = df g . 1 = af{de}+{bcg}⋆ ; and next to ′ 2 = df{eg}+ . Let us follow from here ′
Assume that the Merging procedure applies rule M 3 first
3 = cf{de}+g ? ; then , to ′ 4 = bf{de}+{cg}⋆ ; then , to rewrite ′ 5 = f{ab}+{de}+{cg}⋆ . Finally , rule M 4 ′ 6 = f{abc}+{de}+g ? . The ′ to R1 and R2 , yielding R R7 and R8 , yielding R two possible computations of the Merging procedure that yield different outputs . In the first computation , rule M 3 is applied to rewrite R5 and R6 to R rewrite R3 and R4 to R ′ R 1 and R is able to rewrite R final result is then {R In the second computation , rule M 5 is applied to rewrite 7 = df{ceg}+ ; then , to rewrite R ′ ′ ′ 7 and R3 2 and R5 to R 8 = df{bceg}+ . Finally , rule M 3 is used to rewrite ′ 9 = ef{bc}+g ? . The final result is then ′ ′ 8 ; R
R to R R4 and R6 to R {R
′ ′ 5 and R 3 to R 2} . ′
′ 4 to R
′ 6 ; R
′ 1 ; R
9} . ′
In the actual implementation of the Merging procedure , the selection of a pair R1 ; R2 for which one of the rules M 1 , M 4 , and M 5 can be applied is preferred . The rationale is that these rules tend to smoothly add one item at a time to extended items of the form Y + or Y ⋆ . Rules M 2 , M 3 and
Figure 3 : Number of frequent , closed , free and regular itemsets .
0 1e+006 2e+006 3e+006 4e+006 5e+006 6e+006 7e+006 8e+006 9e+006 24000 26000 28000 30000 32000 34000Number of itemsetsminsupppumsb ( size = 49046)frequentfreeregularclosed 0 500000 1e+006 1.5e+006 2e+006 2.5e+006 3e+006 20 40 60 80 100Number of itemsetsminsuppcensus ( size = 48842)frequentfreeregularclosed 0 50000 100000 150000 200000 250000 300000 350000 20 40 60 80 100Number of itemsetsminsuppmushroom ( size = 8124)frequentfreeregularclosed 0 200000 400000 600000 800000 1e+006 1.2e+006 1.4e+006 1.6e+006 0 5 10 15 20 25 30 35 40 45Number of itemsetsminsuppBMS Webview 2 ( size = 77512)frequentfreeregularclosed 0 100000 200000 300000 400000 500000 600000 700000 28 30 32 34 36 38Number of itemsetsminsuppBMS Webview 1 ( size = 59602)frequentfreeregularclosed 0 200000 400000 600000 800000 1e+006 1.2e+006 1.4e+006 4 6 8 10 12 14 16 18 20Number of itemsetsminsuppT10I8D100K ( size = 100000)frequentfreeregularclosed 0 200000 400000 600000 800000 1e+006 1.2e+006 1.4e+006 4 6 8 10 12 14 16 18 20Number of itemsetsminsuppT10I4D100K ( size = 100000)frequentfreeregularclosed 0 2e+006 4e+006 6e+006 8e+006 1e+007 1.2e+007 800 1000 1200 1400 1600 1800 2000Number of itemsetsminsuppchess ( size = 3196)frequentfreeregularclosed Figure 4 : Number of regular itemsets extracted by RegularMine for different orderings of free itemsets .
Figure 5 : Execution times for mining closed , closed & free , and regular itemsets .
M 6 instead , introduce new or merge existing extended items of the form above , which could compromise further rewritings . Of course , this choice is an heuristics . Experimentally it performs well , but there are cases , as in the previous example , where it does not yield the smallest output .
Finally , notice that Algorithm 3 does not further specify how to extract closed and free sets . To this purpose , we can resort to a large body of algorithms for frequent closed itemset mining . Most of them actually screen ( and some explicitly store , eg , [ 22 ] ) the frequent free sets associated to a closed one as a sufficient condition for pruning the search space . We refer the reader to [ 20 ] for a survey .
5 . EXPERIMENTAL RESULTS
We have experimented the RegularMine procedure on standard dense ( pumsb , census , mushroom , chess ) and sparse ( BMS Webview 1 , BMS Webview 2 , T10I4D100K , T10I8D100K ) datasets obtained from the FIMI public repository [ 10 ] , or generated by the Quest synthetic data generator [ 1 ] . Figure 3 reports the number of frequent , free , closed and regular itemsets at the variation of the minimum support threshold ( for mushroom and T10I8D100K , the plot of frequent itemsets is well beyond the y range , thus it is not visible ) . Apart from the BMS Webview 1 dataset , the size of regular itemsets is very close to the size of closed itemsets . For sparse datasets , this result is expected , since the number of frequent , free and closed itemsets ( and even of advanced concise representations [ 12 ] ) tend to coincide – apart from very low minimum support , eg , the plot of T10I4D100K shows a relative support in the range of 0.004 % 002 % For dense datases , this result supports our claim that regular itemsets , when compared to closed itemsets , are a good trade off between conciseness and interpretability .
Figure 4 shows , for the sample mushroom dataset , how the ordering of free sets in the RegularMine procedure affects the number of regular itemsets extracted . regular is the ordering of Definition 4.13 ; regular inverse sorts free sets by descending size , rather than ascending ; and regular random is a random shuffle of the free sets . The rationale behind the choice of the ≼ ordering is supported by its performances . Let us consider now efficiency of RegularMine . When compared to frequent closed itemset mining , the additional tasks in the procedure consist of : ( 1 ) first collecting the free sets associated to a closed one ; and ( 2 ) then computing a covering through the Covering and Merging procedures . To understand the relative weight of these two tasks , we report in Figure 5 , for the sample pumsb dataset , the running times for extracting closed itemsets , for extracting closed and their associated free itemsets , and for the overall RegularMine procedure . Experiments were execute on a PC with Intel Xeon 2.8Ghz and 3Gb RAM running Linux core 2617 Our implementation of RegularMine is written in standard C++ , and it builts on the open source code of the FP growth algorithm by Borgelt [ 3 ] . Figure 5 highlights that the overhead required by RegularMine over the extraction of frequent closed itemsets is mainly due to the extraction and storage of free itemsets .
6 . RELATED WORK
In addition to the cornerstone concepts of closed and free itemsets , other concise representations in the literature exploit identities ( eg , inclusion exclusion [ 9 ] ) and regularities ( eg , disjunction rules X ⇒ a ∨ b ) in order to prune from a representation those itemsets whose support can be derived from other ones in the representation . We mention disjunction free sets [ 5 ] , non derivable itemsets [ 6 ] , closed non derivable itemsets [ 16 ] , and , more recently , approaches that maintain the disjunctive or the negative support of itemsets [ 12 , 13 ] , or that refer to measures other than support [ 19 ] . While these proposals achieve a higher compactness when compared to closed itemsets ( actually , mainly for dense datasets ) , they all share , and perhaps exacerbate , the interpretability problem highlighted in the introduction for closed itemsets . Among the large body of literature about this subject , the investigation of a concise form for free itemsets seems the closest work to ours . [ 8 ] introduced and [ 11 ] systematized succint minimal generators . They observed that free sets in a class of equivalence can be partitioned with respect to another equivalence relation , called the relation . Hence , only a representative of each equivalence class needs to be maintained . On a general level , we also try and reduce the covering produced by Covering ( starting from a non compositional itemset for each free set ) by merging extended itemsets through the + operator . On a more concrete level , we rely on the total order ≼ of simplerto complex itemsets that is introduced by [ 8 ] for defining the
0 50000 100000 150000 200000 250000 20 40 60 80 100Number of itemsetsminsuppmushroom ( size = 8124)regular randomregular inverseregular 1 10 100 24000 26000 28000 30000 32000 34000Elapsed time ( secs)minsupppumsb ( size = 49046)regularclosed+freeclosed [ 10 ] B . Goethals . Frequent Itemset Mining Implementations
Repository . http://fimicshelsinkifi
[ 11 ] T . Hamrouni , S . B . Yahia , and E . M . Nguifo . Succinct minimal generators : Theoretical foundations and applications . Int . J . Foundations of Computer Science , 19(2):271–296 , 2008 .
[ 12 ] T . Hamrouni , S . B . Yahia , and E . M . Nguifo . Sweeping the disjunctive search space towards mining new exact concise representations of frequent itemsets . Data & Knowledge Engineering , 68(10):1091–1111 , 2009 .
[ 13 ] M . Kryszkiewicz , H . Rybinski , and K . Cichon . On concise representations of frequent patterns admitting negation . In Advances in Machine Learning II , pages 259–289 . Springer , 2010 .
[ 14 ] G . Liu , J . Li , L . Wong , and W . Hsu . Positive borders or negative borders : How to make lossless generator based representations concise . In Proc . of SIAM Data Mining 2006 . SIAM , 2006 .
[ 15 ] H . Mannila and H . Toivonen . Multiple uses of frequent sets and condensed representations . In Proc . of KDD 1996 , pages 189–194 . AAAI Press , 1996 .
[ 16 ] J . Muhonen and H . Toivonen . Closed non derivable itemsets . In Proc . of PKDD 2006 , volume 4213 of LNCS , pages 601–608 . Springer , 2006 .
[ 17 ] N . Pasquier , Y . Bastide , R . Taouil , and L . Lakhal . Discovering frequent closed itemsets for association rules . In Proc . of ICDT 1999 , volume 1540 of LNCS , pages 398–416 . Springer , 1999 .
[ 18 ] N . Pasquier , R . Taouil , Y . Bastide , G . Stumme , and L . Lakhal . Generating a condensed representation for association rules . Journal of Intelligent Information Systems , 24(1):29–60 , 2005 .
[ 19 ] A . Soulet and B . Cr´emilleux . Adequate condensed representations of patterns . Data Mining & Knowledge Discovery , 17(1):94–110 , 2008 .
[ 20 ] S . B . Yahia , T . Hamrouni , and E . M . Nguifo . Frequent closed itemset based algorithms : A thorough structural and analytical survey . SIGKDD Explorations , 8(1):93–104 , 2006 .
[ 21 ] M . J . Zaki . Mining non redundant association rules . Data Mining & Knowledge Discovery , 9(3):223–248 , 2004 .
[ 22 ] M . J . Zaki and C J Hsiao . Efficient algorithms for mining closed itemsets and their lattice structure . IEEE Trans . on Knowledge and Data Engineering , 17(4):462–478 , 2005 .
relation . However , there is no direct relation between succint minimal generators and regular itemsets . First , succint minimal generators are not a concise representation , since free sets alone are not . Second , to reconstruct the free sets of a equivalence class , one has to look at succint minimal generators of that class and of other classes , so the meaning of a succint minimal generator is not and compositional .
7 . CONCLUSIONS
The study of patterns that are easy to understand , to manipulate and to reason about by data analysts , not necessarily data mining experts , is of primary importance for a general acceptance of the knowledge discovery methodology in everyday working life . In this paper , we have introduced an extension of itemsets , called regular itemsets , its clean semantics and a procedure , called RegularMine , for mining a concise representation of frequent itemsets . The main idea consists of finding a covering of a equivalence class in terms of regular itemsets . Experiments support our claim that regular itemsets are a good trade off between conciseness and direct interpretability by a data analyst .
A few open directions include the application of regular itemsets in non redundant association rule mining [ 18 , 21 ] and in case studies to validate their actionability on the field . From a computational side , our approach acts as a post processing phase starting from the closed itemset and the free sets in a equivalence class . As a future work , we intend to study how the approach can be integrated directly within the closed frequent itemset mining phase .
8 . REFERENCES [ 1 ] R . Agrawal and R . Srikant . Quest synthetic data generator . http://wwwalmadenibmcom/cs/projects/iis/hdb/Projects/data_mining/datasets/syndatahtml
[ 2 ] Y . Bastide , R . Taouil , N . Pasquier , G . Stumme , and
L . Lakhal . Mining frequent patterns with counting inference . SIGKDD Explorations , 2(2):66–75 , 2000 .
[ 3 ] C . Borgelt . An implementation of the FP growth algorithm . In Proc . of OSDM 2005 , pages 1–5 . ACM , 2005 .
[ 4 ] J F Boulicaut , A . Bykowski , and C . Rigotti .
Free sets : A condensed representation of boolean data for the approximation of frequency queries . Data Mining and Knowledge Discovery , 7(1):5–22 , 2003 .
[ 5 ] A . Bykowski and C . Rigotti . DBC : A condensed representation of frequent patterns for efficient mining . Information Systems , 28(8):949–977 , 2003 . [ 6 ] T . Calders and B . Goethals . Non derivable itemset mining . Data Mining & Knowledge Discovery , 14(1):171–206 , 2007 .
[ 7 ] T . Calders , C . Rigotti , and J F Boulicaut . A survey on condensed representations for frequent sets . In Constraint Based Mining and Inductive Databases , volume 3848 of LNCS , pages 64–80 . Springer , 2004 .
[ 8 ] G . Dong , C . Jiang , J . Pei , J . Li , and L . Wong . Mining succinct systems of minimal generators of formal concepts . In Proc . of DASFAA 2005 , volume 3453 of LNCS , pages 175–187 . Springer , 2005 .
[ 9 ] J . Galambos and I . Simonelli . Bonferroni type Inequalities with Applications . Springer , 1996 .
