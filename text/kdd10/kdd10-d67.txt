Fast Online Learning through Offline Initialization for
Time sensitive Recommendation
Deepak Agarwal Yahoo! Research
Sunnyvale , CA , USA dagarwal@yahoo inc.com
Bee Chung Chen
Yahoo! Research
Sunnyvale , CA , USA beechun@yahoo inc.com
Pradheep Elango
Yahoo! Labs
Sunnyvale , CA , USA elango@yahoo inc.com
ABSTRACT Recommender problems with large and dynamic item pools are ubiquitous in web applications like content optimization , online advertising and web search . Despite the availability of rich item meta data , excess heterogeneity at the item level often requires inclusion of item specific “ factors ” ( or weights ) in the model . However , since estimating item factors is computationally intensive , it poses a challenge for time sensitive recommender problems where it is important to rapidly learn factors for new items ( eg , news articles , event updates , tweets ) in an online fashion . In this paper , we propose a novel method called FOBFM ( Fast Online Bilinear Factor Model ) to learn item specific factors quickly through online regression . The online regression for each item can be performed independently and hence the procedure is fast , scalable and easily parallelizable . However , the convergence of these independent regressions can be slow due to high dimensionality . The central idea of our approach is to use a large amount of historical data to initialize the online models based on offline features and learn linear projections that can effectively reduce the dimensionality . We estimate the rank of our linear projections by taking recourse to online model selection based on optimizing predictive likelihood . Through extensive experiments , we show that our method significantly and uniformly outperforms other competitive methods and obtains relative lifts that are in the range of 10 15 % in terms of predictive log likelihood , 200 300 % for a rank correlation metric on a proprietary My Yahoo! dataset ; it obtains 9 % reduction in root mean squared error over the previously best method on a benchmark MovieLens dataset using a time based train/test data split .
Categories and Subject Descriptors H33 [ Information Search and Retrieval ] : Information filtering ; G.3 [ Mathematics of Computing ] : Probability and Statistics
General Terms Algorithms , Design , Experimentation
Keywords Reduced rank regression , recommender systems , latent factor , factorization , dyadic data
1 .
INTRODUCTION
We consider recommender problems where it is usual to have high churn in items and/or users . Such applications are common in problems like content optimization [ 2 ] , news personalization [ 15 ] , recommendation of dynamically changing items ( updates , tweets , etc ) , computational advertising[9 ] and many others . Rapidly learning user to item affinities for new items/users is key to success in such scenarios . Motivating application : To motivate our problem , consider a web portal that recommends articles to users ( eg , [ 2 ] ) with the goal of optimizing some user engagement metric like click through rate ( CTR ) . Items in such applications are usually content articles on different topics . The item pool in such applications is typically large and/or dynamic with short lifetimes . Some desired properties of a recommender algorithm in such applications include :
• Fast learning of user to item affinities : While some item/user characteristics may be captured by a set of features ( eg , keywords , categories , browse behavior ) and feature weights can be learned retrospectively through historical data , constructing predictive features is often difficult [ 2 ] ; CTR of items/users sharing the same set of features may vary substantially . It is attractive to model user to item affinities at the individual item/user level . Such item/user specific factors ( or weights ) are not known for new items/users and have to be learned rapidly in an online manner to provide timely recommendations .
• Scalability : The item pool can be large and the user visit rate can also be high . Online learning should be computationally efficient and scalable .
To clarify terminology , by offline learning we mean building a predictive model based on historical data . Note that new items and users are not in historical data . Also , offline models may be rebuilt periodically but with long latency ( eg , daily ) . On the contrary , online learning uses response data in the recent past and updates the states of a predictive model with low latency ( eg , every minute ) . Potential solutions : Before we discuss our approach , we first review a number of potential solutions and point out some limitations of these methods .
• Offline feature based regression : A standard approach is to characterize user i and item j by feature vectors xi and xj
703 respectively ( we slightly abuse notation and use the subscripts i and j to distinguish between user and item feacture vectors ) An offline regression model is trained using xi and xj as features to predict expected response μij when user i interacts with item j . Such models , although effective , provide inferior performance compared to user/item specific models since users/items tend to be heterogeneous in large scale recommender problems . An ideal solution would converge to user/item specific models with increase in sample size but fallback on feature based model in small sample size scenarios [ 1 ] . However , another important aspect which we consider in this paper is quick convergence to user/item specific models in an online fashion ; this tends to have a significant impact in applications where timely recommendations are critical for better user experience .
• Standard online regression : Another routine approach is to build an online model for users/items . For instance , consider a scenario where we want to learn an item specific regression for a set of user features . One can model the expected response μij ( or some monotone transformation ) using a generalized model h(μij ) = x . iβj , where βj is the regression weight vector for item j on user features xi . This is an attractive approach when the dimension of user feature vector is small ; large dimensional βj would generally lead to slow convergence and inferior performance in online scenarios . The methods in this paper are motivated by this issue and provide effective ways of seeding the online model by leveraging historical data to reduce dimensionality .
• Collaborative filtering methods : While most collaborative filtering methods do not address fast online learning , several incremental collaborative filtering techniques have been studied in the context of similarity based methods ( eg , [ 7] ) . Although these techniques can be used to recommend in the context of time sensitive applications , they have been found to be less accurate than factorization style methods we work with in this paper [ 5 , 1 ] . This is also observed in our experiments described in section 5 .
Overview of our solution : We now provide an overview of our approach . For simplicity , we assume all user features ( factors ) are known but there exists a large fraction of new items for which we want to learn user affinity weights rapidly in an online fashion . Our method generalize to scenarios where the roles are reversed — we want to learn affinities for new users with known item features(factors ) . A general approach that learns both user and item factors in an online fashion is described in section 23
Conceptually , our solution consists of two main components : ( 1 ) Feature based initialization for online models using historical data , and ( 2 ) dimension reduction of our online learning problem by leveraging historical data to enable fast model convergence . We note that the second component works even in applications without any item/user features and hence it is attractive when feature ( or content ) agnostic collaborative filtering is a focus .
At a high level , we model some monotone function h of expected response μij as u . iAxj + u . ivj , where vj = Bθj . ui is the vector of features ( or factors leant offline ) for user i ; xj is the feature vector for item j ; A is a regression weight matrix ( learnt offline ) that models the interaction between ui and xj ; vj is the item factor vector of item j ( having the same dimensionality as ui ) . For instance , ui can be a set of user features based on age , gender , browse behavior , etc ; it can even be user factors learnt from historic data by using matrix factorization or any other feature construction method . Since the dimensionality of item weight vj is the same as uj ( which is typically large ) , we decompose it into a global linear projection matrix B ( learnt offline ) that is shared by all items times a low dimensional item specific factor correction θj associated with item j ( learnt online ) . We provide the rationale for the model below .
• Feature based initialization : u . iAxj can be thought of as a bilinear offline regression model and provides a good offset for online learning based on item features xj ; online model only needs to learn the “ correction ” over this offset . Before we observe any online data ( when θj = 0 ) , the response is actually predicted by this offline regression model . For instance , if click rates for males on sports articles are four times more than females , the offline part will use this knowledge for a new sports article and expedite convergence of the online item factor estimates . • Dimensionality reduction : .
In practice , the dimensionality of vj needs to be reasonably large to model the data well . However , vj also needs to be learnt online . For faster convergence , some form of dimension reduction is called for , especially during the early part of an item ’s lifetime . In the context of regression , this can be achieved either through shrinkage estimation techniques that constrains the degrees of freedom in vj by estimating an informative prior through retrospective data . Such an approach although attractive is computationally expensive since it still requires updates of large number of parameters in an online setting . In order to achieve both objectives ( “ shrinkage ” and “ fast updates ” ) , we appeal to an old technique known as reduced regression [ 4 ] where the idea is to reduce the dimension of parameter space when estimating a large set of related regressions through a lower dimensional projection . More specifically , we assume vj = Bθj , where B is learnt offline and only a small dimensional vector θj needs to be learnt online per item . In fact , rank reduction is equivalent to putting linear constraints on the parameter vector vj , thus reduced rank imposes “ hard ” constraints on the parameters as opposed to “ soft ” constraints that are imposed through a prior on vj by shrinkage methods . • Rapid online regression : Note that the rank reduction now implies that only a small dimensional θj needs to be learnt online for each item j , which is also independent of other items . Since the dimensionality of θj is small and the number of data points for each item is relatively larger , even sophisticated regression methods can be fitted . Also , the models for different items can simply be fitted in parallel .
• Online model selection : The rank reduction parameter k = rank(B ) is crucial and needs to be estimated properly , we do so by simultaneously fitting K online models for each item j for K different rank values and selecting the model with the current best predictive log likelihood .
Our contributions are as follows . We address the problem of fast online learning of user item affinities by effective initialization through offline analysis . Initialization is an important problem for online models when the number of available observations are small or fast convergence is important but have not been studied much in the literature . In this work , we provide a novel solution that combines feature based regression and user item specific learning in a single framework that significantly expedites convergence of online
704 models for both new users and items . The main idea of our methods is to reduce dimension of user/item factors by leveraging large amounts of historic data . We discuss two scenarios — one in which user or item features are known and the goal is to learn the other in an online fashion , while the second scenario is more general and includes joint online learning of both user and item factors . We consider two shrinkage estimation techniques to accomplish this — the first one updates large number of parameters online but is initialized with an informative prior learnt offline ; the second strategy reduces the dimension of the parameters by projecting into a lower dimensional subspace which is also learnt offline . We examine several real life scenarios and report significant improvement in performance through variants of our fast online learning methods .
2 . MODELING DETAILS
In this section , we develop our model in steps and discuss the rationale behind the it . We begin with notations .
Data : We shall denote by ( i , j ) the pair corresponding to user i and item j . Let yijt denote the response ( rating or click ) obtained when item j is displayed to user i at time t . We note that our approach works for any response that can be modeled in a generalized linear model framework [ 20 ] . Slightly abusing notations , we let xit , xj and xijt denote feature vectors for user i ( at time t ) , item j and pair ( i , j ) ( at time t ) respectively . For instance , xit may include user demographics , geo location , browse behavior and so on . The vector xj denotes the set of item features and may include content category , tokens extracted from the title , body when items have textual description and so on . Although item features may also be time sensitive , in most of our examples we do not have such features , hence no subscript t for item features xj in our notation . Finally , xijt is a vector of features that are not entirely attributable to either user or item ; examples include position on a page where an item is displayed , time of day when an item is displayed and so on . Note that we may drop the time index t from our notations when not required .
Observation model : For binary ratings or clicks , we assume yijt ∼ Bernoulli(pijt ) and let sijt = log pijt 1−pijt
, where pijt and sijt are click probability and log odds of a click respectively . For known values of pijt ’s , the response values yijt ’s are statistically independent . The log likelihood of our data under the Bernoulli model above is given by .({pijt} ; {yijt} ) =
( yijt log(pijt ) + ( 1 − yijt ) log(1 − pijt ) )
. i,j,t
For numeric ratings , we assume yijt ∼ Normal(sijt , σ2
) , where sijt is the mean and σ2 is the variance , and the log likelihood of data under the Gaussian model is .({pijt};{yijt} ) = − R log σ2 − 2
( yijt − sijt)2
+ constant ,
.
2σ2 i,j,t where R is the number of observed ratings .
2.1 Online Regression + Feature based Offset The key modeling challenge is to estimate the sijt ’s that capture interaction between user i and item j over time . We first describe our model for applications where user characteristics can be captured by user features xi . Later , we will extend our model to include user factors.1 Our approach is to model sijt in terms of two components given by
( 1 ) sijt = ( x . ijtb + x . • Feature based regression x . itAxj ) + x . ijtb + x . itvjt itAxj : Here , b and A are unknown regression weights that can be estimated from large amounts of historical data . Note that we do not consider item IDs as features . This regression is routinely used for estimating click rates ( see for example [ 23 , 11] ) . Although this regression provides a good baseline , the predictive performance can be significantly improved by including itemspecific factors that models heterogeneity at the individual item level .
• Per item regression x . itvjt : This part handles the heterogeneity at the item level , where vjt is the item specific unknown factor vector . Since new items do not appear in historical data , their vjt ’s need to be learnt in a online manner . ijtb + x .
It is important to note that x . itAxj provides a strong offset for online learning of item specific factors . In particular , we only need to learn the “ correction ” to this offset in an online manner . When the features are reasonably predictive , the variation in corrections is small and the online model converges faster .
In general , features xit and xj can be high dimensional ; hence , the regression weight matrix A can be large . However , xit and xj are also typically sparse ; many learning methods ( eg , [ 18 ] ) can exploit this sparsity to obtain estimates of A in a scalable fashion . Having item specific factors vjt increases the complexity of the model and makes parameter estimation challenging . For instance , if user feature vector xit has a few thousand elements , one may have to estimate millions of parameters with a modest inventory pool of a few thousand items using fairly small number of observations ( because new items have small sample size ) . 2.2 Reduced Rank Regression
We now discuss a reduced rank regression approach to dimensionality reduction that is obtained by imposing linear constraints on item regression parameters . The main advantage of this approach is a significant reduction in computational complexity in the online phase obtained by sharing parameters across items . The shared parameters are computed as part of offline process . The sharing happens because we assume there are redundancies in r dimensional item parameters vjt . In particular , we assume vjt ’s belong to a k dimensional linear subspace spanned by the columns of an unknown loading matrix Br×k ( k fi r ) . Hence , there exists θjt such that vjt = Bθjt ,
( 2 ) for all items j . Thus , given loadings B , we only need to learn k parameters online for each item . To avoid numerical ill conditioning during computations , we assume θjt ∼ MVN(0 , σ2 θ I ) , where MVN denotes the multivariate normal distribution . Marginalizing over θjt , it is easy to see that vjt ∼ MVN(0 , σ2BB . ) . Note that since rank(B ) = k < r , this puts all probability mass in a lower dimensional subspace spanned by columns of B . It is generally better to work with a more robust model that assumes vjt = Bθjt + j t , where j t ∼ MVN(0 , τ 2I ) is a white noise process that captures 1In our terminology , features are observed covariates , while factors are unobserved “ model weights ” that need to be estimated from data .
705 idiosyncracies leftover after the k dimensional linear projection . This removes the rank deficiency and the marginal distribution of vjt ∼ MVN(0 , σ2BB . + τ 2I ) . While it is easy to work with this model for Guassian response , it adds significant computational complexity for the logistic model ; hence , in this paper , we assume τ 2 = 0 . We note that reduced rank regression similar in spirit to our approach have been considered in the literature [ 4 ] where coefficient matrix from several simultaneous regressions are assumed to be of reduced rank and τ 2 = 0 . However , all such approaches assume the response matrix to be small and complete . Our user × item matrix is large and highly incomplete ; this adds new technical challenges that we address in this paper . 2.3 Simultaneous Learning of User and Item
Factors
We now describe a general approach for fast online learning for both user and item factors through bilinear factor models . We note that this is the most general approach and the previous model that assumes either user or item features are known is a special case . We still consider these two cases separately because they are important in practical applications — it is routine in web applications for instance to construct a large set of user features by pre processing user activity in several contexts . For applications where it is attractive to work with matrix factorization style models , the simultaneous online learning approach is attractive . We describe our approach below .
We first assume there are no user or item features available and the goal is to learn factors per user/item only through observed response . For simplicity , we will also assume a Gaussian response since factorization models have been more widely used in the context of ratings data . Ignoring the time suffix for the moment ( and suppressing user/item bias terms for simplicity ) , bilinear factor models assume sij = U . i Vj i
U r×1 V r×1 j
∼ MVN(0 , Au ) ∼ MVN(0 , Av )
( 3 )
In practice , one assumes Au = auI and Av = avI and although the total number of factors r ( dimension of u , v ) are same for both users and items , the effective rank depends on the amount of shrinkage which is determined by ratios au/σ2 and av/σ2 respectively . Hence , one simple strategy to perform online learning in this setting is to use retrospective data to estimate the shrinkage parameters and then use these as informative priors to initialize factor learning for new item/users . Although this strategy is attractive , it may lead to problems with online computations since it involves updating a large number of parameters online . Is it possible to consider a concept similar to reduced rank in this scenario that performs shrinkage but also ensures online computational efficiency ? To explore this issue , let us assume there are redundancies in both user and item factors , ie , users and items can be projected into r1 and r2 dimensional subspaces . This implies the factors can be written as Ui = B1ui , Vj = B2θj , where B1 and B2 are of dimensions r × r1 and r × r2 . Then , we obtain an equivalent model to Equation 3 given by sij = u . iB1B2θj ur1×1 θr2×1 i j
∼ MVN(0 , auI ) ∼ MVN(0 , avI )
( 4 )
Since the product B1B2 is not individually identifiable , we assume Br1×r2 = B1B2 . Note that r1 , r2 ≤ r and this can be
Observation :
Offline model :
Online model : pijt 1−pijt ijtb + u . itAxj + u . yijt ∼ Normal(sijt , σ2 ) or yijt ∼ Bernoulli(pijt ) , sijt = log sijt = x . itvjt uit can be just features ( ie , uit = xit ) or uit ∼ MVN(Gxit , σ2 uI ) are user factors vjt = Bθj θj ∼ MVN(0 , σ2 vI ) sijt = x . itAxj + u . ijtb + u . itBθjt θjt learnt through online regression
Table 1 : Our Model regarded as a bilinear form of reduced rank . Working with this model and estimating B offline facilitates fast online learning of user and item factors . Here again , the considerations are similar to one sided reduced rank ; without any constraints on computational resources one could perhaps have a high dimensional prior on regression coefficients estimated offline that is accurate but it is still attractive to opt for reduced rank due to computational reasons .
By obvious arguments , we can extend this model to include known user/item features ; the full model along with time suffixes is given in Table 1 , where G is a regression weight matrix used to predict user factors uit based on user features xit .
3 . MODEL FITTING
We describe our model fitting algorithms in this section . We begin with a discussion of our offline model fitting method that is used to estimate parameters η = ( b , A , B , G , σ2 , σ2 v ) and the posterior mean of the factors , and then the online procedure . 3.1 Offline Model Fitting u , σ2
Our offline model fitting procedure is based on the expectationmaximization ( EM ) algorithm . For ease of exposition , we only provide the algorithm for the Gaussian model and we also drop the time index t . For the Logistic model , one can use the variational approximation [ 1 ] or the classification EM algorithm ( CEM ) [ 10 ] . Also , here we assume ui ’s are user factors that we want to learn from the data . The case where ui ’s are observed features is a special case . Let Y = {yij} denote the set of the observed ratings . This “ incomplete ” data is augmented with unobserved factors Θ = {ui , θj} to obtain the complete data . The goal of the EM algorithm is to find the parameter η that maximizes the “ incomplete ” data likelihood Pr(Y |η ) = Pr(Y , Θ|η)dΘ obtained after marginalization over the distribution of Θ . Such a marginalization is not available in closed form in our case , hence we take recourse to the EM algorithm . fi
EM algorithm : The complete data log likelihood l(η ; Y , Θ ) for our Gaussian model as described in Table 1 is given by l(η ; Y , Θ ) =
' ' ' ff ff ( yij − x . ff ( ui − Gxi ) θ . jθj + k ij i j
2σ2
− 1 − 1 − 1
2σ2 u
2σ2 v ijb − u . iAxj − u .
( ui − Gxi ) + r
. iBθj )2 + log σ2 2 log σ2 u
2 log σ2 v
, where ui is a r dimensional vector and θj is a k dimensional vector . Let η(h ) denote the estimated parameter setting at the hth iteration . The EM algorithm iterates through the following two steps until convergence .
• E step : Compute fh(η ) = EΘ[l(η ; Y , Θ)| η(h ) ] as a function of η , where the expectation is taken over the posterior
706 distribution of ( Θ| η(h ) , Y ) . Note that here η is the input variable of function fh , but η(h ) consists of known quantities ( determined in the previous iteration ) . In fact , we will compute the sufficient statistics of fh(· ) in the E step .
• M step : Find the η that maximizes the expectation com puted in the E step .
η(h+1 )
= arg max
η fh(η )
We will use the sufficient statistics computed in the E step to solve this maximization problem .
Because the expectation in the E step is not available in closed form , we use a Gibbs sampler and compute the Monte Carlo mean .
Monte Carlo E step : The Gibbs sampler repeats the following procedure L times . In the following , we use ( ui | Rest ) , and ( θj | Rest ) to denote the conditional distribution of ui and θj given all the other factors . Let Ij denote the set of users who rated item j , and Ji denote the set of items that user i rated .
1 . For each user i , sample ui from ( ui | Rest ) , which is Gaus sian , for all i .
Let oij = yij − x . I +
' Var[ui|Rest ] = E[ui|Rest ] = Var[ui|Rest ]
1 σ2 u
( −1 ' qj q . σ2 j j∈Ji
1 σ2 u
Gxi + ijb and qj = Axj + Bθj
( j∈Ji oij qj
σ2
2 . For each item j , sample θj from ( θj | Rest ) , which is Gaus sian , for all j .
Let oij = yij − x . I + ijb − u . '
Var[θj|Rest ] = E[θj|Rest ] = Var[θj|Rest ] i∈Ij
1 σ2 v
( −1 iAxj and qi = B.ui qiq . ' σ2
( i
1 σ2 v i∈Ij oij qi
σ2
Let ˜E[· ] and ˜Var[· ] denote the Monte Carlo mean and variance computed using the L Gibbs samples . The output of the E step con˜E[θ . sists of ˜E[ui ] for all i , ˜E[θj ] for all j , i' ˜Var[ui' ] , j ij ˜Var[sij ] . These will be where ui' is the .th element in ui , and used in the M step .
' '
' j θj ] ,
M step : The M step consists of the following steps .
'
˜E[θ . j
1 . We estimate σ2 v by ber of items . j θj ]/(kN ) , where N is the num
2 . We estimate ( G , σ2 u ) as follows . Let G' denote the .th row of G and ui' be the .th component in ui . We find G' by solving a regression problem using xi as features to predict ˜E[ui' ] , for each Let RSS' denote the residual sum of squares of the .th regression . We have σ2 i' ˜Var[ui']+
' u = (
'
' RSS')/(rM ) , where M is the number of users .
3 . We estimate ( b , A , B , σ2 ) as follows . We first solve the fol lowing least square problem to obtain ( b , A , B ) .
( yij − x . ij b − ˜E[ui ]
.Axj − ˜E[ui ]
.B ˜E[θj ] )
2 ,
( 5 )
. ij
Note that in the 3rd step above , we used plug in estimates , instead of the precise expectation formula , to ensure computational feasibility . Approximating the exact formula using plug in estimates is a common practice to speed up computation , eg , [ 24 , 10 ] . In particular , we approximate ijb − u . iAxj − u .
E
2
( yij − x . ( yij − x . iBθj ) .Axj − E[u . ijb − E[ui ] iBθj ] )
2
+ Var[sij ]
) . . ij
= ij by Eq 5 . Since E[u . effectively we treat tr(BCov(ui , θj ) ) and Var[sij ] as constants .
.BE[θj ] + tr(BCov[ui , θj ] ) , iBθj ] = E[ui ]
Scalability : We note that our fitting method is scalable . In the E step , when drawing the .th Gibbs sample , the factors for each user can be drawn independently of other users , thus easily parallelizable . This is the same for items . The M step requires solving several standard least square regression problems . Any scalable software package can be used here . 3.2 Fast Online Regression
The output from the offline training ( that will be used in online learning ) consists of the regression weights ( b , A , B ) , user factors ui ’s and the prior variance σ2 v . Recall that the online model for item j is given by ijtb + u . sijt = x . itAxj is the offset , u . itAxj + u . itBθjt , ijtb+u . where x . itB is the dimension reduced user feature vector and θjt is the regression weight vector . Since the online model for each item j is independent of one another and the dimensionality of θj is small , the model update is very efficient , scalable and parallelizable . In general , one can use the standard Kalman filter [ 22 ] to sequentially update the model by setting the prior mean and variance of θj to be 0 and σ2 3.3 Online Model Selection v , respectively .
We note that the number of factors k per item ( the length of vector θj ) can have an impact on performance ; this is especially true in the early part of an item ’s lifetime . For instance , small values of k are expected to perform better with only a few item observations but large values of k may perform better with increasing item observations . To select the best k , we take the approach of online model selection . Specifically , for each item , we keep multiple models corresponding to a range of k values ( eg k = 1 , ··· , 10 ) . We assume the best k for an item is a function of the number n of observations that the item has received . Further , we use the predictive log likelihood as the selection criterion . Let lk,n denote the average predictive log likelihood on the nth observation for all the k factor online models that were updated using n − 1 observations in the past . Then , for an item that is going to be used to predict the nth observation , we pick the k that has the largest lk,n . To make lk,n smooth over n , one may we use a simple exponential weighting scheme . Let 0 < w ≤ 1 be a pre specified weight . Let lk,n,j denote the predictive log likelihood of item j ’s k factor model tested on the nth observation . Instead of setting lk,n = avgj[lk,n,j ] , we set lk,n = avgj [ l∗ k,n−1,j . k,n,j = wlk,n,j + ( 1 − w)l∗ k,n,j ] , where l∗ which is in fact a large scale least square regression problem ; many scalable programs are available for solve such a problem . Let RSS denote the residual sum of squares of this ij ˜Var[sij ] + RSS)/D , where problem . We estimate σ = ( D is the number of ratings .
'
4 . RELATED WORK
Modeling temporal dynamics in recommender systems is related , but with a different focus . Koren [ 17 ] recently extended matrix factorization to capture the temporal dynamics of old movies and
707 changing behavior of old users . They did not address the cold start problems or fast online learning for new items/users in large scale applications . In contrast , although the online models can also capture temporal dynamics , the focus of this paper is to learn item factors quickly and effectively in a online manner .
Recent work on matrix factorization for movie recommender problem is also related [ 5 , 24 ] . However , they primarily focus on the Netflix problem and do not consider the cold start problem or exploit user/item covariates . Other papers like [ 1 , 26 ] extend matrix factorization to include features and consider online updating of factors . To the best of our knowledge , exploiting retrospective item level data to facilitate rapid online learning have not been considered in the matrix factorization literature .
Reduced rank regression is an old technique in multivariate statistics [ 4 , 14 ] . However , existing literature in this area assumes a small and complete response matrix along with feature vectors attached to each row of the matrix . The goal is to fit regressions to each column using the same row features , this often results in too many parameters . Reduced rank regression provide stable estimates through rank reduction of the coefficient matrix by imposing linear constraints . However , our scenario is different from this setting ; the user × item response matrix in our case is extremely large but highly incomplete . Moreover , we use ideas in reduced rank to generalize regression to new columns that appear in our response matrix , such a problem has not been studied before .
Our work is also related to factor regressions that have been considered in the genomics literature [ 25 ] . Another closely related technique that have been studied extensively in both bioinformatics and chemometrics is partial least squares [ 19 ] . However , though closely related , these methods have been primarily used in the context of a single regression that is estimated offline . The main goal is dimension reduction due to the presence of a large number of covariates and paucity of observations ; in fact , number of covariates far exceeds the number of observations . Our motivation is entirely different , we have data available from multiple regressions ( one for each old item ) that is used to obtain a stable estimate of the loading matrix . This in turn facilitates rapid online learning for new items by significantly reducing the dimension of the item regression problem ( from r to k , k fi r ) . In fact , we seek lower dimensional projections that work simultaneously for multiple regressions as opposed to existing work in this literature that estimate projections only for a single regression .
Our work is related to adaptive news personalization that has received increasing attention in the last few years . For instance , [ 6 ] describes an approach to build user profile models for adaptive personalization in the context of mobile content access . Their approach is based on a hybrid model that combine content based approaches with similarity methods used in recommender systems . This is further exemplified in [ 3 ] where text processing techniques are used to build content profiles for users to recommend personalized news . The system called YourNews tokenize articles from RSS feeds and builds a tf idf vector of tokens for each user ; standard information retrieval approaches are used to fetch personally relevant articles for a user . None of these techniques build models that estimate user profile by simultaneously using both item content and item specific user interactions as we do in our approach . A content agnostic approach based on collaborative filtering technniques was proposed in [ 15 ] , cold start for new items/users was not the focus of that work . The approach that is directly related to our work was proposed in [ 13 ] , they use logistic regression as we do . but only focus on the covariate based regression sijt = x itAxj . They include item parameter through a dynamic covariate given by the overall item CTR at time t . This can be obtained as a special case of our model with k = 1 and θj1t = overall CTR(jt ) . This is inferior to our 1 factor model that estimates θjt online but after adjusting for all other effects . In fact , in section 5 we show that the 1 factor has inferior performance compared to the best model selected by the online selection method ( see Figure 3 ) .
In online advertising , [ 23 ] propose a model to estimate clickrates of new ads using a covariate based logistic regression . They show improved performance and convergence but do not consider ad centric models . Personalization has also been pursued in web search where one builds user models ( short term and long term ) based on queries to personalize search results[21 ] . This is again more in spirit to work done in adaptive news personalization ; document matches are made only in terms of features derived through user queries without considering document level corrections .
Incremental collaborative filtering has been studied in the context of PLSI and similarity based methods . A detailed comparison of all the methods is beyond the scope of this paper . However , fast online learning for factor models that are initialized based on large amount of historical data has received little attention . In this work , we show this approach is significantly superior than two representative incremental collaborative filtering methods [ 7 , 15 ] .
5 . EXPERIMENTS
In this section , we demonstrate our methods on a MyYahoo dataset , the MovieLens 1M dataset and a Y!FP ( Yahoo! Front Page ) dataset . We show our method significantly outperforms a variety of alternative methods in several different application scenarios . Our experimental results also reveal insights into the strong performance of regression based factorization with large number of factors in the online learning setting , which has not been studied in the literature . 5.1 My Yahoo! Dataset
We first use the My Yahoo! dataset to study the effectiveness of the reduced rank regression technique and online model selection for the scenario in which users are represented by features ( not factors ) and items have short lifetimes . This scenario includes applications that have many users who have no past ratings ( ie , user cold start ) , systems that do not have reliable user identifiers , and companies which want to have a unified profile ( features ) for each user ( instead of user factors customized for different application ) .
Data : The data was collected during August and September , 2009 , from the server logs of My Yahoo! ( http://myyahoocom/ ) and consists of 13,808 items ( articles ) and around 3 million users . Each observation represents either a positive event in which a user clicked an item ( article link ) or a negative event in which a user viewed an item but did not click . Each user is represented by a set of around 1K features including include age , gender , user interest categories and user ’s activity levels on different Yahoo! sites [ 12 ] . Item features include top keywords and top URL hosts . The training set consists of all the events that are associated with the first 8,000 items ( based on item publication time ) and the remaining data is our test set .
Models : We compare the following models :
• Offline is a bilinear regression model that is trained using the training data based only on offline features ; ie , sijt = x . ijtb + x . itAxj . No online learning is done for this model . • No init is a saturated item level online regression model without initialization ; ie , sijt = x . itvj , where vj is learned in a online manner with prior M V N ( 0 , σ2I ) , where σ2 is tuned using the test set , and we only report the performance for the
708 best σ2 ( σ2 = 001 ) This model has a large number of parameters to be estimated online , in fact , one parameter for each ( item , user feature ) pair .
• PCR is a principal component regression model without offline bilinear regression ; ie , sijt = x . itBθj , where B consists of the top k principal components of user features . Note that B is purely determined based on the xit ’s in the training set and k is tuned based on the test set ; as before , we only report the performance for the best k = 5 and best σ2 = 01 • PCR+ is a principal component regression model that also includes offline bilinear regression ; ie , sijt = x . ijtb + x . itAxj + x . itBθj , where B consists of the top k principal components of the user features . Note that , while B is determined purely based on the xit ’s , A is estimated in a supervised manner based on the yijt ’s in the training set . Again , we only report the performance of the best k = 5 and best σ2 = 0.1 tuned based on the test set .
• FOBFM is our model with ui being user features and k se lected in a online manner . It has no tuning parameters .
It is important to note that No init , PCR and PCR+ have tuning parameters that are tuned based on the test set . This tuning makes the performance of those models stronger than their real performance . As will be seen , our model FOBFM ( without tuning ) still uniformly outperforms those models ( with tuning ) .
Performance metrics : Model performance metrics are computed using the test data . To report model performance over time , we sort the events in our test set by timestamps and allocate the first n events for each item to bucket 1 , the subsequent n events for each item into bucket 2 , and so on ( in most plots , we use n = 10 ) . We then compute performance metrics for each bucket . For instance , events in bucket b are evaluated by a model trained only using observations of the events prior to bucket b ( excluding bucket b ) . Let pk denote the predicted click probability of the kth test event in bucket b . Let S+ denote the set of pk ’s that correspond to positive events and S− denote the set of pk ’s that correspond to negative events . We use |S| to denote the size of set S . We look at two performance metrics :
' pk∈S+ log pk +
'
• Test set log likelihood : pk∈S− log(1− pk ) . It quantifies how likely the test events are under the model and represents how accurately the model can predict click probabilities .
• Test set rank correlation : For applications where the model is not used for probability estimation but for ranking , comparing models based on rank correlation [ 16 ] between the yk ’s ( the true label ) and the pk ’s is a useful metric to consider . Let s+ denote an element in S+ , and s− denote an element in S− . Let C be the number of ( s+ , s− ) pairs such that s+ > s− , and N be the number of ( s+ , s− ) pairs such that s+ < s− . Then , the test set rank correlation is defined as ( C − N )/(|S+| × |S−| ) , which quantifies a model ’s ability of separating positive cases from negative cases by the predicted scores ( intuitively , it represents the goodness of using the model to rank items ; a model ’s ability to correctly predict probabilities is not captured by this metric ) . A perfect model that ranks all the positive events higher than all the negative events would get rank correlation 1 . Reversing a perfect ranking would give 1 . Random or constant prediction would give 0 rank correlation . d o o h i l e k i l g o l t s e t n i t f i
L %
15
10
5
0
No−init Offline PCR PCR+ FOBFM
0
100
200
300
400
# Observations per item
Figure 1 : Test set log likelihood of different models on the My Yahoo! dataset ( the log likelihood of the Offline model is around 0.64 ) n o i t l a e r r o c k n a r t s e t n i t f i L
%
300
250
200
No−init Offline PCR PCR+ FOBFM
0
100
200
300
400
# Observations per item
Figure 2 : Test set rank correlation of different models on the My Yahoo! dataset ( the rank correlation of the Offline model is around 0.12 )
In Figure 1 and Figure 2 , we compare different models in terms of the test set log likelihood and rank correlation , respectively . In each plot , the x axis represents the number of observations that have been used to update the model for each item , and the y axis represents the performance metric computed for the next bucket . We report the lift in log likelihood ( and rank correlation ) of each model relative to the Offline model . As evident from the figures , our method significantly outperforms all the other models ; the lift obtained is uniformly better than other methods over all time bins , even though parameters for the other models were tuned using the test set ( thus favoring the other models while FOBFM has no tuning parameters ) . We note that , for this dataset , the item features are not significantly predictive as evident from the poor log likelihood and rank correlation of the Offline model . In fact , this contributes to the large lift values we obtain from online models .
Effectiveness of online model selection : To investigate the effectiveness of online model selection in our method ( selecting the rank k ) , we plot log likelihood lift curves ( similar behaviour observed for rank correlation lift curves ) for our reduced rank regression model but with different values of the rank parameter k in Figure 3 . Intuitively , increasing the rank increases number of observations required for online convergence . Roughly speaking , before an item gets 100 observations for online learning , the model with rank 1 per item outperforms all others . Subsequently , the model
709 d o o h i l e k i l g o l t s e t n i t f i
L %
14
13
12
11
10
01 factor 03 factors 05 factors 07 factors 10 factors Selected
0
100
200
300
400
# Observations per item
Figure 3 : Test set log likelihood for different number of factors on the My Yahoo! dataset with rank 3 per item catches up , and then the model with rank 5 per item catches up , and so on . For this dataset , the rank 1 model dominates during the initial part of the curve and then the rank 3 dominates the rest . From this figure , we also see that our online model selection scheme ( the circles ) almost always selects the best number of factors . 5.2 MovieLens Dataset
In this section , we illustrate our method on the widely studied MovieLens 1M dataset . In particular , we show our method outperforms other incremental collaborative filtering methods . We also give insight into the strong performance of the factorization model without reduced rank regression . Since features are an important part of our study , we did not consider Netflix ( no user features are available ) . This dataset has one million ratings , 6,040 users and 3,706 movies . User features used include age , gender , zipcode ( we used the first digit only ) , and occupation ; item features include movie genre .
Models : In [ 1 ] , we have shown that RLFM and Dyn RLFM outperform a number of standard collaborative filter methods on this dataset ; thus we omit those methods . We compare the following four models :
• RLFM is a regression based latent factor model without online learning . Dyn RLFM is the dynamic version of RLFM , which performs computationally intensive online learning . Dyn RLFM was previously applied to MovieLens with batch size 1000 ( and got RMSE 09258 ) Reducing the batch size can increase the accuracy ; however , we do not explore this further since it is too extensive .
• Online UU is a user user similarity based collaborative filtering method , as described in [ 7 ] . The prediction for a user a and item j is given by w(a , i ) ∗ ( ri,j − ¯ri )
|w(a , i)|
. i∈Rj
¯ra +
Model FOBFM RLFM Online UU Constant
Time split RMSE
Item split RMSE
0.8429 0.9363 1.0806 1.1190
0.8549 1.0858 0.9453 1.1162
Table 2 : Test set RMSE on Movielens
Data : We consider two kinds of train/test splits .
• Time split : The natural split of this data into training and test sets is based on time . We take the first 75 % ratings in chronological order as training data and the rest as test data . We note that in the test set , 98 % of the movies have past ratings in the training data ; there is no item cold start . However , around half of the users are new in the test set . Thus , we apply online learning for user factors , instead of movie factors , on this time split data . Specifically , we perform factorization on the training set ; on the test set , we fix the movie factors and learn the user factors in an online manner .
• Movie split : To evaluate the item cold start scenario , we create another training/test split . We randomly split the set of movies into training movies ( 75 % ) and test movies ( 25% ) , and put all the ratings associated with the training movies into the training set and the rest into the test set . For this item split , we perform factorization on the training set ; on the test set , we fix the user factors and learn the movie factors in a online manner .
In Table 2 , we report test set root mean square errors ( RMSE ) of these methods . We note that FOBFM is obtained by the factorization model with 40 user factors , 40 item factors and B fixed to the identity matrix . We note that by increasing the number of factors we usually see slight improvement of performance . Also , learning the B matrix or reducing its dimensionality does not help . Further , the online model selection almost always select the one having the largest number of factors . In the following , we provide explanation of this behavior .
Dimensionality reduction : Reduced rank regression can be used to reduced the number of factors to be learnt . However , FOBFM without reduced rank regression also effectively reduces its dimensionality by shrinkage . Let FOBFM n×k denote the reduced rank version that reduced the online factors from n to k , and FOBFM k denotes the model without reduced rank that has k factors . Table 3 shows that when k is small compared to n , FOBFM n×k is better than FOBFM k . We note that difference diminishes when k becomes larger and FOBFM k may be better than FOBFM n×k . In fact , the effective dimensionality of FOBFM k is not k because of the prior variance components that cause shrinkage . To see this , we show the prior variance for the online factors for different k values ( on the item split data ) in the following table . k Var
1
3
5
10
20
30
40
0.234
0.123
0.075
0.047
0.028
0.020
0.017 where ¯rk is the mean rating of user k , Rj includes all raters of item j ( updated after every event in the test set ) and w(a , i ) is the Pearson ’s coefficient of correlation as used in [ 7 ] .
• Online PLSI is the PLSI method with approximate online update described in [ 15 ] .
• FOBFM is our model with ui being factors .
In general , shrinkage can be thought of as “ soft ” dimensionality reduction . If shrinkage parameters ( ie , prior variances ) are estimated correctly , shrinkage can provide better performance than “ hard ” dimensionality reduction that projects features from a ndimensional space to a k dimensional space .
Comparison with Online PLSI : We note that Online PLSI [ 15 ] only applies to binary data . To compare to this method , we create
710 k 1 3 5 7
Time split
FOBFM 40×k
FOBFM k
Item split
FOBFM 40×k
FOBFM k
0.8680 0.8570 0.8518 0.8514
0.8793 0.8650 0.8567 0.8526
0.8936 0.8789 0.8712 0.8675
0.8949 0.8811 0.8754 0.8727
Table 3 : Test set RMSE on Movielens e t a r e v i t i s o p e u r T
0 . 1
8 . 0
6 . 0
4 . 0
2 . 0
0 . 0
FOBFM Online−UU Online−PLSI RLFM
0.0
0.2
0.4
0.6
0.8
1.0
False positive rate
Figure 4 : ROC curves on MovieLens item split ( binary ) binary ratings from the movie split dataset . For each user , if he/she gives a movie a rating higher than his/her average rating , we have a positive observation ; otherwise , the observation is negative . The ROC curves for FOBFM ( 40 factors ) , Online PLSE ( 50 factors ) , Online UU and RLFM ( 40 factors ) are shown in Figure 4 . 5.3 Yahoo! Front Page Dataset
Finally , we show the performance on a previously studied Yahoo! Front Page dataset [ 1 ] . This dataset consists of 1,909,525 “ binary ratings ” ( clicks vs . views without any subsequent click ) given by 30,635 frequent Yahoo! users ( each has at least 30 ratings in 5 months ) to 4,316 stories . User features are the same as those in the MyYahoo dataset . Item features include a set of editorially labeled categories for each story . We order the events by time and split data into the training set ( first 75 % ) and the test set ( last 25% ) . Figure 5 shows the ROC curves of different methods . Online PLSI uses 50 factors , while FOBFMuses 30 factors without reduced rank regression . As can be seen FOBFM has the best performance .
6 . DISCUSSION
In this paper we proposed FOBFM , a model that provides fast online learning capability through effective initialization that exploits the availability of historical data , to handle the cold start problem in recommender systems and support time sensitive item recommendation . Such scenarios are pervasive in , for example , web applications where the candidate sets of items are usually large , items have short lifetimes and items sharing similar features can have quite different performance . Rapidly learning user item affinities at the per item level is key to success . We have demonstrated that FOBFM provides superior performance over existing methods and explained the reasons behind the strong performance .
One of the extensions to FOBFM is to explore the idea of clustering . One may put users into user clusters and put items into item clusters . Then , for each pair of user item clusters , we learn a different loading matrix B . This leads to a very flexible model , but the estimation also becomes more difficult .
Another direction is to incorporate FOBFM into explore/exploit e t a r e v i t i s o p e u r T
0 . 1
8 . 0
6 . 0
4 . 0
2 . 0
0 . 0
FOBFM RLFM Online−UU Online−PLSI
0.0
0.2
0.4
0.6
0.8
1.0
False positive rate
Figure 5 : ROC curves on the Y!FP dataset schemes . The eventual goal of recommender systems is to display items to users such that we maximize some overall yield ( eg , CTR ) . A good model that quickly learns item affinities helps in achieving this objective . However , learning all user item affinities is not the optimal solution , the key is to allocate items to user visits such that we converge to high yield user item pairs quickly . Other than good models , judicious sampling of items to display helps with this task . Sequential sampling using methods in multi armed bandits ( also known as explore/exploit methods ) is an effective way to achieve this . One popular class of algorithms that are simple and have been shown to work well are upper confidence bound schemes ( UCB)[8 ] . The idea of UCB is to display items that are best not in terms of the estimated CTR but an overestimate that also captures uncertainty in estimates . A function of the form ff
ˆCTR + k
V ar( ˆCTR ) works well in practice , where k is a tuning parameter and ˆCTR is the estimated CTR . A key difficulty that arises is the computation of variance . For item specific regression with correction terms of the form x . itvjt , computing the variance involves inverting a highdimensional matrix ( same as dimension of xit , ie , r ) . Our reduced rank regression makes this computation easier by reducing the dimension from r to k . It will be interesting to study the effectiveness of this approach .
7 . REFERENCES [ 1 ] D . Agarwal and B C Chen . Regression based latent factor models . In Proceedings of the 15th ACM SIGKDD Conference on Knowledge Discovery and Data Mining ( KDD ) , 2009 .
[ 2 ] D . Agarwal , B C Chen , P . Elango , and et al . Online models for content optimization . In Proceedings of the 22nd Annual Conference on Neural Information Processing Systems ( NIPS ) , 2008 .
[ 3 ] J W Ahn , P . Brusilovsky , J . Grady , D . He , and S . Y . Syn .
Open user profiles for adaptive news systems : help or harm ? In Proceedings of the 16th international conference on World Wide Web ( WWW ) , 2007 .
[ 4 ] T . Anderson . Estimating linear restrictions on regression coefficients for multivariate normal distributions . Annals of Mathematical Statsitics , 22:327–351 , 1951 .
[ 5 ] R . Bell , Y . Koren , and C . Volinsky . Modeling relationships at multiple scales to improve accuracy of large recommender systems . In Proceedings of the 13rd ACM SIGKDD Conference on Knowledge Discovery and Data Mining ( KDD ) , 2007 .
711 [ 6 ] D . Billsus and M . Pazanni . Springer , Berlin , 2007 . [ 7 ] J . S . Breese , D . Heckerman , and C . Kadie . Empirical analysis of predictive algorithms for collaborative . In Proceedings of the 4th Conference on Uncertainty in Artificial Intelligence ( UAI ) , 1998 .
[ 8 ] M . Brezzi and T . Lai . Optimal learning and experimentation in bandit problems . journal of economic dynamics and control , 27(1):87–108 , 2001 .
[ 9 ] A . Broder . Computational advertising and recommender systems . In Proceedings of the 2nd ACM International Conference on Recommender Systems ( RecSys ) , 2008 .
[ 10 ] G . Celeux and G . Govaert . A classification em algorithm for clustering and two stochastic versions . Computational Statistics and Data Analysis , 14:315–332 , 1992 .
[ 11 ] D . Chakrabarti , D . Agarwal , and V . Josifovski . Contextual advertising by combining relevance with click feedback . In Proceedings of the 17th international conference on World Wide Web ( WWW ) , 2008 .
[ 12 ] Y . Chen , D . Pavlov , and J . F . Canny . Large scale behavioral targeting . In Proceedings of the 15th ACM SIGKDD Conference on Knowledge Discovery and Data Mining ( KDD ) , 2009 .
[ 13 ] W . Chu and S . T . Park . Personalized recommendation on dynamic content using predictive bilinear models . In Proceedings of the 18th international conference on World Wide Web ( WWW ) , 2009 .
[ 14 ] G . C.Reinsel and R . Velu . Multivariate Reduced Rank
Regression : Theory and Applications . Springer : New York , 1998 .
[ 15 ] A . S . Das , M . Datar , A . Garg , and S . Rajaram . Google news personalization : scalable online collaborative filtering . In Proceedings of the 16th international conference on World Wide Web ( WWW ) , 2007 .
[ 16 ] M . Kendall . A new measure of rank correlation . Biometrika ,
1938 .
[ 17 ] Y . Koren . Collaborative filtering with temporal dynamics . In
Proceedings of the 15th ACM SIGKDD Conference on Knowledge Discovery and Data Mining ( KDD ) , 2009 .
[ 18 ] C J Lin , R . C . Weng , and S . S . Keerthi . Trust region newton methods for large scale logistic regression . In Proceedings of the 24th International Conference on Machine Learning ( ICML ) , 2007 .
[ 19 ] B . Marx . Iteratively reweighted partial least squares estimation for generalized linear regression . Technometrics , 38(4):374–381 , 1996 .
[ 20 ] P . McCullagh and J . A . Nelder . Generalized Linear Models .
Chapman & Hall/CRC , 1989 .
[ 21 ] A . Micarelli , F . Gasparetti , F . Sciarrone , and S . Gauch .
Personalized search on the world wide web . The Adaptive Web , pages 195–230 , 2007 .
[ 22 ] M.West and JHarrison Bayesian Forecasting and Dynamic
Models . 1997 .
[ 23 ] M . Richardson , E . Dominowska , and R . Ragno . Predicting clicks : estimating the click through rate for new ads . In Proceedings of the 16th international conference on World Wide Web ( WWW ) , 2007 .
[ 24 ] R . Salakhutdinov and A . Mnih . Probabilistic matrix factorization . In Proceedings of the 22nd Annual Conference on Neural Information Processing Systems ( NIPS ) , 2008 .
[ 25 ] M . West . Bayesian factor regression models in the "large p , small n" paradigm . Bayesian Statistics , 7:723–732 , 2003 .
[ 26 ] Z.Lu , D.Agarwal , and IDhillon A spatio temporal approach to collaborative filtering . In Proceedings of the 3rd ACM International Conference on Recommender Systems ( RecSys ) , 2009 .
712
