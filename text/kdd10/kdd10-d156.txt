Transfer Metric Learning by Learning Task Relationships
Yu Zhang and Dit Yan Yeung
Department of Computer Science and Engineering Hong Kong University of Science and Technology
Clear Water Bay , Kowloon , Hong Kong {zhangyu , dyyeung}@cseusthk
ABSTRACT Distance metric learning plays a very crucial role in many data mining algorithms because the performance of an algorithm relies heavily on choosing a good metric . However , the labeled data available in many applications is scarce and hence the metrics learned are often unsatisfactory . In this paper , we consider a transfer learning setting in which some related source tasks with labeled data are available to help the learning of the target task . We first propose a convex formulation for multi task metric learning by modeling the task relationships in the form of a task covariance matrix . Then we regard transfer learning as a special case of multitask learning and adapt the formulation of multi task metric learning to the transfer learning setting for our method , called transfer metric learning ( TML ) . In TML , we learn the metric and the task covariances between the source tasks and the target task under a unified convex formulation . To solve the convex optimization problem , we use an alternating method in which each subproblem has an efficient solution . Experimental results on some commonly used transfer learning applications demonstrate the effectiveness of our method .
Categories and Subject Descriptors I26 [ Artificial Intelligence ] : Learning ; H28 [ Database Management ] : Database Applications—Data mining
General Terms Algorithms
Keywords Metric Learning , Transfer Learning , Multi Task Learning
1 .
INTRODUCTION
Many data mining algorithms , eg , means clustering algorithm and nearest neighbor classifier , work by relying on a distance metric . In order to deliver satisfactory results , finding a good distance metric for the problem at hand often plays a very crucial role . As such , metric learning [ 25 ] has received much attention in the research community [ 12 , 25 , 5 , 22 , 8 , 26 , 6 , 7 , 27 , 29 , 13 ] . Many metric learning methods have been proposed . From the perspective of the underlying learning paradigm , these methods can be grouped into three categories , namely , supervised metric learning , unsupervised metric learning , and semi supervised metric learning . Supervised metric learning learns a metric for some supervised learning task , such as classification , so that data points from the same class are kept close while those from different classes are far apart [ 12 , 22 , 8 , 7 , 29 , 13 ] . It has also been used for regression by exploiting the manifold structure contained in the labeled data [ 24 ] . Unsupervised metric learning utilizes some information contained in the data to learn a metric for some unsupervised learning task , such as clustering [ 6 ] . Semi supervised metric learning , which can be viewed as a combination of the supervised and unsupervised paradigms , utilizes both label information from the labeled data and geometric information from the unlabeled data to learn a good metric for classification or clustering . The need for semi supervised metric learning arises from the fact that the labeled data available in a number of real life applications is scarce because labeling data is very laborious and costly . With only limited labeled data , the metrics learned are often unsatisfactory . Semi supervised metric learning tries to exploit additional information from the unlabeled data to alleviate this problem which is known as labeled data deficiency problem here .
The focus of this work is on supervised metric learning for classification applications . However , we consider situations similar to those for semi supervised metric learning in which there is deficiency in labeled data . While the amount of labeled data available in one learning task is limited , it is not uncommon that there exist other related learning tasks with labeled data available . Unlike semi supervised learning which exploits unlabeled data , multi task learning [ 4 , 12 , 20 ] and transfer learning [ 18 ] seek to alleviate the labeled data deficiency problem by utilizing some related learning tasks to help improve the learning performance . In some sense , they mimic human learning activities in that people may learn faster when several related tasks are learned simultaneously , eg , playing different games . In essence , people often apply the knowledge gained from some previous learning tasks to help learn a new task . Even though both multi task learning and transfer learning utilize information from other related learning tasks , there exist some differences between them
1199 in both the problem setting and the objective . In transfer learning , the learning tasks are usually classified into two types : source task and target task . It is assumed that there is enough data in the source tasks but not in the target task . The objective of transfer learning is to utilize the information in the source tasks to help learn the target task with no need for improving the performance of the source tasks . On the other hand , there is no distinction between the tasks in multi task learning and the objective is to improve the performance of all tasks simultaneously .
Even though there exist differences between multi task learning and transfer learning , a central issue common to both is to accurately characterize the relationships between tasks . Given the training data for multiple tasks , there are two important aspects that distinguish between different methods for characterizing the task relationships . The first aspect is on how to obtain the relationships , either from the model assumption or automatically learned from data . Many multi task and transfer learning methods make some prior assumptions . For example , the latent data representation is shared by different tasks [ 4 , 1 ] or the learning models in different tasks have similar model parameters [ 9 , 14 ] . Obviously , learning the task relationships from data automatically is the more favorable option because the model assumption adopted may be incorrect and , worse still , it is not easy to verify the correctness of the assumption from data . The second aspect is on what task relationships can be represented by a method . Generally speaking there are three types of task relationship : positive task correlation , negative task correlation , and task unrelatedness.1 Positive task correlation is a useful task relationship to characterize because similar tasks are likely to have similar model parameters . For negative task correlation , knowing the model parameters of one task will reduce the search space for the model parameters of a negatively correlated task . As for task unrelatedness , identifying outlier tasks can prevent them from impairing the performance of other tasks since outlier tasks are unrelated to other tasks .
In this paper , we study metric learning under the transfer learning setting in which some source tasks are available in addition to the target task . Based on a method called regularized distance metric learning ( RDML ) [ 13 ] , we propose an extension for transfer learning called transfer metric learning ( TML ) . Different from conventional transfer learning methods , we first propose a convex formulation for multitask metric learning by modeling the task relationships in the form of a task covariance matrix which can model positive , negative and zero task correlations . Then we regard transfer learning as a special case of multi task learning in that the source tasks are equally important and independent , and adapt the formulation of multi task metric learning to the transfer learning setting for the formulation of TML . In TML , we learn the metric and the task covariances between the source tasks and the target task under a unified convex formulation . As in multi task metric learning , the task covariance matrix can also model positive , negative and zero task correlations . To solve the convex optimization problem , we use an alternating method in which each subproblem has an efficient solution . Experimental results on some commonly used transfer learning applications demonstrate the effectiveness of our method .
1Task unrelatedness corresponds to zero or close to zero task correlation .
The remainder of this paper is organized as follows . We first briefly introduce some background for metric learning and the related work in Section 2 . We then present our multi task metric learning and TML algorithms in Sections 3 and 4 , respectively . Section 5 reports experimental results on some transfer learning applications . Finally , some concluding remarks are given in the last section .
2 . BACKGROUND AND RELATED WORK Suppose we are given a labeled training set {(x , )} where the th data point x ∈ ℝ and its class label ∈ {1 , . . . , } . In RDML [ 13 ] , the learning problem is formulated as follows :
=1 min
Σ st
2
( − 1 ) ࢣ < Σ ર 0 ,
, 1 − ∥x − x ∥2
Σ +
2 ∥Σ∥2 ( 1 ) where is the regularization parameter which balances the empirical loss and the regularization term , ∥ ⋅ ∥ denotes the Frobenius norm of a matrix , , is equal to 1 when and are identical and −1 otherwise , Σ ર 0 means that Σ is a positive semidefinite ( PSD ) matrix , ∥x − x ∥2 Σ = ( x − x ) Σ(x − x ) , ( ) = max(0 , − ) which is similar to the hinge loss used in the support vector machine ( SVM ) . Here is a constant , satisfying 0 ≤ ≤ 1 , which denotes the classification margin . In [ 13 ] , is set to 0 . In [ 13 ] , an online method is used to learn the optimal Σ and some properties of RDML , such as the generalization error , are studied . Moreover , theoretical analysis shows that RDML is robust against the number of feature dimensions . To the best of our knowledge , [ 28 ] is the only previous work on transfer metric learning . In [ 28 ] , it is assumed that there exist labeled data points for the target task as well as some prior information from the source tasks in the form of a metric matrix learned from each source task . The authors extended information theoretic metric learning ( ITML ) [ 8 ] to transfer metric learning by treating the metric matrices learned from the source tasks as prior information to regularize the learning of the target task . The optimization problem for transfer metric learning in [ 28 ] , which is called L DML , is formulated as follows : min tr(M−1
M ) − log ∣M∣ + tr(SM ) − tr(DM )
M
ࢣ =1 + ∥ ∥2 st M ર 0
2
= 1 , ≥ 0 ,
ࢣ =1
( 2 ) where tr(⋅ ) denotes the trace of a square matrix and ∥ ⋅ ∥2 denotes the 2 norm of a vector . Here S = ࢣ = ( x − ( x −x )(x −x ) , and M ( = x )(x −x ) , D =ࢣ ∕= 1 , . . . , ) is the available metric matrix for the th source task . The first and second terms in the objective function of problem ( 2 ) are derived from the log determinant regularization function as used in [ 8 ] and is the weight that reflects the utility of the metric of the th source task . The third term is to keep the data points in the same class as close as possible and the fourth term is to keep the data points from different classes far apart . The last term is to penal
1200 over , the constraint ࢣ ize the complexity of . Here plays an important role in this formulation since there may exist outlier tasks in real applications and by learning L DML can identity them . However , each element of the vector is non negative and so it cannot model the negative transfer situation [ 19 ] . More=1 = 1 is not very reasonable . Consider a special case in which there is only one source task . Then 1 = 1 even if this source task is an outlier task . When there are multiple source tasks and all of them are outlier tasks , we should set all to zero but then the =1 = 1 cannot be satisfied . Furthermore , problem ( 2 ) is not convex , making it easy to get trapped in ( bad ) local minima during the optimization procedure . constraint ࢣ
There exist some methods for transfer dimensionality reduction [ 21 , 16 , 17 ] , where dimensionality reduction can be viewed as a special case of metric learning in that the metric learned is not of full rank . However , transfer dimensionality reduction is different from transfer metric learning and these methods are not applicable here . For example , [ 21 ] used a transformation matrix for dimensionality reduction in the source tasks for subspace clustering in the target task and so the target task is an unsupervised learning task . Also , [ 16 , 17 ] proposed dimensionality reduction methods for domain adaption in which the target task has no labeled data , and so it is different from the setting here where we utilize the metric matrices learned from the source tasks to help the learning of the target task from labeled data .
3 . MULTI TASK METRIC LEARNING
In this section , we propose a multi task metric learning method which can learn the task relationships between all pairs of tasks .
Suppose we are given learning tasks { }
=1 . For the th task , the training set consists of data points represented in the form of ( x ∈ ℝ and its corresponding class label ∈ {1 , . . . , } . Here the superscript denotes the task index and the subscript denotes the instance index in each task .
) , = 1 , . . . , , with x
,
The optimization problem for multi task metric learning is formulated as follows : straint in ( 3 ) is to restrict the scale of Ω to prevent it from reaching a degenerate solution .
From a probabilistic viewpoint , RDML can be seen as obtaining the maximum a posteriori ( MAP ) solution of a probabilistic model where the likelihood corresponds to the first term in the objective function of problem ( 1 ) and the prior on the metric is Gaussian prior corresponding to the second term . Similar to RDML , our multi task metric learning is also a MAP solution of a probabilistic model where the likelihood is the same as that in RDML for each task and the prior on the metrics of all tasks is matrix variate normal distribution [ 11 ] .
We will prove below that problem ( 3 ) is a convex optimization problem by proving that each term in the objective function is convex and each constraint is also convex .
Theorem 1 . Problem ( 3 ) is convex with respect to W , b and Ω .
Proof It is easy to see that the first two terms in the objective function are convex with respect to ( wrt ) all variables and the constraints in ( 3 ) are also convex . We rewrite the third term as tr(WΩ−1W ) = ࢣ W( , :)Ω−1W( , : ) where W( , : ) is the th row of W . Since W( , :)Ω−1W( , : ) is a matrix fractional function as in Example 3.4 on page 76 of [ 3 ] , it is convex wrt W( , : ) and Ω when Ω is a PSD matrix ( which is satisfied by the first constraint of ( 3) ) . Since W( , : ) is a row of W , W( , :)Ω−1W( , : ) is also convex wrt W and Ω . Because the summation operation can preserve convexity according to the analysis on page 79 of [ 3 ] , tr(WΩ−1W ) = ࢣ W( , :)Ω−1W( , : ) is convex wrt
W , b and Ω . So the objective function and the constraints in problem ( 3 ) are convex wrt all variables and hence problem ( 3 ) is jointly convex . □
Even though problem ( 3 ) is convex with respect to {Σ } and Ω jointly , it is not easy to optimize it with respect to all the variables simultaneously . Here we propose an alternating method to solve the problem more efficiently . Specifically , we first optimize the objective function with respect to Σ def= {Σ1 , . . . , Σ −1 , Σ +1 , . . . , Σ } are when Ω and {Σ}− fixed , and then optimize it with respect to Ω when {Σ } are fixed . This procedure is repeated until convergence . Since the original optimization problem is convex , the solution found by this alternating procedure is guaranteed to be the globally optimal solution [ 2 ] .
Because multi task metric learning is not the focus of this paper , we leave the detailed optimization procedure to Appendix A .
, 1 − ∥x
− x
∥2
Σ tr( ˜ΣΩ−1 ˜Σ
) min
{Σ
},Ω st
2
+
+
1 2
2 2
ࢣ =1
( − 1 ) ࢣ < ࢣ =1 ∥Σ ∥2 Σ ર 0 ∀ ˜Σ = ( vec(Σ1 ) , . . . , vec(Σ ) ) Ω ર 0 tr(Ω ) = 1 ,
( 3 )
4 . TRANSFER METRIC LEARNING
=
, is equal to 1 when where and −1 otherwise , vec(⋅ ) denotes the operator which converts a matrix into a vector in a columnwise manner , and 1 and 2 are the regularization parameters . Ω is a task covariance matrix which describes the relationships between tasks and so it is a PSD matrix . The first term in the objective function of problem ( 3 ) measures the empirical loss for the training sets of the tasks , the second term penalizes the complexity of each Σ , and the last term measures the task relationships between all pairs of tasks based on each Σ . The last con
Based on the multi task metric learning problem formulated in the previous section , we propose a transfer metric learning formulation as a special case which can learn the task relationships between all source tasks and the target task .
Suppose we are given − 1 source tasks { } −1
=1 and one target task , for > 1 . In the target task , the training set contains labeled data points {(x =1 . In transfer learning , it is assumed that each source task has enough labeled data and can learn an accurate model with no need to seek help from the other source tasks . So the source tasks
)}
,
1201 are considered to be independent since each source task does not need help from other source tasks . So , similar to the setting in [ 28 ] , we assume that the metric matrix Σ for the th source task has been learned independently . We hope to use the metric matrices learned to help the learning of the target task because the labeled data there is scarce .
4.1 Optimization Problem
Based on problem ( 3 ) , we formulate the optimization prob lem for TML as follows : tasks . Then we can get tr( ˜ΣΩ−1 ˜Σ
)
˜Σ vec(Σ )
˜Σ
=tr ˜Σ , vec(Σ ) Ω−1 =tr ⎛ ⎝ ⎛ ⎝ vec(Σ ) − ( −1 ) 1− vec(Σ ) − ( −1 ) 1−
˜Σ
˜Σ
˜Σ
⎞ ⎠ ⎞ ⎠
−1
( −1)I
0
1−
−1
0 −1
1
−1 min Σ ,Ω st
, 1 − ∥x
− x
Σ ∥2
2
( − 1 ) ࢣ < 1 2 ∥Σ ∥2
+
2 2
) tr( ˜ΣΩ−1 ˜Σ
+ Σ ર 0 ˜Σ = ( vec(Σ1 ) , . . . , vec(Σ −1 ) , vec(Σ ) ) Ω ર 0 tr(Ω ) = 1 . tr( ˜Σ
− 1 1 − ( 1 − )∥Σ ∥2
=
=
˜Σ ) +
∥vec(Σ ) −
1
( − 1 )
1 −
˜Σ ∥2 2
− 2( − 1)vec(Σ ) ˜Σ + ( − 1 ) tr( ˜Σ
˜Σ )
.
( 1 − ) − ( − 1 )
Moreover , according to the Schur complement [ 3 ] , we have
( 5 )
Ω ર 0 ⇐⇒ ≥ which is equivalent to
− 1 1 − and
( − 1)I −1
1 −
ર 0 ,
( 4 )
Since we assume that the source tasks are independent and each source is of equal importance , we can express Ω as
Ω ર 0 ⇐⇒ ( 1 − ) ≥ ( − 1 )
.
Then problem ( 4 ) can be simplified to
Ω = I −1
, min
Σ , , ,Ω st where I denotes the × identity matrix , denotes the task covariances between the target task and the source tasks , and denotes the variance of the target task . According to the last constraint in problem ( 4 ) , we can get
=
1 − − 1
.
From Theorem 1 , it is easy to show that problem ( 4 ) is also jointly convex with respect to all variables . Moreover , from the block matrix inversion formula , we can get
Ω−1
−1 I −1
= 1− = I −1 a
−1 1 ( −1)I
1− 0
0
−1
−1
−1
0 −1
I −1 0 −1
1 , a
1 where 0 denotes the × 1 zero vector , a = − ( −1 ) = − ( −1 ) Let ˜Σ = ( vec(Σ1 ) , . . . , vec(Σ −1) ) , which is a constant matrix here , denote the parameter matrix of the source and
1−
1−
.
, 1 − ∥x
Σ ∥2 − x tr( ˜ΣΩ−1 ˜Σ
)
2
+
( − 1 ) ࢣ < 1 2 ∥Σ ∥2 + Σ ર 0 Ω = 1−
2 2
−1 I −1
˜Σ = ( ˜Σ , vec(Σ ) ) ( 1 − ) ≥ ( − 1 )
,
( 6 ) where the last term in the objective function can be simplified as in Eq ( 5 ) .
Compared with the L DML method in [ 28 ] , our method has some advantages . First , the formulation of TML is convex and so there is guarantee to find the globally optimal solution . Second , similar to multi task metric learning proposed in the previous section , TML can model positive , negative and zero task correlations in a unified formulation but L DML cannot model negative task correlation . As an extreme case , we can deal with the situation in which all source tasks are outlier tasks , but L DML cannot handle it due to
=1 = 1 in problem ( 2 ) . the constraint ࢣ
Moreover , compared with problem ( 4 ) , there is no PSD constraint on Ω in problem ( 6 ) making it simpler than problem ( 4 ) . In the next section , we will discuss how to solve problem ( 6 ) .
4.2 Optimization Procedure
As in multi task metric learning , problem ( 6 ) is a convex problem and we still use an alternating method to solve it . Specifically , we first optimize the objective function with respect to Σ when and are fixed , and then optimize it with respect to and when Σ is fixed . This procedure is repeated until convergence . As before , the solution found
1202 Table 1 : Online Learning Algorithm for Problem ( 7 )
Input : labeled data ( x Initialize Σ(0 ) M ; for = 1 , . . . , do
= ′
2 ′ 1
,
) ( = 1 , . . . , ) , matrix M , ′
1 , ′
2 and predefined learning rate
Receive a pair of training data points {(x Compute : = 1 if if the training pair ( x
) , ( x , and = −1 otherwise ;
= , x
,
,
)} ;
) , is classified correctly , ie , ( 1 − ∥x
− x
∥2
Σ( −1 )
) > 0 then
− x
) where + ( A ) projects matrix A into the positive
Σ( )
= Σ( −1 ) ; else if == −1 = Σ( −1 ) else
Σ( )
+ ( x
)(x
) ;
− x − ( x
− x
− x )(x
Σ( ) semidefinite cone ;
= + Σ( −1 ) end if end for Output : metric Σ( ) by this alternating procedure is globally optimal [ 2 ] . In what follows , we will present the two subproblems separately .
Optimizing wrt Σ when and are fixed
Utilizing Eq ( 5 ) , the optimization problem with respect to Σ is formulated as min Σ
2
( − 1 ) ࢣ < ′ − ′ 1 2 ∥Σ ∥2
+
, 1 − ∥x
Σ ∥2 − x
2tr(Σ
M ) st
Σ ર 0 , where
′
1 = 1 +
2(1 − )
,
( 1 − ) − ( − 1 ) ,
2( − 1 )
( 1 − ) − ( − 1 )
′
2 =
In [ 13 ] , the initial value for Σ(0 )
=1 Σ where is the th element of .
M is a matrix such that vec(M ) = ˜Σ . It is easy to show that M is a combination of Σ ( = 1 , . . . , − 1 ) as M =ࢣ −1 Similar to [ 13 ] , we can use an online learning method to solve problem ( 7 ) and the algorithm is depicted in Table 1 . This algorithm is similar to that in [ 13 ] except the initial step for Σ(0 ) is a zero . matrix but here it is ′ M . Note that M is a combination of the metrics learned from the source tasks where each combination weight is the task covariance between a source task and the target task . This agrees with our intuition that a positively correlated source task will have a large weight on the initial value for Σ , an outlier task has negligle contribution and a negatively correlated task even has opposite effect .
2 ′ 1
Optimizing wrt and when Σ is fixed
Utilizing Eq ( 5 ) , the optimization problem with respect to and is formulated as min
, ,Ω st tr( ˜ΣΩ−1 ˜Σ
)
−1 I −1
Ω = 1− ( 1 − ) ≥ ( − 1 ) ⪯ 1
.
We impose a constraint as ˜ΣΩ−1 ˜Σ tive function becomes min 1 we can get
I 2 and the objec . Using the Schur complement ,
( 8 )
( 7 )
˜ΣΩ−1 ˜Σ
1
⪯
I 2 ⇐⇒ Ω ˜Σ
˜Σ 1
I 2 ર 0 .
By using the Schur complement again , we get
I 2 ર 0 ⇐⇒ Ω − ˜Σ
˜Σ 1
Ω ˜Σ ˜Σ = Ψ11 Ψ12
We write ˜Σ Ψ12 ∈ ℝ( −1)×1 and Ψ22 ∈ ℝ . Then Ω − ˜Σ equivalent to
12 Ψ22 where Ψ11 ∈ ℝ( −1)×( −1 ) , ˜Σ ર 0 is
Ψ
˜Σ ર 0 .
I −1 − Ψ11 ર 0
1 − − 1 − Ψ22 ≥ ( − Ψ12 ) 1 − − 1
( − Ψ12 ) .
I −1 − Ψ11 −1
Let U and 1 , . . . , −1 denote the eigenvector matrix and eigenvalues of Ψ11 with 1 ≥ . . . ≥ −1 ≥ 0 . Then 1 − − 1 ≥ 1
I −1 − Ψ11 ર 0 ⇐⇒
1 − − 1 and
1 − − 1 = U diag(
I −1 − Ψ11 −1 1 − − 1 − 1 , . . . ,
1 − − 1 − −1 ) U .
1203 Combining the above results , problem ( 8 ) is formulated as min
, ,f , st
− 1 − − 1 ≥ 1 f = U ( − Ψ12 ) ࢣ =1 ( 1 − ) ≥ ( − 1 )
2
−1
1−
−1 − ≤ − Ψ22
,
( 9 ) where is the th element of f . By introducing new variables ℎ and ( = 1 , . . . , − 1 ) , ( 9 ) is reformulated as min
, ,f , ,{ℎ },{ } st
− 1 − − 1 ≥ 1 f = U ( − Ψ12 ) ࢣ =1 ℎ ≤ − Ψ22 1 − − 1 − ∀
=
−1
2
≤ ℎ ∀ ( 1 − ) ≥ ( − 1 )
.
( 10 )
Since and
( 1− ) ≥ ( −1 )
+ ℎ
2
≤
2
−ℎ
≤ ℎ ⇐⇒ flflflflfl 2 flflflflfl2
⇐⇒ flflflflflfl ⎛ ⎝
√ − 1
−1
2
+ 1
2
,
≤ flflflflflfl2 ⎞ ⎠ problem ( 10 ) is a second order cone programming ( SOCP ) problem [ 15 ] with ( ) variables and ( ) constraints . In many applications , is very small and we can use a standard solver to solve problem ( 10 ) very efficiently .
We set the initial value of to 1 and that of to a zero vector which corresponds to the assumption that the target task is unrelated to the source tasks .
After learning the optimal values of Σ , we can make prediction for a new data point . Given a test data point x ★ for the target task , we first calculate the distances between x ★ and all training data points in based on the learned metric Σ and then use the nearest neighbor classifier to classify x ★ , where we choose = 1 for simplicity in our experiments .
5 . EXPERIMENTS
We study TML empirically in this section by comparing it with two metric learning methods , ITML2 [ 8 ] and RDML [ 13 ] , and another metric learning method for transfer learning , L DML [ 28 ] . We use the CVX solver [ 10]3 to
2The implementation of
ITML can be found in http://wwwcsutexasedu/users/pjain/itml/
3http://stanford.edu/∼boyd/cvx solve problem ( 10 ) . We set the learning rate in Table 1 to 001 For ITML , RDML and L DML , the best parameters reported in [ 8 , 13 , 28 ] are used .
5.1 Wine Quality Classification
The wine dataset4 is about wine quality including red and white wine samples . The features include objective tests ( eg , PH values ) and the output is based on sensory data . The labels are given by experts with grades between 0 ( very bad ) and 10 ( very excellent ) . There are 1599 records for the red wine and 4898 for the white wine and so there are two tasks , one for red wine classification and the other for white wine classification . Each task is treated as the target task and the other task as the source task . To see the effect of varying the size of the training set , we vary the percentage of the training data used from 5 % to 20 % . Each configuration is repeated 10 times . The mean and standard deviation of the classification accuracy are reported in Fig 1(a ) and 1(b ) . From the results , we can see that the performance of L DML is comparable with that of ITML and RDML and TML is always the best one for both tasks .
5.2 Handwritten Letter Classification
The handwritten letter classification applicaton5 consists of seven tasks where each task is a binary classification problem . The corresponding letters for each task are : c/e , g/y , m/n , a/g , a/o , f/t and h/n . Each data point has 128 features corresponding to the pixel values of the handwritten letter images . For each task , there are about 1000 positive and 1000 negative data points . The experimental settings are the same as those for wine quality classification above . The results are plotted in Fig 2(a ) to 2(g ) . From the results , we find that the performance of L MDL is worse than that of ITML and RDML on some tasks ( 4th , 6th and 7th tasks ) . This may be due to the fact that the objective function of L MDL is non convex and hence it is easy to get trapped in bad local minima . TML shows the best performance on almost every task .
5.3 USPS Digit Classification
The USPS digit dataset5 contains 7291 examples each of 255 features . There are nine classification tasks , each corresponding to the classification of two digits . The experimental settings are the same as those for handwritten letter classification . The results are reported in Fig 3(a ) to 3(i ) . Similar to handwritten digit classification , L MDL is worse than ITML and RDML on some tasks and TML is better than other methods on almost all tasks .
6 . CONCLUSION
In this paper , we have proposed a transfer metric learning method to alleviate the labeled data deficiency problem in the target learning task by exploiting useful information from some source tasks . The learning of the distance metrics from the source tasks and the relationships between the source tasks and the target task is formulated as a convex optimization problem which can be solved efficiently . In our future research , we will extend TML to the semi supervised setting by exploiting useful information contained in the unlabeled data as well .
4http://archiveicsuciedu/ml/datasets/Wine+Quality 5http://multitaskcsberkeleyedu/
1204 ( a ) 1st task
( b ) 2nd task
Figure 1 : Overall performance on wine quality classification application .
( a ) 1st task
( b ) 2nd task
( c ) 3rd task
( d ) 4th task
( e ) 5th task
( f ) 6th task
( g ) 7th task
Figure 2 : Overall performance on handwritten letter classification application when one task is the target and the others are source tasks .
Acknowledgments This research has been supported by General Research Fund 622209 from the Research Grants Council of Hong Kong .
7 . REFERENCES
[ 1 ] A . Argyriou , T . Evgeniou , and M . Pontil . Convex multi task feature learning . Machine Learning , 73(3):243–272 , 2008 .
[ 2 ] D . P . Bertsekas . Nonlinear Programming . Athena
Scientific , 1999 .
[ 3 ] S . Boyd and L . Vandenberghe . Convex Optimization .
Cambridge University Press , New York , NY , 2004 . [ 4 ] R . Caruana . Multitask learning . Machine Learning ,
28(1):41–75 , 1997 .
[ 5 ] H . Chang and D Y Yeung . Locally linear metric adaptation for semi supervised clustering . In Proceedings of the Twenty first International Conference on Machine Learning , Banff , Alberta , Canada , 2004 .
[ 6 ] J . Chen , Z . Zhao , J . Ye , and H . Liu . Nonlinear adaptive distance metric learning for clustering . In
Proceedings of the 13th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 123–132 , San Jose , California , USA , 2007 . [ 7 ] J . V . Davis and I . S . Dhillon . Structured metric learning for high dimensional problems . In Proceedings of the 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 195–203 , Las Vegas , Nevada , USA , 2008 .
[ 8 ] J . V . Davis , B . Kulis , P . Jain , S . Sra , and I . S .
Dhillon . Information theoretic metric learning . In Proceedings of the Twenty Fourth International Conference on Machine Learning , pages 209–216 , Corvalis , Oregon , USA , 2007 .
[ 9 ] T . Evgeniou and M . Pontil . Regularized multi task learning . In Proceedings of the Tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 109–117 , Seattle , Washington , USA , 2004 .
[ 10 ] M . Grant and S . Boyd . CVX : Matlab software for disciplined convex programming ( web page and software ) , June 2009 .
1205 ( a ) 1st task
( b ) 2nd task
( c ) 3rd task
( d ) 4th task
( e ) 5th task
( f ) 6th task
( g ) 7th task
( h ) 8th task
( i ) 9th task
Figure 3 : Overall performance on USPS digit classification application .
[ 11 ] A . K . Gupta and D . K . Nagar . Matrix Variate
Distributions . Chapman & Hall , 2000 .
[ 12 ] T . Hastie and R . Tibshirani . Discriminant adaptive nearest neighbor classification . IEEE Transactions on Pattern Analysis and Machine Intelligence , 18(6):607–616 , 1996 .
[ 13 ] R . Jin , S . Wang , and Y . Zhou . Regularized distance metric learning : Theory and algorithm . In Y . Bengio , D . Schuurmans , J . Lafferty , C . K . I . Williams , and A . Culotta , editors , Advances in Neural Information Processing Systems 22 , pages 862–870 , Vancouver , British Columbia , Canada , 2009 .
[ 14 ] W . Kienzle and K . Chellapilla . Personalized handwriting recognition via biased regularization . In Proceedings of the Twenty Third International Conference on Machine Learning , pages 457–464 , 2006 .
[ 15 ] M . S . Lobo , L . Vandenberghe , S . Boyd , and H . Lebret .
Applications of second order cone programming . Linear Algebra and its Applications , 284:193–228 , 1998 . via dimensionality reduction . In Proceedings of the Twenty Third AAAI Conference on Artificial Intelligence , pages 677–682 , Chicago , Illinois , USA , 2008 .
[ 17 ] S . J . Pan , I . W . Tsang , J . T . Kwok , and Q . Yang .
Domain adaptation via transfer component analysis . In Proceedings of the 21st International Joint Conference on Artificial Intelligence , pages 1187–1192 , Pasadena , California , USA , 2009 .
[ 18 ] S . J . Pan and Q . Yang . A survey on transfer learning .
IEEE Transactions on Knowledge and Data Engineering , 2009 .
[ 19 ] M . T . Rosenstein , Z . Marx , and L . P . Kaelbling . To transfer or not to transfer . In NIPS 05 Workshop on Inductive Transfer : 10 Years Later , 2005 .
[ 20 ] S . Thrun . Is learning the th thing any easier than learning the first ? In D . S . Touretzky , M . Mozer , and M . E . Hasselmo , editors , Advances in Neural Information Processing Systems 8 , pages 640–646 , Denver , CO , 1996 .
[ 21 ] Z . Wang , Y . Song , and C . Zhang . Transferred
[ 16 ] S . J . Pan , J . T . Kwok , and Q . Yang . Transfer learning dimensionality reduction . In Proceedings of European
1206 Conference on Machine Learning and Knowledge Discovery in Databases , pages 550–565 , Antwerp , Belgium , 2008 .
[ 22 ] K . Q . Weinberger , J . Blitzer , and L . K . Saul . Distance metric learning for large margin nearest neighbor classification . In Y . Weiss , B . Sch¨olkopf , and J . Platt , editors , Advances in Neural Information Processing Systems 18 , pages 1473–1480 , Vancouver , British Columbia , Canada , 2005 .
[ 23 ] K . Q . Weinberger and L . K . Saul . Fast solvers and efficient implementations for distance metric learning . In Proceedings of the Twenty Fifth International Conference on Machine Learning , pages 1160–1167 , Helsinki , Finland , 2008 .
[ 24 ] B . Xiao , X . Yang , Y . Xu , and H . Zha . Learning distance metric for regression by semidefinite programming with application to human age estimation . In Proceedings of the 17th ACM International Conference on Multimedia , pages 451–460 , 2009 .
[ 25 ] E . P . Xing , A . Y . Ng , M . I . Jordan , and S . J . Russell . Distance metric learning with application to clustering with side information . In S . Becker , S . Thrun , and K . Obermayer , editors , Advances in Neural Information Processing Systems 15 , pages 505–512 , Vancouver , British Columbia , Canada , 2002 .
[ 26 ] D Y Yeung and H . Chang . A kernel approach for semisupervised metric learning . IEEE Transactions on Neural Networks , 18(1):141–149 , 2007 .
[ 27 ] D Y Yeung , H . Chang , and G . Dai . A scalable kernel based semi supervised metric learning algorithm with out of sample generalization ability . Neural Computation , 20(11):2839–2861 , 2008 .
[ 28 ] Z J Zha , T . Mei , M . Wang , Z . Wang , and X S Hua .
Robust distance metric learning with auxiliary knowledge . In Proceedings of the 21st International Joint Conference on Artificial Intelligence , pages 1327–1332 , Pasadena , California , USA , 2009 . can be rewritten as tr( ˜ΣΩ−1 ˜Σ
)
2 2
=
=
=
2
2
˜Σ
˜Σ
2 2
2 + 2
−
− vec(Σ ) + tr( ˜Σ− Γ− ˜Σ
Γ− vec(Σ ) tr ( vec(Σ ) , ˜Σ− ) 2 ∥vec(Σ )∥2 2 ∥Σ ∥2 where ∥⋅∥2 denotes the 2 norm of a vector and M is a matrix such that vec(M ) = ˜Σ− . Note that the third term in the last equation above is independent of Σ . It is easy to show that M is a symmetric matrix . The optimization problem with respect to Σ becomes
+ 2tr(MΣ ) + tr( ˜Σ− Γ− ˜Σ
− ) ,
− ) min
Σ st
2
( − 1 ) ࢣ <
1 + 2
∥Σ ∥2
+
2 Σ ર 0 .
, 1 − ∥x
− x
∥2
Σ
+ 2tr(MΣ )
( 11 )
It is easy to see that this problem is a convex semidefinite programming ( SDP ) problem since the objective function is convex with respect to Σ and the constraint is a PSD constraint on Σ . Even though solving an SDP problem is computationally demanding with poor scalability , we can adopt the technique in [ 23 ] and use gradient projection to solve it . Optimizing wrt Ω when {Σ } are fixed
When {Σ } are fixed , the optimization problem for finding
Ω becomes min
Ω st tr(Ω−1 ˜Σ
˜Σ )
Ω ર 0 tr(Ω ) = 1 .
( 12 )
[ 29 ] D C Zhan , M . Li , Y F Li , and Z H Zhou . Learning
Then we have instance specific distances using metric propagation . In Proceedings of the 26th International Conference on Machine Learning , pages 1225–1232 , Montreal , Quebec , Canada , 2009 .
APPENDIX
A . OPTIMIZATION PROCEDURE FOR
PROBLEM ( 3 )
We present here the optimization procedure for solving problem ( 3 ) . We use an alternating method with two subproblems to be presented separately below . Optimizing wrt Σ when Ω and {Σ}− are fixed
We first define ˜Σ and Ω−1 as
˜Σ = vec(Σ ) , ˜Σ− Γ− . Ω−1 =
Then the third term in the objective function of problem ( 3 ) tr(Ω−1A ) = tr(Ω−1A)tr(Ω )
1
1
1 2 )
2 A
2 A
2 Ω− 1
2 )(A 1 1 2 Ω
2 ))tr(Ω 1
= tr((Ω− 1 ≥ ( tr(Ω− 1 ˜Σ . The first equality holds because of the where A = ˜Σ last constraint in problem ( 12 ) and the last inequality holds because of the Cauchy Schwarz inequality for the Frobenius norm . Moreover , tr(Ω−1A ) attains its minimum value ( tr(A
2 ))2 if and only if
1 2 Ω 2 ))2 ,
2 ))2 = ( tr(A
1
Ω− 1
2 A
1 2 = Ω
1 2 for some constant and tr(Ω ) = 1 . So we can get the following analytical solution :
Ω =
1 2
˜Σ ˜Σ tr ˜Σ ˜Σ
.
1
2
1207
