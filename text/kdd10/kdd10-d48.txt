Discovering frequent patterns in sensitive data
Raghav Bhaskar
Microsoft Research India
Srivatsan Laxman Microsoft Research India
Adam Smith
Pennsylvania State University
Abhradeep Thakurta
Pennsylvania State University
ABSTRACT Discovering frequent patterns from data is a popular exploratory technique in data mining . However , if the data are sensitive ( eg patient health records , user behavior records ) releasing information about significant patterns or trends carries significant risk to privacy . This paper shows how one can accurately discover and release the most significant patterns along with their frequencies in a data set containing sensitive information , while providing rigorous guarantees of privacy for the individuals whose information is stored there .
We present two efficient algorithms for discovering the K most frequent patterns in a data set of sensitive records . Our algorithms satisfy differential privacy , a recently introduced definition that provides meaningful privacy guarantees in the presence of arbitrary external information . Differentially private algorithms require a degree of uncertainty in their output to preserve privacy . Our algorithms handle this by returning ‘noisy’ lists of patterns that are close to the actual list of K most frequent patterns in the data . We define a new notion of utility that quantifies the output accuracy of private top K pattern mining algorithms . In typical data sets , our utility criterion implies low false positive and false negative rates in the reported lists . We prove that our methods meet the new utility criterion ; we also demonstrate the performance of our algorithms through extensive experiments on the transaction data sets from the FIMI repository . While the paper focuses on frequent pattern mining , the techniques developed here are relevant whenever the data mining output is a list of elements ordered according to an appropriately ‘robust’ measure of interest .
1 .
INTRODUCTION
Frequent Itemsets Mining ( FIM ) is a fundamental problem in data mining [ 2 , 16 , 15 ] . In this problem , there is a universe M of items ( or symbols ) and each data record , called a transaction , is an unordered collection of items from M . For example , a transaction could represent the items purchased by a customer in one visit to a grocery store . An itemset1 is a ( typically small ) subset of items
1We use the terms pattern and itemset interchangeably . out of M . A transaction supports a pattern if it contains the pattern . The frequency of a pattern is the proportion of transactions in the data that support it . The goal in FIM is to discover and report the patterns that occur most frequently in the data . There are typically two ways to control the size of output : ( i ) user specifies an explicit frequency threshold and the algorithm outputs all patterns whose frequencies in data exceed that threshold , or ( ii ) user specifies a positive number K and the algorithm outputs the K most frequent ( top K ) patterns . The Apriori algorithm [ 2 , 15 ] for FIM is regarded as one of the most successful of techniques in data mining [ 25 ] . It forms the basis of several data mining tasks such as mining association rules [ 2 ] , detecting correlations , discovering emerging patterns [ 7 ] , etc . Beginning with [ 2 ] , there is an extensive body of work ( eg see [ 16 , 13 , 26 , 23 ] ) that deals with FIM and its variants in transactional data sets . In this paper we are concerned with mining top K itemsets from transaction data .
Many compelling applications of frequent pattern mining deal with sensitive data . For example , discovering strong correlations , trends and rules from electronic medical records of hospital patients can be a valuable source of information for society [ 12 , 17 ] ; understanding common user behavior can provide useful information for pricing advertising . However , releasing information about sensitive data carries serious risks to privacy . Simply removing obvious identifiers , such as names and exact addresses , does not protect privacy since the remaining information may identify a person uniquely [ 24 , 4 ] . Even relatively sophisticated anonymization techniques ( eg , those based on k anonymity [ 24 ] ) can fail to hide the exact values of sensitive attributes when combined with background knowledge [ 19 ] or easily available external information [ 11 ] . Recent theoretical and experimental results demonstrate that reasoning about the privacy of high dimensional data is particularly difficult . For example , Dinur and Nissim [ 6 ] showed that even highly noisy answers to a large number of counting queries ( “ how many records in the database satisfy the following predicate ? ” ) allow an adversary to reconstruct large parts of a data set exactly . External information is difficult to reason about in highdimensional settings . For example , Narayanan and Shmatikov [ 21 ] showed how even a few pieces of a long record are enough to link it to outside sources ; Ganta et al . [ 11 ] show that independently anonymized releases of large data sets could be combined to reveal sensitive information . There is a basic tension , then , between utility and privacy . The fundamental problem is to understand where exactly the trade off lies between these two . 1.1 Contributions
We present two efficient algorithms for discovering frequent itemsets in sensitive data sets . Our algorithms satisfy differential privacy [ 9 , 8 ] , a recently introduced definition which provides meaningful privacy guarantees in the presence of arbitrary external in formation . Differential privacy imposes a condition on the algorithm that releases some statistics about a data set x . Roughly , it states that small changes to x should not be noticeable to the users ( or adversaries ) who view the released statistics . This implies that no matter what the adversary knows ahead of time , he learns the same thing about Alice whether or not her data is actually included in the data set x [ 8 , 11 ] . Our algorithms thus provide a picture of a data set ’s most significant structures while preserving privacy under the sole assumption that the internal random coins of the algorithm are secret .
We quantify the notion of utility ( accuracy ) needed for the algorithms’ analysis and give rigorous accuracy bounds . Our experiments show that the algorithms perform well on a standard suite of data sets . Our algorithms are based on different techniques , but have similar performance guarantees . Nevertheless , they are incomparable : one is more accurate , the other simpler . Quantifying “ Utility ” for FPM . Because differentially private algorithms must treat nearby inputs indistinguishably , they can at best return approximate answers . Thus , our algorithms produce a noisy list of itemsets which is “ close ” to the list of the top K itemsets with high probability . ( Our algorithms also release the approximate frequency of each of the itemsets in the output . )
To quantify the algorithms’ utility , we introduce a natural notion of approximation for frequent itemset mining . Roughly , we require that the itemsets in the output have frequencies within a small additive error of those of the K most frequent itemsets . Specifically , let fK be the frequency of the K th most frequent itemset in the input . Given an accuracy parameter γ ∈ [ 0 , 1 ] , we require that with high probability ( a ) every itemset with frequency greater than fK + γ is output and ( b ) no itemset with frequency below fK − γ is output . Equivalently , the algorithm must output the top K itemsets of an input in which all frequencies have been changed by up to γ .
In typical data sets , there is little concentration of patterns at any particular frequency . In such cases , our utility guarantee implies low false positive and false negative rates . For example , if there at most 0.02· K itemsets with frequencies in the range [ fK , fK + γ ] , then with high probability the FNR is at most 2 % . Evaluating Utility . We present a rigorous analysis of the privacy and accuracy of both algorithms . For a given level of differential privacy , quantified by the parameter , we prove high probability bounds on how far the reported itemsets can be from the true top K itemsets . The error parameter γ of both algorithms is O(K log(U )/n ) , where K is the number of itemsets reported , n is the total number of records in the transaction data set and U is the total number of itemsets under consideration ( eg , for sets of items among m pos
and log(U ) is O( log m) ) . sibilities , U is,m
We also provide a extensive experimental evaluation of both algorithms on all the data sets from the FIMI repository [ 1 ] . First , we calculate the concrete bounds implied by our utility theorems , and find that the bounds correspond to meaningful error rates on the FIMI data sets . The empirical error we observe in experiments is even lower than the theoretical bounds . Our results indicate that for all but one FIMI data set , we can release over 100 frequent itemsets while keeping the false negative rate below 20 % . We present the results in detail in Section 4 . Evaluating Efficiency . In both our algorithms , there is a preprocessing phase which extracts the top K > K itemsets using an existing non private algorithm ( Apriori , [ 2 , 15] ) . The preprocessing phase takes time roughly proportional to Kn , where n is the number of records in the database . Here K is the number of itemsets with frequency greater than fK − γ , where γ is the utility parameter . After preprocessing , both of our algorithms require time only
O(K + K log K + nK ) to produce the final output . Since K and K are typically much smaller than n , the non private itemset mining is the efficiency bottleneck . This observation was borne out by our experiments . Techniques . The main difference between our two algorithms is technique . Our first algorithm is based on the exponential mechanism of McSherry and Talwar [ 20 ] . Our main contribution is to give an efficient algorithm for this case of the exponential mechanism ( a priori , the mechanism requires exponential time ) . The second algorithm is based on a new analysis for the established technique of adding Laplace noise to released functions [ 9 , 18 , 14 ] ; we show that in some settings one can add much less noise than was possible with previous analyses . A more detailed discussion of our techniques relative to previous work can be found in Sections 5 and 6 .
The paper is organized as follows . In Sec 2 we review the definition of Differential Privacy . Our new privacy preserving frequent itemset mining algorithms are presented in Sec 3 . The experimental evaluation of these methods is presented in Sec 4 . We extend our ideas to a more general problem called private ranking in Sec 5 . We review related work in Sec 6 and conclude in Sec 7 .
2 . DIFFERENTIAL PRIVACY
Our algorithms satisfy differential privacy [ 9 ] , which bounds the effect that any single record has on the distribution of the released information . Let Dn be the space of transaction data sets containing n transactions . DEFINITION 1
( DIFFERENTIAL PRIVACY [ 9] ) . A randomized algorithm A is differentially private if for all transaction data sets T , T ∈ Dn differing in at most one transaction and all events O ⊆ Range(A ) :
Pr[A(T ) ∈ O ] ≤ e Pr[A(T
) ∈ O ] .
Both algorithms presented in this paper satisfy differential priIn Sec 6 we also discuss some algorithms that satisfy a vacy . weaker notion called ( , δ) differential privacy [ 22 ] .
DEFINITION 2
( ( , δ) DIFFERENTIAL PRIVACY [ 22] ) . A randomized algorithm A is ( , δ) differentially private if for all transaction data sets T , T ∈ Dn differing in at most one transaction and all events O ⊆ Range(A ) :
Pr[A(T ) ∈ O ] ≤ e Pr[A(T
) ∈ O ] + δ .
Both these definitions capture the notion that the probability of seeing a particular output does not depend too much on any particular transaction . However , definition 2 additionally allows a small additive error factor of δ . Example : Laplace noise . Differentially private algorithms must be randomized , since they must blur the distinction between two neighboring inputs T , T even when T and T are known to the adversary . A common technique to introduce randomness is the addition of Laplace noise to outputs . Suppose that we would like to release ( an approximation to ) a vector of real valued statistics . That is , for some function f : Dn → Rd , we would like to release an approximation to close to f ( T ) . Dwork et al . [ 9 ] showed that it suffices to add noise proportional to the sensitivity of the function f . Sensitivity measures the maximum possible change in the value of f when transaction from the data set is changed .
DEFINITION 3
( SENSITIVITY [ 9] ) . The sensitivity of a function f : Dn → Rd is the smallest number ∆f such that for all inputs T , T ∈ Dn which differ in a single entry ( transaction ) , ||f ( T ) − f ( T )||1 ≤ ∆f .
Consider the randomized algorithm Af that computes f ( T ) and releases ˜f ( T ) = f ( T ) + Lap , ∆f
d , where Lap(λ)d denotes a
λ exp(−|y|/λ ) . Dwork et al . [ 9 ] showed that Af is differentially vector of d iid samples from the Laplace distribution Lap(λ ) . Recall that Lap(λ ) is the distribution on R with density at y given by 1 private . The standard deviation of Lap(λ ) is λ rithm adds noise proportional to ∆f / .
√ 2 , so this algo
Noise addition is not directly relevant to FIM because the output cannot be described by a single low sensitivity real valued function . However , we will use this technique for reporting the frequencies of the itemsets we output .
Recently McSherry et al . [ 20 ] proposed a technique , the exponential mechanism , for designing differentially private algorithms for non real valued outputs . In the next section we discuss this mechanism in detail ; we adapt their technique to FIM in our first algorithm ( Section 31 )
We provide two differentially private algorithms for top K FIM with provable privacy and utility guarantees . Since the algorithms are randomized in nature , we cannot provide the exact solution to the FIM problem . Hence , with high probability , we want to output a list of itemsets that is close to the list of K most frequent itemsets in the transaction data set . “ Close ” here means roughly that the itemsets in the output have frequencies within a small additive error of those of the K most frequent itemsets . We formalize this notion in the following section .
3 . PRIVATE FIM ALGORITHMS
The output of frequent itemset mining algorithms is typically a list of itemsets together with their supports or frequencies . Modifying such an algorithm to satisfy differential privacy requires introducing uncertainty into the output . There are two natural approaches to doing this : we can first construct a noisy list of itemsets ( ie by including some ‘infrequent’ sets in the list , while leaving out some ‘frequent’ ones ) and then perturb the frequencies of those itemsets , or we can first add noise to the frequencies of all itemsets and then select the itemsets with the highest noisy frequencies . In this paper , we present algorithms which illustrate each of these approaches . Our first algorithm is based on the exponential mechanism of [ 20 ] ; the second , on the Laplace noise model of [ 9 ] .
To quantify our algorithms’ utility , we introduce a natural notion of approximation for frequent itemset mining . Given an input data set T , the true frequency of an itemset refers to the proportion of records in T in which the itemset actually occurs ; in contrast , the reported , or noisy , frequency refers to the estimate reported by the algorithm .
DEFINITION 4
( APPROXIMATE TOP K FIM ) . Let T be a set of n transactions over an alphabet M of m items . Let K denote the number of frequent itemsets to be reported in the output and let denote the size of itemsets under consideration . Let fK denote the frequency of the K th most frequent itemset of size . For positive real parameters ρ , γ , η , we say an algorithm is ( ρ , γ , eta) useful if , with probability at least ( 1 − ρ ) , the output is a list of K itemsets of size along with estimated frequencies and satisfies :
1 . ( Soundness ) No itemset in the output has true frequency less than ( fK − γ ) .
2 . ( Completeness ) Every itemset with true frequency greater than ( fK + γ ) is in the output .
3 . ( Accuracy ) For every pattern in the output list , the noisy frequency reported differs by no more than η from the corresponding true frequency .
3.1 Exponential Mechanism based Algorithm In this section we describe the exponential mechanism due to McSherry et al . [ 20 ] and show how it can be adapted , with some work , to FIM . The exponential mechanism is in fact a family of algorithms , parametrized by a finite set R of possible outputs ( called the range ) and a real valued function q : Dn × R × R that assigns each possible output r a score q(T , r ) based on the input T . Given R , q , T and , the goal is to produce an output with as high a score as possible , while satisfying differential privacy . To this end , the algorithm draws a single sample from the distribution on R which assigns each element r ∈ R mass proportional to exp( q(T , r)/2∆q ) . Here ∆q is the maximum of the sensitivities ( Def . 3 ) of the functions q(· , r ) . That is , ∆q is the maximum over r and neighboring data sets T , T of |q(r , T )− q(r , T )| . Intuitively , the mechanism is useful since high mass to elements r with high scores . McSherry and Talwar showed that this algorithm is differentially private .
At a high level , our first algorithm consists of K applications of the exponential mechanism . In each round , we sample from the set of itemsets of size . Given a dataset T , the score of an itemset is a truncated version of its frequency , denoted ˆf . The analysis of privacy relies on bounding the sensitivity of the truncated frequency .
Algorithm 1 Exponential Mechanism based FIM Input : Transaction data set T , privacy parameter , itemset length
, K , fK , and error parameter γ . 1 : Preprocessing : Using FIM algorithm , find all length itemsets with frequencies > ψ = fK − γ . Assume all unknown frequencies to be ψ . Call these frequencies as truncated frequencies . P r[Selecting itemset I ] ∝ exp( n truncated frequency of I .
4Kf ( I) ) , where f ( I ) is the
2 : Sampling : Sample K itemsets without replacement such that sampled in the previous step by adding Lap , 2K
3 : Perturbation : Perturb the true frequencies of the itemsets
noise .
4 : return The sampled K itemsets and their noisy frequencies . n
ρ + ln,m
In Algorithm 1 , we describe our exponential mechanism based FIM algorithm . The algorithm takes the transaction data set T , the data set size n , the alphabet size m , the itemset length , the number of desired patterns K , the privacy parameter and the confidence parameter ρ as input . In the Preprocessing step , γ is computed as ( see Lemma 5 ) . A FIM algorithm is run with 4K n a sufficiently low threshold so as to get at least K itemsets in the output and all itemsets with frequency ≥ fK − γ . This may require two runs of the FIM algorithm ( first to get fK and the other to get all itemsets with frequency ≥ fK − γ ) . ln K
In our algorithm , along with the notions of true frequency and noisy frequency , we have a notion of a truncated frequency . For an itemset with true frequency f , if f ≥ fK − γ , then its truncated frequency is f , otherwise its truncated frequency is fK −γ i.e trun cated frequency f = max ( f , fK − γ ) . In the Sampling step , the 4Kf ( I) ) . truncated frequencies are used to sample K itemsets such that the probability of selecting an itemset is proportional to exp( n We give details of the sampling in the next section . In the Perturbation step , the true frequencies of the K sampled itemsets are n before perturbed by a zero mean Laplace noise with parameter 2K being output . In order to compute the true frequencies of all the K itemsets , in the worst case , O(K · n ) of additional work may be required . The noise addition step itself has complexity O(K ) . 311
Implementation details and runtime analysis
Let K(> K ) denote the number of itemsets mined by the FIM algorithm in the Preprocessing step . A trivial lower bound on the runtime of the FIM algorithm is Ω(Kn ) . This is because for every itemset it mines , it has to go through the entire data set once to compute its frequency . We show that FIM runtime is the dominant term in the overall runtime of the algorithm . The Perturbation step has a worst case runtime of O(K · n ) . Next , we analyze the complexity of the Sampling step . In any particular round of sampling , let S1 be the collection of itemsets with true frequencies > fK − γ and S2 be the collection of itemsets with true frequencies ≤ fK − γ . Note that , we sample without replacement , hence , the sets change with each round of sampling . For any itemset I ∈ S1 , the associated probabil4K ) , where the normalization constant C = ity mass is 1 ) . The total probability C exp( n(fK−γ )
C exp( nf ( I ) exp( nf ( I ) 4K ) + |S2| exp( n(fK−γ ) mass associated with the itemsets in S2 is |S2| A simple implementation of the Sampling step is to partition the real number line [ 0 , 1 ] into |S1| + 1 segments ( one each for an itemset in S1 and the last one for all itemsets in S2 ) according to the probability masses defined above . We then sample a number uniformly at random within the interval [ 0 , 1 ] . The partition in which the random number falls decides the itemset that we pick . If it falls in the partition corresponding to S2 , we pick up an itemset from S2 uniformly at random . This technique is inefficient because every time an itemset is picked , one has to recompute the probability masses for all the itemsets . In fact the time complexity is O(K · K ) . One can , in fact , significantly improve the running time .
I∈S1
) .
4K
4K
LEMMA 1 . The Sampling step of algorithm 1 can be imple mented to run in time O(K + K ln(K) ) .
PROOF . ( Sketch ) The idea is to create a static , balanced binary tree with |S1| + 1 = K + 1 leaves . Each leaf is labeled by a set in |S1| except for the last leaf which represents all the itemsets in S2 . The weight of a leaf is initially set to be its sampling weight . At each internal node , we store the sum of the weights in the subtree rooted at the node . This data structure can be built in linear time O(K ) . It allows one to sample from the exponential mechanism ’s distribution in time O(log(K) ) , since one can descend the tree from the root , at each step choosing a child with mass proportional to its subtree weight . Once a leaf has been sampled , its weight can be set to 0 ; updating the subtree wights on the path to the root also takes time O(log(K ) . Since we take K samples , the overall run time is O(K + K log(K) ) .
In our experiments , we used a simpler linked list variant of the data structure ( figure : 1 ) from Lemma 1 , which performed well on our data sets though it has poor worst case performance . Let {1,··· , U} denote a set of elements , where the probability of picking the i th element is proportional to Ai . We sort the elements by weight so that A1 ≥ A2 ≥ ··· AU . We want to sample K elements from this set without replacement . We create a linked . To pick an elelist , where the i th node stores Pi = ment , we traverse the list starting at node 1 . When at the i th node , we pick element i with probability Pi and stop or we move to node i + 1 with probability 1 − Pi . Thus , the probability of picking an element i in a traversal is equal to ( 1−P1)··· ( 1−Pi−1)Pi , which . After we have picked an element i , we remove equals that node from the linked list . We also recompute the Pi ’s for nodes 1,··· , i by removing Ai from their expressions . We start the next round of sampling in an exactly same manner as the previous round
Ai
1≤j≤U Aj i≤j≤U Aj
Ai of sampling , but this time with the new linked list . We repeat this process K times . If the Ai ’s are highly skewed ( ie the difference between the consecutive Ai ’s are quite large ) then , effectively in each round of sampling one has to go a small depth in the linked list before an element is picked .
A1
1≤j≤U Aj
A2
2≤j≤U Aj
Ai i≤j≤U Aj
1
Node 1
Node 2
Node i
Node U
Figure 1 : Link list for sampling without replacement
4K
In our setting , U = |S1| + 1 . We set each of the Ai ’s ( i ∈ [ 1,|S1| ] ) to exp( nf ( I ) 4K ) sorted in descending order , where I ∈ S1 . A|S1|+1 is set to |S2|· exp( n(fK−γ ) ) . In our experiments , the frequencies of the itemsets were highly skewed it was not necessary to go far down the linked list ( on average ) before an itemset was picked . From Theorem 1 , we know that the Sampling step can be implemented in time O(K + K ln(K) ) . Further , the Perturbation step takes O(Kn ) running time . Therefore , in total steps 2 and 3 of the algorithm runs in O(K + K ln(K ) + Kn ) . Earlier in the analysis we saw that the Preprocessing of the algorithm takes time Ω(Kn ) . Hence , we can conclude that for data sets with reasonably large n , the Preprocessing step is the performance bottleneck . 312 Privacy Analysis In this section , we prove that algorithm 1 is differentially private . First , we claim that the sensitivity of truncated frequency of any itemset is bounded
LEMMA 2 . For any itemset I , the truncated frequency of I has n . sensitivity 1
PROOF . Let T and T be two transaction data sets with n trans actions differing in only one transaction . Let fT ( I ) and fT ( I ) rep n . Let f T
We first prove that f T n . If f T
K = θ − 2
K and the K th highest frequency in T as f T resent the true frequency and the truncated frequency of an itemset I in T respectively . We will represent the K th highest frequency K . Note , in T as f T K = θ implies that no more than K − 1 itemsets have frequency f T > θ in T , as well as , that atleast K itemsets ( including the itemset which has frequency exactly θ ) have frequency ≥ θ . K differ by at most 1
K and f T K = θ and f T K = θ , then there are altleast K itemsets in T with frequency ≥ θ . These K itemsets have a frequency ≥ θ− 1 in T . This violates the fact that no more than K − 1 itemsets have a frequency > θ − 2 n in T . A similar contradiction arises for any n . Thus f T f T K < θ− 2 K ≥ f T n . K = θ + 2 K = θ , then there are no more than K − 1 itemsets in T with If f T frequency > θ . Thus , there are no more than K − 1 itemsets with frequency ≥ θ + 1 n in T . This violates the fact that atleast K itemsets have a frequency ≥ θ + 2 n in T . A similar contradiction arises for any f T K ≤ f T n . For an itemset I in T whose true frequency is ≥ f T n , its truncated n between T and T , fT ( I ) and frequency ( in both T and T ) is same as its true frequency . As true frequencies differ by at most 1 n . For an itemset I in T whose true K − γ in
Next we prove that fT ( I ) and fT ( I ) differ by at most 1 fT ( I ) can differ by at most 1 K − γ − 2 n . K + 1 K − γ + 2 n , its truncated frequency is f T frequency is ≤ f T
K = θ and f T n . Thus f T
K > θ + 2 n . Let f T
K − 1 n n n n n n n n n n n n n n n n n n n n n
K
K − γ f T K − γ f T K − γ f T K − γ f T
K − γ − 1 K − γ − 1 f T K − γ − 1 f T K − γ f T
K − γ − 1 K − γ f T K − γ + 1 f T K − γ + 2 f T
K − γ + 1 f T K − γ + 1 f T K − γ + 1 f T K − γ + 1 f T
K − γ f T K − γ f T K − γ + 1 f T K − γ + 2 f T f T K − γ → f T K − γ + 1 f T fT ( I ) ↓ K − γ K − γ + 1 f T f T K − γ + 1 K − γ + 1 f T f T K − γ + 2 K − γ + 2 f T f T Table 1 : Value of fT ( I ) as a function of fT ( I ) and f T f T K − γ → f T fT ( I ) ↓ K − γ − 2 f T K − γ − 1 f T K − γ f T Table 2 : Value of fT ( I ) as a function of fT ( I ) and f T fT ( I ) and fT ( I ) can differ by at most f T K − γ in T . Note that γ is identical in T and T . Thus , K which is ≤ 1 n . For an itemset I , whose true frequency in T is exactly f T K − γ + n . The truncated n , the truncated frequency in T is f T frequency of I in T depends on both the true frequency of I and f T K − γ in T . Table 1 shows the possible values of the truncated frequency of I in T as a function of fT ( I ) ( along y coordinate ) |fT ( I ) − fT ( I)| ≤ 1 and f T K − γ ( along x coordinate ) . As can be seen from the table , n . Similarly , for an itemset I with true freK − γ − 1 n , the truncated frequency in T is quency in T exactly f T K − γ . Table 2 shows the possible values of the truncated fref T K − γ ( along x coordinate ) . Again , |fT ( I ) − fT ( I)| ≤ 1 quency of I in T as a function of fT ( I ) ( along y coordinate ) and f T n . A shows that |fT ( I ) − fT ( I)| ≤ 1 n . Therefore , always fT ( I ) and K − γ in T similar exercise for an itemset I with true frequency f T fT ( I ) can differ by at most 1
K − f T K − γ + 1
T and f T
K
1 n .
The Sampling step is essentially K successive applications of the exponential mechanism . In each round of exponential mechanism an itemset is sampled without replacement . The score function for an itemset I is n × truncated frequency of I . Hence , by lemma 2 the sensitivity of the score function is one . From the analysis of the exponential mechanism ( explained in the begining of section 3.1 ) , each round of the Sampling step guarantees 2K differential privacy . We use the composition lemma ( defined be2 differential privacy for the Sampling step as a low ) to guarantee whole .
LEMMA 3
( COMPOSITION LEMMA [ 9] ) . If a randomized algorithm A runs K algorithms A1,··· ,AK , where each algorithm is i differentially private , and outputs ( A1(T ),··· ,AK ( T ) ) , i=1 i differentially private . Here T is any trans then A(T ) isK action data set .
In the Perturbation step , we use the Laplace noise addtion technique ( described in section 2 ) independently on the true frequencies of the K itemsets chosen in the Sampling step . The scaling paramn . Each of the noise addieter for the Laplace distribution used is 2K 2K differential privacy . By the use of compotion step guarantees sition lemma , the Perturbation step as a whole is 2 differentially private .
We guarantee differential privacy for algorithm 1 by applying composition lemma on the the Sampling and the Perturbation step together .
THEOREM 1 . Algorithm 1 is differentially private .
313 Utility Analysis In this section , we provide theoretical guarantees for the utility of our algorithm . Intuitively , Theorem 2 guarantees that with high probability , the K itemsets output by our algorithm are close to the actual top K itemsets . Theorem 3 guarantees that with high probability , the reported frequencies of the itemsets output are close to their true frequencies . The main steps of the proof of Theorem 2 are stated here as Lemmas 4 , 5 , 6 .
LEMMA 4 . At each round of sampling during the Sampling step , if there exists an unsampled itemset with true frequency ≥ f , then the probability of picking any itemset with true frequency
≤ f − γ is at most,m
exp,− nγ
.
4K e
PROOF . Conditioned on the fact that an itemset with true frequency f is still present , the probability of picking an itemset with true frequency ≤ f − γ is ≤ e
itemsets with true frequency ≤ f−γ
= exp(− nγ 4K ) . n(f−γ ) therefore , by union bound the probability of picking an itemset with
4K nf 4K
Since , there are at most,m true frequency ≤ f − γ is at most,m
LEMMA 5 . Let S be the collection of itemsets sampled in the Sampling step . For all ρ > 0 , with probability at least 1 − ρ , the true frequencies of all the itemsets in S are > fK − γ , where γ =
. When ρ is constant , γ = O , K·ln K+·ln m
ρ + ln,m ln K
4K n
.
exp(− nγ
4K ) . n itemsets , therefore by union bound , in any round of sampling the probability of choosing any itemset with true frequency ≤ fK − γ
PROOF . By lemma 4 , in any round of sampling the probability of choosing a particular itemset with true frequency ≤ fK − γ is at most exp(− nγ 4K ) . This is because in each round of sampling we are guaranteed to have at least one itemset with true frequency
≥ fK which has not been sampled yet . Since , there are at most,m is at most,m K ·,m e− nγ Let ρ ≥ K ·,m
Further by union bound , in the Sampling step the probability of choosing any itemset with true frequency ≤ fK − γ is at most
exp(− nγ e− nγ
4K . Then ,
4K ) .
4K .
− γ n 4K
⇔ γ n 4K
ρ
ρ
≥ ln
≤ ln
K,m K,m
K(ln K+·ln m ) ρ + ln,m ln n
K ρ
⇔ γ ≥ 4K n m
+ ln
For constant ρ , γ = O will suffice . n ln K
LEMMA 6 . For all ρ > 0 , with probability at least 1 − ρ , all length itemsets with true frequency > fK + γ are present in S , where γ = 4K . When ρ is constant , γ =
K(ln K+·ln m ) any itemset with true frequency ≤ fK is at most,m
PROOF . If any one of the itemsets with true frequency > fK + γ is not present in S then , by lemma 4 , probability of picking 4K ) .
exp(− nγ
O n
.
Therefore , the probability of not picking any itemset with true frequency ≤ fK in any of the K rounds of sampling is at least
K ≥,1 − K ·,m K(ln K+·ln m )
exp(− γn 4K ) .
ρ + ln,m ln K n will suffice . n
From the analysis of lemma 5 , γ ≥ 4K
. When
THEOREM 2 . For all ρ > 0 , with probability at least 1 − ρ , all output itemsets have their true frequencies > fK − γ , and all itemsets with true frequency > fK + γ are output , where γ = 4K n
. When ρ is constant , ln 2K
1 −,m
e− γn
4K
ρ is constant , γ = O
. n
γ = O
ρ + ln,m K(ln K+·ln m ) 1−K·,m e− γn 1 − K ·,m e− γn 1 − 2K ·,m e− γn
ρ + ln,m
> fK + γ are present in S .
By union bound , w.p at least
PROOF . From the proof of lemma 5 , we know that wp at least 4K all itemsets in S have true frequencies > fK−γ .
From the proof of lemma 6 , we know that wp at least
4K all the length itemsets with true frequency
Using analysis analogous to Lemma 5 , we get
4K all itemsets output have their true frequencies > fK−γ and all itemsets with true frequency > fK +γ are output . γ ≥ 4K will suffice .
K(ln K+·ln m )
. For constant ρ , γ = O ln 2K n n
THEOREM 3 . For all ρ > 0 , with probability at least 1 − ρ , all noisy frequencies differ by at most η from their corresponding true frequencies , where η = 2K
K
noise to f . Therefore , the probabil ity of the noisy frequency deviating by ≥ η from f is ≥
PROOF . Let the true frequency of an itemset be f . In the pertur n
.
ρ n ln
∞ bation stage we add Lap , 2K − ( x−f )n 2 · n at most K · exp,− ηn f +η exp
4K
2K
2K dx
. = exp,− ηn . Setting , ρ = K · exp,− ηn
2K
2K
Since we add Laplace noise to K true frequencies , therefore , by union bound the probability of any of the noisy frequencies differing by more than η from their corresponding true frequencies is
, we get
ρ . n ln K
η = 2K 3.2 Laplace Mechanism based algorithm
The second algorithm we present is easier to implement and understand than the first . The accuracy ( utility ) bound γ we obtain for the second algorithm slightly worse ( by a factor of roughly 2 ) than the guarantee for the first algorithm . Nevertheless , the second algorithms’ simplicity may make it preferable in some settings . Moreover , the anlysis of privacy requires a new proof technique which may be of independent interest .
The basic idea of the algorithm is to add independent Laplace noise to the frequencies of all itemsets and select the K itemsets with the highest perturbed frequencies . A naive sensitivity analysis suggests that we must add noise proportional to,m
/ for this to be differentially private . However , we show that it suffices to add noise only O(K/ ) to the frequencies . Additional work is required to get an efficient implementation ; in particular , we use the idea of truncated frequencies from the previous algorithm . 321 Steps 1 and 3 of the algorithm are straight forward . The Noise addition and sampling step requires some thought in order to perform it in a computationally efficient manner . Clearly , it is not computationally feasible to add noise to the truncated frequencies of all
Implementation details and runtime analysis
Algorithm 2 Laplace Mechanism based FIM Input : Transaction data set T , privacy parameter , itemset length
, K , fK , and error parameter γ . 1 : Preprocessing : Using FIM algorithm , find all length itemsets with frequencies > ψ = fK − γ . Assume all unknown frequencies to be ψ . Call these frequencies as truncated frequencies .
2 : Noise addition and sampling : Add Lap , 4K cated frequencies of all,m
to the trun itemsets to obtain the noisy fre n n
4K
,m
3 : Perturbation : Perturb the true frequencies of the itemsets in quencies . Pick the top K itemsets in terms of the noisy frequencies . Let this set be denoted as S . {We will discuss later how to perform this step in a computationally efficient manner.}
noise to obtain the noisy frequencies S with fresh Lap , 2K itemsets as the number of itemsets to be dealt with is large .
4 : return The set S and the corresponding noisy frequencies . for the itemsets in S .
However , the number of itemsets with true frequencies > fK − γ is within computable limit . Hence , we can add noise to the truncated frequencies of these itemsets . Using the same notation of the previous subsection , S1 represents itemsets with true frequencies > fK − γ and S2 represents itemsets with true frequencies ≤ fK − γ . We only need a special strategy for S2 . Let lf reqS1 be the Kth largest noisy frequency in the set S1 . Let ψ = fK − γ . Now , an itemset whose true frequency is ≤ ψ , if it has to make it to the final output then its noisy frequency should be greater than lf reqS1 . Therefore , the probability of it making 2 e−|ψ−(cid:92)lf reqS1|n if lf reqS1 ≥ ψ and to the final output is < 1 if lf reqS1 < ψ . Let us denote this < 1 − 1 probability as p . Thus , the number of itemsets with true frequency < fK − γ which has noisy frequency > lf reqS1 follows a Bino mial distribution with parameters,m
− |S1| and p .
2 e−|ψ−(cid:92)lf reqS1|n
We now pick a random number X according to the Binomial distribution mentioned above and pick X itemsets uniformly at random from the set S2 . For now let us assume that lf reqS1 ≥ ψ . In fact almost all the time this will be true . Conditioned on the fact that there are X itemsets with true frequencies ≤ ψ , whose noisy frequencies are greater than lf reqS1 , the distribution of these X itemsets follow an exponential distribution with mean lf reqS1 + 4K n . This follows from the memorylessness and standard deviation 4K property of exponential distribution . Thus , the noisy frequencies of these X itemsets are picked iid from the mentioned exponential distribution . We call the set of these noisy frequencies and the corresponding itemsets V . In the unlikely event of lf reqS1 ≤ ψ , we can get a similar distribution using Bayes’ Theorem . Now , we pick the top K itemsets in terms of the noisy frequencies from the set S1 ∪ V and pass them on to the the Perturbation step . We next discuss about the running time of the algorithm . Let ρ be the confidence parameter ( defined earlier ) . We set the error . We will see in section 332 , the parameter γ = 8K n utility guarantee requires γ to be set to this value . For this value of γ , the following theorem holds true .
( m
) ρ ln
4K n
THEOREM 4 . With probability at least 1 − ρ , steps 2 and 3 of algorithm 2 runs in time O(K + Kn ) , where K is the number of itemsets mined by the FIM algorithm .
PROOF . To prove this claim , we will use the result from theorem 6 . Theorem 6 is stated and proved in section 332 From the statement of theorem 6 we know that with probability at least 1 − ρ , no itemset from S2 is present in the final output . This implies , with probability at least 1 − ρ the value of the random number X ( which denotes the number of itemsets from S2 whose noisy frequencies are greater than lf reqS1 ) is zero . Therefore , in such a situation the Noise addition and sampling step will take time O(K ) . Clearly , the Perturbation step takes time O(Kn ) . Hence , with probability at least 1 − ρ , steps 2 and 3 of algorithm 2 runs in time O(K + Kn ) .
In the runtime analysis of algorithm 1 , we have seen that the step that involves the Apriori algorithm is usually the performance bottleneck . From the theorem above , we know that with high probablity steps 2 and 3 of algorithm 2 runs in time O(K + Kn ) . And earlier we saw that runtime of FIM algorithm is Ω(Kn ) . Hence , with high probability even for the present algorithm , Apriori algorithm is the performance bottleneck . 3.3 Privacy and Utility Analysis
331 Privacy guarantee
THEOREM 5 . The algorithm is differentially private . PROOF . Let Dn be the domain of data sets of n transactions where each transaction is a subset of M . Let ST = {I1 , f T ( I1),··· ,IK , f T ( IK )} represent the output of the algorithm A running on data set T ∈ Dn . Similar to that in the proof of theorem 1 , Ii ⊆ U represents the itemsets and f T ( Ii ) represent the corresponding noisy frequencies . We prove the privacy guarantee in two parts . First , we prove that the collection of K itemsets ( ie {I1,··· ,IK} ) sampled after step two of algorithm 2 preserves 2 differential privacy for the noisy frequencies output for these particular K itemsets after step three of the algorithm 2 . We then argue that by the composability property from lemma 3 , the algorithm as a whole is differentially private . Let W denote the collection of the K itemsets output by the algorithm A . Let T , T ∈ Dn be any two data sets differing in exactly one transaction . We want to first show that Pr [ A(T ) = W ] ≤ 2 Pr [ A(T ) = W ] . This is an abuse of notation as the output of e A is actually the collection of itemsets and their frequencies . For now we will consider just the collection of itemsets it outputs . To denote the intermediate noisy frequency for an itemset I in step
2 differential privacy . Then we prove the two of the algorithm , we use fT ( I ) .
Now ,
···
Pr[A(T ) = W ] = v1∈R pdfT [ fI1 = v1 ] · pdfT [ fIK = vK ] [ fI < min{v1 , v2,··· , vk} ] vK∈R
Pr T
I∈2U −W,|I|=
We use the notation pdfT [ · ] , PrT [ ] to parameterize the probability density function and the probability mass function on data set T .
We want to upper bound the ratio Pr[A(T )=W ]
2 . In order to upper bound the ratio by e 2 , we will minimize the denominator . To minimize Pr[A(T ) = W ] , ∀I ∈ 2U ,|I| = , we can
Pr[A(T )=W ] by e either increase or decrease fI(T ) by 1 fififi can be at most 1 fifififI(T ) − fI(T ) n to obtain fI(T ) , since n ( as discussed in the proof of
λ
λ
λ n
2 e− |v−fI ( T )| theorem 1 ) . fI(T ) represent the truncated frequency of an itemto have fI(T ) − fI(T ) = 1 set I in data set T . Thus , to minimize Pr[A(T ) = W ] , one has For all the itemsets I ∈ W , depending on the value of fI(T ) n for all I ∈ 2U − W,|I| = . one has either fI(T ) − fI(T ) = 1 n or fI(T ) − fI(T ) = 1 I ∈ 2U and for any v ∈ R , pdfT [ fI = v ] = 1 in order to minimize Pr[A(T ) = W ] . This is because for any 2λ e− |v−fI ( T )| , when v < fI(T ) , and Similarly , PrT [ fI < v ] = 1 . 2 e− |v−fI ( T )| , when v ≥ fI(T ) . Note that Pr[fI < v ] = 1 − 1 Pr[fI < v ] decreases when fI increases .
One critical observation is that algorithm A behaves the same ( in terms of outputting the itemsets ) on a data set T ∈ Dn as it behaves on T ∈ Dn if all the truncated frequencies of itemsets in n in the same direction ( ie either increase all T are shifted by 1 or decrease all ) to form T , since all that matters are the differences in the truncated frequencies . This property is also known as translation invariance .
Therefore , instead of following the previous procedure , if one increases fI for all I ∈ W which were increased in the previn , increase fI for all I ∈ W ous procedure but this time with 2 n and for which were kept constant in the previous procedure by 1 all I ∈ W,|I| = whose truncated frequencies were decreased in the previous procedure , keep the same . Also keep the truncated frequencies of I ∈ 2U − W,|I| = same . In this way the two procedures of obtaining Pr[A(T ) = W ] are exactly identical . Thus , change of fI for all I ∈ W,|I| = . As we saw in the previous when we obtain Pr[A(T ) = W ] , we need to only know about the For an itemset I ∈ W , pdfT [ fI =v ] pdfT [ fI =v ] are changing fI by at most 2 2 nλ ( since we n ) . Since , in each term in the integration of the expression for Pr[A(T ) = W ] there are exactly K terms which has I ∈ W , therefore , when we change from T to T each term in the integration changes by at most 2K nλ . Therefore , Pr[A(T )=W ] Pr[A(T )=W ] is upper bounded by 2K nλ . n guarantees n . step , this change can be at max 2
2 differential privacy for the
Hence , setting λ = 4K is at most e
Noise addition and sampling step of the algorithm .
Since , the Perturbation step of both the algorithms 1 and 2 are same hence , the privacy guarantees for this step in both are also same . The Perturbation step assures that the set of the noisy frequencies output for the itemsets sampled in the Noise addition and sampling step is
2 differentially private .
Hence by the composition lemma 3 , the algorithm as a whole is
differentially private . 332 Utility guarantee In this subsection we provide utility guarantees which are analogous to the ones presented in the exponential mechanism based approach . The utility guarantee in theorem 6 is at most two times worse than the utility guarantee in theorem 2 .
THEOREM 6 . For all ρ > 0 : with probability at least 1 − ρ , all itemsets output have their true frequencies > fK − γ , and all itemsets with true frequency > fK + γ are output , where γ = 8K n
( m PROOF . Since , we are adding Lap , 4K · e− Γn 1 −,m cated frequencies , it can be shown that with probability at least 4K all itemsets of length have their noisy frequen
K ln(m ) noise to all the trun
. When ρ is constant , γ = O
) ρ ln n n
. cies within γ margin of their truncated frequencies .
Data set n 340183 accidents 3196 chess 67557 connect 990002 kosarak 8124 mushroom 49046 pumsb 49046 pumsb star 88162 retail T10I4D100K 100000 T40I10D100K 100000 m 469 76 130 41270 120 2114 2089 16471 871 943
|t| 34.81 38 44 8.09 24 75 51.48 11.31 11.1 40.61
Table 3 : Data sets characteristics : Number of transactions N , size of alphabet m , average size of transaction , |t| .
,m ·e− γn if we set ρ =,m
Therefore , if we set γ = 2Γ , then with probability at least 1 − 8K , all itemsets output have their true frequencies > fK− γ and all itemsets with true frequencies > fK + γ are output . Thus suffices .
· e− γn
( m
8K , then γ = 8K n
) ρ ln
For constant ρ , γ = O
K ln(m )
K n
. n ln
ρ
THEOREM 7 . For all ρ > 0 , with probability at least 1 − ρ , all noisy frequencies differ by at most η from their corresponding true frequencies , where η = 2K
.
PROOF . The proof is exactly the same as that for theorem 3 .
4 . EXPERIMENTS
In this section , we present the results of several experiments we performed to evaluate the performance of the above proposed algorithms . We first describe the data sets on which we ran our algorithms . Then we present the relationships between the different parameters ( eg . , γ , ρ , η ) that we obtain by applying the theoretical results to these data sets . We also study extensively the utility of our algorithms for these data sets under a wide range of parameters . For the evaluation of our experiments we use data sets publically available at the FIMI repository http://fimihelsinkifi These data sets are listed in Table 4 . This collection of data sets contain both real world and synthetic data sets , and also have widely varying characteristics like number of transactions n , number of items m and average transaction length |t| .
Summary of the results : a ) Theoretical guarantees result in useful parameter ranges on these data sets We show that our theorems about privacy and utility , when applied to these data sets yield a useful range for all the parameters of the system . In particular , the efficiency of our algorithms greatly depends on the threshold at which the underlying frequent itemset mining ( FIM ) algorithm runs . The threshold we provide to the FIM algorithm is fK − γ . A small γ implies that the privacy overhead in terms of the running time of the FIM al2 , and K . gorithm is not too high . We plot γ fK These plots tell us how low a threshold we have to provide to the FIM algorithm for various choices of other parameters . Our plots show that for most data sets , at typical values of the parameters 2 = 0.7 , ρ = 0.1 , l = 3 , k = 10 ) , γ is a small fraction of fK . ( The other theoretical guarantee that we provide is about η , which is the difference between the reported frequencies of the output itemsets and their true frequencies . For these data sets , we show that the actual value of η obtained is a small fraction of fK . Note that 2 to emphasize that the final we plot variation of γ and η against as a function of
( a ) Algorithm 1
( b ) Algorithm 2
Figure 2 : Variation of γ fK with the privacy parameter 2 l privacy parameter is when both the patterns and their frequency are output . b ) For a wide range of parameters , the algorithms give good utility on these data sets For the same set of parameter ranges as in ( a ) , we run our algorithm on these data sets and plot the False Negative Rate ( FNR ) for the output . Note that False Positive Rate ( FPR ) is essentially small for this output as the number of infrequent patterns are typically high compared to the total number of frequent patterns ( since K <<,m
) . In these data sets , the highest possible FPR that can be achieved is 0.03 ( this is assuming that all the top K itemsets are false positives ) . Our plots show that , again for typical values of the parameters , FNR is under 0.2 for eight data sets ( while for 6 of them it is close to 002 )
In our first set of experiments , we study the behaviour of γ fK and as other parameters , K and vary . For these experiments , η fK 2 varies from 0.04 2 , K varies from 10 100 and varies from 2 6 . In an experiment , while one parameter varies , the other three remain 2 = 0.7 , ρ = 0.1 , K = 10 and fixed . These fixed values are l = 3 . Figure 2(a ) shows the plot of γ 2 varies from 0.04 2 fK ( note x axis is in log scale ) for Algorithm 1 . We clamp the y axis at 1 , as γ greater than 1 implies a negative FIM threshold , that is , fK−γ < 0 . Whenever the theoretical requirement causes fK−γ to fK as
0 0.2 0.4 0.6 0.8 1 0.01 0.1 1 10γ / fKPrivacy Parameter ( ε / 2)accidentschessconnectkosarakmushroompumsbpumsb starretailT10I4D100KT40I10D100K 0 0.2 0.4 0.6 0.8 1 0.01 0.1 1 10γ / fKPrivacy Parameter ( ε / 2)accidentschessconnectkosarakmushroompumsbpumsb starretailT10I4D100KT40I10D100K fK is less than min(1 , 1 fK become negative , one of the utility guarantees ( namely , soundness ) becomes trivial . Also note , that when γ becomes greater than fK −1 , fK +γ becomes greater than 1 . In this case , the other utility 1 fK guarantee ( namely , completeness ) becomes trivial . Thus whenever −1 ) , both the utility guarantees are nonγ fK − 1 trivial . In the figures , the arrowhead on the y axis indicate 1 fK − 1 is greater than 1 , thus for each data set . For some data sets , 1 fK it does not show up in the plots . For algorithm 1 , at 2 = 0.7 , for all data sets except chess and T10I4D100K , both the utility guarantees ( soundness and completeness ) are non trivial as the obtained γ fK is less than min(1 , 1 decreases fK as the privacy requirement ( ) is relaxed . Figure 3(b ) shows the as K varies from 10 100 . It can be observed that variation of γ fK rises rapidly for data sets which have either a large alphabet size γ fK m ( eg . retail ) or a low fK ( eg . T10I4D100K and T40I10D100K ) or a small n ( eg . chess and mushroom ) . Note that for kosarak the rise is not that rapid despite having a big m as n is also quite large as varies from 2 6 . for it . Figure 3(c ) shows the variation of γ fK The trend in this plot is quite similar to the one in 3(b ) .
− 1 ) . As expected , the ratio γ
In the same set of experiments we also study the noise added to the frequencies of the output items . We show the variation of η fK goes with below 0.1 for all data sets . We skip the plots of η v/s ρ and η fK fK v/s K due to lack of space .
2 . In figure 4(a ) , we see that at
2 = 0.7 , the ratio η fK
In our next set of experiments we study the False Negative Rates produced in the output as we vary the parameters over the same ranges as in the earlier set of experiments . The underlying FIM algorithm employed was the "fp growth" version of Ferenc Bodon ’s implementation ( http://wwwcsbmehu/ bodon/en/apriori/ ) . It was run on a machine with an Intel(R ) Xeon(R ) CPU E5345 @2.33 GHz with 16 GB of RAM . In our experiments , we found the running time of the underlying FIM algorithm as the dominant term in the overall running time . Thus , to have a reasonable check on the running time of the complete experiment , we decided to discard all experiment runs in which the underlying FIM algorithm ran for more than 5 minutes or produced a pattern output file of size greater than 5GB . Thus , if for a certain choice of parameters , the fK − γ value was such that the FIM algorithm run violated the above constraints , we don’t report the FNR . This does not mean that our algorithms fail to terminate for that choice of parameters . Infact , under such stringent computational constraints , the algorithms continue to provide good results for a wide range of parameters . Each FNR reading reported in this set of experiments is averaged over 10 runs of the experiment . The standard deviation in the FNR was always under 0.15 for all data sets.except for the T10I4D100K data set in the FNR v/s ρ plot , where it was 02 We don’t show the standard deviations to make the plots more readable .
2 . At
Figure 5(a ) shows the plot of FNR against
2 = 0.7 , except data sets chess and T10I4D100K , all others have a FNR of under 02 In fact for most data sets ( 6 of them ) the FNR is close to 002 We skip FNR v/s ρ plot due to lack of space . In Figs . 6(a) 6(b ) the FNR seems to rise with increasing K or . Note , for some data sets including T10I4D100K , T40I10D100K , chess and retail , there are a lot of missing points as the underlying FIM algorithm run violated our computational constraints often . For all other data sets , the FNR continues to remain low .
5 . GENERAL RANKING
The algorithms 1 and 2 proposed for FIM naturally extends to any generic problem on ranked list . Following [ 20 ] , a ranked list is a list of elements ordered according to some measure of interest .
Instead of considering a universe of itemsets of length drawn from an item base of size m , we can consider an universe of U elements where each element has a score associated with it . Let the universe of elements be represented as S = {E1,··· ,EU} . Let T ∈ Dn be a transaction database of n transactions , where each row is a subset of S . Let q : S × Dn.→ R be a function which assigns score to each element . The score function is analogous to the frequency of an itemset in FIM . The goal in this abstract setting is to output the top K elements in terms of the scores assigned by the function q . As in the case of differentially private FIM , here also we have the error parameters γ and η , and the confidence parameter ρ . Let ∆q be the sensitivity of the function q , ie the amount by which the function changes if one row of the database T is changed . Recall that the sensitivity of the frequency function in the case of FIM is n . In the algorithms and the associtated privacy and utility guaran1 tees in section 3 , if we replace the size of the universe of itemsets
) by the size of the universe of elements ( ie |S| = U ) ,
( ie ,m replace the frequency function by q and replace the sensitivity of n ) by ∆q , we obtain algorithms and the frequency function ( ie 1 their associated privacy and utility guarantees for the problem on ranked lists . Note that , the privacy guarantees will remain exactly the same as that of FIM .
6 . RELATED WORK
Randomized response .
One approach to Privacy Preserving Data Mining is randomized response . In this approach each entry in the data set is independently randomized before allowing the data mining algorithm to access it . Evfimievski et al . [ 10 ] and Agrawal et al . [ 3 ] considered randomized response in the context of FIM . They consider the threshold variant where the goal is to return all the itemsets of length whose frequencies are greater than a predefined threshold θ . They define the term amplification factor which quantifies the privacy guarantee of the mining algorithm . The amplification factor directly corresponds to e , where is the differential privacy parameter . The work of [ 3 ] is an improvement over the work of [ 10 ] .
We compare our algorithms 1 and 2 to the algorithms of [ 3 ] on the same CENSUS data set used by [ 3 ] from the UCI repository http://archiveicsuciedu/ml/ To enable comparison , we set the parameters of our algorithms as follows : First , we set K so that fK equals the threshold θ used by [ 3 ] . Second , they use amplification factor e = 19 , where as we set it to e = e2 ( that is , we impose an even stronger privacy guarantee ) . Third , we set the confidence parameter ρ for our algorithms to 0.05 ; there is no analogous parameter in [ 3 ] .
To measure utility , [ 3 ] used the false negative rate ( FNR ) . We compared the FNR of our algorithms to those of the two bestperforming algorithms from [ 3 ] ( RAN GD and DET GD ) for various itemset lengths ; the results are plotted in Figure 7 . We find that both of our algorithms have consistently lower FNR . The FNR for RAN GD and DET GD were taken from Agrawal et al . [ 3 , Figures 1(a ) and 2(a) ] .
Privacy preserving search log release .
Götz et al . [ 14 ] and Korolova et al . [ 18 ] independently presented algorithms for releasing search log statistics in a differentially private manner . Both the algorithms are very similar to each other . We can adapt the algorithms to provide differentially private algorithms for FIM .
It is difficult to compare the performance of these two algorithms against our algorithms because they were optimized for the search log setting .
Specifically , the algorithms add Lap(λ ) noise to frequencies of the itemsets present in the data set and outputs all the noisy frequencies and their corresponding itemsets which exceed a specified threshold τ . ( In contrast , we output the top K itemsets and add noise independently . ) tially change the frequencies of,m perimental settings we consider , the value of,m
length itemsets . In the ex is far higher than
If we consider the FIM setting , a single transaction can poten the maximum value ω ( ie , the number of elements whose scores change by changing one users data ) used by [ 14 ] and [ 18 ] . In order to make their assumption reasonable for FIM , we impose a bound t on the length of any transaction in the data set . ( The length of a transaction is the number of items present in it . ) A single transac tion can potentially change the frequencies of,t length itemsets . We can map the parameter ω from the search log setting to,t in our setting . Götz et al . [ 14 , Theorem 1 ] state the value of λ ( ie the scaling parameter of Laplace noise ) and τ sufficient to guarantee ( , δ)differential privacy for algorithms by [ 14 ] and [ 18 ] respectively . ( ( , δ) differential privacy is a relaxation to the definition of differential privacy allowing a small additive error of δ . ) Adapting this theorem to our setting we get , λ = τ ≥ 1 τ for the different data sets we have considered in our experiments . We have set = 1 , δ = 0.05 and = 3 .
. Table 4 shows the requirement on ln,2δ/,t
,1 − 1
2(t ) n and
,t n
Data set Accident Chess Connect Kosarak Mushroom Pumsb star Pumsb Retail n
340183 3196 67557 990002 8124 49046 49046 88162
52 38 44 2498 24 64 75 77
τ ≥ 0.8644 32.5796 2.5081 6.55E+04 2.7194 11.8418 19.8569 12.0333
Table 4 : Required values for τ
We find that in all but for the accident data set , τ is greater than one . In order to output the K most frequent itemsets , we would like to have τ be at most fK . This makes the algorithms by Götz et al . and Korolova et al . unreasonable for our experimental setup . Note that in cases where t and are small , their approach might indeed work well . However , in terms of privacy guarantee they provide ( , δ) differential privacy guarantee which is strictly worse than the guarantee we provide .
Synthetic data sets .
Blum et al . [ 5 ] provided a method to output a synthetic data set
T , which provides near accurate answers for frequency queries
( ie close to the frequencies in the original data set T ) . This data set can be output in a differentially private manner . For γ ≥ ˜O , the utility guarantees for the algorithm due to Blum et al . and our algorithms 1 and 2 are similar . Recall that that in our algorithms , we need γ ≥ ˜O , K
. In the experimental set
( m)1/3
( n)1/3 tings we consider , n is far larger than K , hence the lower bound on γ in our case is better . However , in settings where K is larger than 2 3 , the [ 5 ] algorithm gives a better bound on γ . Even in m
1 3 ( n ) n these settings , our approach may be preferable for efficiency . The only known implementation of [ 5 ] runs in time 2 impractical with the current computational resources available .
, which is
O m2 2
7 . CONCLUSIONS
In this paper we presented two efficient differentially private algorithms for top K frequent pattern mining . In our algorithms we adapted the Exponential Mechanism and the Laplace noise addtion mechanism by introducing techniques that are efficient in the context of frequent pattern mining . We introduced a new notion of utility for top K pattern mining and provided theoretical analysis of our methods under this criterion . We also presented extensive experimental results that demonstrate the effectiveness of our methods on the FIMI benchmark data sets . Though we present our algorithms for the problem of frequent pattern mining , our techniques are applicable in the general problem of private ranking as well . For example , our algorithms can be used in the settings of [ 14 ] and [ 18 ] , where they analyze the problem of releasing search log statistics privately .
The utility guarantees we provide in theorems 2 and 6 are dependent on the size of the universe of items . In some cases , the universe of items can be large , resulting in large run times as well as loose utility guarantees . A possible future direction is to devise techniques that remove this dependency on the size of the universe of items , thereby extending the applicability of the algorithms to bigger and more complex data sets . Acknowledgements . AS and AT are partly supported by NSF grants #0747294 , 0729171 . We thank Daniel Kifer for helpful comments .
8 . REFERENCES [ 1 ] Frequent itemset mining implementations repository . http://fimihelsinkifi
[ 2 ] R . Agrawal , T . Imielinski , and A . Swami . Mining association rules between sets of items in large databases . In Proceedings of the ACM SIGMOD Conference on Management of Data , pages 207–216 , May 1993 .
[ 3 ] S . Agrawal and J . R . Haritsa . A framework for high accuracy privacy preserving mining . In ICDE , pages 193–204 , 2005 .
[ 4 ] M . Barbaro and T . Zeller . A face is exposed for aol searcher no .
4417749 . The New York Times , Aug . 2006 .
[ 5 ] A . Blum , K . Ligett , and A . Roth . A learning theory approach to non interactive database privacy . In STOC , pages 609–618 , 2008 . [ 6 ] I . Dinur and K . Nissim . Revealing information while preserving privacy . In PODS , pages 202–210 , 2003 .
[ 7 ] G . Dong and J . Li . Efficient mining of emerging patterns :
Discovering trends and differences . In Proceedings of the 5th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ( KDD ’99 ) , pages 43–52 , 1999 .
[ 8 ] C . Dwork . Differential privacy . In ICALP , LNCS , pages 1–12 , 2006 . [ 9 ] C . Dwork , F . McSherry , K . Nissim , and A . Smith . Calibrating noise to sensitivity in private data analysis . In TCC , pages 265–284 , 2006 .
[ 10 ] A . V . Evfimievski , J . Gehrke , and R . Srikant . Limiting privacy breaches in privacy preserving data mining . In PODS , pages 211–222 , 2003 .
[ 11 ] S . R . Ganta , S . P . Kasiviswanathan , and A . Smith . Composition attacks and auxiliary information in data privacy . In KDD , pages 265–273 , 2008 .
[ 12 ] N . GN , B . A . , H . J . , S . K . , and E . IR Temporal pattern discovery for trends and transient effects : Its application to patient records . In Proceedings of the Fourteenth International Conference on Knowledge Discovery and Data Mining SIGKDD 2008 , pages 963–971 , 2008 .
[ 13 ] B . Goethals . Survey on frequent pattern mining . Manuscript , 2003 . [ 14 ] M . Götz , A . Machanavajjhala , G . Wang , X . Xiao , and J . Gehrke .
Privacy in search logs . CoRR , abs/0904.0682 , 2009 .
[ 15 ] J . Han and M . Kamber . Data mining : Concepts and techniques . Morgan Kaufmann Publishers , San Fransisco , CA , USA , 2001 .
[ 16 ] D . Hand , H . Mannila , and P . Smyth . Principles of data mining . MIT
Press , Cambridge , MA , USA , 2001 .
[ 17 ] V . Hristidis , editor . Information Discovery on Electronic Health
Records . Chapman & Hall/CRC Data Mining and Knowledge Discovery Series , Boca Raton , FL , USA , 2009 .
[ 18 ] A . Korolova , K . Kenthapadi , N . Mishra , and A . Ntoulas . Releasing search queries and clicks privately . In WWW , pages 171–180 , 2009 .
[ 19 ] A . Machanavajjhala , J . Gehrke , D . Kifer , and
M . Venkitasubramaniam . l diversity : Privacy beyond k anonymity . In ICDE , page 24 , 2006 .
[ 20 ] F . McSherry and K . Talwar . Mechanism design via differential privacy . In FOCS , pages 94–103 , 2007 .
[ 21 ] A . Narayanan and V . Shmatikov . De anonymizing social networks . In IEEE Symposium on Security and Privacy , pages 173–187 , 2009 . [ 22 ] K . Nissim , S . Raskhodnikova , and A . Smith . Smooth sensitivity and sampling in private data analysis . In STOC , pages 75–84 , 2007 .
[ 23 ] P . K . Novak , N . Lavrac , and G . I . Webb . Supervised descriptive rule discovery : A unifying survey of contrast set , emerging patterns and subgroup mining . Journal of Machine Learning Research , ( 10):377–403 , 2009 .
[ 24 ] L . Sweeney . k anonymity : A model for protecting privacy .
International Journal on Uncertainty , Fuzziness and Knowledge based Systems , 10(5):557–570 , 2002 .
[ 25 ] X . Wu , V . Kumar , J . R . Quinlan , J . Ghosh , Q . Yang , H . Motoda , G . J . McLachlan , A . Ng , B . Liu , P . S . Yu , Z H Zhou , M . Steinbach , D . J . Hand , and D . Steinberg . Top 10 algorithms in data mining . Knowledge and Information Systems , 14:1–37 , 2008 .
[ 26 ] M . J . Zaki and C J Hsiao . Efficient algorithms for mining closed itemsets and their lattice structure . IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING , 17 , 2005 .
APPENDIX A . PSEUDOCODES OF SAMPLING STEP
FOR ALGORITHMS 1 AND 2
Let S>fK−γ be the set of itemsets and their corresponding true frequencies output by the Apriori algorithm . Let S>fK−γ ( i ) represent the i th itemset in the set S>fK−γ and let f req,S>fK−γ ( i) represent its frequency . We follow this notation for both the algorithms . First we present the pseudocode of the Sampling step of Exponential Mechanism based FIM in algorithm 3 .
Next we present the pseudocode for Noise addition and sampling step in algorithm 4
4K length , K , fK , and error parameter γ .
Algorithm 3 Sampling step of Exponential Mechanism based FIM Input : Set S>fK−γ , database size n , privacy parameter , itemset 1 : N ← |S>fK−γ| + 1 2 : for i = 1 to N − 1 do 3 : Ai.itemset ← S>fK−γ(i ) 4 : Ai.f req ← f req(S>fK−γ(i ) ) 5 : Ai.expData ← exp 6 : end for 7 : AN .itemset ← lowF reqItems n·f req(S>fK−γ ( i ) ) − |S>fK−γ| exp n(fK−γ )
9 : Sort the array A[1,··· , N − 1 ] in descending order on the
8 : AN .expData ←,,m Li stores Ai and Xi = member variable expData i≤j≤N Aj.expData
10 : Create a doubly linked list L with N nodes such that any node 11 : F ORBIDDEN ← ∅ 12 : OU T P U T ← ∅ {Initialize the Output set} 13 : for i = 1 to K do 14 : 15 : 16 : 17 : 18 : 19 : 20 :
Generate Y ∼ Bernoulli( Aj .expData if N == j then f lag ← F ALSE j ← 1 while f lag == F ALSE do
Xj
4K
)
21 : 22 : 23 : 24 : n(fK−γ ) f lag ← T RU E Sample uniformly at random an itemset I from U niverse − ( S>fK−γ ∪ F ORBIDDEN ) , where U niverse is the collection of all length itemsets F ORBIDDEN ← F ORBIDDEN ∪ I OU T P U T.itemset ← I OU T P U T.f req ← fK − γ Update AN ← AN − exp Update ∀1 ≤ q ≤ N , Xq ← Xq − exp OU T P U T.itemset ← Aj.itemset OU T P U T.f req ← Aj.f req Update ∀1 ≤ q < j , Xq ← Xq − Aj.expData Remove Node Lj and decrease N by 1 f lag ← T RU E n(fK−γ )
4K
4K else if 1 == Y then
25 : 26 : 27 : 28 : 29 : 30 : 31 : 32 : 33 : 34 : 35 : end for 36 : return The set OU T P U T end if j ← j + 1 end while n length , K , fK , and error parameter γ .
7 : Xi.noisyF req ← Xi.f req + Lap , 4K
Algorithm 4 Noise addition and sampling step of Laplace Mechanism based FIM Input : Set S>fK−γ , database size n , privacy parameter , itemset 1 : N ← |S>fK−γ| 2 : X ← ∅ 3 : ψ ← fK − γ 4 : for i = 1 to N do 5 : Xi.itemset ← S>fK−γ(i ) 6 : Xi.f req ← f req(S>fK−γ(i ) ) 8 : end for 9 : lF req ← K th highest noisy frequency in X 10 : if lF req ≥ ψ then 11 : 12 : else 13 : 14 : end if 16 : F ORBIDDEN ← ∅ 17 : for i = N + 1 to N + 1 + Y do 18 :
2 e− |ψ−lF req|n 2 e− |ψ−lF req|n − N , p
Sample uniformly at random an itemset I from U niverse− ( S>fK−γ ∪ F ORBIDDEN ) , where U niverse is the collection of all length itemsets F ORBIDDEN ← F ORBIDDEN ∪ I
19 : 20 : Xi.itemset ← I 21 : Xi.f req ← ψ 22 : Xi.noisyF req ∼ Exponential distribution with mean
15 : Y ∼ Binom,,m p ← 1 p ← 1 − 1
4K lF req + 4K n and standard deviation 4K n
23 : end for 24 : Set OU T P U T to top−K of the elements from X in terms of
4K the noisy frequency
25 : return The set OU T P U T
( a ) γ fK v/s ρ
( b ) γ fK v/s K
( c ) γ fK v/s
Figure 3 : Variation of ρ,number of patterns K and size of patterns vary .
, for algorithm 1,as confidence
γ fK
0 0.2 0.4 0.6 0.8 1 0.05 0 0.05 0.1 0.15 0.2 0.25 0.3γ / fKConfidence Parameter ( ρ)accidentschessconnectkosarakmushroompumsbpumsb starretailT10I4D100KT40I10D100K 0 0.2 0.4 0.6 0.8 1 10 20 30 40 50 60 70 80 90 100γ / fKNumber of Patterns ( K)accidentschessconnectkosarakmushroompumsbpumsb starretailT10I4D100KT40I10D100K 0 0.2 0.4 0.6 0.8 1 1 1.5 2 2.5 3 3.5 4 4.5 5 5.5 6γ / fKSize of Patterns ( l)accidentschessconnectkosarakmushroompumsbpumsb starretailT10I4D100KT40I10D100K ( a ) η fK v/s 2
Figure 4 : Variation of ( η fK parameter Kvary .
) under algorithms 1 and 2as DP 2 , confidence parameter ρ and number of patterns
( a ) FNR v/s K
( a ) Algorithm 1
Figure 6 : Variation of FNR under algorithm 1as K and are varied .
( b ) FNR v/s
( b ) Algorithm 2
Figure 7 : FNR obtained while comparing our algorithms 1 and 2 with the FRAPP framework
Figure 5 : Variation of FNR as epsilon varies : FNR v/s 2
0 0.2 0.4 0.6 0.8 1 0.01 0.1 1 10η / fKPrivacy Parameter ( ε / 2)accidentschessconnectkosarakmushroompumsbpumsb starretailT10I4D100KT40I10D100K 0 0.2 0.4 0.6 0.8 1 0.01 0.1 1 10False Negative RatePrivacy Parameter ( ε / 2)accidentschessconnectkosarakmushroompumsbpumsb starretailT10I4D100KT40I10D100K 0 0.2 0.4 0.6 0.8 1 0.01 0.1 1 10False Negative RatePrivacy Parameter ( ε / 2)accidentschessconnectkosarakmushroompumsbpumsb starretailT10I4D100KT40I10D100K 0 0.2 0.4 0.6 0.8 1 10 20 30 40 50 60 70 80 90 100False Negative RateNumber of Patterns ( K)accidentschessconnectkosarakmushroompumsbpumsb starretailT10I4D100KT40I10D100K 0 0.2 0.4 0.6 0.8 1 2 2.5 3 3.5 4 4.5 5 5.5 6False Negative RateSize of Patterns ( l)accidentschessconnectkosarakmushroompumsbpumsb starretailT10I4D100KT40I10D100K2253354455556051015Itemset lengthFalse Negative Rate ( % ) ExponentialLaplaceRAN−GD ( FRAPP)DET−GD ( FRAPP )
