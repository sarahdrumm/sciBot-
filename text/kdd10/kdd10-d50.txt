Discovery of Significant Emerging Trends
Saurabh Goorha Dow Jones & Co .
Lyle Ungar
Dept . of Computer & Information Science
Princeton , NJ
SaurabhGoorha@dowjonescom
ABSTRACT We describe a system that monitors social and mainstream media to determine shifts in what people are thinking about a product or company . We process over 100,000 news articles , blog posts , review sites , and tweets a day for mentions of items ( eg , products ) of interest , extract phrases that are mentioned near them , and determine which of the phrases are of greatest possible interest to , for example , brand managers . Case studies show a good ability to rapidly pinpoint emerging subjects buried deep in large volumes of data and then highlight those that are rising or falling in significance as they relate to the firms interests . The tool and algorithm improves the signal to noise ratio and pinpoints precisely the opportunities and risks that matter most to communications professionals and their organizations .
Categories and Subject Descriptors I27 [ Artificial Intelligence ] : Natural Language Processing , Text Analytics
General Terms Algorithms
Keywords Text Mining , Sentiment Detection , Trend Detection , Entity Extraction , Brand Management , Buzz , Communication , Competitive Intelligence , Reputation Management , Social Media
1 . INTRODUCTION Companies want to be able to quickly discover what the media , including twitter , blogs , and the mainstream press , are saying about a company or a product . Since popular products are mentioned thousands of times in the press , simple collation and summary of known mentions , while useful , limits knowledge about unknown issues . Further having humans read and summarize the reports quickly and cost effectively is not always
University of Pennsylvania ungar@cisupennedu identification of emerging practical . We present in implemented system for what we term “ discovery ” : automatic topics associated with products of interest . In our system , implemented as part of the Dow Jones product1 for communication professionals , the user specifies a fixed set of products or other companies that they are interested in tracking , and a corpus of documents from which trends are to be discovered . We then identify “ interesting/significant ” phrases that occur near the terms of interest . Note that the products are described by a fixed set of names specified by the user , but the phrases can be anything , and , in fact , often have never been seen before . Defining what phrases are interesting is a key question that this paper addresses . As described in detail below , interesting phrases show a dramatic increase in usage , are mentioned sufficiently frequently , and are sufficiently specific to a given topic area . Identifying interesting phrases is important for brand and communication professionals answer one of the most pressing questions for the firm : “ What is the next big threat to/opportunity for my business ? ” A key challenge in today ’s plethora of media content is to offer a tool that can help improve the signal to noise ratio by cutting through thousands of issues and opportunities emerging in relation to their organization and pinpointing the ones that might be worthy of attention and action . With it , communications professionals , as well as other professionals within a firm ( eg Competitive Intelligence ) can detect off theradar and emerging issues faster and act quickly on hidden opportunities and possible threats to companies , brands , and people . A tool designed to improve signal to noise can be used to answer different questions and detect different issues :
1 . A global bank can track threats ( eg credit card frauds ) , which can emerge in any region of the world , and in a specific form of media ( eg social media ) , and monitor the buzz around the topic moving forward .
2 . An oil major uses knowledge of an industry specific topic in media ( eg alternative fuel sources ) as a leading indicator and reviews intelligence generated proactively to help assess how competitive their firm is in their markets .
1 The product based on the methodology presented in this paper was launched Q4 2009 and is now commercially available
57 3 . A technology consulting firm focuses on emerging issues , threats and opportunities in industries in which they sell their services to identify companies , as well as topics , that are suddenly generating significant coverage in the media . like Twitter have services
A variety of companies like “ trendingtopics ” that track which phrases are most increasing in use . Recent work [ 9 ] has expanded such phrase tracking to monitor phrases as they are posted and modified . We contribute to the field of detecting and tracking emerging phrases or trends by developing better methods for determining which phrases out of the hundreds of thousands of new phrases used daily ( or weekly ) are most likely to be “ interesting ” to users . 2 . METHODOLOGY Our discovery method has the following steps :
Input : The user specifies a fixed set of products or other companies that they are interested in tracking , on an aggregated corpus of documents which is continually updated Identify phrases , groups of words that occur together more often than would be expected by chance .
2 ) Extract phrases occurring near the terms of interest . 3 ) Determine which phrases are “ exploding ” ( dramatically
1 )
4 ) Determine which of the exploding phrases are most increasing in usage ) interesting based on i . how often they are mentioned ii . how much more often they are mentioned now than before iii . how specific they are to a given topic
5 ) Present the results to the user .
We present a detailed case study , which illustrates how our method works . Consider a user working for Apple computer . They might choose to monitor articles , blogs , and tweets relating to the IT industry , to monitor a set of companies including Apple , Microsoft , HP , and Dell and to monitor a set of products including the iPhone , iPod and Macintosh . Phrases from all articles relating to the companies and products are extracted using an entity extraction system . The system automatically identifies and extracts key entities such as people , dates , places , companies or other things from the text data source , in multiple languages , based on queries crafted on the companies ( eg Apple ) or products ( eg iPhone ) . Phrases occurring within a narrow window ( <100 characters ) of the target products are extracted and counted . A phrase is determined to be “ exploding ” in a given corpus ( for example , either the IT industry or specific to the iPod ) if the phrase has :
1 ) occurred more than a specified minimum number of
2 ) 3 ) times today , recently occurred more than a specified number of times increased by more than a specified percentage over its recent occurrence rate
The goal of restriction 2 is to avoid “ one day wonders ” , where an article is widely published on one day , but does not lead to any follow up articles . Values for the parameters are customizable ( eg at least eight occurrences , comparison against the past three weeks , and at least a 50 % increase in mention frequency . ) We then determine which of the phrases are interesting/significant . For a phase to be interesting and it should both be mentioned frequently , and should be relatively unique to the product with which it is associated . We trade off these two criteria by taking the ratio of the number of times a phrase occurs in connection with the product of interest to the number of times it occurs overall in the corpus raised to a power . We use ( # mentions with phrase)/(# mentions overall)095 If the exponent were one , this would compute the fraction of times the phrase occurs specifically with the product of interest . This fails to take into account the overall frequency of occurrence of the phrase , and leads to far too many rare phrases being included . If the exponent were zero , this would rank the phrases by how often they occur with the product ; this has the disadvantage of neglecting whether the phrase is specific to the product . Our power law formula gives a good trade off between these.2 Looking for “ interesting ” phrases occurring with iPod gives , for <04/01/2009 to 04/23/2009> the list shown in figure 1 . The top terms identified are a combination of frequently mentioned terms such as “ ATT : and ” baby shaker ” and terms that are particularly exclusive to iPod . Of these top 10 terms , the one that is by far of highest actual interest is “ baby shaker ” , which described as an application for the iPod which cries like a baby until it is shaken . Although this application was released by a third party and not by Apple , it generated a tremendous amount of press , and resulted in Apple officially releasing an apology . It is such terms that identify such potentially contentious problems that users are most eager to identify rapidly . In order to achieve high performance , a number of technical details needed to be addressed . The number of articles that mention a given product and phrase is not a perfect indicator of their interest . Newspaper articles are often duplicates or near duplicates of each other ; many different papers pick up the same article from the newswire services such as Dow Jones Newswires or Associated Press ( AP ) . One could run duplication detection and then count duplicates as less important than unique articles . We have found , however , that most such large scale duplications occur in what we call “ one day wonders ” : news articles that are widely shown on one day , but vanish in the next day . Thus , for mainstream news we do not report potentially interesting phrases unless they appear days in a row .
2 We had initially planned to use a more formal statistical method ( eg , a Bayesian model such as Latent Dirichlet Allocation ; see the “ Related Word ” section ) to determine novelty and interestingness . Also attractive in principle , in practice the standard probabilistic models require making strong distributional assumptions , and specifying at least as many parameters as our simpler models , giving no benefit in spite of their much higher computational cost .
58 in
# IT Indus try
# with iPod Ratio
Powerlaw
403 269 884 88 177 740 60 58 55
405 273 972 88 186 842 60 58 55
0.995 0.985 0.909 1 0.952 0.879 1 1 1
Term ipod discussion 1.30 forum 1.30 sfr 1.28 baby shaker 1.25 family plan 1.24 store 1.23 att 1.23 austin , texas 1.23 exclusive deal zen bound 1.22 Figure 1 . Interesting terms found to be exploding in connection with iPod . The column labeled ratio is the ratio of the preceding two columns : iPod over IT industry . The column labeled power law gives our interestingness result . Figure 2 shows similar results for Hewlett Packard . One can see that several topics of potential importance to HP have been identified . The term with the highest interestingness score , “ moorjani ” , is a financial analyst who made some widely reported comments about HP . The next three terms relate to a problem with recalled lithium ion batteries , and the last term , clearly , to printing supplies . Each of these identified terms is linked back to key documents from which they were extracted , so that users can determine what it is that people are concerned with . For example , HP can see what Moorjani is writing about the company , and what the concern about printing supplies is ( that their market is soft , potentially effecting HP profits ) . _________________________________________________ Score Term 1.22 moorjani 1.21 recalled battery 1.21 burn hazard 1.20 recalled lithium ion batteries 1.20 printing supplies Figure 2 . Top five terms associated with Hewlett Packard during 04/01/2009 their associated interestingness scores . to 04/23/2009 and
_____________________________________________________ Once an interesting term is identified , it is often desirable to track its growth and decay . A key question is : what determines if a term remains interesting . Terms typically go through a life cycle where they rise fairly rapidly in popularity and then decline somewhat more slowly over time . The speed of decline is often proportional to the speed of the rise . Once a term has been identified as exploding and being interesting , we track it until it drops back close to its pre exploding occurrence levels .
3 . USER INTERFACE DESIGN Any data driven tool requires simple visualization which can help users quickly identify trends , patterns , and relationships between issues and topics identified . This is even more important with this tool , given the large volume of content being processed on a daily basis . Because a given user may be interested in tracking many companies and products , interactive visualization of the results is critical . The application surfaces new significant/interesting terms in an interactive and customizable flash bubble chart . The size of the bubble indicates relative interestingness of discovered terms . Figure 3 shows an example screenshot . One potential challenge when collating and collecting results is the chance of clutter in the UI when large numbers of exploding terms are identified . This is addressed by listing all the exploding terms in the form of a list view in the visualization with users able to review and deselect the irrelevant terms from the view . In addition , users can zoom in to a specific area within the visualization to narrow their view of terms . Figure 4 shows an example screenshot with list view of terms . The cross fertilization between social and mainstream media is an important aspect for users . Emerging issues can predominate in one form of media and become viral . Users typically need a snapshot view of the media types that are driving the issue . Figure 5 shows an example screenshot of the split between mainstream and social media on an issue . Once users have understood the issue and the media split where the issue is being discussed , they prefer to deep dive into the underlying news and read the actual articles specific to a media type . This lets users for their own opinion and views on the overall message being conveyed in the articles . Figure 6 shows an example screenshot of the product page where the users can select and read specific articles .
59
Figure 3 . Sample Dow Jones solution screenshot .
Figure 4 . Sample Dow Jones solution screenshot , with list views enabling users to select specific terms to view in the form of bubbles chart
60
Figure 5 . Sample Dow Jones solution screenshot , with breakdown of coverage between mainstream and social media for a discovered term
Figure 6 . Sample Dow Jones solution screenshot , with article headlines categorized by specific source types and source groups . Users can read the complete article by clicking on the headline .
61 4 . CLUSTERING The most obvious potential improvement in our method would be to cluster together related terms , presenting the user with emerging stories or topics , rather then emerging phrases . This can greatly reduce the number of phrases that the user needs to examine . Preliminary work in this direction shows that clustering phrases based on co occurrence gives a sensible set of related phrases , and can substantially help with interpretation of what the phrases ( eg “ moorjani ” ) refer to . However , due to the sparseness of the data , even fairly widely covered stories still result in more than one or two clusters of phrases ; perfect clustering is not possible . To explore the benefit of clustering , we took the phrases identified in the proximity of each occurrence of the target product or company as an “ observation ” and clustered these observations based on the similarities , calculated using the standard TF/IDF weighted cosine measure . Because the number of observations can be quite large , we used a highly scalable streaming clustering algorithm [ 5 ] . Figure 7 shows the “ interesting phrases ” in the most interesting clusters resulting for Hewlett Packard . ( The interestingness of a cluster is taken to be the maximum of the interestingness scores of the phrases in it . ) The first cluster relates to a set of comments on a financial analyst by the name of Dinesh Moorjani . Note that the cluster includes different versions of his name , phrases relating to computer demand and sales and consumer spending , and phrases relating to topics more specific to HP such as printing supplies and printer ink . The clustering does an excellent job of identifying related terms such as “ printing supplies ” and “ printer supplies ” ( which could identified by stemming algorithms ) , “ weak spending ” and “ soft spending ” ( which might , with difficulty , be identified using a specialized dictionary ) and “ personal computer demand ” and “ personal computer sales ” ( which would require a sophisticated ontology of similar terms ) . Clusters two through five show any weakness of our clustering and ; all four of these clusters pertain to the same topic : a set of recalled lithium ion batteries . The clusters are good and sensible , with cluster 2 containing the key phrases relating to the product recall and cluster three capturing most of the product numbers of the recalled batteries . Ideally , these clusters would all be combined . However , data sparseness does not allow this . We experimented with using the Porter stemmer [ 16 ] to collapse words such as “ printing ” and “ printer ” to the stem “ print ” , but found that it made relatively little difference since the clustering method was already doing such a good job of grouping together words that would have been collapsed .
_____________________________________________________ 1 . 1.22 moorjani 1.20 printing supplies 1.19 personal computer demand 1.19 dinesh moorjani 1.19 analyst take 1.19 profit machine 1.19 personal computers sales 1.19 weak spending
1.18 possible pc 0.95 market share gains 0.95 printer ink 0.88 broadpoint amtech 0.78 consumer spending 0.78 computer servers 0.73 paul otellini 0.70 printer supplies 0.63 soft spending 0.62 fiscal second quarter numbers 0.61 overlapping businesses 0.56 large corporations 0.56 market closes 0.54 key developments 0.49 analyst opinion 0.43 pc sales
2 . 1.21 recalled battery 1.21 burn hazard 1.18 electronics stores 1.15 us consumer product safety commission 1.12 cpsc 1.11 minor property damage 1.09 lithium ion batteries 1.08 fire hazard 1.03 catching fire 1.03 free replacement battery 1.03 recall covers 1.00 battery packs
3 . 1.16 c700 1.16 recalling lithium ion batteries 1.15 f700 1.15 v3500 1.15 g6000 1.15 v3700 1.15 v6500 1.05 v3000 1.00 notebook computer batteries
4 . 1.16 g7000 0.71 notebook batteries 0.61 recalled batteries
5 . 1.20 recalled lithium ion batteries 1.07 health canada
Figure 7 . Five clusters from the same date for phrases of interest occurring in connection with Hewlett Packard . The number to the left of each phrase is the interestingness score as defined above . _____________________________________________________
5 . RELATED WORK Work similar in spirit to this work has long been done under the name of “ Topic Detection and Tracking ” ( TDT ) [ 1 ] or
62 “ Emerging Trend Detection ” [ 8 ] where news articles are clustered into groups about the same topic , and researchers attempt to discover new topics as they emerge . Our work differs from the TDT work in the application to business , rather than military intelligence and , more importantly , in that our method focuses on finding the most interesting emerging phrases of interest , rather finding all emerging sets of related documents . We believe that phrases are an attractive level at which to work for this application . Phrases such as ” recalled battery ” or “ printer supplies ” or “ shaken baby ” are far more specific and informative that the individual words ( “ recalled ” , “ batter ” , “ printer ” , etc . ) of which they are composed . Clustering at the level of documents , as is done in projects ranging from the TDT to Google News is a reasonable alternative to identifying phrases , offering potentially better recall due to lower sparsity . However , increased recall comes at some cost in precision . Regardless of whether trends are identified in phrases or documents , one needs to determine which of the many emerging topics are potentially significant to users . One cannot simply present all statistically significant emerging phrases or clusters , even using a good interactive interface ; there are simply too many of them . We process millions of unique novel phrases each year ; analysts or users cannot even skim that many phrases . Earlier work on topic detection ignores the question of what is interesting or , like Google News , assumes that “ interesting ” is synonymous with “ occurs more ” . By taking into account the specificity of the emerging phrases to products and subject areas of interest , we filter out the vast number of phrases that have increased frequency , highlighting those most likely to actually be significant . A number of researchers have applied more rigorous probabilistic models to the problem of identifying topic trends in document collections , often using variations on the Latent Dirichlet Model ( LDA ) . LDA is a good choice because it does not require specifying the number of topics in advance . The vast majority of this work looks retrospectively at an entire collection of documents [ 2 , 17 ] rather than looking in real time at emerging topics , but LDA can be modified to be an online algorithm [ 10 ] . None of the above methods address the question of which of the topics or emerging trends are likely to be of interest to an analyst . As such they ( quite apart from difficulties in scaling to the large corpora we work with ) fail to address our major concern : finding significant emerging trends . 6 . CONCLUSIONS AND FUTURE WORK We presented a method of identifying significant emerging phrases associated with products , companies , or people of interest . The method is broadly applicable , applying to a broad range of content type : not just The Wall Street Journal and The Times , but also emerging social media ( eg Twitter ) , and to phrases associated with politician as well as products . Our choice of choice of algorithm was driven , in part , by efficiency considerations , as we process over 100,000 new articles per day from a heterogeneous mix of mainstream ( eg , business news vs . financial news ) and social media ( eg , blogs vs . discussion boards vs . tweets ) sources . The product based on the methods described above is now being used by a number of clients , and is proving able to rapidly detect emerging stories of interest to the clients . For example , we were able to detect in the social media the story that Apple lost a prototype iPhone ( which Gizmodo acquired and publicly described ) before the story hit the mainstream press . Here , as in the case studies presented above , key phrases like "lost phone" are of high significance when associated with iPhone , but do not show up with related products . Several factors contribute to determining what emerging topic or phrase might be most interesting to a given user . First , the topic or phrase must be relevant to the user , in our case , being associated with products , people or companies specified by the user . Second , the use of the phrase must be significantly increased compared to historic base rates . However , we found that determining what is interesting requires more than just seeing whether the phrase is used more often now than it was historically . Due to the Zipfian distribution of words , new phrases are continually being seen . We observe that most such increased usages are not interesting to users . A key additional criterion is that the “ bursting ” phrases be more often associated with a product of interest than with other similar products . We presented an empirically verified formula for computing interestingness , trading off novelty and topic specificity . A number of enhancements could be made to the above discovery process . We have focused on the rapid identification of “ hot ” breaking concerns . Similar methods could be applied for more slowly developing trends ( eg Atkin ’s diet, ) . The parameters in the algorithm can be modified to use the longer time horizons needed to capture these “ simmering ” trends . No fundamental changes are needed . In fact , some concerns vanish : there is no longer any need to filter out “ one day wonders . ” One could also supplement our system by adding in sentiment analysis to estimate the strength and direction of sentiment ( positive or negative ) about the topics identified . One might expect stronger sentiment to correlate with higher interest from users . Note that because we identify specific short regions of text , we have the advantage that the sentiment would be associated with the specific product attributes in the sprit of [ 3,7,15 ] , not with the news article as a whole as is more commonly done with product reviews [ 6,14 ] . Finally , it would be attractive to obtain more objective measures of “ interestingness ” such as forecasting future rates of occurrences of identified phrases in media or communications of interest . One key question is how often one can identify emerging topics in social media before they are taken up by the mainstream press . Other work [ 6 ] suggests that most , but not all , phrases flow from the mainstream press to blogs . However , feeds from sources like twitter are typically faster than those from mainstream media , and so may still provide useful leading indicators of emerging hot topics . 7 . REFERENCES [ 1 ] J . Allen . Topic detection and tracking : event based information organization , Kluwer . 2002 .
[ 2 ] D . Blei and J . Lafferty . Dynamic topic models . In
Proceedings of the 23rd International Conference on Machine Learning , 2006
[ 3 ] R . Feldman , M . Fresko , J . Goldenberg , O . Netzer and L .
Ungar . “ Extracting Product Comparisons from Discussion Boards , ” Proceedings of ICDM 2007 , Omaha , NB . 2007 .
63 [ 4 ] N Glance , M Hurst , T Tomokiyo BlogPulse : Automated trend discovery for weblogs . WWW 2004 Workshop on the Weblogging Ecosystem . 2004 .
[ 5 ] S . Guha , et al . , “ Clustering Data Streams : Theory and
Practice , ” IEEE Trans . Knowl . Data Eng . 15(3 ) : 515 528 . 2003 .
[ 6 ] M . Hu and B . Liu . “ Mining and Summarizing Customer
Reviews , ” Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pp . 168–177 . 2004 .
[ 7 ] N . Jindal and B . Liu . “ Mining comparative sentences and relations ” Proceedings of AAAI'06 . 2006 .
[ 8 ] A . Kontostathis , L . Galitsky , W . M . Pottenger , S . Roy , and
D . J . Phelps . A survey of emerging trend detection in textual data mining . in Survey of Text Mining , pp 185–224 . 2003
[ 9 ] J . Leskovec and J . Kleinberg . “ Meme tracking and the
Dynamics of the News Cycle , ” KDD 09 . 2009 .
[ 10 ] Loulwah AlSumait , Daniel Barbará , Carlotta Domeniconi ,
"On line LDA : Adaptive Topic Models for Mining Text Streams with Applications to Topic Detection and Tracking," Eighth IEEE International Conference on Data Mining ( ICDM ) , pp . 3 12 . 2008 .
[ 11 ] A . McCallum . “ Information Extraction : Distilling Structured
Data from Unstructured Text , ” ACM Queue , 3(9 ) . 2005 .
[ 12 ] A . McCallum and W . Li . “ Early Results for Named Entity
Recognition with Conditional Random Fields , Feature Induction and Web Enhanced Lexicons , ” Proceedings of CoNLL 2003 , Edmonton , Canada , pp . 188–191 . 2003
[ 13 ] D . Miller , R . Schwartz , R . Weischedel and R . Stone . “ Named
Entity Extraction from Broadcast News , ” Proceedings of DARPA Broadcast News Workshop , Herndon , VA . 1999 .
[ 14 ] B . Pang , L . Lee and S . Vaithyanathan . “ Thumbs up ?
Sentiment Classification Using Machine Learning Techniques , ” Proceedings of EMNLP 02 , 7th Conference on Empirical Methods in Natural Language Processing , Association for Computational Linguistics , Morristown , US , pp . 79–86 . 2002 .
[ 15 ] A M Popescu and O . Etzioni . “ Extracting Product Features and Opinions from Reviews , ” Proceedings of HLT EMNLP , pp . 339–346 . 2005 .
[ 16 ] MF Porter . “ An algorithm for suffix stripping , ” Program ,
14(3 ) pp 130−137 . 1980 .
[ 17]Wang , X . and McCallum , A . Topics over time : a non
Markov continuous time model of topical trends , Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining ( KDD ) pp . 424 – 433 . 2006 .
64
