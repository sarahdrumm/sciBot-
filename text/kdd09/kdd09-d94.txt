Learning Patterns in the Dynamics of Biological Networks
Chang hun You , Lawrence B . Holder , Diane J . Cook
School of Electrical Engineering & Computer Science
Washington State University
Box 642752 , Pullman , WA 99164 2752
{changhun , holder , cook}@eecswsuedu
ABSTRACT Our dynamic graph based relational mining approach has been developed to learn structural patterns in biological networks as they change over time . The analysis of dynamic networks is important not only to understand life at the system level , but also to discover novel patterns in other structural data . Most current graph based data mining approaches overlook dynamic features of biological networks , because they are focused on only static graphs . Our approach analyzes a sequence of graphs and discovers rules that capture the changes that occur between pairs of graphs in the sequence . These rules represent the graph rewrite rules that the first graph must go through to be isomorphic to the second graph . Then , our approach feeds the graph rewrite rules into a machine learning system that learns general transformation rules describing the types of changes that occur for a class of dynamic biological networks . The discovered graph rewriting rules show how biological networks change over time , and the transformation rules show the repeated patterns in the structural changes . In this paper , we apply our approach to biological networks to evaluate our approach and to understand how the biosystems change over time . We evaluate our results using coverage and prediction metrics , and compare to biological literature .
Categories and Subject Descriptors I26 [ Artificial Intelligence ] : Learning ; J.3 [ Life and Medical Science ] : Biology and genetics
General Terms Algorithms
Keywords Dynamic Network Analysis , Graph Mining , Biological Network , Graph Rewriting Rule
1 .
INTRODUCTION
There are many data that can be represented as graphs , where vertices represent entities and edges represent relationships between entities . Moreover , many of them have dynamic properties such that the structure of graphs can be changed over time . Our bodies are well organized and vigorous systems , which promote reproduction and sustain our lives . These well organized systems can be defined by the attributes and structural properties of biological networks , which include various molecules and relationships between molecules . Vigorous systems refer to dynamic properties of biological networks , which continuously change , while an organism performs various biological activities . Therefore , analysis of the dynamics of biological networks is necessary to understand biosystems .
Our approach first learns how one graph is structurally transformed into another using graph rewriting rules , and abstracts these rules into abstract patterns that represent the dynamics of a sequence of graphs . Our goal is to describe how the graphs change over time , not merely whether they change or by how much . In this way , our approach can help us understand the dynamics of biological networks .
This paper introduces our definition of graph rewriting rules and more general transformation rules . We also present our two step algorithm to discover graph rewriting rules in a dynamic graph , and transformation rules in the discovered graph rewriting rules . In our experiments , we generate several dynamic graphs using the KEGG pathway database [ 9 ] in combination with the artificial generation and real data sets . We apply our approach to the pathways to understand how the biosystems change over time . We evaluate our results using coverage and prediction metrics , and compare to biological literature . Our results show important patterns in the dynamics of biological networks , ie , discovering known patterns in the networks . Results also show the learned rules accurately predict future changes in the networks .
2 . RELATED WORK
A graph is a natural way to represent biological networks . There are several graph mining approaches to biological networks [ 10 , 11 , 24 ] . These approaches represent biological networks as graphs , where vertices represent molecules and edges represent relations between molecules , and discover frequent patterns in these graphs . They discover structural features of networks , but they overlook temporal properties . There is much research work on the dynamics of biosystems , such as mathematical modeling [ 16 ] and microarray analysis [ 22 ] . Mathematical modeling is an abstract model
Dynamic Graph
Ri
Sub
Sub
( B )
Gi
Ai+1
Gi+1
( A )
( C )
G1
R1
A2
R2
Rn 1
G2
A3
An
Gn
G1
G5
G7
G11
Sub
Sub
( D )
Figure 1 : A framework of dynamic graph analysis . ( A ) A dynamic graph ( B ) Learning graph rewriting rules from two sequential graphs . ( C ) Learning the entire set of graph rewriting rules . ( D ) Learning a transformation rule to abstract the learned graph rewriting rules ( eg , Sub is removed from Gi and then added back in Gi+4 ) . to describe a system using mathematical formulae . They model the kinetics of pathways and analyze the trends in the amounts of molecules and the flux of biochemical reactions . The microarray is a tool for measuring gene expression levels for thousands of genes at the same time [ 3 , 15 ] . Microarrays can also monitor patterns in gene expression levels over a period of time or for the different conditions . Patterns in gene expression levels can represent changes in the biological status or distinguish two different states , such as the normal and disease state . However , these two approaches disregard the structural aspect of networks .
Temporal data mining attempts to learn temporal patterns in sequential data , which is ordered with respect to some index like time stamps [ 17 ] . Temporal data mining is focused on discovery of relational aspects in data such as discovery of temporal relations or cause effect association so that we can understand how or why the object changes rather than merely static properties of the object . Temporal data mining approaches discover temporal patterns in data , but they disregard relational aspects among entities .
Several methods have addressed dynamic graph analysis . Sun et al . [ 19 ] propose a technique to discover communities and detect changes in dynamic graphs that is represented as matrix and encoding schemes . Tensor analysis is also applied to dynamic graphs [ 20 , 21 ] . Other work [ 1 , 2 , 18 ] proposes several detection measures of abnormal changes in the sequence of graphs and graph distance measures between two graphs . They can measure how much two graphs are different , but not show how they are different . Lahiri et . al . [ 13 , 14 ] introduce an approach to predict the future structure in a dynamic network and mine periodic patterns using frequent subgraphs . Our approach uses a compression based metric instead of the frequency based approach to discover patterns in a dynamic graph .
3 . PROBLEM DEFINITIONS
In this section , we define the graph rewriting rule and the transformation rule to describe the dynamic of a graph . Graph rewriting rules represent topological changes between two sequential versions of the graph , and transformation rules abstract the graph rewriting rules into the repeated patterns that represent the dynamics of the graph . Figure 1 shows a framework of our approach . The dynamic graph contains a sequence of graphs that are generated from sampling snapshots of the graph from a continuously changing graph , ie , a sequence of graphs represent one biological
G1
A ab
B bc bd
R
G2
C
S ce
C ce cd
E
D de
S cd
E fg
D de
A
G de
F
Figure 2 : An instance of graph rewriting rules between graph G1 and G2 . network that changes its structure over time . First , our approach learns graph rewriting rules including removals ( Ri ) and additions ( Ai ) between two sequential graphs Gi and Gi+1 ( figure 1 ( B) ) , and generates a list of the entire graph rewriting rules ( figure 1 ( C) ) . Then , the final step is to learn the transformation rules to abstract the structural change of the dynamic graph based on the repeated patterns in the graph rewriting rules .
3.1 Graph Rewriting Rules
First , we briefly describe graph rewriting rules for our approach with an example in figure 2 . In our research , a graph G denotes the directed labeled graph that is defined as G = ( V , E , Lv(V ) , Le(E) ) , where V is a set of vertices , E is a set of edges . To discover graph rewriting rules between two graphs , we first discover maximum common subgraphs ( denoted by S ) between two sequential graphs G1 and G2 . Then , we derive removal ( remainder in G1 denoted by R ) and addition subgraphs ( remainder in G2 denoted by A ) . Our graph rewriting rules also contain connection edges . The connection edges are edges , which are used to link removal ( or addition ) subgraphs to the original graphs . The edges with boxed labels in figure 2 represent the connection edges between G1 ( G2 ) and removal subgraph R ( addition subgraph A ) . The connection edges are important because they show how the subgraphs are connected to the original graphs . There can be more than one connection edge linking one subgraph to the original graph . The connection edges represent relations between the learned patterns and other elements in the input networks .
Formally , we define DG = {G1 , G2 , · · · , Gn} as a dynamic graph , where each graph Gi is a graph at time i for 1 ≤ i ≤ n . For two consecutive graphs Gi and Gi+1 , we define Si,i+1 as the maximum common subgraph between Gi and Gi+1 . Si,i+1 can be a disconnected graph , ie , describing the set of connected subgraphs common to Gi and Gi+1 . Then , we define a graph rewriting rule GRi,i+1 as follows .
GRi,i+1 = {(Ri , CRi ) , ( Ai+1 , CAi+1 )}
Then , a removal subgraph Ri and an addition subgraph Ai+1 are defined as follows .
Ri = Gi\Si,i+1 , Ai+1 = Gi+1\Si,i+1
CRi and CAi+1 are the sets of connection edges for Ri and Ai+1 respectively . The graph rewriting rule GR1,2 in figure 2 can be represented as follows .
GR1,2 = {(R1 , {(s2 , g3 , bc ) , ( s2 , g4 , bd)} ) ,
( A2 , {(g3 , s1 , de)})} ,
The graph R1 denotes R ( in G1 ) that is linked by two connection edges labeled by ‘bc’ and ‘bd’ . A2 denotes A ( in G2 ) that is linked by one connection edge labeled by ‘de’ . In each edge , sX and gY denote the starting and ending vertices , where s denotes the vertex in the subgraph and g denotes the vertex in the original graph .
After iterating this process for n graph , ie , the entire sequence in the dynamic graph , we have n − 1 Rs and n − 1 As as shown in figure 1 ( C ) . Here , we consider a set of graphs L that is a list of graph rewriting rules learned in DG . L contains n−1 Rs and n−1 As like L = {R1 , A2 , R2 , A3 , · · · , Rn−1 , An} . We arrange R and A in order of time when the event occurs . 3.2 Transformation Rules
Next , we discover transformation rules in the learned graph rewriting rules to abstract the structural changes in the dynamic graph as shown in figure 1 ( D ) . A transformation rule is defined as a pattern in the learned graph rewriting rules , where the pattern best abstracts ( compresses ) the learned graph rewriting rules to best describe structural changes . More description will be in section 4 . If some structural changes are repeated in the dynamic graph , there exist common subgraphs in the Rs and As . Then , we can discover the common patterns over L as our transformation rules . Biologically speaking , if there exists a repeated change of the structure of a biological network , the change can be an important pattern in the network . Here , we propose one simple transformation rule T R , which represents repeated additions and removals ( or vice versa ) , as follows .
T Re = Subeh+ta , −tri
In the case when the transformation rule represents only repeated removals ( or additions ) , −tr ( or +ta ) would be ∅ , like Subh−tri ( or Subh+tai ) . Sub represents a subgraph , which adds to and/or removes from the graph repeatedly . +ta represents the time interval from the last removal to the current addition , and −tr represents the time interval from the last addition to the current removal . If +ta is shown before −tr , the addition precedes the removal . For instance , Subh+4 , −2i denotes a repeated structure added after 4 time intervals from the last removal and removed after 2 time intervals from the last addition as shown in figure 1 ( D ) . e denotes the number of the transformation rules in one dynamic graph . There can be multiple patterns over L to describe the structural change of the dynamic graph , where the best transformation rule that is labeled as T R1 best describes the change .
A
E
A
G1
C
C
B
B
A
A
G2
C
C
B
F
B
( A )
S1
S1
S2
S2
E
S1
S1
F
( B ) e1 e2
E
F
( C )
Figure 3 : Discovery of the best compressed subgraph in a set of graphs at iteration 1 ( A ) , 2 ( B ) , and 3 ( C ) .
There are other forms of transformation rules besides repeated add/remove rules , such as patterns conditional on context , ie , removal/addition of structure X if structure Y is present ( or absent ) , or patterns that describe numeric changes in combination with structure , ie , describing trends of concentration , not just appearance . We will consider other types of transformation rules in future work .
4 . APPROACH
This section describes our approach to analyze dynamic graphs . We present a two step algorithm : Learning Graph Rewriting Rules and Learning Transformation Rules . Algorithm 1 learns graph rewriting rules in a dynamic graph to represent how two sequential graphs are different . Algorithm 2 learns the repeated transformation rules in the learned graph rewriting rules to describe how the graph changes over time , where the changes are actually represented as a sequence of revised graphs . For both algorithms we rely on a previously developed method for finding the best compressing subgraph in a set of graphs . For the first algorithm , repeated application of this method allows us to find the set of all subgraphs common to a pair of consecutive graphs . For the second algorithm this method allows us to find the subgraphs repeatedly added and removed in the dynamic graph . While we could use a frequent subgraph miner [ 12 , 23 ] for this purpose , experiments have shown that the best compressing patterns comparably capture the complete repeated structural changes [ 25 ] .
We define the best compressing subgraphs as those which minimize the description length of the input graph after being compressed by the subgraphs based on the Minimum Description Length ( MDL ) principle [ 4 , 5 ] . Formally , the description length of the substructure S is represented by DL(S ) , the description length of the input graph is DL(G ) , and the description length of the input graph after compression is DL(G|S ) . The approach finds a substructure S that minimizes the Compression of the graph defined as follows .
Compression =
DL(S ) + DL(G|S )
DL(G )
Figure 3 shows an example of the subgraph discovery by this compression based approach . First , we can discover four instances of one common subgraph denoted by a red circle ( A ) . After discovery , we compress each instance replacing by one vertex ( S1 ) , and we iterate the discovery process . In the second iteration ( B ) , we discover two instances of the next common subgraph , and compress them by one vertex ( S2 ) . We stop the iteration because there is no more common subgraph , ie , no more compression ( C ) . 4.1 Learning Graph Rewriting Rules
In this way , mBFS identifies removal subgraphs Ri and addition subgraphs Ai+1 with connection edges . The output of Algorithm 1 includes L and C . L and C are bijective . L = {R1 , A2 , · · · , Rn−1 , An} is used in Algorithm 2 as an input . C = {CR1 , CA2 , · · · CRn−1 , CAn } is used to visualize the relations between the learned subgraphs and original graphs . 4.2 Learning Transformation Rules
Algorithm 1 : Learning Graph Rewriting Rules Input : Dynamic graph DG = {G1 , G2 , · · · , Gn} Output : Rewrite rules L , connection edgesC 1 : L = {} , C = {} 2 : for i = 1 to n − 1 do 3 : Graphs = {Gi , Gi+1} , S = {} 4 : while More compression possible do 5 : BestSub = DiscoverCommonSub in Graphs 6 : 7 : Compress Graphs by BestSub 8 : end while 9 : Find Ri = Gi\S and CRi in Gi 10 : Add Ri into L , and Add CRi into C 11 : Find Ai+1 = Gi+1\S and CAi+1 in Gi+1 12 : Add Ai+1 into L , and add CAi+1 into C 13 : end for
S = S ∪ BestSub
Using the compression based approach ( as DiscoverCommonSub in the algorithm ) , we describe our two step algorithm . Algorithm 1 shows the learning graph rewriting rules algorithm , where the entire algorithm denotes figure 1 ( C ) and the each iteration in the outer loop denotes figure 1 ( B ) . First , the algorithm initialize L and C to store removal and addition subgraphs , and connection edges . At line 3 , the algorithm prepares two sequential graphs as Graphs , and then discovers one common subgraph by the compression based approach . After compression , the algorithm discovers another subgraph at the next iteration until there is no more compression . In this way , the algorithm can discover the maximum common subgraph between two sequential graphs . After compressing the two graphs by the maximum common subgraph , the algorithm identifies removal ( or addition ) subgraphs and connection edges ( lines 9 and 11 ) using a modified Breadth First Search ( mBFS ) , which adds each edge as well as each vertex into the queues as visited or to be visited . After compression , each maximum common subgraph is replaced by one vertex Si . mBFS starts to search from one edge linked to Si to find one disconnected subgraph , and the starting edge is added into C . During the search , if there is one more edge between the disconnected subgraph and maximum common subgraph , the edge becomes the other connection edge . In this way , mBFS can find all disconnected subgraphs ( without considering the link by the connection edges ) , and they become removal ( or addition ) subgraphs . mBFS stops the search when all connected edges are added in C . For example , in figure 3 ( C ) , mBFS starts from one edge linked to S2 ( in case of G1 , choose e1 ) , and these starting edges are added into in C . Since there is one more linked edge ( e2 ) to S2 in case of G1 , e2 is added into C . Then , there is no place to visit from the vertex E , E becomes a disconnected subgraph as an addition subgraph . Since there is no place to visit from the vertex F in G2 , F becomes a disconnected subgraph as a removal subgraph .
Algorithm 2 : Learning Transformation Rules Input : L , Iter Output : BestCommonSubs,ListOf Dist 1 : while More compression possible and Iter > 0 do 2 : BestSub = DiscoverCommonSub in L 3 : Add BestSub into BestCommonSubs 4 : Calculate distance between instances of BestSub 5 : Add distance into ListOf Dist 6 : Compress L by BestSub 7 : 8 : end while
Iter = Iter 1
From the result of Algorithm 1 , we try to discover repeated rewrites as our transformation rules to better understand how graphs change over time as shown in figure 1 ( D ) . The input L contains 2(n − 1 ) graphs : n − 1 Rs and n − 1 As . Note that each example ( each R or A ) contains one or more graphs , which may not be connected to each other . We then use DiscoverCommonSub again to find common subgraphs in L ( line 2 ) . As described in figure 3 , the best common subgraph in L represents the subgraph in our transformation rule . We calculate the temporal distance between two consecutive instances of the best compressing subgraphs to describe the time at which the removal ( or addition ) occurs after the previous addition ( or removal ) at line 4 . After the discovery of the common subgraph , L is compressed by this subgraph ( line 6 ) , and the discovery process is iterated until no more compression is achieved or we reach a user defined limit Iter on the number of iterations . When the best subgraph at a latter iteration includes the best subgraph from a former iteration , the results can show the latter best subgraph includes a previously learned subgraph that is replaced by one vertex . More detail will be described with examples in the results section . In T Re , the e denotes the number of iterations . If a transformation rule is discovered in the first iteration , the rule is labeled as T R1 that is the best subgraph in L . If Iter is not specified , Algorithm 2 finds all possible T R in L . 4.3 Complexity Issue
One challenge of our algorithm is to discover maximum common subgraphs between two sequential graphs , because this problem is known to be NP complete [ 8 ] . To address this issue we use a parameter , limit , in DiscoverCommonSub to restrict the number of substructures to consider in each iteration . We can express the Algorithm 1 ’s total runtime as N1 = NDCS(T − 1 ) , where NDCS is the runtime of DiscoverCommonSub and it runs for T 1 times . Algorithm 2 ’s running time is dominated by NDCS . NDCS is restricted by limit that is calculated based on input data , specifically , the number of unique vertex and edge labels . A previous work [ 6 ] shows NDCS running with a fully connected graph in time polynomial with limit . We can avoid the worst case in our domain , because biological networks are usually sparse graphs and there are not many instances due to plenty of unique labels . But we still need to pursue reducing the running time for other domains . Also , our algorithm does not try to discover the entire set of maximum common substructures at once . In each step , the algorithm discovers a common , connected substructure and iterates the discovery process until discovering the entire set .
Graphs that represent biological networks usually contain unique vertex labels , because each vertex label usually denotes the name of the molecule . Because the maximum common subgraph problem in graphs with unique vertex labels is known to have quadratic complexity [ 7 ] , discovery of the graph rewriting rules is still feasible . However , there will be a tradeoff between exactness and computation time when analyzing very large graphs . 4.4 Evaluation Metrics
We use two metrics to evaluate the learned transformation rules . The first metric is Coverage that represents how well the rule describes the changes in the graphs . The Coverage of the BestSub discovered at iteration i in Algorithm 2 is computed as follows .
Coverage = size(BestSub ) Pg∈coveredAs,Rs
1 size(g )
2(n − 1 ) where the covered As and Rs are the addition and removal subgraphs in L that contain BestSub . The size of a graph G is calculated as size(G ) = |V | + |E| . These graphs are efficiently identified during the discovery of BestSub , avoiding the need for costly subgraph isomorphism tests . Coverage represents the portion of the learned subgraphs ( the removal or addition subgraphs ) described by the transformation rule to be based on BestSub . For example , suppose we have n = 3 graphs from which we find two graph rewriting rules . Then , we have two removal and two addition subgraphs . Assume the size of R1 is 10 , R2 is 12 , A2 is 10 , and A3 is 15 . Also assume the BestSub is found in R1 and A2 , the BestSub has a size of 5 . Coverage is computed as 5(1/10+1/10 ) = 025 Higher Coverage indicates the subgraph can describe more significant ( larger portions of ) changes . Currently , Coverage does not consider the size of connection edges ( |C| ) . Unless the subgraph is isomorphic with all AGs and RGs , Coverage < 1 .
4
We define P rediction as our second metric to evaluate the prediction capability of the learned transformation rules as follows .
P rediction =
Pi∈P d(RealSubi , P redictedSubi )
|P |
P is the set of positions where we predict the P redictedSubi will show up , RealSubi is the actual subgraph found at position i , and d(Gm , Gn ) is defined as follows . d(Gm , Gn ) =
|mcs(Gm , Gn)|
|Gm ∪ Gn| d(Gm , Gn ) is a graph distance metric by Bunke et . al . [ 2 , 18 ] , where mcs(Gm , Gn ) denotes the maximum common subgraph between Gm and Gn . In contrast to their work that defines the size of G as the number of vertices in G , we consider the number of vertices and edges defined in the previous paragraph . If two graphs Gm and Gn are isomorphic , d(Gm , Gn ) = 1 . For example , d(G1 , G2 ) in figure 3 is 11/16 ,
Static Pathway
Dynamic Graph
Dynamic Data
1 to n
Figure 4 : The generation of a dynamic graph in combination with the data of the dynamic properties . If the data of the dynamic properties has n time slices , the dynamic graph has n graphs . where mcs(G1 , G2 ) = 11 and |Gm ∪ Gn| = 16 . P rediction represents how much the predicted subgraph covers the subgraphs in the testing experiments . For example , suppose we predict a subgraph s will be shown 3 times in the testing data . Then , we discover the subgraph rs that is partially different from s at one time point ( (Grs , Gs ) = 0.5 ) , and isomorphic subgraphs with s at another time point . P rediction is computed as 05+10+0 = 05 Currently , our P rediction measure is not for a temporal prediction , ie , the exact time the subgraph appears , but for a sequential prediction , ie , whether the correct sequence of the subgraphs appears .
3
5 . EXPERIMENTS AND RESULTS
We perform four experiments to evaluate our approach using three ways : artificial generation , and combinations with two real world data sets . We generate a static graph representing the biological networks from the KEGG PATHWAY data [ 9 ] , where vertices represent compounds , genes , enzymes , relations and reactions , and edges represent relationships between vertices . Then , we use our data sets to transform the static graph to a dynamic graph as shown in figure 4 . In the artificial generation , we use a real biological network , but we remove and add some subgraphs manually to generate the dynamic graphs . In the real world data , we use the KEGG data [ 9 ] in combination with additional data to generate dynamic graphs . Because the KEGG data contains only the static structure of pathways , we need to use additional data including dynamic properties of pathways . We refer to results of two researches : one for the cell cycle signaling pathway with mathematical modeling [ 16 ] and the other for metabolic pathways with microarray data [ 22 ] . 5.1 Artificial Generation
The biological network used in the artificial generations is the Notch signaling pathway in humans generated from the KEGG data . The Notch signaling pathway contains 46 genes in our experiments , and we assume that each gene can be shown at most once at each time slice . First , we create one list that contains the names of 46 genes , and then duplicate the list for 20 time slices . For varying several conditions , we remove one or more genes at specific times . Because of the biological semantics , the removal of even one gene can cause the removal of one or more larger subgraphs . We generate four dynamic graphs , each of which has 20 time slices . The size of each dynamic graph varies : 3,380 ( 164 to 177 ) for NA , 3,350 ( 149 to 174 ) for NB , 2,733 ( 102 to 174 )
Table 1 : Coverage of the best subgraphs in Artificial Data . Data denotes the artificial biological networks . The number in each iteration denotes x ( y ) , where x denotes the number of the discovered subgraphs and y denotes the Coverage by the best subgraph discovered at the iteration . Total denotes the total Coverage .
Data T R1 NA NB NC ND
T R2 19 ( 1.0 ) NA NA 9 ( 1.0 ) 4 ( 0.032 ) 8 ( 0.16 ) 6 ( 0.15 ) 5 ( 0.125 )
T R3 NA NA 10 ( 0.05 ) 2 ( 0.045 )
Total 1.0 1.0 0.242 0.320
GErel: >
GErel: >
PPrel: |
E_to_Rel
E_to_Rel
Rel_to_E
PPrel: >
Rel_to_E enzyme
Rel_to_E
PPrel: |
Rel_to_E
G_to_E
E_to_Rel
PPrel: > hsa:3516
PPrel:
Figure 5 : The best subgraph discovered in the graph rewriting rules of the dynamic graph NB . for NC and 3,332 ( 152 to 174 ) for ND . The numbers in ( ) denote the minimum size and maximum size of a graph in a dynamic graph respectively .
The goal of the artificial generation experiment is to identify the strengths and weaknesses of our approach . Table 1 shows the coverage of the best subgraph ( our rule ) discovered at each iteration of Algorithm 2 . The first two dynamic graphs , NA and NB , can be represented by one transformation rule , because the removals and additions are simple and regular . Generally , the structural change in the dynamic graph is represented by multiple transformation rules like NC and ND . For example , NC is represented by T R1 as a portion of the coverage 016 But NA is fully covered by T R1 , ie , T R1 can describe the whole structural change .
Figure 5 shows the best subgraph discovered in the NB experiments . The instances of the best subgraphs are discovered in the 9 examples ( 4 removals and 5 additions ) . “ GErel ” denotes the relation between a gene and protein , and “ PPrel ” denotes the relation between two proteins . Therefore , the enzyme generated by a gene , hsa:3516 , has 7 relations , such as 2 relations to other genes and 5 relations to other proteins . The transformation rule including this subgraph can be visualized as shown in figure 6 . The above rhombuses denote the removals at the specified time . The below eclipses denote the additions at the specified time . The numbers on the arrow denote the temporal distance between two events : removals and additions . The first addition occurs at time 1 , and the first removal occurs after 3 time intervals . From the first addition at time 1 to the last addition at time 17 , every removal is repeated after 3 time intervals from the last addition , and every addition is repeated after 1 time interval from the last removal . The repeated transformation rule can be represented as shown in figure 6 and can be expressed as T R1 = Sub1h+3 , −1i .
As described in section 4.2 , figure 7 shows an example of a previously learned subgraph that Sub2 includes Sub1 dis
4
8
12
16
3
1
3
1
3
1
3
1
1
5
9
13
17
Figure 6 : Visualization of transformation rules including the subgraph in figure 5 .
Sub 1 component enzyme
G_to_E
Sub 2
G_to_E enzyme component group hsa:1387 hsa:9794
SUB_1
Figure 7 : Two best subgraphs discovered in ND . Sub1 is discovered at times 3 , 5 , 8 , 10 , 15 , and 18 , and Sub2 is discovered at times 3 , 5 , 8 , 15 and 18 . Sub1 is included into Sub2 as a previously learned subgraph . covered in ND . At the first iteration ( as T R1 ) , the first subgraph ( Sub1 ) is discovered at times 5 , 10 , 15 as removals and at times 3 , 8 , 18 as additions . Then , this subgraph is compressed and replaced by one vertex labeled by “ Sub 1 ” . At the second iteration ( as T R2 ) , the second subgraph ( Sub2 ) is discovered at times 5 , 15 as removals , and at times 3 , 8 , 18 as additions . Because Sub2 includes Sub1 , Sub1 is included into Sub2 as a vertex “ Sub 1 ” . In figure 7 , the dashed line arrow represents a pointer to the previously learned subgraph Sub1 from Sub2 . Biologically hsa:1387 in Sub1 and hsa:9794 in Sub2 are included into a “ group ” ( Sub1 ) as “ component ” s . Here , we discuss the advantage of the compression based subgraph discovery . In NC , the first best subgraphs are discovered 8 times . Actually , the third best subgraphs are discovered 10 times . Because the Compression of the first subgraph is better than the Compression of the third subgraph , our approach prefers the first subgraph . A frequencybased approach would prefer the third subgraph . The size of the first subgraph is 51 , and the size of the third subgraph is 5 . Also , the Coverage ( 0.16 ) of the first subgraph is larger than the Coverage ( 0.05 ) of the third subgraph . For this reason , the compression based approach can be more useful than frequent graph mining in the analysis of dynamic graphs . The detailed comparison results are in [ 25 ] .
5.2 Mathematical Modeling
We also apply our approach to a dynamic graph based on the mathematical modeling data . The dynamic graph represents the cell cycle signaling pathway [ 16 ] . The cell cycle signaling network in our experiment contains 14 molecules ( genes and compounds ) and 11 reactions between molecules . We use a threshold th to activate each compound or gene . At each time , a compound or gene , which has more than th amount , is shown in the graph . In other words , the biological network contains a portion of the 14 molecules with related reactions at each time . We normalize the concentrations of 14 molecules from 0 to 1 , because we are focused on trends in the changes , and the concentrations of different molecules vary significantly . Because the simulation is performed for 700 seconds and we take a snapshot at every 10 seconds , we have 51 time slices ( t = 1 to 51 ) of data for training and the following 20 time series for testing .
Table 2 : Results of the prediction experiments with the modified model . Name denotes the name of the case . Variable denotes the name of the modified parameter . Mod . denotes the modification ( X/Y ) , where X denotes the new value and Y denotes the default value . Size denotes the size of each dynamic graph . Transformation Rule denotes the learned transformation rule . Sub1 size denotes the size of the subgraph in the transformation rule . Coverage denotes the Coverage of the learned rule , and Prediction represents the P rediction of the learned rule .
Name
Variable Mod .
M1 M2 M3 M4 M5 M6 M7 M8 M9 M10
Average k1 k2 k4 k5 k7 k8 k10 k11 k2u tau
200/300
3/5
50/30 02/01
6/10
60/100 20/10 0.5/1 300/50 15/25
Size Transformation Rule 645 Sub1h+8 , −0i 1541 Sub1h+5 , −1i 835 Sub1h+13 , −0i 1530 Sub1h+5 , −1i 1880 Sub1h+6 , −4i 1007 Sub1h+9 , −0i 1741 Sub1h+5 , −2i 1003 Sub1h+10 , −0i 886 Sub1h+19 , −0i 1402 Sub1h+4 , −0i
Sub1 size Coverage Prediction
27 30 27 25 28 27 27 27 27 27
0.115 0.153 0.051 0.155 0.084 0.080 0.119 0.066 0.033 0.185 0.1041
1.0 0.962 1.0 1.0 1.0 0.864 0.852 0.944 1.0 1.0 0.962
Phos_Wee1
Rct_to_P
Rct:+p_CDC
Rct:CKI_Degrad
( A )
3
10
16
23
30
37
43
50
Rct:+P_1_Phos_CDC25
Rct_to_P
Rct_to_M
2 Phos_CDC25
Rct_to_M
Rct_to_R
Rct:+P_Active_Cyclin:CDK
Rct:+P_Wee1
Rct:SKP_Syn
Rct_to_M
Rct_to_M
Rct_to_M
Rct_to_P
Rct_to_R
Active_Cyclin:CDK
Cyclin:CDK_PhosCKI
Rct_to_R
Rct_to_R
Rct_to_M
Rct:CKI+Acive_Cyclin:CDK
Rct_to_P
Rct:Active_Cyclin:CDK_Degrad
Rct:+P_Cyclin:CDK_CKI
Figure 8 : The best subgraph ( Sub1 ) discovered in T R1 .
Figure 8 shows the best subgraph ( Sub1 ) in T R1 discovered at 16 time slices as visualized in figure 9 ( A ) . The vertices containing “ Rct ” in the labels denote reactions like “ Rct:+p CDC ” . The vertices without “ Rct ” denote molecules ( genes or proteins ) . The three edges , “ Rct to R ” , “ Rct to P ” and “ Rct to M ” , denote how the molecules are related to the reactions as reactant , product and modifier respectively . These results are biologically significant , because they describe the repeated structural changes in the networks . Qu et al . [ 16 ] describe periodic changes of molecules ( ie , amount of molecules ) . Specifically , they mention several molecules such as Active Cyclin:CDK and Free Cyclin that show periodic increase and decrease , where the cycles correspond to the change of the cell size . Figure 9 ( A ) shows the subgraph including Active Cyclin:CDK , that is added and removed periodically corresponding to periodic changes in the amount of the molecule . In addition , figure 8 show how the changes are related to other elements ( ie , which elements are removed or added at the same time ) as shown in the discovered subgraphs and how the subgraphs are linked to the original graphs . Our results show patterns in the structural changes , not merely changes of amount .
The Coverage is calculated as 0181 Based on this rule , we predict the future change as shown in figure 9 ( B ) . We predict 6 graph rewriting rules ( future changes ) , as we choose the predicted temporal distance based on the distances observed in training . The temporal distance and graph rewriting rules denoted by the bold fonts represent the same pat
1
6
1
5
1
6
1
6
1
6
1
5
1
6
1
2
9
15
22
29
36
42
49
( B )
57
64
70
6
1
6
1
6
1
56
63
69
Figure 9 : Visualization of the graph rewriting rules including the subgraph in figure 8 in the training data ( A ) and the testing data ( B ) . terns with the testing data . 5 patterns out of 6 predictions are same as training data . The only 6th pattern at time 70 is a non isomorphic graph with Sub1 . d(Sub1 , R70 ) is computed as 0.833 , and the P rediction is 0972 5.3 Prediction Experiment
Next , we process a simple prediction experiment . Because our research is focused on patterns in graph rewriting rules ( ie , patterns in structural changes ) , we can predict which graph rewriting rules appear ( ie , which structural changes occur ) . To evaluate prediction ability of the learned transformation rules , we perform ten prediction experiments using the above modeling data .
We modify some initial parameters in the model to generate different dynamic graphs . The modified parameters and values are shown in table 2 . Like the above modeling experiment , we use 51 time series as training and 20 time series as testing . Table 2 shows the results . M1 shows the transformation rule Sub1h+8 , −0i that describes Sub1 is added after 8 times from the last removal and is removed right after the last addition . For example , Sub1 is added at time 12 ( during the time from 11 to 12 ) , and is removed at time 12 ( during the time from 12 to 13 ) .
As shown in table 2 , the averages of the rule coverage and prediction coverage are larger than 0.9 , indicating that our approach is able to learn accurate rules across the different conditions yielding different dynamic graphs . In case of the M1 , M3 , M5 , M6 and M8 , they show relatively small coverage , because some elements in the best subgraph are
Table 3 : Dynamic graphs of metabolic pathways and results . Name denotes the KEGG IDs of pathways represented by the dynamic graphs . The second to fifth column show the information of pathways , such as the number of compounds ( cpd ) , genes ( gene ) , reactions ( rct ) and relations ( rel ) . Max . denotes the maximum size of one graph in the dynamic graph . Min . denotes the minimum size of one graph in the dynamic graph . Total denotes the size of the dynamic graph . Rule denotes the subgraph is included in the transformation rule . Coverage denotes the Coverage of the transformation rule . Run denotes the running time ( seconds ) .
Name # cpd # gene # rct # rel Max . Min . Total Rule Coverage Run ( sec . ) 10.14 00020 138.78 00230 11.78 00330 00564 12.67
3,483 Sub3 7,861 Sub2 3,528 Sub1 3,695 Sub4
0.024 0.048 0.055 0.027
30 172 14 23
20 73 19 23
17 70 21 21
73 161 25 38
251 618 176 203
46 134 60 56 enzyme
E_to_Rel
Sub 1
E_to_Rel
E_to_Rel maplink:compound
+[maplink:compound ]
+[E_to_Rel ]
+[value ]
+[cpd:C00122 ] path:sce00350 maplink:compound maplink:compound sce:YDR148C
+[enzyme ]
+[E_to_Rel ]
( Rel_to_E )
+[value ]
+[G_to_E ]
+[value ]
+[sce:YPL262W ]
+[E_to_Rel ]
+[maplink:compound ]
Sub 3
SUB_1
E_to_Rct rn:R01082
C_to_Rct enzyme
+[cpd:C16254 ]
G_to_E
Rel_to_E value value value
Rct_to_C cpd:C00149 sce:YPL262W path:sce00220 cpd:C00122
+[maplink:compound ]
( Rel_to_E ) path:sce00330
( A )
C00122
YPL262W sce00330
Figure 10 : Two best subgraphs discovered in the experiment of the TCA cycle with the microarray data . Sub1 is included into Sub3 as a previously learned subgraph . sce00350
( B ) removed ( or added ) separately . The detail discussion of this problem is in [ 25 ] . M9 contains the entire sequence of discovered subgraphs in the transformation rule , but the oscillation in M9 shows only two cycles . In most cases , the oscillation shows more than 5 cycles ( ie , figure 9 ) . Our algorithm can predict the future structural changes from the learned transformation rules of the graph rewriting rules that represent the structural changes of dynamic graphs . We will compare our result with other approaches in the future work . 5.4 Microarray Data
Now , we show the result of the dynamic graphs based on microarray data . Table 3 shows brief information of the dynamic graphs and results . In previous results we show T R1 . Here , it is a little bit different , because the pathway is bigger than the previous cases and contains many redundant labels . In the aspect of the dynamic graph mining , T R1 including Sub1 best describe the structural change . Biologically , T R1 is too general to describe the structural change . In figure 10 , Sub1 that is discovered 46 times at 20 time points contains only general information : three maplink relations ( relation between a gene ( protein ) and pathway ) and one enzyme . Without any specific name of gene or pathway , Sub1 represents too general information . For this reason , we show Sub3 ( as T R3 ) in figure 10 that contains any specific name of the gene , because our microarray data represent the trends of the gene expression values , and the gene is the only information that can be changed over time . Sub1 is included into Sub3 as a previously learned subgraph . Sub3 includes one gene ( YPL262W ) and one pathway ( sce00220 ) and one reaction ( R01082 ) and two compounds ( C00122 and C00149 ) .
Figure 11 : ( A ) A visualization of Sub3 in figure 10 . ( B ) Sub3 on a portion of the TCA cycle pathway map .
Sub3 is discovered as removals at time 14 , 23 , 26 and as additions at time 2 , 23 , 25 . Because the original microarray research [ 22 ] has only 36 time series , we do not perform the prediction task . But this experiment shows that our approach can be applied to real data , because the microarray data is generated from the yeast cells . The original result of microarray shows more than 50 % of genes have three periodic cycles in the gene expression . In our experiment , the appearance of most learned graph rewriting rules in four pathways also shows three periodic cycles like Sub3 .
Figure 11 shows the visualization of Sub3 from figure 10 to describe biological meaning of structural patterns . ( A ) shows an addition rule in our output , and ( B ) shows the same rule marked on the KEGG pathway map [ 9 ] . The labels marked by “ +[ ] ( [ ] ) ” represent the labeled vertices and edges belonging to the subgraphs of addition rules ( removal rules ) . Connection edges between the discovered substructures and original graphs are marked by “ ( ) ” . In figure 10 , we can notice the three edges labeled by “ value ” linked to C00122 , which are from the three “ maplink ” vertices in Sub1 . These three edges are marked by the red boxes in figure 11 ( A ) . The maplink denotes a relation between one gene ( X ) in a pathway ( Y ) and another pathway ( Z ) . The compound that is linked to “ maplink ” relation by “ value ” edge denotes a compound shared in two pathways ( Y and Z ) . Precisely , the compound has two relations with a gene ( X ) and another gene ( that cannot be known at this point ) in pathway ( Z ) . Figure 11 ( A ) can help us understand these relationships . C00122 is added at time 25 with relations to three maplink relations . Two relations out of three maplinkrelations are connected to the other two pathways ( sce00330 and sce00350 ) marked by the blue eclipses . These two pathways are not marked by “ [ ] ” or “ ( ) ” , because they already exist before time 25 . In other words , Sub3 is added at time 25 , and connected to two pathways by two connection edges . Microarray data [ 22 ] can show three periodic cycles in the change of the gene expression values . Our approach also can discover three periodic cycles of removals and additions of the genes ( ie , YPL262W ) . In addition to the three periodic cycles of removal and addition of one element , our results also show what other elements are related to the removed ( or added ) genes , ie , how the removed ( or added ) genes relate to others in the pathway . The connection edge can help us understand how the learned subgraphs relate to the original graph at each time .
6 . CONCLUSION
This research introduces the use of graph rewriting rules to describe structurally changing networks , and more general transformation rules abstracting the graph rewriting rules . We also present a two step algorithm to discover graph rewriting rules and transformation rules in a dynamic graph . The algorithm is evaluated with the dynamic graphs representing the biological networks in combination with the artificial generation , mathematical modeling and microarray data . The graph rewriting rules show how one graph is transformed into another . The learned transformation rules over the graph rewriting rules can describe repeated patterns in the series of the structural changes .
Our results show important patterns in the dynamics of biological networks , for example , discovering known patterns in the various networks . Results also show the learned rules accurately predict future changes in the networks . The connection edge can help us understand how the learned subgraphs relate to the original pathway at each time . Our approach also helps us visualize the change of subgraphs at each time to show how the networks structurally change , helps us better explore how networks change over time , and guides us to understand the structural behaviors of the dynamic network .
For our future work we will explore a better approach to learn transformation rules that can cover graph rewriting rules that are divided over several consecutive time slices . Also , our prediction measure needs to include a temporal distance factor to better evaluate rules in terms of predicting the precise time at which a change occurs .
7 . REFERENCES
[ 1 ] H . Bunke , M . Kraetzl , P . Shoubridge , and W . Wallis .
Detection of abnormal change in time series of graphs . J . of Intercon . Net . , 3 , Nos 1+2:85–101 , 2002 .
[ 2 ] H . Bunke and K . Shearer . A graph distance metric based on the maximal common subgraph . Pattern Recogn . Lett . , 19(3 4):255–259 , 1998 .
[ 3 ] H . Causton , J . Quackenbush , and A . Brazma . A
Beginner ’s Guide Microarray Gene Expression Data Analysis . Blackwell , 2003 .
[ 4 ] D . Cook and L . Holder . Substructure discovery using minimum description length and background knowledge . Journal of AIR , 1:231–255 , 1994 .
[ 5 ] D . Cook and L . Holder . Graph based data mining .
IEEE Intelligent Systems , 15(2):32–41 , 2000 .
[ 6 ] D . Cook , L . Holder , and S . Djoko . Scalable discovery of informative structural concepts using domain knowledge . IEEE Expert , 11:59–68 , 1996 .
[ 7 ] P . Dickinson , H . Bunke , A . Dadej , and M . Kraetzl . On graphs with unique node labels . In IAPR GBR , 2003 .
[ 8 ] M . Garey and D . Johnson . Computers and
Intractability : A Guide to the Theory of NP Completeness . Freeman , 1979 .
[ 9 ] KEGG . http://wwwgenomejp
[ 10 ] M . Koyuturk , A . Grama , and W . Szpankowski . An efficient algorithm for detecting frequent subgraphs in biological networks . In ISMB , 2004 .
[ 11 ] J . Kukluk , C . You , L . Holder , and D . Cook . Learning node replacement graph grammars in metabolic pathways . In BIOCOMP , 2007 .
[ 12 ] M . Kuramochi and G . Karypis . Frequent subgraph discovery . In ICDM , 2001 .
[ 13 ] M . Lahiri and T . Berger Wolf . Structure prediction in temporal networks using frequent subgraphs . In CIDM , 2007 .
[ 14 ] M . Lahiri and T . Berger Wolf . Mining periodic behavior in dynamic social networks . In ICDM , 2008 .
[ 15 ] D . J . Lockhart and E . A . Winzeler . Genomics , gene expression & DNA arrays . Nature , 405:827– 836 , 2000 .
[ 16 ] Z . Qu , W . MacLellan , and J . Weiss . Dynamics of the cell cycle : checkpoints , sizers , and timers . Biophys J , 85(6):3600–11 , Dec 2003 .
[ 17 ] J . F . Roddick and M . Spiliopoulou . A survey of temporal knowledge discovery paradigms and methods . IEEE TKDM , 14(4):750–767 , 2002 .
[ 18 ] P . Shoubridge , M . Kraetzl , W . Wallis , and H . Bunke .
Detection of abnormal change in a time series of graph . J . of Intercon . Net . , 3:85–101 , 2002 .
[ 19 ] J . Sun , C . Faloutsos , S . Papadimitriou , and P . S . Yu .
Graphscope : parameter free mining of large time evolving graphs . In SIGKDD , 2007 .
[ 20 ] J . Sun , D . Tao , and C . Faloutsos . Beyond streams and graphs : dynamic tensor analysis . In SIGKDD , 2006 .
[ 21 ] H . Tong , S . Papadimitriou , J . Sun , P . S . Yu , and
C . Faloutsos . Colibri : Fast mining of large static and dynamic graphs . In SIGKDD , 2008 .
[ 22 ] B . Tu , A . Kudlicki , M . Rowicka , and S . McKnight .
Logic of the yeast metabolic cycle : Temporal compartmentalization of cellular processes . Science , 310 , 2005 .
[ 23 ] X . Yan and J . Han . gspan : Graph based substructure pattern mining . In ICDM , 2002 .
[ 24 ] C . You , L . Holder , and D . Cook . Application of graph based data mining to metabolic pathways . In ICDM Workshop on DMB , 2006 .
[ 25 ] C . You , L . Holder , and D . Cook . Graph based data mining in dynamic networks : Empirical comparison of compression based and frequency based subgraph mining . In ICDM Workshop on ADN , 2008 .
