Scalable Pseudo Likelihood Estimation in Hybrid Random Fields
Antonino Freno freno@diiunisiit
Edmondo Trentin trentin@diiunisiit
Marco Gori marco@diiunisiit
Dipartimento di Ingegneria dell’Informazione
Università degli Studi di Siena
Via Roma , 56 – 53100 Siena ( SI ) , Italy
ABSTRACT Learning probabilistic graphical models from high dimensional datasets is a computationally challenging task . In many interesting applications , the domain dimensionality is such as to prevent state of the art statistical learning techniques from delivering accurate models in reasonable time . This paper presents a hybrid random field model for pseudo likelihood estimation in highdimensional domains . A theoretical analysis proves that the class of pseudo likelihood distributions representable by hybrid random fields strictly includes the class of joint probability distributions representable by Bayesian networks . In order to learn hybrid random fields from data , we develop the Markov Blanket Merging algorithm . Theoretical and experimental evidence shows that Markov Blanket Merging scales up very well to high dimensional datasets . As compared to other widely used statistical learning techniques , Markov Blanket Merging delivers accurate results in a number of link prediction tasks , while achieving also significant improvements in terms of computational efficiency .
Our software implementation of the models investigated in this paper is publicly available at http://wwwdiiunisiit/~freno/ The same website also hosts the datasets used in this work that are not available elsewhere in the same preprocessing used for our experiments .
Categories and Subject Descriptors I26 [ Artificial Intelligence ] : Learning ; H28 [ Database Management ] : Database Applications—data mining
General Terms Algorithms , Experimentation , Performance
Keywords Bayesian networks , Hybrid random fields , Markov random fields , Modularity , Scalability
1 .
INTRODUCTION
Bayesian networks ( BNs ) and Markov random fields ( MRFs ) are useful formalisms for representing joint probability distributions [ 23 , 14 ] . Important research efforts have focused on the problem of learning such models from data [ 5 , 12 , 8 , 21 ] . One major limitation of both BNs and MRFs is that , in the absence of prior knowledge , learning these models can be computationally very expensive . The hybrid random field ( HRF ) model investigated in this paper is a generalization of BNs . The aim of defining HRFs is to allow for efficient model selection in arbitrarily large domains , while retaining the flexibility of BNs and MRFs in modeling complex probability distributions . Although HRFs exploit a BN like factorization of joint distributions into a set of local conditional distributions , they factorize joint distributions into spatially ( rather than ancestrally ) related local distributions , thereby obtaining a MRF like statistical representation .
In order to reduce the computational cost of learning with respect to BNs and MRFs , the idea is to develop a structure learning algorithm which takes advantage of the modular nature of HRFs . At the same time , in order to preserve the expressive power of BNs , HRFs are designed in such a way that BNs turn out to be a special case of HRFs . This will be shown by proving that the class of distributions that can be represented by BNs is strictly included in the class of pseudo likelihood measures that can be represented by HRFs .
The paper is structured as follows .
In Sec 2 , after reviewing some concepts related to BNs , we describe the HRF formalism , and we show that BNs can be seen as a special case of HRFs . Parameter learning is addressed in Sec 3 , while Sec 4 focuses on structure learning . In Sec 5 we discuss some related work on graphical models . Sec 6 contains an experimental investigation of HRFs . The main contributions of the paper are summarized in Sec 7 .
2 . PSEUDO LIKELIHOOD
DISTRIBUTIONS
HRFs can be used to represent pseudo likelihood distributions underlying sets of random variables . A HRF is defined as follows :
Definition 1 . Let X be a set of random variables X1 , . . . , Xn . A hybrid random field for X1 , . . . , Xn is a set of Bayesian networks BN1 , . . . , BNn ( with graphs G1 , . . . ,Gn ) such that : i . Each BNi contains Xi plus a subset R(Xi ) of X\{Xi} ; ii . For each Xi , P ( Xi|X \ {Xi} ) = P ( Xi|MBi(Xi) ) , where MBi(Xi ) is the set containing the parents , the children , and the parents of the children of Xi in Gi .
319 ∗ nY i=1 nY
Clearly , MBi(Xi ) is a Markov blanket ( MB ) of Xi within BNi [ 23 ] . The elements of R(Xi ) are called ‘relatives of Xi’ . That is , the relatives of a node Xi in a HRF are the nodes appearing in graph Gi ( except Xi itself ) . We refer to condition ii in Definition 1 as the ‘modularity property’ . Based on the modularity property , the set MBi(Xi ) is a MB of Xi in X . Both BNs and MRFs assume some kind of conditional independence property . While the representation of joint probabilities in BNs is allowed by the directed Markov assumption [ 23 , 20 ] , MRFs need to assume one of the statistical conditions detailed in the Hammersley Clifford theorem [ 1 , 19 ] . Similarly , the conditional independence property entailed by HRFs is the modularity condition .
The pseudo likelihood of a given state x of the variables in X , denoted by P
∗
P
( X = x ) =
( X = x ) , is defined as follows [ 2 ] : P ( Xi = xi|X \ {Xi} = x \ {xi} )
( 1 )
Given the modularity property of HRFs , Eq 1 can be rewritten as follows :
∗
P i=1
P ( Xi = xi|MBi(Xi ) = mbi(Xi ) )
( X = x ) =
( 2 ) where mbi(Xi ) denotes the state of MBi(Xi ) . Therefore , in order to represent a pseudo likelihood in a HRF , we only need to be able to compute the conditional distribution of each node Xi given the state of MBi(Xi ) . This can be done very efficiently [ 22 ] . When needed , standard Gibbs sampling techniques can be used to extract a strict joint probability from a HRF [ 9 ] .
One detail to note concerns the presence of loops in HRFs . Loops cannot arise at the local level ( ie within the BNs ) , since this is prevented from the very use of BNs as models for the local distributions . On the other hand , loops can arise at the global level , since it may happen that two nodes point to one another if considered simultaneously in different BNs . This is not a problem at all , because of the modular nature of HRFs . Global loops do not affect the way that a pseudolikelihood is computed , since that function is factorized as a product of local distributions such that each one of them is computed independently of the remaining ones .
We now prove two theorems , which illustrate some rela tionships between HRFs and BNs .
Theorem 1 . For each Bayesian network BN , there exists a hybrid random field HRF representing the same joint distribution represented by BN .
Proof . Suppose X1 , . . . , Xn are the nodes contained in BN . Construct a HRF HRF for X1 , . . . , Xn such that , if PA(Xi ) is the set of parents of Xi in BN and PAi(Xi ) is the set of parents of Xi in BNi , then MBi(Xi ) = PAi(Xi ) = PA(Xi ) . Denoting by P ∗ HRF and by PBN the distributions represented by HRF and BN respectively , it follows that P
Qn i=1 P ( Xi|PA(Xi) ) , ie that
Qn i=1 P ( Xi|MBi(Xi ) ) =
∗ HRF ( X1 , . . . , Xn ) = PBN ( X1 , . . . , Xn ) .
In order to prove the second theorem , we need the follow ing definition [ 23 ] :
Definition 2 . An undirected graph G is said to be ‘chordal’ if for every cycle in G containing at least four edges there is at least one chord , ie an edge connecting two non consecutive nodes along that cycle .
It is known that any Markov network M RF obtained from a non chordal graph entails two conditional independence relationships such that no BN can entail both relationships at the same time [ 23 ] . The following theorem shows that the conditional independencies entailed by non chordal graphs can instead be modeled by means of HRFs : Theorem 2 . For any non chordal graph G , there exist two conditional independence statements such that no BN can entail both statements at the same time , while a HRF can always be constructed so as to entail both statements . Proof . Suppose that C = {X1 , . . . , Xn} is a subset of the nodes in G such that n ≥ 4 and C is a cycle that does not contain any chord . For any way of directing the edges in C so as to obtain a BN BN containing X1 , . . . , Xn , there will be a pair of non adjacent nodes Xi and Xj in BN sharing a common child Xk , where 1 ≤ i , j , k ≤ n . Now , the Markov network M RF resulting from G entails that Xi and Xj are independent given {Xk , Xl} ( where Xl is any node in C \ {Xi , Xj , Xk} ) , because the paths connecting Xi and Xj are blocked by {Xk , Xl} . For an analogous reason , M RF entails that Xk and Xl are independent given {Xi , Xj} . Although BN can entail the latter conditional independence by having its edges so directed that the meetings at Xi and Xj are not head to head , Xi and Xj are not d separated by {Xk , Xl} , which means that BN does not entail the conditional independence of Xi and Xj given {Xk , Xl} . Consider now a HRF HRF containing all nodes in C . Set MBi(Xi ) = MBj(Xj ) = {Xk , Xl} and MBk(Xk ) = MBl(Xl ) = {Xi , Xj} . Then , HRF entails both that Xi and Xj are independent given {Xk , Xl} and that Xk and Xl are independent given {Xi , Xj} .
The fact that HRFs generalize BNs does not mean that HRFs are a better probabilistic model than BNs . The proper conclusion we can draw from Theorems 1 and 2 is that by using HRFs instead of BNs we do not lose any representational power . On the contrary , by using HRFs we acquire the capability of representing ( if needed ) some conditional independencies that are not representable by BNs . An empirical argument to the effect that HRFs ( coupled with a particular structure learning technique ) are a reliable probabilistic tool for link prediction applications is provided by the promising results of the experiments reported in Sec 6 .
3 . PARAMETER LEARNING
In HRFs , parameter learning consists of learning the conditional probability tables ( CPTs ) of the BNs modeling the local conditional distributions , given that each Gi has been specified . We use the technique described below [ 20 ] . Since the technique applies in general to any BN , in order to denote the parents of node Xi we use the notation PA(Xi ) , rather than PAi(Xi ) .
Consider a dataset D , where each data point dj is a vector ( x1j , . . . , xnj ) . For a node Xi having no parents in the graph , we only need to estimate the absolute distribution P ( Xi ) . For each value xik of Xi , our estimate is the following : bP ( Xi = xik ) =
|{dj : Xi = xik}| + pik N
|D| + N
( 3 ) where N is the equivalent sample size [ 17 ] . In particular , we assume to have observed any particular value xik for a number of times equal to p · N , where p is the prior probability
320 that Xi = xik . In our implementation of BNs ( and HRFs ) in this work , we assign uniform prior probabilities to the different values of each variable . Therefore , we set pik = 1|Di| , where Di is the domain of variable Xi . The value we assign to N is instead max1≤i≤n |Di| . For a node Xi having parents PA(Xi ) , we need to estimate a distribution P ( Xi|PA(Xi ) = pa(Xi ) ) for each possible state pa(Xi ) of PA(Xi ) . For each value xik of Xi , the bP ( Xi = xik|PA(Xi ) = pa(Xi ) ) = |{dj : Xi = xik ∧ PA(Xi ) = pa(Xi)}| + pik Npai estimate is the following :
( 4 )
|{dj : PA(Xi ) = pa(Xi)}| + Npai
=
| , where DPAi is the set of Given N , we set Npai = N|DPAi all possible states of PA(Xi ) . As a result , each value xik of a non root node Xi turns out to have been observed exactly N|Di| times within the equivalent sample , where N|Di| = pik Npai · |DPAi| .
4 . STRUCTURE LEARNING
Structure learning in HRFs consists of learning , for each variable Xi , what other variables appear in BNi , and what edges are contained in Gi . We now present a heuristic structure learning algorithm for HRFs , which we call ‘Markov Blanket Merging’ ( MBM ) . The aim of MBM is to find an assignment of MBs MB1(X1 ) , . . . ,MBn(Xn ) to X1 , . . . , Xn that ( locally ) maximizes the model pseudo likelihood given a dataset D . The basic idea is to start from a certain assignment of relatives to the model variables , to learn the local BNs of the model , and then to iteratively refine the assignment so as to come up with MBs that increase the model pseudo likelihood with respect to the previous assignment . The algorithm stops when no further refinement of the MBs increases the model pseudo likelihood . MBM is a local search algorithm exploring a space of possible MB assignments to the model variables .
In order to develop the algorithm , we specify three components : ( i ) a way to produce the initial assignment , ie a model initialization strategy ; ( ii ) a way to refine a given assignment so as to produce an alternative assignment , ie a search operator ; ( iii ) a way to evaluate a given assignment , ie an evaluation function . These three components are described in Sec 42 Before addressing them , we specify ( in Sec 4.1 ) a general technique for learning the structure of BNs , since this technique will be used within MBM .
4.1 Learning the Local Structures
While parameter learning requires that the graph of the BN has been previously specified , structure learning aims at inferring from a dataset the graph itself ( together with the CPTs ) . A general way of formalizing this task consists in viewing it as a search problem . Given the random variables X1 , . . . , Xn , the problem space is the set of all possible directed acyclic graphs ( DAGs ) with nodes X1 , . . . , Xn , and the task is to find the DAG such that the corresponding BN maximizes a given evaluation function . Therefore , given the search space , what we have to specify is first a suitable evaluation function , and second a search strategy allowing us to effectively explore that space .
Given a BN h and a set D of patterns x1 , . . . , xm , we write
Algorithm 1 Learning the structure of a BN Input : BN h ; dataset D .
1 . do 2 . s = mdl(h )
3 . N = {n : n is a neighbor of h} = the highest scoring element of N ' 4 . h ' ' s = mdl(h 5 . ' > s ) if(s 6 . ' h = h 7 . ' 8 . while(s 9 . return h
> s )
) down the joint probability of D given h in the following way : mY nY
P ( D|h ) =
P ( Xi = xij|paj(Xi ) )
( 5 ) j=1 i=1 where paj(Xi ) stands for the state of the parents of Xi as it is determined by pattern xj . Our choice for the evaluation function is based on the minimum description length ( MDL ) principle [ 24 ] . The version of the MDL principle that we use for structure learning takes the form of the function mdl(h ) , defined as follows : mdl(h ) = log P ( D|h ) − par(h )
2 log |D|
( 6 ) where par(h ) is the number of parameters specified in h . mdl(h ) penalizes the likelihood of h to an extent that is proportional to the network complexity , where complexity is measured by par(h ) . It can be shown that mdl(h ) is asymptotically correct [ 26 , 20 ] .
Given the evaluation function , we specify a strategy for searching the model space . In order to find the model with the highest MDL score , we use a hill climbing algorithm . The algorithm starts from a BN h with an empty DAG , and it generates a set of neighbors of h , where a neighbor is a BN whose DAG is obtained from h in one of three ways : ( i ) adding one arc ; ( ii ) removing one arc ; ( iii ) reversing one arc . Once a new DAG has been constructed , a corresponding BN is obtained by learning the CPTs for that DAG . While generating new DAGs , we need to discard the ones containing cycles . The neighbors of h are scored , and the ' highest scoring neighbor h scores ' better than h , the whole cycle is iterated for h , and the process continues until no neighbor of the currently accepted network improves on the score of that network . In order to speed up the search , a useful trick is to maintain a tabu list , keeping track of the states explored at each cycle , so as to prevent the algorithm from scoring several times models already encountered during the search . The pseudocode of Algorithm 1 implements the strategy just described . 4.2 Learning the Global Structure
' is compared to h . If h
MBM produces an initial assignment by choosing an initial size k of the set of relatives , and then by selecting as relatives of each Xi the k variables that display the highest dependence ( as measured by the χ2 test ) with respect to Xi . Given the sets of relatives , an assignment of MBs to the respective variables is obtained by learning ( both the structure and the parameters of ) BNi for each variable Xi , where BNi contains Xi together with its relatives R(Xi ) . In order
321 ∗
' 1 , . . . , BN to learn the structure of the local BNs , we use Algorithm 1 . In each application , a suitable value for k can be assessed by preliminary cross validation . Given a current assignment of MBs to the model variables , where the assignment is given by MB1(X1 ) , . . . ,MBn(Xn ) ( as determined by BN1 , . . . , BNn ) , a new assignment is obtained as follows . For each variable Xi , we construct the set Ui as the union of MBi with the MBs of Xi in all graphs Gj such that Xi appears in Gj . Given the sets U1 , . . . ,Un , we first check whether the cardinality of each Ui does not exceed a certain threshold k , and then we construct a new set n such that , if |Ui| ≤ k ' ' of BNs BN i is the BN learned ( from the dataset at hand ) for the variables in {Xi}∪Ui , whereas , if |Ui| > k ' i = BNi . Given ' P|D| the networks BN n , a new assignment of MBs to X1 , . . . , Xn is obtained in the following manner . For each j=1 log P ( xij|mbij ( Xi ) ) to the Xi , we compare the value ' ij ( Xi) ) . This values are , respecvalue tively , the conditional log likelihoods of Xi given its MB , as determined on the one hand by BNi , and on the other hand ' by BN i . If the latter value is higher than the former , ie if the conditional log likelihood of Xi given its MB increases after replacing MBi(Xi ) with MB' i(Xi ) is chosen as the MB of Xi in the new assignment , otherwise Xi is assigned again MBi(Xi ) . As for the parameter k in the model initialization step , a suitable value for k can also be determined by means of cross validation .
P|D| j=1 log P ( xij|mb i(Xi ) , then MB'
' 1 , . . . , BN
, then BN
, then BN
∗
∗
∗
An assignment of MBs to the variables is evaluated by measuring the model pseudo log likelihood , ie the logarithm of the formula given in Eq 2 . Therefore , the evaluation function for model h given dataset D is the following :
|D|X nX
∗
( D|h ) = log P log P ( Xi = xij|mbij ( Xi ) )
( 7 ) j=1 i=1
In fact , by defining an alternative assignment based on the current one , MBM implicitly evaluates the new assignment , because the new assignment will differ from the old one only if there is at least one variable Xi such that the new MB of Xi increases the conditional log likelihood of Xi given the MB . Clearly , an increase in any one of the n local loglikelihoods ensures an increase in the global ( pseudo )loglikelihood . The reason is that our search operator works in a modular fashion , that is the way each MBi(Xi ) is modified during MBM is such that the change does not affect any other MB within the model . Therefore , after MBM builds a new assignment , it is sufficient to compare it to the old one in order to know whether it increases the model pseudolikelihood : if the two assignments are different , then MBM endorses the new assignment ( as a better one ) , otherwise the old assignment is retained and MBM stops searching . Pseudocode for MBM is provided by Algorithm 2 .
By using bounds on the size of the sets of relatives , MBM restricts significantly the size of the search space with respect to Algorithm 1 . To understand why , consider that the total number of DAGs containing n nodes is given by a function f ( n ) which grows exponentially with n [ 5 ] . On the other hand , given the upper bound k on the size of the set of relatives , the worst case size of the search space for MBM ( n ) = i · n · f ( k ∗ is given by f ) , where i is the number of iterations run by MBM until convergence . This result is particularly encouraging , since f ( n ) grows only linearly with n .
∗
∗
∗
.
∗
Algorithm 2 Learning the structure of a HRF Input : Set X of variables X1 , . . . , Xn ; dataset D ; integers k , k External routines : χ2 ( i , j ) , returning the value of the χ2 test on Xi and Xj ; learnBN(Xi,Ri ) , using Algorithm 1 to learn a BN for {Xi} ∪ Ri from D ; getMB(Xi , BNj ) , returning the MB of Xi in BNj if Xi is in BNj , or ∅ otherwise ; getL(Xi,MBi ) , returning
P|D| j=1 log P ( xij|mbij ( Xi) ) .
1 . for(i = 1 to n )
2 . Ri = {Xj in X \ {Xi} with k top χ2(i , j)} do
3 . 4 . 5 . 6 . 7 . 8 . 9 . 10 . 11 .
)
∗
Sn for(i = 1 to n ) assignmentW asRef ined = false for(i = 1 to n ) BNi = learnBN(Xi,Ri ) Ui = if(|Ui| <= k i = learnBN(Xi,Ui ) ' BN 12 . MBi = getMB(Xi , BNi ) 13 . MB' ' i = getMB(Xi , BN i ) j=1 getMB(Xi , BNj ) for(i = 1 to n ) if(getL(Xi,MB' Ri = MB' assignmentW asRef ined = true
14 . 15 . 16 . 17 . while(assignmentW asRef ined ) 18 . h = {BN1 , . . . , BNn} 19 . return h i i ) > getL(Xi,MBi ) )
5 . RELATED WORK
Dependency networks ( DNs ) significantly reduce the computational cost of learning with respect to BNs and MRFs [ 11 ] . While the structure of DNs is fixed by using a feature selection algorithm to assign each node a set of neighbors ( ie a MB ) , in MBM feature selection only initializes the model structure , and the HRF can then be refined to better fit the data distribution . HRFs can be viewed as a particular class of DNs , designed with the primary aim of allowing for iterative structure learning .
Chain graphs ( CGs ) define a mathematical framework for studying the properties of probabilistic graphical models at a high level of abstraction [ 15 ] . BNs and MRFs are special cases of CGs . While the basic idea of developing a formalism capable of subsuming some known classes of probabilistic graphical models is common to CGs and HRFs , our work on the latter models is more strictly focused on learning and its algorithmic aspects , such as scalability . In practical applications , CGs have been learned in the form of particular graphical models ( such as BNs and MRFs ) or combinations thereof [ 4 ] . Since our experimental study compares HRFs to BNs and MRFs , our model is thereby compared to the most representative kinds of CGs for which effective learning algorithms exist .
The ‘local to global search’ algorithm [ 13 ] for MB discovery achieves computational efficiency whithout making the faithfulness assumption . However , this algorithm is not generally warranted to optimize the chosen evaluation function , since the score of the learned network can happen to decrease during the learning process .
A computationally efficient method for learning MBs is the Max Min Markov Blanket ( MMMB ) algorithm [ 28 ] . A
322 crucial difference between MMMB and MBM is that the former method is committed to the faithfulness assumption [ 27 , 20 ] with respect to the learned BNs , which is dispensed with in MBM .
6 . EXPERIMENTAL EVALUATION
We now offer an experimental investigation of the behavior of HRFs in a number of respects , comparing them to BNs , MRFs , DNs , and also to the naive Bayes ( NB ) estimator [ 6 ] . In Sec 6.1 HRFs are applied to some link prediction tasks , while Sec 6.2 explicitly focuses on the computational burden of learning HRFs as opposed to related graphical models . All models and algorithms have been implemented in the JProGraM software library , which is released at http://wwwdiiunisiit/~freno/ under an open source license . The same website also hosts those datasets used in this work that are not otherwise available on the web .
Before describing the experiments , we briefly explain how we use MRFs and DNs . Concerning MRFs , joint distributions are estimated using the pseudo likelihood approximation ( for the sake of computational efficiency ) . The model weights are learned by means of a maximum ( pseudo)likelihood strategy . In particular , the model pseudolikelihood is optimized using the L BFGS algorithm [ 16 ] . In order to construct the graph in MRFs , we adopt the following strategy . First , for each variable Xi in the domain , we run a χ2 test between Xi and each other variable Xj , in order to measure the strength of the correlation existing between Xi and Xj . Then , for each Xi , we select the k variables that achieve the highest scores on the χ2 test , and we add these k variables as relatives to Xi . In each application , a suitable value for k is determined by preliminary cross validation . Clearly , the way we construct the graph in MRFs is very similar to the model initialization step in HRFs .
Concerning DNs , a set of k neighbors is assigned to each node based on the results of the χ2 test , where k is tuned by preliminary validation tests . The local distributions are then learned using the techniques suggested in the relevant literature [ 11 , 7 ] . In all the experiments described below , the parameter k will refer to the number of neighbors ( or relatives ) initially assigned to each node based on the results of the χ2 test , both in the case of MRFs , DNs , and HRFs . On the other hand , the parameter k will denote the upper bound on the size of the set of relatives considered when learning HRFs by MBM . 6.1 Application to Link Prediction
∗
Sec 611 explains how probabilistic graphical models are applied to link prediction tasks . Two applications to the task of predicting references in scientific papers are described in Sec 612 , while Sec 613 deals with the collaborative recommendation of movies . HRFs are compared not only to BNs , DNs , and MRFs , but also to the naive Bayes ( NB ) algorithm [ 6 ] .
611 Ranking Strategy
In general terms , our link prediction system has to deal with a set of users of a database and a set of items contained in the database , where the items can be papers , movies , or virtually anything else . For each user , information is available concerning which items in the database have already been chosen by that user . Formally , the aim of the system is to compute , for each user , a scoring function measuring the expected interest of the user for each item in the database . The goal is to measure the interest in items that the user has not yet considered , so that they can be ranked according to their relevance for the next choice the user will make . We denote the set of database users as U = {u1 , . . . , um} , and the set of database items as O = {o1 , . . . , on} . For each user ui , we have a set Oi ⊂ O of items such that Oi contains the items already chosen by ui . The aim of the link prediction system is to provide , for each user ui , a scoring function scorei(oj ) , defined for each item oj in the database , such that , if scorei(oj ) > scorei(ok ) for j ( = k , then the predicted interest of ui in oj is higher than the predicted interest of ui in ok . Therefore , the scoring function scorei(oj ) allows to rank objects in the database according to their expected interest to ui .
In order to predict the interest a user ui will have in object oj , the kind of information we try to exploit is the conditional probability of choosing ( i.e linking to ) oj given the set Oi of objects that ui is known to have already chosen . If we define a way to estimate that conditional probability using each model , then we can simply use the value of that probability as the score assigned by each model to the object being ranked . In other words , if oj is the object we want to rank for ui once we know the elements of Oi , then for each model we need to specify a way to compute the value of the function scorei(oj ) , defined as follows : scorei(oj ) = P ( Li(oj ) = 1|
^
Li(ok ) )
( 8 ) kff=j where Li(oj ) is a boolean function such that
Li(oj ) =
1 if ui links to oj 0 otherwise
( 9 )
That is , Li(oj ) is simply the truth function of the sentence ‘ui will link to oj ’ .
The NB classifier can be applied to link prediction and collaborative recommendation in the following way [ 18 , 25 ] . If oj is the object we want to rank for user ui , then we compute the following scoring function : j
X scorei(oj ) =
= log P ( Li(oj ) = 1 ) + kff=j log P ( Li(ok)|Li(oj ) = 1 )
( 10 ) such that each di
In order to estimate the probabilities referred to in Eq 10 , our relational dataset is formalized as a set of patterns {d1 , . . . , dm} , is a boolean vector ( Li(o1 ) , . . . , Li(on ) ) specifying which objects were chosen by ui . In other words , for each user we construct a corresponding pattern whose dimension is the total number of objects contained in the database . Therefore , the resulting dataset will contain a number of patterns which is equal to the number of database users . Given such a dataset , absolute and conditional probabilities are estimated by computing relative frequencies and exploiting them in the way described in Sec 3 . This formalization of the data is also exploited for applying the other probabilistic models .
The way that BNs , DNs , MRFs , and HRFs are applied to ranking is the following . Given the formalization of the dataset described above , we first learn a model containing n ( boolean ) random variables X1 , . . . , Xn , where n is the number of objects contained in the database and each Xj
323 corresponds to object oj . Once the model has been learned , the notion of MB provides a conceptually straightforward ( and computationally very efficient ) way of computing the value specified in Eq 8 : scorei(oj ) = P ( Li(oj ) = 1|
^
Li(ok ) ) kff=j
= P ( Xj = 1|x1i , . . . , xj−1i , xj+1i , . . . , xni ) = P ( Xj = 1|mbi(Xj ) )
( 11 ) where each xki is the value of Li(ok ) , and mbi(Xj ) is the state of the MB of Xj in the graphical model , as that state is determined by pattern di .
612 Predicting References in Scientific Papers
The task we deal with in this section is the prediction of citations in research papers . In particular , given a paper containing a specific set of references , the task is to rank all remaining papers in a certain database , based on their relevance as additional references to be included in the paper at hand .
We test the ranking algorithms on the CiteSeer and Cora datasets . We exploit a preprocessing of the data which is publicly available at http://wwwcsumdedu/projects/ linqs/projects/lbc/indexhtml From each dataset we extract the citation graph of the paper corpus . We then check the number of references contained in each paper , and we remove papers that do not contain at least 3 references . After this preprocessing , each dataset is formalized as a list containg m vectors of n boolean features , where each vector is a paper and each feature stands for the presence or absence of a certain reference within the paper . For the CiteSeer dataset we have that m = 547 and n = 1067 , while for Cora we have that m = 956 and n = 1229 . In other words , m corresponds to the number of database users , while n corresponds to the number of database objects .
Each dataset is partitioned into training and test sets according to a 5 fold cross validation procedure . The test consists in the following task . For each example ( ie a paper ) in the test set , we remove one reference from the paper , and we require the tested model to rank that reference given the remaining references contained in the paper at hand . The idea behind this query is that the removed reference should receive the highest possible rank from a good ranking algorithm .
The result of ranking is evaluated using the mean recipIf j is the index of a certain rocal rank ( MRR ) metric . example ( hence query ) within the test set , oj is the object ( that is the reference ) that should receive the highest rank for that query , and rank(oj ) is the rank assigned to oj by the algorithm at hand , then MRR is defined as follows : mX
M RR =
1 m
1 rank(oj ) j=1
( 12 ) where m is the size of the test set . The results of the experiments are shown in Tables 1–2 .
Concerning the standard BN model , the dimensionality of these tasks prevents us from applying Algorithm 1 because of computational limitations . Therefore , BNs are trained using the K2 structure learning algorithm [ 5 ] , where the model likelihood is used as evaluation function and the maximum number of parents allowed for each node is set to 2 . Although the K2 algorithm is much faster than Algorithm 1
Mean Reciprocal Rank
Average
Standard Deviation
BN DN HRF MRF NB
0.2823 0.0130 0.2865 0.1771 0.0537
0.0470 0.0010 0.0251 0.0306 0.0108
Table 1 : MRR values ( 5 fold cross validation ) measured on the CiteSeer dataset for BN , DN ( k = 8 ) , HRF ( k = 8 , k
= 10 ) , MRF ( k = 3 ) , and NB .
∗
( at the cost of being less accurate ) , it is still very expensive to run for high dimensional problems . In fact , its worstcase computational complexity is O(n4 ) [ 5 ] . On the CiteSeer dataset , K2 requires about 20 hours computation on a 1.83 GHz PC architecture , while for Cora it requires about 40 hours . On the other hand , the difference between running MBM on the CiteSeer dataset and running it on Cora is relatively small ( in the order of a few minutes ) , and in both cases training time does not exceed 1 hour . Learning DNs is even less expensive . Training time for NB is also not significant ( about half an hour on Cora ) , whereas MRFs require about 6 hours training for CiteSeer and 8 hours for Cora .
Mean Reciprocal Rank
Average
Standard Deviation
BN DN HRF MRF NB
0.2916 0.0417 0.2647 0.0704 0.1519
0.0228 0.0034 0.0168 0.0096 0.0131
Table 2 : MRR values ( 5 fold cross validation ) measured on the Cora dataset for BN , DN ( k = 8 ) , HRF ( k = 8 , k
= 10 ) , MRF ( k = 3 ) , and NB .
∗
The results of the experiments are quite encouraging for HRFs . Both HRFs and BNs significantly outperform NB and MRFs . In general , the behavior of HRFs and BNs is much more reliable across the two tasks than the behavior of NB and MRFs , for the following reason . While MRFs outperform NB on the CiteSeer dataset , NB outperforms instead MRFs the Cora dataset . Given this result , the kind of probability distribution underlying the former domain must be significantly different from the distribution revealed by the second one . Since both HRFs and BNs behave stably well across the two tasks , the experiments show these two models to be more robust than the competing ones . Finally , the advantage of HRFs over DNs is pretty strong . For this reason , we believe that the kind of structure learning implemented by MBM makes pseudo likelihood estimation in HRFs much more robust than it is in standard DNs .
613 Predicting Preferences for Movies
The task we deal with in this section involves the MovieLens database . The dataset used in the experiment contains data concerning 1,682 movies . The number of database users is 943 . The MovieLens dataset is publicly available
324 at http://wwwgrouplensorg/ We formalize the MovieLens link prediction task according to an implicit votingwith binary preferences strategy [ 3 ] . ‘Implicit voting’ means that we only exploit information concerning whether a user rated a certain item or not , without taking into account the specific rating . Therefore , user choices are modeled as ‘binary preferences’ . Given such a formalization , applying the ranking strategy described in Sec 611 is straightforward . For the MovieLens database , we also consider the results achieved by the ItemRank ( IR ) recommender system [ 10 ] . The reason is that , to the best of our knowledge , the results achieved by IR on this particular dataset are the best ones achieved thus far with respect to the evaluation metric we also adopt in the experiments , and therefore they provide an authoritative term of comparison for evaluating the behavior of HRFs .
Results on the MovieLens link prediction task are evaluated using two versions of the degree of agreement ( DOA ) metric , which we describe next . The DOA metric is aimed at measuring how accurate a ranking of database items is for a user ui . Let us denote by L a given training set and by T the corresponding test set . Moreover , let Li denote the set of movies such that each one of these movies is rated by ui in L , and Ti the set of movies rated by ui in T . Finally , let Ni denote the set of movies that are never rated by ui , so that Ni = O\(Li∪Ti ) . The first step in specifying the DOA for a ranking algorithm R is to define , for each user ui and for any pair of movies oj and ok , a function orderi(oj , ok ) such that j orderi(oj , ok ) =
1 if Ri(oj ) > Ri(ok ) 0 otherwise
( 13 ) where Ri(oj ) is the rank assigned by R to movie oj for user ui . Given this function , we define the DOA for each user ui in the following way :
P
DOAi = oj∈Ti∧ok∈Ni orderi(oj , ok )
|Ti| · |Ni|
( 14 )
For each user ui , DOAi measures the percentage of movie pairs in Ti ×Ni ranked in the correct order by the algorithm at hand .
Once defined the DOA with respect to each user ui , we specify macro averaged and micro averaged DOA . The macroaveraged DOA is defined as
P Tiff=∅ DOAi |{Tj : Tj ( = ∅}| macro DOA =
( 15 )
In other words , the macro DOA is the average of all DOAi such that Ti is not empty . On the other hand , the microaveraged DOA is given by
P
P
Tiff=∅ oj∈Ti∧ok∈Ni orderi(oj , ok )
P Tlff=∅ |Tl| · |Nl| micro DOA =
( 16 )
Clearly , the micro DOA assigns a higher weight to users with a larger number of ratings in the test set , whereas the macroDOA assigns the same weight to all users , no matter how many ratings are present in the test set for each one of them . Macro averaged and micro averaged DOA values are measured by 5 fold cross validation . The test employs a publicly available partitioning of the dataset into five pairs of training and test sets , which allows to easily compare different results to be found in the literature . Training the MRF model requires about 12 hours on average for each fold ( on the same PC architecture used for the previous measurements ) . The number of feature functions contained in each model ( averaged over the five MRFs learned for the different folds ) is equal to 16,396 . This means that , in order to learn the weights of each MRF , we need to optimize a function of 16,396 parameters ( on average ) . On the other hand , learning HRFs by MBM takes about one hour and a half for each fold , while training DNs requires less than one hour . Table 3 collects the results . BNs are not included in this comparison because the K2 algorithm does not finish running in 72 hours .
Degree of Agreement
Macro DOA 0.8051 ± 0.0123 0.8983 ± 0.0052 0.8776 ± 0.0027 0.8947 ± 0.0044 0.8887 ± 0.0022
Micro DOA 0.8133 ± 0.0043 0.8807 ± 0.0059 0.8706 ± 0.0010 0.8809 ± 0.0050 0.8666 ± 0.0030
DN HRF IR MRF NB
Table 3 : Average DOA ( ± standard deviation ) measured on the MovieLens dataset for DN ( k = 8 ) , HRF ( k = 8 , k
= 10 ) , IR , MRF ( k = 3 ) , and NB .
∗
The HRF model achieves the highest accuracy with respect to the macro averaged DOA , while its performance is nearly equivalent to the best one ( achieved by MRFs ) with respect to the micro averaged DOA . Both MRFs and HRFs are more accurate than NB and IR , according to both evaluation metrics . On the other hand , the accuracy displayed by DNs is significantly lower with respect to all other models . 6.2 Assessing the Computational Burden of
Structure Learning
In order to compare the computational cost of learning HRFs to the cost of learning BNs , MRFs , and DNs , we measure the time needed to learn the respective models from a number of artificial datasets of growing dimensionality . Each dataset contains 1000 patterns , drawn from a single distribution ( that is from only one class ) . All features are binary . Given each dataset , we measure the time needed for learning ( i ) BNs using Algorithm 1 , ( ii ) BNs using the K2 structure learning algorithm , ( iii ) DNs , ( iv ) HRFs , and ( v ) MRFs using the algorithms described above . Clearly , while we are going to learn the structure ( and not only the parameters ) of BNs and HRFs , for DNs and MRFs we only learn the parameters , since for the latter models structure learning is limited to the initialization of the MBs . This means that the task is more demanding in the case of BNs and HRFs . For MRFs the value of k is set to 6 , for DNs it is set to 8 , while for HRFs the values of k and k are set to 8 and 10 respectively . In the K2 algorithm , likelihood is used as evaluation function and the maximum number of parents allowed for each node is set to 3 . We choose these specific parameter values because they are the largest ones we ever considered in our applications , while tuning the parameters in preliminary cross validation runs of the experiments . Time was measured on a PC equipped with a 2.34 GHz processor . The results are illustrated in Figs . 1–4 , where learning time ( in seconds ) is plotted for the different models against the increasing dimensionality of the data .
∗
325 BN HRF
1400
1200
1000
800
600
400
200
) s ( e m T i
0
25
30
35
40
45
50
55
60
65
70
75
) s ( e m T i
20
18
16
14
12
10
8
6
4
2
0
25
DN HRF
30
35
40
45
50
55
60
65
70
75
Number of variables
Number of variables
Figure 1 : Learning time for BNs ( Algorithm 1 ) and HRFs ( k = 8 , k = 10 ) as the problem size increases .
∗
) s ( e m T i
80
70
60
50
40
30
20
10
0
25
K2 HRF
30
35
40
45
50
55
60
65
70
75
Number of variables
Figure 2 : Learning time for BNs ( K2 algorithm ) and HRFs ( k = 8 , k = 10 ) as the problem size increases .
∗
The comparison displays a clear advantage of HRFs over
BNs and MRFs . The improvement of HRFs over BNs ( trained with Algorithm 1 ) is dramatic , while the difference between HRFs and MRFs is less consistent . Concerning the K2 algorithm for BNs , training time grows much more quickly than the corresponding time for HRFs . Although K2 is very fast for low dimensional datasets , the time measurements reported in the figures show that as the number of variables increases , learning HRFs ( or even MRFs ) becomes more and more convenient with respect to learning BNs . The significance of the gap between MBM and K2 becomes even more apparent if we consider the time measurements reported ( in Sec 6.1 ) for the link prediction experiments , where we deal with datasets involving more than a thousand variables . On the other hand , learning DNs is more efficient than learning HRFs , but in this respect we should note once again that MBM is a full fledged structure learning algorithm , while for DNs ( as for MRFs ) only the parameters are learned . Moreover , the increase in the amount of time needed to learn HRFs with respect to learning DNs is quite small if compared to the amount of time needed to learn BNs or MRFs .
Figure 3 : Learning time for DNs ( k = 8 ) and HRFs ( k = 8 , k
= 10 ) as the problem size increases .
∗
) s ( e m T i
90
80
70
60
50
40
30
20
10
0
25
MRF HRF
30
35
40
45
50
55
60
65
70
75
Number of variables
Figure 4 : Learning time for MRFs ( k = 6 ) and HRFs ( k = 8 , k
= 10 ) as the problem size increases .
∗
7 . CONCLUSIONS
The investigation on HRFs presented in this paper allows us to draw two conclusions . On the one hand , MBM is able to learn networks of probabilistic relationships to a degree of accuracy that is higher than ( or comparable to ) the accuracy displayed by standard learning algorithms for BNs , DNs , and MRFs . On the other hand , the accuracy of MBM is coupled with a dramatic improvement , in terms of computational efficiency , over standard learning techniques for BNs and MRFs .
Two limitations of HRFs need to be considered too . First , HRFs are more suitable for pseudo likelihood estimation than they are for learning joint probability distributions . The reason is that computing a strict joint probability in HRFs requires to perform Gibbs sampling , which can take considerable time before converging to a stationary point . Second , learning HRFs by MBM is computationally more expensive than learning DNs . However , the heavier burden of learning HRFs as compared to DNs is largely compensated for by the higher prediction accuracy of the learned models .
326 8 . ACKNOWLEDGMENTS
The authors are grateful to Manfred Jaeger for providing suggestions and comments concerning a preliminary version of this work .
9 . REFERENCES [ 1 ] J . Besag . Spatial Interaction and the Statistical
Analysis of Lattice Systems . Journal of the Royal Statistical Society . Series B , 36:192–236 , 1974 .
[ 2 ] J . Besag . Statistical Analysis of Non Lattice Data .
The Statistician , 24:179–195 , 1975 .
[ 3 ] J . S . Breese , D . Heckerman , and C . M . Kadie .
Empirical Analysis of Predictive Algorithms for Collaborative Filtering . In Proceedings of the Fourteenth Annual Conference on Uncertainty in Artificial Intelligence , pages 43–52 , 1998 .
[ 4 ] S . Carroll and V . Pavlovic . Protein Classification Using Probabilistic Chain Graphs and the Gene Ontology Structure . Bioinformatics , 22:1871–1878 , 2006 .
[ 5 ] G . F . Cooper and E . Herskovits . A Bayesian Method for the Induction of Probabilistic Networks from Data . Machine Learning , 9:309–347 , 1992 .
[ 6 ] P . Domingos and M . Pazzani . On the Optimality of the Simple Bayesian Classifier under Zero One Loss . Machine Learning , 29:103–130 , 1997 .
[ 7 ] N . Friedman and M . Goldszmidt . Learning Bayesian Networks with Local Structure . In Proceedings of the Twelfth Annual Conference on Uncertainty in Artificial Intelligence ( UAI ’96 ) , pages 252–262 . Morgan Kaufmann , 1996 .
[ 8 ] N . Friedman and D . Koller . Being Bayesian about
Bayesian Network Structure:A Bayesian Approach to Structure Discovery in Bayesian Networks . Machine Learning , 50:95–125 , 2003 .
[ 9 ] W . R . Gilks , S . Richardson , and D . Spiegelhalter .
Markov Chain Monte Carlo in Practice . Chapman & Hall/CRC , 1996 .
[ 10 ] M . Gori and A . Pucci . ItemRank : A Random Walk Based Scoring Algorithm for Recommender Engines . In 20th International Joint Conference on Artificial Intelligence ( IJCAI07 ) , pages 2766–2771 , 2007 .
[ 11 ] D . Heckerman , D . M . Chickering , C . Meek ,
R . Rounthwaite , and C . M . Kadie . Dependency Networks for Inference , Collaborative Filtering , and Data Visualization . Journal of Machine Learning Research , 1:49–75 , 2000 .
[ 12 ] D . Heckerman , D . Geiger , and D . M . Chickering .
Learning Bayesian Networks : The Combination of Knowledge and Statistical Data . Machine Learning , 20:197–243 , 1995 .
[ 13 ] K B Hwang , J . W . Lee , S W Chung , and B T
Zhang . Construction of Large Scale Bayesian
Networks by Local to Global Search . In M . Ishizuka and A . Sattar , editors , PRICAI 2002 , volume 2417 of LNAI , pages 375–384 . Springer , 2002 .
[ 14 ] R . Kindermann and J . L . Snell . Markov Random
Fields and Their Applications . American Mathematical Society , Providence ( RI ) , 1980 .
[ 15 ] S . L . Lauritzen and N . Wermuth . Graphical Models for Associations between Variables , some of which are Qualitative and some Quantitative . The Annals of Statistics , 17:31–57 , 1989 .
[ 16 ] D . C . Liu and J . Nocedal . On the Limited Memory
BFGS Method for Large Scale Optimization . Mathematical Programming , 45:503–528 , 1989 .
[ 17 ] T . M . Mitchell . Machine Learning . McGraw Hill , 1997 . [ 18 ] K . Miyahara and M . J . Pazzani . Collaborative
Filtering with the Simple Bayesian Classifier . In PRICAI , pages 679–689 , 2000 .
[ 19 ] J . Moussouris . Gibbs and Markov Random Systems with Constraints . Journal of Statistical Physics , 10:11–33 , 1974 .
[ 20 ] R . E . Neapolitan . Learning Bayesian Networks .
Prentice Hall , Upper Saddle River ( NJ ) , 2004 .
[ 21 ] S . Parise and M . Welling . Bayesian Model Scoring in
Markov Random Fields . In Proceedings of the Twentieth Annual Conference on Neural Information Processing Systems ( NIPS ) , pages 1073–1080 , 2006 .
[ 22 ] J . Pearl . Evidential Reasoning Using Stochastic
Simulation of Causal Models . Artificial Intelligence , 32:245–257 , 1987 .
[ 23 ] J . Pearl . Probabilistic Reasoning in Intelligent
Systems . Morgan Kaufmann , San Francisco ( CA ) , 1988 .
[ 24 ] J . Rissanen . Stochastic Complexity . Journal of the
Royal Statistical Society . Series B , 49:223–239 , 1987 . [ 25 ] V . Robles , P . Larra˜naga , E . Menasalvas , M . S . P´erez , and V . Herves . Improvement of Na¨ıve Bayes Collaborative Filtering Using Interval Estimation . In Proceedings of the IEEE/WIC International Conference on Web Intelligence ( WI’03 ) , pages 168–174 , 2003 .
[ 26 ] G . Schwarz . Estimating the Dimension of a Model .
The Annals of Statistics , 6:461–464 , 1978 .
[ 27 ] P . Spirtes , C . Glymour , and R . Scheines . Causation ,
Prediction , and Search . MIT Press , Cambridge ( MA ) , second edition , 2001 . Original work published 1993 by Springer Verlag .
[ 28 ] I . Tsamardinos , C . F . Aliferis , and A . R . Statnikov .
Time and Sample Efficient Discovery of Markov Blankets and Direct Causal Relations . In KDD ’03 : Proceedings of the Ninth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 673–678 , New York ( NY ) , 2003 . ACM .
327
