Adapting the Right Measures for K means Clustering
Junjie Wu
Sch’l of Eco . & Mgt Beihang University wujj@buaaeducn
Hui Xiong
Rutgers Business Sch’l
Rutgers University
Jian Chen
Sch’l of Eco . & Mgt Tsinghua University hxiong@rutgers.edu jchen@mailtsinghuaeducn
ABSTRACT Clustering validation is a long standing challenge in the clustering literature . While many validation measures have been developed for evaluating the performance of clustering algorithms , these measures often provide inconsistent information about the clustering performance and the best suitable measures to use in practice remain unknown . This paper thus fills this crucial void by giving an organized study of 16 external validation measures for K means clustering . Specifically , we first introduce the importance of measure normalization in the evaluation of the clustering performance on data with imbalanced class distributions . We also provide normalization solutions for several measures . In addition , we summarize the major properties of these external measures . These properties can serve as the guidance for the selection of validation measures in different application scenarios . Finally , we reveal the interrelationships among these external measures . By mathematical transformation , we show that some validation measures are equivalent . Also , some measures have consistent validation performances . Most importantly , we provide a guide line to select the most suitable validation measures for K means clustering .
Categories and Subject Descriptors H28 [ Database Management ] : Database Applications— Data Mining ; I53 [ Pattern Recognition ] : Clustering
General Terms Measurement , Experimentation
Keywords Cluster Validation , External Criteria , K means
1 .
INTRODUCTION
Clustering validation has long been recognized as one of the vital issues essential to the success of clustering applications [ 10 ] . Despite the vast amount of expert endeavor spent on this problem [ 7 ] , there is no consistent and conclusive solution to cluster validation . The best suitable measures to use in practice remain unknown . Indeed , there are many challenging validation issues which have not been fully addressed in the clustering literature . For instance , the importance of normalizing validation measures has not been fully established . Also , the relationship between different validation measures is not clear . Moreover , there are important properties associated with validation measures which are important to the selection of the use of these measures but have not been well characterized . Finally , given the fact that different validation measures may be appropriate for different clustering algorithms , it is necessary to have a focused study of cluster validation measures on a specified clustering algorithm at one time .
To that end , in this paper , we limit our scope to provide an organized study of external validation measures for K means clustering [ 14 ] . The rationale of this pilot study is as follows . K means is a well known , widely used , and successful clustering method . Also , external validation measures evaluate the extent to which the clustering structure discovered by a clustering algorithm matches some external structure , eg , the one specified by the given class labels . From a practical point view , external clustering validation measures are suitable for many application scenarios . For instance , if external validation measures show that a document clustering algorithm can lead to the clustering results which can match the categorization performance by human experts , we have a good reason to believe this clustering algorithm has a practical impact on document clustering .
Along the line of adapting validation measures for Kmeans , we present a detailed analysis of 16 external validation measures , as shown in Table 1 . Specifically , we first establish the importance of measure normalization by highlighting some unnormalized measures which have issues in the evaluation of the clustering performance on data with imbalanced class distributions . In addition , to show the importance of measure normalization , we also provide normalization solutions for several measures . The key challenge here is to identify the lower and upper bounds of validation measures . Furthermore , we reveal some major properties of these external measures , such as consistency , sensitivity , and symmetry properties . These properties can serve as the guidance for the selection of validation measures in different application scenarios . Finally , we also show the interrelationships among these external measures . We show that some validation measures are equivalent and some measures have consistent validation performances .
877 Table 1 : External Cluster Validation Measures .
Notation Definition E
P
F
V I
M I
R J
Γ
Γ′
M S ε V D M AP pij pi pj pij pi pij ) pi pij pi pij pi
)
/(
+
) ] log pij pj pij pi pij pj pij pi pj
2 ´ − Pj `n·j
2 ´ + 2Pij `nij
−Pi pi(Pj Pi pi(maxj Pj pj maxi[2 −Pi pi log pi − Pj pj log pj − 2Pi Pj pij log Pi Pj pij log 2´ − Pi `ni· [ `n 2 ´]/`n 2´ 2 ´ + Pj `n·j Pij `nij 2 ´ − Pij `nij 2 ´/[Pi `ni· 2 ´ ] 2 ´/qPi `ni· Pij `nij 2 ´Pj `n·j 2 ´ 2 ” Pj “ n·j 2 ” Pij “ nij 2 ” −Pi “ ni· “ n 2 ” rPi “ ni· 2 ” Pj “ n·j 2 ” −Pj “ n·j 2 ” −Pi “ ni· 2 ” [ “ n 2 ” ][ “ n 2 ” ] 2 ´ + 4Pij `nij 2 ´ − 2Pj `n·j 2´ − 2Pi `ni· 2 ´]/`n [ `n 2´ 2 ´/qPj `n·j qPi `ni· 2 ´ − 2Pij `nij 2 ´ + Pj `n·j 2 ´ 1 − 1 n maxσ Pj nσ(j),j ( 2n − Pi maxj nij − Pj maxi nij )/2n Pi pi(maxj Pi pi(1 − maxj Pi n2 i· + Pj n2
) pij pi pij pi
)
Range [ 0 , log K ′ ]
( 0,1 ]
( 0,1 ]
[ 0 , 2 log max(K , K ′ ) ]
( 0 , log K ′ ]
( 0,1 ] [ 0,1 ]
[ 0,1 ]
( 1,1 ]
[ 0,1 ] [ 0 , +∞ ) [ 0,1 ) [ 0 , 1 ) ( 0,1 ]
[ 0,1 )
Measure Entropy
Purity
F measure
Variation of Information
Mutual Information
Rand statistic Jaccard coefficient
Fowlkes and Mallows index
F M
1
2
3
4
5
6 7
8
9
Hubert Γ statistic I
10 Hubert Γ statistic II
11 Minkowski score 12 13 14 micro average precision classification error van Dongen criterion
15 Goodman Kruskal coefficient GK 16 Mirkin metric Note : pij = nij /n , pi = ni·/n , pj = n·j /n .
M
Most importantly , we provide a guide line to select the most suitable validation measures for K means clustering . After carefully profiling these validation measures , we believe it is most suitable to use the normalized van Dongen criterion ( V Dn ) which has a simple computation form , satisfies mathematically sound properties , and can measure well on the data with imbalanced class distributions . However , for the case that the clustering performance is hard to distinguish , we may want to use the normalized Variation of Information ( V In ) instead , since the measure V In has high sensitivity on detecting the clustering changes .
2 . EXTERNAL VALIDATION MEASURES In this section , we introduce a suite of 16 widely used external clustering validation measures . To the best of our knowledge , these measures represent a good coverage of the validation measures available in different fields , such as data mining , information retrieval , machine learning , and statistics . A common ground of these measures is that they can be computed by the contingency matrix as follows .
Table 2 : The Contingency Matrix .
Partition P
C1 P1 n11 P2 n21 · · PK P n·1 nK1
Partition C C2 · · · n12 · · · n22 · · · · · · · nK2 · · · n·2 · · ·
CK ′ n1K ′ n2K ′
· nKK ′ n·K ′
P n1· n2· · nK · n
The Contingency Matrix . Given a data set D with n objects , assume that we have a partition P = {P1 , · · · , PK }
K , and K is the number of clusters . If we have “ true ” class labels for the data , we can have another partition on D : i=1 Pi = D and PiT Pj = φ for 1 ≤ i 6= j ≤ of D , where SK C = {C1 , · · · , CK ′ } , where SK ′ for 1 ≤ i 6= j ≤ K ′ , where K ′ is the number of classes . Let nij denote the number of objects in cluster Pi from class Cj , then the information on the overlap between the two partitions can be written in the form of a contingency matrix , as shown in Table 2 . Throughout this paper , we will use the notations in this contingency matrix . i=1 Ci = D and CiT Cj = φ
The Measures . Table 1 shows the list of measures to be studied . The “ Definition ” column gives the computation ij
·j − 2Pi Pj n2 forms of the measures by using the notations in the contingency matrix . Next , we briefly introduce these measures .
[ 0 , 2`n 2´ )
The entropy and purity are frequently used external measures for K means [ 20 , 26 ] . They measure the “ purity ” of the clusters with respect to the given class labels .
F measure was originally designed for the evaluation of hierarchical clustering [ 19 , 13 ] , but has also been employed for partitional clustering . It combines the precision and recall concepts from the information retrieval community .
The Mutual Information ( MI ) and Variation of Information ( VI ) were developed in the field of information theory [ 3 ] . MI measures how much information one random variable can tell about another one [ 21 ] . VI measures the amount of information that is lost or gained in changing from the class set to the cluster set [ 16 ] .
The Rand statistic [ 18 ] , Jaccard coefficient , Fowlkes and Mallows index [ 5 ] , and Hubert ’s two statistics [ 8 , 9 ] evaluate the clustering quality by the agreements and/or disagreements of the pairs of data objects in different partitions .
The Minkowski score [ 1 ] measures the difference between the clustering results and a reference clustering ( true clusters ) . And the difference is computed by counting the disagreements of the pairs of data objects in two partitions .
The classification error takes a classification view on clustering [ 2 ] . It tries to map each class to a different cluster so as to minimize the total misclassification rate . The “ σ ” in Table 1 is the mapping of class j to cluster σ(j ) .
The van Dongen criterion [ 23 ] was originally proposed for evaluating graph clustering . It measures the representativeness of the majority objects in each class and each cluster . Finally , the micro average precision , Goodman Kruskal coefficient [ 6 ] and Mirkin metric [ 17 ] are also popular measures . However , the former two are equivalent to the purity measure and the Mirkin metric is equivalent to the Rand statistic ( M/2`n these three measures in the future sections .
2´ + R = 1 ) . As a result , we will not discuss
In summary , we have 13 ( out of 16 ) candidate measures . Among them , P , F , M I , R , J , F M , Γ , and Γ′ are positive measures — a higher value indicates a better clustering performance . The remainder , however , consists of measures based on the distance notion . Throughout this paper , we will use the acronyms of these measures .
878 3 . DEFECTIVE VALIDATION MEASURES In this section , we present some validation measures which will produce misleading validation results for K means on data with skewed class distributions .
3.1 K means : The Uniform Effect
One of the unique characteristic of K means clustering is the so called uniform effect ; that is , K means tends to produce clusters with relatively uniform sizes [ 25 ] . To quantify the uniform effect , we use the coefficient of variation ( CV ) [ 4 ] , a statistic which measures the dispersion degree of a random distribution . CV is defined as the ratio of the standard deviation to the mean . Given a sample data objects X = {x1 , x2 , . . . , xn} , we have CV = s/¯x , where i=1(xi − ¯x)2/(n − 1 ) . CV is a dimensionless number that allows the comparison of the variations of populations that have significantly different mean values . In general , the larger the CV value is , the greater the variability in the data . i=1 xi/n and s = pPn
¯x = Pn
Example . Let CV0 denote the CV value of the “ true ” class sizes and CV1 denote the CV value of the resultant cluster sizes . We use the sports data set [ 22 ] to illustrate the uniform effect by K means . The “ true ” class sizes of sports have CV0 = 102 We then use the CLUTO implementation of K means [ 11 ] with default settings to cluster sports into seven clusters . We also compute the CV value of the resultant cluster sizes and get CV1 = 042 Therefore , the CV difference is DCV = CV1 − CV0 = −0.6 , which indicates a significant uniform effect in the clustering result . Indeed , it has been empirically validated that the 95 % confidence interval of CV1 values produced by K means is in [ 0.09 , 0.85 ] [ 24 ] . In other words , for data sets with CV0 values greater than 0.85 , the uniform effect of K means can distort the cluster distribution significantly .
Now the question is : Can these widely used validation measures capture the negative uniform effect by K means clustering ? Next , we provides a necessary but not sufficient criterion to testify whether a validation measure can be effectively used to evaluate K means clustering .
3.2 A Necessary Selection Criterion
Assume that we have a sample document data containing 50 documents from 5 classes . The class sizes are 30 , 2 , 6 , 10 and 2 , respectively . Thus , we have CV0 = 1.166 , which implies a skewed class distribution .
For this sample data set , we assume there are two clustering results as shown in Table 3 . In the table , the first result consists of five clusters with extremely balanced sizes . This is also indicated by CV1 = 0 . In contrast , for the second result , the five clusters have varied cluster sizes with CV1 = 1.125 , much closer to the CV value of the “ true ” class sizes . Therefore , from a data distribution point of view , the second result should be better than the first one .
Indeed , if we take a closer look on contingency Matrix I in Table 3 , we can find that the first clustering partitions the objects of the largest class C1 into three balanced subclusters . Meanwhile , the two small classes C2 and C5 are
Table 3 : Two Clustering Results .
I P1 P2 P3 P4 P5
C1 C2 C3 C4 C5 10 10 10 0 0
0 0 0 10 0
0 0 0 0 2
0 0 0 0 2
0 0 0 0 6
II C1 C2 C3 C4 C5 P1 P2 P3 P4 P5
27 0 0 3 0
0 0 0 0 2
0 2 0 0 0
0 0 6 0 0
2 0 0 8 0 totally “ disappeared ” — they are overwhelmed in cluster P5 by the objects from class C3 . In contrast , we can easily identify all the classes in the second clustering result , since they have the majority objects in the corresponding clusters . Therefore , we can draw the conclusion that the first clustering is indeed much worse than the second one .
As shown in Section 3.1 , K means tends to produce clusters with relatively uniform sizes . Thus the first clustering in Table 3 can be regarded as the negative result of the uniform effect . So we establish the first necessary but not sufficient criterion for selecting the measures for K means as follows .
Criterion 1 . If an external validation measure cannot capture the uniform effect by K means on data with skewed class distributions , this measure is not suitable for validating the results of K means clustering .
Next , we proceed to see which existing external cluster validation measures can satisfy this criterion .
3.3 The Cluster Validation Results
Table 4 shows the validation results for the two clusterings in Table 3 by all 13 external validation measures . We highlighted the better evaluation of each validation measure . As shown in Table 4 , only three measures , E , P and M I , cannot capture the uniform effect by K means and their validation results can be misleading . In other words , these measures are not suitable for evaluating the K means clustering . These three measures are defective validation measures .
3.4 The Issues with the Defective Measures
Here , we explore the issues with the defective measures . First , the problem of the entropy measure lies in the fact that it cannot evaluate the integrity of the classes . pij pi log pij pi
Cj} , and pi = ni·/n is the marginal probability . There
. If we take a random variable view on cluster P and class C , then pij =
We know E = −Pi piPj nij/n is the joint probability of the event : {P = PiV C = fore , E = Pi piPj −p(Cj|Pi ) log p(Cj|Pi ) = Pi piH(C|Pi )
= H(C|P ) , where H(· ) is the Shannon entropy [ 3 ] . The above implies that the entropy measure is nothing but the conditional entropy of C on P . In other words , if the objects in each large partition are mostly from the same class , the entropy value tends to be small ( indicating a better clustering quality ) . This is usually the case for K means clustering on highly imbalanced data sets , since K means tends to partition a large class into several pure sub clusters . This leads to the problem that the integrity of the objects from the same class has been damaged . The entropy measure cannot capture this information and penalize it .
The mutual information is strongly related to the entropy measure . We illustrate this by the following Lemma .
Lemma 1 . The mutual information measure is equivalent to the entropy measure for cluster validation .
Proof . By information theory , M I = PiPj pij log pij
= H(C ) − H(C|P ) = H(C ) − E . Since H(C ) is a constant for any given data set , M I is essentially equivalent to E . 2 The purity measure works in a similar fashion as the entropy measure . That is , it measures the “ purity ” of each cluster by the ratio of the objects from the majority class . Thus , it has the same problem as the entropy measure for evaluating K means clustering . pipj
In summary , entropy , purity and mutual information are defective measures for validating K means clustering .
879 E
0.274 0.396
P
0.920
0.9
F
0.617 0.902
I II
1.371 1.249
1.225 0.822
0.732 0.857
0.375 0.696
Table 4 : The Cluster Validation Results M I
V I
R
Γ
J
Γ′
F M 0.589 0.821
0.454 0.702
0.464 0.714
M S 0.812 0.593
ε
0.480 0.100
V D 0.240 0.100
3.5
Improving the Defective Measures
Here , we give the improved versions of the above three defective measures : entropy , mutual information , and purity .
Lemma 2 . The Variation of Information measure is an improved version of the entropy measure .
Proof . If we view cluster P and class C as two random variables , it has been shown that V I = H(C ) + H(P ) − 2M I = H(C|P ) + H(P |C ) [ 16 ] . The component H(C|P ) is nothing but the entropy measure , and the component H(P |C ) is a valuable supplement to H(C|P ) . That is , H(P |C ) evaluates the integrity of each class along different clusters . Thus , we complete the proof . 2 By Lemma 1 , we know M I is equivalent to E . Therefore ,
V I is also an improved version of M I .
Lemma 3 . The van Dongen criterion is an improved ver sion of the purity measure .
2n−Pi maxj nij −Pj maxi nij
Proof . V D =
Pj maxi nij of the classes and is a supplement to the purity measure . 2
2 P − . Apparently , Pj maxi nij/n reflects the integrity
= 1 − 1
2n
2n
4 . MEASURE NORMALIZATION
In this section , we show the importance of measure normalization and provide normalization solutions to some measures whose normalized forms are not available .
4.1 Normalizing the Measures
Generally speaking , normalizing techniques can be divided into two categories . One is based on a statistical view , which formulates a baseline distribution to correct the measure for randomness . A clustering can then be termed “ valid ” if it has an unusually high or low value , as measured with respect to the baseline distribution . The other technique uses the minimum and maximum values to normalize the measure into the [ 0,1 ] range . We can also take a statistical view on this technique with the assumption that each measure takes a uniform distribution over the value interval .
The Normalizations of R , F M , Γ , Γ′ , J and M S .
The normalization scheme can take the form as
S − E(S )
Sn =
( 1 ) where max(S ) is the maximum value of the measure S , and E(S ) is the expected value of S based on the baseline distribution . Some measures derived from the statistics community , such as R , F M , Γ and Γ′ , usually take this scheme . max(S ) − E(S )
,
Specifically , Hubert and Arabie ( 1985 ) [ 9 ] suggested to use the multivariate hypergeometric distribution as the baseline distribution in which the row and column sums are fixed in Table 2 , but the partitions are randomly selected . This determines the expected value as follows .
E(Xi Xj “ nij
2 ´Pj `n·j 2 ” ) = Pi `ni· 2 ´ `n 2´
.
( 2 )
Based on this value , we can easily compute the expected values of R , F M , Γ and Γ′ respectively , since they are the
Table 5 : The Normalized Measures .
Measure
Normalization
6
5
7 8
−maxj n·j )
( 2n−maxi ni·
V Dn Fn εn
J ′ n , M S ′ n F Mn Γn V In
1 Rn , Γ′ n 2 3 4
( m − m1m2/M )/(m1/2 + m2/2 − m1m2/M ) ( m1 + m2 − 2m)/(m1 + m2 − 2m1m2/M ) ( m − m1m2/M )/(√m1m2 − m1m2/M ) ( mM − m1m2)/pm1m2(M − m1)(M − m2 ) 1 + 2 Pi Pj pij log(pij /pi pj ) ( Pi pi log pi+Pj pj log pj ) ( 2n−Pi maxj nij −Pj maxi nij ) ( F − F−)/(1 − F− ) ( 1 − 1 Note : ( 1 ) m = Pi,j `nij linear functions of PiPj `nij n maxσ Pj nσ(j),j )/(1 − 1/ max(K , K ′ ) ) 2 ´ , m1 = Pi `ni·
( 2 ) pi = ni·/n , pj = n·j /n , pij = nij /n . ( 3 ) Refer to Table 1 for F , and Procedure 1 for F− .
2 ´ , m2 = Pj `n·j
2 ´ , M = `n 2´ . 2 ´ under the hypergeometric distribution assumption . Furthermore , although the exact maximum values of the measures are computationally prohibited under the hypergeometric distribution assumption , we can still reasonably approximate them by 1 . Then , according to Equation ( 1 ) and ( 2 ) , we can finally have the normalized R , F M , Γ and Γ′ measures , as shown in Table 5 . The normalization of J and M S is a little bit complex , since they are not linear to PiPj `nij can still normalize the equivalent measures converted from them . Let J ′ = 1−J
1+J − 1 and M S ′ = M S2 .
2 ´ . Nevertheless , we
1+J = 2
It is easy to show J ′ ⇔ J and M S ′ ⇔ M S . Then based on the hypergeometric distribution assumption , we have the normalized J ′ and M S ′ as shown in Table 5 . Since J ′ and M S ′ are negative measures — a lower value implies a better clustering , we normalize them by modifying Equation ( 1 ) as Sn = ( S − min(S))/(E(S ) − min(S) ) .
Finally , we would like to point out some interrelationships between these measures as follows .
Proposition 1 .
( Rn ≡ Γ′ ( 1 ) ( 2 ) Γn ≡ Γ . n ) ⇔ ( J ′ n ≡ M S ′ n ) .
The above proposition indicates that the normalized Hubert Γ statistic I ( Γn ) is the same as Γ . Also , the normalized Rand statistic ( Rn ) is the same as the normalized Hubert Γ statistic II ( Γ′ n ) . In addition , the normalized Rand statistic ( Rn ) is equivalent to J ′ n , which is the same as M S ′ n . Therefore , we have three independent normalized measures including Rn , F Mn and Γn for further study . Note that this proposition can be easily proved by mathematical transformation . Due to the space limitation , we omit the proof .
The Normalizations of V I and V D . Another nor malization scheme is formalized as Sn = S−min(S ) max(S)−min(S ) .
Some measures , such as V I and V D , often take this scheme .
However , to know the exact maximum and minimum values is often impossible . So we usually turn to a reasonable approximation , eg , the upper bound for the maximum , or the lower bound for the minimum .
When the cluster structure matches the class structure perfectly , V I = 0 . So , we have min(V I ) = 0 . However , finding the exact value of max(V I ) is computationally infeasible . Meila suggested to use 2 log max(K , K ′ ) to approx2 log max(K,K ′ ) . imate max(V I ) [ 16 ] , so the normalized V I is The V D in Table 1 can be regarded as a normalized meaIn this measure , 2n has been taken as the upper
V I sure . bound [ 23 ] , and min(V D ) = 0 .
880 However , we found that the above normalized V I and V D cannot well capture the uniform effect of K means , because the proposed upper bound for V I or V D is not tight enough . Therefore , we propose new upper bounds as follows .
Lemma 4 . Let random variables C and P denote the class and cluster sizes respectively , H(· ) be the entropy function , then V I ≤ H(C ) + H(P ) ≤ 2 log max(K ′ , K ) .
Lemma 4 gives a tighter upper bound H(C ) + H(P ) than 2 log max(K ′ , K ) which was provided by Meila [ 16 ] . With this new upper bound , we can have the normalized V In as shown in Table 5 . Also , we would like to point out that , if we use H(P )/2 + H(C)/2 as the upper bound to normalize mutual information , the V In can be equivalent to the normalized mutual information M In ( V In + M In = 1 ) .
Lemma 5 . Let ni· , n·j and n be the values in Table 2 , then V D ≤ ( 2n − maxi ni· − maxj n·j)/2n ≤ 1 .
Due to the page limit , we omit some proofs . The above two lemmas imply that the tighter upper bounds of V I and V D are the functions of the class and cluster sizes . Using these two new upper bounds , we can derive the normalized V In and V Dn in Table 5 .
The Normalization of F and ε have been seldom discussed in the literature . As we know , max(F ) = 1 . Now the goal is to find a tight lower bound . In the following , we propose a procedure to find the lower bound of F .
Let n∗ = maxi ni· . Sort the class sizes so that n·[1 ] ≤ n·[2 ] ≤ · · · ≤ n·[K ′ ] . Let aj = 0 , for j = 1 , 2 , · · · , K ′ . for j = 1 : K ′
Procedure 1 : The computation of F− . 1 : 2 : 3 : 4 : 5 : 6 : 7 : aj = n·[j ] , n∗ ← n∗ − n·[j ] . j=1 aj /(1 + maxi ni·/n·[j] ) . if n∗ ≤ n·[j ] , F− = ( 2/n)PK ′ aj = n∗ , break . else
With the above procedure , we can have the following lemma , which finds a lower bound for F .
Lemma 6 . Given F− computed by Procedure 1 , F ≥ F− .
Proof . It is easy to show :
F =Xj n·j n max i
2nij ni· + n·j
≥
2 n nij ni·/n·j + 1
( 3 ) max i Xj
Let Fi = 2 j=1 n PK ′ xi[j ] ni·/n·[j]+1 = 2 xi[j]/ni· n PK ′
1/n·[j]+1/ni· j=1 ” by “ pi[j ] ” , we have Fi =
. Denote
“ xi[j]/ni· ” by “ yi[j ] ” , and “
1
1/n·[j]+1/ni·
2 arg max
Fi = arg max j=1 pi[j]yi[j ] . Next , we remain to show n PK ′ Assume ni· ≤ ni′ · , and for some l,Pl yi[j]( ≥ yi′[j ] , 1 ≤ j ≤ l ; l ∈ {0 , 1 , · · · , K ′ − 1} . This implies that i i ni· .
≤ yi′[j ] , l + 1 < j ≤ K ′ . j=0 n·[j ] < ni· ≤Pl+1 j=0 n·[j ] ,
Since PK ′ have PK ′ j=1 yi[j ] = PK ′ j=1 pi[j]yi[j ] ≤PK ′ pi′[j ] , ∀ j ∈ {1 , · · · , K ′} . Therefore , j=1 yi′[j ] = 1 and j ↑ ⇒ pi[j ] ↑ , we j=1 pi[j]yi′[j ] .
Furthermore , according to the definition of pi[j ] , we have pi[j ] ≤
Fi =
2 n
K ′
Xj=1 pi[j]yi[j ] ≤
2 n
K ′
Xj=1 pi[j]yi′[j ] ≤
2 n
K ′
Xj=1 pi′[j]yi′[j ] = F ′ i , which implies that “ ni· ≤ ni′ · ” is the sufficient condition for “ Fi ≤ F ′ i ” . Therefore , by Procedure 1 , we have F− = maxi Fi , which finally leads to F ≥ F− . Thus we complete the proof .
2 Therefore , Fn = ( F − F−)/(1 − F− ) , as listed in Table 5 .
Finally , as to ε , we have the following lemma .
Lemma 7 . Given K ′ ≤ K , ε ≤ 1 − 1/K .
Proof . Assume σ1 : {1 , · · · , K ′} → {1 , · · · , K} is the optimal mapping of the classes to different clusters , ie ,
ε = 1 − PK ′ n j=1 nσ1(j),j
.
Then we construct a series of mappings σs : {1 , · · · , K ′} 7→
{1 , · · · , K} ( s = 2 , · · · , K ) which satisfy
σs+1(j ) = mod(σs(j ) , K ) + 1 , ∀j ∈ {1 , · · · , K ′} , where “ mod(x , y ) ” returns the remainder of positive integer x divided by positive integer y . By definition , σs ( s = 2 , · · · , K ) can also map {1 , · · · , K ′} to K ′ different indices in {1 , · · · , K} as σ1 . j=1 nσs(j),j , ∀s = j=1 nσ1(j),j ≥PK ′ j=1 nσs(j),j = n .
More importantly we have PK ′ 2 , · · · , K , and PK Accordingly , we have PK ′ s=1PK ′
1 − 1/K . The proof is completed .
2 Therefore , we can use 1 − 1/K as the upper bound of ε , j=1 nσ1(j),j ≥ n
K , which implies ε ≤
Let us consider an optimization problem as follows . and the normalized εn is shown in Table 5 . xij ni·/n·j + 1 min xij Xj xij = ni· ; ∀j , xij ≤ n·j ; ∀j , xij ∈ Z+ st Xj
4.2 The DC V Criterion
Here , we present some experiments to show the importance of DCV ( CV1−CV0 ) for selecting validation measures . Experimental Data Sets . Some synthetic data sets were generated as follows . Assume we have a two dimensional mixture of two Gaussian distributions . The means of the two distributions are [ 2,0 ] and [ 2,0 ] , respectively . And their covariance matrices are exactly the same as [ σ2 0 ; 0 σ2 ] .
Therefore , given any specific value of σ2 , we can generate a simulated data set with 6000 instances , n1 instances from the first distribution , and n2 instances from the second one , where n1 + n2 = 6000 . To produce simulated data sets with imbalanced class sizes , we set a series of n1 values : {3000 , 2600 , 2200 , 1800 , 1400 , 1000 , 600 , 200} . If n1 = 200 , n2 = 5800 , we have a highly imbalanced data set with CV0 = 1320 For each mixture model , we generated
For this optimization problem , to have the minimum objective value , we need to assign as many objects as possible to the cluster with highest ni·/n·j + 1 , or equivalently , with smallest n·j . Let n·[0 ] ≤ n·[1 ] ≤ · · · ≤ n·[K ′ ] where the virtual n·[0 ] = 0 , and j=0 n·[j ] , l ∈ {0 , 1 , · · · , K ′ − 1} , we assume Pl have the optimal solution : j=0 n·[j ] < ni· ≤Pl+1 xi[j ] =8>>< >> : ni· −Pl
Therefore , according to ( 3 ) , F ≥ 2 n·[j ] , 1 ≤ j ≤ l ;
0 , l + 1 < j ≤ K ′ . k=1 n·[k ] , j = l + 1 ; n maxiPK ′ j=1 xi[j ] ni·/n·[j]+1 .
881
0 ohscal
OHSUMED
6
4
2
Y
0
−2
−4
−6 −8
Class 1
Class 2
−6
−4
−2
0 X
2
4
6
8
Figure 1 : A Simulated Data Set ( n1 = 1000 , σ2 = 25 )
1.4
1.2
1
0.8
0.6
0.4
0.2
0 V C
0
−1.4
DCV = 0.97CV0 + 0.38 R2=0.99
−0.5
V C D
−1
σ2=0.5 σ2=2.5 σ2=5
−1.2
−1
−0.8
−0.6 DCV
−0.4
−0.2
0
0.2
−1.5
0.6
0.8
1
1.2 CV0
1.4
1.6
1.8
( a ) Simulated Data Sets .
( b ) Sampled Data Sets . Figure 2 : Relationship of C V0 and DC V .
8 simulated data sets with CV0 ranging from 0 to 1320 Further , to produce data sets with different clustering tendencies , we set a series of σ2 values : {0.5 , 1 , 1.5 , 2 , 2.5 , 3 , 3.5 , 4 , 4.5 , 5} . As σ2 increases , the mixture model tends to be more unidentifiable . Finally , for each pair of σ2 and n1 , we repeated the sampling 10 times , thus we can have the average performance evaluation . In summary , we produced 8 × 10 × 10 = 800 data sets . Figure 1 shows a sample data set with n1 = 1000 and σ2 = 25
We also did sampling on a real world data set hitech to get some sample data sets with imbalanced class distributions . This data set was derived from the San Jose Mercury newspaper articles [ 22 ] , which contains 2301 documents about computers , electronics , health , medical , research and technology . Each document is characterized by 126373 terms , and the class sizes are 485 , 116 , 429 , 603 , 481 and 187 , respectively . We carefully set the sampling ratio for each class , and get 8 sample data sets with the class size distributions ( CV0 ) ranging from 0.490 to 1.862 , as shown in Table 6 . For each data set , we repeated sampling 10 times , so we can observe the averaged clustering performance .
Experimental Tools . We used the MATLAB 7.1 [ 15 ] and CLUTO 211 [ 11 ] implementations of K means . The MATLAB version with the squared Euclidean distance is suitable for low dimensional and dense data sets , while CLUTO with the cosine similarity is used to handle high dimensional and sparse data sets . Note that the number of clusters , ie , K , was set to match the number of “ true ” classes .
The Application of Criterion 1 . Here , we show how we can apply Criterion 1 for selecting measures . As pointed out in Section 3.1 , K means tends to have the uniform effect on imbalanced data sets . This implies that for data sets with skewed class distributions , the clustering results by K means tend to be away from “ true ” class distributions .
Table 6 : The Sizes of the Sampled Data Sets .
Data Set Class 1 Class 2 Class 3 Class 4 Class 5 Class 6
CV0
1
100 100 100 250 100 100 0.49
2 90 90 90 300 90 90
0.686
3 80 80 80 350 80 80 0.88
4 70 70 70 400 70 70
1.078
5 60 60 60 450 60 60 1.27
6 50 50 50 500 50 50 1.47
7 40 40 40 550 40 40
1.666
8 30 30 30 600 30 30 1.86
Table 8 : The Benchmark Data Sets .
Data Set cacmcisi classic cranmed fbis hitech k1a k1b la1 la2 la12 mm
Source CA/CI CA/CI CR/ME TREC TREC
WebACE WebACE
TREC TREC TREC TREC re0 re1 sports tr11 tr12 tr23 tr31 tr41 tr45 wap
DLBCL Leukemia
LungCancer ecoli pageblocks letter pendigits
MIN MAX
Reuters Reuters TREC TREC TREC TREC TREC TREC TREC
WebACE KRBDSR KRBDSR KRBDSR
UCI UCI UCI UCI
41681 41681 41681 2000
126373 21839 21839 31472 31472 31472 126373 11465 2886 3758
126373
4663 7094 2431 2463 2301 2340 2340 3204 3075 6279 2521 11162 1504 1657 8580 414 313 204 927 878 690 1560
#Class #Case #Feature CV0 0.53 0.55 0.21 0.96 0.50 1.00 1.32 0.49 0.52 0.50 0.14 0.27 1.50 1.39 1.02 0.88 0.64 0.93 0.94 0.91 0.67 1.04 0.25 0.58 1.36 1.16 1.95 0.03 0.04 0.03 1.95
2 4 2 17 6 20 6 6 6 6 2 10 13 25 7 9 8 6 7 10 10 20 3 7 5 8 5 26 10 2 26
6429 5804 5832 10128 7454 8261 8460 7129 12558 12600
77 325 203 336 5473 20000 10992
77
20000
7 10 16 16 7
126373
Note : CA CACM , CI CISI , CR CRANFIELD , ME MEDLINE . To further illustrate this , let us take a look at Figure 2(a ) of the simulated data sets . As can be seen , for the extreme case of σ2 = 5 , the DCV values decrease as the CV0 values increase . Note that DCV values are usually negative since K means tends to produce clustering results with relative uniform cluster sizes ( CV1 < CV0 ) . This means that , when data become more skewed , the clustering results by K means tend to be worse . From the above , we know that we can select measures by observing the relationship between the measures and the DCV values . As the DCV values go down , the good measures are expected to show worse clustering performances . Note that , in this experiment , we applied the MATLAB version of K means .
A similar trend can be found in Figure 2(b ) of the sampled data sets . That is , as the CV0 values go up , the DCV values decrease , which implies worse clustering performances . Indeed , DCV is a good indicator for finding the measures which cannot capture the uniform effect by K means clustering . Note that , in this experiment , we applied the CLUTO version of K means clustering .
In the next section , we use the Kendall ’s rank correlation ( κ ) [ 12 ] to measure the relationships between external validation measures and DCV . Note that , κ ∈ [ −1 , 1 ] . κ = 1 indicates a perfect positive rank correlation , whereas κ = −1 indicates an extremely negative rank correlation .
4.3 The Effect of Normalization
In this subsection , we show the importance of measure normalization . Along this line , we first apply K means clustering on the simulated data sets with σ2 = 5 and the sampled data sets from hitech . Then , both unnormalized and normalized measures are used for cluster validation . Finally , the rank correlation between DCV and the measures are computed and the results are shown in Table 7 .
As can be seen in the table , if we use the unnormalized measures to do cluster validation , only three measures , namely R , Γ , Γ′ , have strong consistency with DCV on both groups of data sets . V I , V D and M S even show strong con
882 κ
κ
V I
0.71 0.93
Simulated Data Sampled Data
Table 7 : The Correlation between DCV and the Validation Measures . Γ′ 1.00 1.00 Γ′ n 1.00 1.00
Simulated Data Sampled Data Note : Poor or even negative correlations have been highlighted by the bold and italic fonts .
V D M S 0.79 0.79 1.00 1.00 V Dn M S ′ n 1.00 1.00 1.00 1.00
0.91 0.50 J ′ n 1.00 1.00
1.00 0.93 Γn 1.00 0.93
1.00 0.21
Fn 1.00 0.79
1.00 0.50
εn 1.00 0.50
F M 0.71 0.43
F Mn 1.00 1.00
R
1.00 1.00 Rn 1.00 1.00
V In 1.00 1.00
ε
F
J
Γ s e u l a V
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Figure 3 : Un normalized and Normalized Measures .
V D
V Dn
R
Rn
′
R Γ
S Γ M
I V
M J F
D F ε V
1
R
Γ′ Γ
M S
V I
J
F M
F
ε
V D
0.8
0.6
0.4
0.2
0
−0.2
−0.4
εn
Fn J ′n
Rn Γ′n M S′n
F Mn
Γn
V Dn
V In n
ε n F
′n J n R
′n S ′n M Γ n M F n Γ n D V n
I V
1
0.9
0.8
0.7
0.6
0.5
( a ) Unnormalized Measures .
( b ) Normalized Measures .
Figure 4 : Correlations of the Measures . flict with DCV on the sampled data sets , since their κ values are all close to 1 on sampled data . In addition , we notice that F , ε , J and F M show weak correlation with DCV .
Table 7 shows the rank correlations between DCV and the normalized measures . As can be seen , all the normalized measures show perfect consistency with DCV except for Fn and εn . This indicates that the normalization is crucial for evaluating K means clustering . The proposed bounds for the measures are tight enough to capture the uniform effect in the clustering results .
In Table 7 , we can observe that both Fn and εn are not consistent with DCV . This indicates that normalization does not help F and ε too much . The reason is that the proposed lower bound for F and upper bound for ε are not very tight . Indeed , the normalizations of F and ε are very challenging . This is due to the fact that they both exploit relatively complex optimization schemes in the computations . As a result , we cannot easily compute the expected values from a multivariate hypergeometric distribution perspective , and it is also difficult to find tighter bounds .
Nevertheless , the above experiments show that the normalization is very valuable . In addition , Figure 3 shows the cluster validation results of the measures on all the simulated data sets with σ2 ranging from 0.5 to 5 . It is clear that the normalized measures have much wider value range than the unnormalized ones along [ 0,1 ] . This indicates that the values of normalized measures are more spread in [ 0 , 1 ] . In summary , to compare cluster validation results across different data sets , we should use normalized measures .
5 . MEASURE PROPERTIES
In this section , we investigate measure properties , which can serve as the guidance for the selection of measures . s=0.75 s=0.77 s=0.85 s=0.95 s=0.89 s=0.98 s=1
Rn
Γ′n
J′n
M S′n
F Mn
Γn
V Dn
Fn
εn
V In
Figure 5 : The Measure Similarity Hierarchy .
Table 9 : M ( R1 ) − M ( R2 ) .
Rn 0.00 0.09 0.13 0.08 0.10 0.26 0.01
F Mn 0.09 0.00 0.04 0.00 0.10 0.22 0.10
Γn 0.13 0.04 0.00 0.04 0.14 0.22 0.06
V Dn 0.08 0.00 0.04 0.00 0.05 0.20 0.18
Fn 0.10 0.10 0.14 0.05 0.00 0.08 0.08
εn 0.26 0.22 0.22 0.20 0.08 0.00 0.04
V In 0.01 0.10 0.06 0.18 0.08 0.04 0.00
Rn F Mn Γn V Dn Fn εn V In
5.1 The Consistency between Measures
Here , we define the consistency between a pair of measures in terms of the similarity between their rankings on a series of clustering results . The similarity is measured by the Kendall ’s rank correlation . And the clustering results are produced by the CLUTO version of K means clustering on 29 benchmark real world data sets listed in Table 8 . In the experiment , for each data set , the cluster number is set to be the same as the “ true ” class number .
Figure 4(a ) and 4(b ) show the correlations between the unnormalized and normalized measures , respectively . One interesting observation is that the normalized measures have much stronger consistency than the unnormalized measures . For instance , the correlation between V I and R is merely −0.21 , but it reaches 0.74 for the corresponding normalized measures . This observation indeed implies that the normalized measures tend to give more robust validation results , which also agrees with our previous analysis . n , J ′ n , M S ′
Let us take a closer look on the normalized measures in Figure 4(b ) . According to the colors , we can roughly find that Rn , Γ′ n , F Mn and Γn are more similar to one another , while V Dn , Fn , V In and εn show inconsistency with others in varying degrees . To gain the precise understanding , we do hierarchical clustering on the measures by using their correlation matrix . The resultant hierarchy can be found in Figure 5 ( “ s ” means the similarity ) . As we know before , Rn , Γ′ n are equivalent , so they have perfect correlation to one another , and form the first group . The second group contains F Mn and Γn . These two measures behave similarly , and have just slightly weaker consistency with the measures in the first group . Finally , V Dn , Fn , εn and V In have obviously weaker consistency with other measures in a descending order . n and M S ′ n , J ′
Furthermore , we explore the source of the inconsistency among the measures . To this end , we divide the data sets in Table 8 into two repositories , where R1 contains data sets with CV0 < 0.8 , and R2 contains the rest . Then we compute the correlation matrices of the measures on the two
883 repositories respectively ( denoted by M ( R1 ) and M ( R2) ) , and observe their difference ( M ( R1 ) − M ( R2 ) ) in Table 9 . As can be seen , roughly speaking , all the measures except V In show weaker consistency with one another on data sets in R2 . In other words , while V In acts in the opposite way , most measures tend to disagree with one another on data sets with highly imbalanced classes .
5.2 Properties of Measures
In this subsection , we investigate some key properties of external clustering validation measures .
Table 10 : Two Clustering Results . C1 C2 C3 P
C1 C2 C3 P
0
3
4
7
11 12
0 12 19
12 12 0 24
19 23 24 66
I P1 P2 P3
I II
8 12
3 12 19
12 12 0 24
19 23 24 66
II P1 P2 P3
P 23 Table 11 : The Cluster Validation Results .
P 23
Rn 0.16 0.24
F Mn 0.16 0.24
Γn 0.16 0.24
V Dn 0.71 0.71
Fn 0.32 0.32
εn 0.77 0.70
V In 0.78 0.62
The Sensitivity . The measures have different sensitivity to the clustering results . Let us illustrate this by an example . For two clustering results in Table 10 , the differences between them are the numbers in bold . Then we employ the measures on these two clusterings . Validation results are shown in Table 11 . As can be seen , all the measures show different validation results for the two clusterings except for V Dn and Fn . This implies that V Dn and Fn are less sensitive than other measures . This is due to the fact that both V Dn and Fn use maximum functions , which may loose some information in the contingency matrix . Furthermore , V In is the most sensitive measure , since the difference of V In values for the two clusterings is the largest .
Impact of the Number of Clusters . We use the data set la2 in Table 8 to show the impact of the number of clusters on the validation measures . Here , we change the cluster numbers from 2 to 15 . As shown in Figure 6 , the measurement values for all the measures will change as the increase of the cluster numbers . However , the normalized measures including V In , V Dn and Rn can capture the same optimal cluster number 5 . Similar results can also be observed for other normalized measures , such as Fn , F Mn and Γn .
A Summary of Math Properties . We summarize five math properties of measures as follows . Due to the space limit , we omit the proofs here .
Property 1
( Symmetry ) . A measure O is symmet ric , if O(M T ) = O(M ) for any contingence matrix M .
The symmetry property treats the pre defined class structure as one of the partitions . Therefore , the task of cluster validation is the same as the comparison of partitions . This means transposing two partitions in the contingency matrix should not bring any difference to the measure value . This property is not true for Fn which is a typical measure in asymmetry . Also , εn is symmetric if and only if K = K ′ .
Property 2
( N invariance ) . For a contingence matrix M and a positive integer λ , a measure O is n invariant , if O(λM ) = O(M ) , where n is the number of objects .
Intuitively , a mathematically sound validation measure should satisfy the n invariance property . However , three measures , namely Rn , F Mn and Γn cannot fulfill this requirement . Nevertheless , we can still treat them as the asymptotically n invariant measures , since they tend to be n invariant as the increase of n .
Table 12 : Math Properties of Measures .
εn
Fn No Yes
V In Yes Yes
V Dn P1 Yes P2 Yes P3 Yes* Yes* Yes* Yes P4 P5 Yes Note : Yes* — Yes for the un normalized measures .
Rn Yes** Yes No No No Yes
F Mn Yes No No No Yes
Yes Yes* No Yes
No Yes
Yes Yes
Γn Yes No No No Yes
Yes** — Yes for K = K ′ .
Property 3
( Convex additivity ) . Let P = {P1 , · · · , PK } be a clustering , P ′ be a refinement of P 1 , and P ′ l be the partitioning induced by P ′ on Pl . Then a measure O is l ) ) , where nl is the number of data points in Pl , IPl represents the partitioning on Pl into one cluster , and M ( X , Y ) is the contingency matrix of X and Y . convex additive , if O(M ( P , P ′ ) ) = PK nl n O(M ( IPl , P ′ l=1
The convex additivity property was introduced by Meila [ 16 ] .
It requires the measures to show additivity along the lattice of partitions . Unnormalized measures including F , V D , V I and ε hold this property . However , none of the normalized measures studied in this paper holds this property .
Property 4
( Left domain completeness ) . A measure O is left domain complete , if , for any contingence matrix M with statistically independent rows and columns ,
O(M ) =  0 ,
1 ,
O is a positive measure ; O is a negative measure .
When the rows and columns in the contingency matrix are statistically independent , we should expect to see the poorest values of the measures , ie , 0 for positive measures and 1 for negative measures . Among all the measures , however , only V In and V Dn can meet this requirement .
Property 5
( Right domain completeness ) . A measure O is right domain complete , if , for any contingence matrix M with perfectly matched rows and columns ,
O(M ) =  1 ,
0 ,
O is a positive measure ; O is a negative measure .
This property requires measures to show optimal values when the class structure matches the cluster structure perfectly . The above normalized measures hold this property .
5.3 Discussions
In a nutshell , among 16 external validation measures shown in Table 1 , we first know that Mirkin metric ( M ) is equivalent to Rand statistic ( R ) , and micro average precision ( M AP ) and Goodman Kruskal coefficient ( GK ) are equivalent to the purity measure ( P ) by observing their computational forms . Therefore , the scope of our measure selection is reduced from 16 measures to 13 measures . In Section 3 , our analysis shows that purity , mutual information ( M I ) , and entropy ( E ) are defective measures for evaluating K means clustering . Also , we know that variation of information ( V I ) is an improved version of M I and E , and van Dongen criterion ( V D ) is an improved version of P . As a result , our selection pool is further reduced to 10 measures .
In addition , as shown in Section 4 , it is necessary to use the normalized measures for evaluating K means clustering , since the normalized measures can capture the uniform effect by K means and allow to evaluate different clustering results on different data sets . By Proposition 1 , we know
1 “ P ′ be a refinement of P ” means P ′ is the descendant node of node P in the lattice of partitions . See [ 16 ] for details .
884 V I
V In
3.2
3
2.8
2.6
2.4
2.2
2
I V
0.65
0.6
0.55 n
I V
0.5
0.45
0.4
0.38
0.36
0.34
0.32
0.3
0.28
0.26
0.24
0.22
D V
V D
V Dn
1.8
2
4
6
8
10
Number of Clusters
12
14
0.4
16
0.2
2
4
6
8
10
Number of Clusters
0.55
0.5
0.45 n
D V
0.4
0.35
12
14
16
0.9
0.85
0.8
0.75
R
0.7
0.65
0.6
0.55
0.5
2
4
6
R
Rn
0.65
0.6
0.55
0.5
0.45 n
R
0.4
0.35
0.3
0.25
0.2
16
12
14
8
10
Number of Clusters
( a )
( b )
( c )
Figure 6 : Impact of the Number of Clusters . n , Γ′ n as well as M S ′ that the normalized Rand statistic ( Rn ) is the same as the normalized Hubert Γ statistic II ( Γ′ n ) . Also , the normalized n , which is the same as M S ′ Rand statistic is equivalent to J ′ n . Therefore , we only need to further consider Rn and can exclude J ′ n . The results in Section 4 show that the normalized F measure ( Fn ) and classification error ( εn ) cannot well capture the uniform effect by K means . Also , these two measures do not satisfy some math properties in Table 12 . As a result , we can exclude them . Now , we have five normalized measures : V In , V Dn , Rn , F Mn , and Γn . In Figure 5 , we know that the validation performances of Rn , F Mn , and Γn are very similar to each other . Therefore , we only need to consider to use Rn .
From the above study , we believe it is most suitable to use the normalized van Dongen criterion ( V Dn ) , since V Dn has a simple computation form , satisfies all mathematically sound properties as shown in Table 12 , and can measure well on the data with imbalanced class distributions . However , for the case that the clustering performances are hard to distinguish , we may want to use the normalized variation of information ( V In ) instead2 , since V In has high sensitivity on detecting the clustering changes . Finally , Rn can also be used as a complementary to the above two measures .
6 . CONCLUDING REMARKS
In this paper , we compared and contrasted external validation measures for K means clustering . As our results revealed , it is necessary to normalize validation measures before they can be employed for clustering validation , since unnormalized measures may lead to inconsistent or even misleading results . This is particularly true for data with imbalanced class distributions . Along this line , we also provide normalization solutions for the measures whose normalized solutions are not available . Furthermore , we summarized the key properties of these measures . These properties should be considered before deciding what is the right measure to use in practice . Finally , we investigated the relationships among these validation measures . The results showed that some validation measures are mathematically equivalent and some measures have very similar validation performances .
7 . ACKNOWLEDGEMENTS
This research was partially supported by the National Natural Science Foundation of China ( NSFC ) ( No . 70621061 , 70890082 , and 70521001 ) , the Rutgers Seed Funding for Collaborative Computing Research , and the National Science Foundation ( NSF ) of USA via grant number CNS 0831186 .
8 . REFERENCES [ 1 ] A . Ben Hur and I . Guyon . Detecting stable clusters using principal component analysis . In Methods in Molecular Biology . Humana press , 2003 .
2Note that the normalized variation of information is equivalent to the normalized mutual information .
[ 2 ] M . Brun , C . Sima , J . Hua , J . Lowey , B . Carroll , E . Suh , and ER Dougherty . Model based evaluation of clustering validation measures . Pattern Recognition , 40:807–824 , 2007 .
[ 3 ] TM Cover and JA Thomas . Elements of Information
Theory ( 2nd Edition ) . Wiley Interscience , 2006 .
[ 4 ] M . DeGroot and M . Schervish . Probability and Statistics
( 3rd Edition ) . Addison Wesley , 2001 .
[ 5 ] EB Fowlkes and CL Mallows . A method for comparing two hierarchical clusterings . Journal of the American Statistical Association , 78:553–569 , 1983 .
[ 6 ] LA Goodman and WH Kruskal . Measures of association for cross classification . Journal of the American Statistical Association , 49:732–764 , 1954 .
[ 7 ] M . Halkidi , Y . Batistakis , and M . Vazirgiannis . Cluster validity methods : Part i . SIGMOD Rec . , 31(2):40–45 , 2002 .
[ 8 ] L . Hubert . Nominal scale response agreement as a generalized correlation . British Journal of Mathematical and Statistical Psychology , 30:98–103 , 1977 .
[ 9 ] L . Hubert and P . Arabie . Comparing partitions . Journal of
Classification , 2:193–218 , 1985 .
[ 10 ] AK Jain and RC Dubes . Algorithms for Clustering Data .
Prentice Hall , 1988 .
[ 11 ] G . Karypis . Cluto — software for clustering high dimensional datasets , version 211 Oct . 2007 .
[ 12 ] MG Kendall . Rank Correlation Methods . New York :
Hafner Publishing Co . , 1955 .
[ 13 ] B . Larsen and C . Aone . Fast and effective text mining using linear time document clustering . In KDD , 1999 .
[ 14 ] J . MacQueen . Some methods for classification and analysis of multivariate observations . In BSMSP , Vol . I , Statistics . University of California Press , 1967 .
[ 15 ] MathWorks . K means clustering in statistics toolbox . [ 16 ] M . Meila . Comparing clusterings—an axiomatic view . In
ICML , pages 577–584 , 2005 .
[ 17 ] B . Mirkin . Mathematical Classification and Clustering .
Kluwer Academic Press , 1996 .
[ 18 ] WM Rand . Objective criteria for the evaluation of clustering methods . Journal of the American Statistical Association , 66:846–850 , 1971 .
[ 19 ] CJV Rijsbergen . Information Retrieval ( 2nd Edition ) .
Butterworths , London , 1979 .
[ 20 ] Michael Steinbach , George Karypis , and Vipin Kumar . A comparison of document clustering techniques . In Workshop on Text Mining , KDD , 2000 .
[ 21 ] A . Strehl , J . Ghosh , and RJ Mooney . Impact of similarity measures on web page clustering . In Workshop on Artificial Intelligence for Web Search , AAAI , pages 58–64 , 2000 .
[ 22 ] TREC . Text retrieval conference . Oct . 2007 . [ 23 ] S . van Dongen . Performance criteria for graph clustering and markov cluster experiments . TRINS= R0012 , Centrum voor Wiskunde en Informatica . 2000 .
[ 24 ] J . Wu , H . Xiong , J . Chen , and W . Zhou . A generalization of proximity functions for k means . In ICDM , 2007 .
[ 25 ] H . Xiong , J . Wu , and J . Chen . K means clustering versus validation measures : A data distribution perspective . In KDD , 2006 .
[ 26 ] Y . Zhao and G . Karypis . Criterion functions for document clustering : Experiments and analysis . Machine Learning , 55(3):311–331 , 2004 .
885
