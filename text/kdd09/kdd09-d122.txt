OpinionMiner : A Novel Machine Learning System for Web
Opinion Mining and Extraction
Wei Jin
Hung Hay Ho
Rohini K . Srihari
Department of Computer Science
Department of Computer Science &
Department of Computer Science &
North Dakota State University
Engineering
Engineering
Fargo , ND 58108 weijin@ndsuedu
State University of New York at Buffalo
State University of New York at Buffalo
Buffalo , NY 14260
Buffalo , NY 14260 hungho@buffalo.edu rohini@cedarbuffaloedu
ABSTRACT Merchants selling products on the Web often ask their customers to share their opinions and hands on experiences on products they have purchased . Unfortunately , reading through all customer reviews is difficult , especially for popular items , the number of reviews can be up to hundreds or even thousands . This makes it difficult for a potential customer to read them to make an informed decision . The OpinionMiner system designed in this work aims to mine customer reviews of a product and extract high detailed product entities on which reviewers express their opinions . Opinion expressions are identified and opinion orientations for each recognized product entity are classified as positive or negative . Different from previous approaches that employed rule based or statistical techniques , we propose a novel machine learning approach built under the framework of lexicalized HMMs . The approach naturally integrates multiple important linguistic features into automatic learning . In this paper , we describe the architecture and main components of the system . The evaluation of the proposed method is presented based on processing the online product reviews from Amazon and other publicly available datasets .
Categories and Subject Descriptors H33 [ Information Storage and Retrieval ] : Information Search and Retrieval – Information filtering . I27 [ Natural Language Processing ] – Text analysis
General Terms Algorithms , Design , Experimentation , Human Factors
Keywords Opinion Mining , Sentiment Analysis , Lexicalized HMMs
1 . INTRODUCTION As e commerce is becoming more and more popular , it has entities and opinion product become a common practice for online merchants to ask their customers to share their opinions and hands on experiences on products they have purchased . Such information is highly valuable to manufacturers , online advertisers and potential customers . Unfortunately , reading through all customer reviews is difficult , especially for popular items , the number of reviews can be up to hundreds or even thousands . This makes it difficult for a potential customer to read them to make an informed decision on whether to purchase the product . This paper aims to design a system that is capable of extracting , learning and classifying expressions automatically from product reviews . A novel lexicalized HMMbased approach is proposed and an opinion mining and extraction system , OpinionMiner , has been developed . Our objective in this system is to answer the following questions : given a particular product , 1 ) how to automatically extract potential product entities and opinion entities from the reviews ? 2 ) how to identify opinion sentences which describe each extracted product entity ? and 3 ) how to determine opinion orientation ( positive or negative ) given each recognized product entity ? Different from previous approaches that have mostly relied on rule based techniques [ 3 , 4 ] or statistic information [ 10 , 13 ] , we propose a new framework that naturally integrates multiple linguistic features ( eg , part of speech , phrases’ internal formation patterns , and surrounding contextual clues of words/phrases ) learning . The experimental results demonstrate the effectiveness of the proposed approach in web opinion mining and extraction from online product reviews . into automatic
Our contributions in this paper include : ( 1 ) a proposal of a new machine learning framework that naturally integrates multiple linguistic features into web opinion mining and extraction ; ( 2 ) a proposal of a unified and self adaptive tagging approach including use of dictionary , transformations and bootstrapping ; ( 3 ) a proposal of an effective approach of extracting complex product entities , opinion expressions , as well as infrequently mentioned entities from reviews ; ( 4 ) a proposal of a practically effective system design . token
The rest of this paper is organized as follows : section 2 discusses related work . Section 3 describes in detail the system framework and each system component . We report in section 4 our experimental results and give our conclusions on this work in section 5 . level , Turney
2 . Related Work Opinion analysis has been studied by many researchers in recent years . Two main research directions are explored , ie , document level opinion mining and feature level opinion mining . In document [ 3 ] presented an approach of determining document ’s polarity by calculating the average semantic orientation ( SO ) of extracted phrases . SO was computed by using pointwise mutual information ( PMI ) to measure the dependence between extracted phrases and the reference words “ excellent ” and “ poor ” by using web search hit counts . One year later Turney and Littman [ 4 ] further expanded their work by using cosine distance in latent semantic analysis ( LSA ) as the distance measure . Dave , Lawrence and Pennock [ 5 ] classified reviews on Amazon by calculating scores using normalized term frequency on uni gram , bi gram and tri gram with different smoothing techniques . Das and Chen [ 8 ] studied document level sentiment polarity classification on financial documents . Pang , Lee and Vaithyanathan [ 6 ] used several machine learning approaches to classify movie reviews and in [ 7 ] , they further studied another machine learning approach based on subjectivity detection and minimum cuts in graphs for sentiment classification of movie reviews . Our work is different from these as their goal is to determine the sentiment of documents while ours is to perform extraction and classification on entities . Another difference is they were not focused on features being commented on .
In feature level opinion mining , Zhuang , Jing and Zhu [ 10 ] classified and summarized movie reviews by extracting high frequency feature keywords and high frequency opinion keywords . Feature opinion pairs were identified by using a dependency grammar graph . However , it used a fixed list of keywords to recognize high frequency feature words , and thus the system capability is limited . Popescu and Etzioni [ 11 ] proposed a relaxation labeling approach to find the semantic orientation of words . However , their approach only extracted feature words with frequency greater than an experimentally set threshold value and ignored low frequency feature words . Hu and Liu [ 9 ] proposed a statistical approach capturing high frequency feature words by using association rules . Infrequent feature words are captured by extracting known opinion words’ adjacent noun phrases . A summary is generated by using high frequency feature words ( the top ranked features ) and ignoring infrequent features . Ding , Liu and Yu [ 12 ] further improved Hu ’s system by adding some rules to handle different kinds of sentence structures . However , the capability of recognizing phrase features is limited by the accuracy of recognizing noungroup boundaries . Their approach also lacks an effective way to address infrequent features . In this work , we propose a new machine learning framework that naturally integrates linguistic features into automatic learning . Complex product specific features ( which are possible low frequency phrases in the reviews ) are effectively identified , and new potential product and opinion entities are discovered based on the patterns the classifier has seen from the training data .
Another related research area is the Part of Speech ( POS ) Tagging and Named Entity Recognition ( NER ) problems . The task of POS tagging is the process of marking up the words in a text ( corpus ) as corresponding to a particular part of speech , such as noun and verb . The task of NER is identifying and classifying person names , organization names , and etc . In opinion mining , similar tasks need to be performed , such as identifying different entity names , classifying entities into appropriate categories , and further determining the opinion word/phrase ’s polarity . To correlate the web opinion mining task with POS Tagging and NER may well be a significant contribution in itself in this work .
3 . THE PROPOSED FRAMEWORK Motivated by [ 1 , 2 ] which employed a lexicalized HMM approach in Korean part of speech ( POS ) tagging and Chinese named entity tagging respectively , we propose in this paper a hybrid approach the lexicalization technique under the HMM framework . Figure 1 gives the architectural overview of our opinion mining system and each system component is detailed subsequently . information with integrating POS
Figure 1 . The System Framework
3.1 Entity Types and Tag Sets In our work , we have defined four entity types as shown below ( a digital camera is used as an example ) :
Table 1 . Definitions of entity types and examples
Components : Physical objects of a camera , including the
Functions :
Features :
Opinions : camera itself , eg , LCD , viewfinder , battery Capabilities provided by a camera , eg , movie playback , zoom , automatic fillflash , auto focus Properties of components or functions , eg , color , speed , size , weight , clarity Ideas and thoughts expressed by reviewers on product features / components / functions .
Correspondingly , we have further defined the basic tag set to identify each above entity type , which is given below .
Table 2 . Basic tag set and its corresponding entities
Tag set
Corresponding Entities
<PROD_FEAT>
Feature entity
<PROD_PARTS>
Component entity
<PROD_FUNCTION>
Function entity
<OPINION_POS_EXP>
<OPINION_NEG_EXP>
<OPINION_POS_IMP>
<OPINION_NEG_IMP>
<BG>
Explicit Positive Opinion Entities Explicit Negative Opinion Entities Implicit Positive Opinion Entities Implicit Negative Opinion Entities Background Words
In general , an entity can be a single word or a phrase . In other words , a word may present itself as an independent entity or a component of entity . Therefore , a word w in an entity may take one of the following four patterns to present itself : ( i ) w is an independent entity ; ( ii ) w is the beginning component of an entity ; ( iii ) w is at the middle of an entity ; ( iv ) w is at the end of an entity . We adopt a pattern tag set proposed in [ 2 ] to denote the above four patterns , which is shown in table 3 :
Table 3 . Pattern tag set and its corresponding pattern
Basic tags :
<BG>I</BG><OPINION_POS_EXP>love</OPINION_POS_E XP><BG>the</BG><PROD_FEAT>ease of transferring the pictures</PROD_FEAT><BG>to</BG><BG>my</BG><BG>c omputer</BG>
3.2 Lexicalized HMMs Integrating POS Different from traditional Hidden Markov Models ( HMMs ) , in our work , we integrate linguistic features such as part of speech and lexical patterns into HMMs . An observable state is represented by a pair ( wordi , POS(wordi ) ) where POS(wordi ) represents the part of speech of wordi . The task is then described as follows : Given a sequence of words W= w1w2w3…wn and corresponding parts of speech S = s1s2s3…sn , the task is to find an appropriate sequence of hybrid tags ˆ the conditional probability T that maximize
321= ttt nt
P(T|W,S ) such that
ˆ T
= arg max T
SWTP
(
,
|
( 1 )
)
By taking Bayes law , we can rewrite equation ( 1 ) as
ˆ T
= arg max T
)( TPTSWP
)
(
,
|
( 2 )
SWP
(
,
)
Since the probability P(W , S ) remains unchanged for all candidate tag sequences , we can disregard it . Thus , we have a general statistical model as follows :
Pattern Tag
Corresponding Pattern
<>
Independent Entity
ˆ T
= arg ( max T
)( ) TPTSWP
,
|
=
|(max arg T
)( ) , TpSTWPTSP
( )
|
( 3 )
< BOE>
The Beginning Component of an Entity
< MOE>
The Middle Component of an Entity
=
< EOE>
The End of an Entity
Both the basic tag set and pattern tag set are used to represent each word ’s entity type and pattern ( referred to as a hybrid tag representation [ 2 ] ) in the following format : tbtp where tb represents a basic tag and tp represents a pattern tag . Thus , an opinion sentence can be represented as
<tbtp>w1</tbtp>……<tbtp>wn</tbtp> where wi stands for a single word .
Patterns of background words are considered as independent entities . This hybrid tag labeling method is applied to all the training data and system outputs . The following example illustrates the hybrid tag and basic tag representations of an opinion sentence : “ I love the ease of transferring the pictures to my computer . ”
Hybrid tags :
<BG>I</BG><OPINION_POS_EXP>love</OPINION_POS_E XP><BG>the</BG><PROD_FEATBOE>ease</PROD_FEAT BOE><PROD_FEATMOE>of</PROD_FEAT MOE><PROD_FEATMOE>transferring</PROD_FEAT MOE><PROD_FEATMOE>the</PROD_FEAT MOE><PROD_FEATEOE>pictures</PROD_FEATEOE><BG>to</BG><BG>my</BG><BG>computer</BG> n
  ∏ 
= 1 i max arg T i i
|
,
(
s i
1 swwsP 1 swwwP 1 i ( , swwtP 1
− 1 i
− 1 ,
, t − 11 , tss − 1 1 i , s t − 11 i
(
− 1
|
|
1
1 i i i
)
× i
t t − 1 i t t − 1
)
× i t i
− 1 i )
  
Theoretically the above general model can provide the system with a powerful capacity of disambiguation . However , in practice this general model is not computable for it involves too many parameters . Two types of approximations are employed to simplify this general model . The first approximation is based on the independent hypothesis used in standard HMMs . First order HMMs is used in view of data sparseness , ie , P(ti | ti K…ti 1 ) ≈ P(ti | ti 1 ) . The second approximation employs the lexicalization technique together with POS where three main hypotheses are made :
1 . The assignment of current tag ti is supposed to depend not only on its previous tag ti 1 but also previous J ( 1≤J≤i 1 ) words wi J…wi 1 .
2 . The appearance of current word wi is assumed to depend not only on the current tag ti , current POS si , but also the previous K(1≤K≤i 1 ) words wi K…wi 1 .
3 . The appearance of current POS si is supposed to depend both on the current tag ti and previous L(1≤L≤i 1 ) words wiL…wi 1 .
With a view to the issue of data sparseness , we set J=K=L=1 . Based on these assumptions , the general model in equation ( 3 ) can be rewritten as :
ˆ T
= arg max T n
∏ i
=
1
   i | wsP
(
| wwP
(
− i wtP i (
| i
( 4 )
W2 = 0.01 for expert tagged combinations and combinations obtained from expansion , respectively .
, t s
, i t
)
× t i
)
× i ,
) i
−
1
   i
− 1 ,
1 i
−
1
Maximum Likelihood Estimation ( MLE ) is used to estimate the parameters in equation ( 4 ) . For instance , P(si|wi 1,ti ) can be estimated as :
, twsP
(
| i
− 1 i
) i
= ∑
S
, twC
(
, s i
− 1 i (
, twC i
− 1 i
) i ) , s
=
,
, twC
( i
− 1 i , twC
( i
− 1 s i ) i
)
( 5 )
Note that the sum of counts of C(wi 1 , ti , s ) for all s is equivalent to the count of C(wi 1 , ti ) . MLE values for other estimations in equation ( 4 ) can be computed similarly . If a large training corpus is available , the parameters in equation ( 4 ) can be easily estimated using the MLE technique . To account for zero probabilities for any cases that are not observed in the training data , we employ the linear interpolation smoothing technique to smooth higher order models with their relevant lower order models , or to smooth the lexicalized parameters using the related non lexicalized probabilities , namely
, twsP
( '
| i
− 1 i
)
= i
λ
, twsP
(
| i
− 1
)
+
1(
−
λ ) i
( sP
| t i
) i
( 6 ) i β
  
, tswwP
(
,
| i β ) i
− 1 i , tswP i (
|
1(
−
)
+
) i i
  
)
= i
− 1
α
, twtP
(
| i
− 1 i
)
+
1( i
− 1
α )
( tP i
| t i
− 1
) i −
, tswwP
( '
,
| i
− 1 i i
)
= i i i
|
− 1
( '
, twtP Where λ ,
β and
α denote the interpolation coefficients . technique
3.3 Information Propagation using Entity ’s Synonyms , Antonyms and Related Words To cover more language phenomenon and large domains , in the training step , we have employed a new to automatically propagate information of each expert tagged entity to its synonyms , antonyms , similar words and related words . Figure 2 illustrates an example . As mentioned above , an entity can be a single word or a phrase . By expanding each single word to a list of its related words , different word combinations can be formed . In Figure 2 , the sentence “ Good picture quality ” is an expert tagged opinion sentence . During the training course , the system looks up synonyms and antonyms for opinion entities . The tag of the original opinion entity “ good ” , <OPINION_POS_EXP> ( positive opinion ) , gets propagated to each synonym of “ good ” ( red box on the left in Figure 2 ) . The negative tag <OPINION_NEG_EXP> gets propagated to “ good ” ’s antonyms ( dark red box on the bottom left ) . Similarly , for each single word in other entity types , similar words and related words are looked up . The tag of the original word gets propagated to each newly discovered related word ( blue boxes ) . Using this expansion , a number of bi gram combinations ( green arrows ) can be obtained . In this example , there are several possible instances derived from “ Good picture quality ” , such as “ Decent picture quality ” , “ Poor image quality ” , and etc .
Obviously , only “ Good picture quality ” is the expert tagged truth data . All other combinations generated from expansion might contain noise . To reduce the noise impact , a confidence weight is given to each bi gram combination when computing the MLE values in equation 4 . We empirically set W1 = 1 and
Figure 2 . Information propagation using entity ’s synonyms , antonyms , similar words and related words
A dictionary program has been built to return an input word ’s synonyms , antonyms , similar words and related words using Microsoft Word ’s thesaurus . The reason we decided not to use WordNet 1 for this purpose is that after experimenting with WordNet , we found it returned too many less commonly used synonyms and antonyms . However , most reviewers are prone to use commonly used words to express their opinions . Expanding entities using less frequently used terms creates more noise and affects the classifier ’s performance .
3.4 Token Transformations Another problem with many entities is that they may be overly specific . For example , “ I love its 28mm lens ” and “ I love its 300mm lens ” . Both sentences talk about lens . They could be ideally grouped together as “ I love its Xmm lens ” where X can be any numerical value . This transformation generalizes the information contained in sentences and is useful in solving the problem of sparseness in the training data . In our framework , we use this transformation to handle high detailed information in sentences such as Model Number , Focal Length , and ISO ( the sensitivity three transformations are performed . Given the transformation table 4 : sensor ) . The following image of
1
2
3
Table 4 . The transformation table
Regular Expression
Examples
^'|[`";,!?:()\[\]]|\.+$|'$
Match ' ` " ; , ! ? : ( ) [ ] .
\d+|\d+\.\d+|\d+\ \d+
Match 3 , 3.5 , 3 4
[ A Z ]+\d+([A Zaz]+ ) ?
Match DMC LS70S , P5100 , A570IS
1 . Remove any punctuation that matches regular expression 1 .
2 . Transform any token that matches regular expression 2 but does not match regular expression 3 to symbol “ #NUM# ” .
3 . Transform any token that matches regular expression 3 to symbol “ #MODEL# ” .
1 http://wordnetprincetonedu/
Step 1 removes any unnecessary punctuations in a token . Step 2 generalizes all numerical expressions except model numbers . For the previous example , both opinion sentences will be transformed lens ” . Step 3 generalizes product model numbers . This transformation step was applied to both the training and classification . its #NUM#mm into “ I love
3.5 Decoding Based on the above model , the decoding algorithm aims at finding the most probable sequence of hybrid tags for a given sequence of known words and corresponding parts of speech . As discussed above , a hybrid tag of an observable word involves a category tag and a pattern tag . The candidate hybrid tags of a known word are a combination of its candidate category tags and its candidate pattern tags . The Viterbi algorithm is employed to score all candidate hybrid tags with the proposed language models , and then search the best path that has the maximal score .
3.6 Opinion Sentence Extraction This step identifies opinion sentences in the reviews . Opinion sentences in our work are defined as sentences that express opinions on product related entities . In our system , the following two types of sentences are not considered as effective opinion sentences .
1 . Sentences that describe product related entities without expressing reviewers’ opinions .
2 . Sentences that express opinions on another product model ’s entities .
3.7 Determining Opinion Orientation The following step further classifies opinion orientation given each identified product entity . Due to the complexity and flexibility of natural language , opinion orientation is not simply equal to opinion entity ( word/phrase ) ’s orientation . For example , “ I can tell you right now that the auto mode and the program modes are not that good . ” The reviewer expressed his negative comment on both “ auto mode ” and “ program modes ” even in the presence of the opinion entity ( word “ good ” ) in the sentence .
To determine opinion orientation , for each recognized product entity , we first search its matching opinion entity , which is defined as the nearest opinion entity identified by the tagger . The orientation of this matching opinion entity becomes the initial opinion orientation for the corresponding product entity . Next , natural language rules reflecting sentence context are employed to address specific language constructs , such as the presence of negation words ( eg , not ) , which may change the opinion orientation .
Specifically , we check the presence of any negation words ( eg , not , didn’t , don’t ) within five word distance in front of an opinion entity and changes opinion orientation accordingly , except
1 . A negation word appears in front of a coordinating conjunction ( eg and , or , but ) .
2 . A negation word appears after the appearance of a product entity during the backward search within the five word window .
3 . A negation word appears before another negation word .
The coordinating conjunctions such as “ but ” and prepositions such as “ except ” and “ apart from ” are addressed as follows : if opinion entity is in front of the corresponding product entity and prepositions such as “ but/except ” appear between opinion entity and product entity , then the opinion orientation for the corresponding product entity is updated with the opposite of its initial orientation .
4 . EXPERIMENTS We used Amazon ’s digital camera reviews as the evaluation dataset . The reviews for the first 16 unique cameras listed on Amazon during November 2007 were crawled . For each review page , each individual review content , model number as well as manufacturer name were extracted from the HTML documents . Sentence segmentation was applied to the data and the information was stored as plain text documents , which we call review documents . POS parsing was applied to each review document . We used the Part of Speech tagger designed by Stanford NLP Group2 and default settings were used .
4.1 Training Design After downloading and pre processing , there were altogether 1728 review documents obtained . We separated the documents into 2 sets . One set ( 293 documents for 6 cameras ) was manually tagged . Opinion sentences were identified and product entities , opining entities and opinion orientations were manually labeled using the tag sets described in section 31 The remaining documents ( 1435 documents for 10 cameras ) were used by the bootstrapping process ( described next ) to self learn new vocabularies .
4.2 Bootstrapping Labeling training documents manually is a labor intensive task . Thus , it would be nice if the system can identify new vocabularies automatically by using what it has learned . To achieve this , we have designed a bootstrapping approach which can extract high confidence data through self learning . The process is shown in Fig 3 and composed of the following steps :
1 . First , the bootstrapping program creates two child processes . The parent process acts as master and the rest acts as workers . Master is responsible for coordinating the bootstrapping process , extracting and distributing high confidence data to each worker .
2 . We split the training documents into two halves , t1 and t2 by random selection . Each half is used as seeds for each worker ’s HMM .
3 . Each worker first trains its own HMM classifier based on its training set , and then each worker ’s trained HMM is used to tag the documents in the bootstrap document set and produces a new set of tagged review documents .
4 . As two workers’ training documents are different from each other , the tagging results from step 3 may be
2 http://nlpstanfordedu/software/lex parsershtml inconsistent . Therefore after the tagging step , master inspects each sentence tagged by each HMM classifier and only extracts opinion sentences that are agreed upon by both classifiers . In the experiments , only the identical sentences with identical tags were considered to agree with one another .
5 . A hash value is then calculated for each extracted opinion sentence from step 4 and compared with those of sentences already stored in the database ( The database contains newly discovered data from the bootstrap process and is initialized to empty in the first bootstrap cycle ) . If it is a newly discovered sentence , master stores it into the database .
6 . Master then randomly splits the newly discovered data ’ ’ , and adds t1 from the database into two halves t1 ’ to the training set of two workers respectively . This and t2 bootstrap process is repeated until no more new data being discovered .
’ and t2
Figure 3 . The Bootstrapping Process
One characteristic of this bootstrap process is each HMM classifier always has its set of unique training data . Additionally , in each bootstrap cycle , both HMM classifiers’ training data are different from the previous cycle .
4.3 Evaluation As mentioned above , the review documents for 6 cameras were manually labeled by experts . We chose the largest four data sets ( containing 270 documents ) and performed a 4 fold crossvalidation . The remaining review documents for 2 cameras ( containing 23 documents ) were used for training only . The bootstrap document set ( containing 1435 documents for 10 cameras ) was used by the bootstrapping process to extract high confidence data through self learning ( newly discovered high confidence data were then added into the original training set in each iteration ) . Finally , our best classifier was trained based on the accumulated truth ( and high confidence ) data collected from the original training set and bootstrap data set , and was then applied to our test data and evaluated against the baseline .
The effectiveness of the proposed framework was evaluated by measuring the recall , precision and F score of extracted entities , opinion sentences and opinion orientations , respectively . The system performance is evaluated by comparing the results tagged by the system with the manually tagged truth data . Only an exact match is considered as a correct recognition in our evaluation . For entity recognition , this means the exact same word/phrase is identified and classified correctly as one of four pre defined entity types . Furthermore , each identified entity should occur in the same sentence , same position and same document as compared with the truth data . For opinion sentence extraction , exact match means the exact same sentence from the same document is identified compared with the truth data . For opinion orientation classification , exact match means the exact same entity and entity identified with correct orientation ( positive or negative ) . type are as opinion words ) were
431 Baseline System We have designed and implemented a rule based baseline system motivated by [ 3 ] and [ 9 ] ’s approaches . [ 3 ] describes a document level opinion mining system . It uses a number of rules to identify opinion bearing words . In our baseline system , the rules shown in Table 5 were used to extract product entities and opinion bearing words . This was accomplished by searching for any nouns and adjectives matching the rules . Matching nouns ( considered as product entities ) and matching adjectives ( considered extracted . The corresponding sentences were identified as opinion sentences . In the next step , identified adjectives’ semantic orientations were determined . We used twenty five commonly used positive adjectives and twenty five commonly used negative adjectives as seeds . By using the bootstrapping technique proposed in [ 9 ] , we expanded these two seeds lists by searching synonyms and antonyms for each seed word . Newly discovered words were added into their corresponding seeds lists . This process was repeated until no new words were discovered . As semantic orientation of each list of adjective words is known , the orientations of extracted adjectives by the system can be determined by checking the existence of these words in the lists .
Table 5 . Baseline rules for extracting product entities and opinion bearing words
1
2
3
4
First word Second
Third word word
JJ
NN or NNS
Anything
RB , RBR or RBS
JJ
NN or NNS
JJ
JJ
JJ
NN or NNS
NN or NNS
Not NN nor NNS(not extracted )
432 Further Experiments on Hu ’s Corpus In addition to using the dataset downloaded from Amazon.com , the publicly available Hu and Liu ’s corpus [ 9 ] was also used as evaluation data . Their corpus review summarization , which is closely related to our work . However , there are two major differences between Hu ’s task and ours . 1 ) Hu ’s work is focused on summarization where extracting for product is generic terms and frequent terms are their major concern , whereas our work is focused on extracting high detailed product entities and both frequent and infrequent entities are considered equally important ; 2 ) Other than identifying desired entities , we further classify these entities into different categories . This could lead to the automatic construction of a hierarchical relationship ( such as the Entity Relationship schema ) from free texts between product entities and their associated attributes . Due to these differences , some extra work was done on Hu ’s corpus . First , Hu ’s corpus did not include any entity type information . We manually labeled the desired entity types so that the system performance for each entity type . Second , if reviewers use specific terms ( eg , optical viewfinder ) instead of generic terms ( eg , viewfinder ) , specific terms are considered as unique correct terms . In other words , identifying entities capturing finest details of the product is one of our aims . The following example illustrates the major difference between Hu ’s labeled data and ours . the evaluation program can measure
“ The menus are easy to navigate and the buttons are easy to use . ”
Hu ’s labels : [ menu|+ ] [ button|+ ]
Our labels : [ menu|+ [ navigate|+ ] ] [ buttons|+ [ use|+ ] ]
Each bracket represents an entity ( entity type is not shown ) . The ‘+’ symbol represents positive polarity . In our corpus , “ navigate ” is considered as a feature of “ menu ” and “ use ” ( usability ) as a feature of “ buttons ” . “ Menus ” and “ buttons ” are function and product component , respectively . labeled as product
4.4 Evaluation Results and Discussions The detailed evaluation results are presented in Table 6 and Table 7 . As a post analysis , the proposed machine learning framework performs significantly better than the rule based baseline system in terms of entity extraction , opinion sentence recognition and opinion polarity classification . Through manual inspection , we observed our approach effectively identified highly specific product entities and opinion expressions ( usually complex phrases ) and self learned new vocabularies based on the patterns it has seen from the training data ( the examples are shown in Table 8 ) . entities , such as infrequent
Another observation is in addition to effectively extracting frequent entities , the system also excels in identifying important but infrequently mentioned entities , which was under analyzed or ignored by previously proposed methods . In this work , we propose “ on/off button ” , “ battery/memory compartment ” and “ focus assist light ” ( identified by the system but only occur once or twice in the dataset ) , could be useful product descriptors when answering user ’s specific queries in many web applications ( eg , recommender systems ) . In such applications , frequent generic features might be satisfied by most candidate products . However , infrequent product specific features might be better able to differentiate different products ( eg recommending a list of cameras which have positive feedbacks on “ kids mode ” ) . Additionally , the user ’s preferences could be highly specific . For example , “ automatic white balance ” , “ custom white balance ” and “ preset white balance ” represent different user preferences and a recommender system should be able to distinguish among these to answer the user ’s specific queries . Such information can be effectively extracted by the proposed learning system .
In this paper , we also propose the potential non noun product entities , such as “ engineered ” and “ operated ” ( an example is shown below ) . These non noun entities were ignored by previously proposed approaches which were based on the assumption that product entities must be noun or noun phrases . Our system can well identify these overlooked product entity information .
Operated = 2 ( “ = X ” represents the number of occurrences of an entity )
The <PROD_FUNCTION> zoom </PROD_FUNCTION> is <OPINION_POS_EXP> </OPINION_POS_EXP> <PROD_FEAT> operated </PROD_FEAT> without looking . easily
The/DT zoom/NN is/VBZ easily/RB operated/VBN without/IN looking/VBG
4.5 User Interface Figure 4 shows the OpinionMiner system interface and the format of answers we would like to provide for the user . In this interface , opinion sentences are identified ; product related entities and opinion related entities appearing in opinion sentences are recognized and highlighted using different colors ( corresponding to different entity types such as <PROD_FEAT> , <PROD_FUNCTION> and <OPINION_POS_EXP> ) .
5 . CONCLUSIONS In this paper , a novel and robust machine learning system is designed for opinion mining and extraction . The model provides solutions for several problems that have not been addressed by previous approaches . Specifically ,
•
•
The model naturally integrates multiple linguistic features ( eg , part of speech , phrases’ internal formation patterns , surrounding contextual clues ) into automatic learning .
The system can predict new potential product and opinion entities based on the patterns it has learned , which is extremely useful in text and web mining due to the complexity and flexibility of natural language . This capability was not supported by previous rule based or statistical approaches .
• Complex product entities and opinion expressions as well as infrequently mentioned entities can be effectively and efficiently identified , which was under analyzed or ignored by previously proposed methods .
• A bootstrapping approach combining active learning through committee votes and L HMM is employed to handle situations in which collecting a large training set could be expensive and difficult to accomplish .
The existing problems are :
( 1 ) People like to describe a long story about their experiences . For example , some people like to describe how bad/good their former cameras were . This influences the system performance on some camera reviews in the experiments . We are looking into this issue further .
( 2 ) Some researchers suggested pronoun resolution . We have applied pronoun resolution to each sentence in our experiments . However , the results are not satisfying . We found pronoun resolution caused too many false positives . After a closer look at the data , we consider sentence classification might be needed to determine which sentences should perform pronoun resolution . This is also left for future work .
6 . REFERENCES [ 1 ] Lee , S . Z . , Tsujii , J . , and Rim , H . C . 2000 . Lexicalized Hidden Markov Models for Part of Speech Tagging . In Proceedings of the 18th International Conference on Computational Linguistics ( COLING'00 ) , 481 487 .
[ 2 ] Fu , G . and Luke , K . K . 2005 . Chinese Named Entity Recognition using Lexicalized HMMs . ACM SIGKDD Explorations Newsletter 7,1 ( 2005 ) , 19 25 .
[ 3 ] Turney , P . D . 2002 . Thumbs up or Thumbs Down ? Semantic Orientation Applied to Unsupervised Classification of Reviews . In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics ( ACL’02 ) , 417 424 .
[ 4 ] Turney , P . D . and Littman , M . L . 2003 . Measuring praise and criticism : Inference of semantic orientation from association . ACM Trans . On Information Systems , 21 , 4 ( 2003 ) , 315 346 .
[ 5 ] Dave , K . , Lawrence , S . , and Pennock , D . M . 2003 . Mining the Peanut Gallery : Opinion Extraction and Semantic Classification of Product Reviews . In Proceedings of the 12th international conference on World Wide Web ( WWW’03 ) , 519 528 .
[ 6 ] Pang , B . , Lee , L . , and Vaithyanathan , S . 2002 . Thumbs up ? Sentiment learning techniques . In Proceedings of 2002 Conference on Empirical Methods in Natural Language Processing ( EMNLP’02 ) , 79 86 . using machine classification
[ 7 ] Pang , B . and Lee , L . 2004 . A sentimental education : Sentiment analysis using subjectivity summarization based on minimum cuts . In Proceedings of the 42th Annual Meeting of the Association for Computational Linguistics ( ACL’04 ) , 271 278 .
[ 8 ] Das , S . and Chen , M . 2001 . Yahoo! for Amazon : Extracting market sentiment from stock message boards . In Proceedings of the 8th Asia Pacific Finance Association Annual Conference ( APFA’01 ) .
[ 9 ] Hu , M . and Liu , B . 2004 . Mining and Summarizing Customer Reviews . In Proceedings of the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining ( KDD’04 ) , 168 177
[ 10 ] Zhuang , L . , Jing , F . , and Zhu , X . 2006 . Movie Review Mining and Summarization . In Proceedings of the International Conference on Information and Knowledge Management ( CIKM’06 ) , 43 50 .
[ 11 ] Popescu , A . and Etzioni , O . 2005 . Extracting Product Features and Opinions from Reviews . In Proceeding of 2005 Conference on Empirical Methods in Natural Language Processing ( EMNLP’05 ) , 339 346 .
[ 12 ] Ding , X . , Liu , B . , and Yu , P . S . 2008 . A Holistic Lexiconbased Approach to Opinion Mining . In Proceeding of the international conference on Web Search and Web Data Mining ( WSDM’08 ) , 231 239 .
Figure 4 . The user interface and example output ( Opinion sentences are identified and product entities and opinion entities appearing in opinion sentences are recognized and highlighted using different colors ( corresponding to different entity types ) )
Table 6 . Experimental results on entity extraction ( R : Recall ; P : Precision ; F : F score ; VE : Vocabulary Expansion ; BS :
Bootstrapping )
Products
Methods
Feature Entities
Function Entities
All Entities ( % )
Component Entities ( % )
( % )
P
R
F
R
P
F
R
( % )
P
F
R
P
F
Camera A
L HMM+POS+VE+BS
86.5
79.9
83.1
82.7
81.7
82.2
65.6
79.3
71.8
82.7
80.3
81.5
L HMM+POS+VE
82.4
75.8
78.9
74.4
72.5
73.4
65.6
67.7
66.7
77.8
73.9
75.8
L HMM+POS
82.0
77.7
79.8
73.1
73.1
73.1
65.6
70.0
67.7
77.2
75.4
76.3
L HMM Baseline
80.7
75.9
78.2
70.4
70.3
70.3
60.2
67.2
63.5
75.8 20.4
73.2 30.0
74.5 24.3
Camera B
L HMM+POS+VE+BS
88.4
73.5
80.3
80.9
73.8
77.2
65.2
88.2
75.0
83.7
74.4
78.8
L HMM+POS+VE L HMM+POS L HMM Baseline L HMM+POS+VE+BS
L HMM+POS+VE L HMM+POS L HMM Baseline L HMM+POS+VE+BS
86.4 84.4 80.7
69.8 72.1 71.5
77.2 77.7 75.8
79.8 74.5 71.7
75.0 70.9 70.5
77.3 72.7 71.1
56.5 52.2 47.8
76.5 75.0 64.7
65.0 61.5 55.0
80.5
79.8
80.2
97.6
79.4
87.6
72.7
82.7
77.4
75.3 74.0 70.3
77.3 80.3 77.3
76.3 77.0 73.7
97.6 97.6 97.6
76.9 78.4 74.1
86.0 86.9 84.2
72.7 63.6 63.6
78.9 80.5 70.0
75.6 71.1 66.7
88.6
62.0
72.9
82.2
70.2
75.7
86.9
76.8
81.5
81.4 78.0 74.8 15.5 85.3
82.2 80.6 78.2 17.1 86.0
71.9 71.8 70.9 24.3 80.3
77.5 79.6 75.5 23.7 66.7
76.4 74.8 72.8 18.9 82.7
79.8 80.1 76.9 19.8 75.1
Camera C
Hu ’s corpus Camera D
Table 7 . Experimental results on opinion sentence identification and opinion orientation classification
Products
Methods
Opinion sentence extraction
Entity opinion pair
( sentence level )
L HMM+POS+VE+BS L HMM+POS+VE L HMM+POS L HMM Baseline L HMM+POS+VE+BS L HMM+POS+VE L HMM+POS L HMM Baseline L HMM+POS+VE+BS L HMM+POS+VE L HMM+POS L HMM Baseline L HMM+POS+VE+BS
R( % ) 91.41 89.00 87.63 86.32 51.89 89.16 89.76 86.75 85.14 46.39 87.36 82.76 80.46 79.76 43.68 85.58
Camera A
Camera B
Camera C corpus
Hu ’s camera D
P( % ) 85.81 82.48 83.88 82.11 60.64 80.87 80.54 81.82 80.29 57.04 85.85 82.76 80.34 78.82 54.29 69.17
F( % ) 88.52 85.62 85.71 84.16 55.93 84.81 84.90 84.21 82.64 51.16 86.60 82.76 80.40 79.29 48.41 76.50 orientation ( feature level ) F( % ) R( % ) 77.15 78.59 72.40 74.46 73.40 74.26 73.25 71.53 23.36 19.65 70.59 75.00 67.38 71.97 69.70 67.77 66.69 68.45 16.17 13.26 76.57 79.84 75.47 77.52 72.87 72.59 69.40 72.09 19.82 17.05 73.32 66.01
P( % ) 75.76 70.45 72.55 69.89 28.82 66.67 63.33 65.95 65.02 20.71 73.55 73.53 72.31 66.91 23.66 60.03
Table 8 . Examples of self learned vocabularies
Auto = 3 auto setting = 2 auto flash* = 3 auto focus = 1 auto function* = 1 auto ISO setting* = 1
* represents a new self learned vocabulary “ = X ” represents the number of occurrences of an entity auto red eye correction = 1 auto stabilizer* = 2 auto white balance* = 3 automatic = 2 automatic setting = 5 automatic fill flash* = 1 automatic focus* = 1 automatic white balance = 1 automatic zoom* = 1 automatic functions* = 1 automatic point and shoot mode* = 1
