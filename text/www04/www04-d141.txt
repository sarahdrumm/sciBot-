Updating PageRank with Iterative Aggregation
Amy N . Langville NC State University
Mathematics Department Raleigh , NC 27695 8205 anlangvi@unityncsuedu
Carl D . Meyer
NC State University
Mathematics Department Raleigh , NC 27695 8205 meyer@mathncsuedu
ABSTRACT We present an algorithm for updating the PageRank vector [ 1 ] . Due to the scale of the web , Google only updates its famous PageRank vector on a monthly basis . However , the Web changes much more frequently . Drastically speeding the PageRank computation can lead to fresher , more accurate rankings of the webpages retrieved by search engines . It can also make the goal of real time personalized rankings within reach . On two small subsets of the web , our algorithm updates PageRank using just 25 % and 14 % , respectively , of the time required by the original PageRank algorithm . Our algorithm uses iterative aggregation techniques [ 7 , 8 ] to focus on the slow converging states of the Markov chain . The most exciting feature of this algorithm is that it can be joined with other PageRank acceleration methods , such as the dangling node lumpability algorithm [ 6 ] , quadratic extrapolation [ 4 ] , and adaptive PageRank [ 3 ] , to realize even greater speedups ( potentially a factor of 60 or more speedup when all algorithms are combined ) .
Categories and Subject Descriptors F20 [ Analysis of Algorithms and Problem Complexity ] : General
General Terms Algorithms , Performance
Keywords PageRank , updating , link analysis , power method , aggregation , disaggregation , Markov chains , stationary vector
1 .
INTRODUCTION
We have discovered a new technique that can drastically affect ( and perhaps completely crack ) one of the major bottlenecks associated with web based information retrieval systems that are driven by eigenvector ranking schemes—the primary example is the PageRank mechanism that drives Google . The bottleneck is the need to update importance rankings of pages to account for the continual changes that occur in the web ’s structure when pages are added or deleted and links are created or destroyed . At last report , Google uses several days for this computation ( because they use brute force and start from scratch each time an update is
Copyright is held by the author/owner(s ) . WWW2004 , May 17–22 , 2004 , New York , NY USA . ACM xxxxxx attempted ) . Consequently , updating can only be afforded every few weeks . Our solution harnesses the power of iterative aggregation principles for Markov chains to allow for much more frequent updates to the valuable ranking vectors .
2 . THE UPDATING ALGORITHM
Our primary goal is to adapt the theory of exact [ 7 ] and approximate aggregation [ 8 ] to efficiently solve the updating problem . Suppose the Markov transition matrices and distributions at times t and t + 1 are respectively given by
Qm×m and ΦT = ( φ1 , φ2 , . . . , φm ) at Pn×n and πT = ( π1 , π2 , . . . , πn ) at time = t + 1 . Quantities Q , P , and ΦT are known while πT is unknown , and m 6= n because states may be added or deleted . Partition ( and perhaps reorder ) the state space S = G ∪ G for the chain at time t + 1 so that P has the partitioned form time = t
Pn×n =
G
G G P11 P12
µ G P21 P22¶ .
All newly added states go into G along with some of the preexisting states . The idea is to leave the g states in G unaggregated while the n − g states in G are aggregated into a single superstate . Let {φi}n i=g+1 be conformably ordered with {πi}n i=g+1 , and approximate ( what , in the theory of stochastic complementation [ 7 ] , is known as ) the censored distribution sT
2 with sT
2 ≈esT
2 =
( φg+1 , . . . , φn )
, i=g+1 φi
Pn so the exact aggregated transition matrix ( of stochastic complementation ) is approximated by the ( g+1)×(g+1 ) matrix
A ≈ eA =µ P11 esT
2 P21
P12e
2 P21e ¶
1 −esT where e is the vector of all ones . If eαT = ( eα1 , . . . ,eαg,eαg+1 ) is the stationary distribution of eA , then the aggregation the orem [ 7 ] yields an approximation tothe updated distribution ,
πT ≈ eπT =³eα1 , . . . ,eαg |eαg+1esT 2 ´ .
This approximation is further refined with a smoothing step eπT P = ( xT | yT ) , where ( xT | yT ) is a vector partitioned ac cording to the G and G sets . Then the process is iterated by restarting the procedure with
2 ←− yT /yT e . esT
Interestingly , this procedure always converges to the PageRank vector .
Successful implementation of these ideas hinges on the ability to identify an optimal choice for the partition S = G ∪ G , and this is a main facet of future research . Extensive testing seems to be the best way to produce practical heuristics for determining the appropriate partition for a given dataset . In fact , on several small datasets , we have experiments showing the numerical feasibility of the updating algorithm ( see section 22 )
2.1 Convergence
References [ 2 , 5 ] prove that ( 1 ) this updating algorithm converges to the PageRank vector for all partitions S = G ∪ G , and ( 2 ) there always exists a partition such that the convergence rate of the updating algorithm is strictly less than the convergence rate of the Google ’s power method .
3 . RESULTS
We have experimented with a variety of datasets that were extracted as subsets of the Web . However , we describe just two case studies with typical characteristics and outcomes . NCstate.dat contains 10,000 pages obtained from a crawl that started with the NCSU homepage . This small web has n = 10 , 000 pages and l = 101 , 118 links . California.dat is a topical net of n = 9664 pages pertaining to the query topic of “ California . ” It has l = 16 , 150 links .
Tables 1 and 2 compare the aggregation updating algorithm with Google ’s current method for updating PageRank , which is called full recomputation since the power method is started from scratch . We report the number of iterations and the total computation time required by each method .
Table 1 : Comparison of updating methods on NCstate.dat ( n = 10 , 000 , l = 101 , 118 )
Iterative Aggregation Full Recomputation Iterations
Iterations
Time
|G| 500 1000 1500 2000 2500 3000 5000
|G| 500 1000 1250 1500 2000 5000
160 51 33 21 16 13 7
38 28 28 14 13 10
Time 16.64 6.47 4.57 3.64 3.19 3.26 3.62
Time 1.82 2.47 2.61 1.42 1.57 1.65
Table 2 : Comparison of updating methods on California.dat ( n = 9 , 664 , l = 16 , 150 )
Iterative Aggregation Full Recomputation Iterations
Iterations
Time
162
13.17
176
9.63
These tables show the speedups ( as much as a factor of 10 , on some other datasets ) that are obtainable with this updating method . In effect , most of the work done by the updating algorithm is done on the very small aggregation matrix of size |G| + 1 . For example , for California.dat with |G| = 1500 , the aggregation algorithm converges in just 14 iterations and 1.42 seconds compared to the 176 iterations and 9.63 seconds required by the power method because most of the work was done on a 1 , 501 × 1 , 501 matrix , rather than a 9 , 664×9 , 664 matrix . Tables 1 and 2 also show the crucial role that |G| plays in the speedups achieved , and l a u d s e r i g o l
0 1 l a u d s e r i g o l
0 1
0
2
4
6
8
10
12 0
0
2
4
6
8
10
12 0 residual for iterative aggregation algorithm residual for power method
20
40
60 iteration
80
100
120 residual for iterative aggregation algorithm residual for power method
20
40
60 iteration
80
100
120
Figure 1 : Norm of residual vector for abortion.dat for |G| = 50 ( upper ) and |G| = 5 ( lower ) thus , choosing |G| becomes an issue . Examine Figure 1 . The upper pane shows the norm of the residual vector for the updating algorithm applied to another dataset abortion.dat with |G| = 50 , which creates a good choice for G and provides a factor of 6 speedup . The lower pane shows the norm of the residual vector for the same dataset with |G| = 5 , which creates a bad partition and causes the updating algorithm to take nearly as much time as the notoriously slow power method . The slippery problem of choosing a good partition of the chain ’s states is an active area of research .
4 . FUTURE WORK
By the WWW 2004 conference , we hope to have : ( 1 ) tested this updating algorithm on larger datasets , such as those used in [ 3 , 4 , 6 ] , ( 2 ) made progress toward understanding and determining the partitioning of states into G and G , and ( 3 ) created code that incorporates this updating algorithm with the other PageRank acceleration techniques .
5 . REFERENCES [ 1 ] S . Brin , L . Page , R . Motwami , and T . Winograd . The PageRank citation ranking : bringing order to the web . Technical report , Computer Science Department , Stanford University , 1998 . [ 2 ] I . C . F . Ipsen and S . Kirkland . Convergence analysis of an improved PageRank algorithm . December 2003 .
[ 3 ] S . D . Kamvar , T . H . Haveliwala , and G . H . Golub . Adaptive methods for the computation of pagerank . Technical report , Stanford University , 2003 .
[ 4 ] S . D . Kamvar , T . H . Haveliwala , C . D . Manning , and G . H .
Golub . Extrapolation methods for accelerating pagerank computations . Twelfth International World Wide Web Conference , 2003 .
[ 5 ] A . N . Langville and C . D . Meyer . Updating the stationary vector of an irreducible Markov chain . Technical Report crsc02 tr33 , N . C . State , Mathematics Dept . , CRSC , 2002 .
[ 6 ] C . P C Lee , G . H . Golub , and S . A . Zenios . Partial state space aggregation based on lumpability and its application to pagerank . Technical report , Stanford University , 2003 .
[ 7 ] C . D . Meyer . Stochastic complementation , uncoupling Markov chains , and the theory of nearly reducible systems . SIAM Review , 31(2):240–272 , 1989 .
[ 8 ] W . J . Stewart . Introduction to the Numerical Solution of
Markov Chains . Princeton University Press , 1994 .
