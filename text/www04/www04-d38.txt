Automatically Generating Metadata for Digital Photographs with Geographic Coordinates
Mor Naaman , Yee Jiun Song , Andreas Paepcke , Hector Garcia Molina
Stanford University
{mor , yeejiun , paepcke , hector}@csstanfordedu
ABSTRACT Given location information on digital photographs , we can automatically generate an abundance of photo related metadata using off the shelf and web based data sources . These metadata can serve as additional memory cues and filters when browsing a personal or global collection of photos .
Categories and Subject Descriptors H51 [ Information Systems Applications ] : Information Interfaces and Presentation—Multimedia Information Systems
General Terms Human Factors , Algorithms
1 .
INTRODUCTION
Augmenting a collection of digital photographs with contextual information about the images it contains is often beneficial – especially as images , like other multimedia documents , are inherently hard to index or search otherwise . Users can utilize these contextual cues when browsing the collection . However , it is tedious to add such context manually .
Advancements in technology have made it feasible to add location as well as time information to digital photographs , namely the exact coordinates and time where each photo was taken . Using time and location , we can augment the photographs with additional contextual information .
We have developed [ 1 ] a system for organizing , browsing and generating metadata for geo referenced photo collections . Figure 1 shows all the different metadata facets the system automatically generates , as they appear in the opening screen of the interface . The interface was produced using the Flamenco toolkit [ 2 ] .
When browsing the collection , users can filter the photos based on any of the metadata facets and their combination . As shown in Figure 1 , the metadata in each facet is divided into groups . For example , the Location facet is divided into countries . Clicking on one country will advance the user to the next screen , filtering the collection to show pictures from the selected country . Clicking on “ Clear ” in the Weather Status facet will similarly restrict the collection to photos that were taken in clear weather . Copyright is held by the author/owner(s ) . WWW2004 , May 17–20 , 2004 , New York , New York , USA . .
Figure 1 : The system ’s metadata facets ( Clicking on any link displays respective photos ) .
In Figure 1 we only see the first level grouping for each facet . For some facets , further refinements of the groups are available . For the Location facet , once users click on a country , eg “ United States ” , they are able to further refine their filter to , eg , “ San Francisco ” .
Any combination of filters is also possible . Users can restrict the viewed set , for example , to photos taken in San Francisco , when the weather was clear , in near freezing temperature ( Temperature facet , “ 20–40 ” group ) .
The metadata we generated thus adds value to any photo collection : users have plenty of additional contextual information when they browse and search for photos . Moreover , this value is added without any user intervention : our system utilizes the location and time data embedded in the photographs to generate all the other metadata .
In this paper we address the problem of finding available sources for relevant and useful contextual information . We show how we get the information from the various sources , and how we adapt it for the user interface . All the metadata we generate is available either from off the shelf geographic datasets , or from various web based sources .
2 . METADATA CATEGORIES
This section describes the metadata facets , how we gen erated each , and how we use them in the interface . Location . An off the shelf geographical dataset enables us to query with a ( latitude,longitude ) pair to get the containing country , province/state , and ( for the United States only ) county , city ( if any ) and park ( if any ) . We can use the query results to generate a location hierarchy , for example , a Country → State → City hierarchy . Alternatively , we can first group the photos into geographic clusters that are expected to make sense to users , but do not necessarily correspond to the administrative division . Then we can assign names to these clusters using the aforementioned dataset . In [ 1 ] we show how the latter method applies to personal photo collections .
Given an location hierarchy , users can click through and navigate , at various levels of granularity , to photos from a specific location . Figure 1 shows the first level of this hierarchy , the country level . Clicking on any country will show the next level down the hierarchy for this country . Time of Day . Knowledge about the time of day a photo was shot can be used when searching for an image in a collection ( eg , one remembers a certain photo was taken late at night ) . In most cases , however , users set their camera clock once , usually when they operate the camera for the first time . The pitfall appears when the user travels to a different time zone . Most of the users do not bother resetting their camera ’s clock , resulting in timestamps that inaccurately portray the time the picture was taken .
This problem can be solved given the location information where each photo was taken and the original time zone according to which the camera clock was set . This information is sufficient to compute the local time for each photo , using a geographical dataset containing the world ’s time zones . The dataset can be queried by the photo coordinates , returning the correct time zone for the photo .
Given an exact , dependable local time , we can utilize it to help the user search for photos by “ time of day ” . Users are not likely to remember the exact hour each photo was taken . Therefore , we group photos by the major parts of the day , as shown in Figure 1 : Morning , Afternoon , Evening , etc . Users can click any of the groups to filter the photo collection accordingly . Light Status . People ’s perception of the time is sometimes not derived from the local time , but rather from the daylight status . For example , people may recall a certain picture was taken when it was dark outside ; around sunset ; before sunrise ; etc .
Given the local time and location for each photo , we can find how many minutes away from the sunset and sunrise each picture was taken . The data source we use is the US Naval Observatory web service1 . The service returns sunset and sunrise times for a ( year , latitude , longitude ) query . Each reply contains data for a full year , and can be re used across different photos in the same latitude and longitude . As shown in Figure 1 , we group photos into day , dusk ; night and dawn . Users can click on one of these groups to filter pictures according to the daylight status . In our current implementation , the dusk category includes all photos taken within one hour before or after sunset ; the night category includes all photos taken one hour after sunset to one hour before sunrise , and so on . Weather Status and Temperature . Often , people can filter photos using weather information : they recall a certain event occurred on a stormy night ( even if it was indoors ) , another event on a clear day , etc . In addition , people may remember the outside temperature at the time the picture was taken ( “ it was freezing! ” ) .
We use the Weather Underground2 web service to get weather information . Historic data can be queried by a ( zipcode , date ) pair or a ( weather station , date ) pair for weather outside the United States . We have geographic datasets that allow us to translate any ( latitude , longitude ) pair into a zip code or weather station . The results of a query to the server can be used for all photos taken in the same day and same area , reducing the required number of queries .
The weather data we get for each day is an hourly report of the weather conditions ( eg , “ rainy ” , “ clear ” ) and temperature . We annotate each photo with all weather conditions that appear between two hours before and after the photo . The temperature is computed as the average of temperatures measured in the hours around the photo time .
In the interface , users can click on a temperature range ( 20–40 , 40–60 , etc . ) or on a specific weather condition to limit their search for photos , as shown in Figure 1 . Additional Facets . Other metadata facets that appear in Figure 1 are : elevation – available either from the GPS data or from an earth elevation model ; season ( autumn , winter , spring , summer ) – by the date in which the photo was taken . We also show the time zone ( offset from GMT ) as a separate category in addition to using it to compute local time .
3 . WEB SERVICE
We have implemented a web service to supply a subset of the metadata described in this paper to users . The service can be queried by latitude and longitude , or by latitude , longitude and time . The reply consists of place names , local time , and daylight status data . To use this web service , contact the authors . As of today , the service does not support weather as our current data source is a private company .
4 . SUMMARY
We showed some practical ways to automatically add metadata to geo and time referenced photographs using webavailable and off the shelf data sources . This metadata serves as contextual information , when browsing and searching for photographs in a collection . We are working on conducting user experiments to test the usefulness of the metadata . Additional metadata can be automatically generated using available image processing techniques , for example indoor/outdoor categorization , number of faces in the image , and prominent colors .
Finally , the metadata we describe is not specific to photographs it can be used for other types of geo temporal collections , eg geo referenced news reports .
5 . REFERENCES [ 1 ] M . Naaman , Y . J . Song , A . Paepcke , and H . G . Molina .
Automatic organization for digital photographs with geographic coordinates . In Proceedings of the Fourth ACM/IEEE CS Joint Conference on Digital Libraries , 2004 .
[ 2 ] K P Yee , K . Swearingen , K . Li , and M . Hearst .
Faceted metadata for image search and browsing . In Proceedings of the conference on Human factors in computing systems , pages 401–408 . ACM Press , 2003 .
1http://aausnonavymil/
2http://wwwwundergroundcom/
