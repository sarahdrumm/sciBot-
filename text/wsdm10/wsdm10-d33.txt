Early Online Identification of Attention Gathering
Items in Social Media
Michael Mathioudakis
Computer Science University of Toronto mathiou@cstorontoedu
Nick Koudas
Computer Science University of Toronto koudas@cstorontoedu
Peter Marbach Computer Science University of Toronto marbach@cstorontoedu
ABSTRACT Activity in social media such as blogs , micro blogs , social networks , etc is manifested via interaction that involves text , images , links and other information items . Naturally , some items attract more attention than others , expressed with large volumes of linking , commenting or tagging activity , to name a few examples . Moreover , high attention can be indicative of emerging events , breaking news or generally indicate information items of interest to a vast set of people . The numbers associated with digital social activity are astonishing : in excess of millions of blog posts , tweets and forums updates per day , millions of tags in photos , news articles or blogs . Being able to identify information items that gather much attention in such a real time information collective is a challenging task .
In this paper , we consider the problem of early online identification of items that gather a lot of attention in social media . We model social media activity using ISIS , a stochastic model for Interacting Streaming Information Sources , that intuitively captures the concept of attention gathering information items . Given the challenge of the information overload characterizing digital social activity , we present sequential statistical tests that enable early identification of attention gathering items . This effectively reduces the set of items one has to monitor in real time in order to identify pieces of information attracting a lot of attention .
Experiments on real data demonstrate the utility of our model , as well as the efficiency and effectiveness of the proposed sequential statistical tests .
Categories and Subject Descriptors J.7 [ Computer Applications ] : COMPUTERS IN OTHER SYSTEMS—Real time ; H.m [ Information Systems ] : MISCELLANEOUS
General Terms Measurement
Keywords Social media analysis , User activity modeling and exploitation
1 .
INTRODUCTION
Activity in social media such as blogs and micro blogs ( hosted by eg , Blogger , Wordpress , LiveSpace , Twitter , Jaiku ) , social networks ( eg , Facebook , MySpace , Friendster ) , multimedia sharing services ( eg Youtube , Flickr ) or online newspapers and magazines has been increasing at a phenomenal pace . Millions of individuals participate daily in a social process of information exchange , generating information items such as blog posts , images , videos or status messages , as well as engaging with each other ’s generated items , eg by leaving comments or sharing them with friends . Indicative of the participation in social media are the 300 million users of MySpace and Facebook [ 1 , 9 ] , the more than 30 million regularly updated blogs [ 2 ] , millions of users of Twitter , Youtube , Flickr , etc . At an abstract level , individuals participating in social media can be thought of as information sources that emit units of information in a streaming fashion . Digital items such as blog posts , videos , pictures and short ‘status’ messages are all examples of information units . Besides acting as information sources , individuals also interact with each other . For instance , friends in a social network such as Facebook or Friendster visit each other ’s profiles to view the newly updated status messages or posted pictures and possibly engage with them . Engaging with an item involves performing actions such as leaving a comment , rating it or recommending it to others who might find it interesting .
Naturally , some generated items gather more attention than others . For example , blog posts , pictures or videos related to important emerging events often attract significant number of links and comments in a few hours . Distinguishing those items among the plethora of items generated in social media necessitates the definition of a measure for attention gathering potential , ie the ‘ability’ of items to attract their audience ’s attention and stimulate their reactions . In the case of blogs , for example , common measures include the total number of attracted links or comments , the number of distinct linkers ( as it is the case with Technorati [ 3] ) , etc .
Such measures , however , fail to capture significant temporal aspects of social media activity . For instance , consider a blog post p1 that attracts 10 links after remaining on the front page of its hosting blog for 1 week . Consider , as well , a blog post p2 that also attracts 10 links , but only after remaining on the front page of its hosting blog for 1 hour . Taking into account the time each post remained visible on a blog webpage , it is reasonable to claim that post p2 is associated with higher potential in attracting links than post p1 , even though the total number of links is the same . As another example , consider different blogs that are visited with varying rates by their readers . A post p3 published on a blog that is rarely visited by its readers is less probable to attract the same number of actions ( links or comments ) with a post p4 published on a frequently visited blog . Therefore , in case p3 attracts the same number of actions
301 with p4 , that fact should be interpreted as p3 having larger attention gathering potential than p4 . These examples indicate that it is more intuitive to measure the attention gathering potential of items by taking into account not only the total number of actions they attract , but also temporal aspects of social media activity .
To capture such temporal aspects , we propose a novel measure of attention gathering potential that encompasses the temporal dimension . The measure is derived from the analysis of ISIS , a general stochastic model for Interacting Streaming Information Sources that is carefully defined to intuitively follow the way individuals in social media generate and engage with each other ’s items . In what follows , items with large attention gathering potential will be referred to as ‘attention gathering items’ .
Activity in social media is a dynamic process , with a large number of new items generated continuously and attention constantly shifting among items . In such a dynamic setting , it is important that attention gathering items are identified in real time , as social media activity evolves . For example , if a recently published blog post reports an interesting story that attracts a significant number of links from other sites and comments from its viewers , it is preferable to report it in real time , as it might correspond to important emerging news ( a crisis , accident , announcement , etc ) . Therefore , identification of attention gathering items is best suited as an online – rather than offline – task . Also , given the large volume of data such a task needs to process in real time , it is more efficient to prune from consideration as early as possible items that do not appear likely to attract much attention and focus on monitoring a smaller candidate set of items with larger attention gathering potential .
A heuristic way to identify attention gathering items in online fashion is the following : “ Maintain the number of actions each item attracts over time and report as ‘attention gathering’ the ones that exceed a threshold k . Also , discard items that do not exceed the threshold after dt time from their creation . ” However , setting the parameters k and dt in a meaningful way that takes into account temporal aspects of social media activity , is a non trivial issue : How would k be set for sources that interact at different rates with other sources ? If we wish to prune items that do not gather attention , what would be the ‘right’ value for dt so that we discard them early , but also avoid missing items that exceed threshold k later ?
To address the aforementioned issues , we present a principled approach that uses sequential statistical tests in order to achieve early online identification of attention gathering items . The tests are based on the assumptions of the ISIS model and allow for the exploration of trade offs between early reporting of results and quality . Experiments over real data from social media activity demonstrate that this approach can achieve significantly early identification of attention gathering items , compromising little quality in its results .
To summarize , we make the following contributions : • We propose and analyze ISIS , a general stochastic model for interacting streaming information sources .
• Under ISIS , we derive a measure for the attention gathering potential of information units , that incorporates temporal aspects of social media activity in an intuitive way .
• We present sequential statistical tests for early online identi fication of items with large attention gathering potential .
• We present experimental results on real data collected from a period of blogging activity . The experiments demonstrate the application of the model in real world scenarios and attest to the efficiency and effectiveness of the proposed statistical tests for early identification of attention gathering items .
To the best of our knowledge , this is the first work in the context of social media that formalizes and addresses the problem of early online identification of attention gathering items . 1.1 Roadmap
The paper is organized as follows . Connection with previous work is discussed in section 2 . The technical part of the paper is covered by sections 3 and 4 . In section 3 , we describe ISIS , a model that intuitively follows the way social media activity evolves and we propose a measure for attention gathering potential . Subsequently , based on the model and its analysis , section 4 describes how sequential tests are used in order to achieve early , online identification of items with large attention gathering potential . Section 5 provides experimental results from the analysis of a blogging activity period that demonstrate the trade offs in the performance of the sequential tests over real data . The paper concludes with section 6 .
2 . RELATED WORK
Link analysis has been widely used to obtain measures for the ‘importance’ of webpages [ 7 , 8 , 17 , 20 ] . Conventionally , webpages are modeled as nodes of a graph , with directed edges between nodes corresponding to hyperlinks between webpages [ 18 ] . Importance values are then obtained for each webpage using graphrelated measures – for example , the PageRank of a webpage is such a graph based measure ( [7 ] provides an in depth summary of link analysis approaches ) . Yet , the way social media activity evolves suggests a departure from the traditional web model . For instance , linking in social media is explicitly associated with individual documents , pictures , news articles , etc and not just with the webpages that host those items . Therefore , it is reasonable to have separate measures for the importance or attention gathering potential of different items . Moreover , linking activity in social media is the product of continuous interaction between participating individuals . Dynamic aspects of this process ( such as the rate with which content is generated or interactions occur ) are not captured by the graph model , since it only considers the total number of links between webpages . Finally , linking is not the only action by which structure arises in social media , as individuals also interact by commenting , sharing , recommending or rating items they encounter online . In summary , in the case of social media , individual webpages are better modeled as information sources that emit information units in a streaming fashion and interact by dynamically performing different types of actions upon each other ’s units . In this work , we provide a first formal definition and analysis of such a model and use it as a basis to identify attention gathering items in online fashion .
Since attention gathering items possibly point to emerging events , our work has some affinity to event detection [ 4 , 10 , 11 , 16 , 19 , 23 ] . Note , however , that there are strong dissimilarities between the two . As described in [ 4 ] , the goal of event detection is to identify stories over a collection or stream of documents . Text analysis is applied towards that end , possibly taking into account linking activity or an underlying social network structure [ 23 ] . On the contrary , our work identifies individual items that attract a significant number of actions and its main focus is ‘early identification’ of such items – ie given a definition of what constitutes an ‘attention gathering item’ , identify it as early as possible .
3 . THE ISIS MODEL
In this section , we present ISIS , a model for interacting streaming information sources , that intuitively follows the way social media activity evolves and captures the concept of attention gathering
302 information items . The formal definition of the model is given in section 3.1 and its analysis is provided in section 32 Notation used in this section and throughout the paper is summarized in table 1 . time period under study streaming information source the set of sources information unit set of units emitted by source u ∈ U set of all units generated during T creation time of unit p validity period of unit p the rate at which other sources interact with source u the set of interaction rates for all sources in U action timestamp of action x interaction weight of unit p
T u U p Pu P tp dp λu Λ x tx wp W set of interaction weights of all units in P Xp Xu X the set of all actions attracted by units in P the set of actions attracted by unit p the set of actions attracted by units of source u infinite amount of time . For example , readers of a blog are not expected to read and comment on posts that were created a long time ago or have been removed from the front page of that blog . In practice , we consider the validity period to be equal to the time interval for which a post , news article , status update or other item remains on the front page of the related blog , news portal , social network profile , etc . During the validity period of a unit , we refer to the unit as valid .
For the purposes of the analysis that follows in section 3.2 , assume that all quantities refer to social media activity that takes place during a time period T . In particular , let Pu denote the set of all units p emitted by source u ∈ U and P denote the set of all units .
[
P =
Pu u∈U
Table 1 : Notation
3.1 Model Definition
The purpose of the ISIS model is to serve as an abstraction of social media activity . Information sources ( or ‘sources’ , for simplicity ) in the model correspond to individuals contributing information . A source is assumed to participate in two sets of stochastic processes :
1 . The process of emitting information units in a streaming fashion .
2 . Processes of interaction with other sources .
Information units ( or , simply , ‘units’ ) emitted by sources conceptually correspond to items such as blog posts , status messages , photos , etc that appear in the social media stream . Interaction between sources corresponds to individuals engaging with each other ’s items . Thus , interaction between sources is assumed to involve sources performing actions upon units emitted by other sources . In the ISIS model , the notion of ‘action’ is used to represent different forms of engagement with items ( such as linking , commenting , recommending , etc ) . The two sets of processes are subsequently described in detail ( Subsections 311 and 312 )
311 Emission of Information Units Consider a set U of streaming information sources . A source u ∈ U emits units according to a stochastic process , with every arrival of the process corresponding to the emission of a unit p ( Figure 1 ) . For example , units emitted by a source might correspond to blog posts published on a blog . Each unit p is associated with two time values , a timestamp tp and a validity period dp , both of which are known ( observed variables ) .
Timestamp tp denotes the time when unit p is emitted . For example , posts published on a blog or status updates on micro blogging websites ( eg Twitter ) are accompanied by a timestamp declaring the time the post or status update was generated .
Validity period dp is used to model the temporary nature of social media activity , ie the fact that items generated in social media do not remain relevant , interesting or available to the public for an
Figure 1 : Information source . Each unit is associated with a timestamp tp and a validity period dp . Notice that validity periods of units emitted by the same source might overlap .
312 Interactions between Streaming
Information Sources fi with another source u , there is a probability that u
Besides emitting information units , sources also interact with each other – eg , friends in a social network interact by visiting each other ’s profile webpage . Moreover , during interactions of a fi source u performs an action upon valid units of u . For example , while individuals interact with their friends in a social network by visiting their profiles , they sometimes perform an action ( eg leave a comment ) upon their friends’ posted items ( pictures , status updates , etc ) . The time tx an action x occurs is known ( observed variable ) . For instance , when a person leaves a comment on an item , the comment is accompanied by a timestamp that declares the time the action took place .
In general , it is not possible to know when interactions occur , unless they involve an action . For example , it is not possible to determine when friends in a social network visit each other ’s profiles , as browsing history information is only available to the administrator of the social network website . Consequently , the time interval fi δt between successive interactions of source u with another source u is a latent ( unobserved ) variable . In interest of simplicity , the process by which interactions occur is assumed memoryless . Specifically , a source ui ∈ U is assumed to interact with source uj ∈ U \ {ui} according to a Poisson process Iui,uj ( λuj ) of rate λuj [ 12 ] , with every arrival of the process corresponding to a single interaction of ui with uj . Equivalently , for any two successive interactions of ui with uj at times tk and tk+1 , the inter arrival interval δt = tk+1 − tk of process Iui,uj ( λuj ) is the value of a random variable Δt that follows an exponential distribution with parameter λuj .
P r(Δt = δt ) = Exp(λuj ) = λuj e
−λuj
δt
Interaction rate λu is a latent variable , the value of which can be estimated based on the values of observed variables , as explained in detail in section 32
303 Notice that interactions between sources are not assumed to be the process according to which a source u ∈ U symmetric , ie fi ∈ U is assumed distinct and indeinteracts with another source u fi pendent from the process according to which u interacts with u . Notice also that the rate λuj with which source ui interacts with source uj is assumed to depend on uj only and it will be referred 1 . In what follows , Λ will be to as the interaction rate of source uj used to denote the interaction rates of all sources .
Λ = {λu|u ∈ U}
Figure 2 : Source interaction . fi with source u , u fi During interaction of source u might perform an action upon a valid unit p of u . More specifically , it is assumed that each valid unit p emitted by a source u is associated with an interaction weight wp that determines the probability that a source fi which interacts with source u performs an action upon p . For u example , when a blog post p is viewed by a reader for the first time , the reader leaves a comment to p with probability wp .
Interaction weight wp is not known a priori ( it is a latent variable ) . However , it can be estimated , given the number of actions unit p attracts , its validity period dp and the interaction rate λu of source u . At a high level , the values of dp and λu determine the fi number of interactions of sources u with source u that occur while p is valid and therefore how many ‘chances’ unit p has to attract an action . The smaller the values of dp and λu , the smaller is the expected number of such interactions . Therefore , for a given number of actions attracted by unit p , the smaller its validity period dp and/or interaction rate λu , the larger the estimated value of wp . On the other hand , for fixed values of dp and λu , the larger the number of actions attracted by unit p , the larger its estimated wp . This connection between interaction weight wp and other variables ( number of actions , dp and λu ) is shown analytically in section 3.2 and experimentally in section 52
We propose and use the estimated value of wp as a measure for the attention gathering potential of items . In contrast with measures based solely on the number of actions an item attracts , the estimated value of wp is not only a function of the number of actions , but it also depends on temporal aspects of social media activity captured by dp and λu and has an intuitive interpretation as a probability value in the ISIS model . Estimation of wp through maximum likelihood analysis will be the subject of section 32
In formal terms , if an arrival of process Iui,uj ( λuj ) occurs at time t , source ui performs an action x upon unit p emitted by source uj with probability action
P r
( p ) = wp
1One could consider a more general model with a distinct interaction rate λui,uj for each pair of sources ui , uj . However , in order to keep the presentation and analysis of the ISIS model as simple as possible , we make the assumption that all sources ui interact with uj at the same rate λuj . as long as unit p satisfies the following two constraints : ( 1 ) p is valid at time t and ( 2 ) t is the first time ui interacts with uj while unit p is valid . The two constraints are imposed to model in a simple manner the temporary nature of social media activity , ie the fact that items do not attract actions for an infinite amount of time . If any of these two constraints is not satisfied , ui performs no action upon unit p . Each action x is associated with a timestamp tx that denotes the time it occurred and which coincides with the time of the corresponding arrival of process Iui,uj ( λuj ) .
In the example of figure 2 , each arrow corresponds to an arrival of process Iui,uj ( λuj ) and thus to an interaction of ui with units emitted by uj . According to this specific example , interactions occur at times t1 , t2 , . . . , t5 and according to ISIS , source ui might perform an action upon units p1 , p2 , p3 at times t1 , t3 , t5 , respectively , each time with probability wpi , i = 1 , 2 , 3 . However , it cannot perform an action upon any item at time t2 , since there is no valid unit emitted by source uj at that time , nor at time t4 , since ui had already interacted with uj at time t3 , while unit p2 was still valid .
In principle , one can model different types of actions with different w ’s associated with each of them ( ie use different w ’s for the actions of linking , commenting and so on ) . In interest of simplicity , a single type of action is assumed in this work ; however extension of the model to more than one types of actions is straightforward . In what follows , W will be used to denote the set of interaction weights for all emitted units p ∈ P
W = {wp| emitted unit p ∈ P} .
In addition , let Xp denote the set of actions x along with their associated timestamp tx attracted by a single unit p and Xu denote all actions ( together with their timestamps ) attracted by units p of source u . ( Notation p ∈ u will be used to denote that unit p has been emitted by source u ) . X will denote the entire set of actions created during T .
[
[
Xu = p∈u
Xp , X =
Xu u∈U
3.2 Analysis
In this section , a maximum likelihood analysis for ISIS is provided . The purpose of the analysis is to estimate the values of latent variables W and Λ given the values of the observed variables .
Consider the two examples shown in figure 3 . Both depict source u emitting a unit p at time tp , with the unit remaining valid for period dp . However , in figure 3(a ) unit p attracts a small number of actions in total , while in 3(b ) unit p ends up attracting many actions . If an estimate has to be derived for the respective interaction weights w0 , w1 of unit p for the two cases , then , since the number of actions attracted by unit p in fig . 3(b ) is more than in fig . 3(a ) in the same time period , interaction weight w1 will be larger than w0 . w0 < w1
In other words , since under ISIS a higher value of wp implies a larger expected number of attracted actions |Xp| for unit p , then maximum likelihood analysis returns higher estimates for wp when a larger number of actions |Xp| is observed . However , the number of actions |Xp| attracted by a unit p emitted by source u does not depend only on wp . In fact , besides wp , |Xp| also depends on the validity interval dp of unit p and the interaction rate λu of source u . Specifically , a larger validity interval dp or interaction rate λu implies a larger expected number of actions |Xp| under ISIS . Therefore , the same value of |Xp| might
304 tp unit p source u tp unit p source u tp+dp
Time actions tp+dp
Time actions
( a )
( b )
Figure 3 : Small and Large wp . lead to different ( smaller or larger ) estimates for wp , depending on the value of dp or λu . For example , if two units p1 ∈ u , p2 ∈ u fi have the same number of attracted actions |Xp1| = |Xp2| but different validity periods dp1 < dp2 then , unit p1 will have a larger estimated interaction weight than p2 , since it attracted the same number of actions in less time . wp1 > wp2
321 Maximum Likelihood Estimation
Assume that the sets of observed variables P and X are available for a period T . Based on their values , the maximum likelihood values for the sets of latent variables Λ and W are computed . Let u ∈ U be a source that emits a sequence of units Pu = [ p1 , p2 , . . . ] during time period T and let Xp = [ x1 , x2 , . . . ] be the set of actions attracted by unit p . Then , the log likelihood function of the latent variables is given by the formula X
X
L(W , Λ ) = log P r(X|P ; W , Λ ) =
Lp(wp , λuj ) uj∈U p∈Puj with
Lp(wp , λuj ) = log P r(Xp|tp , dp ; wp , λuj ) , p ∈ uj
( 1 )
( 2 ) being the log likelihood of a unit p attracting actions Xp , given its time values tp , dp , its interaction weight wp and the rate λuj of interactions with source uj . Calculating the rhs expression of equation 2 ( details omitted due to space restrictions ) , we get ( tx − tp ) + Lp(wp , λuj ) = |Xp| log(λuj wp ) − λuj · ( N − |Xp| ) log(1 − qpwp )
( 3 ) with N = |U| being the total number of sources participating and qp being the likelihood that source ui has interacted with uj while unit p was valid .
X x∈Xp qp = 1 − e
−λuj dp this does not happen . Maximizing L(W , Λ ) requires W , Λ such that
8< :
∇L(W , Λ ) = 0 0 ≤ w ∈ W ≤ 1 λ ∈ Λ ≥ 0 .
( 4 )
System 4 can be solved using well known numerical methods [ 13 , 21 , 15 ] . A special case of the model that helps obtain better intuition upon the solutions of system 4 is analyzed in the following section .
322 A special case According to the definition of ISIS ( Section 3.1 ) , units p ∈ u are assumed to be associated with an interaction weight wp , that fi determines the probability they attract an action from sources u interacting with u . No further assumption is made about weights wp , apart from the fact that they take values in the range [ 0 , 1 ] . To gain some intuition into solutions of system 4 , assume that all units p emitted by source u ∈ U share the same interaction weight wu ( 5 ) p ∈ Pu wp = wu , and that the units are emitted and remain valid uniformly over time , ie that dp = du = k · T|Pu| , p ∈ Pu , k = constant
( 6 ) where k denotes the number of items of source u that are valid at the same time . Assume also that all sources share the same interaction rate λ – which will be referred to as the global interaction rate .
λu = λ , u ∈ U
( 7 )
As it is easy to verify , for a fixed value of λ , the interaction weights wp = wu of units p emitted by source u are given by the formula
|Xu|
|Xu| wp = wu =
N · |Pu| · qp = −λudp = 1 − e
N · |Pu| · ( 1 − e−kλu T /|Pu| ) −λudu = 1 − e
−kλ T /|Pu|
( 8 ) where qp = 1 − e is the fi probability a source u interacts with source u while a particular unit p is valid . Let us consider two extreme cases for λ in relation with du . Case 1 : λk T|Pu| = λdu → 0 . Then , qp = 1 − e
−λdu ≈ 1 − ( 1 − λdu ) = λdu = kλ · T /|Pu| and wu = wp ≈
|Xu|
N · |Pu| · λ · du ∝ |Xu|
λT
|Xu|
N · |Pu| · λ · k · T|Pu|
=
∝
∝ |Xu|
Case 2 : λk T|Pu| = λdu → ∞ . Then , and qp = 1 − e
−λdu ≈ 1 − 0 = 1 wu = wp ≈
|Xu|
N · |Pu| · 1
∝ |Xu| |Pu|
The first two terms of equation 3 represent the probability that a source ui interacts with item p while it is valid and performs an action x at time tx , while the third term expresses the probability
The first case demonstrates that when the rate λ at which other sources interact with source u is small compared to the rate |Pu|/T = −1 u at which source u emits units , then the estimated value of the d
305 interaction weight wu is determined by the average number of acλT and thus by the total number |Xu| of |Xu| tions per interaction attracted actions , since all sources u share a global interaction rate λu = λ . |Pu|/T = d number of actions per unit emitted .
On the other extreme , when rate λ is large in comparison with −1 u , then the value of wu is determined by the average
The value wu , estimated under the assumptions of equations 5 , 6 and 7 , will be referred to as the aggregate interaction weight of source u ∈ U . As it is also the case with interaction weight wp of individual items p , wu has a simple and intuitive interpretation as a probability in ISIS and characterizes the overall ‘ability’ of a source u to attract actions from other sources with its units . Thus , just as interaction weights wp are used to measure and compare the attention gathering potential of individual items , aggregate interaction weights wu are used to perform a similar comparison at the source level .
4 . EARLY ONLINE IDENTIFICATION OF
ATTENTION GATHERING ITEMS
The ISIS model provides a formal framework for the estimation of interaction weights wp of units p , as well as interaction rates λu of sources u , based on activity observed during a time period T . According to the analysis of section 3.2 , estimation is achieved by solving system 4 and is performed in offline fashion , after data from period T is collected . In the context of social media monitoring , units p with large estimated interaction weight wp correspond to items with high attention gathering potential .
In this section , we explain how ISIS is used when identification of items with high attention gathering potential needs to be performed in online fashion and return results as early as possible . The motivation for early , online identification of such items comes from the fact that they might contain information that refers to an evolving event ( eg a crisis ) or point to novel information that people deem important . When such items are identified , they are reported as ‘attention gathering items’ . At the same time , items that are not likely to be of large attention gathering potential are pruned from consideration . In this way , identification focuses on a smaller subset of candidate items .
For an illustrative introduction to the problem , consider the two cases depicted in figure 4 . Similarly with the examples of figure 3 , they involve source u emitting a unit p at time tp that remains valid for a period of length dp . However , unlike figure 3 , figure 4 provides a ‘snapshot’ of the activity up to time t within the validity period of unit p .
Let w1 , w0 be the interaction weights used in the examples of figures 3(b ) and 3(a ) , respectively , with w0 < w1 . The question addressed in this section is the following : having observed the interaction of sources U \ {u} with source u only up to time t , is it possible to decide , with high confidence , whether unit p has a large interaction weight w1 or a small interaction weight w0 ? In fig . 4(b ) , for example , unit p has attracted many actions up to time t . Under the assumptions of ISIS , it is reasonable to predict that unit p will indeed end up with a large number of attracted actions until the end ( tp + dp ) of validation period , just as in fig3(b ) Thus in the example of fig . 4(b ) , we have strong early indication that unit p has large interaction weight wp rather than small and that it is more likely to be wp = w1 rather than wp = w0 . On the contrary , the example of figure 4(a ) is more similar to that of figure 3(a ) , and the small number of actions attracted by unit p up to time t indicate that its interaction weight wp is more likely to be ‘closer’ to w0 than to w1 . More formally , consider a source u with known interaction rate tp t tp+dp
Time unit p source u tp unit p source u actions
( a ) t actions
( b ) tp+dp
Time
Figure 4 : Early Identification .
λu . In practice , λu is estimated offline according to the analysis of section 3.2 , based on activity of source u during a recent time period T . The value of λu is considered to remain relatively invariant over short time periods and we make sure that new estimates of its value are obtained regularly . For each unit p emitted by u , we wish to resolve as early as possible and with high confidence whether the interaction weight wp associated with p is large or small , where ‘small’ and ‘large’ are quantified by two values of interaction weight wu
1 , that are given as input .
0 < wu
Specifically , based on the actions Xp unit p gathers with time , we attempt to determine which of the two values , wu 1 is the more likely interaction weight of unit p . If wu 1 is decided to be the one , then unit p is reported , otherwise if wu 0 is the most likely value , it is ignored . In both cases , we require that a decision is taken with high confidence , ie that the probability our decision is mistaken is less than an error parameter .
0 or wu
The values of wu
1 can be specified in various ways . One option is that a user of a social media monitoring system who wishes to detect attention gathering items of source u in real time sets wu 0 and wu 1 , thus specifying what level of interaction weight constitutes an attention gathering item or not . A second option is to set them automatically . One way to do this is the following . If the interaction weight of units p generated by source u over a recent time period T have an average of mu = avgp∈u(wp ) and a standard deviation of su = stdp∈u(wp ) , then wu
1 are set to
0 , wu u 0 = mu w
0 and wu 1 = mu + 2 · su . w u
The rationale for this selection of values is that if interaction weights wp follow a Gaussian distribution with mean mu and standard deviation su , then the probability of interaction weight higher than mu + 2su is less than 5 % and thus it would be intuitive to report p as ‘attention gathering’ . Notice that , in this way , items of source u that are identified as ‘attention gathering’ are not necessarily ones with large interaction weight in absolute terms , but rather ones that have significantly large interaction weight relatively to the average estimate obtained from period T . 4.1 Early Identification
In this section , we explain how sequential tests [ 14 , 22 ] offer a principled way to address the problem under discussion . For a source u ∈ U , two interaction weight values wu 1 are specified . For every unit p emitted by u , consider hypotheses H0 and H1 .
0 , wu p 0 : wp = w u 0 H u p 1 : wp = w 1
H
( 9 )
306 To decide which of the two hypotheses to accept , we apply sequential test S , which is summarized in table 2 . Specifically , we observe the actions X t p attracted by p in the time period [ tp , t ] . Every time t such an observation is made , a decision about which hypothesis to accept is based on the likelihood ratio rt =
Lt 1 Lt 0
=
P r(X t P r(X t p|tp ; wu p|tp ; wu
1 , λu ) 0 , λu )
, p till time t .
1 are the likelihoods that unit p has interaction weight
0 , Lt 1 , given that it attracts actions X t where Lt 0 or wu wu If rt is sufficiently large , then hypothesis H1 is accepted . How large rt needs to be for H1 to be accepted is specified by test S based on the error parameter . Similarly , if rt is sufficiently small , then hypothesis H0 is accepted . In the case that rt is not small or large enough to decide which hypothesis to accept , the same procedure is repeated after a small time interval δs . In case the validity period dp of unit p expires before a decision is made , a decision is immediately made in favor of the hypothesis that corresponds to the larger likelihood Lt
1 at time t = tp + dp .
0 or Lt
At any point in time , we maintain a set C of units that are candidates to be identified as attention gathering . All units are added to set C as soon as they are generated and remain its members for p as long as test S has not decided which of the two hypotheses H 0 p 1 to accept . Units are removed from set C when test S termior H p nates . If hypothesis H 1 is accepted , they are reported as ‘attention gathering’ , otherwise they are discarded . consists of the activity of the 1000 most ‘active’ blogs in that period , ie the blogs that attracted the most links from their viewers . In total , the dataset contained 280k posts , as well as 180k links attracted from those posts .
The correspondence between blogging activity and ISIS is displayed in table 3 . According to that , the set of blogs that were active during period T act as streaming information sources , with blog posts as their emitted units . Moreover , blogs interact when blog owners visit the webpage of other blogs and they perform the action of linking upon each other ’s posts – ie during interaction fi of blog u with blog u , blog u possibly creates a link towards a fi blog post p generated on blog u . Given this correspondence , the notation used previously for the definition of ISIS ( Section 3 ) will also be used for the description of the experiments .
Table 3 : Correspondence between Model & Data
Blogging Activity
ISIS Model
Blog Post Visit a Blog owner visits another Blog
Link
Streaming Information Source
Emitted Information Unit
Interaction between Sources
Action from a Blog to a Post performed by a Source upon a Unit
Table 2 : Sequential Test S
5.1 Attention Gathering Items tp ≤ t ≤ tp + dp tp + dp < t
1−
Condition rt < 1− ≤ rt ≤ 1− 1− < rt Lt 1 < Lt 1 ≥ Lt 0 Lt 0
Decision wp = wu 0 no decision yet wp = wu 1 wp = wu 0 wp = wu 1
Sequential test S allows for the exploration of a trade off between error parameter ( ie the probability a correct decision is reached before the test is truncated ) and the number of observations the test collects before one of the two hypotheses is accepted . More specifically , the larger error , the smaller is the time needed for a decision to be reached . In section 5 , this trade off is displayed experimentally over real datasets and it is shown that early identification can be achieved by compromising little quality in the results .
5 . EXPERIMENTS
We provide experimental results from the application of ISIS ( Section 3 ) and usage of sequential tests [ 22 ] ( Section 4 ) on real social media data . In particular , section 5.1 presents real examples of attention gathering items that prove that ISIS is able to identify items related to emerging events and/or of increased interest to social media audience . Subsequently , section 5.2 demonstrates the ability of interaction weight w to capture temporal aspects of social media activity . Finally , section 5.3 presents the trade offs that arise from the usage of the sequential tests .
The dataset used in the experiments was collected from BlogScope
[ 5 , 6 ] , a social media warehousing platform developed at the University of Toronto and which currently hosts a multi terabyte collection of data from social media activity . In particular , experiments were performed over real data from a 15 day period of blogging activity ( T = [ May 1st 2008 May 15th 2008] ) . The dataset
In this part of experiments , we give examples of blog posts that are identified as attention gathering items under ISIS . Following section 4 , for each post p generated by blog u we compare two hypotheses , H p 0 and H p 1 . p 0 : wp = w u 0 H u p 1 : wp = w 1
H
If the average value of interaction weight wp for posts p of blog u is mu = avgp∈u(wp ) during a recent period of activity and standard deviation is su = stdp∈u(wp ) , then wu
1 are set as
0 and wu u 0 = mu w u 1 = mu + 2su . w
Test S is performed with error parameter = 0 and posts p for which hypothesis H p 1 gets accepted are reported .
We present examples of posts that are reported as attention gath
0 ,wu ering items . The posts come from two specific blogs , ie engadget . com and techcrunch.com and the wu 1 values that were used for each blog during test S are mentioned in table 4 . For illustration purposes , figure 5 contains the values of interaction weights wp of posts belonging to the two blogs , as estimated by solving system 4 . The bottom horizontal line in each plot inside figure 5 corresponds to wu 0 while the top horizontal line corresponds to wu 1 . The posts that were identified as ‘attention gathering’ from test S are the ones with interaction weight wp that was closer to wu 1 than to wu 0 .
A sample of these posts ( ie ones that were identified as attention gathering items ) is shown in table 5 . For example , on March 12th engadget.com published a post titled ‘iPhone OS 3.0 is coming , preview on March 17th’2 . The post reported on emerging news about the release of a new operating system for iPhone and attracted nearly 100 links from other blogs that also reported on the news and cited engadget.com as their source . Similarly , on March
2http://wwwengadgetcom/2009/03/12/ iphone os 3 0 is coming march 17th/
307 4th techcrunch.com published a post with title ‘Facebook ’s response to Twitter’3 . The post commented on the just announced change in Facebook ’s design and attracted a large number of links from other blogs that also commented on the news . The examples indicate that ISIS successfully identifies items related to emerging events or draw much attention from social media users .
Table 5 : Attention Gathering Posts wwwengadgetcom
Microsoft shows a glimpse at the future of computing
Apple notebook in Q3 iPhone OS 3.0 is coming March 17th
Ubuntu 9.04 ported to Nokias N8x0 internet tablets’
Third party iPod Shuffle headphones will require license
Apple planning a March 24 event wwwtechcrunchcom
Big music will surrender but not until at least 2011
GrandCentral to finally launch as Google Voice
Google privacy blunder shares your docs without permission
Wolfram Alpha computes answers to factual questions
Facebook ’s response to twitter
It ’s time to start thinking of Twitter as a search engine
( a )
( b )
Figure 5 : Interaction weights of posts in ( a ) engadget.com ( b ) techcrunchcom
Blog engadget.com techcrunch.com
Table 4 : Blogs 4.8 · 10−6 4.6 · 10−6 w0 w1
2.6 · 10−5 2.3 · 10−5
5.2 Connection between Λ , W
In previous sections of this paper , we propose and use interaction weight wp as an intuitive measure for the attention gathering potential of items p , that is not based only on the number of actions attracted , but also takes into account the temporal dimension of social media activity . The purpose of this part of experiments is to demonstrate that dependence of interaction weights on the temporal dimension through real examples . Towards that end , we apply the analysis of section 3.2 on the blogging activity dataset collected from BlogScope and exhibit the connection between latent variables Λ and W of ISIS .
In fact , in order to keep the presentation simple , we focus on the connection between global interaction rate λ and aggregate interaction weight wu of blogs u ∈ U , defined in section 322 Following section 322 , we assume that all blogs U share the same
3http://wwwtechcrunchcom/2009/03/04/ facebooks response to twitter/ interaction rate λ
λ = λu , u ∈ U and that posts of the same blog u ∈ U share the same length of validity period dp = du = k · T|Pu| , p ∈ u .
The value of constant k is set to k = 50 , as it was experimentally found that for this value most ( nearly 90 % ) of observed links were included in the validity periods of the corresponding posts . Based on these assumptions and solving system 4 , we estimate the aggregate interaction weight wu of blogs u based on three different −1 , λ = and explicitly set values of λ ( λ = 10 −1 , h = 1 hour ) . For each value of λ , the 10 blogs with 10 maximum wu were computed and are reported in figures 6(a ) , 6(b ) and 6(c ) , respectively .
−1 , λ = 10
−5h
−3h
−1h
The results in figure 6 are consistent with the theoretical analysis of section 322 More specifically , for small interaction rate λ , aggregate interaction weight wu is determined by the total number of links . For this reason , the list of blogs with maximum wu ( Figure 6(a ) ) is dominated by the blogs with largest total number of links . On the other hand , for large λ values , wu is determined by the average number of links per post . Consequently , the list of blogs with maximum wu ( Figure 6(c ) ) is dominated by blogs with the largest average number of links per post . Finally , when the value of λ is neither too big nor too small , the list of blogs with maximum wu is mixed both with blogs with large total number of links or large average number of links .
The results demonstrate an intuitive relationship between interaction weights and interaction rates . In an setting where sources interact very frequently with each other , all generated units have the ‘chance’ to attract an action . Therefore it is reasonable to estimate the ‘ability’ of a source to attract actions by the average number of actions attracted per unit . On the other hand , in a setting where sources rarely interact with each other , the average number of actions attracted per unit is not a reasonable measure anymore : it would underestimate sources that emit many units , most of which do not actually get a ‘chance’ to attract an action while they are valid . In such settings , it is more intuitive to measure the ‘ability’ of a source to attract actions by the number of attracted actions per interaction , or simply the total number of actions if the interaction rate is equal for all sources . This argumentation can be extended from the source level to the level of units p and their interaction weight wp . Under the described rationale , interaction weight wp is an intuitive measure for attention gathering potential of items , that
308 mental type I and type II error , w1 impurity and true w1 miss rate . Experimental type I error expresses the fraction of true w0 posts that are decided by test S to be of interaction weight w1 . type I error =
#(true w0 ∧ decided w1 )
#(true w0 )
Similarly , experimental type II error expresses the fraction of true w1 posts that are decided by the sequential test S to be of interaction weight w0 . type II error =
#(true w1 ∧ decided w0 )
#(true w1 )
Moreover , w1 impurity measures the fraction of posts identified as w1 that are true w0 posts . impurity =
#(true w0 ∧ decided w1 )
#( decided w1 )
Finally , miss rate expresses the fraction of true w1 posts that are either decided by test S to be of interaction weight w0 or are not decided until their validity period expires . miss rate =
#(true w1 ∧ ( (decided w0 ) ∨ ( test truncated) ) )
=
= type II error +
#(true w1 ) #(true w1 ∧ ( test truncated ) )
#(true w1 )
Efficiency is measured through average workload , ie the average number of posts over time that are considered as candidate attention gathering items . If Dp ∈ [ 0 , dp ] is the time it takes for a post to be decided either as attention gathering or be pruned from consideration , then
P p Dp T workload =
Similarly with the qualitative experiments for attention gathering items ( Section 5.1 ) , the hypotheses tested by sequential test S were p 0 : wp = w u 0 = avgp∈u(wp )
H p 1 : wp = w u
1 = avgp∈u(wp ) + 2 · stdp∈u(wp )
H
Blog engadget.com xkcd.com guardiancouk thinkprogress.org techcrunch.com hotair.com icanhascheezburger.com michellemalkin.com thestorybeginningsblogspotcom
Blog u xkcd.com thestorybeginningsblogspotcom stevenberlinjohnson grosgrainfabulousblogspotcom sethgodintypepadcom pinktentacle.com asofterworld.com funnyordie.com smashingmagazine.com
Rank
1
2
3
4
5
6
7
8
9
10
Rank
1
2
3
4
5
6
7
8
9
10
1812
519
1324
1030
926
927
862
823
224
563
7
1561
179
200
291
93
124
5
734
271
519
224
107
363
341
116
156
449
330
7
5
3
14
17
6
9
26
20
128
8
3.2
74
0.85
5.8
4.6
3.2
9.3
6.6
45
2.7
74
45
36
26
20
19
17
17
17
16
Rank
Blog
Links
Posts
Links/Post
1
2
3
4
5
6
7
8
9 engadget.com guardiancoukcom thinkprogress.org hotair.com techcrunch.com icanhascheezburger.com michellemalkin.com lifehacker.com pajamasmedia.com
1812
1324
1030
927
926
862
823
734
604
563
1561
179
291
200
93
124
271
714
10 xkcd.com
( a ) λ = 10
519
7
−5 h
−1 , dp = 50 · T|Pu|
3.2
0.85
5.8
3.2
4.6
9.3
6.6
2.7
0.85
74
Links
Posts
Links/Post lifehacker.com
( b ) λ = 10
−3 h
−1 , dp = 50 · T|Pu|
Links
Posts
Links/Post lonelyheartscasino.com
( c ) λ = 10
−1 h
−1 , dp = 50 · T|Pu|
Figure 6 : Blogs with maximum aggregate interaction weight for different λ values . takes into account the temporal aspects of social media activity .
5.3 Quality vs Efficiency Trade offs
The experiments presented in this section aim to demonstrate the performance benefits from utilizing the sequential tests described in section 4 as well as the arising trade offs in efficiency and quality . At a high level , quality in the experiments is measured by the fraction of correct decisions made by the sequential test wrt the interaction weight of a post . Since for real data it is impossible to know the ‘real’ values of interaction weights , the classical measures of precision and recall cannot be used and we thus need to resort to measures that are based on experimentally defined ‘ground truth’ . The following seems to be a reasonable choice : a post will be said to be ‘true w0’ ( ‘true w1’ ) when it is more likely to be of interaction weight w0 ( w1 ) at the end of its validity period .
Quality is measured through the following quantities : experi with avgp∈u(wp ) being the average interaction weight wp of posts p of blog u in a recent period of activity and stdp∈u(wp ) , being the standard deviation .
Figure 7 demonstrates the workload for different model errors . As shown in the figure , workload ranges from 50k posts when = 0 and sequential test S is always truncated , to 5k posts when test S is performed with = 05 Notice that by performing test S with = 0.05 , we already have a 50 % decrease in the workload .
Figure 8 demonstrates the trade off between the workload and the quality in its results , as measured by the experimental type I and type II errors ( please note that workload is normalized wrt its maximum value ) . As shown in the figure , if a type I error and type II error of 5 % is tolerated , a 50 % reduction in workload is achieved for = 005
Finally , it is interesting to notice that for small values of ( < 0.275 ) there is a trade off between miss rate and impurity ( Figure 9 ) . Recall that miss rate corresponds to true w1 posts that are either ( a ) identified as w0 ( type II error ) or ( b ) posts that test S fails to identify before it is truncated . For small most missed true w1 posts correspond to the second case . The interpretation of this trade off is that , in order to make substantial use of the sequential
309 in the sequential statistical tests as parameters that define which items are considered as ‘attention gathering’ .
In future work , we plan to explore possible extensions of ISIS to capture a wider range of behavior in the context of social media . In particular , we plan to explore the usage of stochastic modeling to capture early the development of viral phenomena or to monitor the formulation and dissolution of user communities .
Acknowledgements We wish to thank Amalia Kokkinaki and Dimitris Tsirogiannis for their insightful comments on this paper .
7 . REFERENCES [ 1 ] Is facebook growing up too fast ? , http://www.nytimes
com/2009/03/29/technology/internet/29facehtml
[ 2 ] State of the blogosphere 2008 , http://technorati.com/ blogging/state of the blogosphere// .
[ 3 ] Technorati authority and rank , http://technorati . com/weblog/2007/05/354html
[ 4 ] J . Allan , J . Carbonell , G . Doddington , J . Yamron , and
Y . Yang . Topic detection and tracking pilot study : Final report , 1998 .
[ 5 ] N . Bansal , F . Chiang , N . Koudas , and F . W . Tompa . Seeking stable clusters in the blogosphere . In VLDB , 2007 .
[ 6 ] N . Bansal and N . Koudas . Blogscope : A system for online analysis of high volume text streams . In WebDb , 2007 .
[ 7 ] A . Borodin , G . O . Roberts , J . S . Rosenthal , and P . Tsaparas . Link analysis ranking : algorithms , theory , and experiments . TIS , 2005 .
[ 8 ] S . Brin and L . Page . The anatomy of a large scale hypertextual web search engine . Computer Networks , 1998 .
[ 9 ] Facebook . Latest facebook statistics , http://wwwfacebookcom/press/infophp?statistics
[ 10 ] G . P . C . Fung , J . X . Yu , H . Liu , and P . S . Yu . Time dependent event hierarchy construction . In KDD , 2007 .
[ 11 ] G . P . C . Fung , J . X . Yu , P . S . Yu , and H . Lu . Parameter free bursty events detection in text streams . In VLDB , 2005 .
[ 12 ] R . Gallager . Discrete Stochastic Processes . 1st edition , 1995 . [ 13 ] T . Hoang . Convex Analysis and Global Optimization . 1998 . [ 14 ] P . Hoel . Introduction to Mathematical Statistics . 1984 . [ 15 ] R . Horst , P . Pardalos , and N . V . Thoai . Introduction to
Global Optimization , volume 3 of Nonconvex Optimization and Its Applications . Springer , 1995 .
[ 16 ] J . Kleinberg . Bursty and hierarchical structure in streams . In
KDD , 2002 .
[ 17 ] J . M . Kleinberg . Authoritative sources in a hyperlinked environment . Journal of the ACM , 46 , 1999 .
[ 18 ] J . M . Kleinberg , R . Kumar , P . Raghavan , S . Rajagopalan , and
A . S . Tomkins . The web as a graph : Measurements , models and methods . In Lecture Notes in Computer Science . 1999 .
[ 19 ] A . Krause , J . Leskovec , and C . Guestrin . Data association for topic intensity tracking . In ICML ’06 , 2006 .
[ 20 ] R . Lempel and S . Moran . The stochastic approach for link structure analysis ( salsa ) and the tkc effect . In TIS , 2000 .
[ 21 ] J . D . Pintér . Global Optimization in Action . 1996 . [ 22 ] A . Wald . Sequential Analysis . Dover Phoenix Editions , 1947 . [ 23 ] Q . Zhao , P . Mitra , and B . Chen . Temporal and information flow based event detection from social text streams . In AAAI , 2007 .
Figure 7 : Workload vs Model Error
Figure 8 : Trade off between workload and type I , type II errors . Workload is normalized wrt its maximum value .
Figure 9 : Trade off between miss rate and impurity , for < 0275 test ( ie do not allow it to be truncated often ) , we need to accept some increase of the impurity of the identified attention gathering items ( ie also identify some that are not true w1 ) . However , after some point ( > 0.275 ) the fraction of missed w1 posts is dominated by the type II error and the trade off between miss rate and impurity stops .
Overall , the experiments suggest that we can achieve significant decrease in the number of items we monitor by compromising little quality in the results .
6 . CONCLUSIONS AND FUTURE WORK
This paper describes how sequential statistical tests are used to achieve early online identification of attention gathering items in social media . A significant part of our contribution lies with the definition and analysis of ISIS , a stochastic model for interacting streaming information sources that follows the way social media activity evolves . Its analysis leads to an intuitive measure for the attention gathering potential of items . Values of this measure are used
310
