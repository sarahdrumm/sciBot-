2008 Eighth IEEE International Conference on Data Mining 2008 Eighth IEEE International Conference on Data Mining
Exploiting Local and Global Invariants for the Management of Large Scale
Information Systems
Haifeng Chen(1 )
Haibin Cheng(2 )
4 Independence Way , Princeton , NJ 08540
( 1 ) NEC Laboratories America , Inc . {haifeng , gfj , kenji}@nec labs.com
Guofei Jiang(1 ) ( 2 ) CSE Department , Michigan State University
Kenji Yoshihira(1 )
East Lansing , MI 48824 chenghai@msu.edu
Abstract
This paper presents a data oriented approach to modeling the complex computing systems , in which an ensemble of correlation models are discovered to represent the system status . If the discovered correlations can continually hold under different user scenarios and workloads , they are regarded as invariants of the information system . In our previous work [ 12 ] , we have developed an algorithm to automatically search the invariants between any pair of system attributes , which we call local invariants . However that method is unable to deal with the high order dependency models due to the combinatorial explosion of search space . In this paper we use Bayesian regression technique to discover those high order correlation models , called global invariants . We treat each attribute as a response variable in turn and express its dependency with the other attributes in a regression model . By adding the prior constraint of Laplacian distribution to the regression coefficients , we can find the solution in which only the correlated attributes with respect to the response have nonzero regression coefficients . After that we further consider the temporal dependencies of those extracted attributes by incorporating their past observations . We also provide a confidence metric and a validation procedure to measure the reliability of learned models . If the model does not break down in the validation , it is regarded as a true invariant of the system . Experimental results on a real wireless networking system show that the discovered invariants can be used to effectively detect system failures as well as provide valuable information about the failure source .
1 Introduction
With the rapid advances in networking and computing technology , we are facing an explosive growth of complexity in networked applications and information services . Typical systems such as Google , Yahoo! and Amazon consist of thousands of components including operating sys tems , applications software , servers , and storage and networking devices , which are widely distributed across the system . Since the system complexity appears to be approaching the limits of human capability , it is crucial to develop autonomic management tools to reduce the burden of system operators .
Meeting the grand challenges of such self management requires advanced techniques to correctly characterize the system state . One approach to achieving this relies on the expert knowledge of system structure and turns such prior knowledge into a set of event condition action rules to model the system [ 1][8 ] . However , the models and rules provided by those approaches are usually system dependent and may be incomplete and inaccurate . Recently statistical techniques [ 5][4][6 ] have been drawing a surge of interest in modeling the system activity given that large amount of measurement data can be collected from system monitoring tools . This data contains many implicit evidences about the system structure and activity . By discovering those evidences from the data and correlating them to the high level system behavior , we can effectively characterize the system status and hence facilitate many management tasks . However , there are usually huge amount of attributes and observations in the measurement data due to the large scale of computing systems , which makes the data modeling a big challenge . For instance , commercial frameworks such as HP ’s OpenView [ 7 ] and IBM ’s Tivoli [ 11 ] aggregate attributes from a variety of sources including hardware , networking , operating systems , application servers , and so on . It is hard to create a single powerful model that can effectively describe the system and efficiently deploy in practice .
To address this issue , this paper presents an invariants based solution to model the behavior of information systems . We learn an ensemble of correlation models among system attributes from a large amount of measurement data . If the dependency models continually hold under different user scenarios and workloads , they are regarded as invariants of the computing system . For example , the frequency
1550 4786/08 $25.00 © 2008 IEEE 1550 4786/08 $25.00 © 2008 IEEE DOI 101109/ICDM200851 DOI 101109/ICDM200851
113 113
Authorized licensed use limited to : NEC Labs . Downloaded on May 5 , 2009 at 09:40 from IEEE Xplore . Restrictions apply . of SQL queries issued in the backend database in a web based system is usually correlated with the frequency of HTTP requests issued at the front end as a result of fixed business logic of the application . Such relationship is usually difficult to be quantitatively described by the system operators . Our algorithm can automatically discover those implicit constraints in the system to assist operators to understand the system internal status . As a result , many management tasks can be facilitated such as failure detection , capacity planning , policy generation , and so on . For instance , by online checking the number of ‘healthy’ invariants , ie , those models that fit the online measurements well , we can identify anomalies during system operation .
In our previous work [ 12 ] , a brute force search method has been developed to explore all the pair wised correlation models in the system , which we call local invariants . In distributed systems , however , some attributes may depend on more than one other attributes . For instance , the input of a load balancer is always equal to the summation of multiple output variables . If we use the method in [ 12 ] to explore high order correlation models , which we call global invariants , we need to check all the models with various combinations of system attributes . In order to avoid the problem of ‘combinatorial explosion’ for large scale computing systems , this paper uses a statistical mining based approach to discovering global invariant models for the system . Given the measurement data , we use the regression model to express the correlation between each attribute and its related partners . That is , we treat each attribute as a response variable in turn and express its dependency with the correlated attributes in a regression model . Since we do not know how many attributes are relevant to the response and what those attributes are , we put all the rest attributes in the regression as possible independent variables at the beginning . We add Laplacian priors on the regression coefficients and formulate the dependency discovery in the Bayesian regression framework . As a result , we can expose a subset of attributes that have statistically significant relationship with the response . If such high order relationship is strong enough , we further explore the temporal dependency between the response and discovered subset of relevant attributes by incorporating their past observations . We also provide a confidence metric and a validation procedure to measure the reliability of learned models . If the model does not break down in the validation , it is regarded as a true invariant of the system . Comparing with the local invariants as described in [ 12 ] , the global invariants reveal more complex dependency relationships among the system attributes .
We have successfully applied the discovered invariants to the management of a 3G telecommunication system . It shows that the discovered global invariants are necessary additions to the previous learned local invariants . Combining local and global invariants can present a more compre hensive and effective characterization of the system behavior . The discovered invariants have been successfully applied to detect and localize the system failures . Experimental results based on the real system data demonstrate that the percentage of broken invariants is an effective indication of the failure occurrence . In addition , it is easy to pinpoint the suspicious attributes from the broken invariant set , which significantly facilitates the failure localization task .
2 Background and Related Work
To support the autonomic management of computing systems , several statistical approaches have been proposed in the literature . In the project of Magpie [ 2 ] , Barham and his colleagues collected request traces from software components in the distributed system , and used the stochastic context free grammar to model the request ’s control flow for the purpose of detecting component failures as well as localizing performance bottlenecks . The Pinpoint project [ 5 ] , a close relative to Magpie , used request path shapes and component interactions as two features to represent the user request flow across the system . The probabilistic context free grammar ( PCFG ) and χ2 statistical test were employed to model those features for detecting high level software failures in application servers . In the same context of component interaction analysis as in [ 5 ] , [ 4 ] put forward a subspace decomposition based algorithm to explore the correlations between interaction profiles of multiple components . A simplified Bayesian network model was presented by Cohen et al . [ 6 ] to discover the root cause of service level agreement ( SLA ) violations . In the work [ 3 ] , Bodik et al . made use of the user access behavior as an evidence of system ’s health , and applied several statistical approaches such as the Naive Bayes to mining such information for detecting application level failures .
( a )
( b )
Figure 1 . Examples of invariants in information systems . ( a)The input output relationship in a load balancer ; ( b)Packet volume vs . number of SQL query in a database .
The above approaches mostly focused on either a specific type of system measurements such as the request
114114
Authorized licensed use limited to : NEC Labs . Downloaded on May 5 , 2009 at 09:40 from IEEE Xplore . Restrictions apply . traces , or a specific system management task . Compared with them , our invariant based solution can accept the data measurements from various sources such as software log files and network traffic statistics , and generalize well for many system management scenarios . We observe that there exist invariant properties of system measurements since most of the attributes in measurement data are strongly correlated . For example , the resource utilizations of the system such as CPU and memory usages always increase or decrease in accordance with the change of system workloads . Furthermore , the system structure and design also introduce a lot of correlated attributes . As shown in Figure 1(a ) , assuming that a load balancer has one input I1 and three outputs O1 , O2 and O3 , we should always have I1 = O1 + O2 + O3 because this is the physical property of the load balancer . Meantime , in a web system , the volume of network packets V1 going through the database , as shown in Figure 1(b ) , should always be correlated with the number of queries issued in the database because of the underlying logic of system components . We believe there are many of such constant relationships among the measured attributes . As a consequence , an ensemble of invariant models can be discovered to correlate the large amount of monitoring data collected from various points of the system . Each invariant contains a specific dependency relationship among the measurement attributes , which reveals some specific aspects of system activity . If we put all the discovered invariants together we can achieve a comprehensive view of the system situation and facilitate many management tasks . For example ,
• By monitoring the number of ‘healthy’ invariants during system operation , we can detect unknown system failures . The detected failures can also be isolated based on the correlation of broken invariants and their related system attributes .
• Since each invariant is usually represented as a dependency function , we can use such function for system capacity planning . That is , we can predict the capacity requirements for system resources such as CPU , memory and disks under heavy workload based on the dependency functions as well as those resource usages under light system workload .
• The discovered invariants can assist system administrators to better understand the system and define rules that distinguish different system activities .
The invariants are usually identified by analyzing the historical system measurements . Given a set of monitoring data zl , l = 1 , . . . , n , with each measurement containing p attributes , zi ∈ Rp , we divide the data into two parts : one is used for training , and the other is for the validation . The purpose of training is to build dependency relationships among the data attributes , which serve as the hypotheses of system invariants . The validation process uses the second part of data to mimic actual system dynamics and sequentially validate the effectiveness of hypotheses under those situations . The hypotheses that pass the validation process are regarded as true invariants of the information system . In Section 3 we describe the work [ 12 ] of modeling the local invariants in the training process . Section 4 then presents our proposed method of discovering system global invariants . The validation of those discovered correlation models are described in Section 5 .
3 Learning Local Invariants
The proposed system invariant model has to consider both spatial and temporal dependencies among system attributes . While spatial relationship concerns the correlation across different attributes , the temporal correlation is related to dependency in consecutive measurements of each attribute along time . In the work [ 12 ] , a brute force search method is used to build correlation models between any pair of attributes x and y from the data z , y = f(x ) . The relationship between x(t ) and y(t ) is learned by the AutoRegressive model with eXogenous inputs ( ARX ) [ 13 ] y(t)+a1y(t−1)+···+any(t−n ) = b0x(t)+···+bmx(t−m ) ( 1 ) where [ n , m ] is the order of the model , which determines how many previous steps are affecting the current output . ai and bj are the coefficient parameters that reflect how strongly a previous step is affecting the current output . Let ’s denote
θ = [ a1 , ··· , an , b0,··· , bm ]
T
,
ϕ(t ) = [ −y(t − 1 ) , , −y(t − n ) , x(t ) , , x(t − m ) ] then Equation ( 1 ) can be rewritten as :
T y(t ) = ϕ(t)T θ .
( 2 ) .(3 )
( 4 )
Assuming that we have observed the measurements over a time interval 1 ≤ t ≤ N , ON = {x(1 ) , y(1 ) , , x(N ) , y(N)} , the parameter θ can be obtained by the least squares solution
ˆθN = [
ϕ(t)y(t ) .
( 5 ) t=1
−1
N .
ϕ(t)ϕ(t)T ]
N . fi''ffN N t=1 |y(t ) − ˆy(t|θ)|2 t=1 |y(t ) − ¯y|2 t=1
In order to evaluate how well the learned model ( 1 ) fits the measurement data , the following fitness score is defined
F ( θ ) = [ 1 −
] · 100 ,
( 6 ) where ˆy(t|θ ) is the estimated value of y based on equation ( 4 ) and ¯y is the mean of the real output y(t ) . A higher score
115115
Authorized licensed use limited to : NEC Labs . Downloaded on May 5 , 2009 at 09:40 from IEEE Xplore . Restrictions apply .
Note this time only a small number of attributes , x1 , ··· , xs , are involved in the time series modeling . We still use the Bayesian approach but with slight modification to identify the function ( 8 ) . Eventually we obtain a model that contains both the spatial and temporal correlations between y and its related attributes .
F ( θ ) indicates that the model fits the observed data better and its upper bound is 100 . Only a model with high fitness score is selected to characterize the data relationship . We can set a range of the order [ n , m ] to learn a list of model candidates and select a right model from them according to the highest fitness score . For more detailed description of local invariants extraction , please see [ 12 ] . Given measurements with p attributes , the above method needs to construct p(p − 1)/2 models as all possible candidates of local invariants , ie , pair wise dependency models . If we want to discover the high order dependency models among attributes , however , the above brute force search does not scale well because it requires the search of all the models with various combinations of system attributes . In the following we propose a statistical mining based method to discover those high order correlations .
4 Learning Global Invariants
While the local invariants reveal the correlations between any pair of measurement attributes , the global method explores the relationship between each attribute y and multiple other attributes ˜x = [ x1 , x2,··· , xs ] , 2 ≤ s ≤ p − 1 , where p is the total number of attributes in the measurement data z . Since all the attributes in the data are measured as time series , we have to model both the spatial and temporal correlations among the attributes . To simplify the problem , we separate these two stages in the algorithm . In the first step , we explore all the contemporary dependencies among attributes , eg identify the subsets of attributes that exhibit strong spatial correlations . Given the measurements z with p attributes , we treat each attribute y as the response in turn and express the dependency between y and other attributes in a regression model . Since we do not know how many attributes are relevant to y and what those attributes are , at the beginning we put the other p − 1 attributes in the model as possible independent variables y(t ) = β1x1(t ) + β2x2(t ) + ··· + βp−1xp−1(t ) .(7 ) We use the Bayesian technique to trim the regression coefficients βis . That is , by choosing proper prior distribution for the regression coefficients , we can force the coefficients whose associated attributes have no relationship with the response y to be exactly zeroes . As a result , we can extract a subset of variables , whose corresponding coefficients are not zero , as correlated variables with respect to the response y .
We use the fitness score as described in ( 6 ) to measure the significance of the statistical relationship between y and the extracted attributes ˜x . If it is strong enough , we further explore their dependency by incorporating their past observations y(t ) = f ( ˜x(t ) , ˜x(t− 1),··· , ˜x(t− m ) , y(t− 1),· ·· , y(t− n ) ) . ( 8 )
Figure 2 . The workflow of extracting global invariant hypotheses .
Figure 2 presents the workflow of extracting global dependency models . In Section 4.1 , we focus on the extraction of spatial correlations among attributes . Section 4.2 then models the temporal correlations among attributes .
4.1 Modeling Spatial Correlations
This section focuses on the modeling of spatial dependencies among attributes . We rewrite equation ( 7 ) in a simplified way y = β1x1 + β2x2 + ··· + βp−1xp−1
( 9 ) where β = [ β1 , β2,··· , βp−1 ] . is the regression coefficients . The common solution such as the least squares estimation for equation ( 9 ) is to maximize the likelihood p(y|β ) = exp{− ( yl − x . p(yl|β ) ∝ ( n n l β)2
} ,
1√ 2πσ2 n
) l=1
2σ2 l=1
( 10 ) where [ xl yl ] is the lth observation of measurement data and σ2 is the variance of residuals l = yl − x . l β , l = 1,··· , n . In order to extract a subset of variables that have relationship with the response y , we make a prior assumption of the distribution on regression coefficients β and use Bayesian method to find the maximum a posterior solution of ( 9 ) . It has been shown in [ 9 ] that if we choose the Laplacian prior on each coefficient βi
√ 2 exp(−√ γ
γ|βi| )
( 11 ) p(βi|γ ) =
116116
Authorized licensed use limited to : NEC Labs . Downloaded on May 5 , 2009 at 09:40 from IEEE Xplore . Restrictions apply .
Since
E[τ
( ∞ ( ∞
0
=
0
−1 i
|y , ˆσ2 ( t ) , ˆβ(t ) ] N ( ˆβi,(t)|0 , τi ) γ N ( ˆβi,(t)|0 , τi ) γ
1 τi
2 exp{ γ 2 exp{ γ
2 τi}dτi 2 τi}dτi
=
γ
| ˆβi,(t)|
, ( 18 ) thus V(t ) = γdiag{| ˆβ1,(t)|−1,··· ,| ˆβp−1,(t)|−1} .
( 19 ) • The M step carries out the maximization of ( 16 ) with respect to σ2 and β except that the matrix Γ(τ ) is replaced with its conditional expectation V(t ) . We obtain ˆσ2
( t+1 ) = arg max
) y − H ˆβ(t)2
2
=
2
σ2
σ2 ( −n log σ2 − y − Hβ2 ) −y − Hβ2 n
2
V(t)β
( 20 )
− β . .y
σ2 .
−1H
H )
( 21 ) and ˆβ(t+1 ) = arg max
β we can shrink the coefficients of irrelevant input variables to exactly zero . That is , given the data set D = [ (x1 , y1 ) , ( x2 , y2),··· , ( xn , yn) ] , by maximizing the following posterior distribution p(β|D , γ ) ∝ p(y|β)p(β|γ )
( 12 ) instead of equation ( 10 ) , we will get a model in which the coefficients of irrelevant attributes are zeroes . Since the variance σ2 in ( 10 ) is also unknown , we incorporate it into the optimization process and revise the posterior ( 12 ) as p(β , σ2|D , γ ) ∝ p(y|β , σ2)p(β|γ ) .
( 13 )
The parameter γ in the Laplacian prior ( 11 ) is a predefined constant . Here we choose γ = 01
Since the Laplacian distribution ( 11 ) is non convex , we rewrite the Laplacian prior ( 11 ) as a hierarchical decomposition of two other distributions : a zero mean Gaussian prior p(βi|τi ) = N ( βi|0 , τi ) with a variance τi that has an exponential hyper prior p(τi|γ ) = γ
2 exp{− γ
2 τi} .
( 14 )
= ( ˆσ2
( t+1)V(t ) + H
( 15 )
As a result , the distribution ( 13 ) can be rewritten as p(y|β , σ2)p(β|γ ) = p(y|β , σ2)p(β|τ )p(τ|γ ) . Suppose we could observe the values of new parameter τ = [ τ1 , τ2,··· , τp−1 ] . , then p(τ|γ ) = 1 and the posterior distribution ( 15 ) is simplified because both p(y|β , σ2 ) and p(β|τ ) in the right side of equation ( 15 ) are Gaussian distributions . We write the log posterior of the right side in equation ( 15 ) log{p(y|β , σ Γ(τ )β ( 16 ) where the matrix H = [ x1 , x2,··· , xn ] . , and Γ(τ ) = −1 p−1 ) is the diagonal matrix with the indiag(τ verse variances of all βis . By taking the derivatives with respect to β and σ2 respectively , we obtain the solution that maximizes ( 16 ) .
)p(β|τ )} ∝ −n log σ
2−'y − Hβ'2
1 , ··· , τ −1
−β . n
2
2
In reality , however , since we do not know the values of τ ( and hence the matrix Γ(τ ) in ( 16) ) , we can not maximize the equation ( 16 ) directly . Instead the following expectation maximization ( EM ) algorithm is used to find the solution . The EM algorithm is an iterative process which computes the expectation of hidden variables τ and uses such expectation as the estimation of τ to find the optimal solution . Each iteration consists of two steps .
• the E step computes the conditional expectation of ( t ) and ˆβ(t )
Γ(τ ) given y and the current estimate ˆσ2 V(t ) = E[Γ(τ )|y , ˆσ2
= diag{E[τ
1 |y , ˆσ2 −1
( t ) , ˆβ(t ) ] ( t ) , ˆβ(t)],·· · , E[τ p |y , ˆσ2 −1
( 17 ) ( t ) , ˆβ(t)]} .
117117
The EM algorithm is easy to implement , and converges to the maximum of posterior probability ( 13 ) quickly .
4.2 Modeling Temporal Dependencies
The coefficient vector ˆβ computed from the above EM algorithm contains many zeroes . By selecting those attributes with nonzero coefficients , we obtain a subset of variables ˜x = [ x1 , x2,··· , xs ] that are correlated with y as well as a function ˜f to express such dependency y = ˜f(x1,··· , xs ) .
( 22 ) We measure the fitness of function ˜f using the metric ( 6 ) , in which ˆy is the estimated value of y based on equation ( 22 ) . If the confidence score is low , we discard that model . Otherwise , we further consider the temporal dependency between y and the subset ˜x = [ x1 , x2,··· , xs ] by incorporating their past observations . Such dependency can be described in the following multivariate autoregressive model with eXogenous inputs y(t ) + a1y(t − 1 ) + ··· + any(t − n ) = b01x1(t ) + ··· + b0sxs(t ) + b11x1(t − 1 ) + · ·· + b1sxs(t − 1 ) + ··· + bm1x1(t − m ) + ·· · + bmsxs(t − m ) . ( 23 ) The values [ n , m ] denote the maximum time lags for y and xis respectively in the autoregressive modeling . If we define
θ = [ a1,··· , an , b01,··· , b0s , b11,··· , b1s , bm1,··· , bms ] ( 24 )
ϕ(t ) = [ −y(t − 1 ) , , −y(t − n ) , x1(t − k ) , , xs(t − k ) ,
T
··· , x1(t − k − m ) , , xs(t − k − m ) ]
T
( 25 )
Authorized licensed use limited to : NEC Labs . Downloaded on May 5 , 2009 at 09:40 from IEEE Xplore . Restrictions apply . the equation ( 23 ) can be rewritten in the same format as ( 4 ) , and its solution can be obtained by the equation ( 5 ) . Note we put the same maximum time lag m for all attributes x1,··· , xs in equation ( 23 ) . In reality , however , different attributes may have temporal dependency with y(t ) up to different maximum time lags . For example , some attributes may only have contemporaneous dependency with y(t ) , eg m = 0 . If we place the same maximum order m for all variables and solve the equation ( 23 ) by traditional least squares method , the results may not be accurate because many irrelevant variables are involved in the model ( 23 ) . Those irrelevant parts have to be removed in the estimation process .
γ = 0.1 γ = 1 γ = 5
1.4
1.2
1
0.8
0.6
0.4
0.2
)
|
γ β ( P
0 −6
−4
−2
0 β
2
4
6
Figure 3 . The effects of different γ values on the Laplacian distribution .
We still use the Bayesian method in Section 4.1 to prune the irrelevant variables . The difference here is that we are more interested in pruning those inputs with longer time delays because those inputs are more likely to be irrelevant to the response y(t ) . As a result , we choose different prior parameter γ values in the Laplacian distribution ( 11 ) for different coefficients to control the level of penalties for those coefficients . Figure 3 plots the shape of Laplacian distribution with different γ values . It shows that a large γ value strengthens the constraint that the coefficient β will be zero . On the other hand , small γ value conveys our expectation that the corresponding variable is correlated to the response . We utilize such knowledge and choose different γ values for the variables with different time lags in ( 23 ) . While the coefficients a1,··· , an and b01,··· , b0s in ( 24 ) are added with Laplacian prior ( 11 ) with parameter γ , the coefficients bi1,··· , bis , i = 1,··· , m are imposed with the same prior √ i + 1γ . By doing so , the old distribution with parameter observations are penalized more severely . The same EM algorithm described in Section 4.1 is used to obtain the MAP solution θ . The only modification is that in the E step the matrix V ( t ) in equation ( 19 ) is replaced with V(t ) = diag{γ1| ˆβ1,(t)|−1,··· , γp−1| ˆβp−1,(t)|−1} ( 26 ) because of different γ values . We learn a list of model candidates from a range of orders [ n , m ] and then select the one with the highest fitness score ( 6 ) as the final global invariant hypothesis associated with y(t ) .
5 Invariants Validation
Given the measurement data , we treat each attribute as the response variable in turn and use the algorithm presented in Section 4 to obtain following high order correlation model y(t ) + a1y(t − 1 ) + ··· + any(t − n )
= b0,1x1(t ) + ··· + bk1,1x1(t − k1 ) + b0,2x2(t ) + ··· + bk2,2x2(t − k2 ) + ··· + b0,sx1(t ) + · ·· + bks,sxs(t − ks ) ( 27 ) where k1 , ··· , ks are the maximum time lags for each variable . As a consequence we get a set of correlation models . However , those models only fit the training data well . They may not work properly for other data that contains different user scenarios and system workloads . The purpose of validation is to use another data set called ‘validation data’ to test the validity of invariant hypotheses and hence remove the unqualified ones . Those correlation models that survive the validation process are regarded as system invariants . For simplicity we express the equation ( 27 ) as the y(t ) = F ( θ ) , where θ denotes all the coefficients in the model θ = [ −a1,··· ,−an , b0,1,··· , bk1,1,··· , b0,s,··· , bks,s ] . ( 28 ) We divide the validation data into K windows , each of which contains l measurements . For every window Wi , we use its data to fit each hypothesis θ and calculate the fitness score F ( θ ) given by Equation ( 6 ) . Further we select a threshold ffF to determine whether the model fits that seg ment of data or not fi
1 0 k if F ( θ ) > ffF , if F ( θ ) ≤ ffF . fi(F ( θ ) ) =
( 29 ) After receiving k such windows of data , 1 ≤ k ≤ l , we can calculate an overall confidence score for the invariant hypothesis θ which is the average of fitness scores computed from previous k windows pk(θ ) = i=1 fi(F ( θ ) ) k
.
( 30 )
We compare the value pk(θ ) with predefined threshold P . If pk(θ ) < P , the invariant hypothesis θ is discarded . Those hypotheses that survive in all the test windows are finally regarded as the invariants of system . Note in the implementation the confidence pk(θ ) in ( 30 ) can be online updated for each window of dataset pk(θ ) = pk−1(θ ) · ( k − 1 ) + f(Fk(θ ) )
.
( 31 ) k
118118
Authorized licensed use limited to : NEC Labs . Downloaded on May 5 , 2009 at 09:40 from IEEE Xplore . Restrictions apply .
6 Experimental Results
We use the real monitoring data from a Universal Mobile Telecommunication System(UMTS ) to demonstrate the results of extracting both local and global invariants in the system . We also apply the discovered invariants to detect and localize failures in the system . lowing we extract both the local and global invariants in each RNS and use those invariants to monitor the status of RNSs .
Figure 4 . The architecture of UMTS network .
The UMTS is the third generation ( 3G ) wireless network , which is divided into a Core Network ( CN ) and UMTS Terrestrial Radio Access Network ( UTRAN ) as shown in Figure 4 . The CN is responsible for switching/routing calls and data connections to external networks . The UTRAN consists of a set of radio network subsystems(RNSs ) connected to the CN . Figure 4 plots one of the RNS subsystems , which is composed of a radio network controller ( RNC ) and one or more Node Bs . While RNC is in charge of controlling the use of radio resources , the Node B is responsible for radio transmission/reception to/from the User Equipment(UE ) . Asynchronous transfer mode ( ATM ) is chosen as the transport technology to interconnect the UTRAN elements such as Node Bs and RNCs . Two sets of data have been collected from two radio network subsystems(RNSs ) in the UTRAN network system . Table 1 gives a rough description of the two data sets . We see that both RNSs cover over 550 radio cells and the data are sampled at 15 minutes interval . While the data from RNS A contains 556 attributes , there are 731 attributes in the RNS B data set . They contain comprehensive information about the system behavior such as load , capacity , resource availability and accesses , and service quality . Figure 5 plots some of those attribute curves . With this large amount of data , it is hard for operators to check each individual attribute and their correlations manually . In the fol
Table 1 . Raw Data Description number of covered cells number of attributes sampling rate starting date data length failure existence
RNS A data > 550 556 15 min 6/16/2006 15 days no failure
RNS B data > 550 731 15 min 3/7/2006 5 days 1 failure at 5th day
Figure 5 . Some attribute curves in the data from RNS A .
6.1 Invariants Extraction
We divide each data set into three parts for training , validation and testing respectively . For the data from RNS A , we use the first 5 days measurements as training data , the next 6 days data as the validation set , and the last 4 days as the test set . For the data from RNS B , both training and validation sets contain 2 days measurements and the test data contains 1 day measurements .
Figure 6(a ) presents the results of invariants extraction in RNS A . After initial training , we have extracted 6449 invariant hypotheses from the data , in which 6282 candidates are learned by the local method and the remaining 167 are from the global method . The 6 days validation data is then divided into 6 validation phases , with each phase containing 1 day measurements . In each validation window , we calculate the confidence score for every invariant hypothesis and discard those hypotheses with confidence lower than 85 . The curve in Figure 6 exhibits the number of remaining invariant hypotheses after each sequential validation phase . We see that although the number of valid hypotheses shows a rapid decrease at the first three validation windows , it changes a little during the last three validation days . This tells us that the remaining candidates after validation are stable under different system variations and can be regarded as invariants of the system . Eventually we discover 565 invariant models , in which 423 are local invariants and 142 are global ones . Compared with the initial number of invariant hypotheses , we see that a large percent of local hypotheses disappear after the validation due to their sensitivity to system dynamics . This is because many local relationships identified from the training data only reveal partial dependencies between attributes , which can not always hold under different system variations . On the other hand , the global models are not likely to be affected by various
119119
Authorized licensed use limited to : NEC Labs . Downloaded on May 5 , 2009 at 09:40 from IEEE Xplore . Restrictions apply . system dynamics . Most of the global hypotheses continue to hold after the validation process . invariants in our experiment , we regard that the system has encountered an unexpected failure .
7000
6000
5000
4000
3000
2000
1000 s e s e h t o p y h d i l a v f o r e b m u n
0 0
1 global : 167 −−−−− 142 local : 6282 −−−−− 423
8000
7000
6000
5000
4000
3000
2000
1000 s e s e h t o p y h d i l a v f o r e b m u n global : 175 −−−−− 145 local : 7349 −−−−− 706
Figure 7 . Residual generation for each new measurement based on the invariant model .
7
8
9
2
3
4 sequential validation phase
5
6
0 0
1
2
3
4
5
6 sequential validation phase
( a )
( b )
Figure 6 . The invariants sequential validation results in ( a ) RNS A and ( b ) RNS B .
The invariants extraction in RNS B presents similar results , which are shown in Figure 6(b ) . After training with 2 days data , we obtain 7524 invariant hypotheses including 7349 local models and 175 global candidates . We then divide the validation data into 9 windows to sequentially validate those hypotheses . It shows that the number of valid hypotheses becomes almost stable after the third validation phase . Eventually 851 invariants have been discovered in which 706 invariants are local ones and the remaining are global invariants . One interesting observation is that the percentages of survived local and global invariant hypotheses are very close to those from the RNS A data . It is probably because of the similar underlying physical properties of two systems even though they have different capacities and configurations .
6.2 Failure Detection
Since the learned invariants reflect the system internal property and are robust to normal system dynamics such as the workload variations , we can monitor the system runtime status by checking the consistencies of those invariants during system operation . That is , we use the test data as samples to test the invariant model . As shown in Figure 7 , given a new measurement znew , we select relevant attributes from znew to get xnew and ynew based on the invariant equation y = f(x ) . The xnew is then fed to the invariant model to generate the estimated output ˆynew . We calculate the difference between ˆynew and the real value ynew as the residual
R = ynew − ˆynew .
( 32 )
We set a threshold for the residual R to determine whether the invariant model is broken or not . The threshold value is set as 1.2 times the maximum value of historical residuals collected from the validation phase . We count the number of broken invariants for each coming measurement as the evidence of system ’s health . Only when that number is larger than certain threshold , which is the 10 percent of total
Figure 8(a ) presents the number of broken invariants for each test sample from RNS A , in which the X axis is the index of test samples and the Y axis denotes the number of broken invariants . The maximum of Y axis is the total number of discovered invariants in RNS A . From that Figure , we see that only a small portion of invariants ( less than 5 percent ) are occasionally broken for the test samples . Therefore , we conclude that the system works well during the testing period , which is actually consistent with the groundtruth we got from the original data source .
( a )
( b )
Figure 8 . The number of broken invariants on the test data from ( a)RNS A ( b)RNS B .
We use the same strategy to monitor the status of RNS B on one day test samples . In this case , we are told that the test data of RNS B contains a failure which happened at 7:30am and was resolved two hours later . The results of our detector for that test data are presented in Figure 8(b ) . It shows that the number of broken invariants suddenly increases to over 200 at the 30th test sample , which is exactly the time when the actual failure occurred given that each measurement is sampled at 15 minutes interval . Furthermore the number of broken invariants immediately drops at the 38th test sample , two hours after the detected failure which coincides with the actual time of failure settlement . From this example we see that the set of discovered invariants does provide a real time view of the system internal state . We also plot the number of broken global and local invariants in Figure 9(a ) and ( b ) respectively . It shows that both global and local invariants present strong evidences about the incidence of failure . Combining the global and local invariants can present more comprehensive description of the system behavior .
120120
Authorized licensed use limited to : NEC Labs . Downloaded on May 5 , 2009 at 09:40 from IEEE Xplore . Restrictions apply .
( a )
( b )
Figure 9 . The number of ( a ) broken global invariants and ( b ) broken local invariants on the test data from RNS B .
After a failure has been detected , we look into the broken invariants and their related attributes to provide information about the failure source . We build a dependency matrix and use the market data analysis [ 10 ] to determine a list of attributes that are likely to co occur with the failure . An example is shown in Figure 10 to illustrate such process . There are five attributes m1 , m2,··· , m5 in the figure , and six invariants have been discovered among those attributes which are plotted as lines connecting the related attributes . After the failure , four invariants are broken . To find the most suspicious attributes , we build a dependency matrix in Table 2 . Each row in that matrix presents the information of one invariant : the column titled ‘broken’ represents whether the invariant is broken ( ‘1’ ) or not ( ‘0’ ) , and the other five columns show whether each of the five attributes is involved in the invariant ( ‘1’ ) or not ( ‘0’ ) . We define the values in the ‘broken’ column as a vector Tb and those in other columns as Ti , i = 1,··· , 5 . The Jaccard coefficient is applied to indicate the relevance of each attribute to the failure
Ji =
|Ti ∩ Tb| |Ti ∪ Tb| i = 1,··· , 5
( 33 ) which is based on the number of 1s in the intersection set divided by the number of 1s in the union set between Tb and Ti . The attributes with higher Jaccard coefficient are considered more suspicious with respect to the failure . In the example of Figure 10 , the Jaccard coefficients for the five attributes are 0.2 , 0.2 , 1 , 0.2 , and 0.2 respectively . Obviously m3 is the most suspicious attribute .
Table 2 . Data Dependency Matrix invariant 1 2 3 4 5 6 broken m1 m2 m3 m4 m5 0 0 0 1 0 1 1 0 1 1 0 1
0 0 0 1 0 1
1 0 1 0 0 0
1 1 0 0 0 0
0 1 1 1 1 0
Figure 10 . Illustration of broken invariants after the component m3 breaks down .
We then calculate the Jacarrd coefficient for each attribute after we detected the RNS B failure shown in Figure 9 . Based on the system operator , such failure is caused by the broken DHT component in the system . In our diagnosis results , the DHT related attribute is ranked as the third highest among all system attributes . Note the attribute with the highest Jaccard coefficient may not be the exact failure root cause because of the cascading effects of failures . Our strategy is to provide a list of highly suspicious attributes to the system operator to help them for the failure localization . Although the final root cause is determined by the system operator , our ranked attributes can still provide useful clues to guide the localization .
6.3 More Real Data Testing
Besides the previous two data sets , we have tested our invariant based failure detection technique by using more than one year ’s system operation data ( ranging from 12/2004 through 4/2006 ) from nine radio network systems(RNSs ) . Along with the data , a trouble ticket file is provided by the system operator in which 337 different system failures have been recorded . The logged failures belong to either of two categories based on their confidence level . The first category , which includes 46 cases , is related to the failures with strong confidence . Each failure in that category has a clear problem description such as DHT failure , partial power outage and so on . The second failure category contains the remaining 291 cases , which do not have clear problem descriptions and may be just false alarms . According to the original source , only 30 percent of the second category failures are real ones and the others are false alarms .
We first extract and validate the invariants for each RNS based on their normal data . The test data for each failure case is retrieved based on the failure equipment ID , problem start time , and the resolved time recorded in the trouble ticket file . We use the percentage of broken invariants as the anomaly score to determine whether there exists a failure or not . Figure 11 plots the histogram of the anomaly score for the two categories of failures respectively . We see that the anomaly score for the first category of failures shows a
121121
Authorized licensed use limited to : NEC Labs . Downloaded on May 5 , 2009 at 09:40 from IEEE Xplore . Restrictions apply .
10
9
8
7
6
5
4
3
2
1
45
40
35
30
25
20
15
10
5
0 0
0.1
0.2
0.3
0.5
0.4 0.6 anomaly score
( a )
0.7
0.8
0.9
0 0
1
0.1
0.2
0.3
0.5
0.4 0.6 anomaly score
0.7
0.8
0.9
1
( b )
Figure 11 . Histogram of the anomaly score for ( a ) the first category and ( b ) the second category of failures . uni modal distribution with the peak at around 025 On the other hand the histogram for the second category of failures shows a bi modal distribution . This is consistent with our original knowledge because the second category contains a large amount of false alarms . If we choose the anomaly score 0.1 as the threshold , around 84.8 percent of recorded cases in the first category are reported as failures , and 33.6 percent of cases in the second category are regarded as failures . Here we assume the first category failures are all true failures . Therefore our technique can achieve the detection rate 0848 For the second failure category , however , we do not have any groundtruth for the recorded cases . If we assume 30 percent of recorded cases are true failures , as described by the field operators , we can achieve the false positive rate 0.336 03*0848 = 008 Compared with the current detection tool used by the system operators , our detection technique can reduce the false alarms significantly while still keep the satisfactory detection rate . Due to the confidentiality of the test data , we do not plan to describe the testing results in more detail .
7 Conclusions and Future Work
This paper has presented an invariants based framework to model complex information systems . In addition to the brute force local invariant search , we have proposed a statistical mining based algorithm to extract global invariants that represent multivariate dependencies among attributes . Combining local and global invariants can provide a more comprehensive and effective characterization of the system behavior , and hence facilitate many system management tasks . Experimental results from a real wireless system have demonstrated that the discovered system invariants can be used to effectively detect and localize failures in the system . Since the discovered invariants capture the essentials of system state , the set of broken invariants under failure can serve as a ‘signature’ of system anomaly condition . One direction of our future work is to associate each signature with its related problem and solution , and build a database to store such information . By defining an appropriate metric to measure the similarity between different signatures , we can quickly identify and solve recurrent system failures by retrieving similar signatures in the database .
References
[ 1 ] G . A . Alvarez , E . Borowsky , S . Go , T . H . Romer , R . BeckerSzendy , R . Golding , A . Merchant , M . Spasojevic , A . Veitch , and J . Wilkes . Minerva : An automated resource provisioning tool for large scale storage systems . ACM Transactions on Computer Systems , 19(4):483–518 , 2001 .
[ 2 ] P . Barham , R . Isaacs , R . Mortier , and D . Narayanan . Magpie : real time modelling and performance aware systems . In 9th Workshop on Hot Topics in Operating Systems ( HotOS IX ) , May 2003 .
[ 3 ] P . Bodik , G . Friedman , L . Biewald , and et al . Combining visualization and statistical analysis to improve operator confidence and efficiency for failure detection and localization . In Proceedings of the Second International Conference on Autonomic Computing ( ICAC 2005 ) , pages 89–100 , Seattle , WA , June 2005 .
[ 4 ] H . Chen , G . Jiang , C . Ungureanu , and K . Yoshihira . Failure detection and localization in component based systems by online tracking . In the 11th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining , pages 750–755 , Chicago , IL , 2005 .
[ 5 ] M . Chen , E . Kiciman , E . Fratkin , A . Fox , and E . Brewer . Pinpoint : Problem determination in large , dynamic systems . In 2002 International Performance and Dependability Symposium , Washington , DC , June 2002 .
[ 6 ] I . Cohen , S . Jeffrey , M . Goldszmidt , T . Kelly , and J . Symons . Correlating instrumentation data to system states : A building block for automated diagnosis and control . In 6th Symposium on Operating Systems Design and Implementation ( OSDI04 ) , San Francisco , CA , December 2004 .
[ 7 ] HP
Corporation . http://wwwopenviewhpcom/
HP
Openview .
[ 8 ] R . Doyle , J . Chase , O . Asad , W . Jin , and A . Vahdat . Modelbased resource provisioning in a web service utility . In Proceedings of the 4th USENIX Symposium on Internet Technologies and Systems ( USITS ’03 ) , 2003 .
[ 9 ] M . Figueiredo and AK Jain . Bayesian learning of sparse classifiers . In Proc . IEEE Conf . on Computer Vision and Pattern Recognition , volume 1 , pages 35–41 , Kauai , Hawaii , 2001 .
[ 10 ] J . Han and M . Kamber . Data Mining : Concepts and Tech niques . Morgan Kaufmann , 2000 .
[ 11 ] IBM .
Tivoli http://wwwtivolicom/ business system manager .
[ 12 ] G . Jiang , H . Chen , and K . Yoshihira . Discovering likely invariants of distributed transaction systems for autonomic system management . In Proceedings of the 3rd International Conference on Autonomic Computing ( ICAC 2006 ) , pages 199–208 , Dublin , Ireland , June 2006 .
[ 13 ] L . Ljung .
System Identification Theory for The User .
Prentice Hall , second edition , 1998 .
122122
Authorized licensed use limited to : NEC Labs . Downloaded on May 5 , 2009 at 09:40 from IEEE Xplore . Restrictions apply .
