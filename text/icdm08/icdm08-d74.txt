A Topic Modeling Approach and its Integration into the Random Walk
Framework for Academic Search
. Department of Computer Science and Technology , Tsinghua University , China , 100084
Jie Tang . Ruoming Jin
Jing Zhang .
†
† jietang@tsinghuaeducn , zhangjing@kegcstsinghuaeducn
Department of Computer Science , Kent State University , Kent , OH 44241 jin@cskentedu
Abstract
In this paper , we propose a unified topic modeling approach and its integration into the random walk framework for academic search . Specifically , we present a topic model for simultaneously modeling papers , authors , and publication venues . We combine the proposed topic model into the random walk framework . Experimental results show that our proposed approach for academic search significantly outperforms the baseline methods of using BM25 and language model , and those of using the existing topic models ( including pLSI , LDA , and the AT model ) .
1
Introduction
Over the last several years , quite a few academic search engines , such as Citeseer , Google Scholar , and Libra , have been built to facilitate the online search over the huge volume of literatures . However , there are still many challenging issues : First , the information seeking practice [ 5 ] is not only about papers , but also about other information sources , such as authors , conferences and journals , etc . Second , academic search typically requires much higher retrieval accuracy . Given a query , such as “ data mining ” , a user does not typically mean to find papers containing these two words . Her/his intention is to find papers on the data mining topic . Additionally , these two issues are often intertwined .
Existing work has tried to address different aspects of these issues . To rank different objects , random walk over heterogeneous networks has been proposed [ 9][15 ] . However , these methods do not consider sub topics of documents . In the meantime , several work utilizes the topic model to improve the retrieval accuracy [ 6][14 ] . However , this is an open issue on how to extend the topic model to deal with heterogeneous data with link information .
In this work , we investigate how the topic model can help with academic search . Specifically , we are interested in :
1 . Heterogeneous topic modeling : How can we simultaneously model papers , authors , and publication venues within a unified probabilistic topic model ?
2 . Academic search : How to apply the topic model to academic search with better retrieval accuracy ?
3 . Ranking with topic model and random walk : How can we combine the topic model with a random walk framework to improve ranking ?
We propose a probabilistic topic model for simultaneously extracting topics of papers , authors , and publicationvenues . We further present two methods to combine the proposed topic models with the random walk for ranking different objects simultaneously . Our experimental results show that the proposed method can significantly improve the search quality in comparison with the baseline methods .
2 Preliminary
Let a paper d contain a vector wd of Nd words , a vector ad of Ad authors , and be published at the venue cd . Then a collection of D papers can be represented as D = {(w1 , a1 , c1),··· , ( wD , aD , cD)} . Table 1 summarizes the notations used in this paper .
We introduce several related work , including : language model [ 2 ] , pLSI [ 6 ] , LDA [ 3 ] , and random walk [ 10 ] .
Nd
Nd + λ
Nd
· tf ( w , d )
+ ( 1 − Nd
Language model is one of the state of the art approaches for information retrieval . It interprets the relevance between a document and a query word as a generative probability : P ( w|d ) =
( 1 ) where tf(w , d ) is the word frequency of word w in paper d , ND is the number of word tokens in the entire collection , and tf(w , D ) is the word frequency of word w in the collection D . λ is the Dirichlet smoothing factor . The probability of document d generating a query q can be defined as P ( q|d ) = Πw∈qP ( w|d ) .
) · tf ( w , D )
Nd + λ
ND
Table 1 : Notations .
SYMBOL DESCRIPTION number of topics number of papers number of unique words number of unique authors number of unique publication venues number of word tokens in paper d number of authors in paper d vector form of word tokens in paper d vector form of authors in paper d the publication venue of paper d the ith word token in paper d the topic assigned to word token wdi the chosen author associated with the word token wdi multinomial distribution over topics specific to an author x multinomial distribution over words specific to topic z multinomial distribution over publication venues specific to topic z α , β , μ Dirichlet priors to multinomial distribution θ , φ , and ψ , respectively
T D V A C Nd Ad wd ad cd wdi zdi xdi θx φz ψz
Hofmann proposes the probabilistic Latent Semantic Indexing ( pLSI ) model [ 6 ] , which assumes that there is a latent topic layer Z = {z1 , z2,··· , zT} between words and documents . Thus , the probability of generating a word w from a document d can be calculated using the topic layer :
P ( w|d ) =
P ( w|z)P ( z|d )
( 2 )
T . z=1
T .
Latent Dirichlet Allocation ( LDA ) [ 3 ] also models documents by using a topic layer . In LDA , for each document d , a multinomial θd is first sampled from a Dirichlet with parameter α . Second , for each word wdi , a topic zdi is chosen from this distribution . Finally , the word wdi is generated from a topic specific multinomial φzdi . Accordingly , the generating probability of word w from document d is :
P ( w|d , θ , φ ) =
P ( w|z , φz)P ( z|d , θd )
( 3 ) z=1
Several extensions to LDA have been proposed , such as the Author Topic ( AT ) model [ 12 ] .
Considerable research has been conducted on analyzing link structures of the Web , for example PageRank [ 10 ] and HITS [ 7 ] . Many extensions of the random walk model have been proposed , for example [ 9 ] and [ 15 ] . Much other effort has also been made for applying the random walk ranking model to mine the bibliography data .
3 Our Proposed Topic Models
Modeling the academic network can be done in many different ways , for example , a separated LDA model for each type of object [ 14 ] . However , the separated way may result in unsatisfactory performance . Experimental results in Section 5 confirm this assumption . Our main idea in this work is to use a probabilistic topic model to model papers , authors , and publication venues together .
The proposed model is called Author Conference Topic ( ACT ) model . For simplicity , we use conference to denote all kinds of publication venues , including conference , jour
( cid:302 )
( cid:537 )
A d x z
( cid:541 )
( cid:533 )
( cid:301 ) w c
( cid:549 )
T
Nd
D
T
Figure 1 : Graphical representation of the ACT1 model . nal , and article . Essentially , the model utilizes the topic distribution to represent the inter dependencies among authors , papers , and publication venues . Different strategies can be used to implement the topic model . Specifically , we consider three different types of implementations .
3.1 ACT Model 1
In the first model , the conference is associated with each word as a stamp . For generating a word wdi in paper d , an author xdi is first chosen uniformly to be responsible for the word . Each author is associated with a topic distribution . Then a topic is sampled from the author specific topic distribution . Finally the word and the conference stamp is generated from the chosen topic . Figure 1 shows the graphical representation of the ACT model . Formally , the generative process can be described as follows :
1 . For each topic z , draw φz and ψz respectively from
Dirichlet(β ) and Dirichlet(μ ) ;
2 . For each word wdi in paper d :
• draw an author xdi from ad uniformly ; • draw a topic zdi from M ultinomial(θxdi ) specific to author xdi , where θ is generated from Dirichlet(α ) ; • draw a word wdi from M ultinomial(φzdi ) ; • draw a conference cdi from M ultinomial(ψzdi ) .
For inference , the task is to estimate the two sets of unknown parameters in the ACT1 model : ( 1 ) the distribution θ of A author topics , the distribution φ of T topic words , and the distribution ψ of T topic conferences ; and ( 2 ) the corresponding topic zdi and author xdi for each word wdi . We use Gibbs sampling for parameter estimation . Instead of estimating the model parameters directly , we calculate the posterior distribution on just x and z and then use the results to infer θ , φ , and ψ . The posterior probability is defined as : m−di fi xdizdi ( m−di
+ αzdi xdiz + αz ) z
P ( zdi , xdi|z−di , x−di , w , c , α , β , μ ) ∝ + μcd n−di fi zdiwdi ( n−di
+ βwdi zdiv + βv ) zdic + μc ) n−d fi zdicd ( n−d c v
( 4 ) where mxz is the number of times that topic z has been associated with the author x , nzv is the number of times that word wv was generated by topic z , and nzc is the number of times that conference c was generated by topic z ; z−di and x−di represent all topics and authors assignments excluding the i th word in the paper d ; a number with the superscript
2
−di denote a quantity , excluding the current instance . α , β , and μ are hyperparameters and were set with fixed values ( ie , α = 50/T , β = 0.01 , and μ = 01 ) During parameter estimation , the algorithm keeps track of a A × T ( author by topic ) count matrix , a T × V ( topic by word ) count matrix , and a T × C ( topic by conference ) count matrix . Given these three count matrices , we can easily estimate the probability of a topic given an author θxz , the probability of a word given a topic φzv , and the probability of a conference given a topic ψzc :
θxz = fi mxz + αz z . ( mxz . + αz . )
, φzv =
ψzc = fi fi nzv + βv v . ( nzv . + βv . ) nzc + μc c . ( nzc . + μc . )
( 5 )
( cid:172)dd
Vd
( cid:172)dc
( cid:172)cd
Vc
Va
( cid:172)ad
( cid:172)da
Figure 2 : Transition probability P ( q|c ) = PLM ( q|c ) × PACT ( q|c )
( 8 ) where in the language model , a and c is represented by a collection of papers published by author a and a collection of papers published on conference c .
4 Ranking with Topic Model and Random
3.2 ACT Model 2 and ACT Model 3
Walk
In the second model , each topic is chosen from a multinomial topic distribution specific to an author conference pair , instead of an author as that in ACT1 . The model is derived from the observation : authors usually first choose a publication venue and then write the paper based on themes of the publication venue and interests of the authors . We use a similar method as that in ACT1 for parameter estimation . In the third model , the conference is taken as a numerical value . Each conference stamp of a paper is sampled after topics have been sampled for all word tokens in the paper . Intuitively , this corresponds to a natural way to publish a paper : authors first write the paper and then determine where to publish it based on topics discussed in the paper . In this model , the conference stamp comes from a normal linear model . Thus , for parameter estimation , there is a slight difference from that in ACT1 and ACT2 . We use a Gibbs EM algorithm [ 1 ] [ 8 ] for inference of this model .
3.3 Applying ACT to Academic Search
Based on the ACT models , we can obtain a form of document model using a similar equation to Equation ( 3 ) . However , the learned topics by the topic model is usually general and not specific to a given query . Therefore , only using ACT itself for modeling is too coarse for academic search [ 14 ] . Our preliminary experiments also show that employing only the ACT or LDA models to information retrieval hurts the retrieval performance . In general , we would like to have a balance between generality and specificity . Thus , we derive a combination form of the ACT model and the word based language model : ( 6 ) where PLM ( w|d ) is the generating probability of word w from paper d by the language model and PACT ( w|d ) is the generating probability by the ACT model .
P ( w|d ) = PLM ( w|d ) × PACT ( w|d )
Similarly , we can define an author model and a confer ence model in an analogous way :
P ( q|a ) = PLM ( q|a ) × PACT ( q|a )
( 7 )
3
We present two methods to integrate the proposed topic models into the random walk framework .
The academic network is composed of three composite networks ( Figure 2 ) . At the center is a directed graph of paper citations Gd = ( Vd , Edd ) , where Vd includes all papers , and the directed edge ( d1 , d2 ) ∈ Edd suggests the paper d1 cites the paper d2 . Similarly , relationships between authors and papers are modeled by a bipartite graph Gad = ( Va ∪ Vd , Ead ) and relationships between publication venues and papers are modeled by another bipartite graph Gcd = ( Vc ∪ Vd , Ecd ) . We augment these different graphs to form a heterogeneous graph : G = ( Vd∪Va∪Vc , Edd∪Ead∪Ecd ) . In addition , for the sake of random walk , we represent each ( undirected ) edge in the bipartite graph as two directed edges , ie {ai , dj} = ( ai , dj ) ∪ ( dj , ai ) . Further , we define a graph which describes the transition probability between different types of nodes . Clearly , we need λdd + λda + λdc = 1 . We also define λad = λcd = 1 . This transition graph formalizes a random surfer ’s behavior as follows . The random surfer will have the λdd probability to stay in the paper citation network , and will have λda and λdc probabilities to find authors and the publication venue related to the paper . Given this , similar to PageRank , we can define a general form of the random walk ranking score for each node x as : r[x ] =
ξ
|V | + ( 1 − ξ ) ×
λyxr[y]P ( x|y )
( 9 )
.
( x,y)∈E where |V | is the number of nodes in the network ; ξ is a random jump parameter ; λyx is the transition probability between the type of node y and the type of node x ; P ( x|y ) is the probability between two specific nodes y and x .
4.1 Combination Method 1
The first method combines the random walk ranking score with the relevance score from the topic model by simple multiplication . Formally , given a query q , the final ranking score of a paper d is the multiplication of random walk
V_q
( cid:540)tq
( cid:540)qt
V_t
( cid:540)dt
( cid:540)td
V_d
( cid:540)qa
( cid:540)aq
( cid:540)at
( cid:540)ta
( cid:540)da
( cid:540)ad
V_a
( cid:540)qc
( cid:540)cq
( cid:540)qd
( cid:540)dq
( cid:540)ct
( cid:540)tc
( cid:540)dc
( cid:540)cd
V_c
Figure 3 : Transition probability ranking score r[d ] and the paper ’s relevance score P ( q|d ) : ( 10 ) Similarly , we can define the combination formulas for
R[d ] = r[d ] × P ( q|d ) conferences and authors :
R[a ] = r[a ] × P ( q|a ) , R[c ] = r[c ] × P ( q|c )
( 11 ) We also tried the weighted sum method for combination , ie R[d ] = γ × r[d ] + ( 1 − γ ) × P ( q|d ) , where γ is a coefficient to control the strength of the two terms . It always underperforms the method of the multiplication combination , even with different values of the coefficient γ .
4.2 Combination Method 2
The second method directly integrates the topic model into the random walk . It augments the network with topic nodes Vt and a query node Vq . Let Gtd = ( Vt ∪ Vd , Etd ) be a bipartite graph where Vt is the set of topic nodes estimated in the topic model , and if paper d can be generated from topic z with a probability P ( wd|z ) > ( where is a parameter to control the density of the constructed network ) , then we have an edge ( z , d ) ∈ Etd . Similarly , we can define edges Ect between conferences and topics and edges Eat between authors and topics . Furthermore , we add edges between the query node and different other nodes ( papers , authors , conferences , and topics ) . Figure 3 shows the new heterogeneous network .
In this method , we consider that after the random surfer walks to a topic node from some other node , he/she will always walk to the ( virtual ) query node and then walk back to another topic node . The transition probability between the query and a paper/author/conference node is calculated using the language model ( eg , PLM ( q|d) ) . The transition probabilities between a topic node and the other nodes are calculated using the topic model , ie , P ( aj|zi ) =
P ( zi|aj )P ( aj )
P ( zi|aj ) = θaj zi ,
P ( zi )
P ( zi|dj ) =
1 Ad
. x∈ad
θxzi ,
P ( dj|zi ) =
Nd' i=1
P ( cj|zi ) = ψzicj ,
P ( zi|cj ) =
P ( cj|zi)P ( zi )
P ( cj )
P ( q|zi ) =
P ( w|zi ) ,
P ( zi|q ) ∝ P ( q|zi)P ( zi )
( 12 )
' w∈q where θ and ψ are obtained from ( 5 ) ; P ( zi ) , P ( aj ) , and P ( cj ) can be obtained by counting the number after Gibbs sampling .
The method can make use of the topic distribution in the random walk and we can also adjust the different λ between the other nodes to the topic nodes to weight how the random walk and the topic model affect the final rank . The ranking scores after random walk are query dependent .
5 Experimental Results
We evaluated the proposed models in our developed sys tem ArnetMiner ( http://arnetminer.org ) [ 13 ] .
5.1 Experimental Setting
511 Data sets
As there is no a standard data set with ground truth and also it is difficult to create such a data set of ground truth , for evaluation purpose , we collected 43 most frequent queries from the query log of ArnetMiner . We divided these queries into two sub sets and carried out two experiments .
In the first experiment , we used 7 queries and conducted evaluation on a subset of the data ( including 14 , 134 authors , 10 , 716 papers , and 1 , 434 conference ) from ArnetMiner . For evaluation , we used the method of pooled relevance judgments [ 4 ] together with human judgments . Specifically , for each query , we first pooled the top 30 results from three academic search systems ( Libra , Rexa , and ArnetMiner ) . Then , two faculties and five graduates from CS provided human judgments . Four grade scores ( 3 , 2 , 1 , and 0 ) were assigned respectively representing best relevance , relevance , marginal relevance , and not relevance .
In the second experiment , we used the rest 36 queries and conducted evaluation on the entire data of ArnetMiner ( including 448 , 365 authors , 981 , 599 papers , and 4 , 501 conferences ) . For evaluation , we used only the pooled relevance judgments without human judgements . For pooling purpose , we added one baseline method , ie BM25 [ 11 ] . Specifically , for a query , we pooled the top 30 results returned by BM25 , our method , and two systems : Libra and Rexa . We define as relevance only when a candidate was returned by at least three of the four methods .
512 Experimental Setting
P ( wdi|zi )
In all experiments , we conducted evaluation in terms of P@5 , P@10 , P@20 , R pre , and MAP [ 4 ] .
4
We used BM25 [ 11 ] , language model ( LM ) [ 2 ] , pLSI [ 6 ] , LDA [ 3 ] , and the Author Topic ( AT ) model [ 12 ] as baseline methods . BM25 is a state of the art method for information retrieval . In BM25 , we used the method in [ 11 ] to calculate the relevance of a query and a paper . For language model , we used Equation ( 1 ) to calculate the relevance between a query term and a paper and for pLSI , we used Equation ( 2 ) to calculate the relevance . For LDA , we used Equation ( 3 ) to calculate the relevance of a term and a paper . For the AT model , we used similar equations to Equation ( 6 ) and ( 7 ) to calculate the relevance of a query term with a paper and an author respectively . We also compared with the results obtained by combining LM with random walk using combination method 1 . We also tried to combine BM25 with RW1 . The result underperforms that of LM+RW1 .
To learn the pLSI model , we used the EM algorithm [ 6 ] . For LDA and AT , we performed model estimation with the same setting as that for the ACT models . In the first experiment , we empirically set the number of topics as T = 80 for all topic models . In the second experiment , we set the number of topics as T = 200 .
5.2 Experimental Results
521 Performances of the First Experiment
Table 2 shows the performance of retrieving papers , conferences , and authors using our proposed methods and the baseline methods . +RW denotes integration of a method into the random walk . RW1 denotes the combination method 1 , and RW2 denotes the combination method 2 . We see that our proposed topic models outperform all the baseline methods ( BM25 , LM , pLSI , LDA , and AT ) . We can also see that ACT1+RW1 achieves the best performance in terms of all evaluation measures .
522 Performances of the Second Experiment
In the second experiment , we evaluated the results of our best approach ( ACT1+RW1 ) , one baseline method : BM25 , and the two systems : Libra and Rexa . ( Rexa only has paper and author search . ) Table 3 shows the performance of the four methods . We see that our proposed method outperforms the baseline method and the two systems .
5.3 Discussion
( 1 ) Our proposed methods for academic search significantly outperform the baseline methods . We see from both Table 2 and Table 3 that ACT1+RW1 achieves the best performance . This indicates that the proposed approach indeed improves the quality of academic search .
( 2 ) We see that by combining the topic models with random walk , we can significantly enhance the ranking perfor
Table 2 : Performance of academic ranking approaches ( % ) .
Method
BM25
LM
LM+RW1 pLSI
LDA
AT
ACT1
ACT1+RW1
ACT1+RW2
ACT2
ACT2+RW1
ACT2+RW2
ACT3
ACT3+RW1
ACT3+RW2
Object Paper Author
Conference
Average Paper Author
Conference
Average Paper Author
Conference
Average Paper Author
Conference
Average Paper Paper Author Average Paper Author
Conference
Average Paper Author
Conference
Average Paper Author
Conference
Average Paper Author
Conference
Average Paper Author
Conference
Average Paper Author
Conference
Average Paper Author
Conference
Average Paper Author
Conference
Average Paper Author
Conference
Average
P@5 42.9 77.1 51.4 57.1 40.0 65.7 51.4 52.4 62.9 71.4 60.0 64.8 32.5 65.0 47.5 48.3 31.4 42.9 82.9 62.9 42.9 91.4 62.9 65.7 68.6 80.0 62.9 70.5 45.7 71.4 51.4 56.2 42.9 74.3 54.3 57.1 62.9 77.1 60.0 66.7 40.0 74.3 51.4 55.2 42.9 71.4 57.1 57.1 65.7 77.1 60.0 67.6 40.0 74.3 54.3 56.2
P@10 45.7 47.1 38.6 43.8 38.6 44.3 32.9 38.6 55.7 48.6 35.7 46.7 33.8 40.0 36.3 36.7 48.6 48.6 45.7 47.1 45.7 50.0 41.4 45.7 61.4 51.4 42.9 51.9 40.0 44.3 32.9 39.1 47.1 50.0 41.4 46.2 58.6 50.0 40.0 49.5 41.4 42.9 32.9 39.1 38.6 47.1 38.6 41.4 54.3 50.0 41.4 48.6 38.6 41.4 32.9 37.6
P@20 R pre MAP 47.2 41.4 85.5 26.4 66.0 22.9 66.2 30.2 37.1 46.4 73.4 25.0 63.1 21.4 61.0 27.9 65.3 44.3 83.8 25.7 64.6 22.1 30.7 71.2 40.4 30 75.5 22.5 54.1 21.3 56.7 24.6 45.8 42.9 42.9 49.3 78.1 25.7 63.7 34.3 51.0 43.6 89.6 26.4 72.3 23.6 31.2 71.0 66.6 50.7 87.4 27.1 72.0 23.6 75.4 33.8 52.2 38.6 24.3 71.5 60.7 20.0 61.4 27.6 47.7 39.3 80.1 25.7 63.9 22.1 29.1 63.9 63.5 48.6 82.8 26.4 65.8 23.6 70.7 32.9 47.3 40.0 72.2 24.3 22.1 63.1 60.9 28.8 47.0 41.4 78.7 25.7 65.7 23.6 63.8 30.2 49.3 63.0 84.0 26.4 66.0 23.6 71.0 33.1 47.4 38.6 72.0 24.3 22.1 62.6 60.7 28.3
12.0 67.5 48.8 42.8 10.0 58.8 47.6 38.8 12.9 64.6 53.6 43.7 9.7 60.4 45.1 38.4 13.5 13.1 73.5 43.3 16.6 80.0 60.7 52.4 17.1 77.6 59.5 51.4 13.4 65.4 53.6 44.1 15.0 69.4 54.2 46.2 16.9 69.4 55.4 47.2 13.5 63.6 50.0 42.4 17.1 70.0 58.3 48.5 19.5 74.8 55.4 49.9 14.0 63.6 50.0 42.5
Table 3 : Performance of academic ranking approaches ( % ) .
Method
ACT1+RW1
BM25
Libra
Rexa
Object Paper Author
Conference
Average Paper Author
Conference
Average Paper Author
Conference
Average Paper Author Average
P@5 39.3 45.7 48.6 44.5 41.4 43.6 41.4 42.1 35.0 37.1 48.6 40.2 27.9 24.3 26.1
P@10 35.7 37.9 41.8 38.5 35.0 33.2 33.9 34.0 26.1 30.7 37.5 31.4 21.1 19.6 20.4
P@20 R pre MAP 31.6 46.7 50.6 30.7 52.9 30.9 50.1 31.1 49.1 33.2 51.9 29.3 28.9 46.0 49.0 30.5 38.0 24.1 44.8 27.9 57.4 29.5 46.7 27.1 15.4 38.9 30.1 15.9 15.6 34.5
30.9 33.6 47.4 37.3 31.7 27.9 36.9 32.2 23.2 21.8 47.3 30.8 20.9 17.3 19.1
5 mance ( +4.4 % , +6.8 % , and +7.2 % respectively for ACT1 , ACT2 , and ACT3 in terms of MAP ) .
We have also observed a surprising result : the first combination method uses the simple multiplication to combine the relevance scores by the topic model with the score from the random walking model while the second method integrates the topic model directly into the random walk . Intuitively , the second combination method seems to work in a more “ elegant ” way and would have resulted in a better performance . However , results in Table 2 show that the first simple combination method obtains significant improvements while the second combination method hurts the retrieval performance ( eg , 9.6 % for ACT1 when combining random walk using the method 2 ) .
Further analysis shows that the second combination method integrates the topic model into each step in the random walk , which leads to too many parameters to tune . For example , there are eighteen λ needed to tune ( cf . Figure 3 ) . It is hard to find a best setting for all the parameters .
( 3 ) We can also see from Table 2 that the proposed different topic models perform different behaviors , but ACT1 performs the best either with ( +4.7 % than ACT2 and +4.4 % than ACT3 in terms of MAP ) or without the random walk ( +7.1 % than ACT2 and +7.2 % than ACT3 by MAP ) .
With a further analysis , we found that the sampling process of ACT2 results in a very huge and sparse ( authorconference pair by topic ) count matrix of AC × T , which is scaled up to 10million rows . The problem of ACT3 might be that we take the conference stamp as a numerical value , which makes it not accurate enough to describe the conference information of discrete value . How to accurately capture the conference information in the topic model is also one of our ongoing research issues .
( 4 ) Experiments ( cf . Table 3 ) show that our approach outperforms the existing academic search systems Libra ( +3.4 % in terms of average MAP ) and Rexa ( +15.6 % by average MAP ) . The reasons include : ( 1 ) Rexa only supports paper search and author search , thus cannot make use of dependencies between authors , papers , and conferences ; ( 2 ) Libra supports search of the three objects . However , its ranking is based on the language model and the PageRank method [ 9 ] . Again , it cannot make use of the semantic ( topic level ) dependencies between different objects .
6 CONCLUSION
In this paper , we investigate the problem of modeling heterogeneous academic network using a unified probabilistic model . We present three topic models for simultaneously modeling papers , authors , and publication venues . We further propose two methods to combine the proposed topic models with the random walk framework for academic
6 search . Experimental results show that our approach outperforms the baseline methods and the existing systems .
Our proposed approach is very general and flexible . The topic model can be implemented in many other ways and the random walk can run in either an offline mode or an online mode . Variations of the approach can be applied to many other applications such as social search and blog search .
7 ACKNOWLEDGMENTS
Jie Tang and Jing Zhang would like to thank the support of NSFC research funding ( 90604025 , 60703059 ) , Chinese 973 research funding ( 2007CB310803 ) , and Chinese Young Faculty Funding ( 20070003093 ) .
References
[ 1 ] C . Andrieu , N . de Freitas , A . Doucet , and M . I . Jordan . An introduction to mcmc for machine learning . Machine Learning , 50:5–43 , 2003 .
[ 2 ] R . Baeza Yates and B . Ribeiro Neto . Modern Information
Retrieval . ACM Press , 1999 .
[ 3 ] D . M . Blei , A . Y . Ng , and M . I . Jordan . Latent dirichlet allocation . Journal of Machine Learning Research , 3:993– 1022 , 2003 .
[ 4 ] C . Buckley and E . M . Voorhees . Retrieval evaluation with incomplete information . In Proc . of SIGIR’04 , pages 25–32 . [ 5 ] M . Hertzum and A . M . Pejtersen . The information seeking practices of engineers : Searching for documents as well as for people . Information Processing & Management , 36(5):761–778 , 2000 .
[ 6 ] T . Hofmann . Probabilistic latent semantic indexing . In Proc . of SIGIR’99 , pages 50–57 , 1999 .
[ 7 ] J . M . Kleinberg . Authoritative sources in a hyperlinked en vironment . Journal of the ACM , 46(5):604–632 , 1999 .
[ 8 ] T . Minka . Estimating a dirichlet distribution . Technical report , http://researchmicrosoftcom/ minka/papers/dirichlet/ , 2003 .
[ 9 ] Z . Nie , Y . Zhang , J R Wen , and W Y Ma . ObjectIn Proc . of level ranking : bringing order to web objects . WWW’05 , pages 567–574 , 2005 .
[ 10 ] L . Page , S . Brin , R . Motwani , and T . Winograd . The pagerank citation ranking : Bringing order to the web . Technical Report SIDL WP 1999 0120 , Stanford University , 1999 .
[ 11 ] S . Robertson , S . Walker , M . Beaulieu , M . Gatford , and
A . Payne . Okapi at trec 4 . In TREC’96 , 1996 .
[ 12 ] M . Steyvers , P . Smyth , and T . Griffiths . Probabilistic authortopic models for information discovery . In Proc . of KDD’04 . [ 13 ] J . Tang , J . Zhang , L . Yao , J . Li , L . Zhang , and Z . Su . Arnetminer : Extraction and mining of academic social networks . In Proc . of SIGKDD’08 , pages 990–998 , 2008 .
[ 14 ] X . Wei and W . B . Croft . Lda based document models for ad hoc retrieval . In Proc . of SIGIR’06 , pages 178–185 , 2006 .
[ 15 ] W . Xi , B . Zhang , Y . Lu , Z . Chen , S . Yan , H . Zeng , W Y Ma , and E . A . Fox . Link fusion : a unified link analysis framework for multi type interrelated data objects . In Proc . of WWW’04 , pages 319–327 , 2004 .
