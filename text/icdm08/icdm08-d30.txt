2008 Eighth IEEE International Conference on Data Mining 2008 Eighth IEEE International Conference on Data Mining
Unsupervised Face Annotation by Mining the Web
Duy Dinh Le
National Institute of Informatics 2 1 2 Hitotsubashi , Chiyoda ku
Tokyo , JAPAN 101 8430 ledduy@niiacjp
Shin’ichi Satoh
National Institute of Informatics 2 1 2 Hitotsubashi , Chiyoda ku
Tokyo , JAPAN 101 8430 satoh@niiacjp
Abstract
Searching for images of people is an essential task for image and video search engines . However , current search engines have limited capabilities for this task since they rely on text associated with images and video , and such text is likely to return many irrelevant results . We propose a method for retrieving relevant faces of one person by learning the visual consistency among results retrieved from textcorrelation based search engines . The method consists of two steps . In the first step , each candidate face obtained from a text based search engine is ranked with a score that measures the distribution of visual similarities among the faces . Faces that are possibly very relevant or irrelevant are ranked at the top or bottom of the list , respectively . The second step improves this ranking by treating this problem as a classification problem in which input faces are classified as ’person X’ or ’non person X’ ; and the faces are re ranked according to their relevant score inferred from the classifier ’s probability output . To train this classifier , we use a bagging based framework to combine results from multiple weak classifiers trained using different subsets . These training subsets are extracted and labeled automatically from the rank list produced from the classifier trained from the previous step . In this way , the accuracy of the ranked list increases after a number of iterations . Experimental results on various face sets retrieved from captions of news photos show that the retrieval performance improved after each iteration , with the final performance being higher than those of the existing algorithms .
1 . Introduction
With the rapid growth of digital technology , large image and video databases have become more available than ever to users . This trend has shown the need for effective and efficient tools for indexing and retrieving based on visual content . A typical application is searching for a specific person by providing his or her name . Most current search engines use the text associated with images and video as significant clues for returning results . However , other un queried faces and names may appear with the queried ones ( Figure 1 ) , and this significantly lowers the retrieval performance . One way to improve the retrieval performance is to take into account visual information present in the retrieved faces . This task is challenging for the following reasons :
• Large variations in facial appearance due to pose changes , illumination conditions , occlusions , and facial expressions make face recognition difficult even with state of the art techniques [ 1 , 21 , 2 ] ( see example in Figure 2 ) .
• The fact that the retrieved face set consists of faces of several people with no labels makes supervised and unsupervised learning methods inapplicable .
We propose a method for solving the above problem . The main idea is to assume that there is visual consistency among the results returned from text based search engines and this visual consistency is then learned through an interactive process . This method consists of two stages . In the first stage , we explore the local density of faces to identify potential candidates for relevant faces1 and irrelevant faces2 . This stage reflects the fact that the facial images of the queried person tend to form dense clusters , whereas irrelevant facial images are sparse since they look different from each other . For each face , we define a score to measure the density of its neighbor set . This score is used to form a ranked list , in which faces with high density scores are considered relevant and are put at the top .
The above ranking method is weak since dense clusters have no guarantee of containing relevant faces . Therefore , a second stage is necessary to improve this ranked list . We model this problem as a classification problem in which input faces are classified as person X ( the queried person )
1faces related to the queried person . 2faces unrelated to the queried person .
1550 4786/08 $25.00 © 2008 IEEE 1550 4786/08 $25.00 © 2008 IEEE DOI 101109/ICDM200847 DOI 101109/ICDM200847
383 383
Figure 2 . Large variations in facial expressions , poses , illumination conditions and occlusions making face recognition difficult . Best viewed in color .
• The bagging framework helps to leverage noises in the unsupervised labeling process .
Our contribution is two fold : • We propose a general framework to boost the face retrieval performance of text based search engines by visual consistency learning . The framework seamlessly integrates data mining techniques such as supervised learning and unsupervised learning based on bagging . Our framework requires only a few parameters and works stably .
• We demonstrate its feasibility with a practical web mining application . A comprehensive evaluation on a large face dataset of many people was carried out and confirmed that our approach is promising .
2 . Related Work
There are several approaches for re ranking and learning models from web images . Their underlying assumption is that text based search engines return a large fraction of relevant images . The challenge is how to model what is common in the relevant images . One approach is to model this problem in a probabilistic framework in which the returned images are used to learn the parameters of the model . For examples , as described by Fergus et al . [ 12 ] , objects retrieved using an image search engine are re ranked by extending the constellation model . Another proposal , described in [ 15 ] , uses a non parametric graphical model and an interactive framework to simultaneously learn object class models and collect object class datasets . The main contribution of these approaches is probabilistic models that can be learned with a small number of training images . However , these models are complicated since they
Figure 1 . A news photo and its caption . Extracted faces are shown on the top . These faces might be returned for the query of person Bush . or non person X ( the un queried person ) . The faces are ranked according to a relevancy score that is inferred from the classifier ’s probability output . Since annotation data is not available , the rank list from the previous step is used to assign labels for a subset of faces . This subset is then used to train a classifier using supervised methods such as support vector machines ( SVM ) . The trained classifier is used to re rank faces in the original input set . This step is repeated a number of times to get the final ranked list . Since automatically assigning labels from the ranked list is not reliable , the trained classifiers are weak . To obtain the final strong classifier , we use the idea of ensemble learning [ 6 ] in which weak classifiers trained on different subsets are combined to improve the stability and classification accuracy of single classifiers . The learned classifier can be further used for recognizing new facial images of the queried person .
The second stage improves the ranked list and recogni tion performance for the following reasons :
• Supervised learning methods , such as SVM , provide a strong theoretical background for finding the optimal decision boundary even with noisy data . Furthermore , recent studies [ 20 , 17 ] suggest that SVM classifiers provide probability outputs that are suitable for ranking .
384384 require several hundred parameters for learning and are susceptible to over fitting . Furthermore , to obtain robust models , a small amount of supervision is required to select seed images .
Another study [ 4 , 3 ] proposed a clustering based method for associating names and faces in news photos . To solve the problem of ambiguity between several names and one face , a modified k means clustering process was used in which faces are assigned to the closest cluster ( each cluster corresponding to one name ) after a number of iterations . Although the result was impressive , it is not easy to apply it to our problem since it is based on a strong assumption that requires a perfect alignment when a news photo only has one face and its caption only has one name . Furthermore , a large number of irrelevant faces ( more than 12 % ) have to be manually eliminated before clustering .
A graph based approach was proposed by Ozkan and Duygulu [ 16 ] , in which a graph is formed from faces as nodes , and the weights of edges linked between nodes are the similarity of faces , is closely related to our problem . Assuming that the number of faces of the queried person is larger than that of others and that these faces tend to form the most similar subset among the set of retrieved faces , this problem is considered equal to the problem of finding the densest subgraph of a full graph ; and can therefore be solved by taking an available solution [ 9 ] . Although , experimental results showed the effectiveness of this method , it is still questionable whether the densest subgraph intuitively describes most of the relevant faces of the queried person and it is easy to extend for the ranking problem . Furthermore , choosing an optimal threshold to convert the initial graph into a binary one is difficult and rather ad hoc due to the curse of dimensionality .
An advantage of the methods [ 4 , 3 , 16 ] is they are fully unsupervised . However , a disadvantage is that no model is learned for predicting new images of the same category . Furthermore , they are used for performing hard categorization on input images that are in applicable for re ranking . The balance of recall and precision was not addressed . Typically , these approaches tend to ignore the recall to obtain high precision . This leads to the reduction in the number of collected images .
Our approach combines a number of advances over the existing approaches . Specifically , we learn a model for each query from the returned images for purposes such as reranking and predicting new images . However , we used an unsupervised method to select training samples automatically , which is different from the methods proposed by Fergus et al . and Li et al . [ 12 , 15 ] . This unsupervised method is different from the one by Ozkan and Duygulu [ 16 ] in the modeling of the distribution of relevant images . We use density based estimation rather than the densest graph .
3 Proposed Framework
Given a set of images returned by any text based search engine for a queried person ( eg ’George Bush’ ) , we perform a ranking process and learning of person X ’s model as follows :
• Step 1 : Detect faces and eye positions , and then per form face normalizations .
• Step 2 : Compute an eigenface space and project the input faces into this subspace .
• Step 3 : Estimate the ranked list of these faces using
Rank By Local Density Score .
• Step 4 :
Improve this ranked list using Rank By
Bagging ProbSVM .
Steps 1 and 2 are typical for any face processing system , and they are described in section 42 The algorithms used in Steps 3 and 4 are described in section 3.1 and section 3.2 , respectively . Figure 3 illustrates the proposed framework .
3.1 Ranking by Local Density Score
Figure 4 . An example of faces retrieved for person Donald Rumsfeld . Irrelevant faces are marked with a star . Irrelevant faces might form several clusters , but the relevant faces form the largest cluster .
Among the faces retrieved by text based search engines for a query of person X , as shown in Figure 4 , relevant faces usually look similar and form the largest cluster . One approach of re ranking these faces is to cluster based on visual similarity . However , to obtain ideal clustering results is impossible since these faces are high dimensional data and the clusters are in different shapes , sizes , and densities . Instead , a graph based approach was proposed by Ozkan and Duygulu [ 16 ] in which the nodes are faces and edge weights
385385
Figure 3 . The proposed framework for re ranking faces returned by text based search engines . are the similarities between two faces . With the observation that the nodes ( faces ) of the queried person are similar to each other and different from other nodes in the graph , the densest component of the full graph the set of highly connected nodes in the graph will correspond to the face of the queried person . The main drawback of this approach is it needs a threshold to convert the initial weighted graph to a binary graph . Choosing this threshold in high dimensional spaces is difficult since different persons might have different optimal thresholds .
We use the idea of density based clustering described by Ester et al . and Breunig et al . [ 11 , 7 ] to solve this problem . Specifically , we define the local density score ( LDS ) of a point p ( ie a face ) as the average distance to its k nearest neighbors .
LDS(p , k ) =
. q∈R(p,k ) distance(p , q ) k where R(p , k ) is the set of k neighbors of p , and distance(p , q ) is the similarity between p and q .
Since faces are represented in high dimensional feature space , and face clusters might have different sizes , shapes , and densities , we do not directly use the Euclidean distance between two points in this feature space for distance(p , q ) . Instead , we use another similarity measure defined by the number of shared neighbors between two points . The efficiency of this similarity measure for density based clustering methods was described in [ 10 ] . distance(p , q ) =
|R(q , k ) ∩ R(p , k)| k
Therefore
LDS(p , k ) =
. q∈R(p,k ) |R(q , k ) ∩ R(p , k)| k2
A high value of LDS(p , k ) indicates a strong association between p and its neighbors . Therefore , we can use this local density score to rank faces . Faces with higher scores are considered to be potential candidates that are relevant to person X , while faces with lower scores are considered as outliers and thus are potential candidates for non person X . Algorithm 1 describes these steps .
Algorithm 1 : Rank By Local Density Score Step 1 : For each face p , compute LDS(p , k ) , where k is the number of neighbors of p and is the input of the ranking process . Step 2 : Rank these faces using LDS(p , k ) ( The higher the score the more relevant ) .
3.2 Ranking by Bagging of SVM Classi fiers
One limitation of the local density score based ranking is it cannot handle faces of another person strongly associated in the k neighbor set ( for example , many duplicates ) . Therefore , another step is proposed for handling this case . As a result , we have a model that can be used for both reranking current faces and predicting new incoming faces . The main idea is to use a probabilistic model to measure the relevancy of a face to person X , P ( person − X|f ace ) . Since the labels are not available for training , we use the input rank list found from the previous step to extract a subset of faces lying at the top and bottom of the ranked list to form the training set . After that , we use SVM with probabilistic output [ 17 ] implemented in LibSVM [ 8 ] to learn the person X model . This model is applied to faces of the original set , and the output probabilistic scores are used to re rank these faces . Since it is not guaranteed that faces lying at two ends of the input rank list correctly correspond to the faces of person X and faces of non person X , we adopt the idea of a bagging framework [ 6 ] in which randomly selecting subsets to train weak classifiers , and then combining these classifiers help reduce the risk of using noisy training sets .
The details the Rank By Bagging ProbSVMof InnerLoop method , rank list by combining weak classifiers trained from subsets annotated by that rank list are described in Algorithm 2 . improving an input
Given an input ranked list , Rank By Bagging ProbSVMInnerLoop is used to improve this list . We repeat the process a number of times whereby the ranked list output from the previous step is used as the input ranked list of the next
386386 pos from Spos . pos as positive samples .
Algorithm 2 : Rank By Bagging ProbSVM InnerLoop Step 1 : Train a weak classifier , hi . Step 1.1 : Select a set Spos including p % of top ranked faces and then randomly select a subset S∗ Label faces in S∗ Step 1.2 : Select a set Sneg including p % of bottom ranked faces and then randomly select a subset S∗ Label faces in S∗ Step 1.3 : Use S∗ classifier , hj , using LibSVM [ 8 ] with probability outputs . Step 2 : Compute ensemble classifier Hi = j=1 hj . Step 3 : Apply Hi to the original face set and form the rank list , Ranki , using the output probabilistic scores . Step 4 : Repeat steps 1 to 3 until Dist2RankList(Ranki−1 , Ranki ) <= . Step 5 : Return Hi = neg as negative samples . pos and S∗ neg to train a weak neg from Sneg .
. i
. i j=1 hj .
Algorithm 3 : Rank By Bagging ProbSVM OuterLoop Step 1 : Rankcur = Rank By Bagging ProbSVM InnerLoop(Rankprev ) . Step 2 : dist = Dist2RankList(Rankprev , Rankcur ) . Step 3 : Rankf inal = Rankcur . Step 4 : Rankprev = Rankcur . Step 5 : Repeat steps 1 to 4 until dist <= . Step 6 : Return Rankf inal .
To determine the number of step . In this way , the iterations significantly improve the final ranked list . The details are described in Algorithm 3 . iterations of RankBy Bagging ProbSVM InnerLoop and Rank By BaggingProbSVM OuterLoop , we use the Kendall − tau distance [ 13 ] , which is a metric that counts the number of pairwise disagreements between two lists . The larger the distance , the more dissimilar the two lists are . The Kendall− tau distance between two lists , τ1 and τ2 , is defined as follows : fi
( i,j)∈P
K(τ1 , τ2 ) =
K i,j(τ1 , τ2 ) where P is the set of unordered pairs of distinct elements in τ1 and τ2 . K i,j(τ1 , τ2 ) = 0 if i and j are in the same order in τ1 and τ2 , and K i,j(τ1 , τ2 ) = 1 if i and j are in the opposite order in τ1 and τ2 . Since the maximum value of K(τ1 , τ2 ) is N(N − 1)/2 , where N is the number of members of the list , the normalized Kendall tau distance can be written as follows :
Knorm(τ1 , τ2 ) = K(τ1 , τ2 )
N(N − 1)/2 .
Using this measure for checking when the loops stop means that if the ranked list does not change significantly after a number of iterations , it is reasonable to stop .
387387
4 Experiments
4.1 Dataset
We used the dataset described by Berg et al . [ 4 ] for our experiments . This dataset consists of approximately half a million news photos and captions from Yahoo News collected over a period of roughly two years . This dataset is better than datasets collected from image search engines such as Google that usually limit the total number of returned images to 1,000 . Furthermore , it has annotations that are valuable for evaluation of methods . Note that these annotations are used for evaluation purpose only . Our method is fully unsupervised , so it assumes the annotations are not available at running time . leaders ,
Only frontal faces were considered since current frontal face detection systems [ 19 ] work in real time and have accuracies exceeding 95 % . 44,773 faces were detected and normalized to the size of 86×86 pixels . We selected fifteen government including George W . Bush ( US ) , Vladimir Putin ( Russia ) , Ziang Jemin ( China ) , Tony Blair ( UK ) , Junichiro Koizumi ( Japan ) , Roh Moo hyun ( Korea ) , Abdullah Gul ( Turkey ) , and other key individuals , such as John Paul II ( the Former Pope ) and Hans Blix ( UN ) , because their images frequently appear in the dataset [ 16 ] . Variations in each person ’s name were collected . For example , George W . Bush , President Bush , US President , etc . , all refer to the current US president .
We performed simple string search in captions to check whether a caption contained one of these names . The faces extracted from the corresponding image associated with this caption were returned . The faces retrieved from the different name queries were merged into one set and used as input for ranking .
Figure 5 shows the distribution of retrieved faces from this method and the corresponding number of relevant faces for these fifteen individuals . In total , 5,603 faces were retrieved in which 3,374 faces were relevant . On average , the accuracy was 6022 %
4.2 Face Processing
We used an eye detector to detect the positions of the eyes of the detected faces . The eye detector , built with the same approach as that of Viola and Jones [ 19 ] , had an accuracy of more than 95 % . If the eye positions were not detected , predefined eye locations were assigned . The eye positions were used to align faces to a predefined canonical pose .
To compensate for illumination effects , the subtraction of the bestfit brightness plane followed by histogram equalization was applied . This normalization process is shown in lated as follows :
Recall = Nrel Nhit
P recision = Nrel Nret
Precision and recall are only used to evaluate the quality of an unordered set of retrieved faces . To evaluate ranked lists in which both recall and precision are taken into account , average precision is usually used . The average precision is computed by taking the average of the interpolated precision measured at the 11 recall levels of 0.0 , 0.1 , 0.2 , , 10
The interpolated precision pinterp at a certain recall level r is defined as the highest precision found for any recall level q ≥ r : pinterp = maxr.≥rp(rff )
In addition , to evaluate the performance of multiple queries , we used mean average precision , which is the mean of average precisions computed from queries3 .
4.4 Parameters
The parameters of our method include : • p : the fraction of faces at the top and bottom of the ranked list that are used to form a positive set Spos and negative set Sneg for training weak classifiers in RankBy Bagging ProbSVM InnerLoop . We empirically selected p = 20 % ( i.e 40 % samples of the rank list were used ) since a larger p will increase the number of incorrect labels , and a smaller p will cause over fitting . In pos consists of 0.7×|Spos| samples that are addition , S∗ selected randomly with replacement from Spos . This sampling strategy is adopted from the bagging framework [ 6 ] . The same setting was used for S∗ • : the maximum Kendall tau distance Knorm(τ1 , τ2 ) between two rank lists τ1 and τ2 . This value is used to determine when the inner loop and the outer loop stop . We set = 0.05 for balancing between accuracy and processing time . Note that a smaller requires more iterations , making the system ’s speed slower . neg .
• kernel : the kernel type is used for the SVM . The default is a linear kernel that is defined as : k(x , y ) = xff∗y . We have tested other kernel types such as RBF or polynomial , but the performance did not change much . Therefore , we used the linear kernel for simplicity .
3http://trecnistgov/pubs/trec10/appendices/measurespdf
Figure 5 . Distribution of retrieved faces and relevant faces of 16 individuals used in experiments . Due to space limitation , bars corresponding to George Bush ( 2,282 vs . 1,284 ) and Tony Blair ( 682 vs . 323 ) were cut off at the upper limit of the graph .
Figure 6 .
We then used principle component analysis [ 18 ] to reduce the number of dimensions of the feature vector for face representation . Eigenfaces were computed from the original face set returned using the text based query method . The number of eigenfaces used to form the eigen space was selected so that 97 % of the total energy was retained [ 5 ] . The number of dimensions of these feature spaces ranged from 80 to 500 .
Figure 6 . Face normalization . ( top ) faces with detected eyes , ( bottom ) faces after normalization process .
4.3 Evaluation Criteria
We evaluated the retrieval performance with measures that are commonly used in information retrieval , such as precision , recall , and average precision . Given a queried person and letting Nret be the total number of faces returned , Nrel the number of relevant faces , and Nhit the total number of relevant faces , recall and precision can be calcu
388388
4.5 Results
451 Performance Comparison with Existing Ap proaches
We performed a comparison between our proposed method with other existing approaches .
• Supervised Learning ( SVM SUP ) : We randomly selected a portion p of the data with annotations to train the classifier ; and then used this classifier to re rank the remaining faces . This process was repeated five times and the average performance was reported . We used a range of portion p values for experiments : p = 1 % , 2 % , 3 % , , 5 % .
• Text Based Baseline ( TBL ) : Once faces corresponding with images whose captions contain the query name are returned , they are ranked in time order . This is a rather naive method in which no prior knowledge between names and faces is used .
• Distance Based Outlier ( DBO ) : We adopted the idea of distance based outliers detection for ranking [ 14 ] . Given a threshold dmin , for each point p , we counted the number of points q so that dist(p , q ) ≤ dmin , where dist(p , q ) is the Euclidean distance between p and q in the feature space mentioned in section 42 This number was then used as the score to rank faces . We selected a range of dmin values for experiments : dmin = 10 , 15 , 20 , , 90 .
• Densest Sub Graph based Method ( DSG ) : We reimplemented the densest sub graph based method [ 16 ] for ranking . Once the densest subgraph was found after an edge elimination process , we counted the number of surviving edges of each node ( i.e face ) and used this number as the ranking score . To form the graph , the Euclidean distance dist(p , q ) was used to assign the weight for the edge linked between node p and node q . DSG require a threshold θ to convert the weighted graph to the binary graph before searching for the densest subgraph . We selected a range of θ values that are the same as the values used in DBO : θ = 10 , 15 , 20 , , 90 .
• Local Density Score ( LDS ) : This is the first stage of our proposed method . It requires the input value k to compute the local density score . Since we do not know the number of returned faces from text based search engines , we used another input value f raction defined as the fraction of neighbors and estimated k by the formula : k = f raction ∗ N , where N is the number of returned faces . We used a range of f raction values for experiments : f raction = 5 % , 10 % , 15 % , , 50 % . For a large number of returned faces , we set k to the maximum value of 200 : k = 200 .
• Unsupervised Ensemble Learning Using Local Density Score ( UEL LDS ) : This is a combination of ranking by local density scores and then the ranked list is used for training a classifier to boost the rank list .
Figure 7 . Performance comparison of methods . Due to different settings , performances are superimposed for better evaluation .
Figure 7 shows a performance comparison of these methods . Our proposed methods ( LDS and UEL LDS ) outperform other unsupervised methods such as TBL , DBO and DSG . Furthermore , the performance of the DBO and DSG methods are sensitive to the distance threshold , while the performance of our proposed method is less sensitive . It confirms that the similarity measure using shared nearest neighbors is reliable for estimation of the local density score . The performance of UEL LDS is slightly better than LDS since the training sets labeled automatically from the ranked list are noisy . However , UEL LDS improves significantly even when the performance of LDS is poor . These performances are worse than that of SVM SUP using a small number of labeled samples .
Figure 8 shows an example of the top 50 faces ranked using the TBL , DBO , DSG and LDS methods . The performance of DBO is poor since a low threshold is used . This ranks irrelevant faces that are near duplicates ( rows 2 and 3 in Figure 8(b ) ) higher than relevant faces . This explains the same situation with DSG .
452 Performance of Ensemble Classifiers
In Figure 9 , we show the performance of five single classifiers and that of five ensemble classifiers . The ensemble
389389
Method GoogleSE UEL LDS SVM SUP 05 SVM SUP 10
Precision at top 20 Recall 100.00 79.33 72.50 89.00 73.14 85.00 90.67 74.94
Precision 57.08 76.41 76.46 78.30
Table 1 . Comparison of different methods on the new test set returned by Google Image Search Engine . classifier k is formed by combining single classifiers from 1 to k . It clearly indicates that the ensemble classifier is more stable than single weak classifiers .
453 New Face Annotation
We conducted another experiment to show the effectiveness of our approach in which learned models are used to annotate new faces of other databases . We used each name in the list as a query to obtain the top 500 images from the Google Image Search Engine ( GoogleSE ) . Next , these images were processed using the steps described in section 4.2 : extracting faces , detecting eyes and doing normalization . We projected these faces to the PCA subspace trained for that name and used the learned model to re rank faces .
There were 4,103 faces ( including false positives nonfaces detected as faces ) detected from 7,500 returned images . We manually labeled these faces and there were 2,342 relevant faces . On average , the accuracy of the GoogleSE is 5708 %
In Table 1 , we compare the performance of the methods . The performance of UEL LDS was obtained by running the best system , which is shown as the peak of the UELLDS curve in Figure 7 . The performances of SVM SUP 05 and SVM SUP 10 correspond to the supervised systems ( cf . section 451 ) that used p = 5 % and p = 10 % of the data set respectively . We evaluated the performance by calculating the precision at the top 20 returned faces , which is common for image search engines and recall and precision on all detected faces of the test set . UEL LDS achieved comparable performance to the supervised methods and outperformed the baseline GoogleSE . The precision at the top 20 of SVM SUP 05 is poorer than that of UEL LDS due to the small number of training samples . Figure 10 shows top 20 faces ranked using these two methods .
5 Discussion
Our approach works fairly well for well known people , where the main assumption that text based search engines return a large fraction of relevant images is satisfied . Figure 12 shows an example where this assumption is broken . Consequently , as shown in Figure 13 , the model learned by this set performed poorly in recognizing new faces returned by GoogleSE . Our approach solely relies on the above assumption ; therefore , it is not affected by the ranking of textbased search engines .
The iteration of bagging SVM classifiers does not guarantee a significant improvement in performance . The aim of our future work is to study how to improve the quality of the training sets used in this iteration .
6 Conclusion
We presented a method for ranking faces retrieved using text based correlation methods in searches for a specific person . This method learns the visual consistency among faces in a two stage process . In the first stage , a relative density score is used to form a ranked list in which faces ranked at the top or bottom of the list are likely to be relevant or irrelevant faces , respectively . In the second stage , a bagging framework is used to combine weak classifiers trained on subsets labeled from the ranked list into a strong classifier . This strong classifier is then applied to the original set to re rank faces on the basis of the output probabilistic scores . Experiments on various face sets showed the effectiveness of this method . Our approach is beneficial when there are several faces in a returned image , as shown in Figure 11 .
References
[ 1 ] O . Arandjelovic and A . Zisserman . Automatic face recognition for film character retrieval in feature length films . In Proc . Intl . Conf . on Computer Vision and Pattern Recognition , volume 1 , pages 860–867 , 2005 .
[ 2 ] M . S . Bartlett , J . R . Movellan , and T . J . Sejnowski . Face recognition by independent component analysis . IEEE Transactions on Neural Networks , 13(6):1450–1464 , Nov 2002 .
[ 3 ] T . L . Berg , A . C . Berg , J . Edwards , and D . A . Forsyth . Who ’s in the picture ? In Advances in Neural Information Processing Systems , 2004 .
[ 4 ] T . L . Berg , A . C . Berg , J . Edwards , M . Maire , R . White , Y . W . Teh , E . G . Learned Miller , and D . A . Forsyth . Names and faces in the news . In Proc . Intl . Conf . on Computer Vision and Pattern Recognition , volume 2 , pages 848–854 , 2004 .
[ 5 ] D . Bolme , R . Beveridge , M . Teixeira , and B . Draper . The csu face identification evaluation system : Its purpose , features and structure . In International Conference on Vision Systems , pages 304–311 , 2003 .
[ 6 ] L . Breiman .
Bagging predictors . Machine Learning ,
24(2):123140 , 1996 .
390390
[ 7 ] M . M . Breunig , H P Kriegel , R . T . Ng , and J . Sander . LOF : Identifying density based local outliers . In Proc . ACM SIGMOD Int . Conf . on Management of Data(SIGMOD ) , pages 93–104 , 2000 .
[ 8 ] C C Chang and C J Lin . support vector machines , 2001 . http://wwwcsientuedutw/" "cjlin/libsvm .
LIBSVM : a library for Software available at
[ 9 ] M . Charikar . Greedy approximation algorithms for finding In APPROX ’00 : Proceeddense components in a graph . ings of the Third International Workshop on Approximation Algorithms for Combinatorial Optimization , pages 84–95 . Springer Verlag , 2000 .
[ 10 ] L . Ertoz , M . Steinbach , and V . Kumar . Finding clusters of different sizes , shapes , and densities in noisy high dimensional data . In SIAM International Conference on Data Mining , pages 47–58 , 2003 .
[ 11 ] M . Ester , H P Kriegel , J . Sander , and X . Xu . A densitybased algorithm for discovering clusters in large spatial databases with noise . In Proc . ACM SIGKDD Int . Conf . on Knowledge Discovery and Data Mining ( SIGKDD ) , pages 226–231 , 1996 .
[ 12 ] R . Fergus , P . Perona , and A . Zisserman . A visual category filter for google images . In Proc . Intl . European Conference on Computer Vision , volume 1 , pages 242–256 , 2004 .
[ 13 ] M . Kendall . Rank Correlation Methods . Charles Griffin
Company Limited , 1948 .
[ 14 ] E . M . Knorr , R . T . Ng , and V . Tucakov . Distance based outliers : Algorithms and applications . VLDB Journal : Very Large Data Bases , 8(3 4):237–253 , 2000 .
[ 15 ] L J Li , G . Wang , and L . Fei Fei . Optimol : automatic online picture collection via incremental model learning . In Proc . Intl . Conf . on Computer Vision and Pattern Recognition , volume 2 , pages 1–8 , 2007 .
[ 16 ] D . Ozkan and P . Duygu . A graph based approach for naming faces in news photos . In Proc . Intl . Conf . on Computer Vision and Pattern Recognition , volume 2 , pages 1477–1482 , 2006 .
[ 17 ] J . Platt . Probabilistic outputs for support vector machines and comparison to regularized likelihood methods . In Advances in Large Margin Classifiers , pages 61–74 , 1999 .
[ 18 ] M . Turk and A . Pentland . Face recognition using eigenfaces . In Proc . Intl . Conf . on Computer Vision and Pattern Recognition , 1991 .
[ 19 ] P . Viola and M . Jones . Rapid object detection using a boosted cascade of simple features . In Proc . Intl . Conf . on Computer Vision and Pattern Recognition , volume 1 , pages 511–518 , 2001 .
[ 20 ] T F Wu , C J Lin , and R . C . Weng . Probability estimates for multi class classification by pairwise coupling . Journal of Machine Learning Research , 5:975–1005 , 2004 .
[ 21 ] W . Zhao , R . Chellappa , P . J . Phillips , and A . Rosenfeld . Face recognition : A literature survey . ACM Computing Surveys , 35(4):399–458 , 2003 .
( a ) TBL 11 irrelevant faces
( b ) DBO 17 irrelevant faces
( c ) DSG 18 irrelevant faces
( d ) LDS 4 irrelevant faces
Figure 8 . Top 50 faces ranked by the methods TBL , DBO , DSG and LDS . Irrelevant faces are marked with a star .
391391
Figure 9 . Performance of the ensemble classifiers and single classifiers .
( a ) 5 irrelevant faces
( b ) no any irrelevant face
Figure 10 . Top 20 faces ranked by Google Image Search Engine ( a ) and ranked using our learned model ( b ) . Irrelevant faces are marked with a star .
Figure 12 . Example in which portion of relevant faces is dominant , but it is difficult to group all these faces into one cluster due to large facial variations . In feature space , the largest cluster formed from relevant faces is not largest cluster among those formed from all returned faces . Irrelevant faces are marked with a star .
Figure 11 . Image returned by GoogleSE for query ’Gerhard Schroeder’ . GoogleSE was unable to accurately identify who the queried person was , while the learned model of our approach accurately identified him .
Figure 13 . Many irrelevant faces annotated using the model learned from the data set shown in Figure 12 . Irrelevant faces are marked with a star .
392392
