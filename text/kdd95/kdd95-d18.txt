From : KDD 95 Proceedings . Copyright © 1995 , AAAI ( wwwaaaiorg ) All rights reserved .
Discovery and Maintenance of Functional Dependencies by Independencies
Siegfried
Bell
Informatik VIII
University Dortmund
44221 Dortmund Germany bell@lsSinformatikuni dortmundde
Abstract
For semantic query optimization one needs detailed knowledge about the contents of the database . Traditional techniques use static knowledge about all possible states of the database which is already given . New techniques use knowledge only about the current state of the database which can be found by methods of knowledge discovery in databases . Databases are often very large and permanently in use . Therefore , methods of knowledge discovery are only allowed to take a small amount of the capacity of the database system . So database access has to be reduced to a minimum during the process of discovery and obviously if the database changes during the process of maintenance of the discovered knowledge . In this paper , the main effort has been put into minimizing the number of database accesses , wrt , discovery and maintenance . This is exemplified by the discovery of functional dependencies . We improve the inference of functional dependencies by using independencies and cardinality dependencies . First we give an axiomatization . Then we describe the three parts of our system : the initialization by cardinality dependencies , the exclusion of hypothetical dependencies by entailment , and the verification of hypothetical dependencies by SQL queries . Moreover , we investigate the complexity of each subsystem . In addition , we describe the maintenance of discovered dependencies and finally draw some conclusions .
Introduction and Related Work
Query optimization can be regarded as the process of transforming a query Q into another query Q~ that can be evaluated more efficiently , as mentioned by ( Chakravarthy , Grant , & Minker Chakravarthy et al . 1990 ) . Semantic query optimization ( SQO ) is mainly based on the use of semantic knowledge during the optimization process . Thus , the user is motivated to concentrate on the application rather than forming queries with explicit semantic knowledge of the application .
So far , the main problem is to provide the optimizers with semantic knowledge about the database during SQO . Obviously , the only kind of semantic knowledge which is always available in relational databases management systems ( DBMS ) are integrity constraints like primary or foreign keys . Thus , Chakravarthy et al . ( Chakravarthy , Grant , & Minker 1990 ) have defined SQO in respect of integrity constraints as to transform a query into one which is semantically equivalent to the original query , but which can be executed more efficiently . King ( King 1981 ) argued that the costs evaluating the transformed query plus the transformation costs should be lower than the costs of evaluating the original query . Semantic equivalence means that the transformed query has the same answer as the original query on all database states satisfying the integrity constraints . Jarke et al . ( Jarke , Clifford , & Vassiliou 1984 ) have shown several ways to use functional dependencies for SQO . But the constraints provided by a DBMS are few and often in the sense that they are valid in all possible database states . too general
Another way is to provide SQO with semantic know techledge by hand which also seems no adequate nique . For example , King ( King 1981 ) uses constraints on attribute values to optimize queries by his system QUIST . Zhang and Ozsoyoglu ( Zhang & Ozsoyoglu 1994 ) have presented also techniques for semantic query optimization which are based on implication constraints . Implication constraints are a generalization of functional dependencies .
The arise of knowledge discovery in databases to solve both prob a new approach
( KDD ) offers lems : provides SQO automatically with constraints reand extends them to constraints which precisely flects the present content of the database . Siegel has reported this by the first time ( Siegel 1988 ) and ( Siegel , Sciore , ~z Salveter 1991 ) . Such constraints have been termed , for example , Database Abstractions in ( Hsu Knoblock 1993 ) , Metadala in ( Siegel & Madnick 1991 ) , and Meta Knowledge in ( Schlimmer 1991 ) . Also , Hsu and Knoblock ( Hsu & Knoblock 1993 ) have shown the benefits of optimization techniques based on automatically discovered constraints . But we have to keep in mind that these constraints are only valid in the present state of the database and therefore describe the content of the database precisely . The constraints may become invalid , if the database changes . Therefore , we have to maintain the discovered knowledge , if
Bell 27 we use it more than once .
Problmns arise if knowledge discovery is applied to real world databases which are continuously in use and large . Therefore , knowledge discovery ill databases is only allowed to take a small portion of the system resources .
Comparable to our approach in order to discover functional dependencies , there are similar ones by Mannila and R/iih~i ( Mannila & Riiildi 199l ) , Dehaspe et al . ( Dehaspe , Laer , & Raedt 1994 ) , Savnik and Flach ( Savnik & Flach 1993 ) , and Schlimmer ( Schlimthe mer 1993 ) . Mannila and Riiih~i have investigated problem of inferring FDs from example relations in order to determine database schemes . But they do not use a complete inference relation regarding independencies . Sawfik and Flach have investigated a special data structure for the FDs . Briefly , they start with a bottom up analysis of the tuples and construct a negative cover , which is a set of FIs . In the next step they use a top down search approach . They check the validity of a dependency by searching for FIs in the negative cover . Also , the negative cover is not complete regarding a classical consequence relation . Schlimmer also uses a top down approach , but in conjunction with a hash function in order to avoid redundant computations . However , he does not use a complete inference relation even regarding functional dependencies . Also do Dehaspe et al . because their inferences are based on ® subsumption . In addition , is based on theorem proving which is not suitable for real world databases . the verification
In general , these authors do not use a relational database like OracleV7 or any other commercial DBMS . In such case , we argue that the proposed algorithm and approaches have to redesign according the set oriented interface of a relational database system . For example , the concept of the negative cover has only advantages if the tuples can be accessed directly , ie the tuples are stored in the main memory as Prologfacts . Savnik and Flach have introduced it because the complexity for testing contradiction of the FDs is reduced .
In contrast to these appproaches our purpose is different because we maintain the discovered FDs in order to use them all the time by semantic query optimization .
In addition , we argue that by using a relational database system , the higher complexity of the complete inference relation is justified by the size of a real world database .
We have already investigated the discovery of value unary inclusion dependencies , and timerestrictions , tional dependencies in relational databases and has implemented this approach by using the database management system ORACLE ( Bell & Brockhausen 1995 ) . Also , we have given an approach to test these dependencies by SQL statements and have given an empirical evaluation .
28 KDD 95
NULL
1
2
1 true false false
NULL false true false
2 false false true
Figure 1 : Equality operator
Thus , this paper focuses on minimizing the number the discovery of funcof accesses to the database wrt , tional dependencies and their maintenance . The inference of functional dependencies is improved by using functional independencies and by cardinality dependencies . Also , we regard Nu:l_:k values because they frequently arise in databases . We give an axiomatization of these independencies and discuss the complexity of the implemented inference relation which is given by three algorithms . Then we describe dependency maintenance caused by insertion or deletion of tuples .
Functional
Independencies
In this section we discuss functional independencies and their axiomatization . We assume familiarity with the definitions of relational database theory ( see for example ( Kanellakis 1990 ) ) and the basic properties of the classical consequence relation . The capital letters A , B , C , denote attributes , and X , Y , Z denote sets . We do not distinguish between an atattribute tribute A and an attribute set {A} . We omit proofs when they are trivial . Remember that every attribute is associated with a set of values , called its domain . Functional dependencies are defined as usual . Additionally , we consider Null values because the ISO standard permits Nu]:I values in any attribute of a candidate key . Therefore , we adopt a special equality operator for the definition of the FDs , ~ , which is illustrated in figure 1 .
The so called Armstrong ’s Axioms provide a correct and complete axiomatization for them and establish an inference relation I A .
We now can define the consequences of a set of dependencies . Let E be a set of functional dependencies , then X ~ Y is a consequence of E , or X + Y 6 Cn(E ) : whenever a relation satisfies E it satisfies X + Y . The closure of attributes X wrt , a set of FDs ? , is defined as : closure(X , ~ ) = {Y I X + Y e Cn(Z)} and is denoted by X .
Functional independencies have been introdnced by aan~ ( aanas 1988 ) to mirror functional dependencies . But they are meant for a totally different purpose : FIs are not semantical constraints on the data , but a support for the database designer in the task of identifying functional dependencies . In addition , they also help to improve the inference of fimctional dependencies . We simplify the definition of functional independencies here by ignoring Null values .
1 than our functional
In ( Paredaens el al . 1989 ) afunctional dependencies are introduced , but they are a sort of semantic constraints and much stronger independencies . Therefore , we cannot use them to improve the inference of FDs . Independency Definition X 74 Y denotes a functional independency . A relalion r satisfies X 7t* Y ( r ~ X 74 Y ) if there exist tuples 11 , t2 of r with tl[XI~ I2[X ] and tl[Y]~t2[Y ] .
1 ( Functional
( FI ) )
The consequences of FDs and FIs are defined as follows : Let ~ be a set of FDs and ~’ aset of FIs . Cn(~ U ~,’ ) := {~l for each relation r if r M ~ U ~’ , r ~ ~} where a is a FD or FI . ~ U ~’ is then called inconsistent , if there exists a X 7¢ Y so that X ~ Y e Cn(~ . U ~’ ) and X ~ Y e Cn(~,U ~.’ ) vice versa .
An axiomatization of FIs has already been given by Janas ( Janas 1988 ) which establishes an inference relation ba , Definition 2 ( FIs ) The axiomatization given by : by Janas is
XJ.Y 1 . X~CYZ
2 .
XZ~ ~YZX ZTt , Y xc ,z
YC ,z
3 . x ,z ,
We show with a counterexample that this inference relation is not complete , ie with X 74 Y E Cn(EUZ’ ) and EU~.’ ~a,~ X 74 Lemma 1 The following inference rule is correct : there exists some X 74 Y z ,Y , ZTCY
Lemma 2 { X * Y , Z 74 Y } ~anas Z ~/ ~ X . Proof " We assume that X , Y and Z are disjoint . Then obviously the first and the second rule cannot be applied to infer Z 74 X . Thus , the third rule can be applied only . But Z is not in the closure of Y and ~ ] , ie {X ~ Y} I;/A Y * Z . Thus , we cannot infer [ ] by Janas ( Janas
Theorem 1 The axiomatization 1988 ) is not complete . x .
Instead , we propose the following axiomatization :
Definition 3 ( Inference of FIs ) An inference relation ~ li is given by an axiomatization of the FDs and the following inference rules :
FII :
XV;I , YW , W CV xl~Y
FI2 : x .Y , XOZ
Y74Z
FI3 : Y ~Z,X?4ZX74Y
For example , the functional independency X 74 YZ which is a consequence of Janas’ first inference rule can be inferred by P1i as follows : we infer YZ ~ Y by Armstrong ’s Axioms and use FI3 to infer a FIX 74 YZ fromX74YandYZ~Y . Theorem 2 ( Soundness The inference rules FI1 to FI3 are correct and complete for a consistent set of functional dependencies , respectively independencies . and Completeness )
Proof : For details refer to ( Bell 1995 ) . A rough sketch is as follows : First , it has to be shown that the FIs do the inference of FDs . Second , that we can not affect infer from a set of FIs only trivial inferences , eg if AB 74 C then A 74 Cor ifAB 74 C , then AB 74 CD . The last part can be seen by a negative proof of Armstrong ’s Axioms , or by a construction of the certain possible cases . [ ]
Independencies of Functional
Inference Our system consists of three elements : initialization , It is roughly sketched in entailment , and verification . table 1 . First , we initialize our data structure List for the FDs and FIs . Then , we generate hypothetical dependencies , check if these are already entailed by the known dependencies or independencies , and the remaining ones by querying the database . verify We use a kind of breath first search because we generate only hypotheses which are not related by each other . Terminating is ensured , because if no already entailed hypotheses can be generated , then the algorithm stops . The algorithms are written and connected to an OR.ACLE7 server by a SQL interface via TCP/IP . in PROLOG
Verification Functional dependencies can be verified by sorting the tuples of the relation which takes O(n log n ) time wrt the number of tuples , cf . ( Mannila & RAthe . 1991 ) . our implementation we use the nvl statement to handle the NULL values . in SQL
Entailment Entailment of FDs is often discussed by studying if [ A X + Y holds where ~ is a set of FDs and n = ]~4 . This can be decided in linear time with appropriate data structures 2 , we can easily construct an algorithm for testing FIs :
( Kanellakis 1990 ) . By Lemma function ~ t3 ~’ I fi X 74 Y ; begin aThe definition of the AD X //¢ Y requires that for each tuple t there exists a tuple t’ so that fiX] a t’[X ] and t[Y]~ t’[Y ] . end ; for eachV 74 W E ~’ do if ~ I A V ~ X and E [ A Y ~ W then return Yes ; else return No ;
Bell
29
1 . Initialize List . 2 . Repeat ( a ) Take an element t from List and generate all tuples T with a fixed length that are not entailed by List .
( b ) Query DB server for T . ( c ) Add T to List and find a minimal cover for it .
3 . until no already entailed hypothesis can be generated
Table 1 : Description of our System
It is obvious that testing FIs takes O(n2 ) time where n = max(E , E~ ) . Correctness and completeness follow immediately from the previous section .
The sets of FDs and FIs are usually very large . We can reduce these sets taking into account the following observation : The set of functional dependencies is partitioned into equivalence classes by the satisfiability definition . Each class of functional dependencies specifies the same set of admissible relations . As these equivalence classes will typically contain a large number of elements , it is reasonable to define a suitable representation with a minimal number of elements . This representation is usually called a minimal cover , see ( Maier 1980 ) . We can simply extend the definitions ( Maier 1980 ) by using our inference relation t ]i :
Definition set of FDs .
4 ( Minimal Cover ) Let E be a minimal
E’ is a set of FIs and is called minimal if for all V 7c , W E Cn(E O E’ ) there exists no X ~c , y E E’ with E u E’\{X ¢~ r} ~s , V ¢ . W .
Therefore , minimizing can be done by repeated apand takes O(na ) time for some set of plication of I ]i FDs and FIs .
Initialization The data structures of the FDs and FIs are initialized with information about primary keys and sufficient conditions for FIs . These conditions are given by the cardinality of the attributes which were introduced by Kanellakis et al . as Unary Cardinality Dependencies ( UCDs ) in the unary case ( Kanellakis , Cosmadakis , Vardi 1983 ) . We have extended these UCDs to the general case of CDs and have given an axiomatization in ( Bell t995 ) . Thus , we propose the following two rules as sufficient conditions for FIs : Definition 5 ( Cm’dinality of Attributes ) and Y be sets of attributes :
Let X
CD FII : IXl>_lYI , X;/~Y
Y~X
30 KDD 95
CD FI2 : IxI>WI Y~X
The correctness of these rules is indicated by the fact that for every FD X , Y equal X values demand equal Y values . But this implies that there must exist at least as many X values as Y values which can be formulated only with independencies . This fact clearly demonstrates the usefulness of FIs . Unfortunately , it turned out that testing CDs by our SQL interface is as expensive as testing FDs2 . Thus , we check the cardinality of UCDs in a single pass for each attribute and approximate CDs by the following Lemma without a proof : Lemma 3 Let A E X be the attribute with the maximal cardinality If IA[ >_ ( IBxll~,~l ) , then IXI _> Irl and Y = B1,,Bn
Hence , we initialize our data structures of FDs and FIs with CDs approximated in this manner and the inference rule CD FI2 only . Since the number of CDs is a combinatorial function of the number of attributes , it is easy to see that the number of CDs grows exponentially wrt , the nmnber of attributes . Therefore , the algorithm is in EXPTIME . But , as a matter of fact , this approximation algorithm does not need any resources of the database system . In addition , the worst cases arise only rarely . of the System the performance cannot the number of attributes .
Complexity Our system is in EXPTIME because there exist relations with the number of PDs in a minimal cover growing exponentially wrt , This has been shown by Mannila and R~iih/i ( Mannila & R/iih~i 1991 ) . As there are relations with the munber of FIs growing exponentially be improved by using FIs instead of FDs . Theorem 3 ( Cardinality For each n there exisls a relation r which satisfies a minimum cover of FIs with lhe cardinality f~(2n/2 ) . Proofi see ( Bell 1995 ) .
[ ] If the relation of Mannila and R/iih~i is added to ours , then it is easy to see that relations exist where the sets of FDs and FIs grow exponentially wrt , the number of attributes . Again , we argue that our goal , to minimize database access , can be achieved with this system . of the set of FIs )
Maintenance of FDs
Obviously , the discovered FDs can become invalid , because they only describe the current state of the database . Therefore , the discovered FDs have to be maintained if new tuples are added , old tuples are deleted , or existing tuptes are updated .
If maintenance of FDs is seen as revision , it is more to do theory revision than base revision as suitable
2We can only count the number of values of single at tributes by the SQL statement count . z.:={} for each A1 , , Aa * B1 , ¯ ¯ . , Bm E E do begin bl,,brn,Cl,,cI
:= select B1 , . ¯ . , Bin , C1 , ¯ ¯ . , Cz from r where Ai , = ail , ¯ ¯ ¯ , Ai , , = aim ifAi=o mbi=d +i then
En := En UAI,,An
* B1,,Bin else begin
o B1,,Bm
E := E\A1,,A , if there is a minimal u with C5 , , Cl~ and Ai=l vdt~ ~ ct~ then E~ := En UA1,,An,Ch,,C~ end end
B1 , , Bm
Table 2 : Algorithm for Inserting New Tuples introduced by G~irdenfors ( G~irdenfors 1988 ) . In contrast to theory revision , base revision works on the whole consequnce set So it is easy to see , for example , that by adding a new tuple the second FD of the set {AB * CD , CD ~ EF} may become invalid , but the AB * EF remains valid . Therefore , in a first step the minimal set of FDs E is transformed into a set Em of FDs . This new set is called most general and can be computed with the following algorithm : for each X * Y E E do if Y = closure(X , E)\X then
Obviously , the complexity depends on the cardinal ity of E and the closure operation which is mentioned above .
Inserting
Tuples
If new tuples are added , FDs may become invalid . Thus , each FD is checked if it is still valid . If not then the FD has to be replaced by a set of FDs which are valid . The algorithm is listed in table 2 and is applied before the tuple is inserted . r the corLet ( dl,,dn+m+t ) responding scheme R = ( A1,,An,B1,,Bm,C1,,Ct ) , B1 , , Bm the selected FD and CI , , Ci the remaining attributes . The ci can consist of values and that we expand the left hand side of each invalid FD by attributes which values are different from the selected ones . be the new tuple , relation with the relation
A1,,A ,
*
The advantage of this algorithm is that it only one simple query for each new tuple and for each FD is needed . It is easy to see that the removed FDs are
B1,,B,~ the new tuple no longer valid . For the correctness , we first give the following lemma : Lemma 4 Each generated FD is valid . Proof : We call is invalid . Then there must AI,,An , be least at one tuple t2 so that tl [ As , , An]~ t2[A1 , , Aa ] and We know by contl[B1,,Bm]~t2[B1,,B, , ] struction that tl[Ch , , Ct~]~ t2 [ Ch , . . . , Ct~ ] . Hence , and tl IX , Ch , . . . , Ct~]~ t~[X , Ch , . . . , Ct , ] A1,,A,,Ch,,Ct~ [ ] Completeness can now be seen by the following tl . We know that
~ B1,,Bin is valid . lemma :
Lemma 5 Let E be the former set of FDs and En be the revised set of FDs . rn is obtained by expanding r by one tuple . Assume that E ~ X * Y and r ~ X * Y . If En ~ X * Y , then rn ~ X ~ Y . Proof." By correctness we only add valid FDs . By minimality of the added attributes to the LHS of the FD , it is guaranteed that an FD with less attributes at the LHS is not valid . [ ] We conclude that if our algorithm is applied on E and the result is E~ , then r~ ~ E~ by the lemmas .
Tuples
Deleting Deleting tuples does not affect the old set of FDs , but some new FDs may become valid . Therefore , we have the FDs and add new FDs if necessary . Unto revise it turned out , that deleting tuples is the fortunately same as discovering FDs with a given starting set of FDs . Therefore computation in this case can be as expensive as the discovery process .
Tuples
Updating Normally , updating tuples can be seen as a combination of deleting and inserting tuples . But sometimes we can simplify this process by comparing the old values with the new ones .
Assume that d = ( al,,a~,bl,,bm,cl,,cg )
,
’ ’
’ ’ ¯ ,an,bl,,bin,el ,
c~ ) , and the selected is the tuple which will be updated by the values ( a~ , is A1,,An ~ B1,,Bm ¯
If the values of the attributes of the left and the right hand side do not change , then we have nothing to do . If Ai=l bl = b~ and at least one value of Ai , 1 < i < n , does not occur in r , then we have only to apply the algorithm for deleting tuples .
¯
Discussion
Our goal has been to minimize database access during the discovery of FDs and the maintenance of the discovered FDs . We have shown , that this can be achieved by the axiomatization of functional dependencies and independencies presented in this paper and the use of
Bell
31 relational
Jarke , M . ; Clifford , J . ; and Vassiliou , Y . 1984 . An optimizing prolog front end to a relational query system . ACM SIGMOD . Kanellakis , P . ; Cosmadakis , S . ; and Vardi , M . 1983 . Unary inclusion dependencies have polynomial time inference problems . Proc . 15th Annual ACM Symposium on Theory of Computation . Kanellakis , P . 1990 . Formal Models and Semantics , Handbook of Theoretical Computer Science . Elsevier . chapter Element.s of Relational Database Theory , 12 , 1074 1156 . King , J . J . 1981 . Query optimization by semantic reasoning . Technical Report STAN CS 81 857 , Stanford University . Maier , D . 1980 . Minimum covers in tile database model . Journal of the A CM 27(4):664 674 . Mannila , H . , and RS.ih~i , K J 1991 . The design of relational databases . Addison Wesley . Paredaens , J . ; de Bra , P . ; Gyssens , M . ; and van Gucht , D . 1989 . The Structure of the Relational Database Model . Springer Verlag Berlin Heidelberg . Savnik , I . , and Flach , P . 1993 . Bottum up indution of functional dependencies from relations . In PiatetskyShapiro , G . , ed . , KDD 93 : Workshop on Knowledge Discovery in Databases . AAAI . Schlimmer , J . C . 1991 . Database consistency via inductive learning . In Eight International Conference on Machine Learning . Schlimmer , J . 1993 . Using learned dependencies to automatically construct sufficient and sensible editing views . In Piatetsky Shapiro , G . , ed . , KDD 93 : Workshop on KT~owledge Discovery in Databases . AAAI . Siegel , M . , and Madnick , S . M . i991 . A metadata approach to resolving semantic conflicts . In Conference on Very Lalye Databases . Siegel , M . ; Sciore , E . ; and Salveter , S . 1991 . Rule discovery for query optimization . In Knowledge Discovery in Databases . Menlo Park : AAAI Press . chapter 24 . Siegel , M . D . 1988 . Automatic rule derivation for semantic query optimization . In Second International Conference on Expert Database Systems . Zhang , X . , and Ozsoyoglu , Z . M . 1994 . Reasoning with implicational and referential constraints in semantic query optimization . In Workshop on Constraiuts and Databases , Post lLPS . to a com cardinality dependencies . The alternative plete inference would be a more or less exhaustive test of FDs oll tile database . Usually , real world databases are very large , tile number of tuples is much larger than the number of attributes . Tile main costs of database management systems are caused by reading from secondary memory . Therefore , a single saved database query makes up for tile costs of inferring FDs and FIs . This is true for tile maintenance , too .
Basically , our system is to discover candidate keys because these can be used efficiently for optimization techniques . Candidate keys are based on FDs so we have concentrated on only discovery of FDs . In general , algorithms for discovering PDs are in EXPTIME wrt , the number of attributes . We have already investigated discovering foreign keys which play also an important role in SQO .
Currently , we are investigating tile use of data de pendencies in semantic query optimization .
Acknowledgment : I would like to thank Peter
Brockhausen , Martin Mfihlenbrock , Steffo Weber and Sabine Wohlrab for comments . This work is partly supported by the European Community ( ESPRIT Basic Research Action 6020 , project Inductive Logic Programming ) .
References
Bell , S . , and Brockhausen , P . 1995 . Discovery of constraints and data dependencies in databases ( extended abstract ) . In Lavrac , N . , and Wrobel , S . , eds . , Machine Learning : ECML 95 ( Proc . European Conf . on Machine Learning , 1995 ) , Lecture Notes in Artificial Intelligence 914 , 267 270 . Berlin , Heidelberg , New York : Springer Verlag . An extended version is also available as Research Report by the authors . Bell , S . 1995 . Inferring data independencies . Technical Report 16 , University Dortmund , Informatik VIII , 44221 Dortmund , Germany . Chakravarthy , U . S . ; Grant , J . ; and Minker , J . 1990 . Logic based approach to semantic query optimization . ACM Transaction on Database Systems 15(2 ) . Dehaspe , L . ; Laer , W . V . ; and Raedt , L . D . 1994 . Applications of a logical discovery engine . In Wrobel , S . , ed . , Proe . of the Fourth International Workshop oll hlductive Logic Programmiug , GMD Studien Nr . 237 , 291 304 . St . Augustin , Germany : GMD . G~rdenfors , P . 1988 . Knowledge in Flux Modeling the Dynamics of Epistenlic Slates . Cambridge , MA : MIT Press . Hsu , C N , and Knoblock , C . A . 1993 . Learning database abstractions In Knowledge Discovery in Database , Workshop , AAAI93 . Janas , J . M . 1988 . Covers for functional independencies . In Conference of Database Theory . Springer , Lecture Notes in Computer Science 338 . for query reformulation .
32 KDD 95
