From : KDD 95 Proceedings . Copyright © 1995 , AAAI ( wwwaaaiorg ) All rights reserved .
Efficient Algorithms for Attribute Oriented
Induction
Hoi Yee Hwang and Wai Chee Fu
Department of Computer Science Chinese University of Hong Kong
Shatin , Hong Kong hyhwang@cscuhkhk , adafu@cscuhkhk
Abstract
Data mining or knowledge discovery in databases is the search for relationships and global patterns that exist but are hidden in large databases . Many different methods have been proposed and one of them is the attribute oriented induction method . In this method , domain knowledge in the form of concept hierarchies helps to generalize the concepts of the attributes in the database relations . This approach has been generalized to the rule based attribute oriented induction . The time complexity of the original algorithms is given by O(N log N ) , where N is the number of relevant tuples in the database . In this paper , we make use of the static property of the database schema and the concept hierarchies to derive more efficient algorithms . Given that the concept hierarchies and the resulting knowledge are small in size compared to the database , the complexity of our algorithm is O(N ) . The amount of disk I/O is decreased by O(log N ) times compared to the previous methods . We believe that this improvement in performance will give extra power to the attribute oriented method .
1 . Introduction
Data mining is the search for relationships and global patterns that exist in large databases , but are ‘hidden’ among the vast amounts of data [ Frawley , PiatetskyShapiro & Matheus 19911 . Many different methods for data mining , or knowledge discovery in databases , have been proposed in the past . Overview of this area can be found in [ Agrawal 1994 , Piatetsky Shapiro & Frawley 19911 . Some recent works include [ Agrawal & Srikant 1994 , Faloutsos & Lin 1995 , Park,Chen & Yu 19951 .
In [ Cai , Cercone & Han 1991 , Han , Cai & Cercone 1992 , Han , Cai & Cercone 19931 , an attribute oriented induction method for data driven discovery of quantitative rules in relational databases is presented and a database learning system DBLEARN has been constructed based upon this approach [ Han et al . 19921 . It uses domain knowledge to generate descriptions for predefined subsets in a relational database . The method integrates learningfrom examples techniques with database operations and extracts generalized data from actual data in databases . the concept This attribute oriented approach uses
168
KDD 95 hierarchy to direct the learning process . In the attributeoriented induction process , lower level concepts in a concept tree or lattice are generalized to higher level concepts . The generalization algorithm can be well integrated with database operations , since generalization operations are set oriented , and both data and knowledge are represented as relational tables .
It has been shown that the complexity of this attributeoriented approach is O(NlogN ) [ Cheung , Fu & Han 1994 , Han , Cai & Cercone 19931 , where N is the size of the initial relation . In this paper , we would enhance this performance . It is found that , as soon as the concept hierarchies are given , the generalization path of each attribute in each tuple of the database can be found . So we can set a path id for each attribute concept in the database . The generalization step is made much more efficient and an improved algorithm of O(N ) is proposed . We also replace the algorithm in [ Cheung , Fu & Han 19941 for the rule based attribute oriented approach by this method . With the help of path id , backtracking is eliminated and an efficient algorithm of O(N ) is derived .
The paper is organized as follows . Section 2 gives a brief review on the original attribute oriented induction approach . Terminology and definitions are introduced in Section 3 . Preprocessing work will be stated in Section 4 . In Section 5 , an improved generalization algorithm for the attribute oriented the complexity of this algorithm is discussed in Section 6 . Generalization procedure for rule based attribute oriented induction approach is presented in Section 7 . A conclusion will be given in Section 8 . is proposed , and induction
2 . Original Attribute Oriented Approach
In [ Cai , Cercone 8z Han 1991 , Han , Cai & Cercone 1992 , Han , Cai & Cercone 19931 , an attribute oriented induction method for data driven discovery of quantitative rules in relational databases is presented . It uses domain knowledge to generate descriptions for predefined subsets of a relationa database . This attribute oriented approach uses the concept hierarchy to direct the learning process .
A concept hierarchy is related to a specific attribute and is partially ordered according to a general to specific ordering . The most general point in the hierarchy is the null description ( ANY ) , while the most specific points correspond to the specific values of an attribute in the database .
For example , assume that a university student database has the following schema .
Student( Name , Status , Sex , Age , GPA )
The concept tree table for Student is shown in Figure 1 , the concept tree of the attribute Status will be the one shown in Figure 2 .
( sophomore ) + ( senior ) + ( M.S . ) + undergraduate graduate undergraduate undergraduate undergraduate graduate graduate
( freshman ) + ( junior ) + ( MA ) + ( PhD ) + ( undergraduate , graduate ) + ( 0.0 l .99 ) + ( 30 349 ) + ( poor , average ) + ( weak , strong ) + ( M , F) + ANY(Sex ) ( 16 25 ) + ( 16 25,26 30 ) + poor good
16 25 weak ANY(GPA )
ANY(Age )
ANY(Status )
( 20 299 ) + ( 35 40 ) + ( good , excellent ) + average excellent strong
( 26 30 ) +
26 30
Figure 1 Concept tree table for a university student database level 0
ANY level 1
/ry ,
/
\
Tyha level 2 freshman sophomore junior senior MA MS PhD
Figure 2 Concept tree for Status
A relation . results intermediate is called an relation which represents intermediate ( final ) learning ( final ) In a generalized relation , some or generalized all of its attribute values are generalized data , that is , nonleaf nodes in the concept hierarchies . An attribute in a ( generalized ) relation is at a desirable level if it contains at most a small number of distinct values in the relation . This small number is specified by the user as a desirable attribute threshold .
A set of basic principles for the attribute oriented relational databases is summarized as in induction follows .
1 . Generalization should be performed only on the set of data which is relevant to the learning task .
2 . Generalization should be performed on the smallest decomposable components ( or attributes ) of a data relation .
3 .
4 .
5 .
6 .
Attribute removal : If an attribute has too many distinctive values and there is no higher level concept provided for further generalization , it should be removed from the relation . Concept tree ascension : For an attribute in an intermediate relation , if its values can be generalized to higher level concepts in the concept tree of the attribute , all values of the attributes are replaced by the higher level concepts . Outcome of the ascension is a generalized relation . Vote propagation : Vote of a generalized tuple indicates the number of tuples in the initial relation that are generalized to this tuple . The value of the vote of a tuple is carried to its generalized tuple and the votes should be accumulated when merging tuples . Attribute threshold control : For an attribute , if the number of its distinct values in an intermediate relation is still larger than its desirable attribute threshold , further generalization on this attribute should be performed .
By applying the above principles , an initial relation _ _ would be reduced to a generalized relation call prime relation . This prime relation has a small number of the attribute distinct values ( less than or equal to threshold ) . This prime to be generalized further to produce the final relation . Two additional principles are used to complete the AttributeOriented induction process . relation may need
1 .
2 .
Generalization threshold control : If the number of tuples in a generalized relation is larger than the further generalization generalization should be performed . Rule formation : A is transformed to conjunctive normal form , and multiple tuples are transformed to disjunctive normal form . the final tuple in threshold , relation relation
3 . Terminology and definition
Suppose the database we work on has n attributes . A concept tree Ti is given for each attribute Ai , for i = 1 , . . ,n For each Ti , the root is denoted by ANY and assume that each Ti is a balanced tree .
Definition I For an attribute A , let T be the concept tree of A . For each leaf node a of the concept tree T , we call the path from a to the root ANY a generalization path .
Definition 2 Two paths are said to be equivalent if they pass through the same non empty set of nodes . Two paths are distinct if they are not equivalent .
Hwang
169
4 . Preprocess for generalization
We shall make use of the distinct paths . Assume that there are mi distinct paths for attribute Ai , we can label the distinct paths by { 1,2,,mi} , we call this the path id of the path . Each ground value a of attribute Ai has a unique path to the root ANY whose path id is r , where 15 r I mi . The entire database can be transformed to a Path relation which contains only path id of each ground value . For example , if the generalization relation threshold g is 6 and the concept tree table and the corresponding path id ’s for a university student database is as shown in Figure 3 , the Initial relation of Table 1 will be transformed to the Path relation shown in Table 2 . The attribute Name is removed as we found that there are a large number of distinct names in the initial relation and there is no concept at a higher level to generalize these names . attribute path id generalization path
Name Status
Sex
Age
GPA undergraduate ANY undergraduate +ANY undergraduate +ANY undergraduate ANY removed no 1 2 3 4 5 6 7 1 2 1 2 1 2 3 4 freshman + sophomore + junior + senior + MA +graduate rANY MS + graduate +ANY PhD + M+ANY F ANY { 16 25 ) + ( 26 30 ) 4 ( 0.0 l .99} + ( 20 299 ) + ( 30 349 ) + good + { 35 40 ) + excellent + poor + average +
16 25 +ANY 26 30 +ANY graduate +ANY weak +ANY weak +ANY strong +ANY strong +ANY
Figure 3 Concept tree table and path id for each attribute
Name John Hack JOe MalV Donald l&y Calvin
Status freshman freshman junior senior MA PhD MS
Sex M M M F M M M
Age 20 19 21 22 23 26 26
GPA 3.2 2.8 2.7 3.3 3.3 3.2 3.6
Table 1 Initial relation of the university student database
1 1 3 4 5 7
1 1 1 2 1 1
I
1 1 1 1 1 2
3 2 2 3 3 3
Once we have the Path relation , we can perform generalization on this relation . The user or the system would specify the generalization order of attributes of the relation . The concept trees of Sex , Age and GPA are shown in Figure 4 below . The initial relation is at levels 2,1,2,3 with respect to the attributes Status , Sex , Age and GPA . We can use vectors to represent the order of generalization . As in the student database , let vo = { 2,1,2,3} be the levels of corresponding attributes of the initial relation . If the user wants to generalize the attribute Age to level 1 first , then vi = { 2,1,1,3} . Note that with this sequence of vectors , elements of \ will be less than or equal to the corresponding element of vj whenever i 2 j . Eventually , there is an integer t , where t is less than or equal to the sum of elements in VO , such that vt = { O,O,O,O} , this means that if the generalization is done t times , then all the tuples will be generalized to one tuple in the final relation . There is no restriction that each generalization step should generalize one attribute and one level only . The user can set one generalization step to generalize two or more attributes simultaneously and generalize any attribute by more than one level . For example , vi can be {2,1,1,2},{2,1,2,1} oreven {2,1,1,1} . level 0
ANY
/\ 16 25
1
26 30
ANY
/\ M
F
ANY
/ weak
/\
\ strong
I\
//I\
2 ( j 116 I j I 25 ) ( j 125 I j 5 30 ) poor average good excellent
3
( 0.0 l .99 ) ( 20 299 ) ( 30 349 ) { 35 40 )
Figure 4 Concept trees and levels for the Sex , Age , GPA
Let us call the vectors as described above the level vectors . These vectors may be set by the user or generated by the system and can be set dynamically or statically . A dynamic approach would consider the attribute thresholds .
Let A i,,A , be the attributes not removed , suppose vo = {e0b,e0J , VI = h,,ehl ,
. . . vt = h,,etnl = W
, , 01 are the level vectors where eij is the level of concept of attribute j after i generalization steps . For each ej , there is a corresponding qij which is the number of distinct concepts in the concept tree at that level for attribute j . The maximum possible size of generalization steps , is given by qi , where the relation after i
Table 2 Path relation transformed from the initial relation
9i =
4ij fi j=l
( 1 )
170
KDD 95
Let Si be the set of tuples in the intermediate or final generalized relation after i generalization steps . Let ISil be the number of tuples in Si , we have lSil< qi .
5 . Path id generalization algorithm
Assume that the generalization relation threshold g is given , our task is to find the smallest s such that the number of tuples in the generalized relation , with attribute levels v , , is smaller than or equal to g . We describe two approaches here .
Bottom up approach
The system stores the information of Figure 4 and then use the Path relation to do generalization . At the i th generalization step , a multi dimensional array of integer VoteArray[lqir][lqiz][lqiJ of size qi can be used . Each element in VoteArray corresponds to a unique combination of concepts at vi . Alternatively , since the value of qi may be large , allocating an array of this size may be inefficient or even impossible , in that case we can use a list VoteList to store the same information instead and insert the list by the B tree method , where the index of the B tree is the concept combination . As we shall see , the size of the list will not exceed the threshold g .
We describe in more details here the use of VoteArray . For example , with the previous student database , if vi = { 1,1,1,2} , then we know that Status , Sex , Age , and GPA should generalize to level l,l,l , and 2 respectively and they shall have 2,2,2,4 concepts respectively at the corresponding levels . status : c , , = undergraduate Cl2 = graduate Sex : Age : C31 = 16 25 GPA : Cdl = poor Cd3 = good c22 =F C32 = 26 30 C42 = average CM = excellent q11=2 q12 = 2 q13 = 2 q14 = 4
Gl =M
C43 , so the concept combination is Cri , C2i , C3i , C43 . We shall increment one entry of VoteArray , that correspond to this concept combination , by 1 . For example , the array index for the above concept combination is ( 1 ,l ,1,3 ) . If the value of this entry is equal to zero before the increment , we should increment the counter U by 1 and check if the counter U is greater than the threshold value g , if U > g then we should retrieve the next level vector and start the next generalization and reset the counter U to 0 . If the counter is not greater than g , we then increment that entry of VoteArray and process the next tuple .
In
The remaining tuples of the Path relation are processed and VoteArray is incremented accordingly . After all the tuples of the Path relation is processed and if the counter U is still not greater than the threshold value g , we can form the final relation S . For each entry of VoteArray not equal to zero , we can find the tuple of concepts that the entry represents .
For the method using VoteList , we can keep a similar counter U , which counts the number of elements in the list . Similarly , the value of U is bounded by g and hence the size of VoteList is also bounded by g . fact , we can cut down on the computational complexity of the above : we notice that when we need to start the next generalization ( as the counter is greater than g ) , we don’t have to process the tuples in the Path relation which have been processed in previous generalizations again , This is because VoteArray or VoteList has stored the concept combinations and votes which these tuples generalize to . We can propagate the value of VoteArray or VoteList to the next generalization by using the concept tree table and then process the remaining tuples of the Path relation which have not been processed before . Hence , each tuple of the Path relation will be processed only once in the entire process in order to get the final relation .
The product of qil , q12 , q13 , q14 is 2~2x2~4 = 32 . We may use a multi dimensional array VoteArray[l2 ] [ 12][ 12][ 14 ] , of size 32 , to store the information during generalization .
Initially , each entry of VoteArray and a counter U is set to zero . Then the tuples of the Path relation is processed one by one . For each tuple T of the Path relation , each attribute ’s path id is generalized to a concept of that attribute . For example , with the tuple
Status path id 1 Sex path id 1 Agepath id 1 GPApath id we can find the corresponding concept of each path id from the path id table , eg we find that Status path id = 1 corresponds to the concept undergraduate , which is Cl 1 . The other path id ’s corresponding concepts are C21 , C31 ,
Top down approach
In viewing that the threshold g is small in general , a top down approach can be used instead of the bottom up approach . Let vt = {0,0 , , 0} , we calculate qt , qt i , . . . by equation ( 1 ) to find the value w such that qw 5 g and qw i > g . Then we begin the process by retrieving vw and forming VoteArray or VoteList accordingly . It is clear that IS,1 I g , but table S , may not be the final relation we want since this may be an over generalized table . We must retrieve the level vector v, 1 and check if the counter U, l is greater than g , if this is the case then S , will be the final relation table we want . Otherwise , we retrieve the level v,.~ and check Uw 2 accordingly , we repeat this procedure until there is an r , where 1 5 r < t 1 , such that U , s g and the counter U 1 > g , then S , will be final relation we want .
Mwang
171
RI : Rz :
2 ; Rs : % : RT : Rs : R9 : RIO : &I :
R12 : R13 :
Note that with the top down approach , we must generalize from the Path relation to the desired level each time . However , the top down approach may need less number of generalization steps than the bottom up approach .
6 . complexity of the algorithm
For the proposed method , we need O(N ) time complexity to transform the initial relation to the Path relation . For the bottom up approach , suppose we use a list to store the votes of the concept combinations at each generalization . ( We can choose to use list at any generalization steps since the size of the VoteList is limited by the threshold g and the height of the B tree is limited by log g . The time complexity of the i th generalization will then be O(log g N ) , which indicates the complexity of processing the tuples of Path relation and inserting them into the list by B tree method . In the worst case , we have to do the generalization for t times , where t is the number of level vectors . Therefore , the time complexity of the algorithm is O(t.log g N ) . We shall use the VoteArray method only if it can give better or similar performance . As stated at the end of the subsection on the Bottom up approach , we can cut down the computational complexity of this algorithm . The complexity will be bounded by O(N.log g + t.g log g ) . Given that t and g are small and independent of N , the complexity is equal to O(N ) . Generally , the generalization relation threshold g is a small value , eg around 50 , we can expect that the VoteList can be stored entirely in the main memory of the computer system , therefore , the number of disk I/O is !!! , where B is the number of tuples in a disk page . This is an improvement in comparison to the algorithm of DBLEARN [ Han , Cai & Cercone 19931 , which requires O(et ) disk I/O as it has to merge tuples in the relation in each generalization step .
NlogN
B
B
7 . Generalization for Rule based attribute oriented approach rule based hierarchy
A for background knowledge representation called Rule Based Concept Graph is proposed in [ Cheung , Fu & Han 19941 . In a rule based concept graph , a concept can be generalized to more than one higher level concept , and rules are used to determine which generalization path should be taken . For example , with the university student database defined above , if the expectation for the graduate student is higher , we may have the set of conditional generalization rules for GPA as in Figure 5 .
172
KDD 95 poor poor average average good
{0.0 l .99} + { 20 249 ) and { Status=graduate ] + { 20 249 ) and { Status=undergraduate ) + { 25 299 ) + { 30 349 ) + { 35 379 ) and { Status=graduate ) + { 35 379 ) and { Status=undergraduate ) + { 38 40 ) + {poor ) + weak {average ) and [ Status=senior or Status=gmduate ) + {average ) and { Status=freshman or Status=sophomore or excellent excellent good
Status=junior ) + strong weak
{good ) 4 {excellent ) + strong strong
Figure 5 Conditional generalization rules for GPA
For example , in R2 of Figure 5 , { Status=graduate} is a condition for generalizing the concept of GPA from { 20249} to poor .
Note that for the rule based induction approach , there may be more than one path from a leaf to the root ANY in a concept hierarchy . We have to label each distinct path by a unique path id for each attribute . For example , the paths and their corresponding path ids of GPA may be labelled as follows , ( the paths and path ids of other attributes are the same as before in Figure 3 ) . weak + ANY weak + ANY poor + ( 0.0 l .99 ) + poor + { 20 249 ) + average + { 20 249 ) + average + { 20 249 ) + { 25 299 ) __ ) average + { 25 299 ) + average y { 30 349 ) + good + good + { 35 379 ) + { 35 379 ) + excellent + excellent + { 38 40 ) + path 1 : path 2 : path 3 : path 4 : path 5 : path 6 : path 7 : path 8 : path 9 : path 10 : Once we have labelled the path id of each path in each attribute , we should reformulate the rules by replacing each concept C by a path id list . For example , suppose path 5 , path 6 , and path 7 of Status contain the concept graduate ( see Figure 3 ) , rule R6 will be transformed to strong + ANY strong + ANY weak + strong + weak + strong +
ANY ANY ANY ANY strong + strong +
ANY ANY
Ra’ : { 35 379 ) and { pathjd(Status ) E { 5,6,7} ) + good We call the list {5,6,7} a path id list of the concept graduate . The transformed rule will help us to determine the path id of each attribute in each tuple . there are cycles of dependency . We make
From R2 in Figure 5 , we see that the generalization on the attribute GPA depends on the value of attribute Status . We say that GPA depends on Status . Problems may arise if the assumption that with the given set of rules , if attribute Al depends on attribute AZ , attribute A2 will not depend on Al , and there does not exists a sequence of attributes { B1 , * , B,} such that Al depends on B1 , B1 depends on B2 , . . . . Brml depends on B , , and B , depends on Al . This property ensure that no cycle of dependency can occur .
We can build a causal relation diagram for the generalization according to the rules . For the set of rules in Figure 3 generalization rules such as {M,F} + could build the following causal relation diagram other unconditional ANY(Sex ) , we together with status level 0 t level 1 t level 2 >c
Sex level 0
1‘
1‘ level 1 level 2
Age level 0 t level 1
GPA level 0 t t t level 1 level 2 level 3
Form the causal relation diagram , the generalization in attribute GPA depends on the condition of the attribute Status as there are arrows from Status to GPA . With this casual diagram , and by the assumption that there is no cycle of dependency , we can find at least one dependency of attributes [ A,(l ) , AP(~ ) , . . . . A,,, ) ] which ordering satisfies the following property , ( Pl ) appear in the order list before Ai .
If generalization of Ai depends on Aj , Aj will in id list
From the above causal relation diagram , the list [ Sex , Age , Status , GPA ] is one of the ordering of attributes which satisfy the above property .
After we get an ordering of attributes , we can build the Path relation for the entire database as in section 4 . We can use the generalization rules of each concept to transform the initial relation to the Path relation one attribute by one attribute according to the dependency ordering . information of path the
After forming the Path relation , we can perform generalization by the algorithm proposed in section 5 to get the final relation . However , for each generalization step , we have to process all tuples of the Path relation . Note that the Path relation in corporated the information of the concept hierarchy . This eliminates the need of a “ backtracking ” procedure as described in [ Cheung , Fu & Han 19941 and enhances performance . The complexity of this algorithm is O(t log gN ) Given that t and g are small and independent of N , the complexity is equal to O(N ) .
8 . Conclusion
An important application of knowledge discovery is to support co operative query answering [ Motro & Yuan 19901 . With the attribute oriented induction method , it is possible to ask query about high level concepts such as “ what type of undergraduate students have strong GPA ” . This kind of query cannot be answered directly by querying the underlying database since the system does not understand the high level concepts like undergraduate or strong GPA .
In [ Cai , Cercone & Han 1991 , Han , Cai & Cercone 1992 , Han , Cai & Cercone 19931 , an attribute oriented concept tree ascension technique has been proposed . The system DBLEARN applies this technique for knowledge discovering in large database . The performance of the system is good and the time complexity of the algorithm is O(N log N ) , where N is the number of tuples in the initial relation [ Han , Cai & Cercone 19931 . As we find that the structure of the database and the set of generalization rules is static compare to the dynamic change of the data , preprocessing work can be done . In the preprocessing , the path id table is formed . Then we apply an efficient generalization process . We show the generalization threshold and concept hierarchies are small , the time complexity of our algorithm is O(N ) . The amount of disk YO is O(log N ) times less than the original method . that given
A Rule based attribute oriented approach , which is a generalized version of the attribute oriented approach , has been proposed in [ Cheung , Fu & Han 19941 . This rulebased attribute oriented induction method can handle induction on a rule based concept hierarchy . We have shown that the idea of path id is used to derive an efficient generalization algorithm . The costly backtracking in the original algorithm is eliminated and similar improvement in performance is achieved .
References [ U PI
[ 31 r41
[ 51
Fl
E71
181
M
[ lOI
Agrawal , R . 1994 . Tutorial : Data Mining . In Proc . 13th ACM Symp . on Principles of Database Systems . Agrawal , R . ; and Srikant , R . 1994 . Fast Algorithms for Mining Association Rules in Large Databases . In Proc . 20th Intl Conf . , VLDB . Cai , Y . ; Cercone , N . ; and Han , J . 1991 . Attribute oriented induction in relational databases . In G . Piatetsky Shapiro and W . J . Frawley , editors , Knowledge Discovery in Databases , pages 213 228 . AAAUMIT Press . Cheung , D . ; Fu , A . ; and Han , J . 1994 . Knowledge discovery in databases : A rule based attribute oriented approach . In 8 th Intl . Symp . of Methodologies for Intelligent Systems . Faloutsos , C . ; and Lin , K . 1995 . FastMap : A Fast Algorithm for Indexing , Data Mining and Visualization . ACM SIGMOD Intl . Conf . on Management of Data . Frawley , W . J . ; P&et&y Shapiro , G . ; and Matheus , C . J . 1991 . Knowledge discovery in databases : An overview . In G . PiatetskyShapiro and W . J . Frawley , editors , Knowledge Discovery in Databases , pages l 27 . AAAFMIT Press . Han , J . ; Cai , Y . ; and Cercone , N . 1992 . Knowledge discovery in databases : An attribute oriented approach . In Proc . 18th Intl . Conf . , VLDB , pages 547 559 , Canada . Han , J . ; Cai , Y . ; Cercone , N . ; and Y . Huang . 1992 . DBLEARN : A knowledge discovery system for databases . In Proc . 1st Intl . Conf . on Information and Knowledge Management , pages 473 48 1 , Baltimore , Maryland , Nov . Han , J . ; Cai , Y . ; and Cercone . N . 1993 . Data driven discovery of quantitative rules in relational databases . IEEE Trans . Knowledge and Data Engineering , 5:29 40 . Motro , A . ; and Yuan , Q . 1990 . Querying database knowledge . In Proceedings of 1990 ACM SIGMOD Intl . Conf . on Management of Data , pages 173 183 , Atlantic City , NJ . Park , J . ; Chen , M . ; and Yu , P . 1995 . An Effective Hash Based Algorithm for Mining Association Rules . ACM SIGMOD Intl . Conf . on Management of Data . Piatetsky Shapiro , G . ; and Frawley , W . J . 1991 . Knowledge Discovery in Databases . AAAUMIT Press .
[ 111
WI
Hwang
173
