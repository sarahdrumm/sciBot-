From : KDD 95 Proceedings . Copyright Â© 1995 , AAAI ( wwwaaaiorg ) All rights reserved .
Applying a Data Miner to Heterogeneous
Schema Integration
Son Dao Brad Perry Information Sciences Laboratory
Hughes Research Laboratories
Malibu , CA 90265
{son,perry}@islhrlhaccom
Abstract
An application of data mining techniques to heterogeneous database schema integration is introduced . We use attribute oriented induction to mine for characteristic and classification rules about individual attributes from heterogeneous databases . Each mining request is conditioned on a subset of attributes identified as "common" between the multiple databases . We develop a method to compare the rules for two or more attributes ( from different databases ) and use the similarity between the rules as a basis to suggest similarity between attributes . As a result , we use relationships between and among entire sets of attributes from multiple databases to drive the schema integration process . Our initial efforts and prototypes applying data mining to assist schema integration prove promising and , we feel , identify a fruitful application area for data mining research . goywords : schema integration , multi database interrelationships , attribute similarity , data mining , attribute oriented induction .
Introduction
A large organization may have hundreds or even thousands independently developed and autonomous databases . US West reports having 5 terabytes of data managed by 1000 systems , with customer information alone spread across 200 different databases ( Drew et ai . 1993 ) . In such a multidatabase environment , the sharing and exchange of information among the semantically heterogeneous components is often desired . A federated architecture for database systems has been recognized as one of several settings in which we can consider the semantic heterogeneity problem ( Drew et ai . 1993 ) . It is also pointed out in that a key aspect of identifying and semi automatically resolving semantic heterogeneity involves making semantics explicit .
One important problem in identifying and resolving semantic heterogeneity is to determine equivalent attributes between component databases . Research in this field has usually been carried out in pairwise comparing fashion . However , incremental and multiattribute relationships across database boundaries have not been considered , and the semantics behind data is hardly revealed .
There is a new and active research area in database community whose aim is to discover knowledge hidden in huge amounts of data : Data Mining . Useful data patterns are to be discovered that are beyond the structural level . We believe that integration semantics can be naturally expressed via relationships among multidatabase attributes . The incorporation of data mining is a natural techniques to identify these relationships approach and will provide more powerful solutions to the semantic integration problem .
We describe our initial in the difficult mining techniques automated heterogeneous schema integration . paper we analyze how knowledge discovered attribute oriented 1991 ) can be used to assist schema integration . efforts for exploiting data problem of semiIn this through induction
( Cai , Cercone , &Han
Background relies on to compare attribute then complete , automated integration
A framework for schema integration involves identifying a representation basis , inter database relationships , and schema conforming/restructuring rules ( Batini , Lenzerini , ~z Navathe 1986 ) . If we can idenfrom heterogeneous databases as tify all attributes being {equivalent , superclass , subclass , sibling , or incompatible} can occur . Thus , one method of integration identifying semantic relationships between attributes . names ( Hayne One approach is & Ram 1990 ) and determine degrees of similarity from a lexicon of synonyms . Another approach is to compare structural information , or meta data , ( Navathe & Buneman 1986 ; Larson , Navathe , & Elmasri 1989 ) ; although no solid theoretical foundation yet exists to compute degrees of similarity from meta data . Comparing data at the content level is also employed by ussuch as mean , variance , and coefficient of ing statistics variance for individual attributes ( Li & Clifton 1994 ) . In all approaches , attributes are compared in a pairwise fashion , at best , to decide their equivalence . Relationships between and among entire classes of attributes from multiple databases have not been utilized .
Dao
63
Data mining is defined as "the nontrivial extraction of implicit , previous unknown , and potentially useful information from data" ( Piatetsky Shapiro & Frawley 1991 ) . Various techniques for data mining have been suggested : each using a specialized set of input requirements and producing a specialized form of knowledge . To apply data mining to schema integration requires identifying a specific class of mining techniques and then exploiting the knowledge generated .
General Architecture
Figure 1 : General Architecture the knowledge based
Applying data mining to schema integration ( figure 1 ) is currently under implementation and experimentation in our Heterogeneous DataBase ( HDB ) prototype ( Dao & Ebeid 1992 ) at Hughes Research Laboratories . SDD is the smart data dictionary process that maintains and services a federated schema to our heterogeneous database environment ( Dao , Keirsey , & et at . 1991 ) . KBSIT is schema tool that exists as one of the services integration the SDD controls to construct and evolve the federated schema . DBMiner is an implementation of the attribute oriented induction process described in ( Cai , Cercone , & Han 1991 ; Fu & Hart 1994 ) . Whenever KBSIT requires knowledge about the relationship between two or more attributes , it constructs a mining request that is sent to DBMiner . DBMiner mines the databases to satisfy the request and returns a set classification rules . KBSIT analyzes these rules , as described herein , and computes a suggested relationship for the attributes of interest . and/or characterization
Data Mining for Schema Integration
Induction
Attribute oriented In ( Cai , Cercone , & Han 1991 ) , an attribute oriented induction method to extract from relational databases is developed . Assuming conceptual hierarchies on instances of attributes , each attribute value of a tuple can be replaced by a higher level concept . In this way , a generalized relation with fewer tuples is produced . This process is repeated until some threshold is reached . The final relation is then transformed into a rules
64
KDD 95 logical formula , or a rule , according to the correspondence between relational tuples and logical formulas ( Gallaire , Minker , & Nicolas 1984 ) . Two kinds of rules can be derived in this approach : characteristic rules and classification rules . to represent
We use h(B bjl{Ai} ) the request to mine for characteristic rules for instance bj of attribute B in relevance to attributes {Ai} . h(B[{Ai} ) represents mining for rules for all instances of B . Similarly l(B = biI{Ai} ) and l(BI{Ai} ) are be used for classification rule requests . Figure 2 outlines the general process performed by induction for learning characteristic attribute oriented rules ( see ( Cai , Cercone , & Han 1991 ) for the complete algorithm ) , where : ( 1 ) An input relation is constructed . ( 2 ) The training data is selected from the input relation ( to learn rules for all graduate students , we select out the Category attribute and keep all tuples ) . ( 3 ) The training data is recursively "compressed" concept hierarchies on attribute tribute instance from the concept hierarchies , tuples are removed from the training relation . is computed . Each tuple final "generalized relation" in the generalized relation represents a logic formula characterizing the tuples in the initial training data . We can translate the generalized relation into logic formula(s ) about the characteristic nature of the training data on the learning criteria ( ie , characteristic rules for graduate student tuples ) : instances . Each atinstance can be replaced by a more abstract then duplicate ( 4 )
V(t).Category(t ) E graduate
( Birth_Place(t ) E Canada A GPA(t ) E excellent ) ( Major(t ) E science A Birth_Place(t ) E foreignA
GPA(t ) E good )
A similar process is performed to learn classification rules from an input relation of positive and negative instances of an initial tuple class .
The generalized relation for characteristic rules covers all positive data and.forms a necessary condition of the target class , where condition(t ) is a formula on attribute values of tuple t : target_attribute(t ) E target_class =~ condition(t )
The generalized relation rules the target class from the contrasting distinguishes class(es ) . The learned rule forms sufficient co ndition of the form : for classification target_attribute(t ) E target_class ~ condition(t ) to Schema Integration
Applicability Our goal is to apply the data mining techniques of ( Cai , Cercone , & Han 1991 ) to the problems of schema integration in our heterogeneous database prototype . We show how both classification and characteristic can be used to guide and suggest relationships attributes . rules among
FrN~ MX
PhD sauh l~x/ ) , MS . c~apsU~ smsl~l~cs
Vk ~Drt ,
NI
LM Monk Wm~
/ /
\
\
O
GTA
X.9 X3
&$ 3.2 hk~ry Vsno~vNO~m ~.brj
Wq
GPA
3J 3.9 3.3 3,4 3.S 3.2
Figure 2 : Attributed oriented
Induction Example of Characteristic
Applicability Rules For attribute B1 from DB1 , we discover a set of characteristic rules CHR1 ( n is the number of instance values for B1 in DBI ) :
CgRn : h(B1 = bnI{Ai} ) CHR~ , : h(B1 = bl,l{Ai} )
For attribute B2 from DB2 , we discover a set of rules CHR2 ( m is the number of instance characteristic values for B2 in DB2 ) :
CHR= , : h(B2 = b2 , l{A,} ) CIIR2= : h(B2 = b==l{A,} )
Any tuple violating rule CHRij cannot participate in the tuple class ( Bi = bij ) . Yet , ifa tuple does satisfy CHRij then we have no information on its participation in tuple class ( Bi = bij ) . To ascertain whether B1 and B2 represent similar attribute semantics , we compare the rules from CHR1 and CHR2 . This is possible because , although B1 and B2 have unknown relationship , we constructed the two characteristic rule sets based on a set of attributes ( {Ai} ) known to be common to the two databases . Comparing a rule CHRtl with a rule CHR21 we find : chr l : CHRli n CHR21 = 0 ( no tuple can satisfy both CHRti and CHR21 ) : we know that bli and b2j cannot be two encodings of the semantically compatible ( equivalent , superclass , subclass ) underlying instance ( regardless of whether bli = b2j ) .
Furthermore , if
V(i , j ) CHRll n CHR2j = {~ then we can assume that B1 is semantically incompatible with B2 . Rules For atApplicability tribute B1 from DB1 , we discover a set of classification rules CLRI : CLRal : I(BI = bnl{Ai} ) CLR~ , : l(B , = bl,l(Ai} ) of Classification
For attribute B2 from DB2 , we discover a set of classification rules CLR~ :
CLR2 ] : l(B2 = b21]{Ai} ) CLR2m : l(B2 = b2,,~I{A,} )
Any tuple satisfying rule CLl~ii must participate in the tuple class ( Bi = bij ) . Yet , if a tuple does not satisfy CLRii then we have no information on its participation in tuple class ( Bi = hi~ ) . To ascertain whether B1 and B2 are representing similar attribute semantics , we compare the rules from CLR1 and CLR2 . Comparing a rule CLR~i with a rule CLR2/we find : clr l : CLRli will also satisfy CLR2i and vice versa ) :
CLRli = CLR2j ( every tuple satisfying
( 1 ) if bli = b2i then these two rules suggest that B~ is equivalent to B2 .
( 2 ) if b~i ~ b2j then B1 is equivalent to B2 only if there is a translation between instances b~i and b2j establishing equivalent semantics using different encodings . clr 2 : CLRIi < CLR2j ( every CLRli also satisfies CLR2j , but not vice versa ) : ( 1 ) if bli = b2i then these two rules suggest that tuple satisfying is a subclass of B~ .
( 2 ) if b~i 7~ b2i then B1 is a subclass of B2 only if there is a translation M between b~i and b2j such that M(bli ) < M(b2i ) ( ie , the translation of b~j is equivalent to or a superclass of the translation of bli ) . tuples satis tuple satisfying clr 3 : CLR~i > CLR2i ( every CLR2i also satisfies CLRli , but not vice versa ) : this is the duM case of clr 2 . clr 4:CLR~iACLR21 ~ 0 ( there exists fying a subset of the conditions of CLRIi and CLR21 but not completely satisfying both ) : This "weak" correspondence that B1 and B2 may be sibling concepts of some common , yet unknown , superconcept . We use the term "weak" because this correspondence provides nothing more than a casual suggestion that must be further verified before integration could take place using it . clr 5 : CLR~i n CLR2j = 0 & bli = b2j ( there no correspondence between the classification is rules suggests
Dao
65 reprethe outcome from comparing rules CHRli and on equal instance values bli and b2j ) : B1 can be in a positive relationship ( equivalent , subclass , superclass ) with B2 only if there is a translation for the instances of B1 and B2 into a compatible encoding . Deriving the Suggested Relationship We need to combine the comparisons of rules in CHR into a single integration conclusion . We form a table chrTBL of dimension n Ã m where entry chrTBL(i,j ) sents CHR2j . Finally , a series of reductions/manipulations are performed to generate a single integration suggestion , termed H(B1/B2I{Ai} ) . H(B1/B2I{Ai} ) will be one of ( inc , eq_inc , null , O ) , where : inc says ( B1 incompatible with B2 ) ; eq_inc says ( B1 and B2 do not use equivalent encodings to represent attribute instances ) ; null says no consistent reduction exists ; and O says that {Ai} did not provide enough relevance to mine attributes B1 and B2 .
The reduction of chrTBL to H(B1/B2I{Ai} ) is acIf every entry in the tually quite straight forward . table is 0 ( ie , upholds relationship chr 1 ) , then reduce to conclusion inc . If every entry on the diagonal of chrTBL is 0 , then we reduce to conclusion eq_inc . If some elements of chrTBL are 0 and others are not , then we reduce to null . Otherwise , there was not enough information to draw a conclusion about the two attributes .
Similarly we combine the comparisons of rules in CLR into a table clrTBL and then a single integration conclusion , termed L(B1/B21{Ai} ) . L(B1/B21{Ai} ) will be one of ( eq , sup , sub , sibl , null , 0 ) , where : eq says ( B1 equivalent with B2 ) ; sup says ( B1 a superclass of B2 ) ; sub says ( B1 a subclass of B2 ) ; sibl says ( B1 sibling with B2 ) ; null says no consistent reduction exists ; and 0 says that {Ai} did not provide enough relevance to mine attributes B1 and B2 . The reduction of clrTBL is more involved than that for chrTBL ; but we perform the following basic algorithm1 : ( 1 ) if outcome = ( ie , clr 1 ) exists at least once in every row and column of clrTBL , then we suggest eq as the relationship ; ( 2 ) if outcomes = or < occur at least once in every row and column , then we suggest subclass as the relationship ; ( 3 ) if outcomes = or > occur at least once in every row column , then we suggest superclass ; ( 4 ) if both ( 2 ) and ( 3 ) hold , then we suggest null ; ( 5 ) if outcomes = , sibl , < , or > occur at least once in every row and column , then we suggest sibling ; and ( 6 ) if none of ( 1) (5 ) hold , we suggest 0 as the relationship . If we are only concerned about the discovering the relationship when B1/B2 are using the same instance encodings , then the above reduction still holds but the "every row and column" must be the diagonal elements of clrTBL .
1The full paper ( Dao & Perry 1995 ) contains details on the reduction of chrTBL and clrTBL to a single suggestion .
66 KDD 95
Summary
Data Mining Attribute oriented induction has been presented as a tool to discover attribute relationships for schema integration . For our scenario , the integration engine is the application using attributed oriented induction ( eg , requesting discovery knowledge from DBMiner ) and responsible for generating mining requests ( h(Bl{Ai} ) or l(B[{Ai}) ) . KBSIT instructs DBMiner to learn classification and characteristic rules for data instances from heterogeneous databases . The of two attributes rules can then be compared to arrive at a singular suggestion , H(B1/B2 I{A,} ) or L(Bz/B2 I{Ai} ) , for the integration from two databases . relationship between attributes schemas based on correspondences between from the heterogeneous schemas . At any
Schema Integration with Data Mining KBSIT operates as an autonomous server to integrate relational attributes point during its processing , KBSIT will have : ( 1 ) correknowledge base of attribute relationships ( ie , spondences ) identified between two or more database schemas ; and ( 2 ) an integrated representation of those relations rendered comparable by the knowledge base . When KBSIT reaches an impasse , where it cannot determine the relationship between two heterogeneous atit must use its current knowledge base to detributes , rive data mining requests for DBMiner . From these requests , KBSIT can reduce the discovered rules to a common suggestion about semantic correspondence . Figure 3 summarizes this flow between KBSIT and DBMiner . information derived attribute
KBSIT~ ,~ â
Common
CA ) IK._~Atlxs ( rulesâ~,,~[_
~ In r~elevance to
_ ~,.,â~ a subset of CA
Figure 3 : Schema Integration/Data Mining Loop
State
Schema Integration In order to understand how KBSIT generates requests to DBMiner , we will examine a "snapshot" of its integration processing . At any given point , KBSIT has a current set of federated attributes that represent those that have been unified into local database attributes common semantic structures this set CA ) . Now , should KBSIT be at a point where it has insufficient knowledge to unify attributes Bz ( from DB1 ) and B2
( label
A more positive way to examine the state of KBSIT from CA properly determine the relation
( from DB2 ) , it must generate a mining request based on CA to learn about B1/B2 . In the naive case , we submit the request L(B1/BzlCA ) to learn based on the common attributes we have identified 2 . Unall fortunately , it may be the case that a subset of the attributes ship between B1/B2 ; yet , when conditioned on all data from CA , DBMiner becomes inundated with meaningless data correlations and derives incorrect , null , or over qualified rules . Thus , the data that B1/B2 is considered in relevance to is critical in the successful discovery of proper integration relationships . is to consider the power set of CA and the 2n subsets it represents . Ideally , we would like submit requests L(B1/B21S ) for each set S in the power set of CA and gather , from DBMiner , the B1/B2 relationships for every possible relevance subset . Our task would then be to determine which relationship ( from the power set requests ) to use as the suggestion for B1/B2 . We reduce to a single suggestion adhering to the following prejudices : Â¯ We favor the discovery of a strong relationship over weaker relationships . If the data miner is able to recover eq as an implicit attribute relationship based on some relevance set , then we are inclined to use it over other suggestions ( similarly for sup or sub over sibl ) .
Â¯ We favor few attribute correlations over complex , suggestions . This prejudice taints many attribute that are the mining process to prefer suggestions smaller derived from fewer relevant attributes ( ie , relevance clauses ) we use this assumption to guide the mining/integration algorithm to seek fundamental/primary relationships over spurious and artifactual coincidences .
Process
DBMiner Control Computing mining requests based on the power set of CA is , of course , not computationally practical . We must devise a control process in KBSIT that generates requests to DBMiner that approaches the ideal scenario .
We define an ordering and comparison function on computed for any two attributes the relationships BI/B2 as : eq > sup > sibl eq > sub > sibl sibl > null > O sup Â¢ sub compare(r1 , r2 ) = positive if ra > r2 , else negative We begin mining for a relationships between B1/B2 by computing L(B1/B21{Ai} ) for each common attribute Ai E CA . Then , for a specific L(B1/B2]{Aj} ) , we compute L(Bx/B2I{Ai,Ak}).k
Â¢ fo r al l k E
2This section holds equally for H(Bx/B2ICA ) , we use only L(Ba/B2ICA ) to minimize confusion and assume the parallel reading with H substituted for L .
L(B1/B21{Aj,Ak} ) to L(B1/B21{Aj,Ak,Ap}).j
{1]CAI} Any particular that does not compare as positive with L(B1/B21{Aj} ) marks the end of the "search" down this branch . For all positive steps , we then make a next step from L(B1/B2[{Aj,Ak} ) k # p and apply the same "positive comparison" criteria for stopping or continuing search down this branch . Once we have exhausted the search from Aj , we compute the overall suggested relationship to be the most positive relationship in the search tree . This process is repeated beginning from every attribute Ai E CA . The final suggested relationship for B1/B2 is then the most positive relationship among the set of Ai search trees . KBSIT can add this relationship and attributes BI/B2 to its set of common attributes . to its knowledge base
Note that in the worst case this search is still the power set evaluation ; but , in our experiments , we have found that the search tree is terminated fairly quickly and relationships are determined after minimal search iterations . Nevertheless , the control loop presented should be augmented to work in a breadth first fashion and/or perform a cutoff when the relevance sets grow too large .
Integration
Analysis
In this section we summarize the analyses and lessons learned from applying the techniques presented herein to actual heterogeneous database environments . There are four general analyses that should be presented to judge the scope , applicability , and future directions of our current data mining for schema integration . Analysis 1 : The current algorithms use instancelevel mining and comparison for relationship discovery . We have found that this process performs well for finite and discrete domains ( ie , Birth_Place or Diagnosed_Disease ) . Yet , the algorithms are too focused on individual instances to capture general relationships in continuous valued domains . We feel that intelligent pre clustering techniques , applied to the attributes in isolation , may generate a discretized domain readily applicable to our mining/integration techniques . Analysis 2 : Attributes translations handled . Our mining and rule composition algorithms properly identify the need for translations for relationships to is often occur . Yet , how to suggest such translations extremely domain specific . We have some initial techniques that use the knowledge mined to suggest translations , but this area needs more work to be acceptable in general schema integration servers . Analysis 3 : We currently compare all conditions from the mined rules to suggest relationships . We are working on techniques to use only those conditions that represent a high degree of coverage of the data instances . The motivation being that if one database has the only occurrences of an infrequently occurring attribute value , we do not want this value to adversely affect to unify are not satisfactorily instance level that require
Dao
67 it generate the mining results . in the rule comparison/reduction
The attribute oriented to discover algorithms . and control minto DBMiner in a heuristic manner that in degenerate cases . Clearly we need in or distort induction process we are using rules can compute this coverage for us , we need to define how to exploit Analysis 4 : We currently ing requests is non tractable to incorporate ( Agrawal & Srikant tractable ertheless , satisfactorily case studies . and optimized manner for all cases . Nevour heuristic control algorithm has behaved for a number of heterogeneous database such as those developed to control DBMiner in algorithms
1994 )
None of the above analyses proach described herein . or direction , general purpose required identify flaws in the apInstead , each outlines a task , to extend the approach to a more schema integration engine .
Conclusion
Our schema integration/data has been tested on actual heterogeneous databases and the to auresults prove promising that our approach leads tomated discovery of integration based on multi database correspondences mining prototype relationships ( Dao & Perry 1995 ) . the problems and partial area of semantic level heteroSpecifically , we addressed
In this paper we discussed to the difficult solutions geneous schema integration . the following points : Â¯ How to compare and combine knowledge discovered by attributed oriented cone , & Han 1991 ) , applied to gain attributes from heterogeneous insight inductive mining ( Cai , Cer to multiple databases , on the semantic correspondence of schemas .
Â¯ How to generate , and heuristic manthe mining in relevance to clauses from the cur in a controlled ner , rent set of common attributes .
Â¯ How to combine the pieces schema integration trolled rithm . into a unified and conwith data mining algo a new field
Â¯ The architecture of our prolotype system . The ideas and algorithms described herein have been validated in our prototype system ( figure 1 ) . We have outlined for applying data minproblem of database extensively ing technology and enhancing the difficult schema generation/maintenance systems . We are currently with the attribute oriented acknowledge that ing effort of various semi automated it will most likely schema integration experimenting data mining technique , but take a parallel minthe level of in federated techniques to attain we seek . testing the prototype
Our future plans further begun to see the results lationships validate our initial two goals in this new technology direction . include completing , enhancing , and system . We have only reto results . For the long term , we have First , we of mining for integration and need to do more experimentation
68 KDD 95 such that techniques as services is not dependent but uses a set of are building our prototype on any one data mining technique , available process . Second , we plan to investigate methods to exgenerated by data ploit miners , to suggest scaling , mapping , etc . ) between attranslations tributes integration to occur . coupled with domain knowledge , to aid the integration the instance level relationships for specific constraints
( ie ,
References rules .
In Proc . 2Oth VLDB . in Multidatabase Systems .
Agrawal , R . , and Srikant , R . 1994 . Fast algorithms for mining association Batini , C . ; Lenzerini , M . ; and Navathe , S . 1986 . A comparative analysis of methodologies for database schema integration . Computing Surveys 18(4 ) . Cai , Y . ; Cercone , N . ; and Han , J . 1991 . Attributeoriented induction in relational databases . In PiatetskyShapiro , G . , and Frawley , W . , eds . , Knowledge Discovery in Databases . AAAI Press . 213 228 . Dao , S . , and Ebeid , N . 1992 . Interoperability of heterogeneous information management systems : a federated approach . Technical Report 585 , Hughes Research Laboratories . Dao , S . , and Perry , B . 1995 . Data mining for semantic schema integration : Extended report . Technical report , Hughes Research Laboratories . Dao , S . ; Keirsey , D . ; and et al . , R . W . 1991 . Smart data dictionary : a knowledge object oriented approach for interoperability of heterogeneous information management systems . In Proc . 1st International Workshop on Interoperability Drew , P . ; King , R . ; McLeod , D . ; Rusinkiewicz , M . ; and Silberschatz , A . 1993 . Report of the workshop on semantic heterogeneity and interoperation in multidatabase systems . SIGMOD Record 22(3 ) . Fu , Y . , and Han , J . 1994 . DBMiner user âs guide . Technical report , School of Computing Science , Simon Fraser University . Gallaire , H . ; Minker , J . ; and Nicolas , and databases : A deductive Survey 16(2 ) . Hayne , S . , and Ram , S . 1990 . Multiuser view integration system ( muvis ) : An expert system for view integration . Proc . 6th International Conference on Data Engineering . Larson , J . ; Navathe , S . ; and Elmasri , R . 1989 . A theory of attribute equivalence in database with application to schema integration . IEEE Transactions on Software Engineering 15(4 ) . Li , W . , and Clifton , C . 1994 . Semantic integration in heterogeneous databases using neural network . In Proc . 20th VLDB . Navathe , S . , and Buneman , P . 1986 . Integrating views in database design . Computers 19(1 ) . Piatetsky Shapiro , G . , and Frawley , W . 1991 . Knowledge discovery in databases . AAAI Press .
J . 1984 . Logic approach . ACM Computing user
