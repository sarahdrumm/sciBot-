From : KDD 95 Proceedings . Copyright © 1995 , AAAI ( wwwaaaiorg ) All rights reserved .
Automated Proteins
Discovery from Amino acid of Functional
Rough Sets and Change of Representation
Components of sequences based on
Shusaku Tsumoto and Hiroshi Tanaka
Department of Information Medicine , Medical Research Institute
Tokyo Medical and Dental University l 5 45 Yushima , Bunkyo ku Tokyo 113 Japan
TEL : +81 3 3813 6111(6159 ) FAX : +81 3 5684 3618
Email:{tsumoto , tanaka}Oquasartmdacjp
Abstract
Although the problems important structure analysis from DNA sequences is an Protein important and fast growing area in both computeT interesting apscience and biochemistry . proaches have been studied , it is very dificult to capture the characteristics of protein , since even a simple protein are made of more than 100 amino acids , which makes biochemical experiments very dificult to detect functional components . For this reason , almost in this field are left unsolved and it all to develop a system which assists is very researchers on molecular biology to remove the dificulties caused by combinatorial explosions . In this paper we report a system , called MWI biologists’ Workbench version l.O ) , which extracts knowledge from amino acid sequences by controlling application of domain knowledge automatically . We apply this method to comparative analysis of lysozyme and LXlactalbumin . The results show that we obtain several from amino acid sequences , which interesting have not been reported before .
( Molecular results
1 . Introduction
Protein structure analysis from DNA sequences is an important and fast growing area in both computer science and biochemistry . Although interesting approaches have been studied , it is very difficult to capture the characteristics of proteins , because even a simple protein has a complex combinatorial structure . For example , let us consider a very small protein made of an one hundred amino acid sequence ( most of the proteins have larger than three hundred sequences ) . Then , there are 201°0 N 2*O ” kinds of possibilities , because each component of its sequence can take one value from 20 kinds of amino acids . Thus , it is hard to estimate possible structure or chemical properties of proteins from these sequences . What makes the matters worse is that we have only iittie knowiedge about possibie function and structure of proteins .
For this reason , almost all the problems in this field are left unsolved because of the above intractable nature caused by complex structure , and it is very important to develop a system which assists researchers on molecular biology to remove the difficulties caused by
318
KDD 95 combinatorial explosions ( Hunter 1993 ) . For this purpose , we can introduce a rule induction method , such as AQ15 ( Michalski et aZ . 1986 ) and ID3 ( Quinlan 1986 ) . However , applications of such machine learning methods only induce classification rules , which are not sufficient to analyze the functional differences . Therefore we also need to introduce a mechanism which controls the application of domain knowledge in order to analyze the characteristics of induced results and to extract as much information as oossible from databases . In order to incorporate the above control strategy into machine learning methods , we develop a system , called MWl ( Molecular biologists’ Workbench version 1.0 ) ) which extracts knowledge from amino acid sequences by controlling application of domain knowledge automatically .
r m
MWl consists of the following five procedures . First , it exhaustively induces all the classification rules from databases of amino acid sequences . Second , MWl changes representation of amino acid sequences with respect to the main chemical features Then , third , all the rules are induced from each transformed database . Next , the program estimates the secondary structure of amino acid sequences via Chou Fasman method ( Chou and Fasman 1974 ) . Finally , fifth , MWl induces all the rules from the databases of secondary structure . fourth ,
This method is applied to comparative analysis of lysozyme and a lactalbumin , and the results show that several interesting results are obtained from aminoacid sequences , which has not been reported before . Based on these new discovered knowledge , several experiments are being planned in order to validate discovered results . Interestingly enough , some of them are recently confirmed by biochemical experiments(Tsumoto,K . 1994 ) . The evaluation of other re,lL , 111 L _ A. , .I LL L 1 : A. 211 5~165 WILI oe reporbea WIIBII GKIC : w1101e exper~~~~erlbs : WII~ have been completed .
The paper is organized as follows : Section 2 gives a brief description about our domain : comparative analysis of lysozyme Section 3 gives discussion on problems on application of empirical learning methods to sequential analysis . Section
IIc and cx lactalbumin .
Table 1 : Primary ( Amino acid ) Sequences
Protein CY
Lactalbumin
Lysozyme
Sequence KQFTKCELSQLLKB@DIDGYGGIALPELIC
TMFIiTSGYDTQAIVEN@QNESTEYGLFQIS
NKLWCKSSQVPQSRNICDISCDKFLDDDIT DDIMCAKKILODIKGIDYWLAHKALCTEKL
EOQWL@@CEKLO
KVFERCELARTLKRLGMDGYRGISLANWMC LAKWESGYNTRATNYNAGDRSTDYGIFQIN
SRYWCNDGKTPGAVNACHLSCSALLQDNIA _1=1~ “ __,lln__h ” ~_ UtlYk%btlRnY v n ” r~ “ lnrrr ”
1,,*~ln,m ” ~.v~~ “ nvrnnn~bpn ” contributions to molecular biology and computational biology . First , as to molecular biology , the analysis will make it clear what kind of knowledge biological systems acquired through the evolution from birds to mammals . Second , as to computational biology , the analysis will make it clear what kind of mechanisms is useful to analyze the sequences of similar proteins .
3 . Problems of Empirical
Learning
Mtathnrlp *.lv ” .LvuY
VRQYVQGCQ@GV
,I
, , Q denotes “ gap ” regions after processing multiple alignment procedure .
4 presents the discovery strategy of MWl and how it works . Section 5 shows the results of application of this system to comparative analysis of lysozyme IIc and a lactalbumin . Section 6 compares our method with related work . Finally , Section 7 concludes this paper .
2 . Lysozyme and a Lactalbumin
Lysozyme IIc is a enzyme which dissolves the bacterial walls and suppress the growth of bacteria . All living things have this kind of enzyme , and especially , in the category of vertebrate animals , such as fishes , birds , and monkeys , the sequences are almost preserved .
On the other hand , a lactalbumin functions as a coenzyme of one reaction which dissolves the chemicals in milk into those easy for babies to take nutrition . So this enzyme only exists in the mammals , such as monkeys , and the marsupials , such as kangaroos . from
The comparative analysis of these two proteins is one of the most interesting subjects in molecular biology because of the following two reasons ( McKenzie and White 1991 ) . First , cr lactalbumin are thought to be originated lysozyme IIc , since both of the sequences are very similar ( Table 1 ) . According to the results of homological search , about 60 % of the sequences of a lactalbumin matches with those of 1 _ .LI L __ L LL 1 LL ^ l AL ^ ^ 2 rysozyme , wnicn suggests 6na~ cney are 01 LII~ same OKIgin I . the global threedimensional structure of these two proteins are almost the same . Second , it is not well known what kinds of sequences mainly contributes to the functions of both enzymes , although many experiments suggests that interactions of several components play an important role in those functions .
In addition to this similarity , lIn this methodology , a amino acid sequence of a protein of one species , such as cytochrome c of the mammals , only matches with only 25 % of sequences of different species , L _ L L _ I AL *:I sucn as r;yL ” ulr ” IIK! c “ I LIE rapLwza .
It is easy to see that simple application of machine learning methods to DNA or amino acid sequences without using domain specific knowledge cannot induce enough knowledge .
For example , simple application of induction of decision trees ( Breiman et al . 1984 ; Quinlan 1986 ) generates only one rule from many possible rules . However , many attributes ( exactly , 52 attributes ) have the maximum value of information gain . Thus , we have to choose one of such attributes . If simplicity is preferred , th.t nf lewna hn m;nim;nml “ Ilcv ” ,Y’~~‘&‘A~YUU ) “ A 1~W.V ” vu then location 44 will be selected as shown below . ia nmmhnr ‘ “ 1 AL “ ALL . 1LUYL ” “ L chnmlrl “ zA ” UIU thn if
44 = N 44=F/
. lysozyme . . . o Eactalbumin
a (45cases ) ( 23cases )
In this case , we get a simple tree , which consists of one node and two leaves . Unfortunately , this result is not enough , since our objective is not to find a simple rule for classification , but to find as much information as possible .
However , exhaustive induction of possible rules also cause another problem : it is very difficult to interpret all the possible rules without using domain knowledge . Hence it is very crucial to control application of domain knowledge , according to what problem we want to solve . If we need only some evidential knowledge , we should strictly apply domain knowledge , and focus only on several attributes of training samples . These cognitive aspects of machine discovery system are discussed by researchers on machine discovery ( Zytkow 1992 ) .
In order to implement discovery strategy of molecular biologists , we develop a system , called MWl ( Molecular biologists’ Workbench version l.O ) , which extracts knowledge from amino acid sequences by controlling application of domain knowledge automatically .
MWl consists of the following six procedures . First , it applies PRIMEROSEEX , discussed in the next subsection , and exhaustively induces all the classification rules from databases of amino acid sequences . Second , MWl changes representation of amino acid seIT"an qulzuLc5"
+ ax+ran Lcia.llULGju nh~m:n"l bLIcx,,~LaL
wnrrnn+ Lr;up~L"
. . +1 Wlbll mT:r Ulcwl ,
CL , CUG
+rr II"
Tsumoto
319 li’Y fDs h l:l:,+ : , \’
I ” “ c& “ IIIDCIL
D , , ILUlt : nr\ll, .A LaIIcxl
Structure
DDTXZli’DACE’ I lLIIvIuIc ” L)u uA
Rearrange fifth , MWl
Rearrangement ) . of amino acids , such as the characteristics of electronic charge ( ie , basic , neutral , or acidic ) ( PriThat is , MWl mary Structure generates new databases focused on a certain chemical property from original databases . Then , third , PRIMEROSEEX is applied again , all the rules are induced from each database generated by the second procedure . Furthermore , the statistics of each chemical characteristic are calculated . Next , fourth , the program estimates the secondary structure of aminoacid sequences using Chou Fasman method ( Chou and Fasman 1974 ) ( S econdary ment ) . Finally , induces all the rules from the databases of secondary structure , applying PRIMEROSEEX . 4.1 PRIMEROSE EX In order to induce rule exhaustively , we introduce a rnnrnp,r ” glallL , Induction Method based on Rough Sets for Exhaustive induction ) . This method is based on rough set theory , which gives a mathematical approach to the reduction of decision tables , corresponding to the exhaustive search for possible rules . For the limitation of the space , we only discuss the definition of probabilistic rules of PRIMEROSE EX and an induction algorithm of this system . Readers , who would like to know further information on rough sets , could refer to ( Pawlak 1991 ; Ziarko 1991 ; Ziarko 1994 ) . Ruies of PRIIvIERCSE EX . in the framework of rough set theory , we have several specific notations as follows . First , a combination of attribute value pairs , corresponding to a complex in AQ terminology , is deFor example , noted by an equivalence relation R . [ u = l]&[b = l ] will b e one equivalence relation , denoted by R = [ a = l]&[b = 11 . Second , a set of samples which satisfies R is denoted by [ & , corresponding to a star in AQ terminology . For example , when {1,2,3} is a set of samples which satisfy R , [ E]R is equal to {1,2,3 ) 2 . Finally , third , U , which stands for “ Universe ” ? denotes the whole training samples . According to this notation , probabilistic rules are defined as follows : Definition equivalence belong to a class d , or positive examples training ing samples which satisfies an equivalence let IDI d enote the cardinality of D , Finally , total number of samples in D .
Let R , be an 1 ( Probabilistic relation , D denote a set whose elements the whole samples , U , and [ x]~ , denote the set of trainrelation Ri . that is , the
Rules ) in
A probabilistic rule of D
< R a2P d,a , ~,p > , where R a3P d satisfies following proposition : is defined as a quadruple , the
R a3P d st
[ x]~ n D # 4 ,
21n this notation , “ 1 ” denotes the first(lst ) dataset . sample in a
320
KDD 95 where ( Y and n are defined as :
~= wd m I[xlRI and
’
K = IbiRm
PI
’ and where p is a p value of x2 statistics when the relation between [ x]~ , D , and U is tested as a contingency +l1 , ‘UVK . ci The intuitive meaning of the above three variables , CY , K , and p value is given as follows . First , ( Y corresponds to the accuracy measure . For example , if Q of a rule is equal to 0.9 , then the accuracy is also equal to 09 Second , K is a statistical measure of how proportion of D is covered by this rule , that is , coverage or true positive rate . For example , when IE is equal to 0.5 , half of the members of a class belongs to the set whose members satisfy that equivalence relation . Finally , third , pvalue denotes the statistical reliability of a rule R a3P d . For example , when p is equai to 0.95 , the reiiabiiity of the rule is 95 % .
As to the calculation of p value , we view the relation between [ x]~ , D , and U as a contingency table as shown in the following table .
Total s+t u+v s+t+u+v(=n )
Total s+u t+v
In the above table , TR and yd denotes the negation of R and d ; respectively . Note that each items in the table can be described in the framework of rough set theory , is , s , t , u , v can be described as ][x]R n Dl(= that $1 , I[+ n ( u D>l(= t> , ID [ X]R n Dl(= u> , and It is ](U D ) also notable that s + t = ][x]n ] , s + u = IDI , and s+t+u+v=IUI .
[ x]~ n ( V D)l(= v ) , respectively .
From the above table , x2 statistics can be calculated
ZlS : n(sv tu)Z x2 = ( 3 + u)(t + v)(s + t)(u + v)’ where n> s! tt u!v is given in the above table . This statistics is a test staGstics to check whether R is independent of d . In other words , it indicates whether R is not useful for classification of d or not . From the value of this statistics , pvalue is calculated from where this value is located in the x2 distribution . For example , when the p value of x2 statistics ~0 is equal to 0.99 , the region whose x2 statistics is below ~0 occupies 99 % of the whole distribution . Thus , the probability with which this event will occur is 99 % .
According to those values , we classify the induced probabilistic rules into the following four categories :
( 1 ) Definite Rules : cr = 1.0 and K = 1.0 , ( 2 ) Significant Rules : 0.5 < Q : < 1.0 and 0.9 I p < 1.0 ( 3 ) Strong Rules : 0.5 < CLI < 1.0 and 0.5 < p < 0.9 , ( 4 ) Weak Rules : cr > 0 . for PRIMEROSE EX .
Let D deAn algorithm note training samples of the target class d , or positive examples . In the following algorithm , we provide two kinds of specific sets . The one is Li , which denotes a set of equivaience reiations whose size of attributevalue pairs is equal to i 1 . For example , L3 includes [ a = l]&[b = 11 , whereas Lz includes [ a = l ] and [ b = 11 . The other is Mi , which denotes a set of equivalence relations for weak rules . For example , when Ms includes a [ u = l]&[b = 11 , the accuracy of [ u = l]&[b = l ] as to the target concept is lower than 0.5 or the pvalue of x2 statistics as to the target concept is lower than 05 Thus , an equivalence relation in iV& is weak for classification or do not cover enough training samples .
( 3 ) nn thew . nntatinns .
( 2 )
L C d&l L , 1__ L _ _ = Rn.sd the search orocedure can be described as a kind of the greedy algorithm in the following . ( 1 )
Let LO be equal to a set of all the attribute value pairs [ a , = vj](selectors in terms of AQ method ) and i be equal to 0 . Set A& to ( 1 , an empty list . Repeat the following three procedures for all the members in a list L , until Li is empty . If L , is empty , got0 ( 7 ) . Select one pair R = A[Q = v3 ] and check whether [ x]nrlD # #(CX > 0 ) . If so , then goto ( 4 ) . Otherwise , remove the pair from Li , and repeat this procedure again . Check whether ( Y > 05 If so , then goto ( 5 ) . Otherwise , include the pair in a list of weak rules of d , and add this pair to Mi and goto ( 2 ) . If cy = 1.0 and K = 1.0 , then save this pair as a definite rule of d . Remove the pair from L , and goto ( 2 ) . Otherwise , goto ( 6 ) . If p > 0.9 , register this pair as a Check the pvalue . significant rule of d . Remove the pair from Li and g&n ( 2 ) . this pair as a strong rule of d . Remove the pair from L , and goto ( 2 ) . Otherwise , include the pair in a list of weak rules of d , and add this pair to A& and goto ( 2 ) . If Mi is empty , quit . Otherwise , generate a list of the whole combination of the conjunction formulae in Mi as Li+l . Then increment i(i:=i+l ) , goto ( 2 ) . The above procedure is repeated for all the attributevalue pairs . It is notable that the above algorithm is very similar to discovery of association rules developed by Mannila et al . ( Mannila et a11994 ) We will discuss thn rnmnaricnn “ &AU ~ “ ~L’yw~‘ “ “ ”
If p > 0,5 , rqjster nf vI yA.vI “ , , twn m&,hnd! : __ , ” _ I in ‘b +inn L l thraae
( 7 )
_ fj . .
( 4 )
( 5 )
( 6 )
In the above algorithm , equivalence relations for significant rules and strong rules in L , are removed from candidates for generation of Lz+l , because they are not included in Mi . Thus , if significant members of Li are then computational complexity of not included in Mi , is small . However , when significant generation of L,+l members are included in Mi , then the complexity will be very large . This tendency has already been well studied by ( Mannila et al . 1994 ) , although in their approaches the complexity will be large when significant members are not included in n/r , . According to Mannila ’s results , the running time would be linear in the size of training sampies , but exponentiai in the size of M , . We also discuss this issue later in Section 6 . of Representation
4.2 Change We introduce two kinds of change of representation . One is to generate new databases which focus on a certain chemical characteristic from original databases , called primary structure rearrangement . The other one is to transform original databases , according to the estimation of the secondary structure , called secondary structure Primary The most important chemical characteristics of amino acids which are thought to contribute to determine a protein structure are the following : hydrophobicity , polarity or electronic charge of a side chain , the size of an amino acid , and the tendency of an amino acid to locate the interior of proteins . rearrangement . Structure
Rearrangement .
_
[ 33 =
Structure
1 .A? ~
[ hydrophobicity
Rearrangement .
= yes ] or [ hydrophobicity
For example , in the case of hydrophobicity , which denotes how much an amino acid is intimate with water molecule , there are two kinds of attribute value pairs : [ hydrophobicity = no ] 3 . Vsing these notatrons , we can change representation of amino acid sequences . For example , let us consider a case when an attribute value pair of an original database is [ 33 = F ] , which denotes that the 33th amino acid of a protein is F ( phenylalanine ) . Because phenylalanine ( F ) is hydrophobic , this attribute value pair is transformed into : = yes] ] . This procedure is repeated for all the aminoacids in an original sequence . Secondary Next , MWl estimates secondary structure from aminoacid sequences using the C/~LUB ~CLSI~I(L~L III~~IIUU l~lrouFasman 1974 ) , which is the most popular estimation method 4 . This Chou Fasman method outputs the place where specific secondary structures : a! helix , According to this estimation , PMWl changes representation of original databases . For example , the 4th to 10th amino acids are estimated to form an o helix . Based on the above results , the value of each attribute , which is the address of a primary sequence , are replaced by the above knowledge on secondary structure . In the above example , the values of the 4 th to 10th attributes are substituted for o helix , 31n this paper , we only use these qualitative values , although we also have the coefficients of hydrophobicity , which are quantitative values . It would be our future work to deal with quantitative coefficients . 41t is notable that our method is independent of this estimation method . Thus , we can replace the Chow Fasman method with the new methods which may gain more predictive accuracy , when such methods are obtained . sheet , and turn .
Tsumoto
321
Table 2 : Results of Primary Structure Rearrangement
Protein lysozyme c a lact lysozyme c cu lact lysozyme c cr lact lysozyme c a lact
Amino Acid and its Location N 27 E 27 E 35
( A,L 31 )
K 33 F 33
( Y,D 53 )
T 31 N 44 v 44
E 53
W,T 35 ) ( A G 76 ) i 76
( G,D,Q 117 ) s 117
( A,R 107 )
D 107 L 129 E 129 a helix , a helix , a helix , o helix , and a helix . That is ,
Primary Structure
1
Secondary Structure
ERCELA 111111 cr a Q a Q cr .
It is notable that some attributes may have no specific secondary structure . In these cases , the value of these attributes are replaced by one of the four characteristics : {hydrophobic , polar , acidic , basic} , since they play an important role in making secondary structure , as discussed in the section on primary structure rearrangement . For example , let us consider a case when an attribute value pair of an original database is [ 86 = 01 , which denotes that the 86th amino acid of a protein is D ( asparatic acid ) . Because asparatic acid ( D ) is acidic , this attribute value pair is transformed into : [ 86 = acidic ] 5 .
5 . Results and Discussion
We apply MWl to 23 sequences of cr lactalbumin and 45 sequences of lysozyme from PIR databases , both of which are used as original training samples 6 Then , as inputs of MWl , we use the sequences processed by multiple alignment procedures .
The induced results are shown in Table 2 to 4 , where the following three interesting results are obtained 7 . First , Table 2 shows the induced definite rules before change of representation . From the second to sixth columns , alphabets denote amino acids , and the numbers denote the location in the sequence of a protein . % is notable that this information can be retrieved from the database generated in the process of primary structure rearrangement .
‘Readers may say that 68 samples are very small . However , these samples are now all included in Protein databases . As pointed out , most of the datasets collected in genome databases are genes of bacteria , mouse , and other animals which are often used in biochemical experiments . This tendency is one of the difficult problems in genome databases .
7The shown results are mainly rules and significant rules , because including strong and weak rules takes much more space . Thus , due to the limitation of space , we only discuss the results of definite rules and significant rules . induced definite
322
KDD 95
Table 3 : Results of Primary Structure Rearrangement with respect to Hydrophobicity Protein
2 1
4 0
Location 11 9 1 1
33 0
35 0 lysozyme c cr lactalbumin lysozyme c a lactalbumin lysozyme c & lactalbumin lysozyme c cr lactalbumin
0 73 1 0 98 1 0
0 72 1 0 92 0 1
1 45 0 1 88 1 0
7 ” s 1 74 0 44 0 0 1 1 1 0 103 106 83 0 0 1 0 1 1 112 114 115 116 118 123 0 0 1 1 129 1 0
0 1
0 1
0 1
1 0 lysozyme c cr lactalbumin Notations : 1 : yes , and 0 : no .
Table 4 : Results of Secondary Structure Rearrangement
70 77 polar 107 110 a helix
Location
83 94 hydrophobic acidic 113 117 basic hydrophobic hydrophobic
98 104 loop a helix
Protein lysozyme c hydrophobic a lact lysozyme c a lact
For example , N 27 means that the 27th amino acid of lysozyme IIc is N , or aspargine . These results mean that these amino acids are specific to each protein . In other words , the most characteristic regions are expected to be included . Actually , it is known that E 35 , and Y or D 53 are the active site of lysozyme , and also K 33 , N 44 and A or R 107 are said to play an important role in its function ( McKenzie and White 1991 ) . However , N 27 and L 129 are new discovery results , and no observations or experimental results are reported . Thus , these acids may contribute to the function of lysozyme .
Second , Table 3 shows the results of definite and significant rules after change of representation with respect to hydrophobicity . This table shows that the non hydrophobic region of 73 to 92th amino acid is specific to a lactalbumin , and that non hydrophobic region of 112 to 116th amino acid is specific to lysozyme . The former region corresponds to the binding site of calcium ion , which is a main functional part of CXlactalbumin . However , the function of the latter region is unknown . role in the function of lysozyme , because that region easily interacts
It may play an important with targets and water , which causes the dehydration of targets ( Lewin , 1994 ) .
Third , Table 4 shows the results of the definite rules after secondary structure rearrangement . The second row shows the location in sequences , for example , 70 77 means 70th to 77th amino acid in sequences of lysozyme c . Interestingly , although specific amino acids are mainly located at the lower address part ( called it N terminal ) , specific local structure are mainly located at the higher address part ( called it C terminal ) . The most significant regions are 98 104 and 113 117 lnnnnn ,,,h o,nr . “ Anrrr o+r*n+ra : ” ,3,sl r;a.Lll oca ” wAody UblUblrUlG ID “ GLJ different . Other regions also show that hydrophobic regions of lysozyme correspond to non hydrophobic regions of cY lactalbumin , and vice versa . Thus , these regions may play an important role in realizing each function 8 .
, “ ~LQIUJO
According to these results , they are now planning to validate these results by the experiment8 based on technique of recombinant DNA . Since it takes about one to three weeks to study the characteristics of one “ mutant ” protein , we need more that 6 months to confirm our induced results . Readers may say that it takes too much long time for validation , but it is said that we need 10 to 20 years to study the characteristics of the two proteins . Therefore we can save our time to make efficient experiments .
6 . Related Work
Rules of Association
6.1 Discovery Mannila et al.(Mannila et al . 1994 ) report a new alfor discovery of association rules , which is gorithm one class of regularities , introduced by Agrawal et al.(Agrawal et al . 1993 ) . Their method is very similar to ours with respect to the following two points . The concept of association ( 1 ) Association rules is similar to our induced rules . Actually , association rules can be described in the rough set framework . That is , we say that an association rule over T satis
Rules . fies W =+ 3 with respect to 7 and u , if I[+v f l [ +I 2 cm blw ” MB and
2 7 , blw _ where n , 7 , and c denotes the size of training samples , confidence threshold , and support threshold , respectively . Also , W and B denotes an equivalence relation and a class , respectively . Furthermore , we also say that W is covering , if
It is notable that the above formulae correspond to the formula as to K and p value shown in 411 , coverage ‘Recently , our collaborating domain experts have got the results! which suggest that 9%104th amino acid plays an important role in lysoayme function(Tsumoto , K . 1994 ) . and the formula as to CY , accuracy . The only difference is that we classify rules , corresponding to association rules , into three categories : definite rules , significant rules , and strong rules . lx II
. :I , I . , ^^_I :J 1
The reason why we classify these rules is that this type of classification can be viewed as the ordering of rules or hypothesis . That is , definite rules correspond to the strongest hypotheses . However , these strongest rules may not be interesting for discovery . Then , significant rules will be considered for the candidates of discovery . If they are not so important , then strong I 11 AL CL I: 1 , LuleD Will “ t : L ; “ IIsIutxtxl . r umuy , au Cllt : Irllree KIIKlS rules are found to be not important , then we should search for weak rules . In this way , we simulate the discovery strategy of biochemists by using the classification of classification rules . intro(2 ) Mannila ’s duce an algorithm to find association rules based on Agrawal ’s algorithm . The main point8 of their algorithms are database pass and candidate generation . Database pass produces a set of attributes L , as the collection of all covering sets of size s in C , . Then , can,: l L .L: L 1^^^L^^ LLUKl&lrt : generalJ1on Cal(;lllabes Lls+1 , WlllCll uelloces IJIlt : collection of all the sets of attribute8 of size s , from L , . Then , again , database pass is repeated to produce L s+l . The effectiveness of this algorithm is guaranteed by the fact that all subsets of a covering set are covering .
Mannila et al .
~~1~1L~/*
A:
Algorithm .
The main difference between Mannila ’s algorithm and our MWl algorithm is that Mannila uses the check algorithm for covering to obtain association rules , whereas we use statistical analysis to compute and classify rules .
In the discovery of association urles , all of the combination of attribute value pairs in C , have the property of covering . On the other hand , our algorithm do not focus on the above property of covering . It removes an attribute value pair which has both high accuracy and high coverage from L , and does not include in Ms . That is , PRIMEROSEEX does not search for regularities which satisfy covering , but search for regularities important for classification .
Thus , interestingly enough , when many attributevalue pairs have the covering property , or covers many training samples , Mannila ’s algorithm will be slow , although PRIlMEROSE EX algorithm wiii be fast in this case . When few pairs covers many training samples , Mannila ’s algorithm will be fast , and our system will not be faster .
6.2 Ziarko ’s KDD R Ziarko and Shan develop a comprehensive system for knowledge discovery in databases using rough sets , called KDD R ( Ziarko and Shan 1995b ) . Their system consists of the four functional units : data processing unit , a unit for analysis of dependencies , a unit for computation of rules from data , and decision unit .
Tsumoto
323
Intelligence and Molec
A 1 ZLl E
1994 . ror Discovering Association of Knowledge Discovery in pp . 181 192 , AAAI press .
Chou , PY and Fasman , GD 1974 . Prediction of protein conformation . Biochemistry , 13 , 222 244 . Dayhoff , MO 1972 . Atlas of Protein Sequence and Structure . Natl . Biom . Res . Foundation , Washington DC Hunter , L.(ed ) 1993 . Artificial ular Biology , AAAI press , CA . Lewin , B . 1994 . Genes V . , Oxford University Press , London . Mannila , H . , Toivonen , H . , Verkamo , AI . nnz : L llrmciem nrgorrrnms Rules , Proceedings Databases ( KDD 94 ) , McKenzie , HA and White , Jr . , FH 1991 . Lysozyme and a lactalbumin : Structure , Function , and Interrelationships , in : Advances in Protein Engineering , pp.173 315 , Academic Press . Michalski , RS , et al . 1986 . The Multi Purpose Incremental Learning System AQl5 and its Testing Apto Three Medical Domains , Proceedings of plication 1041 1045 , Morgan Kaufmann , CA . AAAI 86 , Pawlak , Z . 1991 . Rough Sets , Kluwer Academic Pub lishers , Dordrecht . Quinlan , JR 1986 . Induction of decision trees , Machine Learning , 1 , 81 106 . Skowron , A . and Rauszer , C . 1992 . The Discerniblity Matrices and Functions in Information Systems , In Slowinski , R . ( ed . ) Intelligent Decision Support : Handbook of Applications and Advances of Rough Sets Theory , Kluwer , Dordrecht . Tsumoto , K . et al . 1994 . Journal of Biochemistry . ‘;l;nrLrr Rn , , rc~pYACUIR ” ) resentation of Data Dependencies in Databases , in : Shapir0,GP and Frawley , WJ ( eds . ) Knowledge Discovery an Database , AAAI press , 1991 . Ziarko , W . ( Ed . ) 1994 . Rough Sets , Fuzzy Sets and Knowledge Discovery . Workshops in Computing , Springer Verlag , London . Ziarko , W . and Shan , N . 1995a . A Rough Set Based Method for Computing All Minimal Deterministic Rules in Attribute Value Systems , Computational Intelligence 11 ( in press ) . “ I I TTI .~ 3 t 4 , . .~ hT * r.rrr l~ 7, n? % n bomprebiaxo , vv . ana anan , IY . ~Yynn . nuu n : hensive System for Knowledge Discovery in Databases Using Rough Sets . Proceedings of RSSC 94 ( in press ) . Zytkow , JM ( Ed . ) 1992 . Proceedings of the ML 92 Workshop on Machine Discovery ( MD 92 ) . Wichita , KS : National Institute for Aviation Research . nbonmrr A nal.r&o uLon , “ “ ~rg,rrrLaryuru , l l A ,
T&7 .
1aa1 l7ilL
I%I l‘zi
3 l CllllU
The most important unit is one for computation of rules from data . This unit computes all , or some , approximate rules with decision probabilities , where the probabilities are restricted by lower and upper limit parameters specifying the area of user interest . The rules can be computed for a selected reduct using the method of decision matrix ( Ziarko and Shan 1995a ) , which is an extention of discerniblity matrix ( Skowron and Rauzer 1992 ) .
The main difference between KDD R and our system adopts statistical measures is that PRIMEROSEEX A. ._ ^ ^LLALL^ ^,A : A T T)T)T’IIblTnAclTII riv bU psu11t’ abbl llJULe Vitlue pami . 111 rllllvlWn.u3~~h , attribute value pairs which have high accuracy and high coverage will be used for rule generation and removed from the candidates of complexed rules . On the other hand , KDD R first removes dependent superfluous attributes using the extension of rough set model , called Variable Precision Rough Set model and then calculates rules using the technique of decision matrix , which is very useful to generate all approximate rules . focuses mainly on dependencies of attributes with respect to selection of attribute value pairs , whereas PRIMEROSEEX focuses on mainly on statistical significance of attribute value pairs , which is used for selection of attribute value pairs . Therefore the performance of each system may depend on the characteristics of an applied domain . That is , KDD R may outperform our method when a dataset has many dependent attributes .
Thus , KDD R
7 . Conclusion
In this paper , we propose a system based on combination of a probabilistic rule induction method with domain knowledge , which we call MWl ( Molecular biologists’ Workbench version l.Oj in order to retrieve the difficulties from the experimental environments of molecular biologists . We apply this method to comparative analysis of lysozyme and a lactalbumin , and the results show that we get some interesting results from amino acid sequences , which have not been reported before . Acknowledgements The authors would like to thank Jan Zytkow and the reviewers for insightful comments . This research is supported pll~ . 06680343 from the Ministry of Education , Science and Culture , Japan . by &ants in .Aeid fenr S&fit;ific
&spar&
References
Agrawal , R . , Imielinski , T . , and Swami , A . 1993 . Mining association rules between sets of items in large databases . Proceedings of the 1993 International Conference on Management of Data ( SIGMOD 93 ) , pp . 207 216 . Breiman , L . , Freidman , J . , Olshen , R . , and Stone , C . 1984 . Classification And Regression Trees . Belmont , CA : Wadsworth International Group .
324
KDD 95
