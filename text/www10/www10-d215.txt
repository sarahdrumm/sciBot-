Diversifying Landmark Image Search Results by Learning
Interested Views from Community Photos Yuheng Renâ€ * , Mo Yuâ€ * , Xin Jing Wangâ€¡ , Lei Zhangâ€¡ , Wei Ying Maâ€¡
â€¡Microsoft Research Asia , 49 Zhichun Road , Beijing , China â€ Harbin Technology Institute , Harbin , 150001 , PRChina
â€ {yuhengren,yumo}@vilabhiteducn ; â€¡{xjwang , leizhang , wyma}@microsoft.com
ABSTRACT In this paper , we demonstrate a novel landmark photo search and browsing system , Agate , which ranks landmark image search results considering their relevance , diversity and quality . Agate learns from community photos the most interested aspects and related activities of a landmark , and generates adaptively a Table of Content ( TOC ) as a summary of the attractions to facilitate user browsing . Image search results are thus re ranked with the TOC so as to ensure a quick overview of the attractions of the landmarks . A novel non parametric TOC generation and re ranking algorithm , MoM DPM Sets , is proposed as the key technology of Agate . Experimental results based on human evaluation show the effectiveness of our model and user preference for Agate . Categories and Subject Descriptors H33 [ Information Storage and Retrieval ] : Information Search and Retrieval â€“ retrieval models , clustering . G.3 [ Mathematics of Computing ] : Probability and Statistics â€“ nonparametric statistics . H53 [ Information Interface and Presentation ] : Group and Organization Interfaces â€“ organizational design , Web based interaction . General Terms Algorithms , Performance , Human Factors Keywords User interest modeling , set based ranking , landmark image search .
1 . INTRODUCTION Online travel services have become increasingly important in user experience . The pre trip behavior of a typical user is first to seek for inspiration or destination guidance , collect information , do research and comparison , and then plan and book their trip [ 4 ] . In this loop , existing search engines are generally serving as a hub to help redirect users to travel agent sites . We believe that search engines should be able to contribute more . Imagine that the online photo search of a tourist resort is so advanced that it presents the user a comprehensive overview of the attractions of this place , eg , when the user searches â€œ Bora Bora island â€ , beach , underwater activities , and revelry , etc . are outlined . Obviously image search engines will become competitive travel guidance agents in the online travel market .
* The work was performed at Microsoft Research Asia . Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . Distribution of these papers is limited to classroom use , and personal use by others . WWW 2010 , April 26â€“30 , 2010 , Raleigh , North Carolina , USA . ACM 978 1 60558 799 8/10/04 .
( a ) ( b ) Figure 1 . Google ( left ) and Agate ( right ) results of â€œ Parthenon on Acropolis â€
Unfortunately , existing image search engines are far from satisfying such user needs : they return unorganized list of images based on keyword matching , which would decelerate userâ€Ÿs convergence to the attractive aspects of a landmark . Meanwhile , text based image retrieval suffers from word ambiguity and visual redundancy . For example , Figure 1(a ) shows the Google image search results of â€œ Parthenon on Acropolis â€ ; redundant images which differ only in size and irrelevant images like cups and cup pads were ranked high . In this work , we demonstrate a new landmark search and browsing system , Agate , as an attempt to sketch the attractions of a place and deliver relevant , diverse and high quality photo search results . As shown in Figure 1(b ) , Agate automatically generates a table of content ( TOC ) as a navigation panel on the left , which summarizes the attractive aspects of Acropolis , and rendered search results with improved relevance and diversity . Similar ideas of generating TOC were addressed by Wang et al . [ 8 ] and the IGroup system [ 3 ] . Both these work group web images to improve the search result . Wang et al . [ 8 ] made use of the visual context of an image while IGroup identifies salient key phrases from image surrounding texts . They attempted to structuralize image search results to facilitate user browsing , but neither of them identified the most interested aspects , nor did they re rank image search results to punish irrelevance and encourage diversity . The knowledge of the most attractive views of a landmark , however , is embedded in user generated content ( UGC ) , eg the votes that a Flickr image obtains suggest to certain extent the corresponding viewâ€Ÿs attractiveness . In this study , we propose a novel algorithm called Multimodal Dirichlet Process Mixture Sets ( MoM DPM Sets ) to learn such knowledge from UGC data , and
WWW 2010 â€¢ DemoApril 26 30 â€¢ Raleigh â€¢ NC â€¢ USA1289 In this work , we propose to leverage the metadata of user votes associated with Flickr images to discover the most interested aspects of a landmark . A user votes for an image due to various reasons , eg it is a professional shot ; it catches the most famous view , or some noisy reasons such as friendship . However , it is reasonable to assume that the majority of user votes will favor the high quality and attractive contents [ 5 ] . This is the intuition behind our TOC generation technique . There are many measurements of interestingness of an image . In our current approach , we simply used the â€œ interestingness â€ property provided by Flickr since the Flickr ratings should have considered user preference and is thus more trustable . Given a location name , we query the Flickr search service and sort the image results in their descending order of â€œ interestingness â€ . We crawl at most top 500 images as well as their user submitted tags for TOC generation . 2.3 TOC Generation and Image Re Ranking A natural way to generate TOC from a photo collection is clustering [ 8][3][5 ] . Then we re rank the original image search results against these clusters . There are three major challenges : 1 ) different landmarks will have different number of attractive aspects , and how to determine the number adaptively is challenging ; 2 ) both visual and textual features are valuable to ensure the clustering effectiveness , while how to fuse these heterogeneous features is still an open research topic ; and 3 ) how to provide a unified measurement for both clustering and re ranking . Recent research achievements on topic modeling suggest a promising solution for feature fusion [ 7][2 ] [ 1 ] , while the Dirichlet Process ( DP ) technique [ 7 ] gives a solution to automatically determine the number of clusters . Combining these two , the MultiModal Dirichlet Process Mixture model ( MoM DPM ) [ 1 ] is able to address the former two challenges mentioned above . However , as to our knowledge , there are no such previous works which are able to simultaneously solve all the three challenges with a single model . 231 The MoM DPM Sets model We propose the Multi Modal Dirichlet Process Mixture Sets algorithm ( MoM DPM Sets ) to fill in the vacancy . Firstly , it is a DP mixture model which generates adaptively a number of latent topics , each indexes a cluster . Secondly , it is multimodal which conditionally independently generates visual and textual representations of an image given a topic . Thirdly , it formulates the reranking step as a set based Bayesian inference problem . Rather than learning a single ( optimal ) parameter set from training data and measuring a new image against the model as previous works did [ 1][2 ] , MoM DPM Sets identifies which images should be in one cluster , and measures a new image against the images in a cluster given all possible distributions of model parameters . Note that since all parameter distributions are taken into consideration in MoM DPM Sets , it gives a truly Bayesian inference , which is a fundamental theoretic difference to the previous models . This formulation provides a great capability to summarize community images and re rank web images ( in a different domain ) in a fundamental way . We represent an image both by ( a ) a bag of visual words ğ‘£ representing the visual features and ( b ) a bag of terms ğ‘¡ generated from its surrounding tags . Let ğœƒğ‘£ be the multinomial distribution over visual words with a Dirichlet prior ğ»ğ‘£ , and ğœƒğ‘¡ be the Ber
Figure 2 . Sketch of Agate â€™s framework : 1 ) collect top voted Flickr photos , 2 ) image auto group to generate TOC , 3 ) rerank the image search results of commercial engine , and 4 ) deliver the TOC and ranking results in the UI . then apply the knowledge to re rank image search results accordingly . 2 . THE AGATE SYSTEM 2.1 The Framework As shown in Figure 2 , Agate consists of three parts : 1 ) collecting top voted Flickr images , 2 ) generating TOC , and 3 ) re ranking image search results . Given a location name , we collect the most interested images from Flickr.com using its â€œ search by interestingness â€ service . After filtering out stop words ( including general stop words and the query location name ) , extracting visual features ( color sift descriptor ) [ 6 ] and textual features ( word occurrence ) , we group these images into clusters and then assign a name for each cluster . We use the clusters to re rank Bing image search results and present the output to the user . The UI of Agate is shown in Figure 1(b ) . On the left is a TOC navigation panel and on the right shows the image search result . Given a location query , the TOC panel shows the thumbnails along with cluster names about the corresponding attractions , ranked in descending order of their importance , and the search result panel shows the image search results re ranked against the attractions , which have improved relevance , diversity and quality . The user can also select to browse images of a certain view by clicking on the corresponding thumbnails . Image search results will then be ranked against this certain category so that the less interested aspects of the query location will be ranked lower . 2.2 Top voted Flickr Image Collection Mining from UGC data has enabled many interesting research on computer vision nowadays . However , most of them use only images and their tags ; there are still many useful metadata that have not been fully taken advantages of .
Set BasedRerankingQuery : Bora Bora islandCommercial engine resultTop voted flickr photoTOC generationUnderwater , DiveDance , HotRe rank all imagesRender TOC and corresponding result Online PartOffline PartHigh quality , diversityIrrelevance redundancyWWW 2010 â€¢ DemoApril 26 30 â€¢ Raleigh â€¢ NC â€¢ USA1290 noulli distribution over terms with the Beta prior ğ»ğ‘¡ = {ğœ¸0 , ğœ¸1} . We use Bernoulli distribution for terms because generally unique Flickr tag appears only once for an image . The generative process of MoM DPM Sets is shown in Table 1 . Let ğ‘£ğ‘– , ğ‘¡ğ‘– , ğ‘§ğ‘– represent the visual features , textual features , and cluster label of the ğ‘– th image respectively . Let ğ’›\ğ‘– be the cluster labels of all the observed images with the ğ‘– th image removed , and ğ‘‰ğ‘§ , ğ‘‡ğ‘§ be the visual and textual features of images in a certain cluster ğ‘§ . Let ğœ™ğ‘£ and ğœ™ğ‘¡ be the parameter set corresponding to visual and textual features respectively , the model is to learn the probability ğ‘ ğ‘§ğ‘– = ğ‘§ ğ‘£ğ‘– , ğ‘¡ğ‘– , ğ‘‰ğ‘§ , ğ‘‡ğ‘§ , ğœ™ğ‘£ , ğœ™ğ‘¡ . Note that the key difference of this model from the previous work [ 1 ] lies in the existence of ğ‘‰ğ‘§ , ğ‘‡ğ‘§ . This is the key of set based Bayesian inference . We solve this model with Gibbs sampling , as below : For an existing ( active ) topic ğ‘§ğ‘– = ğ‘§ âˆˆ {1 , . . ğ¾} ğ‘ ğ‘§ğ‘– = ğ‘§ ğ‘£ğ‘– , ğ‘¡ğ‘– , ğ‘‰ğ‘§ , ğ‘‡ğ‘§ , ğœ™ğ‘£ , ğœ™ğ‘¡ )
ğ‘§ ğ‘›\ğ‘–
ğ‘› âˆ’ 1 + ğ›¼
âˆ
ğ‘ ğ‘£ğ‘– ğ‘§ğ‘– = ğ‘§ , ğ‘‰ğ‘§ , ğœ™ğ‘£ ğ‘ ğ‘¡ğ‘– ğ‘§ğ‘– = ğ‘§ , ğ‘‡ğ‘§ , ğœ™ğ‘¡ ( 1 )
And for a new ( inactive ) topic , ğ‘§ğ‘– = ğ‘§ , ğ‘“ğ‘œğ‘Ÿ âˆ€ğ‘§ğ‘— âˆˆ 1 , . . , ğ¾ , ğ‘§ â‰  ğ‘§ğ‘— ğ‘ ğ‘§ğ‘– = ğ‘§ ğ‘£ğ‘– , ğ‘¡ğ‘– , ğ›¼ , ğœ™ğ‘£ , ğœ™ğ‘¡ )
âˆ
ğ›¼
ğ‘› âˆ’ 1 + ğ›¼
ğ‘ ğ‘£ğ‘– = ğ‘£ ğ»ğ‘£ ğ‘ ğ‘¡ğ‘– = ğ‘¡ ğ»ğ‘¡ ( 2 )
Where ğ¾ is number of existing ( active ) clusters in current iteration , ğ‘§ is the number of images ( except the i th ) labeled by topic ğ‘§ . ğ‘›\ğ‘– This was in the same form of algorithm 3 presented by Neal et al . [ 7 ] , while our approach can be regarded as its multi modal extension . Taking the specific multinomial and Bernoulli distribution into the form , we have : ğ‘ ğ‘£ğ‘– ğ‘§ğ‘– = ğ‘§ , ğ‘‰ğ‘§ \ğ‘– , ğœ™ğ‘£
= ğ‘€ğ‘¢ğ‘™ ğ‘£ğ‘– = ğ‘£|ğœƒğ‘§,\ğ‘–
ğ‘£ ğ·ğ‘–ğ‘Ÿ ğœƒğ‘§,\ğ‘–
ğ‘£ ğ‘‰ğ‘§ \ğ‘– , ğ»ğ‘£
ğ‘£
ğœƒğ‘§,\ğ‘–
=
ğ›¤ ( ğ»ğ‘˜
ğ‘˜
ğ›±ğ‘˜ ğ›¤ ( ğ»ğ‘˜
ğ‘£,ğ‘§ ) ğ‘£ + ğ‘›ğ‘˜,\ğ‘–
ğ‘£,ğ‘§ ğ‘£ + ğ‘›ğ‘˜,\ğ‘–
ğ‘£ + ğ‘›ğ‘˜,\ğ‘– ğ›±ğ‘˜ ğ›¤ ğ»ğ‘˜ ğ‘£ ğ›¤ ( ğ»ğ‘˜ + ğ‘›ğ‘˜,\ğ‘–
ğ‘£,ğ‘§ + ğ‘£ğ‘˜ ğ‘£,ğ‘§ + ğ‘£ğ‘˜ )
ğ‘˜
( 3 )
ğ‘ ğ‘¡ğ‘– = ğ‘¡ ğ‘§ğ‘– = ğ‘§ , ğ‘‡ğ‘§ \ğ‘– , ğœ™ğ‘¡
= ğµğ‘’ğ‘Ÿ ğ‘¡ğ‘– = ğ‘¡|ğœƒğ‘§,\ğ‘–
ğ‘¡ ğµğ‘’ğ‘¡ğ‘ ğœƒğ‘§,\ğ‘–
ğ‘¡
ğ‘¡
ğœƒğ‘§,\ğ‘–
ğ‘‡ğ‘§ \ğ‘– , ğ»ğ‘¡
= ğ‘˜
ğ›¾ğ‘˜
ğ‘¡,ğ‘§ 1 + ğ‘›ğ‘˜,\ğ‘–
ğ‘¡ğ‘˜ ( ğ›¾ğ‘˜ 1 + ğ›¾ğ‘˜ ( ğ›¾ğ‘˜
ğ‘¡,ğ‘§ 0 + ğ‘›ğ‘— ,\ğ‘–
âˆ’ ğ‘›ğ‘˜,\ğ‘– ğ‘¡,ğ‘§ 0 + ğ‘›ğ‘— ,\ğ‘–
)
ğ‘—
ğ‘—
ğ‘¡,ğ‘§ )(1âˆ’ğ‘¡ğ‘˜ )
( 4 )
ğ‘£,ğ‘§ and ğ‘›ğ‘— ,\ğ‘– where ğ‘£ğ‘˜ denotes the count of the ğ‘˜ th visual word in the query image , and ğ‘¡ğ‘˜ = 1 means that term ğ‘˜ appears in the query imageâ€Ÿs ğ‘¡,ğ‘§ indicate the number of tag list and ğ‘¡ğ‘˜ = 0 otherwise . ğ‘›ğ‘˜,\ğ‘– images with topic ğ‘§ in their visual and textual appearances respectively . In our evaluation , the Gibbs sampling generally converges in about 30 iterations . And then we save the learnt clusters for the reranking step . 232 Cluster name generation In order to display the TOC categories in plain sight , we randomly select three images in each cluster and show them in the naviga
Table1 : The generative process of MoM DPM sets tion panel . Meanwhile , we assign a name to each cluster to make the semantics clearer . The clustering effectiveness is ensured in two aspects : 1 ) it is applied onto top voted search results , so that the image collection used to learn the clusters is comparatively clear ; 2 ) the MoMDPM Sets is effective in clustering . Therefore , a simple key phrase extractor is able to produce representative cluster names . We observed that after filtering stop words , meaningful tags which describe the attractions have high frequency within certain clusters but have relatively low frequency over all clusters . For example , in the cluster of night views of the Golden Gate Bridge , we observed that those representative words like â€œ night â€ , â€œ light â€ have relatively high frequency , while those noisy keywords such as â€œ awesome â€ and â€œ Nikon â€ are fairly common among all clusters . So we adopt the TF IDF measure to score the associated words of images in a cluster . Concretely , we collect all the words in a cluster as one single document , and compute the TF IDF score for each word among all clusters . Then for each cluster , we sort their words in the descending order of their TF IDF score and the topranked four words are selected as the cluster name . We observed from our demo that this simple approach is fairly effective . 233 Re ranking image search results Our demo supports two types of re ranking : 1 ) re ranking the image search results against all learnt clusters , and 2 ) re ranking against a certain cluster . This is helpful when the user is only interested in a certain attractive view . We used the Bing image search engine for our evaluation . In the case of re ranking against all clusters , a new image is scored by Eq ( 5 ) : ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ ğ‘£ğ‘ , ğ‘¡ğ‘ = max ğ‘§âˆˆğ’›
ğ‘ ğ‘§ ğ‘£ğ‘ , ğ‘¡ğ‘ , ğ’› , ğ‘‰ğ‘§ , ğ‘‡ğ‘§ , ğœ™ğ‘£ , ğœ™ğ‘¡ )
{ âˆ max ğ‘› + ğ›¼ ğ‘§âˆˆğ’›
ğ‘›ğ‘§
ğ‘ ğ‘£ğ‘ ğ‘‰ğ‘§ , ğœ™ğ‘£ ğ‘ ğ‘¡ğ‘ ğ‘‡ğ‘§ , ğœ™ğ‘¡ } ( 5 )
Where ğ‘£ğ‘ , ğ‘¡ğ‘ represent the features of the query image . ğ‘› is the number of images in all the learnt clusters and ğ‘›ğ‘§ is cluster size of a topic ğ‘§ , and ğ’› represents all the available topics . In the case of re ranking against one single cluster , we adopt Eq ( 6 ) : ğ‘ ğ‘ğ‘œğ‘Ÿğ‘’ ğ‘£ğ‘ , ğ‘¡ğ‘ = ğ‘ ğ‘§ ğ‘£ğ‘ , ğ‘¡ğ‘ , ğ’› , ğ‘‰ğ‘§ , ğ‘‡ğ‘§ , ğœ™ğ‘£ , ğœ™ğ‘¡ ) ( 6 )
Generative Process of MoM DPM Sets ,x draw ğ…~ğºğ¸ğ‘€(ğ›¼ ) using a stick breaking process ,x for each image ğ‘– = 1,2,â€¦,ğ‘ o draw a topic ğ‘§ğ‘–~ ğ·ğ‘–ğ‘ ğ‘ğ‘Ÿğ‘’ğ‘¡ğ‘’ ğ… o if ğ‘§ğ‘– not exist in z ï‚§ draw a multinomial distribution over visual words , ğœƒğ‘§ğ‘–ğ‘£~ğ·ğ‘–ğ‘Ÿ ğ»ğ‘£ ï‚§ draw a Bernoulli distribution over terms , ğœƒğ‘§ğ‘–ğ‘¡~ğµğ‘’ğ‘¡ğ‘(ğ»ğ‘¡ ) o draw ğ‘£~ğ‘€ğ‘¢ğ‘™ğ‘¡(ğœƒğ’›ğ’Šğ’— ) using Eq ( 3 ) o draw ğ‘¡~ğµğ‘’ğ‘Ÿ(ğœƒğ‘§ğ‘–ğ‘¡ ) using Eq ( 4 ) WWW 2010 â€¢ DemoApril 26 30 â€¢ Raleigh â€¢ NC â€¢ USA1291 Figure 3 . Percentage of queries wined by Agate and IGroup on TOC quality
Figure 4 . Average user scoring of TOC quality 3 . EVALUATIONS Since there is no benchmark dataset or ground truth data available , we asked ten volunteers to manually evaluate the system . The participants were asked to act as travelers searching for information about their destination landmarks . 3.1 Quality of Generated TOC The first session of user study is to compare the outputs of Agate and IGroup[3 ] , a state of the art image grouping system , on the effectiveness of TOC generation and categorized search . In this session , twenty landmarks randomly selected from the Wikipedia list of landmarks1 formed the testing query set . The TOC outputs of both IGroup[3 ] and Agate are presented to participants simultaneously , but which results came from which system was kept blind to the labeler . They need to assign a score between one to five to measure 1 ) diversity , which evaluates whether the learnt categories contain diverse aspects of a landmark , and 2 ) accuracy , which measures whether the member images are relevant to the TOC concept . Figure shows the evaluation result . Most of participants agreed d that on 70 % of the queries , Agate outperformed IGroup [ 3 ] in diversity , and on 65 % of the queries , Agate won in accuracy . IGroup [ 3 ] was superior just on 5 % of queries in diversity and 10 % of queries in accuracy , while for the rest of queries , they tied . Figure shows the average scores of the two systems . We can see that Agate greatly outperformed IGroup [ 3 ] both in diversity and in satisfaction . 3.2 Effectiveness of Image Re Ranking The second session of user study is to measure whether Agate can improve the quality of image search results . We measure the quality with the following factors : 1 ) relevance , whether the number of irrelevant images is reduced ; 2 ) diversity , whether the search results cover diverse topics about the query landmark ; 3 ) image quality , whether low resolution images will be ranked lower . We used Bing as our baseline and Bing image search results as the resource of new images . Again all participants were asked to score one to five to each criterion above ; the larger score the better . Meanwhile , we asked them to give an â€œ overall â€ score to indicate their overall impression of the search results . The performance was tested on forty randomly selected landmark queries .
1 http://enwikipediaorg/wiki/List_of_landmarks
Figure 5 . Image search performance of Agate vs . Bing .
Figure illustrates the result . It can be seen that the re ranked sets outperformed original Bing image search results on all three criteria . And the overall impression of Agate greatly surpassed Bing . According to our close observation , if the score of a criterion is larger than four , then the search result volunteers would describe the search engine as â€œ effective â€ . And as it could be seen in the figure , Agate was scored higher than four in all criteria . 4 . CONCLUSION In this paper , we propose Agate , a novel landmark image search and browsing system . Agate attempts to enrich an image search engine with the service of travel guidance , via which the user obtains a comprehensive understanding of the attractions of a location . Agate seeks such knowledge from community photos , and then applies it to re rank commercial image search results . A MoM DPM Sets model was proposed as the key technology underlying Agate , which determines the number of attractive aspects adaptively , fuses visual and textual features , and unifies the clustering and ranking steps . A friendlier user interface was designed to facilitate user browsing and help her quickly discover the interested photos . Comprehensive user studies showed the effectiveness and the superiority of Agate to existing systems . 5 . REFERENCES [ 1 ] A . Velivelli and TS Huang . Automatic Video Annotation
Using Multimodal Dirichlet Process Mixture Model . ICNSC 2008 .
[ 2 ] B . David and M . Jordan . Modeling annotated data . ACM
SIGIR conference , pp . 127â€“134 , 2003 .
[ 3 ] F . Jing , C . Wang , Y . Yao , K . Dong , L . Zhang and W . Ma . IGroup : Web Image Search Results Clustering . ACM Multimedia , Oct . , 2006 .
[ 4 ] J . Butcher . Travel â€Experiencesâ€Ÿ : The Ancillary Product Con text . WTM Seminar of Isangocom Nov . 2008 .
[ 5 ] I . Simon , N . Snavely et al . Scene Summarization for Online
Image Collections . ICCV , 2007 .
[ 6 ] K . Sande , T . Gevers and C . Snoek . Evaluating Color De scriptors for Object and Scene Recognition , IEEE Trans . On PAMI ( in press ) , 2010
[ 7 ] RM Neal . Markov Chain Sampling Methods for Dirichlet
Process Mixture Models . Journal of Computational And Graphical Statistics , vol.9(2):249 265,2000
[ 8 ] X . Wang , W . Ma , Q . He and X . Li . Grouping Web Image
Search Result . In Proceeding of the 12th International ACM Conference on Multimedia , Oct . 2004 .
0%20%40%60%80%100%DiversityAccuracyIGroup WinsTieAgate Wins01234DiversityAccruacyIGroupAgate0051152253354455QualityDiversityContextualOverallAgateBingWWW 2010 â€¢ DemoApril 26 30 â€¢ Raleigh â€¢ NC â€¢ USA1292
