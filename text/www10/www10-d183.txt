Query Parsing in Mobile Voice Search
Junlan Feng
AT&T Labs Research
180 Park Avenue
Florham Park , NJ 07920 junlan@researchattcom
ABSTRACT Mobile voice search is a fast growing business . It provides users an easier way to search for information using voice from mobile devices . In this paper , we describe a statistical approach to query parsing to assure search effectiveness . The task is to segment speech recognition ( ASR ) output , including ASR 1 Best and ASR word lattices , into segments and associate each segment with needed concepts in the application . We train the models including concept prior probability , query segment generation probability , and query subject probability from application data such as query log and source database . We apply the learned models on a mobile business search application and demonstrate the robustness of query parsing to ASR errors .
Categories and Subject Descriptors H33 [ Information Search and Retrieval ] : Retrieval models
General Terms Algorithms , Applications
Keywords Query parsing , Mobile voice search
1 .
INTRODUCTION
Voice search is essentially an integration of automatic speech recognition ( ASR ) and text or database search . In this paper , we describe a query parser between ASR and Search . As expected , the ASR and Search components perform speech recognition and search tasks . The role of query parsing is three fold : ( a ) segmenting the automatic speech recognition ( ASR ) output ( 1 best and word lattices ) into meaningful segments , ( b)associating each segment with needed concepts in the application , and ( c)identifying the main subject of the query such as night clubs in night clubs open on christmas day .
There are two research literatures closely relevant to our work , namely query segmentation and named entity extraction(NEE ) . [ 3 ] proposed an unsupervised approach to query segmentation based on a generative language model , where the task was to segment the query into segments of text .
Copyright is held by the author/owner(s ) . WWW 2010 , April 26–30 , 2010 , Raleigh , North Carolina , USA . ACM 978 1 60558 799 8/10/04 .
The argument is that segments carry implicit word proximity and ordering constraints , and hence can help improve retrieval accuracy . It used an expectation maximization ( EM ) algorithm to estimate the model ’s parameters . NEE attempts to identify entities of interest in text . Typical entities include locations , persons , organizations , dates , times monetary amounts and percentages ( Kubala et al . , 1998 ) . Most approaches for NEE tasks rely on machine learning approaches using annotated data .
Our task of voice query parsing confronts a combination of challenges in both NEE and query segmentation . Its complexity is beyond query segmentation . In addition , application concepts in the parser are broader than named entities . Furthermore , we face challenges posed by error prone ASR and mobile context , in which users expect that search performs highly effective with location and time awareness .
In the rest of the paper , we will describe a scalable statistical approach to query parsing in Section 2 . We then present experimental results in Section 3 . Finally , we conclude the paper in Section 4 .
2 . A STATISTICAL APPROACH
We formulate the query parsing task as follows . The query parser takes ASR 1 best and ASR lattices as input . For ASR lattices , we use the form of Word Confusion Networds ( WCNs ) , represented as Qwcn [ 2 ] . Figure 1 shows an example of WCN . There are one or multiple arcs between a pair of consecutive nodes . Symbols on these arcs are alternative words for the given word position . Numbers on the arcs are negative log posterior probabilities of the associated word . ASR 1 best is a special case of WCN , where there is only one word for each word position .
The parsing task is to segment Qwcn = q1 , q2 , . . . , qi , . . . , qn into a sequence of concepts . Each qi is a set of possible words on the arcs of the ith word position qi = {wa(i)|1 ≤ a(i ) ≤ nai} , where nai is the number of available arcs . Each concept can possibly span multiple words . Let W j i = wa(i ) , . . . , wa(j ) be one possible word sequence from the ith word to the jth word . a(i ) and a(j ) are indices of the arcs . Let S = s1 , s2 , . . . , sk , . . . , sm be one of the possible segmentations comprising of m segments , where sk = W j i . The corresponding concept sequence is represented as C = c1 , c2 , . . . , ck , . . . , cm .
∗
( S
, C
∗|Qwcn , D ) = argmax P ( S , C|D ) · Pcf ( S|D)λcf {S,C|Qwcn} P ( S|C , D ) · P ( C|D)λc · Pcf ( S|D)λcf
( 1 )
( 2 )
= argmax {S,C|Qwcn}
WWW 2010 • PosterApril 26 30 • Raleigh • NC • USA1089 Figure 1 : An example confusion network for ” Gary crities Sprin gfield Missouri ”
For a given Qwcn ,our goal is to search for the best segmentation and concept sequence ( S∗ , C∗ ) as defined by Equation 1 , which is rewritten using Bayes rule as Equation 2 with extra parameters λc and λcf . D represents mobile context information such as location , speed , history usage , and time of the mobile device . It impacts the meaning of the query . For instance , Glendale Restaurant means different in neighborhoods close to the business named as Glendal Restaurant than anywhere else . Features of a mobile devices also impact ASR modeling and performance . There are three components in Equation 2 . P ( C|D ) is the prior probability of the concept sequence . We use λc to scale the prior P ( C|D ) . P ( S|C , D ) is the segment sequence generation probability . Pcf ( S|D ) is the posterior probability of the word sequence of S on Qwcn . λcf is used to adjust the influence of ASR posterior probabilities . The values of both λc and λcf are determined empirically . In this paper , we focus on a simplified model without including D as a modeling factor . Hence P ( C|D ) , P ( S|C , D ) and Pcf ( S|D ) become P ( C ) , P ( S|C ) and Pcf ( S ) . We will describe how these probabilities are learned from data later in this section . In [ 1 ] , we proposed to re rank ASR WCNs to prefer paths containing a query subject . We defined a query subject as the core concept of the query , which is the must match part . Each valid query has a query subject . For examples , night club is the query subject in night clubs open christmas day . Query open doesn’t have the query subject . We represent the query subject probability as Psb(S ) and introduce it as the forth component to the parsing optimization . Equation 2 hence is extended to Equation 3 .
∗
( S
, C
∗|Qwcn ) = argmax {S,C|Qwcn}
P ( S|C ) ∗ P ( C)λc ∗ Pcf ( S)λcf ∗ Psb(S)λsb
( 3 )
We approximate the prior probability P(C ) using an ngram model on the concept sequence . Training examples of concept sequences can be created from annotated queries . We model the segment sequence generation probability P ( S|C ) using independence assumptions , assume each segment in S is generated independently by C . Contextual reliance on concept level is captured in P ( C ) . A corpus of instantiations of the concept ck are needed to infer condii |ck ) . This corpus can be a union tional probabilities P ( W j of query logs , database field values and human generated examples . There are many ways to model P ( S|C ) . In this i |ck ) paper , we take a simple approach , approximating P ( W j as relative frequency .
We estimated the query subject probability Psb(S ) through mining query logs , which latently encapsulate the most likely subject phrases . Subject phrases are phrases appearing often as a complete query . More details were reported in [ 1 ] .
3 . EXPERIMENTS
We applied the proposed approach on a mobile voice search application , Speak4It . It is a system developed by yellowpages.com and AT&T Labs Research , which allows users to speak local search queries in a single utterance and returns information of relevant businesses .
Our training data consists of 18 million web queries to http://wwwyellowpagescom/ , where a query comprises two fields , SearchTerm and LocationTerm , 11 million unique business entries , and 15 thousand annotated voice queries . The parsing task is to parse a voice query into two layered concepts . The taxnomy includes 2 coarse grained concepts ( SearchTerm and LocationTerm ) and 8 fine grained concepts ( eg Landmark ) . We tested our approaches on 1000 randomly selected voice queries from a newer time period than the training data . We measure the parsing performance using concept extraction accuracy via exact string match .
We report the first level parsing performance in Table 1 . The Transcription column presents the parser ’s performances on human transcriptions ( ie word accuracy=100 % ) of the speech . The 1 best and WCN respectively corresponds to ASR 1 best and WCN output . ASR word accuracy is 672 % The promising aspect is that we improved SearchTerm extraction accuracy by 2.0 % when using WCN as input . Performance on the second level concepts will be published in near future . Though 63.0 % SearchTerm extraction accuracy on ASR output is low , search performance is much higher for its robustness to certain ASR errors such as restaurant being misrecognized as restaurants .
Slots
1 best WCN Transcription
SearchTerm 61.0 % 63.0 % LocationTerm 88.5 % 88.4 %
95.1 % 97.4 %
Table 1 : Concept Extraction Accuracy
4 . CONCLUSIONS
This paper described a statistical approach to voice query parsing . We demonstrated the effectiveness of this approach on a mobile search application . 5 . REFERENCES [ 1 ] J.Feng , S . Bangalore , and MGilbert Role of natural language understanding in voice local search . In INTERSPEECH , 2009 .
[ 2 ] A . S . L . Mangu , E . Brill . Finding consensus in speech recognition : Word error minimization and other applications of confusion networks . Computation and Language , 14(4):273–400 , October 2000 .
[ 3 ] B . T . F . Peng . Unsupervised query segmentation using generative language models and wikipedia . In Proceedings of WWW 2008 , 2008 .
01gary/0323cherry/4104dairy/1442jerry/39562crites/0652christ/2857creek/3872queen/1439kreep/4540kersten/20453springfield/0303in/13464springfield/1367_epsilon/02945/1missouri/7021WWW 2010 • PosterApril 26 30 • Raleigh • NC • USA1090
