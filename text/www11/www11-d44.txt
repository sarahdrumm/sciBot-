Measuring a Commercial Content Delivery Network ∗
Sipat Triukose
Zhihua Wen
Michael Rabinovich
Case Western Reserve University
EECS Department
{firstlast}@caseedu
ABSTRACT Content delivery networks ( CDNs ) have become a crucial part of the modern Web infrastructure . This paper studies the performance of the leading content delivery provider – Akamai . It measures the performance of the current Akamai platform and considers a key architectural question faced by both CDN designers and their prospective customers : whether the co location approach to CDN platforms adopted by Akamai , which tries to deploy servers in numerous Internet locations , brings inherent performance benefits over a more consolidated data center approach pursued by other influential CDNs such as Limelight . We believe the methodology we developed for this study will be useful for other researchers in the CDN arena .
Categories and Subject Descriptors C21 [ COMPUTER COMMUNICATION NETWORKS ] : Network Architecture and Design
General Terms Measurement , Performance , Experimentation
Keywords Content Delivery Networks , Akamai , CDN Performance
1 .
INTRODUCTION
After a period of industry consolidation , there is a resurgence of interest in content delivery networks . Dozens new CDN companies have emerged and become a critical part of the Web infrastructure : Akamai alone claims to be delivering 20 % of all Web traffic [ 3 ] .
Two main “ selling points ” of a CDN service are ( a ) that they supply on demand capacity to content providers and ( b ) that they improve performance of accessing the content from user perspective because they deliver the content from a nearby location . This paper focuses on the second aspect , and considers the performance of the current Akamai ∗ This work is supported by the National Science Foundation under Grant No . CNS 0721890 . S . Triukose is currently with NICTA ( National ICT Australia ) and Z . Wen with Microsoft .
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . Distribution of these papers is limited to classroom use , and personal use by others . WWW 2011 , March 28–April 1 , 2011 , Hyderabad , India . ACM 978 1 4503 0632 4/11/03 . platform and the question of how widely dispersed a CDN platform needs to be to provide proximity benefits to the users .
Our study of platform distribution is motivated by the ongoing active discussion on the two main approaches in CDN design that have emerged over the years . One approach , exemplified by Akamai and Digital Island ( currently owned by Level 3 Communications ) , aims at creating relatively limited capacity points of presence at as many locations as possible . For example , Akamai platform in 2007 spanned more than 3,000 locations in over 750 cities in over 70 countries , with each location having on average less than ten servers , and their footprint has grown further since then ( see http://wwwakamaicom/hdwp p2 ) The other approach utilizes massive data centers , comprising thousands of servers , but in many fewer locations . The examples of providers pursuing this approach include Limelight and AT&T . Limelight currently lists 20 data centers on its web site [ 13 ] .
In practice , there may be complex reasons contributing to this design choice . On one hand , Akamai attempts to obtain free deployment of its cache servers at some ISPs in return for reducing the ISPs’ upstream traffic thus reducing the cost of running its platform . On the other hand , consolidated platforms pursued by Limelight and AT&T can be more manageable and often are deployed in data centers owned rather than rented by the CDN . Yet a large number of locations is often cited as directly translating to improved client proximity and content delivery performance . Thus , without passing judgment on the overall merits of the two approaches , we focus on this marketing claim and address the question : how many locations is enough from the client observed performance perspective ? Or , said differently , when does one hit the diminishing return in terms of improving client proximity by increasing the number of locations ? In fact , by considering performance implications of platform consolidation , our study addresses an important aspect of the two approaches and thus contributes to the debate regarding their overall strengths .
Note that the number of locations is orthogonal to the overall CDN capacity and hence to the CDN ’s ability to provide capacity on demand to content providers . By provisioning enough network connectivity , power supply , and servers at a given data center , one can assemble a very large aggregate CDN capacity at relatively small number of data centers . For example , from the statement on Limelight ’s website that “ Each Limelight Networks Delivery Center houses thousands of servers ” [ 13 ] one can infer that Limelight has at least 20,000 servers across their 20 data centers ,
WWW 2011 – Session : Performance and SystemsMarch 28–April 1 , 2011 , Hyderabad , India467 which is at worst three times as few as Akamai , despite having two orders of magnitude fewer locations . In terms of network capacity , Limelight had 2.5Tbps aggregate bandwidth in August 2009 [ 12 ] ; while we could not find a similar number for Akamai , this is more than the aggregate peak traffic it has delivered [ 2 ] .
One would assume that content delivery networks would have done this study themselves long time ago . This might be true we will never know . However , proprietary research is not open to public ( and public scrutiny ) and is often driven by vested interests . This paper attempts to answer the above question by examining Akamai performance . We chose Akamai because it is the dominant CDN provider , both in terms of the market share and size . Our general approach is to study how performance of Akamai accelerated content delivery would suffer if it were done from fewer data centers . Considering performance implications of data center consolidation by the same CDN is important because it eliminates a possibility that unrelated issues in different CDNs could affect the results . An abstract of our preliminary results appeared in [ 24 ] . The current paper present the complete study .
Our work contributes insights into the following aspects of content delivery networks :
• CDN performance improvement . CDNs offer capacity on demand , and hence overload protection , to subscribing content providers . But do CDNs improve user experience during normal load ? Krishnamurthy et al . [ 11 ] compared the performance of different CDNs , but to our knowledge ours is the first study that provides an independent direct estimate of the performance improvement of Akamai accelerated downloads . In particular , we consider both performance improvement Akamai offers to content providers and the quality of Akamai server selection when it selects a cache for a download .
• The extent of platform distribution . We address a question to what extent a large number of points of presence improves CDN performance . While considering just one aspect – performance – of this issue , this contributes to the debate on the merits of the highly distributed vs . more consolidated approaches to CDN design from the customer perspective .
In addition to the above performance insights , we hope the methodology we develop to obtain them will be useful for others conducting research in this area .
2 . RELATED WORK
A number of CDNs offer acceleration services today [ 19 , 1 , 13 , 8 , 17 ] . Our study could be useful for them as they decide on their infrastructure investment priorities and for their customers in selecting a CDN provider .
Several papers have studied the performance of CDNs . Krishnamurthy et al . compared the performance of several CDNs in existence at the time of the study [ 11 ] . This study provided the first indication that the CDN footprint might not directly translate into performance . Ours is a direct study of the performance implications of data center consolidation by the same CDN .
Canali et al . [ 5 ] study user perceived performance of CDN delivery , focusing on longitudinal aspects , by monitoring
Figure 1 : Content Delivery Network the CDN delivery performance from three locations for two years . Su and Kuzmanovic analyzed Akamai ’s streaming content delivery from the security perspective [ 22 ] . We concentrate on regular Web traffic delivery by Akamai , which is engineered differently from streaming .
Biliris et al . considered performance implications of accelerating the same content through different CDNs for different users [ 4 ] . It indicated that no single CDN provided adequate coverage for all Internet users . Coupled with our current results that Akamai would not suffer performance degradation from consolidating their data centers , this would indicate ( if these findings still hold today ) that CDNs may be able to optimize their facility location .
Su et al .
[ 21 ] investigated a possibility to leverage Akamai ’s server selection for finding high quality overlay routes on the Internet and in the process considered various performance aspects of Akamai . Poese et al . [ 16 ] observed that CDN server selection could be improved through help from the clients’ ISP . These studies require the discovery of Akamai ’s servers ; our experience in this regard should prove useful for future investigations of this kind .
3 . BACKGROUND : CONTENT DELIVERY
NETWORKS
A CDN is an infrastructure for efficient delivery of Webrelated content to Internet users . A CDN operator ( eg , Akamai ) deploys a large number of edge servers throughout the Internet . The content provider “ outsources ” certain hostnames to the CDN ’s domain name service , so that when a user clicks on an outsourced URL , the content is downloaded through a nearby edge server rather than from the content provider ’s site .
The basic mechanism is illustrated in Figure 1 . To accomplish the outsourcing of hostname imagesfirm xcom , firmx ’s DNS server redirects DNS queries for outsourced hostnames to CDN by returning a CNAME ( canonical name ) type response to the user , eg , “ imagesfirm xcomCDNnamenet ” ( step 2 in the figure ) . The user would now have to resolve the canonical name , with a query that will arrive at the DNS system for the CDN name.net domain , operated by the CDN ( step 3 ) . The latter selects an appropriate edge server ( typically close to the client as long as server load and network conditions allow ) and responds to the query with the selected server IP address , enacting the content download from the selected server ( step 5 ) . The edge server acts as a cache – it typically provides the content from its local storage ( if it has the content from previous requests ) or it
WWW 2011 – Session : Performance and SystemsMarch 28–April 1 , 2011 , Hyderabad , India468 ery process . By clustering these edge servers by city1 and autonomous system , we conservatively estimate we discovered at least 308 locations . The real number is likely higher as the discovered edge servers represented 864 distinct /24 prefixes . Clearly , our discovered portion of Akamai platform represents only a subset of the Akamai ’s servers and locations ; however , as we discuss in Section 6.1 , this does not impact our conclusions .
4.2 Overriding CDN Edge Server Selection
In assessing CDN ’s performance , our performance metric is the effective throughput of the page download as reported by the curl tool [ 6]2 . To measure download performance from a particular edge server rather than the server of Akamai ’s choosing , we need connect to the desired edge server directly using its raw IP address rather than the DNS hostname from the URL . We found that to trick an arbitrary Akamai ’s edge server into processing the request , it is sufficient to simply include the HTTP host header that would have been submitted with a request using the proper DNS hostname .
For example , the following invocation will successfully down load the object from a given Akamai edge server ( with IP address 20613212275 ) by supplying the expected host header through the “ H ” command argument : curl H Host:akbuycom \
"http://20613212275/db_assets /large_images/093/207502093.jpg"
4.3 Controlling Edge Server Caching
Some of our experiments require forcing the HTTP requests to be fulfilled from the origin server and not from the edge server cache . Normally , requesting a cache to obtain an object from the origin server could be done by using HTTP ’s Cache Control header . However , as we will show shortly , Akamai ’s edge servers do not honor the CacheControl header in client requests [ 23 ] . To manipulate the edge server to obtain the content from the origin , we exploit the following observation . On the one hand , modern caches use the entire URL strings , including the search string ( the optional portion of a URL after “ ? ” ) as the cache key . In particular , a request for foo.jpg?randomstring will be forwarded to the origin server because the cache is unlikely to have previously stored an object with this URL . On the other hand , origin servers ignore unexpected search strings in otherwise valid URLs . Thus , the above request will return the valid foo.jpg image from the origin server .
To verify this technique , we performed a series of downloads from “ planetlab1iiiu tokyoacjp ” of an Amazon object ” http://g ec2images amazoncom/images/G/01/nav2/gamma/n2CoreLibs/n2CoreLibs utilities 12475js ” using edge server 6025418589 By selecting the client and edge server that are close to each other but likely distant from the origin server ( both the client and the edge server are in Japan while the origin is likely to be in the US ) , we hope to be
1We used the GeoIP database from MaxMind [ 14 ] ( commercial version ) to obtain server ’s geographical information . GeoIP was able to map 98.13 % of our discovered edge servers . 2We initially used wget for this purpose but encountered a persistent accuracy problem with wget on some Planet Lab nodes .
Figure 2 : A typical Google map snapshot of active DipZoom measurement points . obtains the content from the origin site , forwards it to the client , and stores it for future use .
In fact , Akamai employs a two level DNS system ( not shown in the figure for simplicity ) : the centralized highlevel servers return NS type responses to queries , redirecting them to nearby low level DNS servers , and the latter perform the actual hostname to IP resolution . The actual platform architecture involves addressing many other complex issues . For example , Sherman et al . describe Akamai ’s sophisticated configuration management system [ 20 ] .
4 . METHODOLOGY
This section describes the major experimental approaches we used to conduct our study . 4.1 Edge Server Discovery
Most CDN investigations involve the discovery of the CDN ’s edge servers [ 11 , 5 , 21 ] . The basic technique for edge server discovery is well established and involves simply identifying and resolving an outsourced hostname . For example , nslookup on “ imagesamazoncom ” or its canonical name “ a1794lakamainet ” will usually return at least two IP addresses of edge servers .
The challenge , however , arises when one needs to harvest a large collection of edge servers since this requires hostname lookups resolutions from different geographical locations . To avoid the complexities of gaining access to and communicating with multiple hosts , we utilized DipZoom , a peer to peer Internet measurement platform , for this purpose [ 7 , 26 ] . DipZoom has a large number of measurement points around the world , and it allows global experiments to be implemented as local java applications , without the need to explicitly interact with the individual measurement points . While the available DipZoom measurement points vary in time , there are typically more then 400 active MPs available , mostly on PlanetLab nodes but also on some academic and residential hosts . As an indication of geographical coverage , Figure 2 shows a typical Google map snapshot of active DipZoom peers cropped from [ 7 ] .
In our discovery process , we compiled canonical names outsourced to Akamai by downloading and examining Web page sources of the 95 Akamai customers listed on the Akamai ’s Web site . We then periodically ( twice a week ) performed DNS resolution of these names from a large number of network locations over a period of 13 weeks . As the result , we harvested just under 12 , 000 Akamai edge servers , of which 10 , 231 servers were pingable at the end of the discov
WWW 2011 – Session : Performance and SystemsMarch 28–April 1 , 2011 , Hyderabad , India469 Target & Parameter
/foo.js?rand1 /foo.js?rand1 /foo.js?rand1 /foo.js?rand2 /foo.js?rand2 /foo.js?rand2 no cache , /foo.js?rand2 no cache , /foo.js?rand2 no cache , /foo.js?rand3
Throughput 43 KB/s 7750 KB/s 5300 KB/s 61 KB/s 8000 KB/s 4850 KB/s 5070 KB/s 6780 KB/s 56 KB/s
1 2 3 4 5 6 7 8 9
Throughput
RTT
10000
1000
100
10
1
) s / B K
( t u p h g u o r h T
1000
800
600
400
200
) s m
(
T T R
0.1
0 0 1000 2000 3000 4000 5000 6000 7000
Trial(s )
Table 1 : Initial vs . repeat download performance of an object with an appended random search string .
Figure 3 : Relation between download throughput and RTT . able to distinguish download from cache vs . from the origin by the performance difference .
Table 1 lists the throughput of the download series ( the long object URL is replaced with “ foo.js ” for convenience ) . Download 1 is a non cache download and shows poor performance . Downloads 2 and 3 are the downloads with the same random string ; they exhibit distinctly higher performance , reflecting the fact that these requests are fulfilled from the cache , which stored this URL as the result of the first download . The downloads 4 6 confirm this behavior with a different random string . However , downloads 7 and 8 , using the previously seen URLs with a no cache header , produce similarly high performance , indicating they are processed from the cache despite the no cache directive . Yet download 9 , with the no cache directive and a new random string , exhibits performance comparable to downloads 1 and 4 and indicative of non cache downloads . This shows that the No Cache directive of the HTTP Cache control header in client requests does not affect caching by Akamai .
In summary , we can precisely control the caching behavior of Akamai ’s edge servers by appending search strings to image URLs . The first appearance of a string will cause the download to occur from the origin server while the subsequent downloads of the same string from the same edge server will occur from the edge server cache . A series of retrievals of the same content with different random strings will cause the edge server to obtain the original copy every time .
4.4 Assessing Client Side Caching Bias
Most of our experiments below involve comparing download performance from different Akamai locations . A crucial question is a possible bias introduced by transparent caching potentially used by the ISPs through which our measuring points connect to the Internet . Indeed , a cached download would then be performed from the cache regardless to which Akamai location we ostensibly direct the HTTP request .
To estimate the extent of transparent cache use by the ISPs utilized by DipZoom MPs , we consider how HTTP download performance from a given Akamai edge server depends on its ping round trip latency . If transparent caching is widely used , we would see no dependency .
To study these correlations , we perform a set of four curl downloads , five pings , and a traceroute from each measuring point to various edge servers . For HTTP download performance , we average the download throughputs reported by the last three curls ( the first curl ensures that the object is in the edge server cache ) ; for ping RTT , we average the
RTTs from the five pings . We use an outsourced cacheable 437 , 688B Amazon object for curl downloads .
We used 385 measuring points and 20 widely distributed edge servers in this experiment . To ensure that target edge servers are widely distributed across the world , we clustered all the discovered edge servers into twenty clusters based on the estimated distance between the servers ( see Section 6 ) and selected centers of the clusters as our targets .
Figure 3 plots the values of the ping RTT and curl download throughput in each trial , sorted in the order of the increasing throughput . ( The total number of trials is less than 385 × 20 because not all measurements were successful . ) The figure shows clear dependency of the download performance on ping distance . Quantitatively , the two metrics show Spearman ’s rank correlation coefficient of −0.8074 indicating a strong dependency and thus no significant use of client side ISP caching .
In fact , we later discovered a direct method to detect a transparent cache . We deploy our own Web server with a cache able object and request it twice from every measuring point . We then examine the server’ access log . If the downloads from a given MP are filtered through an ISP cache , the log would contain only one request from this MP ( the other would be terminated by the ISP cache ) ; otherwise the log would contain both requests . We tested 527 measurement points ( as many as we could assemble ) and found only three3 with a single request in our log . Thus , the overwhelming majority ( 99.43 % ) of MPs had no transparent caches between them and the Web servers . While this test was conducted a few months later than the rest of our study , the two experiments described here give us a high level of confidence that client side caching does not bias our findings .
4.5 Measuring Edge Server Performance
In Sections 5 and 6.1 , we use download performance as the “ goodness metric ” of a given edge server , and we express it as effective throughput , which is the object size divided by the download time . Given that the performance of downloads of different sized objects is predominantly affected by different network characteristics ( bandwidth for large objects and RTT for small objects ) , we verify our main findings on objects of a wide size range ( from 10K to 400K ) . In addition , Section 6.3 uses round trip time from the client as the goodness metric of a given server .
3These MPs 12dynipnusedusg , ( planetlab1exp mathuni essende , and 14712695167 ( unknown hostname , Chicago ) .
13713225012
Singapore ) , were
( nusnet 250132252152193 Essen ) ,
Germany ,
WWW 2011 – Session : Performance and SystemsMarch 28–April 1 , 2011 , Hyderabad , India470 1
0.8
0.6
0.4
0.2
F D C
0
0
5 cache / non cache cache / origin
10 Ratio
15
20
F D C
1
0.8
0.6
0.4
0.2
0 cache / non cache cache / origin
0
2
4
6
10
8 Ratio
12
14
16
18
Figure 4 : The performance benefits of Akamai delivery .
Figure 5 : The residential client performance benefits of Akamai delivery .
5 . PERFORMANCE OF AKAMAI CDN
This section considers how well the existing Akamai platform fulfills its mission of accelerating content delivery . First , we study how it affects the end user download performance , then consider the quality of its server selection .
5.1 Does a CDN Enhance Performance ?
In general , a content delivery network can improve Web performance in two ways : by providing overload protection to Web sites and by delivering content to users from nearby locations . In this study , we are focusing on the latter aspect . To answer this question precisely , one would need to compare download performance from a CDN with the direct download of the same object from the origin server . Unfortunately , we found that the origin servers hosting Akamaidelivered content are usually hidden from the Internet users : our attempts to request this content from the origin sites that host the container pages were not successful .
Thus , we resort to two estimates of the download performance from the origin servers . First , we estimate it by the download time of the Akamai delivered content when we prevent caching at the edge servers . This actually measures the Akamai cache miss performance and hence adds the miss penalty to the true value . But it can indicate the performance of the direct download , assuming Akamai infrastructure is highly optimized . Second , we estimate the origin server performance by the download performance of a different object of similar size , which is not outsourced to CDN delivery , from the same Web site . Even if the nonoutsourced object is served from a different server than the one used by Akamai on a miss , the performance of this download indicates the performance that the Web site can achieve without resorting to an external CDN .
We used 377 measuring points for these experiments . For the CDN delivered content , we use an outsourced Amazon object with size 50K , and we use the methodology in Section 4.3 to control its caching . For the download from the origin , we found a non outsourced static page4 of 55K bytes on the Amazon website . ( We assume the page is static by the fact that multiple downloads from different vantage points resulted in the same content . ) Obviously , the results in this subsection are strictly applicable only to Amazon , as another customer may have a differently provisioned origin site with different performance . However , they offer a specific data point for a large , and presumably well provisioned , content provider .
4http://72212065/gp/help/customer/displayhtml
F D C
1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 non cache / origin
0
0.5
1
1.5 Ratio
2
2.5
3
Figure 6 : The comparison of no cache download through Akamai and download from origin server .
Figure 4 plots the cumulative distribution functions of the cache to no cache and cache to origin throughput ratios in all the collected measurements . In both cases , values over 1 mean the CDN improves performance over direct delivery ( under the corresponding estimate of the direct delivery performance ) and values below 1 indicate the opposite . The figure indicates that a CDN promises a significant performance improvement under both estimates of the direct delivery performance . CDN delivery outperforms both nocache and origin delivery in 98 % and 96 % of cases respectively . Furthermore , in 67 % and 41 % of the cases , the CDN delivery is at least five times faster than no cache and origin delivery respectively . A possible reason for such dramatic improvement could be because most of our measuring points are well connected to the Internet and do not experience the last mile bottleneck .
Therefore , to see the benefits for residential clients , we reproduce , in Figure 5 , the same results but only for measuring points with maximum download bandwidth less than 1.5Mbps – typical residential connectivity . For these measuring points , the performance benefits drop significantly . CDN delivery is now at least five times faster that origin delivery only in 2.3 % of the cases . However , CDN delivery still improves the download performance of residential clients : the CDN delivery outperforms no cache in 95.5 % of cases and origin delivery in 91 % of cases .
Finally , the gap between the two curves in both figures indicates the Akamai global cache miss penalty , ie , the overhead the edge servers add for a request when the requested object has to be fetched from the origin server . We quantify this penalty in Figure 6 , which plots the CDF of the nocache to origin throughput ratio . It shows that in 70 % of the cases , origin downloads are faster than no cache down
WWW 2011 – Session : Performance and SystemsMarch 28–April 1 , 2011 , Hyderabad , India471 loads , and in 50 % of the cases they are at least twice as fast . This indicates that Akamai miss penalty can be significant . A potential limitation of the experiment in this subsection is that it considers performance of a single Web object and not entire page downloads . Pages typically include multiple embedded objects , which may affect direct and CDNaccelerated downloads differently . Indeed , depending on the setup of the CDN service , the browser can download the initial container HTML object directly from the origin site and the embedded objects from the CDN ’s edge server . Thus , the CDN delivery could entail an extra DNS resolution ( to resolve host names of embedded URLs ) and an extra TCP connection establishment ( to establish connections to both the origin and edge server ) . However , this should not materially affect our conclusions because these effects are amortized over the embedded objects on a page and often over several pages in a session ( if the user accesses these pages in short succession so that cached DNS responses and persistent connections remain valid between page accesses ) . Akamai allows clients to cache DNS responses for 20 seconds ( although many use them far longer [ 15] ) . We also probed around 1000 Akamai edge servers for persistent connection support and found they maintain them for unusually long time 500 seconds after a request ( compared to Apache ’s default of 15s ) . This provides ample opportunity for connection reuse .
5.2 How Good Is Akamai Server Selection ?
When a client initiates the download to a content cached by Akamai , the best edge server for this particular client and content is selected dynamically . This section investigates how good is the Akamai selection algorithm from the client performance perspective .
To answer this question , we selected one customer , Amazon , and measured the download throughput of an Akamaidelivered object of 50K bytes from 391 measuring points . Out of 10 , 231 edge servers we discovered , 430 servers were discovered for Amazon . At each of the 391 measuring points , 80 edge servers are randomly selected from these 430 servers , and the object is downloaded from the Akamai selected edge server and from each of the 80 alternative edge servers , using the methodology of Section 4.2 to download from a particular edge . Because the entire experiment from a given measuring point takes considerable time , we always perform a pair of measurements one right after the other , one for the Akamai selected server , and one for a given alternative edge server . Note that the Akamai selected server may change from one pair to the next . Finally , we use the techniques of Section 4.3 to ensure that the edge server delivers the object from its cache in each case .
Figure 7 shows , for each measuring point , the percentage of time that the Akamai selected server performed better than the alternative server , in the increasing order of this metric . For example , at measuring point number 200 , it shows that roughly 80 % of the random 80 edge servers were outperformed by the Akamai selected server . The server selection was less successful for the 199 measurement points numbered lower and more successful for the the 191 measuring points numbered higher . Overall , this experiment confirms an early limited study [ 9 ] that CDNs rarely select the best edge server but successfully avoid the worst ones . Indeed , in roughly 75 % of the MPs , the Akamai selected server outperformed half of the alternatives . s r e v r e S d e m r o f r e p u O t f o n o i t c a r F
1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0
0
50
100 150 200 250 300 350 400
Measuring Point Number
Figure 7 : The fraction of servers outperformed by the Akamai selected server .
) s / e t y B M
( e c n e r e f f i
D t u p h g u o r h T
4
2
0
2
4
6
Average Difference Maximum Gain Minimum Loss
0
50
100 150 200 250 300 350 400
Measuring Point Number
Figure 8 : Download throughput difference between Akamai selected and an alternative edge server
Figure 7 shows how many times Akamai selected servers perform better or worse than the alternatives but does not say by how much . To provide this information we plot on Figure 8 the average difference , the maximum gain , and the maximum loss of throughput of the Akamai selected server vs . the alternatives . The average difference is taken over all 80 alternative servers ; negative values indicate the alternative servers performed better on average and positive values correspond to the advantage of the Akamai selected server . Maximum gain and maximum loss are the throughput differences of the Akamai selected server over , resp . , the slowest and fastest alternative server . If positive , the maximum gain shows the advantage of the Akamai selected server over the worst alternative . Similarly , if negative , the maximum loss shows the maximum penalty vs . the best alternative .
The “ average difference ” curve shows that there are 147 measuring points where Akamai selected server delivers on average inferior performance , by at most 255 KB/s for measuring point 1 . However , Akamai selected servers have superior performance in average on 244 measuring points with up to 3.38 MB/s average advantage . Interestingly , although Akamai selected servers have superior performance on average , the “ maximum loss ” curve shows that , in a number of cases , the best alternative servers outperform Akamaiselected servers significantly , by up to 6.35 MB/s .
In summary , Akamai usually makes good server selection decisions , but there is a substantial room for further improvements .
WWW 2011 – Session : Performance and SystemsMarch 28–April 1 , 2011 , Hyderabad , India472 6 . PERFORMANCE OF CONSOLIDATED
AKAMAI CDN
Akamai attempts to deliver content to users from nearby servers by placing edge server in a large number of network locations . The question we pose is : how much would it cost in performance if the number of data centers were reduced significantly ?
We first describe our technique for data center consolidation , then present a study using measurements from DipZoom measurement points , and conclude with a live study involving real Internet users . Both studies show that a considerable consolidation is possible without a noticeable effect on performance . 6.1 Data Center Consolidation
Our methodology for studying a hypothetical consolidated CDN is as follows . We first group edge servers that we believe are close to each other into hypothetical consolidated data centers , which we refer to as big clusters . We then “ place ” each big cluster into the location of a central server in the cluster called the representative of the cluster . To this end , for a given client , we replace the server selected by Akamai , Sakam with the representative of the cluster to which Sakam belongs . In other words , we assume that all clients that would have been sent to any server in a given big cluster in the existing platform , will be served from the cluster center in the consolidated case . We then consider performance implications of this replacement by comparing the performance of the downloads from both servers .
We would like to stress again that our study only considers the implication of CDN consolidation on the proximity of clients to data centers : the aggregate CDN capacity , both in terms of network bandwidth and server capacity , is orthogonal to the number of data centers as fewer locations can be compensated by higher processing and connectivity capacity at each data center . Because our probes impose trivial load on Akamai servers , the performance of our downloads reflect the proximity between servers and clients under normal load . In fact , any server load differences in individual server pair comparisons should work against platform consolidation because Akamai avoids overloaded servers in its server selection while we use cluster centers regardless of their load .
To cluster edge servers , we start by estimating the pairwise network distances between all the servers using a recently proposed dynamic triangles method [ 25 ] , and then group nearby servers into a predefined number of big clusters by applying a hierarchical clustering algorithm to the resulting distance matrix . ( We use the so called hierarchical clustering with complete linkage method , following by the cut the tree procedure , both provided by the R software [ 18 ] for this computation . ) We could equally use other techniques , such as network aware clustering [ 10 ] . However , our goal is to show that we can consolidate large numbers of servers into fewer locations , and how we select servers for consolidation is immaterial as long as we find the performance of the consolidated platform comparable . In other words , imperfect clustering makes our finding conservative : Better clustering could lead to a better constructed consolidated platform with even fewer data centers .
Similarly , a consequence of incomplete discovery of Akamai ’s platform is that we have fewer potential locations for consolidated data centers ( indeed , our methodology only
F D C
1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0
150 Clusters
100 Clusters
60 Clusters
40 Clusters
20 Clusters
0
0.5
1
1.5
2
2.5
3
3.5
4
Ratio
Figure 9 : The performance of a consolidated Akamai platform with different number of data centers . chooses between discovered edge servers as potential consolidated locations ) . This makes our finding that significant consolidation is possible , again , more conservative . In other words , the incomplete discovery does not undermine our findings regarding the consolidation of the locations that we did discover .
6.2 DipZoom Experiment
To judge the performance of the hypothetical consolidated Akamai platform , we compare the performance of downloads from the current and consolidated platforms using DipZoom measurement points . We had 412 measurement points in this experiment . From each measurement point , we downloaded the object of a given size from the Akamai selected server and from the center of its cluster in the consolidated platform . The center is represented by a randomly selected available server from the five closest servers to the center of the cluster5 .
To avoid the bias from changing network conditions , we perform each pair of downloads in immediate succession . Further , we pre request each object from both servers to ensure the server is delivering the object from its cache , thus excluding the possibility of skewing results by the cache miss penalty . Having placed the object into the servers’ cache , we perform three downloads from either server and take the average as its download performance . We compare the performance of the existing and consolidated Akamai platforms by the ratio between the download throughput in both platforms . The performance ratio more than 1 means Akamai ’s existing configuration yields better download performance than the consolidated configuration and vice versa .
We grouped the 10 , 231 edge servers into 150 , 100 , 60 , 40 , and 20 data centers , thus considering the varying degree of consolidation . To check if our conclusions might depend on the size of downloaded objects , we controlled the size of the downloads precisely by finding a large ( over 400K ) object6 and specifying an appropriate “ Range ” header in our HTTP request . We verified that Akamai servers honor range requests .
Figure 9 presents the CDF of the download throughput ratios of the existing to consolidated configurations . The figure reflects data points obtained by downloading an out
5We choose from five closest servers instead of always using the centroid node to reduce an undue effect of a single server on the entire experiment . 6http://<>/images/G/01/digital/video/preview/Player V16565163 .swf
WWW 2011 – Session : Performance and SystemsMarch 28–April 1 , 2011 , Hyderabad , India473 F D C
1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0
400k Download Size
300k Download Size
200k Download Size
100k Download Size
50k Download Size
10k Download Size
0
0.5
1
1.5
2
2.5
3
3.5
4
Ratio
( a ) 60 Data Centers
F D C
1
0.8
0.6
0.4
0.2
0
400k Download Size
300k Download Size
200k Download Size
100k Download Size
50k Download Size
10k Download Size
0
0.5
1
1.5
2
2.5
3
3.5
4
Ratio
( b ) 40 Data Centers
Figure 10 : The performance of a consolidated Akamai platform with different target object size . sourced Amazon object of size 150K , 100K , 50K , and 10K from 412 measurement points world wide . The curves reflect 5522 ratios ( some downloads were unsuccessful ) .
As seen in Figure 9 , consolidating edge servers into 150 , 100 , and 60 data centers does not cause noticeable performance degradation : the consolidated and current platforms show performance advantage over each other with equal probability . Only when we get down to 40 and 20 data centers , does the original platform start outperforming the consolidated configuration – 60 % and 70 % of the time for 40 and 20 data centers , respectively . Furthermore , as Figure 10 shows , these results are largely independent of the target object size .
The above experiment reflects our mix of measurement points , which are skewed towards well connected hosts . Because CDNs are often used by high volume consumer oriented sites , where users may have lower capacity connections , we consider the performance of consolidated configurations separately for measurement points with different download bandwidth . Specifically , we group the measurement points by the maximum download throughput observed in the course of the experiment of Figure 9 .
The results , shown in Figure 11 , indicate that the existing Akamai configuration with large number of data centers favors well connected users . For measurement points with over 6Mbps bandwidth , the existing configuration outperformed consolidated configurations once they get down to 60 data centers . However , the less the bandwidth of the measurement points the less the advantage of the existing configuration . Given this trend , and because CDNs are often used by high volume consumer oriented sites , a pertinent question is how the consolidation may affect typical residential users .
Thus , we compare , in Figure 12 , the performance of existing vs . consolidated configurations for all measurement points with bandwidth below 1.5Mbps , which is a typical download bandwidth for DSL users . Figure 12 shows that these clients would not see noticeable performance difference if the servers were further consolidated into 40 data centers . Overall , we conclude that one could consolidate our discovered portion of Akamai platform to 60 data centers , and for typical residential users , even to 40 data centers without noticeable performance penalty . Even compared with our conservative approximation of 308 original data centers , this represents significant consolidation . However , as we mentioned , the real number of Akamai locations represented in our study is likely higher , which makes our findings even more significant .
6.3 A Live Study
The study of the previous subsection measured real down loads but performed them from DipZoom measurement points . In this section , we perform live measurement from a larger number of vantage points and from real Internet users but measure the latency between the users and the edge servers . We built a Web page7 with an AJAX application that , when loaded , measures latency to the server that Akamai selects for this browser as well as to a list of other Akamai edge servers , and reports the results to us . We requested a midsize commercial company to embed our special page into a zero sized frame , and we also embedded it into our own Web pages . As clients access these Web sites , we collect our measurement results .
We picked a CNAME ( a1694gakamainet , utilized by pcworld.com ) which we found is mapped by Akamai to a large number – 979 – of edge servers . These servers represent 343 different /24 networks ; using the city+AS heuristic , we estimate them to represent 168 locations .
To compare the current configuration with consolidated configurations , we partitioned the 979 servers into 10 , 50 and 100 clusters using our clustering approach . We selected 100 servers from the centers of the 100 clusters and measured the latency from clients to these servers from the AJAX application . To cut down on the number of measurements , we selected representatives of larger clusters among these 100 servers as well ( in our clustering , a larger cluster is built as a union of smaller clusters , so we could always find an appropriate server this way ) . This does not undermine our results because we have a discretion where to place our consolidated data centers .
We could not find a way to pass a custom Host header to requests sent from Javascript , which is necessary to obtain a real object from a non Akamai selected edge server ( Section 42 Thus , we submit a bogus URL that returns “ Bad Request ” in all cases . We verified with tcpdump that obtaining this response by the client involves two RTTs , allowing us to measure the latency between the client and the edge server involved .
We have collected 24,079 measurements from 2,926 client IP addresses by the time of this writing . According to the GeoIP database , these vantage points cover a wide area , representing 47 US states and 43 foreign countries , and as
7Available at http://haddockcaseedu:8000/realdistquery
WWW 2011 – Session : Performance and SystemsMarch 28–April 1 , 2011 , Hyderabad , India474 F D C
F D C
1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0
1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0
0 256 Kbps
256 512 Kbps
512 Kbps 1.5 Mbps
1.5 3.0 Mbps
3.0 6.0 Mbps
> 6.0 Mbps
0
0.5
1
1.5
2
2.5
3
3.5
4
Ratio
( a ) 100 Data Centers
0 256 Kbps
256 512 Kbps
512 Kbps 1.5 Mbps
1.5 3.0 Mbps
3.0 6.0 Mbps
> 6.0 Mbps
0
0.5
1
1.5
2
2.5
3
3.5
4
Ratio
( c ) 40 Data Centers
F D C
F D C
1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0
1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0
0 256 Kbps
256 512 Kbps
512 Kbps 1.5 Mbps
1.5 3.0 Mbps
3.0 6.0 Mbps
> 6.0 Mbps
0
0.5
1
1.5
2
2.5
3
3.5
4
Ratio
( b ) 60 Data Centers
0 256 Kbps
256 512 Kbps
512 Kbps 1.5 Mbps
1.5 3.0 Mbps
3.0 6.0 Mbps
> 6.0 Mbps
0
0.5
1
1.5
2
2.5
3
3.5
4
Ratio
( d ) 20 Data Centers
Figure 11 : The performance of a consolidated Akamai platform with different download speed . our statistical analysis will show , are sufficient to derive a meaningful result .
We consider the differences between the measured latencies from each client to its closest consolidated data center and the Akamai selected server . A negative value indicates that the consolidated platform performed better than the existing Akamai platform in the corresponding observation , while a positive value reflects an advantage of the existing Akamai platform . This assumes that the consolidated configuration performs perfect data center selection and thus should be viewed as an upper bound of the consolidation benefits . However , we note that fewer farther apart locations make server selection easier .
To avoid using correlated measurements in the analysis , we average all the measurements from the same client , so that each client will contribute only one data point to our analysis . Further , to remove possibly correlated measurements from the same network in the same locale , we use only one randomly selected client from all the clients with the same city and autonomous system according to GeoIP8 . This reduced the number of data points for our analysis from 2,926 to 2,029 .
To assess the significance of the results , we build confidence intervals for the reported means . Because the distribution of the observations is unknown , we use the nonparametric bootstrap method to estimate the population mean and median and to build the confidence interval for the mean . In particular , we used the bootstrap bias corrected accelerated ( BCa ) interval method [ 16 ] with 10,000 resampling sets and relied on Matlab provided functions that implement the core of the method .
8Note that the observations should not be averaged in this case because we do not know if in fact these measurements are all correlated .
Table 2 summarizes the results of these measurements , with confidence intervals for the means built for confidence probability 95 % . The results show that with both 100 and 50 consolidated data centers , we could still find a closer data center than the Akamai selected server for a majority of clients , and the average distance to the nearest consolidated data center across all clients is also lower . In fact , the entire confidence interval for the mean distance difference is negative , indicating that the above conclusion is statistically significant , and even the upper limit of the confidence interval indicates the RTT difference of over 40ms for 50 data centers and 70ms for 100 data centers . Only with 10 data centers do we see a mixed result : while the entire confidence interval for the average distance difference is still negative ( indicating the distance from clients to the nearest consolidated data center still smaller on average than to the Akamai selected server in the current platform ) , the median difference indicates an advantage of the current platform , indicating that current Akamai platform would perform better for a majority of clients . We also note that the median difference between Akamai and consolidated platforms is much smaller than average in all configurations . This says that the average difference is skewed against Akamai by occasional poor server selections , confirming a finding from Section 52
Overall , our results show that even with significant consolidation , better server selection can more than make up for any performance impact from consolidation .
7 . CONCLUSION
This paper presents a large scale performance study of the Akamai CDN . Using DipZoom measurement platform , we were able to discover a large number of Akamai edge servers for our study , and to utilize hundreds of vantage points for our performance measurements . To our knowl
WWW 2011 – Session : Performance and SystemsMarch 28–April 1 , 2011 , Hyderabad , India475 Configuration Sample Median Sample Mean
Bootstrap Median Bootstrap Mean 95 % conf . interval of the mean
Best in 10 16.00 −15.66 15.954417 −15.695077
[ −33.816798 , −5.129345 ]
Best in 50 −5.00 −54.43 −5.013368 −54.313225
[ −72.209521 , −43.798741 ]
Best in 100 −18.40 −81.53
−18.260679 −81.697586
[ −99.081914 , −70.692385 ]
Table 2 : The difference of RTT distance ( in milliseconds ) from clients to the nearest data center in a given consolidated platform and to the Akamai selected server in the current platform ( live clients ) .
F D C
1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0
150 Clusters
100 Clusters
60 Clusters
40 Clusters
20 Clusters
0
0.5
1
1.5
2
2.5
3
3.5
4
Ratio
Figure 12 : The performance of a consolidated Akamai platform for residential speed links . edge , ours is the first study to provide an independent direct estimate of the performance improvement of Akamaiaccelerated downloads . We further studied the quality of Akamai server selection at a large scale . A central to this paper is an evaluation , from the performance perspective , of the possibility of consolidating Akamai ’s platform into fewer large data centers . We found that quite significant consolidation is possible without appreciably degrading the platform performance .
8 . REFERENCES [ 1 ] Akamai Technologies . http://wwwakamaicom/html/technology/indexhtml
[ 2 ] Akamai Technologies . Facts and Figures . http://wwwakamaicom/html/about/facts figureshtml
[ 3 ] Akamai Technologies . Perspectives . http://wwwakamaicom/html/perspectives/indexhtml
[ 4 ] A . Biliris , C . Cranor , F . Douglis , M . Rabinovich ,
S . Sibal , O . Spatscheck , and W . Sturm . CDN brokering . In 6th Int . Web Caching Workshop , 2001 .
[ 5 ] C . Canali , V . Cardellini , M . Colajanni , and
R . Lancellotti . Evaluating user perceived benefits of content distribution networks . In Int’l Symp . on Perf . Eval . of Comp . and Telecomm . Sys . ( SPECTS ) , 2004 .
[ 6 ] cURL tool for transferring files with url syntax . http://curlhaxxse/
[ 7 ] Dipzoom deep internet performance zoom . http://dipzoomcaseedu
[ 8 ] Intelligent content distribution service . AT&T Inc . http://wwwbusinessattcom/service fam overview.jsp?repoid=ProductSub Category&repoitem=eb intelligent content distribution&serv port=eb hosting storage and it&serv fam=eb intelligent content distribution&segment=ent biz .
[ 9 ] K . Johnson , J . Carr , M . Day , and M . Kaashoek . The measured performance of content distribution networks . In 5th Web Caching Workshop , 2000 .
[ 10 ] B . Krishnamurthy and J . Wang . On Network Aware Clustering of Web Clients . In The ACM SIGCOMM , Aug . 2000 .
[ 11 ] B . Krishnamurthy , C . Wills , and Y . Zhang . On the use and performance of content distribution networks . In The First ACM SIGCOMM Internet Measurement Workshop , pages 169–182 , 2001 .
[ 12 ] Limelight Networks brings dynamic streaming to the web . http://blogllnwcom/2009/08/limelight networks brings dynamic streaming to the web/
[ 13 ] Limelight Neworks . http://wwwlimelightnetworkscom/platform/cdn/
[ 14 ] MaxMind . http://wwwmaxmindcom [ 15 ] J . Pang , A . Akella , A . Shaikh , B . Krishnamurthy , and S . Seshan . On the responsiveness of dns based network control . In ACM IMC , pages 21–26 , 2004 .
[ 16 ] I . Poese , B.Frank , B . Ager , G . Smaragdakis , and
A . Feldmann . Improving content delivery using provider aided distance information . In ACM IMC , 2010 .
[ 17 ] Rapid Edge Content Delivery Network . http://wwwrapidedgecdncom/
[ 18 ] The R project for statistical computing . http://wwwr projectorg
[ 19 ] Savvis Inc . http://wwwsavvisnet/corp/Products+Services/Digital+Content+Services/Content+Delivery+Services/
[ 20 ] A . Sherman , P . A . Lisiecki , A . Berkheimer , and
J . Wein . Acms : the akamai configuration management system . In NSDI , pages 245–258 , 2005 .
[ 21 ] A J Su , D . R . Choffnes , A . Kuzmanovic , and F . E .
Bustamante . Drafting behind akamai ( travelocity based detouring ) . In SIGCOMM , pages 435–446 , 2006 .
[ 22 ] A J Su and A . Kuzmanovic . Thinning akamai . In
The 8th ACM IMC , pages 29–42 , Oct . 2008 .
[ 23 ] S . Triukose , Z . Al Qudah , and M . Rabinovich .
Content delivery networks : Protection or threat ? In ESORICS , pages 371–389 , 2009 .
[ 24 ] S . Triukose , Z . Wen , and M . Rabinovich . Content delivery networks : How big is big enough ? ( Poster paper ) . In ACM SIGMETRICS , 2009 .
[ 25 ] Z . Wen and M . Rabinovich . Network distance estimation with dynamic landmark triangles . In ACM SIGMETRICS , pages 433–434 , 2008 .
[ 26 ] Z . Wen , S . Triukose , and M . Rabinovich . Facilitating focused internet measurements . In ACM SIGMETRICS , pages 49–60 , 2007 .
WWW 2011 – Session : Performance and SystemsMarch 28–April 1 , 2011 , Hyderabad , India476
