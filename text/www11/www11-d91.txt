Sentence Level Contextual Opinion Retrieval
Sylvester Olubolu Orimaye
School of IT , Monash University , Malaysia sylvesterorimaye@infotechmonashedumy Supervised by : Saadat M . Alhashmi and Siew Eu Gene
{saadatmalhashmi@infotechmonashedumy and sieweugene@busecomonashedumy}
ABSTRACT  Existing opinion retrieval techniques do not provide contextdependent relevant results . Most of the approaches used by state ofthe art techniques are based on frequency of query terms , such that all documents containing query terms are retrieved , regardless of contextual relevance to the intent of the human seeking the opinion . However , in a particular opinionated document , words could occur in different contexts , yet meet the frequency attached to a certain opinion threshold , thus explicitly creating a bias in overall opinion retrieved . In this paper we propose a sentence level contextual model for opinion retrieval using grammatical tree derivations and approval voting mechanism . Model evaluation performed between our contextual model , BM25 , and language model shows that the model can be effective for contextual opinion retrieval such as faceted opinion retrieval . Categories and Subject Descriptors H33 [ Information Search and Retrieval ] : Information filtering , Query formulation , Retrieval models , Search process   General Terms Algorithms , Design , Experimentation , Performance Keywords Contextual opinion , sentence level , grammatical tree derivation , approval voting 1 . INTRODUCTION Understanding subjective contributions is a complex process , especially when it involves contributors with diversified styles and knowledge of making contributions . The arrival of web 2.0 interactive medias such as web logs ( blogs ) creates an avenue whereby people display their diversities in terms of style and knowledge when making subjective contributions . To make matter worse , when people contribute , they do so in their own ways ; they write with self perception often conveyed by psychological inference ; they present contributions with different language styles , and even play upon words . The summary of the factors highlighted above is not far from sentiment or opinion , especially within a complex interactive space such as collection of blogs called blogosphere . In fact , there is
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . Distribution of these papers is limited to classroom use , and personal use by others . WWW 2011 , March 28–April 1 , 2011 , Hyderabad , India . ACM 978 1 4503 0637 9/11/03 . contribution such huge human oriented reasonable amount of interest in mining different kind of knowledge from space[29 ] . Organizations wish to know relevant opinions towards products or services rendered [ 26 ] ; individuals wish to retrieve relevant information for personal use , and the need for understanding human behaviors is becoming more apparent and necessary1 . Therefore , we believe a technique that can take into account the need for contextual understanding of sentences would be appropriate for opinion retrieval tasks . through trends
Many opinion retrieval systems avoid computational models that treats opinion as a process of language understanding [ 23 ] , in fact they are mostly probabilistic or statistical [ 38 ] . Existing opinion retrieval models presume words that belong to specific targets [ 39 ] , hence count the occurrence of such words in a given document to meet certain opinion threshold . We argue that in a particular document , words could occur in different contexts , yet meet the frequency attached to a certain opinion threshold , thus explicitly creates bias in overall opinion . For example , these two sentences , the fight for academic success and I will fight you to finish , have regular occurrence of the word “ fight ” , which could imply violence opinion upon certain threshold , whereas , the word “ fight ” has appeared in two different contexts . More explanatory examples can be found in [ 10 ] on page 345 .
Towards addressing this issue , we believe existing models and techniques in computational linguistics can be used , such as contextsensitive Combinatory Categorial Grammar ( CCG)[18 ] . We believe opinion retrieval should benefit more from the impact and aggregation of textual understanding in context [ 32 ] , rather than frequency of terms alone . 2 . RELATED WORK Existing opinion retrieval techniques do not provide contextdependent relevant results . Most of the approaches used by state ofthe art techniques are based on frequency of query terms , such that all documents containing query terms are retrieved , regardless of contextual relevance to the intent of the human seeking the opinion[12,38 ] . Little have also been done on contextual understanding of sentences used in opinionated contributions [ 26 , 32 , 40 ] . We believe frequency of query terms can not imply subjectivity alone , without establishing the context at which a term must be frequent [ 23 , 32 ] . In this work , we propose a contextdependent approach that can solve the non contextual relevance problem common to existing opinion retrieval systems .                                                              1http://wwwnytimescom/2009/08/24/technology/internet/24emotionhtml
WWW 2011 – Ph . D . SymposiumMarch 28–April 1 , 2011 , Hyderabad , India403 Some research works have treated opinion retrieval as text classification ( TC ) problem . The TC technique enables the introduction of both traditional supervised and unsupervised ML techniques with reasonable efficiencies recorded in most research works[29 ] . However , determining an effective labeling strategy for contextual opinion is still an open problem [ 27 ] . According to Pang and Lee[32 ] subjectivity can be interpreted differently in some cases as they come with different levels of challenges , such as “ agreement ” or “ disagreement ” [ 5 ] and “ winner ” or “ looser ” [ 4 ] . For example in [ 27 ] , the use of ironical words or phrases and inverted polarity in opinionated documents led to lower precision for positive opinions with 77 % accuracy . As a result of this , the choice of features for determining context in opinionated documents is still a problem factor [ 1 , 9 , 32 ] . Lexicon based opinion generation has also been used for opinion retrieval , and many research works have combined both lexiconbased and TC for retrieving opinions [ 20 ] . However , this approach is domain specific [ 9 , 31 ] , and there have been instances of conflict between opinions and lexicon . For example , a positive comment about a product could have a negative meaning in the lexicon [ 22 ] . We believe that analysis of independent words to show meaning may not necessarily reflect opinion except when words are processed together in a sentence . Probabilistic models have also been used to retrieve and rank opinions from documents[38 ] , and some level of success have been recorded by the technique . However , the probabilistic approach is full of probabilistic assumptions based on frequency of query terms [ 16 , 23 , 32 ] . For example , in [ 38 ] , a probabilistic model is used to determine proximity of words to the query terms , which may not necessarily reflect the context at which user information is required . Whereas , most opinionated documents have sentences that describe different opinions even within the same paragraph [ 5 , 32 ] , thus opinionated words occurring at proximity to query terms might have occurred in different context . The language model approach has also been used for opinion retrieval [ 33 , 35 ] . Most language models go as far as word level processing ; sentence level processing ; and paragraph level or bagof words . Some language models combine probabilistic techniques for efficient ranking of opinionated documents[14 ] . A common limitation of this approach is the estimation of model parameters [ 19 ] , that is , an effective way to model a document to give a higher probability of relevance to user query is still very challenging . For example , [ 19 ] addressed the parameter tuning or optimization problem in higher order language models by incorporating different component models as features . A basic approach is to perform smoothing at varying levels for effective document retrieval . However , the methodology proposed in [ 19 ] leads to having higher number of model parameters , whereby all of such parameters would also require optimization at different levels . 3 . CONTEXTUAL DERIVATION MODEL In this work , we look at underlying meaning of each sentence and then compare with underlying meaning of the given query or opinion target . We believe sentences form the base of the overall opinion being expressed in a document , and opinionated information is better represented in sentences than individual query words . In our contextual model , we assume an ideal user would give query in the context at which the information is needed . We categorize the contextual model into three stages as we discourse in the following sections . 3.1 Contextual Query Formulation Model We define opinion target T as a set of query terms Q :
( cid:1846)(cid:4666)(cid:1843)(cid:4667 ) ( cid:1843)(cid:4666)(cid:4667 ) ( cid:1370 ) ( cid:1829)(cid:3051 ) , ( 3.1 ) where ( cid:1843)(cid:4666)(cid:4667 ) is a set of query terms composed of one or more words in its original sequence , ( cid:1829)(cid:3051 ) is the context to be derived from sequence ( cid:1843)(cid:4666)(cid:4667 ) . Therefore , ( cid:1843)(cid:4666)(cid:4667 ) ( cid:1370 ) ( cid:1829)(cid:3051 ) , shows the context of opinion target ( cid:1846)(cid:4666)(cid:1843)(cid:4667 ) for each document D in the collection . We expand the original opinion target ( cid:1846)(cid:4666)(cid:1843)(cid:4667 ) by deriving related opinion targets from ( cid:1846)(cid:4666)(cid:1843)(cid:4667 ) ( cid:4657)(cid:1755)(cid:1755)(cid:1755)(cid:4654)(cid:4666)(cid:1846)(cid:1843),(cid:1846)(cid:2870)(cid:1843),…(cid:1846)(cid:3040)(cid:1843)(cid:4667 ) . ( 3.2 ) ( cid:1846)(cid:4666)(cid:2034)(cid:4667)(cid:4666)(cid:3018)(cid:4667 ) ( cid:3300)(cid:3284)(cid:3280)(cid:3287)(cid:3279)(cid:3294 ) ( cid:1482)(cid:1846)(cid:4666)(cid:1843)(cid:4667 ) ( cid:1488 ) ( cid:1846)(cid:4666)(cid:2034)(cid:4667 ) | ( cid:1846)(cid:3040)(cid:4666)(cid:1843)(cid:4667 ) ( cid:1843)(cid:4666)(cid:4667 ) ( cid:1370 ) ( cid:1829)(cid:3051 ) . ( 3.3 )
Therefore , we can rewrite equation 3.1 to represent each of the opinion target contained in equation 3.2 as follows : substitution[21 ] as shown below : through contextual query formulation or
Note that the composition of the above related opinion targets becomes a reference profile2 to the original opinion target . derivation , we are particularly interested in sentences that have the same context with the opinion target . Also , we define reference
We shall show how P can be used in the contextual matching process using approval voting technique[7 , 28 ] .
Figure 1 . Similar opinion targets from a single original user query 3.2 Sentential Context Derivation Process We identify initial document collection using BM25[37 ] . Using CCG [ 18 ] , we understand the meaning of each sentence in order to derive context of a given sentence as ( cid:1829)(cid:3051)(cid:4666)(cid:4667 ) . Upon sentential context profile ( cid:1842)(cid:4668)(cid:1846)(cid:4666)(cid:2034)(cid:4667)(cid:4669 ) as a set of similar opinion target formed above . is the tree derivation ( cid:2034)(cid:3047 ) which shows the global property of phrase property is the semantic properties ( cid:2034)(cid:3046)(cid:3040 ) derived from S which ( cid:2034)(cid:3047)(cid:4666)(cid:4667)(cid:2034)(cid:3047 ) ( cid:4666)(cid:1514)(cid:4666 ) ( cid:1488)(cid:4667)(cid:4667 ) ( 3.4 ) where r is a rule element in a set of CCG rules R , ( cid:1514)(cid:4666 ) ( cid:1488)(cid:4667 ) is automatically selected from set of CCG rules R , and ( cid:2034)(cid:3047 ) is the phrase ( cid:2034)(cid:3046)(cid:3040)(cid:4666)(cid:4667)(cid:2034)(cid:3046)(cid:3040 ) ( cid:4666)(cid:1875 ) ( cid:1488)(cid:4667 ) , ( 3.5 ) tree derivation performed on S . The second property is defined as follows : shows the grammatical realization of content words . We define the first property as follows : the appropriate rule that matches the complexity of S and
We have two important properties for our model . The first property structure tree for S using a selected CCG rule r . The second
                                                             2 The reference profile defines a broader interpretation of the query
WWW 2011 – Ph . D . SymposiumMarch 28–April 1 , 2011 , Hyderabad , India404 In equation 3.6 above , a relationship is established between global of a set of grammatical realizations of each content word in S . Therefore , the context flagged by S can be defined as follows : relationship forms the context that defines the underlying meaning of the sentence . Now that we can derive sentential context , recall that our aim is to identify contextual sentences that match the where ( cid:1875 ) is a word element of sentence S , ( cid:2034)(cid:3046)(cid:3040 ) is the grammatical realization of each content word , and ( cid:2034)(cid:3046)(cid:3040)(cid:4666)(cid:4667 ) is semantic property ( cid:1829)(cid:3051)(cid:4666)(cid:4667 ) ( cid:2034)(cid:3047)(cid:4666)(cid:4667 ) ( cid:1514 ) ( cid:2034)(cid:3046)(cid:3040)(cid:4666)(cid:4667 ) . ( 3.6 ) property ( cid:2034)(cid:3047)(cid:4666)(cid:4667 ) and its corresponding semantic annotations ; this opinion target ; we therefore find the context ( cid:1829)(cid:3051 ) for query formulation ( cid:1843)(cid:4666)(cid:4667 ) by replacing S with ( cid:1843)(cid:4666)(cid:4667 ) as shown below : ( cid:1829)(cid:3051)(cid:4666)(cid:1843)(cid:4666)(cid:4667 ) ( cid:4667 ) ( cid:2034)(cid:3047)(cid:4666)(cid:1843)(cid:4666)(cid:4667 ) ( cid:4667 ) ( cid:1514 ) ( cid:2034)(cid:3046)(cid:3040)(cid:4666)(cid:1843)(cid:4666)(cid:4667 ) ( cid:4667 ) , ( 3.7 ) where ( cid:2034)(cid:3047)(cid:4666)(cid:1843)(cid:4666)(cid:4667 ) ( cid:4667 ) and ( cid:2034)(cid:3046)(cid:3040)(cid:4666)(cid:1843)(cid:4666)(cid:4667 ) ( cid:4667 ) are derived from equation 3.4 and 3.5 respectively by substituting ( cid:1843)(cid:4666)(cid:4667 ) for S . Therefore , a contribution to user information need is established when each ( cid:1829)(cid:3051)(cid:4666)(cid:4667 ) is identical to ( cid:1829)(cid:3051)(cid:4666)(cid:1843)(cid:4666)(cid:4667 ) ( cid:4667 ) ( cid:1488 ) ( cid:1846)(cid:4666)(cid:2034)(cid:4667 ) , and ( cid:1829)(cid:3051)(cid:4666)(cid:1843)(cid:4666)(cid:4667 ) ( cid:4667 ) can be seen as a ( cid:1846)(cid:3040)(cid:4666)(cid:1843)(cid:4667 ) ( cid:1370 ) ( cid:1829)(cid:3051)(cid:4666)(cid:1843)(cid:4666)(cid:4667 ) ( cid:4667 ) , ( 3.8 ) ( cid:1829)(cid:3051)(cid:4666)(cid:4667).(cid:1842)(cid:1568 ) ( cid:1829)(cid:3051)(cid:4666)(cid:1843)(cid:4666)(cid:4667 ) ( cid:4667 ) . ( 3.9 ) representation of original opinion target or its reference profile P defined in 3.2 above . This process is shown below :
3.3 Contextual Matching by Voting In this process we use approval voting [ 7 , 24 , 28 ] technique in order to differentiate between the size of relevant opinions and nonrelevant opinions present in the document . Each contextual sentence that can describe the opinion target is an implicit vote for the opinion target[28 ] . The size of the opinion relevant to the opinion target can be defined as the respective accumulation of contextual sentences ( cid:1829)(cid:3051)(cid:4666)(cid:4667).(cid:1842)(cid:1568)(cid:1829)(cid:3051)(cid:4666)(cid:1843)(cid:4666)(cid:4667 ) ( cid:4667 ) shown below :
||(cid:1841)(cid:3043)(cid:3030)|| ∑ ( cid:1829)(cid:3051)(cid:4666)(cid:4667).(cid:1842)(cid:1568)(cid:1829)(cid:3051)(cid:4666)(cid:1843)(cid:4666)(cid:4667 ) ( cid:4667 ) . ( 3.10 )
However , our research interest is not just to know sentences that support the opinion target only , as opinionated documents can have diverse opinions[26 , 32 ] , we are also interested in sentences that describe other context too , which is why the voting technique comes in . A very important question in every voting technique is “ who the candidates are ? ” Therefore , using the sentential context derivation process described in section 3.2 , we are able to recursively define candidates from each opinionated document , to include the opinion target , and other unique contexts different from the opinion target .
Equation 3.12 above describes a situation where a particular sentence does not support the opinion target ; therefore a contextual
( cid:1829)(cid:3051)(cid:4666)(cid:4667 ) ( cid:3405 ) ( cid:1829)(cid:3051)(cid:4666)(cid:1843)(cid:4666)(cid:4667 ) ( cid:4667 ) , ( 3.11 ) ( cid:1829)(cid:3051)(cid:4666)(cid:4667)(cid:1370)(cid:1829)(cid:3051)′ . ( 3.12 ) sentence ( cid:1829)(cid:3051)′ can be seen as a potential candidate ( cid:1877)′ in a set of contesting candidates ( cid:1829)(cid:3031 ) . Recall that each candidate has a profile P ( cid:1829)(cid:3051)′(cid:1370 ) ( cid:1877)′ , ( 3.13 ) ( cid:1829)(cid:3031)(cid:4666 ) ( cid:1877 ) ( cid:1842 ) , ( cid:1877)′ ( cid:1842),(cid:1877)′(cid:2870)(cid:1842)…(cid:1877)′(cid:1842)(cid:4667 ) ( 3.14 ) described as a broader representation of the context flagged by the particular candidate . This process is shown below : are then added to the set . For the approval voting process , we assume a leader rule3 strategy with element of sincerity and admissibility [ 24 ] , and then define a voter ’s choice , that is , when a sentence can vote for one or more candidates .
In equation 3.14 above , ( cid:1829)(cid:3031 ) is a set of candidates , ( cid:1877 ) is the context of the opinion target ( cid:1846)(cid:4666)(cid:1843)(cid:4667 ) as the first candidate , subsequent contexts ( cid:1848)(cid:3030)(cid:3035)(cid:3042)(cid:3030)(cid:3032 ) ( cid:2880 ) ( cid:1482)(cid:1877 ) ( cid:1488 ) ( cid:1829)(cid:3031 ) | ( cid:1842)(cid:3435 ) ( cid:1877 ) ( cid:2880 ) ( cid:3439)(cid:1514 ) ( cid:1842)(cid:3435 ) ( cid:1877 ) ( cid:3439 ) ( 3.15 ) || ( cid:1841)(cid:3043)(cid:3030 ) ′||∑ ( cid:1829)(cid:3051)′(cid:4666)(cid:4667 ) ( 3.16 ) Therefore , equation 3.10 is the size or weight of the opinion ||(cid:1841)(cid:3043)(cid:3030)|| 3.16 is the size or weight of non opinion || ( cid:1841)(cid:3043)(cid:3030 ) ′|| derived from the same given document . A document ’s relevance ( cid:3031)(cid:3042)(cid:3030 ) to user ’s intent relevant to the opinion target from a given document and equation is determined when the size of relevant opinion is greater than the size non relevant opinion clouds derived from the document . Opinion weights for relevant documents can then be used to rank documents hierarchically . Relevance of a document can be defined below : ( cid:3031)(cid:3042)(cid:3030 ) ( cid:1482 ) || ( cid:1841)(cid:3043)(cid:3030 ) ′|| ( cid:4666)||(cid:1841)(cid:3043)(cid:3030)|| ( cid:3408 ) || ( cid:1841)(cid:3043)(cid:3030 ) ′||(cid:4667 ) . ( 3.17 )
Figure 2 . Contextual voting process using candidates’ profiles
4 . Evaluation using AIC Model Selection We used Akaike Information Criterion ( AIC)4 to perform model selection between BM255 [ 37 ] , language models [ 19 ] , and our contextual model . By this , we are able to understand the approximating capability of our contextual model by simply computing and comparing the AIC values for each of the candidate models , the model with the least AIC value is believed to be the best fitted model for the opinion retrieval task[3 , 6 , 8 ] . Moreover , AIC has strong theoretical foundations built over Kullback Leibler distance[30 ] , for selecting appropriate approximating model for statistical inference from many types of empirical data [ 2 3 , 6 , 8 ] .
We show AIC ’s criteria for estimating the expected relative distance between models as follows :
( cid:1775)(cid:1783)(cid:1777 ) 2log ( cid:4666)(cid:1838)(cid:4666)(cid:2016)(cid:3552 ) |(cid:1877)(cid:4667)(cid:4667)(cid:3397)2 . ( 4.1 ) maximum point is represented by log ( cid:4666)(cid:1838)(cid:4666)(cid:2016)(cid:3552)|(cid:1877)(cid:4667)(cid:4667 ) where is the
4.1 Baselines for AIC Model Selection In equation 4.1 , the numerical value of the log likelihood at its number of estimable parameters in each participating model[8 ] . We set the optimized parameters and values for BM25 and Bigram Language Model ( LM ) in [ 19 ] as our baselines to be compared with our contextual model using AIC values . Arguably , we assume                                                              3 A behavioral rule with rational foundation [ 24 ] . 4 Selects best approximating model from finite samples by minimizing the K L information through parameters estimation [ 2 3 , 6 , 8 ] . 5 BM25 has been used in [ 11 , 17 , 34 , 38 ] .
WWW 2011 – Ph . D . SymposiumMarch 28–April 1 , 2011 , Hyderabad , India405 sentence in a document as follows :
( cid:1868)(cid:3435)(cid:1829)(cid:3051)(cid:3627)(cid:1830)(cid:1867)(cid:1855)(cid:3042)(cid:3043)(cid:3439)∑ ( cid:3031)(cid:1488)(cid:3005)(cid:3042)(cid:3030)(cid:3290)(cid:3291 ) ( cid:3015)(cid:4666)(cid:3004)(cid:3299),(cid:3031)(cid:4667 ) ∑(cid:3031)(cid:1488)(cid:3005)(cid:3042)(cid:3030)(cid:3290)(cid:3291 ) |(cid:3020)|
Normalized Discounted Cumulative Gain ( NDGC)6 values@1 reported in [ 19 ] as our estimated likelihood values for the two models above . 4.2 Likelihood Ratio and Parameter Estimation for the Contextual Model For our contextual model we compute the opinion score based on the Likelihood Ratio ( LR ) method presented in [ 13 ] . The major difference between this method and our approach is that , rather than “ frequency of terms ” we used frequency of contextual opinionated sentence as described in section 3.2 , that is , the frequency of sentences that support the context of the opinion target . Therefore , we represent set of documents with opinions as ( cid:1830)(cid:1867)(cid:1855)(cid:3042)(cid:3043 ) and relevant documents with ( cid:3031)(cid:3042)(cid:3030 ) and then compute the frequency of relevant In equation 4.2 above , ( cid:1840)(cid:4666)(cid:1829)(cid:3051),(cid:1856 ) ) is the number of contextual relevant sentence ( cid:1829)(cid:3051 ) in document d , || is the total number of sentences in document d , and ( cid:1868)(cid:4666)(cid:1829)(cid:3051)|(cid:3031)(cid:3042)(cid:3030 ) ( cid:4667 ) can be computed as the ratio of ( cid:1868)(cid:4666)(cid:1829)(cid:3051)|(cid:3031)(cid:3042)(cid:3030 ) ( cid:4667 ) to ( cid:1868)(cid:3435)(cid:1829)(cid:3051)(cid:3627)(cid:1830)(cid:1867)(cid:1855)(cid:3042)(cid:3043)(cid:3439 ) as shown below : ( cid:1841)(cid:1868)(cid:1861)(cid:1861)(cid:1867)(cid:3020)(cid:3030)(cid:3042)(cid:3045)(cid:3032)(cid:1829)(cid:3051 ) ( cid:3043)(cid:3435)(cid:3004)(cid:3299)(cid:3627)(cid:3005)(cid:3042)(cid:3030)(cid:3290)(cid:3291)(cid:3439 ) ratio of number of sentences with at least one of the terms ( see section 3.2 ) of the opinion target to the total number of sentences . Therefore , the LR of contextual relevant sentence can be seen as the
( cid:3043)(cid:4666)(cid:3004)(cid:3299)|(cid:3019)(cid:3279)(cid:3290)(cid:3278 ) ( cid:4667 ) . ( 4.3 ) [ 36 ] , whereby we derived parameter ( cid:2011 ) as the number of appropriate
Before we compute the contextual model ’s estimated value of the opinion score for AIC , we wish to quickly state that the contextual model can be interpreted using the Hidden Markov Models ( HMM )
. ( 4.2 )
[ 19 ] ,
( ie NDGC@1 ) hidden states that generates the best probability distribution for our contextual model . For example , the appropriate number of related opinion targets to be generated such as described in section 31 by Google blogs8 using “ The 2008 Obama electoral process ” as
Since the likelihood values for our baselines models were derived for an estimated for one page
( cid:1841)(cid:1868)(cid:1861)(cid:1861)(cid:1867)(cid:3020)(cid:3030)(cid:3042)(cid:3045)(cid:3032)(cid:1829)(cid:3051 ) , we manually observed the first blog result7 shown query , and we set our parameter ( cid:2011)1 . For example , we assume section 33 ) From our observation ( cid:1840)(cid:4666)(cid:1829)(cid:3051),(cid:1856 ) ) is equal to 3 and || is query . With ( cid:1840)(cid:4666)(cid:1829)(cid:3051),(cid:1856 ) ) equal to 8 for “ Support for US elections ” , section 3.1 has generated one related opinion target such as “ Obama and 2008 US elections ” , and then observe the total number of sentences that can support or vote for the above two targets ( see equal to 25 for the query given above . In this particular blog , we could however observe other targets such as “ Support for US elections ” attract more sentences or votes other than the initial obviously our contextual model would not have retrieved this blog for the query “ The 2008 Obama electoral process ” , as it will
                                                             6 Used for performance measurement of models in IR[19 ] . 7 http://wwwamerican electioncom/2010/10/05/michelle obama i needyour help/ 8 http://blogsearchgooglecom/
We assume the latter query ( ie “ Support for US elections ” ) as the consider other context that outweighs the query , such as “ Support for US elections ” . likely target for the blog above , therefore we used ( cid:1840)(cid:4666)(cid:1829)(cid:3051),(cid:1856 ) ) = 8 , || = 25 , and computed ( cid:1868)(cid:4666)(cid:1829)(cid:3051)|(cid:3031)(cid:3042)(cid:3030 ) ( cid:4667 ) using number of sentences with at ( cid:1868)(cid:4666)(cid:1829)(cid:3051)|(cid:3031)(cid:3042)(cid:3030 ) ( cid:4667 ) would be 13/25 = 052 Using equation 4.2 , ( cid:1868)(cid:3435)(cid:1829)(cid:3051)(cid:3627)(cid:1830)(cid:1867)(cid:1855)(cid:3042)(cid:3043)(cid:3439 ) is computed as 8/25 = 0.32 , and using equation 4.3 , ( cid:1841)(cid:1868)(cid:1861)(cid:1861)(cid:1867)(cid:3020)(cid:3030)(cid:3042)(cid:3045)(cid:3032)(cid:1829)(cid:3051 ) is computed as 032/052 = 062 least one unique query term or synonyms equals 13 , thus
Table 1 . Parameters and likelihood values for AIC candidate models[19 ] .
No of parameters 2 7
Likelihood
0.2556 0.2630
Model
Parameters
BM25 Bigram LM k1 = 1.0 , b = 0.5 λ1 = 0.24 , λ2 = 0.29 , λ3 = 0.94 , μ1 = 1800 , μ2 = 400 , μ3 = 792 , μ4 = 900
( cid:2011)1
1
0.62
AIC9 the best approximating model[6 , 8 ] .
Contextual Model 4.3 Results Table 2 . AIC values for the candidate models derived based on [ 6 , 8 ] with the appropriate formulas shown in footnotes on this page .
The least AIC or AIC(cid:3030 ) and the highest ( cid:1875 ) values respectively denote ( cid:1875 ) 12 Using the above table we can compute the evidence ratio ( (cid:3050)(cid:3284)(cid:3050)(cid:3285)(cid:1568 ) ( cid:3050)(cid:3288)(cid:3284)(cid:3289)(cid:3050)(cid:3285)(cid:4667 ) as a rule of thumb [ 3 , 6 , 8 ] , which shows the best
Model Contextual Model BM25 Bigram LM
AIC(cid:3030)10
0.131569 0.000912
3.772211 13.71513
4.728283 14.6712
6.728283 16.6712
∆11
2.956072
0.867519
K 1
2 7
0.956072
0 and can be computed then Bigram LM the highest cannot be considered as good approximating model[3 , 6 , approximating model , given the data and the candidate models . The strength of evidence for our sentence level contextual model against BM25 as 0867619/0131569 ≈ 6.6 , and 0867619/0000912 ≈ 951.5 respectively . Obviously , the evidence for sentence level contextual model is very strong against Bigram LM while BM25 seems reasonable . In addition , candidate model with ( cid:1875 ) less than 10 % of 8 ] . In this case , 10 % of the highest ( cid:1875 ) ( ie 0.867519 * 0.10 ) is 10 AIC requires bias adjustment if n/K < 40 [ 8 ] , therefore , AIC(cid:3030 ) ( cid:1775)(cid:1783)(cid:1777)(cid:3397 ) 2(cid:1499)K ( cid:3397)(cid:4666)2(cid:1499)K(cid:1499)(cid:4666)K(cid:3397)1(cid:4667)(cid:4667 ) / ( cid:4666)nK1(cid:4667 ) , where n = number of 11 Differences between AIC , that is , ∆ AIC AIC(cid:3040 ) [ 8 ] . 12 Akaike weight is the normalized relative likelihood , that is , ( cid:1875 ) ( cid:1857)(cid:1876)(cid:1868)(cid:4666)0.5 ∆(cid:4667 ) / ∑ , where the denominator is the sum of ( cid:3019)(cid:3045)(cid:2880 ) observations and K = number of parameters , in our case we have 1 observation and K is 1 , therefore n/K < 40 .
                                                             9 Formula is shown in equation 4.1
0.086752 ; therefore since 0.867519 is greater than 0.086752 , we can
( cid:1857)(cid:1876)(cid:1868)(cid:4666)0.5 ∆(cid:3045)(cid:4667 ) all the relative likelihoods of the candidate models[8 ] .
WWW 2011 – Ph . D . SymposiumMarch 28–April 1 , 2011 , Hyderabad , India406 conclude that sentence level contextual model is most likely to be a good approximating model for opinion retrieval task . 5 . CONCLUSION In this paper , we introduced and successfully evaluated a contextual sentence level contextual model for effective opinion retrieval task . The technique considered in this model is based on NLP technique ( ie CCG ) which gives a clear representation of meaning and context for each sentence . Our argument is that , rather than word counts or probabilistic processes , contextual meaning of opinionated sentences can be derived . Using approval voting technique , the aggregates of votes show the size of opinion for each contextual candidate . Contextual candidate with the largest opinion size best describes the overall opinion flagged by each document . Relevant opinionated document can be ranked hierarchically using their respective relevant opinion sizes . For future work , we plan to implement our model on TREC blog 2009 data set for detecting faceted opinions and also revisit our model to include multisentence contextual dependencies . 6 . REFERENCES [ 1 ] Abbasi , A . , Chen , H . and Salem , A . ( 2008 ) . Sentiment analysis in multiple languages : Feature selection for opinion classification . In ACM Trans . Inf . Syst,1 34
[ 2 ] Akaike , H . ( 1987 ) . Factor analysis and AIC . In Psychometrika
317 332 .
[ 3 ] Akaike , H . ( 1981 ) . Likelihood of a model and information criteria . In Econometrics , 3 14 .
[ 4 ] Tumasjan , A . , Sprenger , TO , Sandner , PG , and Welpe , IM ( 2010 ) . Predicting Elections with Twitter:What 140 Characters Reveal about Political Sentiment . In WSM '10 .
[ 5 ] Bermingham , A . and Smeaton , AF ( 2009 ) . A study of interannotator agreement for opinion retrieval . In SIGIR , 784 785 .
[ 6 ] Bozdogan , H . ( 1987 ) . Model Selection and Akaike's
Information Criterion ( AIC ) : The general theory and its analytical extentions . In Psychometrika , 345 370 .
[ 7 ] Fishburn , PC and Brams , SJ ( 2010 ) . Approval Voting ,
Condorcet's Principle , and Runoff Elections . In Public Choice '10 , 89 114 .
[ 8 ] Burnham , KP , Anderson , DR ( 2002 ) . Model Selection and
Multimodel Inference . Springer Verlag New York , Inc . ,
[ 9 ] Choi , Y . , Kim , Y . and Myaeng , S H . ( 2009 ) . Domain specific sentiment analysis using contextual feature generation . In CIKM '09 , 37 44 .
[ 10 ] Chung , C . and Pennebaker , J . ( 2009 ) . The Psychological
Functions of Function Words . In Social Communication , 343 359 .
[ 11 ] Macdonald , C , Ounis , I . , and Soboroff , I . ( 2009 ) . Overview of the TREC2009 Blog Track . In TREC '09 .
[ 12 ] Hannah , D . , Macdonald , C . , Peng , J . , He , B . , and Ounis , I .
( 2007 ) . University of Glasgow at TREC 2007 : Experiments in Blog and Enterprise Tracks with Terrier . In TREC '07 .
[ 13 ] Gerani , S . , Carman , MJ , and Crestani , F . ( 2009 ) .
Investigating Learning Approaches for Blog Post Opinion Retrieval . In ECIR '09 . 313 324 .
[ 14 ] Hiemstra , D . , ( 2000 ) Using language models for information retrieval . PhD Thesis , Centre for Telematics and Information Technology , The Netherlands .
[ 15 ] Hiemstra , D . , Robertson , S . , and Zaragoza , H . ( 2004 ) .
Parsimonious language models for information retrieval . In SIGIR '04 , 178 185 .
[ 16 ] Huang , X . and Croft , WB ( 2009 ) . A unified relevance model for opinion retrieval . In CIKM '09 , 947 956 .
[ 17 ] Ounis , I . , Macdonald C . , and Soboroff , I . ( 2008 ) . Overview of the TREC2008 Blog Track . In TREC '08 .
[ 18 ] Hockenmaier , J . and Steedman , M . ( 2007 ) . CCGbank : A Corpus of CCG Derivations and Dependency Structures Extracted from the Penn Treebank . Computational Linguistics 33(3 ) , 355 396 .
[ 19 ] Javanmardi , S . , Gao , J . , and Wang , K . ( 2010 ) . Optimizing two stage bigram language models for IR . In WWW '10 , 11251126 .
[ 20 ] Bollen , J . , Pepe , A . , and Mao , H . ( 2010 ) . Modeling public mood and emotion:Twitter sentiment and socioeconomic phenomena . In WWW ' 10 .
[ 21 ] Jones , R . , Rey , B . , Madani , O . , Greiner , W . ( 2006 ) . Generating query substitutions . In WWW '06 , 387 396 .
[ 22 ] Kanayama , H . and Nasukawa , T . ( 2006 ) . Fully automatic lexicon expansion for domain oriented sentiment analysis . In EMNLP '06 , 355 363 .
[ 23 ] Krahmer , E . ( 2010 ) . What Computational Linguists Can Learn from Psychologists ( and Vice Versa ) . In ACL '10 , 285 294 .
[ 24 ] Laslier , J F and Maniquet , F . ( 2010 ) . Classical Electoral
Competition Under Approval Voting . In Handbook on Approval Voting , 415 429 .
[ 25 ] Kullback , S . and Leibler , RA ( 1951 ) . On Information and
Sufficiency . In The Annals of Mathematical Statistics , 79 86 . [ 26 ] Liu , B . ( 2010 ) . Sentiment Analysis and Subjectivity . In HNLP . [ 27 ] Sarmento , L . , Carvalho , P . , Silva , MJ , and Eugénio de
Oliveira . ( 2009 ) . Automatic creation of a reference corpus for political opinion mining in user generated content . In CIKM '09 , 29 36 .
[ 28 ] Macdonald , C . ( 2009 ) . The Voting Model for People Search .
PhD Thesis , University of Glasgow .
[ 29 ] Macdonald , C . ( 2010 ) . Blog track research at TREC . In SIGIR
'10 , 58 75 .
[ 30 ] Nederhof , M J and Satta , G . ( 2004 ) . Kullback Leibler distance between probabilistic context free grammars and probabilistic finite automata . In ACL '04 , 71 .
[ 31 ] Pan , SJ , ( 2010 ) . Cross domain sentiment classification via spectral feature alignment . In WWW '10,751 760 .
[ 32 ] Pang , B . and Lee , L . ( 2008 ) . Opinion Mining and Sentiment
Analysis . In Found . Trends Inf . Retr,1 135 .
[ 33 ] Jiang , P . , Yang , Q . , Zhang , C , and Niu , Z . ( 2009 ) . BIT at TREC 2009 Faceted Blog Distillation Task . In TREC '09 .
[ 34 ] Pickens , J . and MacFarlane , A . ( 2006 ) . Term context models for information retrieval . In CIKM '06 , 559 566 .
[ 35 ] Ponte , JM and Croft , WB ( 1998 ) . A language modeling approach to information retrieval . In SIGIR , 275 281 .
[ 36 ] Rabiner , LR ( 1989 ) . A Tutorial on Hidden Markov Models and Selected Applications . In Speech Recognition , IEEE , 257286 .
[ 37 ] Robertson , S . , and Zaragoza , H . ( 2009 ) . The Probabilistic Relevance Framework : BM25 and Beyond . In Found . , and Trends in Information Retrieval , 333–389 .
[ 38 ] Gerani , S . , Carman , MJ , and Crestani , F . ( 2010 ) . Proximity
Based Opinion Retrieval . In SIGIR '10 , 978 .
[ 39 ] Tausczik , YR , and Pennebaker , JW ( 2010 ) . The
Psychological Meaning of Words : LIWC and Computerized Text Analysis Methods . In Journal of Language and Social Psychology , 24 54 .
[ 40 ] Wilson , T . , Wiebe , J . , and Hoffmann , P . ( 2009 ) . Recognizing Contextual Polarity : an exploration of features for phrase level sentiment analysis . Computational Linguistics 35(3 ) .
WWW 2011 – Ph . D . SymposiumMarch 28–April 1 , 2011 , Hyderabad , India407
