Geographical Topic Discovery and Comparison
Zhijun Yin1 , Liangliang Cao2 , Jiawei Han1 , Chengxiang Zhai1 , Thomas Huang2
1Department of Computer Science
2Department of ECE and Beckman Institute University of Illinois at Urbana Champaign zyin3@illinois.edu , cao4@ifpuiucedu , hanj@csuiucedu , czhai@csuiucedu , huang@ifpuiucedu
ABSTRACT This paper studies the problem of discovering and comparing geographical topics from GPS associated documents . GPSassociated documents become popular with the pervasiveness of location acquisition technologies . For example , in Flickr , the geo tagged photos are associated with tags and GPS locations . In Twitter , the locations of the tweets can be identified by the GPS locations from smart phones . Many interesting concepts , including cultures , scenes , and product sales , correspond to specialized geographical distributions . In this paper , we are interested in two questions : ( 1 ) how to discover different topics of interests that are coherent in geographical regions ? ( 2 ) how to compare several topics across different geographical locations ? To answer these questions , this paper proposes and compares three ways of modeling geographical topics : location driven model , text driven model , and a novel joint model called LGTA ( Latent Geographical Topic Analysis ) that combines location and text . To make a fair comparison , we collect several representative datasets from Flickr website including Landscape , Activity , Manhattan , National park , Festival , Car , and Food . The results show that the first two methods work in some datasets but fail in others . LGTA works well in all these datasets at not only finding regions of interests but also providing effective comparisons of the topics across different locations . The results confirm our hypothesis that the geographical distributions can help modeling topics , while topics provide important cues to group different geographical regions .
Categories and Subject Descriptors H28 [ Database applications ] : Data mining
General Terms Algorithms
Keywords Geographical topics , topic modeling , topic comparison
1 .
INTRODUCTION
With the popularity of low cost GPS chips and smart phones , geographical records have become prevalent on the Web . A geographical record is usually denoted by a two
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . Distribution of these papers is limited to classroom use , and personal use by others . WWW 2011 , March 28–April 1 , 2011 , Hyderabad , India . ACM 978 1 4503 0632 4/11/03 . dimensional vector , latitude and longitude , representing a unique location on the Earth . There are several popular ways to obtain geographical records on the Web :
1 . Advanced cameras with GPS receivers could record GPS locations when the photos were taken . When users upload these photos on the Web , we can get the geographical records from the digital photo files .
2 . Some applications including Google Earth and Flickr provide interfaces for users to specify a location on the world map . Such a location can be treated as a geographical record in a reasonable resolution .
3 . People can record their locations by GPS functions in their smart phones . Popular social networking websites , including Facebook , Twitter , Foursquare and Dopplr , provide services for their users to publish such geographical information .
In the above three scenarios , GPS records are provided together with different documents including tags , user posts , etc . We name those documents with GPS records as GPSassociated documents . The amount of GPS associated documents is increasing dramatically . For example , Flickr hosts more than 100 million photos associated with tags and GPS locations . The large amount of GPS associated documents makes it possible to analyze the geographical characteristics of different subjects . For example , by analyzing the geographical distribution of food and festivals , we can compare the cultural differences around the world . We can also explore the hot topics regarding the candidates in presidential election in different places . Moreover , we can compare the popularity of specific products in different regions and help make the marketing strategy . The geographical characteristics of these topics call for effective approaches to study the GPS associated documents on the Web .
In recent years , some studies have been conducted on GPS associated documents including organizing geo tagged photos [ 4 ] and searching large geographical datasets [ 7 ] . However , none of them addressed the following two needs in analyzing GPS associated documents .
• Discovering different topics of interests those are coherent in geographical regions . Administrative divisions such as countries and states can be used as regions to discover topics . However , we are more interested in different region segmentations corresponding to different topics . For example , a city can be grouped into different sub regions in terms of architecture or
WWW 2011 – Session : Spatio Temporal AnalysisMarch 28–April 1 , 2011 , Hyderabad , India247 entertainment characteristics ; a country might be separated into regions according to landscapes like desert , beach and mountain . Unfortunately , existing studies either overlook the differences across geographical regions or employ country/state as the fixed configuration .
• Comparing several topics across different geographical locations . It is often more interesting to compare several topics than to analyze a single topic . For example , people would like to know which products are more popular in different regions , and sociologists may want to know the cultural differences across different areas . With the help of GPS associated documents , we can map topics of interests into their geographical distributions . None of the previous work addressed this problem and we aim to develop an effective method to compute such comparison .
In this paper , we propose three different models for geographical topic discovery and comparison . First , we introduce a location driven model , where we cluster GPSassociated documents based on their locations and make each document cluster as one topic . The location driven model works if there exist apparent location clusters . Second , we introduce a text driven model , which discovers topics based on topic modeling with regularization by spatial information . The text driven model can discover geographical topics if the regularizer is carefully selected . However , it cannot get the topic distribution in different locations for topic comparison , since locations are only used for regularization instead of being incorporated into the generative process . Third , considering the facts that a good geographical configuration benefits the estimation of topics , and that a good topic model helps identify the meaningful geographical segmentation , we build a unified model for both topic discovery and comparison . We propose a novel locationtext joint model called LGTA ( Latent Geographical Topic Analysis ) , which combines geographical clustering and topic modeling into one framework . Not only can we discover the geographical topics of high quality , but also can estimate the topic distribution in different geographical locations for topic comparison .
The rest of the paper is organized as follows . We formulate the problem of geographical topic discovery and comparison in Section 2 . We introduce the location driven model in Section 3 and the text driven model in Section 4 . In Section 5 , we propose the Latent Geographical Topic Analysis model . We compare the performance of different methods in Section 6 . We summarize the related work in Section 7 and conclude the paper in Section 8 .
2 . PROBLEM FORMULATION
In this section , we define the problem of geographical topic discovery and comparison . The notations used in this paper are listed in Table 1 .
Definition 1 . A GPS associated document is a text document associated with a GPS location . Formally , document d contains a set of words wd , where the words are from vocabulary set V . ld = ( xd , yd ) is the location of document d where xd and yd are longitude and latitude respectively . One example of a GPS associated document can be a set of tags for a geo tagged photo in Flickr , where the location
Table 1 : Notations used in the paper . Description Vocabulary ( word set ) , w is a word in V Document collection A document d that consists of words and GPS location
V D d wd The text of document d ld Z θ
The GPS location of document d The topic set , z is a topic in Z The word distribution set for Z , ie , {θz}z∈Z is the GPS location where the photo was taken . Another example can be a tweet in Twitter , where the location is the GPS location from the smart phone .
Definition 2 . A geographical topic is a spatially coherent meaningful theme . In other words , the words that are often close in space are clustered in a topic . We give two geographical topic examples as follows .
Example 1 . Given a collection of geo tagged photos related to festival with tags and locations in Flickr , the desired geographical topics are the festivals in different areas , such as Cherry Blossom Festival in Washington DC and South by Southwest Festival in Austin , etc .
Example 2 . Given a collection of geo tagged photos related to landscape with tags and locations in Flickr , the desired geographical topics are landscape categories that are spatially coherent , such as coast , desert , mountain , etc .
In this paper , we study the problem of geographical topic discovery and comparison . Given a collection of GPS associated documents , we would like to discover the geographical topics . We would also like to compare the topics in different geographical locations . Here we give an example of geographical topic discovery and comparison .
Example 3 . Given a collection of geo tagged photos related to food with tags and locations in Flickr , we would like to discover the geographical topics , ie , what people eat in different areas . After we discover the food preferences , we would like to compare the food preference distributions in different geographical locations .
To support topic comparison in different locations , we define the topic distribution in geographical location as follows .
Definition 3 . A topic distribution in geographical location is the conditional distribution of topics given a specific location . Formally , p(z|l ) is the probability of topic z given location l = ( x , y ) where x is longitude and y is z∈Z p(z|l ) = 1 . From p(z|l ) , we can know latitude , st , which topics are popular in location l .
The problem of geographical topic discovery and com parison is formulated as follows . Given a collection of GPS associated documents D and the number of topics K , we would like to discover K geographical topics , ie , θ =
{θz}z∈Z where Z is the topic set and a geographical topic z is represented by a word distribution θz = {p(w|z)}w∈V w∈V p(w|z ) = 1 . Along with the discovered geographst ical topics , we also would like to know the topic distribution in different geographical locations for topic comparison , ie , p(z|l ) for all z ∈ Z in location l as in Definition 3 . In the next sections , we will present three different models for solving this problem .
WWW 2011 – Session : Spatio Temporal AnalysisMarch 28–April 1 , 2011 , Hyderabad , India248 3 . LOCATION DRIVEN MODEL
In the location driven model , we simply cluster the documents based on their locations . Each document cluster corresponds to one topic . p(z|d ) is the probability of topic z given document d from the location clustering result . We then estimate the word distribution θz for topic z by p(w|z ) ∝ d∈D p(w|d)p(d|z ) , where p(d|z ) is obtained from p(z|d ) by Bayes’ theorem . In Festival dataset in Example 1 , after we cluster the photos according to their locations , those photos close to each other are merged into the same cluster . And then we can generate the geographical topics ( ie , festival descriptions for each region ) based on tags in each cluster . To cluster objects in 2 D space , we can use partition based clustering like KMeans , density based clustering like Meanshift [ 3 ] and DBScan [ 5 ] , and mixture model based clustering . After we get the word distribution θz for topic z ∈ Z based on the clustering result , we would like to know the topic distribution in geographical location p(z|l ) for topic comparison . Therefore , we prefer a generative model for location clustering because we can get the estimation of p(l|z ) . p(z|l ) can be obtained by Bayes’ theorem from p(l|z ) . A popular generative model is Gaussian Mixture Model ( GMM ) . In GMM , we assume that each cluster is mathematically represented by a Gaussian distribution and the entire data set is modeled by a mixture of Gaussian distributions .
Although the location driven model is straightforward , it is likely to fail if the document locations do not have good cluster patterns . A geographical topic may be from several different areas and these areas may not be close to each other . For example , in Landscape dataset in Example 2 , there are no apparent location clusters ; mountains exist in different areas and some are distant from each other . Therefore , the location driven model fails in Landscape dataset as shown in the experiment in Section 621
4 . TEXT DRIVEN MODEL
In the text driven model , we discover the geographical topics based on topic modeling . To incorporate location information , we can use the idea of NetPLSA [ 8 ] to regularize topic modeling . PLSA [ 6 ] models the probability of each co occurrence of words and documents as a mixture of conditionally independent multinomial distributions . NetPLSA regularizes PLSA with a harmonic regularizer based on a graph structure in the data . In our case , the nodes of the graph are documents and the edge weights are defined as the closeness in location between two documents . Therefore , documents that are close in location would be assumed to have similar topic distributions .
The objective function that NetPLSA aims to minimize is as follows . L(D ) = −(1 − λ ) c(w , d ) log p(w|z)p(z|d ) d∈D w∈V z∈Z z∈Z
+
λ 2
( u,v)∈E w(u , v )
( p(z|du ) − p(z|dv))2 ( 1 ) where c(w , d ) is the count of word w in document d and w(u , v ) is the closeness of document du and dv . p(w|z ) is the word distribution of topic z and p(z|d ) is the topic distribution of document d . λ controls the regularization strength . With the guidance of text information , the text driven model may discover geographical topics that are missed by the location driven model . However , there are still several
Table 2 : Notations used in LGTA framework .
Description
R The region set , r is a region in R φ The topic distribution set for R , ie , {φr}r∈R µ The mean vector set for R , ie , {µr}r∈R Σ The covariance matrix set for R , ie , {Σr}r∈R α The region importance weights problems in the text driven model . First , we can only get the word distribution of geographical topics θz for z ∈ Z , but we cannot get the topic distribution of geographical locations in Definition 3 , which is important for geographical topic In text driven model we cannot know p(z|l ) comparison . because location is only used for regularization instead of being modeled in the topic generative process . Second , it is difficult to define the document closeness measure used in regularization . For example , in Food data set in Example 3 , some food preferences exist only in some small regions , while some others exist throughout the continent . It is difficult to choose the closeness measure in this case .
5 . LOCATION TEXT JOINT MODEL
In this section , we propose a novel location text joint model called LGTA ( Latent Geographical Topic Analysis ) , which combines geographical clustering and topic modeling into one framework . 5.1 General Idea
To discover geographical topics , we need a model to encode the spatial structure of words . The words that are close in space are likely to be clustered into the same geographical topic . In order to capture this property , we assume there are a set of regions . The topics are generated from regions instead of documents . If two words are close to each other in space , they are more likely to belong to the same region . If two words are from the same region , they are more likely to be clustered into the same topic . In Festival dataset in Example 1 , the regions can be the areas in different cities , so the discovered geographical topics are different festivals . In Landscape data set in Example 2 , the regions can be different areas such as the long strips along the coast and the areas in the mountains , so the discovered geographical topics are different landscapes . In Food data set in Example 3 , the regions can be different areas that people live together , so the discovered geographical topics are different food preferences . We would like to design a model that can identify these regions as well as discover the geographical topics . 5.2 Latent Geographical Topic Analysis
In this section , we introduce our LGTA framework for geographical topic discovery and comparison . The notations used in the framework are listed in Table 2 .
521 Discovering geographical topics We would like to discover K geographical topics . The word distribution set of all the topics is denoted as θ , ie , {θz}z∈Z . Let us assume there are N regions and denote the region set as R . We assume that the geographical distribution of each region is Gaussian , parameterized as ( µ , Σ ) = {(µr , Σr)}r∈R where µr and Σr are the mean vector and covariance matrix of region r . α is a weight distribution over all the regions . p(r|α ) indicates the weight of region r and
WWW 2011 – Session : Spatio Temporal AnalysisMarch 28–April 1 , 2011 , Hyderabad , India249 and Σr . p(ld|µr , Σr ) =
|Σr| exp(
1
2π
−(ld − µr)T Σ−1 r ( ld − µr )
2
) p(r|d , Ψ(t ) ) =
( 2 ) where p(wd , ld|r , Ψ(t ) ) is calculated as follows . r∈R p(r|α ) = 1 . Since topics are generated from regions , we use φ = {φr}r∈R to indicate topic distributions for all the regions . φr = {p(z|r)}z∈Z where p(z|r ) is the probability of topic z given region r . z∈Z p(z|r ) = 1 for each r .
In our model , topics are generated from regions instead of documents and the geographical distribution of each region follows a Gaussian distribution . The words that are close in space are more likely to belong to the same region , so they are more likely to be clustered into the same topic . The generative procedure of the model is described as follows . To generate a geographical document d in collection D :
1 . Sample a region r from the discrete distribution of re gion importance α , r ∼ Discrete(α ) .
2 . Sample location ld from Gaussian distribution of µr
3 . To generate each word in document d :
( a ) Sample a topic z from multinomial φr . ( b ) Sample a word w from multinomial θz .
Instead of aligning each topic with a single region , each topic in our model can be related to several regions . Therefore , our model can handle topics with complex shapes . Our model identifies the regions considering both location and text information . Meanwhile , it discovers the geographical topics according to the identified geographical regions . Let us denote all parameters by Ψ = {θ , α , φ , µ , Σ} . Given the data collection {(wd , ld)}d∈D where wd is the text of document d and ld is the location of document d , the loglikelihood of the collection given Ψ is as follows .
L(Ψ ; D ) = log p(D|Ψ )
= log p(wd , ld|Ψ )
( 3 ) d∈D
In Section 5.3 , we show how to estimate all the parameters using an EM algorithm . 522 Comparing geographical topics To compare the topics in different geographical locations , we need to get p(z|l ) in Definition 3 for all topics z ∈ Z given location l = ( x , y ) where x is longitude and y is latitude . Given the estimated Ψ , we first estimate the density of location l given topic z . r∈R r∈R r∈R
5.3 Parameter Estimation
In order to estimate parameters Ψ = {θ , α , φ , µ , Σ} in Equation 3 , we use maximum likelihood estimation . Specifically , we use Expectation Maximization(EM ) algorithm to solve the problem , which iteratively computes a local maximum of likelihood . Let us denote rd as the region of document d . We introduce the hidden variable p(r|d , Ψ ) , which is the probability of rd = r given document d and Ψ . In the E step , it computes the expectation of the complete likelihood Q(Ψ|Ψ(t) ) , where Ψ(t ) is the value of Ψ estimated in iteration t . In the M step , it finds the estimation Ψ(t+1 ) that maximizes the expectation of the complete likelihood . The derivation detail is listed in Appendix A . In the E step , p(r|d , Ψ(t ) ) is updated according to Bayes formulas as in Equation 6 . p(t)(r|α)p(wd , ld|r , Ψ(t ) ) r∈R p(t)(r|α)p(wd , ld|r , Ψ(t ) )
( 6 ) p(wd , ld|r , Ψ(t ) ) = p(wd|r , Ψ(t))p(ld|r , Ψ(t ) )
( 7 ) where p(ld|r , Ψ(t ) ) = p(ld|µ(t ) r ) is defined as Gaussian distribution in Equation 2 and p(wd|r , Ψ(t ) ) is multinomial distribution for the words in document d in terms of probability p(w|r , Ψ(t) ) . r , Σ(t ) p(wd|r , Ψ(t ) ) ∝ p(w|r , Ψ(t))c(w,d )
( 8 ) w∈wd where c(d , w ) is the count of word w in document d .
We assume that the words in each region are generated from a mixture of a background model and the region based topic models . The purpose of using a background model is to make the topics concentrated more on more discriminative words , which leads to more informative models [ 16 ] . p(w|r , Ψ(t ) ) = λBp(w|B ) + ( 1 − λB ) p(t)(w|z)p(t)(z|r ) z∈Z
( 9 ) p(t)(w|z ) is from θ(t ) , and p(t)(z|r ) is from φ(t ) . p(w|B ) is the background model , which we set as follows . p(w|B ) = d∈D c(w , d ) w∈V d∈D c(w , d )
In the M step , we find the estimation Ψ(t+1 ) that maximizes the expectation of the complete likelihood Q(Ψ|Ψ(t ) ) using the following updating formulas . p(t+1)(r|α ) = d∈D p(r|d , Ψ(t ) ) d∈D p(r|d , Ψ(t))ld d∈D p(r|d , Ψ(t ) ) d∈D p(r|d , Ψ(t))(ld − µ(t ) d∈D p(r|d , Ψ(t ) )
µ(t+1 )
|D|
= r r )(ld − µ(t ) r )T
( 10 )
( 11 )
( 12 )
( 13 ) p(l|z , Ψ ) =
= p(l|r , Ψ)p(r|z , Ψ ) p(l|µr , Σr ) p(z|r)p(r|α ) p(z|Ψ )
( 4 ) where p(z|Ψ ) = on Equation 2 . r∈R p(z|r)p(r|α ) and p(l|µr , Σr ) is based After we get p(l|z , Ψ ) , we can get p(z|l , Ψ ) according to
Σ(t+1 ) r
=
Bayes’ theorem . p(z|l , Ψ ) ∝ p(l|z , Ψ)p(z|Ψ )
∝ p(l|µr , Σr)p(z|r)p(r|α )
( 5 )
In order to get updated θ(t+1 ) and φ(t+1 ) in the M step , we use another EM algorithm to estimate them . We define the hidden variable ϕ(w , r , z ) , which corresponds to the events that word w in region r is from topic z . The relevant EM updating process is as follows .
WWW 2011 – Session : Spatio Temporal AnalysisMarch 28–April 1 , 2011 , Hyderabad , India250
ϕ(w , r , z ) ← p(z|r ) ← p(w|z ) ←
( 1 − λB)p(w|z)p(z|r ) r∈R p(w|z)p(z|r )
λBp(w|B ) + ( 1 − λB ) w∈V c(w , d)p(r|d , Ψ(t))ϕ(w , r , z ) w∈V c(w , d)p(r|d , Ψ(t))ϕ(w , r , z ) d∈D c(w , d)p(r|d , Ψ(t))ϕ(w , r , z ) d∈D c(w , d)p(r|d , Ψ(t))ϕ(w , r , z ) z∈Z w∈V
( 14 )
( 15 )
( 16 )
θ and φ obtained from the above EM steps are considered as θ(t+1 ) and φ(t+1 ) . 5.4 Discussion r r and Σ(t+1 )
541 Complexity analysis We analyze the complexity of parameter estimation process in Section 53 In the E step , it needs O(KN|V | ) to calculate p(w|r , Ψ(t ) ) in Equation 9 for all ( w , r ) pairs , where K is the number of topics , N is the number of regions and |V | is the vocabulary size . To calculate p(wd|r , Ψ(t ) ) in Equation 8 for all ( d , r ) pairs , it needs O(N|W| ) where |W| is the total counts of the words in all the documents . It also needs O(|D| ) to calculate p(ld|r , Ψ(t ) ) for all the documents . Therefore , the complexity of getting p(r|d , Ψ(t ) ) for all ( r , d ) pairs is O(KN|V |+N|W| ) . In the M step , it needs O(N|D| ) to get the updated p(t+1)(r|α ) , µ(t+1 ) as in Equations 11 , 12 and 13 for all the regions . To get updated θ(t+1 ) and φ(t+1 ) , it needs O(T2KN|V | ) where T2 is the number of iterations for Equations 14 , 15 and 16 . Therefore , the complexity of M step is O(N|D| + T2KN|V | ) . The complexity of the whole framework is O(T1(KN|V | + N|W| + N|D| + T2KN|V |) ) , where T1 is the number of iterations in the EM algorithm . 542 Parameter setting In our model , we have three parameters , ie , the mixing weight of the background model λB , the number of topics K and the number of regions N . A large λB can exclude the common words from the topics . In this paper λB is fixed as 0.9 following the empirical studies [ 16 , 9 ] . K is the desired number of geographical topics . Users can specify the value of K according to their needs . N is the number of the regions used in our model for generating the topics , which provides the flexility for users to adjust the granularity of regions . The larger N is , the more fine grained the regions are . For example , in Landscape dataset in Example 2 , a large N is preferred , since we would like to use fine grained regions to handle complex shapes of different landscape categories . In Festival dataset in Example 1 , N is preferred to be close to K , since we would like to discover the topics in different areas . In our experiment , small changes of N yield similar results . When the parameters are unknown , Schwarz ’s Bayesian information criterion ( BIC ) provides an efficient way to select the parameters . The BIC measure includes two parts : the log likelihood and the model complexity . The first part characterizes the fitness over the observations , while the second is determined by the number of parameters . In practice we can train models with different parameters , and compare their BIC values . The model with the lowest value will be selected as the final model .
543 Topic guidance in comparison We can add some guidance in the framework to make the discovered geographical topics aligned with our needs for topic comparison . For example , in Food data set , we would like to compare the geographical distribution of Chinese food and Italian food , we can add some prior knowledge in two topics and guide one topic to be related to Chinese food and the other to be related to Italian food . Specifically , we define a conjugate prior ( ie , Dirichlet prior ) on each multinomial topic distribution . Let us denote the Dirichlet prior σz for topic z . σz(w ) can be interpreted as the corresponding pseudo counts for word w when we estimate the topic distribution p(w|z ) . With this conjugate prior , we can use the Maximum a Posteriori ( MAP ) estimator for parameter estimation , which can be computed using the same EM algorithm except that we would replace Equation 16 with the following formula : d∈D c(w , d)p(r|d , Ψ(t))ϕ(w , r , z ) + σz(w ) d∈D(c(w , d)p(r|d , Ψ(t))ϕ(w , r , z ) + σz(w ) ) w∈V p(w|z ) ←
( 17 )
544 Comparison with GeoFolk In [ 13 ] , Sizov proposed a novel model named GeoFolk to combine the semantics of text feature and spatial knowledge . Sizov shows that GeoFolk works better than text only analysis in tag recommendation , content classification and clustering . However , GeoFolk is not suitable for region clustering due to two facts : First , GeoFolk models each region as an isolated topic and thus fails to find the common topics in different geographical sites . Second , GeoFolk assumes the geographical distribution of each topic is Gaussian , which makes its results similar to the results of the location driven model using GMM . As a result , it would fail to discover the meaningful topics with non Gaussian geographical distributions . For example , in the Landscape dataset in Example 2 , the coast topic is along the coastline , GeoFolk fails to discover it . For the mountain topic , GeoFolk cannot discover it because the mountain topic is located in different areas . In contrast , our LGTA model separates the concepts of topics and regions , and the coordinates are generated from regions instead of topics . Therefore , we can discover the meaningful geographical topics properly .
6 . EXPERIMENT 6.1 Data Set
We evaluate the proposed models on Flickr dataset . We crawl the images with GPS locations through Flickr API 1 . Flickr API supports search criteria including tag , time , GPS range , etc We select several representative topics including Landscape , Activity , Manhattan , National Park , Festival , Car and Food . The statistics of the datasets are listed in Table 3 . For Landscape dataset , we crawl the images containing tag landscape and keep the images containing tags mountains , mountain , beach , ocean , coast , desert around US . For Activity data set , we crawl the images containing tags hiking and surfing around US . For Manhattan dataset , we crawl the images containing tag manhattan in New York City . For National Park dataset , we crawl the images containing
1http://wwwflickrcom/services/api/
WWW 2011 – Session : Spatio Temporal AnalysisMarch 28–April 1 , 2011 , Hyderabad , India251 Table 3 : The statistics of the datasets .
# image # words 5791 1931 28922 1751 2384 34707 151747
1143 408 868 421 351 12 278
Data set Landscape Activity Manhattan Festival National Park Car Food
Time span 09/01/09 09/01/10 09/01/09 09/01/10 09/01/09 09/01/10 09/01/09 09/01/10 09/01/09 09/01/10 01/01/06 09/01/10 01/01/06 09/01/10 tag nationalpark and keep the images with tags rockymountain , yellowstone , olympic , grandcanyon , everglades , smokymountain , yosemite , acadia . For Festival dataset , we crawl the images containing tag festival in New York , Los Angeles , Chicago , Washington DC , San Francisco and Austin area . For Car data set , we crawl the images containing tags chevrolet , pontiac , cadillac , gmc , buick , audi , bmw , mercedesbenz , fiat , peugeot , citroen , renault . We remove the images with tags autoshow , show , race , racing and only keep car brand names in the dataset . For Food dataset , we crawl the images containing tags cuisine , food , gourmet , restaurant , restaurants , breakfast , lunch , dinner , appetizer , entree , dessert and keep 278 related food tags including dish names and food style names .
We compare the following methods in the experiment . • LDM : Location driven model in Section 3 . • TDM : Text driven model in Section 4 . We set regularization factor λ as 0.5 and add one edge between two documents if their distance is within threshold ε . ε varies according to different settings in the datasets as shown in Section 62
• GeoFolk : The topic modeling method proposed in [ 13 ] , which uses both text and spatial information ( see Section 544 )
• LGTA : Latent Geographical Topic Analysis framework in Section 5 .
6.2 Geographical Topic Discovery
In this section , we compare the discovered geographical topics by different methods in several representative datasets . 621 Topic discovery for Landscape dataset In Landscape dataset , we intend to discover 3 topics , ie , different landscapes . We set ε in TDM as 0.1(∼10km ) , since we assume that two locations within 10km should have similar landscapes . In LGTA , we set the number of regions N as 30 , since we would like to use 10 regions in average to cover each landscape topic . We list the topics discovered by different methods in Table 4 , and we also plot the document locations for different topics on the map in Figure 1 . Since there are no apparent location clusters for the topics , LDM and GeoFolk fail to discover meaningful geographical topics due to their inappropriate assumption that each topic has a location distribution like Gaussian . TDM performs better than LDM and GeoFolk . Topic 1 of TDM is related to coast , but Topic 2 and Topic 3 are not distinguishable . In LGTA , we assume that the topics are generated from a set of regions , so we can clearly identify three clusters coast , desert and mountain in Table 4 . From the LGTA topics in Figure 1 , we can see that Topic 1(coast ) is along the coastline , Topic 2(desert ) is aligned with the desert areas in US and Topic 3(mountain ) maps to the mountain areas in US .
622 Topic discovery for Activity dataset In Activity dataset , we intend to discover 2 topics , ie , hiking and surfing . We set ε in TDM as 0.1(∼10km ) , since we assume that two locations within 10km should have similar activities . In LGTA , we set the number of regions N as 20 , since we would like to use 10 regions in average to cover each activity topic . Similar to Landscape dataset , LDM and GeoFolk fail to discover meaningful geographical topics because there are no apparent location clusters for the topics . The result of LDM is similar to GeoFolk , while the result of TDM is similar to LGTA . Both TDM and LGTA can identify two topics , ie , hiking and surfing . We list the topics discovered by GeoFolk and LGTA in Table 5 .
Table 5 : Topics discovered for Activity dataset .
GeoFolk
LGTA
Topic 1 hiking 0.077 mountains 0.037 mountain 0.027 california 0.027 surfing 0.024 beach 0.023 nature 0.020 ocean 0.019 trail 0.015 hike 0.015 *[mtn ] is mountain . [ nh ] is newhampshire .
Topic 2 hiking 0.095 mountains 0.050 mountain 0.041 surfing 0.032 beach 0.030 [ nh ] 0.029 white[mtn]s 0.022 trail 0.021 ocean 0.021 nature 0.019
Topic 1(surfing ) surfing 0.070 beach 0.065 california 0.059 ocean 0.053 surf 0.031 hiking 0.031 waves 0.028 water 0.025 surfer 0.022 pacific 0.018
Topic 2(hiking ) hiking 0.109 mountains 0.059 mountain 0.042 nature 0.027 trail 0.019 hike 0.017 desert 0.017 washington 0.014 lake 0.013 camping 0.013
623 Topic discovery for Manhattan dataset In Manhattan dataset , we intend to discover 5 topics , ie , different regions in Manhattan . We set ε in TDM as 0001(∼01km ) , since the photos in Manhattan are very dense . In LGTA , we make the number of regions close to the number of topics , since we would like to discover large regions in Manhattan . We set the number of regions N as 10 . Overall , LDM , GeoFolk and LGTA can identify different regions in Manhattan because meaningful topics can be obtained by clustering based on location , such as topic lowermanhattan and topic midtown . Although we have the regularization based on spatial information in TDM , it can only guarantee the smoothness of topics in the neighborhood . TDM is likely to mix the words from distant areas in the same topic . For example , TDM mix timessquare 0.060 , upperwestside 0.051 , chinatown 0.033 , greenwichvillage 0.031 and unionsquare 0.017 into one topic , and these words are distant from each other . 624 Topic discovery for Festival dataset In Festival dataset , we intend to discover 10 topics , ie , festivals in different cities . We set ε in TDM as 0.01(∼1km ) , since 1km is a reasonable range in cities . In LGTA , we set the number of regions N as 20 . Similar to Manhattan dataset , LDM , GeoFolk and LGTA can discover meaningful geographical topics , because the cities are distant from each other in space . TDM is possible to mix the festivals from different areas into the same topic . We list the topics related to southbysouthwest festival discovered by TDM , GeoFolk and LGTA in Table 6 . The result of LDM is similar to GeoFolk . From Table 6 , we can find that GeoFolk and LGTA discover pure topics related to southbysouthwest festival in Austin , but TDM mix southbysouthwest in Austin and atlanticantic streetfair in New York together . 625 Topic discovery for National Park dataset In National Park dataset , we intend to discover 8 topie , different national parks . We set ε in TDM as ics , 0.01(∼1km ) , since 1km is a reasonable range in national park
WWW 2011 – Session : Spatio Temporal AnalysisMarch 28–April 1 , 2011 , Hyderabad , India252 Table 4 : Topics discovered for Landscape dataset .
Topic 1 california ocean mountains water beach desert mountain sunset coast sea
LDM Topic 2 mountains desert mountain utah arizona lake snow southwest rock water
Topic 3 beach ocean water mountains sea sunset mountain blue seascape lake
Topic 1 ocean beach california water sea sunset seascape sand arizona blue
TDM
Topic 2 mountains desert mountain california utah nationalpark snow rock park lake
Topic 3 mountains water mountain trees coast lake reflection oregon scenery washington
Topic 1 california ocean water beach mountains coast mountain sea sunset pacific
GeoFolk
Topic 2 desert mountains mountain california water utah arizona sunset rock snow
Topic 3 beach ocean water mountains sea sunset mountain blue seascape lake
Topic 1 beach ocean water california sea coast sunset seascape pacific sand
LGTA
Topic 2 desert california mountains mountain arizona utah rock southwest park sunset
Topic 3 mountains mountain lake trees water snow scenery hiking washington reflection
LDM(Topic 1 )
LDM(Topic 2 )
LDM(Topic 3 )
TDM(Topic 1 )
TDM(Topic 2 )
TDM(Topic 3 )
GeoFolk(Topic 1 )
GeoFolk(Topic 2 )
GeoFolk(Topic 3 )
LGTA(Topic 1(coast ) )
LGTA(Topic 2(desert ) )
LGTA(Topic 3(mountain ) )
Figure 1 : The document locations of different topics for Landscape dataset .
Table 6 : Topic southbysouthwest for Festival dataset .
TDM sxsw 0.124 brooklyn 0.082 southbysouthwest 0.061 south 0.055 streetfestival 0.050 southwest 0.049 funfunfunfest 0.044 atlanticavenue 0.044 atlanticantic 0.041 streetfair 0.040
GeoFolk sxsw 0.173 austin 0.136 southbysouthwest 0.127 texas 0.125 south 0.121 southwest 0.103 downtown 0.093 musicfestival 0.074 live 0.034 stage 0.010
LGTA sxsw 0.163 austin 0.149 texas 0.142 southbysouthwest 0.085 south 0.070 funfunfunfest 0.061 southwest 0.060 musicfestival 0.057 downtown 0.040 music 0.034 areas . In LGTA , we set the number of regions N as 20 . We show that even if there are apparent location clusters , LDM and GeoFolk may obtain misleading results . As shown in Table 7 , GeoFolk merges acadia , everglades and greatsmokymountain together into topic acadia , because these three national parks have fewer photos than other parks and are all located on the east coast of US . GeoFolk , similar to LDM , uses one Gaussian distribution to cover all these three parks , so the words from these parks are mixed into a single topic . In TDM , topic acadia is mixed with rockymountain . In LGTA , we use the fine grained regions to generate the topics , so all the words in LGTA are related to acadia , where mountdesertisland is home to acadia and barharbor is a town on mountdesertisland .
Table 7 : Topic acadia for National park dataset . TDM acadia[npk ] 0.088 maine 0.087 acadia 0.087 colorado 0.081 rocky[mtn][npk ] 0.071 northrim 0.050 rockymountain 0.036 newengland 0.036 barharbor 0.036 rockymountains 0.034 *[mtn ] is mountain . [ npk ] is nationalpark . [ isl ] is island .
GeoFolk acadia[npk ] 0.108 maine 0.107 acadia 0.107 everglades 0.079 florida 0.058 tennessee 0.050 barharbor 0.043 newengland 0.043 greatsmoky[mtn][npk ] 0.043 mountdesert[isl ] 0.036
LGTA acadia[npk ] 0.208 maine 0.205 acadia 0.205 barharbor 0.084 newengland 0.084 mountdesert[isl ] 0.070 beach 0.025 outdoor 0.016 flowers 0.015 wood 0.012
626 Topic discovery for Car dataset . In Car dataset , we intend to discover 3 topics . We set ε in TDM as 0.1(∼10km ) , since 10km is a reasonable range in the world scale . In LGTA , we would like to use the fine grained regions to discover the possible topics , so we set the number of regions N as 50 . In Car dataset , there are no apparent location clusters or good text indications . As shown in Table 8 , LDM , TDM and GeoFolk all fail to discover mean ingful topics . However , LGTA can get the interesting geographical topics . In LGTA , Topic 1 is about American cars including chevrolet , pontiac , cadillac , gmc and buick . Topic 2 is related to German cars including audi , mercedesbenz and bmw . Topic 3 is about those European cars excluding German brands , including fiat , peugeot , citroen and renault . These interesting patterns can be discovered because these car brands in the same topic have similar geographical distributions . 627 Summary With the experiments on these representative datasets , we can summarize the results as follows . If there are apparent location cluster patterns such as Manhattan and Festival datasets , LDM and GeoFolk are able to work , so is LGTA . If there are no apparent location clusters but good text indications in the datasets such as Landscape and Activity datasets , LDM and GeoFolk fail , TDM may work and LGTA works well . Even if there are location cluster patterns , LDM and GeoFolk may fail , while LGTA is still robust , such as in National Park dataset . In the difficult datasets such as Car dataset , only LGTA can discover meaningful geographical topics . Overall , LGTA is the best and most robust method for geographical topic discovery . 6.3 Quantitative Measures
In this section , we use some quantitative measures to eval uate the performances of different methods .
We use perplexity to evaluate the performance of topic modeling [ 1 ] . We keep 80 % of the data collection as the train set and use the remaining collection as the held out test set . We train the models on the train set and compute the perplexity of the test set to evaluate the models . A lower perplexity score indicates better generalization performance of the model . Specifically , we use text perplexity to measure the topic qualities and use location/text perplexity to measure the performance of geographical topics . perplexitytext(Dtest ) = exp{− d∈Dtest log p(wd )
} perplexitylocation/text(Dtest ) = exp{−
Nd d∈Dtest d∈Dtest log p(wd , ld )
} d∈Dtest
Nd
WWW 2011 – Session : Spatio Temporal AnalysisMarch 28–April 1 , 2011 , Hyderabad , India253 Table 8 : Topics discovered for Car dataset
TDM
LDM Topic 2 chevrolet pontiac cadillac buick gmc
Topic 3 fiat renault citroen peugeot audi
Topic 1 chevrolet gmc cadillac buick pontiac *If the probability of a word in a topic is less than 1e 4 , output as ‘ ’ .
Topic 2 renault peugeot mercedesbenz buick
Topic 1 bmw chevrolet fiat citroen buick
Topic 3 cadillac audi pontiac gmc buick where Dtest is the test collection and Nd is document length of document d .
We list the results of text perplexity for different methods in Table 9 and the results of location/text perplexity for LDM , GeoFolk and LGTA in Table 10 . TDM is not available in Table 10 because we cannot estimate the location probabilities using TDM . From Table 9 and 10 , we can see both text perplexity and location/text perplexity of LGTA are the lowest in all the datasets . Especially , in Landscape , Activity and Car datasets , neither LDM nor GeoFolk can discover meaningful geographical topics , so the perplexities of LDM and GeoFolk in these data sets are much larger than those of LGTA .
Table 9 : Text perplexity in datasets .
Data set Landscape Activity Manhattan National Park Festival Car
LDM
394.680 184.970 193.823 118.159 177.978 9.936
TDM
444.676 176.234 201.042 120.100 214.975 9.926
GeoFolk 384.411 184.979 193.001 117.238 173.621 9.937
LGTA 366.546 157.775 192.010 117.077 170.033 9.924
Table 10 : Location/text perplexity in datasets . Data set Landscape Activity Manhattan National Park Festival Car
LGTA 569.047 257.086 105.684 103.853 91.230 8718.927
LDM 688.628 358.559 109.103 136.435 99.308 40242.767
GeoFolk 672.967 358.577 107.620 112.973 94.604 40348.974
In Table 11 , we show the average distance of word distributions of all pairs of topics measured by KL divergence . The larger the average KL divergence is , the more distinct the topics are . In Landscape and Activity datasets , LDM and GeoFolk fail to discover meaningful topics , so the average KL divergence of TDM and LGTA is much larger than those of LDM and GeoFolk . In Manhattan , National Park and Festival datasets , the average KL divergence of different methods are similar . In Car datasets , the average KLdivergence of TDM and LGTA are much larger than LDM and GeoFolk . Although the words from different topics of TDM in Car dataset are distinct , the topics are not meaningful as shown in Section 626
Table 11 : Average KL divergence between topics in datasets . Data set Landscape Activity Manhattan National Park Festival Car 6.4 Geographical Topic Comparison
GeoFolk 0.141 0.164 0.965 2.474 2.080 2.365
LGTA 0.281 0.491 1.020 2.598 2.258 3.731
TDM 0.311 0.402 1.091 2.325 2.109 3.745
LDM 0.159 0.164 0.908 2.576 2.206 2.518
In this section , we show the results of topic comparison for Car and Food datasets .
Topic 1 fiat renault citroen peugeot mercedesbenz
GeoFolk Topic 2 peugeot chevrolet bmw fiat renault
Topic 3 chevrolet pontiac cadillac gmc buick
Topic 1 fiat renault citroen peugeot
LGTA
Topic 2 bmw audi mercedesbenz
Topic 3 chevrolet pontiac cadillac gmc buick
641 Topic comparison for Car dataset In Figure 2 , we plot the topic distribution in different locations for Car dataset according to the discovered topics from LGTA in Section 626 Compared with European cars , American cars are mainly in North America . European excluding German cars dominate most of European areas . German cars , as luxury brands , are popular in Germany and other areas such as East Asia and Australia . 642 Topic comparison for Food dataset In Food dataset , we set the number of topics K as 10 . To derive the topics that we are interested in , we set the priors according to Equation 17 . We use the words chinese , japanese , italian , french , spanish and mexican as priors for six topics and leave the remaining four topics to other possible food preferences . We set the number of regions N as 100 , since we would like to use more find grained regions to discover the food preferences . As shown in Table 12 , each of the six topics consists of the typical food related to the preferences . We plot the comparison of the topics on the maps in Figure 3 . From Figure 3 , we can find that Chinese food is popular in China and Southeast Asia . In US and West Europe , Chinese food also has certain popularity . Japanese food is dominant in Japan , and it is welcome on the west coast of US . Italian food is very popular in Mediterranean area , and it is popular in US too . French food is popular in France and US . Spanish food is popular in Spain , US and part of South America . Mexican food is the main food in Mexico , and it highly influences the Southwestern area of US . From all these figures , we can find that each food preference has its main area . In the metropolitan areas in US , different kinds of food co exist .
7 . RELATED WORK
In this section we discuss some work related to our study , including geo tagged social media mining , topic modeling and image processing using spatial coherence .
Geo tagged social media mining With the development of GPS technology , several studies have been done in geotagged social media mining . Rattenbury et al . [ 11 ] use Scalestructure Identification method to extract place and event semantics for tags based on the GPS metadata of the images in Flickr . Crandall et al . [ 4 ] combine content analysis based on text tags and image data with structural analysis based on geospatial data to estimate the photo locations . In [ 7 ] , Kennedy et al . use location , tags and visual features of the images to generate diverse and representative images for the landmarks . All these studies are related to the interplay between tags and locations in different applications , but they do not touch the problem of geographical topics discussed in this paper . Sizov [ 13 ] proposed a framework called GeoFolk to combine text and spatial information together to construct better algorithms for content management , retrieval , and sharing in social media . To make use of spatial information , GeoFolk assumes that each topic generates latitude and longitude from two topic specific Gaussian
WWW 2011 – Session : Spatio Temporal AnalysisMarch 28–April 1 , 2011 , Hyderabad , India254 American Car
European(excluding German ) Car
German Car
Figure 2 : Topic comparison for Car dataset . For topic z , we plot p(z|l ) for all the locations . The larger p(z|l ) is , the darker the location is . We only plot the locations with p(l|z ) > 1e−4 .
Chinese Food chinese 0.552 noodles 0.067 dimsum 0.064 hotpot 0.039 rice 0.038 noodle 0.035 tofu 0.020 dumpling 0.018 duck 0.018 prawn 0.017
Table 12 : Topic discovered for Food dataset .
Japanese Food japanese 0.519 ramen 0.104 soba 0.066 noodle 0.065 sashimi 0.039 yakitori 0.030 okonomiyaki 0.026 udon 0.026 tempura 0.020 curry 0.016
Italian Food italian 0.848 cappuccino 0.067 latte 0.048 gelato 0.030 pizza 0.002 pizzeria 0.002 mozzarella 0.001 pasta 0.001 ravioli 0.000 pesto 0.000
French Food french 0.564 bistro 0.070 patisserie 0.056 bakery 0.049 resto 0.044 pastry 0.033 tarte 0.026 croissant 0.021 baguette 0.019 mediterranean 0.018
Spanish Food spanish 0.488 tapas 0.269 paella 0.076 pescado 0.059 olives 0.032 stickyrice 0.017 tortilla 0.013 mediterranean 0.010 mussels 0.008 octopus 0.008
Mexican Food mexican 0.484 tacos 0.069 taco 0.059 salsa 0.036 cajun 0.031 burrito 0.027 crawfish 0.023 guacamole 0.022 margarita 0.020 cocktails 0.020 distributions . However , geographical topics may not be like Gaussian distributions , such as topics “ hiking ” and “ surfing ” . In our model , we distinguish the concepts of topics and regions and provide a more systematic way to discover geographical topics and we also provide geographical topic comparison which is not available in the existing models .
Topic modeling Topic modeling is a classic problem in text mining . The most representative models include PLSA [ 6 ] and LDA [ 1 ] . Wang et al . [ 15 ] use an LDA style topic model to capture both the topic structure and the changes over time . In these studies , they do not consider the location information of the documents , so they do not focus on geographical topics . In [ 14 ] , Wang et al . propose a Location Aware Topic Model to explicitly model the relationships between locations and words , where the locations are represented by predefined location terms in the documents . Mei et al.[9 ] proposed a probabilistic approach to model the subtopic themes and spatiotemporal theme patterns simultaneously in weblogs , where the locations need to be predefined . However , in geographical topic discovery , we do not know the locations or regions of interest beforehand . If we directly use the administrative region partitions , it would be difficult to discover topics whose corresponding regions are not aligned well with the pre segmented regions . In [ 8 ] , Mei et al . proposed a model called NetPLSA to combine PLSA with a graph based regularizer , where adjacent nodes in document similarity graph should have similar topic distribution . We use NetPLSA in the text driven model . However , NetPLSA cannot provide the geographical distribution of the topics . As shown in experiment , our LGTA model not only is more robust but also can provide interesting topic comparison results .
Spatial coherence inside images Our work is also partially motivated by the recent work in computer vision [ 2 , 10 , 12 , 14 ] which try to simultaneously do object classification and segmentation in images . However , these studies are fundamentally different from this paper in three aspects . First , a spatial coherent segment is part of a image , while our geographical region contains multiple documents . This fundamental difference leads to different generative models . Second , segmentations in one image are usually clearly separated by contours and boundaries , which makes it possible to rely on superpixels [ 2 , 12 ] to merge into an object of interests . However , there are no contours in geographical distribution . At last , the computer vision community focus on image classification instead of topic comparison , while the latter is important in Web mining .
8 . CONCLUSION
The emerging trend of GPS associated document opens up a wide variety of novel applications . In this paper , we introduce the problem of geographical topic discovery and comparison . We propose and compare three strategies of modeling geographical topics including location driven model , text driven model , and a novel joint model called LGTA ( Latent Geographical Topic Analysis ) that combines both location and text information . To test our approaches , we collect several representative datasets from Flickr website including Landscape , Activity , Manhattan , National park , Festival , Car , and Food . Evaluation results show that the new LGTA model works well for not only finding regions of interests but also providing effective comparisons of different topics across locations .
Our work opens up several interesting future directions . First , we can apply our models on other interesting data sources . For example , we can mine interesting geographical topics from the tweets associated with user locations in Twitter . Second , other than topic discovery and comparison , we would like to extend our model to other text mining tasks . For example , we can do geographical sentiment analysis for different subjects .
Acknowledgement Research was sponsored in part by the US National Science Foundation under grants CCF 0905014 , CNS 0931975 , CNS 1027965 , and IIS 0713581 , by the Army Research Laboratory under Cooperative Agreement Number W911NF 092 0053 ( NS CTA ) , and Air Force Office of Scientific Research MURI award FA9550 08 1 0265 , in part by a Beckman Institute ( Illinois ) Seed Grant and in part by an NSF Grant IIS 1049332 EAGER . The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies , either expressed or implied , of the Army Research Laboratory or the US Government . The US Government is authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation here on .
WWW 2011 – Session : Spatio Temporal AnalysisMarch 28–April 1 , 2011 , Hyderabad , India255 Chinese Food
Japanese Food
Italian Food
French Food
Spanish Food
Mexican Food
Figure 3 : Topic comparison for Food dataset . For topic z , we plot p(z|l ) for all the locations . The larger p(z|l ) is , the darker the location is . We only plot the locations with p(l|z ) > 1e−4 . 9 . REFERENCES [ 1 ] D . M . Blei , A . Y . Ng , and M . I . Jordan . Latent geographic knowledge using location aware topic model . In GIR , pages 65–70 , 2007 . dirichlet allocation . Journal of Machine Learning Research , 3:993–1022 , 2003 .
[ 2 ] L . Cao and L . Fei Fei . Spatially coherent latent topic model for concurrent segmentation and classification of objects and scenes . In ICCV , pages 1–8 , 2007 . [ 3 ] D . Comaniciu and P . Meer . Mean shift : A robust approach toward feature space analysis . IEEE Trans . Pattern Anal . Mach . Intell . , 24(5):603–619 , 2002 .
[ 4 ] D . J . Crandall , L . Backstrom , D . P . Huttenlocher , and
J . M . Kleinberg . Mapping the world ’s photos . In WWW , pages 761–770 , 2009 .
[ 5 ] M . Ester , H P Kriegel , J . Sander , and X . Xu . A density based algorithm for discovering clusters in large spatial databases with noise . In KDD , pages 226–231 , 1996 .
[ 6 ] T . Hofmann . Probabilistic latent semantic indexing . In
SIGIR , pages 50–57 , 1999 .
[ 7 ] L . S . Kennedy and M . Naaman . Generating diverse and representative image search results for landmarks . In WWW , pages 297–306 , 2008 .
[ 8 ] Q . Mei , D . Cai , D . Zhang , and C . Zhai . Topic modeling with network regularization . In WWW , pages 101–110 , 2008 .
[ 9 ] Q . Mei , C . Liu , H . Su , and C . Zhai . A probabilistic approach to spatiotemporal theme pattern mining on weblogs . In WWW , pages 533–542 , 2006 .
[ 10 ] J . C . Niebles , H . Wang , and F F Li . Unsupervised learning of human action categories using spatial temporal words . International Journal of Computer Vision , 79(3):299–318 , 2008 .
[ 11 ] T . Rattenbury , N . Good , and M . Naaman . Towards automatic extraction of event and place semantics from flickr tags . In SIGIR , pages 103–110 , 2007 .
[ 12 ] B . C . Russell , W . T . Freeman , A . A . Efros , J . Sivic , and A . Zisserman . Using multiple segmentations to discover objects and their extent in image collections . In CVPR ( 2 ) , pages 1605–1614 , 2006 .
[ 13 ] S . Sizov . Geofolk : latent spatial semantics in web 2.0 social media . In WSDM , pages 281–290 , 2010 .
[ 14 ] C . Wang , J . Wang , X . Xie , and W Y Ma . Mining
[ 15 ] X . Wang and A . McCallum . Topics over time : a non markov continuous time model of topical trends . In KDD , pages 424–433 , 2006 .
[ 16 ] C . Zhai , A . Velivelli , and B . Yu . A cross collection mixture model for comparative text mining . In KDD , pages 743–748 , 2004 .
APPENDIX A . EM ALGORITHM DERIVATION
The expectation of the complete likelihood Q(Ψ|Ψ(t ) ) is .
Q(Ψ|Ψ(t ) ) = E[log p(rd|α)p(wd , ld|rd , Ψ)|D , Ψ(t ) ]
= p(r|d , Ψ(t ) ) log p(r|α ) + d∈D r∈R r∈R d∈D d∈D d∈D r∈R p(r|d , Ψ(t ) ) log p(ld|r , Ψ ) + p(r|d , Ψ(t ) ) log p(wd|r , Ψ )
( 18 )
In the E step , p(r|d , Ψ(t ) ) is updated according to Bayes’ rule as in Equation 6 . In the M step , it find the estimation Ψ(t+1 ) that maximize the complete likelihood Q(Ψ|Ψ(t) ) . Since θ , α , φ , µ and Σ are in three different summands in Equation 18 , we can optimize each summand separately to find Ψ(t+1 ) that maximize the complete likelihood Q(Ψ|Ψ(t ) ) as in Equation 11 , 12 and 13 .
We use EM algorithm to find the optimal parameters θ and φ which maximize the last summand in Equation 18 . The corresponding log likelihood that we would like to maximize is as follows . c(w , d)p(r|d , Ψ(t ) )
L(θ , φ ; D ) = r∈R w∈V d∈D log(λBp(w|B ) + ( 1 − λB ) p(w|z)p(z|r ) ) z∈Z
Equations 14 , 15 and 16 correspond to the EM steps to update θ(t+1 ) and φ(t+1 ) .
WWW 2011 – Session : Spatio Temporal AnalysisMarch 28–April 1 , 2011 , Hyderabad , India256
