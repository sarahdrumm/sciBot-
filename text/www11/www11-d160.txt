A Fine Grained Digestion of News Webpages through Event Snippet Extraction
Rui Yan
Dept . of Computer Science
Peking University , China ryan@pkueducn
Liang Kong
Dept . of Machine Intelligence
Peking University , China kongliang@pkueducn ∗
Yu Li
School of Computer Science
Beihang University , China carp84@gmail.com
Yan Zhang
Dept . of Machine Intelligence
Peking University , China zhy@cispkueducn
Xiaoming Li
Dept . of Computer Science
Peking University , China lxm@pkueducn
ABSTRACT We describe a framework to digest news webpages in finer granularity : to extract event snippets from contexts . “ Events ” are atomic text snippets and a news article is constituted by more than one event snippet . Event Snippet Extraction ( ESE ) aims to mine these snippets out . The problem is important because its solutions may be applied to many information mining and retrieval tasks . The challenge is to exploit rich features to detect snippet boundaries , including various semantic , syntactic and visual features . We run experiments to present the effectiveness of our approaches .
Categories and Subject Descriptors H4m [ Information Systems ] : Miscellaneous
General Terms Algorithms , Experimentation , Measurement
Keywords News digestion , event snippet extraction , web mining
1 .
INTRODUCTION
With a large volume of news webpages on the Web , news digestion increasingly becomes an essential component of web contents analysis . We investigate the problem of Event Snippet Extraction ( ESE ) to divide a news webpage into event centered snippets . ESE is highly motivated because the event distilling improves retrieval experience by presenting only the relevant parts instead of the whole page and is of potential use in applications like discourse analysis . News clustering and classification can also be in accurate granularity with less jeopardized noises and so be content extraction and webpage deduplication . To sum up , fine grained digestions by ESE open doors to wide use on Web .
ESE is related to traditional text segmentation which often fails to be event oriented [ 1 ] . [ 2 ] proposes an introductive ∗
Corresponding author .
Copyright is held by the author/owner(s ) . WWW 2011 , March 28–April 1 , 2011 , Hyderabad , India . ACM 978 1 4503 0637 9/11/03 . work but can still be polished : we consider more detailed elements such as rich semantic , syntactic and visual features .
2 . SNIPPET EXTRACTION
Based on the topic drift principle investigated in [ 2 ] , we treat the sentence s with a timestamp as a potential head sentence ( sh ) of an event snippet ( S ) . Assume in the news document D ( D = {s1 ; s2 ; : : : ; sjDj} ) each S can be represented as <t:{s}> , where t is the timestamp of sh and {s} is the set of sentences that belong to S . Suppose there are m snippets in D , ( ∪m k=1Sk ) ⊆ D and ∀i ̸= j ; Si ∩ Sj = ∅ . Original sentence sequence is preserved in snippets . Neighboring contexts tend to describe the same event due to the semantic consecutiveness of natural language discourse . A snippet expands by absorbing texts pertinent to the event . 2.1 Semantic Relevance
Intuitively , semantic relevance Rel of a pending sentence ( sp ) to S can be measured by the probability being generated from the language model of the snippet ( LM(S) ) , as defined in Equation ( 1 ) . Sentences with low probability are clearly off event and not related to the expanding snippet .
 ∏ w2sp
∑ ( 1 + ) ∑ tf ( w ; si ) + jsij
2S si
 1jspj
2S si
( 1 )
Rel(sp ; S ) = p(spjLM ( S ) ) = is empirically set at 0.01 as a smoothing factor and |s| is the size of sentence s . tf ( w ; s ) is the term frequency of word w in s . Equation ( 1 ) assumes all sentences are equally weighted while in fact some sentences have larger probability to be on event than others in S . We denote such probability as sentence significance . Semantic , syntactic and visual features distinguish significance and we exploit them next . 2.2 Weighted Semantic Relevance
Distance Decay ( DD ) . The tendency for contexts to agglomerate attenuates as distance becomes larger from head sentence sh , ie , a distance decay . According to our investigation and statistics in [ 2 ] , the snippet length L follows a Gaussian distribution N ( ; 2 ) . Given x = ||sp|| where ||s|| is the offset of sentence s from sh , distance decay fd(x ) is : fd(x ) = P ( x < L ) =
+1
N ( t ; ; 2)dt :
( 2 )
∫ x
WWW 2011 – PosterMarch 28–April 1 , 2011 , Hyderabad , India157 3 . EXPERIMENTS
In a 10 fold cross validation manner , we test our proposed approaches on a corpus of 1000 webpages from the Xinhua News website . There are on average 1.893 snippets per news document and for all snippets , = 6:97 , = 2:11 . Golden standards are created by human annotators . ff , fi , r are set experimentally at 0.6 , 0.5 , 0.174 correspondingly . We stick to the precision/recall evaluation metrics in [ 2 ] . Figure 1 shows the experiment results of semantic relevance ( SeRel ) and weighted semantic relevance ( WSeRel ) compared with TextTiling proposed in [ 1 ] , TTM and LGM proposed in [ 2 ] . The perfromance of different features is shown in Figure 2 .
Figure 1 : Performance
Figure 2 : Features
WSeRel generally outperforms others . TextTiling shows significant weakness because it is not event oriented . The contribution of significance is obvious ( +26.56 % ) by comparing WSeRel with SeRel . DD is the most essential for snippet expansion . TP , NE , CI are also necessary . LP seems not to perform well due to misleading line breaks and visual noises . We present a system demonstration snapshot .
Figure 3 : Fine grained news digestion system demo .
4 . CONCLUSIONS
We describe a fine grained news digestion framework of ESE , utilizing semantic , syntactic and visual features . ESE is an on going infrastructure work facilitating other researches . We show that our approach outperforms rival methods . 5 . ACKNOWLEDGMENTS
This work is partially supported by NSFC with Grant
No.60933004 , 61050009 and 61073081 . 6 . REFERENCES [ 1 ] M . A . Hearst . Texttiling : segmenting text into multi paragraph subtopic passages . Comput . Linguist . , 23(1):33–64 , 1997 .
[ 2 ] R . Yan , Y . Li , Y . Zhang , and X . Li . Event recognition p(spjLM ( S ) ) =
( 6 ) from news webpages through latent ingredients extraction . In AIRS ’10 , pages 490–501 .
,ff . ∆t
Temporal Proximity ( TP ) . Re mention of adjacent temporal information may strengthen event continuousness and raise significance , but huge time gap indicates separate events . Given ∆t = |tn − t| where tn is the new time contained in sentence st and t is from sh , TD as the time span TD × fd(x − ||st|| ) : of D , temporal proximity ft(x ) = e Named Entities ( NE ) . Sentence with named entities ( se ) might indicate strong relevance if entities are connected by existing knowledge databases ( eg WordNet or Wikipedia ) , but [ 2 ] assumed equal distance for all adjacent entities in hierarchical taxonomy structures . Leaf/lower level entities should be closer than general concepts from higher levels . Consider a fragment , <health [ food safety , public health organization(Centers for Disease Control , World Health Organization)]> , ( CDC , WHO ) are closer than ( food safety , public health organization ) . We model synonyms , hyponyms and hypernyms into entity distance . We assign a distance ek2H(e ) wek where weight ( we ) to every entity we = 1 + H(e ) is the hyponym set of entity e . The distance from a hyernym e to one of its hyponym ek is defined as :
∑
∑ dist =
2H(e ) ek wek jH(e)j :
( 3 )
The weight of leaf node is set as 1 . dist and weight are measured separately and penalization costs more for category ,fi.dist × fd(x − ||se|| ) . entities . Entity influence fe(x ) = e ff , fi are scaling factors . fd(x ) , fe(x ) , ft(x ) affect sentence significance separately and there are more than one se or st in S . For snippet completeness we choose the maximum fe(x ) and ft(x ) and take the arithmetic average of the three . Conjunctive Indicators ( CI ) . Conjunctions such as “ however ” , “ so ” , etc . reflect the author ’s intention of a semantic bridge between the adjacent sentences , which raises sentence significance . For the sentence with these conjunctive indicators , we assume it shares the same significance with its neighboring sentence prior to it . The conjunctive influence is local and not accumulative to following texts . sig(x ) = sig(x , 1 ) if ( sx \ sx,1 ) CI :
( 4 )
Layout Presentation ( LP ) . The visual structure of the news article in the webpage can give some clues to the event atoms , since writing style implies event principles as well . • Line break . When meet the tag of <br> or <p> , the line break as the author ’s intention of topic drifting . • Visual Elements . An inserted image , table or hyperlink ( <img> , <a> , etc . ) indicates similar effect as line breaks due to news writing style . for simplicity we assume they are all r . Hence final sig( : ) is :
The effects of line break and visual elements are accumulative . After visual changes , the probability drops by
∏ ( 1 − ri ) . ri are not equal due to specific contexts but sig(x ) = ( fd(x ) + maxffe(x)g + maxfft(x)g ) . ( 1 , r ) =3 Combining Significance . Each sentence in snippet affects following sentences , either increasing or decreasing the significance . We apply sig( : ) in Equation ( 1 ) and obtain a weighted relevance score from all sentence pairs between sp and sentences in the expanding snippet S . We add sp into S when relevance exceeds a threshold .
( 5 )
 ∏ w2sp
∑ ( 1 + ) ∑
2S si sig(si ) tf ( w ; si ) + sig(si ) jsij
 1jspj
2S si
WWW 2011 – PosterMarch 28–April 1 , 2011 , Hyderabad , India158
