Semi Supervised Truth Discovery
Xiaoxin Yin , Wenzhao Tan
Microsoft Research One Microsoft Way
Redmond , WA 98052
{xyin , wentan}@microsoft.com
ABSTRACT Accessing online information from various data sources has become a necessary part of our everyday life . Unfortunately such information is not always trustworthy , as different sources are of very different qualities and often provide inaccurate and conflicting information . Existing approaches attack this problem using unsupervised learning methods , and try to infer the confidence of the data value and trustworthiness of each source from each other by assuming values provided by more sources are more accurate . However , because false values can be widespread through copying among different sources and out of date data often overwhelm up to date data , such bootstrapping methods are often ineffective . In this paper we propose a semi supervised approach that finds true values with the help of ground truth data . Such ground truth data , even in very small amount , can greatly help us identify trustworthy data sources . Unlike existing studies that only provide iterative algorithms , we derive the optimal solution to our problem and provide an iterative algorithm that converges to it . Experiments show our method achieves higher accuracy than existing approaches , and it can be applied on very huge data sets when implemented with MapReduce .
Categories and Subject Descriptors H33 [ Information Storage and Retrieval ] : Information Search and Retrieval – search process .
General Terms Algorithms , Measurement , Experimentation .
Keywords Truth discovery , Semi supervised , Data quality .
1 . INTRODUCTION The web has become the major information source for most of us . However , is information on the web always trustworthy and accurate ? It is not surprising that many people will say “ no ” . According to a recent survey reported in [ 9 ] , US consumers have low trust in online information sources . Even the most trusted online source , company web sites , are only trusted by 22 % of consumers . The inaccuracy of online information also causes problems for search engines that provide structured data as results . Figure 1 contains two examples of incorrect fact answers from Google as in August 2010 . Figure 1 ( a ) shows the answer for the query “ ps3 release date ” , which is obviously incorrect as PS3 has been on the market since 2006 . The answer in Figure 1 ( b ) provides a number from various out dated sources . The number from the recently updated official site ( Figure 1 ( c ) ) is actually much larger . Many
Copyright is held by the International World Wide Web Conference Committee ( IW3C2 ) . Distribution of these papers is limited to classroom use , and personal use by others . WWW 2011 , March 28–April 1 , 2011 , Hyderabad , India . ACM 978 1 4503 0632 4/11/03 . good examples of erroneous information and their propagation on the web can be found in [ 8 ] .
It is a very important task to distinguish between true and false information on the web . This task , which has been studied as the truth discovery problem by different researchers [ 6][10][16 ] , is defined as follows . Given a set of data sources ( eg , web sites ) and a set of facts each provided by one or more data sources , how do we predict the confidence of each fact ( ie , likelihood of being true ) and the trustworthiness of each data source . In our usage the word “ fact ” is used to represent something claimed as true , whether it is right or wrong . In the three approaches described in [ 16 ] , [ 6 ] and [ 10 ] the truth discovery problem is formulated as an unsupervised learning problem . It is assumed that a fact provided by more sources ( especially more trustworthy and more independent sources ) is more likely to be correct . They all use iterative approaches , which start by assigning the same trustworthiness to all data sources , and iterate by computing the confidence of each fact and propagating back to the data sources .
There are two major problems with the above approaches . First , each step of the iterative procedure is performed using simple weighted voting . Consequently the rich will get richer over iterations . However , voting by the majority is not very trustworthy . Information copying is extremely common on the web [ 5 ] . Erroneous information can often appear in many sites . The situation is even worse for facts changing with time , since out of date information often exists in more web sites than up to date information . A good way to solve this problem is to introduce some level of supervision , so that the truth discovery procedure can be guided toward the right direction . It is usually easy to obtain a small set of highly confident facts , either by manual labeling or from a highly trusted source such as Wikipedia or government web sites . We can treat this set of facts as ground truth , and use them to infer the trustworthiness of data sources and confidence of facts .
The second problem with the existing approaches is that , although they all use iterative algorithms , they provide no guarantee
( a ) Google ’s direct answer for “ ps3 release date ”
( b ) Google ’s direct answer for “ minot air force base population ”
( c ) Part of page wwwminotafmil/library/factsheets/factsheetasp?id=3787
Figure 1 : Two incorrect fact answers from Google
WWW 2011 – Session : Trust and DiversityMarch 28–April 1 , 2011 , Hyderabad , India217 of convergence , and no description of the objective function being optimized . In this paper we formulate the truth discovery problem as an optimization problem and prove that our iterative algorithm converges to the optimal solution .
In this paper we study the problem of Semi Supervised Truth Discovery , which is a truth discovery problem where a small number of ground truth facts that are known . The goal of semisupervised truth discovery is to assign a confidence score to each fact , so that true facts have higher scores than false facts . We call our approach Semi Supervised Truth Finder , or SSTF , which considers truth discovery as a graph learning problem by treating each fact with a graph node and encoding the relationships between facts into graph edges .
There are three types of relationships between facts that help us infer the confidence scores of unlabeled facts from the labeled facts ( ie , ground truth facts ) . Some facts , such as “ Google has 21000 employees ” and “ Google has 21500 employees ” , are mutual supportive . If one of them is correct , the other is likely to be correct as well . Thus they should have similar confidence scores . Some facts , such as “ Microsoft was founded in New Mexico ” and “ Microsoft was founded in Washington ” , are mutual exclusive . If one of them has a positive score , the other should have a negative score . The third type of relationship is among facts from same data source . There should be some consistency among the scores of facts from the same data source . If we know a data source provides many true facts and few false facts , then it is trustworthy . Any other facts it provides are likely to be true as well . We represent all these relationships with edge weights in the graph , and convert the semi supervised truth discovery problem into an optimization problem that aims to assign scores to graph nodes that are consistent with the relationships indicated by the graph edges . We first provide an analytical solution to this optimization problem , although it is very expensive to compute for large scale problems . Then we provide an iterative procedure that can be computed and prove it converges to the optimal solution .
Compared to existing approaches [ 6][10][16 ] , we do not assign higher score to facts provided by more data sources , because it is very difficult to distinguish whether they are independently authored or copied from each other . The data sources play a different role in our approach : They help link different facts so that we can infer the confidence scores of facts from the ground truth .
First , we test our approach on five real world data sets collected from the web , and find our approach achieves higher accuracy than existing approaches . Then we test our approach on a very large , diverse , and noisy data set containing attribute values for all kinds of entities extracted from HTML tables of the whole web , with data from Wikipedia serving as ground truth . Our approach can distinguish true and false facts with high accuracy and is more accurate than previous approaches .
The remaining of this paper is organized as follows . Related work is discussed in Section 2 . We define our problem in Section 3 and describe the analytical solution in Section 4 . Section 5 presents the iterative solution . Experiments are presented in Section 6 and we conclude this study in Section 7 .
2 . RELATED WORK There has been some research on the general problem of combining conflicting information , with a brief survey in [ 1 ] . Early work in this area is more focused on how to integrate conflicting answers from different sources , such as the approach in [ 15 ] .
The truth discovery problem was first proposed in [ 16 ] , which provides a probabilistic approach based on the assumption that different data sources are independent and thus false values appearing on different data sources should be different from each other . The same assumption is used in [ 10 ] , which applies a different model for estimating the confidence of facts . The authors in [ 6 ] propose a method that considers the dependencies among data sources , although such dependencies need to be inferred from the confidence associated with each fact . Truth discovery on timevariant facts is studied in [ 7 ] .
The approaches in [ 16 ] and [ 10 ] assign confidence scores to facts based on the principle that a fact provided by more ( and more trustworthy ) data sources is more likely to be correct . A data source providing mostly high confidence facts is more trustworthy . This assumption holds when different data sources are independent . But this is generally not true as data copying is prevalent on the web [ 5 ] .
The problem caused by data copying is alleviated in [ 6 ] , which detects copying relationships during the iterative process of truth discovery . However , the copying relationships can only be detected by false facts , as two data sources sharing many true facts do not indicate copying behavior . Therefore , it still finds true and false facts according to the numbers of data sources providing each fact at the beginning . The existence of a false or out of date fact in many data sources will cause the fact to receive high confidence in the first iteration , which poisons the remaining iterations . Moreover , sometimes it is simply impossible to distinguish true facts from false ones in the data itself , especially when large amounts of out of date facts exist on more data sources than upto date facts .
In this paper we study the problem of truth discovery with semi supervised graph learning , by using a small set of ground truth data to help distinguishing true facts from false ones as well as identifying trustworthy data sources . Semi supervised graph learning has been studied by Zhu et al . [ 11][19][20 ] and Zhou et al . [ 18 ] . The main purpose of these approaches is to make predictions consistent with both labeled data and the graph structure . We adapt the approach in [ 19][20 ] to our problem and make it scale to very large data sets .
3 . PROBLEM FORMULATION In this paper we study semi supervised truth discovery , which aims to distinguish true from false facts by utilizing a small set of ground truth facts . It is semi supervised because a large amount of unlabeled facts also participate in the learning process .
The input to our problem is the same as traditional truth discovery , except that there is a subset of facts which are labeled as correct ( ie , ground truth facts ) . The goal is to assign a confidence score to each unlabeled fact , so that true facts have higher scores . In this paper we define a confidence score to be a real value between −1 and 1 . A score close to 1 indicates we are very confident that a fact is true . A score close to −1 indicates the reverse . A score close to 0 indicates that we do not know if a fact is true or false . Each ground truth fact has a confidence score of 1 .
Our approach is based on three basic principles . First , facts provided by the same data source should have similar confidence scores . This is also an important principle utilized in all existing approaches [ 6][10][16 ] , which assign a trustworthiness score to each data source and estimate the confidence scores of facts using the trustworthiness of their data sources .
Second , similar ( and therefore mutual supportive ) facts should have similar confidence scores . For example , suppose one data source says the population of Seattle is 560,000 and another says
WWW 2011 – Session : Trust and DiversityMarch 28–April 1 , 2011 , Hyderabad , India218 it is 561,000 . If one of these two facts has a high confidence score , the other should have a high score as well .
Third , if two facts are conflicting , they cannot be both true . If one of them has a high positive confidence score , the other should have negative score . For example , if a ground truth fact says that Tom Hanks was born on 1956/07/09 , while another fact says he was born on 1956/08/09 , the second fact is likely to be wrong .
Britney Spears born on 1981/12/02
Madonna ’s spouse is Guy Ritchie
2
Tom Hanks height 6’1 ”
6
4
D1
Tom Hanks born
D2 on 1956/07/09
1
D3
Here we provide a formal definition of the semi supervised
Hanks was born on 1956/07/09 ” is about the subject “ Tom Hanks’ truth discovery problem . There are ݊ facts ܨ = ሼ݂ଵ,…,݂௡ሽ , each provided by one or more of the ݉ data sources ܦ = ሼ݀ଵ,…,݀௠ሽ . A subset of facts ܨ௟ = ሼ݂ଵ,…,݂௟ሽ are ground truth and thus labeled as true , while the remaining facts ܨ௨ = ሼ݂௟ାଵ,…,݂௡ሽ are unlabeled . Each fact ݂ is on a subject ݏሺ݂ሻ . For example , the fact “ Tom birth date ” . Two facts ݂ଵ and ݂ଶ on the same subject may be consistent or in conflict with each other . A function simሺ݂ଵ,݂ଶሻ is them ሺ−1 ≤ simሺ݂ଵ,݂ଶሻ ≤ 1ሻ . simሺ݂ଵ,݂ଶሻ will be used in our different ) scores to ݂ଵ and ݂ଶ . As mentioned in other works on [ 20 ] , the definition of simሺ݂ଵ,݂ଶሻ is often domain specific and simሺ݂ଵ,݂ଶሻ = simሺ݂ଶ,݂ଵሻ , and simሺ݂,݂ሻ = 1 for any fact ݂ . Each usually needs to be provided by people with proper domain knowledge . The similarity function should be symmetric , ie , truth discovery [ 6][16 ] and semi supervised learning in graphs provided to indicate the degree of consistency or conflict between optimization to indicate how important it is to assign similar ( or data source can only provide one fact for each subject , although a fact can be a set value , such as the authors of a book .
We model this problem as a graph optimization problem . The facts are modeled by a graph , with a node for each fact and an edge between each pair of related facts . The above three prin ciples can be encoded into the graph using edge weights . ݓ௜௝ is the weight of the edge between ݂௜ and ݂௝ , which indicates the relationship of their confidence scores . If ݂௜ and ݂௝ are provided by the same data source , then ݓ௜௝ is set to a positive value ߙ ( 0<ߙ<1 ) because if ݂௜ has a high ( or low ) confidence score , ݂௝ should probably have that as well . If ݂௜ and ݂௝ are on the same subject , then we set ݓ௜௝ = sim൫݂௜,݂௝൯ . Otherwise ݓ௜௝ is set to zero .
ܧ′ሺࢉሻ = ଵ
In order to formulate the semi supervised truth discovery as an optimization problem , we choose the loss function based on studies on semi supervised graph learning [ 18][19][20 ] , which have been widely used in many applications such as question answering [ 3 ] to image annotation [ 14 ] .
Consider an assignment of confidence scores to facts ࢉ = ሺܿଵ,…,ܿ௡ሻ , where ܿ௜ ∈ ሾ−1,1ሿ is the score of ݂௜ . If ݓ௜௝ ≥ 0 for all ݅,݆ , the loss function in [ 20 ] is suitable : ൫ܿ௜ −ܿ௝൯ଶ . ( 1 ) By minimizing ܧ′ሺࢉሻ we minimize the weighted sum of differenc es between the confidence scores of related facts . Although this is an option , it does not consider conflicting relationships between facts , which causes much information to be lost . Furthermore , we
The second option is to use the same loss function , but allow can easily minimize ܧ′ሺࢉሻ by assigning the score of 1 to each fact . ݓ௜௝ to be negative . If ݓ௜௝ < 0 ( ie , facts ݂௜ and ݂௝ in conflict ) , then ܧ′ሺࢉሻ is minimized when ܿ௜ and ܿ௝ are different from each other . However , under this definition ܧ′ሺࢉሻ is not a convex function and may have many local minimums . Thus it is extremely difficult to optimize , especially for large scale problems .
ଶ∑ ݓ௜௝ ௜,௝
Finally we choose a loss function from [ 11 ] , which is a variant of Equation ( 1 ) but handles both similarity and dissimilarity :
Tom Hanks net worth $140M
Tom Hanks net worth $150M
5
3
Tom Hanks born on 1958/08/09
7
൫ܿ௜ −ݏ௜௝ܿ௝൯ଶ , ( 2 )
Figure 2 : An example graph of facts
ଶ∑ หݓ௜௝ห ௜,௝
ܧሺࢉሻ = ଵ where ݏ௜௝ = ቊ 1 , if ݓ௜௝ ≥ 0 −1 , if ݓ௜௝ < 0 . In order to minimize ܧሺࢉሻ , ݂௜ and ݂௝ should have similar confidence scores when ݓ௜௝ > 0 ( ie , ݂௜ and ݂௝ are mutual supportive ) . When ݓ௜௝ < 0 ( ie , ݂௜ and ݂௝ are mutual exclusive ) , ݂௜ and ݂௝ minimizing ܧሺࢉሻ we get an assignment of scores that are not long should have opposite scores or scores both close to zero . The scores of labeled facts are fixed at 1 and cannot be changed . By consistent with the relationships among facts , but also consistent with the scores given to the labeled facts .
An example graph of facts is shown in Figure 2 . It contains seven facts ݂ଵ,…,݂଻ provided by three data sources ܦଵ,ܦଶ,ܦଷ . ݂ଵ is a ground truth fact . Because ݂଻ is mutual exclusive from ݂ଵ , simሺ݂ଵ,݂଻ሻ should be close to −1 . Thus ݂଻ will have a low confidence score , which also leads to a low score for ݂଺ . ݂ଶ and ݂ଷ have ݂ଵ . ݂ହ is consistent with ݂ଷ and thus has high score as well . ݂ସ also has high score because of its connections to ݂ଶ and ݂ହ . high scores because they are provided by the same data source as solution exists .
4 . ANALYTICAL SOLUTION Although Equation ( 2 ) is proposed in [ 11 ] , the authors of [ 11 ] did not provide a solution to optimize it since the paper is focused on multi class SVMs with dissimilarity . In this section we provide an analytical solution to minimize ܧሺࢉሻ and discuss when such a ܧሺࢉሻ is convex in ࢉ because each ൫ܿ௜ −ݏ௜௝ܿ௝൯ଶ is convex . Therefore , to minimize ܧሺࢉሻ we only need to find ࢉ∗ such that డா డࢉቚࢉୀࢉ∗ = 0 , ( 3 ) under the constraint that ܿଵ,…,ܿ௟ are fixed to their initial values . We split ࢉ into the labeled set ࢉ௟ = ሺܿଵ,…,ܿ௟ሻ and the unlabeled set ࢉ௨ = ሺܿ௟ାଵ,…,ܿ௡ሻ . With simple derivations , we can show that ܿ௝ = 0 . ( 4 ) We define the weight matrix ܹ = ൣݓ௜௝൧ , diagonal matrix ܦ such that ܦ௜௜ = ∑ หݓ௜௝ห , and matrix ܲ = ܦିଵܹ . We split the weight matrix ܹ into four blocks as ܹ = ൤ܹ௟௟ ܹ௟௨ ܹ௨௟ ܹ௨௨൨ , where ܹ௫௬ is an ݔ ×ݕ matrix . ܦ and ܲ are split similarly . Thus we can rewrite ሺܦ௨௨ −ܹ௨௨ሻࢉ௨ −ܹ௨௟ࢉ௟ = 0 . ( 5 )
Equation ( 3 ) is equivalent to ௝
∀݅ ∈ ሼ݈+1,…,݊ሽ , ∑ หݓ௜௝ห
∙ܿ௜ −∑ ݓ௜௝
Equation ( 4 ) as
௝
௝
Therefore , we can solve
WWW 2011 – Session : Trust and DiversityMarch 28–April 1 , 2011 , Hyderabad , India219 ࢉ௨ = ሺܦ௨௨ −ܹ௨௨ሻିଵܹ௨௟ࢉ௟ = ሺܫ−ܲ௨௨ሻିଵܲ௨௟ࢉ௟ , ( 6 ) if ሺܫ−ܲ௨௨ሻ is invertible .
In [ 20 ] the authors provide the optimal solution to Equation ( 1 ) , which shares some similarity with our solution , although it does not consider dissimilarity relationships among nodes . A major drawback of the approach in [ 20 ] is that it requires ݓ௜௝ > 0 for all ݅,݆ , in order to guarantee that ሺܫ −ܲ௨௨ሻ is invertible . This rewith only a hundred thousand facts will have a matrix ܹ with ten quirement is impractical for most real world data sets . A data set billion entries , which is too big to fit in memory . In this paper we work on a Web scale data set with hundreds of millions of facts , and we have to find a scalable method that can handle sparse matrices and converge to the optimal solution .
We first analyze an example in which ሺܫ−ܲ௨௨ሻ is not invertible . If for an unlabeled fact ݂௞ ( ݇ ∈ ሺ݈,݊ሿ ) , ݓ௜௞ = ݓ௞௜ = 0 for any ݅ ≠ ݇ , then the kth row and kth column of the matrix ሺܫ −ܲ௨௨ሻ are 0 , resulting in a non invertible ሺܫ −ܲ௨௨ሻ . This is not surprising because ݂௞ is not related to any labeled facts either directly or cases there is no unique solution that minimizes ܧሺࢉሻ . Any confidence score of ݂௞ yields the same ܧሺࢉሻ , and therefore ݂௞ may get indirectly , and its confidence score will remain undefined . In such an arbitrary confidence score .
We solve this problem by introducing a “ neutral fact ” to the set of labeled facts . It has a confidence score of 0 and is connected to every unlabeled fact . Suppose ݂ଵ is the neutral fact and has score ܿଵ = 0 . The weight of the edge between ݂ଵ and an unlabeled fact ݂௜ must be above zero , ie , ݓଵ௜ = ݓ௜ଵ > 0 . existence of a unique solution that minimizes ܧሺࢉሻ , which is
The neutral fact has two important roles . First , it guarantees the proved in Theorem 1 below . If an unlabeled fact is not connected to any labeled facts either directly or indirectly , it will have a confidence score of 0 since it is connected to the neutral fact . Second , the neural fact lowers the confidence scores of unlabeled facts that are only remotely connected to the labeled facts . This is desirable because there are noises in the connections among facts . Thus a long sequence of connections introduces more uncertainty , which should lower our confidence about a fact being true or not . This property will be studied in details in Section 53
The weight on edges from/to the neutral fact can be defined in many ways . We discuss two simple definitions in this paper . The first definition is to use a constant weight : tional to the total weight of edges from each node :
ݓଵ௜ = ݓ௜ଵ = ߬ , ݅ = ݈+1,…,݊ , ( 7 ) where ߬ > 0 . The second definition is to assign a weight propor , ݅ = ݈+1,…,݊ , ( 8 ) where ߤ is a small constant . The first definition is suitable for
ݓଵ௜ = ݓ௜ଵ = ߤ∙∑ หݓ௜௝ห problems in which the distribution of edges is fairly uniform , ie , the degrees of the nodes do not differ too much . The second definition is suitable for problems where different nodes have very different degrees , such as web scale problems where some nodes have millions of edges while many others have only a few edges .
௝வଵ
Theorem 1 : There exists a unique solution to minimizing ܧሺࢉሻ . Proof : We first show that ሺܫ −ܲ௨௨ሻ is positive definite . Because ܲ = ܦିଵܹ and ܦ௜௜ = ∑ หݓ௜௝ห for ݅ = 1,…,݊ . Because ݓଵ௜ > 0 , we know ܲଵ௜ > 0 for ݅ = ݈ +1,…,݊ . Since ܲ௨௨ is a sub matrix of ܲ , we know that ∑ หሾܲ௨௨ሿ௜௝ห < 1 ௝ ݅ = 1,…,݊−݈ . Let ܯ = ܫ −ܲ௨௨ . ∀ݔ ∈ ℝ௡ି௟/ሼ૙ሽ ,
, we know ∑ หܲ௜௝ห = 1 for
௝
௝
ݔ்ܯݔ = ݔ்ݔ −ݔ்ܲ௨௨ݔ = ෍ݔ௜ଶ
−෍ሾܲ௨௨ሿ௜௝
ݔ௜ݔ௝
௜
ݔ௜ଶ −෍ሾܲ௨௨ሿ௜௝
௜௝ > ෍หሾܲ௨௨ሿ௜௝ห ݔ௜ݔ௝ ௜௝ ≥ 1 2෍หሾܲ௨௨ሿ௜௝ห൫ݔ௜ଶ−2ݔ௜ݔ௝ +ݔ௝ଶ൯ ௜௝
௜௝
≥ 0
Therefore , ሺܫ −ܲ௨௨ሻ is positive definite and is thus invertible . As shown in Equation ( 5 ) , ࢉ௨ = ሺܫ −ܲ௨௨ሻିଵܲ௨௟ࢉ௟ is the unique solution to minimizing ܧሺࢉሻ . ∎
5 . ITERATIVE COMPUTATION Although Equation ( 6 ) provides an analytical solution to minimiz ing ܧሺࢉሻ , it is very expensive or impractical to compute . In a real world truth discovery problem , the number of facts is usually at least tens of thousands , and can even reach hundreds of millions in some problems . It is very expensive or impossible to compute the inverse of a matrix of such size . Sometimes it is even impossi
5.1 Iterative Algorithm and Its Convergence The goal of ble to fully materialize the matrix ܹ . In this section we will discuss how to use an iterative procedure to compute ࢉ௨ efficiently . to compute ࢉ௨ = ሺܫ −ܲ௨௨ሻିଵܲ௨௟ࢉ௟ without involving matrix inversion or other in [ 19 ] . The confidence score vector ࢉ after ݐ iterations is denoted by ࢉ௧ . We initialize the confidence scores by setting ܿ௜ to the labeled data for ݅ = 1,…,݈ , and ܿ௜ = 0 for ݅ = ݈ +1,…,݊ . In this way the initial confidence score vector is ࢉ଴ = ሺܿଵ,…,ܿ௟,0,…,0ሻ . Then we repeat the following steps until ࢉ converges . expensive operations . We use an iterative procedure similar to that iterative procedure the is
Step 1 : ࢉ௧ = ܲࢉ௧ିଵ
Step 2 : Restore the confidence scores for the labeled facts , ie , set ܿ௧௜ = ܿ௜ for ݅ = 1,…,݈ .
It can be shown that the above steps are equivalent to computing
Lemma 1 .
In order to prove this procedure converges , we need to first
ࢉ௨௧ = ܲ௨௨ࢉ௨௧ିଵ +ܲ௨௟ࢉ௟ . ( 9 ) provide a bound to the sum of each column in ܲ௨௨ , as shown in Lemma 1 : ∃ߛ < 1 , such that ∀݅ = 1,…,ݑ , ∑ หሾܲ௨௨ሿ௜௝ห ≤ ߛ . ௝ Proof : Please recall that ܲ = ܦିଵܹ , and thus ≤ 1− |௪೔భ| , ೙ೕసభ ∑ ห௪೔ೕห where ݓ௜ଵis the weight of the edge from ݂௜ to the neutral fact ݂ଵ . According to our definitions in Equations ( 7 ) and ( 8 ) , ݓ௜ଵ = ߬ or . If ݓ௜ଵ = ߬ , let ߱max = maxଵஸ௜ஸ௡൫∑ หݓ௜௝ห ݓ௜ଵ = ߤ∙∑ หݓ௜௝ห ൯ ௡௝ୀଵ ௝வଵ , then 1− |௪೔భ| = ଵ and ߛ = 1− ఛ . If ݓ௜ଵ = ߤ∙∑ หݓ௜௝ห ଵାఓ , ೙ೕసభ ∑ ఠmax ห௪೔ೕห and we let ߛ = ଵ ଵାఓ . In both cases ߛ < 1 and ∑ หሾܲ௨௨ሿ௜௝ห ≤ ߛ . ∎
∑ หሾܲ௨௨ሿ௜௝ห ௝
೙ೕస೗శభ = ∑ ೙ೕసభ ∑
ห௪೔ೕห ห௪೔ೕห
௝வଵ
௝
With Lemma 1 we can prove the convergence of our algorithm using the conclusions from [ 19 ] , which we briefly describe here . It can be easily shown that lim௧→ஶࢉ௨௧ = lim௧→ஶܲ௨௨௧ ࢉ௨଴ +ൣ∑ ܲ௨௨௜ିଵ = ∑ ሾܲ௨௨௧ିଵሿ௜௞∑ ሾܲ௨௨ሿ௞௝ ≤ ∑ ሾܲ௨௨௧ିଵሿ௜௞ߛ ≤ ߛ௧
We first study the sum of each column in matrix ܲ௨௨௧ . ∑ ሾܲ௨௨௧ ሿ௜௝ ௝
௧௜ୀଵ
௞
௞
௝
൧ܲ௨௟ࢉ௟ . ( 10 )
. ( 11 )
WWW 2011 – Session : Trust and DiversityMarch 28–April 1 , 2011 , Hyderabad , India220 Because ߛ < 1 , lim௧→ஶܲ௨௨௧ ࢉ௨଴ = 0 , which means the initial point of ࢉ௨ is inconsequential . It can be easily derived that ࢉ௨ = ሺܫ −ܲ௨௨ሻିଵܲ௨௟ࢉ௟ is a fixed point for function ݂ሺ࢞ሻ = ܲ௨௨࢞+ ܲ௨௟ࢉ௟ , which is our iterative procedure in Equation ( 8 ) . It is the unique fixed point because the initial point of ࢉ௨ is inconsequen tial . Thus it is the solution to the iterative algorithm .
5.2 Efficient Computation The iterative procedure presented above converges to the optimal solution and avoids computing matrix inverse . However , in a realworld truth discovery problem there are often millions of facts ( eg , those provided by Wikipedia or IMDB ) , and thus there are often millions times millions edges in the graph , which makes it impossible to materialize and store the matrices ܹ and ܲ . In this subsection we describe a way to decompose these matrices so that computation can be done in an affordable way .
Let us go over the definition of a truth discovery problem to see
1 . Facts on the same subject are connected to each other : ject may be consistent or in conflict with each other as indicated how the computation can be simplified . There are ݊ facts ܨ = ሼ݂ଵ,…,݂௡ሽ provided by ݉ data sources ܦ = ሼ݀ଵ,…,݀௠ሽ , and let ݀ሺ݂ሻ denote the set of data sources providing fact ݂ . Each fact ݂ is about a subject ݏሺ݂ሻ , and two facts ݂ଵ and ݂ଶ on the same subby simሺ݂ଵ,݂ଶሻ . The graph of facts is usually built as follows : For any ݂௜ and ݂௝ that ݏሺ݂௜ሻ = ݏ൫݂௝൯ , ݓ௜௝ = sim൫݂௜,݂௝൯ . other : If a data source ݀௞ provides both ݂௜ and ݂௝ , it will contribute a certain weight to the edge weight between ݂௜ and ݂௝ . Therefore , for any ݂௜ and ݂௝ that ݀ሺ݂௜ሻ∩݀൫݂௝൯ ≠ ∅ , ݓ௜௝ = ߙ ∙ห݀ሺ݂௜ሻ∩݀൫݂௝൯ห , where ߙ ∈ ሺ0,1ሻ .
2 . Facts from the same data source are connected to each
Since in each iteration we need to compute
௝
௝
.
ࢉ௧ = ܲࢉ௧ିଵ = ܦିଵܹࢉ௧ିଵ , ( 12 )
As mentioned before , a data source cannot provide multiple the number of unique values for each subject is usually small . and ሾܦௗሿ௜௜ = ∑ หሾܹௗሿ௜௝ห we will decompose both ܦ and ܹ for efficient computation . facts on same subject , ie , if ݀ሺ݂௜ሻ∩݀൫݂௝൯ ≠ ∅ , then ݏሺ݂௜ሻ ≠ ݏ൫݂௝൯ . Thus matrix ܹ can be decomposed into two sparse matrices without overlapping entries : ܹ = ܹ௦ +ܹௗ , where ሾܹ௦ሿ௜௝ = sim൫݂௜,݂௝൯ if ݏሺ݂௜ሻ = ݏ൫݂௝൯ and ሾܹௗሿ௜௝ = ߙ∙ห݀ሺ݂௜ሻ∩݀൫݂௝൯ห if ݀ሺ݂௜ሻ∩݀൫݂௝൯ ≠ ∅ . We also decompose ܦ as ܦ = ܦ௦ +ܦௗ , where ሾܦ௦ሿ௜௜ = ∑ หሾܹ௦ሿ௜௝ห The number of non zero entries in ܹ௦ is usually small because Therefore , we can store ܹ௦ as a sparse matrix and compute ܦ௦ from it . In contrast , ܹௗ may contain billions or trillions of nonfacts . Thus we have to further decompose ܹௗ . Let ܸ be a ݊×݉ matrix and ܸ௜௞ = ൜1 , if ݀௞ ∈ ݀ሺ݂௜ሻ ; It can be shown that ห݀ሺ݂௜ሻ∩ 0 , otherwise . ݀൫݂௝൯ห = ∑ ܸ௜௞ܸ௝௞ , and thus ܹௗ = ߙܸܸ୘ . Therefore , ܹࢉ௧ିଵ = ܹ௦ࢉ௧ିଵ +ߙܸܸ୘ࢉ௧ିଵ , ( 13 ) which can be easily computed because ܹ௦ is of manageable size , ܸ is part of the input , and ܸܸ୘ࢉ௧ିଵ can be computed by two operThe diagonal matrix ܦ can also be computed efficiently . ܦ௦ can be computed from ܹ௦ , and ܦௗ can be computed as : zero entries because some data sources may provide millions of ations of multiplying a vector by a matrix .
௠௞ୀଵ
௠௞ୀଵ
ܸ௜௞ܸ௝௞
ܸ௜௞൫∑ ܸ௝௞
ሾܦௗሿ௜௜ = ߙ∑ ∑ ௝ ௝
௝ Let |݀௞| be the number of facts provided by ݀௞ . Obviously |݀௞| = ∑ ܸ௝௞ . In this way ܦ௦ and ܦௗ can be pre computed , and we can easily compute ࢉ௧ = ܦିଵܹࢉ௧ିଵ . Since the only operation involved in each iteration is
, and thus ሾܦௗሿ௜௜ = ߙ∑
௠௞ୀଵ ܸ௜௞|݀௞|
= ߙ∑ ௠௞ୀଵ multiplying a vector by a sparse matrix , we easily implement this algorithm with MapReduce and run it in a distributed framework .
. ( 14 )
൯
5.3 Complexity Analysis Here we analyze the complexity of the algorithm presented in
We discuss the complexity of computing Equations ( 13 ) and the total number of cases of a data source providing a fact , ie ,
Section 52 Suppose there are ݊ facts and ݉ data sources . Let ݈ be there are ݈ non zero entries in matrix ܸ . Suppose for each fact ݂ , on average there are ݍ facts on the same subject as ݂ . ( 14 ) . ܹ௦ is a ݊×݊ matrix and there are ܱሺ݊ݍሻ non zero entries in it . It takes ܱሺ݊ݍሻ time to compute ܹ௦ and ܹ௦ࢉ௧ିଵ . It takes ܱሺ݈ሻ time to compute ܸܸ୘ࢉ௧ିଵ . Therefore , it takes ܱሺ݊ݍ+݈ሻ time to compute ܹࢉ௧ିଵ in each iteration . We also need to compute matrix ܦ which has two parts : ܦ௦ and ܦௗ . ܦ௦ can be directly computed from ܹ௦ in ܱሺ݊ݍሻ time . To compute ܦௗ as in Equation ( 14 ) , we first compute ∑ ܸ௝௞ for ݇ = 1,…,݉ , and then iterate through the ݈ non zero entries in ܸ to compute ܦௗ , which takes ܱሺ݈ሻ time in ܱ൫ሺ݊ݍ+݈ሻݐ൯ for ݐ iterations . total . In summary , the time complexity of our algorithm is
௝
5.4 Decay of Confidences in Propagation It is mentioned before that the neutral fact is important to our algorithm as it guarantees the existence of a unique solution . In Section 5.1 we can see it is also important to the convergence of our iterative algorithm . In this subsection we further study how the neutral fact influences our algorithm , and show that it is equivalent to introducing a small decay to the confidence scores of facts in each iteration .
First let us compare two versions of algorithms , one without the neutral fact and one with it . We start from a simple example . Sup pose there is one labeled fact ݂ଶ with confidence score 1 , and three unlabeled facts ݂ଷ , ݂ସ , ݂ହ . We created two graphs as shown in Figure 3 : Graph ܩ̅ without the neutral fact and ܩ with the neutral fact ݂ଵ . The weights of edges to and from the neutral fact is defined by Equation ( 8 ) with ߤ = 01 The weights of edges and In order to minimize ܧሺࢉሻ , in ܩ̅ the confidence scores of ݂ଷ , ݂ସ , and ݂ହ should all be set to 1 . In fact , in any graph where all confidence scores are shown in the figure . labeled facts have confidence scores of 1 and there is no negative edge , any unlabeled fact connected to any labeled facts will have score of 1 , no matter how far away it is from the labeled facts . Such assignment of scores is not reasonable because we have different confidences in the correctness of these facts . For exam ple , ݂ହ may be provided by the same data source as ݂ସ , which is somewhat similar to ݂ଷ , which is provided by the same data
1 f2
1 f3
0.5
1 f4
0.5
1 f5
0.5
1
0.7
0.54
0.49
0.5 f2 f3
0.5 f4
0.5 f5
0.1 0.1 0.05
( a ) ܩ̅ , without neutral fact ( b ) ܩ , with neutral fact
Figure 3 : Graphs without and with the neutral fact
0 f1
WWW 2011 – Session : Trust and DiversityMarch 28–April 1 , 2011 , Hyderabad , India221 source as ݂ଶ . Since we know ݂ଶ is true , we are pretty confident that ݂ଷ is true , somewhat confident for ݂ସ , but not that confident with ݂ହ , because each hop introduces uncertainty .
In order to model such uncertainty and the resulting decrease in confidence , we introduce the concept of propagation decay , and we will show such decay has exactly the same effect as adding the neutral fact . In the discussion below we will compare the compu tation in ܩ̅ and ܩ , using ܦഥ , ܵ̅ , ܹഥ , ܲത and ࢉത to represent the matrices and vectors in ܩ̅ . Let us consider the computation in ܩ̅ which has no neutral fact . confidence scores with equation ࢉത௧ = ܲതࢉത௧ିଵ , ie , propagating the ܲത . Now we introduce some decay in each iteration , defined as
As shown in Section 5.1 , in each iteration we are propagating the confidence score from each node to its neighbors using the matrix follows .
Definition 1 . ( Propagation Decay ) In Step 1 of each iteration , when propagating confidence scores from a labeled fact ݂௜ to an unlabeled fact ݂௝ , we add the score ߩܲത௜௝ܿ̅௧ିଵ௜ to ܿ̅௧௝ , instead of ܲത௜௝ܿ̅௧ିଵ௜ , where ߩ ∈ ሺ0,1ሻ is they decay factor . This can also be written as ࢉത௧ = ߩܲതࢉത௧ିଵ . ∎
Here we will show that adding a propagation decay is equiva lent to adding a neutral fact in the graph .
Theorem 2 : Let ࢉത௨௧ be the confidence score vector of unlabeled facts in the graph ܩ̅ without a neutral fact after ݐ iterations with propagation decay . Let ࢉ௨௧ be the confidence score vector in graph ܩ with a neutral fact but without propagation decay ( weight of edges to/from the neutral fact is set as in Equation ( 8) ) . Then
௝
௝வଵ
,
ࢉ௨௧ = ߩࢉത௨௧ if ߩ = ଵ have
ܲ௟௨ after each iteration , the computation in each iteration is actually
ሺଵାఓሻ . ( 14 ) Proof : We first look at the computation in ܩ . In each iteration we compute ࢉ௧ = ܲࢉ௧ିଵ , which can be rewritten as ൤ࢉ௟௧ ࢉ௨௧൨ = ൤ܲ௟௟ ܲ௨௟ ܲ௨௨൨൤ࢉ௟௧ିଵ ࢉ௨௧ିଵ൨ . Because we restore ࢉ௟ to its original value ࢉ௨௧ = ܲ௨௨ࢉ௨௧ିଵ +ܲ௨௟ࢉ௟ . With induction we can easily prove that ࢉ௨௧ = ܲ௨௨௧ ࢉ௨଴ +ൣ∑ ܲ௨௨௜ିଵ ൧ܲ௨௟ࢉ௟ . Because we set ࢉ௨଴ = ૙ , we ൧ܲ௨௟ࢉ௟ . ( 15 ) ௧௜ୀଵ Now we analyze how the neutral fact influences ܲ௨௨ and ܲ௨௟ . Re , ܦഥ௜௜ = ∑ หݓ௜௝ห member that ܲ = ܦିଵܹ . Since ܦ௜௜ = ∑ หݓ௜௝ห , we know that ܦ௜௜ = ሺ1+ߤሻܦഥ௜௜ and ݓଵ௜ = ݓ௜ଵ = ߤ∙∑ หݓ௜௝ห and thus ܦ௨௨ = ሺ1+ߤሻܦഥ௨௨ . From the definition of ܲ௨௟ we know Because ܹ௨௟ only differs with ܹഥ௨௟ in the first column , and ࢉ௟ = ࢉത௟ and ࢉ௟ଵ = ࢉത௟ଵ = 0 , we have
௝வଵ ܲ௨௟ࢉ௟ = ܦ௨௨ିଵܹ௨௟ࢉ௟
௧௜ୀଵ ࢉ௨௧ = ൣ∑ ܲ௨௨௜ିଵ
ܹ௨௟ࢉ௟ = ܹഥ௨௟ࢉത௟ ⇒ ܲ௨௟ࢉ௟ = ൫ሺ1+ߤሻܦഥ௨௨൯ିଵܹഥ௨௟ࢉത௟ = Because ܹ௨௨ = ܹഥ௨௨ , we have ܲ௨௨ = ଵ
1 ሺ1+ߤሻܲത௨௟ࢉത௟ ሺଵାఓሻܲത௨௨ . Therefore , ൨ܲത௨௟ࢉത௟ . ( 16 ) When iterating with propagation decay in ܩ̅ , in each iteration we are computing ࢉത௨௧ = ߩܲത௨௨ࢉത௨௧ିଵ +ܲത௨௟ࢉത௟ . Similar to Equation ( 9 )
ሺଵାఓሻ൤∑ ቀ భ
ሺభశഋሻܲത௨௨ቁ௜ିଵ
ࢉ௨௧ = ଵ
௧௜ୀଵ we can prove that ࢉത௨௧ = ൣ∑ ሺߩܲത௨௨ሻ௜ିଵ ௧௜ୀଵ to Equation ( 16 ) . If we let ߩ = ଵ ሺଵାఓሻ , then ࢉ௨௧ = ߩࢉത௨௧ . ∎
൧ܲത௨௟ࢉത௟ , which is similar
Theorem 2 shows that adding a neutral fact achieves the same effect as performing propagation decay in each iteration . Thus it is unnecessary to perform such decay when using the neutral fact . This is the second role of neutral fact ( the first role is to guarantee the existence of a unique solution and convergence of the iterative algorithm ) , which is also very important to our approach .
6 . EXPERIMENT RESULTS We test our approach SSTF on six real world data sets , including the data set containing book authors used in [ 16 ] and [ 6 ] , four data sets from HTML tables on the web for entities of certain types , and a huge data set containing hundreds of millions of entityattribute value triples extracted from HTML tables all over the web . Small scale experiments are performed on a PC with Intel Quad Core 2.66GHz CPU , 32GB memory . Web scale experiments are performed on a PC cluster based on Dryad [ 12 ] that supports MapReduce . We also test the scalability of our approach on synthetic data sets at different scales .
6.1 Book Authors Data Set The first experiment is based on a real world data set containing authors of computer science books , which is the only real world data set used in [ 16 ] and [ 6 ] . This data set is extracted from AbeBookscom Each book is listed on a set of online bookstores , each providing the authors of the book . The goal is to find the correct list of authors for each book . There is a ground truth set containing the authors of 100 randomly selected books , created by manually looking at the images of the book covers . This data set contains 1263 books and 24364 listings from 877 bookstores .
Both [ 16 ] and [ 6 ] provide detailed experiment results on this data set , although using different evaluation criteria . We adopt the criteria of [ 6 ] so we can directly compare with its results . For each book , the author names are normalized into a list of names , where duplicate names are removed and middle names are ignored . The author names of a book are considered to be correct if and only if they exactly match with the ground truth after normalization . Cases such as additional , missing , mis ordered and misspelled names are all considered incorrect .
We use the definition of similarity between two sets of authors from [ 16 ] 1 . The parameters of SSTF are set as follows . The weight of an edge between two facts from same data source is set to ߙ = 001 The weight of an edge from the neutral fact to each the confidence score vector as ‖ࢉ௧ −ࢉ௧ିଵ‖/‖ࢉ௧ିଵ‖ , and the itera fact is 1 . After each iteration , we compute the relative change of tive procedure stops if the relative change is less than 0.01 after any iteration .
We first test how fast SSTF converges and how its accuracy changes over iterations . Figure 4 shows the accuracy of our approach SSTF ( Semi supervised Truth Finder ) , as we vary the amount of training data from 12.5 % to 87.5 % of the 100 labeled examples . n fold validation is used in each experiment . For example , 8 fold validation is used when using 12.5 % of labeled examples as training data , which means 12 training examples are used in four folds and 13 used in the other four folds . We can see the accuracy improves over iterations most of the time . The final
1 The similarity definition from [ 16 ] is asymmetric and is in the range [ 0 , 1 ] . To use it in our approach , we take the average of the similarities in both directions and scale it to [ –1 , 1 ] .
WWW 2011 – Session : Trust and DiversityMarch 28–April 1 , 2011 , Hyderabad , India222 1
0.9
0.8
0.7
0.6
0.5 y c a r u c c A
87.5 % 75 % 50 % 25 % 12.5 %
1
3
5
7
9
11 13 15 17 19 21 23 25
Figure 4 : Accuracy of SSTF with different training set sizes
Iteration accuracy wrt the training set size is shown in Table 1 . SSTF achieves accuracy of 91 % with only 75 training examples .
Table 1 : Accuracy of SSTF wrt Size of the Training Set 87.5
Avg . #Training examples 12.5
25 4
8
50 2
75 4
8
#Fold
Accuracy
.816
.857
.880
.910
.910
Figure 5 shows the relative change in the confidence score vector after each iteration . We can see that SSTF converges with a steady and reasonably fast pace . Figure 6 shows the sensitivity of SSTF to different parameter values , where we vary the weight of an edge to/from the neutral fact from 0.1 to 5 and ߙ from 0.001 to
005 We can see that SSTF is not sensitive to changes in its parameters .
We compare our approach ( with 75 training examples ) to the following algorithms : ( 1 ) Voting , which considers the fact provided by most data sources as the true fact ( a fact is randomly chosen in case of a tie ) ; ( 2 ) TruthFinder as described in [ 16 ] ; ( 3 ) Accu as described in [ 6 ] ; ( 4 ) AccuWithSim as described in [ 6 ] ; ( 5 ) 2 Estimates , which is described in [ 10 ] and has the highest accuracy among the methods in [ 10 ] . Because we use the same data set and evaluation criteria as in [ 6 ] , we simply report their results of Accu and AccuWithSim . The other methods are implemented according to their papers . Table 2 shows the accuracy , number of iterations used , and total running time for each approach . ( The running time of Accu and AccuWithSim are from [ 6 ] , which may be using a less powerful computer , as the reported running time of TruthFinder in [ 6 ] is four times of that in our experiment . ) Our approach , SSTF , achieves higher accuracy than existing approaches , especially when compared to TruthFinder , which does not detect data copying behaviors ( and neither does SSTF ) . This experiment shows that SSTF can significantly improve accuracy with a small training set . It is also significantly
0.12
0.1
0.08 e g n a h C
0.06
0.04
0.02
0
87.5 % 75 % 50 % 25 % 12.5 %
1
3
5
7
9
11 13 15 17 19 21 23 25 Iteration
Figure 5 : Changes after each iteration of SSTF y c a r u c c A
1
0.9
0.8
0.7
0.6
0.5 y c a r u c c A
1
0.9
0.8
0.7
0.6
0.5
0.1
1 neutral fact weight
0.001
0.01 α
Figure 6 : Parameter sensitivity of SSTF faster than many existing approaches .
Table 2 : Accuracy on the Book Authors data set
Approach
Voting
TruthFinder
Accu
AccuWithSim
2 Estimates
SSTF
Accuracy
#Iteration
Time ( s )
0.71 0.83 0.87 0.89 0.73 0.91
1 5 22 18 29 23
1.3 2.9
185.8 ( [6 ] ) 197.5 ( [6 ] )
21.2 7.9
6.2 Web Data Sets 621 Data Collection It has been observed that HTML tables on the web provide a huge number of facts , though they contain much noise [ 4 ] . We extract facts from tables and use our approach to distinguish true facts from false ones . As in [ 4 ] , we focus on attribute value tables , each of which contains one column of attribute names and another column of values , with two examples shown in Figure 7 . Such tables widely exist on the web and usually provide popular facts for each entity , making them the best subjects for truth discovery . The following method is used to extract facts from HTML tables . We build a table classifier using the approach from [ 2 ] , and train it with a manually labeled set of attribute value tables . With this classifier , we extract 744M attribute value tables from 20B web pages in Bing ’s index on 2010/06/22 . and click
Spears music ”
However , as these attribute value tables are not associated with any entity , we use the following method to find the main entity that each web page talks about . The main entity of a web page can often be found by matching user queries leading to a click on this page with the page content . For example , a user may search for “ Britney on http://wwwlastfm/music/Britney+Spears , whose title is “ Britney Spears – Discover music , videos , concerts , & pictures at Last.fm ” . We find the longest common substring between the query and the title , which is “ Britney Spears ” , the subject of this page . In addition , for each query and clicked web page , we try to match the query with the text in each <h1> element . If no match is found , it tries to match with each <h2> element , and so on , until it finds a match or has tried each element in the page . The matched part is considered as a candidate of the main entity of the page . For each candidate we build a wrapper based on HTML tag paths [ 13 ] . For example , the wrapper for the above page from Last.fm is “ <html><head><title>(* ) – Discover music , videos , concerts , & pictures at Last.fm ” .
In order to select good wrappers and use them to extract entity names , we utilize the fact that many websites contain large num
WWW 2011 – Session : Trust and DiversityMarch 28–April 1 , 2011 , Hyderabad , India223 ( a ) A table in http://enwikipediaorg/wiki/Tom_Hanks
( b ) A table in http://wwwcelebrinacom/tom hankshtml
Figure 7 : Two examples of attribute value tables bers of web pages in the same format ( eg , all movie pages on IMDB ) . If we can build a wrapper for extracting the main entity from some pages , we can extract entities from other pages of same format . We use the approach in [ 17 ] to find sets of web pages in the same format . For each such set of pages , we choose the wrapper that extracts entities from the most pages that match the user queries . This wrapper will be used to extract the main entity from every page in that set .
We use all query click logs from the US market between 2008/08/01 and 2009/05/31 , which contains each search query and all URLs clicked for it . Based on these queries and the 20B web pages in Bing ’s index on 2010/06/22 , we extract the main entities from 93.3M pages with attribute value tables , which have 164M tables in total . These entities are joined with the attributevalues extracted from the tables on these pages . 749M entityattribute value triples are created , which will be used in our experiment .
We extract the data from Wikipedia page titles and infobox tables ( eg , the table in Figure 7 ( a ) ) and use them as ground truth data . We want to remove all web sites getting majority of their data from Wikipedia , in order to perform a fair comparison between our approach and unsupervised approaches . For any web site with at least half of its data identical to some Wikipedia data , we consider it as a “ Wikipedia copier ” and remove it from our data set . Although this may falsely remove some websites , we can be sure that the remaining web sites are getting the majority of their data from sources other than Wikipedia . 622 Domain Specific Experiments We first test our approach on four data sets in special domains and compare it with existing approaches . The four data sets are directors of American films , developers ( ie , studios ) of video games , governors of US states , and presidents of universities . We collect the four sets of entities from special Wikipedia categories , as shown in Table 3 , where all entities with disambiguation pages are removed ( except US states ) . Then we collect the values on the specified attribute from the HTML table data set , and create four fact sets as described in Table 4 . Please note entities without the specific attributes provided by any site are ignored .
SSTF uses the same parameters as in the book authors data set , and all other approaches are implemented according to their papers . The similarity function for directors of films is the same as that in the book authors data set . In the other three data sets the similarity function between two string values is defined as their edit distance divided by the sum of their textual lengths ( the similarity is scaled to [ –1 , 1 ] for SSTF ) . We ignore all ground truth facts that are not provided by any other web sites . 4 fold experiments are used for SSTF , with 75 % of ground truth facts allocated
Table 3 : Data sources for four classes of entities
Class of entity
Num . Entity
Wikipedia categories
American films video games
US states universities
8772 5110
50
7191
*_ american_films
*_video_games states_of_the_united_states universities_and_colleges_*
Table 4 : Four data sets from HTML tables
Data set
#entity #provider #facts directors of films 4893 developer of video
3418 games governors of states
50 presidents of uni versities
543
370
181
70
64
31154
16961
8187
1195
1890
312
756
#distinct facts 7132
#ground truth fact
4105
1911
49
254 as training data and 25 % for testing in each fold . All other approaches use all ground truth facts for testing .
SSTF is compared to Voting , TruthFinder , AccuWithSim and 2 Estimates . Accuracy of an approach is defined as the percentage of entities for which the correct fact is selected . All algorithms converge on all data sets , except AccuWithSim which oscillates on three of the four data sets . When it oscillates among multiple states , we use the average accuracy of these states as its accuracy . Figure 8 shows the accuracies of each approach on these data sets . SSTF achieves accuracies between 78 % to 96 % , and it is significantly more accurate than the other approaches on all data sets except directors of films . On governors of US states and presidents of universities it beats all other approaches by at least 10 % . On directors of films the accuracies of different approaches are very close , with Vote and 2 Estimates being the most accurate and SSTF 0.4 % behind . Figure 9 shows the running time of the five approaches on the four data sets . 623 Web scale Truth Discovery In this subsection we present an experiment that involves all 749M facts extracted from HTML tables as described in Section 621 A web site often provides facts about many attributes for many entities . If a web site provides correct values for an attribute on some entities ( eg , date of birth of some people ) , we can expect it to provide correct values on this attribute for other entities . Therefore , we treat each web site and each attribute as a data source . Similarly we also treat each web site and each entity as a data source . We do not consider two facts with different entities and attributes to be from the same data source , because a web site may have very different trustworthiness on different attributes or different entities .
There are 65.7M entities , 749M facts ( 591M distinct facts ) from 33K websites . According to our definition above , there are 89M data sources , where 15.5M of them are website attribute pairs and 73.5M are website entity pairs . Some data sources provide very large numbers of facts ( as many as 5.2M ) , while on average each data source only provides 8.42 facts . The numbers of edges from different facts vary greatly . Thus we define the weight of an edge to/from the neutral fact according to Equation ( 7 ) :
ݓଵ௜ = ݓ௜ଵ = ߤ∙∑ หݓ௜௝ห
௝வଵ
, where ߤ = 01 The edge weight be tween two facts from the same data source is set to 0.5 , since facts from each data source are highly homogenous : They are either about the same entity or the same attribute .
Again the facts from Wikipedia infobox tables are used as ground truth . There are three runs of our approach : One uses all
WWW 2011 – Session : Trust and DiversityMarch 28–April 1 , 2011 , Hyderabad , India224 1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
Vote
TruthFinder
AccuWithSim
2 Estimates
SSTF
Directors of films
Developers of video games
Governors of
US states
Presidents of universities
Figure 8 : Accuracies of five approaches on four data sets
1000
100
10
1
0.1
Vote
TruthFinder
AccuWithSim
2 Estimates
SSTF
Directors of films
Developers of video games
Governors of
US states
Presidents of universities
Figure 9 : Running time ( s ) of five approaches on four data sets ground truth facts for training ( 30.7M facts ) , one uses 10 % of them , and the last uses 1 % of them .
Instead of continuing using Wikipedia to measure the accuracy of our approach , we measure that based on whether such data is useful in answering queries containing an entity and an attribute , which better reflects the usefulness of such data for web search . For example , if the user searches for {Barack Obama date of birth} and our data set contains some values for the entity “ Barack Obama ” and attribute “ date of birth ” , we will measure if the corresponding values are correct .
First we need to create a test set such that facts appearing more often in user queries have a larger chance to be selected . Our fact set is tail heavy where most facts , such as price of a product or version of some software , are uninteresting . In order to avoid selecting many trivial facts for evaluation , we only consider facts that appear in the Bing web search queries between 2008/08/01 and 2009/05/31 . A fact is consider to be in the query set if there is a query consisting of the entity name and attribute name . Each fact is weighted by the frequency of the corresponding query ( ie , number of times the query is submitted to Bing ) . We randomly select 1000 facts with the probability each fact is selected propor tional to its weight . We exclude 20 facts that appear in the ground truth set . We also exclude 120 facts whose values are long textual contents such as the biography of people and symptoms of diseases , because it is hard to judge if such facts are correct or not .
We manually label each fact as true or false according to the semantic meaning of the corresponding query using the following method . Given a fact which is an entity attribute value triple , we need to first decide the identity of its entity , as the entity name for some facts can be very ambiguous ( eg , “ system ” as the entity ) . We consider the entity with the specified name in the first result page of Bing as the true entity . Let us consider the fact “ Brazil : Time zone = UTC 2 to 5 ” ( ie , entity is “ Brazil ” , attribute is “ Time zone ” and value is “ UTC 2 to 5 ” ) . We consider the entity to be the country of Brazil which is the main entity in the first result page of Bing for query “ Brazil time zone ” , and thus this fact is true . The fact “ System : Security = Basic ” is false because the first result page of the query “ system security ” is not about the entity “ system ” . The second requirement for a fact to be true is that there exists an entity with the specified attribute and value , as some facts are simply wrong , such as “ Sony : Camera = Canon 300D ” . Among the 860 labeled facts , 68 are true and 792 are false . Please note that most of the false facts are simply not facts , such as “ baby : games = 32 ” , “ Comcast : email = enter missing info ” and “ myspace : comments = add ” . They are extracted because the HTML table classifier has limited accuracy .
We compare SSTF with TruthFinder [ 16 ] . We implement SSTF with MapReduce according to Section 5.2 , and implement TruthFinder with MapReduce as well . The approach in [ 6 ] is not MapReduceable as it involves sorting . Therefore we do not include it in our evaluation . assignment is defined as follows .
௟ሺ௙೔ሻୀ்,௟൫௙ೕ൯ୀி
Each approach assigns a confidence score to each fact . The accuracy is defined as the probability of a true fact having a higher score than a false fact . Let ݈ሺ݂௜ሻ and ܿ௜ be the label and confidence score of fact ݂௜ , respectively . The accuracy of a confidence score Accuracyሺࢉሻ = ∑ ܫ൫ܿ௜ = ܿ௝൯ In the rare case of ܿ௜ = ܿ௝ we consider it to be half correct .
ܫ൫ܿ௜ > ܿ௝൯ ห൛൫݂௜,݂௝൯|݈ሺ݂௜ሻ = ܶ,݈൫݂௝൯ = ܨൟห
+0.5∙∑
௟ሺ௙೔ሻୀ்,௟൫௙ೕ൯ୀி
Figure 10 compares the accuracy of TruthFinder and SSTF with varying amounts of training data . We can see SSTF achieves an accuracy of 83 % , which is much higher than TruthFinder . The accuracy of SSTF is not significantly affected by training data size . It achieves an accuracy of 81 % when only 1 % of Wikipedia infobox facts are used as training data .
Figure 11 shows the relative changes in the confidence score
1
0.9
0.8
0.7
0.6
0.5 y c a r u c c A e g n a h C
1
0.8
0.6
0.4
0.2
0
100 % 10 % 1 % TruthFinder
100 %
10 %
1 %
TruthFinder
1
2
3
4
5
6 Iteration
7
8
9
10
11
12
13
Figure 10 : Accuracy of SSTF and TruthFinder on Attribute value Table data
1
2
3
4
5
7
6 Iteration
8
9
10 11 12 13
Figure 11 : Changes after each iteration of SSTF with differ ent amounts of training data and TruthFinder
WWW 2011 – Session : Trust and DiversityMarch 28–April 1 , 2011 , Hyderabad , India225 vector after each iteration . Because of the high computation cost in processing hundreds of millions of facts , we stop iterating after the change falls below 0.05 , and SSTF stops after 10 to 13 iterations . The precision/recall curve of SSTF and TruthFinder are shown in Figure 12 . Considering only 7.9 % of the facts are correct , SSTF achieves reasonably high accuracy , and is much more accurate than TruthFinder . Table 5 shows the running time , #CPUs used and bytes read/write of SSTF with all training data .
1000
100 l
) c e s ( d o f r e p e m T i
10
1
0.1
10000
1000
) B M
( y r o m e M
100
10
Table 5 : Runtime of SSTF with MapReduce
Time ( min )
#bytes read/write
Initialization Each iteration
125 56.3
#CPU 152 184
3.36T 4.80T
Number of facts
Figure 13 : Runtime and accuracy of SSTF on synthetic data
Number of facts
6.3 Scalability on Synthetic Data Sets We test the scalability of our approach on synthetic data sets . Each data set contains 1000 websites that provide n facts in total on n/5 subjects . The trustworthiness of each website is uniformly sampled from [ 0 , 1 ] , with the true value of each subject uniformly sampled from [ 1000 , 10000 ] . The probability that a fact is set to the true value is given by the trustworthiness of the website . If a fact is false , it is a random number that deviates at most by 50 % from the true value . We perform a 5 fold experiment on each data set , using 80 % of data for training and 20 % for testing . The running time and memory usage of SSTF are shown in Figure 13 . Running time grows by 150 times when number of facts grows by 100 times , while memory usage grows by 42 times . The accuracy is always above 95 % .
7 . CONCLUSIONS As online sources often provide inaccurate and conflicting information , truth discovery has become an important research problem . Existing studies all employ unsupervised approaches , which are often ineffective as it is sometimes very difficult to distinguish between true and false facts using only the data itself . In this paper we propose a semi supervised approach that finds true values with the help of a small amount of ground truth data . Unlike existing studies that only provide iterative algorithms , we derive the optimal solution and provide an efficient iterative algorithm that converges to it . Experiments show our method achieves higher accuracy than existing approaches and can be applied on very large data sets .
8 . REFERENCES [ 1 ] J . Bleiholder and F . Naumann . Conflict handling strategies in an integrated information system . WWW’06 .
Web . VLDB’08 .
[ 3 ] A . Celikyilmaz , M . Thint , Z . Huang . A graph based semisupervised learning for question answering . IJCNLP’09 .
[ 4 ] E . Crestan and P . Pantel . Web scale knowledge extraction from semi structured tables . WWW’10 .
[ 5 ] X . L . Dong , L . Berti Equille , Y . Hu and D . Srivastava . Glob al detection of complex copying relationships between sources . In VLDB’10 .
[ 6 ] X . L . Dong , L . Berti Equille and D . Srivastava . Integrating conflicting data : The role of source dependence . VLDB’09 .
[ 7 ] X . L . Dong , L . Berti Equille and D . Srivastava . Truth dis covery and copying detection in a dynamic world . VLDB’09 .
[ 8 ] X . L . Dong . Presentation for [ 6 ] . http://www2researchattcom/~lunadong/talks/depenDetectionpptx
[ 9 ] A . Enright . Consumers trust information found online less than offline messages . Internet Retailer , Aug 25 , 2010 .
[ 10 ] A . Galland , S . Abiteboul , A . Marian and P . Senellart . Corro borating information from disagreeing views . WSDM’10 .
[ 11 ] A . B . Goldberg , X . Zhu and S . Wright . Dissimilarity in graph based semi supervised classification . AISTATS’07 .
[ 12 ] M . Isard , M . Budiu , Y . Yu , A . Birrell and D . Fetterly .
Dryad : distributed data parallel programs from sequential building blocks . Operating Systems Review , 41(3 ) , 2007 . [ 13 ] G . Miao , J . Tatemura , W P Hsiung , A . Sawires and L . E .
Moser . Extracting data records from the web using tag path clustering . WWW’09 .
[ 14 ] J . Tang , H . Li , Q J Qi and T S Chua . Integrated graphbased semi supervised multiple/single instance learning framework for image annotation . ACM Multimedia’08 .
[ 15 ] M . Wu and A . Marian . Corroborating answers from multiple
[ 2 ] M . J . Cafarella , A . Halevy , D . Z . Wang , E . Wu and Y . web sources . WebDB’07 .
100 %
Zhang . WebTables : Exploring the Power of Tables on the 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0
TruthFinder
10 %
1 % n o i s i c e r P
0
0.2
0.4
0.6
0.8
1
Figure 12 : Precision and recall of SSTF and TruthFinder
Recall
[ 16 ] X . Yin , J . Han and P . S . Yu . Truth discovery with multiple conflicting information providers on the web . KDD’07 .
[ 17 ] X . Yin , W . Tan , X . Li and Y C Tu . Automatic Extraction of Clickable Structured Web Contents for Name Entity Queries . WWW’10 .
[ 18 ] D . Zhou , O . Bousquet , TN Lal , J . Weston and B . Schölkopf .
Learning with local and global consistency . NIPS’04 .
[ 19 ] X . Zhu and Z . Ghahramani . Learning from labeled and unla beled data with label propagation . CMU Technical Report CMU CALD 02 107 , 2002 .
[ 20 ] X . Zhu , Z . Ghahramani and J . Lafferty . Semi supervised learning using Gaussian fields and harmonic functions . ICML’03 .
WWW 2011 – Session : Trust and DiversityMarch 28–April 1 , 2011 , Hyderabad , India226
