Personalized Mobile App Recommendation : Reconciling
App Functionality and User Privacy Preference
∗ Bin Liu
Deguang Kong
Lei Cen
Rutgers University binbenliu@rutgersedu
Samsung Research America deguangk@samsungcom
Purdue University lcen@purdue.edu
Neil Zhenqiang Gong
Hongxia Jin
UC Berkeley
Samsung Research America neilzgong@berkeleyedu hongxia@acm.org
Hui Xiong
Rutgers University hxiong@rutgers.edu
ABSTRACT Recent years have witnessed a rapid adoption of mobile devices and a dramatic proliferation of mobile applications ( Apps for brevity ) . However , the large number of mobile Apps makes it difficult for users to locate relevant Apps . Therefore , recommending Apps becomes an urgent task . Traditional recommendation approaches focus on learning the interest of a user and the functionality of an item ( eg , an App ) from a set of user item ratings , and they recommend an item to a user if the item ’s functionality well matches the user ’s interest . However , Apps could have privileges to access a user ’s sensitive resources ( eg , contact , message , and location ) . As a result , a user chooses an App not only because of its functionality , but also because it respects the user ’s privacy preference .
To the best of our knowledge , this paper presents the first systematic study on incorporating both interest functionality interactions and users’ privacy preferences to perform personalized App recommendations . Specifically , we first construct a new model to capture the trade off between functionality and user privacy preference . Then we crawled a real world dataset ( 16 , 344 users , 6 , 157 Apps , and 263 , 054 ratings ) from Google Play and use it to comprehensively evaluate our model and previous methods . We find that our method consistently and substantially outperforms the state of the art approaches , which implies the importance of user privacy preference on personalized App recommendations . Moreover , we explore the impact of different levels of privacy information on the performances of our method , which gives us insights on what resources are more likely to be treated as private by users and influence users’ behaviors at selecting Apps .
∗This work was done during an internship at Samsung Research America , San Jose , CA .
Categories and Subject Descriptors H28 [ Database Management ] : Database Applications— Data mining General Terms Algorithms , Experimentation Keywords Recommender Systems ; Mobile Apps ; Privacy and Security
1 .
INTRODUCTION
Mobile devices are becoming more and more popular in the past few years . For instance , it was reported that the smartphone market was bigger than the PC market in 2011 for the first time in history [ 28 ] . Thereafter , the smartphone market has continued to increase dramatically , eg , the smartphones shipped in the third quarter of 2013 increased 44 % year on year [ 27 ] . One of the reasons lies in the fact that users are able to augment the mobile devices’ functions via taking advantage of various feature rich thirdparty applications ( or Apps for brevity ) , which can be easily obtained from centralized markets such as Google Play and App Store . However , the number of Apps has recently increased dramatically , which makes it hard for a user to locate relevant Apps . For instance , as of July 2013 , Google Play had over 1 million Apps with over 50 billion cumulative downloads , and the number of Apps has reached over 1.2 million in June 2014 [ 12 ] ; as the beginning of June 2014 , App Store had 1.2 million Apps and a cumulative of 75 billion downloads [ 4 ] . Therefore , it is urgent to develop effective personalized App recommendation systems .
Conventional recommender systems [ 1 , 18 , 25 , 19 , 8 , 13 ] essentially aim to learn the interest of each user and the functionality of each item ( eg , an App in our problem ) , given the list of items used or rated by each user . Then , an item is recommended to a user if the item ’s functionality matches the user ’s interest . For instance , matrix factorizationbased approaches [ 18 , 25 ] model a user ’s interest as a latent vector and an item ’s functionality as another latent vector ; and an item is recommended to a user if the item ’s functionality vector is close to the user ’s interest vector in the latent space . Such interest functionality driven recommendation systems have been successfully used to recommend products in e commence ( eg , Amazon ) [ 21 ] , movies ( eg , Netflix ) [ 5 ] , musics [ 3 ] , point of interests [ 29 , 22 ] , and used for link prediction and attribute inference [ 10 ] .
However , these approaches are not appropriate for App recommendations . Specifically , unlike items such as music , movies , and point of interests , Apps could have privileges to access the user ’s personal information such as locations , contacts , and messages . Moreover , users might have different privacy preferences , eg , user A tends to not share contacts with the App while user B tends to not allow the App to access her/his locations . Although an App ’s functionality may matches a user ’s interest well , the user could still choose to not install it or dislike it if it does not respect the user ’s privacy preference . Indeed , according to a recent report [ 7 ] , 54 % of surveyed users have decided not to install Apps that want to access their sensitive personal information and 30 % of users have uninstalled at least one App after they realized that the App was collecting unexpected personal information . Therefore , whether a user selects/likes an App is a result of the trade off between two factors :
( 1 ) the degree of match between the user ’s interest and the App ’s functionality , which we call functionality match ; ( 2 ) the degree to which the App respects the user ’s pri vacy preference , which we call privacy respect . However , conventional recommendation approaches do not capture this trade off , which limits their performances on recommending Apps .
Our work : In this paper , we aim to bridge this gap via incorporating both interest functionality interactions and users’ privacy preferences . Specifically , we first construct a new latent factorization model to capture the trade off between functionality and user privacy preference . Different users might have different definitions on private data and could have different privacy concerns on different operations ( eg , read or write ) on the private data . Thus , in our model , we consider three levels of privacy information to characterize users’ privacy preferences . Moreover , our model takes the sparse user app rating matrix and the set of privacy sensitive privileges ( eg , App ’s permissions ) of each App at a given privacy level as an input , and it automatically learns the interest and privacy preference of each user , and the functionality of each App in the latent space , which are further used to predict users’ preferences for new Apps . Then , we crawled a real world dataset which consists of 16 , 344 users , 6 , 157 Apps , and 263 , 054 rating observations from Google play , and we use the dataset to comprehensively evaluate our method and previous approaches . We find that our method consistently and substantially outperforms the state of theart approaches . Furthermore , we explore the impact of different privacy levels on the performance of our method , and we observe that treating different operations with different privacy concerns achieves better recommendation performances .
Our key contributions are summarized as follows :
• We provide the first systematic study on leveraging both interest functionality expectation and user privacy preference to provide personalized App recommendations .
• We propose a new model to capture the trade off between functionality and user privacy preference .
• We crawled a real world dataset from Google Play , and we use it to comprehensively evaluate our approach and state of the art methods and explore the impact of privacy levels on the performance of our method . We find that our method consistently and substantially outperforms state of the art approaches .
Table 1 : Six dangerous permissions . They manipulate sensitive information locations , contacts , and messages , respectively .
Permission
ACCESS_FINE_LOCATION
Description allow App to access precise ( eg , GPS ) location
ACCESS_COARSE_LOCATION allow App to access approximate
READ_CONTACTS
WRITE_CONTACTS
READ_SMS
WRITE_SMS
SEND_SMS
( eg , cell towers , Wi Fi ) location allow App to read contacts info allow App to write contacts info allow App to read SMS messages allow App to write SMS messages allow App to send SMS messages
2 . PROBLEM FORMALIZATION
We first identify that whether a user adopts an App is a result of the trade off between the App ’s functionality and the user ’s privacy preference . Second , we introduce our defined hierarchy of user privacy concerns . Third , we formally define our privacy respect App recommendation problem .
2.1 Trade off between Functionality and Privacy
We focus on Android Apps , though our approach is also applicable to other types of Apps . Android system is a permission based framework . A permission is related to a critical resource ( eg , Internet , contact , and message ) on the mobile device , and granting a permission to an App allows the App to either read or write the corresponding resource . Table 1 shows some permission examples and their corresponding descriptions . For instance , giving the permission READ CONTACTS to an App makes it capable to read the user ’s contact data .
We identify that whether a user adopts an App is a result of the trade off between the App ’s functionality and the user ’s privacy preference . To achieve the functionality desired by the user , the App might need to manipulate the user ’s certain type of private data through requesting the corresponding sensitive permissions . For instance , Google Map , a navigation App , requires the user ’s GPS location data and thus needs the ACCESS FINE LOCATION permission . Moreover , the App could also request other sensitive permissions intentionally [ 26 ] or unintentionally [ 9 ] for non functionality purposes such as advertisements . For instance , Shekhar et al . [ 26 ] found that around 25 % of Android Apps access users’ location data only for advertisements ; Felt et al . [ 9 ] found that around 30 % of Android Apps request sensitive permissions that are not used by them at all . A user with low privacy concerns with the requested permissions/resources might sacrifice its privacy for the App ’s functionality , while a user with high privacy concerns might sacrifice the App ’s functionality for privacy or might transfer to another App that provides the same functionality but uses less private resources .
2.2 User Privacy Levels
Different users could have different definitions on private resources and could have different privacy concerns to different operations ( eg , read or write ) on the resources . We define three privacy levels , each of which consists of a set of resources and corresponding operations . A user ’s privacy
Contact
Level I
Table 2 : Privacy sensitive resources ( Level I ) vs . corresponding privacy sensitive permissions ( Level II ) .
W RITE_ C O N TA C TS
R E A D _ C O N TA C TS
Level II
O T H
W RIT E_ C O N TA C TS
R E A D _ C O N TA C TS
Level III
Message
SE N D _ S M S
W RIT E_ S M S
R E A D _ S M S
R E C EIV E_ S M S
SE N D _ S M S
W RIT E_ S M S
R E A D _ S M S
R E C EIV E_ S M S
IN T E R N E T
BL U ET O
Figure 1 : Illustration of the three privacy levels . Level I corresponds to privacy sensitive resources ; Level II corresponds to privacy sensitive permissions ( refer to Table 2 ) ; Level III is a superset of Level II . preference essentially characterizes the concerns for the operations on the private resources in a given privacy level . Figure 1 illustrates the hierarchy of the three privacy levels .
• Level I : This level considers 10 resources ( eg , contact , message , and location ) as private . The 10 resources are listed in the first column of Table 2 . However , this level does not distinguish the operations that can be applied to the private resources . Thus , this privacy level is represented as a binary vector of the 10 resources . If a user does not concern a certain private resource such as message , the user would accept an App to read , write , or even send messages .
• Level II : This level considers the same 10 resources in Level I as private . However , this level explicitly distinguishes different operations that can be applied to the resources . In this level , a user could have a low privacy concerns on reading messages but a high privacy concern on writing messages . This level of privacy can be expressed by the set of Android permissions that are related to the 10 resources . In total , there are 23 such permissions . Level II is more fine gained than level I , and Table 2 described mappings between level I and level II .
• Level III : This level considers all critical resources including the 10 resources in the Level I and II and other resources ( eg , Internet and bluetooth ) on a mobile device as private , and it also distinguishes different operations . This level is more complete and more finegrained than the Level II , and it can be expressed as a binary vector of all dangerous Android permissions . In total , we identified 72 such permissions , which are a superset of level II permissions .
For the same App , users with different privacy levels could behave differently at whether adopting the App or not . In our experiments , we will explore the impact of the three privacy levels on the performance of our method .
2.3 Privacy respect App Recommendation
We use M and N to denote the number of users and the number of apps , respectively ; we denote by the set of users as U = {u1 , u2 , · · · , uM } and the set of Apps as V = {v1 , v2 , , vN } . Let S be the set of privacy sensitive operations or resources at a given privacy level . Depending on
Privacy sensitive
Resources
Contact
Message
Location
Phone state
Phone call
Calendar
Call log
Browser history
Camera
Audio
Privacy sensitive Permissions
READ_CONTACTS WRITE_CONTACTS READ_SMS WRITE_SMS SEND_SMS RECEIVE_SMS RECEIVE_MMS SEND_RESPOND_VIA_MESSAGE ACCESS_FINE_LOCATION ACCESS_COARSE_LOCATION MODIFY_PHONE_STATE READ_PHONE_STATE CALL_PHONE CALL_PRIVILEGED READ_CALENDAR WRITE_CALENDAR READ_CALL_LOG WRITE_CALL_LOG READ_HISTORY_BOOKMARKS WRITE_HISTORY_BOOKMARKS CAMERA RECORD_AUDIO MODIFY_AUDIO_SETTINGS the privacy level , S can be the 10 private resources ( Level I ) , the 23 sensitive Android permissions ( Level II ) , or all dangerous Android permissions ( Level III ) . For each App j , we have its privacy sensitive operations/resources Πj at a given privacy level , where Πj ⊆ S . Πj can be obtained by App code analysis .
Suppose we are given a sparse matrix of user App response records ( eg , ratings or likes ) and the set of privacy sensitive operations/resources of each App at a given privacy level , our goal is to recommend most relevant Apps for each user by learning both interest and privacy preference of each user and functionality of each App .
3 . PROPOSED METHOD
This section presents our proposed user privacy respect
App recommendation model .
3.1 General Idea
We aim to quantify the trade off between App ’s functionality and user privacy preference . Suppose gfunc,i,j is the functionality match score of the interest of user i and functionality of App j and gprivacy,i,j is the privacy respect score of the privacy preference of user i and the privacy information used by App j . Modeling functionality match : Following the latent factor models in standard recommendation systems [ 18 , 25 ] , we model a user i ’s interest as a user latent vector uinterest ∈ RK and an App j ’s functionality as an App latent vector vj ∈ RK , where K is the number of latent dimensions of user interests and App functionalities . More specifically , each i
Table 3 : Mathematical Notations
Symbol
Size
Description
U V P Πj yij
K × M user latent factor K × N App latent factor K × S Πj ∈ S privacy information latent factor privacy information set for App j user i ’s rating for App j
R i element uik ∈ uinterest encodes the preference of user i to “ preference aspect ” k , and each element vik ∈ vj reflects the aspect affinity of App j to aspect k , where k = 1 , 2 , · · · , K . Then the functionality match score gfunc,i,j is modeled as : gfunc,i,j = f uinterest i
, vj ; Θ1 .
Modeling privacy respect : We also adopt a latent factor model to describe user privacy preference and App ’s private information . This latent factor model assumes that it is possible to group users by a relatively small number of privacy profiles . Specifically , we denote a user i ’s privacy preference as a latent factor uprivacy ∈ RK . Accordingly , we model each privacy information ( ie , a privacy sensitive resource or permission ) in the set of privacy information S at a given privacy level as a privacy latent factor ps ∈ RK . Note that although different number of latent dimensions can be applied to model functionality factors and privacy factors , we assume they are the same for simplicity . Therefore , we model the privacy respect score as : i gprivacy = f  i
uprivacy
, Xs∈Πj ps ; Θ2  , where Πj is the set of privacy information associated with the App j .
Trade off between functionality and privacy : We model a user i ’s overall preference ( denoted as gi,j ) for an App j as a weighted sum of the functionality match score and the privacy respect score . Specifically , we have : gi,j = gfunc,i,j + λgprivacy,i,j ,
( 1 ) where λ is used to balance App functionality and user privacy preference .
3.2 Model Specifications
Here we present a detailed model specification . Instead of separately representing user interest and user privacy preference with two latent factors , we amalgamate user interest latent vector and user privacy latent vector as one user profile latent factor ui ∈ RK , which is a K dimension vector . This amalgamation can reduce parameters to learn and thus improve computational efficiency . and a privacy latent factor as vj + λPs∈Πj
Each App j is modeled by a functionality latent factor ps , where Πj is the privacy information set for App j . For example , if App j requests three permissions ACCESS_FINE_LOCATION ( index : 2 ) , READ_CONTACTS ( index : 4 ) , and INTERNET ( index : 7 ) , then Πj = {2 , 4 , 7} at the privacy level Level III . The cardinality of the set Πj is the number of elements in Πj , ie , |Πj| = 3 in our example . Privacy latent factor represenps provides flexibility for Apps with different tation Ps∈Πj number of privacy information .
Figure 2 : Rating distribution .
Then a user i ’s preference score for an App j can be rep resented as
( 2 ) xij = uT i  vj + λ
1
|Πj| Xs∈Πj ps 
1
|Πj | is placed for each App to adjust the unbalanced where number of privacy informations .
To model user profile and App profile , it is practical to formulate the user App preference score xij to follow some probability distribution Pr(yij |xij , Θ ) , then we can infer the latent factors ui , vj , and ps through statistical inference methods . One most used probabilistic model , as used in probabilistic matrix factorization ( PMF ) [ 25 ] , is to assume Pr(yij |xij , Θ ) as a Gaussian distribution . However , the rating distribution in an App dataset is polarized as shown in Figure 2 , which indicates that Gaussian distribution would not be a good choice for our problem . Therefore , instead of using a Gaussian distribution , we adopt a Poisson distribution : yij ∼ Poisson(xij )
Pr(yij |xij ) = ( xij)yij exp {−xij} yij!
.
( 3 )
As noticed by [ 13 , 8 , 23 ] , Poisson distribution is a better choice for modeling discrete user item responses . Firstly , it better captures real user item response data . By setting non negative constrains on latent factors , Poisson latent factor model force response variables to be in a wider range than the rating based response . As a result , it can better capture preference order . Secondly , due to the form of Poisson distribution , only the observed part of user item matrix needs to be iterated during modeling , which provides advantage for the sparsity of user item matrix in recommendation problems . Therefore , we model user App preference as :
Pr(yij |ui , vi , ps ) = ( xij)yij exp {−xij} yij!
,
( 4 ) i vj + λ 1 where xij = uT and psk can be given Gamma distributions as empirical priors , ie , the user App preferences can be modeled as a generative process : ps . Further , uik , vik ,
|Πj | Ps∈Πj
1 . For each user i , generate user latent factor : uik ∼ Gamma(αU , βU ) ,
( 5 )
2 . For each App j , generate App functionality latent fac tor : vjk ∼ Gamma(αV , βV ) ,
( 6 )
3 . For each privacy information s , generate privacy latent
Taking derivatives on Q with respect to uik , vjk , and psk , factor : psk ∼ Gamma(αP , βP ) ,
( 7 )
4 . For each user App pair hi , ji , generate Poisson response :
Pr(yij|ui , vi , ps ) = ( xij)yij exp {−xij} yij !
, we have
∂Q ∂uik
=
αU − 1 uik
−
1 βU
− η × uik
+
N
Xj=1 yij xij
− 1
vjk +
λ
|Πj | Xs∈Πj yij
Xi=1 xij
M psk  − 1 uik
( 12 )
− η × vjk +
− η × psk
1 βV
1 βP
∂Q ∂vjk
∂Q ∂psk
=
=
αV − 1 vjk
αP − 1 psk M
−
−
N
+
Xi=1
Xj=1 yij xij
− 1 λuik
I(s ∈ Πj )
|Πj |
We adopt the ascending gradient method [ 6 ] to infer the latent factors . Specifically , parameters θ are updated by the following equation :
θ ← θ + ǫ ×
∂Q ∂θ
,
( 13 ) where θ is an element in {U , V , P} , ∂Q ∂θ is the derivatives according to Equation ( 12 ) , and ǫ is the learning rate . The algorithms iterate over {U , V , P} until one of the following termination conditions is reached ( a ) the value of objection function Q in Equation ( 11 ) keeps stable , or ( b ) the maximum number of iterations is reached . where Θ = {U , V , P} are parameters to be estimated , and Φ = {αU , βU , αV , βV , αP , βP } are model hyperparameters .
3.3 Model Estimation
Let Pr(U , V , P|Y , Φ ) be the posteriori probability of generation of U , V , P , given observations of Y and prior distribution Φ , according to the maximum a posteriori ( MAP ) rule , we need to maximize : max U,V,P
Pr(U , V , P|Y , Φ )
∝ max U,V,P
Pr(Y|U , V , P)Pr(U , V , P|Φ )
( 8 ) where Pr(ui , vj , ps|αu , βu , αv , βv , αs , βs ) are the prior distributions for U , V , P generated from Eqs.(5 , 6 , 7 ) , and Pr(yij|uuui , vvvj , ps ) can be computed using Eq ( 4 ) .
Following the likelihood principle , we can determine the optimal solution for U , V , P to Eq ( 8 ) by Maximum a Posteriori ( MAP ) estimation . Specifically , we have :
Pr(Y|U , V , P ) =
Pr(U|αU , βU ) =
Pr(V|αV , βV ) =
Pr(P|αP , βP ) =
M
N
Yi=1
Yj=1
M
K
Yi=1 Yj=1
N
Yk=1 Yk=1
K
S
K
Ys=1
Yk=1 where
( xij)yij exp {−xij} /yij ! uαU −1 ik exp(−uik/βU ) βαU U Γ(αU ) vαV −1 jk exp(−vjk/βV ) βαV V Γ(αV ) pαP −1 sk exp(−psk/βP ) βαP P Γ(αP ) i  xij = uuu⊤ vvvj + λ
1
|Πj | Xs∈Πj ppps 
Then the log likelihood of Eq ( 8 ) is given by
L = log Pr(U , V , P , F|Y , Φ )
=
+
+
+
M
Xi=1 Xj=1
N
S
Xs=1 Xi=1
M
K
K
Xk=1(αU − 1 ) ln uik − uik/βU Xk=1(αV − 1 ) ln vjk − vjk/βV Xk=1(αP − 1 ) ln psk − psk/βP Xj=1
( yij ln xij − xij ) + const .
K
N
,
( 10 )
Thus maximization of Eq ( 8 ) wrt U , V , P is equivalent to maximization of Eq ( 10 ) . To control the model complexity , we further add a penalty term , then the objective function becomes
Q = L −
η
2 ,||U||2
F + ||V||2
F + ||F||2 F
( 11 )
4 . EXPERIMENTS
4.1 Experimental setup
( 9 )
We aim to answer the following two questions :
• Question 1 : Whether , and to what extent , our privacyrespect App recommendation model improves upon previous recommendation approaches that do not consider user privacy preferences ?
• Question 2 : How privacy levels ( as introduced in Sec tion 2.2 ) influence the performance of our approach ?
Towards this goal , we first crawled a user app rating dataset from Google Play via reverse engineering the service protocol . Then , using the crawled dataset , we compare our method with state of the art latent factor based recommendation models and explore the impact of the three privacy levels on the performance of our approach .
4.2 Data Collection
We collected our dataset from Google Play . On Google Play , a user ’s ratings about Apps he/she used are publicly available . Once we obtain the Google ID of a user , we can locate all Apps the user has rated . Therefore , we first obtain a list of Google user IDs from Gong et al . [ 11 ] and write a crawler to retrieve all rated Apps of these users . Moreover , for each retrieved App , we crawled its permissions from Google Play . Our crawls were performed during June and July of 2014 .
We remove unpopular Apps and users with too few rated Apps from our collected dataset to avoid cold start problem . Specifically , we first remove Apps with less than 5 users and then exclude users with less than 10 Apps . After this preprocessing step , our dataset has 16 , 344 users , 6 , 157 Apps ,
Table 4 : Data Description users Apps 6,157 16,344 ratings 263,054 sparsity 99.74 % avg ratings
16.09
READ_SMS MODIFY_AUDIO_SETTINGS RECEIVE_SMS SEND_SMS BLUETOOTH READ_CALL_LOG WRITE_CONTACTS CHANGE_WIFI_STATE RECORD_AUDIO GET_TASKS WRITE_SETTINGS CALL_PHONE CAMERA READ_CONTACTS ACCESS_COARSE_LOCATION ACCESS_FINE_LOCATION WAKE_LOCK READ_PHONE_STATE WRITE_EXTERNAL_STORAGE INTERNET
0
1000 2000 3000 4000 5000
Figure 3 : The top 20 most frequently used permissions and the number of Apps ( out of the 6 , 157 Apps in our dataset ) that require those permissions . and 263 , 054 rating observations . The user App rating matrix has a sparsity as high as 9974 % Each user rated 16.09 Apps on average , which is a very small fraction of all the Apps . Table 4 shows some basic statistics of our preprocessed dataset .
Figure 3 shows the top 20 most frequently used permissions and the number of Apps that require those permissions . While permissions such as INTERNET might not lead to privacy concerns for most users , some permissions ( eg , READ_CONTACTS , ACCESS_FINE_LOCATION , and CALL_PHONE ) could raise serious privacy concerns depending on how they are used by the Apps .
4.3 Compared Approaches
We compare our proposed model with the following latent factor based recommendation models :
• Singular Value Decomposition ( SVD ) [ 18 ] : SVD is a low dimension decomposition based recommendation method .
• Probabilistic Matrix Factorization ( PMF ) [ 25 ] : PMF ex tends SVD to a probabilistic framework .
• Non negative Matrix Factorization ( NMF ) [ 19 ] : Similar to SVD , but NMF requires the latent vectors to be nonnegative .
• Poisson Factor Model ( Poi FM ) [ 13 , 8 ] : Poisson factor model provides an alternative for latent factor model for different applications , and previous work [ 13 ] shows that Poisson factor model outperforms Gaussian based PMF .
Besides comparing to previous methods that do not consider user privacy preferences , we also investigate how different privacy levels impact the performance of our method . Specifically , we compare the following three variants of our method :
• Privacy Res . : Privacy respect App recommendation with Level I as the privacy level . Recall that this level considers the 10 resources listed in Table 2 as private data and do not distinguish different operations . Thus , each App ’s permissions are transformed to a 10 dimensional binary vector , which represents the private resources used by the App .
• Sensitive Perm . : Privacy respect App recommendation with Level II as the privacy level . Level II considers the 23 dangerous permissions that are related to the 10 sensitive resources . Therefore , we have a 23 dimensional binary vector to represent the private resources used by an App .
• All Danger Perm . : Privacy respect App recommendation with Level III as the privacy level . Level III considers all critical resources ( corresponding to 72 dangerour Android permissions ) on a mobile device as private . Therefore , we have a 72 dimensional binary vector to represent the private resources used by an App .
ν
Training and testing : We sample 80 % of rated Apps of each user uniformly at random as training data , and we use the remaining rated Apps for testing . All the latent factor models are implemented with stochastic gradient ascent/descent optimization method with an annealing procedure to discount learning rate ǫ at iteration nIter with ǫnIter = ǫ ν+nIter−1 by setting ν = 50 . For SVD , PMF , and NMF , learning rates are set as 1e−3 ; learning rates for Poisson based methods are empirically set as 1e−4 . For Poisson based latent factor models including both baseline Poi FM and our proposed model , we set αU = αV = αP = 20 and βU = βV = βP = 0.5 ; penalty weight η is set as 1e−5 ; functionality privacy trade off weight λ is empirically set as 1 .
4.4 Evaluation Metrics
In App recommendation , we present to the user a list of recommendations , thus we evaluate the models in terms of ranking . Specifically , we present each user with N Apps that have the highest predicted values but are not rated by the user in the training phase , and we evaluate different approaches based on which of these Apps were actually adopted by the user in the test phase .
Precision and Recall : Given a top N recommendation list CN,rec , precision and recall are defined as
Precision@N =
Recall@N =
|CN,recT Cadopted| |CN,recT Cadopted|
|Cadopted|
N
( 14 )
, where Cadopted are the Apps that a user has adopted in the test data . The precision and recall for the entire recommender system are computed by averaging the precision and recall over all the users , respectively .
F measure : F measure balances between precision and recall . We consider the Fβ metric , which is defined as
Fβ = ( 1 + β2 ) ·
Precision × Recall
β2 · Precision + Recall
.
( 15 )
The Fβ metric with β < 1 indicates more emphasis on precision than recall . In our experiments , we use Fβ metric with β = 05
0.175
0.15
0.125
0.1 n o i s i c e r P
0.05
0.025
0
0.2
0.15 l l a c e R
0.1
0.05
0
0.15
0.125
0.1 e u l a V F
0.05
0.025
0
SVD
@1
@5
@10
Rank Position
( a ) K = 20
0.175
0.15
0.125
0.1 n o i s i c e r P
0.05
0.025
0
SVD PMF
@1
@5
@10
Rank Position
( b ) K = 30
0.175
0.15
0.125
0.1 n o i s i c e r P
0.05
0.025
0
SVD PMF
@1
@5
@10
Rank Position
( c ) K = 50
Figure 4 : Precision @N with different latent dimensions K .
0.2
0.15 l l a c e R
0.1
0.05
0
@1
@5
@10
Rank Position
( b ) K = 30
0.2
0.15 l l a c e R
0.1
0.05
0
@1
@5
@10
Rank Position
( c ) K = 50
@1
@5
@10
Rank Position
( a ) K = 20
Figure 5 : Recall @N with different latent dimensions K .
SVD PMF NMF Poi FM Privacy Res . Sensitive_Perm . All_Danger_Perm .
@1
@5
@10
Rank Position
( a ) K = 20
0.15
0.125
0.1 e u l a V F
0.05
0.025
0
SVD PMF NMF Poi FM Privacy Res . Sensitive_Perm . All_Danger_Perm .
@1
@5
@10
Rank Position
( b ) K = 30
0.15
0.125
0.1 e u l a V F
0.05
0.025
0
SVD PMF NMF Poi FM Privacy Res . Sensitive_Perm . All_Danger_Perm .
@1
@5
@10
Rank Position
( c ) K = 50
Figure 6 : Fβ @N with different latent dimensions K ( β = 05 ) e c n a m r o f r e P e v i t a l e R
250
200
150
100
50
0
@1
@5
@10
Rank Position
( a ) K = 20 e c n a m r o f r e P e v i t a l e R
250
200
150
100
50
0
@1
@5
@10
Rank Position
( b ) K = 30 e c n a m r o f r e P e v i t a l e R
250
200
150
100
50
0
@1
@5
@10
Rank Position
( c ) K = 50
Figure 7 : Relative performance @N with different latent dimensions K . r Recall and r Precision : Similar to Yin et al . [ 30 ] , we also compare the different models in terms of relative precision and recall . Let C denote the candidate Apps , the precision and recall in a top N list of a random recommender system are |Cadopted | |C| , respectively . Then , the relative precision and recall [ 30 ] are defined as and N
|C| rPrecision@N = rRecall@N =
Precision@N |Cadopted|/|C| Recall@N
N/|C|
=
=
|Cadopted| · N
|CN,recT Cadopted| · |C| |CN,recT Cadopted| · |C|
|Cadopted| · N
( 16 ) Note that the relative precision and recall have the same value . Therefore , we only show one of them and we name it as the relative performance , which measures the improvement upon a random recommendation method .
4.5 Comparison Results
Figure 4 , Figure 5 , Figure 6 , and Figure 7 respectively show the precision@N , recall@N , Fβ@N , and relative performance@N of all compared approaches on our dataset , where N = 1 , 5 , 10 . For each approach , we explore 3 latent dimension settings , ie , K = 20 , K = 30 , and K = 50 .
451 Comparing Our Method with Previous
Approaches
We find that our approach consistently outperforms previous methods for different N and different K . Specifically , we observe that NMF outperforms both SVD and PMF , and that Poisson based factor model Poi FM can further improve upon NMF with all the three considered number of latent dimensions . Moreover , our privacy respect App recommendation methods with the three privacy levels all further improve upon Poi FM with significant margins for all the four evaluation metrics . To better demonstrate the improvements , Table 5 shows the absolute improvements of our proposed method , with different privacy levels , as compared to the best baseline method Poi FM when K = 30 and N = 1 . We can see significant improvement margins . While precision and recall may change with different N , F measure provides a stable comparisons as it is the harmonic mean of precision and recall . In terms of F measure , we can observe
Table 5 : Absolute improvements of our proposed method with different privacy levels as compared to the best baseline method Poi FM ( K = 30 , N = 1 ) . metric Privacy Res . Sensitive Perm . All Danger perm .
F measure 3.46 % ↑ 5.31 % ↑ precision 1.45 % ↑ 89.16 ↑ recall relative
5.56 % ↑ 8.49 % ↑ 2.33 % ↑ 143.45 ↑
5.80 % ↑ 8.86 % ↑ 2.43 % ↑ 149.39 ↑ a 3.46 % improvement for Privacy Res . , a 5.56 % improvement for Sensitive Perm . , and a 5.80 % improvement for All Danger perm
Our results show that once we consider user privacy preference , performance of App recommendation gets improved no matter what privacy level is used .
452 Impact of Privacy Levels
We find that our method with Level II privacy information ( ie , Sensitive Perm . ) can improve upon our method with Level I privacy information ( ie , Privacy Res . ) with notable margins . This implies that users treat different operations ( eg , read and write ) on the 10 private resources with different privacy concerns . However , Sensitive Perm . and All Danger Perm . have very close performances consistently for all settings we considered . Figure 8 shows a zoom in comparisons of the three levels . Our observations indicate that users probably do not treat resources ( eg , Internet , Bluetooth ) other than the 10 resources in the privacy level Level I and Level II as private resources , and thus accessing those resources would not influence whether a user likes/adopts an App .
453 Summary
We find that our privacy respect App recommendation method significantly outperforms previous approaches that do not consider user privacy preference . Moreover , we find that users are more likely to treat the 10 resources in Level I and Level II as private resources and they treat different operations ( eg , read and write ) on these resources with different privacy concerns .
0.12
0.1 e u l a V F
0.08
0.06
0.04
0
Poi FM Privacy Res . Sensitive_Perm . All_Danger_Perm .
2
4
6
8
10
Rank Position
Figure 8 : Zoom in comparisons between our methods with the three privacy levels ( ie , Privacy Res . , Sensitive Perm . , and All Danger perm . ) and the best baseline method ( ie , Poi FM ) for K = 30 .
5 . RELATED WORK
Most of related works come from two research fields : personalized recommendation methodologies especially latent factor model based recommendation models , and mobile App rankings and recommendations .
Personalized Recommendation : Latent factor models have become popular and been widely used in recommendation systems . These work include matrix factorization [ 18 ] , Probabilistic Matrix Factorization ( PMF ) [ 25 ] and its Bayesian version [ 24 ] , and their other variants [ 17 , 2 , 16 ] . In our case and many cases alike , the recommendation system needs to infer user preferences from user feedbacks . Latent factor models , which are suitable for better capturing preference order are preferred and followed in our approach . One option in designing latent factor model is to set nonnegative constrains on latent factors to force response variables to be in a wider range than the rating based response , which is normally limited to a certain range of integers . As a result , non negative matrix factorization based methods are widely used [ 19 , 31 , 14 ] due to this advantage .
Furthermore , most of these latent factors based studies along this line of research assume that the user response follows Gaussian distribution with expectation from the product of user and item latent factors . However , some recent work [ 13 , 8 , 23 ] have pointed out that Poisson distribution could be a better choice for modeling user response . Firstly , it better captures real consumption data ; secondly , due to the form of Poisson distribution , only the observed part of user item matrix need to be iterated during modeling . This is a big advantage considering the usually extreme sparsity of user item matrix in recommendation problems , providing better scalability .
This paper follows the state of the art latent factor model to propose a novel model that is more suitable for App recommendation task by introducing users’ privacy preference information . Experimental evidence shows advantage of our approach against above state of the art models .
Mobile App Ranking and Recommendation : There have been a few previous works on App recommendation , but these works only focused on recommending the most relevant Apps to a user without considering user privacy preference . Work from [ 15 ] provides a context aware recommendation using tensor factorization by including context information such as location , moving status and time . To address the cold start problem for App recommendation , [ 20 ] proposed to incorporate side information from Twitter . Information of followers of the App ’s official Twitter account is collected and utilized to model the App , providing an estimation about which users may like the App , even when the App still has no official rating yet . Yin et al . [ 30 ] considered a trade off between satisfaction and temptation for App recommendation with a special focus on the case that a user would like to replace an old App with a new one . An interesting dataset is collected via an App from users , revealing users’ process of choosing a new App after comparing it with those already obtained ones . And the satisfaction and temptation of an App is evaluated and used to facilitate the recommendation algorithm . More recently , Zhu et al .
[ 32 ] proposed a mobile App recommendation ( more precisely , ranking ) system by considering both the App ’s popularity and security risks . They provide an identical global ranking of Apps to every user , and thus their work is not personalized App recommendation .
As described above , different from all previous work on App recommendation ( personalized or unpersonalized ) , this paper , to the best of our knowledge , is the first one that proposes to incorporate user privacy preference into mobile App recommendation . Experiments on real life data show affirmative results for the contribution of privacy information in App recommendation .
6 . CONCLUSION AND FUTURE WORK
In this paper , we present the first systematic study on leveraging the trade off between a user ’s interest functionality expectation and her/his privacy preference to perform personalized privacy respect App recommendations . Specifically , we first propose a new model to capture the tradeoff between functionality and user privacy preference . Our model is flexible to incorporate three levels of privacy information . Moreover , we crawled a real world dataset from Google Play and use it evaluate our method . Our results demonstrate that our method achieves consistent and substantial performance improvement over previous approaches . This implies that it is important to consider user privacy preference on personalized App recommendations . Furthermore , we explore the impact of different levels of privacy information on the performances of our method . We find that treating different operations with different privacy concerns achieves better recommendation performances .
A few interesting future directions include measuring users’ different privacy preferences in the three privacy levels in the wild and constructing a more fine grained model to capture the trade off between functionality expectation and privacy preference .
7 . REFERENCES [ 1 ] G . Adomavicius and A . Tuzhilin . Toward the next generation of recommender systems : A survey of the state of the art and possible extensions . Knowledge and Data Engineering , IEEE Transactions on , 17(6):734–749 , 2005 .
[ 2 ] D . Agarwal and B C Chen . Regression based latent factor models . In Proc . of the 15th ACM SIGKDD Int’l Conf . on Knowledge Discovery and Data Mining , KDD ’09 , pages 19–28 , 2009 .
[ 3 ] N . Aizenberg , Y . Koren , and O . Somekh . Build your own music recommender by modeling internet radio streams . In Proc . of the 21st int’l conf . on World Wide Web , pages 1–10 , 2012 .
[ 4 ] App Store Statistics . http://enwikipediaorg/wiki/App_Store_(iOS )
[ 5 ] R . M . Bell and Y . Koren . Lessons from the netflix prize challenge . SIGKDD Explor . Newsl . , 9(2):75–79 , Dec . 2007 .
[ 6 ] D . P . Bertsekas . Nonlinear programming . Athena
Scientific , 1999 .
[ 7 ] J . L . Boyles , A . Smith , and M . Madden . Privacy and data management on mobile devices . Pew Internet & American Life Project , 2012 .
[ 8 ] J . Canny . Gap : A factor model for discrete data . In
Proc . of the 27th ACM SIGIR Conf . on Research and Development in Information Retrieval , SIGIR ’04 , pages 122–129 , 2004 .
[ 9 ] A . P . Felt , E . Chin , S . Hanna , D . Song , and
D . Wagner . Android permissions demystified . In CCS , 2011 .
[ 10 ] N . Z . Gong , A . Talwalkar , L . Mackey , L . Huang ,
E . C . R . Shin , E . Stefanov , E . R . Shi , and D . Song . Joint link prediction and attribute inference using a social attribute network . ACM Transactions on Intelligent Systems and Technology ( TIST ) , 5(2):27 , 2014 .
[ 11 ] N . Z . Gong , W . Xu , L . Huang , P . Mittal , E . Stefanov ,
V . Sekar , and D . Song . Evolution of social attribute networks : measurements , modeling , and implications using google+ . In Proceedings of the 2012 ACM conference on Internet measurement conference , pages 131–144 . ACM , 2012 .
[ 12 ] Google Play Statistics .
[ 17 ] Y . Koren . Factorization meets the neighborhood : a multifaceted collaborative filtering model . In Proc . of the 14th ACM SIGKDD Int’l Conf . on Knowledge Discovery and Data Mining , KDD ’08 , pages 426–434 , 2008 .
[ 18 ] Y . Koren , R . Bell , and C . Volinsky . Matrix factorization techniques for recommender systems . Computer , 42(8):30–37 , Aug . 2009 .
[ 19 ] D . D . Lee and H . S . Seung . Algorithms for non negative matrix factorization . In NIPS , pages 556–562 , 2000 .
[ 20 ] J . Lin , K . Sugiyama , M Y Kan , and T S Chua .
Addressing cold start in app recommendation : latent user models constructed from twitter followers . In Proc . of the 36th int’l ACM SIGIR conf . on Research and development in information retrieval , SIGIR ’13 , pages 283–292 , 2013 .
[ 21 ] G . Linden , B . Smith , and J . York . Amazon.com recommendations : Item to item collaborative filtering . IEEE Internet Computing , 7(1):76–80 , Jan . 2003 .
[ 22 ] B . Liu , Y . Fu , Z . Yao , and H . Xiong . Learning geographical preferences for point of interest recommendation . In Proc . of the 19th ACM SIGKDD Int’l Conf . on Knowledge Discovery and Data Mining , KDD ’13 , pages 1043–1051 , 2013 .
[ 23 ] B . Liu , H . Xiong , S . Papadimitriou , Y . Fu , and
Z . Yao . A general geographical probabilistic factor model for point of interest recommendation . Knowledge and Data Engineering , IEEE Transactions on , PP(99 ) , 2015 .
[ 24 ] R . Salakhutdinov and A . Mnih . Bayesian probabilistic matrix factorization using markov chain monte carlo . ICML ’08 , pages 880–887 , 2008 .
[ 25 ] R . Salakhutdinov and A . Mnih . Probabilistic matrix factorization . In NIPS , volume 20 , 2008 .
[ 26 ] S . Shekhar , M . Dietz , and D . S . Wallach . Adsplit :
Separating smartphone advertising from applications . In Usenix Security , 2012 .
[ 27 ] Smartphone Sales in the Third Quarter of 2013 . http://wwwfinfactsie/irishfinancenews/ article_1026800shtml
[ 28 ] The Smartphone Market is Bigger Than the PC
Market . http://wwwbusinessinsidercom/ smartphone bigger than pc market 2011 2 . http://enwikipediaorg/wiki/Google_Play
[ 29 ] M . Ye , P . Yin , W C Lee , and D L Lee . Exploiting
[ 13 ] P . Gopalan , J . M . Hofman , and D . M . Blei . Scalable recommendation with poisson factorization . CoRR , abs/1311.1704 , 2013 .
[ 14 ] Q . Gu , J . Zhou , and C . H . Ding . Collaborative filtering : Weighted nonnegative matrix factorization incorporating user and item graphs . In SDM , pages 199–210 , 2010 .
[ 15 ] A . Karatzoglou , L . Baltrunas , K . Church , and
M . B¨ohmer . Climbing the app wall : Enabling mobile app discovery through context aware recommendations . In Proc of the 21st ACM Int’l Conf . on Information and Knowledge Management , CIKM ’12 , pages 2527–2530 , 2012 .
[ 16 ] D . Kong , M . Zhang , and C . H . Q . Ding . Minimal shrinkage for noisy data recovery using schatten p norm objective . In ECML/PKDD 2013 , pages 177–193 , 2013 . geographical influence for collaborative point of interest recommendation . In Proc of the 34th Int’l ACM SIGIR Conf on Research and Development in Information Retrieval , SIGIR ’11 , pages 325–334 , 2011 .
[ 30 ] P . Yin , P . Luo , W C Lee , and M . Wang . App recommendation : a contest between satisfaction and temptation . WSDM ’13 , pages 395–404 , 2013 . [ 31 ] S . Zhang , W . Wang , J . Ford , and F . Makedon .
Learning from incomplete ratings using non negative matrix factorization . In SDM’06 , 2006 .
[ 32 ] H . Zhu , H . Xiong , Y . Ge , and E . Chen . Mobile app recommendation with security and privacy awareness . In Proc . of the 20th ACM Int’l Conf . on Knowledge Discovery and Data Mining , KDD ’14 , 2014 .
