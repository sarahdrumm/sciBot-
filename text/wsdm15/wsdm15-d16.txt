FLAME : A Probabilistic Model Combining Aspect Based
Opinion Mining and Collaborative Filtering
Yao Wu
School of Computing Science
Simon Fraser University
Burnaby , BC , Canada wuyaow@sfu.ca
Martin Ester
School of Computing Science
Simon Fraser University
Burnaby , BC , Canada ester@cssfuca
ABSTRACT Aspect based opinion mining from online reviews has attracted a lot of attention recently . Given a set of reviews , the main task of aspect based opinion mining is to extract major aspects of the items and to infer the latent aspect ratings from each review . However , users may have different preferences which might lead to different opinions on the same aspect of an item . Even if fine grained aspect rating analysis is provided for each review , it is still difficult for a user to judge whether a specific aspect of an item meets his own expectation . In this paper , we study the problem of estimating personalized sentiment polarities on different aspects of the items . We propose a unified probabilistic model called Factorized Latent Aspect ModEl ( FLAME ) , which combines the advantages of collaborative filtering and aspect based opinion mining . FLAME learns users’ personalized preferences on different aspects from their past reviews , and predicts users’ aspect ratings on new items by collective intelligence . Experiments on two online review datasets show that FLAME outperforms state of the art methods on the tasks of aspect identification and aspect rating prediction .
Categories and Subject Descriptors H33 [ Information search and retrieval ] : Text Mining
General Terms Algorithms , Experimentation
Keywords Collaborative Filtering ; Opinion Mining ; Text Mining
1 .
INTRODUCTION
Nowadays , products and services offered on most online E commerce websites are accompanied by abundant usergenerated reviews , which can help users make better decision . For instance , if a user wants to know more about the
Figure 1 : A Sample Review On Amazon battery life of a laptop , comments on the battery life of this specific laptop by other users are more reliable than those given in the official description of the product . However , the volume of reviews grows so rapidly that it gets extremely difficult for users to find useful information in short time . Thus mining useful information out of these huge amount of reviews has become an important way to improve user satisfaction of these online E commerce websites .
Aspect based opinion mining [ 10 ] has attracted a lot of attention recently . Given a collection of reviews on a set of items , aspect based opinion mining methods extract major aspects out of every item based on how often they have been commented by users , and learn users’ sentiment polarities toward each aspect based on the opinionated words they used in the reviews . Figure 1 shows a sample review from Amazon1 . The user assigns a 5 star overall rating , and expresses his opinions on several aspects of the product . From a set of reviews like this , aspect based opinion mining methods can automatically extract the aspects of the product , such as performance , display , value and size , as well as infer latent sentiment scores for each aspect , eg , 5 stars on its display .
Much work has been proposed to help users digest and exploit large number of reviews by aspect based opinion mining techniques , including information extraction from reviews [ 11 ] , uncovering the latent aspects of the review sentences [ 13 ] , inferring the latent aspect ratings and aspect weights of each review document [ 22 , 23 ] , aspect based review summarization for products [ 11 , 9 ] , etc . These methods either focus on review level analysis ( extracting useful information within each review ) to help users easily find what they need from a piece of review , or make product level summarization ( aggregating the opinions of all the users ) to provide an overview of users’ feedback on a product . However , an important factor is typically ignored – preference diver
1http://wwwamazoncom sity , ie , users have different preferences that their opinions on the same item may differ from each other . For example , the food of the same restaurant might be delicious for some users but terrible for others . When choosing restaurants , a user might want to know whether a restaurant meets his own expectation on the aspect of food . But when facing a large number of reviews expressing various opinions , it becomes extremely difficult for the user to make the decision : 1 ) it ’s impossible for the user to read all the reviews even if the finegrained review level analysis is provided . 2 ) the user has no idea of which reviews are more reliable or which reviewers share similar tastes with him . 3 ) product level summarization is also unreliable since it is generated from reviews by users with different tastes . To help users better utilize the existing reviews , we argue that a new method is required , which can learn a user ’s personalized preferences on different aspects from his past reviews of other items , and predict his preferences on the aspects of a given item by mining the opinions by other users with similar preferences .
A popular method of learning user preferences is Collaborative Filtering , which predicts a user ’s interests by collaboratively collecting preferences from many other users . Typical collaborative filtering methods take the numeric overall ratings as inputs [ 7 , 19 ] , assuming that users with the same ratings share the same tastes . However , two users who have assigned the same 5 stars to a restaurant might have significantly different reasoning ; one might like its food while the other likes its service . Text reviews provide rich information to make it possible to understand preferences of users at a finer granularity . Some recent work has shown the benefits of utilizing text reviews within the collaborative filtering methods [ 12 , 24 ] . Unlike these work , we aim at collectively exploring users’ preferences on different aspects of the items . A challenge here is that aspect based sentiment scores are not explicitly specified by users , but implicitly expressed in the reviews . We propose a new model combining aspect based opinion mining and collaborative filtering to collectively learn users’ preferences on different aspects .
In this work , we introduce the problem of Personalized Latent Aspect Rating Analysis . Given a collection of reviews of a set of items by a set of users , the goal is to solve the following two tasks : a ) learn the latent aspects and their word distribution over a pre defined vocabulary , and the latent aspect ratings for each review ; b ) for any user u in the data set , predict the latent aspect ratings on the items that he has not yet reviewed . Existing aspect based opinion mining methods such as [ 22 , 23 , 14 ] are able to solve task a , but are unsuitable for solving task b since they require the text of user u ’s review for item i as input . Task b is also different from the well studied rating prediction problem in recommender systems , the goal of which is to predict the overall rating while we want to predict the aspect ratings .
To address the problem of Personalized Latent Aspect Rating Analysis , we propose a unified probabilistic model called Factorized Latent Aspect ModEl ( FLAME ) , which combines the advantages of both collaborative filtering and aspect based opinion mining so that the two methods can mutually enhance each other . The general idea of FLAME is that we can learn users’ preferences based on their past reviews , so that we can collaboratively predict a user ’s preference of an aspect of an item from the opinions of other users with similar tastes . FLAME improves existing aspect based opinion mining methods by being able to infer aspect ratings of users on new items2 , and enhances collaborative filtering methods by leveraging reviews to analyze users’ preferences on different aspects of items .
We empirically evaluate the proposed FLAME on a hotel review data set from TripAdvisor3 and a restaurant review data set from Yelp4 . Experimental results show that FLAME can effectively extract meaningful aspects and predict aspect ratings of a user on new items to him .
The remainder of the paper is organized as follows . Section 2 is devoted to related work . Section 3 introduces the problem definition and useful notations . Section 4 presents the proposed model and describes the inference and parameters estimation techniques . In Section 5 & 6 , we report the experimental results on two review data sets and discuss some other applications of the proposed model . Finally , Section 7 concludes the paper with a summary and discusses potential future work .
2 . RELATED WORK
Our work is related to two research topics : Collaborative
Filtering and Aspect based Opinion Mining .
2.1 Collaborative Filtering
Collaborative filtering ( CF ) is a popular method widely used in recommender systems . The assumption behind collaborative filtering is that a given user is more likely to like items that are liked by other users with similar tastes . Various state of the art CF methods are based on latent factor models [ 7 ] . Latent factor models assume that a user ’s rating on a particular item depends on the inner dot product of the latent user factors and the latent item factors .
Some work combining collaborative filtering with Topic Models has been proposed to leverage text information in recommender systems . Topic models are introduced by [ 1 ] for learning the hidden dimensions of text . The basic assumption of topic models is that documents are represented by mixtures of some latent topics where topics are associated with a multinomial distribution over words of a vocabulary . The earliest work integrating collaborative filtering with topic model is CTM [ 21 ] , which is proposed for article recommendation . CTM simultaneously trains a topic model on the collection of articles and a latent rating factor model on the ratings of users on articles , while assuming that the latent factors of items depend on the latent topic distributions of their text . A recent work [ 12 ] proposes a model called HFT , which aims at improving collaborative filtering using reviews . HFT considers latent rating factors of an item as the properties that the item possesses , and assumes that if a product exhibits a certain property ( higher latent rating factor value ) , this will correspond to a particular topic being discussed frequently ( higher probability in topic distribution ) [ 12 ] . HTF first aggregates all the reviews of an item into a single document , and uses a similar method as CTM to train a topic model and a latent factor model together .
Different from CTM and HTF which learn topic distributions for each item , our approach learns for each review its aspect distribution as well as its rating distribution on each aspect .
2Note that new items for a user are the items that he has not rated yet . 3http://wwwtripadviosrcom 4http://wwwyelpcom
2.2 Aspect based Opinion Mining
The main task of aspect based opinion mining is extracting the aspects and learning the aspect ratings from a collection of reviews of a given item . Most of the early works of opinion mining are frequency based approaches [ 5 , 11 ] . These approaches usually mine the aspects and sentiments by counting the frequencies of words and their co occurrences with some pre defined seed words . Recently , several methods based on the variants of topic models [ 1 ] have been proposed [ 20 , 25 , 6 , 14 , 15 ] to learn the aspects and sentiments automatically from the data . These work extends topic models by adding another kind of latent variables to model the latent sentiments of words , ie , words in reviews are not only dependent on the topics they belong to , but are also related to the sentiments of the reviewers . The most related work is the Latent Aspect Rating Analysis Model ( LARAM ) [ 22 , 23 ] , which aims at inferring the latent aspect ratings of given reviews . LARAM assumes the overall rating of a review is generated by a weighted sum of the latent aspect ratings , and are generated from the words and the latent topic allocations of the words by a linear regression function . LARAM learns the latent aspect ratings for each review and aspect weights for each reviewer . It should be noted that the aspect weights in LARAM are different from the personalized aspect ratings in our problem . The weights in LARAM represent the importance of the aspects for a reviewer , but personalized tastes represent the ratings/sentiments of users on different aspects . Two reviewers may share similar aspect weights but have totally different ratings on a given aspect .
The main limitation of above aspect based opinion mining methods is that they do not consider user preferences ( across multiple reviews and items ) in the learning procedures so that they are unable to predict users’ opinions on other items which they have not written reviews on .
The very recently published ETF [ 24 ] also considers aspect based opinion mining and collaborative filtering simultaneously . However , ETF employs the aspect based opinion mining as a preprocessing step , while ours is a unified model with opinion mining as a part of the model . This enables our approach to be used to analyze the aspect distributions of the reviews and latent aspect ratings expressed in the reviews as in [ 22 , 23 ] . Besides , ETF can not predict users’ preferences on the aspects of items .
3 . PROBLEM DEFINITION
We assume as input a collection of reviews of some products from a specific category ( eg restaurant ) by a group of reviewers , and each review comes with an overall rating ( eg 1 5 stars ) to express the overall satisfaction of the reviewer . Review : A review is a piece of text describing opinions of a reviewer towards a specific item . Formally , we use D = {d1 , d2 , , dD} to denote a set of review text documents . For each d ∈ D , ud ∈ U denotes the user who writes review d and id ∈ I denotes the reviewed item . We use Du to denote the set of reviews that user u writes and use Di to denote the set of reviews for item i .
Overall Rating : The overall rating rd of a review document d is a numerical rating indicating the overall opinion of d , ie , rd ∈ R , where R = {1 , 2 , , R} .
Aspect : An aspect is an attribute of the item that has been commented on in a review , eg , “ food ” , “ location ” and
Table 1 : Mathematical Notations
Symbol
U I D A R
φu φi φi,a
η ηu ηi βa γa,r
θd ϕd,a at st
Size Description U I D A R
Users U = {u|u = 1 , , U } Items I = {i|i = 1 , , I} Documents D = {d|d = 1 , , D} Aspects A = {a|a = 1 , , A} Numerical ratings R = {r|r = 1 , , R} latent vector of user u latent vector of item i latent vector of aspect a of i background aspect distribution aspect distribution of user u aspect distribution of item i word distribution of aspect a word distribution of aspect a and rating r aspect distribution of document d rating distribution of aspect a of document d aspect of sentence t aspect rating of sentence t
RK RK RK RA RA RA RV RV
RA RR
R1 R1
“ service ” for a restaurant . In this paper , we only consider the case that all the items are from a same category , ie , they share the same set of aspects . We use a to denote an aspect , where a ∈ A and A = {1 , 2 , , A} .
Aspect Rating : The aspect rating rd,a of a review document d is the reviewer ud ’s rating towards to the aspect a of the item id.i It indicates the opinion of the reviewer regarding to the properties of the corresponding aspect of the item . Note that our method does not need aspect ratings as input , but instead it infers them from the data .
Personalized Latent Aspect Rating Analysis : Given a collection of reviews of a set of items by a set of users , the goal is to solve two tasks : a ) learn the latent aspects , which represents each aspect as a distribution on a pre defined vocabulary , and the latent aspect ratings for each review , which indicate the opinions of the reviewer towards the aspects of the item ; b ) predict the latent aspect ratings for user u on new item i that he has not reviewed .
Some important notations used in this paper are listed in Table 1 . We use bold math symbols xi to denote vectors , where the subscript i is used for indexing different vectors . The j th element of the vector xi is denoted by xi[j ] .
4 . PROPOSED MODEL
In this section , we propose the unified probabilistic model Factorized Latent Aspect ModEl ( FLAME ) to address the problem of Personalized Latent Aspect Rating Analysis .
When writing the review , the reviewer first selects a subset of aspects he wants to comment on . We assume that each review document d is associated with an aspect distribution θd ∈ RA , which represents the importances of the aspects in the review . The aspect distribution θd depends on three factors : the global aspect distribution η0 , the aspect distribution of the reviewer ηu and the aspect distribution of the item ηi . η0 represents how much each aspect is likely to be mentioned among all the reviews . ηu represents reviewer u ’s preferences on the aspects to comment , eg , if a user cares more on the value of a hotel , he prefers to mention this aspect in his reviews . ηi indicates which aspects of item i are more likely to be mentioned . Some aspects are more likely to be mentioned in the reviews of an item . For example , if the food of a restaurant is great , it will receive a lot of praises of the food in the reviews . On the other hand , if some aspects of an item are terrible , reviewers would like to criticize on these aspects in their reviews .
Based on this assumption , we define θd using a additive generative methods as follows :
θd[a ] = exp ( η0[a ] + ηu[a ] + ηi[a ] ) a′=1 exp ( η0[a′ ] + ηu[a′ ] + ηi[a′ ] )
( 1 ) where {η} = {η0 , ηu , ηi|u ∈ U , i ∈ I} are A dimensional vectors generated from zero mean Gaussian distributions .
PA
φi,a
A
I
φu
U rd
ϕd,a
A
θd st at
βa
γa,r
R
A wn
W
T
D
η0 ∼ N ( 0 , σηI ) ηu ∼ N ( 0 , σηI ) ηi ∼ N ( 0 , σηI )
η0
ηu
ηi
( 2 )
U
I
For each aspect , the reviewer has a latent sentiment polarity expressing his opinion on that aspect of the item . We extend Probabilistic Matrix Factorization ( PMF ) [ 19 ] to model the user specific aspect ratings . PMF assumes that the user u has a vector of latent factors φu ∈ RK , which represents his personalized preferences that influence his opinions . Analogously , each item has a latent vector φi ∈ RK . The overall rating of u for i is generated by the dot product of the user latent factor and the item latent factor . In our model , to predict user u ’s opinion on a specific aspect a of item i , we assume there is a latent factor φi,a ∈ RK for each aspect a of an item i , and the aspect rating rd,a of review document d is generated from the dot product of the user la5 . The tent vector φu and the item aspect latent vector φi,a item aspect latent vector φi,a describes the latent properties of the corresponding aspect of the item . rd,a ∼ N ( φ⊤ u φi,a , σ2 a )
( 3 )
To control the model complexity , zero mean Gaussian pri ors are placed on the latent factors :
φu ∼ N ( 0 , σ2 φi,a ∼ N ( 0 , σ2 uI ) i,aI )
( 4 )
We can not directly use the continuous value rd,a to model the word generative process since we need discrete ratings to define the aspect sentiment vocabulary ( see Equation 11 ) . We introduce another latent variable ϕd,a ∈ RR to represent document d ’s rating distribution on aspect a , where ϕd,a[r ] r=1 ϕd,a[r ] = 1 . We is the probability of p(rd,a = r ) and PR define ϕd,a as follows :
( 5 )
ϕd,a[r ] =
= u φi,a , σ2 r,a )
N ( r|φ⊤ r′=1 N ( r′|φ⊤ ( r−φ
PR exp− r′=1 exp− PR r,a ) u φi,a , σ2 u φi,a)2 2σ2
⊤ r,a u φi,a)2
( r′−φ⊤ 2σ2 r,a
5Note that for simplicity we always assume that there is an extra constant column in user/item latent factors to model the bias effect .
Figure 2 : FLAME in graphical model notation .
We assume the overall rating of document d is generated from the weighted sum of the aspect ratings , where the aspect weights consist to the aspect distribution of the document . rd ∼ N ( Xa
θd[a]E[rd,a ] , σ2 r )
( 6 ) where E[rd,a ] = φ⊤ u φi,a .
For the process of generating words , we follow the assumption in [ 20 , 13 , 25 ] that the words in one sentence of a review refer to the same aspect . Topics learned under this assumption are local topics that preserve sentence level word concurrences [ 20 ] , while models like LDA [ 1 ] produce global topics that preserve document level word concurrences . Global topic models are not suitable for aspect identification . For example , because the words room and location appear together in most reviews , global topic models are mostly likely to cluster them in the same topic , but local topic models assume they refer to different topics .
For each sentence t in the review d , we draw an aspect at from the aspect distribution of the review : at ∼ M ulti(θd )
( 7 ) and a sentiment rating st ∈ {1 , 2 , , R} on the aspect at from the aspect rating distribution : st ∼ M ulti(ϕd,at )
( 8 )
Then , in each sentence t , the reviewer selects a set of words wn ∈ t to express his opinions on the aspect at . We define an aspect sentiment multinomial word distribution αa,s on the vocabulary , where αa,s[j ] represents the probability of generating the j th word from the vocabulary for aspect a and aspect rating s . wn can be an aspect word , eg , battery , or a sentiment word , eg , good . So we assume that αa,s depends on two factors : βa and γa,s , where βa represents the correlation between the words and the aspect a , and γa,s represents the correlation between the words and the pair of
Algorithm 1 Generative process of FLAME .
The variational distributions of the latent variables in ∆
Draw η ∼ N ( 0 , σ2 for all u ∈ U do
ηI )
Draw φu ∼ N ( 0 , σ2 Draw ηu ∼ N ( 0 , σ2 uI ) ηI ) end for for all i ∈ I do
Draw ηi ∼ N ( 0 , σ2 for all a ∈ A do
ηI )
Draw φi,a ∼ N ( 0 , σ2 i,aI ) end for end for for all a ∈ A do
Draw βa ∼ N ( 0 , σ2 for all r ∈ R do
βI )
Draw γa,r ∼ N ( 0 , σ2 Set αa,r using Equation ( 9 )
γ I ) end for end for for all d ∈ D do
Set θd using Equation ( 1 ) Set ϕd using Equation ( 5 ) Draw rd using Equation ( 6 ) // Generate each sentence t in document d for all t ∈ d do
Draw at ∼ Multi(θd ) Draw st ∼ Multi(ϕd , at ) // Generate each word n in sentence t for all n ∈ t do
Draw wn ∼ Multi(αat,st ) end for end for end for aspect a and aspect rating s .
αa,s[j ] = exp(βa[j ] + γa,s[j ] ) l=1 exp(βa[l ] + γa,s[l ] )
PV where βa and γa,r are V dimensional vectors generated from zero mean Gaussian distributions . βa ∼ N ( 0 , σβI ) γa,r ∼ N ( 0 , σγ I )
The word wn is generated as follows : p(wn|at , st , α ) ∼ M ulti(αat,st )
( 11 )
Figure 2 shows the graphical representation of FLAME , omitting the priors {σ} . We summarize the generative process in Algorithm 1 .
4.1 Variational Inference
In general , we use an EM style method to learn the parameters in our model . We adopt a mixture of maximum a posteriori ( MAP ) point estimates and Bayesian inference as in [ 3 ] . To be specific , we use a combination of MAP estimation over Ξ = {{η} , {φ} , β , γ} and Bayesian variational inference over the other latent variables ∆ = {a , s} to derive a lower bound of the log likelihood of the data , and maximize the bound with respect to Ξ and variational parameters . It should be noted that θ and ϕ are not latent variables in our model . They are fixed given η and φ , as shown in Equation ( 1 ) and ( 5 ) . are defined as follows : q(a , s|π , λ ) =Yd Yt∈d q(at|πt)q(st|λt )
( 12 ) where πt ∈ RA and λt ∈ RR are free multinomial parameters .
We get the lower bound of the log likelihood of the data as follows :
L =Xd hlog p(rd|φu , φi,a , θd)i +Xt∈dhlog p(at|θd)i hlog p(wn|at , st , β , γ)i
+ hlog p(st|ϕd , at)i +Xn∈t +Xu hlog p(φu|σu)i + hlog p(ηu|ση)i +Xi hlog p(φi|σi)i +Xa + hlog p(ηi|ση)i + hlog p(η|ση)i hlog p(βa|σβ)i +Xa Xr +Xa −Xd Xt∈dhlog q(at|πt)i + hlog q(st|λt)i hlog p(φi,a|σi,a)i hlog p(γa,r|σγ)i
( 13 ) where hp(Ω)i denotes the expectation of the probability of p given the distribution q(Ω ) .
4.2 Learning the Parameters
In general , the learning procedure can be viewed as coordinate ascent in L , ie , alternatively optimizing one set of parameters while fixing the others .
Updating π : We get the solution of πt by setting
0 with the constraint Pa πt[a ] = 1 . πt[a ] ∝ θd[a]Yr ϕd,a[r]λt[r]Yj
αa,r[j]ct,j λt[r]!
∂L[πt ]
∂πt
=
( 14 ) where ct,j is the frequency of the j th word in sentence t . Since ct,j is sparse , the complexity of updating πt is O(ct ·R· A ) , where ct is the number of words in sentence t . The total complexity for updating π in one EM iteration is O(c·R·A ) , where c is the number of words of all the documents .
Updating λ : The update procedure of λ is similar to that for π .
λt[r ] ∝Ya
ϕd,a[r]πt[a]Yj
αa,r[j]ct,j πt[a ]
( 15 )
The complexity of updating λ in one EM iteration is also
O(c · A · R ) .
Updating φu : We can get L[φu ] by only retaining those terms in L that are a function of φu :
L[φu ] = Xd∈Du − +Xt Xa Xr
2σ2 r u φi,a)2
( rd −Pa θd[a]φ⊤ πt[a]λt[r ] log ϕd,a[r]! −
φ⊤ u φu 2σ2 u
( 16 )
( 9 )
( 10 )
The derivative of L[φu ] with respect to φu depends on φu , so we have to use a gradient ascent based method to update φu . is :
Updating φi,a :
L[φi,a ] = Xd∈Di −
+Xt∈dXa Xr
−
φ⊤ i,aφi,a 2σ2 i,a
( rd −Pa θd[a]φ⊤
2σ2 r u φi,a)2
πt[a]λt[r ] log ϕd,a[r]!
( 17 )
We also use a gradient ascent based method to update
φi,a .
Updating η :
L[η0 ] =Xd∈D , − +Xt∈dXa
2σ2 r
( rd −Pa θd[a]E[rd,a])2 πt[a ] log θd[a] −
η⊤ 0 η0 2σ2 η
2σ2 r
=π⊤
Dη0 −
η⊤ 0 η0 2σ2 η
( rd −Pa θd[a]E[rd,a])2 − Xd∈D Nd log Xa′ exp,η0[a′ ] + ηu[a′ ] + ηi[a′] ! where πD = Pd∈DPt∈d πt and Nd = Pt∈dPa πt[a ] = Pt∈d 1 is the number of sentences in d .
We apply gradient ascent method to optimize η0 . The
− Xd∈D derivative with respect to η0[a ] is :
( 18 ) g(η0[a ] ) =πD[a ] − Xd∈D
Ndθd[a ] −
η0[a ]
σ2 η
( rd −Pa θd[a]E[rd,a])(θd[a])(1 − θd[a ] )
σ2 r
+ Xd∈D
( 19 ) The update formula of ηu and ηi is similar . The only difference is to replace D in Equation ( 19 ) with Du and Di respectively , where Du is the set of reviews of user u and Di is the set of reviews of item i .
Updating β and γ :
L[βa ] = c⊤ a βa −
β⊤ a βa 2σ2 β
−Xd Xt∈d
πt[a]ctXr exp ( βa[l ] + γa,r[l])! where ca[j ] = PdPt∈d πt[a]ct,j , and ct = Pj ct,j denotes
λt[r ] log Xl
We use Newton ’s method to optimize βa . The derivative the number of words in sentence t .
( 20 ) with respect to βa is : g(βa ) =ca −Xr
Ca,rαa,r −
βa σ2 β
( 21 ) where Ca,r =PdPt∈d πt[a]ctλt[r ] represents the expected word counts for each ( a , r ) combination . The Hessian matrix
H(βa ) =Xr
Ca,rαa,rα⊤ a,r − diag(Xr
The update formula for βa is :
Ca,rαa,r +
1 σβ
1 )
( 22 )
( 23 )
β(t+1 ) a
= β(t ) a − H −1(β(t ) a )g(β(t ) a )
We use a linear algorithm for the Hessian matrices with special structure [ 18 , 1 , 3 ] , which lets the complexity of computing H −1(βa)g(βa ) be O(V ) instead of O(V 3 ) .
We can also get the derivative and Hessian of γa,r as fol lows : g(γa,r ) =ca,r − Ca,rαa,r −
γa,r σ2 γ
( 24 ) where ca,r[j ] =PdPt∈d πt[a]λt[r]ct,j .
H(γa,r ) = Ca,rαa,rα⊤ a,r − diag(Ca,rαa,r +
1 σγ
1 )
( 25 )
The complexity of updating γa,r is also linear in the size of the vocabulary .
Computational Complexity : To conclude , the complexity of one update iteration is O(c · A · R + T · A · K + D · K + ( I + U ) · A + A · R · V ) , where c is the total number of words in the corpus , T is the number of sentences in the corpus , and D is the number of documents in the corpus . Usually K , A and R are small constants , so the complexity is linear to the size of the review dataset .
Implementation Notes : An important issue is how to initialize the model . We use the following initialization steps . Taking the TripAdvisor data set as an example , we initialize βa using the names of the aspect , ie , we set βroom,room = 1 for the aspect room , and then learn the aspect distribution of each sentence only based on the initialized β . Similar techniques are also used in [ 13 ] . The aspect ratings of each sentence are initialized using the overall rating of the review . The parameters {σ} can also be learned using the coordinate ascent like procedure . We set them manually in our implementation , eg , we set σ2 r,a = 0.5 , ση = 10 , etc . Some optimization techniques , eg , L BFGS [ 17 ] and backtracking line search [ 2 ] , are applied to accelerate the gradient ascent updates . r = 1 , σ2
5 . EXPERIMENTAL EVALUATION
In this section , we first describe the data sets we used in our experiments and then discuss the experimental results on different tasks .
5.1 Data Sets and Preprocessing
We use two review data sets for our experimental evaluation : the TripAdvisor hotel review data6 and Yelp review data7 . In the TripAdvisor data , besides the overall rating , users are also asked to provide the aspect ratings on 6 pre defined aspects : Location , Sleep Quality , Room , Service , Value and Cleanliness , on a scale from 1 star to 5 stars . We use these ground truth aspect ratings to evaluate our model on the task of aspect rating prediction . For Yelp data set , we
6http://wwwcscmuedu/~jiweil/html/hotel reviewhtml 7http://wwwyelpcom/dataset_challenge
Table 2 : Dataset Statistics
Table 3 : Perplexity on the held out data sets
TripAdvisor
# Users # Items # Reviews Density
9,419 1,904 66,637 0.37 %
Yelp 6,944 3,315
115,290 0.50 %
# Sentences Per Review 12.60 ± 8.64 7.50 ± 3.76
# Words Per Sentence
11.67 ± 7.80 6.47 ± 4.64 extract a subset which only contains the reviews on restaurants .
We use the following preprocessing procedure on both of the data sets . We first remove non English reviews and reviews with less than 3 sentences or 20 words , and then iteratively remove users with less than 5 reviews and items with less than 5 reviews . For the text in reviews , we remove stop words and words that occur in less than 5 reviews , and stem the remaining words using the PorterStemmer8 . After the preprocessing , we have a hotel review data set including 66,637 hotel reviews of 1,904 hotels and a restaurant review data set including 115,290 reviews of 3,315 restaurants . The detailed statistics are listed in Table 2 .
We randomly split both of the data sets into training and test sets . Specifically , for each user , we randomly select 20 % of his reviews as test examples ( For users with less than 10 reviews , we randomly select 2 reviews as test examples ) and put the rest reviews into the training sets . We train the models on the training data sets and test their performance on the test data sets . We use the model initialization method and parameters selection strategies as discussed in Section 4 .
5.2 Quantitative Evaluation
521 Perplexity on Held out Reviews
As in standard topic models , we use perplexity of the heldout test data sets to compare the generalization performance of FLAME with some other state of the art models .
Evaluation Measure . Perplexity is a standard measure for topic models to measure how the model can generate future documents [ 1 ] . For review mining , a good aspect based topic model should be able to predict what the reviewer will write in a new review , which leads to a lower perplexity . A strong correlation of the perplexity and accuracy of aspectbased topic models is shown in [ 15 ] . We use a lower bound on perplexity as in [ 4 ] .
Perplexity(Dtest ) = exp−Pdhlog p(wd|Ξ)i − hp(∆d)i
Pd Nd
We compare FLAME with the basic LDA model [ 1 ] and the D LDA model presented in [ 15 ] . D LDA is a state of theart aspect based opinion mining model which can be seen as a generalization of several other models [ 20 , 6 ] . For D LDA , we also use the assumption that the words in one sentence refer to the same aspect as in FLAME and other models [ 15 , 20 , 6 ] . In the aspect based topic models , we actually use A × R latent topics , so we compare with LDA using both A topics ( LDA A ) and A × R topics ( LDA AR ) .
8http://tartarus.org/martin/PorterStemmer/
TripAdvisor
LDA A LDA AR D LDA FLAME
1012.80 918.07 771.05 733.12
Yelp 767.24 728.00 621.24 590.46
For all the models , we use the same parameter settings and stopping criteria . We set R = 5 for all the aspect based topic models . We train the models using the reviews in the training sets and evaluate the perplexity on the test sets . We test various numbers of latent aspects A = {6 , 12 , 24} . Since the relative results are similar , we choose A = 6 for discussion . Table 3 shows the perplexity on test data sets of FLAME and the comparison partners . We can see that D LDA and FLAME , which are specifically designed for aspect based opinion mining , significantly outperform basic LDA methods . FLAME achieves the best results among all the models on both of the data sets . We believe this is because FLAME can predict personalized aspect distribution as well as aspect rating distribution , which other models do not consider .
522 Aspect Rating Prediction on Held out Reviews Since we need the ground truth aspect ratings to quantitatively compare FLAME with other methods , we evaluate the aspect rating prediction only on the TripAdvisor data set . In order to align the latent aspects to the pre defined aspects in the TripAdvisor data set , we set A to be 6 and use the initialization techniques discussed in Section 4 .
We use the evaluation measures in [ 22 , 23 ] to evaluate different methods :
• Root Mean Square Error ( RMSE ) of the predicted aspect ratings compared with the ground truth aspect ratings .
• Pearson Correlation inside reviews ( ρA ) to measure how well the predicted aspect ratings preserve the relative order of aspects within a review .
ρA =
1 D
D
Xd=1
ρ(sd , s∗ d ) where s∗ ment d , and sd is predicted aspect ratings . d is the ground truth aspect ratings for docu
• Pearson Correlation between personalized ranking of items ρI . For each user and each aspect , we rank the items by their predicted aspect ratings , and measure how the ranked lists preserve the ground truth .
ρI =
1
U · A
U
A
Xu=1
Xa=1
ρ(sIu,a , s∗
Iu,a ) where Iu is the set of items in user u ’s test data , sIu,a is the predicted aspect ratings on the set of items and sIu,a is the ground truth ratings .
• Zero One Ranking loss ( L0/1 ) [ 8 ] , which measures the percentage of mis ordered pairs of items for each user .
Table 4 : Aspect rating prediction on test set of TripAdvisor data
PMF 0.970 N/A 0.304 0.210
RMSE ρA ρI L0/1
LRR+PMF FLAME
1.000 0.110 0.177 0.238
0.980 0.195 0.333 0.196
It is computed as follows :
Xu Xi,j∈Iu
1 Zu
A
Xa=1
1[(su,i,a −su,j,a)·(s∗ u,i,a −s∗ u,j,a ) < 0 ] where Zu is the number of pairs in user u ’s test set , su,i,a is the predicted rating of user u of item i on aspect a , and s∗ u,i,a is the ground truth aspect rating . We do not choose nDCG since each user has few samples in the test data ( 2.2 test samples per user ) , the values of nDCG tend to be very close to 1 for all comparison partners .
An intuitive solution of aspect rating prediction is just using the overall rating of the review as prediction . We use PMF [ 19 ] to predict the overall ratings of the reviews in the test set and use the predicted overall ratings as predictions for aspect ratings . To our best knowledge , [ 22 , 23 ] are the only work that predict aspect ratings at review level . However , they can only predict aspect ratings based on users’ reviews . In order to predict the aspect ratings in test set , we first apply the LRR model [ 22 ] to extract aspect ratings for each review in the training set , and then use PMF [ 19 ] to train and to predict the aspect ratings in test set ( we call it LRR+PMF ) . We use the code of LRR provided by the authors . Same training and testing strategies are applied to all the models for fair comparison . We also test the performance of with different values of the dimensions of latent factors . The relative results are similar , so we only choose K = 10 for discussion . Table 4 presents the results for aspect rating prediction on the test set . We also highlight the best performance in each measure in bold .
A general observation is that FLAME outperforms other baseline models on all the measures except RMSE . It has been discussed in [ 22 ] that RMSE is less important than other measures since it does not reflect how the relative order of the aspect ratings is preserved . ρA measures how a method preserves the relative order of aspect ratings within a review . PMF uses the same predicted ratings for all aspects , so it is not applicable for ρA . ρI and L0/1 are the most important measures for our task where we want to rank items based on the predicted aspect ratings . PMF outputs exactly the same item ranking lists for all aspects , thus it is not suitable for real world applications . We can see that FLAME gets the best results on the two measures . The gain is especially significant compared to LRR+PMF , where there are about 90 % improvement on ρI and 40 % improvement on L0/1 .
Note that LRR+PMF does not achieve desirable performance . The reason is that it is a two step approach that the errors induced in the first step have significant influence on the performance of the second step .
5.3 Qualitative Evaluation
In this subsection , we evaluate FLAME on the task of aspect identification . We perform qualitative analysis of the top words obtained by FLAME to see whether FLAME can produce meaningful aspects .
Figure 3 shows the word cloud visualization of top words ( after stemming ) with the highest generating probability in the aspect rating specific word distributions . We only show 3 aspects due to space limits . The three word cloud figures in the left column present the topic distribution β for the aspects location , service and room , respectively . In general , the top words generated by FLAME represent meaningful and interpretable topics . We observe that the top words match our intuition , eg , words like “ location ” , “ walk ” , “ street ” have higher weights in the word distribution of aspect location . The middle and right columns show the top words of the 2 star ( γa,2 ) and 5 star ( γa,5 ) word distributions of for the three aspects , . The aspect rating specific word distribution can automatically learn the sentiment oriented words , eg , words like “ bad ” , “ old ” , “ creepy ” and “ homeless ” have high weights in the 2 star word distribution of the aspect location , while the words like “ view ” , “ great ” , “ perfect ” , “ best ” have high weights in the 5 star word distribution of location . One contribution of FLAME is that the aspect rating topics have sentiment polarities , ie , 5 star topics are more positive than 4 star , and so on . This is different from previous work [ 20 , 14 , 16 ] where the latent ratings in these models are rating labels which do not correspond to sentiment polarities .
6 . FURTHER APPLICATIONS
The detailed analysis on personalized latent aspect ratings enables a wide range of applications . Here we discuss three sample applications .
Figure 4 : Aspect Weights . Global represents the values of η0 . user 1 and user 2 are the aspect weights ηu of two randomly sampled users , and item 1 and item 2 are the values of ηi for two randomly sampled items .
Aspect Distribution : Since FLAME can infer the aspect weights for users and item , we can easily use the values of η0 , ηu and ηi for the rating behavior analysis . Figure 4 shows some sample results on TripAdviosr data . From the histogram Global in the figure , we can see that Value and Room are the most discussed aspects , and most people rarely mention the aspect Sleep . Note that the values of ηu
( a ) Location
( b ) Location 2 star
( c ) Location 5 star
( d ) Service
( e ) Service 2 star
( f ) Service 5 star
( g ) Room
( h ) Room 2 star
( i ) Room 5 star
Figure 3 : Word cloud visualization of top words with highest generating probability in β and γ . The left Word size reflects the weight of each word . The three rows are the top words in the topic distributions for the aspects location , service and room , respectively . The left column shows the top words in the aspect word distributions β of the three aspects . The middle and right columns show the top words in the aspect ratingword distributions γ . The middle column shows negative ones ( 2 star ) and the right column shows positive ones ( 5 star ) . indicates the biases of users deviating from the global aspect weights . We can see that user 1 likes to comment on the Location and Sleep , while user 2 cares more about the Service , Clean and Location . The two users have opposite weights for the aspects Service and Sleep . Thus , when they are searching for hotels , the aspects they care about are different . It indicates that letting users choose to rank items based on aspects which they cares about is very useful . The aspect weights of items can be used to help merchants to improve their services . If a specific aspect is discussed a lot and most of the reviews are negative , the merchant should think about how to improve this aspect .
Personalized Review Recommendation : As discussed in Section 1 , facing a large number of reviews expressing different opinions , a user might have no idea of which reviews are reliable . FLAME can alleviate this problem by sorting the reviews by the similarities between reviewers with current user . A simple way of computing the similarities between users is to compute the distance between their latent factors . Since personalized review recommendation is hard to evaluate , we would like to leave it as a future work on some data sets with ground truth of user feedback on reviews .
Recommendation Explanation : Traditional collaborative filtering methods only provide predicted scores for then items , but can not produce reasonable explanations with the recommendations . A recent work [ 24 ] has shown the possibility of using the aspect weights to generate some explanations . FLAME can produce more persuasive recommendation explanations by the predicted aspect ratings and some selected reviews written by similar users .
7 . CONCLUSION
In this paper , we introduce the problem of Personalized Latent Aspect Rating Analysis to model users’ preferences on different aspects . We propose a unified probabilistic model FLAME which combines aspect based opinion mining and collaborative filtering . FLAME extracts aspect ratings from the review text , and predicts aspect ratings of an item that a user has not yet reviewed based on aspect ratings within other reviews of the item by other users with similar preferences . Our experimental evaluation on a hotel review data set and a restaurant review data set shows that FLAME can effectively solve the research problem . The qualitative evaluation shows that FLAME can automatically extract meaningful aspects and sentiment oriented aspects . We also investigate the ability of FLAME on the task of generating future review text . Most importantly , our experiments on TripAdvisor data sets show that FLAME significantly outperforms state of the art methods in terms of accuracy of aspect rating prediction .
Some websites like TripAdvisor provide the option of rating some pre defined aspects . Although these aspect ratings are typically incomplete , they may be helpful to partially guide the learning of latent aspect ratings . It is worth to explore a semi supervised extension of FLAME . In this paper , we only consider one same type of items , eg , hotels or restaurants . We plan to consider datasets with multiple types of items which have different aspects , where users may also have different preferences on different types of items .
8 . REFERENCES [ 1 ] D . M . Blei , A . Y . Ng , and M . I . Jordan . Latent dirichlet allocation . J . Mach . Learn . Res . , 3:993–1022 , Mar . 2003 .
[ 2 ] S . P . Boyd and L . Vandenberghe . Convex optimization . Cambridge university press , 2004 . [ 3 ] J . Eisenstein , A . Ahmed , and E . P . Xing . Sparse additive generative models of text . In Proceedings of the 28th International Conference on Machine Learning ( ICML 11 ) , pages 1041–1048 , 2011 .
[ 4 ] M . Hoffman , F . R . Bach , and D . M . Blei . Online learning for latent dirichlet allocation . In advances in neural information processing systems , pages 856–864 , 2010 .
[ 5 ] M . Hu and B . Liu . Mining and summarizing customer reviews . In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining , KDD ’04 , pages 168–177 , New York , NY , USA , 2004 . ACM .
[ 6 ] Y . Jo and A . H . Oh . Aspect and sentiment unification model for online review analysis . In Proceedings of the fourth ACM international conference on Web search and data mining , pages 815–824 . ACM , 2011 .
[ 7 ] Y . Koren , R . Bell , and C . Volinsky . Matrix factorization techniques for recommender systems . Computer , 42(8):30–37 , 2009 .
[ 8 ] J . Lee , S . Bengio , S . Kim , G . Lebanon , and Y . Singer . Local collaborative ranking . In Proceedings of the 18th international conference on World wide web , 2014 .
[ 9 ] F . Li , C . Han , M . Huang , X . Zhu , Y J Xia , S . Zhang , and H . Yu . Structure aware review mining and summarization . In Proceedings of the 23rd International Conference on Computational Linguistics , pages 653–661 . Association for Computational Linguistics , 2010 .
[ 10 ] B . Liu . Opinion mining and sentiment analysis . In Web Data Mining , pages 459–526 . Springer , 2011 .
[ 11 ] B . Liu , M . Hu , and J . Cheng . Opinion observer : analyzing and comparing opinions on the web . In Proceedings of the 14th international conference on World Wide Web , WWW ’05 , pages 342–351 , New York , NY , USA , 2005 . ACM .
[ 12 ] J . McAuley and J . Leskovec . Hidden factors and hidden topics : understanding rating dimensions with review text . In Recsys , 2013 .
[ 13 ] J . McAuley , J . Leskovec , and D . Jurafsky . Learning attitudes and attributes from multi aspect reviews . In
Data Mining ( ICDM ) , 2012 IEEE 12th International Conference on , pages 1020–1025 . IEEE , 2012 .
[ 14 ] S . Moghaddam and M . Ester . Ilda : interdependent lda model for learning latent aspects and their ratings from online product reviews . In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval , SIGIR ’11 , pages 665–674 , New York , NY , USA , 2011 . ACM . [ 15 ] S . Moghaddam and M . Ester . On the design of lda models for aspect based opinion mining . In Proceedings of the 21st ACM international conference on Information and knowledge management , CIKM ’12 , pages 803–812 , New York , NY , USA , 2012 . ACM .
[ 16 ] S . Moghaddam and M . Ester . The flda model for aspect based opinion mining : addressing the cold start problem . In Proceedings of the 22nd international conference on World Wide Web , WWW ’13 , pages 909–918 , 2013 .
[ 17 ] J . Nocedal . Updating quasi newton matrices with limited storage . Mathematics of computation , 35(151):773–782 , 1980 .
[ 18 ] G . Ronning . Maximum likelihood estimation of dirichlet distributions . Journal of statistical computation and simulation , 32(4):215–221 , 1989 .
[ 19 ] R . Salakhutdinov and A . Mnih . Probabilistic matrix factorization . In Advances in neural information processing systems , pages 1257–1264 , 2007 .
[ 20 ] I . Titov and R . McDonald . Modeling online reviews with multi grain topic models . In Proceedings of the 17th international conference on World Wide Web , pages 111–120 . ACM , 2008 .
[ 21 ] C . Wang and D . M . Blei . Collaborative topic modeling for recommending scientific articles . In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining , KDD ’11 , pages 448–456 , New York , NY , USA , 2011 . ACM .
[ 22 ] H . Wang , Y . Lu , and C . Zhai . Latent aspect rating analysis on review text data : a rating regression approach . In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 783–792 . ACM , 2010 .
[ 23 ] H . Wang , Y . Lu , and C . Zhai . Latent aspect rating analysis without aspect keyword supervision . In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining , pages 618–626 . ACM , 2011 .
[ 24 ] Y . Zhang , G . Lai , M . Zhang , Y . Zhang , Y . Liu , and
S . Ma . Explicit factor models for explainable recommendation based on phrase level sentiment analysis . In Proceedings of the 37th international ACM SIGIR conference on Research and development in Information Retrieval , SIGIR ’14 , Gold Coast , Australia , 2014 . ACM .
[ 25 ] W . X . Zhao , J . Jiang , H . Yan , and X . Li . Jointly modeling aspects and opinions with a maxent lda hybrid . In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing , EMNLP ’10 , pages 56–65 , Stroudsburg , PA , USA , 2010 . Association for Computational Linguistics .
