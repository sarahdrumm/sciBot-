Automatic Gloss Finding for a Knowledge Base using Ontological Constraints
Bhavana Dalvi
Carnegie Mellon University
Pittsburgh , PA 15213 bbd@cscmuedu Partha P . Talukdar
Indian Institute of Science Bangalore , India 560012 ppt@serciiscin
Einat Minkov University of Haifa Haifa , Israel , 31905 einatm@ishaifaacil
William W . Cohen
Carnegie Mellon University
Pittsburgh , PA 15213 wcohen@cscmuedu
ABSTRACT While there has been much research on automatically constructing structured Knowledge Bases ( KBs ) , most of it has focused on generating facts to populate the KB . However , a useful KB must go beyond facts . For example , glosses ( short natural language definitions ) have been found to be found to be very useful in other tasks such as Word Sense Disambiguation . However , the important problem of Automatic Gloss Finding , ie , assigning glosses to entities in an initially gloss free KB is relatively unexplored – we address that gap in this paper . In particular , we propose GLOFIN , a hierarchical semi supervised learning algorithm for this problem which makes effective use of limited amounts of supervision and available ontological constraints . To the best of our knowledge , GLOFIN is the first such system for this task .
Through extensive experiments on real world datasets , we demonstrate GLOFIN ’s effectiveness . It is encouraging to see that GLOFIN outperforms other state of the art SSL algorithms , especially in low supervision settings . We also demonstrate GLOFIN ’s robustness to noise through experiments on a wide variety of KBs , ranging from user contributed ( eg , Freebase ) to automatically constructed ( eg , NELL ) . To facilitate further research in this area , we have already made datasets used in this paper publicly available , and we plan to release the code into the public domain upon publication of the paper .
1 .
INTRODUCTION
Automatic construction of knowledge bases ( KBs ) has attracted much attention over the past years . Knowledge bases provide structured representation of entities and the relationships between them , which is key in semantic processing tasks such as concept tagging , disambiguation and normalization . Freebase [ 6 ] and DBPedia [ 27 ] are well known examples of KBs that represent broad domain world knowledge , which are constructed and maintained collaboratively . Much work has been done on development of informa tion extraction systems which produce such KBs : eg , the NeverEnding Language Learner system ( NELL ) [ 7 ] , TextRunner [ 45 ] , and PROSPERA [ 32 ] , are all targeted at extracting general facts at Web scale .
While facts are obviously essential for a KB , a useful KB must contain more than facts . Many widely used KBs , including Freebase and WordNet , also include glosses—ie , natural language definitions of the entities in the KB . A large KB may contain glosses for each of the many entities it contains . In manually constructed KBs like WordNet [ 28 ] , glosses are typically provided as the KBs constructed by human experts ; however , in many automatically generated KBs , like NELL [ 29 ] or YAGO [ 38 ] there are no glosses , or only a few . For instance , YAGO supports glosses , but only a small fraction of entities ( 68.9K out of 10M ) have glosses assigned to them . Since manually adding definitions for a large number of entities is infeasible , glosses must be added automatically . In this paper , we focus on the problem of augmenting an existing KB with gloss information . To the best of our knowledge , this is the first attempt of enriching an automatically constructed KBs , like NELL , with glosses .
To illustrate the problem , Figure 1 ( top part ) describes the structure of NELL KB , as an example . As shown , the entities represented in NELL are organized in a hierarchy , in which nodes are linked over is a ( subset ) relations . General semantic categories , like fruit and company , are represented by nodes that are linked to higher level categories in the hierarchy–food and organization , respectively . Concrete entity nodes , such as Microsoft and Google , are linked to their hypernym–company . In addition , entities are associated in NELL with their lexical aliases ; eg , ‘Microsoft’ and ‘MS’ are both aliases of Microsoft . Notably , lexical aliases are often ambiguous , eg , the name ‘Apple’ refers to either fruit:Apple or company:Apple . While this representation of NELL KB provides valuable structured semantic knowledge , it does not contain glosses . Ideally , we would like to associate glosses to each entity node . For example , Company:Apple may be described as “ Apple , formerly Apple computer Inc , is an american company headquartered in Cupertino ” .
In addition to helping users understand the semantics ( or intended semantics ) of an entity , glosses are used in many technical tasks . In information retrieval , several recent approaches to query expansion make use of glosses [ 44 , 10 , 13 ] to improve the performance of ad hoc information retrieval , based on a semantic , entityrich representation of queries and documents . More generally , in the entity linking ( EL ) task [ 20 , 8 ] , named entity mentions in text are mapped onto canonicalized nodes in the KB , thus disambiguat
Figure 1 : Graph construction for Entity Sense Disambiguation , using features like lexical matches , and is a relationships ( subset constraints ) in the KB . ing the named entity mentions . Classical approaches to EL make heavy use of glosses : typically , an entity mention and surrounding context are treated as a query against a repository of glosses , with cosine similarity or word overlap [ 23 ] , between the query and the node descriptions used for scoring , and the highest scoring gloss being used to indicate the matching entity . For example , given a mention of ‘Apple’ in the context of ‘Cupertino’ , a better match is to be expected against the gloss of Company:Apple ( Fig 1 ) , compared with the alternative , Fruit:Apple . task . However , such labeled data is limited and noisy . We therefore propose Gloss Finder ( GLOFIN ) , a semi supervised Expectation Maximization ( EM ) method that learns effective classifiers given little labeled data and large amount of unlabeled data . GLOFIN uses constrained optimization , taking into account the hierarchy of semantic categories present in the knowledge base . Specifically , we incorporate known constraints between the given semantic classes , including subset relationship ( eg , “ mammal ” is subset of class “ animal ” ) , and mutual exclusion constraints ( eg , “ mammal ” is mutually exclusive with “ automobile ” ) .
Contributions In this paper , we make the following contributions :
• We formulate an approach to the important problem of Automatic Gloss Finding for Knowledge Bases ( KB ) , ie , automatically identifying glosses ( short definitional sentences ) for entities in a KB . Even though glosses have been found to be very useful in other related areas ( eg , Word Sense Disambiguation ) , the task of adding glosses to entities in a gloss free KB is relatively unexplored – we address that gap in this paper .
• We propose GLOFIN for the gloss finding problem . To the best of our knowledge , this is the first such system for this task . GLOFIN is a semi supervised algorithm which also makes use of available Ontological constraints . Through extensive experiments on real world datasets , we demonstrate GLOFIN ’s effectiveness . In particular , it is encouraging to find that GLOFIN outperforms even other state of the art semisupervised baselines , especially in limited supervision settings .
• We demonstrate GLOFIN ’s robustness to KB quality through experiments on a variety of KBs , ranging from hand curated ( eg , Freebase ) to automatically constructed ones ( eg , NELL ) .
• To facilitate further research on this topic , we have already
One potential way of producing glosses might be to construct sentences out of the facts already stored in the KB : eg , if the entity node Michael Jordan is linked to the category node Professor and related to the entity UC/Berkeley via the relationship employedBy , then it is possible to create a gloss that contains the sentence “ Michael Jordan is a professor working at UC/Berkeley ” . However , many KB entities have few known relationships , so many such such descriptions will be short and uninformative . Hence , rather than treating the task as a natural language generation task , we consider an alternative method : we collect large numbers of definitional sentences , and attempt to match these existing sentences to KB entities . While the experiments described in this paper focus on definitions collected from DBPedia , our approach is general , and could be applied as well to definitions harvested from any dictionary or glossary .
In short , the gloss finding task addressed in this paper corresponds to matching potential glosses with the respective KB nodes . While some matches are obvious , many are ambiguous . While ambiguous matches are a problem in many other alignment tasks ( eg , the EL task described above ) , this task is unusual in that it is an asymmetric resource alignment , where a collection of lexical glosses , which contain no structure information , is aligned against a structural KB , which contains no textual descriptions .
We define and address this task using semi supervised learning ( SSL ) techniques . We rely on several simple intuitions to solve the above mentioned problem . First , it has already been observed [ 38 , 33 ] that entity ambiguity is often resolved given its semantic category . Hence , rather than target a named entity linking problem , we solve an entity categorization problem . Next , we use the unambiguous glosses as labeled data for this entity categorization made datasets from this paper publicly available1 . We also plan to make code publicly available upon publication of the paper .
Outline The rest of the paper is organized as follows . We describe the related work in Section 2 , followed by some background material in Section 3 . We then present our proposed gloss finding algorithms in Section 5 . Datasets and experimental methodology in presented in Section 5 . Experimental results are presented in Section 6 , followed by the conclusions and future work .
2 . RELATED WORK
Glosses are an important resource of word meanings , which has been used by word sense disambiguation ( WSD ) [ 34 ] algorithms for decades . For example , the popular Lesk method [ 23 ] and its variants [ 21 , 3 ] infer a word ’s sense by measuring the overlap between available context words and the glosses of candidate senses . Traditionally , WordNet [ 17 ] has been used as the main resource of word senses and respective glosses . Several recent works have investigated the problem of automatic gloss extraction , so as to improve coverage in specific knowledge domains . Duan and Yates [ 14 ] constructed sense descriptions for selected keywords given unlabeled documents in the Biomedical domain , and used these descriptions to perform WSD . Others [ 16 , 5 ] constructed domainspecific glossaries using definitial sentences extracted from the Web , and successfuly used these glossaries for domain WSD . We share their motivation for obtaining glosses , however rather than generate these glosses , our goal is to associate available glosses with an existing KB .
In this work we match given glosses against the respective entity nodes in the KB . This task is closely related to Entity Linking ( EL ) , an entity focused variant of the WSD problem [ 30 ] , where named entity mentions in a given text are linked with the respective nodes in a KB . Advanced EL methods consider multiple entity mentions in a document collectively in order to enrich the contextual information that is modeled per entity [ 18 , 41 ] . Such methods are ineffective for short text fragments , like search queries , or glosses . In fact , we face a ‘chicken and egg’ problem , as most EL methods assume that KB entities have glosses , whereas we do not [ 19 , 24 ] . Here , we are interested in enriching a KB with glosses , so as to support entity linking and other downstream applications , such as ad hoc information retieval [ 44 , 10 ] .
Various works have addressed the problem of resource alignment , but considered different settings . The Yago ontology [ 38 ] , for example , unifies Wikipedia and WordNet using heuristics that consider the structure of both resources . Ponzetto and Navigli [ 37 ] mapped Wikipedia articles onto WordNet synsets , using the textual desctiptions of entity pairs . We rather consider an asymmtric setting , where the KB includes a semantic structure but lacks textual descriptions , and the aligned glosses are not assumed to be organized in any fashion . Similarly , a recent work [ 36 ] addressed the alignment of an arbitrary pair of lexical resources , including machine readable dictionaries with no structure . They proposed to induce a network structure for dictionary resources , however textual similarity remains an important component in their approach . Importantly , having enriched a given KB with glosses using the proposed framework , this will facilitate its alignment and integration with other KBs [ 9 ] .
In this work , we address the gloss finding problem using a semisupervised framework . In particular , we consider label propagation 1Dataset available at http://bit.ly/1zlgG5O
( LP ) , where gloss nodes are being associated with candidate entity nodes based on their relatedness in a joint graph . Talukdar [ 40 ] discuss the use of weakly supervised label propagation methods in information extraction and integration . Previous work applied LP to perform WSD [ 46 ] . In that case , the graph modeled words in parallel documents in two languages , where word ambiguity in one lanaguage was resolved based on graph relatedness to their candidate translation in the other language , and vice versa . The use of graph based methods is highly prevalent in WSD literature . In particular , random walks over a semantic graph , like WordNet , have shown to yield state of the art results [ 37 , 1 ] . Notably , linking nodes in the WordNet graph based on lexical gloss overlaps has been shown to contribute significantly to the performance of graph based WSD [ 1 ] .
The GOLFIN algorithm that is proposed in this paper is inspired by the EM framework that has been employed by Dalvi et al . for the task of exploratory learning ( semisupervised learning in the presence of unanticipated classes ) [ 12 ] and hierarchical semisupservised learning [ 11 ] . The methods proposed in this paper are different in the sense that we incorporate class hierarchy into the model . Further , the Divide and Conquer method proposed by Dalvi et al . [ 11 ] was limited to tree structured class hierarchy , whereas we propose a mixed integer programming based optimization method that can deal with any class hierarchy defined by sets of subset and mutual exclusion constraints . Interestingly , a recent work has used mixed integer LP techniques to encode ontological constraints [ 33]–they assign multiple plausible KB categories to ‘emerging’ entities , which are not yet represented in the KB , and consider mutual exclusion constraints as a post processing step , so as to output a consistent set of category assignments . In constrast , we apply subset as well as mutual exclusion constraints , within an iterative EM algorithm , using semi supervised learning Finally , while the application of earlier variants of the EM based framework focused on the named entity categorization task , we use the proposed methods for addressing the novel task of generating glosses for an existing KB .
3 . BACKGROUND
In this section we present relevant terminologies necessary to understand the rest of the paper , and also the problem statement of gloss finding . 3.1 Preliminaries 311 Knowledge Base ( KB ) In this paper , we consider a KB as a directed graph consisting of the following three types of nodes and relations among them . Part of a KB is shown in the top half of Figure 1 .
1 . Category nodes : Each category node corresponds to a semantic type . For example , in Figure 1 , University and Vegetable are examples of category nodes . Category nodes are inter linked through the subCategoryOf relation , resulting in the overall ontology ( category hierarchy ) . Additionally , two categories may be connected through a mutuallyExclusive relationship ( shown using red dotted lines in Figure 1 ) . For example , in Figure 1 , Fruit subCategoryOf Food and FoodmultuallyExclusive Organization .
2 . Entity nodes : Entities are instances of categories . An entity node is connected to its most specific category node though an isA edge . In Figure 1 , Banana isA Fruit .
3 . Lexical string nodes : Lexical string nodes correspond to text fragments ( usually noun phrases ) used to express enti ties in free text . For example , the lexical strings Apple or Apple Inc . may be used to refer to the entity Company:Apple . Please note an ambiguous lexical string may be connected to multiple entities : Apple in Figure 1 is connected to both Company:Apple and Fruit:Apple .
Note that even though a KB may consist of additional types of relations among its nodes ( eg , Microsoft competesWith Google ) , we omit them here as they are not relevant for the rest of the paper . 312 Glosses Glosses are natural language definitions of entities in the KB . For example , the following is a gloss for Platinum : "Platinum is a chemical element with the chemical symbol Pt and an atomic number of 78" . In this paper , we consider DBPedia abstracts as a repository of glosses . 3.2 The Gloss Finding Problem
Given a KB ( eg , NELL or Freebase ) and a repository of candidate glosses ( eg , DBPedia abstracts ) , the Gloss Finding Problem requires to identify for each entity in the KB the correct gloss(es ) from the candidate gloss pool . For example in Figure 1 , we would like to infer that for entity Fruit:Apple , "Apple is a fruit from apple tree " is the only correct gloss . Sometimes it is possible that for certain entities in the KB , there exists no correct gloss in the given candidate gloss pool ( eg , Strawberry in Figure 1 ) .
4 . AUTOMATIC GLOSS FINDING
In this section , we describe approaches to the Gloss Finding problem , including GLOFIN , our proposed method . Before getting into the details of methods , in Section 4.1 , we first describe an entity gloss candidate generation stage whose output is used by all the methods considered in the paper . After that , in Section 4.2 we propose our first attempt at the gloss finding problem using Label Propagation ( LP ) . However , through experiments on real datasets as we will see in Section 6 , we find that such LP based methods are not always effective on the gloss finding problem . To overcome this limitation , in Section 4.3 we present our proposed method . 4.1 Candidate Entity Gloss Generation
In this step , for each gloss in the candidate pool of glosses given as input , we first identify the noun phrase that is being defined by the gloss . We refer to this noun phrase as head NP in this paper . For DBPedia abstracts this step is trivial in the sense that DBPedia dataset gives us the head NP for each short abstract . However , we can easily apply existing syntactic taggers , eg , the Stanford tagger [ 25 ] , and detect the head NP in the definitional sentence(s ) . After this , the head NP of each gloss is lexically matched against the entities in the KB . Even though simple string matchings are used for the experiments in this paper , more sophisticated string matchers may also be used .
At the end of this stage , we end up with a set of candidate entitygloss matchings . Please note that this relationship may be manymany and thereby ambiguous as one entity may be connected to multiple glosses , and a single gloss may be assigned multiple entities . Such ambiguity are resolved using the techniques described below . 4.2 First ( unsuccessful ) approach : Label Prop agation
In order to remove uncertainties from the candidate matchings generated in Section 4.1 , we first use Modified Adsorption ( MAD ) [ 39 ] , a representative graph based semi supervised learning ( SSL )
Algorithm 1 GLOFIN 1 : Input : Xl labeled glosses ; Yl category labels of Xl ; Xu unlabeled glosses ; O class constraints ( subclass superclass or mutual exclusion kind ) . N = |X| and K is the number of classes .
2 : Output : Yu labels for Xu 3 : Initialize parameters θ0 4 : for t = 1 . . . till convergence do 5 : for i=1 to |X| do j for each Cj using seeds provided for Cj .
{E step : Assign a bit vector of categories to each gloss} Find P ( Cj|xi ; θt−1 i = find consistent assignment by solving MIP(P ( Cj|xi ) , O ) . Y t
) for all classes Cj j end for {M step : Recompute model parameters.} Recompute θt j based on current class assignments Y t .
6 : 7 : 8 :
9 : 10 : end for 11 : return algorithm . This choice was prompted by the fact that such Label Propagation ( LP ) techniques have achieved considerable success in various weakly supervised NLP tasks , and that they could potentially exploit the graph structure of the current problem .
In order to apply MAD to this Gloss Finding problem , we first create an augmented version of the graph in Figure 1 by connecting each gloss to its content words which passed a TF IDF based filtering . Please note that mutual exclusion constraints were not used in this augmented graph as MAD is not capable of handling such relations . We then inject each entity node with its own node specific label . Such self labeling approach was also used in [ 43 ] , although for an entirely different problem . Starting with this augmented graph and self injected seed labels , the MAD algorithm is used to classify the rest of the nodes in the graph . At the end of the algorithm , MAD assigns each candidate gloss a set of labels , where each label corresponds to an entity since the labels were entity specific self injections .
This distribution of entities on a candidate gloss node is intersected with the candidate entities generated in Section 4.1 , and the resulting entities are sorted based on the assignment score generated by MAD . The top entity in this ranked list is then chosen as the inferred entity match for the candidate gloss . As we shall see in Section 6 , while this LP based approach is effective in some settings , it is not always the case . To address this shortcoming , we present GLOFIN , our main proposed method in the following section . 4.3 Proposed Approach : Gloss Finder ( GLOFIN ) We propose Gloss Finder ( GLOFIN ) , a hierarchical semi supervised
Expectation Maximization ( EM ) algorithm for the Gloss Finding problem . GLOFIN uses automatically acquired labeled data ( unambiguous candidate glosses ) and large amount of unlabeled data ( rest of the candidate glosses ) in an iterative EM framework to learn a model for this task . The GLOFIN algorithm is presented in Algorithm 1 . Before getting into the details of the algorithm , let us define the following notations . Let X = {x1 , . . . xN} be the candidate glosses , and {C1 , . . . CK} be the KB categories . Let yji ∈ {0 , 1} be an indicator variable specifying whether candidate gloss xi belongs to category Cj . Let θj denote the centroid for category Ci . Using the model parameters θj for class Cj , we can estimate P ( Cj|xi ) , the probability of gloss xi belonging to category Cj . GLOFIN aims to find optimal values of label assignments yji and cluster models θj , so as to maximize the overall data likelihood . Let Subset be the set of all subset or inclusion constraints , and Mutex be the set of all mutual exclusion constraints . In other words , Subset = {i , k : Ci ⊆ Ck} and Mutex = {(i , k ) : Ci ∩ Ck = φ} .
GLOFIN takes in as input the set of glosses X , out of which Xl is the labeled subset with category labels in Yl , and the remaining Xu is unlabeled . Additionally , it takes as input a set of ontological constraints , O . In the E step of this algorithm , each candidate gloss Xi is assigned a bit vector of labels Yi = [ y1i , . . . yKi ] . The class hierarchy is incorporated as constraints on bits in this bit vector . For example , if for a gloss with head NP cat , a bit corresponding to KB category mammal is set then the bit corresponding to category animal should also be set ( subset constraint : mammal ⊆ animal ) , and for the same gloss the bit corresponding to category reptile should not be set ( mutual exclusion constraint : mammal ∩ reptile = φ ) . The M step recomputes the model parameters for each KB category using the label assignments done in the E step .
The E step of GLOFIN ( Algorithm 1 ) may be broken down into two stages , which we describe in greater details below :
Assigning Entities to Candidate Glosses ( Algorithm 1 : Line 6 ) This step computes probabilities P ( Cj|xi ; θj ) , where θj is the current estimate of model parameters for category Cj . A variety of techniques may be used for this estimation , we briefly describe one such choice here : the semi supervised version of multinomial Naive Bayes [ 35 ] . In this model P ( Cj|xi ) ∝ P ( xi|Cj ) ∗ P ( Cj ) , for each unlabeled gloss xi . The probability P ( xi|Cj ) is estimated by treating each feature in xi as an independent draw from a classspecific multinomial . In this task , the features are word occurrences in the candidate glosses , and the number of outcomes of the multinomial is the vocabulary size . We shall refer to this version of GLOFIN as GLOFIN NB . Additional variants using other learning algorithms are discussed in Section 6 .
Entity Assignment Refinement using Ontological Constraints ( Algorithm 1 : Line 7 ) Given the category memberships probabilities {P ( Cj|xi)} estimated above , this step computes the category membership variables {yji , ∀ 1 ≤ i ≤ N , 1 ≤ j ≤ K} . GLOFIN solves a Mixed Integer Program ( MIP ) to estimate these variables . One such problem is solved for each gloss . This MIP takes the scores {P ( Cj|xi)} , and class constraints O as input and produces a bit vector of labels as output , each bit representing whether the gloss belongs to that particular category .
The MIP formulation for gloss xi is presented in Equation 1 . For each gloss , this method tries to maximize the sum of scores of selected labels , after penalizing for violation of class constraints . Let ζjk are slack variables for Subset constraints , and δjk are slack variables for Mutex constraints . yji ∗ P(Cj|xi ) −
ζik − i,k∈Subset
( i,k)∈Mutex
δik maximize
{yji},ζjk,δjk j subject to , yji ≥ yki − ζjk , ∀j , k ∈ Subset yji + yki ≤ 1 + δjk , ∀(j , k ) ∈ Mutex ζjk , δjk ≥ 0 , yi ∈ {0 , 1} , ∀j , k ( 1 )
These two result in longer runtimes for this method . We make our method scalable and efficient in following ways : • We discard the redundant mutex constraints , the ones that can • We reduce the number of classes considered per gloss , by keeping only top Q classes relevant to the gloss as detailed below . • Since MIP for each gloss is independent , we parallelize the E be inferred using remaining subset and mutex constraints . step of every iteration , and consolidate results in the M step .
Reducing the MIP size per gloss : We keep only a small number of categories in the optimization problem that is being solved for each gloss . We tried following three ways of keeping only some of the candidate classes : • Diameter of the class graph : Class graph is an undirected graph of ontology classes , where nodes are classes and edges represent either subset or mutual exclusion constraints . In this approximation , we rank all classes by the scores P ( Cj|xi ) for a datapoint xi , and choose top Q classes , where Q is the diameter of the category graph . Since the class assignments are hierarchical , we also include all ancestors of these top Q classes in the optimization .
• Square root of number of classes : Here , we select Q =
K , where K is the total number of classes in the ontology . Similar to diameter based method , we include all ancestors of these topQ classes in the optimization . • Thresholding : If the score P ( Cj|xi ) is greater than a predefined threshold then consider the category . Note that the threshold is set for the entire dataset , but for each datapoint , it might result in different number of categories and constraints .
√
5 . DATASETS
AND METHODOLOGY
EXPERIMENTAL
In our experiments , we enrich two existing knowledge bases with available glosses , namely NELL and Freebase . NELL is a machine generated knowledge base that does not have existing glosses , whereas most Freebase entities have descriptions/glosses we can compare against . Our resource of glosses is DBPedia , a database of factual descriptions extracted from Wikipedia editions in 97 different languages . DBPedia contains a large set of Wikipedia titles and short abstracts .
A DBPedia short abstract of an entity is essentially the first paragraph ( up to 500 characters ) on the Wikipedia page of that entity . Some sample entity titles and their corresponding DBPedia abstracts are given in Table 1 . We consider two experimental datasets that were labeled for evaluation purposes . We have made both these gloss finding datasets available 2 for research community to help the future research in this field .
Entity Title Definition ( DBPedia short abstract ) Platinum
Platinum is a chemical element with the chemical symbol Pt and an atomic number of 78 . . . . Britwell is a residential housing estate and civil parish in the north west of Slough Berkshire in the south of England . . . .
Britwell
4.4 Scaling GLOFIN
The MIP formulation presented in Equation 1 adds a constraint per subset and mutual exclusion constraints in the KB ontology . Further , in the E step of every iteration , we solve a MIP per gloss .
2The dataset can be downloaded from http://rtwml cmu.edu/wk/WebSets/glossFinding_wsdm_2015_ online/index.html
Table 1 : Sample candidate glosses
5.1 Freebase dataset
Freebase is a huge tuple database used to structure general human knowledge . The data in Freebase is collaboratively created , structured , and maintained . Public read/write access to Freebase is allowed through an HTTP based graph query API using the Metaweb Query Language ( MQL ) as a data query and manipulation language . Currently Freebase consists of over 44M topics and 2613M facts about entities , their relationships and attributes . We use the Freebase entity snapshot provided by ERD’14 challenge [ 8 ] as gold standard mapping of Freebase to DBPedia abstracts . Thus we get a good quality training and test data for our semisupervised methods on the task of finding glosses for Freebase .
Table 2 includes detailed statistics of the Freebase dataset . Overall , Freebase entities in this dataset belong to 46 Freebase classes . Having considered their parent types , the dataset includes a set of 66 classes in total . There are 5.5M Freebase entities in total that belong to these 66 classes . In order to obtain the underlying subset and mutual exclusion constraints , we built co occurrence matrix of entities belonging to each pair of classes . Based on this matrix , we elicited constraints of the two types . We discovered 46 subset constraints and 1,455 mutual exclusion class constraints from this data .
Statistic
#classes
#Classes #Subset class constraints #Mutex class constraints √ Diameter of class graph #DBPedia abstracts #Words #(abstract , word ) edges #Unambiguous DBPedia abstracts #Ambiguous DBPedia abstracts #Ambiguous abstracts with ground truth KB mappings
Dataset
Freebase 66 46 1455 4 9
NELL 275 313 18.1K 10 17 284.5K 246.7K 496.8K 472.4K 7.1M 257.3K 195.8K 32.8K 50.0K
5.7M
12.4K
383
Table 2 : Statistics about the datasets . Please refer Sections 5.1 , and 5.2 for more details .
5.2 NELL dataset
NELL knowledge base is created by a machine learning system named Never Ending Language Learning [ 29 ] . NELL is composed of various information extraction components [ 7 , 42 , 22 ] that independently extract facts from text and semi structured information on the Web . Recent version of NELL KB consists of 275 categories and 1.67M instances belonging to these categories . Though the facts in NELL are extracted by a computer system , it takes as input a human created ontology containing categories , and subset and mutual exclusion constraints between them .
We constructed a dataset using NELL KB and candidate DBPedia abstracts . Statistics about the NELL dataset are included in Table 2 . Unlike Freebase , NELL entities do not have glosses associated with them , so we do not have a ground truth gloss data for NELL . Further , since this KB is automatically generated by a computer system it contains noisy facts , hence the training data used by our methods is noisy .
Next we present results of two manual evaluation experiments for the NELL dataset . We do our first evaluation to understand the quality of automatically acquired seeds and predicted entity labels for ambiguous DBPedia abstracts . This will later help us to make claims about robustness of our proposed methods towards noisy training data . Further , we do not have a gold standard set of mappings from DBPedia abstracts to NELL entities , which are needed to evaluate our systems . Hence , we manually construct gold standard set of mappings by labeling 383 ambiguous DBPedia abstracts with correct NELL entities . Also note that these gold standard mappings are used only as a test set , and our methods use only automatically generated training data for learning models .
Quality of automatically acquired seeds Our methods consider unambiguous mappings of DBPedia abstract onto NELL entity as labeled data . As such mappings are determined automatically for the NELL dataset , we performed manual evaluation in order to assess the quality of the unambiguous alignments , inspecting 100 randomly sampled unambiguous DBPediaNELL matches . For each abstract in this sample , we evaluate whether the assigned class is precise , correct , and whether its higher level category is correct . We illustrate these measures using examples . If a DBPedia abstract about “ Shively Field ( public airport ) ” was mapped to the category “ airport ” , then the mapping is considered to be precise , correct , and the higher level category is correct as well . Mapping between another DBPedia abstract about “ Christopher McFarland ( baseball player ) ” to the category “ person northamerica ” , is judged as correct , but not precise , as there exists concrete “ athlete ” category in NELL . Finally , a mapping between “ Jonathan Andersson ( hockey player ) ” and “ director ” , is incorrect and not precise . The higher level category in this case is correct however , since “ director ” is a descendant of “ person ” , which is correct .
Statistic #unambiguous abstracts evaluated #abstracts st assigned category was correct #abstracts st assigned category was most precise #abstracts st assigned higher level category was correct
Value 100 81 72 94
Table 3 : Evaluating quality of unambiguous mappings of DBPedia abstracts to NELL entities/categories . Please refer Section 5.2 for more details .
Table 3 shows the results of this evaluation . We found that out of 100 unambiguous mappings between abstracts and NELL categories , 72 % were precise and 81 % were correct . The higher level category was correct in 94 % of the considered examples . While these alignments are imperfect , we consider them to be of high quality . The experimental results described in the following section will show that our techniques make effective use of this automatically labeled data .
Manually creating gold standard mappings from DBPedia abstracts to NELL entities As we have already stated , NELL does not have glosses for its entities and unlike Freebase there is no gold standard mapping available from DBPedia abstracts to NELL entities . Hence we randomly sampled 383 DBPedia abstracts for which multiple candidate NELL entities and categories were found . For each abstract , we manually checked whether one of the candidate NELL entities and categories was a correct match . We also checked whether the most precise entity is present in the NELL KB . For some DBPedia abstracts , most precise ( entity , category ) combination was not present in NELL , but the most precise category was present . The statistics of our evaluation are listed in Table 4 .
From Table 4 we can say that 79 % DBPedia abstracts have at least one correct entity match in the candidate entity set . Eg a DBPedia abstract about “ Michael Jordan ” as Basketball player , can
Statistic Value #abstracts evaluated 383 %abstracts ∃ at least 1 NELL entity , category match 79 % %abstracts ∃ most precise entity candidate in KB 68 % %abstracts ∃ most precise category candidate in KB 98 % Table 4 : NELL Dataset : Manual evaluation of ambiguous glosses . Please refer Section 5.2 for more details . be matched to NELL entity “ michael jordan:person ” , however most precise entity will be “ michael jordan:athlete ” . We consider “ michael jordan:person ” as a accurate candidate entity , however “ michael jordan:athlete’ is the most precise entity , and “ athlete ” is the most precise category . 5.3 Methods
We experimented with following eight methods for the gloss finding task . First two methods are existing supervised and semisupervised methods . • SVM : This is a traditional supervised linear SVM algorithm applied for the task of classifying head NPs from candidate glosses into KB categories . We learnt a separate binary classifier for each KB category . For this purpose , we used the publicly available LibLinear package [ 15 ] with varying values of parameter “ C ” that controls penalty on slack variables . Higher the value of “ C ” , higher the penalty on slack variables , so harder the model will try to fit the training data . Similar method was used by Martinez et al . [ 26 ] which trains a decision list classifier on monosemous ( unambiguous ) words for the word sense Instead we choose a more widely used disambiguation task . supervised learning method SVM . • Label propagation : This is a representative graph based semisupervised learning ( SSL ) algorithm , called Modified Adsorption ( MAD ) [ 39 ] described in Section 42 Next three methods are variants of our proposed GLOFIN algorithm ( Section 4.3 ) using different document representations . • GLOFIN NB : As already described in Section 4.3 , this is a • GLOFIN KM : Here we use the seeded spherical K Means algorithm proposed by Basu and Mooney [ 4 ] as another variant of semi supervised EM . • GLOFIN VMF : Banerjee et al . [ 2 ] proposed a generative mixture model approach for clustering to clustering datapoints based on von Mises Fisher distribution , defined for data distributed on the unit hypersphere ( L2 norm equals 1 ) . We use a seeded version of this algorithm similar to Dalvi et al . [ 12 ] who used it for the task of exploratory learning . semi supervised version of multinomial Naive Bayes [ 35 ] .
To evaluate the real benefits of incorporating hierarchy , we also consider flat versions of semisupervised Naive Bayes , seeded spherical K Means and seeded von Mises Fisher . For each flat method , the E step ( Algorithm 1 : Line 6 ) computes P ( Ci|xj ) for all leaf classes Ci in the ontology and picks the one with maximum probability , skipping the mixed integer programming step ( Algorithm 1 : Line 7 ) . M step does not change . These methods are referred to as GLOFIN flat NB , GLOFIN flat KM and GLOFIN flat VMF . 5.4 Features
Each gloss can be represented by term frequency ( TF ) of words that occurred in it . We can also collect inverse document frequency ( IDF ) of each word in the vocabulary from the entire gloss corpus . This gives us a choice of using either TF ( mere term frequencies ) or TFIDF ( multiplication of TF and IDF values ) feature representations . We use the TFIDF values to threshold the words used for each gloss . For all the experiments presented here , we keep only those words per gloss that cross TFIDF threshold of 1E 3 , thereby discarding stop words .
For each method , we performed a bunch of experiments with both TF and TFIDF based feature representations ( considering only those words that pass TFIDF threshold ) . In our experiments we found that SVM and Label propagation methods give better performance for TFIDF based feature representation , whereas all semisupervised EM methods ( GLOFIN variants ) work best with TF based feature representation . Henceforth , we present all results using these choices of feature representations .
Since feature engineering is not the focus of this paper , we use standard bag of words features for all our experiments . Any additional features can be incorporated easily in our algorithm and are complementary to the techniques introduced in this paper .
6 . EXPERIMENTAL RESULTS 6.1 Gloss Finding Results
In this section we present the experimental results on the gloss finding task . For the first set of results we use all unambiguous glosses ( glosses with only one candidate entity mapping to the KB ) as training data . The next set of experiments make use of only 10 % of unambiguous matches as training data . We compare all eight methods that we presented in Section 4 : SVM , label propagation , the hierarchical and flat variants of GLOFIN .
For the SVM method , we tried different values of ‘C’ for the LibLinear package . We observed the change in performance varying the values of ‘C’ in the range [ 1E 24 , 100 ] for both datasets ( plots omitted due to space constraints ) . We found that best performance is achieved for ‘C’ in the range [ 1E 6 , 001 ] Results presented here are with C = 1E 6 ( results for C = 0.01 are very similar ) .
From the experiments presented here , we try to answer the following research questions : • How does our proposed GLOFIN NB method compare with SVM and label propagation on the task of assigning glosses for NELL and Freebase datasets ? • How do Naive Bayes , K Means and von Mises Fisher variants • Does the use of ontological constraints always improve results • What is the effect of the different strategies of limiting the set of considered classes per gloss on scalability ( and performance ) of GLOFIN method ? of GLOFIN method compare ? for GLOFIN method ?
611 Comparing GLOFIN NB against SVM and la bel propagation
Method
Performance on “ Ambiguous glosses ”
SVM Label Propagation GLOFIN NB
P 59.3 42.8 70.4
NELL R 21.3 54.0 65.4
Freebase
F1 31.3 47.8 67.8
P 87.8 89.8 94.6
R 13.0 89.1 74.2
F1 22.7 89.4 83.2
Table 5 : Comparison of gloss finding methods using all unambiguous glosses as training data and ambiguous glosses as test data . Best values in each column are bold faced . GLOFIN NB method is robust to noisy training data for the NELL dataset . Please refer Section 611 for more details .
Method
SVM Label Propagation GLOFIN NB
NELL Dataset
Ambiguous glosses
Precision Recall 17.3 12.3 62.0
64.2 55.0 71.7
F1 27.3 20.1 66.5
All glosses Precision Recall 27.9 5.2 62.0
99.9 99.7 99.9
F1 43.7 9.8 76.5
Freebase Dataset
Ambiguous glosses
Precision Recall 11.3 27.5 72.0
87.8 84.6 95.1
F1 20.1 41.5 82.0
All glosses Precision Recall 71.1 88.1 79.6
97.9 99.7 97.6
F1 82.5 93.6 87.6
Table 6 : Comparison of gloss finding methods with 10 % unambiguous abstracts used as training data . GLOFIN NB always gives best or near best F1 scores . Please refer Section 611 for more details .
Here we compare our proposed GLOFIN NB method against supervised SVM and semi supervised label propagation methods . We compare them in two settings : first using all unambiguous glosses as training data and second , by simulating a harder problem ie using only 10 % of the unambiguous glosses for training .
Using all unambiguous glosses for training : Table 5 shows the summary of results while using all unambiguous glosses as training data and ambiguous glosses for evaluation .
We can see that , supervised SVM classification performs worst on both datasets . Label propagation gives best F1 score for Freebase , however it performs poorly on the NELL dataset . Whereas GLOFIN NB method works well on both NELL and Freebase datasets . On Freebase dataset , GLOFIN NB has higher precision , lower recall , and hence slightly lower but comparable F1 score wrt the label propagation method .
Both label propagation and GLOFIN NB perform better on the Freebase dataset compared to the NELL dataset . This can be explained by the the difference in quality of automatically acquired seeds for the two datasets . Note that unambiguous glosses used for the Freebase dataset are coming from ERD’14 gold standard dataset hence very accurate ; whereas for the NELL dataset our evaluation in Section 5.2 , Table 3 shows that only 81 % of seed gloss mappings were accurate . Hence the results in Table 5 indicate that our proposed GLOFIN NB method is relatively robust to noise compared to the label propagation method .
We also investigated why the supervised SVM method performs poorly even though 80 % of the total data is used as training . We found that there is a huge skew in the class frequencies . For the Freebase dataset with 45 leaf classes , average training instances per class are 2.27K with a standard deviation of 10.8K ; eg “ /location/location ” category has 72.6K training examples , whereas “ /education/university ” category has just 10 training examples . We hypothesize that small amount of training data for many KB categories is the reason why the SVM method performs poorly .
Note that in experiments presented in table 5 , the number of unambiguous glosses used as training data covered a large part of the overall dataset(80 % for NELL and 90 % for Freebase ) . However , in real life scenarios , the amount of training data can be much smaller . Freebase dataset is artificially created using ERD’14 data and a subset of Freebase KB categories . NELL populates its KB by bootstrapping against many different categories simultaneously , beginning with a small set of hand chosen seeds . It may be the case that this learning process tends to favor entity names that can be confidently assigned to a single category ( ie , that are not highly ambiguous ) ; to support this conjecture , we note that an alternative instance of NELL which used a larger set of automatically generated low quality seeds required modifications to suppress the use of ambiguous entities in bootstrapping [ 31 ] . This suggests that other real world KBs may have a lower proportion of unambiguous entities . Next , we conduct experiments which simulates this setting , by using only 10 % of the available unambiguous matches as seeds .
Using 10 % unambiguous glosses for training : Table 6 shows detailed results of our proposed method GLOFIN NB comapred to SVM and label propagation methods when only 10 % unambiguous glosses are used as training data . Since we are using only a fraction of unambiguous glosses as training data , rest of them can be used as test data . Additionally , all gold standard mappings of ambiguous glosses are always part of test data . We generate 10 random train/test partitions and average results on these 10 runs . Performance on ambiguous glosses is particularly interesting hence listed separately . Note that “ All glosses ” include ambiguous as well as unambiguous glosses .
We can see that with less training data the performance of all methods degrades , however to varying degrees . Also , all methods give higher performance on “ all glosses ” compared to the harder task of matching ambiguous glosses . In terms of F1 scores on ambiguous glosses , SVM results in the worst performance and GLOFINNB method gives the best performance . In terms of F1 score on “ all glosses ” , Comparing GLOFIN NB vs . label propagation we can see that hier NB performs better in all cases , except Freebase dataset “ all glosses ” case where hier NB has higher precision and lower recall , and hence lower F1 score compared to label propagation method .
To summarize , we showed that GLOFIN performs best on the harder task of matching ambiguous glosses when amount of training data is small ( Ambiguous glosses columns in Table 6 ) .
Discussion : Comparing the results across Tables 5 and 6 , we can hypothesize that , with large fraction(90 % for Freebase dataset ) of glosses being unambiguous in our artificially created dataset , its very easy to get high values for F1 score using label propagation method ( Table 5 ) , because rest of the 10 % nodes might get high quality labels from its nearest neighbors . However when the amount of training data is smaller , generative models like hier NB work better ( Table 6 ) as they generalize better .
One more advantage of GLOFIN lies in its generative nature . Label propagation is a transductive approach , whereas GLOFIN is a generative approach . Ie EM models learnt by GLOFIN on a set of datapoints , can be applied to an unseen datapoint having similar vocabulary . In other words , they can predict labels for an unseen datapoint . However label propagation just predicts labels for the datapoints in the set being used while learning . 612 Comparing variants of GLOFIN Table 7 shows detailed results of our proposed methods ( GLOFIN NB , GLOFIN KM and GLOFIN VMF ) wrt their flat counterparts ( GLOFIN flat NB , GLOFIN flat KM and GLOFINflat VMF ) . GLOFIN NB method works best on both NELL and Freebase datasets .
GLOFIN NB outperforms GLOFIN KM in the experiments . Importantly , GLOFIN NB models class priors ( as discussed in Section 611 ) ) As mentioned before , the class frequencies in our datasets are very skewed ; hence modeling class priors is highly useful . In contrast , GLOFIN KM merely computes cosine similarity
Performance on “ Ambiguous glosses ”
Approximations
Performance on “ Ambiguous glosses ”
NELL
Freebase
√ keep all classes Q = diameter Q = score threshold= 1E 5
K
F1 81.7 83.4 83.4
Time
F1
>230.4K 80.4 5.2K 81.8 15.9K 83.1 22.1K 71.4
Time 15.2K 5.7K 3.6K 9.3K
Table 8 : Comparison of different approximations to scale our GLOFIN NB method using 10 % unambiguous glosses as training and ambiguous glosses as test data . Time measurements are in seconds . Please refer to Section 614 for more details . are semantically similar .
Method
P
GLOFIN flat KM 74.8 65.2 GLOFIN KM 73.6 GLOFIN flat VMF 77.2 GLOFIN VMF GLOFIN flat NB 70.3 70.4 GLOFIN NB
NELL R 36.5 49.8+ 44.5 59.5+ 59.1 65.4+
F1 49.1 56.5+ 55.5 67.2+ 64.3 67.8+
P 97.6 96.1 96.3 95.7 95.9 94.6
Freebase R 61.0 71.8+ 56.0 59.3+ 71.1 74.2+
F1 75.1 82.2+ 70.8 73.2+ 81.7 83.2+
Table 7 : Comparison of GLOFIN variants using all unambiguous glosses as training data and ambiguous glosses as test data . Best values of F1 for each dataset is bold faced . ‘+’ in front of a hierarchical method score indicates that the score improved over its flat version . ( a ) GLOFIN NB method performs the best . Please refer to Section 612 for more details . ( b ) All hierarchical methods perform better than their flat counterparts . Refer to Section 613 for more details of a datapoint with respect to a cluster centroid , hence its inferior performance . The GLOFIN VMF method provides second best performance to GLOFIN NB on the ambiguous gloss . Although GLOFIN VMF is cluster based , it also models class priors .
613 Effect of using ontological constraints From Table 7 , we can also see that all hierarchical semisupervised EM methods are better than their flat counterparts . Hence we conclude that using ontological constraints help improve the gloss finding performance . Note that relative improvements of hierarchical methods are higher for the NELL dataset ( upto 21 % relative improvement in F1 scores ) . The reason traces back to evaluation of NELL seeds in Section 5.2 , Table 3 . We saw that 81 % leaf category seed labels were correct , whereas 94 % higher level category labels were correct . Thus learning separate model parameters for higher level categories in the ontology and using ontological constraints to resolve ambiguity employed by hierarchical GLOFIN methods prove beneficial . Since Freebase seed labels are accurate , and hierarchy contains just 2 levels , hierarchical models do not have as much added advantage over flat models as the NELL dataset , resulting in upto 9 % relative improvement in F1 scores .
614 Comparing different ways of scaling GLOFIN We tried various approximations to reduce runtime of GLOFIN(Please refer to Section 4.4 for details ) . The summary is presented in Table 8 . We found that setting Q , the number of classes considered in a MIP ( Equation 1 ) as the diameter of the class graph , gives huge time savings and does not harm the performance in terms of F1 score on ambiguous entities . Hence we use this approximation for all runs of GLOFIN in this paper . In addition to this , we also use 12 parallel threads in the E step to compute label assignments of all datapoints in parallel . Note that for NELL dataset these approximations are crucial . Otherwise , run time on a PC machine ( with 30GB memory ) exceeds 64 hours . Due to large processing requirements , we do not have F1 score values for this case . 6.2 Evaluating NELL to Freebase mappings via common glosses
From the output of our Hierarchical Naive Bayes method , we randomly sampled 100 DBPedia abstracts that got assigned entities from both NELL and Freebase KB . Then we did a manual evaluation whether entities from NELL and Freebase correspond to each other , and whether the categories they belong to in respective KBs
Eval Type #Abstracts Evaluated
Statistic
Assigned entities are correct , corresponding categories are semantically related Assigned NELL category is precise Assigned Freebase category is precise Found in 100 abstracts evaluated NELL category = Freebase category NELL category ⊂ Freebase category Freebase category ⊂ NELL category
#Category pairs
Value 100
93 92 38 39 6 23 1
Table 9 : Evaluating quality of NELL to Freebase mappings via common DBPedia abstracts . Please refer to Section 6.2 for more details .
From Table 9 , we can see that out of 110 abstracts that were evaluated , 93 of them had correct NELL and Freebase entities assigned to them , and their corresponding categories were semantically related . For 92 of those abstracts , NELL category was precisely correct , while for 38 of them Freebase category was precise . This is due to the fact that the Freebase categories we use to build our dataset are more general categories like “ /organization/organization ” , “ /location/location ” , and more precise categories like “ /location/city ” and “ /organization/biotech company ” are missing . NELL has all these categories at higher granularity , hence it can classify DBPedia abstracts into more fine grained categories . For instance , a DBPedia abstract about “ Biotronik ” is classified into “ biotechcompany ” category from NELL , and “ /organization /organization ” category from Freebase . We evaluate the entities from 2 KBs to be correct , and the corresponding categories as semantically related .
We also evaluated whether we can come up with a relationship between the categories corresponding to NELL and Freebase mappings . From 100 abstracts , we found 39 category pairs that got manually evaluated . We found 6 category pairs that can be considered as equivalent . Eg We marked the category “ geopoliticallocation ” from NELL to be equivalent to category “ /location/location ” from Freebase . In 23 category pairs , we found that NELL category was strict subset of Freebase category . Eg “ actor ” category from NELL is strict subset of “ /person/person ” category from Freebase . Only one category in Freebase “ /broadcast/broadcast was found to be a strict subset of the NELL category “ company ” . For 9 category pairs we could not define a equality or subset relation between them . They include either the semantically unrelated class pairs like “ visualartist ” and “ /location/location ” corresponding to incorrect entity matches , and or semantically related categories like “ drug ” and “ /business/brand ” . There are many drugs like Donnatal , Excedrin that are classified as “ drugs ” in NELL and as “ /business/brand ” in Freebase . Though these categories are related to each other we can not easily classify them into equivalence or subset relations .
We have also provided some sample outputs of our methods at following URL http://bitly/1zlgG5O
7 . CONCLUSION
In this paper , we proposed GLOFIN , a method for the important but relatively unexplored problem of Automatic Gloss Identification , ie , automatically generating gloss ( short definitional sentences ) for an initially gloss free knowledge base ( KB ) by matching candidate glosses to entities in the KB . To the best of our knowledge , this is the first such system for this task . GLOFIN employs hierarchical clustering algorithm that internally uses unambiguous DBPdia abstracts as seeds and the KB ontology as constraints to match an ambiguous candidate gloss to the right entity from KB . GLOFIN use mixed integer programming formulation to assign the most likely set of labels for each gloss , while following the class constraints posed by the KB ontology .
We present experiments using NELL and Freebase as KBs and DBPedia abstracts as candidate glosses . Our quantitative and qualitative evaluations show that GLOFIN is effective and that it outperforms other state of the art algorithms like label propagation and Support Vector Machines ( SVM ) . We also demonstrate GLOFIN ’s robustness to noise through experiments on a wide variety of KBs , ranging from user contributed ( eg , Freebase ) to automatically constructed ( eg , NELL ) . To facilitate further research in this area , we have already made datasets used in this paper publicly available , and we plan to release the code into the public domain upon publication of the paper . In future , we would like to extend GLOFIN to discover new entities and new categories to further enrich the knowledge bases .
8 . REFERENCES [ 1 ] E . Agirre , O . L . de Lacalle , and A . Soroa . Random walks for knowledge based word sense disambiguation . Computational Linguistics , 2014 .
[ 2 ] A . Banerjee , I . S . Dhillon , J . Ghosh , and S . Sra . Clustering on the unit hypersphere using von mises fisher distributions . In JMLR , 2005 .
[ 3 ] S . Banerjee and T . Pedersen . Extended gloss overlaps as a measure of semantic relatedness . In IJCAI , 2003 .
[ 4 ] S . Basu , A . Banerjee , and R . Mooney . Semi supervised clustering by seeding . In ICML , 2002 .
[ 5 ] F . D . Benedictis , S . Faralli , and R . Navigli . Glossboot : Bootstrapping multilingual domain glossaries from the web . In ACL , 2013 . [ 6 ] K . Bollacker , C . Evans , P . Paritosh , T . Sturge , and J . Taylor .
Freebase : a collaboratively created graph database for structuring human knowledge . In SIGMOD , 2008 .
[ 7 ] A . Carlson , J . Betteridge , B . Kisiel , B . Settles , E . R . H . Jr . , and T . M . Mitchell . Toward an architecture for never ending language learning . In AAAI , 2010 .
[ 8 ] D . Carmel , M W Chang , E . Gabrilovich , B J P . Hsu , and K . Wang . ERD 2014 : Entity recognition and disambiguation challenge . SIGIR Forum , 2014 ( forthcoming ) .
[ 9 ] N . Choi , I Y Song , and H . Han . A survey on ontology mapping .
SIGMOD , 2006 .
[ 10 ] J . Dalton , L . Dietz , and J . Allan . Entity query feature expansion using knowledge base links .
[ 11 ] B . Dalvi , W . W . Cohen , and J . Callan . Classifying entities into an incomplete ontology . In AKBC , 2013 .
[ 12 ] B . Dalvi , W . W . Cohen , and J . Callan . Exploratory learning . In
ECML , 2013 .
[ 13 ] B . Dalvi , C . Xiong , and J . Callan . A language modeling approach to entity recognition and disambiguation for search queries . In ERD , Entity Recognition and Disambiguation Challenge at SIGIR , 2014 .
[ 14 ] W . Duan and A . Yates . Extracting glosses to disambiguate word senses . In NAACL HLT , 2010 .
[ 15 ] R E Fan , K W Chang , C J Hsieh , X R Wang , and C J Lin . Liblinear : A library for large linear classification . JMLR , 2008 .
[ 16 ] S . Faralli and R . Navigli . A new minimally supervised framework for domain word sense disambiguation . In EMNLP CONLL , 2012 .
[ 17 ] C . Fellbaum . WordNet : An Electronic Lexical Database . MIT Press ,
1998 .
[ 18 ] H . Hajishirzi , L . Zilles , D . S . Weld , and L . Zettlemoyer . Joint coreference resolution and named entity linking with multi pass sieves . In EMNLP , 2010 .
[ 19 ] X . Han , L . Sun , and J . Zhao . Collective entity linking in web text : a graph based method . In SIGIR , 2011 .
[ 20 ] H . Ji , R . Grishman , and H . T . Dang . Overview of the tac2011 knowledge base population track . In TAC .
[ 21 ] A . Kilgarriff and J . Rosenzweig . English senseval:report and results .
In LREC , 2000 .
[ 22 ] J . Krishnamurthy and T . M . Mitchell . Which noun phrases denote which concepts ? In NAACL HLT , 2011 .
[ 23 ] M . Lesk . Automatic sense disambiguation using machine readable dictionaries : how to tell a pine cone from an ice cream cone . In International conference on Systems documentation , 1986 .
[ 24 ] T . Lin , O . Etzioni , et al . Entity linking at web scale . In AKBC , 2012 . [ 25 ] C . D . Manning , M . Surdeanu , J . Bauer , J . Finkel , S . J . Bethard , and D . McClosky . The Stanford CoreNLP natural language processing toolkit . In ACL demo , 2014 .
[ 26 ] D . Martinez , O . L . de Lacalle , and E . Agirre . On the use of automatically acquired examples for all nouns word sense disambiguation . JAIR , 2008 .
[ 27 ] P . N . Mendes , M . Jakob , and C . Bizer . Dbpedia : A multilingual cross domain knowledge base . In LREC , 2012 .
[ 28 ] G . A . Miller . Wordnet : a lexical database for english .
Communications of the ACM , 1995 .
[ 29 ] T . Mitchell . Nell : Never ending language learning . http://rtwmlcmuedu/rtw/
[ 30 ] A . Moro , A . Raganato , and R . Navigli . Entity linking meets word sense disambiguation : a unified approach . TACL , 2014 .
[ 31 ] D . Movshovitz Attias and W . W . Cohen . Alignment hmm based extraction of abbreviations from biomedical text . In BioNLP workshop . NAACL , 2012 .
[ 32 ] N . Nakashole , M . Theobald , and G . Weikum . Scalable knowledge harvesting with high precision and high recall . In WSDM , 2011 .
[ 33 ] N . Nakashole , T . Tylenda , and G . Weikum . Fine grained semantic typing of emerging entities . ACL , 2013 .
[ 34 ] R . Navigli . Word sense disambiguation : A survey . ACM Computing
Surveys , 41(2 ) , 2009 .
[ 35 ] K . Nigam , A . McCallum , S . Thrun , and T . Mitchell . Text classification from labeled and unlabeled documents using em . Machine learning , 2000 .
[ 36 ] M . T . Pilehvar and R . Navigli . A robust approach to aligning heterogeneous lexical resources . In ACL , 2014 .
[ 37 ] S . P . Ponzetto and R . Navigli . Knowledge rich word sense disambiguation rivaling supervised systems . In ACL , 2010 .
[ 38 ] F . M . Suchanek , G . Kasneci , and G . Weikum . Yago : a core of semantic knowledge . In WWW , 2007 .
[ 39 ] P . Talukdar and K . Crammer . New regularized algorithms for transductive learning . In ECML PKDD . 2009 .
[ 40 ] P . P . Talukdar . Graph based weakly supervised methods for information extraction & integration . 2010 .
[ 41 ] C . Wang , K . Chakrabarti , T . Cheng , and S . Chaudhuri . Targeted disambiguation of ad hoc , homogeneous sets of named entities . In WWW , 2012 .
[ 42 ] R . C . Wang and W . W . Cohen . Character level analysis of semi structured documents for set expansion . In EMNLP , 2009 .
[ 43 ] D . Wijaya , P . P . Talukdar , and T . Mitchell . Pidgin : ontology alignment using web text as interlingua . In CIKM , 2013 .
[ 44 ] C . Xiong and J . Callan . Query expansion with Freebase . In Under review , 2014 .
[ 45 ] A . Yates , M . Cafarella , M . Banko , O . Etzioni , M . Broadhead , and
S . Soderland . Textrunner : open information extraction on the web . In NAACL HLT demo , 2007 .
[ 46 ] M . Yu , S . Wang , C . Zhu , and T . Zhao . Semi supervised learning for word sense disambiguation using parallel corpora . In FSKD , 2011 .
