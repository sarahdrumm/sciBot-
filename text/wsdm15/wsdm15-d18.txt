Finding Subgraphs with Maximum Total Density and Limited Overlap
Oana Denisa Balalau∗ Institut Mines Telecom ,
Telecom Paristech , CNRS oanabalalau@telecom paristechfr
Francesco Bonchi
Yahoo Labs
Barcelona , Spain bonchi@yahoo inc.com
T H . Hubert Chan†
Dept . of Computer Science The University of Hong Kong hubert@cshkuhk
Francesco Gullo
Yahoo Labs
Barcelona , Spain gullo@yahoo inc.com
ABSTRACT Finding dense subgraphs in large graphs is a key primitive in a variety of real world application domains , encompassing social network analytics , event detection , biology , and finance . In most such applications , one typically aims at finding several ( possibly overlapping ) dense subgraphs which might correspond to communities in social networks or interesting events . While a large amount of work is devoted to finding a single densest subgraph , perhaps surprisingly , the problem of finding several dense subgraphs with limited overlap has not been studied in a principled way , to the best of our knowledge . In this work we define and study a natural generalization of the densest subgraph problem , where the main goal is to find at most k subgraphs with maximum total aggregate density , while satisfying an upper bound on the pairwise Jaccard coefficient between the sets of nodes of the subgraphs . After showing that such a problem is NP Hard , we devise an efficient algorithm that comes with provable guarantees in some cases of interest , as well as , an efficient practical heuristic . Our extensive evaluation on large realworld graphs confirms the efficiency and effectiveness of our algorithms .
1 .
INTRODUCTION
Finding dense subgraphs in large graphs has emerged as a key primitive in a variety of real world application domains [ 19 ] , ranging from biology [ 13 , 18 ] to finance [ 12 ] . In the Web domain , Gibson et al . [ 14 ] have observed that dense subgraphs might correspond to thematic group of pages or ∗Partially funded by a Google Faculty Research Award . †Partially funded by France/HK Grant : F HK31/11T and Hong Kong RGC HKU17200214E . ‡Partially funded by a Google Faculty Research Award and the France/HK PHC Procore 2012 grant 26893QA .
Mauro Sozio‡
Institut Mines Telecom ,
Telecom Paristech , CNRS sozio@telecom paristech.fr spam link farms . In the context of social networks , finding dense subgraphs has been employed for organizing social events and community detection [ 21 ] , as well as for expert team formation [ 23 , 8 ] . Angel et al . [ 2 ] have shown how finding dense subgraphs in the entity co occurrence graph constructed from micro blogging streams can be used to automatically detect important events .
Many of the aforementioned applications ask for finding several ( possibly overlapping ) dense subgraphs , which might correspond to communities in social networks or important events . Perhaps surprisingly , such a problem has not been studied in a principled way to the best of our knowledge . In this work we aim at filling this gap .
In a first attempt to give a formal definition for such a problem , one could aim at finding at most k subgraphs with maximum aggregate total density . However , it turns out that such a formulation might lead to find several subgraphs being very similar between each other and in particular sharing a large fraction of nodes of a relatively dense subgraph . Such a solution is not really interesting as the dense subgraphs to be found should ideally exhibit some appreciable degree of diversity among each other . Therefore , we enforce an upper bound on the pairwise Jaccard coefficient between the sets of nodes of the subgraphs .
Several definitions of density have been studied in the literature , among which the average degree density stands outs as a natural and widely used definition . Subgraphs with maximum average degree density are usually referred to as densest subgraphs . One appealing feature of such a definition is that densest subgraphs can be found in polynomial time using the linear programming ( LP ) algorithm presented in [ 9 ] or the maximum flow algorithm in [ 15 ] , while there are efficient algorithms which come with provable approximation guarantees [ 9 ] . In our work we focus on the average degree density .
A natural heuristic for our main problem is the following one : Greedily find one densest subgraph in the current graph , remove all its vertices and edges , and iterate until k subgraphs are found or the current graph is empty ( see eg , [ 23] ) . This heuristic , although reasonable , might potentially deliver arbitrarily bad solutions in terms of our objective function , as we show in the remainder . Another observation is that such an approach would produce subgraphs which are pairwise disjoint . By allowing some limited amount of overlap , one could find more interesting ( ie , denser ) solutions , while maintaining enough diversity among the subgraphs extracted . Another drawback of the previous heuristic is that algorithms for finding densest subgraphs ( based on linear programming and maximum flow ) cannot cope with large graphs containing millions of edges .
In our work we present an efficient algorithm for our problem which comes with provable guarantees in some cases of interest . We introduce the concept of minimality of a densest subgraph , ( roughly speaking a densest subgraph is minimal if it does not contain any other densest subgraph ) and develop efficient algorithms for finding minimal densest subgraphs , which will be pivotal in solving our main problem . Our algorithm for finding minimal densest subgraphs turns out to be the fastest known algorithm for the exact computation of a densest subgraph as it can handle large graphs containing up to 10 million edges , as shown by our experimental evaluation . We finally devise an efficient heuristic so to find subgraphs with limited overlap on even larger input graphs .
More in detail , the contributions of this paper are sum marized as follows :
• We define the ( k , α) Dense Subgraph with Limited Overlap problem ( (k , α) DSLO ) : given an integer k > 0 as well as a real number α ∈ [ 0 , 1 ] , find at most k subgraphs that maximize the total aggregate density , ie , the sum of the average degree of each subgraph , under the constraint that the the maximum pairwise Jaccard coefficient between the set of nodes in the subgraphs be at most α . We prove that ( k , α)–DSLO is NP hard even when α = 0 ( disjoint subgraphs ) .
• We improve the LP based approach by Charikar [ 9 ] , thus achieving the fastest known exact algorithm for the densest subgraph problem . Our algorithm has the desirable property of producing minimal densest subgraphs and use our fast LP solver as a subroutine . In particular , we prove that the number of calls to an LP solver is logarithmic in the number of nodes with high probability . This allows us to deal with large realworld graphs .
• We devise an algorithm ( MinAndRemove ) for the ( k , α) DSLO problem . We prove that , in the case the input graph contains k disjoint densest subgraphs , our algorithm is guaranteed to find an optimum solution for ( k , α) DSLO . In the general case , we show empirically that our algorithm can find solutions that are very close to an optimum solution of our problem .
• We present a fast heuristic ( FastDSLO ) for ( k , α )
DSLO which , albeit less accurate than MinAndRemove , is able to find dense subgraphs with limited overlap on even larger graphs ( containing up to 100 million edges ) .
In Section 2 we discuss the related work , while in Section 3 we define our main problem formally and prove its NP hardness . All our algorithms are presented in Section 4 , while Section 5 contains an experimental evaluation on large real world graphs . Finally , in Section 6 we draw our conclusions and discuss interesting directions for future work .
2 . RELATED WORK
Finding a single densest subgraph . The problem of finding a dense subgraph from a large input graph has been widely studied [ 19 ] . Generally speaking , such a problem aims at finding a subgraph of a given input graph that maximizes some notion of density . A density notion widely employed in the literature is the average degree . Due to its popularity , the corresponding problem of finding a subgraph that maximizes the average degree has been commonly referred to as the densest subgraph problem . The densest subgraph can be identified in polynomial time by solving a parametric maximum flow problem [ 15 ] . Charikar [ 9 ] introduces a linear programming formulation of the problem , while also showing that the greedy algorithm proposed by 2 approximation in linear Asashiro et al . time . The densest subgraph problem has also been studied in a streaming context [ 6 ] .
[ 5 ] produces a 1
A more difficult variant of the densest subgraph problem is the so called DkS problem , which consists of finding a densest subgraph of k vertices . Such a problem is known to be NP hard [ 4 ] , while an algorithm with approximation guarantee of O(n 1 4 ) has been presented in [ 7 ] . It is also well known that there cannot be any PTAS for the DkS problem under reasonable complexity assumptions [ 16 ] . Some variants of the DkS problem are introduced by Andersen and Chellapilla [ 1 ] and further investigated in [ 17 ] .
A number of works depart from the classic average degree maximization problem and focus on extracting a subgraph maximizing other notions of density . Tsourakakis et al . [ 23 ] resort to the notion of quasi clique to define an alternative measure of density , while Wang et al . [ 25 ] focus on a density based on triangle counting . Sozio et al . [ 21 ] focus on minimum degree density while enforcing so called monotone constraints .
Finding multiple densest subgraphs . Unlike its singlesubgraph counterpart , the problem of finding a set of k dense subgraphs has received considerably less attention . Few authors [ 24 , 23 ] have discussed it , without providing any rigorous formulation of the problem . Instead they consider the most obvious heuristic that iteratively finds and removes the densest subgraph until k subgraphs have been found . In our work , we precisely formulate and characterize the problem of finding at most k disjoint subgraphs that maximize the sum of densities , while also showing , both theoretically and empirically , that the aforementioned simple heuristic is not well suited for such a problem .
Apart from that , existing research has considered tangentially related problems , such as finding nested subgraphs containing a set of query nodes and exhibiting non increasing densities [ 22 ] , discovering overlapping dense subgraphs containing a query node [ 11 ] , or extracting all large enough dense bipartite subgraphs in massive graphs [ 14 ] . Furthermore , Angel et al . [ 3 ] focus on maintaining the set of all ( possibly overlapping ) subgraphs exceeding a density threshold under streaming edge weight updates . Chen and Saad [ 10 ] instead propose a matrix blocking model to identify dense subgraphs that best cover the input graph . Particularly , the latter problem differs from ours as it aims at finding a set of dense subgraphs that cover most of the input graph , while discarding outlier ( ie , non dense ) graph zones , but it does not attempt at maximizing the sum of the densities of k subgraphs .
3 . DEFINITION AND COMPLEXITY
In this section , we define our problem formally and we study its computational complexity .
Given an undirected graph G = ( V , E ) , we define its den|E| sity ρ(G ) to be |V | , which corresponds to half the average degree of the nodes in G . For a set of vertices S ⊆ V , we denote the subgraph of G induced by S as G(S ) = ( S , E(S) ) , where E(S ) = {{u , v} ∈ E|u , v ∈ S} ) .
In a first attempt to give a formal definition for our problem , one could aim at finding at most k subgraphs with maximum aggregate total density . However , it turns out that such a formulation might lead to find several subgraphs being very similar between each other and in particular sharing a large fraction of nodes of a relatively dense subgraph . Such a solution is not really interesting as the dense subgraphs to be found should ideally exhibit some appreciable degree of diversity among each other . Therefore , we enforce an upper bound α ∈ [ 0 , 1 ] on the pairwise Jaccard coefficient between the sets of nodes of the subgraphs , with one indicating that the two subgraphs contain exactly the same nodes and zero indicating that they are disjoint . Our problem can then be formalized as follows .
Definition 3.1 ( (k , α) DSLO ) Given an undirected graph G = ( V , E ) , an integer k > 0 , as well as a rational number α ∈ [ 0 , 1 ] , find a set of sets of vertices S = {S1 , . . . , S¯k} with ¯k ≤ k , and Si ⊆ V,∀Si ∈ S , such that
¯k
ρ(G(Si) ) ) is maximum , and i=1
|Si ∩ Sj| |Si ∪ Sj| ≤ α ∀Si , Sj ∈ S .
( 1 )
Theorem 3.1 ( k , α) DSLO is NP hard . sum of densitiesk
We prove NP hardness by reducing the well known maximum independent set problem to a special case of ( k , α)DSLO ie , to case where α = 0 . Particularly , we show that given a graph G and a positive integer k , it is NP hard to find k disjoint subsets S1 , S2 , . . . , Sk of nodes such that the i=1 ρ(Si ) is maximized . In particular , we consider a decisional version of the problem , in which we are given a target τ , and the problem is to decide if there are k disjoint subsets whose sum of densities is at least τ .
Our hardness proof reduces from the NP hardness of maxIn imum independent set on degree bounded graphs [ 20 ] . particular , for any fixed ∆ ≥ 3 , given a graph G with maximum degree at most ∆ and an integer k , it is NP hard to decide if G contains an independent set with size k . Reduction Construction . Given an instance G = ( V , E ) of the maximum independent set problem with maximum degree at most ∆ , we construct a graph G and select a iff G contains k disjoint subsets whose sum of densities is threshold τ such that G has an independent set of size k at least τ . Node Gadget . We choose some N = n4 , where n = |V | . Given a node u , we create a gadget graph Gu as follows . Let Cu be a set of N independent nodes , which forms the core of Gu . Let Au be a set ∆ independent nodes , which are the arms of Gu . The graph Gu is a complete bipartite graph between Cu and Au , and so contains N ∆ edges .
Before we state our threshold τ , we consider the densities
2 , then S must contain all the arms Au of some u . most ∆ . Moreover , if the density of a subset S is at least ∆ − 1
Interaction between Node Gadgets . For distinct nodes u and If {u , v} /∈ E , v in V , the cores Cu and Cv are disjoint . then Au and Av are disjoint ; but if {u , v} ∈ E , then |Au ∩ Av| = 1 , ie , the two gadgets Gu and Gv share exactly one arm . Moreover , each arm node can be shared by at most 2 gadget graphs . Since G has degree at most ∆ , each arm of a gadget graph can be potentially used to connect with another gadget according to G . This completes the description of graph G . of subgraphs in G . Lemma 3.1 The density of any subset of nodes in G is at Suppose S is a subset of nodes in G that intersects the cores
Proof . The result follows from the following statement . of some r gadgets . Suppose for some D > 0 , for each i ∈ [ r ] , S contains di arm nodes of gadget graph Gi , where di ≤ D . ( Observe that each arm node can belong to more than one gadget graph Gi . ) Then , we show that the density of S is at most D . For i ∈ [ r ] , suppose S contains ni nodes from the core Ci of gadget graph Gi . The total number of edges induced by S i∈[r ] nidi . If none of the Gi ’s share an arm , the number i∈[r](ni + di ) . Observe that for each pair of Gi ’s that share an arm , the number of nodes decreases by 1 . Since each Gi can share arms with at most di other gadgets , the maximum number of pairs that can share an arm is is of nodes in S is i∈[r ] di
=
Therefore , the density of S is at most i∈[r](ni + di)− ≤ maxi∈[r ] nidi di 2 ni+ i∈[r ] di
2
≤ N D
N + D 2 i∈[r](ni + di
2 ) .
, where the last inequality follows because the expression nidi di ni+ 2 is increasing
2
.
Hence , |S| ≥ i∈[r ] nidi di 2 ) i∈[r](ni+ in both ni and di .
Finally , observing that N D N + D 2 the statement .
≤ D , we finish the proof of
The following lemma completes the reduction proof .
Lemma 3.2 The graph G ( with maximum degree at most
∆ ) contains an independent set of size k iff the graph G contains k disjoint subsets whose sum of densities is at least τ = k∆ − 1 n .
N +∆ ≥ ∆ − 1
Proof . The forward direction is easy because each point in the independent set corresponds to a disjoint gadget graph , which has density ∆N n2 , because ∆ < n and N = n4 . Hence , the sum of the densities of the k disjoint gadget graphs is at least k∆ − 1 n . disjoint subsets Si ’s in G must have density at least ∆ − 1 For the backward direction , observe that each of the k 2 . Otherwise , there exists k − 1 disjoint subsets whose sum of implies that there exists a subset in G with density strictly n > ( k − 1)∆ . This densities is at least ( k − 1)∆ + 1
2 − 1 larger than ∆ , which is impossible by Lemma 31 Hence , we conclude that each of k disjoint subsets Si ’s must have density at least ∆− 1 2 , which implies by Lemma 3.1 that each Si must contain all the arms of some core Au for some u ∈ V . This means the k subsets Si ’s correspond to k independent nodes in G .
Figure 1 : A graph G where Naive gives poor results . Notice that G is a non minimal densest subgraph .
4 . ALGORITHMS
As ( k , α) DSLO is NP Hard , we devise heuristics that work well in practice while also exhibiting provable guarantees in some cases of interest . We start by considering one natural heuristic for the disjoint case ( α = 0 ) : at each step , we compute the densest subgraph in the current graph ( using for example the approach in [ 9] ) , we remove all its nodes and edges from the current graph , iterating until we find exactly k subgraphs or until the current graph contains no edges . We hereinafter refer to this heuristic as Naive .
This simple heuristic gives unfortunately very poor results in the worst case , as illustrated in Figure 1 . In that example the density ρ(G ) of the graph is 2 ( there are 10k + 4(k − 1 ) edges and 5k + 2(k − 1 ) nodes ) , like every subgraph Gi of G . Naive would find the whole graph G and then would stop giving a solution with total density equal to 2 , while an optimum solution to our problem is composed of the disjoint subgraphs G1 , . . . , Gk with total density equal to 2k . This highlights one of the limitations of Naive and paves the way to the definition of minimal dense graphs .
Definition 4.1 ( Minimal dense graphs ) An undirected graph G with density ρ(G ) is a minimal dense graph if for any proper subgraph H of G , ρ(H ) < ρ(G ) . Moreover , we say that G is a minimal densest subgraph if it is minimal and has maximum density .
Notice that the graph G in Figure 1 is a non minimal densest subgraph .
Finding minimal dense graphs plays an important role in solving our problem , as illustrated by the following variant of Naive . At each step we compute a minimal densest subgraph , we remove its nodes and edges from the current graph , and we iterate until k subgraphs are found or there are no edges left in the current graph . Including at each step a minimal dense subgraph H , rather than a supergraph G of H , would not decrease the total density of our solution ( as H is as dense as G ) and might actually increase it , as fewer edges are removed from the current graph after including H in the solution . It turns out that this simple variant of Naive , finds k disjoint densest subgraphs , if they exist . This is proved in Section 42 In Section 4.1 , we show how to efficiently compute minimal densest subgraphs .
Drawing inspiration from the techniques developed for computing minimal densest subgraphs , we then address the ( k , α) DSLO problem . The main challenge here is to take full advantage of the overlap between subgraphs so to maximize our objective function . Computing minimal subgraphs is desirable also in this case , in order to minimize the number of edges that are removed at each step . This is discussed in Section 42 In Section 5 , we perform an extensive evaluation of our algorithms showing the effectiveness of our heuristics for ( k , α) DSLO on large real world graphs and that minimal densest subgraphs can be computed efficiently on large graphs containing millions of edges . 4.1 Finding Minimal Densest Subgraphs
Our algorithm for computing minimal densest subgraphs is inspired by the linear programming ( LP) based algorithm for the densest subgraph developed by Charikar [ 9 ] . In order to have some provable guarantees for our problem , we need to dive deeper into the structure of the solutions of the LP . We start by recalling the algorithm in [ 9 ] .
Given a graph G = ( V , E ) , Charikar [ 9 ] proposed the following LP formulation for the densest subgraph problem . For each edge ij ∈ E we introduce a variable xij taking values in [ 0 , 1 ] , while for each node v we introduce variable xv ( taking values in [ 0 , 1] ) . We have the following linear program : max xij
( BasicLP ) ij∈E st xij ≤ yi xij ≤ yj yi ≤ 1 i∈V xij , yi ≥ 0
∀ij ∈ E ∀ij ∈ E
∀i , j .
( 2 )
( 3 )
( 4 )
( 5 )
To gain an intuition about the above LP , consider a densest subgraph H = ( S , E(S) ) , S ⊆ V . We can then define a feasible solution zS = ( xS , yS ) for BasicLP as follows :
1|S| 1|S|
0
0 xS ij = yS i = if both i , j ∈ S otherwise . if i ∈ S otherwise .
|S|
|E(S)|
Recall that the density of the subgraph H = ( S , E(S ) ) is . Observe that zS is feasible defined as ρ(H ) = ρ(S ) = for the basic LP , and has objective value ρ(S ) . Vice versa , given an optimum solution zS = ( xS , yS ) for BasicLP , one can construct an optimum solution for the densest subgraph problem using the rounding algorithm described in [ 9 ] : We first order the yS i ’s by non increasing order . Let y1 , . . . , yn be the variables so ordered . We then find the prefix y1 , . . . , yk in such ordering whose corresponding induced subgraph H achieves maximum density , for any value of k in [ 2 , n ] . It can be proved that H is a densest subgraph .
One can then solve BasicLP using efficient LP solvers such as Gurobi or CPLEX and then compute the densest subgraph by running the algorithm described above . In the rest of this section , we present a more efficient algorithm for computing the densest subgraph , which allows us to deal with large real world graphs containing millions of edges . The latter algorithm uses the following fact .
Lemma 4.1 Each optimal solution of BasicLP is a convex combination of points in {zS : S ⊆ V , S is densest subgraph} . Proof . Suppose z∗ = ( x∗ , y∗ ) is an optimal solution . Then , since the objective value to be maximized is the sum of all xij ’s , it follows that if z∗ is optimal , it must be the case i = 1 , and for all ij ∈ E , x∗ ij = min{y∗ j } . i , y∗ that i∈V y∗
We prove the result by induction on the number k of nonzero coordinates of y∗ . If E contains at least one edge , it i = y∗ j = 1
2 , the result follows . ij = min{y∗ i , y∗ if both i , j ∈ S otherwise . if i ∈ S otherwise . follows that k ≥ 2 . For the base case k = 2 , suppose {i , j} j } is maximized is the support of y∗ . Since x∗ when y∗ For the inductive step , suppose y∗ has k > 2 non zero coordinates corresponding to some subset S ⊆ V , where k = |S| . If all the non zero y∗ i ’s are the same for i ∈ S , then it follows that z∗ = zS , and the result follows ; otherwise , let α := min{y∗ i : i ∈ S} . Observe that kα ≤ 1 . ij−α 1−kα 0 i −α 1−kα 0
Define z = ( x,y ) as follows . x∗ xij = y∗ yi = Hence , z∗ = kα·zS +(1−kα)z , and the number of non zero coordinates of y is strictly less than k . Hence , to complete the inductive step , it suffices to show that z is an optimal kα · p(zS ) + ( 1 − kα)p(z ) , it is enough to show that z is feasible , because if p(z ) < p(z∗ ) , it must be the case that To check the feasibility ofz , we have for ij ∈ E(S),xij = Moreover , i∈V yi = cause i = 1 . Therefore , z is feasible and this com p(zS ) > p(z∗ ) , which violates the optimality of z∗ . x∗ ij−α 1−kα =
= min{yi,yj} .
Observe that since the objective function is linear , p(z∗ ) = i∈S y∗ 1−kα solution to the basic LP . min{y∗ i ,y∗ 1−kα j }−α y∗ i −α 1−kα = i∈S i −kα
= 1 , be i∈S y∗ pletes the inductive step .
The following corollary follows from Lemma 41
Corollary 4.1 Suppose S1 , S2 both induce densest subgraphs in V . Then , both S1 ∩ S2 and S1 ∪ S2 induce densest subgraphs in V .
Another interesting consequence of Lemma 4.1 is that we can find a densest subgraph by first solving BasicLP , and then returning the subgraph consisting of all nodes whose corresponding variables have values strictly larger than zero in our solution .
We now focus on computing a minimal densest subgraph H of a graph G given in input . We recall that any ( proper ) subgraph of H must have density strictly smaller than H .
As we shall use an LP based approach to find a densest subgraphs , we start by showing how to speed up the LPbased algorithm presented in [ 9 ] . As proved in Lemma 4.1 , the subgraph induced by variables with maximum value in an optimum solution for BasicLP is a densest subgraph . Starting from a solution for BasicLP we can then derive a densest subgraph in O(n ) , in contrast with the rounding algorithm described in [ 9 ] , which requires Ω(n log n + m ) operations , where n , m are the number of nodes and edges in G , respectively . To the best of our knowledge , this fact was not known before . We shall refer to this more efficient algorithm for the densest subgraph as FastLP .
Our algorithm for finding minimal dense subgraphs employs two subroutines : TryRemove and TryEnhance . The former one takes as input a graph G and a node u and checks whether u can be removed from G without decreasing its density . This is done by computing a densest subgraph in the input graph ( V \{u} , E ) and checking whether the density drops . If this is not the case , u can be removed from G . A pseudocode for TryRemove is shown in Algorithm 1 .
Algorithm 1 TryRemove(u , G ) 1 : Input : A graph G = ( V , E ) and a node u to be removed . 2 : Output : Returns a densest subgraph in G not containing u , or null if every densest subgraph in G must contain u . 3 : Solve the BasicLP with input ( V \ {u} , E ) and run FastLP to find a densest subgraph H in ( V \ {u} , E ) . 4 : if ρ(H ) ≥ ρ(G ) then 5 : 6 : else 7 : 8 : end if return null return H
We could then compute H by iterating through all nodes and checking for each such a node whether it can be removed or not . This algorithm would not be efficient , in that , it requires to solve Θ(n ) LPs , one for each node of G . Therefore , we devise a much more efficient algorithm which requires to solve O(log n ) LPs , with high probability . Such an algorithm employs the subroutine TryEnhance , which receives in input a graph G , a node u , as well as density ρmax of a densest subgraph in G . It returns a densest subgraph in G which contains u while having smallest number of nodes ( or null in case there is no densest subgraph containing u ) .
This is achieved by solving a carefully defined LP whose objective is to maximize yu subject to the constraint that the density is equal to ρmax . The main intuition is that for each densest subgraph in G with S nodes there is a solution to the LP where variables have all values 1|S| . Therefore , by maximizing yu we can find a densest subgraph containing u with smallest number of nodes . This is proved in Lemma 4.2 and follows partially from Lemma 41 See Algorithm 2 for a pseudocode of TryEnhance .
Algorithm 2 TryEnhance(u , G , ρmax ) 1 : Input : a graph G = ( V , E ) , a node u ∈ V , the density
ρmax of the densest subgraph in G .
2 : Output : Returns a densest subgraph in G containing u with minimum cardinality or null if there is no densest subgraph containing u .
3 : Modify the basic LP by adding the constraint ij∈E xij = ρmax , maximizing the objective function yu ; solve the modified LP by running FastLP .
4 : If there is no feasible solution to the modified LP then return null .
5 : Run FastLP to find a densest subgraph H = ( ¯V , ¯E ) starting from the LP solution .
6 : return H
Lemma 4.2 Given a graph G = ( V , E ) and a node u ∈ V , the subroutine TryEnhance returns a densest subgraph in G containing u with the smallest number of nodes .
Proof . The smallest densest subgraph containing u is unique , because by Corollary 4.1 , the intersection of all densest subgraphs containing u is also a densest subgraph .
Consider the optimal solution z = ( x , y ) computed from the modified LP in the subroutine TryEnhance(u , G , ρmax ) . By Lemma 4.1 , z is a convex combination of zSi ’s , where each Si induces a densest subgraph in G . Since the objective is to maximize yu , and zS is a feasible solution , it follows that yu is positive , which means that at least one of the Si ’s must contain u . Since for each Si containing u , ySi u = 1|Si| , it follows that if z is a convex combination of more than one Si ’s , the value yu could be strictly improved by zS , where S is the intersection of all Si ’s containing u .
Hence , it follows that z = zS for some densest subgraph induced by S , which has to be the smallest densest subset containing u .
The main steps for finding efficiently a minimal densest subgraph are the following ones . At each iteration : 1 ) we pick one node u from our current graph , uniformly at random ; 2 ) we execute the subroutines TryRemove and TryEnhance with input u and our current graph ; 3 ) our current graph is then set to be the smallest subgraph among the ones returned by the previous subroutines . It turns out n iterations suffice to find a minimal densest subthat 2 log 4 3 graph , with high probability . This is proved in Corollary 4.3 , while Lemma 4.3 proves that our algorithm finds a minimal densest subgraph .
In order to speed up even further our algorithm , we include a preprocessing phase where we remove nodes not belonging to any densest subgraph . This is done as follows . We first run the linear time greedy algorithm presented by Charikar in [ 9 ] so to find a 2 approximation solution to the densest subgraph . Let ρapx be the density of the graphs so found . As noted in [ 17 ] , no nodes with degree smaller than the density of the densest subgraph belongs to any densest subgraph . Therefore , we can safely remove all nodes with degree smaller than ρapx from the input graph . A pseudocode of our algorithm is shown in Algorithm 3 .
Algorithm 3 FindMinimal(G ) 1 : Input : A graph G = ( V , E ) with n nodes . 2 : Output : A minimal densest subgraph in G . 3 : Run the greedy algorithm to find a 2 approximation solution for the densest subgraph . Let ρapx be the density of such a subgraph .
4 : Remove iteratively nodes with degree smaller than ρapx and let ¯G be the graphs so obtained .
5 : Find a densest subgraph H = ( ¯V , ¯E ) in ¯G by running
FastLP . Let ρmax be its density .
6 : while ( true ) do 7 : 8 : 9 : 10 : 11 : let u be a node picked uniformly at random from ¯V let H1 := TryRemove(u , H ) let H2 := TryEnhance(u , H , ρmax ) IF H1 is null return H2 let H be the subgraph with minimum number of nodes between H1 and H2 , breaking ties arbitrarily
12 : H := H
13 : end while 14 : return H
Lemma 4.3 FindMinimal(G ) returns a minimal densest subgraph of G .
Proof . Algorithm 3 always terminates . After each iteration of the while loop , either TryRemove(u , H ) returns null and therefore the algorithm terminates or the node u is removed from the current graph . Hence , at each iteration the number of nodes of the current graph decreases by at least one . Observe that the graph H is always a densest subgraph , throughout the execution of the algorithm . When the algorithm terminates , it must be the case that
TryRemove(u , H ) returns null , for some node u in H . This means that every densest subgraph of H must contain u . By Lemma 4.2 , TryEnhance(u , H , ρmax ) returns the smallest densest subgraph containing u , and so it must be minimal .
We prove that O(log n ) iterations of the while loop of FindMinimal(G ) suffice to find a minimal densest subgraph in G . To this end , we show that at each iteration the number of nodes in the current subgraph decreases by a constant fraction with constant probability . A standard measure concentration argument concludes the proof . Let H = ( ¯V , ¯E ) be a densest subgraph of G . For a node u ∈ ¯V , > 0 , we say that u is bad in H = ( ¯V , ¯E ) if both H1 := TryRemove(u , H ) and H2 := TryEnhance(u , H , ρmax ) contain more than ( 1− )| ¯V | nodes , and neither of them is null .
Lemma 4.4 Given a graph H = ( ¯V , ¯E ) with maximum density ρmax , the fraction of bad nodes in ¯V is at most 2 , for any > 0 .
Proof . For contradiction ’s sake , suppose the set B of bad nodes has size more than 2 | ¯V | . For each u ∈ B , define Au := ¯V \ TryRemove(u , H ) . Observe that u ∈ Au , and by the definition of bad , |Au| < | ¯V | . Consider an arbitrary order of B := {u1 , u2 , . . . ,} . Since B contains more than 2 | ¯V | points , and each |Au| < |¯v| , Observe that there exists u ∈ B \ ( ∪i j=1 Auj| < 2 | ¯V | . there exists a smallest i such that | ¯V | ≤ |∪i j=1Auj ) . Since for each j , TryRemove(uj , H ) is a densest subgraph , then by duces a densest subgraph that contains u and has size at Lemma 4.1 , ∩i j=1Auj ) inTryEnhance(u , H , ρmax ) will return a densest subgraph most ( 1 − )| ¯V | . Therefore , it follows that the algorithm u is bad . that has size at most ( 1 − )| ¯V | , thereby contradicting that j=1TryRemove(uj , H ) = ¯V \ ( ∪i
By taking = 1
4 in Lemma 4.4 , we have the following corollary .
Corollary 4.2 At each iteration of FindMinimal(G ) , the algorithm either terminates with a minimal densest subgraph , or with probability at least 1 at most 3
2 , the number of nodes in H is
4 · | ¯V | .
Corollary 4.3 By standard Chernoff bound , the number of iterations in FindMinimal(G ) is at most a constant times its mean , which is at most 2 log 4 n , where n is the number 3 of nodes in G .
Our algorithm FindMinimal(G ) allows us to compute minimal densest subgraphs in graphs containing millions of edges . In particular , the pruning step and the fact that we can bound the number of iterations by a logarithmic function allows us to save several order of magnitudes in terms of running time . 411 Finding All Minimal Densest Subgraphs Armed with an efficient algorithm for finding minimal densest subgraphs , we now present an algorithm that computes all such graphs . Our algorithm computes at each step a minimal densest subgraph by running Algorithm 3 , it removes all its nodes and edges from the current graph and
Algorithm 4 FindAllMinimal(V ) 1 : Input : Graph G = ( V , E ) . 2 : Output : Returns a list L of all minimal densest subgraphs . 3 : L := ∅ 4 : while ( true ) do 5 :
H = FindMinimal(G ) IF H is not a densest subgraph break ; L := L ∪ {H} remove all nodes and edges incident to H from G
6 : 7 : 8 : end while 9 : return L
Finally , we present a fast heuristic FastDSLO for finding dense subgraphs with limited overlap . Our heuristic computes at each step i a 2 approximation solution Gi to the densest subgraph problem using the greedy algorithm presented in [ 9 ] . Then , similarly to MinAndRemove ( cid:100)(1 − α)|Vi| nodes are removed from the current graph so to satisfy the requirement on the pairwise Jaccard coefficient . A pseudocode is shown in Algorithm 6 . Our experimental evaluation shows that although our heuristic is less accurate than MinAndRemove , it is still not too far from an optimum solution while it can handle graphs with more than 100 million edges within a few hours .
Algorithm 5 MinAndRemove(G , k , α ) 1 : Input : A graph G = ( V , E ) , an integer k > 0 , α ∈ [ 0 , 1 ] 2 : Output : A list L of at most k subgraphs of G , Gi = ( Vi , Ei ) , st the constraint on the pairwise Jaccard coefficient on the Vi ’s is not violated ( Equation ( 1) ) .
3 : L := ∅ 4 : while < k subgraphs are found and G is not empty do Find a minimal densest subgraph Gi = ( Vi , Ei ) of G 5 : by running Algorithm 3 L := L ∪ {Gi} For each node v in Vi , let ∆G(v ) be the set of neighbors of v in G . Remove the ( cid:100)(1 − α)|Vi| nodes with minimum value |∆H ( v ) \ Vi| and all their edges from G .
6 : 7 :
8 :
9 : end while 10 : return L
Algorithm 6 FastDSLO(G , k , α ) 1 : Input : A graph G = ( V , E ) , an integer k > 0 , α ∈ [ 0 , 1 ] 2 : Output : A list L of at most k subgraphs of G , Gi = ( Vi , Ei ) , st the constraint on the pairwise Jaccard coefficient on the Vi ’s is not violated ( Equation ( 1) ) .
3 : L := ∅ 4 : while < k subgraphs are found and G is not empty do Find a 2 approximation solution Gi = ( Vi , Ei ) to the 5 : densest subgraph problem by running the greedy algorithm in [ 9 ] . L := L ∪ {Gi} For each node v in Vi , let ∆G(v ) be the set of neighbors of v in G . Remove the ( cid:100)(1 − α)|Vi| nodes with minimum value |∆H ( v ) \ Vi| and all their edges from G .
6 : 7 :
8 :
9 : end while 10 : return L iterates until no densest subgraph can be found . A pseudocode is shown in Algorithm 4 .
Minimal densest subgraphs must be disjoint , for otherwise , their intersection would be a densest subgraph ( from Corollary 4.1 ) , which would contradict the fact that they are minimal . Lemma 4.5 then follows .
Lemma 4.5 Given an undirected graph G = ( V , E ) , our algorithm FindAllMinimal(V ) finds all minimal densest subgraphs in G . 4.2 Main Algorithms
Drawing inspiration from the theory and the techniques developed in the previous section for finding minimal densest subgraphs , we devise one algorithm for our main problem ( k , α) DSLO . In this case , we face the additional challenge of taking full advantage of the overlap between the subgraphs .
Our algorithm is inspired by FindMinimal and proceeds as follows . At each step i , we compute a minimal densest subgraph Gi = ( Vi , Ei ) of our current graph G = ( V , E ) and we remove ( cid:100)(1− α)|Vi| nodes ( and their edges ) from V . We remove those nodes that are not well connected with nodes outside Gi , as they will contribute less to the total density in the next steps of the algorithm . Formally , for any node v in Vi let ∆G(v ) be the set of neighbors of v in G . We remove the ( cid:100)(1−α)|Vi| nodes ( and their edges ) with minimum value |∆G(v ) \ Vi| . We iterate until k subgraphs are found or the current graph becomes empty . Observe that the constraint on the Jaccard coefficient is not violated . A pseudocode of our algorithm is shown in Algorithm 5 .
We can prove an interesting property of MinAndRemove . Observe that if there are k disjoint densest subgraphs in G then MinAndRemove would return the same solution of FindAllMinimal . Then , our main theorem follows from Lemma 45
Theorem 4.1 If there are k disjoint densest subgraphs in the input graph G , then MinAndRemove computes an optimum solution for ( k , α) DSLO , for any α ≥ 0 .
Although , we cannot give any guarantee for the general for any α ≥ 0 ) we show the efcase of ( k , α) DSLO ( ie fectiveness of our main algorithm in our experimental evaluation . In particular , we are able to derive an upper bound on any optimum solution for ( k , α) DSLO and show that MinAndRemove is very close to such an upper bound in our experiments ( up to a factor of 09 )
5 . EXPERIMENTS
We perform our experimental evaluation on a Linux server with Intel Xeon E7 4870 at 2.40GHz , while limiting the total amount of main memory available to 64 GB . We solve linear programs with the Gurobi Optimizer version 563 All our algorithms are implemented in Java .
We consider 8 datasets in total grouped according to their size1 . We ignore the direction of the edges in the directed graphs , as it is irrelevant to our purposes . Most of our experiments are conducted on the datasets that contain up to 11 million edges , as illustrated in Table 1 . We refer to this set of datasets as large datasets .
Name web Stanford com Youtube web Google Youtube growth As Skitter
1.9M Hyperlink network
Nodes Edges Description 281K 1.1M 3M 875K 3.2M 9.3M Social network 1.69M 11M Internet topology
Social network
4.3M Hyperlink network
Table 1 : Large real world datasets .
The second group of datasets consists of very large datasets containing up to more than 100 million edges where we evaluate our fast heuristic . In Table 2 we specify all the details for this group of datasets . We refer to this set of datasets as very large datasets .
Name Live Journal Hollywood 2009 Orkut
Nodes Edges Description 4.8M 43M Social network 1.1M 57M Social network 117M Social network 3M
Table 2 : Very large real world datasets .
We evaluate our algorithm MinAndRemove against two variants of the Naive algorithm . In the first variant we compute at each step a densest subgraph with the LP based approach proposed in [ 9 ] , we remove all its nodes and edges from the graph , and we iterate until k subgraphs have been found or the graph has become empty . We refer to this algorithm as NaiveDensest . In the second variant we compute at each step the 1 2 approximation algorithm proposed in [ 9 ] instead of a densest subgraph . We refer to this algorithm as NaiveGreedy . The reason to consider also this second variant is that the 1 2 approximation algorithm is much faster than the LP based optimal approach .
We tested NaiveDensest on the large datasets and it did not terminate after 16 hours of computation on any dataset . We also evaluated the maximum flow algorithm proposed in [ 15 ] , which turned out to be even slower . Therefore , in the rest of the experimental evaluation we focus on evaluating MinAndRemove against NaiveGreedy .
We start by measuring the total density when k = 10 , while varying α between 0.1 and 05 Let ρmax be the density of a densest subgraph in the input graph . Observe that k·ρmax gives us an upper bound on the value of any optimum solution for ( k , α) DSLO , for any value of α . Therefore , we can use such an upper bound to give an idea of how close our results are to an optimum solution . Given that we use only
1Sources : lawdiunimiit/datasetsphp snapstanfordedu , konectuni koblenzde , an upper bound , clearly , our results might be even closer to the actual optimum solution .
In Table 3 , we measure the ratio between the total density computed by our main algorithm and our upper bound , when k = 10 . We can see that in all cases our algorithm yields a solution that is at least within a factor of 0.44 of the value of an optimum solution , while in many cases it yields an approximation factor of 0.8 ( meaning that it reaches the 80 % of the upper bound on the optimum objective function value ) . We can also see that the quality of the solution increases as a function of α showing that our algorithm takes full advantage of the overlap between the subgraphs . This is not the case for one dataset only ( web − Google ) , however , we observe that the results are already very good for this dataset when α = 0.1 , making it harder to improve upon such a solution . We also recall that our upper bound might be loose and that we might have computed an optimum solution for such a dataset .
Next , we evaluate our algorithm MinAndRemove against NaiveGreedy , when k = 10 . Table 4 shows the ratio between the total density of the subgraphs found by our algorithm and those of NaiveGreedy . We can see that in most cases MinAndRemove yields a solution that is a factor of 1.5 larger than that of MinAndRemove , and always at least 10 % denser . We expect that the advantage of MinAndRemove against NaiveGreedy would be even more remarkable for larger values of k . Table 5 shows the total running time of our algorithm , which is always at most 3.2 hours , while in many cases is as less as 30 mins . We recall that instead the basic LP based approach by Charikar [ 9 ] could not terminate after 16 hours of computation on any of the selected datasets . On the other hand , as expected , NaiveGreedy is faster than our method . However , NaiveGreedy does not ensure optimality in finding the densest subgraph at each step , and this results in consistently less dense solutions .
In Table 6 , we set α = 0.3 and we measure the ratio between the density of MinAndRemove and an upper bound to any optimum solution as a function of k . We can see that when k is at most 4 our solution is very close to an optimum solution for ( k , α) DSLO ( up to a factor of 09 ) For larger values of k , our solution is still within a factor of 1/2 of an optimum solution or better . This might depend on the fact that our upper bound becomes loose when k is large .
We then evaluate the impact of computing at each step minimal densest subgraphs in MinAndRemove , as opposed to computing densest subgraphs . We perform the following experiment . Starting from the input graph , we remove at each step minimal densest subgraphs until the current graph is left with no edges . We then perform a similar experiment where at each step ( possibly non minimal ) densest subgraphs are removed from the current graph . Our experiments show ( which are omitted for lack of space ) that in the former case we gain a factor of 1 % ( on average ) in the total density , which is significant given that MinAndRemove might deliver near optimal solutions . We also observe that all our datasets contain at most one densest subgraph . This fact could not be verified prior to our work .
Our experimental evaluation shows that MinAndRemove can handle large graphs containing up to more than 10 million edges within 3 hours or less , while delivering nearoptimal solutions for our problem . For even larger graphs we resort to our fast heuristic which is evaluated on graphs k = 10 web Stanford com Youtube web Google Youtube growth As Skitter
α = 0.1 α = 0.2 α = 0.3 α = 0.4 α = 0.5 .717 .480 .808 .440 .585
.816 .623 .808 .579 .647
.790 .613 .808 .593 .625
.738 .521 .808 .467 .597
.767 .518 .808 .538 .599
Table 3 : Ratio between the density of MinAndRemove and our upper bound k = 10 web Stanford com Youtube web Google Youtube growth As Skitter
α = 0.1 α = 0.2 α = 0.3 α = 0.4 α = 0.5 1.469 1.192 1.595 1.2 1.125
1.671 1.547 1.595 1.578 1.244
1.512 1.293 1.595 1.271 1.147
1.570 1.287 1.595 1.467 1.151
1.617 1.522 1.595 1.617 1.202
Table 4 : Ratio between the density of MinAndRemove and NaiveGreedy k = 10 web Stanford com Youtube web Google Youtube growth As Skitter
α = 0.1 α = 0.2 α = 0.3 α = 0.4 α = 0.5 0.3h 0.54h 2.15h 1.5h 1.29h
0.21h 0.47h 2.73h 3.13h 1.78h
0.21h 0.54h 2.31h 1.74h 1.47h
0.21h 0.63h 2.31h 2.19h 2.85h
0.23h 0.55h 2.12h 1.8h 2.53h
Table 5 : Running time when varying α for MinAndRemove
α = 0.3 web Stanford com Youtube web Google Youtube growth As Skitter k = 2 .991 .840 .991 .845 .914 k = 4 .914 .744 .915 .738 .783 k = 6 .858 .638 .863 .664 .693 k = 8 .808 .570 .836 .593 .641 k = 10 .767 .518 .808 .538 .599
Table 6 : Ratio between the density of MinAndRemove and our upper bound containing up to more than 100 million edges . Similarly to the previous case , we can derive an upper bound on the optimum solution as a function of the densest subgraph found by our heuristic . Namely , let ρA be the density of the densest subgraph found by FastDSLO ( which we recall is a 2approximation for the densest subgraph problem ) . Then , 2k · ρA gives an upper bound to any optimum solution for ( k , α) DSLO .
In Table 7 , we set k = 10 while we measure the ratio between the density of FastDSLO and an upper bound to any optimum solution , as a function of α . Although our heuristic turns out to be less accurate than MinAndRemove it delivers solutions with an approximation factor of around 0.2 or more , while it can handle very large graphs with more than 100 million edges within a few hours . We also observe that our upper bound might be even looser in this case , as it is based on an approximation of the density of a densest subgraph . Table 8 show the running time of FastDSLO when k = 10 and α varies between 0.1 and 05 We can observe that the running time is around half an hour for the smaller datasets and does not exceed 2.3 hours on the largest dataset ( Orkut ) .
6 . CONCLUSIONS
This paper studies the problem of finding at most k subgraphs from a large graph given in input such that the to tal density be maximized , while satisfying a constraint on the pairwise Jaccard coefficient between the subgraphs . Although very natural , this variant of the densest subgraph problem has been surprisingly neglected so far .
After showing the NP hardness of this problem ( even when the subgraphs are disjoint ) , we develop an algorithm that computes an optimum solution for our problem in the case when there are k disjoint densest subgraphs in the input graph . Moreover , our experimental evaluation on large realworld graphs shows that our algorithm delivers near optimal solutions , in that , they are very close to an upper bound on any optimum solution .
We introduce the concept of minimality of densest subgraphs and develop efficient algorithms for finding minimal densest subgraphs , which play an important role in solving our main problem . It turns out that our algorithm for finding minimal densest subgraphs is the fastest known algorithm for the exact computation of a densest subgraph , as shown by our experimental evaluation . We presented an efficient heuristic for our problem which , albeit less accurate , can handle graphs containing up to 100 million edges .
We will devote our future investigation to devise even more scalable algorithms and to adapt our algorithm into a dynamic environment , where edges might be added to the current graph or removed . Another interesting direction is to determine whether finding minimal densest subgraphs can k = 10 LiveJournal Hollywood 2009 Orkut
α = 0.1 α = 0.2 α = 0.3 α = 0.4 α = 0.5 .244 .187 .187
.276 .231 .271
.285 .210 .249
.245 .190 .200
.251 .199 .218
Table 7 : Ratio between the density of FastDSLO and our upper bound k = 10 LiveJournal Hollywood 2009 Orkut
α = 0.1 α = 0.2 α = 0.3 α = 0.4 α = 0.5 0.56h 0.34h 1.97h
0.54h 0.34h 2.26h
0.54h 0.37h 2.16h
0.52h 0.3h 2.15h
0.63h 0.33h 1.2h
Table 8 : Running time of FastDSLO on very large datasets as a function of α be a valuable tool in finding interesting patterns in social networks and other real world graphs . large dense subgraphs in massive graphs . In VLDB , 2005 .
[ 15 ] A . V . Goldberg . Finding a maximum density subgraph . Technical report , University of California at Berkeley , 1984 .
[ 16 ] S . Khot . Ruling out PTAS for graph min bisection , dense k subgraph , and bipartite clique . J . Computing , 36(4 ) , 2006 .
[ 17 ] S . Khuller and B . Saha . On finding dense subgraphs .
In ICALP , 2009 .
[ 18 ] M . A . Langston and et al . A combinatorial approach to the analysis of differential gene expression data : The use of graph algorithms for disease prediction and screening . In Methods of Microarray Data Analysis IV . 2005 .
[ 19 ] V . E . Lee , N . Ruan , R . Jin , and C . C . Aggarwal . A survey of algorithms for dense subgraph discovery . In Managing and Mining Graph Data . 2010 . [ 20 ] C . H . Papadimitriou and M . Yannakakis .
Optimization , approximation , and complexity classes . J . Comput . Syst . Sci . , 43(3 ) , 1991 .
[ 21 ] M . Sozio and A . Gionis . The community search problem and how to plan a successful cocktail party . In KDD , pages 939–948 , 2010 .
[ 22 ] N . Tatti and A . Gionis . Discovering nested communities . In ECML/PKDD ( 2 ) , 2013 .
[ 23 ] C . Tsourakakis , F . Bonchi , A . Gionis , F . Gullo , and
M . Tsiarli . Denser than the densest subgraph : Extracting optimal quasi cliques with quality guarantees . In KDD , 2013 .
[ 24 ] E . Valari , M . Kontaki , and A . N . Papadopoulos .
Discovery of top k dense subgraphs in dynamic graph collections . In SSDBM , 2012 .
[ 25 ] N . Wang , J . Zhang , K L Tan , and A . K . H . Tung . On triangulation based dense neighborhood graph discovery . PVLDB , 4(2 ) , 2010 .
7 . REFERENCES
[ 1 ] R . Andersen and K . Chellapilla . Finding dense subgraphs with size bounds . In WAW , 2009 .
[ 2 ] A . Angel , N . Sarkas , N . Koudas , and D . Srivastava . Dense subgraph maintenance under streaming edge weight updates for real time story identification . PVLDB , 5(6 ) , 2012 .
[ 3 ] A . Angel , N . Sarkas , N . Koudas , and D . Srivastava . Dense subgraph maintenance under streaming edge weight updates for real time story identification . PVLDB , 5(6 ) , 2012 .
[ 4 ] Y . Asahiro , R . Hassin , and K . Iwama . Complexity of finding dense subgraphs . Discr . Ap . Math . , 121(1 3 ) , 2002 .
[ 5 ] Y . Asahiro , K . Iwama , H . Tamaki , and T . Tokuyama .
Greedily finding a dense subgraph . J . Algorithms , 34(2 ) , 2000 .
[ 6 ] B . Bahmani , R . Kumar , and S . Vassilvitskii . Densest subgraph in streaming and mapreduce . PVLDB , 5(5 ) , 2012 .
[ 7 ] A . Bhaskara , M . Charikar , E . Chlamtac , U . Feige , and
A . Vijayaraghavan . Detecting high log densities : an O(n1/4 ) approximation for densest k subgraph . In STOC , pages 201–210 , 2010 .
[ 8 ] F . Bonchi , F . Gullo , A . Kaltenbrunner , and
Y . Volkovich . Core decomposition of uncertain graphs . In KDD , 2014 .
[ 9 ] M . Charikar . Greedy approximation algorithms for finding dense components in a graph . In K . Jansen and S . Khuller , editors , APPROX . Springer , 2000 .
[ 10 ] J . Chen and Y . Saad . Dense subgraph extraction with application to community detection . TKDE , 24(7 ) , 2012 .
[ 11 ] W . Cui , Y . Xiao , H . Wang , Y . Lu , and W . Wang .
Online search of overlapping communities . In SIGMOD , 2013 .
[ 12 ] X . Du , R . Jin , L . Ding , V . E . Lee , and J . H . Thornton ,
Jr . Migration motif : a spatial temporal pattern mining approach for financial markets . In KDD , 2009 .
[ 13 ] E . Fratkin , B . T . Naughton , D . L . Brutlag , and
S . Batzoglou . MotifCut : regulatory motifs finding with maximum density subgraphs . In ISMB , 2006 .
[ 14 ] D . Gibson , R . Kumar , and A . Tomkins . Discovering
